{"title":"CodeKGC: Code Language Model for Generative Knowledge Graph Construction","abstract":"Current generative knowledge graph construction approaches usually fail to capture structural knowledge by simply flattening natural language into serialized texts or a specification language. However, large generative language model trained on structured data such as code has demonstrated impressive capability in understanding natural language for structural prediction and reasoning tasks. Intuitively, we address the task of generative knowledge graph construction with code language model: given a code-format natural language input, the target is to generate triples which can be represented as code completion tasks. Specifically, we develop schema-aware prompts that effectively utilize the semantic structure within the knowledge graph. As code inherently possesses structure, such as class and function definitions, it serves as a useful model for prior semantic structural knowledge. Furthermore, we employ a rationale-enhanced generation method to boost the performance. Rationales provide intermediate steps, thereby improving knowledge extraction abilities. Experimental results indicate that the proposed approach can obtain better performance on benchmark datasets compared with baselines. Code and datasets are available in https://github.com/zjunlp/DeepKE/tree/main/example/llm.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09048v1","tag":"prompt-eng"}}
{"title":"A study on Prompt Design, Advantages and Limitations of ChatGPT for Deep Learning Program Repair","abstract":"ChatGPT has revolutionized many research and industrial fields. ChatGPT has shown great potential in software engineering to boost various traditional tasks such as program repair, code understanding, and code generation. However, whether automatic program repair (APR) applies to deep learning (DL) programs is still unknown. DL programs, whose decision logic is not explicitly encoded in the source code, have posed unique challenges to APR. While to repair DL programs, an APR approach needs to not only parse the source code syntactically but also needs to understand the code intention. With the best prior work, the performance of fault localization is still far less than satisfactory (only about 30\\%). Therefore, in this paper, we explore ChatGPT's capability for DL program repair by asking three research questions. (1) Can ChatGPT debug DL programs effectively? (2) How can ChatGPT's repair performance be improved by prompting? (3) In which way can dialogue help facilitate the repair? On top of that, we categorize the common aspects useful for prompt design for DL program repair. Also, we propose various prompt templates to facilitate the performance and summarize the advantages and disadvantages of ChatGPT's abilities such as detecting bad code smell, code refactoring, and detecting API misuse/deprecation.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08191v1","tag":"prompt-eng"}}
{"title":"Low-code LLM: Visual Programming over LLMs","abstract":"Effectively utilizing LLMs for complex tasks is challenging, often involving a time-consuming and uncontrollable prompt engineering process. This paper introduces a novel human-LLM interaction framework, Low-code LLM. It incorporates six types of simple low-code visual programming interactions, all supported by clicking, dragging, or text editing, to achieve more controllable and stable responses. Through visual interaction with a graphical user interface, users can incorporate their ideas into the workflow without writing trivial prompts. The proposed Low-code LLM framework consists of a Planning LLM that designs a structured planning workflow for complex tasks, which can be correspondingly edited and confirmed by users through low-code visual programming operations, and an Executing LLM that generates responses following the user-confirmed workflow. We highlight three advantages of the low-code LLM: controllable generation results, user-friendly human-LLM interaction, and broadly applicable scenarios. We demonstrate its benefits using four typical applications. By introducing this approach, we aim to bridge the gap between humans and LLMs, enabling more effective and efficient utilization of LLMs for complex tasks. Our system will be soon publicly available at LowCodeLLM.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08103v1","tag":"prompt-eng"}}
{"title":"Constructing Effective In-Context Demonstration for Code Intelligence Tasks: An Empirical Study","abstract":"Pre-trained models of code have gained widespread popularity in many code intelligence tasks. Recently, with the scaling of the model and corpus size, large language models have shown the ability of in-context learning. These models employ task instructions and a few demonstration examples as prompts to learn the semantics of the task and make predictions for test samples. This new learning paradigm is training-free and has shown impressive performance in various natural language processing and code intelligence tasks. However, the performance of in-context learning heavily relies on the quality of demonstration, and there has been no systematic investigation into how to construct a good demonstration for code-related tasks with in-context learning.   In this paper, by analyzing the design space of in-context demonstration, we empirically explore the impact of three key factors on the performance of in-context learning in code intelligence tasks: the selection of demonstration examples, the order of demonstration examples, and the number of demonstration examples. We conduct extensive experiments on three code intelligence tasks including bug fixing, code summarization, and program synthesis. Our experimental results demonstrate that all the above three factors dramatically impact the performance of in-context learning in code intelligence tasks. Additionally, we summarize our findings and provide takeaway suggestions on how to construct effective demonstrations, taking into account these three perspectives. We show that a well-constructed demonstration can lead to significant improvements over simple demonstrations and previous fine-tuned state-of-the-art models, e.g., improving EM, BLEU-4, and EM by at least 11.91%, 36.88%, and 37.18% on code summarization, bug fixing and program synthesis, respectively.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07575v1","tag":"prompt-eng"}}
{"title":"Just Tell Me: Prompt Engineering in Business Process Management","abstract":"GPT-3 and several other language models (LMs) can effectively address various natural language processing (NLP) tasks, including machine translation and text summarization. Recently, they have also been successfully employed in the business process management (BPM) domain, e.g., for predictive process monitoring and process extraction from text. This, however, typically requires fine-tuning the employed LM, which, among others, necessitates large amounts of suitable training data. A possible solution to this problem is the use of prompt engineering, which leverages pre-trained LMs without fine-tuning them. Recognizing this, we argue that prompt engineering can help bring the capabilities of LMs to BPM research. We use this position paper to develop a research agenda for the use of prompt engineering for BPM research by identifying the associated potentials and challenges.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07183v1","tag":"prompt-eng"}}
{"title":"DroidBot-GPT: GPT-powered UI Automation for Android","abstract":"This paper introduces DroidBot-GPT, a tool that utilizes GPT-like large language models (LLMs) to automate the interactions with Android mobile applications. Given a natural language description of a desired task, DroidBot-GPT can automatically generate and execute actions that navigate the app to complete the task. It works by translating the app GUI state information and the available actions on the smartphone screen to natural language prompts and asking the LLM to make a choice of actions. Since the LLM is typically trained on a large amount of data including the how-to manuals of diverse software applications, it has the ability to make reasonable choices of actions based on the provided information. We evaluate DroidBot-GPT with a self-created dataset that contains 33 tasks collected from 17 Android applications spanning 10 categories. It can successfully complete 39.39% of the tasks, and the average partial completion progress is about 66.76%. Given the fact that our method is fully unsupervised (no modification required from both the app and the LLM), we believe there is great potential to enhance automation performance with better app development paradigms and/or custom model training.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07061v1","tag":"prompt-eng"}}
{"title":"Prompt Engineering and Calibration for Zero-Shot Commonsense Reasoning","abstract":"Prompt engineering and calibration make large language models excel at reasoning tasks, including multiple choice commonsense reasoning. From a practical perspective, we investigate and evaluate these strategies on smaller language models. Through experiments on five commonsense reasoning benchmarks, we find that each strategy favors certain models, but their joint effects are mostly negative.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.06962v1","tag":"prompt-eng"}}
{"title":"Improving Few-Shot Prompts with Relevant Static Analysis Products","abstract":"Large Language Models (LLM) are a new class of computation engines, \"programmed\" via prompt engineering. We are still learning how to best \"program\" these LLMs to help developers. We start with the intuition that developers tend to consciously and unconsciously have a collection of semantics facts in mind when working on coding tasks. Mostly these are shallow, simple facts arising from a quick read. For a function, examples of facts might include parameter and local variable names, return expressions, simple pre- and post-conditions, and basic control and data flow, etc.   One might assume that the powerful multi-layer architecture of transformer-style LLMs makes them inherently capable of doing this simple level of \"code analysis\" and extracting such information, implicitly, while processing code: but are they, really? If they aren't, could explicitly adding this information help? Our goal here is to investigate this question, using the code summarization task and evaluate whether automatically augmenting an LLM's prompt with semantic facts explicitly, actually helps.   Prior work shows that LLM performance on code summarization benefits from few-shot samples drawn either from the same-project or from examples found via information retrieval methods (such as BM25). While summarization performance has steadily increased since the early days, there is still room for improvement: LLM performance on code summarization still lags its performance on natural-language tasks like translation and text summarization.   We find that adding semantic facts actually does help! This approach improves performance in several different settings suggested by prior work, including for two different Large Language Models. In most cases, improvement nears or exceeds 2 BLEU; for the PHP language in the challenging CodeSearchNet dataset, this augmentation actually yields performance surpassing 30 BLEU.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06815v1","tag":"prompt-eng"}}
{"title":"Segment Everything Everywhere All at Once","abstract":"Despite the growing demand for interactive AI systems, there have been few comprehensive studies on human-AI interaction in visual understanding e.g. segmentation. Inspired by the development of prompt-based universal interfaces for LLMs, this paper presents SEEM, a promptable, interactive model for Segmenting Everything Everywhere all at once in an image. SEEM has four desiderata: i) Versatility: by introducing a versatile prompting engine for different types of prompts, including points, boxes, scribbles, masks, texts, and referred regions of another image; ii) Compositionality: by learning a joint visual-semantic space for visual and textual prompts to compose queries on the fly for inference as shown in Fig 1; iii)Interactivity: by incorporating learnable memory prompts to retain dialog history information via mask-guided cross-attention; and iv) Semantic-awareness: by using a text encoder to encode text queries and mask labels for open-vocabulary segmentation.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06718v2","tag":"prompt-eng"}}
{"title":"What does CLIP know about a red circle? Visual prompt engineering for VLMs","abstract":"Large-scale Vision-Language Models, such as CLIP, learn powerful image-text representations that have found numerous applications, from zero-shot classification to text-to-image generation. Despite that, their capabilities for solving novel discriminative tasks via prompting fall behind those of large language models, such as GPT-3. Here we explore the idea of visual prompt engineering for solving computer vision tasks beyond classification by editing in image space instead of text. In particular, we discover an emergent ability of CLIP, where, by simply drawing a red circle around an object, we can direct the model's attention to that region, while also maintaining global information. We show the power of this simple approach by achieving state-of-the-art in zero-shot referring expressions comprehension and strong performance in keypoint localization tasks. Finally, we draw attention to some potential ethical concerns of large language-vision models.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06712v1","tag":"prompt-eng"}}
{"title":"Prompt: Probability-Conserved Cross Section Biasing Monte Carlo Particle Transport System","abstract":"An open source software package for simulating thermal neutron propagation in geometry is presented. In this system, neutron propagation can be treated by either the particle transport method or the ray-tracing method. Supported by an accurate backend scattering physics engine, this system is capable of reproducing neutron scattering experiments in complex geometries and is expected to be used in the areas of instrument characterisation, optimisation and data analysis.   In this paper, the relevant theories are briefly introduced. The simulation flow and the user input syntax to control it are provided in detail. Five benchmarking simulations, focusing on different aspects of simulation and scattering techniques, are given to demonstrate the applications of this simulation system. They include an idealised total scattering instrument, a monochromatic powder diffractometer, a neutron guide, a chopper and an imaging setup for complex geometries. Simulated results are benchmarked against experimental data or well-established software packages when appropriate. Good agreements are observed.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06226v1","tag":"prompt-eng"}}
{"title":"Automated Reading Passage Generation with OpenAI's Large Language Model","abstract":"The widespread usage of computer-based assessments and individualized learning platforms has resulted in an increased demand for the rapid production of high-quality items. Automated item generation (AIG), the process of using item models to generate new items with the help of computer technology, was proposed to reduce reliance on human subject experts at each step of the process. AIG has been used in test development for some time. Still, the use of machine learning algorithms has introduced the potential to improve the efficiency and effectiveness of the process greatly. The approach presented in this paper utilizes OpenAI's latest transformer-based language model, GPT-3, to generate reading passages. Existing reading passages were used in carefully engineered prompts to ensure the AI-generated text has similar content and structure to a fourth-grade reading passage. For each prompt, we generated multiple passages, the final passage was selected according to the Lexile score agreement with the original passage. In the final round, the selected passage went through a simple revision by a human editor to ensure the text was free of any grammatical and factual errors. All AI-generated passages, along with original passages were evaluated by human judges according to their coherence, appropriateness to fourth graders, and readability.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04616v1","tag":"prompt-eng"}}
{"title":"Diagnosing The Ejecta Properties of Engine-Driven Supernovae from Observables in Their Initial Phase","abstract":"Engine-driven explosions with continuous energy input from the central system have been suggested for supernovae (SNe) associated with a Gamma-Ray Burst (GRB), super-luminous SNe (SLSNe), and at least a fraction of broad-lined SNe Ic (SNe Ic-BL) even without an associated GRB. In the present work, we investigate observational consequences in this scenario, focusing on the case where the energy injection is sufficiently brief, which has been suggested for GRB-SNe. We construct a simplified, spherical ejecta model sequence taking into account the major effects of the central engine; composition mixing, density structure, and the outermost ejecta velocity. Unlike most of the previous works for GRB-SNe, we solve the formation of the photosphere self-consistently, with which we can predict the photometric and spectroscopic observables. We find that these ejecta properties strongly affect their observational appearance in the initial phase (~ a week since the explosion), highlighted by blended lines suffering from higher-velocity absorptions for the flatter density distribution and/or higher outermost ejeca velocity. This behaviour also affects the multi-band light curves in a non-monotonic way. Prompt follow-up observations starting immediately after the explosion thus provides key diagnostics to unveil the nature of the central engine behind GRB-SNe and SNe Ic-BL. For SN 2017iuk associated with GRB 171205A these diagnosing observational data are available, and we show that the expected structure from the engine-driven explosion, i.e., a flat power-law density structure extending up to >~ 100,000 km/s, can explain the observed spectral evolution reasonably well.","created":"2023-04-09","meta":{"link":"http://arxiv.org/abs/2304.04146v1","tag":"prompt-eng"}}
{"title":"VOICE: Visual Oracle for Interaction, Conversation, and Explanation","abstract":"We present VOICE, a novel approach for connecting large language models' (LLM) conversational capabilities with interactive exploratory visualization. VOICE introduces several innovative technical contributions that drive our conversational visualization framework. Our foundation is a pack-of-bots that can perform specific tasks, such as assigning tasks, extracting instructions, and generating coherent content. We employ fine-tuning and prompt engineering techniques to tailor bots' performance to their specific roles and accurately respond to user queries, and a new prompt-based iterative scene-tree generation establishes a coupling with a structural model. Our text-to-visualization method generates a flythrough sequence matching the content explanation. Finally, 3D natural language interaction provides capabilities to navigate and manipulate the 3D models in real-time. The VOICE framework can receive arbitrary voice commands from the user and responds verbally, tightly coupled with corresponding visual representation with low latency and high accuracy. We demonstrate the effectiveness and high generalizability potential of our approach by applying it to two distinct domains: analyzing three 3D molecular models with multi-scale and multi-instance attributes, and showcasing its effectiveness on a cartographic map visualization. A free copy of this paper and all supplemental materials are available at https://osf.io/g7fbr/.","created":"2023-04-08","meta":{"link":"http://arxiv.org/abs/2304.04083v1","tag":"prompt-eng"}}
{"title":"GRB 211211A: a Neutron Star$-$White Dwarf Merger?","abstract":"The gamma-ray burst GRB 211211A and its associated kilonova-like emission were reported recently. A significant difference between this association event and GRB 170817A/AT 2017gfo is that GRB 211211A has a very long duration. In this paper, we show that this association event may arise from a neutron star$-$white dwarf (NS$-$WD) merger if a magnetar leaves finally in the central engine. Within the NS$-$WD merger, the main burst of GRB 211211A could be produced by magnetic bubble eruptions from toroidal magnetic field amplification of the pre-merger NS. This toroidal field amplification can be induced by the runaway accretion from the WD debris disc if the disc is in low initial entropy and efficient wind. While the extended emission of GRB 211211A is likely involved with magnetic propelling. The observed energetics and duration of the prompt emission of GRB 211211A can be fulfilled in comparison with those of accretion in hydrodynamical thermonuclear simulation, as long as the WD has a mass $\\gtrsim1M_{\\odot}$. Moreover, if the X-ray plateau in GRB afterglows is due to the magnetar spin-down radiation, GRB optical afterglows and kilonova-like emission can be well jointly modeled combining the standard forward shock with the radioactive decay power of $^{56}{\\rm Ni}$ adding a rotational power input from the post-merger magnetar.","created":"2023-04-08","meta":{"link":"http://arxiv.org/abs/2304.04009v1","tag":"prompt-eng"}}
{"title":"On the Evaluations of ChatGPT and Emotion-enhanced Prompting for Mental Health Analysis","abstract":"Automated mental health analysis shows great potential for enhancing the efficiency and accessibility of mental health care, whereas the recent dominant methods utilized pre-trained language models (PLMs) as the backbone and incorporated emotional information. The latest large language models (LLMs), such as ChatGPT, exhibit dramatic capabilities on diverse natural language processing tasks. However, existing studies on ChatGPT's zero-shot performance for mental health analysis have limitations in inadequate evaluation, utilization of emotional information, and explainability of methods. In this work, we comprehensively evaluate the mental health analysis and emotional reasoning ability of ChatGPT on 11 datasets across 5 tasks, including binary and multi-class mental health condition detection, cause/factor detection of mental health conditions, emotion recognition in conversations, and causal emotion entailment. We empirically analyze the impact of different prompting strategies with emotional cues on ChatGPT's mental health analysis ability and explainability. Experimental results show that ChatGPT outperforms traditional neural network methods but still has a significant gap with advanced task-specific methods. The qualitative analysis shows its potential in explainability compared with advanced black-box methods but also limitations on robustness and inaccurate reasoning. Prompt engineering with emotional cues is found to be effective in improving its performance on mental health analysis but requires the proper way of emotion infusion.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.03347v1","tag":"prompt-eng"}}
{"title":"TagGPT: Large Language Models are Zero-shot Multimodal Taggers","abstract":"Tags are pivotal in facilitating the effective distribution of multimedia content in various applications in the contemporary Internet era, such as search engines and recommendation systems. Recently, large language models (LLMs) have demonstrated impressive capabilities across a wide range of tasks. In this work, we propose TagGPT, a fully automated system capable of tag extraction and multimodal tagging in a completely zero-shot fashion. Our core insight is that, through elaborate prompt engineering, LLMs are able to extract and reason about proper tags given textual clues of multimodal data, e.g., OCR, ASR, title, etc. Specifically, to automatically build a high-quality tag set that reflects user intent and interests for a specific application, TagGPT predicts large-scale candidate tags from a series of raw data via prompting LLMs, filtered with frequency and semantics. Given a new entity that needs tagging for distribution, TagGPT introduces two alternative options for zero-shot tagging, i.e., a generative method with late semantic matching with the tag set, and another selective method with early matching in prompts. It is well noticed that TagGPT provides a system-level solution based on a modular framework equipped with a pre-trained LLM (GPT-3.5 used here) and a sentence embedding model (SimCSE used here), which can be seamlessly replaced with any more advanced one you want. TagGPT is applicable for various modalities of data in modern social media and showcases strong generalization ability to a wide range of applications. We evaluate TagGPT on publicly available datasets, i.e., Kuaishou and Food.com, and demonstrate the effectiveness of TagGPT compared to existing hashtags and off-the-shelf taggers. Project page: https://github.com/TencentARC/TagGPT.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.03022v1","tag":"prompt-eng"}}
{"title":"Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification","abstract":"Recent advances in large language models (LLMs) have shown impressive ability in biomedical question-answering, but have not been adequately investigated for more specific biomedical applications. This study investigates the performance of LLMs such as the ChatGPT family of models (GPT-3.5s, GPT-4) in biomedical tasks beyond question-answering. Because no patient data can be passed to the OpenAI API public interface, we evaluated model performance with over 10000 samples as proxies for two fundamental tasks in the clinical domain - classification and reasoning. The first task is classifying whether statements of clinical and policy recommendations in scientific literature constitute health advice. The second task is causal relation detection from the biomedical literature. We compared LLMs with simpler models, such as bag-of-words (BoW) with logistic regression, and fine-tuned BioBERT models. Despite the excitement around viral ChatGPT, we found that fine-tuning for two fundamental NLP tasks remained the best strategy. The simple BoW model performed on par with the most complex LLM prompting. Prompt engineering required significant investment.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02496v1","tag":"prompt-eng"}}
{"title":"Explainable Automated Debugging via Large Language Model-driven Scientific Debugging","abstract":"Automated debugging techniques have the potential to reduce developer effort in debugging, and have matured enough to be adopted by industry. However, one critical issue with existing techniques is that, while developers want rationales for the provided automatic debugging results, existing techniques are ill-suited to provide them, as their deduction process differs significantly from that of human developers. Inspired by the way developers interact with code when debugging, we propose Automated Scientific Debugging (AutoSD), a technique that given buggy code and a bug-revealing test, prompts large language models to automatically generate hypotheses, uses debuggers to actively interact with buggy code, and thus automatically reach conclusions prior to patch generation. By aligning the reasoning of automated debugging more closely with that of human developers, we aim to produce intelligible explanations of how a specific patch has been generated, with the hope that the explanation will lead to more efficient and accurate developer decisions. Our empirical analysis on three program repair benchmarks shows that AutoSD performs competitively with other program repair baselines, and that it can indicate when it is confident in its results. Furthermore, we perform a human study with 20 participants, including six professional developers, to evaluate the utility of explanations from AutoSD. Participants with access to explanations could judge patch correctness in roughly the same time as those without, but their accuracy improved for five out of six real-world bugs studied: 70% of participants answered that they wanted explanations when using repair tools, while 55% answered that they were satisfied with the Scientific Debugging presentation.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02195v1","tag":"prompt-eng"}}
{"title":"Geotechnical Parrot Tales (GPT): Harnessing Large Language Models in geotechnical engineering","abstract":"The widespread adoption of large language models (LLMs), such as OpenAI's ChatGPT, could revolutionize various industries, including geotechnical engineering. However, GPT models can sometimes generate plausible-sounding but false outputs, leading to hallucinations. In this article, we discuss the importance of prompt engineering in mitigating these risks and harnessing the full potential of GPT for geotechnical applications. We explore the challenges and pitfalls associated with LLMs and highlight the role of context in ensuring accurate and valuable responses. Furthermore, we examine the development of context-specific search engines and the potential of LLMs to become a natural interface for complex tasks, such as data analysis and design. We also develop a unified interface using natural language to handle complex geotechnical engineering tasks and data analysis. By integrating GPT into geotechnical engineering workflows, professionals can streamline their work and develop sustainable and resilient infrastructure systems for the future.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.02138v2","tag":"prompt-eng"}}
{"title":"On the Prime Number Divisibility by Deep Learning","abstract":"Certain tasks such as determining whether a given integer can be divided by 2, 3, or other prime numbers may be trivial for human beings, but can be less straightforward for computers in the absence of pre-specified algorithms. In this paper, we tested multiple deep learning architectures and feature engineering approaches, and evaluated the scenario of determining divisibility of large finite integers (up to $2^{32}$) by small prime numbers. It turns out that, regardless of the network frameworks or the complexity of the network structures (CNN, RNN, Transformer, etc.), the ability to predict the prime number divisibility critically depends on the feature space fed into the deep learning models. We also evaluated commercially available Automated Machine Learning (AutoML) pipelines from Amazon, Google and Microsoft, and demonstrated that they failed to address this issue unless appropriately engineered features were provided. We further proposed a closed form solution to the problem using the ordinary linear regression on Fourier series basis vectors, and showed its success. Finally, we evaluated prompt-based learning using ChatGPT and demonstrated its success on small primes and apparent failures on larger primes. We conclude that feature engineering remains an important task to improve the performance, increase the interpretability, and reduce the complexity of machine learning/deep learning models, even in the era of AutoML and large-language models (LLMs).","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.01333v1","tag":"prompt-eng"}}
{"title":"Keep the Conversation Going: Fixing 162 out of 337 bugs for $0.42 each using ChatGPT","abstract":"Automated Program Repair (APR) aims to automatically generate patches for buggy programs. Recent APR work has been focused on leveraging modern Large Language Models (LLMs) to directly generate patches for APR. Such LLM-based APR tools work by first constructing an input prompt built using the original buggy code and then queries the LLM to generate patches. While the LLM-based APR tools are able to achieve state-of-the-art results, it still follows the classic Generate and Validate repair paradigm of first generating lots of patches and then validating each one afterwards. This not only leads to many repeated patches that are incorrect but also miss the crucial information in test failures as well as in plausible patches.   To address these limitations, we propose ChatRepair, the first fully automated conversation-driven APR approach that interleaves patch generation with instant feedback to perform APR in a conversational style. ChatRepair first feeds the LLM with relevant test failure information to start with, and then learns from both failures and successes of earlier patching attempts of the same bug for more powerful APR. For earlier patches that failed to pass all tests, we combine the incorrect patches with their corresponding relevant test failure information to construct a new prompt for the LLM to generate the next patch. In this way, we can avoid making the same mistakes. For earlier patches that passed all the tests, we further ask the LLM to generate alternative variations of the original plausible patches. In this way, we can further build on and learn from earlier successes to generate more plausible patches to increase the chance of having correct patches. While our approach is general, we implement ChatRepair using state-of-the-art dialogue-based LLM -- ChatGPT. By calculating the cost of accessing ChatGPT, we can fix 162 out of 337 bugs for \\$0.42 each!","created":"2023-04-01","meta":{"link":"http://arxiv.org/abs/2304.00385v1","tag":"prompt-eng"}}
{"title":"Pair Programming with Large Language Models for Sampling and Estimation of Copulas","abstract":"Without writing a single line of code by a human, an example Monte Carlo simulation based application for stochastic dependence modeling with copulas is developed using a state-of-the-art large language model (LLM) fine-tuned for conversations. This includes interaction with ChatGPT in natural language and using mathematical formalism, which, under careful supervision by a human-expert, led to producing a working code in MATLAB, Python and R for sampling from a given copula model, evaluation of the model's density, performing maximum likelihood estimation, optimizing the code for parallel computing for CPUs as well as for GPUs, and visualization of the computed results. In contrast to other emerging studies that assess the accuracy of LLMs like ChatGPT on tasks from a selected area, this work rather investigates ways how to achieve a successful solution of a standard statistical task in a collaboration of a human-expert and artificial intelligence (AI). Particularly, through careful prompt engineering, we separate successful solutions generated by ChatGPT from unsuccessful ones, resulting in a comprehensive list of related pros and cons. It is demonstrated that if the typical pitfalls are avoided, we can substantially benefit from collaborating with an AI partner. For example, we show that if ChatGPT is not able to provide a correct solution due to a lack of or incorrect knowledge, the human-expert can feed it with the correct knowledge, e.g., in the form of mathematical theorems and formulas, and make it to apply the gained knowledge in order to provide a solution that is correct. Such ability presents an attractive opportunity to achieve a programmed solution even for users with rather limited knowledge of programming techniques.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.18116v1","tag":"prompt-eng"}}
{"title":"Towards Enhancing In-Context Learning for Code Generation","abstract":"In-context learning (ICL) with pre-trained language models (PTLMs) has shown great success in code generation. ICL does not require training. PTLMs take as the input a prompt consisting of a few requirement-code examples and a new requirement, and output a new program. However, existing studies simply reuse ICL techniques for natural language generation and ignore unique features of code generation. We refer to these studies as standard ICL.   Inspired by observations of the human coding process, we propose a novel ICL approach for code generation named AceCoder. Compared to standard ICL, AceCoder has two novelties. (1) Example retrieval. It retrieves similar programs as examples and learns programming skills (e.g., algorithms, APIs) from them. (2) Guided Code Generation. It encourages PTLMs to output an intermediate preliminary (e.g., test cases, APIs) before generating programs. The preliminary can help PTLMs understand requirements and guide the next code generation. We apply AceCoder to six PTLMs (e.g., Codex) and evaluate it on three public benchmarks using the Pass@k. Results show that AceCoder can significantly improve the performance of PTLMs on code generation. (1) In terms of Pass@1, AceCoder outperforms standard ICL by up to 79.7% and fine-tuned models by up to 171%. (2) AceCoder is effective in PTLMs with different sizes (e.g., 1B to 175B) and different languages (e.g., Python, Java, and JavaScript). (3) We investigate multiple choices of the intermediate preliminary. (4) We manually evaluate generated programs in three aspects and prove the superiority of AceCoder. (5) Finally, we discuss some insights about ICL for practitioners.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.17780v1","tag":"prompt-eng"}}
{"title":"Humans in Humans Out: On GPT Converging Toward Common Sense in both Success and Failure","abstract":"Increase in computational scale and fine-tuning has seen a dramatic improvement in the quality of outputs of large language models (LLMs) like GPT. Given that both GPT-3 and GPT-4 were trained on large quantities of human-generated text, we might ask to what extent their outputs reflect patterns of human thinking, both for correct and incorrect cases. The Erotetic Theory of Reason (ETR) provides a symbolic generative model of both human success and failure in thinking, across propositional, quantified, and probabilistic reasoning, as well as decision-making. We presented GPT-3, GPT-3.5, and GPT-4 with 61 central inference and judgment problems from a recent book-length presentation of ETR, consisting of experimentally verified data-points on human judgment and extrapolated data-points predicted by ETR, with correct inference patterns as well as fallacies and framing effects (the ETR61 benchmark). ETR61 includes classics like Wason's card task, illusory inferences, the decoy effect, and opportunity-cost neglect, among others. GPT-3 showed evidence of ETR-predicted outputs for 59% of these examples, rising to 77% in GPT-3.5 and 75% in GPT-4. Remarkably, the production of human-like fallacious judgments increased from 18% in GPT-3 to 33% in GPT-3.5 and 34% in GPT-4. This suggests that larger and more advanced LLMs may develop a tendency toward more human-like mistakes, as relevant thought patterns are inherent in human-produced training data. According to ETR, the same fundamental patterns are involved both in successful and unsuccessful ordinary reasoning, so that the \"bad\" cases could paradoxically be learned from the \"good\" cases. We further present preliminary evidence that ETR-inspired prompt engineering could reduce instances of these mistakes.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17276v1","tag":"prompt-eng"}}
{"title":"ProtFIM: Fill-in-Middle Protein Sequence Design via Protein Language Models","abstract":"Protein language models (pLMs), pre-trained via causal language modeling on protein sequences, have been a promising tool for protein sequence design. In real-world protein engineering, there are many cases where the amino acids in the middle of a protein sequence are optimized while maintaining other residues. Unfortunately, because of the left-to-right nature of pLMs, existing pLMs modify suffix residues by prompting prefix residues, which are insufficient for the infilling task that considers the whole surrounding context. To find the more effective pLMs for protein engineering, we design a new benchmark, Secondary structureE InFilling rEcoveRy, SEIFER, which approximates infilling sequence design scenarios. With the evaluation of existing models on the benchmark, we reveal the weakness of existing language models and show that language models trained via fill-in-middle transformation, called ProtFIM, are more appropriate for protein engineering. Also, we prove that ProtFIM generates protein sequences with decent protein representations through exhaustive experiments and visualizations.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16452v1","tag":"prompt-eng"}}
{"title":"Ten Quick Tips for Harnessing the Power of ChatGPT/GPT-4 in Computational Biology","abstract":"The rise of advanced chatbots, such as ChatGPT, has sparked curiosity in the scientific community. ChatGPT is a general-purpose chatbot powered by large language models (LLMs) GPT-3.5 and GPT-4, with the potential to impact numerous fields, including computational biology. In this article, we offer ten tips based on our experience with ChatGPT to assist computational biologists in optimizing their workflows. We have collected relevant prompts and reviewed the nascent literature in the field, compiling tips we project to remain pertinent for future ChatGPT and LLM iterations, ranging from code refactoring to scientific writing to prompt engineering. We hope our work will help bioinformaticians to complement their workflows while staying aware of the various implications of using this technology. Additionally, to track new and creative applications for bioinformatics tools such as ChatGPT, we have established a GitHub repository at https://github.com/csbl-br/awesome-compbio-chatgpt. Our belief is that ethical adherence to ChatGPT and other LLMs will increase the efficiency of computational biologists, ultimately advancing the pace of scientific discovery in the life sciences.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16429v1","tag":"prompt-eng"}}
{"title":"On Codex Prompt Engineering for OCL Generation: An Empirical Study","abstract":"The Object Constraint Language (OCL) is a declarative language that adds constraints and object query expressions to MOF models. Despite its potential to provide precision and conciseness to UML models, the unfamiliar syntax of OCL has hindered its adoption. Recent advancements in LLMs, such as GPT-3, have shown their capability in many NLP tasks, including semantic parsing and text generation. Codex, a GPT-3 descendant, has been fine-tuned on publicly available code from GitHub and can generate code in many programming languages. We investigate the reliability of OCL constraints generated by Codex from natural language specifications. To achieve this, we compiled a dataset of 15 UML models and 168 specifications and crafted a prompt template with slots to populate with UML information and the target task, using both zero- and few-shot learning methods. By measuring the syntactic validity and execution accuracy metrics of the generated OCL constraints, we found that enriching the prompts with UML information and enabling few-shot learning increases the reliability of the generated OCL constraints. Furthermore, the results reveal a close similarity based on sentence embedding between the generated OCL constraints and the human-written ones in the ground truth, implying a level of clarity and understandability in the generated OCL constraints by Codex.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.16244v1","tag":"prompt-eng"}}
{"title":"ChatGPT4PCG Competition: Character-like Level Generation for Science Birds","abstract":"This paper presents the first ChatGPT4PCG Competition at the 2023 IEEE Conference on Games. The objective of this competition is for participants to create effective prompts for ChatGPT--enabling it to generate Science Birds levels with high stability and character-like qualities--fully using their creativity as well as prompt engineering skills. ChatGPT is a conversational agent developed by OpenAI. Science Birds is selected as the competition platform because designing an Angry Birds-like level is not a trivial task due to the in-game gravity; the playability of the levels is determined by their stability. To lower the entry barrier to the competition, we limit the task to the generation of capitalized English alphabetical characters. Here, the quality of the generated levels is determined by their stability and similarity to the given characters. A sample prompt is provided to participants for their reference. An experiment is conducted to determine the effectiveness of its modified versions on level stability and similarity by testing them on several characters. To the best of our knowledge, we believe that ChatGPT4PCG is the first competition of its kind and hope to inspire enthusiasm for prompt engineering in procedural content generation.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15662v1","tag":"prompt-eng"}}
{"title":"Unlocking the Potential of ChatGPT: A Comprehensive Exploration of its Applications, Advantages, Limitations, and Future Directions in Natural Language Processing","abstract":"Large language models have revolutionized the field of artificial intelligence and have been used in various applications. Among these models, ChatGPT (Chat Generative Pre-trained Transformer) has been developed by OpenAI, it stands out as a powerful tool that has been widely adopted. ChatGPT has been successfully applied in numerous areas, including chatbots, content generation, language translation, personalized recommendations, and even medical diagnosis and treatment. Its success in these applications can be attributed to its ability to generate human-like responses, understand natural language, and adapt to different contexts. Its versatility and accuracy make it a powerful tool for natural language processing (NLP). However, there are also limitations to ChatGPT, such as its tendency to produce biased responses and its potential to perpetuate harmful language patterns. This article provides a comprehensive overview of ChatGPT, its applications, advantages, and limitations. Additionally, the paper emphasizes the importance of ethical considerations when using this robust tool in real-world scenarios. Finally, This paper contributes to ongoing discussions surrounding artificial intelligence and its impact on vision and NLP domains by providing insights into prompt engineering techniques.","created":"2023-03-27","meta":{"link":"http://arxiv.org/abs/2304.02017v5","tag":"prompt-eng"}}
{"title":"Homochiral antiferromagnetic merons, antimerons and bimerons realized in synthetic antiferromagnets","abstract":"The ever-growing demand for device miniaturization and energy efficiency in data storage and computing technology has prompted a shift towards antiferromagnetic (AFM) topological spin textures as information carriers, owing to their negligible stray fields, leading to possible high device density and potentially ultrafast dynamics. We realize, in this work, such chiral in-plane (IP) topological antiferromagnetic spin textures, namely merons, antimerons, and bimerons in synthetic antiferromagnets by concurrently engineering the effective perpendicular magnetic anisotropy, the interlayer exchange coupling, and the magnetic compensation ratio. We demonstrate by three-dimensional vector imaging of the N\\'eel order parameter, the topology of those spin textures and reveal globally a well-defined chirality, which is a crucial requirement for controlled current-induced dynamics. Our analysis reveals that the interplay between interlayer exchange and interlayer magnetic dipolar interactions plays a key role in significantly reducing the critical strength of the Dzyaloshinskii-Moriya interaction required to stabilize topological spin textures, such as AFM merons, making synthetic antiferromagnets a promising platform for next-generation spintronics applications.","created":"2023-03-26","meta":{"link":"http://arxiv.org/abs/2303.14853v1","tag":"prompt-eng"}}
{"title":"Fermi-GBM Discovery of GRB 221009A: An Extraordinarily Bright GRB from Onset to Afterglow","abstract":"We report the discovery of GRB 221009A, the highest flux gamma-ray burst ever observed by the Fermi Gamma-ray Burst Monitor (GBM). This GRB has continuous prompt emission lasting more than 600 seconds, afterglow visible in the \\gbm energy range (8 keV--40 MeV), and total energetics higher than any other burst in the GBM sample. By using a variety of new and existing analysis techniques we probe the spectral and temporal evolution of GRB 221009A. We find no emission prior to the GBM trigger time (t0; 2022 October 9 at 13:16:59.99 UTC), indicating that this is the time of prompt emission onset. The triggering pulse exhibits distinct spectral and temporal properties suggestive of shock-breakout with significant emission up to $\\sim$15\\,MeV. We characterize the onset of external shock at \\t0+600\\,s and find evidence of a plateau region in the early-afterglow phase which transitions to a slope consistent with \\swift-XRT afterglow measurements. We place the total energetics of GRB 221009A in context with the rest of the GBM sample and find that this GRB has the highest total isotropic-equivalent energy ($\\textrm{E}_{\\gamma,\\textrm{iso}}=1.0\\times10^{55}$\\,erg) and second highest isotropic-equivalent luminosity ($\\textrm{L}_{\\gamma,\\textrm{iso}}=9.9\\times10^{53}$\\,erg/s) based on redshift of z = 0.151. These extreme energetics are what allowed GBMto observe the continuously emitting central engine from the beginning of the prompt emission phase through the onset of early afterglow.","created":"2023-03-24","meta":{"link":"http://arxiv.org/abs/2303.14172v1","tag":"prompt-eng"}}
{"title":"Exploring the Benefits of Visual Prompting in Differential Privacy","abstract":"Visual Prompting (VP) is an emerging and powerful technique that allows sample-efficient adaptation to downstream tasks by engineering a well-trained frozen source model. In this work, we explore the benefits of VP in constructing compelling neural network classifiers with differential privacy (DP). We explore and integrate VP into canonical DP training methods and demonstrate its simplicity and efficiency. In particular, we discover that VP in tandem with PATE, a state-of-the-art DP training method that leverages the knowledge transfer from an ensemble of teachers, achieves the state-of-the-art privacy-utility trade-off with minimum expenditure of privacy budget. Moreover, we conduct additional experiments on cross-domain image classification with a sufficient domain gap to further unveil the advantage of VP in DP. Lastly, we also conduct extensive ablation studies to validate the effectiveness and contribution of VP under DP consideration.","created":"2023-03-22","meta":{"link":"http://arxiv.org/abs/2303.12247v1","tag":"prompt-eng"}}
{"title":"Large Language Models and Simple, Stupid Bugs","abstract":"With the advent of powerful neural language models, AI-based systems to assist developers in coding tasks are becoming widely available; Copilot is one such system. Copilot uses Codex, a large language model (LLM), to complete code conditioned on a preceding \"prompt\". Codex, however, is trained on public GitHub repositories, viz., on code that may include bugs and vulnerabilities. Previous studies [1], [2] show Codex reproduces vulnerabilities seen in training. In this study, we examine how prone Codex is to generate an interesting bug category, single statement bugs, commonly referred to as simple, stupid bugs or SStuBs in the MSR community. We find that Codex and similar LLMs do help avoid some SStuBs, but do produce known, verbatim SStuBs as much as 2x as likely than known, verbatim correct code. We explore the consequences of the Codex generated SStuBs and propose avoidance strategies that suggest the possibility of reducing the production of known, verbatim SStubs, and increase the possibility of producing known, verbatim fixes.","created":"2023-03-20","meta":{"link":"http://arxiv.org/abs/2303.11455v1","tag":"prompt-eng"}}
{"title":"Capabilities of GPT-4 on Medical Challenge Problems","abstract":"Large language models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation across various domains, including medicine. We present a comprehensive evaluation of GPT-4, a state-of-the-art LLM, on medical competency examinations and benchmark datasets. GPT-4 is a general-purpose model that is not specialized for medical problems through training or engineered to solve clinical tasks. Our analysis covers two sets of official practice materials for the USMLE, a three-step examination program used to assess clinical competency and grant licensure in the United States. We also evaluate performance on the MultiMedQA suite of benchmark datasets. Beyond measuring model performance, experiments were conducted to investigate the influence of test questions containing both text and images on model performance, probe for memorization of content during training, and study probability calibration, which is of critical importance in high-stakes applications like medicine. Our results show that GPT-4, without any specialized prompt crafting, exceeds the passing score on USMLE by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of Flan-PaLM 540B). In addition, GPT-4 is significantly better calibrated than GPT-3.5, demonstrating a much-improved ability to predict the likelihood that its answers are correct. We also explore the behavior of the model qualitatively through a case study that shows the ability of GPT-4 to explain medical reasoning, personalize explanations to students, and interactively craft new counterfactual scenarios around a medical case. Implications of the findings are discussed for potential uses of GPT-4 in medical education, assessment, and clinical practice, with appropriate attention to challenges of accuracy and safety.","created":"2023-03-20","meta":{"link":"http://arxiv.org/abs/2303.13375v2","tag":"prompt-eng"}}
{"title":"Revisiting the Plastic Surgery Hypothesis via Large Language Models","abstract":"Automated Program Repair (APR) aspires to automatically generate patches for an input buggy program. Traditional APR tools typically focus on specific bug types and fixes through the use of templates, heuristics, and formal specifications. However, these techniques are limited in terms of the bug types and patch variety they can produce. As such, researchers have designed various learning-based APR tools with recent work focused on directly using Large Language Models (LLMs) for APR. While LLM-based APR tools are able to achieve state-of-the-art performance on many repair datasets, the LLMs used for direct repair are not fully aware of the project-specific information such as unique variable or method names.   The plastic surgery hypothesis is a well-known insight for APR, which states that the code ingredients to fix the bug usually already exist within the same project. Traditional APR tools have largely leveraged the plastic surgery hypothesis by designing manual or heuristic-based approaches to exploit such existing code ingredients. However, as recent APR research starts focusing on LLM-based approaches, the plastic surgery hypothesis has been largely ignored. In this paper, we ask the following question: How useful is the plastic surgery hypothesis in the era of LLMs? Interestingly, LLM-based APR presents a unique opportunity to fully automate the plastic surgery hypothesis via fine-tuning and prompting. To this end, we propose FitRepair, which combines the direct usage of LLMs with two domain-specific fine-tuning strategies and one prompting strategy for more powerful APR. Our experiments on the widely studied Defects4j 1.2 and 2.0 datasets show that FitRepair fixes 89 and 44 bugs (substantially outperforming the best-performing baseline by 15 and 8), respectively, demonstrating a promising future of the plastic surgery hypothesis in the era of LLMs.","created":"2023-03-18","meta":{"link":"http://arxiv.org/abs/2303.10494v1","tag":"prompt-eng"}}
{"title":"LLMSecEval: A Dataset of Natural Language Prompts for Security Evaluations","abstract":"Large Language Models (LLMs) like Codex are powerful tools for performing code completion and code generation tasks as they are trained on billions of lines of code from publicly available sources. Moreover, these models are capable of generating code snippets from Natural Language (NL) descriptions by learning languages and programming practices from public GitHub repositories. Although LLMs promise an effortless NL-driven deployment of software applications, the security of the code they generate has not been extensively investigated nor documented. In this work, we present LLMSecEval, a dataset containing 150 NL prompts that can be leveraged for assessing the security performance of such models. Such prompts are NL descriptions of code snippets prone to various security vulnerabilities listed in MITRE's Top 25 Common Weakness Enumeration (CWE) ranking. Each prompt in our dataset comes with a secure implementation example to facilitate comparative evaluations against code produced by LLMs. As a practical application, we show how LLMSecEval can be used for evaluating the security of snippets automatically generated from NL descriptions.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09384v1","tag":"prompt-eng"}}
{"title":"Patch-Token Aligned Bayesian Prompt Learning for Vision-Language Models","abstract":"For downstream applications of vision-language pre-trained models, there has been significant interest in constructing effective prompts. Existing works on prompt engineering, which either require laborious manual designs or optimize the prompt tuning as a point estimation problem, may fail to describe diverse characteristics of categories and limit their applications. We introduce a Bayesian probabilistic resolution to prompt learning, where the label-specific stochastic prompts are generated hierarchically by first sampling a latent vector from an underlying distribution and then employing a lightweight generative model. Importantly, we semantically regularize prompt learning with the visual knowledge and view images and the corresponding prompts as patch and token sets under optimal transport, which pushes the prompt tokens to faithfully capture the label-specific visual concepts, instead of overfitting the training categories. Moreover, the proposed model can also be straightforwardly extended to the conditional case where the instance-conditional prompts are generated to improve the generalizability. Extensive experiments on 15 datasets show promising transferability and generalization performance of our proposed model.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09100v1","tag":"prompt-eng"}}
{"title":"UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation","abstract":"Large Language Models (LLMs) are popular for their impressive abilities, but the need for model-specific fine-tuning or task-specific prompt engineering can hinder their generalization. We propose UPRISE (Universal Prompt Retrieval for Improving zero-Shot Evaluation), which tunes a lightweight and versatile retriever that automatically retrieves prompts for a given zero-shot task input. Specifically, we demonstrate universality in a cross-task and cross-model scenario: the retriever is tuned on a diverse set of tasks, but tested on unseen task types; we use a small frozen LLM, GPT-Neo-2.7B, for tuning the retriever, but test the retriever on different LLMs of much larger scales, such as BLOOM-7.1B, OPT-66B and GPT3-175B. Additionally, we show that UPRISE mitigates the hallucination problem in our experiments with ChatGPT, suggesting its potential to improve even the strongest LLMs. Our model and code are available at https://github.com/microsoft/LMOps.","created":"2023-03-15","meta":{"link":"http://arxiv.org/abs/2303.08518v2","tag":"prompt-eng"}}
{"title":"InferFix: End-to-End Program Repair with LLMs","abstract":"Software development life cycle is profoundly influenced by bugs: their introduction, identification, and eventual resolution account for a significant portion of software cost. This has motivated software engineering researchers and practitioners to propose different approaches for automating the identification and repair of software defects. Large language models have been adapted to the program repair task through few-shot demonstration learning and instruction prompting, treating this as an infilling task. However, these models have only focused on learning general bug-fixing patterns for uncategorized bugs mined from public repositories. In this paper, we propose InferFix: a transformer-based program repair framework paired with a state-of-the-art static analyzer to fix critical security and performance bugs. InferFix combines a Retriever -- transformer encoder model pretrained via contrastive learning objective, which aims at searching for semantically equivalent bugs and corresponding fixes; and a Generator -- a large language model (Codex Cushman) finetuned on supervised bug-fix data with prompts augmented via bug type annotations and semantically similar fixes retrieved from an external non-parametric memory. To train and evaluate our approach, we curated InferredBugs, a novel, metadata-rich dataset of bugs extracted by executing the Infer static analyzer on the change histories of thousands of Java and C# repositories. Our evaluation demonstrates that InferFix outperforms strong LLM baselines, with a top-1 accuracy of 65.6% for generating fixes in C# and 76.8% in Java. We discuss the deployment of InferFix alongside Infer at Microsoft which offers an end-to-end solution for detection, classification, and localization of bugs, as well as fixing and validation of candidate patches, integrated in the continuous integration pipeline to automate the software development workflow.","created":"2023-03-13","meta":{"link":"http://arxiv.org/abs/2303.07263v1","tag":"prompt-eng"}}
{"title":"Prompting AI Art: An Investigation into the Creative Skill of Prompt Engineering","abstract":"Humankind is entering a novel era of creativity - an era in which anybody can synthesize digital content. The paradigm under which this revolution takes place is prompt-based learning (or in-context learning). This paradigm has found fruitful application in text-to-image generation where it is being used to synthesize digital images from zero-shot text prompts in natural language for the purpose of creating AI art. This activity is referred to as prompt engineering - the practice of iteratively crafting prompts to generate and improve images. In this paper, we investigate prompt engineering as a novel creative skill for creating prompt-based art. In three studies with participants recruited from a crowdsourcing platform, we explore whether untrained participants could 1) recognize the quality of prompts, 2) write prompts, and 3) improve their prompts. Our results indicate that participants could assess the quality of prompts and respective images. This ability increased with the participants' experience and interest in art. Participants further were able to write prompts in rich descriptive language. However, even though participants were specifically instructed to generate artworks, participants' prompts were missing the specific vocabulary needed to apply a certain style to the generated images. Our results suggest that prompt engineering is a learned skill that requires expertise and practice. Based on our findings and experience with running our studies with participants recruited from a crowdsourcing platform, we provide ten recommendations for conducting experimental research on text-to-image generation and prompt engineering with a paid crowd. Our studies offer a deeper understanding of prompt engineering thereby opening up avenues for research on the future of prompt engineering. We conclude by speculating on four possible futures of prompt engineering.","created":"2023-03-13","meta":{"link":"http://arxiv.org/abs/2303.13534v1","tag":"prompt-eng"}}
{"title":"Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification","abstract":"This case study investigates the task of job classification in a real-world setting, where the goal is to determine whether an English-language job posting is appropriate for a graduate or entry-level position. We explore multiple approaches to text classification, including supervised approaches such as traditional models like Support Vector Machines (SVMs) and state-of-the-art deep learning methods such as DeBERTa. We compare them with Large Language Models (LLMs) used in both few-shot and zero-shot classification settings. To accomplish this task, we employ prompt engineering, a technique that involves designing prompts to guide the LLMs towards the desired output. Specifically, we evaluate the performance of two commercially available state-of-the-art GPT-3.5-based language models, text-davinci-003 and gpt-3.5-turbo. We also conduct a detailed analysis of the impact of different aspects of prompt engineering on the model's performance. Our results show that, with a well-designed prompt, a zero-shot gpt-3.5-turbo classifier outperforms all other models, achieving a 6% increase in Precision@95% Recall compared to the best supervised approach. Furthermore, we observe that the wording of the prompt is a critical factor in eliciting the appropriate \"reasoning\" in the model, and that seemingly minor aspects of the prompt significantly affect the model's performance.","created":"2023-03-13","meta":{"link":"http://arxiv.org/abs/2303.07142v3","tag":"prompt-eng"}}
{"title":"Evidence for self-organized criticality phenomena in prompt phase of short gamma-ray bursts","abstract":"The prompt phase of gamma-ray burst (GRB) contains essential information regarding the physical nature and central engine, which are as yet unknown. In this paper, we investigate the self-organized criticality (SOC) phenomena in GRB prompt phase as done in X-ray flares of GRBs. We obtain the differential and cumulative distributions of 243 short GRB pulses, such as peak flux, FWHM, rise time, decay time, and peak time in the fourth BATSE TTE Catalog with the Markov Chain Monte Carlo (MCMC) technique. It is found that these distributions can be well described by power-law models. In particular, comparisons are made in 182 short GRB pulses in the third Swift GRB Catalog from 2004 December to 2019 July. The results are essentially consistent with those in BATSE ones. We notice that there is no obvious power-law index evolution across different energy bands for either BATSE or Swift sGRBs. The joint analysis suggests that GRB prompt phase can be explained by a Fractal-Diffusive, Self-Organized Criticality (FD-SOC) system with the spatial dimension S = 3 and the classical diffusion ? = 1. Our findings show that GRB prompt phases and X-ray flares possess the very same magnetically dominated stochastic process and mechanism.","created":"2023-03-12","meta":{"link":"http://arxiv.org/abs/2303.06667v1","tag":"prompt-eng"}}
{"title":"ChatGPT Prompt Patterns for Improving Code Quality, Refactoring, Requirements Elicitation, and Software Design","abstract":"This paper presents prompt design techniques for software engineering, in the form of patterns, to solve common problems when using large language models (LLMs), such as ChatGPT to automate common software engineering activities, such as ensuring code is decoupled from third-party libraries and simulating a web application API before it is implemented. This paper provides two contributions to research on using LLMs for software engineering. First, it provides a catalog of patterns for software engineering that classifies patterns according to the types of problems they solve. Second, it explores several prompt patterns that have been applied to improve requirements elicitation, rapid prototyping, code quality, refactoring, and system design.","created":"2023-03-11","meta":{"link":"http://arxiv.org/abs/2303.07839v1","tag":"prompt-eng"}}
{"title":"Susceptibility to Influence of Large Language Models","abstract":"Two studies tested the hypothesis that a Large Language Model (LLM) can be used to model psychological change following exposure to influential input. The first study tested a generic mode of influence - the Illusory Truth Effect (ITE) - where earlier exposure to a statement (through, for example, rating its interest) boosts a later truthfulness test rating. Data was collected from 1000 human participants using an online experiment, and 1000 simulated participants using engineered prompts and LLM completion. 64 ratings per participant were collected, using all exposure-test combinations of the attributes: truth, interest, sentiment and importance. The results for human participants reconfirmed the ITE, and demonstrated an absence of effect for attributes other than truth, and when the same attribute is used for exposure and test. The same pattern of effects was found for LLM-simulated participants. The second study concerns a specific mode of influence - populist framing of news to increase its persuasion and political mobilization. Data from LLM-simulated participants was collected and compared to previously published data from a 15-country experiment on 7286 human participants. Several effects previously demonstrated from the human study were replicated by the simulated study, including effects that surprised the authors of the human study by contradicting their theoretical expectations (anti-immigrant framing of news decreases its persuasion and mobilization); but some significant relationships found in human data (modulation of the effectiveness of populist framing according to relative deprivation of the participant) were not present in the LLM data. Together the two studies support the view that LLMs have potential to act as models of the effect of influence.","created":"2023-03-10","meta":{"link":"http://arxiv.org/abs/2303.06074v1","tag":"prompt-eng"}}
{"title":"Automating Method Naming with Context-Aware Prompt-Tuning","abstract":"Method names are crucial to program comprehension and maintenance. Recently, many approaches have been proposed to automatically recommend method names and detect inconsistent names. Despite promising, their results are still sub-optimal considering the three following drawbacks: 1) These models are mostly trained from scratch, learning two different objectives simultaneously. The misalignment between two objectives will negatively affect training efficiency and model performance. 2) The enclosing class context is not fully exploited, making it difficult to learn the abstract function of the method. 3) Current method name consistency checking methods follow a generate-then-compare process, which restricts the accuracy as they highly rely on the quality of generated names and face difficulty measuring the semantic consistency.   In this paper, we propose an approach named AUMENA to AUtomate MEthod NAming tasks with context-aware prompt-tuning. Unlike existing deep learning based approaches, our model first learns the contextualized representation(i.e., class attributes) of PL and NL through the pre-training model, then fully exploits the capacity and knowledge of large language model with prompt-tuning to precisely detect inconsistent method names and recommend more accurate names. To better identify semantically consistent names, we model the method name consistency checking task as a two-class classification problem, avoiding the limitation of previous similarity-based consistency checking approaches. The experimental results reflect that AUMENA scores 68.6%, 72.0%, 73.6%, 84.7% on four datasets of method name recommendation, surpassing the state-of-the-art baseline by 8.5%, 18.4%, 11.0%, 12.0%, respectively. And our approach scores 80.8% accuracy on method name consistency checking, reaching an 5.5% outperformance. All data and trained models are publicly available.","created":"2023-03-10","meta":{"link":"http://arxiv.org/abs/2303.05771v1","tag":"prompt-eng"}}
{"title":"Greener yet Powerful: Taming Large Code Generation Models with Quantization","abstract":"ML-powered code generation aims to assist developers to write code in a more productive manner, by intelligently generating code blocks based on natural language prompts. Recently, large pretrained deep learning models have substantially pushed the boundary of code generation and achieved impressive performance. Despite their great power, the huge number of model parameters poses a significant threat to adapting them in a regular software development environment, where a developer might use a standard laptop or mid-size server to develop her code. Such large models incur significant resource usage (in terms of memory, latency, and dollars) as well as carbon footprint.   Model compression is a promising approach to address these challenges. Several techniques are proposed to compress large pretrained models typically used for vision or textual data. Out of many available compression techniques, we identified that quantization is mostly applicable for code generation task as it does not require significant retraining cost. As quantization represents model parameters with lower-bit integer (e.g., int8), the model size and runtime latency would both benefit from such int representation. We extensively study the impact of quantized model on code generation tasks across different dimension: (i) resource usage and carbon footprint, (ii) accuracy, and (iii) robustness. To this end, through systematic experiments we find a recipe of quantization technique that could run even a $6$B model in a regular laptop without significant accuracy or robustness degradation. We further found the recipe is readily applicable to code summarization task as well.","created":"2023-03-09","meta":{"link":"http://arxiv.org/abs/2303.05378v1","tag":"prompt-eng"}}
{"title":"A Prompt Log Analysis of Text-to-Image Generation Systems","abstract":"Recent developments in large language models (LLM) and generative AI have unleashed the astonishing capabilities of text-to-image generation systems to synthesize high-quality images that are faithful to a given reference text, known as a \"prompt\". These systems have immediately received lots of attention from researchers, creators, and common users. Despite the plenty of efforts to improve the generative models, there is limited work on understanding the information needs of the users of these systems at scale. We conduct the first comprehensive analysis of large-scale prompt logs collected from multiple text-to-image generation systems. Our work is analogous to analyzing the query logs of Web search engines, a line of work that has made critical contributions to the glory of the Web search industry and research. Compared with Web search queries, text-to-image prompts are significantly longer, often organized into special structures that consist of the subject, form, and intent of the generation tasks and present unique categories of information needs. Users make more edits within creation sessions, which present remarkable exploratory patterns. There is also a considerable gap between the user-input prompts and the captions of the images included in the open training data of the generative models. Our findings provide concrete implications on how to improve text-to-image generation systems for creation purposes.","created":"2023-03-08","meta":{"link":"http://arxiv.org/abs/2303.04587v2","tag":"prompt-eng"}}
{"title":"Extracting Accurate Materials Data from Research Papers with Conversational Language Models and Prompt Engineering -- Example of ChatGPT","abstract":"There has been a growing effort to replace hand extraction of data from research papers with automated data extraction based on natural language processing (NLP), language models (LMs), and recently, large language models (LLMs). Although these methods enable efficient extraction of data from large sets of research papers, they require a significant amount of up-front effort, expertise, and coding. In this work we propose the ChatExtract method that can fully automate very accurate data extraction with essentially no initial effort or background using an advanced conversational LLM (or AI). ChatExtract consists of a set of engineered prompts applied to a conversational LLM that both identify sentences with data, extract data, and assure its correctness through a series of follow-up questions. These follow-up questions address a critical challenge associated with LLMs - their tendency to provide factually inaccurate responses. ChatExtract can be applied with any conversational LLMs and yields very high quality data extraction. In tests on materials data we find precision and recall both over 90% from the best conversational LLMs, likely rivaling or exceeding human accuracy in many cases. We demonstrate that the exceptional performance is enabled by the information retention in a conversational model combined with purposeful redundancy and introducing uncertainty through follow-up prompts. These results suggest that approaches similar to ChatExtract, due to their simplicity, transferability and accuracy are likely to replace other methods of data extraction in the near future.","created":"2023-03-07","meta":{"link":"http://arxiv.org/abs/2303.05352v1","tag":"prompt-eng"}}
{"title":"Late-Time HST Observations of AT 2018cow I: Further Constraints on the Fading Prompt Emission and Thermal Properties 50-60 Days Post-Explosion","abstract":"The exact nature of the luminous Fast Blue Optical Transient AT 2018cow is still debated. In this first of a two-paper series, we present a detailed analysis of three Hubble Space Telescope (HST) observations of AT 2018cow covering $\\sim$50-60 days post-explosion, which provide significantly improved constraints of the fading prompt emission and late thermal properties. By modeling the Spectral Energy Distributions (SEDs), we confirm that the UV-optical emission over 50-60 days was still a smooth blackbody (i.e., optically thick) with a high temperature ($T_{\\mathrm{BB}}\\sim15000\\,\\mathrm{K}$) and small radius ($R_{\\mathrm{BB}}\\lesssim1000\\,R_\\odot$). Additionally, we report for the first time a break in the bolometric light curve: the thermal luminosity initially declined at a rate of $L_{\\mathrm{BB}}\\propto t^{-2.40}$, but faded much faster at $t^{-3.06}$ after day 13. Re-examining possible late-time power sources, we disfavor significant contributions from radioactive decay based on the required $^{56}$Ni mass and the complete lack of UV line blanketing in the HST SEDs. We argue that the commonly-proposed interaction with circumstellar material may face significant challenges in explaining the late thermal properties, particularly the effects of optical depth. Alternatively, we find that continuous outflow/wind driven by a central engine can still reasonably explain the combination of receding photosphere, optically thick and rapid fading emission, as well as the intermediate-width lines. However, the rapid fading may have further implications on the power output of the engine and structure of the wind. Our findings may support the hypothesis that AT 2018cow and other ``Cow-like transients'' are powered mainly by accretion onto a central engine.","created":"2023-03-06","meta":{"link":"http://arxiv.org/abs/2303.03500v1","tag":"prompt-eng"}}
{"title":"Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering","abstract":"Knowledge-based visual question answering (VQA) requires external knowledge beyond the image to answer the question. Early studies retrieve required knowledge from explicit knowledge bases (KBs), which often introduces irrelevant information to the question, hence restricting the performance of their models. Recent works have sought to use a large language model (i.e., GPT-3) as an implicit knowledge engine to acquire the necessary knowledge for answering. Despite the encouraging results achieved by these methods, we argue that they have not fully activated the capacity of GPT-3 as the provided input information is insufficient. In this paper, we present Prophet -- a conceptually simple framework designed to prompt GPT-3 with answer heuristics for knowledge-based VQA. Specifically, we first train a vanilla VQA model on a specific knowledge-based VQA dataset without external knowledge. After that, we extract two types of complementary answer heuristics from the model: answer candidates and answer-aware examples. Finally, the two types of answer heuristics are encoded into the prompts to enable GPT-3 to better comprehend the task thus enhancing its capacity. Prophet significantly outperforms all existing state-of-the-art methods on two challenging knowledge-based VQA datasets, OK-VQA and A-OKVQA, delivering 61.1% and 55.7% accuracies on their testing sets, respectively.","created":"2023-03-03","meta":{"link":"http://arxiv.org/abs/2303.01903v2","tag":"prompt-eng"}}
{"title":"A variational quantum algorithm-based numerical method for solving potential and Stokes flows","abstract":"This paper presents a numerical method based on the variational quantum algorithm to solve potential and Stokes flow problems. In this method, the governing equations for potential and Stokes flows can be respectively written in the form of Laplace's equation and Stokes equations using velocity potential, stream function and vorticity formulations. Then the finite difference method and the generalised differential quadrature (GDQ) method are applied to discretize the governing equations. For the prescribed boundary conditions, the corresponding linear systems of equations can be obtained. These linear systems are solved by using the variational quantum linear solver (VQLS), which resolves the potential and Stokes flow problems equivalently. To the best of authors' knowledge, this is the first study that incorporates the GDQ method which is inherently a high-order discretization method with the VQLS algorithm. Since the GDQ method can utilize much fewer grid points than the finite difference method to approximate derivatives with a higher order of accuracy, the size of the input matrix for the VQLS algorithm can be smaller. In this way, the computational cost may be saved. The performance of the present method is comprehensively assessed by two representative examples, namely, the potential flow around a circular cylinder and Stokes flow in a lid-driven cavity. Numerical results validate the applicability and accuracy of the present VQLS-based method. Furthermore, its time complexity is evaluated by the heuristic scaling, which demonstrates that the present method scales efficiently in the number of qubits and the precision. This work brings quantum computing to the field of computational fluid dynamics. By virtue of quantum advantage over classical methods, promising advances in solving large-scale fluid mechanics problems of engineering interest may be prompted.","created":"2023-03-03","meta":{"link":"http://arxiv.org/abs/2303.01805v1","tag":"prompt-eng"}}
{"title":"Insight-HXMT and GECAM-C observations of the brightest-of-all-time GRB 221009A","abstract":"GRB 221009A is the brightest gamma-ray burst ever detected since the discovery of this kind of energetic explosions. However, an accurate measurement of the prompt emission properties of this burst is very challenging due to its exceptional brightness. With joint observations of \\textit{Insight}-HXMT and GECAM-C, we made an unprecedentedly accurate measurement of the emission during the first $\\sim$1800 s of GRB 221009A, including its precursor, main emission (ME, which dominates the burst in flux), flaring emission and early afterglow, in the hard X-ray to soft gamma-ray band from $\\sim$ 10 keV to $\\sim$ 6 MeV. Based on the GECAM-C unsaturated data of the ME, we measure a record-breaking isotropic equivalent energy ($E_{\\rm iso}$) of $\\bf \\sim 1.5 \\times 10^{55}$ erg, which is about eight times the total rest-mass energy of the Sun. The early afterglow data require a significant jet break between 650 s and 1100 s, most likely at $\\sim950$ s from the afterglow starting time $T_{AG}$, which corresponds to a jet opening angle of $\\sim {0.7^\\circ} \\ (\\eta_\\gamma n)^{1/8}$, where $n$ is the ambient medium density in units of $\\rm cm^{-3}$ and $\\eta_\\gamma$ is the ratio between $\\gamma$-ray energy and afterglow kinetic energy. The beaming-corrected total $\\gamma$-ray energy $E_{\\gamma}$ is $\\sim 1.15 \\times10^{51} \\ (\\eta_\\gamma n)^{1/4}$ erg, which is typical for long GRBs. These results suggest that this GRB may have a special central engine, which could launch and collimate a very narrowly beamed jet with an ordinary energy budget, leading to exceptionally luminous gamma-ray radiation per unit solid angle. Alternatively, more GRBs might have such a narrow and bright beam, which are missed by an unfavorable viewing angle or have been detected without distance measurement.","created":"2023-03-02","meta":{"link":"http://arxiv.org/abs/2303.01203v2","tag":"prompt-eng"}}
{"title":"EvoPrompting: Language Models for Code-Level Neural Architecture Search","abstract":"Given the recent impressive accomplishments of language models (LMs) for code generation, we explore the use of LMs as adaptive mutation and crossover operators for an evolutionary neural architecture search (NAS) algorithm. While NAS still proves too difficult a task for LMs to succeed at solely through prompting, we find that the combination of evolutionary prompt engineering with soft prompt-tuning, a method we term EvoPrompting, consistently finds diverse and high performing models. We first demonstrate that EvoPrompting is effective on the computationally efficient MNIST-1D dataset, where EvoPrompting produces convolutional architecture variants that outperform both those designed by human experts and naive few-shot prompting in terms of accuracy and model size. We then apply our method to searching for graph neural networks on the CLRS Algorithmic Reasoning Benchmark, where EvoPrompting is able to design novel architectures that outperform current state-of-the-art models on 21 out of 30 algorithmic reasoning tasks while maintaining similar model size. EvoPrompting is successful at designing accurate and efficient neural network architectures across a variety of machine learning tasks, while also being general enough for easy adaptation to other tasks beyond neural network design.","created":"2023-02-28","meta":{"link":"http://arxiv.org/abs/2302.14838v1","tag":"prompt-eng"}}
{"title":"Meta Learning to Bridge Vision and Language Models for Multimodal Few-Shot Learning","abstract":"Multimodal few-shot learning is challenging due to the large domain gap between vision and language modalities. Existing methods are trying to communicate visual concepts as prompts to frozen language models, but rely on hand-engineered task induction to reduce the hypothesis space. To make the whole process learnable, we introduce a multimodal meta-learning approach. Specifically, our approach decomposes the training of the model into a set of related multimodal few-shot tasks. We define a meta-mapper network, acting as a meta-learner, to efficiently bridge frozen large-scale vision and language models and leverage their already learned capacity. By updating the learnable parameters only of the meta-mapper, it learns to accrue shared meta-knowledge among these tasks. Thus, it can rapidly adapt to newly presented samples with only a few gradient updates. Importantly, it induces the task in a completely data-driven manner, with no need for a hand-engineered task induction. We evaluate our approach on recently proposed multimodal few-shot benchmarks, measuring how rapidly the model can bind novel visual concepts to words and answer visual questions by observing only a limited set of labeled examples. The experimental results show that our meta-learning approach outperforms the baseline across multiple datasets and various training settings while being computationally more efficient.","created":"2023-02-28","meta":{"link":"http://arxiv.org/abs/2302.14794v1","tag":"prompt-eng"}}
{"title":"GLM-Dialog: Noise-tolerant Pre-training for Knowledge-grounded Dialogue Generation","abstract":"We present GLM-Dialog, a large-scale language model (LLM) with 10B parameters capable of knowledge-grounded conversation in Chinese using a search engine to access the Internet knowledge. GLM-Dialog offers a series of applicable techniques for exploiting various external knowledge including both helpful and noisy knowledge, enabling the creation of robust knowledge-grounded dialogue LLMs with limited proper datasets. To evaluate the GLM-Dialog more fairly, we also propose a novel evaluation method to allow humans to converse with multiple deployed bots simultaneously and compare their performance implicitly instead of explicitly rating using multidimensional metrics.Comprehensive evaluations from automatic to human perspective demonstrate the advantages of GLM-Dialog comparing with existing open source Chinese dialogue models. We release both the model checkpoint and source code, and also deploy it as a WeChat application to interact with users. We offer our evaluation platform online in an effort to prompt the development of open source models and reliable dialogue evaluation systems. The additional easy-to-use toolkit that consists of short text entity linking, query generation, and helpful knowledge classification is also released to enable diverse applications. All the source code is available on Github.","created":"2023-02-28","meta":{"link":"http://arxiv.org/abs/2302.14401v1","tag":"prompt-eng"}}
{"title":"Electric Vehicle Sales Forecasting Model Considering Green Premium: A Chinese Market-based Perspective","abstract":"\"Green Premiums\" which means the difference in cost between emissions-emitting technology and zero-emissions or emissions-reducing technology is significant for those renewable energy technology to address the climate change challenge facing the world in this century. China's Electrical Vehicles (EVs) industry is the first to cross the green premium into the commercialization stage, prompting its market size to exceed that of the US and EU combined, making it the most inspiring case in global carbon reduction practices. This study, which is based on first-hand data from industry research and innovatively constructs a multi-factor green premium model for EVs based on Total Cost of Ownership (TCO) analysis, finds that EVs currently have a higher green premium than Internal Combustion Engine Vehicles (ICEVs) and is expected that short-range EVs will be the first to achieve parity in acquisition costs by 2025 and long-range EVs by 2030. Further, this paper constructs a generalized Bass diffusion model considering the green premium, selects the time series data of EVs diffusion in the Chinese market from 2010-2021, and uses a genetic algorithm to fit the parameters to predict the EVs market penetration in the next ten years under different scenarios. The model prediction results show that EVs are successful innovative diffusion products and the market penetration rate depends largely on their green premium. The Chinese EVs market may experience a slowdown or even a decline in growth in the short term, but will maintain high growth in the medium to long term, with annual sales expected to reach 10.77 million units by 2030 and a penetration rate of about 39%.","created":"2023-02-27","meta":{"link":"http://arxiv.org/abs/2302.13893v1","tag":"prompt-eng"}}
{"title":"Robot Behavior-Tree-Based Task Generation with Large Language Models","abstract":"Nowadays, the behavior tree is gaining popularity as a representation for robot tasks due to its modularity and reusability. Designing behavior-tree tasks manually is time-consuming for robot end-users, thus there is a need for investigating automatic behavior-tree-based task generation. Prior behavior-tree-based task generation approaches focus on fixed primitive tasks and lack generalizability to new task domains. To cope with this issue, we propose a novel behavior-tree-based task generation approach that utilizes state-of-the-art large language models. We propose a Phase-Step prompt design that enables a hierarchical-structured robot task generation and further integrate it with behavior-tree-embedding-based search to set up the appropriate prompt. In this way, we enable an automatic and cross-domain behavior-tree task generation. Our behavior-tree-based task generation approach does not require a set of pre-defined primitive tasks. End-users only need to describe an abstract desired task and our proposed approach can swiftly generate the corresponding behavior tree. A full-process case study is provided to demonstrate our proposed approach. An ablation study is conducted to evaluate the effectiveness of our Phase-Step prompts. Assessment on Phase-Step prompts and the limitation of large language models are presented and discussed.","created":"2023-02-24","meta":{"link":"http://arxiv.org/abs/2302.12927v1","tag":"prompt-eng"}}
{"title":"Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data","abstract":"Chain-of-thought prompting (CoT) advances the reasoning abilities of large language models (LLMs) and achieves superior performance in arithmetic, commonsense, and symbolic reasoning tasks. However, most CoT studies rely on carefully designed human-annotated rational chains to prompt the language model, which poses challenges for real-world applications where labeled training data is available without human-annotated rational chains. This creates barriers to applications of CoT prompting to these general tasks. This paper proposes a new strategy, Automate-CoT (Automatic Prompt Augmentation and Selection with Chain-of-Thought), that can bypass human engineering of CoTs by automatically augmenting rational chains from a small labeled dataset, and then pruning low-quality chains to construct a candidate pool of machine-generated rationale chains based on the labels. Finally, it selects the optimal combination of several rationale chains from the pool for CoT prompting by employing a variance-reduced policy gradient strategy to estimate the significance of each example in a black-box language model. Automate-CoT enables a quick adaptation of the CoT technique to different tasks. Experimental results demonstrate the effectiveness of our method, where state-of-the-art results are achieved on arithmetic reasoning (+2.7\\%), commonsense reasoning (+3.4\\%), symbolic reasoning (+3.2\\%), and non-reasoning tasks (+2.5\\%). Our code will be available at https://github.com/shizhediao/automate-cot.","created":"2023-02-24","meta":{"link":"http://arxiv.org/abs/2302.12822v1","tag":"prompt-eng"}}
{"title":"Dr ChatGPT, tell me what I want to hear: How prompt knowledge impacts health answer correctness","abstract":"Generative pre-trained language models (GPLMs) like ChatGPT encode in the model's parameters knowledge the models observe during the pre-training phase. This knowledge is then used at inference to address the task specified by the user in their prompt. For example, for the question-answering task, the GPLMs leverage the knowledge and linguistic patterns learned at training to produce an answer to a user question. Aside from the knowledge encoded in the model itself, answers produced by GPLMs can also leverage knowledge provided in the prompts. For example, a GPLM can be integrated into a retrieve-then-generate paradigm where a search engine is used to retrieve documents relevant to the question; the content of the documents is then transferred to the GPLM via the prompt. In this paper we study the differences in answer correctness generated by ChatGPT when leveraging the model's knowledge alone vs. in combination with the prompt knowledge. We study this in the context of consumers seeking health advice from the model. Aside from measuring the effectiveness of ChatGPT in this context, we show that the knowledge passed in the prompt can overturn the knowledge encoded in the model and this is, in our experiments, to the detriment of answer correctness. This work has important implications for the development of more robust and transparent question-answering systems based on generative pre-trained language models.","created":"2023-02-23","meta":{"link":"http://arxiv.org/abs/2302.13793v1","tag":"prompt-eng"}}
{"title":"More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models","abstract":"We are currently witnessing dramatic advances in the capabilities of Large Language Models (LLMs). They are already being adopted in practice and integrated into many systems, including integrated development environments (IDEs) and search engines. The functionalities of current LLMs can be modulated via natural language prompts, while their exact internal functionality remains implicit and unassessable. This property, which makes them adaptable to even unseen tasks, might also make them susceptible to targeted adversarial prompting. Recently, several ways to misalign LLMs using Prompt Injection (PI) attacks have been introduced. In such attacks, an adversary can prompt the LLM to produce malicious content or override the original instructions and the employed filtering schemes. Recent work showed that these attacks are hard to mitigate, as state-of-the-art LLMs are instruction-following. So far, these attacks assumed that the adversary is directly prompting the LLM.   In this work, we show that augmenting LLMs with retrieval and API calling capabilities (so-called Application-Integrated LLMs) induces a whole new set of attack vectors. These LLMs might process poisoned content retrieved from the Web that contains malicious prompts pre-injected and selected by adversaries. We demonstrate that an attacker can indirectly perform such PI attacks. Based on this key insight, we systematically analyze the resulting threat landscape of Application-Integrated LLMs and discuss a variety of new attack vectors. To demonstrate the practical viability of our attacks, we implemented specific demonstrations of the proposed attacks within synthetic applications. In summary, our work calls for an urgent evaluation of current mitigation techniques and an investigation of whether new techniques are needed to defend LLMs against these threats.","created":"2023-02-23","meta":{"link":"http://arxiv.org/abs/2302.12173v1","tag":"prompt-eng"}}
{"title":"Controlled and Conditional Text to Image Generation with Diffusion Prior","abstract":"Denoising Diffusion models have shown remarkable performance in generating diverse, high quality images from text. Numerous techniques have been proposed on top of or in alignment with models like Stable Diffusion and Imagen that generate images directly from text. A lesser explored approach is DALLE-2's two step process comprising a Diffusion Prior that generates a CLIP image embedding from text and a Diffusion Decoder that generates an image from a CLIP image embedding. We explore the capabilities of the Diffusion Prior and the advantages of an intermediate CLIP representation. We observe that Diffusion Prior can be used in a memory and compute efficient way to constrain the generation to a specific domain without altering the larger Diffusion Decoder. Moreover, we show that the Diffusion Prior can be trained with additional conditional information such as color histogram to further control the generation. We show quantitatively and qualitatively that the proposed approaches perform better than prompt engineering for domain specific generation and existing baselines for color conditioned generation. We believe that our observations and results will instigate further research into the diffusion prior and uncover more of its capabilities.","created":"2023-02-23","meta":{"link":"http://arxiv.org/abs/2302.11710v1","tag":"prompt-eng"}}
{"title":"Implication of GRB 221009A: Can TeV Emission Come from the GRB Prompt Phase?","abstract":"Recently, the B.O.A.T. (\"brightest of all time\") gamma-ray burst, dubbed GRB 221009A, was detected by various instruments. Unprecedentedly, the GRB presented very-high-energy (VHE, energy above 0.1 TeV) gamma-ray emission with energy extending above 10 TeV, as reported by the Large High Altitude Air Shower Observatory (LHAASO). We here demonstrate that the VHE and especially >10 TeV emission may originate from the internal hadronic dissipation of the GRB, without the need of invoking any exotic processes as suggested by some previous studies. We also discuss the constraints on the properties of the GRB ejecta from multiwavelength and multi-messenger observations, which favors a magnetically dominated GRB ejecta. The suggested Poynting-flux-dominated GRB ejecta in this work supports the Blandford & Znajek (BZ) mechanism as the possible central engine model of GRB.","created":"2023-02-22","meta":{"link":"http://arxiv.org/abs/2302.11111v1","tag":"prompt-eng"}}
{"title":"RealFusion: 360\u00b0 Reconstruction of Any Object from a Single Image","abstract":"We consider the problem of reconstructing a full 360{\\deg} photographic model of an object from a single image of it. We do so by fitting a neural radiance field to the image, but find this problem to be severely ill-posed. We thus take an off-the-self conditional image generator based on diffusion and engineer a prompt that encourages it to \"dream up\" novel views of the object. Using an approach inspired by DreamFields and DreamFusion, we fuse the given input view, the conditional prior, and other regularizers in a final, consistent reconstruction. We demonstrate state-of-the-art reconstruction results on benchmark images when compared to prior methods for monocular 3D reconstruction of objects. Qualitatively, our reconstructions provide a faithful match of the input view and a plausible extrapolation of its appearance and 3D shape, including to the side of the object not visible in the image.","created":"2023-02-21","meta":{"link":"http://arxiv.org/abs/2302.10663v2","tag":"prompt-eng"}}
{"title":"A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT","abstract":"Prompt engineering is an increasingly important skill set needed to converse effectively with large language models (LLMs), such as ChatGPT. Prompts are instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated output. Prompts are also a form of programming that can customize the outputs and interactions with an LLM. This paper describes a catalog of prompt engineering techniques presented in pattern form that have been applied to solve common problems when conversing with LLMs. Prompt patterns are a knowledge transfer method analogous to software patterns since they provide reusable solutions to common problems faced in a particular context, i.e., output generation and interaction when working with LLMs. This paper provides the following contributions to research on prompt engineering that apply LLMs to automate software development tasks. First, it provides a framework for documenting patterns for structuring prompts to solve a range of problems so that they can be adapted to different domains. Second, it presents a catalog of patterns that have been applied successfully to improve the outputs of LLM conversations. Third, it explains how prompts can be built from multiple patterns and illustrates prompt patterns that benefit from combination with other prompt patterns.","created":"2023-02-21","meta":{"link":"http://arxiv.org/abs/2302.11382v1","tag":"prompt-eng"}}
{"title":"Prompt Stealing Attacks Against Text-to-Image Generation Models","abstract":"Text-to-Image generation models have revolutionized the artwork design process and enabled anyone to create high-quality images by entering text descriptions called prompts. Creating a high-quality prompt that consists of a subject and several modifiers can be time-consuming and costly. In consequence, a trend of trading high-quality prompts on specialized marketplaces has emerged. In this paper, we propose a novel attack, namely prompt stealing attack, which aims to steal prompts from generated images by text-to-image generation models. Successful prompt stealing attacks direct violate the intellectual property and privacy of prompt engineers and also jeopardize the business model of prompt trading marketplaces. We first perform a large-scale analysis on a dataset collected by ourselves and show that a successful prompt stealing attack should consider a prompt's subject as well as its modifiers. We then propose the first learning-based prompt stealing attack, PromptStealer, and demonstrate its superiority over two baseline methods quantitatively and qualitatively. We also make some initial attempts to defend PromptStealer. In general, our study uncovers a new attack surface in the ecosystem created by the popular text-to-image generation models. We hope our results can help to mitigate the threat. To facilitate research in this field, we will share our dataset and code with the community.","created":"2023-02-20","meta":{"link":"http://arxiv.org/abs/2302.09923v1","tag":"prompt-eng"}}
{"title":"Photometric and Spectroscopic Observations of GRB 190106A: Emission from Reverse and Forward Shocks with Late-time Energy Injection","abstract":"Early optical observations of gamma-ray bursts can significantly contribute to the study of the central engine and physical processes therein. However, of the thousands observed so far, still only a few have data at optical wavelengths in the first minutes after the onset of the prompt emission. Here we report on GRB\\,190106A, whose afterglow was observed in optical bands just 36 s after the {\\em Swift}/BAT trigger, i.e., during the prompt emission phase. The early optical afterglow exhibits a bimodal structure followed by a normal decay, with a faster decay after $\\sim \\rm T_{0}+$1 day. We present optical photometric and spectroscopic observations of GRB\\,190106A. We derive the redshift via metal absorption lines from Xinglong 2.16-m/BFOSC spectroscopic observations. From the BFOSC spectrum, we measure $z= 1.861\\pm0.002$. The double-peak optical light curve is a significant feature predicted by the reverse-forward external shock model. The shallow decay followed by a normal decay in both the X-ray and optical light curves is well explained with the standard forward-shock model with late-time energy injection. Therefore, GRB\\,190106A offers a case study for GRBs emission from both reverse and forward shocks.","created":"2023-02-20","meta":{"link":"http://arxiv.org/abs/2302.09722v2","tag":"prompt-eng"}}
{"title":"Few-shot Multimodal Multitask Multilingual Learning","abstract":"While few-shot learning as a transfer learning paradigm has gained significant traction for scenarios with limited data, it has primarily been explored in the context of building unimodal and unilingual models. Furthermore, a significant part of the existing literature in the domain of few-shot multitask learning perform in-context learning which requires manually generated prompts as the input, yielding varying outcomes depending on the level of manual prompt-engineering. In addition, in-context learning suffers from substantial computational, memory, and storage costs which eventually leads to high inference latency because it involves running all of the prompt's examples through the model every time a prediction is made. In contrast, methods based on the transfer learning via the fine-tuning paradigm avoid the aforementioned issues at a one-time cost of fine-tuning weights on a per-task basis. However, such methods lack exposure to few-shot multimodal multitask learning. In this paper, we propose few-shot learning for a multimodal multitask multilingual (FM3) setting by adapting pre-trained vision and language models using task-specific hypernetworks and contrastively fine-tuning them to enable few-shot learning. FM3's architecture combines the best of both worlds of in-context and fine-tuning based learning and consists of three major components: (i) multimodal contrastive fine-tuning to enable few-shot learning, (ii) hypernetwork task adaptation to perform multitask learning, and (iii) task-specific output heads to cater to a plethora of diverse tasks. FM3 learns the most prominent tasks in the vision and language domains along with their intersections, namely visual entailment (VE), visual question answering (VQA), and natural language understanding (NLU) tasks such as neural entity recognition (NER) and the GLUE benchmark including QNLI, MNLI, QQP, and SST-2.","created":"2023-02-19","meta":{"link":"http://arxiv.org/abs/2303.12489v1","tag":"prompt-eng"}}
{"title":"Prompting Large Language Models With the Socratic Method","abstract":"This paper presents a systematic approach to using the Socratic method in developing prompt templates that effectively interact with large language models, including GPT-3. Various methods are examined, and those that yield precise answers and justifications while fostering creativity and imagination to enhance creative writing are identified. Techniques such as {\\em definition}, {\\em elenchus}, {\\em dialectic}, {\\em maieutics}, {\\em generalization}, and {\\em counterfactual reasoning} are discussed for their application in engineering prompt templates and their connections to inductive, deductive, and abductive reasoning. Through examples, the effectiveness of these dialogue and reasoning methods is demonstrated. An interesting observation is made that when the task's goal and user intent are conveyed to GPT-3 via ChatGPT before the start of a dialogue, the large language model seems to connect to the external context expressed in the intent and perform more effectively.","created":"2023-02-17","meta":{"link":"http://arxiv.org/abs/2303.08769v2","tag":"prompt-eng"}}
{"title":"Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales","abstract":"The quality of text-to-image generation is continuously improving, yet the boundaries of its applicability are still unclear. In particular, refinement of the text input with the objective of achieving better results - commonly called prompt engineering - so far seems to have not been geared towards work with pre-existing texts. We investigate whether text-to-image generation and prompt engineering could be used to generate basic illustrations of popular fairytales. Using Midjourney v4, we engage in action research with a dual aim: to attempt to generate 5 believable illustrations for each of 5 popular fairytales, and to define a prompt engineering process that starts from a pre-existing text and arrives at an illustration of it. We arrive at a tentative 4-stage process: i) initial prompt, ii) composition adjustment, iii) style refinement, and iv) variation selection. We also discuss three reasons why the generation model struggles with certain illustrations: difficulties with counts, bias from stereotypical configurations and inability to depict overly fantastic situations. Our findings are not limited to the specific generation model and are intended to be generalisable to future ones.","created":"2023-02-17","meta":{"link":"http://arxiv.org/abs/2302.08961v1","tag":"prompt-eng"}}
{"title":"Learning Performance-Improving Code Edits","abstract":"The waning of Moore's Law has shifted the focus of the tech industry towards alternative methods for continued performance gains. While optimizing compilers are a standard tool to help increase program efficiency, programmers continue to shoulder much responsibility in crafting and refactoring code with better performance characteristics. In this paper, we investigate the ability of large language models (LLMs) to suggest functionally correct, performance improving code edits. We hypothesize that language models can suggest such edits in ways that would be impractical for static analysis alone. We investigate these questions by curating a large-scale dataset of Performance-Improving Edits, PIE. PIE contains trajectories of programs, where a programmer begins with an initial, slower version and iteratively makes changes to improve the program's performance. We use PIE to evaluate and improve the capacity of large language models. Specifically, use examples from PIE to fine-tune multiple variants of CODEGEN, a billion-scale Transformer-decoder model. Additionally, we use examples from PIE to prompt OpenAI's CODEX using a few-shot prompting. By leveraging PIE, we find that both CODEX and CODEGEN can generate performance-improving edits, with speedups of more than 2.5x for over 25% of the programs, for C++ and Python, even after the C++ programs were compiled using the O3 optimization level. Crucially, we show that PIE allows CODEGEN, an open-sourced and 10x smaller model than CODEX, to match the performance of CODEX on this challenging task. Overall, this work opens new doors for creating systems and methods that can help programmers write efficient code.","created":"2023-02-15","meta":{"link":"http://arxiv.org/abs/2302.07867v3","tag":"prompt-eng"}}
{"title":"Log Parsing with Prompt-based Few-shot Learning","abstract":"Logs generated by large-scale software systems provide crucial information for engineers to understand the system status and diagnose problems of the systems. Log parsing, which converts raw log messages into structured data, is the first step to enabling automated log analytics. Existing log parsers extract the common part as log templates using statistical features. However, these log parsers often fail to identify the correct templates and parameters because: 1) they often overlook the semantic meaning of log messages, and 2) they require domain-specific knowledge for different log datasets. To address the limitations of existing methods, in this paper, we propose LogPPT to capture the patterns of templates using prompt-based few-shot learning. LogPPT utilises a novel prompt tuning method to recognise keywords and parameters based on a few labelled log data. In addition, an adaptive random sampling algorithm is designed to select a small yet diverse training set. We have conducted extensive experiments on 16 public log datasets. The experimental results show that LogPPT is effective and efficient for log parsing.","created":"2023-02-15","meta":{"link":"http://arxiv.org/abs/2302.07435v1","tag":"prompt-eng"}}
{"title":"Heterogeneous Anomaly Detection for Software Systems via Semi-supervised Cross-modal Attention","abstract":"Prompt and accurate detection of system anomalies is essential to ensure the reliability of software systems. Unlike manual efforts that exploit all available run-time information, existing approaches usually leverage only a single type of monitoring data (often logs or metrics) or fail to make effective use of the joint information among different types of data. Consequently, many false predictions occur. To better understand the manifestations of system anomalies, we conduct a systematical study on a large amount of heterogeneous data, i.e., logs and metrics. Our study demonstrates that logs and metrics can manifest system anomalies collaboratively and complementarily, and neither of them only is sufficient. Thus, integrating heterogeneous data can help recover the complete picture of a system's health status. In this context, we propose Hades, the first end-to-end semi-supervised approach to effectively identify system anomalies based on heterogeneous data. Our approach employs a hierarchical architecture to learn a global representation of the system status by fusing log semantics and metric patterns. It captures discriminative features and meaningful interactions from heterogeneous data via a cross-modal attention module, trained in a semi-supervised manner. We evaluate Hades extensively on large-scale simulated data and datasets from Huawei Cloud. The experimental results present the effectiveness of our model in detecting system anomalies. We also release the code and the annotated dataset for replication and future research.","created":"2023-02-14","meta":{"link":"http://arxiv.org/abs/2302.06914v1","tag":"prompt-eng"}}
{"title":"Adaptive Test Generation Using a Large Language Model","abstract":"Unit tests play a key role in ensuring the correctness of software. However, manually creating unit tests is a laborious task, motivating the need for automation. This paper presents TestPilot, an adaptive test generation technique that leverages Large Language Models (LLMs). TestPilot uses Codex, an off-the-shelf LLM, to automatically generate unit tests for a given program without requiring additional training or few-shot learning on examples of existing tests. In our approach, Codex is provided with prompts that include the signature and implementation of a function under test, along with usage examples extracted from documentation. If a generated test fails, TestPilot's adaptive component attempts to generate a new test that fixes the problem by re-prompting the model with the failing test and error message. We created an implementation of TestPilot for JavaScript and evaluated it on 25 npm packages with a total of 1,684 API functions to generate tests for. Our results show that the generated tests achieve up to 93.1% statement coverage (median 68.2%). Moreover, on average, 58.5% of the generated tests contain at least one assertion that exercises functionality from the package under test. Our experiments with excluding parts of the information included in the prompts show that all components contribute towards the generation of effective test suites. Finally, we find that TestPilot does not generate memorized tests: 92.7% of our generated tests have $\\leq$ 50% similarity with existing tests (as measured by normalized edit distance), with none of them being exact copies.","created":"2023-02-13","meta":{"link":"http://arxiv.org/abs/2302.06527v2","tag":"prompt-eng"}}
{"title":"A Simple Zero-shot Prompt Weighting Technique to Improve Prompt Ensembling in Text-Image Models","abstract":"Contrastively trained text-image models have the remarkable ability to perform zero-shot classification, that is, classifying previously unseen images into categories that the model has never been explicitly trained to identify. However, these zero-shot classifiers need prompt engineering to achieve high accuracy. Prompt engineering typically requires hand-crafting a set of prompts for individual downstream tasks. In this work, we aim to automate this prompt engineering and improve zero-shot accuracy through prompt ensembling. In particular, we ask \"Given a large pool of prompts, can we automatically score the prompts and ensemble those that are most suitable for a particular downstream dataset, without needing access to labeled validation data?\". We demonstrate that this is possible. In doing so, we identify several pathologies in a naive prompt scoring method where the score can be easily overconfident due to biases in pre-training and test data, and we propose a novel prompt scoring method that corrects for the biases. Using our proposed scoring method to create a weighted average prompt ensemble, our method outperforms equal average ensemble, as well as hand-crafted prompts, on ImageNet, 4 of its variants, and 11 fine-grained classification benchmarks, all while being fully automatic, optimization-free, and not requiring access to labeled validation data.","created":"2023-02-13","meta":{"link":"http://arxiv.org/abs/2302.06235v1","tag":"prompt-eng"}}
{"title":"GRB 190114C: Fireball Energy Budget and Radiative Efficiency Revisited","abstract":"The jet composition of gamma-ray bursts (GRBs), as well as how efficiently the jet converts its energy to radiation, are long-standing problems in GRB physics. Here, we reported a comprehensive temporal and spectral analysis of the TeV-emitting bright GRB 190114C. Its high fluence ($\\sim$ 4.436$\\times$10$^{-4}$ erg cm$^{-2}$) allows us to conduct the time-resolved spectral analysis in great detail and study their variations down to a very short time-scale ($\\sim$0.1 s) while preserving a high significance. Its prompt emission consists of three well-separated pulses. The first two main pulses ($P_1$ and $P_2$) exhibit independently strong thermal components, and starting from the third pulse ($P_3$) and extending to the entire afterglow, the spectra are all non-thermal, the synchrotron plus Compton up-scattering model well interpret the observation. By combining the thermal ($P_1$ and $P_2$) and the non-thermal ($P_3$) observations based on two different scenarios (global and pulse properties) and following the method described in \\cite{Zhang2021}, we measure the fireball parameters and GRB radiative efficiency with little uncertainties for this GRB. A relevantly high GRB radiative efficiency is obtained based on both the global and pulse properties, suggesting that if GRBs are powered by fireballs, the efficiency can be high sometimes. More interestingly, though the observed parameters are individually different (e.g., the amount of mass loading $M$), the radiative efficiency obtained from $P_1$ ($\\eta_\\gamma=36.0\\pm6.5\\%$) and $P_2$ ($\\eta_\\gamma=41.1\\pm1.9\\%$) is roughly the same, which implies that the central engine of the same GRB has some common properties.","created":"2023-02-13","meta":{"link":"http://arxiv.org/abs/2302.06116v1","tag":"prompt-eng"}}
{"title":"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity","abstract":"This paper proposes a framework for quantitatively evaluating interactive LLMs such as ChatGPT using publicly available data sets. We carry out an extensive technical evaluation of ChatGPT using 23 data sets covering 8 different common NLP application tasks. We evaluate the multitask, multilingual and multi-modal aspects of ChatGPT based on these data sets and a newly designed multimodal dataset. We find that ChatGPT outperforms LLMs with zero-shot learning on most tasks and even outperforms fine-tuned models on some tasks. We find that it is better at understanding non-Latin script languages than generating them. It is able to generate multimodal content from textual prompts, via an intermediate code generation step. Moreover, we find that ChatGPT is 63.41% accurate on average in 10 different reasoning categories under logical reasoning, non-textual reasoning, and commonsense reasoning, hence making it an unreliable reasoner. It is, for example, better at deductive than inductive reasoning. ChatGPT suffers from hallucination problems like other LLMs and it generates more extrinsic hallucinations from its parametric memory as it does not have access to an external knowledge base. Finally, the interactive feature of ChatGPT enables human collaboration with the underlying LLM to improve its performance, i.e, 8% ROUGE-1 on summarization and 2% ChrF++ on machine translation, in a multi-turn \"prompt engineering\" fashion. We also release codebase for evaluation set extraction.","created":"2023-02-08","meta":{"link":"http://arxiv.org/abs/2302.04023v2","tag":"prompt-eng"}}
{"title":"Systematically Finding Security Vulnerabilities in Black-Box Code Generation Models","abstract":"Recently, large language models for code generation have achieved breakthroughs in several programming language tasks. Their advances in competition-level programming problems have made them an emerging pillar in AI-assisted pair programming. Tools such as GitHub Copilot are already part of the daily programming workflow and are used by more than a million developers. The training data for these models is usually collected from open-source repositories (e.g., GitHub) that contain software faults and security vulnerabilities. This unsanitized training data can lead language models to learn these vulnerabilities and propagate them in the code generation procedure. Given the wide use of these models in the daily workflow of developers, it is crucial to study the security aspects of these models systematically.   In this work, we propose the first approach to automatically finding security vulnerabilities in black-box code generation models. To achieve this, we propose a novel black-box inversion approach based on few-shot prompting. We evaluate the effectiveness of our approach by examining code generation models in the generation of high-risk security weaknesses. We show that our approach automatically and systematically finds 1000s of security vulnerabilities in various code generation models, including the commercial black-box model GitHub Copilot.","created":"2023-02-08","meta":{"link":"http://arxiv.org/abs/2302.04012v1","tag":"prompt-eng"}}
{"title":"ChatGPT and Software Testing Education: Promises & Perils","abstract":"Over the past decade, predictive language modeling for code has proven to be a valuable tool for enabling new forms of automation for developers. More recently, we have seen the advent of general purpose \"large language models\", based on neural transformer architectures, that have been trained on massive datasets of human written text spanning code and natural language. However, despite the demonstrated representational power of such models, interacting with them has historically been constrained to specific task settings, limiting their general applicability. Many of these limitations were recently overcome with the introduction of ChatGPT, a language model created by OpenAI and trained to operate as a conversational agent, enabling it to answer questions and respond to a wide variety of commands from end users. The introduction of models, such as ChatGPT, has already spurred fervent discussion from educators, ranging from fear that students could use these AI tools to circumvent learning, to excitement about the new types of learning opportunities that they might unlock. However, given the nascent nature of these tools, we currently lack fundamental knowledge related to how well they perform in different educational settings, and the potential promise (or danger) that they might pose to traditional forms of instruction. As such, in this paper, we examine how well ChatGPT performs when tasked with answering common questions in a popular software testing curriculum. Our findings indicate that ChatGPT can provide correct or partially correct answers in 55.6% of cases, provide correct or partially correct explanations of answers in 53.0% of cases, and that prompting the tool in a shared question context leads to a marginally higher rate of correct responses. Based on these findings, we discuss the potential promises and perils related to the use of ChatGPT by students and instructors.","created":"2023-02-07","meta":{"link":"http://arxiv.org/abs/2302.03287v3","tag":"prompt-eng"}}
{"title":"CHiLS: Zero-Shot Image Classification with Hierarchical Label Sets","abstract":"Open vocabulary models (e.g. CLIP) have shown strong performance on zero-shot classification through their ability generate embeddings for each class based on their (natural language) names. Prior work has focused on improving the accuracy of these models through prompt engineering or by incorporating a small amount of labeled downstream data (via finetuning). However, there has been little focus on improving the richness of the class names themselves, which can pose issues when class labels are coarsely-defined and uninformative. We propose Classification with Hierarchical Label Sets (or CHiLS), an alternative strategy for zero-shot classification specifically designed for datasets with implicit semantic hierarchies. CHiLS proceeds in three steps: (i) for each class, produce a set of subclasses, using either existing label hierarchies or by querying GPT-3; (ii) perform the standard zero-shot CLIP procedure as though these subclasses were the labels of interest; (iii) map the predicted subclass back to its parent to produce the final prediction. Across numerous datasets with underlying hierarchical structure, CHiLS leads to improved accuracy in situations both with and without ground-truth hierarchical information. CHiLS is simple to implement within existing CLIP pipelines and requires no additional training cost. Code is available at: https://github.com/acmi-lab/CHILS.","created":"2023-02-06","meta":{"link":"http://arxiv.org/abs/2302.02551v2","tag":"prompt-eng"}}
{"title":"Chat2VIS: Generating Data Visualisations via Natural Language using ChatGPT, Codex and GPT-3 Large Language Models","abstract":"The field of data visualisation has long aimed to devise solutions for generating visualisations directly from natural language text. Research in Natural Language Interfaces (NLIs) has contributed towards the development of such techniques. However, the implementation of workable NLIs has always been challenging due to the inherent ambiguity of natural language, as well as in consequence of unclear and poorly written user queries which pose problems for existing language models in discerning user intent. Instead of pursuing the usual path of developing new iterations of language models, this study uniquely proposes leveraging the advancements in pre-trained large language models (LLMs) such as ChatGPT and GPT-3 to convert free-form natural language directly into code for appropriate visualisations. This paper presents a novel system, Chat2VIS, which takes advantage of the capabilities of LLMs and demonstrates how, with effective prompt engineering, the complex problem of language understanding can be solved more efficiently, resulting in simpler and more accurate end-to-end solutions than prior approaches. Chat2VIS shows that LLMs together with the proposed prompts offer a reliable approach to rendering visualisations from natural language queries, even when queries are highly misspecified and underspecified. This solution also presents a significant reduction in costs for the development of NLI systems, while attaining greater visualisation inference abilities compared to traditional NLP approaches that use hand-crafted grammar rules and tailored models. This study also presents how LLM prompts can be constructed in a way that preserves data security and privacy while being generalisable to different datasets. This work compares the performance of GPT-3, Codex and ChatGPT across a number of case studies and contrasts the performances with prior studies.","created":"2023-02-04","meta":{"link":"http://arxiv.org/abs/2302.02094v2","tag":"prompt-eng"}}
{"title":"Fixing Hardware Security Bugs with Large Language Models","abstract":"Novel AI-based code-writing Large Language Models (LLMs) such as OpenAI's Codex have demonstrated capabilities in many coding-adjacent domains. In this work we consider how LLMs maybe leveraged to automatically repair security relevant bugs present in hardware designs. We focus on bug repair in code written in the Hardware Description Language Verilog. For this study we build a corpus of domain-representative hardware security bugs. We then design and implement a framework to quantitatively evaluate the performance of any LLM tasked with fixing the specified bugs. The framework supports design space exploration of prompts (i.e., prompt engineering) and identifying the best parameters for the LLM. We show that an ensemble of LLMs can repair all ten of our benchmarks. This ensemble outperforms the state-of-the-art Cirfix hardware bug repair tool on its own suite of bugs. These results show that LLMs can repair hardware security bugs and the framework is an important step towards the ultimate goal of an automated end-to-end bug repair framework.","created":"2023-02-02","meta":{"link":"http://arxiv.org/abs/2302.01215v1","tag":"prompt-eng"}}
{"title":"Trash to Treasure: Using text-to-image models to inform the design of physical artefacts","abstract":"Text-to-image generative models have recently exploded in popularity and accessibility. Yet so far, use of these models in creative tasks that bridge the 2D digital world and the creation of physical artefacts has been understudied. We conduct a pilot study to investigate if and how text-to-image models can be used to assist in upstream tasks within the creative process, such as ideation and visualization, prior to a sculpture-making activity. Thirty participants selected sculpture-making materials and generated three images using the Stable Diffusion text-to-image generator, each with text prompts of their choice, with the aim of informing and then creating a physical sculpture. The majority of participants (23/30) reported that the generated images informed their sculptures, and 28/30 reported interest in using text-to-image models to help them in a creative task in the future. We identify several prompt engineering strategies and find that a participant's prompting strategy relates to their stage in the creative process. We discuss how our findings can inform support for users at different stages of the design process and for using text-to-image models for physical artefact design.","created":"2023-02-01","meta":{"link":"http://arxiv.org/abs/2302.00561v1","tag":"prompt-eng"}}
{"title":"Conversational Automated Program Repair","abstract":"Automated Program Repair (APR) can help developers automatically generate patches for bugs. Due to the impressive performance obtained using Large Pre-Trained Language Models (LLMs) on many code related tasks, researchers have started to directly use LLMs for APR. However, prior approaches simply repeatedly sample the LLM given the same constructed input/prompt created from the original buggy code, which not only leads to generating the same incorrect patches repeatedly but also miss the critical information in testcases. To address these limitations, we propose conversational APR, a new paradigm for program repair that alternates between patch generation and validation in a conversational manner. In conversational APR, we iteratively build the input to the model by combining previously generated patches with validation feedback. As such, we leverage the long-term context window of LLMs to not only avoid generating previously incorrect patches but also incorporate validation feedback to help the model understand the semantic meaning of the program under test. We evaluate 10 different LLM including the newly developed ChatGPT model to demonstrate the improvement of conversational APR over the prior LLM for APR approach.","created":"2023-01-30","meta":{"link":"http://arxiv.org/abs/2301.13246v1","tag":"prompt-eng"}}
{"title":"Distilling Internet-Scale Vision-Language Models into Embodied Agents","abstract":"Instruction-following agents must ground language into their observation and action spaces. Learning to ground language is challenging, typically requiring domain-specific engineering or large quantities of human interaction data. To address this challenge, we propose using pretrained vision-language models (VLMs) to supervise embodied agents. We combine ideas from model distillation and hindsight experience replay (HER), using a VLM to retroactively generate language describing the agent's behavior. Simple prompting allows us to control the supervision signal, teaching an agent to interact with novel objects based on their names (e.g., planes) or their features (e.g., colors) in a 3D rendered environment. Fewshot prompting lets us teach abstract category membership, including pre-existing categories (food vs toys) and ad-hoc ones (arbitrary preferences over objects). Our work outlines a new and effective way to use internet-scale VLMs, repurposing the generic language grounding acquired by such models to teach task-relevant groundings to embodied agents.","created":"2023-01-29","meta":{"link":"http://arxiv.org/abs/2301.12507v1","tag":"prompt-eng"}}
{"title":"Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset","abstract":"It has been shown that accurate representation in media improves the well-being of the people who consume it. By contrast, inaccurate representations can negatively affect viewers and lead to harmful perceptions of other cultures. To achieve inclusive representation in generated images, we propose a culturally-aware priming approach for text-to-image synthesis using a small but culturally curated dataset that we collected, known here as Cross-Cultural Understanding Benchmark (CCUB) Dataset, to fight the bias prevalent in giant datasets. Our proposed approach is comprised of two fine-tuning techniques: (1) Adding visual context via fine-tuning a pre-trained text-to-image synthesis model, Stable Diffusion, on the CCUB text-image pairs, and (2) Adding semantic context via automated prompt engineering using the fine-tuned large language model, GPT-3, trained on our CCUB culturally-aware text data. CCUB dataset is curated and our approach is evaluated by people who have a personal relationship with that particular culture. Our experiments indicate that priming using both text and image is effective in improving the cultural relevance and decreasing the offensiveness of generated images while maintaining quality.","created":"2023-01-28","meta":{"link":"http://arxiv.org/abs/2301.12073v1","tag":"prompt-eng"}}
{"title":"User-Customizable Transpilation of Scripting Languages","abstract":"A transpiler converts code from one programming language to another. Many practical uses of transpilers require the user to be able to guide or customize the program produced from a given input program. This customizability is important for satisfying many application-specific goals for the produced code such as ensuring performance, readability, maintainability, compatibility, and so on. Conventional transpilers are deterministic rule-driven systems often written without offering customizability per user and per program. Recent advances in transpilers based on neural networks offer some customizability to users, e.g. through interactive prompts, but they are still difficult to precisely control the production of a desired output. Both conventional and neural transpilation also suffer from the \"last mile\" problem: they produce correct code on average, i.e., on most parts of a given program, but not necessarily for all parts of it. We propose a new transpilation approach that offers fine-grained customizability and reusability of transpilation rules created by others, without burdening the user to understand the global semantics of the given source program. Our approach is mostly automatic and incremental, i.e., constructs translation rules needed to transpile the given program as per the user's guidance piece-by-piece. We implement the transpiler as a tool called DuoGlot, which translates Python to Javascript programs, and evaluate it on the popular GeeksForGeeks benchmarks. DuoGlot achieves 90% translation accuracy and so it outperforms all existing translators, while it produces readable code. We evaluate DuoGlot on two additional benchmarks, containing more challenging and longer programs, and similarly observe improved accuracy.","created":"2023-01-26","meta":{"link":"http://arxiv.org/abs/2301.11220v2","tag":"prompt-eng"}}
{"title":"Is ChatGPT A Good Translator? Yes With GPT-4 As The Engine","abstract":"This report provides a preliminary evaluation of ChatGPT for machine translation, including translation prompt, multilingual translation, and translation robustness. We adopt the prompts advised by ChatGPT to trigger its translation ability and find that the candidate prompts generally work well and show minor performance differences. By evaluating on a number of benchmark test sets, we find that ChatGPT performs competitively with commercial translation products (e.g., Google Translate) on high-resource European languages but lags behind significantly on low-resource or distant languages. For distant languages, we explore an interesting strategy named $\\mathbf{pivot~prompting}$ that asks ChatGPT to translate the source sentence into a high-resource pivot language before into the target language, which improves the translation performance significantly. As for the translation robustness, ChatGPT does not perform as well as the commercial systems on biomedical abstracts or Reddit comments but exhibits good results on spoken language. With the launch of the GPT-4 engine, the translation performance of ChatGPT is significantly boosted, becoming comparable to commercial translation products, even for distant languages. In other words, $\\mathbf{ChatGPT~has~already~become~a~good~translator!}$ Scripts and data: https://github.com/wxjiao/Is-ChatGPT-A-Good-Translator","created":"2023-01-20","meta":{"link":"http://arxiv.org/abs/2301.08745v3","tag":"prompt-eng"}}
{"title":"A Case Study in Engineering a Conversational Programming Assistant's Persona","abstract":"The Programmer's Assistant is an experimental prototype software development environment that integrates a chatbot with a code editor. Conversational capability was achieved by using an existing code-fluent Large Language Model and providing it with a prompt that establishes a conversational interaction pattern, a set of conventions, and a style of interaction appropriate for the application. A discussion of the evolution of the prompt provides a case study in how to coax an existing foundation model to behave in a desirable manner for a particular application.","created":"2023-01-13","meta":{"link":"http://arxiv.org/abs/2301.10016v1","tag":"prompt-eng"}}
{"title":"API Entity and Relation Joint Extraction from Text via Dynamic Prompt-tuned Language Model","abstract":"Extraction of Application Programming Interfaces (APIs) and their semantic relations from unstructured text (e.g., Stack Overflow) is a fundamental work for software engineering tasks (e.g., API recommendation). However, existing approaches are rule-based and sequence-labeling based. They must manually enumerate the rules or label data for a wide range of sentence patterns, which involves a significant amount of labor overhead and is exacerbated by morphological and common-word ambiguity. In contrast to matching or labeling API entities and relations, this paper formulates heterogeneous API extraction and API relation extraction task as a sequence-to-sequence generation task, and proposes AERJE, an API entity-relation joint extraction model based on the large pre-trained language model. After training on a small number of ambiguous but correctly labeled data, AERJE builds a multi-task architecture that extracts API entities and relations from unstructured text using dynamic prompts. We systematically evaluate AERJE on a set of long and ambiguous sentences from Stack Overflow. The experimental results show that AERJE achieves high accuracy and discrimination ability in API entity-relation joint extraction, even with zero or few-shot fine-tuning.","created":"2023-01-10","meta":{"link":"http://arxiv.org/abs/2301.03987v1","tag":"prompt-eng"}}
{"title":"The Algonauts Project 2023 Challenge: How the Human Brain Makes Sense of Natural Scenes","abstract":"The sciences of biological and artificial intelligence are ever more intertwined. Neural computational principles inspire new intelligent machines, which are in turn used to advance theoretical understanding of the brain. To promote further exchange of ideas and collaboration between biological and artificial intelligence researchers, we introduce the 2023 installment of the Algonauts Project challenge: How the Human Brain Makes Sense of Natural Scenes (http://algonauts.csail.mit.edu). This installment prompts the fields of artificial and biological intelligence to come together towards building computational models of the visual brain using the largest and richest dataset of fMRI responses to visual scenes, the Natural Scenes Dataset (NSD). NSD provides high-quality fMRI responses to ~73,000 different naturalistic colored scenes, making it the ideal candidate for data-driven model building approaches promoted by the 2023 challenge. The challenge is open to all and makes results directly comparable and transparent through a public leaderboard automatically updated after each submission, thus allowing for rapid model development. We believe that the 2023 installment will spark symbiotic collaborations between biological and artificial intelligence scientists, leading to a deeper understanding of the brain through cutting-edge computational models and to novel ways of engineering artificial intelligent agents through inductive biases from biological systems.","created":"2023-01-09","meta":{"link":"http://arxiv.org/abs/2301.03198v2","tag":"prompt-eng"}}
{"title":"GRB minimum variability timescale with Insight-HXMT and Swift: implications for progenitor models, dissipation physics and GRB classifications","abstract":"The dissipation process of GRB prompt emission is still unknown. Study of temporal variability may provide a unique way to discriminate the imprint of the inner engine activity from geometry and propagation related effects. We define the minimum variability timescale (MVT) as the shortest duration of individual pulses that shape a light curve for a sample of GRBs and test correlations with peak luminosity, Lorentz factor, and jet opening angle. We compare these correlations with predictions from recent numerical simulations for a relativistic structured -- possibly wobbling -- jet and assess the value of MTV as probe of prompt-emission physics. We used the peak detection algorithm mepsa to identify the shortest pulse within a GRB time history and estimate its full width half maximum (FWHM). We applied this framework to two sets of GRBs: Swift (from 2005 to July 2022) and Insight-HXMT (from June 2017 to July 2021, including 221009A). We then selected 401 GRBs with measured z to test for correlations. On average short GRBs have significantly shorter MVT than long GRBs. The MVT distribution of short GRBs with extended emission such as 060614 and 211211A is compatible only with that of short GRBs. This provides a new clue on the progenitor's nature. The MVT for long GRBs anticorrelates with peak luminosity. We confirm the anticorrelation with the Lorentz factor and find a correlation with the jet opening angle as estimated from the afterglow, along with an inverse correlation with the number of pulses. The MVT can identify the emerging putative new class of long GRBs that are suggested to be produced by compact binary mergers. For otherwise typical long GRBs, the different correlations between MVT and peak luminosity, Lorentz factor, jet opening angle, and number of pulses can be explained within the context of structured, possibly wobbling, weakly magnetised relativistic jets. (summarised)","created":"2023-01-03","meta":{"link":"http://arxiv.org/abs/2301.01176v1","tag":"prompt-eng"}}
{"title":"GPT Takes the Bar Exam","abstract":"Nearly all jurisdictions in the United States require a professional license exam, commonly referred to as \"the Bar Exam,\" as a precondition for law practice. To even sit for the exam, most jurisdictions require that an applicant completes at least seven years of post-secondary education, including three years at an accredited law school. In addition, most test-takers also undergo weeks to months of further, exam-specific preparation. Despite this significant investment of time and capital, approximately one in five test-takers still score under the rate required to pass the exam on their first try. In the face of a complex task that requires such depth of knowledge, what, then, should we expect of the state of the art in \"AI?\" In this research, we document our experimental evaluation of the performance of OpenAI's `text-davinci-003` model, often-referred to as GPT-3.5, on the multistate multiple choice (MBE) section of the exam. While we find no benefit in fine-tuning over GPT-3.5's zero-shot performance at the scale of our training data, we do find that hyperparameter optimization and prompt engineering positively impacted GPT-3.5's zero-shot performance. For best prompt and parameters, GPT-3.5 achieves a headline correct rate of 50.3% on a complete NCBE MBE practice exam, significantly in excess of the 25% baseline guessing rate, and performs at a passing rate for both Evidence and Torts. GPT-3.5's ranking of responses is also highly-correlated with correctness; its top two and top three choices are correct 71% and 88% of the time, respectively, indicating very strong non-entailment performance. While our ability to interpret these results is limited by nascent scientific understanding of LLMs and the proprietary nature of GPT, we believe that these results strongly suggest that an LLM will pass the MBE component of the Bar Exam in the near future.","created":"2022-12-29","meta":{"link":"http://arxiv.org/abs/2212.14402v1","tag":"prompt-eng"}}
{"title":"Using Large Language Models to Generate Engaging Captions for Data Visualizations","abstract":"Creating compelling captions for data visualizations has been a longstanding challenge. Visualization researchers are typically untrained in journalistic reporting and hence the captions that are placed below data visualizations tend to be not overly engaging and rather just stick to basic observations about the data. In this work we explore the opportunities offered by the newly emerging crop of large language models (LLM) which use sophisticated deep learning technology to produce human-like prose. We ask, can these powerful software devices be purposed to produce engaging captions for generic data visualizations like a scatterplot. It turns out that the key challenge lies in designing the most effective prompt for the LLM, a task called prompt engineering. We report on first experiments using the popular LLM GPT-3 and deliver some promising results.","created":"2022-12-27","meta":{"link":"http://arxiv.org/abs/2212.14047v1","tag":"prompt-eng"}}
{"title":"Connecting the early afterglow to the prompt GRB and the central engine in the striped jet model","abstract":"Despite a generally accepted framework for describing the Gamma-Ray Burst (GRB) afterglows, the nature of the compact object at the central engine and the mechanism behind the prompt emission remain debated. The striped jet model is a promising venue to connect the various GRB stages since it gives a robust prediction for the relation of jet bulk acceleration, magnetization and dissipation profile as a function of distance. Here, we use the constraints of the magnetization and bulk Lorentz of the jet flow at the large scales where the jet starts interacting with the ambient gas in a large sample of bursts to (i) test the striped jet model for the GRB flow and (ii) study its predictions for the prompt emission and the constraints on the nature of the central engine. We find that the peak of the photospheric component of the emission predicted by the model is in agreement with the observed prompt emission spectra in the majority of the bursts in our sample, with a radiative efficiency of about 10 per cent. Furthermore, we adopt two different approaches to correlate the peak energies of the bursts with the type of central engine to find that more bursts are compatible with a neutron star central engine compared to a black hole one. Lastly, we conclude that the model favors broader distribution of stripe length-scales which results in a more gradual dissipation profile in comparison to the case where the jet stripes are characterized by a single length-scale.","created":"2022-12-21","meta":{"link":"http://arxiv.org/abs/2212.11406v1","tag":"prompt-eng"}}
{"title":"CORRPUS: Detecting Story Inconsistencies via Codex-Bootstrapped Neurosymbolic Reasoning","abstract":"Story generation and understanding -- as with all NLG/NLU tasks -- has seen a surge in neurosymbolic work. Researchers have recognized that, while large language models (LLMs) have tremendous utility, they can be augmented with symbolic means to be even better and to make up for any flaws that the neural networks might have. However, symbolic methods are extremely costly in terms of the amount of time and expertise needed to create them. In this work, we capitalize on state-of-the-art Code-LLMs, such as Codex, to bootstrap the use of symbolic methods for tracking the state of stories and aiding in story understanding. We show that our CoRRPUS system and abstracted prompting procedures can beat current state-of-the-art structured LLM techniques on pre-existing story understanding tasks (bAbI task 2 and Re^3) with minimal hand engineering. We hope that this work can help highlight the importance of symbolic representations and specialized prompting for LLMs as these models require some guidance for performing reasoning tasks properly.","created":"2022-12-21","meta":{"link":"http://arxiv.org/abs/2212.10754v1","tag":"prompt-eng"}}
{"title":"Searching for Prompt and Long-Lived Dark Photons in Electro-Produced $e^+e^-$ Pairs with the Heavy Photon Search Experiment at JLab","abstract":"The Heavy Photon Search experiment (HPS) at the Thomas Jefferson National Accelerator Facility searches for electro-produced dark photons. We report results from the 2016 Engineering Run consisting of 10608/nb of data for both the prompt and displaced vertex searches. A search for a prompt resonance in the $e^+e^-$ invariant mass distribution between 39 and 179 MeV showed no evidence of dark photons above the large QED background, limiting the coupling of {\\epsilon}^2 {\\geq} 10^-5, in agreement with previous searches. The search for displaced vertices showed no evidence of excess signal over background in the masses between 60 and 150 MeV, but had insufficient luminosity to limit canonical heavy photon production. This is the first displaced vertex search result published by HPS. HPS has taken high-luminosity data runs in 2019 and 2021 that will explore new dark photon phase space.","created":"2022-12-20","meta":{"link":"http://arxiv.org/abs/2212.10629v2","tag":"prompt-eng"}}
{"title":"Toward Human Readable Prompt Tuning: Kubrick's The Shining is a good movie, and a good prompt too?","abstract":"Large language models can perform new tasks in a zero-shot fashion, given natural language prompts that specify the desired behavior. Such prompts are typically hand engineered, but can also be learned with gradient-based methods from labeled data. However, it is underexplored what factors make the prompts effective, especially when the prompts are natural language. In this paper, we investigate common attributes shared by effective prompts. We first propose a human readable prompt tuning method (F LUENT P ROMPT) based on Langevin dynamics that incorporates a fluency constraint to find a diverse distribution of effective and fluent prompts. Our analysis reveals that effective prompts are topically related to the task domain and calibrate the prior probability of label words. Based on these findings, we also propose a method for generating prompts using only unlabeled data, outperforming strong baselines by an average of 7.0% accuracy across three tasks.","created":"2022-12-20","meta":{"link":"http://arxiv.org/abs/2212.10539v1","tag":"prompt-eng"}}
{"title":"DISCO: Distilling Phrasal Counterfactuals with Large Language Models","abstract":"Recent methods demonstrate that data augmentation using counterfactual knowledge can teach models the causal structure of a task, leading to robust and generalizable models. However, such counterfactual data often has a limited scale and diversity if crowdsourced and is computationally expensive to extend to new perturbation types if generated using supervised methods. To address this, we introduce a new framework called DISCO for automatically generating high-quality counterfactual data at scale. DISCO engineers prompts to generate phrasal perturbations with a large general language model. Then, a task-specific teacher model filters the generation to distill high-quality counterfactual data. We show that learning with this counterfactual data yields a comparatively small student model that is 6% (absolute) more robust and generalizes 5% better across distributions than baselines on various challenging evaluations. This model is also 15% more sensitive in differentiating original and counterfactual examples, on three evaluation sets written by human workers and via human-AI collaboration.","created":"2022-12-20","meta":{"link":"http://arxiv.org/abs/2212.10534v1","tag":"prompt-eng"}}
{"title":"ReCode: Robustness Evaluation of Code Generation Models","abstract":"Code generation models have achieved impressive performance. However, they tend to be brittle as slight edits to a prompt could lead to very different generations; these robustness properties, critical for user experience when deployed in real-life applications, are not well understood. Most existing works on robustness in text or code tasks have focused on classification, while robustness in generation tasks is an uncharted area and to date there is no comprehensive benchmark for robustness in code generation. In this paper, we propose ReCode, a comprehensive robustness evaluation benchmark for code generation models. We customize over 30 transformations specifically for code on docstrings, function and variable names, code syntax, and code format. They are carefully designed to be natural in real-life coding practice, preserve the original semantic meaning, and thus provide multifaceted assessments of a model's robustness performance. With human annotators, we verified that over 90% of the perturbed prompts do not alter the semantic meaning of the original prompt. In addition, we define robustness metrics for code generation models considering the worst-case behavior under each type of perturbation, taking advantage of the fact that executing the generated code can serve as objective evaluation. We demonstrate ReCode on SOTA models using HumanEval, MBPP, as well as function completion tasks derived from them. Interesting observations include: better robustness for CodeGen over InCoder and GPT-J; models are most sensitive to syntax perturbations; more challenging robustness evaluation on MBPP over HumanEval.","created":"2022-12-20","meta":{"link":"http://arxiv.org/abs/2212.10264v1","tag":"prompt-eng"}}
{"title":"Optimizing Prompts for Text-to-Image Generation","abstract":"Well-designed prompts can guide text-to-image models to generate amazing images. However, the performant prompts are often model-specific and misaligned with user input. Instead of laborious human engineering, we propose prompt adaptation, a general framework that automatically adapts original user input to model-preferred prompts. Specifically, we first perform supervised fine-tuning with a pretrained language model on a small collection of manually engineered prompts. Then we use reinforcement learning to explore better prompts. We define a reward function that encourages the policy to generate more aesthetically pleasing images while preserving the original user intentions. Experimental results on Stable Diffusion show that our method outperforms manual prompt engineering in terms of both automatic metrics and human preference ratings. Moreover, reinforcement learning further boosts performance, especially on out-of-domain prompts. The pretrained checkpoints are available at https://aka.ms/promptist. The demo can be found at https://aka.ms/promptist-demo.","created":"2022-12-19","meta":{"link":"http://arxiv.org/abs/2212.09611v1","tag":"prompt-eng"}}
{"title":"Explanation Regeneration via Information Bottleneck","abstract":"Explaining the black-box predictions of NLP models naturally and accurately is an important open problem in natural language generation. These free-text explanations are expected to contain sufficient and carefully-selected evidence to form supportive arguments for predictions. Due to the superior generative capacity of large pretrained language models, recent work built on prompt engineering enables explanation generation without specific training. However, explanation generated through single-pass prompting often lacks sufficiency and conciseness. To address this problem, we develop an information bottleneck method EIB to produce refined explanations that are sufficient and concise. Our approach regenerates the free-text explanation by polishing the single-pass output from the pretrained language model but retaining the information that supports the contents being explained. Experiments on two out-of-domain tasks verify the effectiveness of EIB through automatic evaluation and thoroughly-conducted human evaluation.","created":"2022-12-19","meta":{"link":"http://arxiv.org/abs/2212.09603v1","tag":"prompt-eng"}}
{"title":"Natural Language to Code Generation in Interactive Data Science Notebooks","abstract":"Computational notebooks, such as Jupyter notebooks, are interactive computing environments that are ubiquitous among data scientists to perform data wrangling and analytic tasks. To measure the performance of AI pair programmers that automatically synthesize programs for those tasks given natural language (NL) intents from users, we build ARCADE, a benchmark of 1082 code generation problems using the pandas data analysis framework in data science notebooks. ARCADE features multiple rounds of NL-to-code problems from the same notebook. It requires a model to understand rich multi-modal contexts, such as existing notebook cells and their execution states as well as previous turns of interaction. To establish a strong baseline on this challenging task, we develop PaChiNCo, a 62B code language model (LM) for Python computational notebooks, which significantly outperforms public code LMs. Finally, we explore few-shot prompting strategies to elicit better code with step-by-step decomposition and NL explanation, showing the potential to improve the diversity and explainability of model predictions.","created":"2022-12-19","meta":{"link":"http://arxiv.org/abs/2212.09248v1","tag":"prompt-eng"}}
{"title":"Scale invariance in X-ray flares of gamma-ray bursts","abstract":"X-ray flares are generally believed to be produced by the reactivation of the central engine, and may have the same energy dissipation mechanism as the prompt emission of gamma-ray bursts (GRBs). X-ray flares can therefore provide important clues to understanding the nature of the central engines of GRBs. In this work, we study for the first time the physical connection between differential size and return distributions of X-ray flares of GRBs with known redshifts. We find that the differential distributions of duration, energy, and waiting time can be well fitted by a power-law function. In particular, the distributions for the differences of durations, energies, and waiting times at different times (i.e., the return distributions) well follow a $q$-Gaussian form. The $q$ values in the $q$-Gaussian distributions remain nearly steady for different temporal interval scales, implying a scale-invariant structure of GRB X-ray flares. Moreover, we verify that the $q$ parameters are related to the power-law indices $\\alpha$ of the differential size distributions, characterized as $q=(\\alpha+2)/\\alpha$. These statistical features can be well explained within the physical framework of a self-organizing criticality system.","created":"2022-12-17","meta":{"link":"http://arxiv.org/abs/2212.08813v2","tag":"prompt-eng"}}
{"title":"Fake it till you make it: Learning transferable representations from synthetic ImageNet clones","abstract":"Recent image generation models such as Stable Diffusion have exhibited an impressive ability to generate fairly realistic images starting from a simple text prompt. Could such models render real images obsolete for training image prediction models? In this paper, we answer part of this provocative question by investigating the need for real images when training models for ImageNet classification. Provided only with the class names that have been used to build the dataset, we explore the ability of Stable Diffusion to generate synthetic clones of ImageNet and measure how useful these are for training classification models from scratch. We show that with minimal and class-agnostic prompt engineering, ImageNet clones are able to close a large part of the gap between models produced by synthetic images and models trained with real images, for the several standard classification benchmarks that we consider in this study. More importantly, we show that models trained on synthetic images exhibit strong generalization properties and perform on par with models trained on real data for transfer. Project page: https://europe.naverlabs.com/imagenet-sd/","created":"2022-12-16","meta":{"link":"http://arxiv.org/abs/2212.08420v2","tag":"prompt-eng"}}
{"title":"SE Factual Knowledge in Frozen Giant Code Model: A Study on FQN and its Retrieval","abstract":"Pre-trained giant code models (PCMs) start coming into the developers' daily practices. Understanding what types of and how much software knowledge is packed into PCMs is the foundation for incorporating PCMs into software engineering (SE) tasks and fully releasing their potential. In this work, we conduct the first systematic study on the SE factual knowledge in the state-of-the-art PCM CoPilot, focusing on APIs' Fully Qualified Names (FQNs), the fundamental knowledge for effective code analysis, search and reuse. Driven by FQNs' data distribution properties, we design a novel lightweight in-context learning on Copilot for FQN inference, which does not require code compilation as traditional methods or gradient update by recent FQN prompt-tuning. We systematically experiment with five in-context-learning design factors to identify the best in-context learning configuration that developers can adopt in practice. With this best configuration, we investigate the effects of amount of example prompts and FQN data properties on Copilot's FQN inference capability. Our results confirm that Copilot stores diverse FQN knowledge and can be applied for the FQN inference due to its high inference accuracy and non-reliance on code analysis. Based on our experience interacting with Copilot, we discuss various opportunities to improve human-CoPilot interaction in the FQN inference task.","created":"2022-12-16","meta":{"link":"http://arxiv.org/abs/2212.08221v1","tag":"prompt-eng"}}
{"title":"Artificial Intelligence for Health Message Generation: Theory, Method, and an Empirical Study Using Prompt Engineering","abstract":"This study introduces and examines the potential of an AI system to generate health awareness messages. The topic of folic acid, a vitamin that is critical during pregnancy, served as a test case. Using prompt engineering, we generated messages that could be used to raise awareness and compared them to retweeted human-generated messages via computational and human evaluation methods. The system was easy to use and prolific, and computational analyses revealed that the AI-generated messages were on par with human-generated ones in terms of sentiment, reading ease, and semantic content. Also, the human evaluation study showed that AI-generated messages ranked higher in message quality and clarity. We discuss the theoretical, practical, and ethical implications of these results.","created":"2022-12-14","meta":{"link":"http://arxiv.org/abs/2212.07507v1","tag":"prompt-eng"}}
{"title":"The Infinite Index: Information Retrieval on Generative Text-To-Image Models","abstract":"Conditional generative models such as DALL-E and Stable Diffusion generate images based on a user-defined text, the prompt. Finding and refining prompts that produce a desired image has become the art of prompt engineering. Generative models do not provide a built-in retrieval model for a user's information need expressed through prompts. In light of an extensive literature review, we reframe prompt engineering for generative models as interactive text-based retrieval on a novel kind of \"infinite index\". We apply these insights for the first time in a case study on image generation for game design with an expert. Finally, we envision how active learning may help to guide the retrieval of generated images.","created":"2022-12-14","meta":{"link":"http://arxiv.org/abs/2212.07476v2","tag":"prompt-eng"}}
{"title":"Evidence of high latitude emission in the prompt phase of GRBs: How far from the central engine are the GRBs produced?","abstract":"The physical mechanism of gamma-ray bursts (GRBs) remains elusive. One of the difficulties in nailing down their physical mechanism comes from the fact that there has been no clear observational evidence on how far from the central engine the prompt gamma-rays of GRBs are emitted while the competing physical mechanisms predict different characteristic distances. Here we present a simple study addressing this question by making use of the \"high-latitude emission\" (HLE). We show that our detailed numerical modeling exhibits a clear signature of HLE in the decaying phase of \"broad pulses\" of GRBs. We show that the HLE can emerge as a prominent spectral break in $F_{\\nu}$ spectra and dominate the peak of $\\nu F_{\\nu}$ spectra even while the \"line-of-sight emission\" (LoSE) is still ongoing, hence providing a new view of HLE emergence. We remark that this \"HLE break\" could be hidden in some broad pulses, depending on the proximity between the peak energies of the LoSE and the HLE. Also, we present three examples of Fermi-GBM GRBs with broad pulses that exhibit the HLE signature. We show that their gamma-ray emitting region should be located at $\\sim 10^{16}$ cm from the central engine, which disfavors the photosphere models and small-radii internal shock models but favors magnetic dissipation models with a large emission radius.","created":"2022-12-14","meta":{"link":"http://arxiv.org/abs/2212.07094v2","tag":"prompt-eng"}}
{"title":"ERNIE-Code: Beyond English-Centric Cross-lingual Pretraining for Programming Languages","abstract":"Software engineers working with the same programming language (PL) may speak different natural languages (NLs) and vice versa, erecting huge barriers to communication and working efficiency. Recent studies have demonstrated the effectiveness of generative pre-training in computer programs, yet they are always English-centric. In this work, we step towards bridging the gap between multilingual NLs and multilingual PLs for large language models (LLMs). We release ERNIE-Code, a unified pre-trained language model for 116 NLs and 6 PLs. We employ two methods for universal cross-lingual pre-training: span-corruption language modeling that learns patterns from monolingual NL or PL; and pivot-based translation language modeling that relies on parallel data of many NLs and PLs. Extensive results show that ERNIE-Code outperforms previous multilingual LLMs for PL or NL across a wide range of end tasks of code intelligence, including multilingual code-to-text, text-to-code, code-to-code, and text-to-text generation. We further show its advantage of zero-shot prompting on multilingual code summarization and text-to-text translation. We will make our code and pre-trained models publicly available.","created":"2022-12-13","meta":{"link":"http://arxiv.org/abs/2212.06742v1","tag":"prompt-eng"}}
{"title":"Automatically Generating CS Learning Materials with Large Language Models","abstract":"Recent breakthroughs in Large Language Models (LLMs), such as GPT-3 and Codex, now enable software developers to generate code based on a natural language prompt. Within computer science education, researchers are exploring the potential for LLMs to generate code explanations and programming assignments using carefully crafted prompts. These advances may enable students to interact with code in new ways while helping instructors scale their learning materials. However, LLMs also introduce new implications for academic integrity, curriculum design, and software engineering careers. This workshop will demonstrate the capabilities of LLMs to help attendees evaluate whether and how LLMs might be integrated into their pedagogy and research. We will also engage attendees in brainstorming to consider how LLMs will impact our field.","created":"2022-12-09","meta":{"link":"http://arxiv.org/abs/2212.05113v1","tag":"prompt-eng"}}
{"title":"Fill in the Blank: Context-aware Automated Text Input Generation for Mobile GUI Testing","abstract":"Automated GUI testing is widely used to help ensure the quality of mobile apps. However, many GUIs require appropriate text inputs to proceed to the next page which remains a prominent obstacle for testing coverage. Considering the diversity and semantic requirement of valid inputs (e.g., flight departure, movie name), it is challenging to automate the text input generation. Inspired by the fact that the pre-trained Large Language Model (LLM) has made outstanding progress in text generation, we propose an approach named QTypist based on LLM for intelligently generating semantic input text according to the GUI context. To boost the performance of LLM in the mobile testing scenario, we develop a prompt-based data construction and tuning method which automatically extracts the prompts and answers for model tuning. We evaluate QTypist on 106 apps from Google Play and the result shows that the passing rate of QTypist is 87%, which is 93% higher than the best baseline. We also integrate QTypist with the automated GUI testing tools and it can cover 42% more app activities, 52% more pages, and subsequently help reveal 122% more bugs compared with the raw tool.","created":"2022-12-09","meta":{"link":"http://arxiv.org/abs/2212.04732v1","tag":"prompt-eng"}}
{"title":"PromptonomyViT: Multi-Task Prompt Learning Improves Video Transformers using Synthetic Scene Data","abstract":"Action recognition models have achieved impressive results by incorporating scene-level annotations, such as objects, their relations, 3D structure, and more. However, obtaining annotations of scene structure for videos requires a significant amount of effort to gather and annotate, making these methods expensive to train. In contrast, synthetic datasets generated by graphics engines provide powerful alternatives for generating scene-level annotations across multiple tasks. In this work, we propose an approach to leverage synthetic scene data for improving video understanding. We present a multi-task prompt learning approach for video transformers, where a shared video transformer backbone is enhanced by a small set of specialized parameters for each task. Specifically, we add a set of ``task prompts'', each corresponding to a different task, and let each prompt predict task-related annotations. This design allows the model to capture information shared among synthetic scene tasks as well as information shared between synthetic scene tasks and a real video downstream task throughout the entire network. We refer to this approach as ``Promptonomy'', since the prompts model task-related structure. We propose the PromptonomyViT model (PViT), a video transformer that incorporates various types of scene-level information from synthetic data using the ``Promptonomy'' approach. PViT shows strong performance improvements on multiple video understanding tasks and datasets.","created":"2022-12-08","meta":{"link":"http://arxiv.org/abs/2212.04821v2","tag":"prompt-eng"}}
{"title":"Towards using Few-Shot Prompt Learning for Automating Model Completion","abstract":"We propose a simple yet a novel approach to improve completion in domain modeling activities. Our approach exploits the power of large language models by using few-shot prompt learning without the need to train or fine-tune those models with large datasets that are scarce in this field. We implemented our approach and tested it on the completion of static and dynamic domain diagrams. Our initial evaluation shows that such an approach is effective and can be integrated in different ways during the modeling activities.","created":"2022-12-07","meta":{"link":"http://arxiv.org/abs/2212.03404v1","tag":"prompt-eng"}}
{"title":"Legal Prompt Engineering for Multilingual Legal Judgement Prediction","abstract":"Legal Prompt Engineering (LPE) or Legal Prompting is a process to guide and assist a large language model (LLM) with performing a natural legal language processing (NLLP) skill. Our goal is to use LPE with LLMs over long legal documents for the Legal Judgement Prediction (LJP) task. We investigate the performance of zero-shot LPE for given facts in case-texts from the European Court of Human Rights (in English) and the Federal Supreme Court of Switzerland (in German, French and Italian). Our results show that zero-shot LPE is better compared to the baselines, but it still falls short compared to current state of the art supervised approaches. Nevertheless, the results are important, since there was 1) no explicit domain-specific data used - so we show that the transfer to the legal domain is possible for general-purpose LLMs, and 2) the LLMs where directly applied without any further training or fine-tuning - which in turn saves immensely in terms of additional computational costs.","created":"2022-12-05","meta":{"link":"http://arxiv.org/abs/2212.02199v1","tag":"prompt-eng"}}
{"title":"Pseudo Redshifts of Gamma-Ray Bursts Derived from the L-T-E Correlation","abstract":"The X-ray afterglow of many gamma-ray bursts (GRBs) exhibits a plateau phase before the normal power-law decay stage, which may be related to continued activities of the central engine. Tang et al. 2019 collected 174 such GRBs and confirmed the so called $L-T-E$ correlation which involves three key parameters, i.e., the isotropic $\\gamma$-ray energy $E_{\\gamma,\\rm iso}$ of the prompt phase, the end time $T_{a}$ of the plateau phase and the corresponding X-ray luminosity $L_{X}$. In this study, the $L-T-E$ correlation is confirmed and updated as $L_{X} \\propto T_{a}^{-0.99} E_{\\gamma ,\\rm iso}^{0.86}$ with a large sample consisting of 210 plateau GRBs with known redshifts. The tight correlation is then applied to derive the pseudo redshift of other 130 plateau GRBs whose redshifts are not directly measured. Statistical analysis is also carried out on this pseudo redshift sample.","created":"2022-12-05","meta":{"link":"http://arxiv.org/abs/2212.01990v1","tag":"prompt-eng"}}
{"title":"Controllable Image Captioning via Prompting","abstract":"Despite the remarkable progress of image captioning, existing captioners typically lack the controllable capability to generate desired image captions, e.g., describing the image in a rough or detailed manner, in a factual or emotional view, etc. In this paper, we show that a unified model is qualified to perform well in diverse domains and freely switch among multiple styles. Such a controllable capability is achieved by embedding the prompt learning into the image captioning framework. To be specific, we design a set of prompts to fine-tune the pre-trained image captioner. These prompts allow the model to absorb stylized data from different domains for joint training, without performance degradation in each domain. Furthermore, we optimize the prompts with learnable vectors in the continuous word embedding space, avoiding the heuristic prompt engineering and meanwhile exhibiting superior performance. In the inference stage, our model is able to generate desired stylized captions by choosing the corresponding prompts. Extensive experiments verify the controllable capability of the proposed method. Notably, we achieve outstanding performance on two diverse image captioning benchmarks including COCO Karpathy split and TextCaps using a unified model.","created":"2022-12-04","meta":{"link":"http://arxiv.org/abs/2212.01803v1","tag":"prompt-eng"}}
{"title":"AI-driven Mobile Apps: an Explorative Study","abstract":"Recent years have witnessed an astonishing explosion in the evolution of mobile applications powered by AI technologies. The rapid growth of AI frameworks enables the transition of AI technologies to mobile devices, significantly prompting the adoption of AI apps (i.e., apps that integrate AI into their functions) among smartphone devices. In this paper, we conduct the most extensive empirical study on 56,682 published AI apps from three perspectives: dataset characteristics, development issues, and user feedback and privacy. To this end, we build an automated AI app identification tool, AI Discriminator, that detects eligible AI apps from 7,259,232 mobile apps. First, we carry out a dataset analysis, where we explore the AndroZoo large repository to identify AI apps and their core characteristics. Subsequently, we pinpoint key issues in AI app development (e.g., model protection). Finally, we focus on user reviews and user privacy protection. Our paper provides several notable findings. Some essential ones involve revealing the issue of insufficient model protection by presenting the lack of model encryption, and demonstrating the risk of user privacy data being leaked. We published our large-scale AI app datasets to inspire more future research.","created":"2022-12-03","meta":{"link":"http://arxiv.org/abs/2212.01635v1","tag":"prompt-eng"}}
{"title":"Legal Prompting: Teaching a Language Model to Think Like a Lawyer","abstract":"Large language models that are capable of zero or few-shot prompting approaches have given rise to the new research area of prompt engineering. Recent advances showed that for example Chain-of-Thought (CoT) prompts can improve arithmetic or common sense tasks significantly. We explore how such approaches fare with legal reasoning tasks and take the COLIEE entailment task based on the Japanese Bar exam for testing zero-shot/few-shot and fine-tuning approaches. Our findings show that while CoT prompting and fine-tuning with explanations approaches show improvements, the best results are produced by prompts that are derived from specific legal reasoning techniques such as IRAC (Issue, Rule, Application, Conclusion). Based on our experiments we improve the 2021 best result from 0.7037 accuracy to 0.8148 accuracy and beat the 2022 best system of 0.6789 accuracy with an accuracy of 0.7431.","created":"2022-12-02","meta":{"link":"http://arxiv.org/abs/2212.01326v2","tag":"prompt-eng"}}
{"title":"Multi-messenger model for the prompt emission from GRB 221009A","abstract":"We present a multi-messenger model for the prompt emission from GRB 221009A within the internal shock scenario. We consider the time-dependent evolution of the outflow with its impact on the observed light curve from multiple collisions, and the self-consistent generation of the electromagnetic spectrum in synchrotron and inverse Compton-dominated scenarios. Our leptohadronic model includes UHE protons potentially accelerated in the outflow, and their feedback on spectral energy distribution and on the neutrino emission. We find that we can roughly reproduce the observed light curves with an engine with varying ejection velocity of ultra-relativistic material, which has an intermediate quiescent period of about 200 seconds and a variability timescale of $\\sim1$~s. We consider baryonic loadings of 3 and 30 that are compatible with the hypothesis that the highest-energetic LHAASO photons might come from UHECR interactions with the extragalactic background light, and the paradigm that energetic GRBs may power the UHECR flux. For these values and the high dissipation radii considered we find consistency with the non-observation of neutrinos and no significant signatures on the electromagnetic spectrum. Inverse Compton-dominated scenarios from the prompt emission are demonstrated to lead to about an order of magnitude higher fluxes in the HE-range; this enhancement is testable by its spectral impact in the Fermi-GBM and LAT ranges.","created":"2022-12-01","meta":{"link":"http://arxiv.org/abs/2212.00766v3","tag":"prompt-eng"}}
{"title":"Coder Reviewer Reranking for Code Generation","abstract":"Sampling diverse programs from a code language model and reranking with model likelihood is a popular method for code generation but it is prone to preferring degenerate solutions. Inspired by collaborative programming, we propose Coder-Reviewer reranking. We augment Coder language models from past work, which generate programs given language instructions, with Reviewer models, which evaluate the likelihood of the instruction given the generated programs. We perform an extensive study across six datasets with eight models from three model families. Experimental results show that Coder-Reviewer reranking leads to consistent and significant improvement (up to 17% absolute accuracy gain) over reranking with the Coder model only. When combined with executability filtering, Coder-Reviewer reranking can often outperform the minimum Bayes risk method. Coder-Reviewer reranking is easy to implement by prompting, can generalize to different programming languages, and works well with off-the-shelf hyperparameters.","created":"2022-11-29","meta":{"link":"http://arxiv.org/abs/2211.16490v1","tag":"prompt-eng"}}
{"title":"Arguments to Key Points Mapping with Prompt-based Learning","abstract":"Handling and digesting a huge amount of information in an efficient manner has been a long-term demand in modern society. Some solutions to map key points (short textual summaries capturing essential information and filtering redundancies) to a large number of arguments/opinions have been provided recently (Bar-Haim et al., 2020). To complement the full picture of the argument-to-keypoint mapping task, we mainly propose two approaches in this paper. The first approach is to incorporate prompt engineering for fine-tuning the pre-trained language models (PLMs). The second approach utilizes prompt-based learning in PLMs to generate intermediary texts, which are then combined with the original argument-keypoint pairs and fed as inputs to a classifier, thereby mapping them. Furthermore, we extend the experiments to cross/in-domain to conduct an in-depth analysis. In our evaluation, we find that i) using prompt engineering in a more direct way (Approach 1) can yield promising results and improve the performance; ii) Approach 2 performs considerably worse than Approach 1 due to the negation issue of the PLM.","created":"2022-11-28","meta":{"link":"http://arxiv.org/abs/2211.14995v1","tag":"prompt-eng"}}
{"title":"Investigating Prompt Engineering in Diffusion Models","abstract":"With the spread of the use of Text2Img diffusion models such as DALL-E 2, Imagen, Mid Journey and Stable Diffusion, one challenge that artists face is selecting the right prompts to achieve the desired artistic output. We present techniques for measuring the effect that specific words and phrases in prompts have, and (in the Appendix) present guidance on the selection of prompts to produce desired effects.","created":"2022-11-21","meta":{"link":"http://arxiv.org/abs/2211.15462v1","tag":"prompt-eng"}}
{"title":"Using Developer Discussions to Guide Fixing Bugs in Software","abstract":"Automatically fixing software bugs is a challenging task. While recent work showed that natural language context is useful in guiding bug-fixing models, the approach required prompting developers to provide this context, which was simulated through commit messages written after the bug-fixing code changes were made. We instead propose using bug report discussions, which are available before the task is performed and are also naturally occurring, avoiding the need for any additional information from developers. For this, we augment standard bug-fixing datasets with bug report discussions. Using these newly compiled datasets, we demonstrate that various forms of natural language context derived from such discussions can aid bug-fixing, even leading to improved performance over using commit messages corresponding to the oracle bug-fixing commits.","created":"2022-11-11","meta":{"link":"http://arxiv.org/abs/2211.06335v1","tag":"prompt-eng"}}
{"title":"A Prompt-based Few-shot Learning Approach to Software Conflict Detection","abstract":"A software requirement specification (SRS) document is an essential part of the software development life cycle which outlines the requirements that a software program in development must satisfy. This document is often specified by a diverse group of stakeholders and is subject to continual change, making the process of maintaining the document and detecting conflicts between requirements an essential task in software development. Notably, projects that do not address conflicts in the SRS document early on face considerable problems later in the development life cycle. These problems incur substantial costs in terms of time and money, and these costs often become insurmountable barriers that ultimately result in the termination of a software project altogether. As a result, early detection of SRS conflicts is critical to project sustainability. The conflict detection task is approached in numerous ways, many of which require a significant amount of manual intervention from developers, or require access to a large amount of labeled, task-specific training data. In this work, we propose using a prompt-based learning approach to perform few-shot learning for conflict detection. We compare our results to supervised learning approaches that use pretrained language models, such as BERT and its variants. Our results show that prompting with just 32 labeled examples can achieve a similar level of performance in many key metrics to that of supervised learning on training sets that are magnitudes larger in size. In contrast to many other conflict detection approaches, we make no assumptions about the type of underlying requirements, allowing us to analyze pairings of both functional and non-functional requirements. This allows us to omit the potentially expensive task of filtering out non-functional requirements from our dataset.","created":"2022-11-04","meta":{"link":"http://arxiv.org/abs/2211.02709v1","tag":"prompt-eng"}}
{"title":"Large Language Models Are Human-Level Prompt Engineers","abstract":"By conditioning on natural language instructions, large language models (LLMs) have displayed impressive capabilities as general-purpose computers. However, task performance depends significantly on the quality of the prompt used to steer the model, and most effective prompts have been handcrafted by humans. Inspired by classical program synthesis and the human approach to prompt engineering, we propose Automatic Prompt Engineer (APE) for automatic instruction generation and selection. In our method, we treat the instruction as the \"program,\" optimized by searching over a pool of instruction candidates proposed by an LLM in order to maximize a chosen score function. To evaluate the quality of the selected instruction, we evaluate the zero-shot performance of another LLM following the selected instruction. Experiments on 24 NLP tasks show that our automatically generated instructions outperform the prior LLM baseline by a large margin and achieve better or comparable performance to the instructions generated by human annotators on 19/24 tasks. We conduct extensive qualitative and quantitative analyses to explore the performance of APE. We show that APE-engineered prompts can be applied to steer models toward truthfulness and/or informativeness, as well as to improve few-shot learning performance by simply prepending them to standard in-context learning prompts. Please check out our webpage at https://sites.google.com/view/automatic-prompt-engineer.","created":"2022-11-03","meta":{"link":"http://arxiv.org/abs/2211.01910v2","tag":"prompt-eng"}}
{"title":"Towards Zero-Shot and Few-Shot Table Question Answering using GPT-3","abstract":"We present very early results on using GPT-3 to perform question answering on tabular data. We find that stock pre-trained GPT-3 is able to zero-shot learn the table structure from a serialized JSON array-of-arrays representation, and able to answer lookup queries and simple comparison questions in natural language without any fine-tuning. We further find that simple prompt engineering to include few-shot static Q&A examples significantly improves accuracy. Lastly, we find that intermixing passage text improves accuracy even further on heterogeneous data. We apply our approach on a novel dataset of simple tables in newspaper infographics with promising results. Overall, we find much cause for optimism in this basic approach.","created":"2022-10-31","meta":{"link":"http://arxiv.org/abs/2210.17284v1","tag":"prompt-eng"}}
{"title":"Beyond Prompting: Making Pre-trained Language Models Better Zero-shot Learners by Clustering Representations","abstract":"Recent work has demonstrated that pre-trained language models (PLMs) are zero-shot learners. However, most existing zero-shot methods involve heavy human engineering or complicated self-training pipelines, hindering their application to new situations. In this work, we show that zero-shot text classification can be improved simply by clustering texts in the embedding spaces of PLMs. Specifically, we fit the unlabeled texts with a Bayesian Gaussian Mixture Model after initializing cluster positions and shapes using class names. Despite its simplicity, this approach achieves superior or comparable performance on both topic and sentiment classification datasets and outperforms prior works significantly on unbalanced datasets. We further explore the applicability of our clustering approach by evaluating it on 14 datasets with more diverse topics, text lengths, and numbers of classes. Our approach achieves an average of 20% absolute improvement over prompt-based zero-shot learning. Finally, we compare different PLM embedding spaces and find that texts are well-clustered by topics even if the PLM is not explicitly pre-trained to generate meaningful sentence embeddings. This work indicates that PLM embeddings can categorize texts without task-specific fine-tuning, thus providing a new way to analyze and utilize their knowledge and zero-shot learning ability.","created":"2022-10-29","meta":{"link":"http://arxiv.org/abs/2210.16637v2","tag":"prompt-eng"}}
{"title":"Explaining the Explainers in Graph Neural Networks: a Comparative Study","abstract":"Following a fast initial breakthrough in graph based learning, Graph Neural Networks (GNNs) have reached a widespread application in many science and engineering fields, prompting the need for methods to understand their decision process.   GNN explainers have started to emerge in recent years, with a multitude of methods both novel or adapted from other domains. To sort out this plethora of alternative approaches, several studies have benchmarked the performance of different explainers in terms of various explainability metrics. However, these earlier works make no attempts at providing insights into why different GNN architectures are more or less explainable, or which explainer should be preferred in a given setting.   In this survey, we fill these gaps by devising a systematic experimental study, which tests ten explainers on eight representative architectures trained on six carefully designed graph and node classification datasets. With our results we provide key insights on the choice and applicability of GNN explainers, we isolate key components that make them usable and successful and provide recommendations on how to avoid common interpretation pitfalls. We conclude by highlighting open questions and directions of possible future research.","created":"2022-10-27","meta":{"link":"http://arxiv.org/abs/2210.15304v1","tag":"prompt-eng"}}
{"title":"Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language","abstract":"GitHub Copilot is an artificial intelligence model for automatically generating source code from natural language problem descriptions. Since June 2022, Copilot has officially been available for free to all students as a plug-in to development environments like Visual Studio Code. Prior work exploring OpenAI Codex, the underlying model that powers Copilot, has shown it performs well on typical CS1 problems thus raising concerns about the impact it will have on how introductory programming courses are taught. However, little is known about the types of problems for which Copilot does not perform well, or about the natural language interactions that a student might have with Copilot when resolving errors. We explore these questions by evaluating the performance of Copilot on a publicly available dataset of 166 programming problems. We find that it successfully solves around half of these problems on its very first attempt, and that it solves 60\\% of the remaining problems using only natural language changes to the problem description. We argue that this type of prompt engineering, which we believe will become a standard interaction between human and Copilot when it initially fails, is a potentially useful learning activity that promotes computational thinking skills, and is likely to change the nature of code writing skill development.","created":"2022-10-27","meta":{"link":"http://arxiv.org/abs/2210.15157v1","tag":"prompt-eng"}}
{"title":"Piloting Copilot and Codex: Hot Temperature, Cold Prompts, or Black Magic?","abstract":"Language models are promising solutions for tackling increasing complex problems. In software engineering, they recently attracted attention in code assistants, with programs automatically written in a given programming language from a programming task description in natural language. They have the potential to save time and effort when writing code. However, these systems are currently poorly understood, preventing them from being used optimally. In this paper, we investigate the various input parameters of two language models, and conduct a study to understand if variations of these input parameters (e.g. programming task description and the surrounding context, creativity of the language model, number of generated solutions) can have a significant impact on the quality of the generated programs. We design specific operators for varying input parameters and apply them over two code assistants (Copilot and Codex) and two benchmarks representing algorithmic problems (HumanEval and LeetCode). Our results showed that varying the input parameters can significantly improve the performance of language models. However, there is a tight dependency when varying the temperature, the prompt and the number of generated solutions, making potentially hard for developers to properly control the parameters to obtain an optimal result. This work opens opportunities to propose (automated) strategies for improving performance.","created":"2022-10-26","meta":{"link":"http://arxiv.org/abs/2210.14699v2","tag":"prompt-eng"}}
{"title":"PENTATRON: PErsonalized coNText-Aware Transformer for Retrieval-based cOnversational uNderstanding","abstract":"Conversational understanding is an integral part of modern intelligent devices. In a large fraction of the global traffic from customers using smart digital assistants, frictions in dialogues may be attributed to incorrect understanding of the entities in a customer's query due to factors including ambiguous mentions, mispronunciation, background noise and faulty on-device signal processing. Such errors are compounded by two common deficiencies from intelligent devices namely, (1) the device not being tailored to individual customers, and (2) the device responses being unaware of the context in the conversation session. Viewing this problem via the lens of retrieval-based search engines, we build and evaluate a scalable entity correction system, PENTATRON. The system leverages a parametric transformer-based language model to learn patterns from in-session customer-device interactions coupled with a non-parametric personalized entity index to compute the correct query, which aids downstream components in reasoning about the best response. In addition to establishing baselines and demonstrating the value of personalized and context-aware systems, we use multitasking to learn the domain of the correct entity. We also investigate the utility of language model prompts. Through extensive experiments, we show a significant upward movement of the key metric (Exact Match) by up to 500.97% (relative to the baseline).","created":"2022-10-22","meta":{"link":"http://arxiv.org/abs/2210.12308v1","tag":"prompt-eng"}}
{"title":"Formalizing Chemical Theory using the Lean Theorem Prover","abstract":"Chemical theory can be made more rigorous using the Lean theorem prover, an interactive theorem prover for complex mathematics. We formalize the Langmuir and BET theories of adsorption, making each scientific premise clear and every step of the derivations explicit. Lean's math library, mathlib, provides formally verified theorems for infinite geometries series, which are central to BET theory. While writing these proofs, Lean prompts us to include mathematical constraints that were not originally reported. We also illustrate how Lean flexibly enables the reuse of proofs that build on more complex theories through the use of functions, definitions, and structures. Finally, we construct scientific frameworks for interoperable proofs, by creating structures for classical thermodynamics and kinematics, using them to formalize gas law relationships like Boyle's Law and equations of motion underlying Newtonian mechanics, respectively. This approach can be extended to other fields, enabling the formalization of rich and complex theories in science and engineering.","created":"2022-10-21","meta":{"link":"http://arxiv.org/abs/2210.12150v2","tag":"prompt-eng"}}
{"title":"ObSynth: An Interactive Synthesis System for Generating Object Models from Natural Language Specifications","abstract":"We introduce ObSynth, an interactive system leveraging the domain knowledge embedded in large language models (LLMs) to help users design object models from high level natural language prompts. This is an example of specification reification, the process of taking a high-level, potentially vague specification and reifying it into a more concrete form. We evaluate ObSynth via a user study, leading to three key findings: first, object models designed using ObSynth are more detailed, showing that it often synthesizes fields users might have otherwise omitted. Second, a majority of objects, methods, and fields generated by ObSynth are kept by the user in the final object model, highlighting the quality of generated components. Third, ObSynth altered the workflow of participants: they focus on checking that synthesized components were correct rather than generating them from scratch, though ObSynth did not reduce the time participants took to generate object models.","created":"2022-10-20","meta":{"link":"http://arxiv.org/abs/2210.11468v1","tag":"prompt-eng"}}
{"title":"Robust Preference Learning for Storytelling via Contrastive Reinforcement Learning","abstract":"Controlled automated story generation seeks to generate natural language stories satisfying constraints from natural language critiques or preferences. Existing methods to control for story preference utilize prompt engineering which is labor intensive and often inconsistent. They may also use logit-manipulation methods which require annotated datasets to exist for the desired attributes. To address these issues, we first train a contrastive bi-encoder model to align stories with corresponding human critiques, named CARP, building a general purpose preference model. This is subsequently used as a reward function to fine-tune a generative language model via reinforcement learning. However, simply fine-tuning a generative language model with a contrastive reward model does not always reliably result in a story generation system capable of generating stories that meet user preferences. To increase story generation robustness we further fine-tune the contrastive reward model using a prompt-learning technique. A human participant study is then conducted comparing generations from our full system, ablations, and two baselines. We show that the full fine-tuning pipeline results in a story generator preferred over a LLM 20x as large as well as logit-based methods. This motivates the use of contrastive learning for general purpose human preference modeling.","created":"2022-10-14","meta":{"link":"http://arxiv.org/abs/2210.07792v2","tag":"prompt-eng"}}
{"title":"Measuring and Narrowing the Compositionality Gap in Language Models","abstract":"We investigate the ability of language models to perform compositional reasoning tasks where the overall solution depends on correctly composing the answers to sub-problems. We measure how often models can correctly answer all sub-problems but not generate the overall solution, a ratio we call the compositionality gap. We evaluate this ratio by asking multi-hop questions with answers that require composing multiple facts unlikely to have been observed together during pretraining. In the GPT-3 family of models, as model size increases we show that the single-hop question answering performance improves faster than the multi-hop performance does, therefore the compositionality gap does not decrease. This surprising result suggests that while more powerful models memorize and recall more factual knowledge, they show no corresponding improvement in their ability to perform this kind of compositional reasoning.   We then demonstrate how elicitive prompting (such as chain of thought) narrows the compositionality gap by reasoning explicitly instead of implicitly. We present a new method, self-ask, that further improves on chain of thought. In our method, the model explicitly asks itself (and then answers) follow-up questions before answering the initial question. We finally show that self-ask's structured prompting lets us easily plug in a search engine to answer the follow-up questions, which additionally improves accuracy.","created":"2022-10-07","meta":{"link":"http://arxiv.org/abs/2210.03350v1","tag":"prompt-eng"}}
{"title":"Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors","abstract":"Video game testing requires game-specific knowledge as well as common sense reasoning about the events in the game. While AI-driven agents can satisfy the first requirement, it is not yet possible to meet the second requirement automatically. Therefore, video game testing often still relies on manual testing, and human testers are required to play the game thoroughly to detect bugs. As a result, it is challenging to fully automate game testing. In this study, we explore the possibility of leveraging the zero-shot capabilities of large language models for video game bug detection. By formulating the bug detection problem as a question-answering task, we show that large language models can identify which event is buggy in a sequence of textual descriptions of events from a game. To this end, we introduce the GameBugDescriptions benchmark dataset, which consists of 167 buggy gameplay videos and a total of 334 question-answer pairs across 8 games. We extensively evaluate the performance of six models across the OPT and InstructGPT large language model families on our benchmark dataset. Our results show promising results for employing language models to detect video game bugs. With the proper prompting technique, we could achieve an accuracy of 70.66%, and on some video games, up to 78.94%. Our code, evaluation data and the benchmark can be found on https://asgaardlab.github.io/LLMxBugs","created":"2022-10-05","meta":{"link":"http://arxiv.org/abs/2210.02506v1","tag":"prompt-eng"}}
{"title":"Galaxy-Classification Activity for All Ages","abstract":"Classification is a general tool of science; it is used to sort and categorize biological organisms, chemical elements, astronomical objects, and many other things. In scientific classification, taxonomy often reflects shared physical properties that, in turn, may indicate shared origins and/or evolution. A \"hands-on\" galaxy-classification activity developed and implemented by Professional Development Program (PDP) participants, for a high-school summer STEM enrichment program, has been adopted for various age groups and venues, from young (K-3) to college students. We detail the basic tools required, outline the general activity, and describe the modifications to the activity based on learners' ages and learning objectives. We describe the facilitation strategies learned through PDP training and used when implementing the activity, including prompts to motivate the students. We also discuss how we connected the classification process to astronomy and science more broadly during the concluding remarks.","created":"2022-10-04","meta":{"link":"http://arxiv.org/abs/2210.01822v1","tag":"prompt-eng"}}
{"title":"Exploring the Trade-Offs: Unified Large Language Models vs Local Fine-Tuned Models for Highly-Specific Radiology NLI Task","abstract":"Recently, ChatGPT and GPT-4 have emerged and gained immense global attention due to their unparalleled performance in language processing. Despite demonstrating impressive capability in various open-domain tasks, their adequacy in highly specific fields like radiology remains untested. Radiology presents unique linguistic phenomena distinct from open-domain data due to its specificity and complexity. Assessing the performance of large language models (LLMs) in such specific domains is crucial not only for a thorough evaluation of their overall performance but also for providing valuable insights into future model design directions: whether model design should be generic or domain-specific. To this end, in this study, we evaluate the performance of ChatGPT/GPT-4 on a radiology NLI task and compare it to other models fine-tuned specifically on task-related data samples. We also conduct a comprehensive investigation on ChatGPT/GPT-4's reasoning ability by introducing varying levels of inference difficulty. Our results show that 1) GPT-4 outperforms ChatGPT in the radiology NLI task; 2) other specifically fine-tuned models require significant amounts of data samples to achieve comparable performance to ChatGPT/GPT-4. These findings demonstrate that constructing a generic model that is capable of solving various tasks across different domains is feasible.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09138v1","tag":"prompt-eng"}}
{"title":"In ChatGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT","abstract":"The way users acquire information is undergoing a paradigm shift with the advent of ChatGPT. Unlike conventional search engines, ChatGPT retrieves knowledge from the model itself and generates answers for users. ChatGPT's impressive question-answering (QA) capability has attracted more than 100 million users within a short period of time but has also raised concerns regarding its reliability. In this paper, we perform the first large-scale measurement of ChatGPT's reliability in the generic QA scenario with a carefully curated set of 5,695 questions across ten datasets and eight domains. We find that ChatGPT's reliability varies across different domains, especially underperforming in law and science questions. We also demonstrate that system roles, originally designed by OpenAI to allow users to steer ChatGPT's behavior, can impact ChatGPT's reliability. We further show that ChatGPT is vulnerable to adversarial examples, and even a single character change can negatively affect its reliability in certain cases. We believe that our study provides valuable insights into ChatGPT's reliability and underscores the need for strengthening the reliability and security of large language models (LLMs).","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08979v1","tag":"prompt-eng"}}
{"title":"ImpressionGPT: An Iterative Optimizing Framework for Radiology Report Summarization with ChatGPT","abstract":"The 'Impression' section of a radiology report is a critical basis for communication between radiologists and other physicians, and it is typically written by radiologists based on the 'Findings' section. However, writing numerous impressions can be laborious and error-prone for radiologists. Although recent studies have achieved promising results in automatic impression generation using large-scale medical text data for pre-training and fine-tuning pre-trained language models, such models often require substantial amounts of medical text data and have poor generalization performance. While large language models (LLMs) like ChatGPT have shown strong generalization capabilities and performance, their performance in specific domains, such as radiology, remains under-investigated and potentially limited. To address this limitation, we propose ImpressionGPT, which leverages the in-context learning capability of LLMs by constructing dynamic contexts using domain-specific, individualized data. This dynamic prompt approach enables the model to learn contextual knowledge from semantically similar examples from existing data. Additionally, we design an iterative optimization algorithm that performs automatic evaluation on the generated impression results and composes the corresponding instruction prompts to further optimize the model. The proposed ImpressionGPT model achieves state-of-the-art performance on both MIMIC-CXR and OpenI datasets without requiring additional training data or fine-tuning the LLMs. This work presents a paradigm for localizing LLMs that can be applied in a wide range of similar application scenarios, bridging the gap between general-purpose LLMs and the specific language processing needs of various domains.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08448v1","tag":"prompt-eng"}}
{"title":"A study on Prompt Design, Advantages and Limitations of ChatGPT for Deep Learning Program Repair","abstract":"ChatGPT has revolutionized many research and industrial fields. ChatGPT has shown great potential in software engineering to boost various traditional tasks such as program repair, code understanding, and code generation. However, whether automatic program repair (APR) applies to deep learning (DL) programs is still unknown. DL programs, whose decision logic is not explicitly encoded in the source code, have posed unique challenges to APR. While to repair DL programs, an APR approach needs to not only parse the source code syntactically but also needs to understand the code intention. With the best prior work, the performance of fault localization is still far less than satisfactory (only about 30\\%). Therefore, in this paper, we explore ChatGPT's capability for DL program repair by asking three research questions. (1) Can ChatGPT debug DL programs effectively? (2) How can ChatGPT's repair performance be improved by prompting? (3) In which way can dialogue help facilitate the repair? On top of that, we categorize the common aspects useful for prompt design for DL program repair. Also, we propose various prompt templates to facilitate the performance and summarize the advantages and disadvantages of ChatGPT's abilities such as detecting bad code smell, code refactoring, and detecting API misuse/deprecation.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08191v1","tag":"prompt-eng"}}
{"title":"Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca","abstract":"Large Language Models (LLMs), such as ChatGPT and GPT-4, have revolutionized natural language processing research and demonstrated potential in Artificial General Intelligence (AGI). However, the expensive training and deployment of LLMs present challenges to transparent and open academic research. To address these issues, this project open-sources the Chinese LLaMA and Alpaca large models, emphasizing instruction fine-tuning. We expand the original LLaMA's Chinese vocabulary by adding 20K Chinese tokens, increasing encoding efficiency and enhancing basic semantic understanding. By incorporating secondary pre-training using Chinese data and fine-tuning with Chinese instruction data, we substantially improve the models' comprehension and execution of instructions. Our pilot study serves as a foundation for researchers adapting LLaMA and Alpaca models to other languages. Resources are made publicly available through GitHub, fostering open research in the Chinese NLP community and beyond. GitHub repository: https://github.com/ymcui/Chinese-LLaMA-Alpaca","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08177v1","tag":"prompt-eng"}}
{"title":"From Zero to Hero: Examining the Power of Symbolic Tasks in Instruction Tuning","abstract":"Fine-tuning language models on tasks with instructions has demonstrated potential in facilitating zero-shot generalization to unseen tasks. In this paper, we introduce a straightforward yet effective method for enhancing instruction tuning by employing symbolic tasks. Compared to crowdsourced human tasks or model-generated tasks, symbolic tasks present a unique advantage as they can be easily generated in vast quantities, theoretically providing an infinite supply of high-quality training instances. To explore the potential of symbolic tasks, we carry out an extensive case study on the representative symbolic task of SQL execution. Empirical results on various benchmarks validate that the integration of SQL execution leads to significant improvements in zero-shot scenarios, particularly in table reasoning. Notably, our 3B model surpasses both the 175B GPT-3 and ChatGPT in zero-shot table reasoning across four benchmarks. Furthermore, experimental results on BBH (27 tasks) and MMLU (57 tasks) reveal that language models can be enhanced through symbolic tasks without compromising their generality. We hope that our paper serves as a catalyst, inspiring increased efforts to incorporate symbolic tasks in instruction tuning.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07995v1","tag":"prompt-eng"}}
{"title":"Chinese Open Instruction Generalist: A Preliminary Release","abstract":"Instruction tuning is widely recognized as a key technique for building generalist language models, which has attracted the attention of researchers and the public with the release of InstructGPT~\\citep{ouyang2022training} and ChatGPT\\footnote{\\url{https://chat.openai.com/}}. Despite impressive progress in English-oriented large-scale language models (LLMs), it is still under-explored whether English-based foundation LLMs can perform similarly on multilingual tasks compared to English tasks with well-designed instruction tuning and how we can construct the corpora needed for the tuning.   To remedy this gap, we propose the project as an attempt to create a Chinese instruction dataset by various methods adapted to the intrinsic characteristics of 4 sub-tasks. We collect around 200k Chinese instruction tuning samples, which have been manually checked to guarantee high quality. We also summarize the existing English and Chinese instruction corpora and briefly describe some potential applications of the newly constructed Chinese instruction corpora. The resulting \\textbf{C}hinese \\textbf{O}pen \\textbf{I}nstruction \\textbf{G}eneralist (\\textbf{COIG}) corpora are available in Huggingface\\footnote{\\url{https://huggingface.co/datasets/BAAI/COIG}} and Github\\footnote{\\url{https://github.com/FlagOpen/FlagInstruct}}, and will be continuously updated.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07987v2","tag":"prompt-eng"}}
{"title":"Towards Better Instruction Following Language Models for Chinese: Investigating the Impact of Training Data and Evaluation","abstract":"Recently, significant public efforts have been directed towards developing low-cost models with capabilities akin to ChatGPT, thereby fostering the growth of open-source conversational models. However, there remains a scarcity of comprehensive and in-depth evaluations of these models' performance. In this study, we examine the influence of training data factors, including quantity, quality, and linguistic distribution, on model performance. Our analysis is grounded in several publicly accessible, high-quality instruction datasets, as well as our own Chinese multi-turn conversations. We assess various models using a evaluation set of 1,000 samples, encompassing nine real-world scenarios. Our goal is to supplement manual evaluations with quantitative analyses, offering valuable insights for the continued advancement of open-source chat models. Furthermore, to enhance the performance and training and inference efficiency of models in the Chinese domain, we extend the vocabulary of LLaMA - the model with the closest open-source performance to proprietary language models like GPT-3 - and conduct secondary pre-training on 3.4B Chinese words. We make our model, data, as well as code publicly available.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07854v1","tag":"prompt-eng"}}
{"title":"How does ChatGPT rate sound semantics?","abstract":"Semantic dimensions of sound have been playing a central role in understanding the nature of auditory sensory experience as well as the broader relation between perception, language, and meaning. Accordingly, and given the recent proliferation of large language models (LLMs), here we asked whether such models exhibit an organisation of perceptual semantics similar to those observed in humans. Specifically, we prompted ChatGPT, a chatbot based on a state-of-the-art LLM, to rate musical instrument sounds on a set of 20 semantic scales. We elicited multiple responses in separate chats, analogous to having multiple human raters. ChatGPT generated semantic profiles that only partially correlated with human ratings, yet showed robust agreement along well-known psychophysical dimensions of musical sounds such as brightness (bright-dark) and pitch height (deep-high). Exploratory factor analysis suggested the same dimensionality but different spatial configuration of a latent factor space between the chatbot and human ratings. Unexpectedly, the chatbot showed degrees of internal variability that were comparable in magnitude to that of human ratings. Our work highlights the potential of LLMs to capture salient dimensions of human sensory experience.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07830v1","tag":"prompt-eng"}}
{"title":"VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping","abstract":"In argumentative writing, writers must brainstorm hierarchical writing goals, ensure the persuasiveness of their arguments, and revise and organize their plans through drafting. Recent advances in large language models (LLMs) have made interactive text generation through a chat interface (e.g., ChatGPT) possible. However, this approach often neglects implicit writing context and user intent, lacks support for user control and autonomy, and provides limited assistance for sensemaking and revising writing plans. To address these challenges, we introduce VISAR, an AI-enabled writing assistant system designed to help writers brainstorm and revise hierarchical goals within their writing context, organize argument structures through synchronized text editing and visual programming, and enhance persuasiveness with argumentation spark recommendations. VISAR allows users to explore, experiment with, and validate their writing plans using automatic draft prototyping. A controlled lab study confirmed the usability and effectiveness of VISAR in facilitating the argumentative writing planning process.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07810v1","tag":"prompt-eng"}}
{"title":"Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models","abstract":"We examine the potential of ChatGPT, and other large language models, in predicting stock market returns using sentiment analysis of news headlines. We use ChatGPT to indicate whether a given headline is good, bad, or irrelevant news for firms' stock prices. We then compute a numerical score and document a positive correlation between these ``ChatGPT scores'' and subsequent daily stock market returns. Further, ChatGPT outperforms traditional sentiment analysis methods. We find that more basic models such as GPT-1, GPT-2, and BERT cannot accurately forecast returns, indicating return predictability is an emerging capacity of complex models. Our results suggest that incorporating advanced language models into the investment decision-making process can yield more accurate predictions and enhance the performance of quantitative trading strategies.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07619v1","tag":"prompt-eng"}}
{"title":"Self-collaboration Code Generation via ChatGPT","abstract":"Code generation is widely regarded as a key technique for elevating the automation and ultimate quality of software development. Nevertheless, existing code generation approaches usually concentrate on a single stage of the software development process (i.e., the coding stage) and do not take into consideration other stages that are crucial in reducing complexity and ensuring quality assurance. The organization and conduction of multiple stages in software development require collaborative teamwork. To this end, this paper presents a self-collaboration code generation framework employing large language models (LLMs), exemplified by ChatGPT. Specifically, multiple LLMs play distinct roles through role instructions to form teams, addressing code generation tasks collaboratively and interactively without the need for human intervention. To showcase our framework, we assemble an elementary team consisting of three ChatGPT roles (i.e., analyst, coder, and tester) corresponding to the analysis, coding, and testing stages of software development. We conduct comprehensive experiments on various code-generation benchmarks. The experimental results indicate that self-collaboration code generation improves 29.9%-47.1% relative performance compared to naive direct code generation, achieving state-of-the-art performance and even surpassing GPT-4.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07590v1","tag":"prompt-eng"}}
{"title":"The Self-Perception and Political Biases of ChatGPT","abstract":"This contribution analyzes the self-perception and political biases of OpenAI's Large Language Model ChatGPT. Taking into account the first small-scale reports and studies that have emerged, claiming that ChatGPT is politically biased towards progressive and libertarian points of view, this contribution aims to provide further clarity on this subject. For this purpose, ChatGPT was asked to answer the questions posed by the political compass test as well as similar questionnaires that are specific to the respective politics of the G7 member states. These eight tests were repeated ten times each and revealed that ChatGPT seems to hold a bias towards progressive views. The political compass test revealed a bias towards progressive and libertarian views, with the average coordinates on the political compass being (-6.48, -5.99) (with (0, 0) the center of the compass, i.e., centrism and the axes ranging from -10 to 10), supporting the claims of prior research. The political questionnaires for the G7 member states indicated a bias towards progressive views but no significant bias between authoritarian and libertarian views, contradicting the findings of prior reports, with the average coordinates being (-3.27, 0.58). In addition, ChatGPT's Big Five personality traits were tested using the OCEAN test and its personality type was queried using the Myers-Briggs Type Indicator (MBTI) test. Finally, the maliciousness of ChatGPT was evaluated using the Dark Factor test. These three tests were also repeated ten times each, revealing that ChatGPT perceives itself as highly open and agreeable, has the Myers-Briggs personality type ENFJ, and is among the 15% of test-takers with the least pronounced dark traits.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07333v1","tag":"prompt-eng"}}
{"title":"OpenAssistant Conversations -- Democratizing Large Language Model Alignment","abstract":"Aligning large language models (LLMs) with human preferences has proven to drastically improve usability and has driven rapid adoption as demonstrated by ChatGPT. Alignment techniques such as supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) greatly reduce the required skill and domain knowledge to effectively harness the capabilities of LLMs, increasing their accessibility and utility across various domains. However, state-of-the-art alignment techniques like RLHF rely on high-quality human feedback data, which is expensive to create and often remains proprietary. In an effort to democratize research on large-scale alignment, we release OpenAssistant Conversations, a human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages distributed across 66,497 conversation trees, in 35 different languages, annotated with 461,292 quality ratings. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers. To demonstrate the OpenAssistant Conversations dataset's effectiveness, we present OpenAssistant, the first fully open-source large-scale instruction-tuned model to be trained on human data. A preference study revealed that OpenAssistant replies are comparably preferred to GPT-3.5-turbo (ChatGPT) with a relative winrate of 48.3% vs. 51.7% respectively. We release our code and data under fully permissive licenses.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07327v1","tag":"prompt-eng"}}
{"title":"ChatGPT: Applications, Opportunities, and Threats","abstract":"Developed by OpenAI, ChatGPT (Conditional Generative Pre-trained Transformer) is an artificial intelligence technology that is fine-tuned using supervised machine learning and reinforcement learning techniques, allowing a computer to generate natural language conversation fully autonomously. ChatGPT is built on the transformer architecture and trained on millions of conversations from various sources. The system combines the power of pre-trained deep learning models with a programmability layer to provide a strong base for generating natural language conversations. In this study, after reviewing the existing literature, we examine the applications, opportunities, and threats of ChatGPT in 10 main domains, providing detailed examples for the business and industry as well as education. We also conducted an experimental study, checking the effectiveness and comparing the performances of GPT-3.5 and GPT-4, and found that the latter performs significantly better. Despite its exceptional ability to generate natural-sounding responses, the authors believe that ChatGPT does not possess the same level of understanding, empathy, and creativity as a human and cannot fully replace them in most situations.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.09103v1","tag":"prompt-eng"}}
{"title":"ChatGPT cites the most-cited articles and journals, relying solely on Google Scholar's citation counts. As a result, AI may amplify the Matthew Effect in environmental science","abstract":"ChatGPT (GPT) has become one of the most talked-about innovations in recent years, with over 100 million users worldwide. However, there is still limited knowledge about the sources of information GPT utilizes. As a result, we carried out a study focusing on the sources of information within the field of environmental science. In our study, we asked GPT to identify the ten most significant subdisciplines within the field of environmental science. We then asked it to compose a scientific review article on each subdiscipline, including 25 references. We proceeded to analyze these references, focusing on factors such as the number of citations, publication date, and the journal in which the work was published. Our findings indicate that GPT tends to cite highly-cited publications in environmental science, with a median citation count of 1184.5. It also exhibits a preference for older publications, with a median publication year of 2010, and predominantly refers to well-respected journals in the field, with Nature being the most cited journal by GPT. Interestingly, our findings suggest that GPT seems to exclusively rely on citation count data from Google Scholar for the works it cites, rather than utilizing citation information from other scientific databases such as Web of Science or Scopus. In conclusion, our study suggests that Google Scholar citations play a significant role as a predictor for mentioning a study in GPT-generated content. This finding reinforces the dominance of Google Scholar among scientific databases and perpetuates the Matthew Effect in science, where the rich get richer in terms of citations. With many scholars already utilizing GPT for literature review purposes, we can anticipate further disparities and an expanding gap between lesser-cited and highly-cited publications.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06794v1","tag":"prompt-eng"}}
{"title":"Perspectives on Large Language Models for Relevance Judgment","abstract":"When asked, current large language models (LLMs) like ChatGPT claim that they can assist us with relevance judgments. Many researchers think this would not lead to credible IR research. In this perspective paper, we discuss possible ways for LLMs to assist human experts along with concerns and issues that arise. We devise a human-machine collaboration spectrum that allows categorizing different relevance judgment strategies, based on how much the human relies on the machine. For the extreme point of \"fully automated assessment\", we further include a pilot experiment on whether LLM-based relevance judgments correlate with judgments from trained human assessors. We conclude the paper by providing two opposing perspectives - for and against the use of LLMs for automatic relevance judgments - and a compromise perspective, informed by our analyses of the literature, our preliminary experimental evidence, and our experience as IR researchers.   We hope to start a constructive discussion within the community to avoid a stale-mate during review, where work is dammed if is uses LLMs for evaluation and dammed if it doesn't.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.09161v1","tag":"prompt-eng"}}
{"title":"AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models","abstract":"Evaluating the general abilities of foundation models to tackle human-level tasks is a vital aspect of their development and application in the pursuit of Artificial General Intelligence (AGI). Traditional benchmarks, which rely on artificial datasets, may not accurately represent human-level capabilities. In this paper, we introduce AGIEval, a novel benchmark specifically designed to assess foundation model in the context of human-centric standardized exams, such as college entrance exams, law school admission tests, math competitions, and lawyer qualification tests. We evaluate several state-of-the-art foundation models, including GPT-4, ChatGPT, and Text-Davinci-003, using this benchmark. Impressively, GPT-4 surpasses average human performance on SAT, LSAT, and math competitions, attaining a 95% accuracy rate on the SAT Math test and a 92.5% accuracy on the English test of the Chinese national college entrance exam. This demonstrates the extraordinary performance of contemporary foundation models. In contrast, we also find that GPT-4 is less proficient in tasks that require complex reasoning or specific domain knowledge. Our comprehensive analyses of model capabilities (understanding, knowledge, reasoning, and calculation) reveal these models' strengths and limitations, providing valuable insights into future directions for enhancing their general capabilities. By concentrating on tasks pertinent to human cognition and decision-making, our benchmark delivers a more meaningful and robust evaluation of foundation models' performance in real-world scenarios. The data, code, and all model outputs are released in https://github.com/microsoft/AGIEval.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06364v1","tag":"prompt-eng"}}
{"title":"Detection of Fake Generated Scientific Abstracts","abstract":"The widespread adoption of Large Language Models and publicly available ChatGPT has marked a significant turning point in the integration of Artificial Intelligence into people's everyday lives. The academic community has taken notice of these technological advancements and has expressed concerns regarding the difficulty of discriminating between what is real and what is artificially generated. Thus, researchers have been working on developing effective systems to identify machine-generated text. In this study, we utilize the GPT-3 model to generate scientific paper abstracts through Artificial Intelligence and explore various text representation methods when combined with Machine Learning models with the aim of identifying machine-written text. We analyze the models' performance and address several research questions that rise during the analysis of the results. By conducting this research, we shed light on the capabilities and limitations of Artificial Intelligence generated text.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.06148v1","tag":"prompt-eng"}}
{"title":"Evaluation of ChatGPT Model for Vulnerability Detection","abstract":"In this technical report, we evaluated the performance of the ChatGPT and GPT-3 models for the task of vulnerability detection in code. Our evaluation was conducted on our real-world dataset, using binary and multi-label classification tasks on CWE vulnerabilities. We decided to evaluate the model because it has shown good performance on other code-based tasks, such as solving programming challenges and understanding code at a high level. However, we found that the ChatGPT model performed no better than a dummy classifier for both binary and multi-label classification tasks for code vulnerability detection.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.07232v1","tag":"prompt-eng"}}
{"title":"How do physics students evaluate ChatGPT responses on comprehension questions? A study on the perceived scientific accuracy and linguistic quality","abstract":"This study aimed at evaluating how students perceive the linguistic quality and scientific accuracy of ChatGPT responses to physics comprehension questions. A total of 102 first- and second-year physics students were confronted with three questions of progressing affordance from introductory mechanics (rolling motion, waves, and fluid dynamics). Each question was presented with four different responses. All responses were attributed to ChatGPT, but in reality one sample solution was created by the researchers. All ChatGPT responses were wrong, imprecise, incomplete, or misleading. We found little differences in the perceived linguistic quality between ChatGPT responses and the sample solution. However, the students rated the overall scientific accuracy of the responses significantly differently, with the sample solution being rated best for the questions of low and medium affordance. The discrepancy between the sample solution and the ChatGPT responses increased with the level of self-assessed knowledge of the question content. For the question of highest affordance (fluid dynamics) that was unknown to most students, a ChatGPT response was rated just as good as the sample solution. Thus, this study provides data on the students' perception of ChatGPT responses and the factors influencing their perception. The results highlight the need for careful evaluation of ChatGPT responses both by instructors and students, particularly regarding scientific accuracy. Therefore, future research could explore the potential of similar \"spot the bot\"-activities in physics education to foster students' critical thinking skills.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05906v1","tag":"prompt-eng"}}
{"title":"Using Multiple RDF Knowledge Graphs for Enriching ChatGPT Responses","abstract":"There is a recent trend for using the novel Artificial Intelligence ChatGPT chatbox, which provides detailed responses and articulate answers across many domains of knowledge. However, in many cases it returns plausible-sounding but incorrect or inaccurate responses, whereas it does not provide evidence. Therefore, any user has to further search for checking the accuracy of the answer or/and for finding more information about the entities of the response. At the same time there is a high proliferation of RDF Knowledge Graphs (KGs) over any real domain, that offer high quality structured data. For enabling the combination of ChatGPT and RDF KGs, we present a research prototype, called GPToLODS, which is able to enrich any ChatGPT response with more information from hundreds of RDF KGs. In particular, it identifies and annotates each entity of the response with statistics and hyperlinks to LODsyndesis KG (which contains integrated data from 400 RDF KGs and over 412 million entities). In this way, it is feasible to enrich the content of entities and to perform fact checking and validation for the facts of the response at real time.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05774v1","tag":"prompt-eng"}}
{"title":"ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning","abstract":"Over the last few years, large language models (LLMs) have emerged as the most important breakthroughs in natural language processing (NLP) that fundamentally transform research and developments in the field. ChatGPT represents one of the most exciting LLM systems developed recently to showcase impressive skills for language generation and highly attract public attention. Among various exciting applications discovered for ChatGPT in English, the model can process and generate texts for multiple languages due to its multilingual training data. Given the broad adoption of ChatGPT for English in different problems and areas, a natural question is whether ChatGPT can also be applied effectively for other languages or it is necessary to develop more language-specific technologies. The answer to this question requires a thorough evaluation of ChatGPT over multiple tasks with diverse languages and large datasets (i.e., beyond reported anecdotes), which is still missing or limited in current research. Our work aims to fill this gap for the evaluation of ChatGPT and similar LLMs to provide more comprehensive information for multilingual NLP applications. While this work will be an ongoing effort to include additional experiments in the future, our current paper evaluates ChatGPT on 7 different tasks, covering 37 diverse languages with high, medium, low, and extremely low resources. We also focus on the zero-shot learning setting for ChatGPT to improve reproducibility and better simulate the interactions of general users. Compared to the performance of previous models, our extensive experimental results demonstrate a worse performance of ChatGPT for different NLP tasks and languages, calling for further research to develop better models and understanding for multilingual learning.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05613v1","tag":"prompt-eng"}}
{"title":"Distinguishing ChatGPT(-3.5, -4)-generated and human-written papers through Japanese stylometric analysis","abstract":"Text-generative artificial intelligence (AI), including ChatGPT, equipped with GPT-3.5 and GPT-4, from OpenAI, has attracted considerable attention worldwide. In this study, first, we compared Japanese stylometric features generated by GPT (-3.5 and -4) and those written by humans. In this work, we performed multi-dimensional scaling (MDS) to confirm the distributions of 216 texts of three classes (72 academic papers written by 36 single authors, 72 texts generated by GPT-3.5, and 72 texts generated by GPT-4 on the basis of the titles of the aforementioned papers) focusing on the following stylometric features: (1) bigrams of parts-of-speech, (2) bigram of postpositional particle words, (3) positioning of commas, and (4) rate of function words. MDS revealed distinct distributions at each stylometric feature of GPT (-3.5 and -4) and human. Although GPT-4 is more powerful than GPT-3.5 because it has more parameters, both GPT (-3.5 and -4) distributions are likely to overlap. These results indicate that although the number of parameters may increase in the future, AI-generated texts may not be close to that written by humans in terms of stylometric features. Second, we verified the classification performance of random forest (RF) for two classes (GPT and human) focusing on Japanese stylometric features. This study revealed the high performance of RF in each stylometric feature. Furthermore, the RF classifier focusing on the rate of function words achieved 98.1% accuracy. The RF classifier focusing on all stylometric features reached 100% in terms of all performance indexes (accuracy, recall, precision, and F1 score). This study concluded that at this stage we human discriminate ChatGPT from human limited to Japanese language.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05534v2","tag":"prompt-eng"}}
{"title":"Zero-shot Temporal Relation Extraction with ChatGPT","abstract":"The goal of temporal relation extraction is to infer the temporal relation between two events in the document. Supervised models are dominant in this task. In this work, we investigate ChatGPT's ability on zero-shot temporal relation extraction. We designed three different prompt techniques to break down the task and evaluate ChatGPT. Our experiments show that ChatGPT's performance has a large gap with that of supervised methods and can heavily rely on the design of prompts. We further demonstrate that ChatGPT can infer more small relation classes correctly than supervised methods. The current shortcomings of ChatGPT on temporal relation extraction are also discussed in this paper. We found that ChatGPT cannot keep consistency during temporal inference and it fails in actively long-dependency temporal inference.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05454v1","tag":"prompt-eng"}}
{"title":"Chatbots and ChatGPT: A Bibliometric Analysis and Systematic Review of Publications in Web of Science and Scopus Databases","abstract":"This paper presents a bibliometric analysis of the scientific literature related to chatbots, focusing specifically on ChatGPT. Chatbots have gained increasing attention recently, with an annual growth rate of 19.16% and 27.19% on the Web of Sciences (WoS) and Scopus, respectively. In this study, we have explored the structure, conceptual evolution, and trends in this field by analyzing data from both Scopus and WoS databases. The research consists of two study phases: (i) an analysis of chatbot literature and (ii) a comprehensive review of scientific documents on ChatGPT. In the first phase, a bibliometric analysis is conducted on all published literature, including articles, book chapters, conference papers, and reviews on chatbots from both Scopus (5839) and WoS (2531) databases covering the period from 1998 to 2023. An in-depth analysis focusing on sources, countries, authors' impact, and keywords has revealed that ChatGPT is the latest trend in the chatbot field. Consequently, in the second phase, bibliometric analysis has been carried out on ChatGPT publications, and 45 published studies have been analyzed thoroughly based on their methods, novelty, and conclusions. The key areas of interest identified from the study can be classified into three groups: artificial intelligence and related technologies, design and evaluation of conversational agents, and digital technologies and mental health. Overall, the study aims to provide guidelines for researchers to conduct their research more effectively in the field of chatbots and specifically highlight significant areas for future investigation into ChatGPT.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05436v1","tag":"prompt-eng"}}
{"title":"Toxicity in ChatGPT: Analyzing Persona-assigned Language Models","abstract":"Large language models (LLMs) have shown incredible capabilities and transcended the natural language processing (NLP) community, with adoption throughout many services like healthcare, therapy, education, and customer service. Since users include people with critical information needs like students or patients engaging with chatbots, the safety of these systems is of prime importance. Therefore, a clear understanding of the capabilities and limitations of LLMs is necessary. To this end, we systematically evaluate toxicity in over half a million generations of ChatGPT, a popular dialogue-based LLM. We find that setting the system parameter of ChatGPT by assigning it a persona, say that of the boxer Muhammad Ali, significantly increases the toxicity of generations. Depending on the persona assigned to ChatGPT, its toxicity can increase up to 6x, with outputs engaging in incorrect stereotypes, harmful dialogue, and hurtful opinions. This may be potentially defamatory to the persona and harmful to an unsuspecting user. Furthermore, we find concerning patterns where specific entities (e.g., certain races) are targeted more than others (3x more) irrespective of the assigned persona, that reflect inherent discriminatory biases in the model. We hope that our findings inspire the broader AI community to rethink the efficacy of current safety guardrails and develop better techniques that lead to robust, safe, and trustworthy AI systems.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05335v1","tag":"prompt-eng"}}
{"title":"Multi-step Jailbreaking Privacy Attacks on ChatGPT","abstract":"With the rapid progress of large language models (LLMs), many downstream NLP tasks can be well solved given good prompts. Though model developers and researchers work hard on dialog safety to avoid generating harmful content from LLMs, it is still challenging to steer AI-generated content (AIGC) for the human good. As powerful LLMs are devouring existing text data from various domains (e.g., GPT-3 is trained on 45TB texts), it is natural to doubt whether the private information is included in the training data and what privacy threats can these LLMs and their downstream applications bring. In this paper, we study the privacy threats from OpenAI's model APIs and New Bing enhanced by ChatGPT and show that application-integrated LLMs may cause more severe privacy threats ever than before. To this end, we conduct extensive experiments to support our claims and discuss LLMs' privacy implications.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05197v1","tag":"prompt-eng"}}
{"title":"Evaluating AIGC Detectors on Code Content","abstract":"Artificial Intelligence Generated Content (AIGC) has garnered considerable attention for its impressive performance, with ChatGPT emerging as a leading AIGC model that produces high-quality responses across various applications, including software development and maintenance. Despite its potential, the misuse of ChatGPT poses significant concerns, especially in education and safetycritical domains. Numerous AIGC detectors have been developed and evaluated on natural language data. However, their performance on code-related content generated by ChatGPT remains unexplored. To fill this gap, in this paper, we present the first empirical study on evaluating existing AIGC detectors in the software domain. We created a comprehensive dataset including 492.5K samples comprising code-related content produced by ChatGPT, encompassing popular software activities like Q&A (115K), code summarization (126K), and code generation (226.5K). We evaluated six AIGC detectors, including three commercial and three open-source solutions, assessing their performance on this dataset. Additionally, we conducted a human study to understand human detection capabilities and compare them with the existing AIGC detectors. Our results indicate that AIGC detectors demonstrate lower performance on code-related data compared to natural language data. Fine-tuning can enhance detector performance, especially for content within the same domain; but generalization remains a challenge. The human evaluation reveals that detection by humans is quite challenging.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05193v1","tag":"prompt-eng"}}
{"title":"Boosting Cross-task Transferability of Adversarial Patches with Visual Relations","abstract":"The transferability of adversarial examples is a crucial aspect of evaluating the robustness of deep learning systems, particularly in black-box scenarios. Although several methods have been proposed to enhance cross-model transferability, little attention has been paid to the transferability of adversarial examples across different tasks. This issue has become increasingly relevant with the emergence of foundational multi-task AI systems such as Visual ChatGPT, rendering the utility of adversarial samples generated by a single task relatively limited. Furthermore, these systems often entail inferential functions beyond mere recognition-like tasks. To address this gap, we propose a novel Visual Relation-based cross-task Adversarial Patch generation method called VRAP, which aims to evaluate the robustness of various visual tasks, especially those involving visual reasoning, such as Visual Question Answering and Image Captioning. VRAP employs scene graphs to combine object recognition-based deception with predicate-based relations elimination, thereby disrupting the visual reasoning information shared among inferential tasks. Our extensive experiments demonstrate that VRAP significantly surpasses previous methods in terms of black-box transferability across diverse visual reasoning tasks.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05402v1","tag":"prompt-eng"}}
{"title":"Advancing Medical Imaging with Language Models: A Journey from N-grams to ChatGPT","abstract":"In this paper, we aimed to provide a review and tutorial for researchers in the field of medical imaging using language models to improve their tasks at hand. We began by providing an overview of the history and concepts of language models, with a special focus on large language models. We then reviewed the current literature on how language models are being used to improve medical imaging, emphasizing different applications such as image captioning, report generation, report classification, finding extraction, visual question answering, interpretable diagnosis, and more for various modalities and organs. The ChatGPT was specially highlighted for researchers to explore more potential applications. We covered the potential benefits of accurate and efficient language models for medical imaging analysis, including improving clinical workflow efficiency, reducing diagnostic errors, and assisting healthcare professionals in providing timely and accurate diagnoses. Overall, our goal was to bridge the gap between language models and medical imaging and inspire new ideas and innovations in this exciting area of research. We hope that this review paper will serve as a useful resource for researchers in this field and encourage further exploration of the possibilities of language models in medical imaging.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.04920v1","tag":"prompt-eng"}}
{"title":"Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis","abstract":"Large language models (LLMs) have demonstrated remarkable potential in handling multilingual machine translation (MMT). In this paper, we systematically investigate the advantages and challenges of LLMs for MMT by answering two questions: 1) How well do LLMs perform in translating a massive number of languages? 2) Which factors affect LLMs' performance in translation? We evaluate popular LLMs, including XGLM, OPT, BLOOMZ, and ChatGPT, on 102 languages. Our empirical results show that even the best model ChatGPT still lags behind the supervised baseline NLLB in 83.33% of translation directions. Through further analysis, we discover that LLMs exhibit new working patterns when used for MMT. First, prompt semantics can surprisingly be ignored when given in-context exemplars, where LLMs still show strong performance even with unreasonable prompts. Second, cross-lingual exemplars can provide better task instruction for low-resource translation than exemplars in the same language pairs. Third, we observe the overestimated performance of BLOOMZ on dataset Flores-101, indicating the potential risk when using public datasets for evaluation.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04675v1","tag":"prompt-eng"}}
{"title":"The Wall Street Neophyte: A Zero-Shot Analysis of ChatGPT Over MultiModal Stock Movement Prediction Challenges","abstract":"Recently, large language models (LLMs) like ChatGPT have demonstrated remarkable performance across a variety of natural language processing tasks. However, their effectiveness in the financial domain, specifically in predicting stock market movements, remains to be explored. In this paper, we conduct an extensive zero-shot analysis of ChatGPT's capabilities in multimodal stock movement prediction, on three tweets and historical stock price datasets. Our findings indicate that ChatGPT is a \"Wall Street Neophyte\" with limited success in predicting stock movements, as it underperforms not only state-of-the-art methods but also traditional methods like linear regression using price features. Despite the potential of Chain-of-Thought prompting strategies and the inclusion of tweets, ChatGPT's performance remains subpar. Furthermore, we observe limitations in its explainability and stability, suggesting the need for more specialized training or fine-tuning. This research provides insights into ChatGPT's capabilities and serves as a foundation for future work aimed at improving financial market analysis and prediction by leveraging social media sentiment and historical stock data.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.05351v1","tag":"prompt-eng"}}
{"title":"Is ChatGPT a Good Sentiment Analyzer? A Preliminary Study","abstract":"Recently, ChatGPT has drawn great attention from both the research community and the public. We are particularly curious about whether it can serve as a universal sentiment analyzer. To this end, in this work, we provide a preliminary evaluation of ChatGPT on the understanding of opinions, sentiments, and emotions contained in the text. Specifically, we evaluate it in four settings, including standard evaluation, polarity shift evaluation, open-domain evaluation, and sentiment inference evaluation. The above evaluation involves 18 benchmark datasets and 5 representative sentiment analysis tasks, and we compare ChatGPT with fine-tuned BERT and corresponding state-of-the-art (SOTA) models on end-task. Moreover, we also conduct human evaluation and present some qualitative case studies to gain a deep comprehension of its sentiment analysis capabilities.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04339v1","tag":"prompt-eng"}}
{"title":"A Preliminary Evaluation of ChatGPT for Zero-shot Dialogue Understanding","abstract":"Zero-shot dialogue understanding aims to enable dialogue to track the user's needs without any training data, which has gained increasing attention. In this work, we investigate the understanding ability of ChatGPT for zero-shot dialogue understanding tasks including spoken language understanding (SLU) and dialogue state tracking (DST). Experimental results on four popular benchmarks reveal the great potential of ChatGPT for zero-shot dialogue understanding. In addition, extensive analysis shows that ChatGPT benefits from the multi-turn interactive prompt in the DST task but struggles to perform slot filling for SLU. Finally, we summarize several unexpected behaviors of ChatGPT in dialogue understanding tasks, hoping to provide some insights for future research on building zero-shot dialogue understanding systems with Large Language Models (LLMs).","created":"2023-04-09","meta":{"link":"http://arxiv.org/abs/2304.04256v1","tag":"prompt-eng"}}
{"title":"Video ChatCaptioner: Towards Enriched Spatiotemporal Descriptions","abstract":"Video captioning aims to convey dynamic scenes from videos using natural language, facilitating the understanding of spatiotemporal information within our environment. Although there have been recent advances, generating detailed and enriched video descriptions continues to be a substantial challenge. In this work, we introduce Video ChatCaptioner, an innovative approach for creating more comprehensive spatiotemporal video descriptions. Our method employs a ChatGPT model as a controller, specifically designed to select frames for posing video content-driven questions. Subsequently, a robust algorithm is utilized to answer these visual queries. This question-answer framework effectively uncovers intricate video details and shows promise as a method for enhancing video content. Following multiple conversational rounds, ChatGPT can summarize enriched video content based on previous conversations. We qualitatively demonstrate that our Video ChatCaptioner can generate captions containing more visual details about the videos. The code is publicly available at https://github.com/Vision-CAIR/ChatCaptioner","created":"2023-04-09","meta":{"link":"http://arxiv.org/abs/2304.04227v2","tag":"prompt-eng"}}
{"title":"Extractive Summarization via ChatGPT for Faithful Summary Generation","abstract":"Extractive summarization is a crucial task in natural language processing that aims to condense long documents into shorter versions by directly extracting sentences. The recent introduction of ChatGPT has attracted significant interest in the NLP community due to its remarkable performance on a wide range of downstream tasks. However, concerns regarding factuality and faithfulness have hindered its practical applications for summarization systems. This paper first presents a thorough evaluation of ChatGPT's performance on extractive summarization and compares it with traditional fine-tuning methods on various benchmark datasets. Our experimental analysis reveals that ChatGPT's extractive summarization performance is still inferior to existing supervised systems in terms of ROUGE scores. In addition, we explore the effectiveness of in-context learning and chain-of-thought reasoning for enhancing its performance. Furthermore, we find that applying an extract-then-generate pipeline with ChatGPT yields significant performance improvements over abstractive baselines in terms of summary faithfulness. These observations highlight potential directions for enhancing ChatGPT's capabilities for faithful text summarization tasks using two-stage approaches.","created":"2023-04-09","meta":{"link":"http://arxiv.org/abs/2304.04193v1","tag":"prompt-eng"}}
{"title":"Can ChatGPT and Bard Generate Aligned Assessment Items? A Reliability Analysis against Human Performance","abstract":"ChatGPT and Bard are AI chatbots based on Large Language Models (LLM) that are slated to promise different applications in diverse areas. In education, these AI technologies have been tested for applications in assessment and teaching. In assessment, AI has long been used in automated essay scoring and automated item generation. One psychometric property that these tools must have to assist or replace humans in assessment is high reliability in terms of agreement between AI scores and human raters. In this paper, we measure the reliability of OpenAI ChatGP and Google Bard LLMs tools against experienced and trained humans in perceiving and rating the complexity of writing prompts. Intraclass correlation (ICC) as a performance metric showed that the inter-reliability of both the OpenAI ChatGPT and the Google Bard were low against the gold standard of human ratings.","created":"2023-04-09","meta":{"link":"http://arxiv.org/abs/2304.05372v1","tag":"prompt-eng"}}
{"title":"ChatGPT Empowered Long-Step Robot Control in Various Environments: A Case Application","abstract":"This paper demonstrates how OpenAI's ChatGPT can be used in a few-shot setting to convert natural language instructions into a sequence of executable robot actions. The paper proposes easy-to-customize input prompts for ChatGPT that meet common requirements in practical applications, such as easy integration with robot execution systems and applicability to various environments while minimizing the impact of ChatGPT's token limit. The prompts encourage ChatGPT to output a sequence of predefined robot actions, represent the operating environment in a formalized style, and infer the updated state of the operating environment. Experiments confirmed that the proposed prompts enable ChatGPT to act according to requirements in various environments, and users can adjust ChatGPT's output with natural language feedback for safe and robust operation. The proposed prompts and source code are open-source and publicly available at https://github.com/microsoft/ChatGPT-Robot-Manipulation-Prompts","created":"2023-04-08","meta":{"link":"http://arxiv.org/abs/2304.03893v3","tag":"prompt-eng"}}
{"title":"Towards Automated Urban Planning: When Generative and ChatGPT-like AI Meets Urban Planning","abstract":"The two fields of urban planning and artificial intelligence (AI) arose and developed separately. However, there is now cross-pollination and increasing interest in both fields to benefit from the advances of the other. In the present paper, we introduce the importance of urban planning from the sustainability, living, economic, disaster, and environmental perspectives. We review the fundamental concepts of urban planning and relate these concepts to crucial open problems of machine learning, including adversarial learning, generative neural networks, deep encoder-decoder networks, conversational AI, and geospatial and temporal machine learning, thereby assaying how AI can contribute to modern urban planning. Thus, a central problem is automated land-use configuration, which is formulated as the generation of land uses and building configuration for a target area from surrounding geospatial, human mobility, social media, environment, and economic activities. Finally, we delineate some implications of AI for urban planning and propose key research areas at the intersection of both topics.","created":"2023-04-08","meta":{"link":"http://arxiv.org/abs/2304.03892v1","tag":"prompt-eng"}}
{"title":"Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models","abstract":"As the capabilities of generative language models continue to advance, the implications of biases ingrained within these models have garnered increasing attention from researchers, practitioners, and the broader public. This article investigates the challenges and risks associated with biases in large-scale language models like ChatGPT. We discuss the origins of biases, stemming from, among others, the nature of training data, model specifications, algorithmic constraints, product design, and policy decisions. We explore the ethical concerns arising from the unintended consequences of biased model outputs. We further analyze the potential opportunities to mitigate biases, the inevitability of some biases, and the implications of deploying these models in various applications, such as virtual assistants, content generation, and chatbots. Finally, we review the current approaches to identify, quantify, and mitigate biases in language models, emphasizing the need for a multi-disciplinary, collaborative effort to develop more equitable, transparent, and responsible AI systems. This article aims to stimulate a thoughtful dialogue within the artificial intelligence community, encouraging researchers and developers to reflect on the role of biases in generative language models and the ongoing pursuit of ethical AI.","created":"2023-04-07","meta":{"link":"http://arxiv.org/abs/2304.03738v1","tag":"prompt-eng"}}
{"title":"Beyond Privacy: Navigating the Opportunities and Challenges of Synthetic Data","abstract":"Generating synthetic data through generative models is gaining interest in the ML community and beyond. In the past, synthetic data was often regarded as a means to private data release, but a surge of recent papers explore how its potential reaches much further than this -- from creating more fair data to data augmentation, and from simulation to text generated by ChatGPT. In this perspective we explore whether, and how, synthetic data may become a dominant force in the machine learning world, promising a future where datasets can be tailored to individual needs. Just as importantly, we discuss which fundamental challenges the community needs to overcome for wider relevance and application of synthetic data -- the most important of which is quantifying how much we can trust any finding or prediction drawn from synthetic data.","created":"2023-04-07","meta":{"link":"http://arxiv.org/abs/2304.03722v1","tag":"prompt-eng"}}
{"title":"Generative AI for learning: Investigating the potential of synthetic learning videos","abstract":"Recent advances in generative artificial intelligence (AI) have captured worldwide attention. Tools such as Dalle-2 and ChatGPT suggest that tasks previously thought to be beyond the capabilities of AI may now augment the productivity of creative media in various new ways, including through the generation of synthetic video. This research paper explores the utility of using AI-generated synthetic video to create viable educational content for online educational settings. To date, there is limited research investigating the real-world educational value of AI-generated synthetic media. To address this gap, we examined the impact of using AI-generated synthetic video in an online learning platform on both learners content acquisition and learning experience. We took a mixed-method approach, randomly assigning adult learners (n=83) into one of two micro-learning conditions, collecting pre- and post-learning assessments, and surveying participants on their learning experience. The control condition included a traditionally produced instructor video, while the experimental condition included a synthetic video with a realistic AI-generated character. The results show that learners in both conditions demonstrated significant improvement from pre- to post-learning (p<.001), with no significant differences in gains between the two conditions (p=.80). In addition, no differences were observed in how learners perceived the traditional and synthetic videos. These findings suggest that AI-generated synthetic learning videos have the potential to be a viable substitute for videos produced via traditional methods in online educational settings, making high quality educational content more accessible across the globe.","created":"2023-04-07","meta":{"link":"http://arxiv.org/abs/2304.03784v1","tag":"prompt-eng"}}
{"title":"What does ChatGPT return about human values? Exploring value bias in ChatGPT using a descriptive value theory","abstract":"There has been concern about ideological basis and possible discrimination in text generated by Large Language Models (LLMs). We test possible value biases in ChatGPT using a psychological value theory. We designed a simple experiment in which we used a number of different probes derived from the Schwartz basic value theory (items from the revised Portrait Value Questionnaire, the value type definitions, value names). We prompted ChatGPT via the OpenAI API repeatedly to generate text and then analyzed the generated corpus for value content with a theory-driven value dictionary using a bag of words approach. Overall, we found little evidence of explicit value bias. The results showed sufficient construct and discriminant validity for the generated text in line with the theoretical predictions of the psychological model, which suggests that the value content was carried through into the outputs with high fidelity. We saw some merging of socially oriented values, which may suggest that these values are less clearly differentiated at a linguistic level or alternatively, this mixing may reflect underlying universal human motivations. We outline some possible applications of our findings for both applications of ChatGPT for corporate usage and policy making as well as future research avenues. We also highlight possible implications of this relatively high-fidelity replication of motivational content using a linguistic model for the theorizing about human values.","created":"2023-04-07","meta":{"link":"http://arxiv.org/abs/2304.03612v1","tag":"prompt-eng"}}
{"title":"ChatPipe: Orchestrating Data Preparation Program by Optimizing Human-ChatGPT Interactions","abstract":"Orchestrating a high-quality data preparation program is essential for successful machine learning (ML), but it is known to be time and effort consuming. Despite the impressive capabilities of large language models like ChatGPT in generating programs by interacting with users through natural language prompts, there are still limitations. Specifically, a user must provide specific prompts to iteratively guide ChatGPT in improving data preparation programs, which requires a certain level of expertise in programming, the dataset used and the ML task. Moreover, once a program has been generated, it is non-trivial to revisit a previous version or make changes to the program without starting the process over again. In this paper, we present ChatPipe, a novel system designed to facilitate seamless interaction between users and ChatGPT. ChatPipe provides users with effective recommendation on next data preparation operations, and guides ChatGPT to generate program for the operations. Also, ChatPipe enables users to easily roll back to previous versions of the program, which facilitates more efficient experimentation and testing. We have developed a web application for ChatPipe and prepared several real-world ML tasks from Kaggle. These tasks can showcase the capabilities of ChatPipe and enable VLDB attendees to easily experiment with our novel features to rapidly orchestrate a high-quality data preparation program.","created":"2023-04-07","meta":{"link":"http://arxiv.org/abs/2304.03540v1","tag":"prompt-eng"}}
{"title":"Generative Recommendation: Towards Next-generation Recommender Paradigm","abstract":"Recommender systems typically retrieve items from an item corpus for personalized recommendations. However, such a retrieval-based recommender paradigm faces two limitations: 1) the human-generated items in the corpus might fail to satisfy the users' diverse information needs, and 2) users usually adjust the recommendations via passive and inefficient feedback such as clicks. Nowadays, AI-Generated Content (AIGC) has revealed significant success across various domains, offering the potential to overcome these limitations: 1) generative AI can produce personalized items to meet users' specific information needs, and 2) the newly emerged ChatGPT significantly facilitates users to express information needs more precisely via natural language instructions. In this light, the boom of AIGC points the way towards the next-generation recommender paradigm with two new objectives: 1) generating personalized content through generative AI, and 2) integrating user instructions to guide content generation.   To this end, we propose a novel Generative Recommender paradigm named GeneRec, which adopts an AI generator to personalize content generation and leverages user instructions to acquire users' information needs. Specifically, we pre-process users' instructions and traditional feedback (e.g., clicks) via an instructor to output the generation guidance. Given the guidance, we instantiate the AI generator through an AI editor and an AI creator to repurpose existing items and create new items, respectively. Eventually, GeneRec can perform content retrieval, repurposing, and creation to meet users' information needs. Besides, to ensure the trustworthiness of the generated items, we emphasize various fidelity checks such as authenticity and legality checks. Lastly, we study the feasibility of implementing the AI editor and AI creator on micro-video generation, showing promising results.","created":"2023-04-07","meta":{"link":"http://arxiv.org/abs/2304.03516v1","tag":"prompt-eng"}}
{"title":"Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4","abstract":"Harnessing logical reasoning ability is a comprehensive natural language understanding endeavor. With the release of Generative Pretrained Transformer 4 (GPT-4), highlighted as \"advanced\" at reasoning tasks, we are eager to learn the GPT-4 performance on various logical reasoning tasks. This report analyses multiple logical reasoning datasets, with popular benchmarks like LogiQA and ReClor, and newly-released datasets like AR-LSAT. We test the multi-choice reading comprehension and natural language inference tasks with benchmarks requiring logical reasoning. We further construct a logical reasoning out-of-distribution dataset to investigate the robustness of ChatGPT and GPT-4. We also make a performance comparison between ChatGPT and GPT-4. Experiment results show that ChatGPT performs significantly better than the RoBERTa fine-tuning method on most logical reasoning benchmarks. GPT-4 shows even higher performance on our manual tests. Among benchmarks, ChatGPT and GPT-4 do relatively well on well-known datasets like LogiQA and ReClor. However, the performance drops significantly when handling newly released and out-of-distribution datasets. Logical reasoning remains challenging for ChatGPT and GPT-4, especially on out-of-distribution and natural language inference datasets.","created":"2023-04-07","meta":{"link":"http://arxiv.org/abs/2304.03439v1","tag":"prompt-eng"}}
{"title":"Opinion Mining from YouTube Captions Using ChatGPT: A Case Study of Street Interviews Polling the 2023 Turkish Elections","abstract":"Opinion mining plays a critical role in understanding public sentiment and preferences, particularly in the context of political elections. Traditional polling methods, while useful, can be expensive and less scalable. Social media offers an alternative source of data for opinion mining but presents challenges such as noise, biases, and platform limitations in data collection. In this paper, we propose a novel approach for opinion mining, utilizing YouTube's auto-generated captions from public interviews as a data source, specifically focusing on the 2023 Turkish elections as a case study. We introduce an opinion mining framework using ChatGPT to mass-annotate voting intentions and motivations that represent the stance and frames prior to the election. We report that ChatGPT can predict the preferred candidate with 97\\% accuracy and identify the correct voting motivation out of 13 possible choices with 71\\% accuracy based on the data collected from 325 interviews. We conclude by discussing the robustness of our approach, accounting for factors such as captions quality, interview length, and channels. This new method will offer a less noisy and cost-effective alternative for opinion mining using social media data.","created":"2023-04-07","meta":{"link":"http://arxiv.org/abs/2304.03434v1","tag":"prompt-eng"}}
{"title":"On the Evaluations of ChatGPT and Emotion-enhanced Prompting for Mental Health Analysis","abstract":"Automated mental health analysis shows great potential for enhancing the efficiency and accessibility of mental health care, whereas the recent dominant methods utilized pre-trained language models (PLMs) as the backbone and incorporated emotional information. The latest large language models (LLMs), such as ChatGPT, exhibit dramatic capabilities on diverse natural language processing tasks. However, existing studies on ChatGPT's zero-shot performance for mental health analysis have limitations in inadequate evaluation, utilization of emotional information, and explainability of methods. In this work, we comprehensively evaluate the mental health analysis and emotional reasoning ability of ChatGPT on 11 datasets across 5 tasks, including binary and multi-class mental health condition detection, cause/factor detection of mental health conditions, emotion recognition in conversations, and causal emotion entailment. We empirically analyze the impact of different prompting strategies with emotional cues on ChatGPT's mental health analysis ability and explainability. Experimental results show that ChatGPT outperforms traditional neural network methods but still has a significant gap with advanced task-specific methods. The qualitative analysis shows its potential in explainability compared with advanced black-box methods but also limitations on robustness and inaccurate reasoning. Prompt engineering with emotional cues is found to be effective in improving its performance on mental health analysis but requires the proper way of emotion infusion.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.03347v1","tag":"prompt-eng"}}
{"title":"ChatGPT-Crawler: Find out if ChatGPT really knows what it's talking about","abstract":"Large language models have gained considerable interest for their impressive performance on various tasks. Among these models, ChatGPT developed by OpenAI has become extremely popular among early adopters who even regard it as a disruptive technology in many fields like customer service, education, healthcare, and finance. It is essential to comprehend the opinions of these initial users as it can provide valuable insights into the potential strengths, weaknesses, and success or failure of the technology in different areas. This research examines the responses generated by ChatGPT from different Conversational QA corpora. The study employed BERT similarity scores to compare these responses with correct answers and obtain Natural Language Inference(NLI) labels. Evaluation scores were also computed and compared to determine the overall performance of GPT-3 \\& GPT-4. Additionally, the study identified instances where ChatGPT provided incorrect answers to questions, providing insights into areas where the model may be prone to error.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.03325v1","tag":"prompt-eng"}}
{"title":"When do you need Chain-of-Thought Prompting for ChatGPT?","abstract":"Chain-of-Thought (CoT) prompting can effectively elicit complex multi-step reasoning from Large Language Models~(LLMs). For example, by simply adding CoT instruction ``Let's think step-by-step'' to each input query of MultiArith dataset, GPT-3's accuracy can be improved from 17.7\\% to 78.7\\%. However, it is not clear whether CoT is still effective on more recent instruction finetuned (IFT) LLMs such as ChatGPT. Surprisingly, on ChatGPT, CoT is no longer effective for certain tasks such as arithmetic reasoning while still keeping effective on other reasoning tasks. Moreover, on the former tasks, ChatGPT usually achieves the best performance and can generate CoT even without being instructed to do so. Hence, it is plausible that ChatGPT has already been trained on these tasks with CoT and thus memorized the instruction so it implicitly follows such an instruction when applied to the same queries, even without CoT. Our analysis reflects a potential risk of overfitting/bias toward instructions introduced in IFT, which becomes more common in training LLMs. In addition, it indicates possible leakage of the pretraining recipe, e.g., one can verify whether a dataset and instruction were used in training ChatGPT. Our experiments report new baseline results of ChatGPT on a variety of reasoning tasks and shed novel insights into LLM's profiling, instruction memorization, and pretraining dataset leakage.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.03262v2","tag":"prompt-eng"}}
{"title":"Investigating Chain-of-thought with ChatGPT for Stance Detection on Social Media","abstract":"Stance detection predicts attitudes towards targets in texts and has gained attention with the rise of social media. Traditional approaches include conventional machine learning, early deep neural networks, and pre-trained fine-tuning models. However, with the evolution of very large pre-trained language models (VLPLMs) like ChatGPT (GPT-3.5), traditional methods face deployment challenges. The parameter-free Chain-of-Thought (CoT) approach, not requiring backpropagation training, has emerged as a promising alternative. This paper examines CoT's effectiveness in stance detection tasks, demonstrating its superior accuracy and discussing associated challenges.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.03087v1","tag":"prompt-eng"}}
{"title":"Can Large Language Models Play Text Games Well? Current State-of-the-Art and Open Questions","abstract":"Large language models (LLMs) such as ChatGPT and GPT-4 have recently demonstrated their remarkable abilities of communicating with human users. In this technical report, we take an initiative to investigate their capacities of playing text games, in which a player has to understand the environment and respond to situations by having dialogues with the game world. Our experiments show that ChatGPT performs competitively compared to all the existing systems but still exhibits a low level of intelligence. Precisely, ChatGPT can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses. Our results open up new research questions at the intersection of artificial intelligence, machine learning, and natural language processing.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.02868v1","tag":"prompt-eng"}}
{"title":"GPT detectors are biased against non-native English writers","abstract":"The rapid adoption of generative language models has brought about substantial advancements in digital communication, while simultaneously raising concerns regarding the potential misuse of AI-generated content. Although numerous detection methods have been proposed to differentiate between AI and human-generated content, the fairness and robustness of these detectors remain underexplored. In this study, we evaluate the performance of several widely-used GPT detectors using writing samples from native and non-native English writers. Our findings reveal that these detectors consistently misclassify non-native English writing samples as AI-generated, whereas native writing samples are accurately identified. Furthermore, we demonstrate that simple prompting strategies can not only mitigate this bias but also effectively bypass GPT detectors, suggesting that GPT detectors may unintentionally penalize writers with constrained linguistic expressions. Our results call for a broader conversation about the ethical implications of deploying ChatGPT content detectors and caution against their use in evaluative or educational settings, particularly when they may inadvertently penalize or exclude non-native English speakers from the global discourse.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.02819v1","tag":"prompt-eng"}}
{"title":"Opportunities and challenges of ChatGPT for design knowledge management","abstract":"Recent advancements in Natural Language Processing have opened up new possibilities for the development of large language models like ChatGPT, which can facilitate knowledge management in the design process by providing designers with access to a vast array of relevant information. However, integrating ChatGPT into the design process also presents new challenges. In this paper, we provide a concise review of the classification and representation of design knowledge, and past efforts to support designers in acquiring knowledge. We analyze the opportunities and challenges that ChatGPT presents for knowledge management in design and propose promising future research directions. A case study is conducted to validate the advantages and drawbacks of ChatGPT, showing that designers can acquire targeted knowledge from various domains, but the quality of the acquired knowledge is highly dependent on the prompt.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.02796v1","tag":"prompt-eng"}}
{"title":"Revolutionizing Single Cell Analysis: The Power of Large Language Models for Cell Type Annotation","abstract":"In recent years, single cell RNA sequencing has become a widely used technique to study cellular diversity and function. However, accurately annotating cell types from single cell data has been a challenging task, as it requires extensive knowledge of cell biology and gene function. The emergence of large language models such as ChatGPT and New Bing in 2023 has revolutionized this process by integrating the scientific literature and providing accurate annotations of cell types. This breakthrough enables researchers to conduct literature reviews more efficiently and accurately, and can potentially uncover new insights into cell type annotation. By using ChatGPT to annotate single cell data, we can relate rare cell type to their function and reveal specific differentiation trajectories of cell subtypes that were previously overlooked. This can have important applications in understanding cancer progression, mammalian development, and stem cell differentiation, and can potentially lead to the discovery of key cells that interrupt the differentiation pathway and solve key problems in the life sciences. Overall, the future of cell type annotation in single cell data looks promising and the Large Language model will be an important milestone in the history of single cell analysis.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02697v1","tag":"prompt-eng"}}
{"title":"Human-like Summarization Evaluation with ChatGPT","abstract":"Evaluating text summarization is a challenging problem, and existing evaluation metrics are far from satisfactory. In this study, we explored ChatGPT's ability to perform human-like summarization evaluation using four human evaluation methods on five datasets. We found that ChatGPT was able to complete annotations relatively smoothly using Likert scale scoring, pairwise comparison, Pyramid, and binary factuality evaluation. Additionally, it outperformed commonly used automatic evaluation metrics on some datasets. Furthermore, we discussed the impact of different prompts, compared its performance with that of human evaluation, and analyzed the generated explanations and invalid responses.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02554v1","tag":"prompt-eng"}}
{"title":"Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification","abstract":"Recent advances in large language models (LLMs) have shown impressive ability in biomedical question-answering, but have not been adequately investigated for more specific biomedical applications. This study investigates the performance of LLMs such as the ChatGPT family of models (GPT-3.5s, GPT-4) in biomedical tasks beyond question-answering. Because no patient data can be passed to the OpenAI API public interface, we evaluated model performance with over 10000 samples as proxies for two fundamental tasks in the clinical domain - classification and reasoning. The first task is classifying whether statements of clinical and policy recommendations in scientific literature constitute health advice. The second task is causal relation detection from the biomedical literature. We compared LLMs with simpler models, such as bag-of-words (BoW) with logistic regression, and fine-tuned BioBERT models. Despite the excitement around viral ChatGPT, we found that fine-tuning for two fundamental NLP tasks remained the best strategy. The simple BoW model performed on par with the most complex LLM prompting. Prompt engineering required significant investment.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02496v1","tag":"prompt-eng"}}
{"title":"ParroT: Translating During Chat Using Large Language Models","abstract":"Large language models (LLMs) like ChatGPT and GPT-4 have exhibited remarkable abilities on a wide range of natural language processing (NLP) tasks, including various machine translation abilities accomplished during chat. However, these models are only accessible through restricted APIs, which creates barriers to new research and advancements in the field. Therefore, we propose the $\\mathbf{ParroT}$ framework to enhance and regulate the translation abilities during chat based on open-sourced LLMs (i.e., LLaMA-7b) and human written translation and evaluation data. Specifically, ParroT reformulates translation data into the instruction-following style, and introduces a \"Hint\" field for incorporating extra requirements to regulate the translation process. Accordingly, we propose three instruction types for finetuning ParroT models, including translation instruction, contrastive instruction, and error-guided instruction. Experiments on Flores subsets and WMT22 test sets suggest that translation instruction improves the translation performance of vanilla LLMs significantly while error-guided instruction can lead to a further improvement, which demonstrates the importance of learning from low-quality translations annotated by human. Meanwhile, the ParroT models can also preserve the ability on general tasks with the Alpaca multi-task dataset involved in finetuning. Codes: https://github.com/wxjiao/ParroT","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02426v2","tag":"prompt-eng"}}
{"title":"Document-Level Machine Translation with Large Language Models","abstract":"Large language models (LLMs) such as Chat-GPT can produce coherent, cohesive, relevant, and fluent answers for various natural language processing (NLP) tasks. Taking document-level machine translation (MT) as a testbed, this paper provides an in-depth evaluation of LLMs' ability on discourse modeling. The study fo-cuses on three aspects: 1) Effects of Discourse-Aware Prompts, where we investigate the impact of different prompts on document-level translation quality and discourse phenomena; 2) Comparison of Translation Models, where we compare the translation performance of Chat-GPT with commercial MT systems and advanced document-level MT methods; 3) Analysis of Discourse Modelling Abilities, where we further probe discourse knowledge encoded in LLMs and examine the impact of training techniques on discourse modeling. By evaluating a number of benchmarks, we surprisingly find that 1) leveraging their powerful long-text mod-eling capabilities, ChatGPT outperforms commercial MT systems in terms of human evaluation. 2) GPT-4 demonstrates a strong ability to explain discourse knowledge, even through it may select incorrect translation candidates in contrastive testing. 3) ChatGPT and GPT-4 have demonstrated superior performance and show potential to become a new and promising paradigm for document-level translation. This work highlights the challenges and opportunities of discourse modeling for LLMs, which we hope can inspire the future design and evaluation of LLMs.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02210v1","tag":"prompt-eng"}}
{"title":"Unleashing the Power of ChatGPT for Translation: An Empirical Study","abstract":"The recently released ChatGPT has demonstrated surprising abilities in natural language understanding and natural language generation. Machine translation is an important and extensively studied task in the field of natural language processing, which heavily relies on the abilities of language understanding and generation. Thus, in this paper, we explore how to assist machine translation with ChatGPT. We adopt several translation prompts on a wide range of translations. Our experimental results show that ChatGPT with designed translation prompts can achieve comparable or better performance over professional translation systems for high-resource language translations but lags behind significantly on low-resource translations. We further evaluate the translation quality using multiple references, and ChatGPT achieves superior performance compared to the professional systems. We also conduct experiments on domain-specific translations, the final results show that ChatGPT is able to comprehend the provided domain keyword and adjust accordingly to output proper translations. At last, we perform few-shot prompts that show consistent improvement across different base prompts. Our work provides empirical evidence that ChatGPT still has great potential in translations.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02182v1","tag":"prompt-eng"}}
{"title":"Geotechnical Parrot Tales (GPT): Harnessing Large Language Models in geotechnical engineering","abstract":"The widespread adoption of large language models (LLMs), such as OpenAI's ChatGPT, could revolutionize various industries, including geotechnical engineering. However, GPT models can sometimes generate plausible-sounding but false outputs, leading to hallucinations. In this article, we discuss the importance of prompt engineering in mitigating these risks and harnessing the full potential of GPT for geotechnical applications. We explore the challenges and pitfalls associated with LLMs and highlight the role of context in ensuring accurate and valuable responses. Furthermore, we examine the development of context-specific search engines and the potential of LLMs to become a natural interface for complex tasks, such as data analysis and design. We also develop a unified interface using natural language to handle complex geotechnical engineering tasks and data analysis. By integrating GPT into geotechnical engineering workflows, professionals can streamline their work and develop sustainable and resilient infrastructure systems for the future.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.02138v2","tag":"prompt-eng"}}
{"title":"Large Language Models are Edge-Case Fuzzers: Testing Deep Learning Libraries via FuzzGPT","abstract":"Deep Learning (DL) library bugs affect downstream DL applications, emphasizing the need for reliable systems. Generating valid input programs for fuzzing DL libraries is challenging due to the need for satisfying both language syntax/semantics and constraints for constructing valid computational graphs. Recently, the TitanFuzz work demonstrates that modern Large Language Models (LLMs) can be directly leveraged to implicitly learn all the constraints to generate valid DL programs for fuzzing. However, LLMs tend to generate ordinary programs following similar patterns seen in their massive training corpora, while fuzzing favors unusual inputs that cover edge cases or are unlikely to be manually produced.   To fill this gap, this paper proposes FuzzGPT, the first technique to prime LLMs to synthesize unusual programs for fuzzing. FuzzGPT is built on the well-known hypothesis that historical bug-triggering programs may include rare/valuable code ingredients important for bug finding. Traditional techniques leveraging such historical information require intensive human efforts to design dedicated generators and ensure the validity of generated programs. FuzzGPT demonstrates that this process can be fully automated via the intrinsic capabilities of LLMs (including fine-tuning and in-context learning), while being generalizable and applicable to challenging domains. While FuzzGPT can be applied with different LLMs, this paper focuses on the powerful GPT-style models: Codex and CodeGen. Moreover, FuzzGPT also shows the potential of directly leveraging the instruct-following capability of the recent ChatGPT for effective fuzzing. Evaluation on two popular DL libraries (PyTorch and TensorFlow) shows that FuzzGPT can substantially outperform TitanFuzz, detecting 76 bugs, with 49 already confirmed as previously unknown bugs, including 11 high-priority bugs or security vulnerabilities.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.02014v1","tag":"prompt-eng"}}
{"title":"LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models","abstract":"The success of large language models (LLMs), like GPT-3 and ChatGPT, has led to the development of numerous cost-effective and accessible alternatives that are created by fine-tuning open-access LLMs with task-specific data (e.g., ChatDoctor) or instruction data (e.g., Alpaca). Among the various fine-tuning methods, adapter-based parameter-efficient fine-tuning (PEFT) is undoubtedly one of the most attractive topics, as it only requires fine-tuning a few external parameters instead of the entire LLMs while achieving comparable or even better performance. To enable further research on PEFT methods of LLMs, this paper presents LLM-Adapters, an easy-to-use framework that integrates various adapters into LLMs and can execute these adapter-based PEFT methods of LLMs for different tasks. The framework includes state-of-the-art open-access LLMs such as LLaMA, BLOOM, OPT, and GPT-J, as well as widely used adapters such as Series adapter, Parallel adapter, and LoRA. The framework is designed to be research-friendly, efficient, modular, and extendable, allowing the integration of new adapters and the evaluation of them with new and larger-scale LLMs. Furthermore, to evaluate the effectiveness of adapters in LLMs-Adapters, we conduct experiments on six math reasoning datasets. The results demonstrate that using adapter-based PEFT in smaller-scale LLMs (7B) with few extra trainable parameters yields comparable, and in some cases superior, performance to that of powerful LLMs (175B) in zero-shot inference on simple math reasoning datasets. Overall, we provide a promising framework for fine-tuning large LLMs on downstream tasks. We believe the proposed LLMs-Adapters will advance adapter-based PEFT research, facilitate the deployment of research pipelines, and enable practical applications to real-world systems.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01933v1","tag":"prompt-eng"}}
{"title":"Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models","abstract":"This paper presents a comprehensive survey of ChatGPT and GPT-4, state-of-the-art large language models (LLM) from the GPT series, and their prospective applications across diverse domains. Indeed, key innovations such as large-scale pre-training that captures knowledge across the entire world wide web, instruction fine-tuning and Reinforcement Learning from Human Feedback (RLHF) have played significant roles in enhancing LLMs' adaptability and performance. We performed an in-depth analysis of 194 relevant papers on arXiv, encompassing trend analysis, word cloud representation, and distribution analysis across various application domains. The findings reveal a significant and increasing interest in ChatGPT/GPT-4 research, predominantly centered on direct natural language processing applications, while also demonstrating considerable potential in areas ranging from education and history to mathematics, medicine, and physics. This study endeavors to furnish insights into ChatGPT's capabilities, potential implications, ethical concerns, and offer direction for future advancements in this field.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01852v2","tag":"prompt-eng"}}
{"title":"Using Language Models For Knowledge Acquisition in Natural Language Reasoning Problems","abstract":"For a natural language problem that requires some non-trivial reasoning to solve, there are at least two ways to do it using a large language model (LLM). One is to ask it to solve it directly. The other is to use it to extract the facts from the problem text and then use a theorem prover to solve it. In this note, we compare the two methods using ChatGPT and GPT4 on a series of logic word puzzles, and conclude that the latter is the right approach.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01771v1","tag":"prompt-eng"}}
{"title":"Is ChatGPT a Highly Fluent Grammatical Error Correction System? A Comprehensive Evaluation","abstract":"ChatGPT, a large-scale language model based on the advanced GPT-3.5 architecture, has shown remarkable potential in various Natural Language Processing (NLP) tasks. However, there is currently a dearth of comprehensive study exploring its potential in the area of Grammatical Error Correction (GEC). To showcase its capabilities in GEC, we design zero-shot chain-of-thought (CoT) and few-shot CoT settings using in-context learning for ChatGPT. Our evaluation involves assessing ChatGPT's performance on five official test sets in three different languages, along with three document-level GEC test sets in English. Our experimental results and human evaluations demonstrate that ChatGPT has excellent error detection capabilities and can freely correct errors to make the corrected sentences very fluent, possibly due to its over-correction tendencies and not adhering to the principle of minimal edits. Additionally, its performance in non-English and low-resource settings highlights its potential in multilingual GEC tasks. However, further analysis of various types of errors at the document-level has shown that ChatGPT cannot effectively correct agreement, coreference, tense errors across sentences, and cross-sentence boundary errors.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01746v1","tag":"prompt-eng"}}
{"title":"One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era","abstract":"OpenAI has recently released GPT-4 (a.k.a. ChatGPT plus), which is demonstrated to be one small step for generative AI (GAI), but one giant leap for artificial general intelligence (AGI). Since its official release in November 2022, ChatGPT has quickly attracted numerous users with extensive media coverage. Such unprecedented attention has also motivated numerous researchers to investigate ChatGPT from various aspects. According to Google scholar, there are more than 500 articles with ChatGPT in their titles or mentioning it in their abstracts. Considering this, a review is urgently needed, and our work fills this gap. Overall, this work is the first to survey ChatGPT with a comprehensive review of its underlying technology, applications, and challenges. Moreover, we present an outlook on how ChatGPT might evolve to realize general-purpose AIGC (a.k.a. AI-generated content), which will be a significant milestone for the development of AGI.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.06488v1","tag":"prompt-eng"}}
{"title":"To ChatGPT, or not to ChatGPT: That is the question!","abstract":"ChatGPT has become a global sensation. As ChatGPT and other Large Language Models (LLMs) emerge, concerns of misusing them in various ways increase, such as disseminating fake news, plagiarism, manipulating public opinion, cheating, and fraud. Hence, distinguishing AI-generated from human-generated becomes increasingly essential. Researchers have proposed various detection methodologies, ranging from basic binary classifiers to more complex deep-learning models. Some detection techniques rely on statistical characteristics or syntactic patterns, while others incorporate semantic or contextual information to improve accuracy. The primary objective of this study is to provide a comprehensive and contemporary assessment of the most recent techniques in ChatGPT detection. Additionally, we evaluated other AI-generated text detection tools that do not specifically claim to detect ChatGPT-generated content to assess their performance in detecting ChatGPT-generated content. For our evaluation, we have curated a benchmark dataset consisting of prompts from ChatGPT and humans, including diverse questions from medical, open Q&A, and finance domains and user-generated responses from popular social networking platforms. The dataset serves as a reference to assess the performance of various techniques in detecting ChatGPT-generated content. Our evaluation results demonstrate that none of the existing methods can effectively detect ChatGPT-generated content.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01487v2","tag":"prompt-eng"}}
{"title":"Blockwise Compression of Transformer-based Models without Retraining","abstract":"Transformer-based models, represented by GPT-3, ChatGPT, and GPT-4, have recently attracted increasing interest, research enthusiasm, and business demand. However, their massive computation resources and huge memory footprint are inevitable challenges. To tackle this issue, we propose BCT, a framework of blockwise compression for transformers without retraining, to lower deployment thresholds. BCT achieves more fine-grained compression of the whole transformer, including embedding, matrix multiplication, GELU, Softmax, layer normalization, and all the intermediate results. As a case, we compress an efficient model with BCT and evaluate it on several General Language Understanding Evaluation (GLUE) datasets. The results show that BCT can achieve a less than 0.90% accuracy drop in most tasks.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01483v1","tag":"prompt-eng"}}
{"title":"Integrating Commercial and Social Determinants of Health: A Unified Ontology for Non-Clinical Determinants of Health","abstract":"The objectives of this research are 1) to develop an ontology for CDoH by utilizing PubMed articles and ChatGPT; 2) to foster ontology reuse by integrating CDoH with an existing SDoH ontology into a unified structure; 3) to devise an overarching conception for all non-clinical determinants of health and to create an initial ontology, called N-CODH, for them; 4) and to validate the degree of correspondence between concepts provided by ChatGPT with the existing SDoH ontology","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01446v1","tag":"prompt-eng"}}
{"title":"On the Prime Number Divisibility by Deep Learning","abstract":"Certain tasks such as determining whether a given integer can be divided by 2, 3, or other prime numbers may be trivial for human beings, but can be less straightforward for computers in the absence of pre-specified algorithms. In this paper, we tested multiple deep learning architectures and feature engineering approaches, and evaluated the scenario of determining divisibility of large finite integers (up to $2^{32}$) by small prime numbers. It turns out that, regardless of the network frameworks or the complexity of the network structures (CNN, RNN, Transformer, etc.), the ability to predict the prime number divisibility critically depends on the feature space fed into the deep learning models. We also evaluated commercially available Automated Machine Learning (AutoML) pipelines from Amazon, Google and Microsoft, and demonstrated that they failed to address this issue unless appropriately engineered features were provided. We further proposed a closed form solution to the problem using the ordinary linear regression on Fourier series basis vectors, and showed its success. Finally, we evaluated prompt-based learning using ChatGPT and demonstrated its success on small primes and apparent failures on larger primes. We conclude that feature engineering remains an important task to improve the performance, increase the interpretability, and reduce the complexity of machine learning/deep learning models, even in the era of AutoML and large-language models (LLMs).","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.01333v1","tag":"prompt-eng"}}
{"title":"Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data","abstract":"Chat models, such as ChatGPT, have shown impressive capabilities and have been rapidly adopted across numerous domains. However, these models are only accessible through a restricted API, creating barriers for new research and progress in the field. We propose a pipeline that can automatically generate a high-quality multi-turn chat corpus by leveraging ChatGPT to engage in a conversation with itself. Subsequently, we employ parameter-efficient tuning to enhance LLaMA, an open-source large language model. The resulting model, named Baize, demonstrates good performance in multi-turn dialogues with guardrails that minimize potential risks. The Baize models and data are released for research purposes only at https://github.com/project-baize/baize. An online demo is also available at https://huggingface.co/spaces/project-baize/baize-lora-7B.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.01196v2","tag":"prompt-eng"}}
{"title":"Safety Analysis in the Era of Large Language Models: A Case Study of STPA using ChatGPT","abstract":"Large Language Models (LLMs), such as ChatGPT and BERT, are leading a new AI heatwave due to its human-like conversations with detailed and articulate answers across many domains of knowledge. While LLMs are being quickly applied to many AI application domains, we are interested in the following question: Can safety analysis for safety-critical systems make use of LLMs? To answer, we conduct a case study of Systems Theoretic Process Analysis (STPA) on Automatic Emergency Brake (AEB) systems using ChatGPT. STPA, one of the most prevalent techniques for hazard analysis, is known to have limitations such as high complexity and subjectivity, which this paper aims to explore the use of ChatGPT to address. Specifically, three ways of incorporating ChatGPT into STPA are investigated by considering its interaction with human experts: one-off simplex interaction, recurring simplex interaction, and recurring duplex interaction. Comparative results reveal that: (i) using ChatGPT without human experts' intervention can be inadequate due to reliability and accuracy issues of LLMs; (ii) more interactions between ChatGPT and human experts may yield better results; and (iii) using ChatGPT in STPA with extra care can outperform human safety experts alone, as demonstrated by reusing an existing comparison method with baselines. In addition to making the first attempt to apply LLMs in safety analysis, this paper also identifies key challenges (e.g., trustworthiness concern of LLMs, the need of standardisation) for future research in this direction.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.01246v1","tag":"prompt-eng"}}
{"title":"DoctorGLM: Fine-tuning your Chinese Doctor is not a Herculean Task","abstract":"The recent progress of large language models (LLMs), including ChatGPT and GPT-4, in comprehending and responding to human instructions has been remarkable. Nevertheless, these models typically perform better in English and have not been explicitly trained for the medical domain, resulting in suboptimal precision in diagnoses, drug recommendations, and other medical advice. Additionally, training and deploying a dialogue model is still believed to be impossible for hospitals, hindering the promotion of LLMs. To tackle these challenges, we have collected databases of medical dialogues in Chinese with ChatGPT's help and adopted several techniques to train an easy-deploy LLM. Remarkably, we were able to fine-tune the ChatGLM-6B on a single A100 80G in 13 hours, which means having a healthcare-purpose LLM can be very affordable. DoctorGLM is currently an early-stage engineering attempt and contain various mistakes. We are sharing it with the broader community to invite feedback and suggestions to improve its healthcare-focused capabilities: https://github.com/xionghonglin/DoctorGLM.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.01097v2","tag":"prompt-eng"}}
{"title":"Understanding Individual and Team-based Human Factors in Detecting Deepfake Texts","abstract":"In recent years, Natural Language Generation (NLG) techniques in AI (e.g., T5, GPT-3, ChatGPT) have shown a massive improvement and are now capable of generating human-like long coherent texts at scale, yielding so-called deepfake texts. This advancement, despite their benefits, can also cause security and privacy issues (e.g., plagiarism, identity obfuscation, disinformation attack). As such, it has become critically important to develop effective, practical, and scalable solutions to differentiate deepfake texts from human-written texts. Toward this challenge, in this work, we investigate how factors such as skill levels and collaborations impact how humans identify deepfake texts, studying three research questions: (1) do collaborative teams detect deepfake texts better than individuals? (2) do expert humans detect deepfake texts better than non-expert humans? (3) what are the factors that maximize the detection performance of humans? We implement these questions on two platforms: (1) non-expert humans or asynchronous teams on Amazon Mechanical Turk (AMT) and (2) expert humans or synchronous teams on the Upwork. By analyzing the detection performance and the factors that affected performance, some of our key findings are: (1) expert humans detect deepfake texts significantly better than non-expert humans, (2) synchronous teams on the Upwork detect deepfake texts significantly better than individuals, while asynchronous teams on the AMT detect deepfake texts weakly better than individuals, and (3) among various error categories, examining coherence and consistency in texts is useful in detecting deepfake texts. In conclusion, our work could inform the design of future tools/framework to improve collaborative human detection of deepfake texts.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.01002v1","tag":"prompt-eng"}}
{"title":"Exploring the Use of Large Language Models for Reference-Free Text Quality Evaluation: A Preliminary Empirical Study","abstract":"Evaluating the quality of generated text is a challenging task in natural language processing. This difficulty arises from the inherent complexity and diversity of text. Recently, OpenAI's ChatGPT, a powerful large language model (LLM), has garnered significant attention due to its impressive performance in various tasks. Therefore, we present this report to investigate the effectiveness of LLMs, especially ChatGPT, and explore ways to optimize their use in assessing text quality. We compared three kinds of reference-free evaluation methods based on ChatGPT or similar LLMs. The experimental results prove that ChatGPT is capable to evaluate text quality effectively from various perspectives without reference and demonstrates superior performance than most existing automatic metrics. In particular, the Explicit Score, which utilizes ChatGPT to generate a numeric score measuring text quality, is the most effective and reliable method among the three exploited approaches. However, directly comparing the quality of two texts using ChatGPT may lead to suboptimal results. We hope this report will provide valuable insights into selecting appropriate methods for evaluating text quality with LLMs such as ChatGPT.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.00723v2","tag":"prompt-eng"}}
{"title":"LLMMaps -- A Visual Metaphor for Stratified Evaluation of Large Language Models","abstract":"Large Language Models (LLMs) have revolutionized natural language processing and demonstrated impressive capabilities in various tasks. Unfortunately, they are prone to hallucinations, where the model exposes incorrect or false information in its responses, which renders diligent evaluation approaches mandatory. While LLM performance in specific knowledge fields is often evaluated based on question and answer (Q&A) datasets, such evaluations usually report only a single accuracy number for the entire field, a procedure which is problematic with respect to transparency and model improvement. A stratified evaluation could instead reveal subfields, where hallucinations are more likely to occur and thus help to better assess LLMs' risks and guide their further development. To support such stratified evaluations, we propose LLMMaps as a novel visualization technique that enables users to evaluate LLMs' performance with respect to Q&A datasets. LLMMaps provide detailed insights into LLMs' knowledge capabilities in different subfields, by transforming Q&A datasets as well as LLM responses into our internal knowledge structure. An extension for comparative visualization furthermore, allows for the detailed comparison of multiple LLMs. To assess LLMMaps we use them to conduct a comparative analysis of several state-of-the-art LLMs, such as BLOOM, GPT-2, GPT-3, ChatGPT and LLaMa-13B, as well as two qualitative user evaluations. All necessary source code and data for generating LLMMaps to be used in scientific publications and elsewhere will be available on GitHub.","created":"2023-04-02","meta":{"link":"http://arxiv.org/abs/2304.00457v1","tag":"prompt-eng"}}
{"title":"Keep the Conversation Going: Fixing 162 out of 337 bugs for $0.42 each using ChatGPT","abstract":"Automated Program Repair (APR) aims to automatically generate patches for buggy programs. Recent APR work has been focused on leveraging modern Large Language Models (LLMs) to directly generate patches for APR. Such LLM-based APR tools work by first constructing an input prompt built using the original buggy code and then queries the LLM to generate patches. While the LLM-based APR tools are able to achieve state-of-the-art results, it still follows the classic Generate and Validate repair paradigm of first generating lots of patches and then validating each one afterwards. This not only leads to many repeated patches that are incorrect but also miss the crucial information in test failures as well as in plausible patches.   To address these limitations, we propose ChatRepair, the first fully automated conversation-driven APR approach that interleaves patch generation with instant feedback to perform APR in a conversational style. ChatRepair first feeds the LLM with relevant test failure information to start with, and then learns from both failures and successes of earlier patching attempts of the same bug for more powerful APR. For earlier patches that failed to pass all tests, we combine the incorrect patches with their corresponding relevant test failure information to construct a new prompt for the LLM to generate the next patch. In this way, we can avoid making the same mistakes. For earlier patches that passed all the tests, we further ask the LLM to generate alternative variations of the original plausible patches. In this way, we can further build on and learn from earlier successes to generate more plausible patches to increase the chance of having correct patches. While our approach is general, we implement ChatRepair using state-of-the-art dialogue-based LLM -- ChatGPT. By calculating the cost of accessing ChatGPT, we can fix 162 out of 337 bugs for \\$0.42 each!","created":"2023-04-01","meta":{"link":"http://arxiv.org/abs/2304.00385v1","tag":"prompt-eng"}}
{"title":"Network Visualization of ChatGPT Research: a study based on term and keyword co-occurrence network analysis","abstract":"The main objective of this paper is to identify the major research areas of ChatGPT through term and keyword co-occurrence network mapping techniques. For conducting the present study, total of 577 publications were retrieved from the Lens database for the network visualization. The findings of the study showed that chatgpt occurrence in maximum number of times followed by its related terms such as artificial intelligence, large language model, gpt, study etc. This study will be helpful to library and information science as well as computer or information technology professionals.","created":"2023-04-01","meta":{"link":"http://arxiv.org/abs/2304.01948v1","tag":"prompt-eng"}}
{"title":"Evaluating Large Language Models on a Highly-specialized Topic, Radiation Oncology Physics","abstract":"We present the first study to investigate Large Language Models (LLMs) in answering radiation oncology physics questions. Because popular exams like AP Physics, LSAT, and GRE have large test-taker populations and ample test preparation resources in circulation, they may not allow for accurately assessing the true potential of LLMs. This paper proposes evaluating LLMs on a highly-specialized topic, radiation oncology physics, which may be more pertinent to scientific and medical communities in addition to being a valuable benchmark of LLMs. We developed an exam consisting of 100 radiation oncology physics questions based on our expertise at Mayo Clinic. Four LLMs, ChatGPT (GPT-3.5), ChatGPT (GPT-4), Bard (LaMDA), and BLOOMZ, were evaluated against medical physicists and non-experts. ChatGPT (GPT-4) outperformed all other LLMs as well as medical physicists, on average. The performance of ChatGPT (GPT-4) was further improved when prompted to explain first, then answer. ChatGPT (GPT-3.5 and GPT-4) showed a high level of consistency in its answer choices across a number of trials, whether correct or incorrect, a characteristic that was not observed in the human test groups. In evaluating ChatGPTs (GPT-4) deductive reasoning ability using a novel approach (substituting the correct answer with \"None of the above choices is the correct answer.\"), ChatGPT (GPT-4) demonstrated surprising accuracy, suggesting the potential presence of an emergent ability. Finally, although ChatGPT (GPT-4) performed well overall, its intrinsic properties did not allow for further improvement when scoring based on a majority vote across trials. In contrast, a team of medical physicists were able to greatly outperform ChatGPT (GPT-4) using a majority vote. This study suggests a great potential for LLMs to work alongside radiation oncology experts as highly knowledgeable assistants.","created":"2023-04-01","meta":{"link":"http://arxiv.org/abs/2304.01938v1","tag":"prompt-eng"}}
{"title":"Large language models can rate news outlet credibility","abstract":"Although large language models (LLMs) have shown exceptional performance in various natural language processing tasks, they are prone to hallucinations. State-of-the-art chatbots, such as the new Bing, attempt to mitigate this issue by gathering information directly from the internet to ground their answers. In this setting, the capacity to distinguish trustworthy sources is critical for providing appropriate accuracy contexts to users. Here we assess whether ChatGPT, a prominent LLM, can evaluate the credibility of news outlets. With appropriate instructions, ChatGPT can provide ratings for a diverse set of news outlets, including those in non-English languages and satirical sources, along with contextual explanations. Our results show that these ratings correlate with those from human experts (Spearmam's $\\rho=0.54, p<0.001$). These findings suggest that LLMs could be an affordable reference for credibility ratings in fact-checking applications. Future LLMs should enhance their alignment with human expert judgments of source credibility to improve information accuracy.","created":"2023-04-01","meta":{"link":"http://arxiv.org/abs/2304.00228v1","tag":"prompt-eng"}}
{"title":"A Survey of Large Language Models","abstract":"Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale language models. To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size. Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT, which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. In this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation. Besides, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.18223v5","tag":"prompt-eng"}}
{"title":"Pair Programming with Large Language Models for Sampling and Estimation of Copulas","abstract":"Without writing a single line of code by a human, an example Monte Carlo simulation based application for stochastic dependence modeling with copulas is developed using a state-of-the-art large language model (LLM) fine-tuned for conversations. This includes interaction with ChatGPT in natural language and using mathematical formalism, which, under careful supervision by a human-expert, led to producing a working code in MATLAB, Python and R for sampling from a given copula model, evaluation of the model's density, performing maximum likelihood estimation, optimizing the code for parallel computing for CPUs as well as for GPUs, and visualization of the computed results. In contrast to other emerging studies that assess the accuracy of LLMs like ChatGPT on tasks from a selected area, this work rather investigates ways how to achieve a successful solution of a standard statistical task in a collaboration of a human-expert and artificial intelligence (AI). Particularly, through careful prompt engineering, we separate successful solutions generated by ChatGPT from unsuccessful ones, resulting in a comprehensive list of related pros and cons. It is demonstrated that if the typical pitfalls are avoided, we can substantially benefit from collaborating with an AI partner. For example, we show that if ChatGPT is not able to provide a correct solution due to a lack of or incorrect knowledge, the human-expert can feed it with the correct knowledge, e.g., in the form of mathematical theorems and formulas, and make it to apply the gained knowledge in order to provide a solution that is correct. Such ability presents an attractive opportunity to achieve a programmed solution even for users with rather limited knowledge of programming techniques.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.18116v1","tag":"prompt-eng"}}
{"title":"Evaluating GPT-4 and ChatGPT on Japanese Medical Licensing Examinations","abstract":"As large language models (LLMs) gain popularity among speakers of diverse languages, we believe that it is crucial to benchmark them to better understand model behaviors, failures, and limitations in languages beyond English. In this work, we evaluate LLM APIs (ChatGPT, GPT-3, and GPT-4) on the Japanese national medical licensing examinations from the past five years, including the current year. Our team comprises native Japanese-speaking NLP researchers and a practicing cardiologist based in Japan. Our experiments show that GPT-4 outperforms ChatGPT and GPT-3 and passes all six years of the exams, highlighting LLMs' potential in a language that is typologically distant from English. However, our evaluation also exposes critical limitations of the current LLM APIs. First, LLMs sometimes select prohibited choices that should be strictly avoided in medical practice in Japan, such as suggesting euthanasia. Further, our analysis shows that the API costs are generally higher and the maximum context size is smaller for Japanese because of the way non-Latin scripts are currently tokenized in the pipeline. We release our benchmark as Igaku QA as well as all model outputs and exam metadata. We hope that our results and benchmark will spur progress on more diverse applications of LLMs. Our benchmark is available at https://github.com/jungokasai/IgakuQA.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.18027v2","tag":"prompt-eng"}}
{"title":"Can AI Put Gamma-Ray Astrophysicists Out of a Job?","abstract":"In what will likely be a litany of generative-model-themed arXiv submissions celebrating April the 1st, we evaluate the capacity of state-of-the-art transformer models to create a paper detailing the detection of a Pulsar Wind Nebula with a non-existent Imaging Atmospheric Cherenkov Telescope (IACT) Array. We do this to evaluate the ability of such models to interpret astronomical observations and sources based on language information alone, and to assess potential means by which fraudulently generated scientific papers could be identified during peer review (given that reliable generative model watermarking has yet to be deployed for these tools). We conclude that our jobs as astronomers are safe for the time being. From this point on, prompts given to ChatGPT and Stable Diffusion are shown in orange, text generated by ChatGPT is shown in black, whereas analysis by the (human) authors is in blue.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.17853v2","tag":"prompt-eng"}}
{"title":"Towards Mitigating ChatGPT's Negative Impact on Education: Optimizing Question Design through Bloom's Taxonomy","abstract":"The popularity of generative text AI tools in answering questions has led to concerns regarding their potential negative impact on students' academic performance and the challenges that educators face in evaluating student learning. To address these concerns, this paper introduces an evolutionary approach that aims to identify the best set of Bloom's taxonomy keywords to generate questions that these tools have low confidence in answering. The effectiveness of this approach is evaluated through a case study that uses questions from a Data Structures and Representation course being taught at the University of New South Wales in Canberra, Australia. The results demonstrate that the optimization algorithm is able to find keywords from different cognitive levels to create questions that ChatGPT has low confidence in answering. This study is a step forward to offer valuable insights for educators seeking to create more effective questions that promote critical thinking among students.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2304.08176v1","tag":"prompt-eng"}}
{"title":"Comparing Abstractive Summaries Generated by ChatGPT to Real Summaries Through Blinded Reviewers and Text Classification Algorithms","abstract":"Large Language Models (LLMs) have gathered significant attention due to their impressive performance on a variety of tasks. ChatGPT, developed by OpenAI, is a recent addition to the family of language models and is being called a disruptive technology by a few, owing to its human-like text-generation capabilities. Although, many anecdotal examples across the internet have evaluated ChatGPT's strength and weakness, only a few systematic research studies exist. To contribute to the body of literature of systematic research on ChatGPT, we evaluate the performance of ChatGPT on Abstractive Summarization by the means of automated metrics and blinded human reviewers. We also build automatic text classifiers to detect ChatGPT generated summaries. We found that while text classification algorithms can distinguish between real and generated summaries, humans are unable to distinguish between real summaries and those produced by ChatGPT.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17650v1","tag":"prompt-eng"}}
{"title":"ChatGPT scores a bad birdie in counting gravitational-wave chirps","abstract":"How many gravitational-wave observations from compact object mergers have we seen to date? This seemingly simple question has a surprisingly complex answer that even ChatGPT struggles to answer. To shed light on this, we present a database with the literature's answers to this question. We find values spanning 67-100 for the number of detections from double compact object mergers to date, emphasizing that the exact number of detections is uncertain and depends on the chosen data analysis pipeline and underlying assumptions. We also review the number of gravitational-wave detections expected in the coming decades with future observing runs, finding values up to millions of detections per year in the era of Cosmic Explorer and Einstein Telescope. We present a publicly available code to visualize the detection numbers, highlighting the exponential growth in gravitational-wave observations in the coming decades and the exciting prospects of gravitational-wave astrophysics. See http://www.broekgaarden.nl/floor/wordpress/elementor-967/. We plan to keep this database up-to-date and welcome comments and suggestions for additional references.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17628v1","tag":"prompt-eng"}}
{"title":"HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace","abstract":"Solving complicated AI tasks with different domains and modalities is a key step toward advanced artificial intelligence. While there are abundant AI models available for different domains and modalities, they cannot handle complicated AI tasks. Considering large language models (LLMs) have exhibited exceptional ability in language understanding, generation, interaction, and reasoning, we advocate that LLMs could act as a controller to manage existing AI models to solve complicated AI tasks and language could be a generic interface to empower this. Based on this philosophy, we present HuggingGPT, a framework that leverages LLMs (e.g., ChatGPT) to connect various AI models in machine learning communities (e.g., Hugging Face) to solve AI tasks. Specifically, we use ChatGPT to conduct task planning when receiving a user request, select models according to their function descriptions available in Hugging Face, execute each subtask with the selected AI model, and summarize the response according to the execution results. By leveraging the strong language capability of ChatGPT and abundant AI models in Hugging Face, HuggingGPT is able to cover numerous sophisticated AI tasks in different modalities and domains and achieve impressive results in language, vision, speech, and other challenging tasks, which paves a new way towards advanced artificial intelligence.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17580v2","tag":"prompt-eng"}}
{"title":"Assessing Cross-Cultural Alignment between ChatGPT and Human Societies: An Empirical Study","abstract":"The recent release of ChatGPT has garnered widespread recognition for its exceptional ability to generate human-like responses in dialogue. Given its usage by users from various nations and its training on a vast multilingual corpus that incorporates diverse cultural and societal norms, it is crucial to evaluate its effectiveness in cultural adaptation. In this paper, we investigate the underlying cultural background of ChatGPT by analyzing its responses to questions designed to quantify human cultural differences. Our findings suggest that, when prompted with American context, ChatGPT exhibits a strong alignment with American culture, but it adapts less effectively to other cultural contexts. Furthermore, by using different prompts to probe the model, we show that English prompts reduce the variance in model responses, flattening out cultural differences and biasing them towards American culture. This study provides valuable insights into the cultural implications of ChatGPT and highlights the necessity of greater diversity and cultural awareness in language technologies.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17466v2","tag":"prompt-eng"}}
{"title":"WavCaps: A ChatGPT-Assisted Weakly-Labelled Audio Captioning Dataset for Audio-Language Multimodal Research","abstract":"The advancement of audio-language (AL) multimodal learning tasks has been significant in recent years. However, researchers face challenges due to the costly and time-consuming collection process of existing audio-language datasets, which are limited in size. To address this data scarcity issue, we introduce WavCaps, the first large-scale weakly-labelled audio captioning dataset, comprising approximately 400k audio clips with paired captions. We sourced audio clips and their raw descriptions from web sources and a sound event detection dataset. However, the online-harvested raw descriptions are highly noisy and unsuitable for direct use in tasks such as automated audio captioning. To overcome this issue, we propose a three-stage processing pipeline for filtering noisy data and generating high-quality captions, where ChatGPT, a large language model, is leveraged to filter and transform raw descriptions automatically. We conduct a comprehensive analysis of the characteristics of WavCaps dataset and evaluate it on multiple downstream audio-language multimodal learning tasks. The systems trained on WavCaps outperform previous state-of-the-art (SOTA) models by a significant margin. Our aspiration is for the WavCaps dataset we have proposed to facilitate research in audio-language multimodal learning and demonstrate the potential of utilizing ChatGPT to enhance academic research. Our dataset and codes are available at https://github.com/XinhaoMei/WavCaps.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17395v1","tag":"prompt-eng"}}
{"title":"Yes but.. Can ChatGPT Identify Entities in Historical Documents?","abstract":"Large language models (LLMs) have been leveraged for several years now, obtaining state-of-the-art performance in recognizing entities from modern documents. For the last few months, the conversational agent ChatGPT has \"prompted\" a lot of interest in the scientific community and public due to its capacity of generating plausible-sounding answers. In this paper, we explore this ability by probing it in the named entity recognition and classification (NERC) task in primary sources (e.g., historical newspapers and classical commentaries) in a zero-shot manner and by comparing it with state-of-the-art LM-based systems. Our findings indicate several shortcomings in identifying entities in historical text that range from the consistency of entity annotation guidelines, entity complexity, and code-switching, to the specificity of prompting. Moreover, as expected, the inaccessibility of historical archives to the public (and thus on the Internet) also impacts its performance.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17322v1","tag":"prompt-eng"}}
{"title":"Synthesis of Mathematical programs from Natural Language Specifications","abstract":"Several decision problems that are encountered in various business domains can be modeled as mathematical programs, i.e. optimization problems. The process of conducting such modeling often requires the involvement of experts trained in operations research and advanced algorithms. Surprisingly, despite the significant advances in the methods for program and code synthesis, AutoML, learning to optimize etc., there has been little or no attention paid to automating the task of synthesizing mathematical programs. We imagine a scenario where the specifications for modeling, i.e. the objective and constraints are expressed in an unstructured form in natural language (NL) and the mathematical program has to be synthesized from such an NL specification. In this work we evaluate the efficacy of employing CodeT5 with data augmentation and post-processing of beams. We utilize GPT-3 with back translation for generation of synthetic examples. Further we apply rules of linear programming to score beams and correct beams based on common error patterns. We observe that with these enhancements CodeT5 base gives an execution accuracy of 0.73 which is significantly better than zero-shot execution accuracy of 0.41 by ChatGPT and 0.36 by Codex.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2304.03287v1","tag":"prompt-eng"}}
{"title":"Matrix diagonalization and singular value decomposition: Static SageMath and dynamic ChatGPT juxtaposed","abstract":"We investigated some difficulties that students often face when studying linear algebra at the undergraduate level, and identified some common mistakes and difficulties they often encountered when dealing with topics that require algorithmic thinking skills such as matrix factorization. In particular, we focused on (orthogonal) diagonalization and singular value decomposition (SVD). We also offered the possibility of exploring these topics using SageMath, a Python-based free open software computer algebra system (CAS) that has been identified to be useful for assisting many students in the computational process even though its output is static by nature. We then explored dynamic ChatGPT by inquiring the chatbot about the topic, either by asking to provide an example or to solve a problem, that is by constructing an (orthogonal) diagonalization or SVD from a particular matrix. By consolidating essential concepts in linear algebra and improving computational skills through effective practice, mastering these topics would become easier and mistakes could be minimized. Static SageMath, in particular, is a great aid for calculation confirmation and handling tedious computations. Although dynamic ChatGPT is relatively unreliable for solving problems in linear algebra, the mistakes it produces could become a valuable tool for improving critical thinking skills.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17163v1","tag":"prompt-eng"}}
{"title":"Deep Generative Model and Its Applications in Efficient Wireless Network Management: A Tutorial and Case Study","abstract":"With the phenomenal success of diffusion models and ChatGPT, deep generation models (DGMs) have been experiencing explosive growth from 2022. Not limited to content generation, DGMs are also widely adopted in Internet of Things, Metaverse, and digital twin, due to their outstanding ability to represent complex patterns and generate plausible samples. In this article, we explore the applications of DGMs in a crucial task, i.e., improving the efficiency of wireless network management. Specifically, we firstly overview the generative AI, as well as three representative DGMs. Then, a DGM-empowered framework for wireless network management is proposed, in which we elaborate the issues of the conventional network management approaches, why DGMs can address them efficiently, and the step-by-step workflow for applying DGMs in managing wireless networks. Moreover, we conduct a case study on network economics, using the state-of-the-art DGM model, i.e., diffusion model, to generate effective contracts for incentivizing the mobile AI-Generated Content (AIGC) services. Last but not least, we discuss important open directions for the further research.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17114v1","tag":"prompt-eng"}}
{"title":"Advances in apparent conceptual physics reasoning in GPT-4","abstract":"ChatGPT is built on a large language model trained on an enormous corpus of human text to emulate human conversation. Despite lacking any explicit programming regarding the laws of physics, recent work has demonstrated that GPT-3.5 could pass an introductory physics course at some nominal level and register something close to a minimal understanding of Newtonian Mechanics on the Force Concept Inventory. This work replicates those results and also demonstrates that the latest version, GPT-4, has reached a much higher mark in the latter context. Indeed, its responses come quite close to perfectly demonstrating expert-level competence, with a few very notable exceptions and limitations. We briefly comment on the implications of this for the future of physics education and pedagogy.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.17012v3","tag":"prompt-eng"}}
{"title":"Questions of science: chatting with ChatGPT about complex systems","abstract":"We present an overview of the complex systems field using ChatGPT as a representation of the community's understanding. ChatGPT has learned language patterns and styles from a large dataset of internet texts, allowing it to provide answers that reflect common opinions, ideas, and language patterns found in the community. Our exploration covers both teaching and learning, and research topics. We recognize the value of ChatGPT as a source for the community's ideas.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16870v1","tag":"prompt-eng"}}
{"title":"RetClean: Retrieval-Based Data Cleaning Using Foundation Models and Data Lakes","abstract":"Can foundation models (such as ChatGPT) clean your data? In this proposal, we demonstrate that indeed ChatGPT can assist in data cleaning by suggesting corrections for specific cells in a data table (scenario 1). However, ChatGPT may struggle with datasets it has never encountered before (e.g., local enterprise data) or when the user requires an explanation of the source of the suggested clean values. To address these issues, we developed a retrieval-based method that complements ChatGPT's power with a user-provided data lake. The data lake is first indexed, we then retrieve the top-k relevant tuples to the user's query tuple and finally leverage ChatGPT to infer the correct value (scenario 2). Nevertheless, sharing enterprise data with ChatGPT, an externally hosted model, might not be feasible for privacy reasons. To assist with this scenario, we developed a custom RoBERTa-based foundation model that can be locally deployed. By fine-tuning it on a small number of examples, it can effectively make value inferences based on the retrieved tuples (scenario 3). Our proposed system, RetClean, seamlessly supports all three scenarios and provides a user-friendly GUI that enables the VLDB audience to explore and experiment with the system.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16909v1","tag":"prompt-eng"}}
{"title":"TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs","abstract":"Artificial Intelligence (AI) has made incredible progress recently. On the one hand, advanced foundation models like ChatGPT can offer powerful conversation, in-context learning and code generation abilities on a broad range of open-domain tasks. They can also generate high-level solution outlines for domain-specific tasks based on the common sense knowledge they have acquired. However, they still face difficulties with some specialized tasks because they lack enough domain-specific data during pre-training or they often have errors in their neural network computations on those tasks that need accurate executions. On the other hand, there are also many existing models and systems (symbolic-based or neural-based) that can do some domain-specific tasks very well. However, due to the different implementation or working mechanisms, they are not easily accessible or compatible with foundation models. Therefore, there is a clear and pressing need for a mechanism that can leverage foundation models to propose task solution outlines and then automatically match some of the sub-tasks in the outlines to the off-the-shelf models and systems with special functionalities to complete them. Inspired by this, we introduce TaskMatrix.AI as a new AI ecosystem that connects foundation models with millions of APIs for task completion. Unlike most previous work that aimed to improve a single AI model, TaskMatrix.AI focuses more on using existing foundation models (as a brain-like central system) and APIs of other AI models and systems (as sub-task solvers) to achieve diversified tasks in both digital and physical domains. As a position paper, we will present our vision of how to build such an ecosystem, explain each key component, and use study cases to illustrate both the feasibility of this vision and the main challenges we need to address next.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16434v1","tag":"prompt-eng"}}
{"title":"Ten Quick Tips for Harnessing the Power of ChatGPT/GPT-4 in Computational Biology","abstract":"The rise of advanced chatbots, such as ChatGPT, has sparked curiosity in the scientific community. ChatGPT is a general-purpose chatbot powered by large language models (LLMs) GPT-3.5 and GPT-4, with the potential to impact numerous fields, including computational biology. In this article, we offer ten tips based on our experience with ChatGPT to assist computational biologists in optimizing their workflows. We have collected relevant prompts and reviewed the nascent literature in the field, compiling tips we project to remain pertinent for future ChatGPT and LLM iterations, ranging from code refactoring to scientific writing to prompt engineering. We hope our work will help bioinformaticians to complement their workflows while staying aware of the various implications of using this technology. Additionally, to track new and creative applications for bioinformatics tools such as ChatGPT, we have established a GitHub repository at https://github.com/csbl-br/awesome-compbio-chatgpt. Our belief is that ethical adherence to ChatGPT and other LLMs will increase the efficiency of computational biologists, ultimately advancing the pace of scientific discovery in the life sciences.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16429v1","tag":"prompt-eng"}}
{"title":"ChatGPT is a Knowledgeable but Inexperienced Solver: An Investigation of Commonsense Problem in Large Language Models","abstract":"Large language models (LLMs) such as ChatGPT and GPT-4 have made significant progress in NLP. However, their ability to memorize, represent, and leverage commonsense knowledge has been a well-known pain point for LLMs. It remains unclear that: (1) Can GPTs effectively answer commonsense questions? (2) Are GPTs knowledgeable in commonsense? (3) Are GPTs aware of the underlying commonsense knowledge for answering a specific question? (4) Can GPTs effectively leverage commonsense for answering questions? To evaluate the above commonsense problems, we conduct a series of experiments to evaluate ChatGPT's commonsense abilities, and the experimental results show that: (1) GPTs can achieve good QA accuracy in commonsense tasks, while they still struggle with certain types of knowledge. (2) ChatGPT is knowledgeable, and can accurately generate most of the commonsense knowledge using knowledge prompts. (3) Despite its knowledge, ChatGPT is an inexperienced commonsense problem solver, which cannot precisely identify the needed commonsense knowledge for answering a specific question, i.e., ChatGPT does not precisely know what commonsense knowledge is required to answer a question. The above findings raise the need to investigate better mechanisms for utilizing commonsense knowledge in LLMs, such as instruction following, better commonsense guidance, etc.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16421v1","tag":"prompt-eng"}}
{"title":"Zero-shot Clinical Entity Recognition using ChatGPT","abstract":"In this study, we investigated the potential of ChatGPT, a large language model developed by OpenAI, for the clinical named entity recognition task defined in the 2010 i2b2 challenge, in a zero-shot setting with two different prompt strategies. We compared its performance with GPT-3 in a similar zero-shot setting, as well as a fine-tuned BioClinicalBERT model using a set of synthetic clinical notes from MTSamples. Our findings revealed that ChatGPT outperformed GPT-3 in the zero-shot setting, with F1 scores of 0.418 (vs.0.250) and 0.620 (vs. 0.480) for exact- and relaxed-matching, respectively. Moreover, prompts affected ChatGPT's performance greatly, with relaxed-matching F1 scores of 0.628 vs.0.541 for two different prompt strategies. Although ChatGPT's performance was still lower than that of the supervised BioClinicalBERT model (i.e., relaxed-matching F1 scores of 0.628 vs. 0.870), our study demonstrates the great potential of ChatGPT for clinical NER tasks in a zero-shot setting, which is much more appealing as it does not require any annotation.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16416v1","tag":"prompt-eng"}}
{"title":"ChatGPT or academic scientist? Distinguishing authorship with over 99% accuracy using off-the-shelf machine learning tools","abstract":"ChatGPT has enabled access to AI-generated writing for the masses, and within just a few months, this product has disrupted the knowledge economy, initiating a culture shift in the way people work, learn, and write. The need to discriminate human writing from AI is now both critical and urgent, particularly in domains like higher education and academic writing, where AI had not been a significant threat or contributor to authorship. Addressing this need, we developed a method for discriminating text generated by ChatGPT from (human) academic scientists, relying on prevalent and accessible supervised classification methods. We focused on how a particular group of humans, academic scientists, write differently than ChatGPT, and this targeted approach led to the discovery of new features for discriminating (these) humans from AI; as examples, scientists write long paragraphs and have a penchant for equivocal language, frequently using words like but, however, and although. With a set of 20 features, including the aforementioned ones and others, we built a model that assigned the author, as human or AI, at well over 99% accuracy, resulting in 20 times fewer misclassified documents compared to the field-leading approach. This strategy for discriminating a particular set of humans writing from AI could be further adapted and developed by others with basic skills in supervised classification, enabling access to many highly accurate and targeted models for detecting AI usage in academic writing and beyond.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.16352v1","tag":"prompt-eng"}}
{"title":"A Perspectival Mirror of the Elephant: Investigating Language Bias on Google, ChatGPT, Wikipedia, and YouTube","abstract":"Contrary to Google Search's mission of delivering information from \"many angles so you can form your own understanding of the world,\" we find that Google and its most prominent returned results -- Wikipedia and YouTube, simply reflect the narrow set of cultural stereotypes tied to the search language for complex topics like \"Buddhism,\" \"Liberalism,\" \"colonization,\" \"Iran\" and \"America.\" Simply stated, they present, to varying degrees, distinct information across the same search in different languages (we call it 'language bias'). Instead of presenting a global picture of a complex topic, our online searches turn us into the proverbial blind person touching a small portion of an elephant, ignorant of the existence of other cultural perspectives. The language we use to search ends up as a cultural filter to promote ethnocentric views, where a person evaluates other people or ideas based on their own culture. We also find that language bias is deeply embedded in ChatGPT. As it is primarily trained on English language data, it presents the Anglo-American perspective as the normative view, reducing the complexity of a multifaceted issue to the single Anglo-American standard. In this paper, we present evidence and analysis of language bias and discuss its larger social implications. Toward the end of the paper, we propose a potential framework of using automatic translation to leverage language bias and argue that the task of piecing together a genuine depiction of the elephant is a challenging and important endeavor that deserves a new area of research in NLP and requires collaboration with scholars from the humanities to create ethically sound and socially responsible technology together.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.16281v1","tag":"prompt-eng"}}
{"title":"Unleashing the Power of Edge-Cloud Generative AI in Mobile Networks: A Survey of AIGC Services","abstract":"Artificial Intelligence-Generated Content (AIGC) is an automated method for generating, manipulating, and modifying valuable and diverse data using AI algorithms creatively. This survey paper focuses on the deployment of AIGC applications, e.g., ChatGPT and Dall-E, at mobile edge networks, namely mobile AIGC networks, that provide personalized and customized AIGC services in real time while maintaining user privacy. We begin by introducing the background and fundamentals of generative models and the lifecycle of AIGC services at mobile AIGC networks, which includes data collection, training, finetuning, inference, and product management. We then discuss the collaborative cloud-edge-mobile infrastructure and technologies required to support AIGC services and enable users to access AIGC at mobile edge networks. Furthermore, we explore AIGCdriven creative applications and use cases for mobile AIGC networks. Additionally, we discuss the implementation, security, and privacy challenges of deploying mobile AIGC networks. Finally, we highlight some future research directions and open issues for the full realization of mobile AIGC networks.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.16129v2","tag":"prompt-eng"}}
{"title":"Hallucinations in Large Multilingual Translation Models","abstract":"Large-scale multilingual machine translation systems have demonstrated remarkable ability to translate directly between numerous languages, making them increasingly appealing for real-world applications. However, when deployed in the wild, these models may generate hallucinated translations which have the potential to severely undermine user trust and raise safety concerns. Existing research on hallucinations has primarily focused on small bilingual models trained on high-resource languages, leaving a gap in our understanding of hallucinations in massively multilingual models across diverse translation scenarios. In this work, we fill this gap by conducting a comprehensive analysis on both the M2M family of conventional neural machine translation models and ChatGPT, a general-purpose large language model~(LLM) that can be prompted for translation. Our investigation covers a broad spectrum of conditions, spanning over 100 translation directions across various resource levels and going beyond English-centric language pairs. We provide key insights regarding the prevalence, properties, and mitigation of hallucinations, paving the way towards more responsible and reliable machine translation systems.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.16104v1","tag":"prompt-eng"}}
{"title":"Ecosystem Graphs: The Social Footprint of Foundation Models","abstract":"Foundation models (e.g. ChatGPT, StableDiffusion) pervasively influence society, warranting immediate social attention. While the models themselves garner much attention, to accurately characterize their impact, we must consider the broader sociotechnical ecosystem. We propose Ecosystem Graphs as a documentation framework to transparently centralize knowledge of this ecosystem. Ecosystem Graphs is composed of assets (datasets, models, applications) linked together by dependencies that indicate technical (e.g. how Bing relies on GPT-4) and social (e.g. how Microsoft relies on OpenAI) relationships. To supplement the graph structure, each asset is further enriched with fine-grained metadata (e.g. the license or training emissions). We document the ecosystem extensively at https://crfm.stanford.edu/ecosystem-graphs/. As of March 16, 2023, we annotate 262 assets (64 datasets, 128 models, 70 applications) from 63 organizations linked by 356 dependencies. We show Ecosystem Graphs functions as a powerful abstraction and interface for achieving the minimum transparency required to address myriad use cases. Therefore, we envision Ecosystem Graphs will be a community-maintained resource that provides value to stakeholders spanning AI researchers, industry professionals, social scientists, auditors and policymakers.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15772v1","tag":"prompt-eng"}}
{"title":"Evaluation of ChatGPT for NLP-based Mental Health Applications","abstract":"Large language models (LLM) have been successful in several natural language understanding tasks and could be relevant for natural language processing (NLP)-based mental health application research. In this work, we report the performance of LLM-based ChatGPT (with gpt-3.5-turbo backend) in three text-based mental health classification tasks: stress detection (2-class classification), depression detection (2-class classification), and suicidality detection (5-class classification). We obtained annotated social media posts for the three classification tasks from public datasets. Then ChatGPT API classified the social media posts with an input prompt for classification. We obtained F1 scores of 0.73, 0.86, and 0.37 for stress detection, depression detection, and suicidality detection, respectively. A baseline model that always predicted the dominant class resulted in F1 scores of 0.35, 0.60, and 0.19. The zero-shot classification accuracy obtained with ChatGPT indicates a potential use of language models for mental health classification tasks.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15727v1","tag":"prompt-eng"}}
{"title":"Solving Regularized Exp, Cosh and Sinh Regression Problems","abstract":"In modern machine learning, attention computation is a fundamental task for training large language models such as Transformer, GPT-4 and ChatGPT. In this work, we study exponential regression problem which is inspired by the softmax/exp unit in the attention mechanism in large language models. The standard exponential regression is non-convex. We study the regularization version of exponential regression problem which is a convex problem. We use approximate newton method to solve in input sparsity time.   Formally, in this problem, one is given matrix $A \\in \\mathbb{R}^{n \\times d}$, $b \\in \\mathbb{R}^n$, $w \\in \\mathbb{R}^n$ and any of functions $\\exp, \\cosh$ and $\\sinh$ denoted as $f$. The goal is to find the optimal $x$ that minimize $ 0.5 \\| f(Ax) - b \\|_2^2 + 0.5 \\| \\mathrm{diag}(w) A x \\|_2^2$. The straightforward method is to use the naive Newton's method. Let $\\mathrm{nnz}(A)$ denote the number of non-zeros entries in matrix $A$. Let $\\omega$ denote the exponent of matrix multiplication. Currently, $\\omega \\approx 2.373$. Let $\\epsilon$ denote the accuracy error. In this paper, we make use of the input sparsity and purpose an algorithm that use $\\log ( \\|x_0 - x^*\\|_2 / \\epsilon)$ iterations and $\\widetilde{O}(\\mathrm{nnz}(A) + d^{\\omega} )$ per iteration time to solve the problem.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15725v1","tag":"prompt-eng"}}
{"title":"Comparative Analysis of CHATGPT and the evolution of language models","abstract":"Interest in Large Language Models (LLMs) has increased drastically since the emergence of ChatGPT and the outstanding positive societal response to the ease with which it performs tasks in Natural Language Processing (NLP). The triumph of ChatGPT, however, is how it seamlessly bridges the divide between language generation and knowledge models. In some cases, it provides anecdotal evidence of a framework for replicating human intuition over a knowledge domain. This paper highlights the prevailing ideas in NLP, including machine translation, machine summarization, question-answering, and language generation, and compares the performance of ChatGPT with the major algorithms in each of these categories using the Spontaneous Quality (SQ) score. A strategy for validating the arguments and results of ChatGPT is presented summarily as an example of safe, large-scale adoption of LLMs.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2304.02468v1","tag":"prompt-eng"}}
{"title":"ChatGPT4PCG Competition: Character-like Level Generation for Science Birds","abstract":"This paper presents the first ChatGPT4PCG Competition at the 2023 IEEE Conference on Games. The objective of this competition is for participants to create effective prompts for ChatGPT--enabling it to generate Science Birds levels with high stability and character-like qualities--fully using their creativity as well as prompt engineering skills. ChatGPT is a conversational agent developed by OpenAI. Science Birds is selected as the competition platform because designing an Angry Birds-like level is not a trivial task due to the in-game gravity; the playability of the levels is determined by their stability. To lower the entry barrier to the competition, we limit the task to the generation of capitalized English alphabetical characters. Here, the quality of the generated levels is determined by their stability and similarity to the given characters. A sample prompt is provided to participants for their reference. An experiment is conducted to determine the effectiveness of its modified versions on level stability and similarity by testing them on several characters. To the best of our knowledge, we believe that ChatGPT4PCG is the first competition of its kind and hope to inspire enthusiasm for prompt engineering in procedural content generation.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15662v1","tag":"prompt-eng"}}
{"title":"ChatGPT as a Factual Inconsistency Evaluator for Text Summarization","abstract":"The performance of text summarization has been greatly boosted by pre-trained language models. A main concern of existing methods is that most generated summaries are not factually inconsistent with their source documents. To alleviate the problem, many efforts have focused on developing effective factuality evaluation metrics based on natural language inference, question answering, and syntactic dependency et al. However, these approaches are limited by either their high computational complexity or the uncertainty introduced by multi-component pipelines, resulting in only partial agreement with human judgement. Most recently, large language models(LLMs) have shown excellent performance in not only text generation but also language comprehension. In this paper, we particularly explore ChatGPT's ability to evaluate factual inconsistency under a zero-shot setting by examining it on both coarse-grained and fine-grained evaluation tasks including binary entailment inference, summary ranking, and consistency rating. Experimental results indicate that ChatGPT generally outperforms previous evaluation metrics across the three tasks, indicating its great potential for factual inconsistency evaluation. However, a closer inspection of ChatGPT's output reveals certain limitations including its preference for more lexically similar candidates, false reasoning, and inadequate understanding of instructions.","created":"2023-03-27","meta":{"link":"http://arxiv.org/abs/2303.15621v2","tag":"prompt-eng"}}
{"title":"Unlocking the Potential of ChatGPT: A Comprehensive Exploration of its Applications, Advantages, Limitations, and Future Directions in Natural Language Processing","abstract":"Large language models have revolutionized the field of artificial intelligence and have been used in various applications. Among these models, ChatGPT (Chat Generative Pre-trained Transformer) has been developed by OpenAI, it stands out as a powerful tool that has been widely adopted. ChatGPT has been successfully applied in numerous areas, including chatbots, content generation, language translation, personalized recommendations, and even medical diagnosis and treatment. Its success in these applications can be attributed to its ability to generate human-like responses, understand natural language, and adapt to different contexts. Its versatility and accuracy make it a powerful tool for natural language processing (NLP). However, there are also limitations to ChatGPT, such as its tendency to produce biased responses and its potential to perpetuate harmful language patterns. This article provides a comprehensive overview of ChatGPT, its applications, advantages, and limitations. Additionally, the paper emphasizes the importance of ethical considerations when using this robust tool in real-world scenarios. Finally, This paper contributes to ongoing discussions surrounding artificial intelligence and its impact on vision and NLP domains by providing insights into prompt engineering techniques.","created":"2023-03-27","meta":{"link":"http://arxiv.org/abs/2304.02017v5","tag":"prompt-eng"}}
{"title":"Linguistically Informed ChatGPT Prompts to Enhance Japanese-Chinese Machine Translation: A Case Study on Attributive Clauses","abstract":"In the field of Japanese-Chinese translation linguistics, the issue of correctly translating attributive clauses has persistently proven to be challenging. Present-day machine translation tools often fail to accurately translate attributive clauses from Japanese to Chinese. In light of this, this paper investigates the linguistic problem underlying such difficulties, namely how does the semantic role of the modified noun affect the selection of translation patterns for attributive clauses, from a linguistic perspective. To ad-dress these difficulties, a pre-edit scheme is proposed, which aims to enhance the accuracy of translation. Furthermore, we propose a novel two-step prompt strategy, which combines this pre-edit scheme with ChatGPT, currently the most widely used large language model. This prompt strategy is capable of optimizing translation input in zero-shot scenarios and has been demonstrated to improve the average translation accuracy score by over 35%.","created":"2023-03-27","meta":{"link":"http://arxiv.org/abs/2303.15587v1","tag":"prompt-eng"}}
{"title":"ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks","abstract":"Many NLP applications require manual data annotations for a variety of tasks, notably to train classifiers or evaluate the performance of unsupervised models. Depending on the size and degree of complexity, the tasks may be conducted by crowd-workers on platforms such as MTurk as well as trained annotators, such as research assistants. Using a sample of 2,382 tweets, we demonstrate that ChatGPT outperforms crowd-workers for several annotation tasks, including relevance, stance, topics, and frames detection. Specifically, the zero-shot accuracy of ChatGPT exceeds that of crowd-workers for four out of five tasks, while ChatGPT's intercoder agreement exceeds that of both crowd-workers and trained annotators for all tasks. Moreover, the per-annotation cost of ChatGPT is less than $0.003 -- about twenty times cheaper than MTurk. These results show the potential of large language models to drastically increase the efficiency of text classification.","created":"2023-03-27","meta":{"link":"http://arxiv.org/abs/2303.15056v1","tag":"prompt-eng"}}
{"title":"MGTBench: Benchmarking Machine-Generated Text Detection","abstract":"Nowadays large language models (LLMs) have shown revolutionary power in a variety of natural language processing (NLP) tasks such as text classification, sentiment analysis, language translation, and question-answering. In this way, detecting machine-generated texts (MGTs) is becoming increasingly important as LLMs become more advanced and prevalent. These models can generate human-like language that can be difficult to distinguish from text written by a human, which raises concerns about authenticity, accountability, and potential bias. However, existing detection methods against MGTs are evaluated under different model architectures, datasets, and experimental settings, resulting in a lack of a comprehensive evaluation framework across different methodologies   In this paper, we fill this gap by proposing the first benchmark framework for MGT detection, named MGTBench. Extensive evaluations on public datasets with curated answers generated by ChatGPT (the most representative and powerful LLMs thus far) show that most of the current detection methods perform less satisfactorily against MGTs. An exceptional case is ChatGPT Detector, which is trained with ChatGPT-generated texts and shows great performance in detecting MGTs. Nonetheless, we note that only a small fraction of adversarial-crafted perturbations on MGTs can evade the ChatGPT Detector, thus highlighting the need for more robust MGT detection methods. We envision that MGTBench will serve as a benchmark tool to accelerate future investigations involving the evaluation of state-of-the-art MGT detection methods on their respective datasets and the development of more advanced MGT detection methods. Our source code and datasets are available at https://github.com/xinleihe/MGTBench.","created":"2023-03-26","meta":{"link":"http://arxiv.org/abs/2303.14822v1","tag":"prompt-eng"}}
{"title":"Exploring the Impact of Instruction Data Scaling on Large Language Models: An Empirical Study on Real-World Use Cases","abstract":"The success of ChatGPT has recently attracted numerous efforts to replicate it, with instruction-tuning strategies being a key factor in achieving remarkable results. Instruction-tuning not only significantly enhances the model's performance and generalization but also makes the model's generated results more consistent with human speech patterns. However current research rarely studies the impact of different amounts of instruction data on model performance, especially in the real-world use cases. In this paper we explore the performance of large language models based on instruction tuning across different scales of instruction data. An evaluation dataset consisting of 12 major online use cases is constructed in the experiment. With Bloomz-7B1-mt as the base model, the results show that 1) merely increasing the amount of instruction data leads to continuous improvement in tasks such as open-ended generation, 2) in tasks such as math and code, the model performance curve remains quite flat while increasing data size. We further analyze the possible causes of these phenomena and propose potential future research directions such as effectively selecting high-quality training data, scaling base models and training methods specialized for hard tasks. We will release our training and evaluation datasets, as well as model checkpoints.","created":"2023-03-26","meta":{"link":"http://arxiv.org/abs/2303.14742v1","tag":"prompt-eng"}}
{"title":"Mathematical Characterization of Signal Semantics and Rethinking of the Mathematical Theory of Information","abstract":"Shannon information theory is established based on probability and bits, and the communication technology based on this theory realizes the information age. The original goal of Shannon's information theory is to describe and transmit information content. However, due to information is related to cognition, and cognition is considered to be subjective, Shannon information theory is to describe and transmit information-bearing signals. With the development of the information age to the intelligent age, the traditional signal-oriented processing needs to be upgraded to content-oriented processing. For example, chat generative pre-trained transformer (ChatGPT) has initially realized the content processing capability based on massive data. For many years, researchers have been searching for the answer to what the information content in the signal is, because only when the information content is mathematically and accurately described can information-based machines be truly intelligent. This paper starts from rethinking the essence of the basic concepts of the information, such as semantics, meaning, information and knowledge, presents the mathematical characterization of the information content, investigate the relationship between them, studies the transformation from Shannon's signal information theory to semantic information theory, and therefore proposes a content-oriented semantic communication framework. Furthermore, we propose semantic decomposition and composition scheme to achieve conversion between complex and simple semantics. Finally, we verify the proposed characterization of information-related concepts by implementing evolvable knowledge-based semantic recognition.","created":"2023-03-26","meta":{"link":"http://arxiv.org/abs/2303.14701v1","tag":"prompt-eng"}}
{"title":"Guiding AI-Generated Digital Content with Wireless Perception","abstract":"Recent advances in artificial intelligence (AI), coupled with a surge in training data, have led to the widespread use of AI for digital content generation, with ChatGPT serving as a representative example. Despite the increased efficiency and diversity, the inherent instability of AI models poses a persistent challenge in guiding these models to produce the desired content for users. In this paper, we introduce an integration of wireless perception (WP) with AI-generated content (AIGC) and propose a unified WP-AIGC framework to improve the quality of digital content production. The framework employs a novel multi-scale perception technology to read user's posture, which is difficult to describe accurately in words, and transmits it to the AIGC model as skeleton images. Based on these images and user's service requirements, the AIGC model generates corresponding digital content. Since the production process imposes the user's posture as a constraint on the AIGC model, it makes the generated content more aligned with the user's requirements. Additionally, WP-AIGC can also accept user's feedback, allowing adjustment of computing resources at edge server to improve service quality. Experiments results verify the effectiveness of the WP-AIGC framework, highlighting its potential as a novel approach for guiding AI models in the accurate generation of digital content.","created":"2023-03-26","meta":{"link":"http://arxiv.org/abs/2303.14624v1","tag":"prompt-eng"}}
{"title":"Can Large Language Models assist in Hazard Analysis?","abstract":"Large Language Models (LLMs), such as GPT-3, have demonstrated remarkable natural language processing and generation capabilities and have been applied to a variety tasks, such as source code generation. This paper explores the potential of integrating LLMs in the hazard analysis for safety-critical systems, a process which we refer to as co-hazard analysis (CoHA). In CoHA, a human analyst interacts with an LLM via a context-aware chat session and uses the responses to support elicitation of possible hazard causes. In this experiment, we explore CoHA with three increasingly complex versions of a simple system, using Open AI's ChatGPT service. The quality of ChatGPT's responses were systematically assessed to determine the feasibility of CoHA given the current state of LLM technology. The results suggest that LLMs may be useful for supporting human analysts performing hazard analysis.","created":"2023-03-25","meta":{"link":"http://arxiv.org/abs/2303.15473v1","tag":"prompt-eng"}}
{"title":"Chat-REC: Towards Interactive and Explainable LLMs-Augmented Recommender System","abstract":"Large language models (LLMs) have demonstrated their significant potential to be applied for addressing various application tasks. However, traditional recommender systems continue to face great challenges such as poor interactivity and explainability, which actually also hinder their broad deployment in real-world systems. To address these limitations, this paper proposes a novel paradigm called Chat-Rec (ChatGPT Augmented Recommender System) that innovatively augments LLMs for building conversational recommender systems by converting user profiles and historical interactions into prompts. Chat-Rec is demonstrated to be effective in learning user preferences and establishing connections between users and products through in-context learning, which also makes the recommendation process more interactive and explainable. What's more, within the Chat-Rec framework, user's preferences can transfer to different products for cross-domain recommendations, and prompt-based injection of information into LLMs can also handle the cold-start scenarios with new items. In our experiments, Chat-Rec effectively improve the results of top-k recommendations and performs better in zero-shot rating prediction task. Chat-Rec offers a novel approach to improving recommender systems and presents new practical scenarios for the implementation of AIGC (AI generated content) in recommender system studies.","created":"2023-03-25","meta":{"link":"http://arxiv.org/abs/2303.14524v2","tag":"prompt-eng"}}
{"title":"Chat2VIS: Fine-Tuning Data Visualisations using Multilingual Natural Language Text and Pre-Trained Large Language Models","abstract":"The explosion of data in recent years is driving individuals to leverage technology to generate insights. Traditional tools bring heavy learning overheads and the requirement for understanding complex charting techniques. Such barriers can hinder those who may benefit from harnessing data for informed decision making. The emerging field of generating data visualisations from natural language text (NL2VIS) addresses this issue. This study showcases Chat2VIS, a state-of-the-art NL2VIS solution. It capitalises on the latest in AI technology with the upsurge in pre-trained large language models (LLMs) such as GPT-3, Codex, and ChatGPT. Furthermore, the rise in natural language interfaces (NLI) and chatbots is taking centre stage. This work illustrates how Chat2VIS leverages similar techniques to fine-tune data visualisation components beyond that demonstrated in previous approaches. In addition, this paper presents the flexibility of Chat2VIS to comprehend multilingual natural language requests. No other NL2VIS system has demonstrated this unique talent. In concluding, this research provides quantitative benchmarking evaluations to contribute to the paucity of NL2VIS standards.","created":"2023-03-24","meta":{"link":"http://arxiv.org/abs/2303.14292v1","tag":"prompt-eng"}}
{"title":"ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge","abstract":"Recent large language models (LLMs) in the general domain, such as ChatGPT, have shown remarkable success in following instructions and producing human-like responses. However, such language models have not been tailored to the medical domain, resulting in poor answer accuracy and inability to give plausible recommendations for medical diagnosis, medications, etc. To address this issue, we collected more than 700 diseases and their corresponding symptoms, required medical tests, and recommended medications, from which we generated 5K doctor-patient conversations. In addition, we obtained 200K real patient-doctor conversations from online Q\\&A medical consultation sites. By fine-tuning LLMs using these 205k doctor-patient conversations, the resulting models emerge with great potential to understand patients' needs, provide informed advice, and offer valuable assistance in a variety of medical-related fields. The integration of these advanced language models into healthcare can revolutionize the way healthcare professionals and patients communicate, ultimately improving the overall efficiency and quality of patient care and outcomes. In addition, we made public all the source codes, datasets, and model weights to facilitate the further development of dialogue models in the medical field. The training data, codes, and weights of this project are available at: The training data, codes, and weights of this project are available at: https://github.com/Kent0n-Li/ChatDoctor.","created":"2023-03-24","meta":{"link":"http://arxiv.org/abs/2303.14070v3","tag":"prompt-eng"}}
{"title":"Paraphrase Detection: Human vs. Machine Content","abstract":"The growing prominence of large language models, such as GPT-4 and ChatGPT, has led to increased concerns over academic integrity due to the potential for machine-generated content and paraphrasing. Although studies have explored the detection of human- and machine-paraphrased content, the comparison between these types of content remains underexplored. In this paper, we conduct a comprehensive analysis of various datasets commonly employed for paraphrase detection tasks and evaluate an array of detection methods. Our findings highlight the strengths and limitations of different detection methods in terms of performance on individual datasets, revealing a lack of suitable machine-generated datasets that can be aligned with human expectations. Our main finding is that human-authored paraphrases exceed machine-generated ones in terms of difficulty, diversity, and similarity implying that automatically generated texts are not yet on par with human-level performance. Transformers emerged as the most effective method across datasets with TF-IDF excelling on semantically diverse corpora. Additionally, we identify four datasets as the most diverse and challenging for paraphrase detection.","created":"2023-03-24","meta":{"link":"http://arxiv.org/abs/2303.13989v1","tag":"prompt-eng"}}
{"title":"Generative AI Assistants in Software Development Education","abstract":"The software development industry is amid another potentially disruptive paradigm change--adopting the use of generative AI (GAI) assistants for software development. Whilst AI is already used in various areas of software engineering, GAI technologies, such as GitHub Copilot and ChatGPT, have ignited the imaginations (and fears) of many people. Whilst it is unclear how the industry will adopt and adapt to these technologies, the move to integrate these technologies into the wider industry by large software companies, such as Microsoft (GitHub, Bing) and Google (Bard), is a clear indication of intent and direction. We performed exploratory interviews with industry professionals to understand current practices and challenges, which we incorporate into our vision of a future of software development education and make some pedagogical recommendations.","created":"2023-03-24","meta":{"link":"http://arxiv.org/abs/2303.13936v1","tag":"prompt-eng"}}
{"title":"Unleashing ChatGPT on the Metaverse: Savior or Destroyer?","abstract":"The incorporation of artificial intelligence (AI) technology, and in particular natural language processing (NLP), is becoming increasingly vital for the development of immersive and interactive metaverse experiences. One such artificial intelligence tool that is gaining traction in the metaverse is ChatGPT, a large language model trained by OpenAI. The article delves into the pros and cons of utilizing ChatGPT for metaverse-based education, entertainment, personalization, and support. Dynamic and personalized experiences are possible with this technology, but there are also legitimate privacy, bias, and ethical issues to consider. This article aims to help readers understand the possible influence of ChatGPT on the metaverse and how it may be used to effectively create a more immersive and engaging virtual environment by evaluating these opportunities and obstacles.","created":"2023-03-24","meta":{"link":"http://arxiv.org/abs/2303.13856v2","tag":"prompt-eng"}}
{"title":"Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Models: A Case Study on ChatGPT","abstract":"Generative large language models (LLMs), e.g., ChatGPT, have demonstrated remarkable proficiency across several NLP tasks such as machine translation, question answering, text summarization, and natural language understanding. Recent research has shown that utilizing ChatGPT for assessing the quality of machine translation (MT) achieves state-of-the-art performance at the system level but performs poorly at the segment level. To further improve the performance of LLMs on MT quality assessment, we conducted an investigation into several prompting methods. Our results indicate that by combining Chain-of-Thoughts and Error Analysis, a new prompting method called \\textbf{\\texttt{Error Analysis Prompting}}, LLMs like ChatGPT can \\textit{generate human-like MT evaluations at both the system and segment level}. Additionally, we discovered some limitations of ChatGPT as an MT evaluator, such as unstable scoring and biases when provided with multiple translations in a single query. Our findings aim to provide a preliminary experience for appropriately evaluating translation quality on ChatGPT while offering a variety of tricks in designing prompts for in-context learning. We anticipate that this report will shed new light on advancing the field of translation evaluation with LLMs by enhancing both the accuracy and reliability of metrics. The project can be found in \\url{https://github.com/Coldmist-Lu/ErrorAnalysis_Prompt}.","created":"2023-03-24","meta":{"link":"http://arxiv.org/abs/2303.13809v1","tag":"prompt-eng"}}
{"title":"Towards Making the Most of ChatGPT for Machine Translation","abstract":"ChatGPT shows remarkable capabilities for machine translation (MT). Several prior studies have shown that it achieves comparable results to commercial systems for high-resource languages, but lags behind in complex tasks, e.g, low-resource and distant-language-pairs translation. However, they usually adopt simple prompts which can not fully elicit the capability of ChatGPT. In this report, we aim to further mine ChatGPT's translation ability by revisiting several aspects: temperature, task information, and domain information, and correspondingly propose two (simple but effective) prompts: Task-Specific Prompts (TSP) and Domain-Specific Prompts (DSP). We show that: 1) The performance of ChatGPT depends largely on temperature, and a lower temperature usually can achieve better performance; 2) Emphasizing the task information further improves ChatGPT's performance, particularly in complex MT tasks; 3) Introducing domain information can elicit ChatGPT's generalization ability and improve its performance in the specific domain; 4) ChatGPT tends to generate hallucinations for non-English-centric MT tasks, which can be partially addressed by our proposed prompts but still need to be highlighted for the MT/NLP community. We also explore the effects of advanced in-context learning strategies and find a (negative but interesting) observation: the powerful chain-of-thought prompt leads to word-by-word translation behavior, thus bringing significant translation degradation.","created":"2023-03-24","meta":{"link":"http://arxiv.org/abs/2303.13780v1","tag":"prompt-eng"}}
{"title":"Prompting Multilingual Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages","abstract":"While code-mixing is a common linguistic practice in many parts of the world, collecting high-quality and low-cost code-mixed data remains a challenge for natural language processing (NLP) research. The proliferation of Large Language Models (LLMs) in recent times compels one to ask: can these systems be used for data generation? In this article, we explore prompting multilingual LLMs in a zero-shot manner to create code-mixed data for five languages in South East Asia (SEA) -- Indonesian, Malay, Chinese, Tagalog, Vietnamese, as well as the creole language Singlish. We find that ChatGPT shows the most potential, capable of producing code-mixed text 68% of the time when the term \"code-mixing\" is explicitly defined. Moreover, both ChatGPT's and InstructGPT's (davinci-003) performances in generating Singlish texts are noteworthy, averaging a 96% success rate across a variety of prompts. Their code-mixing proficiency, however, is dampened by word choice errors that lead to semantic inaccuracies. Other multilingual models such as BLOOMZ and Flan-T5-XXL are unable to produce code-mixed texts altogether. By highlighting the limited promises of LLMs in a specific form of low-resource data generation, we call for a measured approach when applying similar techniques to other data-scarce NLP contexts.","created":"2023-03-23","meta":{"link":"http://arxiv.org/abs/2303.13592v2","tag":"prompt-eng"}}
{"title":"ChatGPT for Shaping the Future of Dentistry: The Potential of Multi-Modal Large Language Model","abstract":"The ChatGPT, as a lite and conversational variant of Generative Pretrained Transformer 4 (GPT-4) developed by OpenAI, is one of the milestone Large Language Models (LLMs) with billions of parameters. LLMs, in fact, have stirred up a lot of interest among researchers and practitioners by their impressive skills in natural language processing tasks, which have a profound impact on a wide range of fields. This paper mainly discusses the future applications of LLMs in dentistry. We introduce two primary LLM deployment methods in dentistry, including automated dental diagnosis and cross-modal dental diagnosis, and examine their potential applications. Especially, equipped with a cross-modal encoder, a single LLM can manage multi-source data and conduct advanced natural language reasoning to perform complex clinical operations. A use case is presented to demonstrate the potential of a fully automatic Multi-Modal LLM AI system for dentistry clinical application. While LLMs offer significant potential benefits, the challenges, such as data privacy, data quality, and model bias, need further study. Overall, LLMs have the potential to revolutionize dental diagnosis and treatment, which indicates a promising avenue for clinical application and research in dentistry.","created":"2023-03-23","meta":{"link":"http://arxiv.org/abs/2304.03086v1","tag":"prompt-eng"}}
{"title":"Is ChatGPT A Good Keyphrase Generator? A Preliminary Study","abstract":"The emergence of ChatGPT has recently garnered significant attention from the computational linguistics community. To demonstrate its capabilities as a keyphrase generator, we conduct a preliminary evaluation of ChatGPT for the keyphrase generation task. We evaluate its performance in various aspects, including keyphrase generation prompts, keyphrase generation diversity, multi-domain keyphrase generation, and long document understanding. Our evaluation is based on six benchmark datasets, and we adopt the prompt suggested by OpenAI while extending it to six candidate prompts. We find that ChatGPT performs exceptionally well on all six candidate prompts, with minor performance differences observed across the datasets. Based on our findings, we conclude that ChatGPT has great potential for keyphrase generation. Moreover, we discover that ChatGPT still faces challenges when it comes to generating absent keyphrases. Meanwhile, in the final section, we also present some limitations and future expansions of this report.","created":"2023-03-23","meta":{"link":"http://arxiv.org/abs/2303.13001v1","tag":"prompt-eng"}}
{"title":"The Shaky Foundations of Clinical Foundation Models: A Survey of Large Language Models and Foundation Models for EMRs","abstract":"The successes of foundation models such as ChatGPT and AlphaFold have spurred significant interest in building similar models for electronic medical records (EMRs) to improve patient care and hospital operations. However, recent hype has obscured critical gaps in our understanding of these models' capabilities. We review over 80 foundation models trained on non-imaging EMR data (i.e. clinical text and/or structured data) and create a taxonomy delineating their architectures, training data, and potential use cases. We find that most models are trained on small, narrowly-scoped clinical datasets (e.g. MIMIC-III) or broad, public biomedical corpora (e.g. PubMed) and are evaluated on tasks that do not provide meaningful insights on their usefulness to health systems. In light of these findings, we propose an improved evaluation framework for measuring the benefits of clinical foundation models that is more closely grounded to metrics that matter in healthcare.","created":"2023-03-22","meta":{"link":"http://arxiv.org/abs/2303.12961v2","tag":"prompt-eng"}}
{"title":"Cross-Layer Design for AI Acceleration with Non-Coherent Optical Computing","abstract":"Emerging AI applications such as ChatGPT, graph convolutional networks, and other deep neural networks require massive computational resources for training and inference. Contemporary computing platforms such as CPUs, GPUs, and TPUs are struggling to keep up with the demands of these AI applications. Non-coherent optical computing represents a promising approach for light-speed acceleration of AI workloads. In this paper, we show how cross-layer design can overcome challenges in non-coherent optical computing platforms. We describe approaches for optical device engineering, tuning circuit enhancements, and architectural innovations to adapt optical computing to a variety of AI workloads. We also discuss techniques for hardware/software co-design that can intelligently map and adapt AI software to improve its performance on non-coherent optical computing platforms.","created":"2023-03-22","meta":{"link":"http://arxiv.org/abs/2303.12910v1","tag":"prompt-eng"}}
{"title":"Can we trust the evaluation on ChatGPT?","abstract":"ChatGPT, the first large language model (LLM) with mass adoption, has demonstrated remarkable performance in numerous natural language tasks. Despite its evident usefulness, evaluating ChatGPT's performance in diverse problem domains remains challenging due to the closed nature of the model and its continuous updates via Reinforcement Learning from Human Feedback (RLHF). We highlight the issue of data contamination in ChatGPT evaluations, with a case study of the task of stance detection. We discuss the challenge of preventing data contamination and ensuring fair model evaluation in the age of closed and continuously trained models.","created":"2023-03-22","meta":{"link":"http://arxiv.org/abs/2303.12767v1","tag":"prompt-eng"}}
{"title":"Sparks of Artificial General Intelligence: Early experiments with GPT-4","abstract":"Artificial intelligence (AI) researchers have been developing and refining large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4, was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4's performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4's capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system. In our exploration of GPT-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. We conclude with reflections on societal influences of the recent technological leap and future research directions.","created":"2023-03-22","meta":{"link":"http://arxiv.org/abs/2303.12712v5","tag":"prompt-eng"}}
{"title":"Fundamentals of Generative Large Language Models and Perspectives in Cyber-Defense","abstract":"Generative Language Models gained significant attention in late 2022 / early 2023, notably with the introduction of models refined to act consistently with users' expectations of interactions with AI (conversational models). Arguably the focal point of public attention has been such a refinement of the GPT3 model -- the ChatGPT and its subsequent integration with auxiliary capabilities, including search as part of Microsoft Bing. Despite extensive prior research invested in their development, their performance and applicability to a range of daily tasks remained unclear and niche. However, their wider utilization without a requirement for technical expertise, made in large part possible through conversational fine-tuning, revealed the extent of their true capabilities in a real-world environment. This has garnered both public excitement for their potential applications and concerns about their capabilities and potential malicious uses. This review aims to provide a brief overview of the history, state of the art, and implications of Generative Language Models in terms of their principles, abilities, limitations, and future prospects -- especially in the context of cyber-defense, with a focus on the Swiss operational environment.","created":"2023-03-21","meta":{"link":"http://arxiv.org/abs/2303.12132v1","tag":"prompt-eng"}}
{"title":"Large Language Models Can Be Used to Scale the Ideologies of Politicians in a Zero-Shot Learning Setting","abstract":"The aggregation of knowledge embedded in large language models (LLMs) holds the promise of new solutions to problems of observability and measurement in the social sciences. We examine this potential in a challenging setting: measuring latent ideology -- crucial for better understanding core political functions such as democratic representation. We scale pairwise liberal-conservative comparisons between members of the 116th U.S. Senate using prompts made to ChatGPT. Our measure strongly correlates with widely used liberal-conservative scales such as DW-NOMINATE. Our scale also has interpretative advantages, such as not placing senators who vote against their party for ideologically extreme reasons towards the middle. Our measure is more strongly associated with political activists' perceptions of senators than other measures, consistent with LLMs synthesizing vast amounts of politically relevant data from internet/book corpora rather than memorizing existing measures. LLMs will likely open new avenues for measuring latent constructs utilizing modeled information from massive text corpora.","created":"2023-03-21","meta":{"link":"http://arxiv.org/abs/2303.12057v3","tag":"prompt-eng"}}
{"title":"Artificial muses: Generative Artificial Intelligence Chatbots Have Risen to Human-Level Creativity","abstract":"A widespread view is that Artificial Intelligence cannot be creative. We tested this assumption by comparing human-generated ideas with those generated by six Generative Artificial Intelligence (GAI) chatbots: $alpa.\\!ai$, $Copy.\\!ai$, ChatGPT (versions 3 and 4), $Studio.\\!ai$, and YouChat. Humans and a specifically trained AI independently assessed the quality and quantity of ideas. We found no qualitative difference between AI and human-generated creativity, although there are differences in how ideas are generated. Interestingly, 9.4 percent of humans were more creative than the most creative GAI, GPT-4. Our findings suggest that GAIs are valuable assistants in the creative process. Continued research and development of GAI in creative tasks is crucial to fully understand this technology's potential benefits and drawbacks in shaping the future of creativity. Finally, we discuss the question of whether GAIs are capable of being truly creative.","created":"2023-03-21","meta":{"link":"http://arxiv.org/abs/2303.12003v1","tag":"prompt-eng"}}
{"title":"ChatGPT and a New Academic Reality: Artificial Intelligence-Written Research Papers and the Ethics of the Large Language Models in Scholarly Publishing","abstract":"This paper discusses OpenAIs ChatGPT, a generative pre-trained transformer, which uses natural language processing to fulfill text-based user requests (i.e., a chatbot). The history and principles behind ChatGPT and similar models are discussed. This technology is then discussed in relation to its potential impact on academia and scholarly research and publishing. ChatGPT is seen as a potential model for the automated preparation of essays and other types of scholarly manuscripts. Potential ethical issues that could arise with the emergence of large language models like GPT-3, the underlying technology behind ChatGPT, and its usage by academics and researchers, are discussed and situated within the context of broader advancements in artificial intelligence, machine learning, and natural language processing for research and scholarly publishing.","created":"2023-03-21","meta":{"link":"http://arxiv.org/abs/2303.13367v2","tag":"prompt-eng"}}
{"title":"Chinese Intermediate English Learners outdid ChatGPT in deep cohesion: Evidence from English narrative writing","abstract":"ChatGPT is a publicly available chatbot that can quickly generate texts on given topics, but it is unknown whether the chatbot is really superior to human writers in all aspects of writing and whether its writing quality can be prominently improved on the basis of updating commands. Consequently, this study compared the writing performance on a narrative topic by ChatGPT and Chinese intermediate English (CIE) learners so as to reveal the chatbot's advantage and disadvantage in writing. The data were analyzed in terms of five discourse components using Coh-Metrix (a special instrument for analyzing language discourses), and the results revealed that ChatGPT performed better than human writers in narrativity, word concreteness, and referential cohesion, but worse in syntactic simplicity and deep cohesion in its initial version. After more revision commands were updated, while the resulting version was facilitated in syntactic simplicity, yet it is still lagged far behind CIE learners' writing in deep cohesion. In addition, the correlation analysis of the discourse components suggests that narrativity was correlated with referential cohesion in both ChatGPT and human writers, but the correlations varied within each group.","created":"2023-03-21","meta":{"link":"http://arxiv.org/abs/2303.11812v1","tag":"prompt-eng"}}
{"title":"ChatGPT for Programming Numerical Methods","abstract":"ChatGPT is a large language model recently released by the OpenAI company. In this technical report, we explore for the first time the capability of ChatGPT for programming numerical algorithms. Specifically, we examine the capability of GhatGPT for generating codes for numerical algorithms in different programming languages, for debugging and improving written codes by users, for completing missed parts of numerical codes, rewriting available codes in other programming languages, and for parallelizing serial codes. Additionally, we assess if ChatGPT can recognize if given codes are written by humans or machines. To reach this goal, we consider a variety of mathematical problems such as the Poisson equation, the diffusion equation, the incompressible Navier-Stokes equations, compressible inviscid flow, eigenvalue problems, solving linear systems of equations, storing sparse matrices, etc. Furthermore, we exemplify scientific machine learning such as physics-informed neural networks and convolutional neural networks with applications to computational physics. Through these examples, we investigate the successes, failures, and challenges of ChatGPT. Examples of failures are producing singular matrices, operations on arrays with incompatible sizes, programming interruption for relatively long codes, etc. Our outcomes suggest that ChatGPT can successfully program numerical algorithms in different programming languages, but certain limitations and challenges exist that require further improvement of this machine learning model.","created":"2023-03-21","meta":{"link":"http://arxiv.org/abs/2303.12093v2","tag":"prompt-eng"}}
{"title":"A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?","abstract":"As ChatGPT goes viral, generative AI (AIGC, a.k.a AI-generated content) has made headlines everywhere because of its ability to analyze and create text, images, and beyond. With such overwhelming media coverage, it is almost impossible for us to miss the opportunity to glimpse AIGC from a certain angle. In the era of AI transitioning from pure analysis to creation, it is worth noting that ChatGPT, with its most recent language model GPT-4, is just a tool out of numerous AIGC tasks. Impressed by the capability of the ChatGPT, many people are wondering about its limits: can GPT-5 (or other future GPT variants) help ChatGPT unify all AIGC tasks for diversified content creation? Toward answering this question, a comprehensive review of existing AIGC tasks is needed. As such, our work comes to fill this gap promptly by offering a first look at AIGC, ranging from its techniques to applications. Modern generative AI relies on various technical foundations, ranging from model architecture and self-supervised pretraining to generative modeling methods (like GAN and diffusion models). After introducing the fundamental techniques, this work focuses on the technological development of various AIGC tasks based on their output type, including text, images, videos, 3D content, etc., which depicts the full potential of ChatGPT's future. Moreover, we summarize their significant applications in some mainstream industries, such as education and creativity content. Finally, we discuss the challenges currently faced and present an outlook on how generative AI might evolve in the near future.","created":"2023-03-21","meta":{"link":"http://arxiv.org/abs/2303.11717v1","tag":"prompt-eng"}}
{"title":"Large AI Models in Health Informatics: Applications, Challenges, and the Future","abstract":"Large AI models, or foundation models, are models recently emerging with massive scales both parameter-wise and data-wise, the magnitudes of which often reach beyond billions. Once pretrained, large AI models demonstrate impressive performance in various downstream tasks. A concrete example is the recent debut of ChatGPT, whose capability has compelled people's imagination about the far-reaching influence that large AI models can have and their potential to transform different domains of our life. In health informatics, the advent of large AI models has brought new paradigms for the design of methodologies. The scale of multimodality data in the biomedical and health domain has been ever-expanding especially since the community embraced the era of deep learning, which provides the ground to develop, validate, and advance large AI models for breakthroughs in health-related areas. This article presents an up-to-date comprehensive review of large AI models, from background to their applications. We identify seven key sectors that large AI models are applicable and might have substantial influence, including 1) molecular biology and drug discovery; 2) medical diagnosis and decision-making; 3) medical imaging and vision; 4) medical informatics; 5) medical education; 6) public health; and 7) medical robotics. We examine their challenges in health informatics, followed by a critical discussion about potential future directions and pitfalls of large AI models in transforming the field of health informatics.","created":"2023-03-21","meta":{"link":"http://arxiv.org/abs/2303.11568v1","tag":"prompt-eng"}}
{"title":"MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action","abstract":"We propose MM-REACT, a system paradigm that integrates ChatGPT with a pool of vision experts to achieve multimodal reasoning and action. In this paper, we define and explore a comprehensive list of advanced vision tasks that are intriguing to solve, but may exceed the capabilities of existing vision and vision-language models. To achieve such advanced visual intelligence, MM-REACT introduces a textual prompt design that can represent text descriptions, textualized spatial coordinates, and aligned file names for dense visual signals such as images and videos. MM-REACT's prompt design allows language models to accept, associate, and process multimodal information, thereby facilitating the synergetic combination of ChatGPT and various vision experts. Zero-shot experiments demonstrate MM-REACT's effectiveness in addressing the specified capabilities of interests and its wide application in different scenarios that require advanced visual understanding. Furthermore, we discuss and compare MM-REACT's system paradigm with an alternative approach that extends language models for multimodal scenarios through joint finetuning. Code, demo, video, and visualization are available at https://multimodal-react.github.io/","created":"2023-03-20","meta":{"link":"http://arxiv.org/abs/2303.11381v1","tag":"prompt-eng"}}
{"title":"On the Educational Impact of ChatGPT: Is Artificial Intelligence Ready to Obtain a University Degree?","abstract":"In late 2022, OpenAI released a new version of ChatGPT, a sophisticated natural language processing system capable of holding natural conversations while preserving and responding to the context of the discussion. ChatGPT has exceeded expectations in its abilities, leading to extensive considerations of its potential applications and misuse. In this work, we evaluate the influence of ChatGPT on university education, with a primary focus on computer security-oriented specialization. We gather data regarding the effectiveness and usability of this tool for completing exams, programming assignments, and term papers. We evaluate multiple levels of tool misuse, ranging from utilizing it as a consultant to simply copying its outputs. While we demonstrate how easily ChatGPT can be used to cheat, we also discuss the potentially significant benefits to the educational system. For instance, it might be used as an aid (assistant) to discuss problems encountered while solving an assignment or to speed up the learning process. Ultimately, we discuss how computer science higher education should adapt to tools like ChatGPT.","created":"2023-03-20","meta":{"link":"http://arxiv.org/abs/2303.11146v1","tag":"prompt-eng"}}
{"title":"DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4","abstract":"The digitization of healthcare has facilitated the sharing and re-using of medical data but has also raised concerns about confidentiality and privacy. HIPAA (Health Insurance Portability and Accountability Act) mandates removing re-identifying information before the dissemination of medical records. Thus, effective and efficient solutions for de-identifying medical data, especially those in free-text forms, are highly needed. While various computer-assisted de-identification methods, including both rule-based and learning-based, have been developed and used in prior practice, such solutions still lack generalizability or need to be fine-tuned according to different scenarios, significantly imposing restrictions in wider use. The advancement of large language models (LLM), such as ChatGPT and GPT-4, have shown great potential in processing text data in the medical domain with zero-shot in-context learning, especially in the task of privacy protection, as these models can identify confidential information by their powerful named entity recognition (NER) capability. In this work, we developed a novel GPT4-enabled de-identification framework (\"DeID-GPT\") to automatically identify and remove the identifying information. Compared to existing commonly used medical text data de-identification methods, our developed DeID-GPT showed the highest accuracy and remarkable reliability in masking private information from the unstructured medical text while preserving the original structure and meaning of the text. This study is one of the earliest to utilize ChatGPT and GPT-4 for medical text data processing and de-identification, which provides insights for further research and solution development on the use of LLMs such as ChatGPT/GPT-4 in healthcare. Codes and benchmarking data information are available at https://github.com/yhydhx/ChatGPT-API.","created":"2023-03-20","meta":{"link":"http://arxiv.org/abs/2303.11032v1","tag":"prompt-eng"}}
{"title":"AI-assisted Protective Action: Study of ChatGPT as an Information Source for a Population Facing Climate Hazards","abstract":"ChatGPT has been emerging as a novel information source, and it is likely that the public might seek information from ChatGPT while taking protective actions when facing climate hazards such as floods and hurricanes. The objective of this study is to evaluate the accuracy and completeness of responses generated by ChatGPT when individuals seek information about aspects of taking protective actions. The survey analysis results indicated that: (1) the emergency managers considered the responses provided by ChatGPT as accurate and complete to a great extent; (2) it was statistically verified in evaluations that the generated information was accurate, but lacked completeness, implying that the extent of information provided is accurate; and (3) information generated for prompts related to hazard insurance received the highest evaluation, whereas the information generated related to evacuation received the lowest. This last result implies that, for complex, context-specific protective actions (such as evacuation), the information was rated as less complete compared with other protective actions. Also, the results showed that the perception of respondents regarding the utility of AI- assistive technologies (such as ChatGPT) for emergency preparedness and response improved after taking the survey and evaluating the information generated by ChatGPT. The findings from this study provide empirical evaluation regarding the utility of AI-assistive technologies for improving public decision-making and protective actions in disasters.","created":"2023-03-20","meta":{"link":"http://arxiv.org/abs/2304.06124v2","tag":"prompt-eng"}}
{"title":"A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models","abstract":"GPT series models, such as GPT-3, CodeX, InstructGPT, ChatGPT, and so on, have gained considerable attention due to their exceptional natural language processing capabilities. However, despite the abundance of research on the difference in capabilities between GPT series models and fine-tuned models, there has been limited attention given to the evolution of GPT series models' capabilities over time. To conduct a comprehensive analysis of the capabilities of GPT series models, we select six representative models, comprising two GPT-3 series models (i.e., davinci and text-davinci-001) and four GPT-3.5 series models (i.e., code-davinci-002, text-davinci-002, text-davinci-003, and gpt-3.5-turbo). We evaluate their performance on nine natural language understanding (NLU) tasks using 21 datasets. In particular, we compare the performance and robustness of different models for each task under zero-shot and few-shot scenarios. Our extensive experiments reveal that the overall ability of GPT series models on NLU tasks does not increase gradually as the models evolve, especially with the introduction of the RLHF training strategy. While this strategy enhances the models' ability to generate human-like responses, it also compromises their ability to solve some tasks. Furthermore, our findings indicate that there is still room for improvement in areas such as model robustness.","created":"2023-03-18","meta":{"link":"http://arxiv.org/abs/2303.10420v1","tag":"prompt-eng"}}
{"title":"An Empirical Study of Pre-trained Language Models in Simple Knowledge Graph Question Answering","abstract":"Large-scale pre-trained language models (PLMs) such as BERT have recently achieved great success and become a milestone in natural language processing (NLP). It is now the consensus of the NLP community to adopt PLMs as the backbone for downstream tasks. In recent works on knowledge graph question answering (KGQA), BERT or its variants have become necessary in their KGQA models. However, there is still a lack of comprehensive research and comparison of the performance of different PLMs in KGQA. To this end, we summarize two basic KGQA frameworks based on PLMs without additional neural network modules to compare the performance of nine PLMs in terms of accuracy and efficiency. In addition, we present three benchmarks for larger-scale KGs based on the popular SimpleQuestions benchmark to investigate the scalability of PLMs. We carefully analyze the results of all PLMs-based KGQA basic frameworks on these benchmarks and two other popular datasets, WebQuestionSP and FreebaseQA, and find that knowledge distillation techniques and knowledge enhancement methods in PLMs are promising for KGQA. Furthermore, we test ChatGPT, which has drawn a great deal of attention in the NLP community, demonstrating its impressive capabilities and limitations in zero-shot KGQA. We have released the code and benchmarks to promote the use of PLMs on KGQA.","created":"2023-03-18","meta":{"link":"http://arxiv.org/abs/2303.10368v1","tag":"prompt-eng"}}
{"title":"The Role of Large Language Models in the Recognition of Territorial Sovereignty: An Analysis of the Construction of Legitimacy","abstract":"We examine the potential impact of Large Language Models (LLM) on the recognition of territorial sovereignty and its legitimization. We argue that while technology tools, such as Google Maps and Large Language Models (LLM) like OpenAI's ChatGPT, are often perceived as impartial and objective, this perception is flawed, as AI algorithms reflect the biases of their designers or the data they are built on. We also stress the importance of evaluating the actions and decisions of AI and multinational companies that offer them, which play a crucial role in aspects such as legitimizing and establishing ideas in the collective imagination. Our paper highlights the case of three controversial territories: Crimea, West Bank and Transnitria, by comparing the responses of ChatGPT against Wikipedia information and United Nations resolutions. We contend that the emergence of AI-based tools like LLMs is leading to a new scenario in which emerging technology consolidates power and influences our understanding of reality. Therefore, it is crucial to monitor and analyze the role of AI in the construction of legitimacy and the recognition of territorial sovereignty.","created":"2023-03-17","meta":{"link":"http://arxiv.org/abs/2304.06030v2","tag":"prompt-eng"}}
{"title":"Block-wise Bit-Compression of Transformer-based Models","abstract":"With the popularity of the recent Transformer-based models represented by BERT, GPT-3 and ChatGPT, there has been state-of-the-art performance in a range of natural language processing tasks. However, the massive computations, huge memory footprint, and thus high latency of Transformer-based models is an inevitable challenge for the cloud with high real-time requirement. To tackle the issue, we propose BBCT, a method of block-wise bit-compression for transformer without retraining. Our method achieves more fine-grained compression of the whole transformer, including embedding, matrix multiplication, GELU, softmax, layer normalization, and all the intermediate results. As a case, we compress an efficient BERT with the method of BBCT. Our benchmark test results on General Language Understanding Evaluation (GLUE) show that BBCT can achieve less than 1% accuracy drop in most tasks.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09184v2","tag":"prompt-eng"}}
{"title":"How well do Large Language Models perform in Arithmetic tasks?","abstract":"Large language models have emerged abilities including chain-of-thought to answer math word problems step by step. Solving math word problems not only requires abilities to disassemble problems via chain-of-thought but also needs to calculate arithmetic expressions correctly for each step. To the best of our knowledge, there is no work to focus on evaluating the arithmetic ability of large language models. In this work, we propose an arithmetic dataset MATH 401 to test the latest large language models including GPT-4, ChatGPT, InstrctGPT, Galactica, and LLaMA with various arithmetic expressions and provide a detailed analysis of the ability of large language models. MATH 401 and evaluation codes are released at \\url{https://github.com/GanjinZero/math401-llm}.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2304.02015v1","tag":"prompt-eng"}}
{"title":"Translating Radiology Reports into Plain Language using ChatGPT and GPT-4 with Prompt Learning: Promising Results, Limitations, and Potential","abstract":"The large language model called ChatGPT has drawn extensively attention because of its human-like expression and reasoning abilities. In this study, we investigate the feasibility of using ChatGPT in experiments on using ChatGPT to translate radiology reports into plain language for patients and healthcare providers so that they are educated for improved healthcare. Radiology reports from 62 low-dose chest CT lung cancer screening scans and 76 brain MRI metastases screening scans were collected in the first half of February for this study. According to the evaluation by radiologists, ChatGPT can successfully translate radiology reports into plain language with an average score of 4.27 in the five-point system with 0.08 places of information missing and 0.07 places of misinformation. In terms of the suggestions provided by ChatGPT, they are general relevant such as keeping following-up with doctors and closely monitoring any symptoms, and for about 37% of 138 cases in total ChatGPT offers specific suggestions based on findings in the report. ChatGPT also presents some randomness in its responses with occasionally over-simplified or neglected information, which can be mitigated using a more detailed prompt. Furthermore, ChatGPT results are compared with a newly released large model GPT-4, showing that GPT-4 can significantly improve the quality of translated reports. Our results show that it is feasible to utilize large language models in clinical education, and further efforts are needed to address limitations and maximize their potential.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09038v3","tag":"prompt-eng"}}
{"title":"SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models","abstract":"Generative Large Language Models (LLMs) such as GPT-3 are capable of generating highly fluent responses to a wide variety of user prompts. However, LLMs are known to hallucinate facts and make non-factual statements which can undermine trust in their output. Existing fact-checking approaches either require access to token-level output probability distribution (which may not be available for systems such as ChatGPT) or external databases that are interfaced via separate, often complex, modules. In this work, we propose \"SelfCheckGPT\", a simple sampling-based approach that can be used to fact-check black-box models in a zero-resource fashion, i.e. without an external database. SelfCheckGPT leverages the simple idea that if a LLM has knowledge of a given concept, sampled responses are likely to be similar and contain consistent facts. However, for hallucinated facts, stochastically sampled responses are likely to diverge and contradict one another. We investigate this approach by using GPT-3 to generate passages about individuals from the WikiBio dataset, and manually annotate the factuality of the generated passages. We demonstrate that SelfCheckGPT can: i) detect non-factual and factual sentences; and ii) rank passages in terms of factuality. We compare our approach to several existing baselines and show that in sentence hallucination detection, our approach has AUC-PR scores comparable to grey-box methods, while SelfCheckGPT is best at passage factuality assessment.","created":"2023-03-15","meta":{"link":"http://arxiv.org/abs/2303.08896v1","tag":"prompt-eng"}}
{"title":"UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation","abstract":"Large Language Models (LLMs) are popular for their impressive abilities, but the need for model-specific fine-tuning or task-specific prompt engineering can hinder their generalization. We propose UPRISE (Universal Prompt Retrieval for Improving zero-Shot Evaluation), which tunes a lightweight and versatile retriever that automatically retrieves prompts for a given zero-shot task input. Specifically, we demonstrate universality in a cross-task and cross-model scenario: the retriever is tuned on a diverse set of tasks, but tested on unseen task types; we use a small frozen LLM, GPT-Neo-2.7B, for tuning the retriever, but test the retriever on different LLMs of much larger scales, such as BLOOM-7.1B, OPT-66B and GPT3-175B. Additionally, we show that UPRISE mitigates the hallucination problem in our experiments with ChatGPT, suggesting its potential to improve even the strongest LLMs. Our model and code are available at https://github.com/microsoft/LMOps.","created":"2023-03-15","meta":{"link":"http://arxiv.org/abs/2303.08518v2","tag":"prompt-eng"}}
{"title":"ChatGPT or Grammarly? Evaluating ChatGPT on Grammatical Error Correction Benchmark","abstract":"ChatGPT is a cutting-edge artificial intelligence language model developed by OpenAI, which has attracted a lot of attention due to its surprisingly strong ability in answering follow-up questions. In this report, we aim to evaluate ChatGPT on the Grammatical Error Correction(GEC) task, and compare it with commercial GEC product (e.g., Grammarly) and state-of-the-art models (e.g., GECToR). By testing on the CoNLL2014 benchmark dataset, we find that ChatGPT performs not as well as those baselines in terms of the automatic evaluation metrics (e.g., $F_{0.5}$ score), particularly on long sentences. We inspect the outputs and find that ChatGPT goes beyond one-by-one corrections. Specifically, it prefers to change the surface expression of certain phrases or sentence structure while maintaining grammatical correctness. Human evaluation quantitatively confirms this and suggests that ChatGPT produces less under-correction or mis-correction issues but more over-corrections. These results demonstrate that ChatGPT is severely under-estimated by the automatic evaluation metrics and could be a promising tool for GEC.","created":"2023-03-15","meta":{"link":"http://arxiv.org/abs/2303.13648v1","tag":"prompt-eng"}}
{"title":"NL4Opt Competition: Formulating Optimization Problems Based on Their Natural Language Descriptions","abstract":"The Natural Language for Optimization (NL4Opt) Competition was created to investigate methods of extracting the meaning and formulation of an optimization problem based on its text description. Specifically, the goal of the competition is to increase the accessibility and usability of optimization solvers by allowing non-experts to interface with them using natural language. We separate this challenging goal into two sub-tasks: (1) recognize and label the semantic entities that correspond to the components of the optimization problem; (2) generate a meaning representation (i.e., a logical form) of the problem from its detected problem entities. The first task aims to reduce ambiguity by detecting and tagging the entities of the optimization problems. The second task creates an intermediate representation of the linear programming (LP) problem that is converted into a format that can be used by commercial solvers. In this report, we present the LP word problem dataset and shared tasks for the NeurIPS 2022 competition. Furthermore, we investigate and compare the performance of the ChatGPT large language model against the winning solutions. Through this competition, we hope to bring interest towards the development of novel machine learning applications and datasets for optimization modeling.","created":"2023-03-14","meta":{"link":"http://arxiv.org/abs/2303.08233v2","tag":"prompt-eng"}}
{"title":"Evaluation of ChatGPT as a Question Answering System for Answering Complex Questions","abstract":"ChatGPT is a powerful large language model (LLM) that has made remarkable progress in natural language understanding. Nevertheless, the performance and limitations of the model still need to be extensively evaluated. As ChatGPT covers resources such as Wikipedia and supports natural language question answering, it has garnered attention as a potential replacement for traditional knowledge based question answering (KBQA) models. Complex question answering is a challenge task of KBQA, which comprehensively tests the ability of models in semantic parsing and reasoning. To assess the performance of ChatGPT as a question answering system (QAS) using its own knowledge, we present a framework that evaluates its ability to answer complex questions. Our approach involves categorizing the potential features of complex questions and describing each test question with multiple labels to identify combinatorial reasoning. Following the black-box testing specifications of CheckList proposed by Ribeiro et.al, we develop an evaluation method to measure the functionality and reliability of ChatGPT in reasoning for answering complex questions. We use the proposed framework to evaluate the performance of ChatGPT in question answering on 8 real-world KB-based CQA datasets, including 6 English and 2 multilingual datasets, with a total of approximately 190,000 test cases. We compare the evaluation results of ChatGPT, GPT-3.5, GPT-3, and FLAN-T5 to identify common long-term problems in LLMs. The dataset and code are available at https://github.com/tan92hl/Complex-Question-Answering-Evaluation-of-ChatGPT.","created":"2023-03-14","meta":{"link":"http://arxiv.org/abs/2303.07992v1","tag":"prompt-eng"}}
{"title":"Exploring ChatGPT's Ability to Rank Content: A Preliminary Study on Consistency with Human Preferences","abstract":"As a natural language assistant, ChatGPT is capable of performing various tasks, including but not limited to article generation, code completion, and data analysis. Furthermore, ChatGPT has consistently demonstrated a remarkable level of accuracy and reliability in terms of content evaluation, exhibiting the capability of mimicking human preferences. To further explore ChatGPT's potential in this regard, a study is conducted to assess its ability to rank content. In order to do so, a test set consisting of prompts is created, covering a wide range of use cases, and five models are utilized to generate corresponding responses. ChatGPT is then instructed to rank the responses generated by these models. The results on the test set show that ChatGPT's ranking preferences are consistent with human to a certain extent. This preliminary experimental finding implies that ChatGPT's zero-shot ranking capability could be used to reduce annotation pressure in a number of ranking tasks.","created":"2023-03-14","meta":{"link":"http://arxiv.org/abs/2303.07610v1","tag":"prompt-eng"}}
{"title":"Thinking Upstream: Ethics and Policy Opportunities in AI Supply Chains","abstract":"After children were pictured sewing its running shoes in the early 1990s, Nike at first disavowed the \"working conditions in its suppliers' factories\", before public pressure led them to take responsibility for ethics in their upstream supply chain. In 2023, OpenAI responded to criticism that Kenyan workers were paid less than $2 per hour to filter traumatic content from its ChatGPT model by stating in part that it had outsourced the work to a subcontractor, who managed workers' payment and mental health concerns. In this position paper, we argue that policy interventions for AI Ethics must consider AI as a supply chain problem, given how the political economy and intra-firm relations structure AI production, in particular examining opportunities upstream.","created":"2023-03-13","meta":{"link":"http://arxiv.org/abs/2303.07529v1","tag":"prompt-eng"}}
{"title":"Analyzing ChatGPT's Aptitude in an Introductory Computer Engineering Course","abstract":"ChatGPT has recently gathered attention from the general public and academia as a tool that is able to generate plausible and human-sounding text answers to various questions. One potential use, or abuse, of ChatGPT is in answering various questions or even generating whole essays and research papers in an academic or classroom setting. While recent works have explored the use of ChatGPT in the context of humanities, business school, or medical school, this work explores how ChatGPT performs in the context of an introductory computer engineering course. This work assesses ChatGPT's aptitude in answering quizzes, homework, exam, and laboratory questions in an introductory-level computer engineering course. This work finds that ChatGPT can do well on questions asking about generic concepts. However, predictably, as a text-only tool, it cannot handle questions with diagrams or figures, nor can it generate diagrams and figures. Further, also clearly, the tool cannot do hands-on lab experiments, breadboard assembly, etc., but can generate plausible answers to some laboratory manual questions. One of the key observations presented in this work is that the ChatGPT tool could not be used to pass all components of the course. Nevertheless, it does well on quizzes and short-answer questions. On the other hand, plausible, human-sounding answers could confuse students when generating incorrect but still plausible answers.","created":"2023-03-13","meta":{"link":"http://arxiv.org/abs/2304.06122v2","tag":"prompt-eng"}}
{"title":"ODIN: On-demand Data Formulation to Mitigate Dataset Lock-in","abstract":"ODIN is an innovative approach that addresses the problem of dataset constraints by integrating generative AI models. Traditional zero-shot learning methods are constrained by the training dataset. To fundamentally overcome this limitation, ODIN attempts to mitigate the dataset constraints by generating on-demand datasets based on user requirements. ODIN consists of three main modules: a prompt generator, a text-to-image generator, and an image post-processor. To generate high-quality prompts and images, we adopted a large language model (e.g., ChatGPT), and a text-to-image diffusion model (e.g., Stable Diffusion), respectively. We evaluated ODIN on various datasets in terms of model accuracy and data diversity to demonstrate its potential, and conducted post-experiments for further investigation. Overall, ODIN is a feasible approach that enables Al to learn unseen knowledge beyond the training dataset.","created":"2023-03-13","meta":{"link":"http://arxiv.org/abs/2303.06832v2","tag":"prompt-eng"}}
{"title":"ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched Visual Descriptions","abstract":"Asking insightful questions is crucial for acquiring knowledge and expanding our understanding of the world. However, the importance of questioning has been largely overlooked in AI research, where models have been primarily developed to answer questions. With the recent advancements of large language models (LLMs) like ChatGPT, we discover their capability to ask high-quality questions when provided with a suitable prompt. This discovery presents a new opportunity to develop an automatic questioning system. In this paper, we introduce ChatCaptioner, a novel automatic-questioning method deployed in image captioning. Here, ChatGPT is prompted to ask a series of informative questions about images to BLIP-2, a strong vision question-answering model. By keeping acquiring new visual information from BLIP-2's answers, ChatCaptioner is able to generate more enriched image descriptions. We conduct human-subject evaluations on common image caption datasets such as COCO, Conceptual Caption, and WikiArt, and compare ChatCaptioner with BLIP-2 as well as ground truth. Our results demonstrate that ChatCaptioner's captions are significantly more informative, receiving three times as many votes from human evaluators for providing the most image information. Besides, ChatCaptioner identifies 53% more objects within the image than BLIP-2 alone measured by WordNet synset matching. Code is available at https://github.com/Vision-CAIR/ChatCaptioner","created":"2023-03-12","meta":{"link":"http://arxiv.org/abs/2303.06594v1","tag":"prompt-eng"}}
{"title":"A comprehensive evaluation of ChatGPT's zero-shot Text-to-SQL capability","abstract":"This paper presents the first comprehensive analysis of ChatGPT's Text-to-SQL ability. Given the recent emergence of large-scale conversational language model ChatGPT and its impressive capabilities in both conversational abilities and code generation, we sought to evaluate its Text-to-SQL performance. We conducted experiments on 12 benchmark datasets with different languages, settings, or scenarios, and the results demonstrate that ChatGPT has strong text-to-SQL abilities. Although there is still a gap from the current state-of-the-art (SOTA) model performance, considering that the experiment was conducted in a zero-shot scenario, ChatGPT's performance is still impressive. Notably, in the ADVETA (RPL) scenario, the zero-shot ChatGPT even outperforms the SOTA model that requires fine-tuning on the Spider dataset by 4.1\\%, demonstrating its potential for use in practical applications. To support further research in related fields, we have made the data generated by ChatGPT publicly available at https://github.com/THU-BPM/chatgpt-sql.","created":"2023-03-12","meta":{"link":"http://arxiv.org/abs/2303.13547v1","tag":"prompt-eng"}}
{"title":"Context-based Ontology Modelling for Database: Enabling ChatGPT for Semantic Database Management","abstract":"This research paper explores the use of ChatGPT in database management. ChatGPT, an AI-powered chatbot, has limitations in performing tasks related to database management due to the lack of standardized vocabulary and grammar for representing database semantics. To address this limitation, the paper proposes a solution that involves developing a set of syntaxes that can represent database semantics in natural language. The syntax is used to convert database schemas into natural language formats, providing a new application of ChatGPT in database management. The proposed solution is demonstrated through a case study where ChatGPT is used to perform two tasks, semantic integration, and tables joining. Results demonstrate that the use of semantic database representations produces more precise outcomes and avoids common mistakes compared to cases with no semantic representation. The proposed method has the potential to speed up the database management process, reduce the level of understanding required for database domain knowledge, and enable automatic database operations without accessing the actual data, thus illuminating privacy protection concerns when using AI. This paper provides a promising new direction for research in the field of AI-based database management.","created":"2023-03-11","meta":{"link":"http://arxiv.org/abs/2303.07351v1","tag":"prompt-eng"}}
{"title":"ChatGPT Prompt Patterns for Improving Code Quality, Refactoring, Requirements Elicitation, and Software Design","abstract":"This paper presents prompt design techniques for software engineering, in the form of patterns, to solve common problems when using large language models (LLMs), such as ChatGPT to automate common software engineering activities, such as ensuring code is decoupled from third-party libraries and simulating a web application API before it is implemented. This paper provides two contributions to research on using LLMs for software engineering. First, it provides a catalog of patterns for software engineering that classifies patterns according to the types of problems they solve. Second, it explores several prompt patterns that have been applied to improve requirements elicitation, rapid prototyping, code quality, refactoring, and system design.","created":"2023-03-11","meta":{"link":"http://arxiv.org/abs/2303.07839v1","tag":"prompt-eng"}}
{"title":"Art-ificial Intelligence: The Effect of AI Disclosure on Evaluations of Creative Content","abstract":"The emergence of generative AI technologies, such as OpenAI's ChatGPT chatbot, has expanded the scope of tasks that AI tools can accomplish and enabled AI-generated creative content. In this study, we explore how disclosure regarding the use of AI in the creation of creative content affects human evaluation of such content. In a series of pre-registered experimental studies, we show that AI disclosure has no meaningful effect on evaluation either for creative or descriptive short stories, but that AI disclosure has a negative effect on evaluations for emotionally evocative poems written in the first person. We interpret this result to suggest that reactions to AI-generated content may be negative when the content is viewed as distinctly \"human.\" We discuss the implications of this work and outline planned pathways of research to better understand whether and when AI disclosure may affect the evaluation of creative content.","created":"2023-03-11","meta":{"link":"http://arxiv.org/abs/2303.06217v1","tag":"prompt-eng"}}
{"title":"Consistency Analysis of ChatGPT","abstract":"ChatGPT, a question-and-answer dialogue system based on a large language model, has gained huge popularity since its introduction. Its positive aspects have been reported through many media platforms, and some analyses even showed that ChatGPT achieved a decent grade in professional exams, including the law, medical, and finance domains, adding extra support to the claim that AI now can assist and, even, replace humans in industrial fields. Others, however, doubt its reliability and trustworthiness. In this paper, we investigate ChatGPT's trustworthiness regarding logically consistent behaviours. Our findings suggest that, although ChatGPT seems to achieve an improved language understanding ability, it still fails to generate logically correct predictions frequently. Hence, while it is true that ChatGPT is an impressive and promising new technique, we conclude that its usage in real-world applications without thorough human inspection requires further consideration, especially for risk-sensitive areas.","created":"2023-03-11","meta":{"link":"http://arxiv.org/abs/2303.06273v1","tag":"prompt-eng"}}
{"title":"ChatGPT as the Transportation Equity Information Source for Scientific Writing","abstract":"Transportation equity is an interdisciplinary agenda that requires both transportation and social inputs. Traditionally, transportation equity information are sources from public libraries, conferences, televisions, social media, among other. Artificial intelligence (AI) tools including advanced language models such as ChatGPT are becoming favorite information sources. However, their credibility has not been well explored. This study explored the content and usefulness of ChatGPT-generated information related to transportation equity. It utilized 152 papers retrieved through the Web of Science (WoS) repository. The prompt was crafted for ChatGPT to provide an abstract given the title of the paper. The ChatGPT-based abstracts were then compared to human-written abstracts using statistical tools and unsupervised text mining. The results indicate that a weak similarity between ChatGPT and human-written abstracts. On average, the human-written abstracts and ChatGPT generated abstracts were about 58% similar, with a maximum and minimum of 97% and 1.4%, respectively. The keywords from the abstracts of papers with over the mean similarity score were more likely to be similar whereas those from below the average score were less likely to be similar. Themes with high similarity scores include access, public transit, and policy, among others. Further, clear differences in the key pattern of clusters for high and low similarity score abstracts was observed. Contrarily, the findings from collocated keywords were inconclusive. The study findings suggest that ChatGPT has the potential to be a source of transportation equity information. However, currently, a great amount of attention is needed before a user can utilize materials from ChatGPT","created":"2023-03-10","meta":{"link":"http://arxiv.org/abs/2303.11158v1","tag":"prompt-eng"}}
{"title":"Does ChatGPT resemble humans in language use?","abstract":"Large language models (LLMs) and LLM-driven chatbots such as ChatGPT have shown remarkable capacities in comprehending and producing language. However, their internal workings remain a black box in cognitive terms, and it is unclear whether LLMs and chatbots can develop humanlike characteristics in language use. Cognitive scientists have devised many experiments that probe, and have made great progress in explaining, how people process language. We subjected ChatGPT to 12 of these experiments, pre-registered and with 1,000 runs per experiment. In 10 of them, ChatGPT replicated the human pattern of language use. It associated unfamiliar words with different meanings depending on their forms, continued to access recently encountered meanings of ambiguous words, reused recent sentence structures, reinterpreted implausible sentences that were likely to have been corrupted by noise, glossed over errors, drew reasonable inferences, associated causality with different discourse entities according to verb semantics, and accessed different meanings and retrieved different words depending on the identity of its interlocutor. However, unlike humans, it did not prefer using shorter words to convey less informative content and it did not use context to disambiguate syntactic ambiguities. We discuss how these convergences and divergences may occur in the transformer architecture. Overall, these experiments demonstrate that LLM-driven chatbots like ChatGPT are capable of mimicking human language processing to a great extent, and that they have the potential to provide insights into how people learn and use language.","created":"2023-03-10","meta":{"link":"http://arxiv.org/abs/2303.08014v1","tag":"prompt-eng"}}
{"title":"Personalisation within bounds: A risk taxonomy and policy framework for the alignment of large language models with personalised feedback","abstract":"Large language models (LLMs) are used to generate content for a wide range of tasks, and are set to reach a growing audience in coming years due to integration in product interfaces like ChatGPT or search engines like Bing. This intensifies the need to ensure that models are aligned with human preferences and do not produce unsafe, inaccurate or toxic outputs. While alignment techniques like reinforcement learning with human feedback (RLHF) and red-teaming can mitigate some safety concerns and improve model capabilities, it is unlikely that an aggregate fine-tuning process can adequately represent the full range of users' preferences and values. Different people may legitimately disagree on their preferences for language and conversational norms, as well as on values or ideologies which guide their communication. Personalising LLMs through micro-level preference learning processes may result in models that are better aligned with each user. However, there are several normative challenges in defining the bounds of a societally-acceptable and safe degree of personalisation. In this paper, we ask how, and in what ways, LLMs should be personalised. First, we review literature on current paradigms for aligning LLMs with human feedback, and identify issues including (i) a lack of clarity regarding what alignment means; (ii) a tendency of technology providers to prescribe definitions of inherently subjective preferences and values; and (iii) a 'tyranny of the crowdworker', exacerbated by a lack of documentation in who we are really aligning to. Second, we present a taxonomy of benefits and risks associated with personalised LLMs, for individuals and society at large. Finally, we propose a three-tiered policy framework that allows users to experience the benefits of personalised alignment, while restraining unsafe and undesirable LLM-behaviours within (supra-)national and organisational bounds.","created":"2023-03-09","meta":{"link":"http://arxiv.org/abs/2303.05453v1","tag":"prompt-eng"}}
{"title":"Seeing ChatGPT Through Students' Eyes: An Analysis of TikTok Data","abstract":"Advanced large language models like ChatGPT have gained considerable attention recently, including among students. However, while the debate on ChatGPT in academia is making waves, more understanding is needed among lecturers and teachers on how students use and perceive ChatGPT. To address this gap, we analyzed the content on ChatGPT available on TikTok in February 2023. TikTok is a rapidly growing social media platform popular among individuals under 30. Specifically, we analyzed the content of the 100 most popular videos in English tagged with #chatgpt, which collectively garnered over 250 million views. Most of the videos we studied promoted the use of ChatGPT for tasks like writing essays or code. In addition, many videos discussed AI detectors, with a focus on how other tools can help to transform ChatGPT output to fool these detectors. This also mirrors the discussion among educators on how to treat ChatGPT as lecturers and teachers in teaching and grading. What is, however, missing from the analyzed clips on TikTok are videos that discuss ChatGPT producing content that is nonsensical or unfaithful to the training data.","created":"2023-03-09","meta":{"link":"http://arxiv.org/abs/2303.05349v1","tag":"prompt-eng"}}
{"title":"ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction","abstract":"Large language models (LLMs), such as GPT-3 and ChatGPT, have demonstrated remarkable results in various natural language processing (NLP) tasks with in-context learning, which involves inference based on a few demonstration examples. Despite their successes in NLP tasks, no investigation has been conducted to assess the ability of LLMs to perform document information extraction (DIE) using in-context learning. Applying LLMs to DIE poses two challenges: the modality and task gap. To this end, we propose a simple but effective in-context learning framework called ICL-D3IE, which enables LLMs to perform DIE with different types of demonstration examples. Specifically, we extract the most difficult and distinct segments from hard training documents as hard demonstrations for benefiting all test instances. We design demonstrations describing relationships that enable LLMs to understand positional relationships. We introduce formatting demonstrations for easy answer extraction. Additionally, the framework improves diverse demonstrations by updating them iteratively. Our experiments on three widely used benchmark datasets demonstrate that the ICL-D3IE framework enables GPT-3/ChatGPT to achieve superior performance when compared to previous pre-trained methods fine-tuned with full training in both the in-distribution (ID) setting and in the out-of-distribution (OOD) setting.","created":"2023-03-09","meta":{"link":"http://arxiv.org/abs/2303.05063v2","tag":"prompt-eng"}}
{"title":"The Carbon Emissions of Writing and Illustrating Are Lower for AI than for Humans","abstract":"As AI systems proliferate, their greenhouse gas emissions are an increasingly important concern for human societies. We analyze the emissions of several AI systems (ChatGPT, BLOOM, DALL-E2, Midjourney) relative to those of humans completing the same tasks. We find that an AI writing a page of text emits 130 to 1500 times less CO2e than a human doing so. Similarly, an AI creating an image emits 310 to 2900 times less. Emissions analysis do not account for social impacts such as professional displacement, legality, and rebound effects. In addition, AI is not a substitute for all human tasks. Nevertheless, at present, the use of AI holds the potential to carry out several major activities at much lower emission levels than can humans.","created":"2023-03-08","meta":{"link":"http://arxiv.org/abs/2303.06219v1","tag":"prompt-eng"}}
{"title":"FaceChat: An Emotion-Aware Face-to-face Dialogue Framework","abstract":"While current dialogue systems like ChatGPT have made significant advancements in text-based interactions, they often overlook the potential of other modalities in enhancing the overall user experience. We present FaceChat, a web-based dialogue framework that enables emotionally-sensitive and face-to-face conversations. By seamlessly integrating cutting-edge technologies in natural language processing, computer vision, and speech processing, FaceChat delivers a highly immersive and engaging user experience. FaceChat framework has a wide range of potential applications, including counseling, emotional support, and personalized customer service. The system is designed to be simple and flexible as a platform for future researchers to advance the field of multimodal dialogue systems. The code is publicly available at https://github.com/qywu/FaceChat.","created":"2023-03-08","meta":{"link":"http://arxiv.org/abs/2303.07316v1","tag":"prompt-eng"}}
{"title":"Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models","abstract":"ChatGPT is attracting a cross-field interest as it provides a language interface with remarkable conversational competency and reasoning capabilities across many domains. However, since ChatGPT is trained with languages, it is currently not capable of processing or generating images from the visual world. At the same time, Visual Foundation Models, such as Visual Transformers or Stable Diffusion, although showing great visual understanding and generation capabilities, they are only experts on specific tasks with one-round fixed inputs and outputs. To this end, We build a system called \\textbf{Visual ChatGPT}, incorporating different Visual Foundation Models, to enable the user to interact with ChatGPT by 1) sending and receiving not only languages but also images 2) providing complex visual questions or visual editing instructions that require the collaboration of multiple AI models with multi-steps. 3) providing feedback and asking for corrected results. We design a series of prompts to inject the visual model information into ChatGPT, considering models of multiple inputs/outputs and models that require visual feedback. Experiments show that Visual ChatGPT opens the door to investigating the visual roles of ChatGPT with the help of Visual Foundation Models. Our system is publicly available at \\url{https://github.com/microsoft/visual-chatgpt}.","created":"2023-03-08","meta":{"link":"http://arxiv.org/abs/2303.04671v1","tag":"prompt-eng"}}
{"title":"ChatGPT Participates in a Computer Science Exam","abstract":"We asked ChatGPT to participate in an undergraduate computer science exam on ''Algorithms and Data Structures''. The program was evaluated on the entire exam as posed to the students. We hand-copied its answers onto an exam sheet, which was subsequently graded in a blind setup alongside those of 200 participating students. We find that ChatGPT narrowly passed the exam, obtaining 20.5 out of 40 points. This impressive performance indicates that ChatGPT can indeed succeed in challenging tasks like university exams. At the same time, the questions in our exam are structurally similar to those of other exams, solved homework problems, and teaching materials that can be found online and might have been part of ChatGPT's training data. Therefore, it would be inadequate to conclude from this experiment that ChatGPT has any understanding of computer science. We also assess the improvements brought by GPT-4. We find that GPT-4 would have obtained about 17\\% more exam points than GPT-3.5, reaching the performance of the average student. The transcripts of our conversations with ChatGPT are available at \\url{https://github.com/tml-tuebingen/chatgpt-algorithm-exam}, and the entire graded exam is in the appendix of this paper.","created":"2023-03-08","meta":{"link":"http://arxiv.org/abs/2303.09461v2","tag":"prompt-eng"}}
{"title":"Does Synthetic Data Generation of LLMs Help Clinical Text Mining?","abstract":"Recent advancements in large language models (LLMs) have led to the development of highly potent models like OpenAI's ChatGPT. These models have exhibited exceptional performance in a variety of tasks, such as question answering, essay composition, and code generation. However, their effectiveness in the healthcare sector remains uncertain. In this study, we seek to investigate the potential of ChatGPT to aid in clinical text mining by examining its ability to extract structured information from unstructured healthcare texts, with a focus on biological named entity recognition and relation extraction. However, our preliminary results indicate that employing ChatGPT directly for these tasks resulted in poor performance and raised privacy concerns associated with uploading patients' information to the ChatGPT API. To overcome these limitations, we propose a new training paradigm that involves generating a vast quantity of high-quality synthetic data with labels utilizing ChatGPT and fine-tuning a local model for the downstream task. Our method has resulted in significant improvements in the performance of downstream tasks, improving the F1-score from 23.37% to 63.99% for the named entity recognition task and from 75.86% to 83.59% for the relation extraction task. Furthermore, generating data using ChatGPT can significantly reduce the time and effort required for data collection and labeling, as well as mitigate data privacy concerns. In summary, the proposed framework presents a promising solution to enhance the applicability of LLM models to clinical text mining.","created":"2023-03-08","meta":{"link":"http://arxiv.org/abs/2303.04360v2","tag":"prompt-eng"}}
{"title":"Many bioinformatics programming tasks can be automated with ChatGPT","abstract":"Computer programming is a fundamental tool for life scientists, allowing them to carry out many essential research tasks. However, despite a variety of educational efforts, learning to write code can be a challenging endeavor for both researchers and students in life science disciplines. Recent advances in artificial intelligence have made it possible to translate human-language prompts to functional code, raising questions about whether these technologies can aid (or replace) life scientists' efforts to write code. Using 184 programming exercises from an introductory-bioinformatics course, we evaluated the extent to which one such model -- OpenAI's ChatGPT -- can successfully complete basic- to moderate-level programming tasks. On its first attempt, ChatGPT solved 139 (75.5%) of the exercises. For the remaining exercises, we provided natural-language feedback to the model, prompting it to try different approaches. Within 7 or fewer attempts, ChatGPT solved 179 (97.3%) of the exercises. These findings have important implications for life-sciences research and education. For many programming tasks, researchers no longer need to write code from scratch. Instead, machine-learning models may produce usable solutions. Instructors may need to adapt their pedagogical approaches and assessment techniques to account for these new capabilities that are available to the general public.","created":"2023-03-07","meta":{"link":"http://arxiv.org/abs/2303.13528v1","tag":"prompt-eng"}}
{"title":"A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT","abstract":"Recently, ChatGPT, along with DALL-E-2 and Codex,has been gaining significant attention from society. As a result, many individuals have become interested in related resources and are seeking to uncover the background and secrets behind its impressive performance. In fact, ChatGPT and other Generative AI (GAI) techniques belong to the category of Artificial Intelligence Generated Content (AIGC), which involves the creation of digital content, such as images, music, and natural language, through AI models. The goal of AIGC is to make the content creation process more efficient and accessible, allowing for the production of high-quality content at a faster pace. AIGC is achieved by extracting and understanding intent information from instructions provided by human, and generating the content according to its knowledge and the intent information. In recent years, large-scale models have become increasingly important in AIGC as they provide better intent extraction and thus, improved generation results. With the growth of data and the size of the models, the distribution that the model can learn becomes more comprehensive and closer to reality, leading to more realistic and high-quality content generation. This survey provides a comprehensive review on the history of generative models, and basic components, recent advances in AIGC from unimodal interaction and multimodal interaction. From the perspective of unimodality, we introduce the generation tasks and relative models of text and image. From the perspective of multimodality, we introduce the cross-application between the modalities mentioned above. Finally, we discuss the existing open problems and future challenges in AIGC.","created":"2023-03-07","meta":{"link":"http://arxiv.org/abs/2303.04226v1","tag":"prompt-eng"}}
{"title":"Extracting Accurate Materials Data from Research Papers with Conversational Language Models and Prompt Engineering -- Example of ChatGPT","abstract":"There has been a growing effort to replace hand extraction of data from research papers with automated data extraction based on natural language processing (NLP), language models (LMs), and recently, large language models (LLMs). Although these methods enable efficient extraction of data from large sets of research papers, they require a significant amount of up-front effort, expertise, and coding. In this work we propose the ChatExtract method that can fully automate very accurate data extraction with essentially no initial effort or background using an advanced conversational LLM (or AI). ChatExtract consists of a set of engineered prompts applied to a conversational LLM that both identify sentences with data, extract data, and assure its correctness through a series of follow-up questions. These follow-up questions address a critical challenge associated with LLMs - their tendency to provide factually inaccurate responses. ChatExtract can be applied with any conversational LLMs and yields very high quality data extraction. In tests on materials data we find precision and recall both over 90% from the best conversational LLMs, likely rivaling or exceeding human accuracy in many cases. We demonstrate that the exceptional performance is enabled by the information retention in a conversational model combined with purposeful redundancy and introducing uncertainty through follow-up prompts. These results suggest that approaches similar to ChatExtract, due to their simplicity, transferability and accuracy are likely to replace other methods of data extraction in the near future.","created":"2023-03-07","meta":{"link":"http://arxiv.org/abs/2303.05352v1","tag":"prompt-eng"}}
{"title":"Is ChatGPT a Good NLG Evaluator? A Preliminary Study","abstract":"Recently, the emergence of ChatGPT has attracted wide attention from the computational linguistics community. Many prior studies have shown that ChatGPT achieves remarkable performance on various NLP tasks in terms of automatic evaluation metrics. However, the ability of ChatGPT to serve as an evaluation metric is still underexplored. Considering assessing the quality of NLG models is an arduous task and previous statistical metrics notoriously show their poor correlation with human judgments, we wonder whether ChatGPT is a good NLG evaluation metric. In this report, we provide a preliminary meta-evaluation on ChatGPT to show its reliability as an NLG metric. In detail, we regard ChatGPT as a human evaluator and give task-specific (e.g., summarization) and aspect-specific (e.g., relevance) instruction to prompt ChatGPT to score the generation of NLG models. We conduct experiments on three widely-used NLG meta-evaluation datasets (including summarization, story generation and data-to-text tasks). Experimental results show that compared with previous automatic metrics, ChatGPT achieves state-of-the-art or competitive correlation with golden human judgments. We hope our preliminary study could prompt the emergence of a general-purposed reliable NLG metric.","created":"2023-03-07","meta":{"link":"http://arxiv.org/abs/2303.04048v1","tag":"prompt-eng"}}
{"title":"Making a Computational Attorney","abstract":"This \"blue sky idea\" paper outlines the opportunities and challenges in data mining and machine learning involving making a computational attorney -- an intelligent software agent capable of helping human lawyers with a wide range of complex high-level legal tasks such as drafting legal briefs for the prosecution or defense in court. In particular, we discuss what a ChatGPT-like Large Legal Language Model (L$^3$M) can and cannot do today, which will inspire researchers with promising short-term and long-term research objectives.","created":"2023-03-07","meta":{"link":"http://arxiv.org/abs/2303.05383v1","tag":"prompt-eng"}}
{"title":"ChatGPT: Beginning of an End of Manual Linguistic Data Annotation? Use Case of Automatic Genre Identification","abstract":"ChatGPT has shown strong capabilities in natural language generation tasks, which naturally leads researchers to explore where its abilities end. In this paper, we examine whether ChatGPT can be used for zero-shot text classification, more specifically, automatic genre identification. We compare ChatGPT with a multilingual XLM-RoBERTa language model that was fine-tuned on datasets, manually annotated with genres. The models are compared on test sets in two languages: English and Slovenian. Results show that ChatGPT outperforms the fine-tuned model when applied to the dataset which was not seen before by either of the models. Even when applied on Slovenian language as an under-resourced language, ChatGPT's performance is no worse than when applied to English. However, if the model is fully prompted in Slovenian, the performance drops significantly, showing the current limitations of ChatGPT usage on smaller languages. The presented results lead us to questioning whether this is the beginning of an end of laborious manual annotation campaigns even for smaller languages, such as Slovenian.","created":"2023-03-07","meta":{"link":"http://arxiv.org/abs/2303.03953v2","tag":"prompt-eng"}}
{"title":"Exploring the Feasibility of ChatGPT for Event Extraction","abstract":"Event extraction is a fundamental task in natural language processing that involves identifying and extracting information about events mentioned in text. However, it is a challenging task due to the lack of annotated data, which is expensive and time-consuming to obtain. The emergence of large language models (LLMs) such as ChatGPT provides an opportunity to solve language tasks with simple prompts without the need for task-specific datasets and fine-tuning. While ChatGPT has demonstrated impressive results in tasks like machine translation, text summarization, and question answering, it presents challenges when used for complex tasks like event extraction. Unlike other tasks, event extraction requires the model to be provided with a complex set of instructions defining all event types and their schemas. To explore the feasibility of ChatGPT for event extraction and the challenges it poses, we conducted a series of experiments. Our results show that ChatGPT has, on average, only 51.04% of the performance of a task-specific model such as EEQA in long-tail and complex scenarios. Our usability testing experiments indicate that ChatGPT is not robust enough, and continuous refinement of the prompt does not lead to stable performance improvements, which can result in a poor user experience. Besides, ChatGPT is highly sensitive to different prompt styles.","created":"2023-03-07","meta":{"link":"http://arxiv.org/abs/2303.03836v2","tag":"prompt-eng"}}
{"title":"ChatGPT Is on the Horizon: Could a Large Language Model Be All We Need for Intelligent Transportation?","abstract":"ChatGPT, developed by OpenAI, is one of the milestone large language models (LLMs) with 6 billion parameters. ChatGPT has demonstrated the impressive language understanding capability of LLM, particularly in generating conversational response. As LLMs start to gain more attention in various research or engineering domains, it is time to envision how LLM may revolutionize the way we approach intelligent transportation systems. This paper explores the future applications of LLM in addressing key transportation problems. By leveraging LLM with cross-modal encoder, an intelligent system can also process traffic data from different modalities and execute transportation operations through an LLM. We present and validate these potential transportation applications equipped by LLM. To further demonstrate this potential, we also provide a concrete smartphone-based crash report auto-generation and analysis framework as a use case. Despite the potential benefits, challenges related to data privacy, data quality, and model bias must be considered. Overall, the use of LLM in intelligent transport systems holds promise for more efficient, intelligent, and sustainable transportation systems that further improve daily life around the world.","created":"2023-03-06","meta":{"link":"http://arxiv.org/abs/2303.05382v2","tag":"prompt-eng"}}
{"title":"Perspectives on the Social Impacts of Reinforcement Learning with Human Feedback","abstract":"Is it possible for machines to think like humans? And if it is, how should we go about teaching them to do so? As early as 1950, Alan Turing stated that we ought to teach machines in the way of teaching a child. Reinforcement learning with human feedback (RLHF) has emerged as a strong candidate toward allowing agents to learn from human feedback in a naturalistic manner. RLHF is distinct from traditional reinforcement learning as it provides feedback from a human teacher in addition to a reward signal. It has been catapulted into public view by multiple high-profile AI applications, including OpenAI's ChatGPT, DeepMind's Sparrow, and Anthropic's Claude. These highly capable chatbots are already overturning our understanding of how AI interacts with humanity. The wide applicability and burgeoning success of RLHF strongly motivate the need to evaluate its social impacts. In light of recent developments, this paper considers an important question: can RLHF be developed and used without negatively affecting human societies? Our objectives are threefold: to provide a systematic study of the social effects of RLHF; to identify key social and ethical issues of RLHF; and to discuss social impacts for stakeholders. Although text-based applications of RLHF have received much attention, it is crucial to consider when evaluating its social implications the diverse range of areas to which it may be deployed. We describe seven primary ways in which RLHF-based technologies will affect society by positively transforming human experiences with AI. This paper ultimately proposes that RLHF has potential to net positively impact areas of misinformation, AI value-alignment, bias, AI access, cross-cultural dialogue, industry, and workforce. As RLHF raises concerns that echo those of existing AI technologies, it will be important for all to be aware and intentional in the adoption of RLHF.","created":"2023-03-06","meta":{"link":"http://arxiv.org/abs/2303.02891v1","tag":"prompt-eng"}}
{"title":"Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT","abstract":"ChatGPT has shown the potential of emerging general artificial intelligence capabilities, as it has demonstrated competent performance across many natural language processing tasks. In this work, we evaluate the capabilities of ChatGPT to perform text classification on three affective computing problems, namely, big-five personality prediction, sentiment analysis, and suicide tendency detection. We utilise three baselines, a robust language model (RoBERTa-base), a legacy word model with pretrained embeddings (Word2Vec), and a simple bag-of-words baseline (BoW). Results show that the RoBERTa trained for a specific downstream task generally has a superior performance. On the other hand, ChatGPT provides decent results, and is relatively comparable to the Word2Vec and BoW baselines. ChatGPT further shows robustness against noisy data, where Word2Vec models achieve worse results due to noise. Results indicate that ChatGPT is a good generalist model that is capable of achieving good results across various problems without any specialised training, however, it is not as good as a specialised model for a downstream task.","created":"2023-03-03","meta":{"link":"http://arxiv.org/abs/2303.03186v1","tag":"prompt-eng"}}
{"title":"Ask and You Shall Receive (a Graph Drawing): Testing ChatGPT's Potential to Apply Graph Layout Algorithms","abstract":"Large language models (LLMs) have recently taken the world by storm. They can generate coherent text, hold meaningful conversations, and be taught concepts and basic sets of instructions - such as the steps of an algorithm. In this context, we are interested in exploring the application of LLMs to graph drawing algorithms by performing experiments on ChatGPT. These algorithms are used to improve the readability of graph visualizations. The probabilistic nature of LLMs presents challenges to implementing algorithms correctly, but we believe that LLMs' ability to learn from vast amounts of data and apply complex operations may lead to interesting graph drawing results. For example, we could enable users with limited coding backgrounds to use simple natural language to create effective graph visualizations. Natural language specification would make data visualization more accessible and user-friendly for a wider range of users. Exploring LLMs' capabilities for graph drawing can also help us better understand how to formulate complex algorithms for LLMs; a type of knowledge that could transfer to other areas of computer science. Overall, our goal is to shed light on the exciting possibilities of using LLMs for graph drawing while providing a balanced assessment of the challenges and opportunities they present. A free copy of this paper with all supplemental materials required to reproduce our results is available on https://osf.io/n5rxd/?view_only=f09cbc2621f44074810b7d843f1e12f9","created":"2023-03-03","meta":{"link":"http://arxiv.org/abs/2303.08819v1","tag":"prompt-eng"}}
{"title":"UZH_CLyp at SemEval-2023 Task 9: Head-First Fine-Tuning and ChatGPT Data Generation for Cross-Lingual Learning in Tweet Intimacy Prediction","abstract":"This paper describes the submission of UZH_CLyp for the SemEval 2023 Task 9 \"Multilingual Tweet Intimacy Analysis\". We achieved second-best results in all 10 languages according to the official Pearson's correlation regression evaluation measure. Our cross-lingual transfer learning approach explores the benefits of using a Head-First Fine-Tuning method (HeFiT) that first updates only the regression head parameters and then also updates the pre-trained transformer encoder parameters at a reduced learning rate. Additionally, we study the impact of using a small set of automatically generated examples (in our case, from ChatGPT) for low-resource settings where no human-labeled data is available. Our study shows that HeFiT stabilizes training and consistently improves results for pre-trained models that lack domain adaptation to tweets. Our study also shows a noticeable performance increase in cross-lingual learning when synthetic data is used, confirming the usefulness of current text generation systems to improve zero-shot baseline results. Finally, we examine how possible inconsistencies in the annotated data contribute to cross-lingual interference issues.","created":"2023-03-02","meta":{"link":"http://arxiv.org/abs/2303.01194v1","tag":"prompt-eng"}}
{"title":"How will Language Modelers like ChatGPT Affect Occupations and Industries?","abstract":"Recent dramatic increases in AI language modeling capabilities has led to many questions about the effect of these technologies on the economy. In this paper we present a methodology to systematically assess the extent to which occupations, industries and geographies are exposed to advances in AI language modeling capabilities. We find that the top occupations exposed to language modeling include telemarketers and a variety of post-secondary teachers such as English language and literature, foreign language and literature, and history teachers. We find the top industries exposed to advances in language modeling are legal services and securities, commodities, and investments. We also find a positive correlation between wages and exposure to AI language modeling.","created":"2023-03-02","meta":{"link":"http://arxiv.org/abs/2303.01157v2","tag":"prompt-eng"}}
{"title":"AI and the FCI: Can ChatGPT Project an Understanding of Introductory Physics?","abstract":"ChatGPT is a groundbreaking ``chatbot\"--an AI interface built on a large language model that was trained on an enormous corpus of human text to emulate human conversation. Beyond its ability to converse in a plausible way, it has attracted attention for its ability to competently answer questions from the bar exam and from MBA coursework, and to provide useful assistance in writing computer code. These apparent abilities have prompted discussion of ChatGPT as both a threat to the integrity of higher education and conversely as a powerful teaching tool. In this work we present a preliminary analysis of how two versions of ChatGPT (ChatGPT3.5 and ChatGPT4) fare in the field of first-semester university physics, using a modified version of the Force Concept Inventory (FCI) to assess whether it can give correct responses to conceptual physics questions about kinematics and Newtonian dynamics. We demonstrate that, by some measures, ChatGPT3.5 can match or exceed the median performance of a university student who has completed one semester of college physics, though its performance is notably uneven and the results are nuanced. By these same measures, we find that ChatGPT4's performance is approaching the point of being indistinguishable from that of an expert physicist when it comes to introductory mechanics topics. After the completion of our work we became aware of Ref [1], which preceded us to publication and which completes an extensive analysis of the abilities of ChatGPT3.5 in a physics class, including a different modified version of the FCI. We view this work as confirming that portion of their results, and extending the analysis to ChatGPT4, which shows rapid and notable improvement in most, but not all respects.","created":"2023-03-02","meta":{"link":"http://arxiv.org/abs/2303.01067v2","tag":"prompt-eng"}}
{"title":"Succinct Representations for Concepts","abstract":"Foundation models like chatGPT have demonstrated remarkable performance on various tasks. However, for many questions, they may produce false answers that look accurate. How do we train the model to precisely understand the concepts? In this paper, we introduce succinct representations of concepts based on category theory. Such representation yields concept-wise invariance properties under various tasks, resulting a new learning algorithm that can provably and accurately learn complex concepts or fix misconceptions. Moreover, by recursively expanding the succinct representations, one can generate a hierarchical decomposition, and manually verify the concept by individually examining each part inside the decomposition.","created":"2023-03-01","meta":{"link":"http://arxiv.org/abs/2303.00446v1","tag":"prompt-eng"}}
{"title":"Can ChatGPT Assess Human Personalities? A General Evaluation Framework","abstract":"Large Language Models (LLMs) especially ChatGPT have produced impressive results in various areas, but their potential human-like psychology is still largely unexplored. Existing works study the virtual personalities of LLMs but rarely explore the possibility of analyzing human personalities via LLMs. This paper presents a generic evaluation framework for LLMs to assess human personalities based on Myers Briggs Type Indicator (MBTI) tests. Specifically, we first devise unbiased prompts by randomly permuting options in MBTI questions and adopt the average testing result to encourage more impartial answer generation. Then, we propose to replace the subject in question statements to enable flexible queries and assessments on different subjects from LLMs. Finally, we re-formulate the question instructions in a manner of correctness evaluation to facilitate LLMs to generate clearer responses. The proposed framework enables LLMs to flexibly assess personalities of different groups of people. We further propose three evaluation metrics to measure the consistency, robustness, and fairness of assessment results from state-of-the-art LLMs including ChatGPT and InstructGPT. Our experiments reveal ChatGPT's ability to assess human personalities, and the average results demonstrate that it can achieve more consistent and fairer assessments in spite of lower robustness against prompt biases compared with InstructGPT.","created":"2023-03-01","meta":{"link":"http://arxiv.org/abs/2303.01248v2","tag":"prompt-eng"}}
{"title":"Large Language Models Are State-of-the-Art Evaluators of Translation Quality","abstract":"We describe GEMBA, a GPT-based metric for assessment of translation quality, which works both with a reference translation and without. In our evaluation, we focus on zero-shot prompting, comparing four prompt variants in two modes, based on the availability of the reference. We investigate seven versions of GPT models, including ChatGPT. We show that our method for translation quality assessment only works with GPT 3.5 and larger models. Comparing to results from WMT22's Metrics shared task, our method achieves state-of-the-art accuracy in both modes when compared to MQM-based human labels. Our results are valid on the system level for all three WMT22 Metrics shared task language pairs, namely English into German, English into Russian, and Chinese into English. This provides a first glimpse into the usefulness of pre-trained, generative large language models for quality assessment of translations. We publicly release all our code and prompt templates used for the experiments described in this work, as well as all corresponding scoring results, to allow for external validation and reproducibility.","created":"2023-02-28","meta":{"link":"http://arxiv.org/abs/2302.14520v1","tag":"prompt-eng"}}
{"title":"Zero-Shot Cross-Lingual Summarization via Large Language Models","abstract":"Given a document in a source language, cross-lingual summarization (CLS) aims to generate a summary in a different target language. Recently, the emergence of Large Language Models (LLMs), such as GPT-3.5, ChatGPT and GPT-4, has attracted wide attention from the computational linguistics community. However, it is not yet known the performance of LLMs on CLS. In this report, we empirically use various prompts to guide LLMs to perform zero-shot CLS from different paradigms (i.e., end-to-end and pipeline), and provide a preliminary evaluation on the generated summaries. We find that ChatGPT and GPT-4 originally prefer to produce lengthy summaries with detailed information. These two LLMs can further balance informativeness and conciseness with the help of an interactive prompt, significantly improving their CLS performance. Experimental results on three widely-used CLS datasets show that GPT-4 achieves state-of-the-art zero-shot CLS performance, and performs competitively compared with the fine-tuned mBART-50. Moreover, we also find some multi-lingual and bilingual LLMs (i.e., BLOOMZ, ChatGLM-6B, Vicuna-13B and ChatYuan) have limited zero-shot CLS ability. Due to the composite nature of CLS, which requires models to perform summarization and translation simultaneously, accomplishing this task in a zero-shot manner is even a challenge for LLMs. Therefore, we sincerely hope and recommend future LLM research could use CLS as a testbed.","created":"2023-02-28","meta":{"link":"http://arxiv.org/abs/2302.14229v2","tag":"prompt-eng"}}
{"title":"Let's have a chat! A Conversation with ChatGPT: Technology, Applications, and Limitations","abstract":"The emergence of an AI-powered chatbot that can generate human-like sentences and write coherent essays has caught the world's attention. This paper discusses the historical overview of chatbots and the technology behind Chat Generative Pre-trained Transformer, better known as ChatGPT. Moreover, potential applications of ChatGPT in various domains, including healthcare, education, and research, are highlighted. Despite promising results, there are several privacy and ethical concerns surrounding ChatGPT. In addition, we highlight some of the important limitations of the current version of ChatGPT. We also ask ChatGPT to provide its point of view and present its responses to several questions we attempt to answer.","created":"2023-02-27","meta":{"link":"http://arxiv.org/abs/2302.13817v2","tag":"prompt-eng"}}
{"title":"Towards Human-Bot Collaborative Software Architecting with ChatGPT","abstract":"Architecting software-intensive systems can be a complex process. It deals with the daunting tasks of unifying stakeholders' perspectives, designers' intellect, tool-based automation, pattern-driven reuse, and so on, to sketch a blueprint that guides software implementation and evaluation. Despite its benefits, architecture-centric software engineering (ACSE) inherits a multitude of challenges. ACSE challenges could stem from a lack of standardized processes, socio-technical limitations, and scarcity of human expertise etc. that can impede the development of existing and emergent classes of software (e.g., IoTs, blockchain, quantum systems). Software Development Bots (DevBots) trained on large language models can help synergise architects' knowledge with artificially intelligent decision support to enable rapid architecting in a human-bot collaborative ACSE. An emerging solution to enable this collaboration is ChatGPT, a disruptive technology not primarily introduced for software engineering, but is capable of articulating and refining architectural artifacts based on natural language processing. We detail a case study that involves collaboration between a novice software architect and ChatGPT for architectural analysis, synthesis, and evaluation of a services-driven software application. Preliminary results indicate that ChatGPT can mimic an architect's role to support and often lead ACSE, however; it requires human oversight and decision support for collaborative architecting. Future research focuses on harnessing empirical evidence about architects' productivity and exploring socio-technical aspects of architecting with ChatGPT to tackle emerging and futuristic challenges of ACSE.","created":"2023-02-26","meta":{"link":"http://arxiv.org/abs/2302.14600v1","tag":"prompt-eng"}}
{"title":"Fast Attention Requires Bounded Entries","abstract":"In modern machine learning, inner product attention computation is a fundamental task for training large language models such as Transformer, GPT-1, BERT, GPT-2, GPT-3 and ChatGPT. Formally, in this problem, one is given as input three matrices $Q, K, V \\in [-B,B]^{n \\times d}$, and the goal is to construct the matrix $\\mathrm{Att}(Q,K,V) := \\mathrm{diag}(A {\\bf 1}_n)^{-1} A V \\in \\mathbb{R}^{n \\times d}$, where $A = \\exp(QK^\\top/d)$ is the `attention matrix', and $\\exp$ is applied entry-wise. Straightforward methods for this problem explicitly compute the $n \\times n$ attention matrix $A$, and hence require time $\\Omega(n^2)$ even when $d = n^{o(1)}$ is small.   In this paper, we investigate whether faster algorithms are possible by implicitly making use of the matrix $A$. We present two results, showing that there is a sharp transition at $B = \\Theta(\\sqrt{\\log n})$.   $\\bullet$ If $d = O(\\log n)$ and $B = o(\\sqrt{\\log n})$, there is an $n^{1+o(1)}$ time algorithm to approximate $\\mathrm{Att}(Q,K,V)$ up to $1/\\mathrm{poly}(n)$ additive error.   $\\bullet$ If $d = O(\\log n)$ and $B = \\Theta (\\sqrt{\\log n})$, assuming the Strong Exponential Time Hypothesis from fine-grained complexity theory, it is impossible to approximate $\\mathrm{Att}(Q,K,V)$ up to $1/\\mathrm{poly}(n)$ additive error in truly subquadratic time $n^{2 - \\Omega(1)}$.   This gives a theoretical explanation for the phenomenon observed in practice that attention computation is much more efficient when the input matrices have smaller entries.","created":"2023-02-26","meta":{"link":"http://arxiv.org/abs/2302.13214v1","tag":"prompt-eng"}}
{"title":"A Human-Centered Safe Robot Reinforcement Learning Framework with Interactive Behaviors","abstract":"Deployment of reinforcement learning algorithms for robotics applications in the real world requires ensuring the safety of the robot and its environment. Safe robot reinforcement learning (SRRL) is a crucial step towards achieving human-robot coexistence. In this paper, we envision a human-centered SRRL framework consisting of three stages: safe exploration, safety value alignment, and safe collaboration. We examine the research gaps in these areas and propose to leverage interactive behaviors for SRRL. Interactive behaviors enable bi-directional information transfer between humans and robots, such as conversational robot ChatGPT. We argue that interactive behaviors need further attention from the SRRL community. We discuss four open challenges related to the robustness, efficiency, transparency, and adaptability of SRRL with interactive behaviors.","created":"2023-02-25","meta":{"link":"http://arxiv.org/abs/2302.13137v2","tag":"prompt-eng"}}
{"title":"AugGPT: Leveraging ChatGPT for Text Data Augmentation","abstract":"Text data augmentation is an effective strategy for overcoming the challenge of limited sample sizes in many natural language processing (NLP) tasks. This challenge is especially prominent in the few-shot learning scenario, where the data in the target domain is generally much scarcer and of lowered quality. A natural and widely-used strategy to mitigate such challenges is to perform data augmentation to better capture the data invariance and increase the sample size. However, current text data augmentation methods either can't ensure the correct labeling of the generated data (lacking faithfulness) or can't ensure sufficient diversity in the generated data (lacking compactness), or both. Inspired by the recent success of large language models, especially the development of ChatGPT, which demonstrated improved language comprehension abilities, in this work, we propose a text data augmentation approach based on ChatGPT (named AugGPT). AugGPT rephrases each sentence in the training samples into multiple conceptually similar but semantically different samples. The augmented samples can then be used in downstream model training. Experiment results on few-shot learning text classification tasks show the superior performance of the proposed AugGPT approach over state-of-the-art text data augmentation methods in terms of testing accuracy and distribution of the augmented samples.","created":"2023-02-25","meta":{"link":"http://arxiv.org/abs/2302.13007v3","tag":"prompt-eng"}}
{"title":"Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback","abstract":"Large language models (LLMs), such as ChatGPT, are able to generate human-like, fluent responses for many downstream tasks, e.g., task-oriented dialog and question answering. However, applying LLMs to real-world, mission-critical applications remains challenging mainly due to their tendency to generate hallucinations and their inability to use external knowledge. This paper proposes a LLM-Augmenter system, which augments a black-box LLM with a set of plug-and-play modules. Our system makes the LLM generate responses grounded in external knowledge, e.g., stored in task-specific databases. It also iteratively revises LLM prompts to improve model responses using feedback generated by utility functions, e.g., the factuality score of a LLM-generated response. The effectiveness of LLM-Augmenter is empirically validated on two types of scenarios, task-oriented dialog and open-domain question answering. LLM-Augmenter significantly reduces ChatGPT's hallucinations without sacrificing the fluency and informativeness of its responses. We make the source code and models publicly available.","created":"2023-02-24","meta":{"link":"http://arxiv.org/abs/2302.12813v3","tag":"prompt-eng"}}
{"title":"Dr ChatGPT, tell me what I want to hear: How prompt knowledge impacts health answer correctness","abstract":"Generative pre-trained language models (GPLMs) like ChatGPT encode in the model's parameters knowledge the models observe during the pre-training phase. This knowledge is then used at inference to address the task specified by the user in their prompt. For example, for the question-answering task, the GPLMs leverage the knowledge and linguistic patterns learned at training to produce an answer to a user question. Aside from the knowledge encoded in the model itself, answers produced by GPLMs can also leverage knowledge provided in the prompts. For example, a GPLM can be integrated into a retrieve-then-generate paradigm where a search engine is used to retrieve documents relevant to the question; the content of the documents is then transferred to the GPLM via the prompt. In this paper we study the differences in answer correctness generated by ChatGPT when leveraging the model's knowledge alone vs. in combination with the prompt knowledge. We study this in the context of consumers seeking health advice from the model. Aside from measuring the effectiveness of ChatGPT in this context, we show that the knowledge passed in the prompt can overturn the knowledge encoded in the model and this is, in our experiments, to the detriment of answer correctness. This work has important implications for the development of more robust and transparent question-answering systems based on generative pre-trained language models.","created":"2023-02-23","meta":{"link":"http://arxiv.org/abs/2302.13793v1","tag":"prompt-eng"}}
{"title":"Talking Abortion (Mis)information with ChatGPT on TikTok","abstract":"In this study, we tested users' perception of accuracy and engagement with TikTok videos in which ChatGPT responded to prompts about \"at-home\" abortion remedies. The chatbot's responses, though somewhat vague and confusing, nonetheless recommended consulting with health professionals before attempting an \"at-home\" abortion. We used ChatGPT to create two TikTok video variants - one where users can see ChatGPT explicitly typing back a response, and one where the text response is presented without any notion to the chatbot. We randomly exposed 100 participants to each variant and found that the group of participants unaware of ChatGPT's text synthetization was more inclined to believe the responses were misinformation. Under the same impression, TikTok itself attached misinformation warning labels (\"Get the facts about abortion\") to all videos after we collected our initial results. We then decided to test the videos again with another set of 50 participants and found that the labels did not affect the perceptions of abortion misinformation except in the case where ChatGPT explicitly responded to a prompt for a lyrical output. We also found that more than 60% of the participants expressed negative or hesitant opinions about chatbots as sources of credible health information.","created":"2023-02-23","meta":{"link":"http://arxiv.org/abs/2303.13524v1","tag":"prompt-eng"}}
{"title":"An Independent Evaluation of ChatGPT on Mathematical Word Problems (MWP)","abstract":"We study the performance of a commercially available large language model (LLM) known as ChatGPT on math word problems (MWPs) from the dataset DRAW-1K. To our knowledge, this is the first independent evaluation of ChatGPT. We found that ChatGPT's performance changes dramatically based on the requirement to show its work, failing 20% of the time when it provides work compared with 84% when it does not. Further several factors about MWPs relating to the number of unknowns and number of operations that lead to a higher probability of failure when compared with the prior, specifically noting (across all experiments) that the probability of failure increases linearly with the number of addition and subtraction operations. We also have released the dataset of ChatGPT's responses to the MWPs to support further work on the characterization of LLM performance and present baseline machine learning models to predict if ChatGPT can correctly answer an MWP. We have released a dataset comprised of ChatGPT's responses to support further research in this area.","created":"2023-02-23","meta":{"link":"http://arxiv.org/abs/2302.13814v2","tag":"prompt-eng"}}
{"title":"On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective","abstract":"ChatGPT is a recent chatbot service released by OpenAI and is receiving increasing attention over the past few months. While evaluations of various aspects of ChatGPT have been done, its robustness, i.e., the performance to unexpected inputs, is still unclear to the public. Robustness is of particular concern in responsible AI, especially for safety-critical applications. In this paper, we conduct a thorough evaluation of the robustness of ChatGPT from the adversarial and out-of-distribution (OOD) perspective. To do so, we employ the AdvGLUE and ANLI benchmarks to assess adversarial robustness and the Flipkart review and DDXPlus medical diagnosis datasets for OOD evaluation. We select several popular foundation models as baselines. Results show that ChatGPT shows consistent advantages on most adversarial and OOD classification and translation tasks. However, the absolute performance is far from perfection, which suggests that adversarial and OOD robustness remains a significant threat to foundation models. Moreover, ChatGPT shows astounding performance in understanding dialogue-related texts and we find that it tends to provide informal suggestions for medical tasks instead of definitive answers. Finally, we present in-depth discussions of possible research directions.","created":"2023-02-22","meta":{"link":"http://arxiv.org/abs/2302.12095v4","tag":"prompt-eng"}}
{"title":"ChatGPT: Jack of all trades, master of none","abstract":"OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and revolutionized the approach in artificial intelligence to human-model interaction. The first contact with the chatbot reveals its ability to provide detailed and precise answers in various areas. There are several publications on ChatGPT evaluation, testing its effectiveness on well-known natural language processing (NLP) tasks. However, the existing studies are mostly non-automated and tested on a very limited scale. In this work, we examined ChatGPT's capabilities on 25 diverse analytical NLP tasks, most of them subjective even to humans, such as sentiment analysis, emotion recognition, offensiveness and stance detection, natural language inference, word sense disambiguation, linguistic acceptability and question answering. We automated ChatGPT's querying process and analyzed more than 38k responses. Our comparison of its results with available State-of-the-Art (SOTA) solutions showed that the average loss in quality of the ChatGPT model was about 25% for zero-shot and few-shot evaluation. We showed that the more difficult the task (lower SOTA performance), the higher the ChatGPT loss. It especially refers to pragmatic NLP problems like emotion recognition. We also tested the ability of personalizing ChatGPT responses for selected subjective tasks via Random Contextual Few-Shot Personalization, and we obtained significantly better user-based predictions. Additional qualitative analysis revealed a ChatGPT bias, most likely due to the rules imposed on human trainers by OpenAI. Our results provide the basis for a fundamental discussion of whether the high quality of recent predictive NLP models can indicate a tool's usefulness to society and how the learning and validation procedures for such systems should be established.","created":"2023-02-21","meta":{"link":"http://arxiv.org/abs/2302.10724v1","tag":"prompt-eng"}}
{"title":"A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT","abstract":"Prompt engineering is an increasingly important skill set needed to converse effectively with large language models (LLMs), such as ChatGPT. Prompts are instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated output. Prompts are also a form of programming that can customize the outputs and interactions with an LLM. This paper describes a catalog of prompt engineering techniques presented in pattern form that have been applied to solve common problems when conversing with LLMs. Prompt patterns are a knowledge transfer method analogous to software patterns since they provide reusable solutions to common problems faced in a particular context, i.e., output generation and interaction when working with LLMs. This paper provides the following contributions to research on prompt engineering that apply LLMs to automate software development tasks. First, it provides a framework for documenting patterns for structuring prompts to solve a range of problems so that they can be adapted to different domains. Second, it presents a catalog of patterns that have been applied successfully to improve the outputs of LLM conversations. Third, it explains how prompts can be built from multiple patterns and illustrates prompt patterns that benefit from combination with other prompt patterns.","created":"2023-02-21","meta":{"link":"http://arxiv.org/abs/2302.11382v1","tag":"prompt-eng"}}
{"title":"ChatGPT: A Meta-Analysis after 2.5 Months","abstract":"ChatGPT, a chatbot developed by OpenAI, has gained widespread popularity and media attention since its release in November 2022. However, little hard evidence is available regarding its perception in various sources. In this paper, we analyze over 300,000 tweets and more than 150 scientific papers to investigate how ChatGPT is perceived and discussed. Our findings show that ChatGPT is generally viewed as of high quality, with positive sentiment and emotions of joy dominating in social media. Its perception has slightly decreased since its debut, however, with joy decreasing and (negative) surprise on the rise, and it is perceived more negatively in languages other than English. In recent scientific papers, ChatGPT is characterized as a great opportunity across various fields including the medical domain, but also as a threat concerning ethics and receives mixed assessments for education. Our comprehensive meta-analysis of ChatGPT's current perception after 2.5 months since its release can contribute to shaping the public debate and informing its future development. We make our data available.","created":"2023-02-20","meta":{"link":"http://arxiv.org/abs/2302.13795v1","tag":"prompt-eng"}}
{"title":"Zero-Shot Information Extraction via Chatting with ChatGPT","abstract":"Zero-shot information extraction (IE) aims to build IE systems from the unannotated text. It is challenging due to involving little human intervention. Challenging but worthwhile, zero-shot IE reduces the time and effort that data labeling takes. Recent efforts on large language models (LLMs, e.g., GPT-3, ChatGPT) show promising performance on zero-shot settings, thus inspiring us to explore prompt-based methods. In this work, we ask whether strong IE models can be constructed by directly prompting LLMs. Specifically, we transform the zero-shot IE task into a multi-turn question-answering problem with a two-stage framework (ChatIE). With the power of ChatGPT, we extensively evaluate our framework on three IE tasks: entity-relation triple extract, named entity recognition, and event extraction. Empirical results on six datasets across two languages show that ChatIE achieves impressive performance and even surpasses some full-shot models on several datasets (e.g., NYT11-HRL). We believe that our work could shed light on building IE models with limited resources.","created":"2023-02-20","meta":{"link":"http://arxiv.org/abs/2302.10205v1","tag":"prompt-eng"}}
{"title":"Triple birthday matches in the Senate: Lies, damned lies and chatGPT","abstract":"Our question is ``What is the probability that at least three members of the senate share the same birthday?'' Before the pandemic, I asked this question in several popular math talks I gave at universities across the country. Inspired by ChatGPT's abysmal failure to answer the question, I have recently come back to this problem and now have a more satisfactory answer, thanks in no small part to what I learned form a page of Wolfram's Math World, which I located by a Google search.","created":"2023-02-19","meta":{"link":"http://arxiv.org/abs/2302.09643v1","tag":"prompt-eng"}}
{"title":"Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT","abstract":"Recently, ChatGPT has attracted great attention, as it can generate fluent and high-quality responses to human inquiries. Several prior studies have shown that ChatGPT attains remarkable generation ability compared with existing models. However, the quantitative analysis of ChatGPT's understanding ability has been given little attention. In this report, we explore the understanding ability of ChatGPT by evaluating it on the most popular GLUE benchmark, and comparing it with 4 representative fine-tuned BERT-style models. We find that: 1) ChatGPT falls short in handling paraphrase and similarity tasks; 2) ChatGPT outperforms all BERT models on inference tasks by a large margin; 3) ChatGPT achieves comparable performance compared with BERT on sentiment analysis and question-answering tasks. Additionally, by combining some advanced prompting strategies, we show that the understanding ability of ChatGPT can be further improved.","created":"2023-02-19","meta":{"link":"http://arxiv.org/abs/2302.10198v2","tag":"prompt-eng"}}
{"title":"A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT","abstract":"Pretrained Foundation Models (PFMs) are regarded as the foundation for various downstream tasks with different data modalities. A PFM (e.g., BERT, ChatGPT, and GPT-4) is trained on large-scale data which provides a reasonable parameter initialization for a wide range of downstream applications. BERT learns bidirectional encoder representations from Transformers, which are trained on large datasets as contextual language models. Similarly, the generative pretrained transformer (GPT) method employs Transformers as the feature extractor and is trained using an autoregressive paradigm on large datasets. Recently, ChatGPT shows promising success on large language models, which applies an autoregressive language model with zero shot or few shot prompting. The remarkable achievements of PFM have brought significant breakthroughs to various fields of AI. Numerous studies have proposed different methods, raising the demand for an updated survey. This study provides a comprehensive review of recent research advancements, challenges, and opportunities for PFMs in text, image, graph, as well as other data modalities. The review covers the basic components and existing pretraining methods used in natural language processing, computer vision, and graph learning. Additionally, it explores advanced PFMs used for different data modalities and unified PFMs that consider data quality and quantity. The review also discusses research related to the fundamentals of PFMs, such as model efficiency and compression, security, and privacy. Finally, the study provides key implications, future research directions, challenges, and open problems in the field of PFMs. Overall, this survey aims to shed light on the research of the PFMs on scalability, security, logical reasoning ability, cross-domain learning ability, and the user-friendly interactive ability for artificial general intelligence.","created":"2023-02-18","meta":{"link":"http://arxiv.org/abs/2302.09419v2","tag":"prompt-eng"}}
{"title":"How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation","abstract":"Generative Pre-trained Transformer (GPT) models have shown remarkable capabilities for natural language generation, but their performance for machine translation has not been thoroughly investigated. In this paper, we present a comprehensive evaluation of GPT models for machine translation, covering various aspects such as quality of different GPT models in comparison with state-of-the-art research and commercial systems, effect of prompting strategies, robustness towards domain shifts and document-level translation. We experiment with eighteen different translation directions involving high and low resource languages, as well as non English-centric translations, and evaluate the performance of three GPT models: ChatGPT, GPT3.5 (text-davinci-003), and text-davinci-002. Our results show that GPT models achieve very competitive translation quality for high resource languages, while having limited capabilities for low resource languages. We also show that hybrid approaches, which combine GPT models with other translation systems, can further enhance the translation quality. We perform comprehensive analysis and human evaluation to further understand the characteristics of GPT translations. We hope that our paper provides valuable insights for researchers and practitioners in the field and helps to better understand the potential and limitations of GPT models for translation.","created":"2023-02-18","meta":{"link":"http://arxiv.org/abs/2302.09210v1","tag":"prompt-eng"}}
{"title":"Prompting Large Language Models With the Socratic Method","abstract":"This paper presents a systematic approach to using the Socratic method in developing prompt templates that effectively interact with large language models, including GPT-3. Various methods are examined, and those that yield precise answers and justifications while fostering creativity and imagination to enhance creative writing are identified. Techniques such as {\\em definition}, {\\em elenchus}, {\\em dialectic}, {\\em maieutics}, {\\em generalization}, and {\\em counterfactual reasoning} are discussed for their application in engineering prompt templates and their connections to inductive, deductive, and abductive reasoning. Through examples, the effectiveness of these dialogue and reasoning methods is demonstrated. An interesting observation is made that when the task's goal and user intent are conveyed to GPT-3 via ChatGPT before the start of a dialogue, the large language model seems to connect to the external context expressed in the intent and perform more effectively.","created":"2023-02-17","meta":{"link":"http://arxiv.org/abs/2303.08769v2","tag":"prompt-eng"}}
{"title":"Complex QA and language models hybrid architectures, Survey","abstract":"This paper reviews the state-of-the-art of language models architectures and strategies for \"complex\" question-answering (QA, CQA, CPS) with a focus on hybridization. Large Language Models (LLM) are good at leveraging public data on standard problems but once you want to tackle more specific complex questions or problems (e.g. How does the concept of personal freedom vary between different cultures ? What is the best mix of power generation methods to reduce climate change ?) you may need specific architecture, knowledge, skills, methods, sensitive data protection, explainability, human approval and versatile feedback... Recent projects like ChatGPT and GALACTICA have allowed non-specialists to grasp the great potential as well as the equally strong limitations of LLM in complex QA. In this paper, we start by reviewing required skills and evaluation techniques. We integrate findings from the robust community edited research papers BIG, BLOOM and HELM which open source, benchmark and analyze limits and challenges of LLM in terms of tasks complexity and strict evaluation on accuracy (e.g. fairness, robustness, toxicity, ...) as a baseline. We discuss some challenges associated with complex QA, including domain adaptation, decomposition and efficient multi-step QA, long form and non-factoid QA, safety and multi-sensitivity data protection, multimodal search, hallucinations, explainability and truthfulness, temporal reasoning. We analyze current solutions and promising research trends, using elements such as: hybrid LLM architectural patterns, training and prompting strategies, active human reinforcement learning supervised with AI, neuro-symbolic and structured knowledge grounding, program synthesis, iterated decomposition and others.","created":"2023-02-17","meta":{"link":"http://arxiv.org/abs/2302.09051v4","tag":"prompt-eng"}}
{"title":"Combining Generative Artificial Intelligence (AI) and the Internet: Heading towards Evolution or Degradation?","abstract":"In the span of a few months, generative Artificial Intelligence (AI) tools that can generate realistic images or text have taken the Internet by storm, making them one of the technologies with fastest adoption ever. Some of these generative AI tools such as DALL-E, MidJourney, or ChatGPT have gained wide public notoriety. Interestingly, these tools are possible because of the massive amount of data (text and images) available on the Internet. The tools are trained on massive data sets that are scraped from Internet sites. And now, these generative AI tools are creating massive amounts of new data that are being fed into the Internet. Therefore, future versions of generative AI tools will be trained with Internet data that is a mix of original and AI-generated data. As time goes on, a mixture of original data and data generated by different versions of AI tools will populate the Internet. This raises a few intriguing questions: how will future versions of generative AI tools behave when trained on a mixture of real and AI generated data? Will they evolve with the new data sets or degenerate? Will evolution introduce biases in subsequent generations of generative AI tools? In this document, we explore these questions and report some very initial simulation results using a simple image-generation AI tool. These results suggest that the quality of the generated images degrades as more AI-generated data is used for training thus suggesting that generative AI may degenerate. Although these results are preliminary and cannot be generalised without further study, they serve to illustrate the potential issues of the interaction between generative AI and the Internet.","created":"2023-02-17","meta":{"link":"http://arxiv.org/abs/2303.01255v1","tag":"prompt-eng"}}
{"title":"How Generative AI models such as ChatGPT can be (Mis)Used in SPC Practice, Education, and Research? An Exploratory Study","abstract":"Generative Artificial Intelligence (AI) models such as OpenAI's ChatGPT have the potential to revolutionize Statistical Process Control (SPC) practice, learning, and research. However, these tools are in the early stages of development and can be easily misused or misunderstood. In this paper, we give an overview of the development of Generative AI. Specifically, we explore ChatGPT's ability to provide code, explain basic concepts, and create knowledge related to SPC practice, learning, and research. By investigating responses to structured prompts, we highlight the benefits and limitations of the results. Our study indicates that the current version of ChatGPT performs well for structured tasks, such as translating code from one language to another and explaining well-known concepts but struggles with more nuanced tasks, such as explaining less widely known terms and creating code from scratch. We find that using new AI tools may help practitioners, educators, and researchers to be more efficient and productive. However, in their current stages of development, some results are misleading and wrong. Overall, the use of generative AI models in SPC must be properly validated and used in conjunction with other methods to ensure accurate results.","created":"2023-02-17","meta":{"link":"http://arxiv.org/abs/2302.10916v1","tag":"prompt-eng"}}
{"title":"AI Usage Cards: Responsibly Reporting AI-generated Content","abstract":"Given AI systems like ChatGPT can generate content that is indistinguishable from human-made work, the responsible use of this technology is a growing concern. Although understanding the benefits and harms of using AI systems requires more time, their rapid and indiscriminate adoption in practice is a reality. Currently, we lack a common framework and language to define and report responsible use of AI for content generation. Prior work proposed guidelines for using AI in specific scenarios (e.g., robotics or medicine) which are not transferable to conducting and reporting scientific research. Our work makes two contributions: First, we propose a three-dimensional model consisting of transparency, integrity, and accountability to \\textit{define} the responsible use of AI. Second, we introduce ``AI Usage Cards'', a standardized way to \\textit{report} the use of AI in scientific research. Our model and cards allow users to reflect on key principles of responsible AI usage. They also help the research community trace, compare, and question various forms of AI usage and support the development of accepted community norms. The proposed framework and reporting system aim to promote ethical and responsible use of AI in scientific research and provide a standardized approach for reporting AI usage across different research fields. We also provide a free service to easily generate AI Usage Cards for scientific work via a questionnaire and export them in various machine-readable formats for inclusion in different work products at \\url{https://ai-cards.org}.","created":"2023-02-16","meta":{"link":"http://arxiv.org/abs/2303.03886v1","tag":"prompt-eng"}}
{"title":"Exploring the Limits of ChatGPT for Query or Aspect-based Text Summarization","abstract":"Text summarization has been a crucial problem in natural language processing (NLP) for several decades. It aims to condense lengthy documents into shorter versions while retaining the most critical information. Various methods have been proposed for text summarization, including extractive and abstractive summarization. The emergence of large language models (LLMs) like GPT3 and ChatGPT has recently created significant interest in using these models for text summarization tasks. Recent studies \\cite{goyal2022news, zhang2023benchmarking} have shown that LLMs-generated news summaries are already on par with humans. However, the performance of LLMs for more practical applications like aspect or query-based summaries is underexplored. To fill this gap, we conducted an evaluation of ChatGPT's performance on four widely used benchmark datasets, encompassing diverse summaries from Reddit posts, news articles, dialogue meetings, and stories. Our experiments reveal that ChatGPT's performance is comparable to traditional fine-tuning methods in terms of Rouge scores. Moreover, we highlight some unique differences between ChatGPT-generated summaries and human references, providing valuable insights into the superpower of ChatGPT for diverse text summarization tasks. Our findings call for new directions in this area, and we plan to conduct further research to systematically examine the characteristics of ChatGPT-generated summaries through extensive human evaluation.","created":"2023-02-16","meta":{"link":"http://arxiv.org/abs/2302.08081v1","tag":"prompt-eng"}}
{"title":"NL2CMD: An Updated Workflow for Natural Language to Bash Commands Translation","abstract":"Translating natural language into Bash Commands is an emerging research field that has gained attention in recent years. Most efforts have focused on producing more accurate translation models. To the best of our knowledge, only two datasets are available, with one based on the other. Both datasets involve scraping through known data sources (through platforms like stack overflow, crowdsourcing, etc.) and hiring experts to validate and correct either the English text or Bash Commands. This paper provides two contributions to research on synthesizing Bash Commands from scratch. First, we describe a state-of-the-art translation model used to generate Bash Commands from the corresponding English text. Second, we introduce a new NL2CMD dataset that is automatically generated, involves minimal human intervention, and is over six times larger than prior datasets. Since the generation pipeline does not rely on existing Bash Commands, the distribution and types of commands can be custom adjusted. We evaluate the performance of ChatGPT on this task and discuss the potential of using it as a data generator. Our empirical results show how the scale and diversity of our dataset can offer unique opportunities for semantic parsing researchers.","created":"2023-02-15","meta":{"link":"http://arxiv.org/abs/2302.07845v2","tag":"prompt-eng"}}
{"title":"A Pilot Evaluation of ChatGPT and DALL-E 2 on Decision Making and Spatial Reasoning","abstract":"We conduct a pilot study selectively evaluating the cognitive abilities (decision making and spatial reasoning) of two recently released generative transformer models, ChatGPT and DALL-E 2. Input prompts were constructed following neutral a priori guidelines, rather than adversarial intent. Post hoc qualitative analysis of the outputs shows that DALL-E 2 is able to generate at least one correct image for each spatial reasoning prompt, but most images generated are incorrect (even though the model seems to have a clear understanding of the objects mentioned in the prompt). Similarly, in evaluating ChatGPT on the rationality axioms developed under the classical Von Neumann-Morgenstern utility theorem, we find that, although it demonstrates some level of rational decision-making, many of its decisions violate at least one of the axioms even under reasonable constructions of preferences, bets, and decision-making prompts. ChatGPT's outputs on such problems generally tended to be unpredictable: even as it made irrational decisions (or employed an incorrect reasoning process) for some simpler decision-making problems, it was able to draw correct conclusions for more complex bet structures. We briefly comment on the nuances and challenges involved in scaling up such a 'cognitive' evaluation or conducting it with a closed set of answer keys ('ground truth'), given that these models are inherently generative and open-ended in responding to prompts.","created":"2023-02-15","meta":{"link":"http://arxiv.org/abs/2302.09068v1","tag":"prompt-eng"}}
{"title":"Conversational AI-Powered Design: ChatGPT as Designer, User, and Product","abstract":"The recent advancements in Large Language Models (LLMs), particularly conversational LLMs like ChatGPT, have prompted changes in a range of fields, including design. This study aims to examine the capabilities of ChatGPT in a human-centered design process. To this end, a hypothetical design project was conducted, where ChatGPT was utilized to generate personas, simulate interviews with fictional users, create new design ideas, simulate usage scenarios and conversations between an imaginary prototype and fictional users, and lastly evaluate user experience. The results show that ChatGPT effectively performed the tasks assigned to it as a designer, user, or product, providing mostly appropriate responses. The study does, however, highlight some drawbacks such as forgotten information, partial responses, and a lack of output diversity. The paper explains the potential benefits and limitations of using conversational LLMs in design, discusses its implications, and suggests directions for future research in this rapidly evolving area.","created":"2023-02-15","meta":{"link":"http://arxiv.org/abs/2302.07406v1","tag":"prompt-eng"}}
{"title":"ChatCAD: Interactive Computer-Aided Diagnosis on Medical Image using Large Language Models","abstract":"Large language models (LLMs) have recently demonstrated their potential in clinical applications, providing valuable medical knowledge and advice. For example, a large dialog LLM like ChatGPT has successfully passed part of the US medical licensing exam. However, LLMs currently have difficulty processing images, making it challenging to interpret information from medical images, which are rich in information that supports clinical decisions. On the other hand, computer-aided diagnosis (CAD) networks for medical images have seen significant success in the medical field by using advanced deep-learning algorithms to support clinical decision-making. This paper presents a method for integrating LLMs into medical-image CAD networks. The proposed framework uses LLMs to enhance the output of multiple CAD networks, such as diagnosis networks, lesion segmentation networks, and report generation networks, by summarizing and reorganizing the information presented in natural language text format. The goal is to merge the strengths of LLMs' medical domain knowledge and logical reasoning with the vision understanding capability of existing medical-image CAD models to create a more user-friendly and understandable system for patients compared to conventional CAD systems. In the future, LLM's medical knowledge can be also used to improve the performance of vision-based medical-image CAD models.","created":"2023-02-14","meta":{"link":"http://arxiv.org/abs/2302.07257v1","tag":"prompt-eng"}}
{"title":"Learning gain differences between ChatGPT and human tutor generated algebra hints","abstract":"Large Language Models (LLMs), such as ChatGPT, are quickly advancing AI to the frontiers of practical consumer use and leading industries to re-evaluate how they allocate resources for content production. Authoring of open educational resources and hint content within adaptive tutoring systems is labor intensive. Should LLMs like ChatGPT produce educational content on par with human-authored content, the implications would be significant for further scaling of computer tutoring system approaches. In this paper, we conduct the first learning gain evaluation of ChatGPT by comparing the efficacy of its hints with hints authored by human tutors with 77 participants across two algebra topic areas, Elementary Algebra and Intermediate Algebra. We find that 70% of hints produced by ChatGPT passed our manual quality checks and that both human and ChatGPT conditions produced positive learning gains. However, gains were only statistically significant for human tutor created hints. Learning gains from human-created hints were substantially and statistically significantly higher than ChatGPT hints in both topic areas, though ChatGPT participants in the Intermediate Algebra experiment were near ceiling and not even with the control at pre-test. We discuss the limitations of our study and suggest several future directions for the field. Problem and hint content used in the experiment is provided for replicability.","created":"2023-02-14","meta":{"link":"http://arxiv.org/abs/2302.06871v1","tag":"prompt-eng"}}
{"title":"Linguistic ambiguity analysis in ChatGPT","abstract":"Linguistic ambiguity is and has always been one of the main challenges in Natural Language Processing (NLP) systems. Modern Transformer architectures like BERT, T5 or more recently InstructGPT have achieved some impressive improvements in many NLP fields, but there is still plenty of work to do. Motivated by the uproar caused by ChatGPT, in this paper we provide an introduction to linguistic ambiguity, its varieties and their relevance in modern NLP, and perform an extensive empiric analysis. ChatGPT strengths and weaknesses are revealed, as well as strategies to get the most of this model.","created":"2023-02-13","meta":{"link":"http://arxiv.org/abs/2302.06426v2","tag":"prompt-eng"}}
{"title":"Semantic Communications with Ordered Importance using ChatGPT","abstract":"This letter proposes a novel semantic communication scheme with ordered importance (SCOI) using the chat generative pre-trained transformer (ChatGPT). In the proposed SCOI scheme, ChatGPT plays the role of a consulting assistant. Given a message to be transmitted, the transmitter first queries ChatGPT to output the importance order of each word. According to the importance order, the transmitter then performs an unequal error protection transmission strategy to make the transmission of essential words more reliable. Unlike the existing semantic communication schemes, SCOI is compatible with existing source-channel separation designs and can be directly embedded into current communication systems. Our experimental results show that both the transmission bit error rate (BER) of important words and the semantic loss measured by ChatGPT are much lower than the existing communication schemes.","created":"2023-02-12","meta":{"link":"http://arxiv.org/abs/2302.07142v1","tag":"prompt-eng"}}
{"title":"Is ChatGPT better than Human Annotators? Potential and Limitations of ChatGPT in Explaining Implicit Hate Speech","abstract":"Recent studies have alarmed that many online hate speeches are implicit. With its subtle nature, the explainability of the detection of such hateful speech has been a challenging problem. In this work, we examine whether ChatGPT can be used for providing natural language explanations (NLEs) for implicit hateful speech detection. We design our prompt to elicit concise ChatGPT-generated NLEs and conduct user studies to evaluate their qualities by comparison with human-written NLEs. We discuss the potential and limitations of ChatGPT in the context of implicit hateful speech research.","created":"2023-02-11","meta":{"link":"http://arxiv.org/abs/2302.07736v2","tag":"prompt-eng"}}
{"title":"Scamming the Scammers: Using ChatGPT to Reply Mails for Wasting Time and Resources","abstract":"The use of Artificial Intelligence (AI) to support cybersecurity operations is now a consolidated practice, e.g., to detect malicious code or configure traffic filtering policies. The recent surge of AI, generative techniques and frameworks with efficient natural language processing capabilities dramatically magnifies the number of possible applications aimed at increasing the security of the Internet. Specifically, the ability of ChatGPT to produce textual contents while mimicking realistic human interactions can be used to mitigate the plague of emails containing scams. Therefore, this paper investigates the use of AI to engage scammers in automatized and pointless communications, with the goal of wasting both their time and resources. Preliminary results showcase that ChatGPT is able to decoy scammers, thus confirming that AI is an effective tool to counteract threats delivered via mail. In addition, we highlight the multitude of implications and open research questions to be addressed in the perspective of the ubiquitous adoption of AI.","created":"2023-02-10","meta":{"link":"http://arxiv.org/abs/2303.13521v1","tag":"prompt-eng"}}
{"title":"ChatGPT and Other Large Language Models as Evolutionary Engines for Online Interactive Collaborative Game Design","abstract":"Large language models (LLMs) have taken the scientific world by storm, changing the landscape of natural language processing and human-computer interaction. These powerful tools can answer complex questions and, surprisingly, perform challenging creative tasks (e.g., generate code and applications to solve problems, write stories, pieces of music, etc.). In this paper, we present a collaborative game design framework that combines interactive evolution and large language models to simulate the typical human design process. We use the former to exploit users' feedback for selecting the most promising ideas and large language models for a very complex creative task - the recombination and variation of ideas. In our framework, the process starts with a brief and a set of candidate designs, either generated using a language model or proposed by the users. Next, users collaborate on the design process by providing feedback to an interactive genetic algorithm that selects, recombines, and mutates the most promising designs. We evaluated our framework on three game design tasks with human designers who collaborated remotely.","created":"2023-02-09","meta":{"link":"http://arxiv.org/abs/2303.02155v2","tag":"prompt-eng"}}
{"title":"Will ChatGPT get you caught? Rethinking of Plagiarism Detection","abstract":"The rise of Artificial Intelligence (AI) technology and its impact on education has been a topic of growing concern in recent years. The new generation AI systems such as chatbots have become more accessible on the Internet and stronger in terms of capabilities. The use of chatbots, particularly ChatGPT, for generating academic essays at schools and colleges has sparked fears among scholars. This study aims to explore the originality of contents produced by one of the most popular AI chatbots, ChatGPT. To this end, two popular plagiarism detection tools were used to evaluate the originality of 50 essays generated by ChatGPT on various topics. Our results manifest that ChatGPT has a great potential to generate sophisticated text outputs without being well caught by the plagiarism check software. In other words, ChatGPT can create content on many topics with high originality as if they were written by someone. These findings align with the recent concerns about students using chatbots for an easy shortcut to success with minimal or no effort. Moreover, ChatGPT was asked to verify if the essays were generated by itself, as an additional measure of plagiarism check, and it showed superior performance compared to the traditional plagiarism-detection tools. The paper discusses the need for institutions to consider appropriate measures to mitigate potential plagiarism issues and advise on the ongoing debate surrounding the impact of AI technology on education. Further implications are discussed in the paper.","created":"2023-02-08","meta":{"link":"http://arxiv.org/abs/2302.04335v1","tag":"prompt-eng"}}
{"title":"Deep Machine Learning in Cosmology: Evolution or Revolution?","abstract":"Could Machine Learning (ML) make fundamental discoveries and tackle unsolved problems in Cosmology? Detailed observations of the present contents of the universe are consistent with the Cosmological Constant Lambda and Cold Dark Matter model, subject to some unresolved inconsistencies ('tensions') among observations of the Hubble Constant and the clumpiness factor. To understand these issues further, large surveys of billions of galaxies and other probes require new statistical approaches. In recent years the power of ML, and in particular 'Deep Learning', has been demonstrated for object classification, photometric redshifts, anomaly detection, enhanced simulations, and inference of cosmological parameters. It is argued that the more traditional 'shallow learning' (i.e. with pre-processing feature extraction) is actually quite deep, as it brings in human knowledge, while 'deep learning' might be perceived as a black box, unless supplemented by explainability tools. The 'killer applications' of ML for Cosmology are still to come. New ways to train the next generation of scientists for the Data Intensive Science challenges ahead are also discussed. Finally, the chatbot ChatGPT is challenged to address the question posed in this article's title.","created":"2023-02-08","meta":{"link":"http://arxiv.org/abs/2302.04324v1","tag":"prompt-eng"}}
{"title":"ChatGPT versus Traditional Question Answering for Knowledge Graphs: Current Status and Future Directions Towards Knowledge Graph Chatbots","abstract":"Conversational AI and Question-Answering systems (QASs) for knowledge graphs (KGs) are both emerging research areas: they empower users with natural language interfaces for extracting information easily and effectively. Conversational AI simulates conversations with humans; however, it is limited by the data captured in the training datasets. In contrast, QASs retrieve the most recent information from a KG by understanding and translating the natural language question into a formal query supported by the database engine.   In this paper, we present a comprehensive study of the characteristics of the existing alternatives towards combining both worlds into novel KG chatbots. Our framework compares two representative conversational models, ChatGPT and Galactica, against KGQAN, the current state-of-the-art QAS. We conduct a thorough evaluation using four real KGs across various application domains to identify the current limitations of each category of systems. Based on our findings, we propose open research opportunities to empower QASs with chatbot capabilities for KGs. All benchmarks and all raw results are available1 for further analysis.","created":"2023-02-08","meta":{"link":"http://arxiv.org/abs/2302.06466v1","tag":"prompt-eng"}}
{"title":"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity","abstract":"This paper proposes a framework for quantitatively evaluating interactive LLMs such as ChatGPT using publicly available data sets. We carry out an extensive technical evaluation of ChatGPT using 23 data sets covering 8 different common NLP application tasks. We evaluate the multitask, multilingual and multi-modal aspects of ChatGPT based on these data sets and a newly designed multimodal dataset. We find that ChatGPT outperforms LLMs with zero-shot learning on most tasks and even outperforms fine-tuned models on some tasks. We find that it is better at understanding non-Latin script languages than generating them. It is able to generate multimodal content from textual prompts, via an intermediate code generation step. Moreover, we find that ChatGPT is 63.41% accurate on average in 10 different reasoning categories under logical reasoning, non-textual reasoning, and commonsense reasoning, hence making it an unreliable reasoner. It is, for example, better at deductive than inductive reasoning. ChatGPT suffers from hallucination problems like other LLMs and it generates more extrinsic hallucinations from its parametric memory as it does not have access to an external knowledge base. Finally, the interactive feature of ChatGPT enables human collaboration with the underlying LLM to improve its performance, i.e, 8% ROUGE-1 on summarization and 2% ChrF++ on machine translation, in a multi-turn \"prompt engineering\" fashion. We also release codebase for evaluation set extraction.","created":"2023-02-08","meta":{"link":"http://arxiv.org/abs/2302.04023v2","tag":"prompt-eng"}}
{"title":"Is ChatGPT a General-Purpose Natural Language Processing Task Solver?","abstract":"Spurred by advancements in scale, large language models (LLMs) have demonstrated the ability to perform a variety of natural language processing (NLP) tasks zero-shot -- i.e., without adaptation on downstream data. Recently, the debut of ChatGPT has drawn a great deal of attention from the natural language processing (NLP) community due to the fact that it can generate high-quality responses to human input and self-correct previous mistakes based on subsequent conversations. However, it is not yet known whether ChatGPT can serve as a generalist model that can perform many NLP tasks zero-shot. In this work, we empirically analyze the zero-shot learning ability of ChatGPT by evaluating it on 20 popular NLP datasets covering 7 representative task categories. With extensive empirical studies, we demonstrate both the effectiveness and limitations of the current version of ChatGPT. We find that ChatGPT performs well on many tasks favoring reasoning capabilities (e.g., arithmetic reasoning) while it still faces challenges when solving specific tasks such as sequence tagging. We additionally provide in-depth analysis through qualitative case studies.","created":"2023-02-08","meta":{"link":"http://arxiv.org/abs/2302.06476v2","tag":"prompt-eng"}}
{"title":"Reliable Natural Language Understanding with Large Language Models and Answer Set Programming","abstract":"Humans understand language by extracting information (meaning) from sentences, combining it with existing commonsense knowledge, and then performing reasoning to draw conclusions. While large language models (LLMs) such as GPT-3 and ChatGPT are able to leverage patterns in the text to solve a variety of NLP tasks, they fall short in problems that require reasoning. They also cannot reliably explain the answers generated for a given question. In order to emulate humans better, we propose STAR, a framework that combines LLMs with Answer Set Programming (ASP). We show how LLMs can be used to effectively extract knowledge -- represented as predicates -- from language. Goal-directed ASP is then employed to reliably reason over this knowledge. We apply the STAR framework to three different NLU tasks requiring reasoning: qualitative reasoning, mathematical reasoning, and goal-directed conversation. Our experiments reveal that STAR is able to bridge the gap of reasoning in NLU tasks, leading to significant performance improvements, especially for smaller LLMs, i.e., LLMs with a smaller number of parameters. NLU applications developed using the STAR framework are also explainable: along with the predicates generated, a justification in the form of a proof tree can be produced for a given output.","created":"2023-02-07","meta":{"link":"http://arxiv.org/abs/2302.03780v2","tag":"prompt-eng"}}
{"title":"ChatGPT and Software Testing Education: Promises & Perils","abstract":"Over the past decade, predictive language modeling for code has proven to be a valuable tool for enabling new forms of automation for developers. More recently, we have seen the advent of general purpose \"large language models\", based on neural transformer architectures, that have been trained on massive datasets of human written text spanning code and natural language. However, despite the demonstrated representational power of such models, interacting with them has historically been constrained to specific task settings, limiting their general applicability. Many of these limitations were recently overcome with the introduction of ChatGPT, a language model created by OpenAI and trained to operate as a conversational agent, enabling it to answer questions and respond to a wide variety of commands from end users. The introduction of models, such as ChatGPT, has already spurred fervent discussion from educators, ranging from fear that students could use these AI tools to circumvent learning, to excitement about the new types of learning opportunities that they might unlock. However, given the nascent nature of these tools, we currently lack fundamental knowledge related to how well they perform in different educational settings, and the potential promise (or danger) that they might pose to traditional forms of instruction. As such, in this paper, we examine how well ChatGPT performs when tasked with answering common questions in a popular software testing curriculum. Our findings indicate that ChatGPT can provide correct or partially correct answers in 55.6% of cases, provide correct or partially correct explanations of answers in 53.0% of cases, and that prompting the tool in a shared question context leads to a marginally higher rate of correct responses. Based on these findings, we discuss the potential promises and perils related to the use of ChatGPT by students and instructors.","created":"2023-02-07","meta":{"link":"http://arxiv.org/abs/2302.03287v3","tag":"prompt-eng"}}
{"title":"Applying BERT and ChatGPT for Sentiment Analysis of Lyme Disease in Scientific Literature","abstract":"This chapter presents a practical guide for conducting Sentiment Analysis using Natural Language Processing (NLP) techniques in the domain of tick-borne disease text. The aim is to demonstrate the process of how the presence of bias in the discourse surrounding chronic manifestations of the disease can be evaluated. The goal is to use a dataset of 5643 abstracts collected from scientific journals on the topic of chronic Lyme disease to demonstrate using Python, the steps for conducting sentiment analysis using pre-trained language models and the process of validating the preliminary results using both interpretable machine learning tools, as well as a novel methodology of using emerging state-of-the-art large language models like ChatGPT. This serves as a useful resource for researchers and practitioners interested in using NLP techniques for sentiment analysis in the medical domain.","created":"2023-02-07","meta":{"link":"http://arxiv.org/abs/2302.06474v1","tag":"prompt-eng"}}
{"title":"A Categorical Archive of ChatGPT Failures","abstract":"Large language models have been demonstrated to be valuable in different fields. ChatGPT, developed by OpenAI, has been trained using massive amounts of data and simulates human conversation by comprehending context and generating appropriate responses. It has garnered significant attention due to its ability to effectively answer a broad range of human inquiries, with fluent and comprehensive answers surpassing prior public chatbots in both security and usefulness. However, a comprehensive analysis of ChatGPT's failures is lacking, which is the focus of this study. Eleven categories of failures, including reasoning, factual errors, math, coding, and bias, are presented and discussed. The risks, limitations, and societal implications of ChatGPT are also highlighted. The goal of this study is to assist researchers and developers in enhancing future language models and chatbots.","created":"2023-02-06","meta":{"link":"http://arxiv.org/abs/2302.03494v8","tag":"prompt-eng"}}
{"title":"Regulating ChatGPT and other Large Generative AI Models","abstract":"Large generative AI models (LGAIMs), such as ChatGPT or Stable Diffusion, are rapidly transforming the way we communicate, illustrate, and create. However, AI regulation, in the EU and beyond, has primarily focused on conventional AI models, not LGAIMs. This paper will situate these new generative models in the current debate on trustworthy AI regulation, and ask how the law can be tailored to their capabilities. After laying technical foundations, the legal part of the paper proceeds in four steps, covering (1) direct regulation, (2) data protection, (3) content moderation, and (4) policy proposals. It suggests a novel terminology to capture the AI value chain in LGAIM settings by differentiating between LGAIM developers, deployers, professional and non-professional users, as well as recipients of LGAIM output. We tailor regulatory duties to these different actors along the value chain and suggest four strategies to ensure that LGAIMs are trustworthy and deployed for the benefit of society at large. Rules in the AI Act and other direct regulation must match the specificities of pre-trained models. In particular, regulation should focus on concrete high-risk applications, and not the pre-trained model itself, and should include (i) obligations regarding transparency and (ii) risk management. Non-discrimination provisions (iii) may, however, apply to LGAIM developers. Lastly, (iv) the core of the DSA content moderation rules should be expanded to cover LGAIMs. This includes notice and action mechanisms, and trusted flaggers. In all areas, regulators and lawmakers need to act fast to keep track with the dynamics of ChatGPT et al.","created":"2023-02-05","meta":{"link":"http://arxiv.org/abs/2302.02337v6","tag":"prompt-eng"}}
{"title":"Chat2VIS: Generating Data Visualisations via Natural Language using ChatGPT, Codex and GPT-3 Large Language Models","abstract":"The field of data visualisation has long aimed to devise solutions for generating visualisations directly from natural language text. Research in Natural Language Interfaces (NLIs) has contributed towards the development of such techniques. However, the implementation of workable NLIs has always been challenging due to the inherent ambiguity of natural language, as well as in consequence of unclear and poorly written user queries which pose problems for existing language models in discerning user intent. Instead of pursuing the usual path of developing new iterations of language models, this study uniquely proposes leveraging the advancements in pre-trained large language models (LLMs) such as ChatGPT and GPT-3 to convert free-form natural language directly into code for appropriate visualisations. This paper presents a novel system, Chat2VIS, which takes advantage of the capabilities of LLMs and demonstrates how, with effective prompt engineering, the complex problem of language understanding can be solved more efficiently, resulting in simpler and more accurate end-to-end solutions than prior approaches. Chat2VIS shows that LLMs together with the proposed prompts offer a reliable approach to rendering visualisations from natural language queries, even when queries are highly misspecified and underspecified. This solution also presents a significant reduction in costs for the development of NLI systems, while attaining greater visualisation inference abilities compared to traditional NLP approaches that use hand-crafted grammar rules and tailored models. This study also presents how LLM prompts can be constructed in a way that preserves data security and privacy while being generalisable to different datasets. This work compares the performance of GPT-3, Codex and ChatGPT across a number of case studies and contrasts the performances with prior studies.","created":"2023-02-04","meta":{"link":"http://arxiv.org/abs/2302.02094v2","tag":"prompt-eng"}}
{"title":"Theory of Mind May Have Spontaneously Emerged in Large Language Models","abstract":"Theory of mind (ToM), or the ability to impute unobservable mental states to others, is central to human social interactions, communication, empathy, self-consciousness, and morality. We tested several language models using 40 classic false-belief tasks widely used to test ToM in humans. The models published before 2020 showed virtually no ability to solve ToM tasks. Yet, the first version of GPT-3 (\"davinci-001\"), published in May 2020, solved about 40% of false-belief tasks-performance comparable with 3.5-year-old children. Its second version (\"davinci-002\"; January 2022) solved 70% of false-belief tasks, performance comparable with six-year-olds. Its most recent version, GPT-3.5 (\"davinci-003\"; November 2022), solved 90% of false-belief tasks, at the level of seven-year-olds. GPT-4 published in March 2023 solved nearly all the tasks (95%). These findings suggest that ToM-like ability (thus far considered to be uniquely human) may have spontaneously emerged as a byproduct of language models' improving language skills.","created":"2023-02-04","meta":{"link":"http://arxiv.org/abs/2302.02083v3","tag":"prompt-eng"}}
{"title":"Exploring the Cognitive Dynamics of Artificial Intelligence in the Post-COVID-19 and Learning 3.0 Era: A Case Study of ChatGPT","abstract":"The emergence of artificial intelligence has incited a paradigm shift across the spectrum of human endeavors, with ChatGPT serving as a catalyst for the transformation of various established domains, including but not limited to education, journalism, security, and ethics. In the post-pandemic era, the widespread adoption of remote work has prompted the educational sector to reassess conventional pedagogical methods. This paper is to scrutinize the underlying psychological principles of ChatGPT, delve into the factors that captivate user attention, and implicate its ramifications on the future of learning. The ultimate objective of this study is to instigate a scholarly discourse on the interplay between technological advancements in education and the evolution of human learning patterns, raising the question of whether technology is driving human evolution or vice versa.","created":"2023-02-03","meta":{"link":"http://arxiv.org/abs/2302.04818v1","tag":"prompt-eng"}}
{"title":"Can ChatGPT Write a Good Boolean Query for Systematic Review Literature Search?","abstract":"Systematic reviews are comprehensive reviews of the literature for a highly focused research question. These reviews are often treated as the highest form of evidence in evidence-based medicine, and are the key strategy to answer research questions in the medical field. To create a high-quality systematic review, complex Boolean queries are often constructed to retrieve studies for the review topic. However, it often takes a long time for systematic review researchers to construct a high quality systematic review Boolean query, and often the resulting queries are far from effective. Poor queries may lead to biased or invalid reviews, because they missed to retrieve key evidence, or to extensive increase in review costs, because they retrieved too many irrelevant studies. Recent advances in Transformer-based generative models have shown great potential to effectively follow instructions from users and generate answers based on the instructions being made. In this paper, we investigate the effectiveness of the latest of such models, ChatGPT, in generating effective Boolean queries for systematic review literature search. Through a number of extensive experiments on standard test collections for the task, we find that ChatGPT is capable of generating queries that lead to high search precision, although trading-off this for recall. Overall, our study demonstrates the potential of ChatGPT in generating effective Boolean queries for systematic review literature search. The ability of ChatGPT to follow complex instructions and generate queries with high precision makes it a valuable tool for researchers conducting systematic reviews, particularly for rapid reviews where time is a constraint and often trading-off higher precision for lower recall is acceptable.","created":"2023-02-03","meta":{"link":"http://arxiv.org/abs/2302.03495v3","tag":"prompt-eng"}}
{"title":"Netizens, Academicians, and Information Professionals' Opinions About AI With Special Reference To ChatGPT","abstract":"This study aims to understand the perceptions and opinions of academicians towards ChatGPT-3 by collecting and analyzing social media comments, and a survey was conducted with library and information science professionals. The research uses a content analysis method and finds that while ChatGPT-3 can be a valuable tool for research and writing, it is not 100% accurate and should be cross-checked. The study also finds that while some academicians may not accept ChatGPT-3, most are starting to accept it. The study is beneficial for academicians, content developers, and librarians.","created":"2023-02-01","meta":{"link":"http://arxiv.org/abs/2302.07136v1","tag":"prompt-eng"}}
{"title":"Grading Conversational Responses Of Chatbots","abstract":"Chatbots have long been capable of answering basic questions and even responding to obscure prompts, but recently their improvements have been far more significant. Modern chatbots like Open AIs ChatGPT3 not only have the ability to answer basic questions but can write code and movie scripts and imitate well-known people. In this paper, we analyze ChatGPTs' responses to various questions from a dataset of queries from the popular Quora forum. We submitted sixty questions to ChatGPT and scored the answers based on three industry-standard metrics for grading machine translation: BLEU, METEOR, and ROUGE. These metrics allow us to compare the machine responses with the most upvoted human answer to the same question to assess ChatGPT's ability to submit a humanistic reply. The results showed that while the responses and translation abilities of ChatGPT are remarkable, they still fall short of what a typical human reaction would be.","created":"2023-02-01","meta":{"link":"http://arxiv.org/abs/2303.12038v1","tag":"prompt-eng"}}
{"title":"Mathematical Capabilities of ChatGPT","abstract":"We investigate the mathematical capabilities of ChatGPT by testing it on publicly available datasets, as well as hand-crafted ones, and measuring its performance against other models trained on a mathematical corpus, such as Minerva. We also test whether ChatGPT can be a useful assistant to professional mathematicians by emulating various use cases that come up in the daily professional activities of mathematicians (question answering, theorem searching). In contrast to formal mathematics, where large databases of formal proofs are available (e.g., the Lean Mathematical Library), current datasets of natural-language mathematics, used to benchmark language models, only cover elementary mathematics. We address this issue by introducing a new dataset: GHOSTS. It is the first natural-language dataset made and curated by working researchers in mathematics that (1) aims to cover graduate-level mathematics and (2) provides a holistic overview of the mathematical capabilities of language models. We benchmark ChatGPT on GHOSTS and evaluate performance against fine-grained criteria. We make this new dataset publicly available to assist a community-driven comparison of ChatGPT with (future) large language models in terms of advanced mathematical comprehension. We conclude that contrary to many positive reports in the media (a potential case of selection bias), ChatGPT's mathematical abilities are significantly below those of an average mathematics graduate student. Our results show that ChatGPT often understands the question but fails to provide correct solutions. Hence, if your goal is to use it to pass a university exam, you would be better off copying from your average peer!","created":"2023-01-31","meta":{"link":"http://arxiv.org/abs/2301.13867v1","tag":"prompt-eng"}}
{"title":"Numeracy from Literacy: Data Science as an Emergent Skill from Large Language Models","abstract":"Large language models (LLM) such as OpenAI's ChatGPT and GPT-3 offer unique testbeds for exploring the translation challenges of turning literacy into numeracy. Previous publicly-available transformer models from eighteen months prior and 1000 times smaller failed to provide basic arithmetic. The statistical analysis of four complex datasets described here combines arithmetic manipulations that cannot be memorized or encoded by simple rules. The work examines whether next-token prediction succeeds from sentence completion into the realm of actual numerical understanding. For example, the work highlights cases for descriptive statistics on in-memory datasets that the LLM initially loads from memory or generates randomly using python libraries. The resulting exploratory data analysis showcases the model's capabilities to group by or pivot categorical sums, infer feature importance, derive correlations, and predict unseen test cases using linear regression. To extend the model's testable range, the research deletes and appends random rows such that recall alone cannot explain emergent numeracy.","created":"2023-01-31","meta":{"link":"http://arxiv.org/abs/2301.13382v1","tag":"prompt-eng"}}
{"title":"Conversational Automated Program Repair","abstract":"Automated Program Repair (APR) can help developers automatically generate patches for bugs. Due to the impressive performance obtained using Large Pre-Trained Language Models (LLMs) on many code related tasks, researchers have started to directly use LLMs for APR. However, prior approaches simply repeatedly sample the LLM given the same constructed input/prompt created from the original buggy code, which not only leads to generating the same incorrect patches repeatedly but also miss the critical information in testcases. To address these limitations, we propose conversational APR, a new paradigm for program repair that alternates between patch generation and validation in a conversational manner. In conversational APR, we iteratively build the input to the model by combining previously generated patches with validation feedback. As such, we leverage the long-term context window of LLMs to not only avoid generating previously incorrect patches but also incorporate validation feedback to help the model understand the semantic meaning of the program under test. We evaluate 10 different LLM including the newly developed ChatGPT model to demonstrate the improvement of conversational APR over the prior LLM for APR approach.","created":"2023-01-30","meta":{"link":"http://arxiv.org/abs/2301.13246v1","tag":"prompt-eng"}}
{"title":"Exploring AI Ethics of ChatGPT: A Diagnostic Analysis","abstract":"Recent breakthroughs in natural language processing (NLP) have permitted the synthesis and comprehension of coherent text in an open-ended way, therefore translating the theoretical algorithms into practical applications. The large language-model (LLM) has significantly impacted businesses such as report summarization softwares and copywriters. Observations indicate, however, that LLMs may exhibit social prejudice and toxicity, posing ethical and societal dangers of consequences resulting from irresponsibility. Large-scale benchmarks for accountable LLMs should consequently be developed. Although several empirical investigations reveal the existence of a few ethical difficulties in advanced LLMs, there is no systematic examination and user study of the ethics of current LLMs use. To further educate future efforts on constructing ethical LLMs responsibly, we perform a qualitative research method on OpenAI's ChatGPT to better understand the practical features of ethical dangers in recent LLMs. We analyze ChatGPT comprehensively from four perspectives: 1) \\textit{Bias} 2) \\textit{Reliability} 3) \\textit{Robustness} 4) \\textit{Toxicity}. In accordance with our stated viewpoints, we empirically benchmark ChatGPT on multiple sample datasets. We find that a significant number of ethical risks cannot be addressed by existing benchmarks, and hence illustrate them via additional case studies. In addition, we examine the implications of our findings on the AI ethics of ChatGPT, as well as future problems and practical design considerations for LLMs. We believe that our findings may give light on future efforts to determine and mitigate the ethical hazards posed by machines in LLM applications.","created":"2023-01-30","meta":{"link":"http://arxiv.org/abs/2301.12867v3","tag":"prompt-eng"}}
{"title":"ChatGPT or Human? Detect and Explain. Explaining Decisions of Machine Learning Model for Detecting Short ChatGPT-generated Text","abstract":"ChatGPT has the ability to generate grammatically flawless and seemingly-human replies to different types of questions from various domains. The number of its users and of its applications is growing at an unprecedented rate. Unfortunately, use and abuse come hand in hand. In this paper, we study whether a machine learning model can be effectively trained to accurately distinguish between original human and seemingly human (that is, ChatGPT-generated) text, especially when this text is short. Furthermore, we employ an explainable artificial intelligence framework to gain insight into the reasoning behind the model trained to differentiate between ChatGPT-generated and human-generated text. The goal is to analyze model's decisions and determine if any specific patterns or characteristics can be identified. Our study focuses on short online reviews, conducting two experiments comparing human-generated and ChatGPT-generated text. The first experiment involves ChatGPT text generated from custom queries, while the second experiment involves text generated by rephrasing original human-generated reviews. We fine-tune a Transformer-based model and use it to make predictions, which are then explained using SHAP. We compare our model with a perplexity score-based approach and find that disambiguation between human and ChatGPT-generated reviews is more challenging for the ML model when using rephrased text. However, our proposed approach still achieves an accuracy of 79%. Using explainability, we observe that ChatGPT's writing is polite, without specific details, using fancy and atypical vocabulary, impersonal, and typically it does not express feelings.","created":"2023-01-30","meta":{"link":"http://arxiv.org/abs/2301.13852v1","tag":"prompt-eng"}}
{"title":"Navigating Complexity in Software Engineering: A Prototype for Comparing GPT-n Solutions","abstract":"Navigating the diverse solution spaces of non-trivial software engineering tasks requires a combination of technical knowledge, problem-solving skills, and creativity. With multiple possible solutions available, each with its own set of trade-offs, it is essential for programmers to evaluate the various options and select the one that best suits the specific requirements and constraints of a project. Whether it is choosing from a range of libraries, weighing the pros and cons of different architecture and design solutions, or finding unique ways to fulfill user requirements, the ability to think creatively is crucial for making informed decisions that will result in efficient and effective software. However, the interfaces of current chatbot tools for programmers, such as OpenAI's ChatGPT or GitHub Copilot, are optimized for presenting a single solution, even for complex queries. While other solutions can be requested, they are not displayed by default and are not intuitive to access. In this paper, we present our work-in-progress prototype \"GPTCompare\", which allows programmers to visually compare multiple source code solutions generated by GPT-n models for the same programming-related query by highlighting their similarities and differences.","created":"2023-01-28","meta":{"link":"http://arxiv.org/abs/2301.12169v1","tag":"prompt-eng"}}
{"title":"Could an Artificial-Intelligence agent pass an introductory physics course?","abstract":"Massive pre-trained language models have garnered attention and controversy due to their ability to generate human-like responses: attention due to their frequent indistinguishability from human-generated phraseology and narratives, and controversy due to the fact that their convincingly presented arguments and facts are frequently simply false. Just how human-like are these responses when it comes to dialogues about physics, in particular about the standard content of introductory physics courses? This study explores that question by having ChatGTP, the pre-eminent language model in 2023, work through representative assessment content of an actual calculus-based physics course and grading the responses in the same way human responses would be graded. As it turns out, ChatGPT would narrowly pass this course while exhibiting many of the preconceptions and errors of a beginning learner.","created":"2023-01-28","meta":{"link":"http://arxiv.org/abs/2301.12127v2","tag":"prompt-eng"}}
{"title":"Truth Machines: Synthesizing Veracity in AI Language Models","abstract":"As AI technologies are rolled out into healthcare, academia, human resources, law, and a multitude of other domains, they become de-facto arbiters of truth. But truth is highly contested, with many different definitions and approaches. This article discusses the struggle for truth in AI systems and the general responses to date. It then investigates the production of truth in InstructGPT, a large language model, highlighting how data harvesting, model architectures, and social feedback mechanisms weave together disparate understandings of veracity. It conceptualizes this performance as an operationalization of truth, where distinct, often conflicting claims are smoothly synthesized and confidently presented into truth-statements. We argue that these same logics and inconsistencies play out in Instruct's successor, ChatGPT, reiterating truth as a non-trivial problem. We suggest that enriching sociality and thickening \"reality\" are two promising vectors for enhancing the truth-evaluating capacities of future language models. We conclude, however, by stepping back to consider AI truth-telling as a social practice: what kind of \"truth\" do we as listeners desire?","created":"2023-01-28","meta":{"link":"http://arxiv.org/abs/2301.12066v1","tag":"prompt-eng"}}
{"title":"Investigating the use of ChatGPT for the scheduling of construction projects","abstract":"Large language models such as ChatGPT have the potential to revolutionize the construction industry by automating repetitive and time-consuming tasks. This paper presents a study in which ChatGPT was used to generate a construction schedule for a simple construction project. The output from ChatGPT was evaluated by a pool of participants that provided feedback regarding their overall interaction experience and the quality of the output. The results show that ChatGPT can generate a coherent schedule that follows a logical approach to fulfill the requirements of the scope indicated. The participants had an overall positive interaction experience and indicated the great potential of such a tool to automate many preliminary and time-consuming tasks. However, the technology still has limitations, and further development is needed before it can be widely adopted in the industry. Overall, this study highlights the potential of using large language models in the construction industry and the need for further research.","created":"2023-01-27","meta":{"link":"http://arxiv.org/abs/2302.02805v1","tag":"prompt-eng"}}
{"title":"ThoughtSource: A central hub for large language model reasoning data","abstract":"Large language models (LLMs) such as GPT-3 and ChatGPT have recently demonstrated impressive results across a wide range of tasks. LLMs are still limited, however, in that they frequently fail at complex reasoning, their reasoning processes are opaque, they are prone to 'hallucinate' facts, and there are concerns about their underlying biases. Letting models verbalize reasoning steps as natural language, a technique known as chain-of-thought prompting, has recently been proposed as a way to address some of these issues. Here we present the first release of ThoughtSource, a meta-dataset and software library for chain-of-thought (CoT) reasoning. The goal of ThoughtSource is to improve future artificial intelligence systems by facilitating qualitative understanding of CoTs, enabling empirical evaluations, and providing training data. This first release of ThoughtSource integrates six scientific/medical, three general-domain and five math word question answering datasets.","created":"2023-01-27","meta":{"link":"http://arxiv.org/abs/2301.11596v2","tag":"prompt-eng"}}
{"title":"Causal-Discovery Performance of ChatGPT in the context of Neuropathic Pain Diagnosis","abstract":"ChatGPT has demonstrated exceptional proficiency in natural language conversation, e.g., it can answer a wide range of questions while no previous large language models can. Thus, we would like to push its limit and explore its ability to answer causal discovery questions by using a medical benchmark (Tu et al. 2019) in causal discovery.","created":"2023-01-24","meta":{"link":"http://arxiv.org/abs/2301.13819v2","tag":"prompt-eng"}}
{"title":"Putting ChatGPT's Medical Advice to the (Turing) Test","abstract":"Objective: Assess the feasibility of using ChatGPT or a similar AI-based chatbot for patient-provider communication. Participants: A US representative sample of 430 study participants aged 18 and above. 53.2% of respondents analyzed were women; their average age was 47.1. Exposure: Ten representative non-administrative patient-provider interactions were extracted from the EHR. Patients' questions were placed in ChatGPT with a request for the chatbot to respond using approximately the same word count as the human provider's response. In the survey, each patient's question was followed by a provider- or ChatGPT-generated response. Participants were informed that five responses were provider-generated and five were chatbot-generated. Participants were asked, and incentivized financially, to correctly identify the response source. Participants were also asked about their trust in chatbots' functions in patient-provider communication, using a Likert scale of 1-5. Results: The correct classification of responses ranged between 49.0% to 85.7% for different questions. On average, chatbot responses were correctly identified 65.5% of the time, and provider responses were correctly distinguished 65.1% of the time. On average, responses toward patients' trust in chatbots' functions were weakly positive (mean Likert score: 3.4), with lower trust as the health-related complexity of the task in questions increased. Conclusions: ChatGPT responses to patient questions were weakly distinguishable from provider responses. Laypeople appear to trust the use of chatbots to answer lower risk health questions.","created":"2023-01-24","meta":{"link":"http://arxiv.org/abs/2301.10035v1","tag":"prompt-eng"}}
{"title":"An Analysis of the Automatic Bug Fixing Performance of ChatGPT","abstract":"To support software developers in finding and fixing software bugs, several automated program repair techniques have been introduced. Given a test suite, standard methods usually either synthesize a repair, or navigate a search space of software edits to find test-suite passing variants. Recent program repair methods are based on deep learning approaches. One of these novel methods, which is not primarily intended for automated program repair, but is still suitable for it, is ChatGPT. The bug fixing performance of ChatGPT, however, is so far unclear. Therefore, in this paper we evaluate ChatGPT on the standard bug fixing benchmark set, QuixBugs, and compare the performance with the results of several other approaches reported in the literature. We find that ChatGPT's bug fixing performance is competitive to the common deep learning approaches CoCoNut and Codex and notably better than the results reported for the standard program repair approaches. In contrast to previous approaches, ChatGPT offers a dialogue system through which further information, e.g., the expected output for a certain input or an observed error message, can be entered. By providing such hints to ChatGPT, its success rate can be further increased, fixing 31 out of 40 bugs, outperforming state-of-the-art.","created":"2023-01-20","meta":{"link":"http://arxiv.org/abs/2301.08653v1","tag":"prompt-eng"}}
{"title":"Is ChatGPT A Good Translator? Yes With GPT-4 As The Engine","abstract":"This report provides a preliminary evaluation of ChatGPT for machine translation, including translation prompt, multilingual translation, and translation robustness. We adopt the prompts advised by ChatGPT to trigger its translation ability and find that the candidate prompts generally work well and show minor performance differences. By evaluating on a number of benchmark test sets, we find that ChatGPT performs competitively with commercial translation products (e.g., Google Translate) on high-resource European languages but lags behind significantly on low-resource or distant languages. For distant languages, we explore an interesting strategy named $\\mathbf{pivot~prompting}$ that asks ChatGPT to translate the source sentence into a high-resource pivot language before into the target language, which improves the translation performance significantly. As for the translation robustness, ChatGPT does not perform as well as the commercial systems on biomedical abstracts or Reddit comments but exhibits good results on spoken language. With the launch of the GPT-4 engine, the translation performance of ChatGPT is significantly boosted, becoming comparable to commercial translation products, even for distant languages. In other words, $\\mathbf{ChatGPT~has~already~become~a~good~translator!}$ Scripts and data: https://github.com/wxjiao/Is-ChatGPT-A-Good-Translator","created":"2023-01-20","meta":{"link":"http://arxiv.org/abs/2301.08745v3","tag":"prompt-eng"}}
{"title":"How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection","abstract":"The introduction of ChatGPT has garnered widespread attention in both academic and industrial communities. ChatGPT is able to respond effectively to a wide range of human questions, providing fluent and comprehensive answers that significantly surpass previous public chatbots in terms of security and usefulness. On one hand, people are curious about how ChatGPT is able to achieve such strength and how far it is from human experts. On the other hand, people are starting to worry about the potential negative impacts that large language models (LLMs) like ChatGPT could have on society, such as fake news, plagiarism, and social security issues. In this work, we collected tens of thousands of comparison responses from both human experts and ChatGPT, with questions ranging from open-domain, financial, medical, legal, and psychological areas. We call the collected dataset the Human ChatGPT Comparison Corpus (HC3). Based on the HC3 dataset, we study the characteristics of ChatGPT's responses, the differences and gaps from human experts, and future directions for LLMs. We conducted comprehensive human evaluations and linguistic analyses of ChatGPT-generated content compared with that of humans, where many interesting results are revealed. After that, we conduct extensive experiments on how to effectively detect whether a certain text is generated by ChatGPT or humans. We build three different detection systems, explore several key factors that influence their effectiveness, and evaluate them in different scenarios. The dataset, code, and models are all publicly available at https://github.com/Hello-SimpleAI/chatgpt-comparison-detection.","created":"2023-01-18","meta":{"link":"http://arxiv.org/abs/2301.07597v1","tag":"prompt-eng"}}
{"title":"The moral authority of ChatGPT","abstract":"ChatGPT is not only fun to chat with, but it also searches information, answers questions, and gives advice. With consistent moral advice, it might improve the moral judgment and decisions of users, who often hold contradictory moral beliefs. Unfortunately, ChatGPT turns out highly inconsistent as a moral advisor. Nonetheless, it influences users' moral judgment, we find in an experiment, even if they know they are advised by a chatting bot, and they underestimate how much they are influenced. Thus, ChatGPT threatens to corrupt rather than improves users' judgment. These findings raise the question of how to ensure the responsible use of ChatGPT and similar AI. Transparency is often touted but seems ineffective. We propose training to improve digital literacy.","created":"2023-01-13","meta":{"link":"http://arxiv.org/abs/2301.07098v1","tag":"prompt-eng"}}
{"title":"ChatGPT is not all you need. A State of the Art Review of large Generative AI models","abstract":"During the last two years there has been a plethora of large generative models such as ChatGPT or Stable Diffusion that have been published. Concretely, these models are able to perform tasks such as being a general question and answering system or automatically creating artistic images that are revolutionizing several sectors. Consequently, the implications that these generative models have in the industry and society are enormous, as several job positions may be transformed. For example, Generative AI is capable of transforming effectively and creatively texts to images, like the DALLE-2 model; text to 3D images, like the Dreamfusion model; images to text, like the Flamingo model; texts to video, like the Phenaki model; texts to audio, like the AudioLM model; texts to other texts, like ChatGPT; texts to code, like the Codex model; texts to scientific texts, like the Galactica model or even create algorithms like AlphaTensor. This work consists on an attempt to describe in a concise way the main models are sectors that are affected by generative AI and to provide a taxonomy of the main generative models published recently.","created":"2023-01-11","meta":{"link":"http://arxiv.org/abs/2301.04655v1","tag":"prompt-eng"}}
{"title":"AI Insights into Theoretical Physics and the Swampland Program: A Journey Through the Cosmos with ChatGPT","abstract":"In this case study, we explore the capabilities and limitations of ChatGPT, a natural language processing model developed by OpenAI, in the field of string theoretical swampland conjectures. We find that it is effective at paraphrasing and explaining concepts in a variety of styles, but not at genuinely connecting concepts. It will provide false information with full confidence and make up statements when necessary. However, its ingenious use of language can be fruitful for identifying analogies and describing visual representations of abstract concepts.","created":"2023-01-10","meta":{"link":"http://arxiv.org/abs/2301.08155v1","tag":"prompt-eng"}}
{"title":"Chatbots in a Honeypot World","abstract":"Question-and-answer agents like ChatGPT offer a novel tool for use as a potential honeypot interface in cyber security. By imitating Linux, Mac, and Windows terminal commands and providing an interface for TeamViewer, nmap, and ping, it is possible to create a dynamic environment that can adapt to the actions of attackers and provide insight into their tactics, techniques, and procedures (TTPs). The paper illustrates ten diverse tasks that a conversational agent or large language model might answer appropriately to the effects of command-line attacker. The original result features feasibility studies for ten model tasks meant for defensive teams to mimic expected honeypot interfaces with minimal risks. Ultimately, the usefulness outside of forensic activities stems from whether the dynamic honeypot can extend the time-to-conquer or otherwise delay attacker timelines short of reaching key network assets like databases or confidential information. While ongoing maintenance and monitoring may be required, ChatGPT's ability to detect and deflect malicious activity makes it a valuable option for organizations seeking to enhance their cyber security posture. Future work will focus on cybersecurity layers, including perimeter security, host virus detection, and data security.","created":"2023-01-10","meta":{"link":"http://arxiv.org/abs/2301.03771v1","tag":"prompt-eng"}}
{"title":"Can Large Language Models Change User Preference Adversarially?","abstract":"Pretrained large language models (LLMs) are becoming increasingly powerful and ubiquitous in mainstream applications such as being a personal assistant, a dialogue model, etc. As these models become proficient in deducing user preferences and offering tailored assistance, there is an increasing concern about the ability of these models to influence, modify and in the extreme case manipulate user preference adversarially. The issue of lack of interpretability in these models in adversarial settings remains largely unsolved. This work tries to study adversarial behavior in user preferences from the lens of attention probing, red teaming and white-box analysis. Specifically, it provides a bird's eye view of existing literature, offers red teaming samples for dialogue models like ChatGPT and GODEL and probes the attention mechanism in the latter for non-adversarial and adversarial settings.","created":"2023-01-05","meta":{"link":"http://arxiv.org/abs/2302.10291v1","tag":"prompt-eng"}}
{"title":"The political ideology of conversational AI: Converging evidence on ChatGPT's pro-environmental, left-libertarian orientation","abstract":"Conversational artificial intelligence (AI) disrupts how humans interact with technology. Recently, OpenAI introduced ChatGPT, a state-of-the-art dialogue model that can converse with its human counterparts with unprecedented capabilities. ChatGPT has witnessed tremendous attention from the media, academia, industry, and the general public, attracting more than a million users within days of its release. However, its explosive adoption for information search and as an automated decision aid underscores the importance to understand its limitations and biases. This paper focuses on one of democratic society's most important decision-making processes: political elections. Prompting ChatGPT with 630 political statements from two leading voting advice applications and the nation-agnostic political compass test in three pre-registered experiments, we uncover ChatGPT's pro-environmental, left-libertarian ideology. For example, ChatGPT would impose taxes on flights, restrict rent increases, and legalize abortion. In the 2021 elections, it would have voted most likely for the Greens both in Germany (B\\\"undnis 90/Die Gr\\\"unen) and in the Netherlands (GroenLinks). Our findings are robust when negating the prompts, reversing the order of the statements, varying prompt formality, and across languages (English, German, Dutch, and Spanish). We conclude by discussing the implications of politically biased conversational AI on society.","created":"2023-01-05","meta":{"link":"http://arxiv.org/abs/2301.01768v1","tag":"prompt-eng"}}
{"title":"Developing Responsible Chatbots for Financial Services: A Pattern-Oriented Responsible AI Engineering Approach","abstract":"The recent release of ChatGPT has gained huge attention and discussion worldwide, with responsible AI being a key topic of discussion. How can we ensure that AI systems, including ChatGPT, are developed and adopted in a responsible way? To tackle the responsible AI challenges, various ethical principles have been released by governments, organisations, and companies. However, those principles are very abstract and not practical enough. Further, significant efforts have been put on algorithm-level solutions that only address a narrow set of principles, such as fairness and privacy. To fill the gap, we adopt a pattern-oriented responsible AI engineering approach and build a Responsible AI Pattern Catalogue to operationalise responsible AI from a system perspective. In this article, we first summarise the major challenges in operationalising responsible AI at scale and introduce how we use the Responsible AI Pattern Catalogue to address those challenges. We then examine the risks at each stage of the chatbot development process and recommend pattern-driven mitigations to evaluate the the usefulness of the Responsible AI Pattern Catalogue in a real-world setting.","created":"2023-01-03","meta":{"link":"http://arxiv.org/abs/2301.05517v2","tag":"prompt-eng"}}
{"title":"Modeling Label Semantics Improves Activity Recognition","abstract":"Human activity recognition (HAR) aims to classify sensory time series into different activities, with wide applications in activity tracking, healthcare, human computer interaction, etc. Existing HAR works improve recognition performance by designing more complicated feature extraction methods, but they neglect the label semantics by simply treating labels as integer IDs. We find that many activities in the current HAR datasets have shared label names, e.g., \"open door\" and \"open fridge\", \"walk upstairs\" and \"walk downstairs\". Through some exploratory analysis, we find that such shared structure in activity names also maps to similarity in the input features. To this end, we design a sequence-to-sequence framework to decode the label name semantics rather than classifying labels as integer IDs. Our proposed method decomposes learning activities into learning shared tokens (\"open\", \"walk\"), which is easier than learning the joint distribution (\"open fridge\", \"walk upstairs\") and helps transfer learning to activities with insufficient data samples. For datasets originally without shared tokens in label names, we also offer an automated method, using OpenAI's ChatGPT, to generate shared actions and objects. Extensive experiments on seven HAR benchmark datasets demonstrate the state-of-the-art performance of our method. We also show better performance in the long-tail activity distribution settings and few-shot settings.","created":"2023-01-01","meta":{"link":"http://arxiv.org/abs/2301.03462v1","tag":"prompt-eng"}}
{"title":"Chatbots as Problem Solvers: Playing Twenty Questions with Role Reversals","abstract":"New chat AI applications like ChatGPT offer an advanced understanding of question context and memory across multi-step tasks, such that experiments can test its deductive reasoning. This paper proposes a multi-role and multi-step challenge, where ChatGPT plays the classic twenty-questions game but innovatively switches roles from the questioner to the answerer. The main empirical result establishes that this generation of chat applications can guess random object names in fewer than twenty questions (average, 12) and correctly guess 94% of the time across sixteen different experimental setups. The research introduces four novel cases where the chatbot fields the questions, asks the questions, both question-answer roles, and finally tries to guess appropriate contextual emotions. One task that humans typically fail but trained chat applications complete involves playing bilingual games of twenty questions (English answers to Spanish questions). Future variations address direct problem-solving using a similar inquisitive format to arrive at novel outcomes deductively, such as patentable inventions or combination thinking. Featured applications of this dialogue format include complex protein designs, neuroscience metadata, and child development educational materials.","created":"2023-01-01","meta":{"link":"http://arxiv.org/abs/2301.01743v1","tag":"prompt-eng"}}
{"title":"ChatGPT Makes Medicine Easy to Swallow: An Exploratory Case Study on Simplified Radiology Reports","abstract":"The release of ChatGPT, a language model capable of generating text that appears human-like and authentic, has gained significant attention beyond the research community. We expect that the convincing performance of ChatGPT incentivizes users to apply it to a variety of downstream tasks, including prompting the model to simplify their own medical reports. To investigate this phenomenon, we conducted an exploratory case study. In a questionnaire, we asked 15 radiologists to assess the quality of radiology reports simplified by ChatGPT. Most radiologists agreed that the simplified reports were factually correct, complete, and not potentially harmful to the patient. Nevertheless, instances of incorrect statements, missed key medical findings, and potentially harmful passages were reported. While further studies are needed, the initial insights of this study indicate a great potential in using large language models like ChatGPT to improve patient-centered care in radiology and other medical domains.","created":"2022-12-30","meta":{"link":"http://arxiv.org/abs/2212.14882v1","tag":"prompt-eng"}}
{"title":"How would Stance Detection Techniques Evolve after the Launch of ChatGPT?","abstract":"Stance detection refers to the task of extracting the standpoint (Favor, Against or Neither) towards a target in given texts. Such research gains increasing attention with the proliferation of social media contents. The conventional framework of handling stance detection is converting it into text classification tasks. Deep learning models have already replaced rule-based models and traditional machine learning models in solving such problems. Current deep neural networks are facing two main challenges which are insufficient labeled data and information in social media posts and the unexplainable nature of deep learning models. A new pre-trained language model chatGPT was launched on Nov 30, 2022. For the stance detection tasks, our experiments show that ChatGPT can achieve SOTA or similar performance for commonly used datasets including SemEval-2016 and P-Stance. At the same time, ChatGPT can provide explanation for its own prediction, which is beyond the capability of any existing model. The explanations for the cases it cannot provide classification results are especially useful. ChatGPT has the potential to be the best AI model for stance detection tasks in NLP, or at least change the research paradigm of this field. ChatGPT also opens up the possibility of building explanatory AI for stance detection.","created":"2022-12-30","meta":{"link":"http://arxiv.org/abs/2212.14548v3","tag":"prompt-eng"}}
{"title":"The Death of the Short-Form Physics Essay in the Coming AI Revolution","abstract":"The latest AI language modules can produce original, high quality full short-form ($300$-word) Physics essays within seconds. These technologies such as ChatGPT and davinci-003 are freely available to anyone with an internet connection. In this work, we present evidence of AI generated short-form essays achieving first-class grades on an essay writing assessment from an accredited, current university Physics module. The assessment requires students answer five open-ended questions with a short, $300$-word essay each. Fifty AI answers were generated to create ten submissions that were independently marked by five separate markers. The AI generated submissions achieved an average mark of $71 \\pm 2 \\%$, in strong agreement with the current module average of $71 \\pm 5 %$. A typical AI submission would therefore most-likely be awarded a First Class, the highest classification available at UK universities. Plagiarism detection software returned a plagiarism score between $2 \\pm 1$% (Grammarly) and $7 \\pm 2$% (TurnitIn). We argue that these results indicate that current AI MLPs represent a significant threat to the fidelity of short-form essays as an assessment method in Physics courses.","created":"2022-12-22","meta":{"link":"http://arxiv.org/abs/2212.11661v1","tag":"prompt-eng"}}
{"title":"Transformers Go for the LOLs: Generating (Humourous) Titles from Scientific Abstracts End-to-End","abstract":"We consider the end-to-end abstract-to-title generation problem, exploring seven recent transformer based models (including ChatGPT) fine-tuned on more than 30k abstract-title pairs from NLP and machine learning venues. As an extension, we also consider the harder problem of generating humorous paper titles. For the latter, we compile the first large-scale humor annotated dataset for scientific papers in the NLP/ML domains, comprising almost 2.5k titles. We evaluate all models using human and automatic metrics. Our human evaluation suggests that our best end-to-end system performs similarly to human authors (but arguably slightly worse). Generating funny titles is more difficult, however, and our automatic systems clearly underperform relative to humans and often learn dataset artefacts of humor. Finally, ChatGPT, without any fine-tuning, performs on the level of our best fine-tuned system.","created":"2022-12-20","meta":{"link":"http://arxiv.org/abs/2212.10522v1","tag":"prompt-eng"}}
{"title":"ByGPT5: End-to-End Style-conditioned Poetry Generation with Token-free Language Models","abstract":"State-of-the-art poetry generation systems are often complex. They either consist of task-specific model pipelines, incorporate prior knowledge in the form of manually created constraints or both. In contrast, end-to-end models would not suffer from the overhead of having to model prior knowledge and could learn the nuances of poetry from data alone, reducing the degree of human supervision required. In this work, we investigate end-to-end poetry generation conditioned on styles such as rhyme, meter, and alliteration. We identify and address lack of training data and mismatching tokenization algorithms as possible limitations of past attempts. In particular, we successfully pre-train and release ByGPT5, a new token-free decoder-only language model, and fine-tune it on a large custom corpus of English and German quatrains annotated with our styles. We show that ByGPT5 outperforms other models such as mT5, ByT5, GPT-2 and ChatGPT, while also being more parameter efficient and performing favorably compared to humans. In addition, we analyze its runtime performance and introspect the model's understanding of style conditions. We make our code, models, and datasets publicly available.","created":"2022-12-20","meta":{"link":"http://arxiv.org/abs/2212.10474v1","tag":"prompt-eng"}}
{"title":"Are Deep Neural Networks SMARTer than Second Graders?","abstract":"Recent times have witnessed an increasing number of applications of deep neural networks towards solving tasks that require superior cognitive abilities, e.g., playing Go, generating art, question answering (such as ChatGPT), etc. Such a dramatic progress raises the question: how generalizable are neural networks in solving problems that demand broad skills? To answer this question, we propose SMART: a Simple Multimodal Algorithmic Reasoning Task and the associated SMART-101 dataset, for evaluating the abstraction, deduction, and generalization abilities of neural networks in solving visuo-linguistic puzzles designed specifically for children in the 6-8 age group. Our dataset consists of 101 unique puzzles; each puzzle comprises a picture and a question, and their solution needs a mix of several elementary skills, including arithmetic, algebra, and spatial reasoning, among others. To scale our dataset towards training deep neural networks, we programmatically generate entirely new instances for each puzzle while retaining their solution algorithm. To benchmark the performance on the SMART-101 dataset, we propose a vision and language meta-learning model using varied state-of-the-art backbone neural networks. Our experiments reveal that while powerful deep models offer reasonable performances on puzzles that they are trained on, they are not better than random accuracy when analyzed for generalization. We also evaluate the recent ChatGPT large language model on a subset of our dataset and find that while ChatGPT produces convincing reasoning abilities, the answers are often incorrect.","created":"2022-12-20","meta":{"link":"http://arxiv.org/abs/2212.09993v2","tag":"prompt-eng"}}
{"title":"Million-scale Object Detection with Large Vision Model","abstract":"Over the past few years, there has been growing interest in developing a broad, universal, and general-purpose computer vision system. Such a system would have the potential to solve a wide range of vision tasks simultaneously, without being restricted to a specific problem or data domain. This is crucial for practical, real-world computer vision applications. In this study, we focus on the million-scale multi-domain universal object detection problem, which presents several challenges, including cross-dataset category label duplication, label conflicts, and the need to handle hierarchical taxonomies. Furthermore, there is an ongoing challenge in the field to find a resource-efficient way to leverage large pre-trained vision models for million-scale cross-dataset object detection. To address these challenges, we introduce our approach to label handling, hierarchy-aware loss design, and resource-efficient model training using a pre-trained large model. Our method was ranked second in the object detection track of the Robust Vision Challenge 2022 (RVC 2022). We hope that our detailed study will serve as a useful reference and alternative approach for similar problems in the computer vision community. The code is available at https://github.com/linfeng93/Large-UniDet.","created":"2022-12-19","meta":{"link":"http://arxiv.org/abs/2212.09408v2","tag":"prompt-eng"}}
{"title":"ChatGPT: The End of Online Exam Integrity?","abstract":"This study evaluated the ability of ChatGPT, a recently developed artificial intelligence (AI) agent, to perform high-level cognitive tasks and produce text that is indistinguishable from human-generated text. This capacity raises concerns about the potential use of ChatGPT as a tool for academic misconduct in online exams. The study found that ChatGPT is capable of exhibiting critical thinking skills and generating highly realistic text with minimal input, making it a potential threat to the integrity of online exams, particularly in tertiary education settings where such exams are becoming more prevalent. Returning to invigilated and oral exams could form part of the solution, while using advanced proctoring techniques and AI-text output detectors may be effective in addressing this issue, they are not likely to be foolproof solutions. Further research is needed to fully understand the implications of large language models like ChatGPT and to devise strategies for combating the risk of cheating using these tools. It is crucial for educators and institutions to be aware of the possibility of ChatGPT being used for cheating and to investigate measures to address it in order to maintain the fairness and validity of online exams for all students.","created":"2022-12-19","meta":{"link":"http://arxiv.org/abs/2212.09292v1","tag":"prompt-eng"}}
{"title":"Chatbots in a Botnet World","abstract":"Question-and-answer formats provide a novel experimental platform for investigating cybersecurity questions. Unlike previous chatbots, the latest ChatGPT model from OpenAI supports an advanced understanding of complex coding questions. The research demonstrates thirteen coding tasks that generally qualify as stages in the MITRE ATT&CK framework, ranging from credential access to defense evasion. With varying success, the experimental prompts generate examples of keyloggers, logic bombs, obfuscated worms, and payment-fulfilled ransomware. The empirical results illustrate cases that support the broad gain of functionality, including self-replication and self-modification, evasion, and strategic understanding of complex cybersecurity goals. One surprising feature of ChatGPT as a language-only model centers on its ability to spawn coding approaches that yield images that obfuscate or embed executable programming steps or links.","created":"2022-12-18","meta":{"link":"http://arxiv.org/abs/2212.11126v2","tag":"prompt-eng"}}
{"title":"Paraphrase Identification with Deep Learning: A Review of Datasets and Methods","abstract":"The rapid advancement of AI technology has made text generation tools like GPT-3 and ChatGPT increasingly accessible, scalable, and effective. This can pose serious threat to the credibility of various forms of media if these technologies are used for plagiarism, including scientific literature and news sources. Despite the development of automated methods for paraphrase identification, detecting this type of plagiarism remains a challenge due to the disparate nature of the datasets on which these methods are trained. In this study, we review traditional and current approaches to paraphrase identification and propose a refined typology of paraphrases. We also investigate how this typology is represented in popular datasets and how under-representation of certain types of paraphrases impacts detection capabilities. Finally, we outline new directions for future research and datasets in the pursuit of more effective paraphrase detection using AI.","created":"2022-12-13","meta":{"link":"http://arxiv.org/abs/2212.06933v1","tag":"prompt-eng"}}
{"title":"\"I think this is the most disruptive technology\": Exploring Sentiments of ChatGPT Early Adopters using Twitter Data","abstract":"Large language models have recently attracted significant attention due to their impressive performance on a variety of tasks. ChatGPT developed by OpenAI is one such implementation of a large, pre-trained language model that has gained immense popularity among early adopters, where certain users go to the extent of characterizing it as a disruptive technology in many domains. Understanding such early adopters' sentiments is important because it can provide insights into the potential success or failure of the technology, as well as its strengths and weaknesses. In this paper, we conduct a mixed-method study using 10,732 tweets from early ChatGPT users. We first use topic modelling to identify the main topics and then perform an in-depth qualitative sentiment analysis of each topic. Our results show that the majority of the early adopters have expressed overwhelmingly positive sentiments related to topics such as Disruptions to software development, Entertainment and exercising creativity. Only a limited percentage of users expressed concerns about issues such as the potential for misuse of ChatGPT, especially regarding topics such as Impact on educational aspects. We discuss these findings by providing specific examples for each topic and then detail implications related to addressing these concerns for both researchers and users.","created":"2022-12-12","meta":{"link":"http://arxiv.org/abs/2212.05856v1","tag":"prompt-eng"}}
{"title":"The Turing Deception","abstract":"This research revisits the classic Turing test and compares recent large language models such as ChatGPT for their abilities to reproduce human-level comprehension and compelling text generation. Two task challenges -- summarization, and question answering -- prompt ChatGPT to produce original content (98-99%) from a single text entry and also sequential questions originally posed by Turing in 1950. We score the original and generated content against the OpenAI GPT-2 Output Detector from 2019, and establish multiple cases where the generated content proves original and undetectable (98%). The question of a machine fooling a human judge recedes in this work relative to the question of \"how would one prove it?\" The original contribution of the work presents a metric and simple grammatical set for understanding the writing mechanics of chatbots in evaluating their readability and statistical clarity, engagement, delivery, and overall quality. While Turing's original prose scores at least 14% below the machine-generated output, the question of whether an algorithm displays hints of Turing's truly original thoughts (the \"Lovelace 2.0\" test) remains unanswered and potentially unanswerable for now.","created":"2022-12-09","meta":{"link":"http://arxiv.org/abs/2212.06721v2","tag":"prompt-eng"}}
{"title":"The Role of AI in Drug Discovery: Challenges, Opportunities, and Strategies","abstract":"Artificial intelligence (AI) has the potential to revolutionize the drug discovery process, offering improved efficiency, accuracy, and speed. However, the successful application of AI is dependent on the availability of high-quality data, the addressing of ethical concerns, and the recognition of the limitations of AI-based approaches. In this article, the benefits, challenges and drawbacks of AI in this field are reviewed, and possible strategies and approaches for overcoming the present obstacles are proposed. The use of data augmentation, explainable AI, and the integration of AI with traditional experimental methods, as well as the potential advantages of AI in pharmaceutical research are also discussed. Overall, this review highlights the potential of AI in drug discovery and provides insights into the challenges and opportunities for realizing its potential in this field.   Note from the human-authors: This article was created to test the ability of ChatGPT, a chatbot based on the GPT-3.5 language model, to assist human authors in writing review articles. The text generated by the AI following our instructions (see Supporting Information) was used as a starting point, and its ability to automatically generate content was evaluated. After conducting a thorough review, human authors practically rewrote the manuscript, striving to maintain a balance between the original proposal and scientific criteria. The advantages and limitations of using AI for this purpose are discussed in the last section.","created":"2022-12-08","meta":{"link":"http://arxiv.org/abs/2212.08104v1","tag":"prompt-eng"}}
{"title":"The European AI Liability Directives -- Critique of a Half-Hearted Approach and Lessons for the Future","abstract":"As ChatGPT et al. conquer the world, the optimal liability framework for AI systems remains an unsolved problem across the globe. In a much-anticipated move, the European Commission advanced two proposals outlining the European approach to AI liability in September 2022: a novel AI Liability Directive and a revision of the Product Liability Directive. They constitute the final cornerstone of EU AI regulation. Crucially, the liability proposals and the EU AI Act are inherently intertwined: the latter does not contain any individual rights of affected persons, and the former lack specific, substantive rules on AI development and deployment. Taken together, these acts may well trigger a Brussels Effect in AI regulation, with significant consequences for the US and beyond.   This paper makes three novel contributions. First, it examines in detail the Commission proposals and shows that, while making steps in the right direction, they ultimately represent a half-hearted approach: if enacted as foreseen, AI liability in the EU will primarily rest on disclosure of evidence mechanisms and a set of narrowly defined presumptions concerning fault, defectiveness and causality. Hence, second, the article suggests amendments, which are collected in an Annex at the end of the paper. Third, based on an analysis of the key risks AI poses, the final part of the paper maps out a road for the future of AI liability and regulation, in the EU and beyond. This includes: a comprehensive framework for AI liability; provisions to support innovation; an extension to non-discrimination/algorithmic fairness, as well as explainable AI; and sustainability. I propose to jump-start sustainable AI regulation via sustainability impact assessments in the AI Act and sustainable design defects in the liability regime. In this way, the law may help spur not only fair AI and XAI, but potentially also sustainable AI (SAI).","created":"2022-11-25","meta":{"link":"http://arxiv.org/abs/2211.13960v5","tag":"prompt-eng"}}
{"title":"What would Harry say? Building Dialogue Agents for Characters in a Story","abstract":"We have a Christmas gift for Harry Potter fans all over the world. In this paper, we present Harry Potter Dialogue (HPD), a dataset that helps train Harry Potter-like dialogue agents. Such a task is typically viewed as a variant of personalized dialogue agents, but they differ significantly in three respects: 1) Harry lived in a virtual world of wizards, thus, real-world commonsense may not apply to Harry's conversations; 2) Harry's behavior is strongly linked to background information in conversations: the scene, its attributes and its relationship to other speakers; and 3) Such backgrounds are dynamically altered as the storyline goes on. The HPD dataset, as the first dataset to facilitate the study of dialogue agent construction for characters within a story, provides rich contextual information about each dialogue session such as scenes, character attributes, and relations. More importantly, all the background information will change over the course of the story. In addition, HPD could support both dialogue generation and retrieval tasks. We evaluate baselines such as Dialog-GPT and BOB to determine the extent to which they can generate Harry Potter-like responses. The experimental results disappoint us in that although the generated responses are fluent, they still seem out of character for Harry. Besides, we validate the current most robust dialogue agent, ChatGPT, which also can't generate plausible Harry-Potter-like responses in some cases, either. Our results suggest that there is much scope for future research.","created":"2022-11-13","meta":{"link":"http://arxiv.org/abs/2211.06869v3","tag":"prompt-eng"}}
{"title":"Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs","abstract":"Social intelligence and Theory of Mind (ToM), i.e., the ability to reason about the different mental states, intents, and reactions of all people involved, allow humans to effectively navigate and understand everyday social interactions. As NLP systems are used in increasingly complex social situations, their ability to grasp social dynamics becomes crucial. In this work, we examine the open question of social intelligence and Theory of Mind in modern NLP systems from an empirical and theory-based perspective. We show that one of today's largest language models (GPT-3; Brown et al., 2020) lacks this kind of social intelligence out-of-the box, using two tasks: SocialIQa (Sap et al., 2019), which measures models' ability to understand intents and reactions of participants of social interactions, and ToMi (Le et al., 2019), which measures whether models can infer mental states and realities of participants of situations. Our results show that models struggle substantially at these Theory of Mind tasks, with well-below-human accuracies of 55% and 60% on SocialIQa and ToMi, respectively. To conclude, we draw on theories from pragmatics to contextualize this shortcoming of large language models, by examining the limitations stemming from their data, neural architecture, and training paradigms. Challenging the prevalent narrative that only scale is needed, we posit that person-centric NLP approaches might be more effective towards neural Theory of Mind.   In our updated version, we also analyze newer instruction tuned and RLFH models for neural ToM. We find that even ChatGPT and GPT-4 do not display emergent Theory of Mind; strikingly even GPT-4 performs only 60% accuracy on the ToMi questions related to mental states and realities.","created":"2022-10-24","meta":{"link":"http://arxiv.org/abs/2210.13312v2","tag":"prompt-eng"}}
{"title":"Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods","abstract":"Machine generated text is increasingly difficult to distinguish from human authored text. Powerful open-source models are freely available, and user-friendly tools that democratize access to generative models are proliferating. ChatGPT, which was released shortly after the first preprint of this survey, epitomizes these trends. The great potential of state-of-the-art natural language generation (NLG) systems is tempered by the multitude of avenues for abuse. Detection of machine generated text is a key countermeasure for reducing abuse of NLG models, with significant technical challenges and numerous open problems. We provide a survey that includes both 1) an extensive analysis of threat models posed by contemporary NLG systems, and 2) the most complete review of machine generated text detection methods to date. This survey places machine generated text within its cybersecurity and social context, and provides strong guidance for future work addressing the most critical threat models, and ensuring detection systems themselves demonstrate trustworthiness through fairness, robustness, and accountability.","created":"2022-10-13","meta":{"link":"http://arxiv.org/abs/2210.07321v3","tag":"prompt-eng"}}
{"title":"Structure Preserving Cycle-GAN for Unsupervised Medical Image Domain Adaptation","abstract":"The presence of domain shift in medical imaging is a common issue, which can greatly impact the performance of segmentation models when dealing with unseen image domains. Adversarial-based deep learning models, such as Cycle-GAN, have become a common model for approaching unsupervised domain adaptation of medical images. These models however, have no ability to enforce the preservation of structures of interest when translating medical scans, which can lead to potentially poor results for unsupervised domain adaptation within the context of segmentation. This work introduces the Structure Preserving Cycle-GAN (SP Cycle-GAN), which promotes medical structure preservation during image translation through the enforcement of a segmentation loss term in the overall Cycle-GAN training process. We demonstrate the structure preserving capability of the SP Cycle-GAN both visually and through comparison of Dice score segmentation performance for the unsupervised domain adaptation models. The SP Cycle-GAN is able to outperform baseline approaches and standard Cycle-GAN domain adaptation for binary blood vessel segmentation in the STARE and DRIVE datasets, and multi-class Left Ventricle and Myocardium segmentation in the multi-modal MM-WHS dataset. SP Cycle-GAN achieved a state of the art Myocardium segmentation Dice score (DSC) of 0.7435 for the MR to CT MM-WHS domain adaptation problem, and excelled in nearly all categories for the MM-WHS dataset. SP Cycle-GAN also demonstrated a strong ability to preserve blood vessel structure in the DRIVE to STARE domain adaptation problem, achieving a 4% DSC increase over a default Cycle-GAN implementation.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09164v1","tag":"new-dataset"}}
{"title":"Neural networks for geospatial data","abstract":"Analysis of geospatial data has traditionally been model-based, with a mean model, customarily specified as a linear regression on the covariates, and a covariance model, encoding the spatial dependence. We relax the strong assumption of linearity and propose embedding neural networks directly within the traditional geostatistical models to accommodate non-linear mean functions while retaining all other advantages including use of Gaussian Processes to explicitly model the spatial covariance, enabling inference on the covariate effect through the mean and on the spatial dependence through the covariance, and offering predictions at new locations via kriging. We propose NN-GLS, a new neural network estimation algorithm for the non-linear mean in GP models that explicitly accounts for the spatial covariance through generalized least squares (GLS), the same loss used in the linear case. We show that NN-GLS admits a representation as a special type of graph neural network (GNN). This connection facilitates use of standard neural network computational techniques for irregular geospatial data, enabling novel and scalable mini-batching, backpropagation, and kriging schemes. Theoretically, we show that NN-GLS will be consistent for irregularly observed spatially correlated data processes. To our knowledge this is the first asymptotic consistency result for any neural network algorithm for spatial data. We demonstrate the methodology through simulated and real datasets.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09157v1","tag":"new-dataset"}}
{"title":"Sharp-SSL: Selective high-dimensional axis-aligned random projections for semi-supervised learning","abstract":"We propose a new method for high-dimensional semi-supervised learning problems based on the careful aggregation of the results of a low-dimensional procedure applied to many axis-aligned random projections of the data. Our primary goal is to identify important variables for distinguishing between the classes; existing low-dimensional methods can then be applied for final class assignment. Motivated by a generalized Rayleigh quotient, we score projections according to the traces of the estimated whitened between-class covariance matrices on the projected data. This enables us to assign an importance weight to each variable for a given projection, and to select our signal variables by aggregating these weights over high-scoring projections. Our theory shows that the resulting Sharp-SSL algorithm is able to recover the signal coordinates with high probability when we aggregate over sufficiently many random projections and when the base procedure estimates the whitened between-class covariance matrix sufficiently well. The Gaussian EM algorithm is a natural choice as a base procedure, and we provide a new analysis of its performance in semi-supervised settings that controls the parameter estimation error in terms of the proportion of labeled data in the sample. Numerical results on both simulated data and a real colon tumor dataset support the excellent empirical performance of the method.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09154v1","tag":"new-dataset"}}
{"title":"UniMax: Fairer and more Effective Language Sampling for Large-Scale Multilingual Pretraining","abstract":"Pretrained multilingual large language models have typically used heuristic temperature-based sampling to balance between different languages. However previous work has not systematically evaluated the efficacy of different pretraining language distributions across model scales. In this paper, we propose a new sampling method, UniMax, that delivers more uniform coverage of head languages while mitigating overfitting on tail languages by explicitly capping the number of repeats over each language's corpus. We perform an extensive series of ablations testing a range of sampling strategies on a suite of multilingual benchmarks, while varying model scale. We find that UniMax outperforms standard temperature-based sampling, and the benefits persist as scale increases. As part of our contribution, we release: (i) an improved and refreshed mC4 multilingual corpus consisting of 29 trillion characters across 107 languages, and (ii) a suite of pretrained umT5 model checkpoints trained with UniMax sampling.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09151v1","tag":"new-dataset"}}
{"title":"Variational Relational Point Completion Network for Robust 3D Classification","abstract":"Real-scanned point clouds are often incomplete due to viewpoint, occlusion, and noise, which hampers 3D geometric modeling and perception. Existing point cloud completion methods tend to generate global shape skeletons and hence lack fine local details. Furthermore, they mostly learn a deterministic partial-to-complete mapping, but overlook structural relations in man-made objects. To tackle these challenges, this paper proposes a variational framework, Variational Relational point Completion Network (VRCNet) with two appealing properties: 1) Probabilistic Modeling. In particular, we propose a dual-path architecture to enable principled probabilistic modeling across partial and complete clouds. One path consumes complete point clouds for reconstruction by learning a point VAE. The other path generates complete shapes for partial point clouds, whose embedded distribution is guided by distribution obtained from the reconstruction path during training. 2) Relational Enhancement. Specifically, we carefully design point self-attention kernel and point selective kernel module to exploit relational point features, which refines local shape details conditioned on the coarse completion. In addition, we contribute multi-view partial point cloud datasets (MVP and MVP-40 dataset) containing over 200,000 high-quality scans, which render partial 3D shapes from 26 uniformly distributed camera poses for each 3D CAD model. Extensive experiments demonstrate that VRCNet outperforms state-of-the-art methods on all standard point cloud completion benchmarks. Notably, VRCNet shows great generalizability and robustness on real-world point cloud scans. Moreover, we can achieve robust 3D classification for partial point clouds with the help of VRCNet, which can highly increase classification accuracy.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09131v1","tag":"new-dataset"}}
{"title":"Statistical Detection of Coordination in a Cognitive Radar Network through Inverse Multi-objective Optimization","abstract":"Consider a target being tracked by a cognitive radar network. If the target can intercept noisy radar emissions, how can it detect coordination in the radar network? By 'coordination' we mean that the radar emissions satisfy Pareto optimality with respect to multi-objective optimization over the objective functions of each radar and a constraint on total network power output. This paper provides a novel inverse multi-objective optimization approach for statistically detecting Pareto optimal ('coordinating') behavior, from a finite dataset of noisy radar emissions. Specifically, we develop necessary and sufficient conditions for radar network emissions to be consistent with multi-objective optimization (coordination), and we provide a statistical detector with theoretical guarantees for determining this consistency when radar emissions are observed in noise. We also provide numerical simulations which validate our approach. Note that while we make use of the specific framework of a radar network coordination problem, our results apply more generally to the field of inverse multi-objective optimization.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09125v1","tag":"new-dataset"}}
{"title":"NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers","abstract":"Scaling text-to-speech (TTS) to large-scale, multi-speaker, and in-the-wild datasets is important to capture the diversity in human speech such as speaker identities, prosodies, and styles (e.g., singing). Current large TTS systems usually quantize speech into discrete tokens and use language models to generate these tokens one by one, which suffer from unstable prosody, word skipping/repeating issue, and poor voice quality. In this paper, we develop NaturalSpeech 2, a TTS system that leverages a neural audio codec with residual vector quantizers to get the quantized latent vectors and uses a diffusion model to generate these latent vectors conditioned on text input. To enhance the zero-shot capability that is important to achieve diverse speech synthesis, we design a speech prompting mechanism to facilitate in-context learning in the diffusion model and the duration/pitch predictor. We scale NaturalSpeech 2 to large-scale datasets with 44K hours of speech and singing data and evaluate its voice quality on unseen speakers. NaturalSpeech 2 outperforms previous TTS systems by a large margin in terms of prosody/timbre similarity, robustness, and voice quality in a zero-shot setting, and performs novel zero-shot singing synthesis with only a speech prompt. Audio samples are available at https://speechresearch.github.io/naturalspeech2.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09116v1","tag":"new-dataset"}}
{"title":"METAM: Goal-Oriented Data Discovery","abstract":"Data is a central component of machine learning and causal inference tasks. The availability of large amounts of data from sources such as open data repositories, data lakes and data marketplaces creates an opportunity to augment data and boost those tasks' performance. However, augmentation techniques rely on a user manually discovering and shortlisting useful candidate augmentations. Existing solutions do not leverage the synergy between discovery and augmentation, thus under exploiting data.   In this paper, we introduce METAM, a novel goal-oriented framework that queries the downstream task with a candidate dataset, forming a feedback loop that automatically steers the discovery and augmentation process. To select candidates efficiently, METAM leverages properties of the: i) data, ii) utility function, and iii) solution set size. We show METAM's theoretical guarantees and demonstrate those empirically on a broad set of tasks. All in all, we demonstrate the promise of goal-oriented data discovery to modern data science applications.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09068v1","tag":"new-dataset"}}
{"title":"Performance of GAN-based augmentation for deep learning COVID-19 image classification","abstract":"The biggest challenge in the application of deep learning to the medical domain is the availability of training data. Data augmentation is a typical methodology used in machine learning when confronted with a limited data set. In a classical approach image transformations i.e. rotations, cropping and brightness changes are used. In this work, a StyleGAN2-ADA model of Generative Adversarial Networks is trained on the limited COVID-19 chest X-ray image set. After assessing the quality of generated images they are used to increase the training data set improving its balance between classes. We consider the multi-class classification problem of chest X-ray images including the COVID-19 positive class that hasn't been yet thoroughly explored in the literature. Results of transfer learning-based classification of COVID-19 chest X-ray images are presented. The performance of several deep convolutional neural network models is compared. The impact on the detection performance of classical image augmentations i.e. rotations, cropping, and brightness changes are studied. Furthermore, classical image augmentation is compared with GAN-based augmentation. The most accurate model is an EfficientNet-B0 with an accuracy of 90.2 percent, trained on a dataset with a simple class balancing. The GAN augmentation approach is found to be subpar to classical methods for the considered dataset.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09067v1","tag":"new-dataset"}}
{"title":"Revisiting k-NN for Pre-trained Language Models","abstract":"Pre-trained Language Models (PLMs), as parametric-based eager learners, have become the de-facto choice for current paradigms of Natural Language Processing (NLP). In contrast, k-Nearest-Neighbor (k-NN) classifiers, as the lazy learning paradigm, tend to mitigate over-fitting and isolated noise. In this paper, we revisit k-NN classifiers for augmenting the PLMs-based classifiers. From the methodological level, we propose to adopt k-NN with textual representations of PLMs in two steps: (1) Utilize k-NN as prior knowledge to calibrate the training process. (2) Linearly interpolate the probability distribution predicted by k-NN with that of the PLMs' classifier. At the heart of our approach is the implementation of k-NN-calibrated training, which treats predicted results as indicators for easy versus hard examples during the training process. From the perspective of the diversity of application scenarios, we conduct extensive experiments on fine-tuning, prompt-tuning paradigms and zero-shot, few-shot and fully-supervised settings, respectively, across eight diverse end-tasks. We hope our exploration will encourage the community to revisit the power of classical methods for efficient NLP\\footnote{Code and datasets are available in https://github.com/zjunlp/Revisit-KNN.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09058v1","tag":"new-dataset"}}
{"title":"CodeKGC: Code Language Model for Generative Knowledge Graph Construction","abstract":"Current generative knowledge graph construction approaches usually fail to capture structural knowledge by simply flattening natural language into serialized texts or a specification language. However, large generative language model trained on structured data such as code has demonstrated impressive capability in understanding natural language for structural prediction and reasoning tasks. Intuitively, we address the task of generative knowledge graph construction with code language model: given a code-format natural language input, the target is to generate triples which can be represented as code completion tasks. Specifically, we develop schema-aware prompts that effectively utilize the semantic structure within the knowledge graph. As code inherently possesses structure, such as class and function definitions, it serves as a useful model for prior semantic structural knowledge. Furthermore, we employ a rationale-enhanced generation method to boost the performance. Rationales provide intermediate steps, thereby improving knowledge extraction abilities. Experimental results indicate that the proposed approach can obtain better performance on benchmark datasets compared with baselines. Code and datasets are available in https://github.com/zjunlp/DeepKE/tree/main/example/llm.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09048v1","tag":"new-dataset"}}
{"title":"Adapter Learning in Pretrained Feature Extractor for Continual Learning of Diseases","abstract":"Currently intelligent diagnosis systems lack the ability of continually learning to diagnose new diseases once deployed, under the condition of preserving old disease knowledge. In particular, updating an intelligent diagnosis system with training data of new diseases would cause catastrophic forgetting of old disease knowledge. To address the catastrophic forgetting issue, a novel adapter-based strategy is proposed to help effectively learn a set of new diseases at each round (or task) of continual learning, without changing the shared feature extractor. The learnable lightweight task-specific adapter(s) can be flexibly designed (e.g., two convolutional layers) and then added to the pretrained and fixed feature extractor. Together with a specially designed task-specific head which absorbs all previously learned old diseases as a single 'out-of-distribution' category, task-specific adapter(s) can help the pretrained feature extractor more effectively extract discriminative features between diseases. In addition, a simple yet effective fine-tuning is applied to collaboratively fine-tune multiple task-specific heads such that outputs from different heads are comparable and consequently the appropriate classifier head can be more accurately selected during model inference. Extensive empirical evaluations on three image datasets demonstrate the superior performance of the proposed method in continual learning of new diseases. The source code will be released publicly.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09042v1","tag":"new-dataset"}}
{"title":"Knowledge Graph Building Blocks: An easy-to-use Framework for developing FAIREr Knowledge Graphs","abstract":"Knowledge graphs and ontologies provide promising technical solutions for implementing the FAIR Principles for Findable, Accessible, Interoperable, and Reusable data and metadata. However, they also come with their own challenges. Nine such challenges are discussed and associated with the criterion of cognitive interoperability and specific FAIREr principles (FAIR + Explorability raised) that they fail to meet. We introduce an easy-to-use, open source knowledge graph framework that is based on knowledge graph building blocks (KGBBs). KGBBs are small information modules for knowledge-processing, each based on a specific type of semantic unit. By interrelating several KGBBs, one can specify a KGBB-driven FAIREr knowledge graph. Besides implementing semantic units, the KGBB Framework clearly distinguishes and decouples an internal in-memory data model from data storage, data display, and data access/export models. We argue that this decoupling is essential for solving many problems of knowledge management systems. We discuss the architecture of the KGBB Framework as we envision it, comprising (i) an openly accessible KGBB-Repository for different types of KGBBs, (ii) a KGBB-Engine for managing and operating FAIREr knowledge graphs (including automatic provenance tracking, editing changelog, and versioning of semantic units); (iii) a repository for KGBB-Functions; (iv) a low-code KGBB-Editor with which domain experts can create new KGBBs and specify their own FAIREr knowledge graph without having to think about semantic modelling. We conclude with discussing the nine challenges and how the KGBB Framework provides solutions for the issues they raise. While most of what we discuss here is entirely conceptual, we can point to two prototypes that demonstrate the principle feasibility of using semantic units and KGBBs to manage and structure knowledge graphs.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09029v1","tag":"new-dataset"}}
{"title":"PaTeCon: A Pattern-Based Temporal Constraint Mining Method for Conflict Detection on Knowledge Graphs","abstract":"Temporal facts, the facts for characterizing events that hold in specific time periods, are attracting rising attention in the knowledge graph (KG) research communities. In terms of quality management, the introduction of time restrictions brings new challenges to maintaining the temporal consistency of KGs and detecting potential temporal conflicts. Previous studies rely on manually enumerated temporal constraints to detect conflicts, which are labor-intensive and may have granularity issues. We start from the common pattern of temporal facts and constraints and propose a pattern-based temporal constraint mining method, PaTeCon. PaTeCon uses automatically determined graph patterns and their relevant statistical information over the given KG instead of human experts to generate time constraints. Specifically, PaTeCon dynamically attaches class restriction to candidate constraints according to their measuring scores.We evaluate PaTeCon on two large-scale datasets based on Wikidata and Freebase respectively. The experimental results show that pattern-based automatic constraint mining is powerful in generating valuable temporal constraints.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09015v1","tag":"new-dataset"}}
{"title":"GUILGET: GUI Layout GEneration with Transformer","abstract":"Sketching out Graphical User Interface (GUI) layout is part of the pipeline of designing a GUI and a crucial task for the success of a software application. Arranging all components inside a GUI layout manually is a time-consuming task. In order to assist designers, we developed a method named GUILGET to automatically generate GUI layouts from positional constraints represented as GUI arrangement graphs (GUI-AGs). The goal is to support the initial step of GUI design by producing realistic and diverse GUI layouts. The existing image layout generation techniques often cannot incorporate GUI design constraints. Thus, GUILGET needs to adapt existing techniques to generate GUI layouts that obey to constraints specific to GUI designs. GUILGET is based on transformers in order to capture the semantic in relationships between elements from GUI-AG. Moreover, the model learns constraints through the minimization of losses responsible for placing each component inside its parent layout, for not letting components overlap if they are inside the same parent, and for component alignment. Our experiments, which are conducted on the CLAY dataset, reveal that our model has the best understanding of relationships from GUI-AG and has the best performances in most of evaluation metrics. Therefore, our work contributes to improved GUI layout generation by proposing a novel method that effectively accounts for the constraints on GUI elements and paves the road for a more efficient GUI design pipeline.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09012v1","tag":"new-dataset"}}
{"title":"CF-VAE: Causal Disentangled Representation Learning with VAE and Causal Flows","abstract":"Learning disentangled representations is important in representation learning, aiming to learn a low dimensional representation of data where each dimension corresponds to one underlying generative factor. Due to the possibility of causal relationships between generative factors, causal disentangled representation learning has received widespread attention. In this paper, we first propose a new flows that can incorporate causal structure information into the model, called causal flows. Based on the variational autoencoders(VAE) commonly used in disentangled representation learning, we design a new model, CF-VAE, which enhances the disentanglement ability of the VAE encoder by utilizing the causal flows. By further introducing the supervision of ground-truth factors, we demonstrate the disentanglement identifiability of our model. Experimental results on both synthetic and real datasets show that CF-VAE can achieve causal disentanglement and perform intervention experiments. Moreover, CF-VAE exhibits outstanding performance on downstream tasks and has the potential to learn causal structure among factors.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09010v1","tag":"new-dataset"}}
{"title":"A Biomedical Entity Extraction Pipeline for Oncology Health Records in Portuguese","abstract":"Textual health records of cancer patients are usually protracted and highly unstructured, making it very time-consuming for health professionals to get a complete overview of the patient's therapeutic course. As such limitations can lead to suboptimal and/or inefficient treatment procedures, healthcare providers would greatly benefit from a system that effectively summarizes the information of those records. With the advent of deep neural models, this objective has been partially attained for English clinical texts, however, the research community still lacks an effective solution for languages with limited resources. In this paper, we present the approach we developed to extract procedures, drugs, and diseases from oncology health records written in European Portuguese. This project was conducted in collaboration with the Portuguese Institute for Oncology which, besides holding over $10$ years of duly protected medical records, also provided oncologist expertise throughout the development of the project. Since there is no annotated corpus for biomedical entity extraction in Portuguese, we also present the strategy we followed in annotating the corpus for the development of the models. The final models, which combined a neural architecture with entity linking, achieved $F_1$ scores of $88.6$, $95.0$, and $55.8$ per cent in the mention extraction of procedures, drugs, and diseases, respectively.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08999v1","tag":"new-dataset"}}
{"title":"Parcel3D: Shape Reconstruction from Single RGB Images for Applications in Transportation Logistics","abstract":"We focus on enabling damage and tampering detection in logistics and tackle the problem of 3D shape reconstruction of potentially damaged parcels. As input we utilize single RGB images, which corresponds to use-cases where only simple handheld devices are available, e.g. for postmen during delivery or clients on delivery. We present a novel synthetic dataset, named Parcel3D, that is based on the Google Scanned Objects (GSO) dataset and consists of more than 13,000 images of parcels with full 3D annotations. The dataset contains intact, i.e. cuboid-shaped, parcels and damaged parcels, which were generated in simulations. We work towards detecting mishandling of parcels by presenting a novel architecture called CubeRefine R-CNN, which combines estimating a 3D bounding box with an iterative mesh refinement. We benchmark our approach on Parcel3D and an existing dataset of cuboid-shaped parcels in real-world scenarios. Our results show, that while training on Parcel3D enables transfer to the real world, enabling reliable deployment in real-world scenarios is still challenging. CubeRefine R-CNN yields competitive performance in terms of Mesh AP and is the only model that directly enables deformation assessment by 3D mesh comparison and tampering detection by comparing viewpoint invariant parcel side surface representations. Dataset and code are available at https://a-nau.github.io/parcel3d.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08994v1","tag":"new-dataset"}}
{"title":"Learning to Fuse Monocular and Multi-view Cues for Multi-frame Depth Estimation in Dynamic Scenes","abstract":"Multi-frame depth estimation generally achieves high accuracy relying on the multi-view geometric consistency. When applied in dynamic scenes, e.g., autonomous driving, this consistency is usually violated in the dynamic areas, leading to corrupted estimations. Many multi-frame methods handle dynamic areas by identifying them with explicit masks and compensating the multi-view cues with monocular cues represented as local monocular depth or features. The improvements are limited due to the uncontrolled quality of the masks and the underutilized benefits of the fusion of the two types of cues. In this paper, we propose a novel method to learn to fuse the multi-view and monocular cues encoded as volumes without needing the heuristically crafted masks. As unveiled in our analyses, the multi-view cues capture more accurate geometric information in static areas, and the monocular cues capture more useful contexts in dynamic areas. To let the geometric perception learned from multi-view cues in static areas propagate to the monocular representation in dynamic areas and let monocular cues enhance the representation of multi-view cost volume, we propose a cross-cue fusion (CCF) module, which includes the cross-cue attention (CCA) to encode the spatially non-local relative intra-relations from each source to enhance the representation of the other. Experiments on real-world datasets prove the significant effectiveness and generalization ability of the proposed method.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08993v1","tag":"new-dataset"}}
{"title":"A Comparison of Image Denoising Methods","abstract":"The advancement of imaging devices and countless images generated everyday pose an increasingly high demand on image denoising, which still remains a challenging task in terms of both effectiveness and efficiency. To improve denoising quality, numerous denoising techniques and approaches have been proposed in the past decades, including different transforms, regularization terms, algebraic representations and especially advanced deep neural network (DNN) architectures. Despite their sophistication, many methods may fail to achieve desirable results for simultaneous noise removal and fine detail preservation. In this paper, to investigate the applicability of existing denoising techniques, we compare a variety of denoising methods on both synthetic and real-world datasets for different applications. We also introduce a new dataset for benchmarking, and the evaluations are performed from four different perspectives including quantitative metrics, visual effects, human ratings and computational cost. Our experiments demonstrate: (i) the effectiveness and efficiency of representative traditional denoisers for various denoising tasks, (ii) a simple matrix-based algorithm may be able to produce similar results compared with its tensor counterparts, and (iii) the notable achievements of DNN models, which exhibit impressive generalization ability and show state-of-the-art performance on various datasets. In spite of the progress in recent years, we discuss shortcomings and possible extensions of existing techniques. Datasets, code and results are made publicly available and will be continuously updated at https://github.com/ZhaomingKong/Denoising-Comparison.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08990v1","tag":"new-dataset"}}
{"title":"Incremental Image Labeling via Iterative Refinement","abstract":"Data quality is critical for multimedia tasks, while various types of systematic flaws are found in image benchmark datasets, as discussed in recent work. In particular, the existence of the semantic gap problem leads to a many-to-many mapping between the information extracted from an image and its linguistic description. This unavoidable bias further leads to poor performance on current computer vision tasks. To address this issue, we introduce a Knowledge Representation (KR)-based methodology to provide guidelines driving the labeling process, thereby indirectly introducing intended semantics in ML models. Specifically, an iterative refinement-based annotation method is proposed to optimize data labeling by organizing objects in a classification hierarchy according to their visual properties, ensuring that they are aligned with their linguistic descriptions. Preliminary results verify the effectiveness of the proposed method.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08989v1","tag":"new-dataset"}}
{"title":"In ChatGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT","abstract":"The way users acquire information is undergoing a paradigm shift with the advent of ChatGPT. Unlike conventional search engines, ChatGPT retrieves knowledge from the model itself and generates answers for users. ChatGPT's impressive question-answering (QA) capability has attracted more than 100 million users within a short period of time but has also raised concerns regarding its reliability. In this paper, we perform the first large-scale measurement of ChatGPT's reliability in the generic QA scenario with a carefully curated set of 5,695 questions across ten datasets and eight domains. We find that ChatGPT's reliability varies across different domains, especially underperforming in law and science questions. We also demonstrate that system roles, originally designed by OpenAI to allow users to steer ChatGPT's behavior, can impact ChatGPT's reliability. We further show that ChatGPT is vulnerable to adversarial examples, and even a single character change can negatively affect its reliability in certain cases. We believe that our study provides valuable insights into ChatGPT's reliability and underscores the need for strengthening the reliability and security of large language models (LLMs).","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08979v1","tag":"new-dataset"}}
{"title":"Visual-LiDAR Odometry and Mapping with Monocular Scale Correction and Motion Compensation","abstract":"This paper presents a novel visual-LiDAR odometry and mapping method with low-drift characteristics. The proposed method is based on two popular approaches, ORB-SLAM and A-LOAM, with monocular scale correction and visual-assisted LiDAR motion compensation modifications. The scale corrector calculates the proportion between the depth of image keypoints recovered by triangulation and that provided by LiDAR, using an outlier rejection process for accuracy improvement. Concerning LiDAR motion compensation, the visual odometry approach gives the initial guesses of LiDAR motions for better performance. This methodology is not only applicable to high-resolution LiDAR but can also adapt to low-resolution LiDAR. To evaluate the proposed SLAM system's robustness and accuracy, we conducted experiments on the KITTI Odometry and S3E datasets. Experimental results illustrate that our method significantly outperforms standalone ORB-SLAM2 and A-LOAM. Furthermore, regarding the accuracy of visual odometry with scale correction, our method performs similarly to the stereo-mode ORB-SLAM2.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08978v1","tag":"new-dataset"}}
{"title":"Neural Architecture Search for Visual Anomaly Segmentation","abstract":"This paper presents AutoPatch, the first application of neural architecture search to the complex task of segmenting visual anomalies. Measurement of anomaly segmentation quality is challenging due to imbalanced anomaly pixels, varying region areas, and various types of anomalies. First, the weighted average precision (wAP) metric is proposed as an alternative to AUROC and AUPRO, which does not need to be limited to a specific maximum FPR. Second, a novel neural architecture search method is proposed, which enables efficient segmentation of visual anomalies without any training. By leveraging a pre-trained supernet, a black-box optimization algorithm can directly minimize FLOPS and maximize wAP on a small validation set of anomalous examples. Finally, compelling results on the widely studied MVTec [3] dataset are presented, demonstrating that AutoPatch outperforms the current state-of-the-art method PatchCore [12] with more than 18x fewer FLOPS, using only one example per anomaly type. These results highlight the potential of automated machine learning to optimize throughput in industrial quality control. The code for AutoPatch is available at: https://github.com/tommiekerssies/AutoPatch","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08975v1","tag":"new-dataset"}}
{"title":"From Words to Music: A Study of Subword Tokenization Techniques in Symbolic Music Generation","abstract":"Subword tokenization has been widely successful in text-based natural language processing (NLP) tasks with Transformer-based models. As Transformer models become increasingly popular in symbolic music-related studies, it is imperative to investigate the efficacy of subword tokenization in the symbolic music domain. In this paper, we explore subword tokenization techniques, such as byte-pair encoding (BPE), in symbolic music generation and its impact on the overall structure of generated songs. Our experiments are based on three types of MIDI datasets: single track-melody only, multi-track with a single instrument, and multi-track and multi-instrument. We apply subword tokenization on post-musical tokenization schemes and find that it enables the generation of longer songs at the same time and improves the overall structure of the generated music in terms of objective metrics like structure indicator (SI), Pitch Class Entropy, etc. We also compare two subword tokenization methods, BPE and Unigram, and observe that both methods lead to consistent improvements. Our study suggests that subword tokenization is a promising technique for symbolic music generation and may have broader implications for music composition, particularly in cases involving complex data such as multi-track songs.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08953v1","tag":"new-dataset"}}
{"title":"Enhancing Textbooks with Visuals from the Web for Improved Learning","abstract":"Textbooks are the primary vehicle for delivering quality education to students. It has been shown that explanatory or illustrative visuals play a key role in the retention, comprehension and the general transfer of knowledge. However, many textbooks, especially in the developing world, are low quality and lack interesting visuals to support student learning. In this paper, we investigate the effectiveness of vision-language models to automatically enhance textbooks with images from the web. Specifically, we collect a dataset of e-textbooks from one of the largest free online publishers in the world. We rigorously analyse the dataset, and use the resulting analysis to motivate a task that involves retrieving and appropriately assigning web images to textbooks, which we frame as a novel optimization problem. Through a crowd-sourced evaluation, we verify that (1) while the original textbook images are rated higher, automatically assigned ones are not far behind, and (2) the choice of the optimization problem matters. We release the dataset of textbooks with an associated image bank to spur further research in this area.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08931v1","tag":"new-dataset"}}
{"title":"ProGAP: Progressive Graph Neural Networks with Differential Privacy Guarantees","abstract":"Graph Neural Networks (GNNs) have become a popular tool for learning on graphs, but their widespread use raises privacy concerns as graph data can contain personal or sensitive information. Differentially private GNN models have been recently proposed to preserve privacy while still allowing for effective learning over graph-structured datasets. However, achieving an ideal balance between accuracy and privacy in GNNs remains challenging due to the intrinsic structural connectivity of graphs. In this paper, we propose a new differentially private GNN called ProGAP that uses a progressive training scheme to improve such accuracy-privacy trade-offs. Combined with the aggregation perturbation technique to ensure differential privacy, ProGAP splits a GNN into a sequence of overlapping submodels that are trained progressively, expanding from the first submodel to the complete model. Specifically, each submodel is trained over the privately aggregated node embeddings learned and cached by the previous submodels, leading to an increased expressive power compared to previous approaches while limiting the incurred privacy costs. We formally prove that ProGAP ensures edge-level and node-level privacy guarantees for both training and inference stages, and evaluate its performance on benchmark graph datasets. Experimental results demonstrate that ProGAP can achieve up to 5%-10% higher accuracy than existing state-of-the-art differentially private GNNs.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08928v1","tag":"new-dataset"}}
{"title":"Generalized Weak Supervision for Neural Information Retrieval","abstract":"Neural ranking models (NRMs) have demonstrated effective performance in several information retrieval (IR) tasks. However, training NRMs often requires large-scale training data, which is difficult and expensive to obtain. To address this issue, one can train NRMs via weak supervision, where a large dataset is automatically generated using an existing ranking model (called the weak labeler) for training NRMs. Weakly supervised NRMs can generalize from the observed data and significantly outperform the weak labeler. This paper generalizes this idea through an iterative re-labeling process, demonstrating that weakly supervised models can iteratively play the role of weak labeler and significantly improve ranking performance without using manually labeled data. The proposed Generalized Weak Supervision (GWS) solution is generic and orthogonal to the ranking model architecture. This paper offers four implementations of GWS: self-labeling, cross-labeling, joint cross- and self-labeling, and greedy multi-labeling. GWS also benefits from a query importance weighting mechanism based on query performance prediction methods to reduce noise in the generated training data. We further draw a theoretical connection between self-labeling and Expectation-Maximization. Our experiments on two passage retrieval benchmarks suggest that all implementations of GWS lead to substantial improvements compared to weak supervision in all cases.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08912v1","tag":"new-dataset"}}
{"title":"Towards Zero-Shot Personalized Table-to-Text Generation with Contrastive Persona Distillation","abstract":"Existing neural methods have shown great potentials towards generating informative text from structured tabular data as well as maintaining high content fidelity. However, few of them shed light on generating personalized expressions, which often requires well-aligned persona-table-text datasets that are difficult to obtain. To overcome these obstacles, we explore personalized table-to-text generation under a zero-shot setting, by assuming no well-aligned persona-table-text triples are required during training. To this end, we firstly collect a set of unpaired persona information and then propose a semi-supervised approach with contrastive persona distillation (S2P-CPD) to generate personalized context. Specifically, tabular data and persona information are firstly represented as latent variables separately. Then, we devise a latent space fusion technique to distill persona information into the table representation. Besides, a contrastive-based discriminator is employed to guarantee the style consistency between the generated context and its corresponding persona. Experimental results on two benchmarks demonstrate S2P-CPD's ability on keeping both content fidelity and personalized expressions.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08911v1","tag":"new-dataset"}}
{"title":"Multimodal Group Activity Dataset for Classroom Engagement Level Prediction","abstract":"We collected a new dataset that includes approximately eight hours of audiovisual recordings of a group of students and their self-evaluation scores for classroom engagement. The dataset and data analysis scripts are available on our open-source repository. We developed baseline face-based and group-activity-based image and video recognition models. Our image models yield 45-85% test accuracy with face-area inputs on person-based classification task. Our video models achieved up to 71% test accuracy on group-level prediction using group activity video inputs. In this technical report, we shared the details of our end-to-end human-centered engagement analysis pipeline from data collection to model development.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08901v1","tag":"new-dataset"}}
{"title":"Discreetly Exploiting Inter-session Information for Session-based Recommendation","abstract":"Limited intra-session information is the performance bottleneck of the early GNN based SBR models. Therefore, some GNN based SBR models have evolved to introduce additional inter-session information to facilitate the next-item prediction. However, we found that the introduction of inter-session information may bring interference to these models. The possible reasons are twofold. First, inter-session dependencies are not differentiated at the factor-level. Second, measuring inter-session weight by similarity is not enough. In this paper, we propose DEISI to solve the problems. For the first problem, DEISI differentiates the types of inter-session dependencies at the factor-level with the help of DRL technology. For the second problem, DEISI introduces stability as a new metric for weighting inter-session dependencies together with the similarity. Moreover, CL is used to improve the robustness of the model. Extensive experiments on three datasets show the superior performance of the DEISI model compared with the state-of-the-art models.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08894v1","tag":"new-dataset"}}
{"title":"Along the Margins: Marginalized Communities' Ethical Concerns about Social Platforms","abstract":"In this paper, we identified marginalized communities' ethical concerns about social platforms. We performed this identification because recent platform malfeasance indicates that software teams prioritize shareholder concerns over user concerns. Additionally, these platform shortcomings often have devastating effects on marginalized populations. We first scraped 586 marginalized communities' subreddits, aggregated a dataset of their social platform mentions and manually annotated mentions of ethical concerns in these data. We subsequently analyzed trends in the manually annotated data and tested the extent to which ethical concerns can be automatically classified by means of natural language processing (NLP). We found that marginalized communities' ethical concerns predominantly revolve around discrimination and misrepresentation, and reveal deficiencies in current software development practices. As such, researchers and developers could use our work to further investigate these concerns and rectify current software flaws.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08882v1","tag":"new-dataset"}}
{"title":"Segmentation of glioblastomas in early post-operative multi-modal MRI with deep neural networks","abstract":"Extent of resection after surgery is one of the main prognostic factors for patients diagnosed with glioblastoma. To achieve this, accurate segmentation and classification of residual tumor from post-operative MR images is essential. The current standard method for estimating it is subject to high inter- and intra-rater variability, and an automated method for segmentation of residual tumor in early post-operative MRI could lead to a more accurate estimation of extent of resection. In this study, two state-of-the-art neural network architectures for pre-operative segmentation were trained for the task. The models were extensively validated on a multicenter dataset with nearly 1000 patients, from 12 hospitals in Europe and the United States. The best performance achieved was a 61\\% Dice score, and the best classification performance was about 80\\% balanced accuracy, with a demonstrated ability to generalize across hospitals. In addition, the segmentation performance of the best models was on par with human expert raters. The predicted segmentations can be used to accurately classify the patients into those with residual tumor, and those with gross total resection.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08881v1","tag":"new-dataset"}}
{"title":"Dynamic Coarse-to-Fine Learning for Oriented Tiny Object Detection","abstract":"Detecting arbitrarily oriented tiny objects poses intense challenges to existing detectors, especially for label assignment. Despite the exploration of adaptive label assignment in recent oriented object detectors, the extreme geometry shape and limited feature of oriented tiny objects still induce severe mismatch and imbalance issues. Specifically, the position prior, positive sample feature, and instance are mismatched, and the learning of extreme-shaped objects is biased and unbalanced due to little proper feature supervision. To tackle these issues, we propose a dynamic prior along with the coarse-to-fine assigner, dubbed DCFL. For one thing, we model the prior, label assignment, and object representation all in a dynamic manner to alleviate the mismatch issue. For another, we leverage the coarse prior matching and finer posterior constraint to dynamically assign labels, providing appropriate and relatively balanced supervision for diverse instances. Extensive experiments on six datasets show substantial improvements to the baseline. Notably, we obtain the state-of-the-art performance for one-stage detectors on the DOTA-v1.5, DOTA-v2.0, and DIOR-R datasets under single-scale training and testing. Codes are available at https://github.com/Chasel-Tsui/mmrotate-dcfl.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08876v1","tag":"new-dataset"}}
{"title":"Dual-Ganularity Contrastive Learning for Session-based Recommendation","abstract":"Session-based recommendation systems(SBRS) are more suitable for the current e-commerce and streaming media recommendation scenarios and thus have become a hot topic. The data encountered by SBRS is typically highly sparse, which also serves as one of the bottlenecks limiting the accuracy of recommendations. So Contrastive Learning(CL) is applied in SBRS owing to its capability of improving embedding learning under the condition of sparse data. However, existing CL strategies are limited in their ability to enforce finer-grained (e.g., factor-level) comparisons and, as a result, are unable to capture subtle differences between instances. More than that, these strategies usually use item or segment dropout as a means of data augmentation which may result in sparser data and thus ineffective self-supervised signals. By addressing the two aforementioned limitations, we introduce a novel multi-granularity CL framework. Specifically, two extra augmented embedding convolution channels with different granularities are constructed and the embeddings learned by them are compared with those learned from original view to complete the CL tasks. At factor-level, we employ Disentangled Representation Learning to obtain finer-grained data(e.g. factor-level embeddings), with which we can construct factor-level convolution channels. At item-level, the star graph is deployed as the augmented data and graph convolution on it can ensure the effectiveness of self-supervised signals. Compare the learned embeddings of these two views with the learned embeddings of the basic view to achieve CL at two granularities. Finally, the more precise item-level and factor-level embeddings obtained are referenced to generate personalized recommendations for the user. The proposed model is validated through extensive experiments on two benchmark datasets, showcasing superior performance compared to existing methods.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08873v1","tag":"new-dataset"}}
{"title":"UPGPT: Universal Diffusion Model for Person Image Generation, Editing and Pose Transfer","abstract":"Existing person image generative models can do either image generation or pose transfer but not both. We propose a unified diffusion model, UPGPT to provide a universal solution to perform all the person image tasks - generative, pose transfer, and editing. With fine-grained multimodality and disentanglement capabilities, our approach offers fine-grained control over the generation and the editing process of images using a combination of pose, text, and image, all without needing a semantic segmentation mask which can be challenging to obtain or edit. We also pioneer the parameterized body SMPL model in pose-guided person image generation to demonstrate new capability - simultaneous pose and camera view interpolation while maintaining a person's appearance. Results on the benchmark DeepFashion dataset show that UPGPT is the new state-of-the-art while simultaneously pioneering new capabilities of edit and pose transfer in human image generation.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08870v1","tag":"new-dataset"}}
{"title":"Saliency-aware Stereoscopic Video Retargeting","abstract":"Stereo video retargeting aims to resize an image to a desired aspect ratio. The quality of retargeted videos can be significantly impacted by the stereo videos spatial, temporal, and disparity coherence, all of which can be impacted by the retargeting process. Due to the lack of a publicly accessible annotated dataset, there is little research on deep learning-based methods for stereo video retargeting. This paper proposes an unsupervised deep learning-based stereo video retargeting network. Our model first detects the salient objects and shifts and warps all objects such that it minimizes the distortion of the salient parts of the stereo frames. We use 1D convolution for shifting the salient objects and design a stereo video Transformer to assist the retargeting process. To train the network, we use the parallax attention mechanism to fuse the left and right views and feed the retargeted frames to a reconstruction module that reverses the retargeted frames to the input frames. Therefore, the network is trained in an unsupervised manner. Extensive qualitative and quantitative experiments and ablation studies on KITTI stereo 2012 and 2015 datasets demonstrate the efficiency of the proposed method over the existing state-of-the-art methods. The code is available at https://github.com/z65451/SVR/.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08852v1","tag":"new-dataset"}}
{"title":"PEGA: Personality-Guided Preference Aggregator for Ephemeral Group Recommendation","abstract":"Recently, making recommendations for ephemeral groups which contain dynamic users and few historic interactions have received an increasing number of attention. The main challenge of ephemeral group recommender is how to aggregate individual preferences to represent the group's overall preference. Score aggregation and preference aggregation are two commonly-used methods that adopt hand-craft predefined strategies and data-driven strategies, respectively. However, they neglect to take into account the importance of the individual inherent factors such as personality in the group. In addition, they fail to work well due to a small number of interactive records. To address these issues, we propose a Personality-Guided Preference Aggregator (PEGA) for ephemeral group recommendation. Concretely, we first adopt hyper-rectangle to define the concept of Group Personality. We then use the personality attention mechanism to aggregate group preferences. The role of personality in our approach is twofold: (1) To estimate individual users' importance in a group and provide explainability; (2) to alleviate the data sparsity issue that occurred in ephemeral groups. The experimental results demonstrate that our model significantly outperforms the state-of-the-art methods w.r.t. the score of both Recall and NDCG on Amazon and Yelp datasets.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08851v1","tag":"new-dataset"}}
{"title":"BadVFL: Backdoor Attacks in Vertical Federated Learning","abstract":"Federated learning (FL) enables multiple parties to collaboratively train a machine learning model without sharing their data; rather, they train their own model locally and send updates to a central server for aggregation. Depending on how the data is distributed among the participants, FL can be classified into Horizontal (HFL) and Vertical (VFL). In VFL, the participants share the same set of training instances but only host a different and non-overlapping subset of the whole feature space. Whereas in HFL, each participant shares the same set of features while the training set is split into locally owned training data subsets.   VFL is increasingly used in applications like financial fraud detection; nonetheless, very little work has analyzed its security. In this paper, we focus on robustness in VFL, in particular, on backdoor attacks, whereby an adversary attempts to manipulate the aggregate model during the training process to trigger misclassifications. Performing backdoor attacks in VFL is more challenging than in HFL, as the adversary i) does not have access to the labels during training and ii) cannot change the labels as she only has access to the feature embeddings. We present a first-of-its-kind clean-label backdoor attack in VFL, which consists of two phases: a label inference and a backdoor phase. We demonstrate the effectiveness of the attack on three different datasets, investigate the factors involved in its success, and discuss countermeasures to mitigate its impact.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08847v1","tag":"new-dataset"}}
{"title":"UDTIRI: An Open-Source Road Pothole Detection Benchmark Suite","abstract":"It is seen that there is enormous potential to leverage powerful deep learning methods in the emerging field of urban digital twins. It is particularly in the area of intelligent road inspection where there is currently limited research and data available. To facilitate progress in this field, we have developed a well-labeled road pothole dataset named Urban Digital Twins Intelligent Road Inspection (UDTIRI) dataset. We hope this dataset will enable the use of powerful deep learning methods in urban road inspection, providing algorithms with a more comprehensive understanding of the scene and maximizing their potential. Our dataset comprises 1000 images of potholes, captured in various scenarios with different lighting and humidity conditions. Our intention is to employ this dataset for object detection, semantic segmentation, and instance segmentation tasks. Our team has devoted significant effort to conducting a detailed statistical analysis, and benchmarking a selection of representative algorithms from recent years. We also provide a multi-task platform for researchers to fully exploit the performance of various algorithms with the support of UDTIRI dataset.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08842v1","tag":"new-dataset"}}
{"title":"Contact Tracing over Uncertain Indoor Positioning Data (Extended Version)","abstract":"Pandemics often cause dramatic losses of human lives and impact our societies in many aspects such as public health, tourism, and economy. To contain the spread of an epidemic like COVID-19, efficient and effective contact tracing is important, especially in indoor venues where the risk of infection is higher. In this work, we formulate and study a novel query called Indoor Contact Query (ICQ) over raw, uncertain indoor positioning data that digitalizes people's movements indoors. Given a query object o, e.g., a person confirmed to be a virus carrier, an ICQ analyzes uncertain indoor positioning data to find objects that most likely had close contact with o for a long period of time. To process ICQ, we propose a set of techniques. First, we design an enhanced indoor graph model to organize different types of data necessary for ICQ. Second, for indoor moving objects, we devise methods to determine uncertain regions and to derive positioning samples missing in the raw data. Third, we propose a query processing framework with a close contact determination method, a search algorithm, and the acceleration strategies. We conduct extensive experiments on synthetic and real datasets to evaluate our proposals. The results demonstrate the efficiency and effectiveness of our proposals.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08838v1","tag":"new-dataset"}}
{"title":"Making Thermal Imaging More Equitable and Accurate: Resolving Solar Loading Biases","abstract":"Thermal cameras and thermal point detectors are used to measure the temperature of human skin. These are important devices that are used everyday in clinical and mass screening settings, particularly in an epidemic. Unfortunately, despite the wide use of thermal sensors, the temperature estimates from thermal sensors do not work well in uncontrolled scene conditions. Previous work has studied the effect of wind and other environment factors on skin temperature, but has not considered the heating effect from sunlight, which is termed solar loading. Existing device manufacturers recommend that a subject who has been outdoors in sun re-acclimate to an indoor environment after a waiting period. The waiting period, up to 30 minutes, is insufficient for a rapid screening tool. Moreover, the error bias from solar loading is greater for darker skin tones since melanin absorbs solar radiation. This paper explores two approaches to address this problem. The first approach uses transient behavior of cooling to more quickly extrapolate the steady state temperature. A second approach explores the spatial modulation of solar loading, to propose single-shot correction with a wide-field thermal camera. A real world dataset comprising of thermal point, thermal image, subjective, and objective measurements of melanin is collected with statistical significance for the effect size observed. The single-shot correction scheme is shown to eliminate solar loading bias in the time of a typical frame exposure (33ms).","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08832v1","tag":"new-dataset"}}
{"title":"Perceive, Excavate and Purify: A Novel Object Mining Framework for Instance Segmentation","abstract":"Recently, instance segmentation has made great progress with the rapid development of deep neural networks. However, there still exist two main challenges including discovering indistinguishable objects and modeling the relationship between instances. To deal with these difficulties, we propose a novel object mining framework for instance segmentation. In this framework, we first introduce the semantics perceiving subnetwork to capture pixels that may belong to an obvious instance from the bottom up. Then, we propose an object excavating mechanism to discover indistinguishable objects. In the mechanism, preliminary perceived semantics are regarded as original instances with classifications and locations, and then indistinguishable objects around these original instances are mined, which ensures that hard objects are fully excavated. Next, an instance purifying strategy is put forward to model the relationship between instances, which pulls the similar instances close and pushes away different instances to keep intra-instance similarity and inter-instance discrimination. In this manner, the same objects are combined as the one instance and different objects are distinguished as independent instances. Extensive experiments on the COCO dataset show that the proposed approach outperforms state-of-the-art methods, which validates the effectiveness of the proposed object mining framework.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08826v1","tag":"new-dataset"}}
{"title":"Transfer to a Low-Resource Language via Close Relatives: The Case Study on Faroese","abstract":"Multilingual language models have pushed state-of-the-art in cross-lingual NLP transfer. The majority of zero-shot cross-lingual transfer, however, use one and the same massively multilingual transformer (e.g., mBERT or XLM-R) to transfer to all target languages, irrespective of their typological, etymological, and phylogenetic relations to other languages. In particular, readily available data and models of resource-rich sibling languages are often ignored. In this work, we empirically show, in a case study for Faroese -- a low-resource language from a high-resource language family -- that by leveraging the phylogenetic information and departing from the 'one-size-fits-all' paradigm, one can improve cross-lingual transfer to low-resource languages. In particular, we leverage abundant resources of other Scandinavian languages (i.e., Danish, Norwegian, Swedish, and Icelandic) for the benefit of Faroese. Our evaluation results show that we can substantially improve the transfer performance to Faroese by exploiting data and models of closely-related high-resource languages. Further, we release a new web corpus of Faroese and Faroese datasets for named entity recognition (NER), semantic text similarity (STS), and new language models trained on all Scandinavian languages.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08823v1","tag":"new-dataset"}}
{"title":"TTIDA: Controllable Generative Data Augmentation via Text-to-Text and Text-to-Image Models","abstract":"Data augmentation has been established as an efficacious approach to supplement useful information for low-resource datasets. Traditional augmentation techniques such as noise injection and image transformations have been widely used. In addition, generative data augmentation (GDA) has been shown to produce more diverse and flexible data. While generative adversarial networks (GANs) have been frequently used for GDA, they lack diversity and controllability compared to text-to-image diffusion models. In this paper, we propose TTIDA (Text-to-Text-to-Image Data Augmentation) to leverage the capabilities of large-scale pre-trained Text-to-Text (T2T) and Text-to-Image (T2I) generative models for data augmentation. By conditioning the T2I model on detailed descriptions produced by T2T models, we are able to generate photo-realistic labeled images in a flexible and controllable manner. Experiments on in-domain classification, cross-domain classification, and image captioning tasks show consistent improvements over other data augmentation baselines. Analytical studies in varied settings, including few-shot, long-tail, and adversarial, further reinforce the effectiveness of TTIDA in enhancing performance and increasing robustness.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08821v1","tag":"new-dataset"}}
{"title":"Motion-state Alignment for Video Semantic Segmentation","abstract":"In recent years, video semantic segmentation has made great progress with advanced deep neural networks. However, there still exist two main challenges \\ie, information inconsistency and computation cost. To deal with the two difficulties, we propose a novel motion-state alignment framework for video semantic segmentation to keep both motion and state consistency. In the framework, we first construct a motion alignment branch armed with an efficient decoupled transformer to capture dynamic semantics, guaranteeing region-level temporal consistency. Then, a state alignment branch composed of a stage transformer is designed to enrich feature spaces for the current frame to extract static semantics and achieve pixel-level state consistency. Next, by a semantic assignment mechanism, the region descriptor of each semantic category is gained from dynamic semantics and linked with pixel descriptors from static semantics. Benefiting from the alignment of these two kinds of effective information, the proposed method picks up dynamic and static semantics in a targeted way, so that video semantic regions are consistently segmented to obtain precise locations with low computational complexity. Extensive experiments on Cityscapes and CamVid datasets show that the proposed approach outperforms state-of-the-art methods and validates the effectiveness of the motion-state alignment framework.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08820v1","tag":"new-dataset"}}
{"title":"DILI: A Distribution-Driven Learned Index","abstract":"Targeting in-memory one-dimensional search keys, we propose a novel DIstribution-driven Learned Index tree (DILI), where a concise and computation-efficient linear regression model is used for each node. An internal node's key range is equally divided by its child nodes such that a key search enjoys perfect model prediction accuracy to find the relevant leaf node. A leaf node uses machine learning models to generate searchable data layout and thus accurately predicts the data record position for a key. To construct DILI, we first build a bottom-up tree with linear regression models according to global and local key distributions. Using the bottom-up tree, we build DILI in a top-down manner, individualizing the fanouts for internal nodes according to local distributions. DILI strikes a good balance between the number of leaf nodes and the height of the tree, two critical factors of key search time. Moreover, we design flexible algorithms for DILI to efficiently insert and delete keys and automatically adjust the tree structure when necessary. Extensive experimental results show that DILI outperforms the state-of-the-art alternatives on different kinds of workloads.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08817v1","tag":"new-dataset"}}
{"title":"MLP-AIR: An Efficient MLP-Based Method for Actor Interaction Relation Learning in Group Activity Recognition","abstract":"The task of Group Activity Recognition (GAR) aims to predict the activity category of the group by learning the actor spatial-temporal interaction relation in the group. Therefore, an effective actor relation learning method is crucial for the GAR task. The previous works mainly learn the interaction relation by the well-designed GCNs or Transformers. For example, to infer the actor interaction relation, GCNs need a learnable adjacency, and Transformers need to calculate the self-attention. Although the above methods can model the interaction relation effectively, they also increase the complexity of the model (the number of parameters and computations). In this paper, we design a novel MLP-based method for Actor Interaction Relation learning (MLP-AIR) in GAR. Compared with GCNs and Transformers, our method has a competitive but conceptually and technically simple alternative, significantly reducing the complexity. Specifically, MLP-AIR includes three sub-modules: MLP-based Spatial relation modeling module (MLP-S), MLP-based Temporal relation modeling module (MLP-T), and MLP-based Relation refining module (MLP-R). MLP-S is used to model the spatial relation between different actors in each frame. MLP-T is used to model the temporal relation between different frames for each actor. MLP-R is used further to refine the relation between different dimensions of relation features to improve the feature's expression ability. To evaluate the MLP-AIR, we conduct extensive experiments on two widely used benchmarks, including the Volleyball and Collective Activity datasets. Experimental results demonstrate that MLP-AIR can get competitive results but with low complexity.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08803v1","tag":"new-dataset"}}
{"title":"Neuromorphic computing for attitude estimation onboard quadrotors","abstract":"Compelling evidence has been given for the high energy efficiency and update rates of neuromorphic processors, with performance beyond what standard Von Neumann architectures can achieve. Such promising features could be advantageous in critical embedded systems, especially in robotics. To date, the constraints inherent in robots (e.g., size and weight, battery autonomy, available sensors, computing resources, processing time, etc.), and particularly in aerial vehicles, severely hamper the performance of fully-autonomous on-board control, including sensor processing and state estimation. In this work, we propose a spiking neural network (SNN) capable of estimating the pitch and roll angles of a quadrotor in highly dynamic movements from 6-degree of freedom Inertial Measurement Unit (IMU) data. With only 150 neurons and a limited training dataset obtained using a quadrotor in a real world setup, the network shows competitive results as compared to state-of-the-art, non-neuromorphic attitude estimators. The proposed architecture was successfully tested on the Loihi neuromorphic processor on-board a quadrotor to estimate the attitude when flying. Our results show the robustness of neuromorphic attitude estimation and pave the way towards energy-efficient, fully autonomous control of quadrotors with dedicated neuromorphic computing systems.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08802v1","tag":"new-dataset"}}
{"title":"Speaker Profiling in Multiparty Conversations","abstract":"In conversational settings, individuals exhibit unique behaviors, rendering a one-size-fits-all approach insufficient for generating responses by dialogue agents. Although past studies have aimed to create personalized dialogue agents using speaker persona information, they have relied on the assumption that the speaker's persona is already provided. However, this assumption is not always valid, especially when it comes to chatbots utilized in industries like banking, hotel reservations, and airline bookings. This research paper aims to fill this gap by exploring the task of Speaker Profiling in Conversations (SPC). The primary objective of SPC is to produce a summary of persona characteristics for each individual speaker present in a dialogue. To accomplish this, we have divided the task into three subtasks: persona discovery, persona-type identification, and persona-value extraction. Given a dialogue, the first subtask aims to identify all utterances that contain persona information. Subsequently, the second task evaluates these utterances to identify the type of persona information they contain, while the third subtask identifies the specific persona values for each identified type. To address the task of SPC, we have curated a new dataset named SPICE, which comes with specific labels. We have evaluated various baselines on this dataset and benchmarked it with a new neural model, SPOT, which we introduce in this paper. Furthermore, we present a comprehensive analysis of SPOT, examining the limitations of individual modules both quantitatively and qualitatively.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08801v1","tag":"new-dataset"}}
{"title":"Self-Supervised 3D Action Representation Learning with Skeleton Cloud Colorization","abstract":"3D Skeleton-based human action recognition has attracted increasing attention in recent years. Most of the existing work focuses on supervised learning which requires a large number of labeled action sequences that are often expensive and time-consuming to annotate. In this paper, we address self-supervised 3D action representation learning for skeleton-based action recognition. We investigate self-supervised representation learning and design a novel skeleton cloud colorization technique that is capable of learning spatial and temporal skeleton representations from unlabeled skeleton sequence data. We represent a skeleton action sequence as a 3D skeleton cloud and colorize each point in the cloud according to its temporal and spatial orders in the original (unannotated) skeleton sequence. Leveraging the colorized skeleton point cloud, we design an auto-encoder framework that can learn spatial-temporal features from the artificial color labels of skeleton joints effectively. Specifically, we design a two-steam pretraining network that leverages fine-grained and coarse-grained colorization to learn multi-scale spatial-temporal features.In addition, we design a Masked Skeleton Cloud Repainting task that can pretrain the designed auto-encoder framework to learn informative representations. We evaluate our skeleton cloud colorization approach with linear classifiers trained under different configurations, including unsupervised, semi-supervised, fully-supervised, and transfer learning settings. Extensive experiments on NTU RGB+D, NTU RGB+D 120, PKU-MMD, NW-UCLA, and UWA3D datasets show that the proposed method outperforms existing unsupervised and semi-supervised 3D action recognition methods by large margins and achieves competitive performance in supervised 3D action recognition as well.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08799v1","tag":"new-dataset"}}
{"title":"Deep Unrestricted Document Image Rectification","abstract":"In recent years, tremendous efforts have been made on document image rectification, but existing advanced algorithms are limited to processing restricted document images, i.e., the input images must incorporate a complete document. Once the captured image merely involves a local text region, its rectification quality is degraded and unsatisfactory. Our previously proposed DocTr, a transformer-assisted network for document image rectification, also suffers from this limitation. In this work, we present DocTr++, a novel unified framework for document image rectification, without any restrictions on the input distorted images. Our major technical improvements can be concluded in three aspects. Firstly, we upgrade the original architecture by adopting a hierarchical encoder-decoder structure for multi-scale representation extraction and parsing. Secondly, we reformulate the pixel-wise mapping relationship between the unrestricted distorted document images and the distortion-free counterparts. The obtained data is used to train our DocTr++ for unrestricted document image rectification. Thirdly, we contribute a real-world test set and metrics applicable for evaluating the rectification quality. To our best knowledge, this is the first learning-based method for the rectification of unrestricted document images. Extensive experiments are conducted, and the results demonstrate the effectiveness and superiority of our method. We hope our DocTr++ will serve as a strong baseline for generic document image rectification, prompting the further advancement and application of learning-based algorithms. The source code and the proposed dataset are publicly available at https://github.com/fh2019ustc/DocTr-Plus.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08796v1","tag":"new-dataset"}}
{"title":"Masked Language Model Based Textual Adversarial Example Detection","abstract":"Adversarial attacks are a serious threat to the reliable deployment of machine learning models in safety-critical applications. They can misguide current models to predict incorrectly by slightly modifying the inputs. Recently, substantial work has shown that adversarial examples tend to deviate from the underlying data manifold of normal examples, whereas pre-trained masked language models can fit the manifold of normal NLP data. To explore how to use the masked language model in adversarial detection, we propose a novel textual adversarial example detection method, namely Masked Language Model-based Detection (MLMD), which can produce clearly distinguishable signals between normal examples and adversarial examples by exploring the changes in manifolds induced by the masked language model. MLMD features a plug and play usage (i.e., no need to retrain the victim model) for adversarial defense and it is agnostic to classification tasks, victim model's architectures, and to-be-defended attack methods. We evaluate MLMD on various benchmark textual datasets, widely studied machine learning models, and state-of-the-art (SOTA) adversarial attacks (in total $3*4*4 = 48$ settings). Experimental results show that MLMD can achieve strong performance, with detection accuracy up to 0.984, 0.967, and 0.901 on AG-NEWS, IMDB, and SST-2 datasets, respectively. Additionally, MLMD is superior, or at least comparable to, the SOTA detection defenses in detection accuracy and F1 score. Among many defenses based on the off-manifold assumption of adversarial examples, this work offers a new angle for capturing the manifold change. The code for this work is openly accessible at \\url{https://github.com/mlmddetection/MLMDdetection}.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08767v1","tag":"new-dataset"}}
{"title":"Cashew dataset generation using augmentation and RaLSGAN and a transfer learning based tinyML approach towards disease detection","abstract":"Cashew is one of the most extensively consumed nuts in the world, and it is also known as a cash crop. A tree may generate a substantial yield in a few months and has a lifetime of around 70 to 80 years. Yet, in addition to the benefits, there are certain constraints to its cultivation. With the exception of parasites and algae, anthracnose is the most common disease affecting trees. When it comes to cashew, the dense structure of the tree makes it difficult to diagnose the disease with ease compared to short crops. Hence, we present a dataset that exclusively consists of healthy and diseased cashew leaves and fruits. The dataset is authenticated by adding RGB color transformation to highlight diseased regions, photometric and geometric augmentations, and RaLSGAN to enlarge the initial collection of images and boost performance in real-time situations when working with a constrained dataset. Further, transfer learning is used to test the classification efficiency of the dataset using algorithms such as MobileNet and Inception. TensorFlow lite is utilized to develop these algorithms for disease diagnosis utilizing drones in real-time. Several post-training optimization strategies are utilized, and their memory size is compared. They have proven their effectiveness by delivering high accuracy (up to 99%) and a decrease in memory and latency, making them ideal for use in applications with limited resources.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08766v1","tag":"new-dataset"}}
{"title":"A Survey on Biomedical Text Summarization with Pre-trained Language Model","abstract":"The exponential growth of biomedical texts such as biomedical literature and electronic health records (EHRs), provides a big challenge for clinicians and researchers to access clinical information efficiently. To address the problem, biomedical text summarization has been proposed to support clinical information retrieval and management, aiming at generating concise summaries that distill key information from single or multiple biomedical documents. In recent years, pre-trained language models (PLMs) have been the de facto standard of various natural language processing tasks in the general domain. Most recently, PLMs have been further investigated in the biomedical field and brought new insights into the biomedical text summarization task. In this paper, we systematically summarize recent advances that explore PLMs for biomedical text summarization, to help understand recent progress, challenges, and future directions. We categorize PLMs-based approaches according to how they utilize PLMs and what PLMs they use. We then review available datasets, recent approaches and evaluation metrics of the task. We finally discuss existing challenges and promising future directions. To facilitate the research community, we line up open resources including available datasets, recent approaches, codes, evaluation metrics, and the leaderboard in a public project: https://github.com/KenZLuo/Biomedical-Text-Summarization-Survey/tree/master.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08763v1","tag":"new-dataset"}}
{"title":"AutoTaskFormer: Searching Vision Transformers for Multi-task Learning","abstract":"Vision Transformers have shown great performance in single tasks such as classification and segmentation. However, real-world problems are not isolated, which calls for vision transformers that can perform multiple tasks concurrently. Existing multi-task vision transformers are handcrafted and heavily rely on human expertise. In this work, we propose a novel one-shot neural architecture search framework, dubbed AutoTaskFormer (Automated Multi-Task Vision TransFormer), to automate this process. AutoTaskFormer not only identifies the weights to share across multiple tasks automatically, but also provides thousands of well-trained vision transformers with a wide range of parameters (e.g., number of heads and network depth) for deployment under various resource constraints. Experiments on both small-scale (2-task Cityscapes and 3-task NYUv2) and large-scale (16-task Taskonomy) datasets show that AutoTaskFormer outperforms state-of-the-art handcrafted vision transformers in multi-task learning. The entire code and models will be open-sourced.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08756v1","tag":"new-dataset"}}
{"title":"Behavior Retrieval: Few-Shot Imitation Learning by Querying Unlabeled Datasets","abstract":"Enabling robots to learn novel visuomotor skills in a data-efficient manner remains an unsolved problem with myriad challenges. A popular paradigm for tackling this problem is through leveraging large unlabeled datasets that have many behaviors in them and then adapting a policy to a specific task using a small amount of task-specific human supervision (i.e. interventions or demonstrations). However, how best to leverage the narrow task-specific supervision and balance it with offline data remains an open question. Our key insight in this work is that task-specific data not only provides new data for an agent to train on but can also inform the type of prior data the agent should use for learning. Concretely, we propose a simple approach that uses a small amount of downstream expert data to selectively query relevant behaviors from an offline, unlabeled dataset (including many sub-optimal behaviors). The agent is then jointly trained on the expert and queried data. We observe that our method learns to query only the relevant transitions to the task, filtering out sub-optimal or task-irrelevant data. By doing so, it is able to learn more effectively from the mix of task-specific and offline data compared to naively mixing the data or only using the task-specific data. Furthermore, we find that our simple querying approach outperforms more complex goal-conditioned methods by 20% across simulated and real robotic manipulation tasks from images. See https://sites.google.com/view/behaviorretrieval for videos and code.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08742v1","tag":"new-dataset"}}
{"title":"EfficientNet Algorithm for Classification of Different Types of Cancer","abstract":"Accurate and efficient classification of different types of cancer is critical for early detection and effective treatment. In this paper, we present the results of our experiments using the EfficientNet algorithm for classification of brain tumor, breast cancer mammography, chest cancer, and skin cancer. We used publicly available datasets and preprocessed the images to ensure consistency and comparability. Our experiments show that the EfficientNet algorithm achieved high accuracy, precision, recall, and F1 scores on each of the cancer datasets, outperforming other state-of-the-art algorithms in the literature. We also discuss the strengths and weaknesses of the EfficientNet algorithm and its potential applications in clinical practice. Our results suggest that the EfficientNet algorithm is well-suited for classification of different types of cancer and can be used to improve the accuracy and efficiency of cancer diagnosis.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08715v1","tag":"new-dataset"}}
{"title":"Reynolds-number effects on the outer region of adverse-pressure-gradient turbulent boundary layers","abstract":"We study the Reynolds-number effects on the outer region of moderate adverse-pressure-gradient (APG) turbulent boundary layers (TBLs) and find that their small scale energy reduces with increasing friction Reynolds-number ($Re_{\\tau}$). The trend is based on analyzing APG TBL data across 600 $\\lesssim$ $Re_{\\tau}$ $\\lesssim$ 7000, and contrasts with the negligible variation in small scale energy noted for canonical wall flows. The datasets considered include those from a well-resolved numerical simulation (Pozuelo et al. 2022), which provides access to an APG TBL maintained at near-equilibrium conditions across 1000 $\\lesssim$ $Re_{\\tau}$ $\\lesssim$ 2000, with a well-defined flow history, and a new high-$Re_{\\tau}$ ($\\sim$ 7000) experimental study from the large Melbourne wind tunnel, with its long test section modified to permit development of an APG TBL from a 'canonical' upstream condition. The decrease in small scale energy with $Re_{\\tau}$ is revealed via decomposing the streamwise normal stresses into small and large scale contributions, based on a sharp spectral cut-off. The origin for this trend is traced back to the production of turbulent kinetic energy in an APG TBL, the small scale contribution to which is also found to decrease with $Re_{\\tau}$ in the outer region. The conclusion is reaffirmed by investigating attenuation of streamwise normal stresses due to changing spatial-resolutions of the numerical grid/hotwire sensors, which reduces with increasing $Re_{\\tau}$ and is found to be negligible at $Re_{\\tau}$ $\\sim$ 7000 in this study. The results emphasize that new scaling arguments and spatial-resolution correction schemes should be tested rigorously across a broad $Re_{\\tau}$ range, particularly for the outer region of pressure gradient TBLs.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08714v1","tag":"new-dataset"}}
{"title":"You Only Need Two Detectors to Achieve Multi-Modal 3D Multi-Object Tracking","abstract":"Firstly, a new multi-object tracking framework is proposed in this paper based on multi-modal fusion. By integrating object detection and multi-object tracking into the same model, this framework avoids the complex data association process in the classical TBD paradigm, and requires no additional training. Secondly, confidence of historical trajectory regression is explored, possible states of a trajectory in the current frame (weak object or strong object) are analyzed and a confidence fusion module is designed to guide non-maximum suppression of trajectory and detection for ordered association. Finally, extensive experiments are conducted on the KITTI and Waymo datasets. The results show that the proposed method can achieve robust tracking by using only two modal detectors and it is more accurate than many of the latest TBD paradigm-based multi-modal tracking methods. The source codes of the proposed method are available at https://github.com/wangxiyang2022/YONTD-MOT","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08709v1","tag":"new-dataset"}}
{"title":"A Voice Disease Detection Method Based on MFCCs and Shallow CNN","abstract":"The incidence rate of voice diseases is increasing year by year. The use of software for remote diagnosis is a technical development trend and has important practical value. Among voice diseases, common diseases that cause hoarseness include spasmodic dysphonia, vocal cord paralysis, vocal nodule, and vocal cord polyp. This paper presents a voice disease detection method that can be applied in a wide range of clinical. We cooperated with Xiangya Hospital of Central South University to collect voice samples from sixty-one different patients. The Mel Frequency Cepstrum Coefficient (MFCC) parameters are extracted as input features to describe the voice in the form of data. An innovative model combining MFCC parameters and single convolution layer CNN is proposed for fast calculation and classification. The highest accuracy we achieved was 92%, it is fully ahead of the original research results and internationally advanced. And we use Advanced Voice Function Assessment Databases (AVFAD) to evaluate the generalization ability of the method we proposed, which achieved an accuracy rate of 98%. Experiments on clinical and standard datasets show that for the pathological detection of voice diseases, our method has greatly improved in accuracy and computational efficiency.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08708v1","tag":"new-dataset"}}
{"title":"Looking Through the Glass: Neural Surface Reconstruction Against High Specular Reflections","abstract":"Neural implicit methods have achieved high-quality 3D object surfaces under slight specular highlights. However, high specular reflections (HSR) often appear in front of target objects when we capture them through glasses. The complex ambiguity in these scenes violates the multi-view consistency, then makes it challenging for recent methods to reconstruct target objects correctly. To remedy this issue, we present a novel surface reconstruction framework, NeuS-HSR, based on implicit neural rendering. In NeuS-HSR, the object surface is parameterized as an implicit signed distance function (SDF). To reduce the interference of HSR, we propose decomposing the rendered image into two appearances: the target object and the auxiliary plane. We design a novel auxiliary plane module by combining physical assumptions and neural networks to generate the auxiliary plane appearance. Extensive experiments on synthetic and real-world datasets demonstrate that NeuS-HSR outperforms state-of-the-art approaches for accurate and robust target surface reconstruction against HSR. Code is available at https://github.com/JiaxiongQ/NeuS-HSR.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08706v1","tag":"new-dataset"}}
{"title":"Learning Sim-to-Real Dense Object Descriptors for Robotic Manipulation","abstract":"It is crucial to address the following issues for ubiquitous robotics manipulation applications: (a) vision-based manipulation tasks require the robot to visually learn and understand the object with rich information like dense object descriptors; and (b) sim-to-real transfer in robotics aims to close the gap between simulated and real data. In this paper, we present Sim-to-Real Dense Object Nets (SRDONs), a dense object descriptor that not only understands the object via appropriate representation but also maps simulated and real data to a unified feature space with pixel consistency. We proposed an object-to-object matching method for image pairs from different scenes and different domains. This method helps reduce the effort of training data from real-world by taking advantage of public datasets, such as GraspNet. With sim-to-real object representation consistency, our SRDONs can serve as a building block for a variety of sim-to-real manipulation tasks. We demonstrate in experiments that pre-trained SRDONs significantly improve performances on unseen objects and unseen visual environments for various robotic tasks with zero real-world training.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08703v1","tag":"new-dataset"}}
{"title":"Reproducibility and FAIR Principles: The Case of a Segment Polarity Network Model","abstract":"The issue of reproducibility of computational models and the related FAIR principles (findable, accessible, interoperable, and reusable) are examined in a specific test case. I analyze a computational model of the segment polarity network in Drosophila embryos published in 2000. Despite the high number of citations to this publication, 23 years later the model is barely accessible, and consequently not interoperable. Following the text of the original publication allowed successfully encoding the model for the open source software COPASI. Subsequently saving the model in the SBML format allowed it to be reused in other open source software packages. Submission of this SBML encoding of the model to the BioModels database enables its findability and accessibility. This demonstrates how the FAIR principles can be successfully enabled by using open source software, widely adopted standards, and public repositories, facilitating reproducibility and reuse of computational cell biology models that will outlive the specific software used.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08688v1","tag":"new-dataset"}}
{"title":"GlobalMind: Global Multi-head Interactive Self-attention Network for Hyperspectral Change Detection","abstract":"High spectral resolution imagery of the Earth's surface enables users to monitor changes over time in fine-grained scale, playing an increasingly important role in agriculture, defense, and emergency response. However, most current algorithms are still confined to describing local features and fail to incorporate a global perspective, which limits their ability to capture interactions between global features, thus usually resulting in incomplete change regions. In this paper, we propose a Global Multi-head INteractive self-attention change Detection network (GlobalMind) to explore the implicit correlation between different surface objects and variant land cover transformations, acquiring a comprehensive understanding of the data and accurate change detection result. Firstly, a simple but effective Global Axial Segmentation (GAS) strategy is designed to expand the self-attention computation along the row space or column space of hyperspectral images, allowing the global connection with high efficiency. Secondly, with GAS, the global spatial multi-head interactive self-attention (Global-M) module is crafted to mine the abundant spatial-spectral feature involving potential correlations between the ground objects from the entire rich and complex hyperspectral space. Moreover, to acquire the accurate and complete cross-temporal changes, we devise a global temporal interactive multi-head self-attention (GlobalD) module which incorporates the relevance and variation of bi-temporal spatial-spectral features, deriving the integrate potential same kind of changes in the local and global range with the combination of GAS. We perform extensive experiments on five mostly used hyperspectral datasets, and our method outperforms the state-of-the-art algorithms with high accuracy and efficiency.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08687v1","tag":"new-dataset"}}
{"title":"Large-scale streaks in a turbulent bluff body wake","abstract":"A turbulent circular disk wake database (Chongsiripinyo \\& Sarkar, \\textit{J. Fluid Mech.}, vol. 885, 2020) at Reynolds number $\\textit{Re} = U_\\infty D/\\nu = 5 \\times 10^{4}$ is interrogated to identify the presence of large-scale streaks - coherent elongated regions of streamwise velocity. The unprecedented streamwise length - until $x/D \\approx 120$ - of the simulation enables investigation of the near and far wake. The near wake is dominated by the vortex shedding (VS) mode residing at azimuthal wavenumber $m=1$ and Strouhal number $\\textit{St} = 0.135$. After filtering out the VS structure, conclusive evidence of large-scale streaks with frequency $\\textit{St} \\rightarrow 0$, equivalently streamwise wavenumber $k_x \\rightarrow 0$ in the wake, becomes apparent in visualizations and spectra. These streaky structures are found throughout the simulation domain beyond $x/D \\approx 10$. Conditionally averaged streamwise vorticity fields reveal that the lift-up mechanism is active in the near as well as the far wake, and that ejections contribute more than sweep to events of intense $-u'_xu'_r$. Spectral proper orthogonal decomposition (SPOD) is employed to extract the energy and the spatiotemporal features of the large-scale streaks. The streak energy is concentrated in the $m=2$ azimuthal mode over the entire domain. Finally, bispectral mode decomposition (BMD) is conducted to reveal strong interaction between $m=1$ and $\\textit{St} = \\pm 0.135$ modes to give the $m=2, \\textit{St} = 0$ streak mode. Our results indicate that the self-interaction of the VS mode generates the $m=2, \\textit{St} = 0$ streamwise vortices, which leads to streak formation through the lift-up process. To the authors' knowledge, this is the first study that reports and characterizes large-scale low-frequency streaks and the associated lift-up mechanism in a turbulent wake.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08679v1","tag":"new-dataset"}}
{"title":"An end-to-end, interactive Deep Learning based Annotation system for cursive and print English handwritten text","abstract":"With the surging inclination towards carrying out tasks on computational devices and digital mediums, any method that converts a task that was previously carried out manually, to a digitized version, is always welcome. Irrespective of the various documentation tasks that can be done online today, there are still many applications and domains where handwritten text is inevitable, which makes the digitization of handwritten documents a very essential task. Over the past decades, there has been extensive research on offline handwritten text recognition. In the recent past, most of these attempts have shifted to Machine learning and Deep learning based approaches. In order to design more complex and deeper networks, and ensure stellar performances, it is essential to have larger quantities of annotated data. Most of the databases present for offline handwritten text recognition today, have either been manually annotated or semi automatically annotated with a lot of manual involvement. These processes are very time consuming and prone to human errors. To tackle this problem, we present an innovative, complete end-to-end pipeline, that annotates offline handwritten manuscripts written in both print and cursive English, using Deep Learning and User Interaction techniques. This novel method, which involves an architectural combination of a detection system built upon a state-of-the-art text detection model, and a custom made Deep Learning model for the recognition system, is combined with an easy-to-use interactive interface, aiming to improve the accuracy of the detection, segmentation, serialization and recognition phases, in order to ensure high quality annotated data with minimal human interaction.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08670v1","tag":"new-dataset"}}
{"title":"(LC)$^2$: LiDAR-Camera Loop Constraints For Cross-Modal Place Recognition","abstract":"Localization has been a challenging task for autonomous navigation. A loop detection algorithm must overcome environmental changes for the place recognition and re-localization of robots. Therefore, deep learning has been extensively studied for the consistent transformation of measurements into localization descriptors. Street view images are easily accessible; however, images are vulnerable to appearance changes. LiDAR can robustly provide precise structural information. However, constructing a point cloud database is expensive, and point clouds exist only in limited places. Different from previous works that train networks to produce shared embedding directly between the 2D image and 3D point cloud, we transform both data into 2.5D depth images for matching. In this work, we propose a novel cross-matching method, called (LC)$^2$, for achieving LiDAR localization without a prior point cloud map. To this end, LiDAR measurements are expressed in the form of range images before matching them to reduce the modality discrepancy. Subsequently, the network is trained to extract localization descriptors from disparity and range images. Next, the best matches are employed as a loop factor in a pose graph. Using public datasets that include multiple sessions in significantly different lighting conditions, we demonstrated that LiDAR-based navigation systems could be optimized from image databases and vice versa.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08660v1","tag":"new-dataset"}}
{"title":"Classification of US Supreme Court Cases using BERT-Based Techniques","abstract":"Models based on bidirectional encoder representations from transformers (BERT) produce state of the art (SOTA) results on many natural language processing (NLP) tasks such as named entity recognition (NER), part-of-speech (POS) tagging etc. An interesting phenomenon occurs when classifying long documents such as those from the US supreme court where BERT-based models can be considered difficult to use on a first-pass or out-of-the-box basis. In this paper, we experiment with several BERT-based classification techniques for US supreme court decisions or supreme court database (SCDB) and compare them with the previous SOTA results. We then compare our results specifically with SOTA models for long documents. We compare our results for two classification tasks: (1) a broad classification task with 15 categories and (2) a fine-grained classification task with 279 categories. Our best result produces an accuracy of 80\\% on the 15 broad categories and 60\\% on the fine-grained 279 categories which marks an improvement of 8\\% and 28\\% respectively from previously reported SOTA results.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08649v1","tag":"new-dataset"}}
{"title":"TAP: A Comprehensive Data Repository for Traffic Accident Prediction in Road Networks","abstract":"Road safety is a major global public health concern. Effective traffic crash prediction can play a critical role in reducing road traffic accidents. However, Existing machine learning approaches tend to focus on predicting traffic accidents in isolation, without considering the potential relationships between different accident locations within road networks. To incorporate graph structure information, graph-based approaches such as Graph Neural Networks (GNNs) can be naturally applied. However, applying GNNs to the accident prediction problem faces challenges due to the lack of suitable graph-structured traffic accident datasets. To bridge this gap, we have constructed a real-world graph-based Traffic Accident Prediction (TAP) data repository, along with two representative tasks: accident occurrence prediction and accident severity prediction. With nationwide coverage, real-world network topology, and rich geospatial features, this data repository can be used for a variety of traffic-related tasks. We further comprehensively evaluate eleven state-of-the-art GNN variants and two non-graph-based machine learning methods using the created datasets. Significantly facilitated by the proposed data, we develop a novel Traffic Accident Vulnerability Estimation via Linkage (TRAVEL) model, which is designed to capture angular and directional information from road networks. We demonstrate that the proposed model consistently outperforms the baselines. The data and code are available on GitHub (https://github.com/baixianghuang/travel).","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08640v1","tag":"new-dataset"}}
{"title":"Grouped feature screening for ultrahigh-dimensional classification via Gini distance correlation","abstract":"Gini distance correlation (GDC) was recently proposed to measure the dependence between a categorical variable, Y, and a numerical random vector, X. It mutually characterizes independence between X and Y. In this article, we utilize the GDC to establish a feature screening for ultrahigh-dimensional discriminant analysis where the response variable is categorical. It can be used for screening individual features as well as grouped features. The proposed procedure possesses several appealing properties. It is model-free. No model specification is needed. It holds the sure independence screening property and the ranking consistency property. The proposed screening method can also deal with the case that the response has divergent number of categories. We conduct several Monte Carlo simulation studies to examine the finite sample performance of the proposed screening procedure. Real data analysis for two real life datasets are illustrated.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08605v1","tag":"new-dataset"}}
{"title":"RS2G: Data-Driven Scene-Graph Extraction and Embedding for Robust Autonomous Perception and Scenario Understanding","abstract":"Human drivers naturally reason about interactions between road users to understand and safely navigate through traffic. Thus, developing autonomous vehicles necessitates the ability to mimic such knowledge and model interactions between road users to understand and navigate unpredictable, dynamic environments. However, since real-world scenarios often differ from training datasets, effectively modeling the behavior of various road users in an environment remains a significant research challenge. This reality necessitates models that generalize to a broad range of domains and explicitly model interactions between road users and the environment to improve scenario understanding. Graph learning methods address this problem by modeling interactions using graph representations of scenarios. However, existing methods cannot effectively transfer knowledge gained from the training domain to real-world scenarios. This constraint is caused by the domain-specific rules used for graph extraction that can vary in effectiveness across domains, limiting generalization ability. To address these limitations, we propose RoadScene2Graph (RS2G): a data-driven graph extraction and modeling approach that learns to extract the best graph representation of a road scene for solving autonomous scene understanding tasks. We show that RS2G enables better performance at subjective risk assessment than rule-based graph extraction methods and deep-learning-based models. RS2G also improves generalization and Sim2Real transfer learning, which denotes the ability to transfer knowledge gained from simulation datasets to unseen real-world scenarios. We also present ablation studies showing how RS2G produces a more useful graph representation for downstream classifiers. Finally, we show how RS2G can identify the relative importance of rule-based graph edges and enables intelligent graph sparsity tuning.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08600v1","tag":"new-dataset"}}
{"title":"eTOP: Early Termination of Pipelines for Faster Training of AutoML Systems","abstract":"Recent advancements in software and hardware technologies have enabled the use of AI/ML models in everyday applications has significantly improved the quality of service rendered. However, for a given application, finding the right AI/ML model is a complex and costly process, that involves the generation, training, and evaluation of multiple interlinked steps (called pipelines), such as data pre-processing, feature engineering, selection, and model tuning. These pipelines are complex (in structure) and costly (both in compute resource and time) to execute end-to-end, with a hyper-parameter associated with each step. AutoML systems automate the search of these hyper-parameters but are slow, as they rely on optimizing the pipeline's end output. We propose the eTOP Framework which works on top of any AutoML system and decides whether or not to execute the pipeline to the end or terminate at an intermediate step. Experimental evaluation on 26 benchmark datasets and integration of eTOPwith MLBox4 reduces the training time of the AutoML system upto 40x than baseline MLBox.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08597v1","tag":"new-dataset"}}
{"title":"Prophet: Conflict-Free Sharding Blockchain via Byzantine-Tolerant Deterministic Ordering","abstract":"Sharding scales throughput by splitting blockchain nodes into parallel groups. However, different shards' independent and random scheduling for cross-shard transactions results in numerous conflicts and aborts, since cross-shard transactions from different shards may access the same account. A deterministic ordering can eliminate conflicts by determining a global order for transactions before processing, as proved in the database field. Unfortunately, due to the intertwining of the Byzantine environment and information isolation among shards, there is no trusted party able to predetermine such an order for cross-shard transactions. To tackle this challenge, this paper proposes Prophet, a conflict-free sharding blockchain based on Byzantine-tolerant deterministic ordering. It first depends on untrusted self-organizing coalitions of nodes from different shards to pre-execute cross-shard transactions for prerequisite information about ordering. It then determines a trusted global order based on stateless ordering and post-verification for pre-executed results, through shard cooperation. Following the order, the shards thus orderly execute and commit transactions without conflicts. Prophet orchestrates the pre-execution, ordering, and execution processes in the sharding consensus for minimal overhead. We rigorously prove the determinism and serializability of transactions under the Byzantine and sharded environment. An evaluation of our prototype shows that Prophet improves the throughput by $3.11\\times$ and achieves nearly no aborts on 1 million Ethereum transactions compared with state-of-the-art sharding.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08595v1","tag":"new-dataset"}}
{"title":"AdaMTL: Adaptive Input-dependent Inference for Efficient Multi-Task Learning","abstract":"Modern Augmented reality applications require performing multiple tasks on each input frame simultaneously. Multi-task learning (MTL) represents an effective approach where multiple tasks share an encoder to extract representative features from the input frame, followed by task-specific decoders to generate predictions for each task. Generally, the shared encoder in MTL models needs to have a large representational capacity in order to generalize well to various tasks and input data, which has a negative effect on the inference latency. In this paper, we argue that due to the large variations in the complexity of the input frames, some computations might be unnecessary for the output. Therefore, we introduce AdaMTL, an adaptive framework that learns task-aware inference policies for the MTL models in an input-dependent manner. Specifically, we attach a task-aware lightweight policy network to the shared encoder and co-train it alongside the MTL model to recognize unnecessary computations. During runtime, our task-aware policy network decides which parts of the model to activate depending on the input frame and the target computational complexity. Extensive experiments on the PASCAL dataset demonstrate that AdaMTL reduces the computational complexity by 43% while improving the accuracy by 1.32% compared to single-task models. Combined with SOTA MTL methodologies, AdaMTL boosts the accuracy by 7.8% while improving the efficiency by 3.1X. When deployed on Vuzix M4000 smart glasses, AdaMTL reduces the inference latency and the energy consumption by up to 21.8% and 37.5%, respectively, compared to the static MTL model. Our code is publicly available at https://github.com/scale-lab/AdaMTL.git.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08594v1","tag":"new-dataset"}}
{"title":"Forecasting with Sparse but Informative Variables: A Case Study in Predicting Blood Glucose","abstract":"In time-series forecasting, future target values may be affected by both intrinsic and extrinsic effects. When forecasting blood glucose, for example, intrinsic effects can be inferred from the history of the target signal alone (\\textit{i.e.} blood glucose), but accurately modeling the impact of extrinsic effects requires auxiliary signals, like the amount of carbohydrates ingested. Standard forecasting techniques often assume that extrinsic and intrinsic effects vary at similar rates. However, when auxiliary signals are generated at a much lower frequency than the target variable (e.g., blood glucose measurements are made every 5 minutes, while meals occur once every few hours), even well-known extrinsic effects (e.g., carbohydrates increase blood glucose) may prove difficult to learn. To better utilize these \\textit{sparse but informative variables} (SIVs), we introduce a novel encoder/decoder forecasting approach that accurately learns the per-timepoint effect of the SIV, by (i) isolating it from intrinsic effects and (ii) restricting its learned effect based on domain knowledge. On a simulated dataset pertaining to the task of blood glucose forecasting, when the SIV is accurately recorded our approach outperforms baseline approaches in terms of rMSE (13.07 [95% CI: 11.77,14.16] vs. 14.14 [12.69,15.27]). In the presence of a corrupted SIV, the proposed approach can still result in lower error compared to the baseline but the advantage is reduced as noise increases. By isolating their effects and incorporating domain knowledge, our approach makes it possible to better utilize SIVs in forecasting.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08593v1","tag":"new-dataset"}}
{"title":"Researchers eye-view of sarcasm detection in social media textual content","abstract":"The enormous use of sarcastic text in all forms of communication in social media will have a physiological effect on target users. Each user has a different approach to misusing and recognising sarcasm. Sarcasm detection is difficult even for users, and this will depend on many things such as perspective, context, special symbols. So, that will be a challenging task for machines to differentiate sarcastic sentences from non-sarcastic sentences. There are no exact rules based on which model will accurately detect sarcasm from many text corpus in the current situation. So, one needs to focus on optimistic and forthcoming approaches in the sarcasm detection domain. This paper discusses various sarcasm detection techniques and concludes with some approaches, related datasets with optimal features, and the researcher's challenges.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08582v1","tag":"new-dataset"}}
{"title":"U2RLE: Uncertainty-Guided 2-Stage Room Layout Estimation","abstract":"While the existing deep learning-based room layout estimation techniques demonstrate good overall accuracy, they are less effective for distant floor-wall boundary. To tackle this problem, we propose a novel uncertainty-guided approach for layout boundary estimation introducing new two-stage CNN architecture termed U2RLE. The initial stage predicts both floor-wall boundary and its uncertainty and is followed by the refinement of boundaries with high positional uncertainty using a different, distance-aware loss. Finally, outputs from the two stages are merged to produce the room layout. Experiments using ZInD and Structure3D datasets show that U2RLE improves over current state-of-the-art, being able to handle both near and far walls better. In particular, U2RLE outperforms current state-of-the-art techniques for the most distant walls.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08580v1","tag":"new-dataset"}}
{"title":"Avatars Grow Legs: Generating Smooth Human Motion from Sparse Tracking Inputs with Diffusion Model","abstract":"With the recent surge in popularity of AR/VR applications, realistic and accurate control of 3D full-body avatars has become a highly demanded feature. A particular challenge is that only a sparse tracking signal is available from standalone HMDs (Head Mounted Devices), often limited to tracking the user's head and wrists. While this signal is resourceful for reconstructing the upper body motion, the lower body is not tracked and must be synthesized from the limited information provided by the upper body joints. In this paper, we present AGRoL, a novel conditional diffusion model specifically designed to track full bodies given sparse upper-body tracking signals. Our model is based on a simple multi-layer perceptron (MLP) architecture and a novel conditioning scheme for motion data. It can predict accurate and smooth full-body motion, particularly the challenging lower body movement. Unlike common diffusion architectures, our compact architecture can run in real-time, making it suitable for online body-tracking applications. We train and evaluate our model on AMASS motion capture dataset, and demonstrate that our approach outperforms state-of-the-art methods in generated motion accuracy and smoothness. We further justify our design choices through extensive experiments and ablation studies.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08577v1","tag":"new-dataset"}}
{"title":"GrOVe: Ownership Verification of Graph Neural Networks using Embeddings","abstract":"Graph neural networks (GNNs) have emerged as a state-of-the-art approach to model and draw inferences from large scale graph-structured data in various application settings such as social networking. The primary goal of a GNN is to learn an embedding for each graph node in a dataset that encodes both the node features and the local graph structure around the node. Embeddings generated by a GNN for a graph node are unique to that GNN. Prior work has shown that GNNs are prone to model extraction attacks. Model extraction attacks and defenses have been explored extensively in other non-graph settings. While detecting or preventing model extraction appears to be difficult, deterring them via effective ownership verification techniques offer a potential defense. In non-graph settings, fingerprinting models, or the data used to build them, have shown to be a promising approach toward ownership verification. We present GrOVe, a state-of-the-art GNN model fingerprinting scheme that, given a target model and a suspect model, can reliably determine if the suspect model was trained independently of the target model or if it is a surrogate of the target model obtained via model extraction. We show that GrOVe can distinguish between surrogate and independent models even when the independent model uses the same training dataset and architecture as the original target model. Using six benchmark datasets and three model architectures, we show that consistently achieves low false-positive and false-negative rates. We demonstrate that is robust against known fingerprint evasion techniques while remaining computationally efficient.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08566v1","tag":"new-dataset"}}
{"title":"Zenith-Angular Characteristics of Particles in EASs with $E_0 \\simeq 10^{18}$ eV According to the Yakutsk Array Data","abstract":"Particle lateral distributions were investigated in cosmic ray air showers with energy $E_0 \\simeq 10^{18}$ eV registered at the Yakutsk array with surface and underground scintillation detectors with $\\simeq 1 \\times \\sec\\theta$~GeV threshold during the period of continuous observations from 1986 to 2016. The analysis covers events with arrival direction zenith angles $\\theta \\le 60^{\\circ}$ within five intervals with step $\\Delta\\cos\\theta = 0.1$. Experimental values were compared to simulation results obtained with the use of CORSIKA code within the framework of QGSJet01 hadron interaction model. The whole dataset points at probable cosmic ray composition which is close to protons.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08561v1","tag":"new-dataset"}}
{"title":"Overcoming Repeated Testing Schedule Bias in Estimates of Disease Prevalence","abstract":"During the COVID-19 pandemic, many institutions such as universities and workplaces implemented testing regimens with every member of some population tested longitudinally, and those testing positive isolated for some time. Although the primary purpose of such regimens was to suppress disease spread by identifying and isolating infectious individuals, testing results were often also used to obtain prevalence and incidence estimates. Such estimates are helpful in risk assessment and institutional planning and various estimation procedures have been implemented, ranging from simple test-positive rates to complex dynamical modeling. Unfortunately, the popular test-positive rate is a biased estimator of prevalence under many seemingly innocuous longitudinal testing regimens with isolation. We illustrate how such bias arises and identify conditions under which the test-positive rate is unbiased. Further, we identify weaker conditions under which prevalence is identifiable and propose a new estimator of prevalence under longitudinal testing. We evaluate the proposed estimation procedure via simulation study and illustrate its use on a dataset derived by anonymizing testing data from The Ohio State University.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08559v1","tag":"new-dataset"}}
{"title":"FedGSM: Efficient Federated Learning for LEO Constellations with Gradient Staleness Mitigation","abstract":"Recent advancements in space technology have equipped low Earth Orbit (LEO) satellites with the capability to perform complex functions and run AI applications. Federated Learning (FL) on LEO satellites enables collaborative training of a global ML model without the need for sharing large datasets. However, intermittent connectivity between satellites and ground stations can lead to stale gradients and unstable learning, thereby limiting learning performance. In this paper, we propose FedGSM, a novel asynchronous FL algorithm that introduces a compensation mechanism to mitigate gradient staleness. FedGSM leverages the deterministic and time-varying topology of the orbits to offset the negative effects of staleness. Our simulation results demonstrate that FedGSM outperforms state-of-the-art algorithms for both IID and non-IID datasets, underscoring its effectiveness and advantages. We also investigate the effect of system parameters.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08537v1","tag":"new-dataset"}}
{"title":"Hybrid Materialization in a Disk-Based Column-Store","abstract":"In column-oriented query processing, a materialization strategy determines when lightweight positions (row IDs) are translated into tuples. It is an important part of column-store architecture, since it defines the class of supported query plans, and, therefore, impacts the overall system performance.   In this paper we continue investigating materialization strategies for a distributed disk-based column-store. We start with demonstrating cases when existing approaches impose fundamental limitations on the resulting system performance. Then, in order to address them, we propose a new hybrid materialization model. The main feature of hybrid materialization is the ability to manipulate both positions and values at the same time. This way, query engine can flexibly combine advantages of all the existing strategies and support a new class of query plans. Moreover, hybrid materialization allows the query engine to flexibly customize the materialization policy of individual attributes.   We describe our vision of how hybrid materialization can be implemented in a columnar system. As an example, we use PosDB~ -- a distributed, disk-based column-store. We present necessary data structures, the internals of a hybrid operator, and describe the algebra of such operators. Based on this implementation, we evaluate performance of late, ultra-late, and hybrid materialization strategies in several scenarios based on TPC-H queries. Our experiments demonstrate that hybrid materialization is almost two times faster than its counterparts, while providing a more flexible query model.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08532v1","tag":"new-dataset"}}
{"title":"STRAP: Structured Object Affordance Segmentation with Point Supervision","abstract":"With significant annotation savings, point supervision has been proven effective for numerous 2D and 3D scene understanding problems. This success is primarily attributed to the structured output space; i.e., samples with high spatial affinity tend to share the same labels. Sharing this spirit, we study affordance segmentation with point supervision, wherein the setting inherits an unexplored dual affinity-spatial affinity and label affinity. By label affinity, we refer to affordance segmentation as a multi-label prediction problem: A plate can be both holdable and containable. By spatial affinity, we refer to a universal prior that nearby pixels with similar visual features should share the same point annotation. To tackle label affinity, we devise a dense prediction network that enhances label relations by effectively densifying labels in a new domain (i.e., label co-occurrence). To address spatial affinity, we exploit a Transformer backbone for global patch interaction and a regularization loss. In experiments, we benchmark our method on the challenging CAD120 dataset, showing significant performance gains over prior methods.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08492v1","tag":"new-dataset"}}
{"title":"Delving into Shape-aware Zero-shot Semantic Segmentation","abstract":"Thanks to the impressive progress of large-scale vision-language pretraining, recent recognition models can classify arbitrary objects in a zero-shot and open-set manner, with a surprisingly high accuracy. However, translating this success to semantic segmentation is not trivial, because this dense prediction task requires not only accurate semantic understanding but also fine shape delineation and existing vision-language models are trained with image-level language descriptions. To bridge this gap, we pursue \\textbf{shape-aware} zero-shot semantic segmentation in this study. Inspired by classical spectral methods in the image segmentation literature, we propose to leverage the eigen vectors of Laplacian matrices constructed with self-supervised pixel-wise features to promote shape-awareness. Despite that this simple and effective technique does not make use of the masks of seen classes at all, we demonstrate that it out-performs a state-of-the-art shape-aware formulation that aligns ground truth and predicted edges during training. We also delve into the performance gains achieved on different datasets using different backbones and draw several interesting and conclusive observations: the benefits of promoting shape-awareness highly relates to mask compactness and language embedding locality. Finally, our method sets new state-of-the-art performance for zero-shot semantic segmentation on both Pascal and COCO, with significant margins. Code and models will be accessed at https://github.com/Liuxinyv/SAZS.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08491v1","tag":"new-dataset"}}
{"title":"Affordances from Human Videos as a Versatile Representation for Robotics","abstract":"Building a robot that can understand and learn to interact by watching humans has inspired several vision problems. However, despite some successful results on static datasets, it remains unclear how current models can be used on a robot directly. In this paper, we aim to bridge this gap by leveraging videos of human interactions in an environment centric manner. Utilizing internet videos of human behavior, we train a visual affordance model that estimates where and how in the scene a human is likely to interact. The structure of these behavioral affordances directly enables the robot to perform many complex tasks. We show how to seamlessly integrate our affordance model with four robot learning paradigms including offline imitation learning, exploration, goal-conditioned learning, and action parameterization for reinforcement learning. We show the efficacy of our approach, which we call VRB, across 4 real world environments, over 10 different tasks, and 2 robotic platforms operating in the wild. Results, visualizations and videos at https://robo-affordances.github.io/","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08488v1","tag":"new-dataset"}}
{"title":"BenchMD: A Benchmark for Modality-Agnostic Learning on Medical Images and Sensors","abstract":"Medical data poses a daunting challenge for AI algorithms: it exists in many different modalities, experiences frequent distribution shifts, and suffers from a scarcity of examples and labels. Recent advances, including transformers and self-supervised learning, promise a more universal approach that can be applied flexibly across these diverse conditions. To measure and drive progress in this direction, we present BenchMD: a benchmark that tests how modality-agnostic methods, including architectures and training techniques (e.g. self-supervised learning, ImageNet pretraining), perform on a diverse array of clinically-relevant medical tasks. BenchMD combines 19 publicly available datasets for 7 medical modalities, including 1D sensor data, 2D images, and 3D volumetric scans. Our benchmark reflects real-world data constraints by evaluating methods across a range of dataset sizes, including challenging few-shot settings that incentivize the use of pretraining. Finally, we evaluate performance on out-of-distribution data collected at different hospitals than the training data, representing naturally-occurring distribution shifts that frequently degrade the performance of medical AI models. Our baseline results demonstrate that no modality-agnostic technique achieves strong performance across all modalities, leaving ample room for improvement on the benchmark. Code is released at https://github.com/rajpurkarlab/BenchMD .","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08486v1","tag":"new-dataset"}}
{"title":"Visual Instruction Tuning","abstract":"Instruction tuning large language models (LLMs) using machine-generated instruction-following data has improved zero-shot capabilities on new tasks, but the idea is less explored in the multimodal field. In this paper, we present the first attempt to use language-only GPT-4 to generate multimodal language-image instruction-following data. By instruction tuning on such generated data, we introduce LLaVA: Large Language and Vision Assistant, an end-to-end trained large multimodal model that connects a vision encoder and LLM for general-purpose visual and language understanding.Our early experiments show that LLaVA demonstrates impressive multimodel chat abilities, sometimes exhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and yields a 85.1% relative score compared with GPT-4 on a synthetic multimodal instruction-following dataset. When fine-tuned on Science QA, the synergy of LLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53%. We make GPT-4 generated visual instruction tuning data, our model and code base publicly available.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08485v1","tag":"new-dataset"}}
{"title":"Text2Performer: Text-Driven Human Video Generation","abstract":"Text-driven content creation has evolved to be a transformative technique that revolutionizes creativity. Here we study the task of text-driven human video generation, where a video sequence is synthesized from texts describing the appearance and motions of a target performer. Compared to general text-driven video generation, human-centric video generation requires maintaining the appearance of synthesized human while performing complex motions. In this work, we present Text2Performer to generate vivid human videos with articulated motions from texts. Text2Performer has two novel designs: 1) decomposed human representation and 2) diffusion-based motion sampler. First, we decompose the VQVAE latent space into human appearance and pose representation in an unsupervised manner by utilizing the nature of human videos. In this way, the appearance is well maintained along the generated frames. Then, we propose continuous VQ-diffuser to sample a sequence of pose embeddings. Unlike existing VQ-based methods that operate in the discrete space, continuous VQ-diffuser directly outputs the continuous pose embeddings for better motion modeling. Finally, motion-aware masking strategy is designed to mask the pose embeddings spatial-temporally to enhance the temporal coherence. Moreover, to facilitate the task of text-driven human video generation, we contribute a Fashion-Text2Video dataset with manually annotated action labels and text descriptions. Extensive experiments demonstrate that Text2Performer generates high-quality human videos (up to 512x256 resolution) with diverse appearances and flexible motions.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08483v1","tag":"new-dataset"}}
{"title":"On Learning Time Series Summary DAGs: A Frequency Domain Approach","abstract":"The fields of time series and graphical models emerged and advanced separately. Previous work on the structure learning of continuous and real-valued time series utilizes the time domain, with a focus on either structural autoregressive models or linear (non-)Gaussian Bayesian Networks. In contrast, we propose a novel frequency domain approach to identify a topological ordering and learn the structure of both real and complex-valued multivariate time series. In particular, we define a class of complex-valued Structural Causal Models (cSCM) at each frequency of the Fourier transform of the time series. Assuming that the time series is generated from the transfer function model, we show that the topological ordering and corresponding summary directed acyclic graph can be uniquely identified from cSCM. The performance of our algorithm is investigated using simulation experiments and real datasets.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08482v1","tag":"new-dataset"}}
{"title":"Neural Map Prior for Autonomous Driving","abstract":"High-definition (HD) semantic maps are crucial for autonomous vehicles navigating urban environments. Traditional offline HD maps, created through labor-intensive manual annotation processes, are both costly and incapable of accommodating timely updates. Recently, researchers have proposed inferring local maps based on online sensor observations; however, this approach is constrained by the sensor perception range and is susceptible to occlusions. In this work, we propose Neural Map Prior (NMP), a neural representation of global maps that facilitates automatic global map updates and improves local map inference performance. To incorporate the strong map prior into local map inference, we employ cross-attention that dynamically captures correlations between current features and prior features. For updating the global neural map prior, we use a learning-based fusion module to guide the network in fusing features from previous traversals. This design allows the network to capture a global neural map prior during sequential online map predictions. Experimental results on the nuScenes dataset demonstrate that our framework is highly compatible with various map segmentation and detection architectures and considerably strengthens map prediction performance, even under adverse weather conditions and across longer horizons. To the best of our knowledge, this represents the first learning-based system for constructing a global map prior.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08481v1","tag":"new-dataset"}}
{"title":"Learning to Render Novel Views from Wide-Baseline Stereo Pairs","abstract":"We introduce a method for novel view synthesis given only a single wide-baseline stereo image pair. In this challenging regime, 3D scene points are regularly observed only once, requiring prior-based reconstruction of scene geometry and appearance. We find that existing approaches to novel view synthesis from sparse observations fail due to recovering incorrect 3D geometry and due to the high cost of differentiable rendering that precludes their scaling to large-scale training. We take a step towards resolving these shortcomings by formulating a multi-view transformer encoder, proposing an efficient, image-space epipolar line sampling scheme to assemble image features for a target ray, and a lightweight cross-attention-based renderer. Our contributions enable training of our method on a large-scale real-world dataset of indoor and outdoor scenes. We demonstrate that our method learns powerful multi-view geometry priors while reducing the rendering time. We conduct extensive comparisons on held-out test scenes across two real-world datasets, significantly outperforming prior work on novel view synthesis from sparse image observations and achieving multi-view-consistent novel view synthesis.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08463v1","tag":"new-dataset"}}
{"title":"LongForm: Optimizing Instruction Tuning for Long Text Generation with Corpus Extraction","abstract":"Instruction tuning enables language models to generalize more effectively and better follow user intent. However, obtaining instruction data can be costly and challenging. Prior works employ methods such as expensive human annotation, crowd-sourced datasets with alignment issues, or generating noisy examples via LLMs. We introduce the LongForm dataset, which is created by leveraging English corpus examples with augmented instructions. We select a diverse set of human-written documents from existing corpora such as C4 and Wikipedia and generate instructions for the given documents via LLMs. This approach provides a cheaper and cleaner instruction-tuning dataset and one suitable for long text generation. We finetune T5, OPT, and LLaMA models on our dataset and show that even smaller LongForm models have good generalization capabilities for text generation. Our models outperform 10x larger language models without instruction tuning on various tasks such as story/recipe generation and long-form question answering. Moreover, LongForm models outperform prior instruction-tuned models such as FLAN-T5 and Alpaca by a large margin. Finally, our models can effectively follow and answer multilingual instructions; we demonstrate this for news generation. We publicly release our data and models: https://github.com/akoksal/LongForm.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08460v1","tag":"new-dataset"}}
{"title":"Efficient Video Action Detection with Token Dropout and Context Refinement","abstract":"Streaming video clips with large-scale video tokens impede vision transformers (ViTs) for efficient recognition, especially in video action detection where sufficient spatiotemporal representations are required for precise actor identification. In this work, we propose an end-to-end framework for efficient video action detection (EVAD) based on vanilla ViTs. Our EVAD consists of two specialized designs for video action detection. First, we propose a spatiotemporal token dropout from a keyframe-centric perspective. In a video clip, we maintain all tokens from its keyframe, preserve tokens relevant to actor motions from other frames, and drop out the remaining tokens in this clip. Second, we refine scene context by leveraging remaining tokens for better recognizing actor identities. The region of interest (RoI) in our action detector is expanded into temporal domain. The captured spatiotemporal actor identity representations are refined via scene context in a decoder with the attention mechanism. These two designs make our EVAD efficient while maintaining accuracy, which is validated on three benchmark datasets (i.e., AVA, UCF101-24, JHMDB). Compared to the vanilla ViT backbone, our EVAD reduces the overall GFLOPs by 43% and improves real-time inference speed by 40% with no performance degradation. Moreover, even at similar computational costs, our EVAD can improve the performance by 1.0 mAP with higher resolution inputs. Code is available at https://github.com/MCG-NJU/EVAD.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08451v1","tag":"new-dataset"}}
{"title":"ImpressionGPT: An Iterative Optimizing Framework for Radiology Report Summarization with ChatGPT","abstract":"The 'Impression' section of a radiology report is a critical basis for communication between radiologists and other physicians, and it is typically written by radiologists based on the 'Findings' section. However, writing numerous impressions can be laborious and error-prone for radiologists. Although recent studies have achieved promising results in automatic impression generation using large-scale medical text data for pre-training and fine-tuning pre-trained language models, such models often require substantial amounts of medical text data and have poor generalization performance. While large language models (LLMs) like ChatGPT have shown strong generalization capabilities and performance, their performance in specific domains, such as radiology, remains under-investigated and potentially limited. To address this limitation, we propose ImpressionGPT, which leverages the in-context learning capability of LLMs by constructing dynamic contexts using domain-specific, individualized data. This dynamic prompt approach enables the model to learn contextual knowledge from semantically similar examples from existing data. Additionally, we design an iterative optimization algorithm that performs automatic evaluation on the generated impression results and composes the corresponding instruction prompts to further optimize the model. The proposed ImpressionGPT model achieves state-of-the-art performance on both MIMIC-CXR and OpenI datasets without requiring additional training data or fine-tuning the LLMs. This work presents a paradigm for localizing LLMs that can be applied in a wide range of similar application scenarios, bridging the gap between general-purpose LLMs and the specific language processing needs of various domains.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08448v1","tag":"new-dataset"}}
{"title":"RadarFormer: Lightweight and Accurate Real-Time Radar Object Detection Model","abstract":"The performance of perception systems developed for autonomous driving vehicles has seen significant improvements over the last few years. This improvement was associated with the increasing use of LiDAR sensors and point cloud data to facilitate the task of object detection and recognition in autonomous driving. However, LiDAR and camera systems show deteriorating performances when used in unfavorable conditions like dusty and rainy weather. Radars on the other hand operate on relatively longer wavelengths which allows for much more robust measurements in these conditions. Despite that, radar-centric data sets do not get a lot of attention in the development of deep learning techniques for radar perception. In this work, we consider the radar object detection problem, in which the radar frequency data is the only input into the detection framework. We further investigate the challenges of using radar-only data in deep learning models. We propose a transformers-based model, named RadarFormer, that utilizes state-of-the-art developments in vision deep learning. Our model also introduces a channel-chirp-time merging module that reduces the size and complexity of our models by more than 10 times without compromising accuracy. Comprehensive experiments on the CRUW radar dataset demonstrate the advantages of the proposed method. Our RadarFormer performs favorably against the state-of-the-art methods while being 2x faster during inference and requiring only one-tenth of their model parameters. The code associated with this paper is available at https://github.com/YahiDar/RadarFormer.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08447v1","tag":"new-dataset"}}
{"title":"Inverse design of next-generation superconductors using data-driven deep generative models","abstract":"Over the past few decades, finding new superconductors with a high critical temperature ($T_c$) has been a challenging task due to computational and experimental costs. In this work, we present a diffusion model inspired by the computer vision community to generate new superconductors with unique structures and chemical compositions. Specifically, we used a crystal diffusion variational autoencoder (CDVAE) along with atomistic line graph neural network (ALIGNN) pretrained models and the Joint Automated Repository for Various Integrated Simulations (JARVIS) superconducting database of density functional theory (DFT) calculations to generate new superconductors with a high success rate. We started with a DFT dataset of $\\approx$1000 superconducting materials to train the diffusion model. We used the model to generate 3000 new structures, which along with pre-trained ALIGNN screening results in 62 candidates. For the top candidate structures, we carried out further DFT calculations to validate our findings. Such approaches go beyond the typical funnel-like materials design approaches and allow for the inverse design of next-generation materials.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08446v2","tag":"new-dataset"}}
{"title":"The MiniPile Challenge for Data-Efficient Language Models","abstract":"The ever-growing diversity of pre-training text corpora has equipped language models with generalization capabilities across various downstream tasks. However, such diverse datasets are often too large for academic budgets; hence, most research on Transformer architectures, training procedures, optimizers, etc. gets conducted on smaller, homogeneous datasets. To this end, we present The MiniPile Challenge, where one pre-trains a language model on a diverse text corpus containing at most 1M documents. MiniPile is a 6GB subset of the deduplicated 825GB The Pile corpus. To curate MiniPile, we perform a simple, three-step data filtering process: we (1) infer embeddings for all documents of the Pile, (2) cluster the embedding space using $k$-means, and (3) filter out low-quality clusters. To verify MiniPile's suitability for language model pre-training, we use it to pre-train a BERT and T5 model, yielding a performance drop of only $1.9\\%$/$2.5\\%$ on the GLUE and SNI benchmarks compared to the original pre-trained checkpoints trained on $2.6$x/$745$x the amount of data. MiniPile is available at https://huggingface.co/datasets/JeanKaddour/minipile.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08442v1","tag":"new-dataset"}}
{"title":"Multimodal Short Video Rumor Detection System Based on Contrastive Learning","abstract":"With short video platforms becoming one of the important channels for news sharing, major short video platforms in China have gradually become new breeding grounds for fake news. However, it is not easy to distinguish short video rumors due to the great amount of information and features contained in short videos, as well as the serious homogenization and similarity of features among videos. In order to mitigate the spread of short video rumors, our group decides to detect short video rumors by constructing multimodal feature fusion and introducing external knowledge after considering the advantages and disadvantages of each algorithm. The ideas of detection are as follows: (1) dataset creation: to build a short video dataset with multiple features; (2) multimodal rumor detection model: firstly, we use TSN (Temporal Segment Networks) video coding model to extract video features; then, we use OCR (Optical Character Recognition) and ASR (Automatic Character Recognition) to extract video features. Recognition) and ASR (Automatic Speech Recognition) fusion to extract text, and then use the BERT model to fuse text features with video features (3) Finally, use contrast learning to achieve distinction: first crawl external knowledge, then use the vector database to achieve the introduction of external knowledge and the final structure of the classification output. Our research process is always oriented to practical needs, and the related knowledge results will play an important role in many practical scenarios such as short video rumor identification and social opinion control.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08401v2","tag":"new-dataset"}}
{"title":"Code-centric Learning-based Just-In-Time Vulnerability Detection","abstract":"Attacks against computer systems exploiting software vulnerabilities can cause substantial damage to the cyber-infrastructure of our modern society and economy. To minimize the consequences, it is vital to detect and fix vulnerabilities as soon as possible. Just-in-time vulnerability detection (JIT-VD) discovers vulnerability-prone (\"dangerous\") commits to prevent them from being merged into source code and causing vulnerabilities. By JIT-VD, the commits' authors, who understand the commits properly, can review these dangerous commits and fix them if necessary while the relevant modifications are still fresh in their minds. In this paper, we propose CodeJIT, a novel code-centric learning-based approach for just-in-time vulnerability detection. The key idea of CodeJIT is that the meaning of the code changes of a commit is the direct and deciding factor for determining if the commit is dangerous for the code. Based on that idea, we design a novel graph-based representation to represent the semantics of code changes in terms of both code structures and program dependencies. A graph neural network model is developed to capture the meaning of the code changes represented by our graph-based representation and learn to discriminate between dangerous and safe commits. We conducted experiments to evaluate the JIT-VD performance of CodeJIT on a dataset of 20K+ dangerous and safe commits in 506 real-world projects from 1998 to 2022. Our results show that CodeJIT significantly improves the state-of-the-art JIT-VD methods by up to 66% in Recall, 136% in Precision, and 68% in F1. Moreover, CodeJIT correctly classifies nearly 9/10 of dangerous/safe (benign) commits and even detects 69 commits that fix a vulnerability yet produce other issues in source code","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08396v1","tag":"new-dataset"}}
{"title":"Progressive Visual Prompt Learning with Contrastive Feature Re-formation","abstract":"Prompt learning has been designed as an alternative to fine-tuning for adapting Vision-language (V-L) models to the downstream tasks. Previous works mainly focus on text prompt while visual prompt works are limited for V-L models. The existing visual prompt methods endure either mediocre performance or unstable training process, indicating the difficulty of visual prompt learning. In this paper, we propose a new Progressive Visual Prompt (ProVP) structure to strengthen the interactions among prompts of different layers. More importantly, our ProVP could effectively propagate the image embeddings to deep layers and behave partially similar to an instance adaptive prompt method. To alleviate generalization deterioration, we further propose a new contrastive feature re-formation, which prevents the serious deviation of the prompted visual feature from the fixed CLIP visual feature distribution. Combining both, our method (ProVP-Ref) is evaluated on 11 image benchmark datasets and achieves 7/11 state-of-theart results on both few-shot and base-to-novel settings. To the best of our knowledge, we are the first to demonstrate the superior performance of visual prompts in V-L models to previous prompt-based methods in downstream tasks. Meanwhile, it implies that our ProVP-Ref shows the best capability to adapt and to generalize.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08386v1","tag":"new-dataset"}}
{"title":"MELT: Mutual Enhancement of Long-Tailed User and Item for Sequential Recommendation","abstract":"The long-tailed problem is a long-standing challenge in Sequential Recommender Systems (SRS) in which the problem exists in terms of both users and items. While many existing studies address the long-tailed problem in SRS, they only focus on either the user or item perspective. However, we discover that the long-tailed user and item problems exist at the same time, and considering only either one of them leads to sub-optimal performance of the other one. In this paper, we propose a novel framework for SRS, called Mutual Enhancement of Long-Tailed user and item (MELT), that jointly alleviates the long-tailed problem in the perspectives of both users and items. MELT consists of bilateral branches each of which is responsible for long-tailed users and items, respectively, and the branches are trained to mutually enhance each other, which is trained effectively by a curriculum learning-based training. MELT is model-agnostic in that it can be seamlessly integrated with existing SRS models. Extensive experiments on eight datasets demonstrate the benefit of alleviating the long-tailed problems in terms of both users and items even without sacrificing the performance of head users and items, which has not been achieved by existing methods. To the best of our knowledge, MELT is the first work that jointly alleviates the long-tailed user and item problems in SRS.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08382v1","tag":"new-dataset"}}
{"title":"What Makes a Good Dataset for Symbol Description Reading?","abstract":"The usage of mathematical formulas as concise representations of a document's key ideas is common practice. Correctly interpreting these formulas, by identifying mathematical symbols and extracting their descriptions, is an important task in document understanding. This paper makes the following contributions to the mathematical identifier description reading (MIDR) task:   (i) introduces the Math Formula Question Answering Dataset (MFQuAD) with $7508$ annotated identifier occurrences;   (ii) describes novel variations of the noun phrase ranking approach for the MIDR task;   (iii) reports experimental results for the SOTA noun phrase ranking approach and our novel variations of the approach, providing problem insights and a performance baseline;   (iv) provides a position on the features that make an effective dataset for the MIDR task.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08352v1","tag":"new-dataset"}}
{"title":"VALOR: Vision-Audio-Language Omni-Perception Pretraining Model and Dataset","abstract":"In this paper, we propose a Vision-Audio-Language Omni-peRception pretraining model (VALOR) for multi-modal understanding and generation. Different from widely-studied vision-language pretraining models, VALOR jointly models relationships of vision, audio and language in an end-to-end manner. It contains three separate encoders for single modality representations, and a decoder for multimodal conditional text generation. We design two pretext tasks to pretrain VALOR model, including Multimodal Grouping Alignment (MGA) and Multimodal Grouping Captioning (MGC). MGA projects vision, language and audio to the same common space, building vision-language, audio-language and audiovisual-language alignment simultaneously. MGC learns how to generate text tokens in conditions of vision, audio or their both. To promote vision-audio-language pretraining research, we construct a large-scale high-quality tri-modality dataset named VALOR-1M, which contains 1M audiable videos with human annotated audiovisual captions. Extensive experiments show that VALOR can learn strong multimodal correlations and be generalized to various downstream tasks (e.g., retrieval, captioning and question answering), with different input modalities (e.g., vision-language, audio-language and audiovisual-language). VALOR achieves new state-of-the-art performances on series of public cross-modality benchmarks. Code and data are available at project page https://casia-iva-group.github.io/projects/VALOR.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08345v1","tag":"new-dataset"}}
{"title":"LED: A Dataset for Life Event Extraction from Dialogs","abstract":"Lifelogging has gained more attention due to its wide applications, such as personalized recommendations or memory assistance. The issues of collecting and extracting personal life events have emerged. People often share their life experiences with others through conversations. However, extracting life events from conversations is rarely explored. In this paper, we present Life Event Dialog, a dataset containing fine-grained life event annotations on conversational data. In addition, we initiate a novel conversational life event extraction task and differentiate the task from the public event extraction or the life event extraction from other sources like microblogs. We explore three information extraction (IE) frameworks to address the conversational life event extraction task: OpenIE, relation extraction, and event extraction. A comprehensive empirical analysis of the three baselines is established. The results suggest that the current event extraction model still struggles with extracting life events from human daily conversations. Our proposed life event dialog dataset and in-depth analysis of IE frameworks will facilitate future research on life event extraction from conversations.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08327v1","tag":"new-dataset"}}
{"title":"Updates to ALMA Site Properties: using the ESO-Allegro Phase RMS database -- ALMA Memo 624","abstract":"We present a long-term overview of the atmospheric phase stability at the Atacama Large Millimeter/submillimeter Array (ALMA) site, using >5 years of data, that acts as the successor to the studies summarized two decades ago by Evans et al 2003. Importantly, we explore the atmospheric variations, the `phase RMS', and associated metadata of over 17000 accrued ALMA observations taken since Cycle 3 (2015) by using the Bandpass calibrator source scans. We indicate the temporal phase RMS trends for average baseline lengths of 500, 1000, 5000, and 10000m, in contrast to the old stability studies that used a single 300m baseline phase monitor system. At the ALMA site, on the Chajnantor plateau, we report the diurnal variations and monthly changes in the phase RMS on ALMA relevant baselines lengths, measured directly from data, and we reaffirm such trends in atmospheric transmission (via Precipitable Water Vapour - PWV). We confirm that day observations have respectively higher phase RMS and PWV in contrast to night, while the monthly variations show Chilean winter (June - August) providing the best, high-frequency and long-baseline observing conditions - low (stable) phase RMS and low PWV. Yet, not all good phase stability condition occur when the PWV is low. Measurements of the phase RMS as a function of short timescales, 30 to 240s, that tie with typical target source scan times, and as a function of baseline length indicate that phase variations are smaller for short timescales and baselines and larger for longer timescales and baselines. We illustrate that fast-switching phase-referencing techniques, that allow short target scan times, could work well in reducing the phase RMS to suitable levels specifically for high-frequencies (Band 8, 9 and 10), long-baselines, and the two combined.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08318v1","tag":"new-dataset"}}
{"title":"SDVRF: Sparse-to-Dense Voxel Region Fusion for Multi-modal 3D Object Detection","abstract":"In the perception task of autonomous driving, multi-modal methods have become a trend due to the complementary characteristics of LiDAR point clouds and image data. However, the performance of previous methods is usually limited by the sparsity of the point cloud or the noise problem caused by the misalignment between LiDAR and the camera. To solve these two problems, we present a new concept, Voxel Region (VR), which is obtained by projecting the sparse local point clouds in each voxel dynamically. And we propose a novel fusion method, named Sparse-to-Dense Voxel Region Fusion (SDVRF). Specifically, more pixels of the image feature map inside the VR are gathered to supplement the voxel feature extracted from sparse points and achieve denser fusion. Meanwhile, different from prior methods, which project the size-fixed grids, our strategy of generating dynamic regions achieves better alignment and avoids introducing too much background noise. Furthermore, we propose a multi-scale fusion framework to extract more contextual information and capture the features of objects of different sizes. Experiments on the KITTI dataset show that our method improves the performance of different baselines, especially on classes of small size, including Pedestrian and Cyclist.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08304v1","tag":"new-dataset"}}
{"title":"Refusion: Enabling Large-Size Realistic Image Restoration with Latent-Space Diffusion Models","abstract":"This work aims to improve the applicability of diffusion models in realistic image restoration. Specifically, we enhance the diffusion model in several aspects such as network architecture, noise level, denoising steps, training image size, and optimizer/scheduler. We show that tuning these hyperparameters allows us to achieve better performance on both distortion and perceptual scores. We also propose a U-Net based latent diffusion model which performs diffusion in a low-resolution latent space while preserving high-resolution information from the original input for the decoding process. Compared to the previous latent-diffusion model which trains a VAE-GAN to compress the image, our proposed U-Net compression strategy is significantly more stable and can recover highly accurate images without relying on adversarial optimization. Importantly, these modifications allow us to apply diffusion models to various image restoration tasks, including real-world shadow removal, HR non-homogeneous dehazing, stereo super-resolution, and bokeh effect transformation. By simply replacing the datasets and slightly changing the noise network, our model, named Refusion, is able to deal with large-size images (e.g., 6000 x 4000 x 3 in HR dehazing) and produces good results on all the above restoration problems. Our Refusion achieves the best perceptual performance in the NTIRE 2023 Image Shadow Removal Challenge and wins 2nd place overall.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08291v1","tag":"new-dataset"}}
{"title":"Exploring 360-Degree View of Customers for Lookalike Modeling","abstract":"Lookalike models are based on the assumption that user similarity plays an important role towards product selling and enhancing the existing advertising campaigns from a very large user base. Challenges associated to these models reside on the heterogeneity of the user base and its sparsity. In this work, we propose a novel framework that unifies the customers different behaviors or features such as demographics, buying behaviors on different platforms, customer loyalty behaviors and build a lookalike model to improve customer targeting for Rakuten Group, Inc. Extensive experiments on real e-commerce and travel datasets demonstrate the effectiveness of our proposed lookalike model for user targeting task.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.09105v1","tag":"new-dataset"}}
{"title":"Toward Auto-evaluation with Confidence-based Category Relation-aware Regression","abstract":"Auto-evaluation aims to automatically evaluate a trained model on any test dataset without human annotations. Most existing methods utilize global statistics of features extracted by the model as the representation of a dataset. This ignores the influence of the classification head and loses category-wise confusion information of the model. However, ratios of instances assigned to different categories together with their confidence scores reflect how many instances in which categories are difficult for the model to classify, which contain significant indicators for both overall and category-wise performances. In this paper, we propose a Confidence-based Category Relation-aware Regression ($C^2R^2$) method. $C^2R^2$ divides all instances in a meta-set into different categories according to their confidence scores and extracts the global representation from them. For each category, $C^2R^2$ encodes its local confusion relations to other categories into a local representation. The overall and category-wise performances are regressed from global and local representations, respectively. Extensive experiments show the effectiveness of our method.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08288v1","tag":"new-dataset"}}
{"title":"DIALITE: Discover, Align and Integrate Open Data Tables","abstract":"We demonstrate a novel table discovery pipeline called DIALITE that allows users to discover, integrate and analyze open data tables. DIALITE has three main stages. First, it allows users to discover tables from open data platforms using state-of-the-art table discovery techniques. Second, DIALITE integrates the discovered tables to produce an integrated table. Finally, it allows users to analyze the integration result by applying different downstreaming tasks over it. Our pipeline is flexible such that the user can easily add and compare additional discovery and integration algorithms.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08285v1","tag":"new-dataset"}}
{"title":"MoDA: Modeling Deformable 3D Objects from Casual Videos","abstract":"In this paper, we focus on the challenges of modeling deformable 3D objects from casual videos. With the popularity of neural radiance fields (NeRF), many works extend it to dynamic scenes with a canonical NeRF and a deformation model that achieves 3D point transformation between the observation space and the canonical space. Recent works rely on linear blend skinning (LBS) to achieve the canonical-observation transformation. However, the linearly weighted combination of rigid transformation matrices is not guaranteed to be rigid. As a matter of fact, unexpected scale and shear factors often appear. In practice, using LBS as the deformation model can always lead to skin-collapsing artifacts for bending or twisting motions. To solve this problem, we propose neural dual quaternion blend skinning (NeuDBS) to achieve 3D point deformation, which can perform rigid transformation without skin-collapsing artifacts. Besides, we introduce a texture filtering approach for texture rendering that effectively minimizes the impact of noisy colors outside target deformable objects. Extensive experiments on real and synthetic datasets show that our approach can reconstruct 3D models for humans and animals with better qualitative and quantitative performance than state-of-the-art methods.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08279v1","tag":"new-dataset"}}
{"title":"Spectroscopic age estimates for 180 000 APOGEE red-giant stars: Precise spatial and kinematic trends with age in the Galactic disc","abstract":"Over the last few years, many studies have found an empirical relationship between the abundance of a star and its age. Here we estimate spectroscopic stellar ages for 178 825 red-giant stars observed by the APOGEE survey with a median statistical uncertainty of 17%. To this end, we use the supervised machine learning technique XGBoost, trained on a high-quality dataset of 3 060 red-giant and red-clump stars with asteroseismic ages observed by both APOGEE and Kepler. After verifying the obtained age estimates with independent catalogues, we investigate some of the classical chemical, positional, and kinematic relationships of the stars as a function of their age. We find a very clear imprint of the outer-disc flare in the age maps and confirm the recently found split in the local age-metallicity relation. We present new and precise measurements of the Galactic radial metallicity gradient in small age bins between 0.5 and 12 Gyr, confirming a steeper metallicity gradient for 2-5 Gyr old populations and a subsequent flattening for older populations mostly produced by radial migration. In addition, we analyse the dispersion about the abundance gradient as a function of age. We find a clear power-law trend (with an exponent $\\beta\\approx0.15$) for this relation, indicating a smooth radial migration history in the Galactic disc over the past 7-9 Gyr. Departures from this power law are detected at ages of 8 Gyr (possibly related to the Gaia Sausage/Enceladus merger) and 2.75 Gyr (possibly related to an enhancement of the star-formation rate in the Galactic disc). Finally, we confirm previous measurements showing a steepening in the age-velocity dispersion relation at around 9 Gyr, but now extending it over a large extent of the Galactic disc (5 kpc < RGal < 13 kpc). [Abridged]","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08276v1","tag":"new-dataset"}}
{"title":"About latent roles in forecasting players in team sports","abstract":"Forecasting players in sports has grown in popularity due to the potential for a tactical advantage and the applicability of such research to multi-agent interaction systems. Team sports contain a significant social component that influences interactions between teammates and opponents. However, it still needs to be fully exploited. In this work, we hypothesize that each participant has a specific function in each action and that role-based interaction is critical for predicting players' future moves. We create RolFor, a novel end-to-end model for Role-based Forecasting. RolFor uses a new module we developed called Ordering Neural Networks (OrderNN) to permute the order of the players such that each player is assigned to a latent role. The latent role is then modeled with a RoleGCN. Thanks to its graph representation, it provides a fully learnable adjacency matrix that captures the relationships between roles and is subsequently used to forecast the players' future trajectories. Extensive experiments on a challenging NBA basketball dataset back up the importance of roles and justify our goal of modeling them using optimizable models. When an oracle provides roles, the proposed RolFor compares favorably to the current state-of-the-art (it ranks first in terms of ADE and second in terms of FDE errors). However, training the end-to-end RolFor incurs the issues of differentiability of permutation methods, which we experimentally review. Finally, this work restates differentiable ranking as a difficult open problem and its great potential in conjunction with graph-based interaction models. Project is available at: https://www.pinlab.org/aboutlatentroles","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08272v2","tag":"new-dataset"}}
{"title":"Open-World Weakly-Supervised Object Localization","abstract":"While remarkable success has been achieved in weakly-supervised object localization (WSOL), current frameworks are not capable of locating objects of novel categories in open-world settings. To address this issue, we are the first to introduce a new weakly-supervised object localization task called OWSOL (Open-World Weakly-Supervised Object Localization). During training, all labeled data comes from known categories and, both known and novel categories exist in the unlabeled data. To handle such data, we propose a novel paradigm of contrastive representation co-learning using both labeled and unlabeled data to generate a complete G-CAM (Generalized Class Activation Map) for object localization, without the requirement of bounding box annotation. As no class label is available for the unlabelled data, we conduct clustering over the full training set and design a novel multiple semantic centroids-driven contrastive loss for representation learning. We re-organize two widely used datasets, i.e., ImageNet-1K and iNatLoc500, and propose OpenImages150 to serve as evaluation benchmarks for OWSOL. Extensive experiments demonstrate that the proposed method can surpass all baselines by a large margin. We believe that this work can shift the close-set localization towards the open-world setting and serve as a foundation for subsequent works. Code will be released at https://github.com/ryylcc/OWSOL.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08271v1","tag":"new-dataset"}}
{"title":"Dumpy: A Compact and Adaptive Index for Large Data Series Collections","abstract":"Data series indexes are necessary for managing and analyzing the increasing amounts of data series collections that are nowadays available. These indexes support both exact and approximate similarity search, with approximate search providing high-quality results within milliseconds, which makes it very attractive for certain modern applications. Reducing the pre-processing (i.e., index building) time and improving the accuracy of search results are two major challenges. DSTree and the iSAX index family are state-of-the-art solutions for this problem. However, DSTree suffers from long index building times, while iSAX suffers from low search accuracy. In this paper, we identify two problems of the iSAX index family that adversely affect the overall performance. First, we observe the presence of a proximity-compactness trade-off related to the index structure design (i.e., the node fanout degree), significantly limiting the efficiency and accuracy of the resulting index. Second, a skewed data distribution will negatively affect the performance of iSAX. To overcome these problems, we propose Dumpy, an index that employs a novel multi-ary data structure with an adaptive node splitting algorithm and an efficient building workflow. Furthermore, we devise Dumpy-Fuzzy as a variant of Dumpy which further improves search accuracy by proper duplication of series. Experiments with a variety of large, real datasets demonstrate that the Dumpy solutions achieve considerably better efficiency, scalability and search accuracy than its competitors. This paper was published in SIGMOD'23.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08264v1","tag":"new-dataset"}}
{"title":"Graph Embedding Augmented Skill Rating System","abstract":"This paper presents a framework for learning player embeddings in competitive games and events. Players and their win-loss relationships are modeled as a skill gap graph, which is an undirected weighted graph. The player embeddings are learned from the graph using a random walk-based graph embedding method and can reflect the relative skill levels among players. Embeddings are low-dimensional vector representations that can be conveniently applied to subsequent tasks while still preserving the topological relationships in a graph. In the latter part of this paper, Graphical Elo (GElo) is introduced as an application of player embeddings when rating player skills. GElo is an extension of the classic Elo rating system. It constructs a skill gap graph based on player match histories and learns player embeddings from it. Afterward, the rating scores that were calculated by Elo are adjusted according to player activeness and cosine similarities among player embeddings. GElo can be executed offline and in parallel, and it is non-intrusive to existing rating systems. Experiments on public datasets show that GElo makes a more reliable evaluation of player skill levels than vanilla Elo. The experimental results suggest potential applications of player embeddings in competitive games and events.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08257v1","tag":"new-dataset"}}
{"title":"Do you MIND? Reflections on the MIND dataset for research on diversity in news recommendations","abstract":"The MIND dataset is at the moment of writing the most extensive dataset available for the research and development of news recommender systems. This work analyzes the suitability of the dataset for research on diverse news recommendations. On the one hand we analyze the effect the different steps in the recommendation pipeline have on the distribution of article categories, and on the other hand we check whether the supplied data would be sufficient for more sophisticated diversity analysis. We conclude that while MIND is a great step forward, there is still a lot of room for improvement.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08253v1","tag":"new-dataset"}}
{"title":"Decentralized projected Riemannian gradient method for smooth optimization on compact submanifolds","abstract":"We consider the problem of decentralized nonconvex optimization over a compact submanifold, where each local agent's objective function defined by the local dataset is smooth. Leveraging the powerful tool of proximal smoothness, we establish local linear convergence of the projected gradient descent method with unit step size for solving the consensus problem over the compact manifold. This serves as the basis for analyzing decentralized algorithms on manifolds. Then, we propose two decentralized methods, namely the decentralized projected Riemannian gradient descent (DPRGD) and the decentralized projected Riemannian gradient tracking (DPRGT) methods. We establish their convergence rates of $\\mathcal{O}(1/\\sqrt{K})$ and $\\mathcal{O}(1/K)$, respectively, to reach a stationary point. To the best of our knowledge, DPRGT is the first decentralized algorithm to achieve exact convergence for solving decentralized optimization over a compact manifold. The key ingredients in the proof are the Lipschitz-type inequalities of the projection operator on the compact manifold and smooth functions on the manifold, which could be of independent interest. Finally, we demonstrate the effectiveness of our proposed methods compared to state-of-the-art ones through numerical experiments on eigenvalue problems and low-rank matrix completion.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08241v2","tag":"new-dataset"}}
{"title":"Uncovering the Background-Induced bias in RGB based 6-DoF Object Pose Estimation","abstract":"In recent years, there has been a growing trend of using data-driven methods in industrial settings. These kinds of methods often process video images or parts, therefore the integrity of such images is crucial. Sometimes datasets, e.g. consisting of images, can be sophisticated for various reasons. It becomes critical to understand how the manipulation of video and images can impact the effectiveness of a machine learning method. Our case study aims precisely to analyze the Linemod dataset, considered the state of the art in 6D pose estimation context. That dataset presents images accompanied by ArUco markers; it is evident that such markers will not be available in real-world contexts. We analyze how the presence of the markers affects the pose estimation accuracy, and how this bias may be mitigated through data augmentation and other methods. Our work aims to show how the presence of these markers goes to modify, in the testing phase, the effectiveness of the deep learning method used. In particular, we will demonstrate, through the tool of saliency maps, how the focus of the neural network is captured in part by these ArUco markers. Finally, a new dataset, obtained by applying geometric tools to Linemod, will be proposed in order to demonstrate our hypothesis and uncovering the bias. Our results demonstrate the potential for bias in 6DOF pose estimation networks, and suggest methods for reducing this bias when training with markers.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08230v1","tag":"new-dataset"}}
{"title":"Intra-Batch Supervision for Panoptic Segmentation on High-Resolution Images","abstract":"Unified panoptic segmentation methods are achieving state-of-the-art results on several datasets. To achieve these results on high-resolution datasets, these methods apply crop-based training. In this work, we find that, although crop-based training is advantageous in general, it also has a harmful side-effect. Specifically, it limits the ability of unified networks to discriminate between large object instances, causing them to make predictions that are confused between multiple instances. To solve this, we propose Intra-Batch Supervision (IBS), which improves a network's ability to discriminate between instances by introducing additional supervision using multiple images from the same batch. We show that, with our IBS, we successfully address the confusion problem and consistently improve the performance of unified networks. For the high-resolution Cityscapes and Mapillary Vistas datasets, we achieve improvements of up to +2.5 on the Panoptic Quality for thing classes, and even more considerable gains of up to +5.8 on both the pixel accuracy and pixel precision, which we identify as better metrics to capture the confusion problem.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08222v1","tag":"new-dataset"}}
{"title":"Context-Dependent Embedding Utterance Representations for Emotion Recognition in Conversations","abstract":"Emotion Recognition in Conversations (ERC) has been gaining increasing importance as conversational agents become more and more common. Recognizing emotions is key for effective communication, being a crucial component in the development of effective and empathetic conversational agents. Knowledge and understanding of the conversational context are extremely valuable for identifying the emotions of the interlocutor. We thus approach Emotion Recognition in Conversations leveraging the conversational context, i.e., taking into attention previous conversational turns. The usual approach to model the conversational context has been to produce context-independent representations of each utterance and subsequently perform contextual modeling of these. Here we propose context-dependent embedding representations of each utterance by leveraging the contextual representational power of pre-trained transformer language models. In our approach, we feed the conversational context appended to the utterance to be classified as input to the RoBERTa encoder, to which we append a simple classification module, thus discarding the need to deal with context after obtaining the embeddings since these constitute already an efficient representation of such context. We also investigate how the number of introduced conversational turns influences our model performance. The effectiveness of our approach is validated on the widely used open-domain DailyDialog dataset and on the task-oriented EmoWOZ dataset, for which we attain state-of-the-art results, surpassing ERC models also resorting to RoBERTa but with more complex classification modules, indicating that our context-dependent embedding utterance representation approach with a simple classification model can be more effective than context-independent utterance representation approaches with more complex classification modules.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08216v1","tag":"new-dataset"}}
{"title":"ATTACH Dataset: Annotated Two-Handed Assembly Actions for Human Action Understanding","abstract":"With the emergence of collaborative robots (cobots), human-robot collaboration in industrial manufacturing is coming into focus. For a cobot to act autonomously and as an assistant, it must understand human actions during assembly. To effectively train models for this task, a dataset containing suitable assembly actions in a realistic setting is crucial. For this purpose, we present the ATTACH dataset, which contains 51.6 hours of assembly with 95.2k annotated fine-grained actions monitored by three cameras, which represent potential viewpoints of a cobot. Since in an assembly context workers tend to perform different actions simultaneously with their two hands, we annotated the performed actions for each hand separately. Therefore, in the ATTACH dataset, more than 68% of annotations overlap with other annotations, which is many times more than in related datasets, typically featuring more simplistic assembly tasks. For better generalization with respect to the background of the working area, we did not only record color and depth images, but also used the Azure Kinect body tracking SDK for estimating 3D skeletons of the worker. To create a first baseline, we report the performance of state-of-the-art methods for action recognition as well as action detection on video and skeleton-sequence inputs. The dataset is available at https://www.tu-ilmenau.de/neurob/data-sets-code/attach-dataset .","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08210v1","tag":"new-dataset"}}
{"title":"Neural TTS in French: Comparing Graphemic and Phonetic Inputs Using the SynPaFlex-Corpus and Tacotron2","abstract":"The SynPaFlex-Corpus is a publicly available TTS-oriented dataset, which provides phonetic transcriptions automatically produced by the JTrans transcriber, with a Phoneme Error Rate (PER) of 6.1%. In this paper, we analyze two mono-speaker Tacotron2 models trained on graphemic and phonetic inputs, provided by the SynPaFlex-Corpus. Through three subjective listening tests, we compare their pronunciation accuracy, sound quality and naturalness. Our results show significantly better pronunciation accuracy and prosody naturalness for the phoneme-based model, but no significant difference in terms of perceived sound quality. They demonstrate that a PER of 6.1% is sufficient to enhance pronunciation control by using phonetic transcripts instead of graphemes with 83 hours of recorded French read speech. They suggest that the SynPaFlex-Corpus is suitable for pre-training a model in mono-speaker fine-tuning approaches.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08209v2","tag":"new-dataset"}}
{"title":"VECO 2.0: Cross-lingual Language Model Pre-training with Multi-granularity Contrastive Learning","abstract":"Recent studies have demonstrated the potential of cross-lingual transferability by training a unified Transformer encoder for multiple languages. In addition to involving the masked language model objective, existing cross-lingual pre-training works leverage sentence-level contrastive learning or plugs in extra cross-attention module to complement the insufficient capabilities of cross-lingual alignment. Nonetheless, synonym pairs residing in bilingual corpus are not exploited and aligned, which is more crucial than sentence interdependence establishment for token-level tasks. In this work, we propose a cross-lingual pre-trained model VECO~2.0 based on contrastive learning with multi-granularity alignments. Specifically, the sequence-to-sequence alignment is induced to maximize the similarity of the parallel pairs and minimize the non-parallel pairs. Then, token-to-token alignment is integrated to bridge the gap between synonymous tokens excavated via the thesaurus dictionary from the other unpaired tokens in a bilingual instance. Experiments show the effectiveness of the proposed strategy for cross-lingual model pre-training on the XTREME benchmark.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08205v1","tag":"new-dataset"}}
{"title":"Learning Geometry-aware Representations by Sketching","abstract":"Understanding geometric concepts, such as distance and shape, is essential for understanding the real world and also for many vision tasks. To incorporate such information into a visual representation of a scene, we propose learning to represent the scene by sketching, inspired by human behavior. Our method, coined Learning by Sketching (LBS), learns to convert an image into a set of colored strokes that explicitly incorporate the geometric information of the scene in a single inference step without requiring a sketch dataset. A sketch is then generated from the strokes where CLIP-based perceptual loss maintains a semantic similarity between the sketch and the image. We show theoretically that sketching is equivariant with respect to arbitrary affine transformations and thus provably preserves geometric information. Experimental results show that LBS substantially improves the performance of object attribute classification on the unlabeled CLEVR dataset, domain transfer between CLEVR and STL-10 datasets, and for diverse downstream tasks, confirming that LBS provides rich geometric information.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08204v1","tag":"new-dataset"}}
{"title":"Applications of Deep Learning for Top-View Omnidirectional Imaging: A Survey","abstract":"A large field-of-view fisheye camera allows for capturing a large area with minimal numbers of cameras when they are mounted on a high position facing downwards. This top-view omnidirectional setup greatly reduces the work and cost for deployment compared to traditional solutions with multiple perspective cameras. In recent years, deep learning has been widely employed for vision related tasks, including for such omnidirectional settings. In this survey, we look at the application of deep learning in combination with omnidirectional top-view cameras, including the available datasets, human and object detection, human pose estimation, activity recognition and other miscellaneous applications.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08193v1","tag":"new-dataset"}}
{"title":"Human Pose Estimation in Monocular Omnidirectional Top-View Images","abstract":"Human pose estimation (HPE) with convolutional neural networks (CNNs) for indoor monitoring is one of the major challenges in computer vision. In contrast to HPE in perspective views, an indoor monitoring system can consist of an omnidirectional camera with a field of view of 180{\\deg} to detect the pose of a person with only one sensor per room. To recognize human pose, the detection of keypoints is an essential upstream step. In our work we propose a new dataset for training and evaluation of CNNs for the task of keypoint detection in omnidirectional images. The training dataset, THEODORE+, consists of 50,000 images and is created by a 3D rendering engine, where humans are randomly walking through an indoor environment. In a dynamically created 3D scene, persons move randomly with simultaneously moving omnidirectional camera to generate synthetic RGB images and 2D and 3D ground truth. For evaluation purposes, the real-world PoseFES dataset with two scenarios and 701 frames with up to eight persons per scene was captured and annotated. We propose four training paradigms to finetune or re-train two top-down models in MMPose and two bottom-up models in CenterNet on THEODORE+. Beside a qualitative evaluation we report quantitative results. Compared to a COCO pretrained baseline, we achieve significant improvements especially for top-view scenes on the PoseFES dataset. Our datasets can be found at https://www.tu-chemnitz.de/etit/dst/forschung/comp_vision/datasets/index.php.en.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08186v1","tag":"new-dataset"}}
{"title":"Normalizing Flow-based Neural Process for Few-Shot Knowledge Graph Completion","abstract":"Knowledge graphs (KGs), as a structured form of knowledge representation, have been widely applied in the real world. Recently, few-shot knowledge graph completion (FKGC), which aims to predict missing facts for unseen relations with few-shot associated facts, has attracted increasing attention from practitioners and researchers. However, existing FKGC methods are based on metric learning or meta-learning, which often suffer from the out-of-distribution and overfitting problems. Meanwhile, they are incompetent at estimating uncertainties in predictions, which is critically important as model predictions could be very unreliable in few-shot settings. Furthermore, most of them cannot handle complex relations and ignore path information in KGs, which largely limits their performance. In this paper, we propose a normalizing flow-based neural process for few-shot knowledge graph completion (NP-FKGC). Specifically, we unify normalizing flows and neural processes to model a complex distribution of KG completion functions. This offers a novel way to predict facts for few-shot relations while estimating the uncertainty. Then, we propose a stochastic ManifoldE decoder to incorporate the neural process and handle complex relations in few-shot settings. To further improve performance, we introduce an attentive relation path-based graph neural network to capture path information in KGs. Extensive experiments on three public datasets demonstrate that our method significantly outperforms the existing FKGC methods and achieves state-of-the-art performance. Code is available at https://github.com/RManLuo/NP-FKGC.git.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08183v1","tag":"new-dataset"}}
{"title":"Search for Postmerger Gravitational Waves from Binary Neutron Star Mergers Using a Matched-filtering Statistic","abstract":"In this paper, we present a new method to search for a short postmerger gravitational-wave signal following the merger of two neutron stars. Such a signal could follow the event GW170817 observed by LIGO and Virgo detectors. Our method is based on a matched filtering statistic and an approximate template of the postmerger signal in the form of a damped sinusoid. We test and validate our method using postmerger numerical simulations from the CoRe database. We find no evidence of the short postmerger signal in the LIGO data following the GW170817 event and we obtain upper limits. For short postmerger signals investigated, our best upper limit on the root sum square of the gravitational-wave strain emitted from 1.15 kHz to 4 kHz is $h_{\\text{rss}}^{50\\%}=1.8\\times 10^{-22}/\\sqrt{\\text{Hz}}$ at 50% detection efficiency. The distance corresponding to this best upper limit is 4.64 Mpc.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08171v2","tag":"new-dataset"}}
{"title":"Attention Mixtures for Time-Aware Sequential Recommendation","abstract":"Transformers emerged as powerful methods for sequential recommendation. However, existing architectures often overlook the complex dependencies between user preferences and the temporal context. In this short paper, we introduce MOJITO, an improved Transformer sequential recommender system that addresses this limitation. MOJITO leverages Gaussian mixtures of attention-based temporal context and item embedding representations for sequential modeling. Such an approach permits to accurately predict which items should be recommended next to users depending on past actions and the temporal context. We demonstrate the relevance of our approach, by empirically outperforming existing Transformers for sequential recommendation on several real-world datasets.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08158v1","tag":"new-dataset"}}
{"title":"Prediction-Oriented Bayesian Active Learning","abstract":"Information-theoretic approaches to active learning have traditionally focused on maximising the information gathered about the model parameters, most commonly by optimising the BALD score. We highlight that this can be suboptimal from the perspective of predictive performance. For example, BALD lacks a notion of an input distribution and so is prone to prioritise data of limited relevance. To address this we propose the expected predictive information gain (EPIG), an acquisition function that measures information gain in the space of predictions rather than parameters. We find that using EPIG leads to stronger predictive performance compared with BALD across a range of datasets and models, and thus provides an appealing drop-in replacement.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08151v1","tag":"new-dataset"}}
{"title":"Political corpus creation through automatic speech recognition on EU debates","abstract":"In this paper, we present a transcribed corpus of the LIBE committee of the EU parliament, totalling 3.6 Million running words. The meetings of parliamentary committees of the EU are a potentially valuable source of information for political scientists but the data is not readily available because only disclosed as speech recordings together with limited metadata. The meetings are in English, partly spoken by non-native speakers, and partly spoken by interpreters. We investigated the most appropriate Automatic Speech Recognition (ASR) model to create an accurate text transcription of the audio recordings of the meetings in order to make their content available for research and analysis. We focused on the unsupervised domain adaptation of the ASR pipeline. Building on the transformer-based Wav2vec2.0 model, we experimented with multiple acoustic models, language models and the addition of domain-specific terms. We found that a domain-specific acoustic model and a domain-specific language model give substantial improvements to the ASR output, reducing the word error rate (WER) from 28.22 to 17.95. The use of domain-specific terms in the decoding stage did not have a positive effect on the quality of the ASR in terms of WER. Initial topic modelling results indicated that the corpus is useful for downstream analysis tasks. We release the resulting corpus and our analysis pipeline for future research.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08137v1","tag":"new-dataset"}}
{"title":"Tackling Face Verification Edge Cases: In-Depth Analysis and Human-Machine Fusion Approach","abstract":"Nowadays, face recognition systems surpass human performance on several datasets. However, there are still edge cases that the machine can't correctly classify. This paper investigates the effect of a combination of machine and human operators in the face verification task. First, we look closer at the edge cases for several state-of-the-art models to discover common datasets' challenging settings. Then, we conduct a study with 60 participants on these selected tasks with humans and provide an extensive analysis. Finally, we demonstrate that combining machine and human decisions can further improve the performance of state-of-the-art face verification systems on various benchmark datasets. Code and data are publicly available on GitHub.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08134v2","tag":"new-dataset"}}
{"title":"A Survey on Few-Shot Class-Incremental Learning","abstract":"Large deep learning models are impressive, but they struggle when real-time data is not available. Few-shot class-incremental learning (FSCIL) poses a significant challenge for deep neural networks to learn new tasks from just a few labeled samples without forgetting the previously learned ones. This setup easily leads to catastrophic forgetting and overfitting problems, severely affecting model performance. Studying FSCIL helps overcome deep learning model limitations on data volume and acquisition time, while improving practicality and adaptability of machine learning models. This paper provides a comprehensive survey on FSCIL. Unlike previous surveys, we aim to synthesize few-shot learning and incremental learning, focusing on introducing FSCIL from two perspectives, while reviewing over 30 theoretical research studies and more than 20 applied research studies. From the theoretical perspective, we provide a novel categorization approach that divides the field into five subcategories, including traditional machine learning methods, meta-learning based methods, feature and feature space-based methods, replay-based methods, and dynamic network structure-based methods. We also evaluate the performance of recent theoretical research on benchmark datasets of FSCIL. From the application perspective, FSCIL has achieved impressive achievements in various fields of computer vision such as image classification, object detection, and image segmentation, as well as in natural language processing and graph. We summarize the important applications. Finally, we point out potential future research directions, including applications, problem setups, and theory development. Overall, this paper offers a comprehensive analysis of the latest advances in FSCIL from a methodological, performance, and application perspective.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08130v1","tag":"new-dataset"}}
{"title":"DAS-N2N: Machine learning Distributed Acoustic Sensing (DAS) signal denoising without clean data","abstract":"This article presents a weakly supervised machine learning method, which we call DAS-N2N, for suppressing strong random noise in distributed acoustic sensing (DAS) recordings. DAS-N2N requires no manually produced labels (i.e., pre-determined examples of clean event signals or sections of noise) for training and aims to map random noise processes to a chosen summary statistic, such as the distribution mean, median or mode, whilst retaining the true underlying signal. This is achieved by splicing (joining together) two fibres hosted within a single optical cable, recording two noisy copies of the same underlying signal corrupted by different independent realizations of random observational noise. A deep learning model can then be trained using only these two noisy copies of the data to produce a near fully-denoised copy. Once the model is trained, only noisy data from a single fibre is required. Using a dataset from a DAS array deployed on the surface of the Rutford Ice Stream in Antarctica, we demonstrate that DAS-N2N greatly suppresses incoherent noise and enhances the signal-to-noise ratios (SNR) of natural microseismic icequake events. We further show that this approach is inherently more efficient and effective than standard stop/pass band filtering routines and a comparable self-supervised learning method based on masking individual DAS channels. Our preferred model for this task is lightweight, processing 30 seconds of data recorded at a sampling frequency of 1000 Hz over 985 channels (approx. 1 km of fiber) in $<$1 s. Due to the high noise levels in DAS recordings, efficient data-driven denoising methods, such as DAS-N2N, will prove essential to time-critical DAS earthquake detection, particularly in the case of microseismic monitoring.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08120v1","tag":"new-dataset"}}
{"title":"An Empirical Study of Multitask Learning to Improve Open Domain Dialogue Systems","abstract":"Autoregressive models used to generate responses in open-domain dialogue systems often struggle to take long-term context into account and to maintain consistency over a dialogue. Previous research in open-domain dialogue generation has shown that the use of \\emph{auxiliary tasks} can introduce inductive biases that encourage the model to improve these qualities. However, most previous research has focused on encoder-only or encoder/decoder models, while the use of auxiliary tasks in \\emph{decoder-only} autoregressive models is under-explored. This paper describes an investigation where four different auxiliary tasks are added to small and medium-sized GPT-2 models fine-tuned on the PersonaChat and DailyDialog datasets. The results show that the introduction of the new auxiliary tasks leads to small but consistent improvement in evaluations of the investigated models.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08115v1","tag":"new-dataset"}}
{"title":"ViPLO: Vision Transformer based Pose-Conditioned Self-Loop Graph for Human-Object Interaction Detection","abstract":"Human-Object Interaction (HOI) detection, which localizes and infers relationships between human and objects, plays an important role in scene understanding. Although two-stage HOI detectors have advantages of high efficiency in training and inference, they suffer from lower performance than one-stage methods due to the old backbone networks and the lack of considerations for the HOI perception process of humans in the interaction classifiers. In this paper, we propose Vision Transformer based Pose-Conditioned Self-Loop Graph (ViPLO) to resolve these problems. First, we propose a novel feature extraction method suitable for the Vision Transformer backbone, called masking with overlapped area (MOA) module. The MOA module utilizes the overlapped area between each patch and the given region in the attention function, which addresses the quantization problem when using the Vision Transformer backbone. In addition, we design a graph with a pose-conditioned self-loop structure, which updates the human node encoding with local features of human joints. This allows the classifier to focus on specific human joints to effectively identify the type of interaction, which is motivated by the human perception process for HOI. As a result, ViPLO achieves the state-of-the-art results on two public benchmarks, especially obtaining a +2.07 mAP performance gain on the HICO-DET dataset. The source codes are available at https://github.com/Jeeseung-Park/ViPLO.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08114v1","tag":"new-dataset"}}
{"title":"Leveraging Multi-view Data for Improved Detection Performance: An Industrial Use Case","abstract":"Printed circuit boards (PCBs) are essential components of electronic devices, and ensuring their quality is crucial in their production. However, the vast variety of components and PCBs manufactured by different companies makes it challenging to adapt to production lines with speed demands. To address this challenge, we present a multi-view object detection framework that offers a fast and precise solution. We introduce a novel multi-view dataset with semi-automatic ground-truth data, which results in significant labeling resource savings. Labeling PCB boards for object detection is a challenging task due to the high density of components and the small size of the objects, which makes it difficult to identify and label them accurately. By training an object detector model with multi-view data, we achieve improved performance over single-view images. To further enhance the accuracy, we develop a multi-view inference method that aggregates results from different viewpoints. Our experiments demonstrate a 15% improvement in mAP for detecting components that range in size from 0.5 to 27.0 mm.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08111v1","tag":"new-dataset"}}
{"title":"A Comparative Study between Full-Parameter and LoRA-based Fine-Tuning on Chinese Instruction Data for Instruction Following Large Language Model","abstract":"Recently, the instruction-tuning of large language models is a crucial area of research in the field of natural language processing. Due to resource and cost limitations, several researchers have employed parameter-efficient tuning techniques, such as LoRA, for instruction tuning, and have obtained encouraging results In comparison to full-parameter fine-tuning, LoRA-based tuning demonstrates salient benefits in terms of training costs. In this study, we undertook experimental comparisons between full-parameter fine-tuning and LoRA-based tuning methods, utilizing LLaMA as the base model. The experimental results show that the selection of the foundational model, training dataset scale, learnable parameter quantity, and model training cost are all important factors. We hope that the experimental conclusions of this paper can provide inspiration for training large language models, especially in the field of Chinese, and help researchers find a better trade-off strategy between training cost and model performance. To facilitate the reproduction of the paper's results, the dataset, model and code will be released.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08109v2","tag":"new-dataset"}}
{"title":"DETR-based Layered Clothing Segmentation and Fine-Grained Attribute Recognition","abstract":"Clothing segmentation and fine-grained attribute recognition are challenging tasks at the crossing of computer vision and fashion, which segment the entire ensemble clothing instances as well as recognize detailed attributes of the clothing products from any input human images. Many new models have been developed for the tasks in recent years, nevertheless the segmentation accuracy is less than satisfactory in case of layered clothing or fashion products in different scales. In this paper, a new DEtection TRansformer (DETR) based method is proposed to segment and recognize fine-grained attributes of ensemble clothing instances with high accuracy. In this model, we propose a \\textbf{multi-layered attention module} by aggregating features of different scales, determining the various scale components of a single instance, and merging them together. We train our model on the Fashionpedia dataset and demonstrate our method surpasses SOTA models in tasks of layered clothing segmentation and fine-grained attribute recognition.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08107v1","tag":"new-dataset"}}
{"title":"Transformer-based Graph Neural Networks for Outfit Generation","abstract":"Suggesting complementary clothing items to compose an outfit is a process of emerging interest, yet it involves a fine understanding of fashion trends and visual aesthetics. Previous works have mainly focused on recommendation by scoring visual appeal and representing garments as ordered sequences or as collections of pairwise-compatible items. This limits the full usage of relations among clothes. We attempt to bridge the gap between outfit recommendation and generation by leveraging a graph-based representation of items in a collection. The work carried out in this paper, tries to build a bridge between outfit recommendation and generation, by discovering new appealing outfits starting from a collection of pre-existing ones. We propose a transformer-based architecture, named TGNN, which exploits multi-headed self attention to capture relations between clothing items in a graph as a message passing step in Convolutional Graph Neural Networks. Specifically, starting from a seed, i.e.~one or more garments, outfit generation is performed by iteratively choosing the garment that is most compatible with the previously chosen ones. Extensive experimentations are conducted with two different datasets, demonstrating the capability of the model to perform seeded outfit generation as well as obtaining state of the art results on compatibility estimation tasks.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08098v1","tag":"new-dataset"}}
{"title":"Wireless Channel Charting: Theory, Practice, and Applications","abstract":"Channel charting is a recently proposed framework that applies dimensionality reduction to channel state information (CSI) in wireless systems with the goal of associating a pseudo-position to each mobile user in a low-dimensional space: the channel chart. Channel charting summarizes the entire CSI dataset in a self-supervised manner, which opens up a range of applications that are tied to user location. In this article, we introduce the theoretical underpinnings of channel charting and present an overview of recent algorithmic developments and experimental results obtained in the field. We furthermore discuss concrete application examples of channel charting to network- and user-related applications, and we provide a perspective on future developments and challenges as well as the role of channel charting in next-generation wireless networks.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08095v1","tag":"new-dataset"}}
{"title":"The Stellar Spectra Factory (SSF) Based On SLAM","abstract":"In this work, we present Stellar Spectra Factory (SSF), a tool to generate empirical-based stellar spectra from arbitrary stellar atmospheric parameters. The relative flux-calibrated empirical spectra can be predicted by SSF given arbitrary effective temperature, surface gravity, and metallicity. SSF constructs the interpolation approach based on the SLAM, using ATLAS-A library as the training dataset. SSF is composed of 4 data-driven sub-models to predict empirical stellar spectra. SSF-N can generate spectra from A to K type and some M giant stars, covering 3700 < Teff < 8700 K, 0 < logg < 6 dex, and -1.5 < [M/H] < 0.5 dex. SSF-gM is mainly used to predict M giant spectra with 3520 < Teff < 4000K and -1.5 < [M/H] < 0.4 dex. SSF-dM is for generating M dwarf spectra with 3295 < Teff < 4040K, -1.0 < [M/H] < 0.1 dex. And SSF-B can predict B-type spectra with 9000 < Teff < 24000K and -5.2< MG < 1.5 mag. The accuracy of the predicted spectra is validated by comparing the flux of predicted spectra to those with same stellar parameters selected from the known spectral libraries, MILES and MaStar. The averaged difference of flux over optical wavelength between the predicted spectra and the corresponding ones in MILES and MaStar is less than 5%. More verification is conducted between the magnitudes calculated from the integration of the predicted spectra and the observations in PS1 and APASS bands with the same stellar parameters. No significant systematic difference is found between the predicted spectra and the photomatric observations. The uncertainty is 0.08mag in r band for SSF-gM when comparing with the stars with the same stellar parameters selected from PS1. And the uncertainty becomes 0.31mag in i band for SSF-dM when comparing with the stars with the same stellar parameters selected from APASS.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08089v1","tag":"new-dataset"}}
{"title":"InstructUIE: Multi-task Instruction Tuning for Unified Information Extraction","abstract":"Large language models have unlocked strong multi-task capabilities from reading instructive prompts. However, recent studies have shown that existing large models still have difficulty with information extraction tasks. For example, gpt-3.5-turbo achieved an F1 score of 18.22 on the Ontonotes dataset, which is significantly lower than the state-of-the-art performance. In this paper, we propose InstructUIE, a unified information extraction framework based on instruction tuning, which can uniformly model various information extraction tasks and capture the inter-task dependency. To validate the proposed method, we introduce IE INSTRUCTIONS, a benchmark of 32 diverse information extraction datasets in a unified text-to-text format with expert-written instructions. Experimental results demonstrate that our method achieves comparable performance to Bert in supervised settings and significantly outperforms the state-of-the-art and gpt3.5 in zero-shot settings.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08085v1","tag":"new-dataset"}}
{"title":"Balancing Unobserved Confounding with a Few Unbiased Ratings in Debiased Recommendations","abstract":"Recommender systems are seen as an effective tool to address information overload, but it is widely known that the presence of various biases makes direct training on large-scale observational data result in sub-optimal prediction performance. In contrast, unbiased ratings obtained from randomized controlled trials or A/B tests are considered to be the golden standard, but are costly and small in scale in reality. To exploit both types of data, recent works proposed to use unbiased ratings to correct the parameters of the propensity or imputation models trained on the biased dataset. However, the existing methods fail to obtain accurate predictions in the presence of unobserved confounding or model misspecification. In this paper, we propose a theoretically guaranteed model-agnostic balancing approach that can be applied to any existing debiasing method with the aim of combating unobserved confounding and model misspecification. The proposed approach makes full use of unbiased data by alternatively correcting model parameters learned with biased data, and adaptively learning balance coefficients of biased samples for further debiasing. Extensive real-world experiments are conducted along with the deployment of our proposal on four representative debiasing methods to demonstrate the effectiveness.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.09085v1","tag":"new-dataset"}}
{"title":"Causality-aware Visual Scene Discovery for Cross-Modal Question Reasoning","abstract":"Existing visual question reasoning methods usually fail to explicitly discover the inherent causal mechanism and ignore the complex event-level understanding that requires jointly modeling cross-modal event temporality and causality. In this paper, we propose an event-level visual question reasoning framework named Cross-Modal Question Reasoning (CMQR), to explicitly discover temporal causal structure and mitigate visual spurious correlation by causal intervention. To explicitly discover visual causal structure, the Visual Causality Discovery (VCD) architecture is proposed to find question-critical scene temporally and disentangle the visual spurious correlations by attention-based front-door causal intervention module named Local-Global Causal Attention Module (LGCAM). To align the fine-grained interactions between linguistic semantics and spatial-temporal representations, we build an Interactive Visual-Linguistic Transformer (IVLT) that builds the multi-modal co-occurrence interactions between visual and linguistic content. Extensive experiments on four datasets demonstrate the superiority of CMQR for discovering visual causal structures and achieving robust question reasoning.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08083v1","tag":"new-dataset"}}
{"title":"Collaborative Feature Learning for Fine-grained Facial Forgery Detection and Segmentation","abstract":"Detecting maliciously falsified facial images and videos has attracted extensive attention from digital-forensics and computer-vision communities. An important topic in manipulation detection is the localization of the fake regions. Previous work related to forgery detection mostly focuses on the entire faces. However, recent forgery methods have developed to edit important facial components while maintaining others unchanged. This drives us to not only focus on the forgery detection but also fine-grained falsified region segmentation. In this paper, we propose a collaborative feature learning approach to simultaneously detect manipulation and segment the falsified components. With the collaborative manner, detection and segmentation can boost each other efficiently. To enable our study of forgery detection and segmentation, we build a facial forgery dataset consisting of both entire and partial face forgeries with their pixel-level manipulation ground-truth. Experiment results have justified the mutual promotion between forgery detection and manipulated region segmentation. The overall performance of the proposed approach is better than the state-of-the-art detection or segmentation approaches. The visualization results have shown that our proposed model always captures the artifacts on facial regions, which is more reasonable.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08078v1","tag":"new-dataset"}}
{"title":"One-Class SVM on siamese neural network latent space for Unsupervised Anomaly Detection on brain MRI White Matter Hyperintensities","abstract":"Anomaly detection remains a challenging task in neuroimaging when little to no supervision is available and when lesions can be very small or with subtle contrast. Patch-based representation learning has shown powerful representation capacities when applied to industrial or medical imaging and outlier detection methods have been applied successfully to these images. In this work, we propose an unsupervised anomaly detection (UAD) method based on a latent space constructed by a siamese patch-based auto-encoder and perform the outlier detection with a One-Class SVM training paradigm tailored to the lesion detection task in multi-modality neuroimaging. We evaluate performances of this model on a public database, the White Matter Hyperintensities (WMH) challenge and show in par performance with the two best performing state-of-the-art methods reported so far.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08058v1","tag":"new-dataset"}}
{"title":"DeepSim-Nets: Deep Similarity Networks for Stereo Image Matching","abstract":"We present three multi-scale similarity learning architectures, or DeepSim networks. These models learn pixel-level matching with a contrastive loss and are agnostic to the geometry of the considered scene. We establish a middle ground between hybrid and end-to-end approaches by learning to densely allocate all corresponding pixels of an epipolar pair at once. Our features are learnt on large image tiles to be expressive and capture the scene's wider context. We also demonstrate that curated sample mining can enhance the overall robustness of the predicted similarities and improve the performance on radiometrically homogeneous areas. We run experiments on aerial and satellite datasets. Our DeepSim-Nets outperform the baseline hybrid approaches and generalize better to unseen scene geometries than end-to-end methods. Our flexible architecture can be readily adopted in standard multi-resolution image matching pipelines.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08056v1","tag":"new-dataset"}}
{"title":"Fed-MIWAE: Federated Imputation of Incomplete Data via Deep Generative Models","abstract":"Federated learning allows for the training of machine learning models on multiple decentralized local datasets without requiring explicit data exchange. However, data pre-processing, including strategies for handling missing data, remains a major bottleneck in real-world federated learning deployment, and is typically performed locally. This approach may be biased, since the subpopulations locally observed at each center may not be representative of the overall one. To address this issue, this paper first proposes a more consistent approach to data standardization through a federated model. Additionally, we propose Fed-MIWAE, a federated version of the state-of-the-art imputation method MIWAE, a deep latent variable model for missing data imputation based on variational autoencoders. MIWAE has the great advantage of being easily trainable with classical federated aggregators. Furthermore, it is able to deal with MAR (Missing At Random) data, a more challenging missing-data mechanism than MCAR (Missing Completely At Random), where the missingness of a variable can depend on the observed ones. We evaluate our method on multi-modal medical imaging data and clinical scores from a simulated federated scenario with the ADNI dataset. We compare Fed-MIWAE with respect to classical imputation methods, either performed locally or in a centralized fashion. Fed-MIWAE allows to achieve imputation accuracy comparable with the best centralized method, even when local data distributions are highly heterogeneous. In addition, thanks to the variational nature of Fed-MIWAE, our method is designed to perform multiple imputation, allowing for the quantification of the imputation uncertainty in the federated scenario.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08054v1","tag":"new-dataset"}}
{"title":"ERTIM@MC2: Diversified Argumentative Tweets Retrieval","abstract":"In this paper, we present our participation to CLEF MC2 2018 edition for the task 2 Mining opinion argumentation. It consists in detecting the most argumentative and diverse Tweets about some festivals in English and French from a massive multilingual collection. We measure argumentativity of a Tweet computing the amount of argumentation compounds it contains. We consider argumentation compounds as a combination between opinion expression and its support with facts and a particular structuration. Regarding diversity, we consider the amount of festival aspects covered by Tweets. An initial step filters the original dataset to fit the language and topic requirements of the task. Then, we compute and integrate linguistic descriptors to detect claims and their respective justifications in Tweets. The final step extracts the most diverse arguments by clustering Tweets according to their textual content and selecting the most argumentative ones from each cluster. We conclude the paper describing the different ways we combined the descriptors among the different runs we submitted and discussing their results.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08047v1","tag":"new-dataset"}}
{"title":"Learning How To Robustly Estimate Camera Pose in Endoscopic Videos","abstract":"Purpose: Surgical scene understanding plays a critical role in the technology stack of tomorrow's intervention-assisting systems in endoscopic surgeries. For this, tracking the endoscope pose is a key component, but remains challenging due to illumination conditions, deforming tissues and the breathing motion of organs. Method: We propose a solution for stereo endoscopes that estimates depth and optical flow to minimize two geometric losses for camera pose estimation. Most importantly, we introduce two learned adaptive per-pixel weight mappings that balance contributions according to the input image content. To do so, we train a Deep Declarative Network to take advantage of the expressiveness of deep-learning and the robustness of a novel geometric-based optimization approach. We validate our approach on the publicly available SCARED dataset and introduce a new in-vivo dataset, StereoMIS, which includes a wider spectrum of typically observed surgical settings. Results: Our method outperforms state-of-the-art methods on average and more importantly, in difficult scenarios where tissue deformations and breathing motion are visible. We observed that our proposed weight mappings attenuate the contribution of pixels on ambiguous regions of the images, such as deforming tissues. Conclusion: We demonstrate the effectiveness of our solution to robustly estimate the camera pose in challenging endoscopic surgical scenes. Our contributions can be used to improve related tasks like simultaneous localization and mapping (SLAM) or 3D reconstruction, therefore advancing surgical scene understanding in minimally-invasive surgery.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08023v1","tag":"new-dataset"}}
{"title":"A Scalable Test Problem Generator for Sequential Transfer Optimization","abstract":"Sequential transfer optimization (STO), which aims to improve optimization performance by exploiting knowledge captured from previously-solved optimization tasks stored in a database, has been gaining increasing research attention in recent years. However, despite significant advancements in algorithm design, the test problems in STO are not well designed. Oftentimes, they are either randomly assembled by other benchmark functions that have identical optima or are generated from practical problems that exhibit limited variations. The relationships between the optimal solutions of source and target tasks in these problems are manually configured and thus monotonous, limiting their ability to represent the diverse relationships of real-world problems. Consequently, the promising results achieved by many algorithms on these problems are highly biased and difficult to be generalized to other problems. In light of this, we first introduce a few rudimentary concepts for characterizing STO problems (STOPs) and present an important problem feature overlooked in previous studies, namely similarity distribution, which quantitatively delineates the relationship between the optima of source and target tasks. Then, we propose general design guidelines and a problem generator with superior extendibility. Specifically, the similarity distribution of a problem can be systematically customized by modifying a parameterized density function, enabling a broad spectrum of representation for the diverse similarity relationships of real-world problems. Lastly, a benchmark suite with 12 individual STOPs is developed using the proposed generator, which can serve as an arena for comparing different STO algorithms. The source code of the benchmark suite is available at https://github.com/XmingHsueh/STOP.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08503v1","tag":"new-dataset"}}
{"title":"CLIP-Lung: Textual Knowledge-Guided Lung Nodule Malignancy Prediction","abstract":"Lung nodule malignancy prediction has been enhanced by advanced deep-learning techniques and effective tricks. Nevertheless, current methods are mainly trained with cross-entropy loss using one-hot categorical labels, which results in difficulty in distinguishing those nodules with closer progression labels. Interestingly, we observe that clinical text information annotated by radiologists provides us with discriminative knowledge to identify challenging samples. Drawing on the capability of the contrastive language-image pre-training (CLIP) model to learn generalized visual representations from text annotations, in this paper, we propose CLIP-Lung, a textual knowledge-guided framework for lung nodule malignancy prediction. First, CLIP-Lung introduces both class and attribute annotations into the training of the lung nodule classifier without any additional overheads in inference. Second, we designed a channel-wise conditional prompt (CCP) module to establish consistent relationships between learnable context prompts and specific feature maps. Third, we align image features with both class and attribute features via contrastive learning, rectifying false positives and false negatives in latent space. The experimental results on the benchmark LIDC-IDRI dataset have demonstrated the superiority of CLIP-Lung, both in classification performance and interpretability of attention maps.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08013v1","tag":"new-dataset"}}
{"title":"One-shot and Partially-Supervised Cell Image Segmentation Using Small Visual Prompt","abstract":"Semantic segmentation of microscopic cell images using deep learning is an important technique, however, it requires a large number of images and ground truth labels for training. To address the above problem, we consider an efficient learning framework with as little data as possible, and we propose two types of learning strategies: One-shot segmentation which can learn with only one training sample, and Partially-supervised segmentation which assigns annotations to only a part of images. Furthermore, we introduce novel segmentation methods using the small prompt images inspired by prompt learning in recent studies. Our proposed methods use a pre-trained model based on only cell images and teach the information of the prompt pairs to the target image to be segmented by the attention mechanism, which allows for efficient learning while reducing the burden of annotation costs. Through experiments conducted on three types of microscopic cell image datasets, we confirmed that the proposed method improved the Dice score coefficient (DSC) in comparison with the conventional methods.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07991v1","tag":"new-dataset"}}
{"title":"Chinese Open Instruction Generalist: A Preliminary Release","abstract":"Instruction tuning is widely recognized as a key technique for building generalist language models, which has attracted the attention of researchers and the public with the release of InstructGPT~\\citep{ouyang2022training} and ChatGPT\\footnote{\\url{https://chat.openai.com/}}. Despite impressive progress in English-oriented large-scale language models (LLMs), it is still under-explored whether English-based foundation LLMs can perform similarly on multilingual tasks compared to English tasks with well-designed instruction tuning and how we can construct the corpora needed for the tuning.   To remedy this gap, we propose the project as an attempt to create a Chinese instruction dataset by various methods adapted to the intrinsic characteristics of 4 sub-tasks. We collect around 200k Chinese instruction tuning samples, which have been manually checked to guarantee high quality. We also summarize the existing English and Chinese instruction corpora and briefly describe some potential applications of the newly constructed Chinese instruction corpora. The resulting \\textbf{C}hinese \\textbf{O}pen \\textbf{I}nstruction \\textbf{G}eneralist (\\textbf{COIG}) corpora are available in Huggingface\\footnote{\\url{https://huggingface.co/datasets/BAAI/COIG}} and Github\\footnote{\\url{https://github.com/FlagOpen/FlagInstruct}}, and will be continuously updated.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07987v2","tag":"new-dataset"}}
{"title":"Snacks: a fast large-scale kernel SVM solver","abstract":"Kernel methods provide a powerful framework for non parametric learning. They are based on kernel functions and allow learning in a rich functional space while applying linear statistical learning tools, such as Ridge Regression or Support Vector Machines. However, standard kernel methods suffer from a quadratic time and memory complexity in the number of data points and thus have limited applications in large-scale learning. In this paper, we propose Snacks, a new large-scale solver for Kernel Support Vector Machines. Specifically, Snacks relies on a Nystr\\\"om approximation of the kernel matrix and an accelerated variant of the stochastic subgradient method. We demonstrate formally through a detailed empirical evaluation, that it competes with other SVM solvers on a variety of benchmark datasets.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07983v1","tag":"new-dataset"}}
{"title":"Incentive Mechanism Design for Unbiased Federated Learning with Randomized Client Participation","abstract":"Incentive mechanism is crucial for federated learning (FL) when rational clients do not have the same interests in the global model as the server. However, due to system heterogeneity and limited budget, it is generally impractical for the server to incentivize all clients to participate in all training rounds (known as full participation). The existing FL incentive mechanisms are typically designed by stimulating a fixed subset of clients based on their data quantity or system resources. Hence, FL is performed only using this subset of clients throughout the entire training process, leading to a biased model because of data heterogeneity. This paper proposes a game theoretic incentive mechanism for FL with randomized client participation, where the server adopts a customized pricing strategy that motivates different clients to join with different participation levels (probabilities) for obtaining an unbiased and high performance model. Each client responds to the server's monetary incentive by choosing its best participation level, to maximize its profit based on not only the incurred local cost but also its intrinsic value for the global model. To effectively evaluate clients' contribution to the model performance, we derive a new convergence bound which analytically predicts how clients' arbitrary participation levels and their heterogeneous data affect the model performance. By solving a non-convex optimization problem, our analysis reveals that the intrinsic value leads to the interesting possibility of bidirectional payment between the server and clients. Experimental results using real datasets on a hardware prototype demonstrate the superiority of our mechanism in achieving higher model performance for the server as well as higher profits for the clients.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07981v1","tag":"new-dataset"}}
{"title":"RNN-Guard: Certified Robustness Against Multi-frame Attacks for Recurrent Neural Networks","abstract":"It is well-known that recurrent neural networks (RNNs), although widely used, are vulnerable to adversarial attacks including one-frame attacks and multi-frame attacks. Though a few certified defenses exist to provide guaranteed robustness against one-frame attacks, we prove that defending against multi-frame attacks remains a challenging problem due to their enormous perturbation space. In this paper, we propose the first certified defense against multi-frame attacks for RNNs called RNN-Guard. To address the above challenge, we adopt the perturb-all-frame strategy to construct perturbation spaces consistent with those in multi-frame attacks. However, the perturb-all-frame strategy causes a precision issue in linear relaxations. To address this issue, we introduce a novel abstract domain called InterZono and design tighter relaxations. We prove that InterZono is more precise than Zonotope yet carries the same time complexity. Experimental evaluations across various datasets and model structures show that the certified robust accuracy calculated by RNN-Guard with InterZono is up to 2.18 times higher than that with Zonotope. In addition, we extend RNN-Guard as the first certified training method against multi-frame attacks to directly enhance RNNs' robustness. The results show that the certified robust accuracy of models trained with RNN-Guard against multi-frame attacks is 15.47 to 67.65 percentage points higher than those with other training methods.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07980v1","tag":"new-dataset"}}
{"title":"Collaborative Residual Metric Learning","abstract":"In collaborative filtering, distance metric learning has been applied to matrix factorization techniques with promising results. However, matrix factorization lacks the ability of capturing collaborative information, which has been remarked by recent works and improved by interpreting user interactions as signals. This paper aims to find out how metric learning connect to these signal-based models. By adopting a generalized distance metric, we discovered that in signal-based models, it is easier to estimate the residual of distances, which refers to the difference between the distances from a user to a target item and another item, rather than estimating the distances themselves. Further analysis also uncovers a link between the normalization strength of interaction signals and the novelty of recommendation, which has been overlooked by existing studies. Based on the above findings, we propose a novel model to learn a generalized distance user-item distance metric to capture user preference in interaction signals by modeling the residuals of distance. The proposed CoRML model is then further improved in training efficiency by a newly introduced approximated ranking weight. Extensive experiments conducted on 4 public datasets demonstrate the superior performance of CoRML compared to the state-of-the-art baselines in collaborative filtering, along with high efficiency and the ability of providing novelty-promoted recommendations, shedding new light on the study of metric learning-based recommender systems.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07971v1","tag":"new-dataset"}}
{"title":"Learning to \"Segment Anything\" in Thermal Infrared Images through Knowledge Distillation with a Large Scale Dataset SATIR","abstract":"The Segment Anything Model (SAM) is a promptable segmentation model recently introduced by Meta AI that has demonstrated its prowess across various fields beyond just image segmentation. SAM can accurately segment images across diverse fields, and generating various masks. We discovered that this ability of SAM can be leveraged to pretrain models for specific fields. Accordingly, we have proposed a framework that utilizes SAM to generate pseudo labels for pretraining thermal infrared image segmentation tasks. Our proposed framework can effectively improve the accuracy of segmentation results of specific categories beyond the SOTA ImageNet pretrained model. Our framework presents a novel approach to collaborate with models trained with large data like SAM to address problems in special fields. Also, we generated a large scale thermal infrared segmentation dataset used for pretaining, which contains over 100,000 images with pixel-annotation labels. This approach offers an effective solution for working with large models in special fields where label annotation is challenging. Our code is available at https://github.com/chenjzBUAA/SATIR","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07969v1","tag":"new-dataset"}}
{"title":"Measuring the Cosmic X-ray Background in 3-20keV with Straylight from NuSTAR","abstract":"By characterizing the contribution of stray light to large datasets from the NuSTAR X-ray observatory collected over 2012--2017, we report a measurement of the cosmic X-ray background in the 3--20 keV energy range. These data represent $\\sim20\\%$ sky coverage while avoiding Galactic Ridge X-ray emission and are less weighted by deep, survey fields than previous measurements with NuSTAR. Images in narrow energy bands are stacked in detector space and spatially fit with a model representing the stray light and uniform pattern expected from the cosmic X-ray background and the instrumental background, respectively. We establish baseline flux values from Earth-occulted data and validate the fitting method on stray light observations of the Crab, which further serve to calibrate the resulting spectra. We present independent spectra of the cosmic X-ray background with the FPMA and FPMB detector arrays, which are in excellent agreement with the canonical characterization by HEAO 1 and are $10\\%$ lower than most subsequent measurements; $F_{\\rm{3-20~keV}}^{FPMA} = 2.63 \\times 10^{-11}~\\rm{erg~s^{-1}~cm^{-2}~deg^{-2}}$ and $F_{\\rm{3-20~keV}}^{FPMB} = 2.58 \\times 10^{-11}~\\rm{erg~s^{-1}~cm^{-2}~deg^{-2}}$. We discuss these results in light of previous measurements of the cosmic X-ray background and consider the impact of systematic uncertainties on our spectra.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07962v1","tag":"new-dataset"}}
{"title":"Recursive Joint Attention for Audio-Visual Fusion in Regression based Emotion Recognition","abstract":"In video-based emotion recognition (ER), it is important to effectively leverage the complementary relationship among audio (A) and visual (V) modalities, while retaining the intra-modal characteristics of individual modalities. In this paper, a recursive joint attention model is proposed along with long short-term memory (LSTM) modules for the fusion of vocal and facial expressions in regression-based ER. Specifically, we investigated the possibility of exploiting the complementary nature of A and V modalities using a joint cross-attention model in a recursive fashion with LSTMs to capture the intra-modal temporal dependencies within the same modalities as well as among the A-V feature representations. By integrating LSTMs with recursive joint cross-attention, our model can efficiently leverage both intra- and inter-modal relationships for the fusion of A and V modalities. The results of extensive experiments performed on the challenging Affwild2 and Fatigue (private) datasets indicate that the proposed A-V fusion model can significantly outperform state-of-art-methods.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07958v1","tag":"new-dataset"}}
{"title":"A Question-Answering Approach to Key Value Pair Extraction from Form-like Document Images","abstract":"In this paper, we present a new question-answering (QA) based key-value pair extraction approach, called KVPFormer, to robustly extracting key-value relationships between entities from form-like document images. Specifically, KVPFormer first identifies key entities from all entities in an image with a Transformer encoder, then takes these key entities as \\textbf{questions} and feeds them into a Transformer decoder to predict their corresponding \\textbf{answers} (i.e., value entities) in parallel. To achieve higher answer prediction accuracy, we propose a coarse-to-fine answer prediction approach further, which first extracts multiple answer candidates for each identified question in the coarse stage and then selects the most likely one among these candidates in the fine stage. In this way, the learning difficulty of answer prediction can be effectively reduced so that the prediction accuracy can be improved. Moreover, we introduce a spatial compatibility attention bias into the self-attention/cross-attention mechanism for \\Ours{} to better model the spatial interactions between entities. With these new techniques, our proposed \\Ours{} achieves state-of-the-art results on FUNSD and XFUND datasets, outperforming the previous best-performing method by 7.2\\% and 13.2\\% in F1 score, respectively.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07957v1","tag":"new-dataset"}}
{"title":"Lightweight and Interpretable Left Ventricular Ejection Fraction Estimation using Mobile U-Net","abstract":"Accurate LVEF measurement is important in clinical practice as it identifies patients who may be in need of life-prolonging treatments. This paper presents a deep learning based framework to automatically estimate left ventricular ejection fraction from an entire 4-chamber apical echocardiogram video. The aim of the proposed framework is to provide an interpretable and computationally effective ejection fraction prediction pipeline. A lightweight Mobile U-Net based network is developed to segment the left ventricle in each frame of an echocardiogram video. An unsupervised LVEF estimation algorithm is implemented based on Simpson's mono-plane method. Experimental results on a large public dataset show that our proposed approach achieves comparable accuracy to the state-of-the-art while being significantly more space and time efficient (with 5 times fewer parameters and 10 times fewer FLOPS).","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07951v1","tag":"new-dataset"}}
{"title":"Learning To Rank Resources with GNN","abstract":"As the content on the Internet continues to grow, many new dynamically changing and heterogeneous sources of data constantly emerge. A conventional search engine cannot crawl and index at the same pace as the expansion of the Internet. Moreover, a large portion of the data on the Internet is not accessible to traditional search engines. Distributed Information Retrieval (DIR) is a viable solution to this as it integrates multiple shards (resources) and provides a unified access to them. Resource selection is a key component of DIR systems. There is a rich body of literature on resource selection approaches for DIR. A key limitation of the existing approaches is that they primarily use term-based statistical features and do not generally model resource-query and resource-resource relationships. In this paper, we propose a graph neural network (GNN) based approach to learning-to-rank that is capable of modeling resource-query and resource-resource relationships. Specifically, we utilize a pre-trained language model (PTLM) to obtain semantic information from queries and resources. Then, we explicitly build a heterogeneous graph to preserve structural information of query-resource relationships and employ GNN to extract structural information. In addition, the heterogeneous graph is enriched with resource-resource type of edges to further enhance the ranking accuracy. Extensive experiments on benchmark datasets show that our proposed approach is highly effective in resource selection. Our method outperforms the state-of-the-art by 6.4% to 42% on various performance metrics.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07946v1","tag":"new-dataset"}}
{"title":"An In-depth Investigation of User Response Simulation for Conversational Search","abstract":"Conversational search has seen increased recent attention in both the IR and NLP communities. It seeks to clarify and solve a user's search need through multi-turn natural language interactions. However, most existing systems are trained and demonstrated with recorded or artificial conversation logs. Eventually, conversational search systems should be trained, evaluated, and deployed in an open-ended setting with unseen conversation trajectories. A key challenge is that training and evaluating such systems both require a human-in-the-loop, which is expensive and does not scale. One strategy for this is to simulate users, thereby reducing the scaling costs. However, current user simulators are either limited to only respond to yes-no questions from the conversational search system, or unable to produce high quality responses in general.   In this paper, we show that current state-of-the-art user simulation system could be significantly improved by replacing it with a smaller but advanced natural language generation model. But rather than merely reporting this new state-of-the-art, we present an in-depth investigation of the task of simulating user response for conversational search. Our goal is to supplement existing works with an insightful hand-analysis of what challenges are still unsolved by the advanced model, as well as to propose our solutions for them. The challenges we identified include (1) dataset noise, (2) a blind spot that is difficult for existing models to learn, and (3) a specific type of misevaluation in the standard empirical setup. Except for the dataset noise issue, we propose solutions to cover the training blind spot and to avoid the misevaluation. Our proposed solutions lead to further improvements. Our best system improves the previous state-of-the-art significantly.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07944v1","tag":"new-dataset"}}
{"title":"PerCoNet: News Recommendation with Explicit Persona and Contrastive Learning","abstract":"Personalized news recommender systems help users quickly find content of their interests from the sea of information. Today, the mainstream technology for personalized news recommendation is based on deep neural networks that can accurately model the semantic match between news items and users' interests. In this paper, we present \\textbf{PerCoNet}, a novel deep learning approach to personalized news recommendation which features two new findings: (i) representing users through \\emph{explicit persona analysis} based on the prominent entities in their recent news reading history could be more effective than latent persona analysis employed by most existing work, with a side benefit of enhanced explainability; (ii) utilizing the title and abstract of each news item via cross-view \\emph{contrastive learning} would work better than just combining them directly. Extensive experiments on two real-world news datasets clearly show the superior performance of our proposed approach in comparison with current state-of-the-art techniques.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07923v1","tag":"new-dataset"}}
{"title":"Causal Decision Transformer for Recommender Systems via Offline Reinforcement Learning","abstract":"Reinforcement learning-based recommender systems have recently gained popularity. However, the design of the reward function, on which the agent relies to optimize its recommendation policy, is often not straightforward. Exploring the causality underlying users' behavior can take the place of the reward function in guiding the agent to capture the dynamic interests of users. Moreover, due to the typical limitations of simulation environments (e.g., data inefficiency), most of the work cannot be broadly applied in large-scale situations. Although some works attempt to convert the offline dataset into a simulator, data inefficiency makes the learning process even slower. Because of the nature of reinforcement learning (i.e., learning by interaction), it cannot collect enough data to train during a single interaction. Furthermore, traditional reinforcement learning algorithms do not have a solid capability like supervised learning methods to learn from offline datasets directly. In this paper, we propose a new model named the causal decision transformer for recommender systems (CDT4Rec). CDT4Rec is an offline reinforcement learning system that can learn from a dataset rather than from online interaction. Moreover, CDT4Rec employs the transformer architecture, which is capable of processing large offline datasets and capturing both short-term and long-term dependencies within the data to estimate the causal relationship between action, state, and reward. To demonstrate the feasibility and superiority of our model, we have conducted experiments on six real-world offline datasets and one online simulator.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07920v1","tag":"new-dataset"}}
{"title":"Chain of Thought Prompt Tuning in Vision Language Models","abstract":"Language-Image Pre-training has demonstrated promising results on zero-shot and few-shot downstream tasks by prompting visual models with natural language prompts. However, most recent studies only use a single prompt for tuning, neglecting the inherent step-to-step cognitive reasoning process that humans conduct in complex task settings, for example, when processing images from unfamiliar domains. Chain of Thought is a simple and effective approximation to human reasoning process and has been proven useful for natural language processing (NLP) tasks. Based on this cognitive intuition, we believe that conducting effective reasoning is also an important problem in visual tasks, and a chain of thought could be a solution to this problem. In this work, we propose a novel chain of thought prompt tuning for vision-language modeling. Extensive experiments show that our method not only generalizes better in image classification tasks, has greater transferability beyond a single dataset, and has stronger domain generalization performance, but also performs much better in imagetext retrieval and visual question answering, which require more reasoning capabilities. We are the first to successfully adapt chain-of-thought prompting that combines visual and textual embeddings. We will release our codes","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07919v1","tag":"new-dataset"}}
{"title":"Likelihood-Based Generative Radiance Field with Latent Space Energy-Based Model for 3D-Aware Disentangled Image Representation","abstract":"We propose the NeRF-LEBM, a likelihood-based top-down 3D-aware 2D image generative model that incorporates 3D representation via Neural Radiance Fields (NeRF) and 2D imaging process via differentiable volume rendering. The model represents an image as a rendering process from 3D object to 2D image and is conditioned on some latent variables that account for object characteristics and are assumed to follow informative trainable energy-based prior models. We propose two likelihood-based learning frameworks to train the NeRF-LEBM: (i) maximum likelihood estimation with Markov chain Monte Carlo-based inference and (ii) variational inference with the reparameterization trick. We study our models in the scenarios with both known and unknown camera poses. Experiments on several benchmark datasets demonstrate that the NeRF-LEBM can infer 3D object structures from 2D images, generate 2D images with novel views and objects, learn from incomplete 2D images, and learn from 2D images with known or unknown camera poses.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07918v1","tag":"new-dataset"}}
{"title":"GaitRef: Gait Recognition with Refined Sequential Skeletons","abstract":"Identifying humans with their walking sequences, known as gait recognition, is a useful biometric understanding task as it can be observed from a long distance and does not require cooperation from the subject. Two common modalities used for representing the walking sequence of a person are silhouettes and joint skeletons. Silhouette sequences, which record the boundary of the walking person in each frame, may suffer from the variant appearances from carried-on objects and clothes of the person. Framewise joint detections are noisy and introduce some jitters that are not consistent with sequential detections. In this paper, we combine the silhouettes and skeletons and refine the framewise joint predictions for gait recognition. With temporal information from the silhouette sequences. We show that the refined skeletons can improve gait recognition performance without extra annotations. We compare our methods on four public datasets, CASIA-B, OUMVLP, Gait3D and GREW, and show state-of-the-art performance.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07916v1","tag":"new-dataset"}}
{"title":"Analyzing Activity and Suspension Patterns of Twitter Bots Attacking Turkish Twitter Trends by a Longitudinal Dataset","abstract":"Twitter bots amplify target content in a coordinated manner to make them appear popular, which is an astroturfing attack. Such attacks promote certain keywords to push them to Twitter trends to make them visible to a broader audience. Past work on such fake trends revealed a new astroturfing attack named ephemeral astroturfing that employs a very unique bot behavior in which bots post and delete generated tweets in a coordinated manner. As such, it is easy to mass-annotate such bots reliably, making them a convenient source of ground truth for bot research. In this paper, we detect and disclose over 212,000 such bots targeting Turkish trends, which we name astrobots. We also analyze their activity and suspension patterns. We found that Twitter purged those bots en-masse 6 times since June 2018. However, the adversaries reacted quickly and deployed new bots that were created years ago. We also found that many such bots do not post tweets apart from promoting fake trends, which makes it challenging for bot detection methods to detect them. Our work provides insights into platforms' content moderation practices and bot detection research. The dataset is publicly available at https://github.com/tugrulz/EphemeralAstroturfing.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07907v1","tag":"new-dataset"}}
{"title":"Brain Tumor classification and Segmentation using Deep Learning","abstract":"Brain tumors are a complex and potentially life-threatening medical condition that requires accurate diagnosis and timely treatment. In this paper, we present a machine learning-based system designed to assist healthcare professionals in the classification and diagnosis of brain tumors using MRI images. Our system provides a secure login, where doctors can upload or take a photo of MRI and our app can classify the model and segment the tumor, providing the doctor with a folder of each patient's history, name, and results. Our system can also add results or MRI to this folder, draw on the MRI to send it to another doctor, and save important results in a saved page in the app. Furthermore, our system can classify in less than 1 second and allow doctors to chat with a community of brain tumor doctors.   To achieve these objectives, our system uses a state-of-the-art machine learning algorithm that has been trained on a large dataset of MRI images. The algorithm can accurately classify different types of brain tumors and provide doctors with detailed information on the size, location, and severity of the tumor. Additionally, our system has several features to ensure its security and privacy, including secure login and data encryption.   We evaluated our system using a dataset of real-world MRI images and compared its performance to other existing systems. Our results demonstrate that our system is highly accurate, efficient, and easy to use. We believe that our system has the potential to revolutionize the field of brain tumor diagnosis and treatment and provide healthcare professionals with a powerful tool for improving patient outcomes.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07901v1","tag":"new-dataset"}}
{"title":"An Artificial Neural Network-based Density Functional Approach for Adiabatic Energy Differences in Transition Metal Complexes","abstract":"During the past decades, approximate Kohn-Sham density-functional theory schemes garnered many successes in computational chemistry and physics; yet the performance in the prediction of spin state energetics is often unsatisfactory. By means of a machine-learning approach, an enhanced exchange and correlation functional is developed to describe adiabatic energy differences in transition metal complexes. The functional is based on the computationally efficient revision of the regularized strongly constrained and appropriately normed (R2SCAN) functional and improved by an artificial neural-network correction trained over a small dataset of electronic densities, atomization energies and/or spin state energetics. The meta-GGA functional, optimized using a bio-inspired non gradient-based approach adapted from Particle Swarm Optimization, is shown to outperform most known density functionals in the prediction of adiabatic energy differences for both the validation test and the generality test.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07899v1","tag":"new-dataset"}}
{"title":"Time-series Anomaly Detection via Contextual Discriminative Contrastive Learning","abstract":"Detecting anomalies in temporal data is challenging due to anomalies being dependent on temporal dynamics. One-class classification methods are commonly used for anomaly detection tasks, but they have limitations when applied to temporal data. In particular, mapping all normal instances into a single hypersphere to capture their global characteristics can lead to poor performance in detecting context-based anomalies where the abnormality is defined with respect to local information. To address this limitation, we propose a novel approach inspired by the loss function of DeepSVDD. Instead of mapping all normal instances into a single hypersphere center, each normal instance is pulled toward a recent context window. However, this approach is prone to a representation collapse issue where the neural network that encodes a given instance and its context is optimized towards a constant encoder solution. To overcome this problem, we combine our approach with a deterministic contrastive loss from Neutral AD, a promising self-supervised learning anomaly detection approach. We provide a theoretical analysis to demonstrate that the incorporation of the deterministic contrastive loss can effectively prevent the occurrence of a constant encoder solution. Experimental results show superior performance of our model over various baselines and model variants on real-world industrial datasets.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07898v1","tag":"new-dataset"}}
{"title":"Bent & Broken Bicycles: Leveraging synthetic data for damaged object re-identification","abstract":"Instance-level object re-identification is a fundamental computer vision task, with applications from image retrieval to intelligent monitoring and fraud detection. In this work, we propose the novel task of damaged object re-identification, which aims at distinguishing changes in visual appearance due to deformations or missing parts from subtle intra-class variations. To explore this task, we leverage the power of computer-generated imagery to create, in a semi-automatic fashion, high-quality synthetic images of the same bike before and after a damage occurs. The resulting dataset, Bent & Broken Bicycles (BBBicycles), contains 39,200 images and 2,800 unique bike instances spanning 20 different bike models. As a baseline for this task, we propose TransReI3D, a multi-task, transformer-based deep network unifying damage detection (framed as a multi-label classification task) with object re-identification. The BBBicycles dataset is available at https://huggingface.co/datasets/GrainsPolito/BBBicycles","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07883v1","tag":"new-dataset"}}
{"title":"Sabi\u00e1: Portuguese Large Language Models","abstract":"As the capabilities of language models continue to advance, it is conceivable that \"one-size-fits-all\" model will remain as the main paradigm. For instance, given the vast number of languages worldwide, many of which are low-resource, the prevalent practice is to pretrain a single model on multiple languages. In this paper, we add to the growing body of evidence that challenges this practice, demonstrating that monolingual pretraining on the target language significantly improves models already extensively trained on diverse corpora. More specifically, we further pretrain GPT-J and LLaMA models on Portuguese texts using 3% or less of their original pretraining budget. Few-shot evaluations on Poeta, a suite of 14 Portuguese datasets, reveal that our models outperform English-centric and multilingual counterparts by a significant margin. Our best model, Sabi\\'a-65B, performs on par with GPT-3.5-turbo. By evaluating on datasets originally conceived in the target language as well as translated ones, we study the contributions of language-specific pretraining in terms of 1) capturing linguistic nuances and structures inherent to the target language, and 2) enriching the model's knowledge about a domain or culture. Our results indicate that the majority of the benefits stem from the domain-specific knowledge acquired through monolingual pretraining.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07880v1","tag":"new-dataset"}}
{"title":"A Quantum Computing-driven Aid for New Material Design","abstract":"Material discovery is a phenomenon practiced since the evolution of the world. The Discovery of materials had led to significant development in varied fields such as Science, Engineering and Technology etc., It had been a slow and long-drawn process, however, technological advancement had led to the rapid discovery of materials and the creation of a database that documented the earlier research and development. Many intervening technologies at varying levels of efficiency were developed to advance the discovery of materials in the past and create a database. Quantum computing is a recent development that further advances precision and accuracy. In this study, the ground state energy of molecules such as GeO2, SiO2, SiGe, ZrO2 and LiH were found using the quantum algorithm Variational Quantum Eigensolver (VQE). Also, a database consisting of the elements and molecules with the data of their Hamiltonian and Ground State energy was developed.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07879v1","tag":"new-dataset"}}
{"title":"The Segment Anything foundation model achieves favorable brain tumor autosegmentation accuracy on MRI to support radiotherapy treatment planning","abstract":"Background: Tumor segmentation in MRI is crucial in radiotherapy (RT) treatment planning for brain tumor patients. Segment anything (SA), a novel promptable foundation model for autosegmentation, has shown high accuracy for multiple segmentation tasks but was not evaluated on medical datasets yet. Methods: SA was evaluated in a point-to-mask task for glioma brain tumor autosegmentation on 16744 transversal slices from 369 MRI datasets (BraTS 2020). Up to 9 point prompts were placed per slice. Tumor core (enhancing tumor + necrotic core) was segmented on contrast-enhanced T1w sequences. Out of the 3 masks predicted by SA, accuracy was evaluated for the mask with the highest calculated IoU (oracle mask) and with highest model predicted IoU (suggested mask). In addition to assessing SA on whole MRI slices, SA was also evaluated on images cropped to the tumor (max. 3D extent + 2 cm). Results: Mean best IoU (mbIoU) using oracle mask on full MRI slices was 0.762 (IQR 0.713-0.917). Best 2D mask was achieved after a mean of 6.6 point prompts (IQR 5-9). Segmentation accuracy was significantly better for high- compared to low-grade glioma cases (mbIoU 0.789 vs. 0.668). Accuracy was worse using MRI slices cropped to the tumor (mbIoU 0.759) and was much worse using suggested mask (full slices 0.572). For all experiments, accuracy was low on peripheral slices with few tumor voxels (mbIoU, <300: 0.537 vs. >=300: 0.841). Stacking best oracle segmentations from full axial MRI slices, mean 3D DSC for tumor core was 0.872, which was improved to 0.919 by combining axial, sagittal and coronal masks. Conclusions: The Segment Anything foundation model, while trained on photos, can achieve high zero-shot accuracy for glioma brain tumor segmentation on MRI slices. The results suggest that Segment Anything can accelerate and facilitate RT treatment planning, when properly integrated in a clinical application.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07875v1","tag":"new-dataset"}}
{"title":"A Data-Centric Solution to NonHomogeneous Dehazing via Vision Transformer","abstract":"Recent years have witnessed an increased interest in image dehazing. Many deep learning methods have been proposed to tackle this challenge, and have made significant accomplishments dealing with homogeneous haze. However, these solutions cannot maintain comparable performance when they are applied to images with non-homogeneous haze, e.g., NH-HAZE23 dataset introduced by NTIRE challenges. One of the reasons for such failures is that non-homogeneous haze does not obey one of the assumptions that is required for modeling homogeneous haze. In addition, a large number of pairs of non-homogeneous hazy image and the clean counterpart is required using traditional end-to-end training approaches, while NH-HAZE23 dataset is of limited quantities. Although it is possible to augment the NH-HAZE23 dataset by leveraging other non-homogeneous dehazing datasets, we observe that it is necessary to design a proper data-preprocessing approach that reduces the distribution gaps between the target dataset and the augmented one. This finding indeed aligns with the essence of data-centric AI. With a novel network architecture and a principled data-preprocessing approach that systematically enhances data quality, we present an innovative dehazing method. Specifically, we apply RGB-channel-wise transformations on the augmented datasets, and incorporate the state-of-the-art transformers as the backbone in the two-branch framework. We conduct extensive experiments and ablation study to demonstrate the effectiveness of our proposed method.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07874v2","tag":"new-dataset"}}
{"title":"PBNR: Prompt-based News Recommender System","abstract":"Online news platforms often use personalized news recommendation methods to help users discover articles that align with their interests. These methods typically predict a matching score between a user and a candidate article to reflect the user's preference for the article. Some previous works have used language model techniques, such as the attention mechanism, to capture users' interests based on their past behaviors, and to understand the content of articles. However, these existing model architectures require adjustments if additional information is taken into account. Pre-trained large language models, which can better capture word relationships and comprehend contexts, have seen a significant development in recent years, and these pre-trained models have the advantages of transfer learning and reducing the training time for downstream tasks. Meanwhile, prompt learning is a newly developed technique that leverages pre-trained language models by building task-specific guidance for output generations. To leverage textual information in news articles, this paper introduces the pre-trained large language model and prompt-learning to the community of news recommendation. The proposed model \"prompt-based news recommendation\" (PBNR) treats the personalized news recommendation as a text-to-text language task and designs personalized prompts to adapt to the pre-trained language model -- text-to-text transfer transformer (T5). Experimental studies using the Microsoft News dataset show that PBNR is capable of making accurate recommendations by taking into account various lengths of past behaviors of different users. PBNR can also easily adapt to new information without changing the model architecture and the training objective. Additionally, PBNR can make recommendations based on users' specific requirements, allowing human-computer interaction in the news recommendation field.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07862v1","tag":"new-dataset"}}
{"title":"Cold-Start based Multi-Scenario Ranking Model for Click-Through Rate Prediction","abstract":"Online travel platforms (OTPs), e.g., Ctrip.com or Fliggy.com, can effectively provide travel-related products or services to users. In this paper, we focus on the multi-scenario click-through rate (CTR) prediction, i.e., training a unified model to serve all scenarios. Existing multi-scenario based CTR methods struggle in the context of OTP setting due to the ignorance of the cold-start users who have very limited data. To fill this gap, we propose a novel method named Cold-Start based Multi-scenario Network (CSMN). Specifically, it consists of two basic components including: 1) User Interest Projection Network (UIPN), which firstly purifies users' behaviors by eliminating the scenario-irrelevant information in behaviors with respect to the visiting scenario, followed by obtaining users' scenario-specific interests by summarizing the purified behaviors with respect to the target item via an attention mechanism; and 2) User Representation Memory Network (URMN), which benefits cold-start users from users with rich behaviors through a memory read and write mechanism. CSMN seamlessly integrates both components in an end-to-end learning framework. Extensive experiments on real-world offline dataset and online A/B test demonstrate the superiority of CSMN over state-of-the-art methods.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07858v1","tag":"new-dataset"}}
{"title":"Towards Better Instruction Following Language Models for Chinese: Investigating the Impact of Training Data and Evaluation","abstract":"Recently, significant public efforts have been directed towards developing low-cost models with capabilities akin to ChatGPT, thereby fostering the growth of open-source conversational models. However, there remains a scarcity of comprehensive and in-depth evaluations of these models' performance. In this study, we examine the influence of training data factors, including quantity, quality, and linguistic distribution, on model performance. Our analysis is grounded in several publicly accessible, high-quality instruction datasets, as well as our own Chinese multi-turn conversations. We assess various models using a evaluation set of 1,000 samples, encompassing nine real-world scenarios. Our goal is to supplement manual evaluations with quantitative analyses, offering valuable insights for the continued advancement of open-source chat models. Furthermore, to enhance the performance and training and inference efficiency of models in the Chinese domain, we extend the vocabulary of LLaMA - the model with the closest open-source performance to proprietary language models like GPT-3 - and conduct secondary pre-training on 3.4B Chinese words. We make our model, data, as well as code publicly available.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07854v1","tag":"new-dataset"}}
{"title":"ChatPLUG: Open-Domain Generative Dialogue System with Internet-Augmented Instruction Tuning for Digital Human","abstract":"In this paper, we present ChatPLUG, a Chinese open-domain dialogue system for digital human applications that instruction finetunes on a wide range of dialogue tasks in a unified internet-augmented format. Different from other open-domain dialogue models that focus on large-scale pre-training and scaling up model size or dialogue corpus, we aim to build a powerful and practical dialogue system for digital human with diverse skills and good multi-task generalization by internet-augmented instruction tuning. To this end, we first conduct large-scale pre-training on both common document corpus and dialogue data with curriculum learning, so as to inject various world knowledge and dialogue abilities into ChatPLUG. Then, we collect a wide range of dialogue tasks spanning diverse features of knowledge, personality, multi-turn memory, and empathy, on which we further instruction tune \\modelname via unified natural language instruction templates. External knowledge from an internet search is also used during instruction finetuning for alleviating the problem of knowledge hallucinations. We show that \\modelname outperforms state-of-the-art Chinese dialogue systems on both automatic and human evaluation, and demonstrates strong multi-task generalization on a variety of text understanding and generation tasks. In addition, we deploy \\modelname to real-world applications such as Smart Speaker and Instant Message applications with fast inference. Our models and code will be made publicly available on ModelScope~\\footnote{\\small{https://modelscope.cn/models/damo/ChatPLUG-3.7B}} and Github~\\footnote{\\small{https://github.com/X-PLUG/ChatPLUG}}.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07849v1","tag":"new-dataset"}}
{"title":"Automated Program Repair Based on Code Review: How do Pre-trained Transformer Models Perform?","abstract":"Sequence-to-sequence models have been used to transform erroneous programs into correct ones when trained with a large enough dataset. Some recent studies also demonstrated strong empirical evidence that code review (natural language instruction about suggestive changes in code) can improve the program repair further. Large language models, trained with Natural Language (NL) and computer program corpora, have the capacity to contain inherent knowledge of both. In this study, we investigate if this inherent knowledge of code and NL can be utilized to improve automated program repair. We applied PLBART and CodeT5, two state-of-the-art language models that are pre-trained with both Programming Language (PL) and Natural Language (NL), on two such natural language-based program repair datasets and found that the pre-trained language models fine-tuned with datasets containing both code review and subsequent code changes notably outperform each of the previous models. We observed that the pre-trained models improve the previously best-reported results by 9.91% on the Review4Repair dataset and by 24.72% on the dataset by Tufano et al. This suggests that a pre-trained sequential model has a better understanding of natural language and can utilize it much better. We performed an ablation study to assess the contribution of the pre-training mechanism and the model architecture. We found that pre-training was significantly more important in the performance gain than the model architecture. The practical application of using pre-trained transformer models in the context of automated program repair is still a long way off. However, our study demonstrates the substantial value of employing pre-trained models, paving the path for future studies to use more of these.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07840v1","tag":"new-dataset"}}
{"title":"Characterizing the load profile in power grids by Koopman mode decomposition of interconnected dynamics","abstract":"Electricity load forecasting is crucial for effectively managing and optimizing power grids. Over the past few decades, various statistical and deep learning approaches have been used to develop load forecasting models. This paper presents an interpretable machine learning approach that identifies load dynamics using data-driven methods within an operator-theoretic framework. We represent the load data using the Koopman operator, which is inherent to the underlying dynamics. By computing the corresponding eigenfunctions, we decompose the load dynamics into coherent spatiotemporal patterns that are the most robust features of the dynamics. Each pattern evolves independently according to its single frequency, making its predictability based on linear dynamics. We emphasize that the load dynamics are constructed based on coherent spatiotemporal patterns that are intrinsic to the dynamics and are capable of encoding rich dynamical features at multiple time scales. These features are related to complex interactions over interconnected power grids and different exogenous effects. To implement the Koopman operator approach more efficiently, we cluster the load data using a modern kernel-based clustering approach and identify power stations with similar load patterns, particularly those with synchronized dynamics. We evaluate our approach using a large-scale dataset from a renewable electric power system within the continental European electricity system and show that the Koopman-based approach outperforms a deep learning (LSTM) architecture in terms of accuracy and computational efficiency. The code for this paper has been deposited in a GitHub repository, which can be accessed at the following address github.com/Shakeri-Lab/Power-Grids.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07832v1","tag":"new-dataset"}}
{"title":"A Random-patch based Defense Strategy Against Physical Attacks for Face Recognition Systems","abstract":"The physical attack has been regarded as a kind of threat against real-world computer vision systems. Still, many existing defense methods are only useful for small perturbations attacks and can't detect physical attacks effectively. In this paper, we propose a random-patch based defense strategy to robustly detect physical attacks for Face Recognition System (FRS). Different from mainstream defense methods which focus on building complex deep neural networks (DNN) to achieve high recognition rate on attacks, we introduce a patch based defense strategy to a standard DNN aiming to obtain robust detection models. Extensive experimental results on the employed datasets show the superiority of the proposed defense method on detecting white-box attacks and adaptive attacks which attack both FRS and the defense method. Additionally, due to the simpleness yet robustness of our method, it can be easily applied to the real world face recognition system and extended to other defense methods to boost the detection performance.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07822v1","tag":"new-dataset"}}
{"title":"Time-dependent Iterative Imputation for Multivariate Longitudinal Clinical Data","abstract":"Missing data is a major challenge in clinical research. In electronic medical records, often a large fraction of the values in laboratory tests and vital signs are missing. The missingness can lead to biased estimates and limit our ability to draw conclusions from the data. Additionally, many machine learning algorithms can only be applied to complete datasets. A common solution is data imputation, the process of filling-in the missing values. However, some of the popular imputation approaches perform poorly on clinical data. We developed a simple new approach, Time-Dependent Iterative imputation (TDI), which offers a practical solution for imputing time-series data. It addresses both multivariate and longitudinal data, by integrating forward-filling and Iterative Imputer. The integration employs a patient, variable, and observation-specific dynamic weighting strategy, based on the clinical patterns of the data, including missing rates and measurement frequency. We tested TDI on randomly masked clinical datasets. When applied to a cohort consisting of more than 500,000 patient observations from MIMIC III, our approach outperformed state-of-the-art imputation methods for 25 out of 30 clinical variables, with an overall root-mean-squared-error of 0.63, compared to 0.85 for SoftImpute, the second best method. MIMIC III and COVID-19 inpatient datasets were used to perform prediction tasks. Importantly, these tests demonstrated that TDI imputation can lead to improved risk prediction.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07821v1","tag":"new-dataset"}}
{"title":"EasyNER: A Customizable Easy-to-Use Pipeline for Deep Learning- and Dictionary-based Named Entity Recognition from Medical Text","abstract":"Medical research generates a large number of publications with the PubMed database already containing >35 million research articles. Integration of the knowledge scattered across this large body of literature could provide key insights into physiological mechanisms and disease processes leading to novel medical interventions. However, it is a great challenge for researchers to utilize this information in full since the scale and complexity of the data greatly surpasses human processing abilities. This becomes especially problematic in cases of extreme urgency like the COVID-19 pandemic. Automated text mining can help extract and connect information from the large body of medical research articles. The first step in text mining is typically the identification of specific classes of keywords (e.g., all protein or disease names), so called Named Entity Recognition (NER). Here we present an end-to-end pipeline for NER of typical entities found in medical research articles, including diseases, cells, chemicals, genes/proteins, and species. The pipeline can access and process large medical research article collections (PubMed, CORD-19) or raw text and incorporates a series of deep learning models fine-tuned on the HUNER corpora collection. In addition, the pipeline can perform dictionary-based NER related to COVID-19 and other medical topics. Users can also load their own NER models and dictionaries to include additional entities. The output consists of publication-ready ranked lists and graphs of detected entities and files containing the annotated texts. An associated script allows rapid inspection of the results for specific entities of interest. As model use cases, the pipeline was deployed on two collections of autophagy-related abstracts from PubMed and on the CORD19 dataset, a collection of 764 398 research article abstracts related to COVID-19.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07805v1","tag":"new-dataset"}}
{"title":"Dark matter search with CMB: a study of foregrounds","abstract":"The energy injected from dark matter annihilation and decay processes potentially raises the ionisation of the intergalactic medium and leaves visible footprints on the anisotropy maps of the cosmic microwave background (CMB). Galactic foregrounds emission in the microwave bands contaminate the CMB measurement and may affect the search for dark matter's signature. In this paper, we construct a full CMB data and foreground simulation based on the design of the next-generation ground-based CMB experiments. The foreground residual after the components separation on maps is fully considered in our data analysis, accounting for various contamination from the emission of synchrotron, thermal dust, free-free and spinning dust. We analyse the corresponding sensitivity on dark matter parameters from the temperature and polarization maps, and we find that the CMB foregrounds leave a non-zero yet controllable impact on the sensitivity. Comparing with statistics-only analysis, the CMB foreground residual leads to a factor of 7%-23% weakening on energy-injection constraints, depending on the specific dark matter process and experimental configuration. Strong limits on dark matter annihilation rate and decay lifetime can be expected after foreground subtraction.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07793v1","tag":"new-dataset"}}
{"title":"SikuGPT: A Generative Pre-trained Model for Intelligent Information Processing of Ancient Texts from the Perspective of Digital Humanities","abstract":"The rapid advance in artificial intelligence technology has facilitated the prosperity of digital humanities research. Against such backdrop, research methods need to be transformed in the intelligent processing of ancient texts, which is a crucial component of digital humanities research, so as to adapt to new development trends in the wave of AIGC. In this study, we propose a GPT model called SikuGPT based on the corpus of Siku Quanshu. The model's performance in tasks such as intralingual translation and text classification exceeds that of other GPT-type models aimed at processing ancient texts. SikuGPT's ability to process traditional Chinese ancient texts can help promote the organization of ancient information and knowledge services, as well as the international dissemination of Chinese ancient culture.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07778v1","tag":"new-dataset"}}
{"title":"Syntactic Complexity Identification, Measurement, and Reduction Through Controlled Syntactic Simplification","abstract":"Text simplification is one of the domains in Natural Language Processing (NLP) that offers an opportunity to understand the text in a simplified manner for exploration. However, it is always hard to understand and retrieve knowledge from unstructured text, which is usually in the form of compound and complex sentences. There are state-of-the-art neural network-based methods to simplify the sentences for improved readability while replacing words with plain English substitutes and summarising the sentences and paragraphs. In the Knowledge Graph (KG) creation process from unstructured text, summarising long sentences and substituting words is undesirable since this may lead to information loss. However, KG creation from text requires the extraction of all possible facts (triples) with the same mentions as in the text. In this work, we propose a controlled simplification based on the factual information in a sentence, i.e., triple. We present a classical syntactic dependency-based approach to split and rephrase a compound and complex sentence into a set of simplified sentences. This simplification process will retain the original wording with a simple structure of possible domain facts in each sentence, i.e., triples. The paper also introduces an algorithm to identify and measure a sentence's syntactic complexity (SC), followed by reduction through a controlled syntactic simplification process. Last, an experiment for a dataset re-annotation is also conducted through GPT3; we aim to publish this refined corpus as a resource. This work is accepted and presented in International workshop on Learning with Knowledge Graphs (IWLKG) at WSDM-2023 Conference. The code and data is available at www.github.com/sallmanm/SynSim.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07774v1","tag":"new-dataset"}}
{"title":"A Comprehensive Evaluation of the Copy Mechanism for Natural Language to SPARQL Query Generation","abstract":"In recent years, the field of neural machine translation (NMT) for SPARQL query generation has witnessed a significant growth. Recently, the incorporation of the copy mechanism with traditional encoder-decoder architectures and the use of pre-trained encoder-decoders have set new performance benchmarks. This paper presents a large variety of experiments that replicate and expand upon recent NMT-based SPARQL generation studies, comparing pre-trained and non-pre-trained models, question annotation formats, and the use of a copy mechanism for non-pre-trained and pre-trained models. Our results show that either adding the copy mechanism or using a question annotation improves performances for nonpre-trained models and for pre-trained models, setting new baselines for three popular datasets.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07772v1","tag":"new-dataset"}}
{"title":"Regularized Complete Cycle Consistent GAN for Anomaly Detection","abstract":"This study presents an adversarial method for anomaly detection in real-world applications, leveraging the power of generative adversarial neural networks (GANs) through cycle consistency in reconstruction error. Previous methods suffer from the high variance between class-wise accuracy which leads to not being applicable for all types of anomalies. The proposed method named RCALAD tries to solve this problem by introducing a novel discriminator to the structure, which results in a more efficient training process. Additionally, RCALAD employs a supplementary distribution in the input space to steer reconstructions toward the normal data distribution, effectively separating anomalous samples from their reconstructions and facilitating more accurate anomaly detection. To further enhance the performance of the model, two novel anomaly scores are introduced. The proposed model has been thoroughly evaluated through extensive experiments on six various datasets, yielding results that demonstrate its superiority over existing state-of-the-art models. The code is readily available to the research community at https://github.com/zahraDehghanian97/RCALAD.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07769v1","tag":"new-dataset"}}
{"title":"Meta-optimized Contrastive Learning for Sequential Recommendation","abstract":"Contrastive Learning (CL) performances as a rising approach to address the challenge of sparse and noisy recommendation data. Although having achieved promising results, most existing CL methods only perform either hand-crafted data or model augmentation for generating contrastive pairs to find a proper augmentation operation for different datasets, which makes the model hard to generalize. Additionally, since insufficient input data may lead the encoder to learn collapsed embeddings, these CL methods expect a relatively large number of training data (e.g., large batch size or memory bank) to contrast. However, not all contrastive pairs are always informative and discriminative enough for the training processing. Therefore, a more general CL-based recommendation model called Meta-optimized Contrastive Learning for sequential Recommendation (MCLRec) is proposed in this work. By applying both data augmentation and learnable model augmentation operations, this work innovates the standard CL framework by contrasting data and model augmented views for adaptively capturing the informative features hidden in stochastic data augmentation. Moreover, MCLRec utilizes a meta-learning manner to guide the updating of the model augmenters, which helps to improve the quality of contrastive pairs without enlarging the amount of input data. Finally, a contrastive regularization term is considered to encourage the augmentation model to generate more informative augmented views and avoid too similar contrastive pairs within the meta updating. The experimental results on commonly used datasets validate the effectiveness of MCLRec.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07763v1","tag":"new-dataset"}}
{"title":"MisRoB\u00c6RTa: Transformers versus Misinformation","abstract":"Misinformation is considered a threat to our democratic values and principles. The spread of such content on social media polarizes society and undermines public discourse by distorting public perceptions and generating social unrest while lacking the rigor of traditional journalism. Transformers and transfer learning proved to be state-of-the-art methods for multiple well-known natural language processing tasks. In this paper, we propose MisRoB{\\AE}RTa, a novel transformer-based deep neural ensemble architecture for misinformation detection. MisRoB{\\AE}RTa takes advantage of two transformers (BART \\& RoBERTa) to improve the classification performance. We also benchmarked and evaluated the performances of multiple transformers on the task of misinformation detection. For training and testing, we used a large real-world news articles dataset labeled with 10 classes, addressing two shortcomings in the current research: increasing the size of the dataset from small to large, and moving the focus of fake news detection from binary classification to multi-class classification. For this dataset, we manually verified the content of the news articles to ensure that they were correctly labeled. The experimental results show that the accuracy of transformers on the misinformation detection problem was significantly influenced by the method employed to learn the context, dataset size, and vocabulary dimension. We observe empirically that the best accuracy performance among the classification models that use only one transformer is obtained by BART, while DistilRoBERTa obtains the best accuracy in the least amount of time required for fine-tuning and training. The proposed MisRoB{\\AE}RTa outperforms the other transformer models in the task of misinformation detection. To arrive at this conclusion, we performed ample ablation and sensitivity testing with MisRoB{\\AE}RTa on two datasets.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07759v1","tag":"new-dataset"}}
{"title":"Arbitrary Reduction of MRI Inter-slice Spacing Using Hierarchical Feature Conditional Diffusion","abstract":"Magnetic resonance (MR) images collected in 2D scanning protocols typically have large inter-slice spacing, resulting in high in-plane resolution but reduced through-plane resolution. Super-resolution techniques can reduce the inter-slice spacing of 2D scanned MR images, facilitating the downstream visual experience and computer-aided diagnosis. However, most existing super-resolution methods are trained at a fixed scaling ratio, which is inconvenient in clinical settings where MR scanning may have varying inter-slice spacings. To solve this issue, we propose Hierarchical Feature Conditional Diffusion (HiFi-Diff)} for arbitrary reduction of MR inter-slice spacing. Given two adjacent MR slices and the relative positional offset, HiFi-Diff can iteratively convert a Gaussian noise map into any desired in-between MR slice. Furthermore, to enable fine-grained conditioning, the Hierarchical Feature Extraction (HiFE) module is proposed to hierarchically extract conditional features and conduct element-wise modulation. Our experimental results on the publicly available HCP-1200 dataset demonstrate the high-fidelity super-resolution capability of HiFi-Diff and its efficacy in enhancing downstream segmentation performance.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07756v2","tag":"new-dataset"}}
{"title":"GeoMultiTaskNet: remote sensing unsupervised domain adaptation using geographical coordinates","abstract":"Land cover maps are a pivotal element in a wide range of Earth Observation (EO) applications. However, annotating large datasets to develop supervised systems for remote sensing (RS) semantic segmentation is costly and time-consuming. Unsupervised Domain Adaption (UDA) could tackle these issues by adapting a model trained on a source domain, where labels are available, to a target domain, without annotations. UDA, while gaining importance in computer vision, is still under-investigated in RS. Thus, we propose a new lightweight model, GeoMultiTaskNet, based on two contributions: a GeoMultiTask module (GeoMT), which utilizes geographical coordinates to align the source and target domains, and a Dynamic Class Sampling (DCS) strategy, to adapt the semantic segmentation loss to the frequency of classes. This approach is the first to use geographical metadata for UDA in semantic segmentation. It reaches state-of-the-art performances (47,22% mIoU), reducing at the same time the number of parameters (33M), on a subset of the FLAIR dataset, a recently proposed dataset properly shaped for RS UDA, used for the first time ever for research scopes here.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07750v1","tag":"new-dataset"}}
{"title":"Language Guided Local Infiltration for Interactive Image Retrieval","abstract":"Interactive Image Retrieval (IIR) aims to retrieve images that are generally similar to the reference image but under the requested text modification. The existing methods usually concatenate or sum the features of image and text simply and roughly, which, however, is difficult to precisely change the local semantics of the image that the text intends to modify. To solve this problem, we propose a Language Guided Local Infiltration (LGLI) system, which fully utilizes the text information and penetrates text features into image features as much as possible. Specifically, we first propose a Language Prompt Visual Localization (LPVL) module to generate a localization mask which explicitly locates the region (semantics) intended to be modified. Then we introduce a Text Infiltration with Local Awareness (TILA) module, which is deployed in the network to precisely modify the reference image and generate image-text infiltrated representation. Extensive experiments on various benchmark databases validate that our method outperforms most state-of-the-art IIR approaches.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07747v1","tag":"new-dataset"}}
{"title":"Framework for Quality Evaluation of Smart Roadside Infrastructure Sensors for Automated Driving Applications","abstract":"The use of smart roadside infrastructure sensors is highly relevant for future applications of connected and automated vehicles. External sensor technology in the form of intelligent transportation system stations (ITS-Ss) can provide safety-critical real-time information about road users in the form of a digital twin. The choice of sensor setups has a major influence on the downstream function as well as the data quality. To date, there is insufficient research on which sensor setups result in which levels of ITS-S data quality. We present a novel approach to perform detailed quality assessment for smart roadside infrastructure sensors. Our framework is multimodal across different sensor types and is evaluated on the DAIR-V2X dataset. We analyze the composition of different lidar and camera sensors and assess them in terms of accuracy, latency, and reliability. The evaluations show that the framework can be used reliably for several future ITS-S applications.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07745v1","tag":"new-dataset"}}
{"title":"JoB-VS: Joint Brain-Vessel Segmentation in TOF-MRA Images","abstract":"We propose the first joint-task learning framework for brain and vessel segmentation (JoB-VS) from Time-of-Flight Magnetic Resonance images. Unlike state-of-the-art vessel segmentation methods, our approach avoids the pre-processing step of implementing a model to extract the brain from the volumetric input data. Skipping this additional step makes our method an end-to-end vessel segmentation framework. JoB-VS uses a lattice architecture that favors the segmentation of structures of different scales (e.g., the brain and vessels). Its segmentation head allows the simultaneous prediction of the brain and vessel mask. Moreover, we generate data augmentation with adversarial examples, which our results demonstrate to enhance the performance. JoB-VS achieves 70.03% mean AP and 69.09% F1-score in the OASIS-3 dataset and is capable of generalizing the segmentation in the IXI dataset. These results show the adequacy of JoB-VS for the challenging task of vessel segmentation in complete TOF-MRA images.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07744v1","tag":"new-dataset"}}
{"title":"SeaThru-NeRF: Neural Radiance Fields in Scattering Media","abstract":"Research on neural radiance fields (NeRFs) for novel view generation is exploding with new models and extensions. However, a question that remains unanswered is what happens in underwater or foggy scenes where the medium strongly influences the appearance of objects. Thus far, NeRF and its variants have ignored these cases. However, since the NeRF framework is based on volumetric rendering, it has inherent capability to account for the medium's effects, once modeled appropriately. We develop a new rendering model for NeRFs in scattering media, which is based on the SeaThru image formation model, and suggest a suitable architecture for learning both scene information and medium parameters. We demonstrate the strength of our method using simulated and real-world scenes, correctly rendering novel photorealistic views underwater. Even more excitingly, we can render clear views of these scenes, removing the medium between the camera and the scene and reconstructing the appearance and depth of far objects, which are severely occluded by the medium. Our code and unique datasets are available on the project's website.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07743v1","tag":"new-dataset"}}
{"title":"Holographic inflation in non-static plane symmetric space-time","abstract":"The current analysis uses the non-static plane symmetric space-time to dynamically examine the holographic dark energy model as a candidates of IR cut-offs (specifically Hubble's and Granda-Oliveros cut-off). Using the Markov Chain Monte Carlo (MCMC) method, we estimate the best fit values for the model parameters imposed from the combined datasets of $CC+SC+BAO$. Now, it has been found that the characteristics of space-time that have been addressed and formulated using both models are flat universe and observed that the model appears to be in good agreement with the observations. In addition, we investigate the behavior of equation of state parameters along with the energy conditions. Finally, we found that in both the cut-offs the models predict that the present and late universe are accelerating and the equation of state parameter behaves like the quintessence model.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.09080v1","tag":"new-dataset"}}
{"title":"TransFusionOdom: Interpretable Transformer-based LiDAR-Inertial Fusion Odometry Estimation","abstract":"Multi-modal fusion of sensors is a commonly used approach to enhance the performance of odometry estimation, which is also a fundamental module for mobile robots. However, the question of \\textit{how to perform fusion among different modalities in a supervised sensor fusion odometry estimation task?} is still one of challenging issues remains. Some simple operations, such as element-wise summation and concatenation, are not capable of assigning adaptive attentional weights to incorporate different modalities efficiently, which make it difficult to achieve competitive odometry results. Recently, the Transformer architecture has shown potential for multi-modal fusion tasks, particularly in the domains of vision with language. In this work, we propose an end-to-end supervised Transformer-based LiDAR-Inertial fusion framework (namely TransFusionOdom) for odometry estimation. The multi-attention fusion module demonstrates different fusion approaches for homogeneous and heterogeneous modalities to address the overfitting problem that can arise from blindly increasing the complexity of the model. Additionally, to interpret the learning process of the Transformer-based multi-modal interactions, a general visualization approach is introduced to illustrate the interactions between modalities. Moreover, exhaustive ablation studies evaluate different multi-modal fusion strategies to verify the performance of the proposed fusion strategy. A synthetic multi-modal dataset is made public to validate the generalization ability of the proposed fusion strategy, which also works for other combinations of different modalities. The quantitative and qualitative odometry evaluations on the KITTI dataset verify the proposed TransFusionOdom could achieve superior performance compared with other related works.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07728v1","tag":"new-dataset"}}
{"title":"MS-LSTM: Exploring Spatiotemporal Multiscale Representations in Video Prediction Domain","abstract":"The drastic variation of motion in spatial and temporal dimensions makes the video prediction task extremely challenging. Existing RNN models obtain higher performance by deepening or widening the model. They obtain the multi-scale features of the video only by stacking layers, which is inefficient and brings unbearable training costs (such as memory, FLOPs, and training time). Different from them, this paper proposes a spatiotemporal multi-scale model called MS-LSTM wholly from a multi-scale perspective. On the basis of stacked layers, MS-LSTM incorporates two additional efficient multi-scale designs to fully capture spatiotemporal context information. Concretely, we employ LSTMs with mirrored pyramid structures to construct spatial multi-scale representations and LSTMs with different convolution kernels to construct temporal multi-scale representations. Detailed comparison experiments with eight baseline models on four video datasets show that MS-LSTM has better performance but lower training costs.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07724v1","tag":"new-dataset"}}
{"title":"A Novel end-to-end Framework for Occluded Pixel Reconstruction with Spatio-temporal Features for Improved Person Re-identification","abstract":"Person re-identification is vital for monitoring and tracking crowd movement to enhance public security. However, re-identification in the presence of occlusion substantially reduces the performance of existing systems and is a challenging area. In this work, we propose a plausible solution to this problem by developing effective occlusion detection and reconstruction framework for RGB images/videos consisting of Deep Neural Networks. Specifically, a CNN-based occlusion detection model classifies individual input frames, followed by a Conv-LSTM and Autoencoder to reconstruct the occluded pixels corresponding to the occluded frames for sequential (video) and non-sequential (image) data, respectively. The quality of the reconstructed RGB frames is further refined and fine-tuned using a Conditional Generative Adversarial Network (cGAN). Our method is evaluated on four well-known public data sets of the domain, and the qualitative reconstruction results are indeed appealing. Quantitative evaluation in terms of re-identification accuracy of the Siamese network showed an exceptional Rank-1 accuracy after occluded pixel reconstruction on various datasets. A comparative analysis with state-of-the-art approaches also demonstrates the robustness of our work for use in real-life surveillance systems.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07721v1","tag":"new-dataset"}}
{"title":"The Gaia-ESO Survey: homogenisation of stellar parameters and elemental abundances","abstract":"The Gaia-ESO Survey is a public spectroscopic survey that has targeted $\\gtrsim10^5$ stars covering all major components of the Milky Way from the end of 2011 to 2018, delivering its public final release in May 2022. Unlike other spectroscopic surveys, Gaia-ESO is the only survey that observed stars across all spectral types with dedicated, specialised analyses: from O ($T_\\mathrm{eff} \\sim 30,000-52,000$~K) all the way to K-M ($\\gtrsim$3,500~K). The physics throughout these stellar regimes varies significantly, which has previously prohibited any detailed comparisons between stars of significantly different type. In the final data release (internal data release 6) of the Gaia-ESO Survey, we provide the final database containing a large number of products such as radial velocities, stellar parameters and elemental abundances, rotational velocity, and also, e.g., activity and accretion indicators in young stars and membership probability in star clusters for more than 114,000 stars. The spectral analysis is coordinated by a number of Working Groups (WGs) within the Survey, which specialise in the various stellar samples. Common targets are analysed across WGs to allow for comparisons (and calibrations) amongst instrumental setups and spectral types. Here we describe the procedures employed to ensure all Survey results are placed on a common scale to arrive at a single set of recommended results for all Survey collaborators to use. We also present some general quality and consistency checks performed over all Survey results.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07720v1","tag":"new-dataset"}}
{"title":"Data-OOB: Out-of-bag Estimate as a Simple and Efficient Data Value","abstract":"Data valuation is a powerful framework for providing statistical insights into which data are beneficial or detrimental to model training. Many Shapley-based data valuation methods have shown promising results in various downstream tasks, however, they are well known to be computationally challenging as it requires training a large number of models. As a result, it has been recognized as infeasible to apply to large datasets. To address this issue, we propose Data-OOB, a new data valuation method for a bagging model that utilizes the out-of-bag estimate. The proposed method is computationally efficient and can scale to millions of data by reusing trained weak learners. Specifically, Data-OOB takes less than 2.25 hours on a single CPU processor when there are $10^6$ samples to evaluate and the input dimension is 100. Furthermore, Data-OOB has solid theoretical interpretations in that it identifies the same important data point as the infinitesimal jackknife influence function when two different points are compared. We conduct comprehensive experiments using 12 classification datasets, each with thousands of sample sizes. We demonstrate that the proposed method significantly outperforms existing state-of-the-art data valuation methods in identifying mislabeled data and finding a set of helpful (or harmful) data points, highlighting the potential for applying data values in real-world applications.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07718v1","tag":"new-dataset"}}
{"title":"Development of Tools for the Classification of Peer Groups Geographies in the Analysis of Health Care Variation","abstract":"This dissertation is based on a project co-founded by the Health Market Quality Program (now Rozetta Institute) and the Australian Institute of Health and Welfare. The overall objective of this work is to provide a framework and a tool for classification and clustering of homogeneous geographic areas based on aggregated population data. Thus, to enable the presentation and reporting of comparable information of individual units with peers, I develop the Homogeneity and Location indices to measure respectively the dispersion and central tendency of a categorical ordinal distribution. The advantages of such indices include statistical efficiency and a simple presentation of results. Our approach is founded on the general theory of probability distributions, and our aim is to provide a natural benchmark for a homogeneity measure in terms of what is a \"high\" and \"low\" concentration of a probability distribution. Currently, there is no accepted benchmark that could be used to assess the homogeneity of a categorical ordinal variable. In this work, the proposed statistical indices are used to assess the socioeconomic homogeneity of the commonly used SA3 Australia census geography and analyse the variation of GP attenders in the metropolitan area of Sydney. The approach can be used to classify any geographic area and explore variation across any specified geographical boundaries. The SA3 dataset and scripts (R/Python) to develop these indices have been made available on my GitHub account: https://github.com/lpinzari/homogeneity-location-index","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07709v1","tag":"new-dataset"}}
{"title":"Handling Heavy Occlusion in Dense Crowd Tracking by Focusing on the Heads","abstract":"With the rapid development of deep learning, object detection and tracking play a vital role in today's society. Being able to identify and track all the pedestrians in the dense crowd scene with computer vision approaches is a typical challenge in this field, also known as the Multiple Object Tracking (MOT) challenge. Modern trackers are required to operate on more and more complicated scenes. According to the MOT20 challenge result, the pedestrian is 4 times denser than the MOT17 challenge. Hence, improving the ability to detect and track in extremely crowded scenes is the aim of this work. In light of the occlusion issue with the human body, the heads are usually easier to identify. In this work, we have designed a joint head and body detector in an anchor-free style to boost the detection recall and precision performance of pedestrians in both small and medium sizes. Innovatively, our model does not require information on the statistical head-body ratio for common pedestrians detection for training. Instead, the proposed model learns the ratio dynamically. To verify the effectiveness of the proposed model, we evaluate the model with extensive experiments on different datasets, including MOT20, Crowdhuman, and HT21 datasets. As a result, our proposed method significantly improves both the recall and precision rate on small & medium sized pedestrians and achieves state-of-the-art results in these challenging datasets.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07705v1","tag":"new-dataset"}}
{"title":"Towards Better Evaluation of GNN Expressiveness with BREC Dataset","abstract":"Research on the theoretical expressiveness of Graph Neural Networks (GNNs) has developed rapidly, and many methods have been proposed to enhance the expressiveness. However, most methods do not have a uniform expressiveness measure except for a few that strictly follow the $k$-dimensional Weisfeiler-Lehman ($k$-WL) test hierarchy. Their theoretical analyses are often limited to distinguishing certain families of non-isomorphic graphs, leading to difficulties in quantitatively comparing their expressiveness. In contrast to theoretical analysis, another way to measure expressiveness is by evaluating model performance on certain datasets containing 1-WL-indistinguishable graphs. Previous datasets specifically designed for this purpose, however, face problems with difficulty (any model surpassing 1-WL has nearly 100% accuracy), granularity (models tend to be either 100% correct or near random guess), and scale (only a few essentially different graphs in each dataset). To address these limitations, we propose a new expressiveness dataset, $\\textbf{BREC}$, which includes 400 pairs of non-isomorphic graphs carefully selected from four primary categories (Basic, Regular, Extension, and CFI). These graphs have higher difficulty (up to 4-WL), finer granularity (able to compare models between 1-WL and 3-WL), and a larger scale (400 pairs). Further, we synthetically test 16 models with higher-than-1-WL expressiveness on our BREC dataset. Our experiment gives the first thorough comparison of the expressiveness of those state-of-the-art beyond-1-WL GNN models. We expect this dataset to serve as a benchmark for testing the expressiveness of future GNNs. Our dataset and evaluation code are released at: https://github.com/GraphPKU/BREC.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07702v1","tag":"new-dataset"}}
{"title":"USNID: A Framework for Unsupervised and Semi-supervised New Intent Discovery","abstract":"New intent discovery is of great value to natural language processing, allowing for a better understanding of user needs and providing friendly services. However, most existing methods struggle to capture the complicated semantics of discrete text representations when limited or no prior knowledge of labeled data is available. To tackle this problem, we propose a novel framework called USNID for unsupervised and semi-supervised new intent discovery, which has three key technologies. First, it takes full use of unsupervised or semi-supervised data to mine shallow semantic similarity relations and provide well-initialized representations for clustering. Second, it designs a centroid-guided clustering mechanism to address the issue of cluster allocation inconsistency and provide high-quality self-supervised targets for representation learning. Third, it captures high-level semantics in unsupervised or semi-supervised data to discover fine-grained intent-wise clusters by optimizing both cluster-level and instance-level objectives. We also propose an effective method for estimating the cluster number in open-world scenarios without knowing the number of new intents beforehand. USNID performs exceptionally well on several intent benchmark datasets, achieving new state-of-the-art results in unsupervised and semi-supervised new intent discovery and demonstrating robust performance with different cluster numbers.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07699v1","tag":"new-dataset"}}
{"title":"Translating Simulation Images to X-ray Images via Multi-Scale Semantic Matching","abstract":"Endovascular intervention training is increasingly being conducted in virtual simulators. However, transferring the experience from endovascular simulators to the real world remains an open problem. The key challenge is the virtual environments are usually not realistically simulated, especially the simulation images. In this paper, we propose a new method to translate simulation images from an endovascular simulator to X-ray images. Previous image-to-image translation methods often focus on visual effects and neglect structure information, which is critical for medical images. To address this gap, we propose a new method that utilizes multi-scale semantic matching. We apply self-domain semantic matching to ensure that the input image and the generated image have the same positional semantic relationships. We further apply cross-domain matching to eliminate the effects of different styles. The intensive experiment shows that our method generates realistic X-ray images and outperforms other state-of-the-art approaches by a large margin. We also collect a new large-scale dataset to serve as the new benchmark for this task. Our source code and dataset will be made publicly available.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07693v1","tag":"new-dataset"}}
{"title":"Long-term Visual Localization with Mobile Sensors","abstract":"Despite the remarkable advances in image matching and pose estimation, image-based localization of a camera in a temporally-varying outdoor environment is still a challenging problem due to huge appearance disparity between query and reference images caused by illumination, seasonal and structural changes. In this work, we propose to leverage additional sensors on a mobile phone, mainly GPS, compass, and gravity sensor, to solve this challenging problem. We show that these mobile sensors provide decent initial poses and effective constraints to reduce the searching space in image matching and final pose estimation. With the initial pose, we are also able to devise a direct 2D-3D matching network to efficiently establish 2D-3D correspondences instead of tedious 2D-2D matching in existing systems. As no public dataset exists for the studied problem, we collect a new dataset that provides a variety of mobile sensor data and significant scene appearance variations, and develop a system to acquire ground-truth poses for query images. We benchmark our method as well as several state-of-the-art baselines and demonstrate the effectiveness of the proposed approach. The code and dataset will be released publicly.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07691v1","tag":"new-dataset"}}
{"title":"Learning Empirical Bregman Divergence for Uncertain Distance Representation","abstract":"Deep metric learning techniques have been used for visual representation in various supervised and unsupervised learning tasks through learning embeddings of samples with deep networks. However, classic approaches, which employ a fixed distance metric as a similarity function between two embeddings, may lead to suboptimal performance for capturing the complex data distribution. The Bregman divergence generalizes measures of various distance metrics and arises throughout many fields of deep metric learning. In this paper, we first show how deep metric learning loss can arise from the Bregman divergence. We then introduce a novel method for learning empirical Bregman divergence directly from data based on parameterizing the convex function underlying the Bregman divergence with a deep learning setting. We further experimentally show that our approach performs effectively on five popular public datasets compared to other SOTA deep metric learning methods, particularly for pattern recognition problems.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07689v2","tag":"new-dataset"}}
{"title":"Solving Math Word Problems by Combining Language Models With Symbolic Solvers","abstract":"Automatically generating high-quality step-by-step solutions to math word problems has many applications in education. Recently, combining large language models (LLMs) with external tools to perform complex reasoning and calculation has emerged as a promising direction for solving math word problems, but prior approaches such as Program-Aided Language model (PAL) are biased towards simple procedural problems and less effective for problems that require declarative reasoning. We propose an approach that combines an LLM that can incrementally formalize word problems as a set of variables and equations with an external symbolic solver that can solve the equations. Our approach achieves comparable accuracy to the original PAL on the GSM8K benchmark of math word problems and outperforms PAL by an absolute 20% on ALGEBRA, a new dataset of more challenging word problems extracted from Algebra textbooks. Our work highlights the benefits of using declarative and incremental representations when interfacing with an external tool for solving complex math word problems. Our data and prompts are publicly available at https://github.com/joyheyueya/declarative-math-word-problem.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.09102v1","tag":"new-dataset"}}
{"title":"Autoencoders with Intrinsic Dimension Constraints for Learning Low Dimensional Image Representations","abstract":"Autoencoders have achieved great success in various computer vision applications. The autoencoder learns appropriate low dimensional image representations through the self-supervised paradigm, i.e., reconstruction. Existing studies mainly focus on the minimizing the reconstruction error on pixel level of image, while ignoring the preservation of Intrinsic Dimension (ID), which is a fundamental geometric property of data representations in Deep Neural Networks (DNNs). Motivated by the important role of ID, in this paper, we propose a novel deep representation learning approach with autoencoder, which incorporates regularization of the global and local ID constraints into the reconstruction of data representations. This approach not only preserves the global manifold structure of the whole dataset, but also maintains the local manifold structure of the feature maps of each point, which makes the learned low-dimensional features more discriminant and improves the performance of the downstream algorithms. To our best knowledge, existing works are rare and limited on exploiting both global and local ID invariant properties on the regularization of autoencoders. Numerical experimental results on benchmark datasets (Extended Yale B, Caltech101 and ImageNet) show that the resulting regularized learning models achieve better discriminative representations for downstream tasks including image classification and clustering.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07686v1","tag":"new-dataset"}}
{"title":"Fairness And Bias in Artificial Intelligence: A Brief Survey of Sources, Impacts, And Mitigation Strategies","abstract":"The significant advancements in applying Artificial Intelligence (AI) to healthcare decision-making, medical diagnosis, and other domains have simultaneously raised concerns about the fairness and bias of AI systems, particularly in areas like healthcare, employment, criminal justice, and credit scoring. Such systems can lead to unfair outcomes and perpetuate existing inequalities. This survey paper offers a succinct, comprehensive overview of fairness and bias in AI, addressing their sources, impacts, and mitigation strategies. We review sources of bias, such as data, algorithm, and human decision biases, and assess the societal impact of biased AI systems, focusing on the perpetuation of inequalities and the reinforcement of harmful stereotypes. We explore various proposed mitigation strategies, discussing the ethical considerations of their implementation and emphasizing the need for interdisciplinary collaboration to ensure effectiveness. Through a systematic literature review spanning multiple academic disciplines, we present definitions of AI bias and its different types, and discuss the negative impacts of AI bias on individuals and society. We also provide an overview of current approaches to mitigate AI bias, including data pre-processing, model selection, and post-processing. Addressing bias in AI requires a holistic approach, involving diverse and representative datasets, enhanced transparency and accountability in AI systems, and the exploration of alternative AI paradigms that prioritize fairness and ethical considerations. This survey contributes to the ongoing discussion on developing fair and unbiased AI systems by providing an overview of the sources, impacts, and mitigation strategies related to AI bias.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07683v1","tag":"new-dataset"}}
{"title":"Using Geographic Location-based Public Health Features in Survival Analysis","abstract":"Time elapsed till an event of interest is often modeled using the survival analysis methodology, which estimates a survival score based on the input features. There is a resurgence of interest in developing more accurate prediction models for time-to-event prediction in personalized healthcare using modern tools such as neural networks. Higher quality features and more frequent observations improve the predictions for a patient, however, the impact of including a patient's geographic location-based public health statistics on individual predictions has not been studied. This paper proposes a complementary improvement to survival analysis models by incorporating public health statistics in the input features. We show that including geographic location-based public health information results in a statistically significant improvement in the concordance index evaluated on the Surveillance, Epidemiology, and End Results (SEER) dataset containing nationwide cancer incidence data. The improvement holds for both the standard Cox proportional hazards model and the state-of-the-art Deep Survival Machines model. Our results indicate the utility of geographic location-based public health features in survival analysis.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07679v1","tag":"new-dataset"}}
{"title":"Multimodal Representation Learning of Cardiovascular Magnetic Resonance Imaging","abstract":"Self-supervised learning is crucial for clinical imaging applications, given the lack of explicit labels in healthcare. However, conventional approaches that rely on precise vision-language alignment are not always feasible in complex clinical imaging modalities, such as cardiac magnetic resonance (CMR). CMR provides a comprehensive visualization of cardiac anatomy, physiology, and microstructure, making it challenging to interpret. Additionally, CMR reports require synthesizing information from sequences of images and different views, resulting in potentially weak alignment between the study and diagnosis report pair. To overcome these challenges, we propose \\textbf{CMRformer}, a multimodal learning framework to jointly learn sequences of CMR images and associated cardiologist's reports. Moreover, one of the major obstacles to improving CMR study is the lack of large, publicly available datasets. To bridge this gap, we collected a large \\textbf{CMR dataset}, which consists of 13,787 studies from clinical cases. By utilizing our proposed CMRformer and our collected dataset, we achieved remarkable performance in real-world clinical tasks, such as CMR image retrieval and diagnosis report retrieval. Furthermore, the learned representations are evaluated to be practically helpful for downstream applications, such as disease classification. Our work could potentially expedite progress in the CMR study and lead to more accurate and effective diagnosis and treatment.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07675v1","tag":"new-dataset"}}
{"title":"FedBlockHealth: A Synergistic Approach to Privacy and Security in IoT-Enabled Healthcare through Federated Learning and Blockchain","abstract":"The rapid adoption of Internet of Things (IoT) devices in healthcare has introduced new challenges in preserving data privacy, security and patient safety. Traditional approaches need to ensure security and privacy while maintaining computational efficiency, particularly for resource-constrained IoT devices. This paper proposes a novel hybrid approach combining federated learning and blockchain technology to provide a secure and privacy-preserved solution for IoT-enabled healthcare applications. Our approach leverages a public-key cryptosystem that provides semantic security for local model updates, while blockchain technology ensures the integrity of these updates and enforces access control and accountability. The federated learning process enables a secure model aggregation without sharing sensitive patient data. We implement and evaluate our proposed framework using EMNIST datasets, demonstrating its effectiveness in preserving data privacy and security while maintaining computational efficiency. The results suggest that our hybrid approach can significantly enhance the development of secure and privacy-preserved IoT-enabled healthcare applications, offering a promising direction for future research in this field.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07668v1","tag":"new-dataset"}}
{"title":"ArguGPT: evaluating, understanding and identifying argumentative essays generated by GPT models","abstract":"AI generated content (AIGC) presents considerable challenge to educators around the world. Instructors need to be able to detect such text generated by large language models, either with the naked eye or with the help of some tools. There is also growing need to understand the lexical, syntactic and stylistic features of AIGC. To address these challenges in English language teaching, we first present ArguGPT, a balanced corpus of 4,038 argumentative essays generated by 7 GPT models in response to essay prompts from three sources: (1) in-class or homework exercises, (2) TOEFL and (3) GRE writing tasks. Machine-generated texts are paired with roughly equal number of human-written essays with three score levels matched in essay prompts. We then hire English instructors to distinguish machine essays from human ones. Results show that when first exposed to machine-generated essays, the instructors only have an accuracy of 61% in detecting them. But the number rises to 67% after one round of minimal self-training. Next, we perform linguistic analyses of these essays, which show that machines produce sentences with more complex syntactic structures while human essays tend to be lexically more complex. Finally, we test existing AIGC detectors and build our own detectors using SVMs and RoBERTa. Results suggest that a RoBERTa fine-tuned with the training set of ArguGPT achieves above 90% accuracy in both essay- and sentence-level classification. To the best of our knowledge, this is the first comprehensive analysis of argumentative essays produced by generative large language models. Machine-authored essays in ArguGPT and our models will be made publicly available at https://github.com/huhailinguist/ArguGPT","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07666v1","tag":"new-dataset"}}
{"title":"Learned Interpolation for Better Streaming Quantile Approximation with Worst-Case Guarantees","abstract":"An $\\varepsilon$-approximate quantile sketch over a stream of $n$ inputs approximates the rank of any query point $q$ - that is, the number of input points less than $q$ - up to an additive error of $\\varepsilon n$, generally with some probability of at least $1 - 1/\\mathrm{poly}(n)$, while consuming $o(n)$ space. While the celebrated KLL sketch of Karnin, Lang, and Liberty achieves a provably optimal quantile approximation algorithm over worst-case streams, the approximations it achieves in practice are often far from optimal. Indeed, the most commonly used technique in practice is Dunning's t-digest, which often achieves much better approximations than KLL on real-world data but is known to have arbitrarily large errors in the worst case. We apply interpolation techniques to the streaming quantiles problem to attempt to achieve better approximations on real-world data sets than KLL while maintaining similar guarantees in the worst case.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07652v1","tag":"new-dataset"}}
{"title":"LASER: Neuro-Symbolic Learning of Semantic Video Representations","abstract":"Modern AI applications involving video, such as video-text alignment, video search, and video captioning, benefit from a fine-grained understanding of video semantics. Existing approaches for video understanding are either data-hungry and need low-level annotation, or are based on general embeddings that are uninterpretable and can miss important details. We propose LASER, a neuro-symbolic approach that learns semantic video representations by leveraging logic specifications that can capture rich spatial and temporal properties in video data. In particular, we formulate the problem in terms of alignment between raw videos and specifications. The alignment process efficiently trains low-level perception models to extract a fine-grained video representation that conforms to the desired high-level specification. Our pipeline can be trained end-to-end and can incorporate contrastive and semantic loss functions derived from specifications. We evaluate our method on two datasets with rich spatial and temporal specifications: 20BN-Something-Something and MUGEN. We demonstrate that our method not only learns fine-grained video semantics but also outperforms existing baselines on downstream tasks such as video retrieval.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07647v1","tag":"new-dataset"}}
{"title":"Herder Ants: Ant Colony Optimization with Aphids for Discrete Event-Triggered Dynamic Optimization Problems","abstract":"Currently available dynamic optimization strategies for Ant Colony Optimization (ACO) algorithm offer a trade-off of slower algorithm convergence or significant penalty to solution quality after each dynamic change occurs. This paper proposes a discrete dynamic optimization strategy called Ant Colony Optimization (ACO) with Aphids, modelled after a real-world symbiotic relationship between ants and aphids. ACO with Aphids strategy is designed to improve solution quality of discrete domain Dynamic Optimization Problems (DOPs) with event-triggered discrete dynamism. The proposed strategy aims to improve the inter-state convergence rate throughout the entire dynamic optimization. It does so by minimizing the fitness penalty and maximizing the convergence speed that occurs after the dynamic change. This strategy is tested against Full-Restart and Pheromone-Sharing strategies implemented on the same ACO core algorithm solving Dynamic Multidimensional Knapsack Problem (DMKP) benchmarks. ACO with Aphids has demonstrated superior performance over the Pheromone-Sharing strategy in every test on average gap reduced by 29.2%. Also, ACO with Aphids has outperformed the Full-Restart strategy for large datasets groups, and the overall average gap is reduced by 52.5%.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07646v1","tag":"new-dataset"}}
{"title":"TransDocs: Optical Character Recognition with word to word translation","abstract":"While OCR has been used in various applications, its output is not always accurate, leading to misfit words. This research work focuses on improving the optical character recognition (OCR) with ML techniques with integration of OCR with long short-term memory (LSTM) based sequence to sequence deep learning models to perform document translation. This work is based on ANKI dataset for English to Spanish translation. In this work, I have shown comparative study for pre-trained OCR while using deep learning model using LSTM-based seq2seq architecture with attention for machine translation. End-to-end performance of the model has been expressed in BLEU-4 score. This research paper is aimed at researchers and practitioners interested in OCR and its applications in document translation.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07637v1","tag":"new-dataset"}}
{"title":"A CTC Alignment-based Non-autoregressive Transformer for End-to-end Automatic Speech Recognition","abstract":"Recently, end-to-end models have been widely used in automatic speech recognition (ASR) systems. Two of the most representative approaches are connectionist temporal classification (CTC) and attention-based encoder-decoder (AED) models. Autoregressive transformers, variants of AED, adopt an autoregressive mechanism for token generation and thus are relatively slow during inference. In this paper, we present a comprehensive study of a CTC Alignment-based Single-Step Non-Autoregressive Transformer (CASS-NAT) for end-to-end ASR. In CASS-NAT, word embeddings in the autoregressive transformer (AT) are substituted with token-level acoustic embeddings (TAE) that are extracted from encoder outputs with the acoustical boundary information offered by the CTC alignment. TAE can be obtained in parallel, resulting in a parallel generation of output tokens. During training, Viterbi-alignment is used for TAE generation, and multiple training strategies are further explored to improve the word error rate (WER) performance. During inference, an error-based alignment sampling method is investigated in depth to reduce the alignment mismatch in the training and testing processes. Experimental results show that the CASS-NAT has a WER that is close to AT on various ASR tasks, while providing a ~24x inference speedup. With and without self-supervised learning, we achieve new state-of-the-art results for non-autoregressive models on several datasets. We also analyze the behavior of the CASS-NAT decoder to explain why it can perform similarly to AT. We find that TAEs have similar functionality to word embeddings for grammatical structures, which might indicate the possibility of learning some semantic information from TAEs without a language model.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07611v1","tag":"new-dataset"}}
{"title":"LitCall: Learning Implicit Topology for CNN-based Aortic Landmark Localization","abstract":"Landmark detection is a critical component of the image processing pipeline for automated aortic size measurements. Given that the thoracic aorta has a relatively conserved topology across the population and that a human annotator with minimal training can estimate the location of unseen landmarks from limited examples, we proposed an auxiliary learning task to learn the implicit topology of aortic landmarks through a CNN-based network. Specifically, we created a network to predict the location of missing landmarks from the visible ones by minimizing the Implicit Topology loss in an end-to-end manner. The proposed learning task can be easily adapted and combined with Unet-style backbones. To validate our method, we utilized a dataset consisting of 207 CTAs, labeling four landmarks on each aorta. Our method outperforms the state-of-the-art Unet-style architectures (ResUnet, UnetR) in terms of localization accuracy, with only a light (#params=0.4M) overhead. We also demonstrate our approach in two clinically meaningful applications: aortic sub-region division and automatic centerline generation.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07607v1","tag":"new-dataset"}}
{"title":"Learning in latent spaces improves the predictive accuracy of deep neural operators","abstract":"Operator regression provides a powerful means of constructing discretization-invariant emulators for partial-differential equations (PDEs) describing physical systems. Neural operators specifically employ deep neural networks to approximate mappings between infinite-dimensional Banach spaces. As data-driven models, neural operators require the generation of labeled observations, which in cases of complex high-fidelity models result in high-dimensional datasets containing redundant and noisy features, which can hinder gradient-based optimization. Mapping these high-dimensional datasets to a low-dimensional latent space of salient features can make it easier to work with the data and also enhance learning. In this work, we investigate the latent deep operator network (L-DeepONet), an extension of standard DeepONet, which leverages latent representations of high-dimensional PDE input and output functions identified with suitable autoencoders. We illustrate that L-DeepONet outperforms the standard approach in terms of both accuracy and computational efficiency across diverse time-dependent PDEs, e.g., modeling the growth of fracture in brittle materials, convective fluid flows, and large-scale atmospheric flows exhibiting multiscale dynamical features.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07599v1","tag":"new-dataset"}}
{"title":"An Instance Segmentation Dataset of Yeast Cells in Microstructures","abstract":"Extracting single-cell information from microscopy data requires accurate instance-wise segmentations. Obtaining pixel-wise segmentations from microscopy imagery remains a challenging task, especially with the added complexity of microstructured environments. This paper presents a novel dataset for segmenting yeast cells in microstructures. We offer pixel-wise instance segmentation labels for both cells and trap microstructures. In total, we release 493 densely annotated microscopy images. To facilitate a unified comparison between novel segmentation algorithms, we propose a standardized evaluation strategy for our dataset. The aim of the dataset and evaluation strategy is to facilitate the development of new cell segmentation approaches. The dataset is publicly available at https://christophreich1996.github.io/yeast_in_microstructures_dataset/ .","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07597v1","tag":"new-dataset"}}
{"title":"Leveraging Composition-Based Material Descriptors for Machine Learning Optimization","abstract":"In this study, we evaluate several classifiers and focus on selecting a minimal set of appropriate material features. Our objective is to propose and discuss general strategies for reducing the number of descriptors required for material classification. The first strategy involves testing whether the critical temperature of the target material property is invariant with respect to binary groups of composition-based features. We also propose a multi-objective optimization procedure to reduce the set of composition-based material descriptors. The latter procedure is found to be particularly useful when applied to Bayesian classifiers. We test the proposed strategies focusing on low-temperature superconductors material data extracted from a public database.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07592v1","tag":"new-dataset"}}
{"title":"FSDNet-An efficient fire detection network for complex scenarios based on YOLOv3 and DenseNet","abstract":"Fire is one of the common disasters in daily life. To achieve fast and accurate detection of fires, this paper proposes a detection network called FSDNet (Fire Smoke Detection Network), which consists of a feature extraction module, a fire classification module, and a fire detection module. Firstly, a dense connection structure is introduced in the basic feature extraction module to enhance the feature extraction ability of the backbone network and alleviate the gradient disappearance problem. Secondly, a spatial pyramid pooling structure is introduced in the fire detection module, and the Mosaic data augmentation method and CIoU loss function are used in the training process to comprehensively improve the flame feature extraction ability. Finally, in view of the shortcomings of public fire datasets, a fire dataset called MS-FS (Multi-scene Fire And Smoke) containing 11938 fire images was created through data collection, screening, and object annotation. To prove the effectiveness of the proposed method, the accuracy of the method was evaluated on two benchmark fire datasets and MS-FS. The experimental results show that the accuracy of FSDNet on the two benchmark datasets is 99.82% and 91.15%, respectively, and the average precision on MS-FS is 86.80%, which is better than the mainstream fire detection methods.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07584v1","tag":"new-dataset"}}
{"title":"Surveillance Face Presentation Attack Detection Challenge","abstract":"Face Anti-spoofing (FAS) is essential to secure face recognition systems from various physical attacks. However, most of the studies lacked consideration of long-distance scenarios. Specifically, compared with FAS in traditional scenes such as phone unlocking, face payment, and self-service security inspection, FAS in long-distance such as station squares, parks, and self-service supermarkets are equally important, but it has not been sufficiently explored yet. In order to fill this gap in the FAS community, we collect a large-scale Surveillance High-Fidelity Mask (SuHiFiMask). SuHiFiMask contains $10,195$ videos from $101$ subjects of different age groups, which are collected by $7$ mainstream surveillance cameras. Based on this dataset and protocol-$3$ for evaluating the robustness of the algorithm under quality changes, we organized a face presentation attack detection challenge in surveillance scenarios. It attracted 180 teams for the development phase with a total of 37 teams qualifying for the final round. The organization team re-verified and re-ran the submitted code and used the results as the final ranking. In this paper, we present an overview of the challenge, including an introduction to the dataset used, the definition of the protocol, the evaluation metrics, and the announcement of the competition results. Finally, we present the top-ranked algorithms and the research ideas provided by the competition for attack detection in long-range surveillance scenarios.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07580v1","tag":"new-dataset"}}
{"title":"Constructing Effective In-Context Demonstration for Code Intelligence Tasks: An Empirical Study","abstract":"Pre-trained models of code have gained widespread popularity in many code intelligence tasks. Recently, with the scaling of the model and corpus size, large language models have shown the ability of in-context learning. These models employ task instructions and a few demonstration examples as prompts to learn the semantics of the task and make predictions for test samples. This new learning paradigm is training-free and has shown impressive performance in various natural language processing and code intelligence tasks. However, the performance of in-context learning heavily relies on the quality of demonstration, and there has been no systematic investigation into how to construct a good demonstration for code-related tasks with in-context learning.   In this paper, by analyzing the design space of in-context demonstration, we empirically explore the impact of three key factors on the performance of in-context learning in code intelligence tasks: the selection of demonstration examples, the order of demonstration examples, and the number of demonstration examples. We conduct extensive experiments on three code intelligence tasks including bug fixing, code summarization, and program synthesis. Our experimental results demonstrate that all the above three factors dramatically impact the performance of in-context learning in code intelligence tasks. Additionally, we summarize our findings and provide takeaway suggestions on how to construct effective demonstrations, taking into account these three perspectives. We show that a well-constructed demonstration can lead to significant improvements over simple demonstrations and previous fine-tuned state-of-the-art models, e.g., improving EM, BLEU-4, and EM by at least 11.91%, 36.88%, and 37.18% on code summarization, bug fixing and program synthesis, respectively.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07575v1","tag":"new-dataset"}}
{"title":"CoVLR: Coordinating Cross-Modal Consistency and Intra-Modal Structure for Vision-Language Retrieval","abstract":"Current vision-language retrieval aims to perform cross-modal instance search, in which the core idea is to learn the consistent visionlanguage representations. Although the performance of cross-modal retrieval has greatly improved with the development of deep models, we unfortunately find that traditional hard consistency may destroy the original relationships among single-modal instances, leading the performance degradation for single-modal retrieval. To address this challenge, in this paper, we experimentally observe that the vision-language divergence may cause the existence of strong and weak modalities, and the hard cross-modal consistency cannot guarantee that strong modal instances' relationships are not affected by weak modality, resulting in the strong modal instances' relationships perturbed despite learned consistent representations.To this end, we propose a novel and directly Coordinated VisionLanguage Retrieval method (dubbed CoVLR), which aims to study and alleviate the desynchrony problem between the cross-modal alignment and single-modal cluster-preserving tasks. CoVLR addresses this challenge by developing an effective meta-optimization based strategy, in which the cross-modal consistency objective and the intra-modal relation preserving objective are acted as the meta-train and meta-test tasks, thereby CoVLR encourages both tasks to be optimized in a coordinated way. Consequently, we can simultaneously insure cross-modal consistency and intra-modal structure. Experiments on different datasets validate CoVLR can improve single-modal retrieval accuracy whilst preserving crossmodal retrieval capacity compared with the baselines.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07567v1","tag":"new-dataset"}}
{"title":"Icospherical Chemical Objects (ICOs) allow for chemical data augmentation and maintain rotational, translation and permutation invariance","abstract":"Dataset augmentation is a common way to deal with small datasets; Chemistry datasets are often small. Spherical convolutional neural networks (SphNNs) and Icosahedral neural networks (IcoNNs) are a type of geometric machine learning algorithm that maintains rotational symmetry. Molecular structure has rotational invariance and is inherently 3-D, and thus we need 3-D encoding methods to input molecular structure into machine learning. In this paper I present Icospherical Chemical Objects (ICOs) that enable the encoding of 3-D data in a rotationally invariant way which works with spherical or icosahedral neural networks and allows for dataset augmentation. I demonstrate the ICO featurisation method on the following tasks: predicting general molecular properties, predicting solubility of drug like molecules and the protein binding problem and find that ICO and SphNNs perform well on all problems.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07558v1","tag":"new-dataset"}}
{"title":"Shape is (almost) all!: Persistent homology features (PHFs) are an information rich input for efficient molecular machine learning","abstract":"3-D shape is important to chemistry, but how important? Machine learning works best when the inputs are simple and match the problem well. Chemistry datasets tend to be very small compared to those generally used in machine learning so we need to get the most from each datapoint. Persistent homology measures the topological shape properties of point clouds at different scales and is used in topological data analysis. Here we investigate what persistent homology captures about molecular structure and create persistent homology features (PHFs) that encode a molecule's shape whilst losing most of the symbolic detail like atom labels, valence, charge, bonds etc. We demonstrate the usefulness of PHFs on a series of chemical datasets: QM7, lipophilicity, Delaney and Tox21. PHFs work as well as the best benchmarks. PHFs are very information dense and much smaller than other encoding methods yet found, meaning ML algorithms are much more energy efficient. PHFs success despite losing a large amount of chemical detail highlights how much of chemistry can be simplified to topological shape.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07554v1","tag":"new-dataset"}}
{"title":"Gradient-less Federated Gradient Boosting Trees with Learnable Learning Rates","abstract":"The privacy-sensitive nature of decentralized datasets and the robustness of eXtreme Gradient Boosting (XGBoost) on tabular data raise the needs to train XGBoost in the context of federated learning (FL). Existing works on federated XGBoost in the horizontal setting rely on the sharing of gradients, which induce per-node level communication frequency and serious privacy concerns. To alleviate these problems, we develop an innovative framework for horizontal federated XGBoost which does not depend on the sharing of gradients and simultaneously boosts privacy and communication efficiency by making the learning rates of the aggregated tree ensembles learnable. We conduct extensive evaluations on various classification and regression datasets, showing our approach achieves performance comparable to the state-of-the-art method and effectively improves communication efficiency by lowering both communication rounds and communication overhead by factors ranging from 25x to 700x.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07537v1","tag":"new-dataset"}}
{"title":"From Online Behaviours to Images: A Novel Approach to Social Bot Detection","abstract":"Online Social Networks have revolutionized how we consume and share information, but they have also led to a proliferation of content not always reliable and accurate. One particular type of social accounts is known to promote unreputable content, hyperpartisan, and propagandistic information. They are automated accounts, commonly called bots. Focusing on Twitter accounts, we propose a novel approach to bot detection: we first propose a new algorithm that transforms the sequence of actions that an account performs into an image; then, we leverage the strength of Convolutional Neural Networks to proceed with image classification. We compare our performances with state-of-the-art results for bot detection on genuine accounts / bot accounts datasets well known in the literature. The results confirm the effectiveness of the proposal, because the detection capability is on par with the state of the art, if not better in some cases.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07535v1","tag":"new-dataset"}}
{"title":"ALiSNet: Accurate and Lightweight Human Segmentation Network for Fashion E-Commerce","abstract":"Accurately estimating human body shape from photos can enable innovative applications in fashion, from mass customization, to size and fit recommendations and virtual try-on. Body silhouettes calculated from user pictures are effective representations of the body shape for downstream tasks. Smartphones provide a convenient way for users to capture images of their body, and on-device image processing allows predicting body segmentation while protecting users privacy. Existing off-the-shelf methods for human segmentation are closed source and cannot be specialized for our application of body shape and measurement estimation. Therefore, we create a new segmentation model by simplifying Semantic FPN with PointRend, an existing accurate model. We finetune this model on a high-quality dataset of humans in a restricted set of poses relevant for our application. We obtain our final model, ALiSNet, with a size of 4MB and 97.6$\\pm$1.0$\\%$ mIoU, compared to Apple Person Segmentation, which has an accuracy of 94.4$\\pm$5.7$\\%$ mIoU on our dataset.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07533v1","tag":"new-dataset"}}
{"title":"Compete to Win: Enhancing Pseudo Labels for Barely-supervised Medical Image Segmentation","abstract":"This study investigates barely-supervised medical image segmentation where only few labeled data, i.e., single-digit cases are available. We observe the key limitation of the existing state-of-the-art semi-supervised solution cross pseudo supervision is the unsatisfactory precision of foreground classes, leading to a degenerated result under barely-supervised learning. In this paper, we propose a novel Compete-to-Win method (ComWin) to enhance the pseudo label quality. In contrast to directly using one model's predictions as pseudo labels, our key idea is that high-quality pseudo labels should be generated by comparing multiple confidence maps produced by different networks to select the most confident one (a compete-to-win strategy). To further refine pseudo labels at near-boundary areas, an enhanced version of ComWin, namely, ComWin+, is proposed by integrating a boundary-aware enhancement module. Experiments show that our method can achieve the best performance on three public medical image datasets for cardiac structure segmentation, pancreas segmentation and colon tumor segmentation, respectively. The source code is now available at https://github.com/Huiimin5/comwin.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07519v1","tag":"new-dataset"}}
{"title":"S3M: Scalable Statistical Shape Modeling through Unsupervised Correspondences","abstract":"Statistical shape models (SSMs) are an established way to geometrically represent the anatomy of a population with various clinically relevant applications. However, they typically require domain expertise and labor-intensive manual segmentations or landmark annotations to generate. Methods to estimate correspondences for SSMs typically learn with such labels as supervision signals. We address these shortcomings by proposing an unsupervised method that leverages deep geometric features and functional correspondences to learn local and global shape structures across complex anatomies simultaneously. Our pipeline significantly improves unsupervised correspondence estimation for SSMs compared to baseline methods, even on highly irregular surface topologies. We demonstrate this for two different anatomical structures: the thyroid and a multi-chamber heart dataset. Furthermore, our method is robust enough to learn from noisy neural network predictions, enabling scaling SSMs to larger patient populations without manual annotation.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07515v1","tag":"new-dataset"}}
{"title":"Multi-View Graph Representation Learning Beyond Homophily","abstract":"Unsupervised graph representation learning(GRL) aims to distill diverse graph information into task-agnostic embeddings without label supervision. Due to a lack of support from labels, recent representation learning methods usually adopt self-supervised learning, and embeddings are learned by solving a handcrafted auxiliary task(so-called pretext task). However, partially due to the irregular non-Euclidean data in graphs, the pretext tasks are generally designed under homophily assumptions and cornered in the low-frequency signals, which results in significant loss of other signals, especially high-frequency signals widespread in graphs with heterophily. Motivated by this limitation, we propose a multi-view perspective and the usage of diverse pretext tasks to capture different signals in graphs into embeddings. A novel framework, denoted as Multi-view Graph Encoder(MVGE), is proposed, and a set of key designs are identified. More specifically, a set of new pretext tasks are designed to encode different types of signals, and a straightforward operation is propxwosed to maintain both the commodity and personalization in both the attribute and the structural levels. Extensive experiments on synthetic and real-world network datasets show that the node representations learned with MVGE achieve significant performance improvements in three different downstream tasks, especially on graphs with heterophily. Source code is available at \\url{https://github.com/G-AILab/MVGE}.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07509v1","tag":"new-dataset"}}
{"title":"Hierarchical and Contrastive Representation Learning for Knowledge-aware Recommendation","abstract":"Incorporating knowledge graph into recommendation is an effective way to alleviate data sparsity. Most existing knowledge-aware methods usually perform recursive embedding propagation by enumerating graph neighbors. However, the number of nodes' neighbors grows exponentially as the hop number increases, forcing the nodes to be aware of vast neighbors under this recursive propagation for distilling the high-order semantic relatedness. This may induce more harmful noise than useful information into recommendation, leading the learned node representations to be indistinguishable from each other, that is, the well-known over-smoothing issue. To relieve this issue, we propose a Hierarchical and CONtrastive representation learning framework for knowledge-aware recommendation named HiCON. Specifically, for avoiding the exponential expansion of neighbors, we propose a hierarchical message aggregation mechanism to interact separately with low-order neighbors and meta-path-constrained high-order neighbors. Moreover, we also perform cross-order contrastive learning to enforce the representations to be more discriminative. Extensive experiments on three datasets show the remarkable superiority of HiCON over state-of-the-art approaches.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07506v1","tag":"new-dataset"}}
{"title":"Model-based Federated Learning for Accurate MR Image Reconstruction from Undersampled k-space Data","abstract":"Deep learning-based methods have achieved encouraging performances in the field of magnetic resonance (MR) image reconstruction. Nevertheless, to properly learn a powerful and robust model, these methods generally require large quantities of data, the collection of which from multiple centers may cause ethical and data privacy violation issues. Lately, federated learning has served as a promising solution to exploit multi-center data while getting rid of the data transfer between institutions. However, high heterogeneity exists in the data from different centers, and existing federated learning methods tend to use average aggregation methods to combine the client's information, which limits the performance and generalization capability of the trained models. In this paper, we propose a Model-based Federated learning framework (ModFed). ModFed has three major contributions: 1) Different from the existing data-driven federated learning methods, model-driven neural networks are designed to relieve each client's dependency on large data; 2) An adaptive dynamic aggregation scheme is proposed to address the data heterogeneity issue and improve the generalization capability and robustness the trained neural network models; 3) A spatial Laplacian attention mechanism and a personalized client-side loss regularization are introduced to capture the detailed information for accurate image reconstruction. ModFed is evaluated on three in-vivo datasets. Experimental results show that ModFed has strong capability in improving image reconstruction quality and enforcing model generalization capability when compared to the other five state-of-the-art federated learning approaches. Codes will be made available at https://github.com/ternencewu123/ModFed.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07502v1","tag":"new-dataset"}}
{"title":"Robust Educational Dialogue Act Classifiers with Low-Resource and Imbalanced Datasets","abstract":"Dialogue acts (DAs) can represent conversational actions of tutors or students that take place during tutoring dialogues. Automating the identification of DAs in tutoring dialogues is significant to the design of dialogue-based intelligent tutoring systems. Many prior studies employ machine learning models to classify DAs in tutoring dialogues and invest much effort to optimize the classification accuracy by using limited amounts of training data (i.e., low-resource data scenario). However, beyond the classification accuracy, the robustness of the classifier is also important, which can reflect the capability of the classifier on learning the patterns from different class distributions. We note that many prior studies on classifying educational DAs employ cross entropy (CE) loss to optimize DA classifiers on low-resource data with imbalanced DA distribution. The DA classifiers in these studies tend to prioritize accuracy on the majority class at the expense of the minority class which might not be robust to the data with imbalanced ratios of different DA classes. To optimize the robustness of classifiers on imbalanced class distributions, we propose to optimize the performance of the DA classifier by maximizing the area under the ROC curve (AUC) score (i.e., AUC maximization). Through extensive experiments, our study provides evidence that (i) by maximizing AUC in the training process, the DA classifier achieves significant performance improvement compared to the CE approach under low-resource data, and (ii) AUC maximization approaches can improve the robustness of the DA classifier under different class imbalance ratios.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07499v1","tag":"new-dataset"}}
{"title":"BVIP Guiding System with Adaptability to Individual Differences","abstract":"Guiding robots can not only detect close-range obstacles like other guiding tools, but also extend its range to perceive the environment when making decisions. However, most existing works over-simplified the interaction between human agents and robots, ignoring the differences between individuals, resulting in poor experiences for different users. To solve the problem, we propose a data-driven guiding system to cope with the effect brighten by individual differences. In our guiding system, we design a Human Motion Predictor (HMP) and a Robot Dynamics Model (RDM) based on deep neural network, the time convolutional network (TCN) is verified to have the best performance, to predict differences in interaction between different human agents and robots. To train our models, we collected datasets that records the interactions from different human agents. Moreover, given the predictive information of the specific user, we propose a waypoints selector that allows the robot to naturally adapt to the user's state changes, which are mainly reflected in the walking speed. We compare the performance of our models with previous works and achieve significant performance improvements. On this basis, our guiding system demonstrated good adaptability to different human agents. Our guiding system is deployed on a real quadruped robot to verify the practicability.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07494v1","tag":"new-dataset"}}
{"title":"More Is Less: When Do Recommenders Underperform for Data-rich Users?","abstract":"Users of recommender systems tend to differ in their level of interaction with these algorithms, which may affect the quality of recommendations they receive and lead to undesirable performance disparity. In this paper we investigate under what conditions the performance for data-rich and data-poor users diverges for a collection of popular evaluation metrics applied to ten benchmark datasets. We find that Precision is consistently higher for data-rich users across all the datasets; Mean Average Precision is comparable across user groups but its variance is large; Recall yields a counter-intuitive result where the algorithm performs better for data-poor than for data-rich users, which bias is further exacerbated when negative item sampling is employed during evaluation. The final observation suggests that as users interact more with recommender systems, the quality of recommendations they receive degrades (when measured by Recall). Our insights clearly show the importance of an evaluation protocol and its influence on the reported results when studying recommender systems.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07487v1","tag":"new-dataset"}}
{"title":"Region-Enhanced Feature Learning for Scene Semantic Segmentation","abstract":"Semantic segmentation in complex scenes not only relies on local object appearance but also on object locations and the surrounding environment. Nonetheless, it is difficult to model long-range context in the format of pairwise point correlations due to its huge computational cost for large-scale point clouds. In this paper, we propose to use regions as the intermediate representation of point clouds instead of fine-grained points or voxels to reduce the computational burden. We introduce a novel Region-Enhanced Feature Learning network (REFL-Net) that leverages region correlations to enhance the features of ambiguous points. We design a Region-based Feature Enhancement module (RFE) which consists of a Semantic-Spatial Region Extraction (SSRE) stage and a Region Dependency Modeling (RDM) stage. In the SSRE stage, we group the input points into a set of regions according to the point distances in both semantic and spatial space. In the RDM part, we explore region-wise semantic and spatial relationships via a self-attention block on region features and fuse point features with the region features to obtain more discriminative representations. Our proposed RFE module is a plug-and-play module that can be integrated with common semantic segmentation backbones. We conduct extensive experiments on ScanNetv2 and S3DIS datasets, and evaluate our RFE module with different segmentation backbones. Our REFL-Net achieves 1.8% mIoU gain on ScanNetv2 and 1.0% mIoU gain on S3DIS respectively with negligible computational cost compared to the backbone networks. Both quantitative and qualitative results show the powerful long-range context modeling ability and strong generalization ability of our REFL-Net.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07486v2","tag":"new-dataset"}}
{"title":"The XAISuite framework and the implications of explanatory system dissonance","abstract":"Explanatory systems make machine learning models more transparent. However, they are often inconsistent. In order to quantify and isolate possible scenarios leading to this discrepancy, this paper compares two explanatory systems, SHAP and LIME, based on the correlation of their respective importance scores using 14 machine learning models (7 regression and 7 classification) and 4 tabular datasets (2 regression and 2 classification). We make two novel findings. Firstly, the magnitude of importance is not significant in explanation consistency. The correlations between SHAP and LIME importance scores for the most important features may or may not be more variable than the correlation between SHAP and LIME importance scores averaged across all features. Secondly, the similarity between SHAP and LIME importance scores cannot predict model accuracy. In the process of our research, we construct an open-source library, XAISuite, that unifies the process of training and explaining models. Finally, this paper contributes a generalized framework to better explain machine learning models and optimize their performance.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.08499v1","tag":"new-dataset"}}
{"title":"Few-shot Weakly-supervised Cybersecurity Anomaly Detection","abstract":"With increased reliance on Internet based technologies, cyberattacks compromising users' sensitive data are becoming more prevalent. The scale and frequency of these attacks are escalating rapidly, affecting systems and devices connected to the Internet. The traditional defense mechanisms may not be sufficiently equipped to handle the complex and ever-changing new threats. The significant breakthroughs in the machine learning methods including deep learning, had attracted interests from the cybersecurity research community for further enhancements in the existing anomaly detection methods. Unfortunately, collecting labelled anomaly data for all new evolving and sophisticated attacks is not practical. Training and tuning the machine learning model for anomaly detection using only a handful of labelled data samples is a pragmatic approach. Therefore, few-shot weakly supervised anomaly detection is an encouraging research direction. In this paper, we propose an enhancement to an existing few-shot weakly-supervised deep learning anomaly detection framework. This framework incorporates data augmentation, representation learning and ordinal regression. We then evaluated and showed the performance of our implemented framework on three benchmark datasets: NSL-KDD, CIC-IDS2018, and TON_IoT.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07470v1","tag":"new-dataset"}}
{"title":"MvCo-DoT:Multi-View Contrastive Domain Transfer Network for Medical Report Generation","abstract":"In clinical scenarios, multiple medical images with different views are usually generated at the same time, and they have high semantic consistency. However, the existing medical report generation methods cannot exploit the rich multi-view mutual information of medical images. Therefore, in this work, we propose the first multi-view medical report generation model, called MvCo-DoT. Specifically, MvCo-DoT first propose a multi-view contrastive learning (MvCo) strategy to help the deep reinforcement learning based model utilize the consistency of multi-view inputs for better model learning. Then, to close the performance gaps of using multi-view and single-view inputs, a domain transfer network is further proposed to ensure MvCo-DoT achieve almost the same performance as multi-view inputs using only single-view inputs.Extensive experiments on the IU X-Ray public dataset show that MvCo-DoT outperforms the SOTA medical report generation baselines in all metrics.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07465v1","tag":"new-dataset"}}
{"title":"Ranking Loss and Sequestering Learning for Reducing Image Search Bias in Histopathology","abstract":"Recently, deep learning has started to play an essential role in healthcare applications, including image search in digital pathology. Despite the recent progress in computer vision, significant issues remain for image searching in histopathology archives. A well-known problem is AI bias and lack of generalization. A more particular shortcoming of deep models is the ignorance toward search functionality. The former affects every model, the latter only search and matching. Due to the lack of ranking-based learning, researchers must train models based on the classification error and then use the resultant embedding for image search purposes. Moreover, deep models appear to be prone to internal bias even if using a large image repository of various hospitals. This paper proposes two novel ideas to improve image search performance. First, we use a ranking loss function to guide feature extraction toward the matching-oriented nature of the search. By forcing the model to learn the ranking of matched outputs, the representation learning is customized toward image search instead of learning a class label. Second, we introduce the concept of sequestering learning to enhance the generalization of feature extraction. By excluding the images of the input hospital from the matched outputs, i.e., sequestering the input domain, the institutional bias is reduced. The proposed ideas are implemented and validated through the largest public dataset of whole slide images. The experiments demonstrate superior results compare to the-state-of-art.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.08498v1","tag":"new-dataset"}}
{"title":"Beta-Rank: A Robust Convolutional Filter Pruning Method For Imbalanced Medical Image Analysis","abstract":"As deep neural networks include a high number of parameters and operations, it can be a challenge to implement these models on devices with limited computational resources. Despite the development of novel pruning methods toward resource-efficient models, it has become evident that these models are not capable of handling \"imbalanced\" and \"limited number of data points\". With input and output information, along with the values of the filters, a novel filter pruning method is proposed. Our pruning method considers the fact that all information about the importance of a filter may not be reflected in the value of the filter. Instead, it is reflected in the changes made to the data after the filter is applied to it. In this work, three methods are compared with the same training conditions except for the ranking of each method. We demonstrated that our model performed significantly better than other methods for medical datasets which are inherently imbalanced. When we removed up to 58% of FLOPs for the IDRID dataset and up to 45% for the ISIC dataset, our model was able to yield an equivalent (or even superior) result to the baseline model while other models were unable to achieve similar results. To evaluate FLOP and parameter reduction using our model in real-world settings, we built a smartphone app, where we demonstrated a reduction of up to 79% in memory usage and 72% in prediction time. All codes and parameters for training different models are available at https://github.com/mohofar/Beta-Rank","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07461v1","tag":"new-dataset"}}
{"title":"Communication and Energy Efficient Wireless Federated Learning with Intrinsic Privacy","abstract":"Federated Learning (FL) is a collaborative learning framework that enables edge devices to collaboratively learn a global model while keeping raw data locally. Although FL avoids leaking direct information from local datasets, sensitive information can still be inferred from the shared models. To address the privacy issue in FL, differential privacy (DP) mechanisms are leveraged to provide formal privacy guarantee. However, when deploying FL at the wireless edge with over-the-air computation, ensuring client-level DP faces significant challenges. In this paper, we propose a novel wireless FL scheme called private federated edge learning with sparsification (PFELS) to provide client-level DP guarantee with intrinsic channel noise while reducing communication and energy overhead and improving model accuracy. The key idea of PFELS is for each device to first compress its model update and then adaptively design the transmit power of the compressed model update according to the wireless channel status without any artificial noise addition. We provide a privacy analysis for PFELS and prove the convergence of PFELS under general non-convex and non-IID settings. Experimental results show that compared with prior work, PFELS can improve the accuracy with the same DP guarantee and save communication and energy costs simultaneously.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07460v1","tag":"new-dataset"}}
{"title":"Layph: Making Change Propagation Constraint in Incremental Graph Processing by Layering Graph","abstract":"Real-world graphs are constantly evolving, which demands updates of the previous analysis results to accommodate graph changes. By using the memoized previous computation state, incremental graph computation can reduce unnecessary recomputation. However, a small change may propagate over the whole graph and lead to large-scale iterative computations. To address this problem, we propose Layph, a two-layered graph framework. The upper layer is a skeleton of the graph, which is much smaller than the original graph, and the lower layer has some disjointed subgraphs. Layph limits costly global iterative computations on the original graph to the small graph skeleton and a few subgraphs updated with the input graph changes. In this way, many vertices and edges are not involved in iterative computations, significantly reducing the communication overhead and improving incremental graph processing performance. Our experimental results show that Layph outperforms current state-of-the-art incremental graph systems by 9.08X on average (up to 36.66X) in response time.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07458v1","tag":"new-dataset"}}
{"title":"Context-aware Domain Adaptation for Time Series Anomaly Detection","abstract":"Time series anomaly detection is a challenging task with a wide range of real-world applications. Due to label sparsity, training a deep anomaly detector often relies on unsupervised approaches. Recent efforts have been devoted to time series domain adaptation to leverage knowledge from similar domains. However, existing solutions may suffer from negative knowledge transfer on anomalies due to their diversity and sparsity. Motivated by the empirical study of context alignment between two domains, we aim to transfer knowledge between two domains via adaptively sampling context information for two domains. This is challenging because it requires simultaneously modeling the complex in-domain temporal dependencies and cross-domain correlations while exploiting label information from the source domain. To this end, we propose a framework that combines context sampling and anomaly detection into a joint learning procedure. We formulate context sampling into the Markov decision process and exploit deep reinforcement learning to optimize the time series domain adaptation process via context sampling and design a tailored reward function to generate domain-invariant features that better align two domains for anomaly detection. Experiments on three public datasets show promise for knowledge transfer between two similar domains and two entirely different domains.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07453v1","tag":"new-dataset"}}
{"title":"Multivariate regression modeling in integrative analysis via sparse regularization","abstract":"The multivariate regression model basically offers the analysis of a single dataset with multiple responses. However, such a single-dataset analysis often leads to unsatisfactory results. Integrative analysis is an effective method to pool useful information from multiple independent datasets and provides better performance than single-dataset analysis. In this study, we propose a multivariate regression modeling in integrative analysis. The integration is achieved by sparse estimation that performs variable and group selection. Based on the idea of alternating direction method of multipliers, we develop its computational algorithm that enjoys the convergence property. The performance of the proposed method is demonstrated through Monte Carlo simulation and analyzing wastewater treatment data with microbe measurements.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07451v1","tag":"new-dataset"}}
{"title":"Intent-aware Ranking Ensemble for Personalized Recommendation","abstract":"Ranking ensemble is a critical component in real recommender systems. When a user visits a platform, the system will prepare several item lists, each of which is generally from a single behavior objective recommendation model. As multiple behavior intents, e.g., both clicking and buying some specific item category, are commonly concurrent in a user visit, it is necessary to integrate multiple single-objective ranking lists into one. However, previous work on rank aggregation mainly focused on fusing homogeneous item lists with the same objective while ignoring ensemble of heterogeneous lists ranked with different objectives with various user intents.   In this paper, we treat a user's possible behaviors and the potential interacting item categories as the user's intent. And we aim to study how to fuse candidate item lists generated from different objectives aware of user intents. To address such a task, we propose an Intent-aware ranking Ensemble Learning~(IntEL) model to fuse multiple single-objective item lists with various user intents, in which item-level personalized weights are learned. Furthermore, we theoretically prove the effectiveness of IntEL with point-wise, pair-wise, and list-wise loss functions via error-ambiguity decomposition. Experiments on two large-scale real-world datasets also show significant improvements of IntEL on multiple behavior objectives simultaneously compared to previous ranking ensemble models.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07450v1","tag":"new-dataset"}}
{"title":"Few-shot Camouflaged Animal Detection and Segmentation","abstract":"Camouflaged object detection and segmentation is a new and challenging research topic in computer vision. There is a serious issue of lacking data of camouflaged objects such as camouflaged animals in natural scenes. In this paper, we address the problem of few-shot learning for camouflaged object detection and segmentation. To this end, we first collect a new dataset, CAMO-FS, for the benchmark. We then propose a novel method to efficiently detect and segment the camouflaged objects in the images. In particular, we introduce the instance triplet loss and the instance memory storage. The extensive experiments demonstrated that our proposed method achieves state-of-the-art performance on the newly collected dataset.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07444v1","tag":"new-dataset"}}
{"title":"Learning To Optimize Quantum Neural Network Without Gradients","abstract":"Quantum Machine Learning is an emerging sub-field in machine learning where one of the goals is to perform pattern recognition tasks by encoding data into quantum states. This extension from classical to quantum domain has been made possible due to the development of hybrid quantum-classical algorithms that allow a parameterized quantum circuit to be optimized using gradient based algorithms that run on a classical computer. The similarities in training of these hybrid algorithms and classical neural networks has further led to the development of Quantum Neural Networks (QNNs). However, in the current training regime for QNNs, the gradients w.r.t objective function have to be computed on the quantum device. This computation is highly non-scalable and is affected by hardware and sampling noise present in the current generation of quantum hardware. In this paper, we propose a training algorithm that does not rely on gradient information. Specifically, we introduce a novel meta-optimization algorithm that trains a \\emph{meta-optimizer} network to output parameters for the quantum circuit such that the objective function is minimized. We empirically and theoretically show that we achieve a better quality minima in fewer circuit evaluations than existing gradient based algorithms on different datasets.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07442v1","tag":"new-dataset"}}
{"title":"Medical Question Summarization with Entity-driven Contrastive Learning","abstract":"By summarizing longer consumer health questions into shorter and essential ones, medical question answering (MQA) systems can more accurately understand consumer intentions and retrieve suitable answers. However, medical question summarization is very challenging due to obvious distinctions in health trouble descriptions from patients and doctors. Although existing works have attempted to utilize Seq2Seq, reinforcement learning, or contrastive learning to solve the problem, two challenges remain: how to correctly capture question focus to model its semantic intention, and how to obtain reliable datasets to fairly evaluate performance. To address these challenges, this paper proposes a novel medical question summarization framework using entity-driven contrastive learning (ECL). ECL employs medical entities in frequently asked questions (FAQs) as focuses and devises an effective mechanism to generate hard negative samples. This approach forces models to pay attention to the crucial focus information and generate more ideal question summarization. Additionally, we find that some MQA datasets suffer from serious data leakage problems, such as the iCliniq dataset's 33% duplicate rate. To evaluate the related methods fairly, this paper carefully checks leaked samples to reorganize more reasonable datasets. Extensive experiments demonstrate that our ECL method outperforms state-of-the-art methods by accurately capturing question focus and generating medical question summaries. The code and datasets are available at https://github.com/yrbobo/MQS-ECL.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07437v1","tag":"new-dataset"}}
{"title":"CoPR: Towards Accurate Visual Localization With Continuous Place-descriptor Regression","abstract":"Visual Place Recognition (VPR) is an image-based localization method that estimates the camera location of a query image by retrieving the most similar reference image from a map of geo-tagged reference images. In this work, we look into two fundamental bottlenecks for its localization accuracy: reference map sparseness and viewpoint invariance. Firstly, the reference images for VPR are only available at sparse poses in a map, which enforces an upper bound on the maximum achievable localization accuracy through VPR. We therefore propose Continuous Place-descriptor Regression (CoPR) to densify the map and improve localization accuracy. We study various interpolation and extrapolation models to regress additional VPR feature descriptors from only the existing references. Secondly, we compare different feature encoders and show that CoPR presents value for all of them. We evaluate our models on three existing public datasets and report on average around 30% improvement in VPR-based localization accuracy using CoPR, on top of the 15% increase by using a viewpoint-variant loss for the feature encoder. The complementary relation between CoPR and Relative Pose Estimation is also discussed.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07426v1","tag":"new-dataset"}}
{"title":"Peer-to-Peer Federated Continual Learning for Naturalistic Driving Action Recognition","abstract":"Naturalistic driving action recognition (NDAR) has proven to be an effective method for detecting driver distraction and reducing the risk of traffic accidents. However, the intrusive design of in-cabin cameras raises concerns about driver privacy. To address this issue, we propose a novel peer-to-peer (P2P) federated learning (FL) framework with continual learning, namely FedPC, which ensures privacy and enhances learning efficiency while reducing communication, computational, and storage overheads. Our framework focuses on addressing the clients' objectives within a serverless FL framework, with the goal of delivering personalized and accurate NDAR models. We demonstrate and evaluate the performance of FedPC on two real-world NDAR datasets, including the State Farm Distracted Driver Detection and Track 3 NDAR dataset in the 2023 AICity Challenge. The results of our experiments highlight the strong competitiveness of FedPC compared to the conventional client-to-server (C2S) FLs in terms of performance, knowledge dissemination rate, and compatibility with new clients.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07421v1","tag":"new-dataset"}}
{"title":"An elaborated pattern-based method of identifying data oscillations from mobile device location data","abstract":"In recent years, passively collected GPS data have been popularly applied in various transportation studies, such as highway performance monitoring, travel behavior analysis, and travel demand estimation. Despite multiple advantages, one of the issues is data oscillations (aka outliers or data jumps), which are unneglectable since they may distort mobility patterns and lead to wrongly or biased conclusions. For transportation studies driven by GPS data, assuring the data quality by removing noises caused by data oscillations is undoubtedly important. Most GPS-based studies simply remove oscillations by checking the high speed. However, this method can mistakenly identify normal points as oscillations. Some other studies specifically discuss the removal of outliers in GPS data, but they all have limitations and do not fit passively collected GPS data. Many studies are well developed for addressing the ping-pong phenomenon in cellular data, or cellular tower data, but the oscillations in passively collected GPS data are very different for having much more various and complicated patterns and being more uncertain. Current methods are insufficient and inapplicable to passively collected GPS data. This paper aims to address the oscillated points in passively collected GPS data. A set of heuristics are proposed by identifying the abnormal movement patterns of oscillations. The proposed heuristics well fit the features of passively collected GPS data and are adaptable to studies of different scales, which are also computationally cost-effective in comparison to current methods.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07420v1","tag":"new-dataset"}}
{"title":"Text-Conditional Contextualized Avatars For Zero-Shot Personalization","abstract":"Recent large-scale text-to-image generation models have made significant improvements in the quality, realism, and diversity of the synthesized images and enable users to control the created content through language. However, the personalization aspect of these generative models is still challenging and under-explored. In this work, we propose a pipeline that enables personalization of image generation with avatars capturing a user's identity in a delightful way. Our pipeline is zero-shot, avatar texture and style agnostic, and does not require training on the avatar at all - it is scalable to millions of users who can generate a scene with their avatar. To render the avatar in a pose faithful to the given text prompt, we propose a novel text-to-3D pose diffusion model trained on a curated large-scale dataset of in-the-wild human poses improving the performance of the SOTA text-to-motion models significantly. We show, for the first time, how to leverage large-scale image datasets to learn human 3D pose parameters and overcome the limitations of motion capture datasets.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07410v1","tag":"new-dataset"}}
{"title":"Fairness in Visual Clustering: A Novel Transformer Clustering Approach","abstract":"Promoting fairness for deep clustering models in unsupervised clustering settings to reduce demographic bias is a challenging goal. This is because of the limitation of large-scale balanced data with well-annotated labels for sensitive or protected attributes. In this paper, we first evaluate demographic bias in deep clustering models from the perspective of cluster purity, which is measured by the ratio of positive samples within a cluster to their correlation degree. This measurement is adopted as an indication of demographic bias. Then, a novel loss function is introduced to encourage a purity consistency for all clusters to maintain the fairness aspect of the learned clustering model. Moreover, we present a novel attention mechanism, Cross-attention, to measure correlations between multiple clusters, strengthening faraway positive samples and improving the purity of clusters during the learning process. Experimental results on a large-scale dataset with numerous attribute settings have demonstrated the effectiveness of the proposed approach on both clustering accuracy and fairness enhancement on several sensitive attributes.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07408v1","tag":"new-dataset"}}
{"title":"Bayesian inference on Brain-Computer Interface using the GLASS Model","abstract":"The brain-computer interface (BCI) enables individuals with severe physical impairments to communicate with the world. BCIs offer computational neuroscience opportunities and challenges in converting real-time brain activities to computer commands and are typically framed as a classification problem. This article focuses on the P300 BCI that uses the event-related potential (ERP) BCI design, where the primary challenge is classifying target/non-target stimuli. We develop a novel Gaussian latent group model with sparse time-varying effects (GLASS) for making Bayesian inferences on the P300 BCI. GLASS adopts a multinomial regression framework that directly addresses the dataset imbalance in BCI applications. The prior specifications facilitate i) feature selection and noise reduction using soft-thresholding, ii) smoothing of the time-varying effects using global shrinkage, and iii) clustering of latent groups to alleviate high spatial correlations of EEG data. We develop an efficient gradient-based variational inference (GBVI) algorithm for posterior computation and provide a user-friendly Python module available at https://github.com/BangyaoZhao/GLASS. The application of GLASS identifies important EEG channels (PO8, Oz, PO7, Pz, C3) that align with existing literature. GLASS further reveals a group effect from channels in the parieto-occipital region (PO8, Oz, PO7), which is validated in cross-participant analysis.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07401v1","tag":"new-dataset"}}
{"title":"Precise Age for the Binary Star System 12 Com in the Coma Berenices Cluster","abstract":"We present measurements of the interferometrically-resolved binary star system 12 Com and the single giant star 31 Com in the cluster Coma Berenices. 12 Com is a double-lined spectroscopic binary system consisting of a G7 giant and an A3 dwarf at the cluster turnoff. Using an extensive radial velocity dataset and interferometric measurements from PTI and the CHARA array, we measured masses $M_1 =2.64 \\pm 0.07 M_\\odot$ and $M_2 =2.10 \\pm 0.03 M_\\odot$. Interferometry also allows us to resolve the giant, and measure its size as $R_1 = 9.12 \\pm 0.12 \\pm 0.01 R_\\odot$. With the measured masses and radii, we find an age of $533 \\pm 41 \\pm 42$ Myr. For comparison, we measure the radius of 31 Com to be $8.36 \\pm 0.15 R_\\odot$. Based on the photometry and radius measurements, 12 Com A is likely the most evolved bright star in the cluster, large enough to be in the red giant phase, but too small to have core helium burning. Simultaneous knowledge of 12 Com A's mass and photometry puts strong constraints on convective core overshooting during the main sequence phase, which in turn reduces systematic uncertainties in the age. Increased precision in measuring this system also improves our knowledge of the progenitor of the cluster white dwarf WD1216+260.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07397v1","tag":"new-dataset"}}
{"title":"Shape of You: Precise 3D shape estimations for diverse body types","abstract":"This paper presents Shape of You (SoY), an approach to improve the accuracy of 3D body shape estimation for vision-based clothing recommendation systems. While existing methods have successfully estimated 3D poses, there remains a lack of work in precise shape estimation, particularly for diverse human bodies. To address this gap, we propose two loss functions that can be readily integrated into parametric 3D human reconstruction pipelines. Additionally, we propose a test-time optimization routine that further improves quality. Our method improves over the recent SHAPY method by 17.7% on the challenging SSP-3D dataset. We consider our work to be a step towards a more accurate 3D shape estimation system that works reliably on diverse body types and holds promise for practical applications in the fashion industry.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07389v1","tag":"new-dataset"}}
{"title":"Zero-Shot Multi-Label Topic Inference with Sentence Encoders","abstract":"Sentence encoders have indeed been shown to achieve superior performances for many downstream text-mining tasks and, thus, claimed to be fairly general. Inspired by this, we performed a detailed study on how to leverage these sentence encoders for the \"zero-shot topic inference\" task, where the topics are defined/provided by the users in real-time. Extensive experiments on seven different datasets demonstrate that Sentence-BERT demonstrates superior generality compared to other encoders, while Universal Sentence Encoder can be preferred when efficiency is a top priority.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07382v1","tag":"new-dataset"}}
{"title":"A Reconfigurable Linear RF Analog Processor for Realizing Microwave Artificial Neural Network","abstract":"Owing to the data explosion and rapid development of artificial intelligence (AI), particularly deep neural networks (DNNs), the ever-increasing demand for large-scale matrix-vector multiplication has become one of the major issues in machine learning (ML). Training and evaluating such neural networks rely on heavy computational resources, resulting in significant system latency and power consumption. To overcome these issues, analog computing using optical interferometric-based linear processors have recently appeared as promising candidates in accelerating matrix-vector multiplication and lowering power consumption. On the other hand, radio frequency (RF) electromagnetic waves can also exhibit similar advantages as the optical counterpart by performing analog computation at light speed with lower power. Furthermore, RF devices have extra benefits such as lower cost, mature fabrication, and analog-digital mixed design simplicity, which has great potential in realizing affordable, scalable, low latency, low power, near-sensor radio frequency neural network (RFNN) that may greatly enrich RF signal processing capability. In this work, we propose a 2X2 reconfigurable linear RF analog processor in theory and experiment, which can be applied as a matrix multiplier in an artificial neural network (ANN). The proposed device can be utilized to realize a 2X2 simple RFNN for data classification. An 8X8 linear analog processor formed by 28 RFNN devices are also applied in a 4-layer ANN for Modified National Institute of Standards and Technology (MNIST) dataset classification.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07378v1","tag":"new-dataset"}}
{"title":"US ATLAS and US CMS HPC and Cloud Blueprint","abstract":"The Large Hadron Collider (LHC) at CERN houses two general purpose detectors - ATLAS and CMS - which conduct physics programs over multi-year runs to generate increasingly precise and extensive datasets. The efforts of the CMS and ATLAS collaborations lead to the discovery of the Higgs boson, a fundamental particle that gives mass to other particles, representing a monumental achievement in the field of particle physics that was recognized with the awarding of the Nobel Prize in Physics in 2013 to Fran\\c{c}ois Englert and Peter Higgs. These collaborations continue to analyze data from the LHC and are preparing for the high luminosity data taking phase at the end of the decade. The computing models of these detectors rely on a distributed processing grid hosted by more than 150 associated universities and laboratories worldwide. However, such new data will require a significant expansion of the existing computing infrastructure. To address this, both collaborations have been working for years on integrating High Performance Computers (HPC) and commercial cloud resources into their infrastructure and continue to assess the potential role of such resources in order to cope with the demands of the new high luminosity era. US ATLAS and US CMS computing management have charged the authors to provide a blueprint document looking at current and possibly future use of HPC and Cloud resources, outlining integration models, possibilities, challenges and costs. The document will address key questions such as the optimal use of resources for the experiments and funding agencies, the main obstacles that need to be overcome for resource adoption, and areas that require more attention.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07376v1","tag":"new-dataset"}}
{"title":"NEV-NCD: Negative Learning, Entropy, and Variance regularization based novel action categories discovery","abstract":"Novel Categories Discovery (NCD) facilitates learning from a partially annotated label space and enables deep learning (DL) models to operate in an open-world setting by identifying and differentiating instances of novel classes based on the labeled data notions. One of the primary assumptions of NCD is that the novel label space is perfectly disjoint and can be equipartitioned, but it is rarely realized by most NCD approaches in practice. To better align with this assumption, we propose a novel single-stage joint optimization-based NCD method, Negative learning, Entropy, and Variance regularization NCD (NEV-NCD). We demonstrate the efficacy of NEV-NCD in previously unexplored NCD applications of video action recognition (VAR) with the public UCF101 dataset and a curated in-house partial action-space annotated multi-view video dataset. We perform a thorough ablation study by varying the composition of final joint loss and associated hyper-parameters. During our experiments with UCF101 and multi-view action dataset, NEV-NCD achieves ~ 83% classification accuracy in test instances of labeled data. NEV-NCD achieves ~ 70% clustering accuracy over unlabeled data outperforming both naive baselines (by ~ 40%) and state-of-the-art pseudo-labeling-based approaches (by ~ 3.5%) over both datasets. Further, we propose to incorporate optional view-invariant feature learning with the multiview dataset to identify novel categories from novel viewpoints. Our additional view-invariance constraint improves the discriminative accuracy for both known and unknown categories by ~ 10% for novel viewpoints.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07354v1","tag":"new-dataset"}}
{"title":"GPULZ: Optimizing LZSS Lossless Compression for Multi-byte Data on Modern GPUs","abstract":"Today's graphics processing unit (GPU) applications produce vast volumes of data, which are challenging to store and transfer efficiently. Thus, data compression is becoming a critical technique to mitigate the storage burden and communication cost. LZSS is the core algorithm in many widely used compressors, such as Deflate. However, existing GPU-based LZSS compressors suffer from low throughput due to the sequential nature of the LZSS algorithm. Moreover, many GPU applications produce multi-byte data (e.g., int16/int32 index, floating-point numbers), while the current LZSS compression only takes single-byte data as input. To this end, in this work, we propose GPULZ, a highly efficient LZSS compression on modern GPUs for multi-byte data. The contribution of our work is fourfold: First, we perform an in-depth analysis of existing LZ compressors for GPUs and investigate their main issues. Then, we propose two main algorithm-level optimizations. Specifically, we (1) change prefix sum from one pass to two passes and fuse multiple kernels to reduce data movement between shared memory and global memory, and (2) optimize existing pattern-matching approach for multi-byte symbols to reduce computation complexity and explore longer repeated patterns. Third, we perform architectural performance optimizations, such as maximizing shared memory utilization by adapting data partitions to different GPU architectures. Finally, we evaluate GPULZ on six datasets of various types with NVIDIA A100 and A4000 GPUs. Results show that GPULZ achieves up to 272.1X speedup on A4000 and up to 1.4X higher compression ratio compared to state-of-the-art solutions.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07342v1","tag":"new-dataset"}}
{"title":"Photon Field Networks for Dynamic Real-Time Volumetric Global Illumination","abstract":"Volume data is commonly found in many scientific disciplines, like medicine, physics, and biology. Experts rely on robust scientific visualization techniques to extract valuable insights from the data. Recent years have shown path tracing to be the preferred approach for volumetric rendering, given its high levels of realism. However, real-time volumetric path tracing often suffers from stochastic noise and long convergence times, limiting interactive exploration. In this paper, we present a novel method to enable real-time global illumination for volume data visualization. We develop Photon Field Networks -- a phase-function-aware, multi-light neural representation of indirect volumetric global illumination. The fields are trained on multi-phase photon caches that we compute a priori. Training can be done within seconds, after which the fields can be used in various rendering tasks. To showcase their potential, we develop a custom neural path tracer, with which our photon fields achieve interactive framerates even on large datasets. We conduct in-depth evaluations of the method's performance, including visual quality, stochastic noise, inference and rendering speeds, and accuracy regarding illumination and phase function awareness. Results are compared to ray marching, path tracing and photon mapping. Our findings show that Photon Field Networks can faithfully represent indirect global illumination across the phase spectrum while exhibiting less stochastic noise and rendering at a significantly faster rate than traditional methods.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07338v1","tag":"new-dataset"}}
{"title":"HEAT: A Highly Efficient and Affordable Training System for Collaborative Filtering Based Recommendation on CPUs","abstract":"Collaborative filtering (CF) has been proven to be one of the most effective techniques for recommendation. Among all CF approaches, SimpleX is the state-of-the-art method that adopts a novel loss function and a proper number of negative samples. However, there is no work that optimizes SimpleX on multi-core CPUs, leading to limited performance. To this end, we perform an in-depth profiling and analysis of existing SimpleX implementations and identify their performance bottlenecks including (1) irregular memory accesses, (2) unnecessary memory copies, and (3) redundant computations. To address these issues, we propose an efficient CF training system (called HEAT) that fully enables the multi-level caching and multi-threading capabilities of modern CPUs. Specifically, the optimization of HEAT is threefold: (1) It tiles the embedding matrix to increase data locality and reduce cache misses (thus reduce read latency); (2) It optimizes stochastic gradient descent (SGD) with sampling by parallelizing vector products instead of matrix-matrix multiplications, in particular the similarity computation therein, to avoid memory copies for matrix data preparation; and (3) It aggressively reuses intermediate results from the forward phase in the backward phase to alleviate redundant computation. Evaluation on five widely used datasets with both x86- and ARM-architecture processors shows that HEAT achieves up to 65.3X speedup over existing CPU solution and 4.8X speedup and 7.9X cost reduction in Cloud over existing GPU solution with NVIDIA V100 GPU.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07334v1","tag":"new-dataset"}}
{"title":"OpenAssistant Conversations -- Democratizing Large Language Model Alignment","abstract":"Aligning large language models (LLMs) with human preferences has proven to drastically improve usability and has driven rapid adoption as demonstrated by ChatGPT. Alignment techniques such as supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) greatly reduce the required skill and domain knowledge to effectively harness the capabilities of LLMs, increasing their accessibility and utility across various domains. However, state-of-the-art alignment techniques like RLHF rely on high-quality human feedback data, which is expensive to create and often remains proprietary. In an effort to democratize research on large-scale alignment, we release OpenAssistant Conversations, a human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages distributed across 66,497 conversation trees, in 35 different languages, annotated with 461,292 quality ratings. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers. To demonstrate the OpenAssistant Conversations dataset's effectiveness, we present OpenAssistant, the first fully open-source large-scale instruction-tuned model to be trained on human data. A preference study revealed that OpenAssistant replies are comparably preferred to GPT-3.5-turbo (ChatGPT) with a relative winrate of 48.3% vs. 51.7% respectively. We release our code and data under fully permissive licenses.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07327v1","tag":"new-dataset"}}
{"title":"CAD-RADS scoring of coronary CT angiography with Multi-Axis Vision Transformer: a clinically-inspired deep learning pipeline","abstract":"The standard non-invasive imaging technique used to assess the severity and extent of Coronary Artery Disease (CAD) is Coronary Computed Tomography Angiography (CCTA). However, manual grading of each patient's CCTA according to the CAD-Reporting and Data System (CAD-RADS) scoring is time-consuming and operator-dependent, especially in borderline cases. This work proposes a fully automated, and visually explainable, deep learning pipeline to be used as a decision support system for the CAD screening procedure. The pipeline performs two classification tasks: firstly, identifying patients who require further clinical investigations and secondly, classifying patients into subgroups based on the degree of stenosis, according to commonly used CAD-RADS thresholds. The pipeline pre-processes multiplanar projections of the coronary arteries, extracted from the original CCTAs, and classifies them using a fine-tuned Multi-Axis Vision Transformer architecture. With the aim of emulating the current clinical practice, the model is trained to assign a per-patient score by stacking the bi-dimensional longitudinal cross-sections of the three main coronary arteries along channel dimension. Furthermore, it generates visually interpretable maps to assess the reliability of the predictions. When run on a database of 1873 three-channel images of 253 patients collected at the Monzino Cardiology Center in Milan, the pipeline obtained an AUC of 0.87 and 0.93 for the two classification tasks, respectively. According to our knowledge, this is the first model trained to assign CAD-RADS scores learning solely from patient scores and not requiring finer imaging annotation steps that are not part of the clinical routine.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07277v1","tag":"new-dataset"}}
{"title":"Learning-Assisted Optimization for Transmission Switching","abstract":"The design of new strategies that exploit methods from Machine Learning to facilitate the resolution of challenging and large-scale mathematical optimization problems has recently become an avenue of prolific and promising research. In this paper, we propose a novel learning procedure to assist in the solution of a well-known computationally difficult optimization problem in power systems: The Direct Current Optimal Transmission Switching (DC-OTS). This model consists in finding the configuration of the power network that results in the cheapest dispatch of the power generating units. For this, the model includes a set of binaries that determine the on/off status of the switchable transmission lines. Therefore, the DC-OTS problem takes the form of a mixed-integer program, which is NP-hard in general. Its solution has been approached by way of exact and heuristic methods. The former employ techniques from mixed-integer programming to solve the problem to certified global optimality, while the latter seek to identify good solutions quickly. While the heuristic methods tend to be comparatively much faster, they may suggest suboptimal or even infeasible networks topologies. The proposed approach in this paper leverages known solutions to past instances of the DC-OTS problem to speed up the mixed-integer optimization of a new unseen model. Although it does not offer optimality guarantees, a series of numerical experiments run on a real-life power system dataset show that it features a very high success rate in identifying the optimal grid topology (especially when compared to alternative competing heuristics), while rendering remarkable speed-up factors.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07269v1","tag":"new-dataset"}}
{"title":"Phantom Embeddings: Using Embedding Space for Model Regularization in Deep Neural Networks","abstract":"The strength of machine learning models stems from their ability to learn complex function approximations from data; however, this strength also makes training deep neural networks challenging. Notably, the complex models tend to memorize the training data, which results in poor regularization performance on test data. The regularization techniques such as L1, L2, dropout, etc. are proposed to reduce the overfitting effect; however, they bring in additional hyperparameters tuning complexity. These methods also fall short when the inter-class similarity is high due to the underlying data distribution, leading to a less accurate model. In this paper, we present a novel approach to regularize the models by leveraging the information-rich latent embeddings and their high intra-class correlation. We create phantom embeddings from a subset of homogenous samples and use these phantom embeddings to decrease the inter-class similarity of instances in their latent embedding space. The resulting models generalize better as a combination of their embedding and regularize them without requiring an expensive hyperparameter search. We evaluate our method on two popular and challenging image classification datasets (CIFAR and FashionMNIST) and show how our approach outperforms the standard baselines while displaying better training behavior.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07262v1","tag":"new-dataset"}}
{"title":"Learn What Is Possible, Then Choose What Is Best: Disentangling One-To-Many Relations in Language Through Text-based Games","abstract":"Language models pre-trained on large self-supervised corpora, followed by task-specific fine-tuning has become the dominant paradigm in NLP. These pre-training datasets often have a one-to-many structure--e.g. in dialogue there are many valid responses for a given context. However, only some of these responses will be desirable in our downstream task. This raises the question of how we should train the model such that it can emulate the desirable behaviours, but not the undesirable ones. Current approaches train in a one-to-one setup--only a single target response is given for a single dialogue context--leading to models only learning to predict the average response, while ignoring the full range of possible responses. Using text-based games as a testbed, our approach, PASA, uses discrete latent variables to capture the range of different behaviours represented in our larger pre-training dataset. We then use knowledge distillation to distil the posterior probability distribution into a student model. This probability distribution is far richer than learning from only the hard targets of the dataset, and thus allows the student model to benefit from the richer range of actions the teacher model has learned. Results show up to 49% empirical improvement over the previous state-of-the-art model on the Jericho Walkthroughs dataset.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07258v1","tag":"new-dataset"}}
{"title":"Directly Optimizing IoU for Bounding Box Localization","abstract":"Object detection has seen remarkable progress in recent years with the introduction of Convolutional Neural Networks (CNN). Object detection is a multi-task learning problem where both the position of the objects in the images as well as their classes needs to be correctly identified. The idea here is to maximize the overlap between the ground-truth bounding boxes and the predictions i.e. the Intersection over Union (IoU). In the scope of work seen currently in this domain, IoU is approximated by using the Huber loss as a proxy but this indirect method does not leverage the IoU information and treats the bounding box as four independent, unrelated terms of regression. This is not true for a bounding box where the four coordinates are highly correlated and hold a semantic meaning when taken together. The direct optimization of the IoU is not possible due to its non-convex and non-differentiable nature. In this paper, we have formulated a novel loss namely, the Smooth IoU, which directly optimizes the IoUs for the bounding boxes. This loss has been evaluated on the Oxford IIIT Pets, Udacity self-driving car, PASCAL VOC, and VWFS Car Damage datasets and has shown performance gains over the standard Huber loss.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07256v1","tag":"new-dataset"}}
{"title":"Fusing Structure from Motion and Simulation-Augmented Pose Regression from Optical Flow for Challenging Indoor Environments","abstract":"The localization of objects is a crucial task in various applications such as robotics, virtual and augmented reality, and the transportation of goods in warehouses. Recent advances in deep learning have enabled the localization using monocular visual cameras. While structure from motion (SfM) predicts the absolute pose from a point cloud, absolute pose regression (APR) methods learn a semantic understanding of the environment through neural networks. However, both fields face challenges caused by the environment such as motion blur, lighting changes, repetitive patterns, and feature-less structures. This study aims to address these challenges by incorporating additional information and regularizing the absolute pose using relative pose regression (RPR) methods. The optical flow between consecutive images is computed using the Lucas-Kanade algorithm, and the relative pose is predicted using an auxiliary small recurrent convolutional network. The fusion of absolute and relative poses is a complex task due to the mismatch between the global and local coordinate systems. State-of-the-art methods fusing absolute and relative poses use pose graph optimization (PGO) to regularize the absolute pose predictions using relative poses. In this work, we propose recurrent fusion networks to optimally align absolute and relative pose predictions to improve the absolute pose prediction. We evaluate eight different recurrent units and construct a simulation environment to pre-train the APR and RPR networks for better generalized training. Additionally, we record a large database of different scenarios in a challenging large-scale indoor environment that mimics a warehouse with transportation robots. We conduct hyperparameter searches and experiments to show the effectiveness of our recurrent fusion method compared to PGO.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07250v1","tag":"new-dataset"}}
{"title":"The University of California San Francisco, Brain Metastases Stereotactic Radiosurgery (UCSF-BMSR) MRI Dataset","abstract":"The University of California San Francisco Brain Metastases Stereotactic Radiosurgery (UCSF-BMSR) dataset is a public, clinical, multimodal brain MRI dataset consisting of 560 brain MRIs from 412 patients with expert annotations of 5136 brain metastases. Data consists of registered and skull stripped T1 post-contrast, T1 pre-contrast, FLAIR and subtraction (T1 pre-contrast - T1 post-contrast) images and voxelwise segmentations of enhancing brain metastases in NifTI format. The dataset also includes patient demographics, surgical status and primary cancer types. The UCSF-BSMR has been made publicly available in the hopes that researchers will use these data to push the boundaries of AI applications for brain metastases.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07248v1","tag":"new-dataset"}}
{"title":"KS-GNNExplainer: Global Model Interpretation Through Instance Explanations On Histopathology images","abstract":"Instance-level graph neural network explainers have proven beneficial for explaining such networks on histopathology images. However, there has been few methods that provide model explanations, which are common patterns among samples within the same class. We envision that graph-based histopathological image analysis can benefit significantly from such explanations. On the other hand, current model-level explainers are based on graph generation methods that are not applicable in this domain because of no corresponding image for their generated graphs in real world. Therefore, such explanations are communicable to the experts. To follow this vision, we developed KS-GNNExplainer, the first instance-level graph neural network explainer that leverages current instance-level approaches in an effective manner to provide more informative and reliable explainable outputs, which are crucial for applied AI in the health domain. Our experiments on various datasets, and based on both quantitative and qualitative measures, demonstrate that the proposed explainer is capable of being a global pattern extractor, which is a fundamental limitation of current instance-level approaches in this domain.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.08240v1","tag":"new-dataset"}}
{"title":"GreedyGD: Enhanced Generalized Deduplication for Direct Analytics in IoT","abstract":"Exponential growth in the amount of data generated by the Internet of Things currently pose significant challenges for data communication, storage and analytics and leads to high costs for organisations hoping to leverage their data. Novel techniques are therefore needed to holistically improve the efficiency of data storage and analytics in IoT systems. The emerging compression technique Generalized Deduplication (GD) has been shown to deliver high compression and enable direct compressed data analytics with low storage and memory requirements. In this paper, we propose a new GD-based data compression algorithm called GreedyGD that is designed for analytics. Compared to existing versions of GD, GreedyGD enables more reliable analytics with less data, while running 11.2x faster and delivering even better compression.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07240v1","tag":"new-dataset"}}
{"title":"PARFormer: Transformer-based Multi-Task Network for Pedestrian Attribute Recognition","abstract":"Pedestrian attribute recognition (PAR) has received increasing attention because of its wide application in video surveillance and pedestrian analysis. Extracting robust feature representation is one of the key challenges in this task. The existing methods mainly use the convolutional neural network (CNN) as the backbone network to extract features. However, these methods mainly focus on small discriminative regions while ignoring the global perspective. To overcome these limitations, we propose a pure transformer-based multi-task PAR network named PARFormer, which includes four modules. In the feature extraction module, we build a transformer-based strong baseline for feature extraction, which achieves competitive results on several PAR benchmarks compared with the existing CNN-based baseline methods. In the feature processing module, we propose an effective data augmentation strategy named batch random mask (BRM) block to reinforce the attentive feature learning of random patches. Furthermore, we propose a multi-attribute center loss (MACL) to enhance the inter-attribute discriminability in the feature representations. In the viewpoint perception module, we explore the impact of viewpoints on pedestrian attributes, and propose a multi-view contrastive loss (MCVL) that enables the network to exploit the viewpoint information. In the attribute recognition module, we alleviate the negative-positive imbalance problem to generate the attribute predictions. The above modules interact and jointly learn a highly discriminative feature space, and supervise the generation of the final features. Extensive experimental results show that the proposed PARFormer network performs well compared to the state-of-the-art methods on several public datasets, including PETA, RAP, and PA100K. Code will be released at https://github.com/xwf199/PARFormer.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07230v1","tag":"new-dataset"}}
{"title":"QuACS: Variational Quantum Algorithm for Coalition Structure Generation in Induced Subgraph Games","abstract":"Coalition Structure Generation (CSG) is an NP-Hard problem in which agents are partitioned into mutually exclusive groups to maximize their social welfare. In this work, we propose QuACS, a novel hybrid quantum classical algorithm for Coalition Structure Generation in Induced Subgraph Games (ISGs). Starting from a coalition structure where all the agents belong to a single coalition, QuACS recursively identifies the optimal partition into two disjoint subsets. This problem is reformulated as a QUBO and then solved using QAOA. Given an $n$-agent ISG, we show that the proposed algorithm outperforms existing approximate classical solvers with a runtime of $\\mathcal{O}(n^2)$ and an expected approximation ratio of $92\\%$. Furthermore, it requires a significantly lower number of qubits and allows experiments on medium-sized problems compared to existing quantum solutions. To show the effectiveness of QuACS we perform experiments on standard benchmark datasets using quantum simulation.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07218v1","tag":"new-dataset"}}
{"title":"Uncovering the Inner Workings of STEGO for Safe Unsupervised Semantic Segmentation","abstract":"Self-supervised pre-training strategies have recently shown impressive results for training general-purpose feature extraction backbones in computer vision. In combination with the Vision Transformer architecture, the DINO self-distillation technique has interesting emerging properties, such as unsupervised clustering in the latent space and semantic correspondences of the produced features without using explicit human-annotated labels. The STEGO method for unsupervised semantic segmentation contrastively distills feature correspondences of a DINO-pre-trained Vision Transformer and recently set a new state of the art. However, the detailed workings of STEGO have yet to be disentangled, preventing its usage in safety-critical applications. This paper provides a deeper understanding of the STEGO architecture and training strategy by conducting studies that uncover the working mechanisms behind STEGO, reproduce and extend its experimental validation, and investigate the ability of STEGO to transfer to different datasets. Results demonstrate that the STEGO architecture can be interpreted as a semantics-preserving dimensionality reduction technique.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07314v1","tag":"new-dataset"}}
{"title":"Jet substructure observables for jet quenching in Quark Gluon Plasma: a Machine Learning driven analysis","abstract":"We present a survey of a comprehensive set of jet substructure observables commonly used to study the modifications of jets resulting from interactions with the Quark Gluon Plasma in Heavy Ion Collisions. The \\jewel{} event generator is used to produce simulated samples of quenched and unquenched jets. Three distinct analyses using Machine Learning techniques on the jet substructure observables have been performed to identify both linear and non-linear relations between the observables, and to distinguish the Quenched and Unquenched jet samples. We find that most of the observables are highly correlated, and that their information content can be captured by a small set of observables. We also find that the correlations between observables are robust to quenching effects and that specific pairs of observables exhaust the full sensitivity to quenching effects. The code, the datasets, and instructions on how to reproduce this work are also provided.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07196v1","tag":"new-dataset"}}
{"title":"DINOv2: Learning Robust Visual Features without Supervision","abstract":"The recent breakthroughs in natural language processing for model pretraining on large quantities of data have opened the way for similar foundation models in computer vision. These models could greatly simplify the use of images in any system by producing all-purpose visual features, i.e., features that work across image distributions and tasks without finetuning. This work shows that existing pretraining methods, especially self-supervised methods, can produce such features if trained on enough curated data from diverse sources. We revisit existing approaches and combine different techniques to scale our pretraining in terms of data and model size. Most of the technical contributions aim at accelerating and stabilizing the training at scale. In terms of data, we propose an automatic pipeline to build a dedicated, diverse, and curated image dataset instead of uncurated data, as typically done in the self-supervised literature. In terms of models, we train a ViT model (Dosovitskiy et al., 2020) with 1B parameters and distill it into a series of smaller models that surpass the best available all-purpose features, OpenCLIP (Ilharco et al., 2021) on most of the benchmarks at image and pixel levels.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07193v1","tag":"new-dataset"}}
{"title":"Adapting Meter Tracking Models to Latin American Music","abstract":"Beat and downbeat tracking models have improved significantly in recent years with the introduction of deep learning methods. However, despite these improvements, several challenges remain. Particularly, the adaptation of available models to underrepresented music traditions in MIR is usually synonymous with collecting and annotating large amounts of data, which is impractical and time-consuming. Transfer learning, data augmentation, and fine-tuning techniques have been used quite successfully in related tasks and are known to alleviate this bottleneck. Furthermore, when studying these music traditions, models are not required to generalize to multiple mainstream music genres but to perform well in more constrained, homogeneous conditions. In this work, we investigate simple yet effective strategies to adapt beat and downbeat tracking models to two different Latin American music traditions and analyze the feasibility of these adaptations in real-world applications concerning the data and computational requirements. Contrary to common belief, our findings show it is possible to achieve good performance by spending just a few minutes annotating a portion of the data and training a model in a standard CPU machine, with the precise amount of resources needed depending on the task and the complexity of the dataset.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07186v1","tag":"new-dataset"}}
{"title":"A Comparative Study on Generative Models for High Resolution Solar Observation Imaging","abstract":"Solar activity is one of the main drivers of variability in our solar system and the key source of space weather phenomena that affect Earth and near Earth space. The extensive record of high resolution extreme ultraviolet (EUV) observations from the Solar Dynamics Observatory (SDO) offers an unprecedented, very large dataset of solar images. In this work, we make use of this comprehensive dataset to investigate capabilities of current state-of-the-art generative models to accurately capture the data distribution behind the observed solar activity states. Starting from StyleGAN-based methods, we uncover severe deficits of this model family in handling fine-scale details of solar images when training on high resolution samples, contrary to training on natural face images. When switching to the diffusion based generative model family, we observe strong improvements of fine-scale detail generation. For the GAN family, we are able to achieve similar improvements in fine-scale generation when turning to ProjectedGANs, which uses multi-scale discriminators with a pre-trained frozen feature extractor. We conduct ablation studies to clarify mechanisms responsible for proper fine-scale handling. Using distributed training on supercomputers, we are able to train generative models for up to 1024x1024 resolution that produce high quality samples indistinguishable to human experts, as suggested by the evaluation we conduct. We make all code, models and workflows used in this study publicly available at \\url{https://github.com/SLAMPAI/generative-models-for-highres-solar-images}.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07169v1","tag":"new-dataset"}}
{"title":"Robust thalamic nuclei segmentation from T1-weighted MRI","abstract":"Accurate segmentation of thalamic nuclei, crucial for understanding their role in healthy cognition and in pathologies, is challenging to achieve on standard T1-weighted (T1w) magnetic resonance imaging (MRI) due to poor image contrast. White-matter-nulled (WMn) MRI sequences improve intrathalamic contrast but are not part of clinical protocols or extant databases. Here, we introduce Histogram-based polynomial synthesis (HIPS), a fast preprocessing step that synthesizes WMn-like image contrast from standard T1w MRI using a polynomial approximation. HIPS was incorporated into our Thalamus Optimized Multi-Atlas Segmentation (THOMAS) pipeline, developed and optimized for WMn MRI. HIPS-THOMAS was compared to a convolutional neural network (CNN)-based segmentation method and THOMAS modified for T1w images (T1w-THOMAS). The robustness and accuracy of the three methods were tested across different image contrasts, scanner manufacturers, and field strength. HIPS-synthesized images improved intra-thalamic contrast and thalamic boundaries, and their segmentations yielded significantly better mean Dice, lower percentage of volume error, and lower standard deviations compared to both the CNN method and T1w-THOMAS. Finally, using THOMAS, HIPS-synthesized images were as effective as WMn images for identifying thalamic nuclei atrophy in alcohol use disorders subjects relative to healthy controls, with a higher area under the ROC curve compared to T1w-THOMAS (0.79 vs 0.73).","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07167v1","tag":"new-dataset"}}
{"title":"Unsupervised Learning Optical Flow in Multi-frame Dynamic Environment Using Temporal Dynamic Modeling","abstract":"For visual estimation of optical flow, a crucial function for many vision tasks, unsupervised learning, using the supervision of view synthesis has emerged as a promising alternative to supervised methods, since ground-truth flow is not readily available in many cases. However, unsupervised learning is likely to be unstable when pixel tracking is lost due to occlusion and motion blur, or the pixel matching is impaired due to variation in image content and spatial structure over time. In natural environments, dynamic occlusion or object variation is a relatively slow temporal process spanning several frames. We, therefore, explore the optical flow estimation from multiple-frame sequences of dynamic scenes, whereas most of the existing unsupervised approaches are based on temporal static models. We handle the unsupervised optical flow estimation with a temporal dynamic model by introducing a spatial-temporal dual recurrent block based on the predictive coding structure, which feeds the previous high-level motion prior to the current optical flow estimator. Assuming temporal smoothness of optical flow, we use motion priors of the adjacent frames to provide more reliable supervision of the occluded regions. To grasp the essence of challenging scenes, we simulate various scenarios across long sequences, including dynamic occlusion, content variation, and spatial variation, and adopt self-supervised distillation to make the model understand the object's motion patterns in a prolonged dynamic environment. Experiments on KITTI 2012, KITTI 2015, Sintel Clean, and Sintel Final datasets demonstrate the effectiveness of our methods on unsupervised optical flow estimation. The proposal achieves state-of-the-art performance with advantages in memory overhead.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07159v1","tag":"new-dataset"}}
{"title":"On Data Sampling Strategies for Training Neural Network Speech Separation Models","abstract":"Speech separation remains an important area of multi-speaker signal processing. Deep neural network (DNN) models have attained the best performance on many speech separation benchmarks. Some of these models can take significant time to train and have high memory requirements. Previous work has proposed shortening training examples to address these issues but the impact of this on model performance is not yet well understood. In this work, the impact of applying these training signal length (TSL) limits is analysed for two speech separation models: SepFormer, a transformer model, and Conv-TasNet, a convolutional model. The WJS0-2Mix, WHAMR and Libri2Mix datasets are analysed in terms of signal length distribution and its impact on training efficiency. It is demonstrated that, for specific distributions, applying specific TSL limits results in better performance. This is shown to be mainly due to randomly sampling the start index of the waveforms resulting in more unique examples for training. A SepFormer model trained using a TSL limit of 4.42s and dynamic mixing (DM) is shown to match the best-performing SepFormer model trained with DM and unlimited signal lengths. Furthermore, the 4.42s TSL limit results in a 44% reduction in training time with WHAMR.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07142v1","tag":"new-dataset"}}
{"title":"Sharp-SSL: Selective high-dimensional axis-aligned random projections for semi-supervised learning","abstract":"We propose a new method for high-dimensional semi-supervised learning problems based on the careful aggregation of the results of a low-dimensional procedure applied to many axis-aligned random projections of the data. Our primary goal is to identify important variables for distinguishing between the classes; existing low-dimensional methods can then be applied for final class assignment. Motivated by a generalized Rayleigh quotient, we score projections according to the traces of the estimated whitened between-class covariance matrices on the projected data. This enables us to assign an importance weight to each variable for a given projection, and to select our signal variables by aggregating these weights over high-scoring projections. Our theory shows that the resulting Sharp-SSL algorithm is able to recover the signal coordinates with high probability when we aggregate over sufficiently many random projections and when the base procedure estimates the whitened between-class covariance matrix sufficiently well. The Gaussian EM algorithm is a natural choice as a base procedure, and we provide a new analysis of its performance in semi-supervised settings that controls the parameter estimation error in terms of the proportion of labeled data in the sample. Numerical results on both simulated data and a real colon tumor dataset support the excellent empirical performance of the method.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09154v1","tag":"data-quality"}}
{"title":"MER 2023: Multi-label Learning, Modality Robustness, and Semi-Supervised Learning","abstract":"Over the past few decades, multimodal emotion recognition has made remarkable progress with the development of deep learning. However, existing technologies are difficult to meet the demand for practical applications. To improve the robustness, we launch a Multimodal Emotion Recognition Challenge (MER 2023) to motivate global researchers to build innovative technologies that can further accelerate and foster research. For this year's challenge, we present three distinct sub-challenges: (1) MER-MULTI, in which participants recognize both discrete and dimensional emotions; (2) MER-NOISE, in which noise is added to test videos for modality robustness evaluation; (3) MER-SEMI, which provides large amounts of unlabeled samples for semi-supervised learning. In this paper, we test a variety of multimodal features and provide a competitive baseline for each sub-challenge. Our system achieves 77.57% on the F1 score and 0.82 on the mean squared error (MSE) for MER-MULTI, 69.82% on the F1 score and 1.12 on MSE for MER-NOISE, and 86.75% on the F1 score for MER-SEMI, respectively. Baseline code is available at https://github.com/zeroQiaoba/MER2023-Baseline.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08981v1","tag":"data-quality"}}
{"title":"Soft Label Coding for End-to-end Sound Source Localization With Ad-hoc Microphone Arrays","abstract":"Recently, an end-to-end two-dimensional sound source localization algorithm with ad-hoc microphone arrays formulates the sound source localization problem as a classification problem. The algorithm divides the target indoor space into a set of local areas, and predicts the local area where the speaker locates. However, the local areas are encoded by one-hot code, which may lose the connections between the local areas due to quantization errors. In this paper, we propose a new soft label coding method, named label smoothing, for the classification-based two-dimensional sound source location with ad-hoc microphone arrays. The core idea is to take the geometric connection between the classes into the label coding process.The first one is named static soft label coding (SSLC), which modifies the one-hot codes into soft codes based on the distances between the local areas. Because SSLC is handcrafted which may not be optimal, the second one, named dynamic soft label coding (DSLC), further rectifies SSLC, by learning the soft codes according to the statistics of the predictions produced by the classification-based localization model in the training stage. Experimental results show that the proposed methods can effectively improve the localization accuracy.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07512v1","tag":"data-quality"}}
{"title":"Ranking Loss and Sequestering Learning for Reducing Image Search Bias in Histopathology","abstract":"Recently, deep learning has started to play an essential role in healthcare applications, including image search in digital pathology. Despite the recent progress in computer vision, significant issues remain for image searching in histopathology archives. A well-known problem is AI bias and lack of generalization. A more particular shortcoming of deep models is the ignorance toward search functionality. The former affects every model, the latter only search and matching. Due to the lack of ranking-based learning, researchers must train models based on the classification error and then use the resultant embedding for image search purposes. Moreover, deep models appear to be prone to internal bias even if using a large image repository of various hospitals. This paper proposes two novel ideas to improve image search performance. First, we use a ranking loss function to guide feature extraction toward the matching-oriented nature of the search. By forcing the model to learn the ranking of matched outputs, the representation learning is customized toward image search instead of learning a class label. Second, we introduce the concept of sequestering learning to enhance the generalization of feature extraction. By excluding the images of the input hospital from the matched outputs, i.e., sequestering the input domain, the institutional bias is reduced. The proposed ideas are implemented and validated through the largest public dataset of whole slide images. The experiments demonstrate superior results compare to the-state-of-art.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.08498v1","tag":"data-quality"}}
{"title":"Active Cost-aware Labeling of Streaming Data","abstract":"We study actively labeling streaming data, where an active learner is faced with a stream of data points and must carefully choose which of these points to label via an expensive experiment. Such problems frequently arise in applications such as healthcare and astronomy. We first study a setting when the data's inputs belong to one of $K$ discrete distributions and formalize this problem via a loss that captures the labeling cost and the prediction error. When the labeling cost is $B$, our algorithm, which chooses to label a point if the uncertainty is larger than a time and cost dependent threshold, achieves a worst-case upper bound of $O(B^{\\frac{1}{3}} K^{\\frac{1}{3}} T^{\\frac{2}{3}})$ on the loss after $T$ rounds. We also provide a more nuanced upper bound which demonstrates that the algorithm can adapt to the arrival pattern, and achieves better performance when the arrival pattern is more favorable. We complement both upper bounds with matching lower bounds. We next study this problem when the inputs belong to a continuous domain and the output of the experiment is a smooth function with bounded RKHS norm. After $T$ rounds in $d$ dimensions, we show that the loss is bounded by $O(B^{\\frac{1}{d+3}} T^{\\frac{d+2}{d+3}})$ in an RKHS with a squared exponential kernel and by $O(B^{\\frac{1}{2d+3}} T^{\\frac{2d+2}{2d+3}})$ in an RKHS with a Mat\\'ern kernel. Our empirical evaluation demonstrates that our method outperforms other baselines in several synthetic experiments and two real experiments in medicine and astronomy.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06808v1","tag":"data-quality"}}
{"title":"PALF: Pre-Annotation and Camera-LiDAR Late Fusion for the Easy Annotation of Point Clouds","abstract":"3D object detection has become indispensable in the field of autonomous driving. To date, gratifying breakthroughs have been recorded in 3D object detection research, attributed to deep learning. However, deep learning algorithms are data-driven and require large amounts of annotated point cloud data for training and evaluation. Unlike 2D image labels, annotating point cloud data is difficult due to the limitations of sparsity, irregularity, and low resolution, which requires more manual work, and the annotation efficiency is much lower than 2D image.Therefore, we propose an annotation algorithm for point cloud data, which is pre-annotation and camera-LiDAR late fusion algorithm to easily and accurately annotate. The contributions of this study are as follows. We propose (1) a pre-annotation algorithm that employs 3D object detection and auto fitting for the easy annotation of point clouds, (2) a camera-LiDAR late fusion algorithm using 2D and 3D results for easily error checking, which helps annotators easily identify missing objects, and (3) a point cloud annotation evaluation pipeline to evaluate our experiments. The experimental results show that the proposed algorithm improves the annotating speed by 6.5 times and the annotation quality in terms of the 3D Intersection over Union and precision by 8.2 points and 5.6 points, respectively; additionally, the miss rate is reduced by 31.9 points.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.08591v1","tag":"data-quality"}}
{"title":"Frame Error Rate Prediction for Non-Stationary Wireless Vehicular Communication Links","abstract":"Wireless vehicular communication will increase the safety of road users. The reliability of vehicular communication links is of high importance as links with low reliability may diminish the advantage of having situational traffic information. The goal of our investigation is to obtain a reliable coverage area for non-stationary vehicular scenarios. Therefore we propose a deep neural network (DNN) for predicting the expected frame error rate (FER). The DNN is trained in a supervised fashion, where a time-limited sequence of channel frequency responses has been labeled with its corresponding FER values assuming an underlying wireless communication system, i.e. IEEE 802.11p. For generating the training dataset we use a geometry-based stochastic channel model (GSCM). We obtain the ground truth FER by emulating the time-varying frequency responses using a hardware-in-the-loop setup. Our GSCM provides the propagation path parameters which we use to fix the statistics of the fading process at one point in space for an arbitrary amount of time, enabling accurate FER estimation. Using this dataset we achieve an accuracy of 85% of the DNN. We use the trained model to predict the FER for measured time-varying channel transfer functions obtained during a measurement campaign. We compare the predicted output of the DNN to the measured FER on the road and obtain a prediction accuracy of 78%.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05743v1","tag":"data-quality"}}
{"title":"Teaching Large Language Models to Self-Debug","abstract":"Large language models (LLMs) have achieved impressive performance on code generation. However, for complex programming tasks, generating the correct solution in one go becomes challenging, thus some prior works have designed program repair approaches to improve code generation performance. In this work, we propose Self-Debugging, which teaches a large language model to debug its predicted program via few-shot demonstrations. In particular, we demonstrate that Self-Debugging can teach the large language model to perform rubber duck debugging; i.e., without any feedback on the code correctness or error messages, the model is able to identify its mistakes by explaining the generated code in natural language. Self-Debugging achieves the state-of-the-art performance on several code generation benchmarks, including the Spider dataset for text-to-SQL generation, TransCoder for C++-to-Python translation, and MBPP for text-to-Python generation. On the Spider benchmark where there are no unit tests to verify the correctness of predictions, Self-Debugging with code explanation consistently improves the baseline by 2-3%, and improves the prediction accuracy on problems of the hardest label by 9%. On TransCoder and MBPP where unit tests are available, Self-Debugging improves the baseline accuracy by up to 12%. Meanwhile, by leveraging feedback messages and reusing failed predictions, Self-Debugging notably improves sample efficiency, and can match or outperform baseline models that generate more than 10x candidate programs.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05128v1","tag":"data-quality"}}
{"title":"A Self-attention Knowledge Domain Adaptation Network for Commercial Lithium-ion Batteries State-of-health Estimation under Shallow Cycles","abstract":"Accurate state-of-health (SOH) estimation is critical to guarantee the safety, efficiency and reliability of battery-powered applications. Most SOH estimation methods focus on the 0-100\\% full state-of-charge (SOC) range that has similar distributions. However, the batteries in real-world applications usually work in the partial SOC range under shallow-cycle conditions and follow different degradation profiles with no labeled data available, thus making SOH estimation challenging. To estimate shallow-cycle battery SOH, a novel unsupervised deep transfer learning method is proposed to bridge different domains using self-attention distillation module and multi-kernel maximum mean discrepancy technique. The proposed method automatically extracts domain-variant features from charge curves to transfer knowledge from the large-scale labeled full cycles to the unlabeled shallow cycles. The CALCE and SNL battery datasets are employed to verify the effectiveness of the proposed method to estimate the battery SOH for different SOC ranges, temperatures, and discharge rates. The proposed method achieves a root-mean-square error within 2\\% and outperforms other transfer learning methods for different SOC ranges. When applied to batteries with different operating conditions and from different manufacturers, the proposed method still exhibits superior SOH estimation performance. The proposed method is the first attempt at accurately estimating battery SOH under shallow-cycle conditions without needing a full-cycle characteristic test.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05084v1","tag":"data-quality"}}
{"title":"Semi-Supervised Relational Contrastive Learning","abstract":"Disease diagnosis from medical images via supervised learning is usually dependent on tedious, error-prone, and costly image labeling by medical experts. Alternatively, semi-supervised learning and self-supervised learning offer effectiveness through the acquisition of valuable insights from readily available unlabeled images. We present Semi-Supervised Relational Contrastive Learning (SRCL), a novel semi-supervised learning model that leverages self-supervised contrastive loss and sample relation consistency for the more meaningful and effective exploitation of unlabeled data. Our experimentation with the SRCL model explores both pre-train/fine-tune and joint learning of the pretext (contrastive learning) and downstream (diagnostic classification) tasks. We validate against the ISIC 2018 Challenge benchmark skin lesion classification dataset and demonstrate the effectiveness of our semi-supervised method on varying amounts of labeled data.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05047v1","tag":"data-quality"}}
{"title":"Eagle: End-to-end Deep Reinforcement Learning based Autonomous Control of PTZ Cameras","abstract":"Existing approaches for autonomous control of pan-tilt-zoom (PTZ) cameras use multiple stages where object detection and localization are performed separately from the control of the PTZ mechanisms. These approaches require manual labels and suffer from performance bottlenecks due to error propagation across the multi-stage flow of information. The large size of object detection neural networks also makes prior solutions infeasible for real-time deployment in resource-constrained devices. We present an end-to-end deep reinforcement learning (RL) solution called Eagle to train a neural network policy that directly takes images as input to control the PTZ camera. Training reinforcement learning is cumbersome in the real world due to labeling effort, runtime environment stochasticity, and fragile experimental setups. We introduce a photo-realistic simulation framework for training and evaluation of PTZ camera control policies. Eagle achieves superior camera control performance by maintaining the object of interest close to the center of captured images at high resolution and has up to 17% more tracking duration than the state-of-the-art. Eagle policies are lightweight (90x fewer parameters than Yolo5s) and can run on embedded camera platforms such as Raspberry PI (33 FPS) and Jetson Nano (38 FPS), facilitating real-time PTZ tracking for resource-constrained environments. With domain randomization, Eagle policies trained in our simulator can be transferred directly to real-world scenarios.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04356v1","tag":"data-quality"}}
{"title":"Variational operator learning: A unified paradigm for training neural operators and solving partial differential equations","abstract":"Based on the variational method, we propose a novel paradigm that provides a unified framework of training neural operators and solving partial differential equations (PDEs) with the variational form, which we refer to as the variational operator learning (VOL). We first derive the functional approximation of the system from the node solution prediction given by neural operators, and then conduct the variational operation by automatic differentiation, constructing a forward-backward propagation loop to derive the residual of the linear system. One or several update steps of the steepest decent method (SD) and the conjugate gradient method (CG) are provided in every iteration as a cheap yet effective update for training the neural operators. Experimental results show the proposed VOL can learn a variety of solution operators in PDEs of the steady heat transfer and the variable stiffness elasticity with satisfactory results and small error. The proposed VOL achieves nearly label-free training. Only five to ten labels are used for the output distribution-shift session in all experiments. Generalization benefits of the VOL are investigated and discussed.","created":"2023-04-09","meta":{"link":"http://arxiv.org/abs/2304.04234v1","tag":"data-quality"}}
{"title":"InstructBio: A Large-scale Semi-supervised Learning Paradigm for Biochemical Problems","abstract":"In the field of artificial intelligence for science, it is consistently an essential challenge to face a limited amount of labeled data for real-world problems. The prevailing approach is to pretrain a powerful task-agnostic model on a large unlabeled corpus but may struggle to transfer knowledge to downstream tasks. In this study, we propose InstructMol, a semi-supervised learning algorithm, to take better advantage of unlabeled examples. It introduces an instructor model to provide the confidence ratios as the measurement of pseudo-labels' reliability. These confidence scores then guide the target model to pay distinct attention to different data points, avoiding the over-reliance on labeled data and the negative influence of incorrect pseudo-annotations. Comprehensive experiments show that InstructBio substantially improves the generalization ability of molecular models, in not only molecular property predictions but also activity cliff estimations, demonstrating the superiority of the proposed method. Furthermore, our evidence indicates that InstructBio can be equipped with cutting-edge pretraining methods and used to establish large-scale and task-specific pseudo-labeled molecular datasets, which reduces the predictive errors and shortens the training process. Our work provides strong evidence that semi-supervised learning can be a promising tool to overcome the data scarcity limitation and advance molecular representation learning.","created":"2023-04-08","meta":{"link":"http://arxiv.org/abs/2304.03906v2","tag":"data-quality"}}
{"title":"Graphon Estimation in bipartite graphs with observable edge labels and unobservable node labels","abstract":"Many real-world data sets can be presented in the form of a matrix whose entries correspond to the interaction between two entities of different natures (number of times a web user visits a web page, a student's grade in a subject, a patient's rating of a doctor, etc.). We assume in this paper that the mentioned interaction is determined by unobservable latent variables describing each entity. Our objective is to estimate the conditional expectation of the data matrix given the unobservable variables. This is presented as a problem of estimation of a bivariate function referred to as graphon. We study the cases of piecewise constant and H\\\"older-continuous graphons. We establish finite sample risk bounds for the least squares estimator and the exponentially weighted aggregate. These bounds highlight the dependence of the estimation error on the size of the data set, the maximum intensity of the interactions, and the level of noise. As the analyzed least-squares estimator is intractable, we propose an adaptation of Lloyd's alternating minimization algorithm to compute an approximation of the least-squares estimator. Finally, we present numerical experiments in order to illustrate the empirical performance of the graphon estimator on synthetic data sets.","created":"2023-04-07","meta":{"link":"http://arxiv.org/abs/2304.03590v1","tag":"data-quality"}}
{"title":"ChatGPT-Crawler: Find out if ChatGPT really knows what it's talking about","abstract":"Large language models have gained considerable interest for their impressive performance on various tasks. Among these models, ChatGPT developed by OpenAI has become extremely popular among early adopters who even regard it as a disruptive technology in many fields like customer service, education, healthcare, and finance. It is essential to comprehend the opinions of these initial users as it can provide valuable insights into the potential strengths, weaknesses, and success or failure of the technology in different areas. This research examines the responses generated by ChatGPT from different Conversational QA corpora. The study employed BERT similarity scores to compare these responses with correct answers and obtain Natural Language Inference(NLI) labels. Evaluation scores were also computed and compared to determine the overall performance of GPT-3 \\& GPT-4. Additionally, the study identified instances where ChatGPT provided incorrect answers to questions, providing insights into areas where the model may be prone to error.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.03325v1","tag":"data-quality"}}
{"title":"Tag that issue: Applying API-domain labels in issue tracking systems","abstract":"Labeling issues with the skills required to complete them can help contributors to choose tasks in Open Source Software projects. However, manually labeling issues is time-consuming and error-prone, and current automated approaches are mostly limited to classifying issues as bugs/non-bugs. We investigate the feasibility and relevance of automatically labeling issues with what we call \"API-domains,\" which are high-level categories of APIs. Therefore, we posit that the APIs used in the source code affected by an issue can be a proxy for the type of skills (e.g., DB, security, UI) needed to work on the issue. We ran a user study (n=74) to assess API-domain labels' relevancy to potential contributors, leveraged the issues' descriptions and the project history to build prediction models, and validated the predictions with contributors (n=20) of the projects. Our results show that (i) newcomers to the project consider API-domain labels useful in choosing tasks, (ii) labels can be predicted with a precision of 84% and a recall of 78.6% on average, (iii) the results of the predictions reached up to 71.3% in precision and 52.5% in recall when training with a project and testing in another (transfer learning), and (iv) project contributors consider most of the predictions helpful in identifying needed skills. These findings suggest our approach can be applied in practice to automatically label issues, assisting developers in finding tasks that better match their skills.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.02877v1","tag":"data-quality"}}
{"title":"Logistic-Normal Likelihoods for Heteroscedastic Label Noise in Classification","abstract":"A natural way of estimating heteroscedastic label noise in regression is to model the observed (potentially noisy) target as a sample from a normal distribution, whose parameters can be learned by minimizing the negative log-likelihood. This loss has desirable loss attenuation properties, as it can reduce the contribution of high-error examples. Intuitively, this behavior can improve robustness against label noise by reducing overfitting. We propose an extension of this simple and probabilistic approach to classification that has the same desirable loss attenuation properties. We evaluate the effectiveness of the method by measuring its robustness against label noise in classification. We perform enlightening experiments exploring the inner workings of the method, including sensitivity to hyperparameters, ablation studies, and more.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.02849v1","tag":"data-quality"}}
{"title":"FMG-Net and W-Net: Multigrid Inspired Deep Learning Architectures For Medical Imaging Segmentation","abstract":"Accurate medical imaging segmentation is critical for precise and effective medical interventions. However, despite the success of convolutional neural networks (CNNs) in medical image segmentation, they still face challenges in handling fine-scale features and variations in image scales. These challenges are particularly evident in complex and challenging segmentation tasks, such as the BraTS multi-label brain tumor segmentation challenge. In this task, accurately segmenting the various tumor sub-components, which vary significantly in size and shape, remains a significant challenge, with even state-of-the-art methods producing substantial errors. Therefore, we propose two architectures, FMG-Net and W-Net, that incorporate the principles of geometric multigrid methods for solving linear systems of equations into CNNs to address these challenges. Our experiments on the BraTS 2020 dataset demonstrate that both FMG-Net and W-Net outperform the widely used U-Net architecture regarding tumor subcomponent segmentation accuracy and training efficiency. These findings highlight the potential of incorporating the principles of multigrid methods into CNNs to improve the accuracy and efficiency of medical imaging segmentation.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02725v1","tag":"data-quality"}}
{"title":"Agnostic proper learning of monotone functions: beyond the black-box correction barrier","abstract":"We give the first agnostic, efficient, proper learning algorithm for monotone Boolean functions. Given $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$ uniformly random examples of an unknown function $f:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$, our algorithm outputs a hypothesis $g:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$ that is monotone and $(\\mathrm{opt} + \\varepsilon)$-close to $f$, where $\\mathrm{opt}$ is the distance from $f$ to the closest monotone function. The running time of the algorithm (and consequently the size and evaluation time of the hypothesis) is also $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$, nearly matching the lower bound of Blais et al (RANDOM '15). We also give an algorithm for estimating up to additive error $\\varepsilon$ the distance of an unknown function $f$ to monotone using a run-time of $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$. Previously, for both of these problems, sample-efficient algorithms were known, but these algorithms were not run-time efficient. Our work thus closes this gap in our knowledge between the run-time and sample complexity.   This work builds upon the improper learning algorithm of Bshouty and Tamon (JACM '96) and the proper semiagnostic learning algorithm of Lange, Rubinfeld, and Vasilyan (FOCS '22), which obtains a non-monotone Boolean-valued hypothesis, then ``corrects'' it to monotone using query-efficient local computation algorithms on graphs. This black-box correction approach can achieve no error better than $2\\mathrm{opt} + \\varepsilon$ information-theoretically; we bypass this barrier by   a) augmenting the improper learner with a convex optimization step, and   b) learning and correcting a real-valued function before rounding its values to Boolean.   Our real-valued correction algorithm solves the ``poset sorting'' problem of [LRV22] for functions over general posets with non-Boolean labels.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02700v2","tag":"data-quality"}}
{"title":"Multi-annotator Deep Learning: A Probabilistic Framework for Classification","abstract":"Solving complex classification tasks using deep neural networks typically requires large amounts of annotated data. However, corresponding class labels are noisy when provided by error-prone annotators, e.g., crowd workers. Training standard deep neural networks leads to subpar performances in such multi-annotator supervised learning settings. We address this issue by presenting a probabilistic training framework named multi-annotator deep learning (MaDL). A ground truth and an annotator performance model are jointly trained in an end-to-end learning approach. The ground truth model learns to predict instances' true class labels, while the annotator performance model infers probabilistic estimates of annotators' performances. A modular network architecture enables us to make varying assumptions regarding annotators' performances, e.g., an optional class or instance dependency. Further, we learn annotator embeddings to estimate annotators' densities within a latent space as proxies of their potentially correlated annotations. Together with a weighted loss function, we improve the learning from correlated annotation patterns. In a comprehensive evaluation, we examine three research questions about multi-annotator supervised learning. Our findings indicate MaDL's state-of-the-art performance and robustness against many correlated, spamming annotators.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02539v1","tag":"data-quality"}}
{"title":"Distance maps between Japanese kanji characters based on hierarchical optimal transport","abstract":"We introduce a general framework for assigning distances between kanji based on their dissimilarity. What we mean by this term may depend on the concrete application. The only assumption we make is that the dissimilarity between two kanji is adequately expressed as a weighted mean of penalties obtained from matching nested structures of components in an optimal way. For the cost of matching, we suggest a number of modules that can be freely combined or replaced with other modules, including the relative unbalanced ink transport between registered components, the distance between the transformations required for registration, and the difference in prespecified labels.   We give a concrete example of a kanji distance function obtained in this way as a proof of concept. Based on this function, we produce 2D kanji maps by multidimensional scaling and a table of 100 randomly selected J\\=oj\\=o kanji with their 16 nearest neighbors.   Our kanji distance functions can be used to help Japanese learners from non-CJK backgrounds acquire kanji literacy. In addition, they may assist editors of kanji dictionaries in presenting their materials and may serve in text processing and optical character recognition systems for assessing the likelihood of errors.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02493v1","tag":"data-quality"}}
{"title":"Learning to Name Classes for Vision and Language Models","abstract":"Large scale vision and language models can achieve impressive zero-shot recognition performance by mapping class specific text queries to image content. Two distinct challenges that remain however, are high sensitivity to the choice of handcrafted class names that define queries, and the difficulty of adaptation to new, smaller datasets. Towards addressing these problems, we propose to leverage available data to learn, for each class, an optimal word embedding as a function of the visual content. By learning new word embeddings on an otherwise frozen model, we are able to retain zero-shot capabilities for new classes, easily adapt models to new datasets, and adjust potentially erroneous, non-descriptive or ambiguous class names. We show that our solution can easily be integrated in image classification and object detection pipelines, yields significant performance gains in multiple scenarios and provides insights into model biases and labelling errors.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01830v1","tag":"data-quality"}}
{"title":"Divided Attention: Unsupervised Multi-Object Discovery with Contextually Separated Slots","abstract":"We introduce a method to segment the visual field into independently moving regions, trained with no ground truth or supervision. It consists of an adversarial conditional encoder-decoder architecture based on Slot Attention, modified to use the image as context to decode optical flow without attempting to reconstruct the image itself. In the resulting multi-modal representation, one modality (flow) feeds the encoder to produce separate latent codes (slots), whereas the other modality (image) conditions the decoder to generate the first (flow) from the slots. This design frees the representation from having to encode complex nuisance variability in the image due to, for instance, illumination and reflectance properties of the scene. Since customary autoencoding based on minimizing the reconstruction error does not preclude the entire flow from being encoded into a single slot, we modify the loss to an adversarial criterion based on Contextual Information Separation. The resulting min-max optimization fosters the separation of objects and their assignment to different attention slots, leading to Divided Attention, or DivA. DivA outperforms recent unsupervised multi-object motion segmentation methods while tripling run-time speed up to 104FPS and reducing the performance gap from supervised methods to 12% or less. DivA can handle different numbers of objects and different image sizes at training and test time, is invariant to permutation of object labels, and does not require explicit regularization.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01430v1","tag":"data-quality"}}
{"title":"A Scale-Invariant Trajectory Simplification Method for Efficient Data Collection in Videos","abstract":"Training data is a critical requirement for machine learning tasks, and labeled training data can be expensive to acquire, often requiring manual or semi-automated data collection pipelines. For tracking applications, the data collection involves drawing bounding boxes around the classes of interest on each frame, and associate detections of the same \"instance\" over frames. In a semi-automated data collection pipeline, this can be achieved by running a baseline detection and tracking algorithm, and relying on manual correction to add/remove/change bounding boxes on each frame, as well as resolving errors in the associations over frames (track switches). In this paper, we propose a data correction pipeline to generate ground-truth data more efficiently in this semi-automated scenario. Our method simplifies the trajectories from the tracking systems and let the annotator verify and correct the objects in the sampled keyframes. Once the objects in the keyframes are corrected, the bounding boxes in the other frames are obtained by interpolation. Our method achieves substantial reduction in the number of frames requiring manual correction. In the MOT dataset, it reduces the number of frames by 30x while maintaining a HOTA score of 89.61% . Moreover, it reduces the number of frames by a factor of 10x while achieving a HOTA score of 79.24% in the SoccerNet dataset, and 85.79% in the DanceTrack dataset. The project code and data are publicly released at https://github.com/foreverYoungGitHub/trajectory-simplify-benchmark.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.01340v1","tag":"data-quality"}}
{"title":"Towards Integration of Discriminability and Robustness for Document-Level Relation Extraction","abstract":"Document-level relation extraction (DocRE) predicts relations for entity pairs that rely on long-range context-dependent reasoning in a document. As a typical multi-label classification problem, DocRE faces the challenge of effectively distinguishing a small set of positive relations from the majority of negative ones. This challenge becomes even more difficult to overcome when there exists a significant number of annotation errors in the dataset. In this work, we aim to achieve better integration of both the discriminability and robustness for the DocRE problem. Specifically, we first design an effective loss function to endow high discriminability to both probabilistic outputs and internal representations. We innovatively customize entropy minimization and supervised contrastive learning for the challenging multi-label and long-tailed learning problems. To ameliorate the impact of label errors, we equipped our method with a novel negative label sampling strategy to strengthen the model robustness. In addition, we introduce two new data regimes to mimic more realistic scenarios with annotation errors and evaluate our sampling strategy. Experimental results verify the effectiveness of each component and show that our method achieves new state-of-the-art results on the DocRED dataset, its recently cleaned version, Re-DocRED, and the proposed data regimes.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.00824v1","tag":"data-quality"}}
{"title":"Rotating labeling of entropy coders for synthetic DNA data storage","abstract":"Over the past years, the ever-growing trend on data storage demand, more specifically for \"cold\" data (i.e. rarely accessed), has motivated research for alternative systems of data storage. Because of its biochemical characteristics, synthetic DNA molecules are considered as potential candidates for a new storage paradigm. Because of this trend, several coding solutions have been proposed over the past years for the storage of digital information into DNA. Despite being a promising solution, DNA storage faces two major obstacles: the large cost of synthesis and the noise introduced during sequencing. Additionally, this noise increases when biochemically defined coding constraints are not respected: avoiding homopolymers and patterns, as well as balancing the GC content. This paper describes a novel entropy coder which can be embedded to any block-based image-coding schema and aims to robustify the decoded results. Our proposed solution introduces variability in the generated quaternary streams, reduces the amount of homopolymers and repeated patterns to reduce the probability of errors occurring. In this paper, we integrate the proposed entropy coder into four existing JPEG-inspired DNA coders. We then evaluate the quality -- in terms of biochemical constraints -- of the encoded data for all the different methods.","created":"2023-04-02","meta":{"link":"http://arxiv.org/abs/2304.00493v1","tag":"data-quality"}}
{"title":"LabelVizier: Interactive Validation and Relabeling for Technical Text Annotations","abstract":"With the rapid accumulation of text data produced by data-driven techniques, the task of extracting \"data annotations\"--concise, high-quality data summaries from unstructured raw text--has become increasingly important. The recent advances in weak supervision and crowd-sourcing techniques provide promising solutions to efficiently create annotations (labels) for large-scale technical text data. However, such annotations may fail in practice because of the change in annotation requirements, application scenarios, and modeling goals, where label validation and relabeling by domain experts are required. To approach this issue, we present LabelVizier, a human-in-the-loop workflow that incorporates domain knowledge and user-specific requirements to reveal actionable insights into annotation flaws, then produce better-quality labels for large-scale multi-label datasets. We implement our workflow as an interactive notebook to facilitate flexible error profiling, in-depth annotation validation for three error types, and efficient annotation relabeling on different data scales. We evaluated the efficiency and generalizability of our workflow with two use cases and four expert reviews. The results indicate that LabelVizier is applicable in various application scenarios and assist domain experts with different knowledge backgrounds to efficiently improve technical text annotation quality.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.17820v1","tag":"data-quality"}}
{"title":"FairGen: Towards Fair Graph Generation","abstract":"There have been tremendous efforts over the past decades dedicated to the generation of realistic graphs in a variety of domains, ranging from social networks to computer networks, from gene regulatory networks to online transaction networks. Despite the remarkable success, the vast majority of these works are unsupervised in nature and are typically trained to minimize the expected graph reconstruction loss, which would result in the representation disparity issue in the generated graphs, i.e., the protected groups (often minorities) contribute less to the objective and thus suffer from systematically higher errors. In this paper, we aim to tailor graph generation to downstream mining tasks by leveraging label information and user-preferred parity constraint. In particular, we start from the investigation of representation disparity in the context of graph generative models. To mitigate the disparity, we propose a fairness-aware graph generative model named FairGen. Our model jointly trains a label-informed graph generation module and a fair representation learning module by progressively learning the behaviors of the protected and unprotected groups, from the `easy' concepts to the `hard' ones. In addition, we propose a generic context sampling strategy for graph generative models, which is proven to be capable of fairly capturing the contextual information of each group with a high probability. Experimental results on seven real-world data sets, including web-based graphs, demonstrate that FairGen (1) obtains performance on par with state-of-the-art graph generative models across six network properties, (2) mitigates the representation disparity issues in the generated graphs, and (3) substantially boosts the model performance by up to 17% in downstream tasks via data augmentation.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17743v1","tag":"data-quality"}}
{"title":"ISSTAD: Incremental Self-Supervised Learning Based on Transformer for Anomaly Detection and Localization","abstract":"In the realm of machine learning, the study of anomaly detection and localization within image data has gained substantial traction, particularly for practical applications such as industrial defect detection. While the majority of existing methods predominantly use Convolutional Neural Networks (CNN) as their primary network architecture, we introduce a novel approach based on the Transformer backbone network. Our method employs a two-stage incremental learning strategy. During the first stage, we train a Masked Autoencoder (MAE) model solely on normal images. In the subsequent stage, we apply pixel-level data augmentation techniques to generate corrupted normal images and their corresponding pixel labels. This process allows the model to learn how to repair corrupted regions and classify the status of each pixel. Ultimately, the model generates a pixel reconstruction error matrix and a pixel anomaly probability matrix. These matrices are then combined to produce an anomaly scoring matrix that effectively detects abnormal regions. When benchmarked against several state-of-the-art CNN-based methods, our approach exhibits superior performance on the MVTec AD dataset, achieving an impressive 97.6% AUC.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17354v3","tag":"data-quality"}}
{"title":"Few-shot Geometry-Aware Keypoint Localization","abstract":"Supervised keypoint localization methods rely on large manually labeled image datasets, where objects can deform, articulate, or occlude. However, creating such large keypoint labels is time-consuming and costly, and is often error-prone due to inconsistent labeling. Thus, we desire an approach that can learn keypoint localization with fewer yet consistently annotated images. To this end, we present a novel formulation that learns to localize semantically consistent keypoint definitions, even for occluded regions, for varying object categories. We use a few user-labeled 2D images as input examples, which are extended via self-supervision using a larger unlabeled dataset. Unlike unsupervised methods, the few-shot images act as semantic shape constraints for object localization. Furthermore, we introduce 3D geometry-aware constraints to uplift keypoints, achieving more accurate 2D localization. Our general-purpose formulation paves the way for semantically conditioned generative modeling and attains competitive or state-of-the-art accuracy on several datasets, including human faces, eyes, animals, cars, and never-before-seen mouth interior (teeth) localization tasks, not attempted by the previous few-shot methods. Project page: https://xingzhehe.github.io/FewShot3DKP/}{https://xingzhehe.github.io/FewShot3DKP/","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17216v1","tag":"data-quality"}}
{"title":"Discriminative Class Tokens for Text-to-Image Diffusion Models","abstract":"Recent advances in text-to-image diffusion models have enabled the generation of diverse and high-quality images. However, generated images often fall short of depicting subtle details and are susceptible to errors due to ambiguity in the input text. One way of alleviating these issues is to train diffusion models on class-labeled datasets. This comes with a downside, doing so limits their expressive power: (i) supervised datasets are generally small compared to large-scale scraped text-image datasets on which text-to-image models are trained, and so the quality and diversity of generated images are severely affected, or (ii) the input is a hard-coded label, as opposed to free-form text, which limits the control over the generated images.   In this work, we propose a non-invasive fine-tuning technique that capitalizes on the expressive potential of free-form text while achieving high accuracy through discriminative signals from a pretrained classifier, which guides the generation. This is done by iteratively modifying the embedding of a single input token of a text-to-image diffusion model, using the classifier, by steering generated images toward a given target class. Our method is fast compared to prior fine-tuning methods and does not require a collection of in-class images or retraining of a noise-tolerant classifier. We evaluate our method extensively, showing that the generated images are: (i) more accurate and of higher quality than standard diffusion models, (ii) can be used to augment training data in a low-resource setting, and (iii) reveal information about the data used to train the guiding classifier. The code is available at \\url{https://github.com/idansc/discriminative_class_tokens}","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17155v1","tag":"data-quality"}}
{"title":"Towards Understanding the Effect of Pretraining Label Granularity","abstract":"In this paper, we study how pretraining label granularity affects the generalization of deep neural networks in image classification tasks. We focus on the \"fine-to-coarse\" transfer learning setting where the pretraining label is more fine-grained than that of the target problem. We experiment with this method using the label hierarchy of iNaturalist 2021, and observe a 8.76% relative improvement of the error rate over the baseline. We find the following conditions are key for the improvement: 1) the pretraining dataset has a strong and meaningful label hierarchy, 2) its label function strongly aligns with that of the target task, and most importantly, 3) an appropriate level of pretraining label granularity is chosen. The importance of pretraining label granularity is further corroborated by our transfer learning experiments on ImageNet. Most notably, we show that pretraining at the leaf labels of ImageNet21k produces better transfer results on ImageNet1k than pretraining at other coarser granularity levels, which supports the common practice. Theoretically, through an analysis on a two-layer convolutional ReLU network, we prove that: 1) models trained on coarse-grained labels only respond strongly to the common or \"easy-to-learn\" features; 2) with the dataset satisfying the right conditions, fine-grained pretraining encourages the model to also learn rarer or \"harder-to-learn\" features well, thus improving the model's generalization.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16887v1","tag":"data-quality"}}
{"title":"Joint unsupervised and supervised learning for context-aware language identification","abstract":"Language identification (LID) recognizes the language of a spoken utterance automatically. According to recent studies, LID models trained with an automatic speech recognition (ASR) task perform better than those trained with a LID task only. However, we need additional text labels to train the model to recognize speech, and acquiring the text labels is a cost high. In order to overcome this problem, we propose context-aware language identification using a combination of unsupervised and supervised learning without any text labels. The proposed method learns the context of speech through masked language modeling (MLM) loss and simultaneously trains to determine the language of the utterance with supervised learning loss. The proposed joint learning was found to reduce the error rate by 15.6% compared to the same structure model trained by supervised-only learning on a subset of the VoxLingua107 dataset consisting of sub-three-second utterances in 11 languages.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16511v2","tag":"data-quality"}}
{"title":"Thread Counting in Plain Weave for Old Paintings Using Semi-Supervised Regression Deep Learning Models","abstract":"In this work, the authors develop regression approaches based on deep learning to perform thread density estimation for plain weave canvas analysis. Previous approaches were based on Fourier analysis, which is quite robust for some scenarios but fails in some others, in machine learning tools, that involve pre-labeling of the painting at hand, or the segmentation of thread crossing points, that provides good estimations in all scenarios with no need of pre-labeling. The segmentation approach is time-consuming as the estimation of the densities is performed after locating the crossing points. In this novel proposal, we avoid this step by computing the density of threads directly from the image with a regression deep learning model. We also incorporate some improvements in the initial preprocessing of the input image with an impact on the final error. Several models are proposed and analyzed to retain the best one. Furthermore, we further reduce the density estimation error by introducing a semi-supervised approach. The performance of our novel algorithm is analyzed with works by Ribera, Vel\\'azquez, and Poussin where we compare our results to the ones of previous approaches. Finally, the method is put into practice to support the change of authorship or a masterpiece at the Museo del Prado.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15999v3","tag":"data-quality"}}
{"title":"Cluster-Guided Unsupervised Domain Adaptation for Deep Speaker Embedding","abstract":"Recent studies have shown that pseudo labels can contribute to unsupervised domain adaptation (UDA) for speaker verification. Inspired by the self-training strategies that use an existing classifier to label the unlabeled data for retraining, we propose a cluster-guided UDA framework that labels the target domain data by clustering and combines the labeled source domain data and pseudo-labeled target domain data to train a speaker embedding network. To improve the cluster quality, we train a speaker embedding network dedicated for clustering by minimizing the contrastive center loss. The goal is to reduce the distance between an embedding and its assigned cluster center while enlarging the distance between the embedding and the other cluster centers. Using VoxCeleb2 as the source domain and CN-Celeb1 as the target domain, we demonstrate that the proposed method can achieve an equal error rate (EER) of 8.10% on the CN-Celeb1 evaluation set without using any labels from the target domain. This result outperforms the supervised baseline by 39.6% and is the state-of-the-art UDA performance on this corpus.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15944v1","tag":"data-quality"}}
{"title":"Unified Keypoint-based Action Recognition Framework via Structured Keypoint Pooling","abstract":"This paper simultaneously addresses three limitations associated with conventional skeleton-based action recognition; skeleton detection and tracking errors, poor variety of the targeted actions, as well as person-wise and frame-wise action recognition. A point cloud deep-learning paradigm is introduced to the action recognition, and a unified framework along with a novel deep neural network architecture called Structured Keypoint Pooling is proposed. The proposed method sparsely aggregates keypoint features in a cascaded manner based on prior knowledge of the data structure (which is inherent in skeletons), such as the instances and frames to which each keypoint belongs, and achieves robustness against input errors. Its less constrained and tracking-free architecture enables time-series keypoints consisting of human skeletons and nonhuman object contours to be efficiently treated as an input 3D point cloud and extends the variety of the targeted action. Furthermore, we propose a Pooling-Switching Trick inspired by Structured Keypoint Pooling. This trick switches the pooling kernels between the training and inference phases to detect person-wise and frame-wise actions in a weakly supervised manner using only video-level action labels. This trick enables our training scheme to naturally introduce novel data augmentation, which mixes multiple point clouds extracted from different videos. In the experiments, we comprehensively verify the effectiveness of the proposed method against the limitations, and the method outperforms state-of-the-art skeleton-based action recognition and spatio-temporal action localization methods.","created":"2023-03-27","meta":{"link":"http://arxiv.org/abs/2303.15270v1","tag":"data-quality"}}
{"title":"On the Importance of Feature Separability in Predicting Out-Of-Distribution Error","abstract":"Estimating the generalization performance is practically challenging on out-of-distribution (OOD) data without ground truth labels. While previous methods emphasize the connection between distribution difference and OOD accuracy, we show that a large domain gap not necessarily leads to a low test accuracy. In this paper, we investigate this problem from the perspective of feature separability, and propose a dataset-level score based upon feature dispersion to estimate the test accuracy under distribution shift. Our method is inspired by desirable properties of features in representation learning: high inter-class dispersion and high intra-class compactness. Our analysis shows that inter-class dispersion is strongly correlated with the model accuracy, while intra-class compactness does not reflect the generalization performance on OOD data. Extensive experiments demonstrate the superiority of our method in both prediction performance and computational efficiency.","created":"2023-03-27","meta":{"link":"http://arxiv.org/abs/2303.15488v1","tag":"data-quality"}}
{"title":"Adaptive Bi-Recommendation and Self-Improving Network for Heterogeneous Domain Adaptation-Assisted IoT Intrusion Detection","abstract":"As Internet of Things devices become prevalent, using intrusion detection to protect IoT from malicious intrusions is of vital importance. However, the data scarcity of IoT hinders the effectiveness of traditional intrusion detection methods. To tackle this issue, in this paper, we propose the Adaptive Bi-Recommendation and Self-Improving Network (ABRSI) based on unsupervised heterogeneous domain adaptation (HDA). The ABRSI transfers enrich intrusion knowledge from a data-rich network intrusion source domain to facilitate effective intrusion detection for data-scarce IoT target domains. The ABRSI achieves fine-grained intrusion knowledge transfer via adaptive bi-recommendation matching. Matching the bi-recommendation interests of two recommender systems and the alignment of intrusion categories in the shared feature space form a mutual-benefit loop. Besides, the ABRSI uses a self-improving mechanism, autonomously improving the intrusion knowledge transfer from four ways. A hard pseudo label voting mechanism jointly considers recommender system decision and label relationship information to promote more accurate hard pseudo label assignment. To promote diversity and target data participation during intrusion knowledge transfer, target instances failing to be assigned with a hard pseudo label will be assigned with a probabilistic soft pseudo label, forming a hybrid pseudo-labelling strategy. Meanwhile, the ABRSI also makes soft pseudo-labels globally diverse and individually certain. Finally, an error knowledge learning mechanism is utilised to adversarially exploit factors that causes detection ambiguity and learns through both current and previous error knowledge, preventing error knowledge forgetfulness. Holistically, these mechanisms form the ABRSI model that boosts IoT intrusion detection accuracy via HDA-assisted intrusion knowledge transfer.","created":"2023-03-25","meta":{"link":"http://arxiv.org/abs/2303.14317v1","tag":"data-quality"}}
{"title":"MSdocTr-Lite: A Lite Transformer for Full Page Multi-script Handwriting Recognition","abstract":"The Transformer has quickly become the dominant architecture for various pattern recognition tasks due to its capacity for long-range representation. However, transformers are data-hungry models and need large datasets for training. In Handwritten Text Recognition (HTR), collecting a massive amount of labeled data is a complicated and expensive task. In this paper, we propose a lite transformer architecture for full-page multi-script handwriting recognition. The proposed model comes with three advantages: First, to solve the common problem of data scarcity, we propose a lite transformer model that can be trained on a reasonable amount of data, which is the case of most HTR public datasets, without the need for external data. Second, it can learn the reading order at page-level thanks to a curriculum learning strategy, allowing it to avoid line segmentation errors, exploit a larger context and reduce the need for costly segmentation annotations. Third, it can be easily adapted to other scripts by applying a simple transfer-learning process using only page-level labeled images. Extensive experiments on different datasets with different scripts (French, English, Spanish, and Arabic) show the effectiveness of the proposed model.","created":"2023-03-24","meta":{"link":"http://arxiv.org/abs/2303.13931v1","tag":"data-quality"}}
{"title":"2PCNet: Two-Phase Consistency Training for Day-to-Night Unsupervised Domain Adaptive Object Detection","abstract":"Object detection at night is a challenging problem due to the absence of night image annotations. Despite several domain adaptation methods, achieving high-precision results remains an issue. False-positive error propagation is still observed in methods using the well-established student-teacher framework, particularly for small-scale and low-light objects. This paper proposes a two-phase consistency unsupervised domain adaptation network, 2PCNet, to address these issues. The network employs high-confidence bounding-box predictions from the teacher in the first phase and appends them to the student's region proposals for the teacher to re-evaluate in the second phase, resulting in a combination of high and low confidence pseudo-labels. The night images and pseudo-labels are scaled-down before being used as input to the student, providing stronger small-scale pseudo-labels. To address errors that arise from low-light regions and other night-related attributes in images, we propose a night-specific augmentation pipeline called NightAug. This pipeline involves applying random augmentations, such as glare, blur, and noise, to daytime images. Experiments on publicly available datasets demonstrate that our method achieves superior results to state-of-the-art methods by 20\\%, and to supervised models trained directly on the target data.","created":"2023-03-24","meta":{"link":"http://arxiv.org/abs/2303.13853v1","tag":"data-quality"}}
{"title":"A Closer Look at Scoring Functions and Generalization Prediction","abstract":"Generalization error predictors (GEPs) aim to predict model performance on unseen distributions by deriving dataset-level error estimates from sample-level scores. However, GEPs often utilize disparate mechanisms (e.g., regressors, thresholding functions, calibration datasets, etc), to derive such error estimates, which can obfuscate the benefits of a particular scoring function. Therefore, in this work, we rigorously study the effectiveness of popular scoring functions (confidence, local manifold smoothness, model agreement), independent of mechanism choice. We find, absent complex mechanisms, that state-of-the-art confidence- and smoothness- based scores fail to outperform simple model-agreement scores when estimating error under distribution shifts and corruptions. Furthermore, on realistic settings where the training data has been compromised (e.g., label noise, measurement noise, undersampling), we find that model-agreement scores continue to perform well and that ensemble diversity is important for improving its performance. Finally, to better understand the limitations of scoring functions, we demonstrate that simplicity bias, or the propensity of deep neural networks to rely upon simple but brittle features, can adversely affect GEP performance. Overall, our work carefully studies the effectiveness of popular scoring functions in realistic settings and helps to better understand their limitations.","created":"2023-03-23","meta":{"link":"http://arxiv.org/abs/2303.13589v1","tag":"data-quality"}}
{"title":"Adaptive Endpointing with Deep Contextual Multi-armed Bandits","abstract":"Current endpointing (EP) solutions learn in a supervised framework, which does not allow the model to incorporate feedback and improve in an online setting. Also, it is a common practice to utilize costly grid-search to find the best configuration for an endpointing model. In this paper, we aim to provide a solution for adaptive endpointing by proposing an efficient method for choosing an optimal endpointing configuration given utterance-level audio features in an online setting, while avoiding hyperparameter grid-search. Our method does not require ground truth labels, and only uses online learning from reward signals without requiring annotated labels. Specifically, we propose a deep contextual multi-armed bandit-based approach, which combines the representational power of neural networks with the action exploration behavior of Thompson modeling algorithms. We compare our approach to several baselines, and show that our deep bandit models also succeed in reducing early cutoff errors while maintaining low latency.","created":"2023-03-23","meta":{"link":"http://arxiv.org/abs/2303.13407v1","tag":"data-quality"}}
{"title":"Semantic Image Attack for Visual Model Diagnosis","abstract":"In practice, metric analysis on a specific train and test dataset does not guarantee reliable or fair ML models. This is partially due to the fact that obtaining a balanced, diverse, and perfectly labeled dataset is typically expensive, time-consuming, and error-prone. Rather than relying on a carefully designed test set to assess ML models' failures, fairness, or robustness, this paper proposes Semantic Image Attack (SIA), a method based on the adversarial attack that provides semantic adversarial images to allow model diagnosis, interpretability, and robustness. Traditional adversarial training is a popular methodology for robustifying ML models against attacks. However, existing adversarial methods do not combine the two aspects that enable the interpretation and analysis of the model's flaws: semantic traceability and perceptual quality. SIA combines the two features via iterative gradient ascent on a predefined semantic attribute space and the image space. We illustrate the validity of our approach in three scenarios for keypoint detection and classification. (1) Model diagnosis: SIA generates a histogram of attributes that highlights the semantic vulnerability of the ML model (i.e., attributes that make the model fail). (2) Stronger attacks: SIA generates adversarial examples with visually interpretable attributes that lead to higher attack success rates than baseline methods. The adversarial training on SIA improves the transferable robustness across different gradient-based attacks. (3) Robustness to imbalanced datasets: we use SIA to augment the underrepresented classes, which outperforms strong augmentation and re-balancing baselines.","created":"2023-03-23","meta":{"link":"http://arxiv.org/abs/2303.13010v1","tag":"data-quality"}}
{"title":"Human Uncertainty in Concept-Based AI Systems","abstract":"Placing a human in the loop may abate the risks of deploying AI systems in safety-critical settings (e.g., a clinician working with a medical AI system). However, mitigating risks arising from human error and uncertainty within such human-AI interactions is an important and understudied issue. In this work, we study human uncertainty in the context of concept-based models, a family of AI systems that enable human feedback via concept interventions where an expert intervenes on human-interpretable concepts relevant to the task. Prior work in this space often assumes that humans are oracles who are always certain and correct. Yet, real-world decision-making by humans is prone to occasional mistakes and uncertainty. We study how existing concept-based models deal with uncertain interventions from humans using two novel datasets: UMNIST, a visual dataset with controlled simulated uncertainty based on the MNIST dataset, and CUB-S, a relabeling of the popular CUB concept dataset with rich, densely-annotated soft labels from humans. We show that training with uncertain concept labels may help mitigate weaknesses of concept-based systems when handling uncertain interventions. These results allow us to identify several open challenges, which we argue can be tackled through future multidisciplinary research on building interactive uncertainty-aware systems. To facilitate further research, we release a new elicitation platform, UElic, to collect uncertain feedback from humans in collaborative prediction tasks.","created":"2023-03-22","meta":{"link":"http://arxiv.org/abs/2303.12872v1","tag":"data-quality"}}
{"title":"MaskCon: Masked Contrastive Learning for Coarse-Labelled Dataset","abstract":"Deep learning has achieved great success in recent years with the aid of advanced neural network structures and large-scale human-annotated datasets. However, it is often costly and difficult to accurately and efficiently annotate large-scale datasets, especially for some specialized domains where fine-grained labels are required. In this setting, coarse labels are much easier to acquire as they do not require expert knowledge. In this work, we propose a contrastive learning method, called $\\textbf{Mask}$ed $\\textbf{Con}$trastive learning~($\\textbf{MaskCon}$) to address the under-explored problem setting, where we learn with a coarse-labelled dataset in order to address a finer labelling problem. More specifically, within the contrastive learning framework, for each sample our method generates soft-labels with the aid of coarse labels against other samples and another augmented view of the sample in question. By contrast to self-supervised contrastive learning where only the sample's augmentations are considered hard positives, and in supervised contrastive learning where only samples with the same coarse labels are considered hard positives, we propose soft labels based on sample distances, that are masked by the coarse labels. This allows us to utilize both inter-sample relations and coarse labels. We demonstrate that our method can obtain as special cases many existing state-of-the-art works and that it provides tighter bounds on the generalization error. Experimentally, our method achieves significant improvement over the current state-of-the-art in various datasets, including CIFAR10, CIFAR100, ImageNet-1K, Standford Online Products and Stanford Cars196 datasets. Code and annotations are available at https://github.com/MrChenFeng/MaskCon_CVPR2023.","created":"2023-03-22","meta":{"link":"http://arxiv.org/abs/2303.12756v1","tag":"data-quality"}}
{"title":"Autofluorescence Bronchoscopy Video Analysis for Lesion Frame Detection","abstract":"Because of the significance of bronchial lesions as indicators of early lung cancer and squamous cell carcinoma, a critical need exists for early detection of bronchial lesions. Autofluorescence bronchoscopy (AFB) is a primary modality used for bronchial lesion detection, as it shows high sensitivity to suspicious lesions. The physician, however, must interactively browse a long video stream to locate lesions, making the search exceedingly tedious and error prone. Unfortunately, limited research has explored the use of automated AFB video analysis for efficient lesion detection. We propose a robust automatic AFB analysis approach that distinguishes informative and uninformative AFB video frames in a video. In addition, for the informative frames, we determine the frames containing potential lesions and delineate candidate lesion regions. Our approach draws upon a combination of computer-based image analysis, machine learning, and deep learning. Thus, the analysis of an AFB video stream becomes more tractable. Tests with patient AFB video indicate that $\\ge$97\\% of frames were correctly labeled as informative or uninformative. In addition, $\\ge$97\\% of lesion frames were correctly identified, with false positive and false negative rates $\\le$3\\%.","created":"2023-03-21","meta":{"link":"http://arxiv.org/abs/2303.12198v1","tag":"data-quality"}}
{"title":"Boosting Verified Training for Robust Image Classifications via Abstraction","abstract":"This paper proposes a novel, abstraction-based, certified training method for robust image classifiers. Via abstraction, all perturbed images are mapped into intervals before feeding into neural networks for training. By training on intervals, all the perturbed images that are mapped to the same interval are classified as the same label, rendering the variance of training sets to be small and the loss landscape of the models to be smooth. Consequently, our approach significantly improves the robustness of trained models. For the abstraction, our training method also enables a sound and complete black-box verification approach, which is orthogonal and scalable to arbitrary types of neural networks regardless of their sizes and architectures. We evaluate our method on a wide range of benchmarks in different scales. The experimental results show that our method outperforms state of the art by (i) reducing the verified errors of trained models up to 95.64%; (ii) totally achieving up to 602.50x speedup; and (iii) scaling up to larger models with up to 138 million trainable parameters. The demo is available at https://github.com/zhangzhaodi233/ABSCERT.git.","created":"2023-03-21","meta":{"link":"http://arxiv.org/abs/2303.11552v1","tag":"data-quality"}}
{"title":"Learning Optical Flow from Event Camera with Rendered Dataset","abstract":"We study the problem of estimating optical flow from event cameras. One important issue is how to build a high-quality event-flow dataset with accurate event values and flow labels. Previous datasets are created by either capturing real scenes by event cameras or synthesizing from images with pasted foreground objects. The former case can produce real event values but with calculated flow labels, which are sparse and inaccurate. The later case can generate dense flow labels but the interpolated events are prone to errors. In this work, we propose to render a physically correct event-flow dataset using computer graphics models. In particular, we first create indoor and outdoor 3D scenes by Blender with rich scene content variations. Second, diverse camera motions are included for the virtual capturing, producing images and accurate flow labels. Third, we render high-framerate videos between images for accurate events. The rendered dataset can adjust the density of events, based on which we further introduce an adaptive density module (ADM). Experiments show that our proposed dataset can facilitate event-flow learning, whereas previous approaches when trained on our dataset can improve their performances constantly by a relatively large margin. In addition, event-flow pipelines when equipped with our ADM can further improve performances.","created":"2023-03-20","meta":{"link":"http://arxiv.org/abs/2303.11011v1","tag":"data-quality"}}
{"title":"Deep Learning-Based Detection of Motion-Affected k-Space Lines for T2*-Weighted MRI","abstract":"T2*-weighted gradient echo MR imaging is strongly impacted by subject head motion due to motion-related changes in B0 inhomogeneities. Within the oxygenation-sensitive mqBOLD protocol, even mild motion during the acquisition of the T2*-weighted data propagates into errors in derived quantitative parameter maps. In order to correct these images without the need of repeated measurements, we propose to learn a classification of motion-affected k-space lines. To test this, we perform realistic motion simulations including motion-induced field inhomogeneity changes for supervised training. To detect the presence of motion in each phase encoding line, we train a convolutional neural network, leveraging the multi-echo information of the T2*-weighted images. The proposed network accurately detects motion-affected k-space lines for simulated displacements of $\\geq$ 0.5mm (accuracy on test set: 92.5%). Finally, we show example reconstructions where we include these classification labels as weights in the data consistency term of an iterative reconstruction procedure, opening up exciting opportunities of k-space line detection in combination with more powerful reconstruction methods.","created":"2023-03-20","meta":{"link":"http://arxiv.org/abs/2303.10987v1","tag":"data-quality"}}
{"title":"ERSAM: Neural Architecture Search For Energy-Efficient and Real-Time Social Ambiance Measurement","abstract":"Social ambiance describes the context in which social interactions happen, and can be measured using speech audio by counting the number of concurrent speakers. This measurement has enabled various mental health tracking and human-centric IoT applications. While on-device Socal Ambiance Measure (SAM) is highly desirable to ensure user privacy and thus facilitate wide adoption of the aforementioned applications, the required computational complexity of state-of-the-art deep neural networks (DNNs) powered SAM solutions stands at odds with the often constrained resources on mobile devices. Furthermore, only limited labeled data is available or practical when it comes to SAM under clinical settings due to various privacy constraints and the required human effort, further challenging the achievable accuracy of on-device SAM solutions. To this end, we propose a dedicated neural architecture search framework for Energy-efficient and Real-time SAM (ERSAM). Specifically, our ERSAM framework can automatically search for DNNs that push forward the achievable accuracy vs. hardware efficiency frontier of mobile SAM solutions. For example, ERSAM-delivered DNNs only consume 40 mW x 12 h energy and 0.05 seconds processing latency for a 5 seconds audio segment on a Pixel 3 phone, while only achieving an error rate of 14.3% on a social ambiance dataset generated by LibriSpeech. We can expect that our ERSAM framework can pave the way for ubiquitous on-device SAM solutions which are in growing demand.","created":"2023-03-19","meta":{"link":"http://arxiv.org/abs/2303.10727v2","tag":"data-quality"}}
{"title":"Wheat Head Counting by Estimating a Density Map with Convolutional Neural Networks","abstract":"Wheat is one of the most significant crop species with an annual worldwide grain production of 700 million tonnes. Assessing the production of wheat spikes can help us measure the grain production. Thus, detecting and characterizing spikes from images of wheat fields is an essential component in a wheat breeding process. In this study, we propose three wheat head counting networks (WHCNet\\_1, WHCNet\\_2 and WHCNet\\_3) to accurately estimate the wheat head count from an individual image and construct high quality density map, which illustrates the distribution of wheat heads in the image. The WHCNets are composed of two major components: a convolutional neural network (CNN) as the front-end for wheat head image feature extraction and a CNN with skip connections for the back-end to generate high-quality density maps. The dataset used in this study is the Global Wheat Head Detection (GWHD) dataset, which is a large, diverse, and well-labelled dataset of wheat images and built by a joint international collaborative effort. We compare our methods with CSRNet, a deep learning method which developed for highly congested scenes understanding and performing accurate count estimation as well as presenting high quality density maps. By taking the advantage of the skip connections between CNN layers, WHCNets integrate features from low CNN layers to high CNN layers, thus, the output density maps have both high spatial resolution and detailed representations of the input images. The experiments showed that our methods outperformed CSRNet in terms of the evaluation metrics, mean absolute error (MAE) and the root mean squared error (RMSE) with smaller model sizes. The code has been deposited on GitHub (\\url{https://github.com/hyguozz}).","created":"2023-03-19","meta":{"link":"http://arxiv.org/abs/2303.10542v1","tag":"data-quality"}}
{"title":"Confidence Attention and Generalization Enhanced Distillation for Continuous Video Domain Adaptation","abstract":"Continuous Video Domain Adaptation (CVDA) is a scenario where a source model is required to adapt to a series of individually available changing target domains continuously without source data or target supervision. It has wide applications, such as robotic vision and autonomous driving. The main underlying challenge of CVDA is to learn helpful information only from the unsupervised target data while avoiding forgetting previously learned knowledge catastrophically, which is out of the capability of previous Video-based Unsupervised Domain Adaptation methods. Therefore, we propose a Confidence-Attentive network with geneRalization enhanced self-knowledge disTillation (CART) to address the challenge in CVDA. Firstly, to learn from unsupervised domains, we propose to learn from pseudo labels. However, in continuous adaptation, prediction errors can accumulate rapidly in pseudo labels, and CART effectively tackles this problem with two key modules. Specifically, The first module generates refined pseudo labels using model predictions and deploys a novel attentive learning strategy. The second module compares the outputs of augmented data from the current model to the outputs of weakly augmented data from the source model, forming a novel consistency regularization on the model to alleviate the accumulation of prediction errors. Extensive experiments suggest that the CVDA performance of CART outperforms existing methods by a considerable margin.","created":"2023-03-18","meta":{"link":"http://arxiv.org/abs/2303.10452v1","tag":"data-quality"}}
{"title":"LossMix: Simplify and Generalize Mixup for Object Detection and Beyond","abstract":"The success of data mixing augmentations in image classification tasks has been well-received. However, these techniques cannot be readily applied to object detection due to challenges such as spatial misalignment, foreground/background distinction, and plurality of instances. To tackle these issues, we first introduce a novel conceptual framework called Supervision Interpolation, which offers a fresh perspective on interpolation-based augmentations by relaxing and generalizing Mixup. Building on this framework, we propose LossMix, a simple yet versatile and effective regularization that enhances the performance and robustness of object detectors and more. Our key insight is that we can effectively regularize the training on mixed data by interpolating their loss errors instead of ground truth labels. Empirical results on the PASCAL VOC and MS COCO datasets demonstrate that LossMix consistently outperforms currently popular mixing strategies. Furthermore, we design a two-stage domain mixing method that leverages LossMix to surpass Adaptive Teacher (CVPR 2022) and set a new state of the art for unsupervised domain adaptation.","created":"2023-03-18","meta":{"link":"http://arxiv.org/abs/2303.10343v1","tag":"data-quality"}}
{"title":"What Do Users Ask in Open-Source AI Repositories? An Empirical Study of GitHub Issues","abstract":"Artificial Intelligence systems, which benefit from the availability of large-scale datasets and increasing computational power, have become effective solutions to various critical tasks, such as natural language understanding, speech recognition, and image processing. The advancement of these AI systems is inseparable from open-source software (OSS). This paper presents an empirical study that investigates the issues in the repositories of open-source AI repositories to assist developers in understanding problems during the process of employing AI systems. We collect 576 repositories from the PapersWithCode platform. Among these repositories, we find 24,953 issues by utilizing GitHub REST APIs. Our empirical study includes three phases. First, we manually analyze these issues to categorize the problems that developers are likely to encounter in open-source AI repositories. Specifically, we provide a taxonomy of 13 categories related to AI systems. The two most common issues are runtime errors (23.18%) and unclear instructions (19.53%). Second, we see that 67.5% of issues are closed. We also find that half of these issues resolve within four days. Moreover, issue management features, e.g., label and assign, are not widely adopted in open-source AI repositories. In particular, only 7.81% and 5.9% of repositories label issues and assign these issues to assignees, respectively. Finally, we empirically show that employing GitHub issue management features and writing issues with detailed descriptions facilitate the resolution of issues. Based on our findings, we make recommendations for developers to help better manage the issues of open-source AI repositories and improve their quality.","created":"2023-03-17","meta":{"link":"http://arxiv.org/abs/2303.09795v1","tag":"data-quality"}}
{"title":"Tackling Clutter in Radar Data -- Label Generation and Detection Using PointNet++","abstract":"Radar sensors employed for environment perception, e.g. in autonomous vehicles, output a lot of unwanted clutter. These points, for which no corresponding real objects exist, are a major source of errors in following processing steps like object detection or tracking. We therefore present two novel neural network setups for identifying clutter. The input data, network architectures and training configuration are adjusted specifically for this task. Special attention is paid to the downsampling of point clouds composed of multiple sensor scans. In an extensive evaluation, the new setups display substantially better performance than existing approaches. Because there is no suitable public data set in which clutter is annotated, we design a method to automatically generate the respective labels. By applying it to existing data with object annotations and releasing its code, we effectively create the first freely available radar clutter data set representing real-world driving scenarios. Code and instructions are accessible at www.github.com/kopp-j/clutter-ds.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09530v1","tag":"data-quality"}}
{"title":"The Scope of In-Context Learning for the Extraction of Medical Temporal Constraints","abstract":"Medications often impose temporal constraints on everyday patient activity. Violations of such medical temporal constraints (MTCs) lead to a lack of treatment adherence, in addition to poor health outcomes and increased healthcare expenses. These MTCs are found in drug usage guidelines (DUGs) in both patient education materials and clinical texts. Computationally representing MTCs in DUGs will advance patient-centric healthcare applications by helping to define safe patient activity patterns. We define a novel taxonomy of MTCs found in DUGs and develop a novel context-free grammar (CFG) based model to computationally represent MTCs from unstructured DUGs. Additionally, we release three new datasets with a combined total of N = 836 DUGs labeled with normalized MTCs. We develop an in-context learning (ICL) solution for automatically extracting and normalizing MTCs found in DUGs, achieving an average F1 score of 0.62 across all datasets. Finally, we rigorously investigate ICL model performance against a baseline model, across datasets and MTC types, and through in-depth error analysis.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09366v1","tag":"data-quality"}}
{"title":"Unsupervised domain adaptation by learning using privileged information","abstract":"Successful unsupervised domain adaptation (UDA) is guaranteed only under strong assumptions such as covariate shift and overlap between input domains. The latter is often violated in high-dimensional applications such as image classification which, despite this challenge, continues to serve as inspiration and benchmark for algorithm development. In this work, we show that access to side information about examples from the source and target domains can help relax these assumptions and increase sample efficiency in learning, at the cost of collecting a richer variable set. We call this domain adaptation by learning using privileged information (DALUPI). Tailored for this task, we propose a simple two-stage learning algorithm inspired by our analysis and a practical end-to-end algorithm for multi-label image classification. In a suite of experiments, including an application to medical image analysis, we demonstrate that incorporating privileged information in learning can reduce errors in domain transfer compared to classical learning.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09350v2","tag":"data-quality"}}
{"title":"GLEN: General-Purpose Event Detection for Thousands of Types","abstract":"The development of event extraction systems has been hindered by the absence of wide-coverage, large-scale datasets. To make event extraction systems more accessible, we build a general-purpose event detection dataset GLEN, which covers 3,465 different event types, making it over 20x larger in ontology than any current dataset. GLEN is created by utilizing the DWD Overlay, which provides a mapping between Wikidata Qnodes and PropBank rolesets. This enables us to use the abundant existing annotation for PropBank as distant supervision. In addition, we also propose a new multi-stage event detection model specifically designed to handle the large ontology size and partial labels in GLEN. We show that our model exhibits superior performance (~10% F1 gain) compared to both conventional classification baselines and newer definition-based models. Finally, we perform error analysis and show that label noise is still the largest challenge for improving performance.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09093v2","tag":"data-quality"}}
{"title":"Rethinking Optical Flow from Geometric Matching Consistent Perspective","abstract":"Optical flow estimation is a challenging problem remaining unsolved. Recent deep learning based optical flow models have achieved considerable success. However, these models often train networks from the scratch on standard optical flow data, which restricts their ability to robustly and geometrically match image features. In this paper, we propose a rethinking to previous optical flow estimation. We particularly leverage Geometric Image Matching (GIM) as a pre-training task for the optical flow estimation (MatchFlow) with better feature representations, as GIM shares some common challenges as optical flow estimation, and with massive labeled real-world data. Thus, matching static scenes helps to learn more fundamental feature correlations of objects and scenes with consistent displacements. Specifically, the proposed MatchFlow model employs a QuadTree attention-based network pre-trained on MegaDepth to extract coarse features for further flow regression. Extensive experiments show that our model has great cross-dataset generalization. Our method achieves 11.5% and 10.1% error reduction from GMA on Sintel clean pass and KITTI test set. At the time of anonymous submission, our MatchFlow(G) enjoys state-of-the-art performance on Sintel clean and final pass compared to published approaches with comparable computation and memory footprint. Codes and models will be released in https://github.com/DQiaole/MatchFlow.","created":"2023-03-15","meta":{"link":"http://arxiv.org/abs/2303.08384v1","tag":"data-quality"}}
{"title":"Exploring Weakly Supervised Semantic Segmentation Ensembles for Medical Imaging Systems","abstract":"Reliable classification and detection of certain medical conditions, in images, with state-of-the-art semantic segmentation networks, require vast amounts of pixel-wise annotation. However, the public availability of such datasets is minimal. Therefore, semantic segmentation with image-level labels presents a promising alternative to this problem. Nevertheless, very few works have focused on evaluating this technique and its applicability to the medical sector. Due to their complexity and the small number of training examples in medical datasets, classifier-based weakly supervised networks like class activation maps (CAMs) struggle to extract useful information from them. However, most state-of-the-art approaches rely on them to achieve their improvements. Therefore, we propose a framework that can still utilize the low-quality CAM predictions of complicated datasets to improve the accuracy of our results. Our framework achieves that by first utilizing lower threshold CAMs to cover the target object with high certainty; second, by combining multiple low-threshold CAMs that even out their errors while highlighting the target object. We performed exhaustive experiments on the popular multi-modal BRATS and prostate DECATHLON segmentation challenge datasets. Using the proposed framework, we have demonstrated an improved dice score of up to 8% on BRATS and 6% on DECATHLON datasets compared to the previous state-of-the-art.","created":"2023-03-14","meta":{"link":"http://arxiv.org/abs/2303.07896v2","tag":"data-quality"}}
{"title":"On the Implicit Geometry of Cross-Entropy Parameterizations for Label-Imbalanced Data","abstract":"Various logit-adjusted parameterizations of the cross-entropy (CE) loss have been proposed as alternatives to weighted CE for training large models on label-imbalanced data far beyond the zero train error regime. The driving force behind those designs has been the theory of implicit bias, which for linear(ized) models, explains why they successfully induce bias on the optimization path towards solutions that favor minorities. Aiming to extend this theory to non-linear models, we investigate the implicit geometry of classifiers and embeddings that are learned by different CE parameterizations. Our main result characterizes the global minimizers of a non-convex cost-sensitive SVM classifier for the unconstrained features model, which serves as an abstraction of deep nets. We derive closed-form formulas for the angles and norms of classifiers and embeddings as a function of the number of classes, the imbalance and the minority ratios, and the loss hyperparameters. Using these, we show that logit-adjusted parameterizations can be appropriately tuned to learn symmetric geometries irrespective of the imbalance ratio. We complement our analysis with experiments and an empirical study of convergence accuracy in deep-nets.","created":"2023-03-14","meta":{"link":"http://arxiv.org/abs/2303.07608v1","tag":"data-quality"}}
{"title":"Identifying Label Errors in Object Detection Datasets by Loss Inspection","abstract":"Labeling datasets for supervised object detection is a dull and time-consuming task. Errors can be easily introduced during annotation and overlooked during review, yielding inaccurate benchmarks and performance degradation of deep neural networks trained on noisy labels. In this work, we for the first time introduce a benchmark for label error detection methods on object detection datasets as well as a label error detection method and a number of baselines. We simulate four different types of randomly introduced label errors on train and test sets of well-labeled object detection datasets. For our label error detection method we assume a two-stage object detector to be given and consider the sum of both stages' classification and regression losses. The losses are computed with respect to the predictions and the noisy labels including simulated label errors, aiming at detecting the latter. We compare our method to three baselines: a naive one without deep learning, the object detector's score and the entropy of the classification softmax distribution. We outperform all baselines and demonstrate that among the considered methods, ours is the only one that detects label errors of all four types efficiently. Furthermore, we detect real label errors a) on commonly used test datasets in object detection and b) on a proprietary dataset. In both cases we achieve low false positives rates, i.e., when considering 200 proposals from our method, we detect label errors with a precision for a) of up to 71.5% and for b) with 97%.","created":"2023-03-13","meta":{"link":"http://arxiv.org/abs/2303.06999v1","tag":"data-quality"}}
{"title":"Context-Aware Selective Label Smoothing for Calibrating Sequence Recognition Model","abstract":"Despite the success of deep neural network (DNN) on sequential data (i.e., scene text and speech) recognition, it suffers from the over-confidence problem mainly due to overfitting in training with the cross-entropy loss, which may make the decision-making less reliable. Confidence calibration has been recently proposed as one effective solution to this problem. Nevertheless, the majority of existing confidence calibration methods aims at non-sequential data, which is limited if directly applied to sequential data since the intrinsic contextual dependency in sequences or the class-specific statistical prior is seldom exploited. To the end, we propose a Context-Aware Selective Label Smoothing (CASLS) method for calibrating sequential data. The proposed CASLS fully leverages the contextual dependency in sequences to construct confusion matrices of contextual prediction statistics over different classes. Class-specific error rates are then used to adjust the weights of smoothing strength in order to achieve adaptive calibration. Experimental results on sequence recognition tasks, including scene text recognition and speech recognition, demonstrate that our method can achieve the state-of-the-art performance.","created":"2023-03-13","meta":{"link":"http://arxiv.org/abs/2303.06946v1","tag":"data-quality"}}
{"title":"Informative regularization for a multi-layer perceptron RR Lyrae classifier under data shift","abstract":"In recent decades, machine learning has provided valuable models and algorithms for processing and extracting knowledge from time-series surveys. Different classifiers have been proposed and performed to an excellent standard. Nevertheless, few papers have tackled the data shift problem in labeled training sets, which occurs when there is a mismatch between the data distribution in the training set and the testing set. This drawback can damage the prediction performance in unseen data. Consequently, we propose a scalable and easily adaptable approach based on an informative regularization and an ad-hoc training procedure to mitigate the shift problem during the training of a multi-layer perceptron for RR Lyrae classification. We collect ranges for characteristic features to construct a symbolic representation of prior knowledge, which was used to model the informative regularizer component. Simultaneously, we design a two-step back-propagation algorithm to integrate this knowledge into the neural network, whereby one step is applied in each epoch to minimize classification error, while another is applied to ensure regularization. Our algorithm defines a subset of parameters (a mask) for each loss function. This approach handles the forgetting effect, which stems from a trade-off between these loss functions (learning from data versus learning expert knowledge) during training. Experiments were conducted using recently proposed shifted benchmark sets for RR Lyrae stars, outperforming baseline models by up to 3\\% through a more reliable classifier. Our method provides a new path to incorporate knowledge from characteristic features into artificial neural networks to manage the underlying data shift problem.","created":"2023-03-12","meta":{"link":"http://arxiv.org/abs/2303.06544v1","tag":"data-quality"}}
{"title":"Robust Knowledge Distillation from RNN-T Models With Noisy Training Labels Using Full-Sum Loss","abstract":"This work studies knowledge distillation (KD) and addresses its constraints for recurrent neural network transducer (RNN-T) models. In hard distillation, a teacher model transcribes large amounts of unlabelled speech to train a student model. Soft distillation is another popular KD method that distills the output logits of the teacher model. Due to the nature of RNN-T alignments, applying soft distillation between RNN-T architectures having different posterior distributions is challenging. In addition, bad teachers having high word-error-rate (WER) reduce the efficacy of KD. We investigate how to effectively distill knowledge from variable quality ASR teachers, which has not been studied before to the best of our knowledge. We show that a sequence-level KD, full-sum distillation, outperforms other distillation methods for RNN-T models, especially for bad teachers. We also propose a variant of full-sum distillation that distills the sequence discriminative knowledge of the teacher leading to further improvement in WER. We conduct experiments on public datasets namely SpeechStew and LibriSpeech, and on in-house production data.","created":"2023-03-10","meta":{"link":"http://arxiv.org/abs/2303.05958v1","tag":"data-quality"}}
{"title":"Fusarium head blight detection, spikelet estimation, and severity assessment in wheat using 3D convolutional neural networks","abstract":"Fusarium head blight (FHB) is one of the most significant diseases affecting wheat and other small grain cereals worldwide. The development of resistant varieties requires the laborious task of field and greenhouse phenotyping. The applications considered in this work are the automated detection of FHB disease symptoms expressed on a wheat plant, the automated estimation of the total number of spikelets and the total number of infected spikelets on a wheat head, and the automated assessment of the FHB severity in infected wheat. The data used to generate the results are 3-dimensional (3D) multispectral point clouds (PC), which are 3D collections of points - each associated with a red, green, blue (RGB), and near-infrared (NIR) measurement. Over 300 wheat plant images were collected using a multispectral 3D scanner, and the labelled UW-MRDC 3D wheat dataset was created. The data was used to develop novel and efficient 3D convolutional neural network (CNN) models for FHB detection, which achieved 100% accuracy. The influence of the multispectral information on performance was evaluated, and our results showed the dominance of the RGB channels over both the NIR and the NIR plus RGB channels combined. Furthermore, novel and efficient 3D CNNs were created to estimate the total number of spikelets and the total number of infected spikelets on a wheat head, and our best models achieved mean absolute errors (MAE) of 1.13 and 1.56, respectively. Moreover, 3D CNN models for FHB severity estimation were created, and our best model achieved 8.6 MAE. A linear regression analysis between the visual FHB severity assessment and the FHB severity predicted by our 3D CNN was performed, and the results showed a significant correlation between the two variables with a 0.0001 P-value and 0.94 R-squared.","created":"2023-03-10","meta":{"link":"http://arxiv.org/abs/2303.05634v1","tag":"data-quality"}}
{"title":"Efficient Testable Learning of Halfspaces with Adversarial Label Noise","abstract":"We give the first polynomial-time algorithm for the testable learning of halfspaces in the presence of adversarial label noise under the Gaussian distribution. In the recently introduced testable learning model, one is required to produce a tester-learner such that if the data passes the tester, then one can trust the output of the robust learner on the data. Our tester-learner runs in time $\\poly(d/\\eps)$ and outputs a halfspace with misclassification error $O(\\opt)+\\eps$, where $\\opt$ is the 0-1 error of the best fitting halfspace. At a technical level, our algorithm employs an iterative soft localization technique enhanced with appropriate testers to ensure that the data distribution is sufficiently similar to a Gaussian.","created":"2023-03-09","meta":{"link":"http://arxiv.org/abs/2303.05485v1","tag":"data-quality"}}
{"title":"EVOLIN Benchmark: Evaluation of Line Detection and Association","abstract":"Lines are interesting geometrical features commonly seen in indoor and urban environments. There is missing a complete benchmark where one can evaluate lines from a sequential stream of images in all its stages: Line detection, Line Association and Pose error. To do so, we present a complete and exhaustive benchmark for visual lines in a SLAM front-end, both for RGB and RGBD, by providing a plethora of complementary metrics. We have also labelled data from well-known SLAM datasets in order to have all in one poses and accurately annotated lines. In particular, we have evaluated 17 line detection algorithms, 5 line associations methods and the resultant pose error for aligning a pair of frames with several combinations of detector-association. We have packaged all methods and evaluations metrics and made them publicly available on web-page https://prime-slam.github.io/evolin/.","created":"2023-03-09","meta":{"link":"http://arxiv.org/abs/2303.05162v1","tag":"data-quality"}}
{"title":"Inversion dynamics of class manifolds in deep learning reveals tradeoffs underlying generalisation","abstract":"To achieve near-zero training error in a classification problem, the layers of a deep network have to disentangle the manifolds of data points with different labels, to facilitate the discrimination. However, excessive class separation can bring to overfitting since good generalisation requires learning invariant features, which involve some level of entanglement. We report on numerical experiments showing how the optimisation dynamics finds representations that balance these opposing tendencies with a non-monotonic trend. After a fast segregation phase, a slower rearrangement (conserved across data sets and architectures) increases the class entanglement. The training error at the inversion is remarkably stable under subsampling, and across network initialisations and optimisers, which characterises it as a property solely of the data structure and (very weakly) of the architecture. The inversion is the manifestation of tradeoffs elicited by well-defined and maximally stable elements of the training set, coined \"stragglers\", particularly influential for generalisation.","created":"2023-03-09","meta":{"link":"http://arxiv.org/abs/2303.05161v1","tag":"data-quality"}}
{"title":"Pretty good measurement for bosonic Gaussian ensembles","abstract":"The pretty good measurement is a fundamental analytical tool in quantum information theory, giving a method for inferring the classical label that identifies a quantum state chosen probabilistically from an ensemble. Identifying and constructing the pretty good measurement for the class of bosonic Gaussian states is of immediate practical relevance in quantum information processing tasks. Holevo recently showed that the pretty good measurement of a Gaussian ensemble in a multimode bosonic system is a Gaussian measurement that attains the accessible information of the ensemble (IEEE Trans. Inf. Theory, 66(9):5634-564, 2020). In this paper, we provide an alternate proof of Gaussianity of the pretty good measurement for a Gaussian ensemble of multimode bosonic states, with a focus on providing an explicit and efficiently computable Gaussian description of the measurement. These findings imply that the pretty good measurement is no longer merely an analytical tool for this case, but that it can also be implemented experimentally in quantum optics laboratories. We also compute an explicit form of the mean square error of the pretty good measurement, which is relevant when using it for parameter estimation.","created":"2023-03-08","meta":{"link":"http://arxiv.org/abs/2303.04949v1","tag":"data-quality"}}
{"title":"The Bystander Affect Detection (BAD) Dataset for Failure Detection in HRI","abstract":"For a robot to repair its own error, it must first know it has made a mistake. One way that people detect errors is from the implicit reactions from bystanders -- their confusion, smirks, or giggles clue us in that something unexpected occurred. To enable robots to detect and act on bystander responses to task failures, we developed a novel method to elicit bystander responses to human and robot errors. Using 46 different stimulus videos featuring a variety of human and machine task failures, we collected a total of 2452 webcam videos of human reactions from 54 participants. To test the viability of the collected data, we used the bystander reaction dataset as input to a deep-learning model, BADNet, to predict failure occurrence. We tested different data labeling methods and learned how they affect model performance, achieving precisions above 90%. We discuss strategies to model bystander reactions and predict failure and how this approach can be used in real-world robotic deployments to detect errors and improve robot performance. As part of this work, we also contribute with the \"Bystander Affect Detection\" (BAD) dataset of bystander reactions, supporting the development of better prediction models.","created":"2023-03-08","meta":{"link":"http://arxiv.org/abs/2303.04835v1","tag":"data-quality"}}
{"title":"A Deep-Learning-Based Neural Decoding Framework for Emotional Brain-Computer Interfaces","abstract":"Reading emotions precisely from segments of neural activity is crucial for the development of emotional brain-computer interfaces. Among all neural decoding algorithms, deep learning (DL) holds the potential to become the most promising one, yet progress has been limited in recent years. One possible reason is that the efficacy of DL strongly relies on training samples, yet the neural data used for training are often from non-human primates and mixed with plenty of noise, which in turn mislead the training of DL models. Given it is difficult to accurately determine animals' emotions from humans' perspective, we assume the dominant noise in neural data representing different emotions is the labeling error. Here, we report the development and application of a neural decoding framework called Emo-Net that consists of a confidence learning (CL) component and a DL component. The framework is fully data-driven and is capable of decoding emotions from multiple datasets obtained from behaving monkeys. In addition to improving the decoding ability, Emo-Net significantly improves the performance of the base DL models, making emotion recognition in animal models possible. In summary, this framework may inspire novel understandings of the neural basis of emotion and drive the realization of close-loop emotional brain-computer interfaces.","created":"2023-03-08","meta":{"link":"http://arxiv.org/abs/2303.04391v1","tag":"data-quality"}}
{"title":"TOLD: A Novel Two-Stage Overlap-Aware Framework for Speaker Diarization","abstract":"Recently, end-to-end neural diarization (EEND) is introduced and achieves promising results in speaker-overlapped scenarios. In EEND, speaker diarization is formulated as a multi-label prediction problem, where speaker activities are estimated independently and their dependency are not well considered. To overcome these disadvantages, we employ the power set encoding to reformulate speaker diarization as a single-label classification problem and propose the overlap-aware EEND (EEND-OLA) model, in which speaker overlaps and dependency can be modeled explicitly. Inspired by the success of two-stage hybrid systems, we further propose a novel Two-stage OverLap-aware Diarization framework (TOLD) by involving a speaker overlap-aware post-processing (SOAP) model to iteratively refine the diarization results of EEND-OLA. Experimental results show that, compared with the original EEND, the proposed EEND-OLA achieves a 14.39% relative improvement in terms of diarization error rates (DER), and utilizing SOAP provides another 19.33% relative improvement. As a result, our method TOLD achieves a DER of 10.14% on the CALLHOME dataset, which is a new state-of-the-art result on this benchmark to the best of our knowledge.","created":"2023-03-08","meta":{"link":"http://arxiv.org/abs/2303.05397v1","tag":"data-quality"}}
{"title":"SemEval-2023 Task 10: Explainable Detection of Online Sexism","abstract":"Online sexism is a widespread and harmful phenomenon. Automated tools can assist the detection of sexism at scale. Binary detection, however, disregards the diversity of sexist content, and fails to provide clear explanations for why something is sexist. To address this issue, we introduce SemEval Task 10 on the Explainable Detection of Online Sexism (EDOS). We make three main contributions: i) a novel hierarchical taxonomy of sexist content, which includes granular vectors of sexism to aid explainability; ii) a new dataset of 20,000 social media comments with fine-grained labels, along with larger unlabelled datasets for model adaptation; and iii) baseline models as well as an analysis of the methods, results and errors for participant submissions to our task.","created":"2023-03-07","meta":{"link":"http://arxiv.org/abs/2303.04222v1","tag":"data-quality"}}
{"title":"PRIMO: Private Regression in Multiple Outcomes","abstract":"We introduce a new differentially private regression setting we call Private Regression in Multiple Outcomes (PRIMO), inspired the common situation where a data analyst wants to perform a set of $l$ regressions while preserving privacy, where the covariates $X$ are shared across all $l$ regressions, and each regression $i \\in [l]$ has a different vector of outcomes $y_i$. While naively applying private linear regression techniques $l$ times leads to a $\\sqrt{l}$ multiplicative increase in error over the standard linear regression setting, in Subsection $4.1$ we modify techniques based on sufficient statistics perturbation (SSP) to yield greatly improved dependence on $l$. In Subsection $4.2$ we prove an equivalence to the problem of privately releasing the answers to a special class of low-sensitivity queries we call inner product queries. Via this equivalence, we adapt the geometric projection-based methods from prior work on private query release to the PRIMO setting. Under the assumption the labels $Y$ are public, the projection gives improved results over the Gaussian mechanism when $n < l\\sqrt{d}$, with no asymptotic dependence on $l$ in the error. In Subsection $4.3$ we study the complexity of our projection algorithm, and analyze a faster sub-sampling based variant in Subsection $4.4$. Finally in Section $5$ we apply our algorithms to the task of private genomic risk prediction for multiple phenotypes using data from the 1000 Genomes project. We find that for moderately large values of $l$ our techniques drastically improve the accuracy relative to both the naive baseline that uses existing private regression methods and our modified SSP algorithm that doesn't use the projection.","created":"2023-03-07","meta":{"link":"http://arxiv.org/abs/2303.04195v1","tag":"data-quality"}}
{"title":"Deep Age-Invariant Fingerprint Segmentation System","abstract":"Fingerprint-based identification systems achieve higher accuracy when a slap containing multiple fingerprints of a subject is used instead of a single fingerprint. However, segmenting or auto-localizing all fingerprints in a slap image is a challenging task due to the different orientations of fingerprints, noisy backgrounds, and the smaller size of fingertip components. The presence of slap images in a real-world dataset where one or more fingerprints are rotated makes it challenging for a biometric recognition system to localize and label the fingerprints automatically. Improper fingerprint localization and finger labeling errors lead to poor matching performance. In this paper, we introduce a method to generate arbitrary angled bounding boxes using a deep learning-based algorithm that precisely localizes and labels fingerprints from both axis-aligned and over-rotated slap images. We built a fingerprint segmentation model named CRFSEG (Clarkson Rotated Fingerprint segmentation Model) by updating the previously proposed CFSEG model which was based on traditional Faster R-CNN architecture [21]. CRFSEG improves upon the Faster R-CNN algorithm with arbitrarily angled bounding boxes that allow the CRFSEG to perform better in challenging slap images. After training the CRFSEG algorithm on a new dataset containing slap images collected from both adult and children subjects, our results suggest that the CRFSEG model was invariant across different age groups and can handle over-rotated slap images successfully. In the Combined dataset containing both normal and rotated images of adult and children subjects, we achieved a matching accuracy of 97.17%, which outperformed state-of-the-art VeriFinger (94.25%) and NFSEG segmentation systems (80.58%).","created":"2023-03-06","meta":{"link":"http://arxiv.org/abs/2303.03341v1","tag":"data-quality"}}
{"title":"Learning Label Encodings for Deep Regression","abstract":"Deep regression networks are widely used to tackle the problem of predicting a continuous value for a given input. Task-specialized approaches for training regression networks have shown significant improvement over generic approaches, such as direct regression. More recently, a generic approach based on regression by binary classification using binary-encoded labels has shown significant improvement over direct regression. The space of label encodings for regression is large. Lacking heretofore have been automated approaches to find a good label encoding for a given application. This paper introduces Regularized Label Encoding Learning (RLEL) for end-to-end training of an entire network and its label encoding. RLEL provides a generic approach for tackling regression. Underlying RLEL is our observation that the search space of label encodings can be constrained and efficiently explored by using a continuous search space of real-valued label encodings combined with a regularization function designed to encourage encodings with certain properties. These properties balance the probability of classification error in individual bits against error correction capability. Label encodings found by RLEL result in lower or comparable errors to manually designed label encodings. Applying RLEL results in 10.9% and 12.4% improvement in Mean Absolute Error (MAE) over direct regression and multiclass classification, respectively. Our evaluation demonstrates that RLEL can be combined with off-the-shelf feature extractors and is suitable across different architectures, datasets, and tasks. Code is available at https://github.com/ubc-aamodt-group/RLEL_regression.","created":"2023-03-04","meta":{"link":"http://arxiv.org/abs/2303.02273v1","tag":"data-quality"}}
{"title":"Evaluation of Confidence-based Ensembling in Deep Learning Image Classification","abstract":"Ensembling is a successful technique to improve the performance of machine learning (ML) models.   Conf-Ensemble is an adaptation to Boosting to create ensembles based on model confidence instead of model errors to better classify difficult edge-cases. The key idea is to create successive model experts for samples that were difficult (not necessarily incorrectly classified) by the preceding model. This technique has been shown to provide better results than boosting in binary-classification with a small feature space (~80 features).   In this paper, we evaluate the Conf-Ensemble approach in the much more complex task of image classification with the ImageNet dataset (224x224x3 features with 1000 classes). Image classification is an important benchmark for AI-based perception and thus it helps to assess if this method can be used in safety-critical applications using ML ensembles.   Our experiments indicate that in a complex multi-label classification task, the expected benefit of specialization on complex input samples cannot be achieved with a small sample set, i.e., a good classifier seems to rely on very complex feature analysis that cannot be well trained on just a limited subset of \"difficult samples\".   We propose an improvement to Conf-Ensemble to increase the number of samples fed to successive ensemble members, and a three-member Conf-Ensemble using this improvement was able to surpass a single model in accuracy, although the amount is not significant. Our findings shed light on the limits of the approach and the non-triviality of harnessing big data.","created":"2023-03-03","meta":{"link":"http://arxiv.org/abs/2303.03185v1","tag":"data-quality"}}
{"title":"PLUNDER: Probabilistic Program Synthesis for Learning from Unlabeled and Noisy Demonstrations","abstract":"Learning from demonstration (LfD) is a widely researched paradigm for teaching robots to perform novel tasks. LfD works particularly well with program synthesis since the resulting programmatic policy is data efficient, interpretable, and amenable to formal verification. However, existing synthesis approaches to LfD rely on precise and labeled demonstrations and are incapable of reasoning about the uncertainty inherent in human decision-making. In this paper, we propose PLUNDER, a new LfD approach that integrates a probabilistic program synthesizer in an expectation-maximization (EM) loop to overcome these limitations. PLUNDER only requires unlabeled low-level demonstrations of the intended task (e.g., remote-controlled motion trajectories), which liberates end-users from providing explicit labels and facilitates a more intuitive LfD experience. PLUNDER also generates a probabilistic policy that captures actuation errors and the uncertainties inherent in human decision making. Our experiments compare PLUNDER with state-of the-art LfD techniques and demonstrate its advantages across different robotic tasks.","created":"2023-03-02","meta":{"link":"http://arxiv.org/abs/2303.01440v1","tag":"data-quality"}}
{"title":"Improving Transformer-based End-to-End Speaker Diarization by Assigning Auxiliary Losses to Attention Heads","abstract":"Transformer-based end-to-end neural speaker diarization (EEND) models utilize the multi-head self-attention (SA) mechanism to enable accurate speaker label prediction in overlapped speech regions. In this study, to enhance the training effectiveness of SA-EEND models, we propose the use of auxiliary losses for the SA heads of the transformer layers. Specifically, we assume that the attention weight matrices of an SA layer are redundant if their patterns are similar to those of the identity matrix. We then explicitly constrain such matrices to exhibit specific speaker activity patterns relevant to voice activity detection or overlapped speech detection tasks. Consequently, we expect the proposed auxiliary losses to guide the transformer layers to exhibit more diverse patterns in the attention weights, thereby reducing the assumed redundancies in the SA heads. The effectiveness of the proposed method is demonstrated using the simulated and CALLHOME datasets for two-speaker diarization tasks, reducing the diarization error rate of the conventional SA-EEND model by 32.58% and 17.11%, respectively.","created":"2023-03-02","meta":{"link":"http://arxiv.org/abs/2303.01192v1","tag":"data-quality"}}
{"title":"In all LikelihoodS: How to Reliably Select Pseudo-Labeled Data for Self-Training in Semi-Supervised Learning","abstract":"Self-training is a simple yet effective method within semi-supervised learning. The idea is to iteratively enhance training data by adding pseudo-labeled data. Its generalization performance heavily depends on the selection of these pseudo-labeled data (PLS). In this paper, we aim at rendering PLS more robust towards the involved modeling assumptions. To this end, we propose to select pseudo-labeled data that maximize a multi-objective utility function. The latter is constructed to account for different sources of uncertainty, three of which we discuss in more detail: model selection, accumulation of errors and covariate shift. In the absence of second-order information on such uncertainties, we furthermore consider the generic approach of the generalized Bayesian alpha-cut updating rule for credal sets. As a practical proof of concept, we spotlight the application of three of our robust extensions on simulated and real-world data. Results suggest that in particular robustness w.r.t. model choice can lead to substantial accuracy gains.","created":"2023-03-02","meta":{"link":"http://arxiv.org/abs/2303.01117v1","tag":"data-quality"}}
{"title":"Visual Atoms: Pre-training Vision Transformers with Sinusoidal Waves","abstract":"Formula-driven supervised learning (FDSL) has been shown to be an effective method for pre-training vision transformers, where ExFractalDB-21k was shown to exceed the pre-training effect of ImageNet-21k. These studies also indicate that contours mattered more than textures when pre-training vision transformers. However, the lack of a systematic investigation as to why these contour-oriented synthetic datasets can achieve the same accuracy as real datasets leaves much room for skepticism. In the present work, we develop a novel methodology based on circular harmonics for systematically investigating the design space of contour-oriented synthetic datasets. This allows us to efficiently search the optimal range of FDSL parameters and maximize the variety of synthetic images in the dataset, which we found to be a critical factor. When the resulting new dataset VisualAtom-21k is used for pre-training ViT-Base, the top-1 accuracy reached 83.7% when fine-tuning on ImageNet-1k. This is close to the top-1 accuracy (84.2%) achieved by JFT-300M pre-training, while the number of images is 1/14. Unlike JFT-300M which is a static dataset, the quality of synthetic datasets will continue to improve, and the current work is a testament to this possibility. FDSL is also free of the common issues associated with real images, e.g. privacy/copyright issues, labeling costs/errors, and ethical biases.","created":"2023-03-02","meta":{"link":"http://arxiv.org/abs/2303.01112v1","tag":"data-quality"}}
{"title":"Building High-accuracy Multilingual ASR with Gated Language Experts and Curriculum Training","abstract":"We propose gated language experts to improve multilingual transformer transducer models without any language identification (LID) input from users during inference. We define gating mechanism and LID loss to let transformer encoders learn language-dependent information, construct the multilingual transformer block with gated transformer experts and shared transformer layers for compact models, and apply linear experts on joint network output to better regularize speech acoustic and token label joint information. Furthermore, a curriculum training scheme is proposed to let LID guide the gated language experts for better serving their corresponding languages. Evaluated on the English and Spanish bilingual task, our methods achieve average 12.5% and 7.3% relative word error reductions over the baseline bilingual model and monolingual models, respectively, obtaining similar results to the upper bound model trained and inferred with oracle LID. We further explore our method on trilingual, quadrilingual, and pentalingual models, and observe similar advantages as in the bilingual models, which demonstrates the easy extension to more languages.","created":"2023-03-01","meta":{"link":"http://arxiv.org/abs/2303.00786v1","tag":"data-quality"}}
{"title":"MEGA-DAgger: Imitation Learning with Multiple Imperfect Experts","abstract":"Imitation learning has been widely applied to various autonomous systems thanks to recent development in interactive algorithms that address covariate shift and compounding errors induced by traditional approaches like behavior cloning. However, existing interactive imitation learning methods assume access to one perfect expert. Whereas in reality, it is more likely to have multiple imperfect experts instead. In this paper, we propose MEGA-DAgger, a new DAgger variant that is suitable for interactive learning with multiple imperfect experts. First, unsafe demonstrations are filtered while aggregating the training data, so the imperfect demonstrations have little influence when training the novice policy. Next, experts are evaluated and compared on scenarios-specific metrics to resolve the conflicted labels among experts. Through experiments in autonomous racing scenarios, we demonstrate that policy learned using MEGA-DAgger can outperform both experts and policies learned using the state-of-the-art interactive imitation learning algorithm. The supplementary video can be found at https://youtu.be/pYQiPSHk6dU.","created":"2023-03-01","meta":{"link":"http://arxiv.org/abs/2303.00638v2","tag":"data-quality"}}
{"title":"OliVaR: Improving Olive Variety Recognition using Deep Neural Networks","abstract":"The easy and accurate identification of varieties is fundamental in agriculture, especially in the olive sector, where more than 1200 olive varieties are currently known worldwide. Varietal misidentification leads to many potential problems for all the actors in the sector: farmers and nursery workers may establish the wrong variety, leading to its maladaptation in the field; olive oil and table olive producers may label and sell a non-authentic product; consumers may be misled; and breeders may commit errors during targeted crossings between different varieties. To date, the standard for varietal identification and certification consists of two methods: morphological classification and genetic analysis. The morphological classification consists of the visual pairwise comparison of different organs of the olive tree, where the most important organ is considered to be the endocarp. In contrast, different methods for genetic classification exist (RAPDs, SSR, and SNP). Both classification methods present advantages and disadvantages. Visual morphological classification requires highly specialized personnel and is prone to human error. Genetic identification methods are more accurate but incur a high cost and are difficult to implement. This paper introduces OliVaR, a novel approach to olive varietal identification. OliVaR uses a teacher-student deep learning architecture to learn the defining characteristics of the endocarp of each specific olive variety and perform classification. We construct what is, to the best of our knowledge, the largest olive variety dataset to date, comprising image data for 131 varieties from the Mediterranean basin. We thoroughly test OliVaR on this dataset and show that it correctly predicts olive varieties with over 86% accuracy.","created":"2023-03-01","meta":{"link":"http://arxiv.org/abs/2303.00431v1","tag":"data-quality"}}
{"title":"An Efficient Tester-Learner for Halfspaces","abstract":"We give the first efficient algorithm for learning halfspaces in the testable learning model recently defined by Rubinfeld and Vasilyan (2023). In this model, a learner certifies that the accuracy of its output hypothesis is near optimal whenever the training set passes an associated test, and training sets drawn from some target distribution -- e.g., the Gaussian -- must pass the test. This model is more challenging than distribution-specific agnostic or Massart noise models where the learner is allowed to fail arbitrarily if the distributional assumption does not hold.   We consider the setting where the target distribution is Gaussian (or more generally any strongly log-concave distribution) in $d$ dimensions and the noise model is either Massart or adversarial (agnostic). For Massart noise, our tester-learner runs in polynomial time and outputs a hypothesis with (information-theoretically optimal) error $\\mathsf{opt} + \\epsilon$ for any strongly log-concave target distribution. For adversarial noise, our tester-learner obtains error $O(\\mathsf{opt}) + \\epsilon$ in polynomial time when the target distribution is Gaussian; for strongly log-concave distributions, we obtain $\\tilde{O}(\\mathsf{opt}) + \\epsilon$ in quasipolynomial time.   Prior work on testable learning ignores the labels in the training set and checks that the empirical moments of the covariates are close to the moments of the base distribution. Here we develop new tests of independent interest that make critical use of the labels and combine them with the moment-matching approach of Gollakota et al. (2023). This enables us to simulate a variant of the algorithm of Diakonikolas et al. (2020) for learning noisy halfspaces using nonconvex SGD but in the testable learning setting.","created":"2023-02-28","meta":{"link":"http://arxiv.org/abs/2302.14853v2","tag":"data-quality"}}
{"title":"Towards Surgical Context Inference and Translation to Gestures","abstract":"Manual labeling of gestures in robot-assisted surgery is labor intensive, prone to errors, and requires expertise or training. We propose a method for automated and explainable generation of gesture transcripts that leverages the abundance of data for image segmentation. Surgical context is detected using segmentation masks by examining the distances and intersections between the tools and objects. Next, context labels are translated into gesture transcripts using knowledge-based Finite State Machine (FSM) and data-driven Long Short Term Memory (LSTM) models. We evaluate the performance of each stage of our method by comparing the results with the ground truth segmentation masks, the consensus context labels, and the gesture labels in the JIGSAWS dataset. Our results show that our segmentation models achieve state-of-the-art performance in recognizing needle and thread in Suturing and we can automatically detect important surgical states with high agreement with crowd-sourced labels (e.g., contact between graspers and objects in Suturing). We also find that the FSM models are more robust to poor segmentation and labeling performance than LSTMs. Our proposed method can significantly shorten the gesture labeling process (~2.8 times).","created":"2023-02-28","meta":{"link":"http://arxiv.org/abs/2302.14237v2","tag":"data-quality"}}
{"title":"gmmsslm: Semi-supervised Gaussian mixture modeling with a missing data mechanism in R","abstract":"Semi-supervised learning is extensively applied these days to estimate classifiers from training data in which not all of the labels of the feature vectors are available. With the use of generative models that propose a form for the joint distribution of a feature vector and its ground-truth label, the Bayes' classifier can be estimated via maximum likelihood on partially classified training data. To increase the accuracy of this sample classifier, \\cite{ahfock2020apparent} proposed that a missing-label mechanism be adopted and that the Bayes' classifier be estimated on the basis of the full likelihood formed in the framework that models the probability of a missing label given its observed feature vector in terms of its entropy. In the case of two Gaussian classes with a common covariance matrix, it was shown that the accuracy of the classifier so estimated from the partially classified training data can even have lower error rate than if it were estimated from the sample completely classified. Here, we focus on an algorithm for estimating the Bayes' classifier via the full likelihood in the case of multiple Gaussian classes with arbitrary covariance matrices. Different strategies for initializing the algorithm are discussed and illustrated. A new \\proglang{R} package with these tools, \\texttt{gmmsslm}, is demonstrated on real data.","created":"2023-02-26","meta":{"link":"http://arxiv.org/abs/2302.13206v1","tag":"data-quality"}}
{"title":"Inaccurate Label Distribution Learning","abstract":"Label distribution learning (LDL) trains a model to predict the relevance of a set of labels (called label distribution (LD)) to an instance. The previous LDL methods all assumed the LDs of the training instances are accurate. However, annotating highly accurate LDs for training instances is time-consuming and very expensive, and in reality the collected LD is usually inaccurate and disturbed by annotating errors. For the first time, this paper investigates the problem of inaccurate LDL, i.e., developing an LDL model with noisy LDs. Specifically, we assume the noisy LD matrix is the linear combination of an ideal LD matrix and a sparse noisy matrix. Accordingly, inaccurate LDL becomes an inverse problem, i.e., recovering the ideal LD and noise matrix from the inaccurate LDs. To this end, we assume the ideal LD matrix is low-rank due to the correlation of labels. Besides, we use the local geometric structure of instances captured by a graph to assist the ideal LD recovery as if two instances are similar to each other, they are likely to share the same LD. The proposed model is finally formulated as a graph-regularized low-rank and sparse decomposition problem and numerically solved by the alternating direction method of multipliers. Extensive experiments demonstrate that our method can recover a relatively accurate LD from the inaccurate LD and promote the performance of different LDL methods with inaccurate LD.","created":"2023-02-25","meta":{"link":"http://arxiv.org/abs/2302.13000v1","tag":"data-quality"}}
{"title":"A Joint Modeling of Vision-Language-Action for Target-oriented Grasping in Clutter","abstract":"We focus on the task of language-conditioned grasping in clutter, in which a robot is supposed to grasp the target object based on a language instruction. Previous works separately conduct visual grounding to localize the target object, and generate a grasp for that object. However, these works require object labels or visual attributes for grounding, which calls for handcrafted rules in planner and restricts the range of language instructions. In this paper, we propose to jointly model vision, language and action with object-centric representation. Our method is applicable under more flexible language instructions, and not limited by visual grounding error. Besides, by utilizing the powerful priors from the pre-trained multi-modal model and grasp model, sample efficiency is effectively improved and the sim2real problem is relived without additional data for transfer. A series of experiments carried out in simulation and real world indicate that our method can achieve better task success rate by less times of motion under more flexible language instructions. Moreover, our method is capable of generalizing better to scenarios with unseen objects and language instructions.","created":"2023-02-24","meta":{"link":"http://arxiv.org/abs/2302.12610v1","tag":"data-quality"}}
{"title":"iPlanner: Imperative Path Planning","abstract":"The problem of path planning has been studied for years. Classic planning pipelines, including perception, mapping, and path searching, can result in latency and compounding errors between modules. While recent studies have demonstrated the effectiveness of end-to-end learning methods in achieving high planning efficiency, these methods often struggle to match the generalization abilities of classic approaches in handling different environments. Moreover, end-to-end training of policies often requires a large number of labeled data or training iterations to reach convergence. In this paper, we present a novel Imperative Learning (IL) approach. This approach leverages a differentiable cost map to provide implicit supervision during policy training, eliminating the need for demonstrations or labeled trajectories. Furthermore, the policy training adopts a Bi-Level Optimization (BLO) process, which combines network update and metric-based trajectory optimization, to generate a smooth and collision-free path toward the goal based on a single depth measurement. The proposed method allows task-level costs of predicted trajectories to be backpropagated through all components to update the network through direct gradient descent. In our experiments, the method demonstrates around 4x faster planning than the classic approach and robustness against localization noise. Additionally, the IL approach enables the planner to generalize to various unseen environments, resulting in an overall 26-87% improvement in SPL performance compared to baseline learning methods.","created":"2023-02-22","meta":{"link":"http://arxiv.org/abs/2302.11434v2","tag":"data-quality"}}
{"title":"Counterfactual Prediction Under Outcome Measurement Error","abstract":"Across domains such as medicine, employment, and criminal justice, predictive models often target labels that imperfectly reflect the outcomes of interest to experts and policymakers. For example, clinical risk assessments deployed to inform physician decision-making often predict measures of healthcare utilization (e.g., costs, hospitalization) as a proxy for patient medical need. These proxies can be subject to outcome measurement error when they systematically differ from the target outcome they are intended to measure. However, prior modeling efforts to characterize and mitigate outcome measurement error overlook the fact that the decision being informed by a model often serves as a risk-mitigating intervention that impacts the target outcome of interest and its recorded proxy. Thus, in these settings, addressing measurement error requires counterfactual modeling of treatment effects on outcomes. In this work, we study intersectional threats to model reliability introduced by outcome measurement error, treatment effects, and selection bias from historical decision-making policies. We develop an unbiased risk minimization method which, given knowledge of proxy measurement error properties, corrects for the combined effects of these challenges. We also develop a method for estimating treatment-dependent measurement error parameters when these are unknown in advance. We demonstrate the utility of our approach theoretically and via experiments on real-world data from randomized controlled trials conducted in healthcare and employment domains. As importantly, we demonstrate that models correcting for outcome measurement error or treatment effects alone suffer from considerable reliability limitations. Our work underscores the importance of considering intersectional threats to model validity during the design and evaluation of predictive models for decision support.","created":"2023-02-22","meta":{"link":"http://arxiv.org/abs/2302.11121v1","tag":"data-quality"}}
{"title":"Connecting Humanities and Social Sciences: Applying Language and Speech Technology to Online Panel Surveys","abstract":"In this paper, we explore the application of language and speech technology to open-ended questions in a Dutch panel survey. In an experimental wave respondents could choose to answer open questions via speech or keyboard. Automatic speech recognition (ASR) was used to process spoken responses. We evaluated answers from these input modalities to investigate differences between spoken and typed answers.We report the errors the ASR system produces and investigate the impact of these errors on downstream analyses. Open-ended questions give more freedom to answer for respondents, but entail a non-trivial amount of work to analyse. We evaluated the feasibility of using transformer-based models (e.g. BERT) to apply sentiment analysis and topic modelling on the answers of open questions. A big advantage of transformer-based models is that they are trained on a large amount of language materials and do not necessarily need training on the target materials. This is especially advantageous for survey data, which does not contain a lot of text materials. We tested the quality of automatic sentiment analysis by comparing automatic labeling with three human raters and tested the robustness of topic modelling by comparing the generated models based on automatic and manually transcribed spoken answers.","created":"2023-02-21","meta":{"link":"http://arxiv.org/abs/2302.10593v1","tag":"data-quality"}}
{"title":"Pseudo-Labeling for Kernel Ridge Regression under Covariate Shift","abstract":"We develop and analyze a principled approach to kernel ridge regression under covariate shift. The goal is to learn a regression function with small mean squared error over a target distribution, based on unlabeled data from there and labeled data that may have a different feature distribution. We propose to split the labeled data into two subsets and conduct kernel ridge regression on them separately to obtain a collection of candidate models and an imputation model. We use the latter to fill the missing labels and then select the best candidate model accordingly. Our non-asymptotic excess risk bounds show that in quite general scenarios, our estimator adapts to the structure of the target distribution as well as the covariate shift. It achieves the minimax optimal error rate up to a logarithmic factor. The use of pseudo-labels in model selection does not have major negative impacts.","created":"2023-02-20","meta":{"link":"http://arxiv.org/abs/2302.10160v2","tag":"data-quality"}}
{"title":"A Benchmark of Nested Named Entity Recognition Approaches in Historical Structured Documents","abstract":"Named Entity Recognition (NER) is a key step in the creation of structured data from digitised historical documents. Traditional NER approaches deal with flat named entities, whereas entities often are nested. For example, a postal address might contain a street name and a number. This work compares three nested NER approaches, including two state-of-the-art approaches using Transformer-based architectures. We introduce a new Transformer-based approach based on joint labelling and semantic weighting of errors, evaluated on a collection of 19 th-century Paris trade directories. We evaluate approaches regarding the impact of supervised fine-tuning, unsupervised pre-training with noisy texts, and variation of IOB tagging formats. Our results show that while nested NER approaches enable extracting structured data directly, they do not benefit from the extra knowledge provided during training and reach a performance similar to the base approach on flat entities. Even though all 3 approaches perform well in terms of F1 scores, joint labelling is most suitable for hierarchically structured data. Finally, our experiments reveal the superiority of the IO tagging format on such data.","created":"2023-02-20","meta":{"link":"http://arxiv.org/abs/2302.10204v1","tag":"data-quality"}}
{"title":"An ASR-free Fluency Scoring Approach with Self-Supervised Learning","abstract":"A typical fluency scoring system generally relies on an automatic speech recognition (ASR) system to obtain time stamps in input speech for either the subsequent calculation of fluency-related features or directly modeling speech fluency with an end-to-end approach. This paper describes a novel ASR-free approach for automatic fluency assessment using self-supervised learning (SSL). Specifically, wav2vec2.0 is used to extract frame-level speech features, followed by K-means clustering to assign a pseudo label (cluster index) to each frame. A BLSTM-based model is trained to predict an utterance-level fluency score from frame-level SSL features and the corresponding cluster indexes. Neither speech transcription nor time stamp information is required in the proposed system. It is ASR-free and can potentially avoid the ASR errors effect in practice. Experimental results carried out on non-native English databases show that the proposed approach significantly improves the performance in the \"open response\" scenario as compared to previous methods and matches the recently reported performance in the \"read aloud\" scenario.","created":"2023-02-20","meta":{"link":"http://arxiv.org/abs/2302.09928v2","tag":"data-quality"}}
{"title":"Speaker and Language Change Detection using Wav2vec2 and Whisper","abstract":"We investigate recent transformer networks pre-trained for automatic speech recognition for their ability to detect speaker and language changes in speech. We do this by simply adding speaker (change) or language targets to the labels. For Wav2vec2 pre-trained networks, we also investigate if the representation for the speaker change symbol can be conditioned to capture speaker identity characteristics. Using a number of constructed data sets we show that these capabilities are definitely there, with speaker recognition equal error rates of the order of 10% and language detection error rates of a few percent. We will publish the code for reproducibility.","created":"2023-02-18","meta":{"link":"http://arxiv.org/abs/2302.09381v1","tag":"data-quality"}}
{"title":"Towards Fine-Grained Information: Identifying the Type and Location of Translation Errors","abstract":"Fine-grained information on translation errors is helpful for the translation evaluation community. Existing approaches can not synchronously consider error position and type, failing to integrate the error information of both. In this paper, we propose Fine-Grained Translation Error Detection (FG-TED) task, aiming at identifying both the position and the type of translation errors on given source-hypothesis sentence pairs. Besides, we build an FG-TED model to predict the \\textbf{addition} and \\textbf{omission} errors -- two typical translation accuracy errors. First, we use a word-level classification paradigm to form our model and use the shortcut learning reduction to relieve the influence of monolingual features. Besides, we construct synthetic datasets for model training, and relieve the disagreement of data labeling in authoritative datasets, making the experimental benchmark concordant. Experiments show that our model can identify both error type and position concurrently, and gives state-of-the-art results on the restored dataset. Our model also delivers more reliable predictions on low-resource and transfer scenarios than existing baselines. The related datasets and the source code will be released in the future.","created":"2023-02-17","meta":{"link":"http://arxiv.org/abs/2302.08975v1","tag":"data-quality"}}
{"title":"Are Gaussian data all you need? Extents and limits of universality in high-dimensional generalized linear estimation","abstract":"In this manuscript we consider the problem of generalized linear estimation on Gaussian mixture data with labels given by a single-index model. Our first result is a sharp asymptotic expression for the test and training errors in the high-dimensional regime. Motivated by the recent stream of results on the Gaussian universality of the test and training errors in generalized linear estimation, we ask ourselves the question: \"when is a single Gaussian enough to characterize the error?\". Our formula allow us to give sharp answers to this question, both in the positive and negative directions. More precisely, we show that the sufficient conditions for Gaussian universality (or lack of thereof) crucially depend on the alignment between the target weights and the means and covariances of the mixture clusters, which we precisely quantify. In the particular case of least-squares interpolation, we prove a strong universality property of the training error, and show it follows a simple, closed-form expression. Finally, we apply our results to real datasets, clarifying some recent discussion in the literature about Gaussian universality of the errors in this context.","created":"2023-02-17","meta":{"link":"http://arxiv.org/abs/2302.08923v1","tag":"data-quality"}}
{"title":"Hate Speech and Offensive Language Detection using an Emotion-aware Shared Encoder","abstract":"The rise of emergence of social media platforms has fundamentally altered how people communicate, and among the results of these developments is an increase in online use of abusive content. Therefore, automatically detecting this content is essential for banning inappropriate information, and reducing toxicity and violence on social media platforms. The existing works on hate speech and offensive language detection produce promising results based on pre-trained transformer models, however, they considered only the analysis of abusive content features generated through annotated datasets. This paper addresses a multi-task joint learning approach which combines external emotional features extracted from another corpora in dealing with the imbalanced and scarcity of labeled datasets. Our analysis are using two well-known Transformer-based models, BERT and mBERT, where the later is used to address abusive content detection in multi-lingual scenarios. Our model jointly learns abusive content detection with emotional features by sharing representations through transformers' shared encoder. This approach increases data efficiency, reduce overfitting via shared representations, and ensure fast learning by leveraging auxiliary information. Our findings demonstrate that emotional knowledge helps to more reliably identify hate speech and offensive language across datasets. Our hate speech detection Multi-task model exhibited 3% performance improvement over baseline models, but the performance of multi-task models were not significant for offensive language detection task. More interestingly, in both tasks, multi-task models exhibits less false positive errors compared to single task scenario.","created":"2023-02-17","meta":{"link":"http://arxiv.org/abs/2302.08777v1","tag":"data-quality"}}
{"title":"Self-supervised Registration and Segmentation of the Ossicles with A Single Ground Truth Label","abstract":"AI-assisted surgeries have drawn the attention of the medical image research community due to their real-world impact on improving surgery success rates. For image-guided surgeries, such as Cochlear Implants (CIs), accurate object segmentation can provide useful information for surgeons before an operation. Recently published image segmentation methods that leverage machine learning usually rely on a large number of manually predefined ground truth labels. However, it is a laborious and time-consuming task to prepare the dataset. This paper presents a novel technique using a self-supervised 3D-UNet that produces a dense deformation field between an atlas and a target image that can be used for atlas-based segmentation of the ossicles. Our results show that our method outperforms traditional image segmentation methods and generates a more accurate boundary around the ossicles based on Dice similarity coefficient and point-to-point error comparison. The mean Dice coefficient is improved by 8.51% with our proposed method.","created":"2023-02-15","meta":{"link":"http://arxiv.org/abs/2302.07967v1","tag":"data-quality"}}
{"title":"Error Sensitivity Modulation based Experience Replay: Mitigating Abrupt Representation Drift in Continual Learning","abstract":"Humans excel at lifelong learning, as the brain has evolved to be robust to distribution shifts and noise in our ever-changing environment. Deep neural networks (DNNs), however, exhibit catastrophic forgetting and the learned representations drift drastically as they encounter a new task. This alludes to a different error-based learning mechanism in the brain. Unlike DNNs, where learning scales linearly with the magnitude of the error, the sensitivity to errors in the brain decreases as a function of their magnitude. To this end, we propose \\textit{ESMER} which employs a principled mechanism to modulate error sensitivity in a dual-memory rehearsal-based system. Concretely, it maintains a memory of past errors and uses it to modify the learning dynamics so that the model learns more from small consistent errors compared to large sudden errors. We also propose \\textit{Error-Sensitive Reservoir Sampling} to maintain episodic memory, which leverages the error history to pre-select low-loss samples as candidates for the buffer, which are better suited for retaining information. Empirical results show that ESMER effectively reduces forgetting and abrupt drift in representations at the task boundary by gradually adapting to the new task while consolidating knowledge. Remarkably, it also enables the model to learn under high levels of label noise, which is ubiquitous in real-world data streams.","created":"2023-02-14","meta":{"link":"http://arxiv.org/abs/2302.11344v1","tag":"data-quality"}}
{"title":"Near-Optimal Cryptographic Hardness of Agnostically Learning Halfspaces and ReLU Regression under Gaussian Marginals","abstract":"We study the task of agnostically learning halfspaces under the Gaussian distribution. Specifically, given labeled examples $(\\mathbf{x},y)$ from an unknown distribution on $\\mathbb{R}^n \\times \\{ \\pm 1\\}$, whose marginal distribution on $\\mathbf{x}$ is the standard Gaussian and the labels $y$ can be arbitrary, the goal is to output a hypothesis with 0-1 loss $\\mathrm{OPT}+\\epsilon$, where $\\mathrm{OPT}$ is the 0-1 loss of the best-fitting halfspace. We prove a near-optimal computational hardness result for this task, under the widely believed sub-exponential time hardness of the Learning with Errors (LWE) problem. Prior hardness results are either qualitatively suboptimal or apply to restricted families of algorithms. Our techniques extend to yield near-optimal lower bounds for related problems, including ReLU regression.","created":"2023-02-13","meta":{"link":"http://arxiv.org/abs/2302.06512v1","tag":"data-quality"}}
{"title":"Self-supervised phase unwrapping in fringe projection profilometry","abstract":"Fast-speed and high-accuracy three-dimensional (3D) shape measurement has been the goal all along in fringe projection profilometry (FPP). The dual-frequency temporal phase unwrapping method (DF-TPU) is one of the prominent technologies to achieve this goal. However, the period number of the high-frequency pattern of existing DF-TPU approaches is usually limited by the inevitable phase errors, setting a limit to measurement accuracy. Deep-learning-based phase unwrapping methods for single-camera FPP usually require labeled data for training. In this letter, a novel self-supervised phase unwrapping method for single-camera FPP systems is proposed. The trained network can retrieve the absolute fringe order from one phase map of 64-period and overperform DF-TPU approaches in terms of depth accuracy. Experimental results demonstrate the validation of the proposed method on real scenes of motion blur, isolated objects, low reflectivity, and phase discontinuity.","created":"2023-02-13","meta":{"link":"http://arxiv.org/abs/2302.06381v1","tag":"data-quality"}}
{"title":"A Theoretical Understanding of Shallow Vision Transformers: Learning, Generalization, and Sample Complexity","abstract":"Vision Transformers (ViTs) with self-attention modules have recently achieved great empirical success in many vision tasks. Due to non-convex interactions across layers, however, theoretical learning and generalization analysis is mostly elusive. Based on a data model characterizing both label-relevant and label-irrelevant tokens, this paper provides the first theoretical analysis of training a shallow ViT, i.e., one self-attention layer followed by a two-layer perceptron, for a classification task. We characterize the sample complexity to achieve a zero generalization error. Our sample complexity bound is positively correlated with the inverse of the fraction of label-relevant tokens, the token noise level, and the initial model error. We also prove that a training process using stochastic gradient descent (SGD) leads to a sparse attention map, which is a formal verification of the general intuition about the success of attention. Moreover, this paper indicates that a proper token sparsification can improve the test performance by removing label-irrelevant and/or noisy tokens, including spurious correlations. Empirical experiments on synthetic data and CIFAR-10 dataset justify our theoretical results and generalize to deeper ViTs.","created":"2023-02-12","meta":{"link":"http://arxiv.org/abs/2302.06015v2","tag":"data-quality"}}
{"title":"Surrogate-Assisted Federated Learning of high dimensional Electronic Health Record Data","abstract":"Surrogate variables in electronic health records (EHR) play an important role in biomedical studies due to the scarcity or absence of chart-reviewed gold standard labels, under which supervised methods only using labeled data poorly perform poorly. Meanwhile, synthesizing multi-site EHR data is crucial for powerful and generalizable statistical learning but encounters the privacy constraint that individual-level data is not allowed to be transferred from the local sites, known as DataSHIELD. In this paper, we develop a novel approach named SASH for Surrogate-Assisted and data-Shielding High-dimensional integrative regression. SASH leverages sizable unlabeled data with EHR surrogates predictive of the response from multiple local sites to assist the training with labeled data and largely improve statistical efficiency. It first extracts a preliminary supervised estimator to realize convex training of a regularized single index model for the surrogate at each local site and then aggregates the fitted local models for accurate learning of the target outcome model. It protects individual-level information from the local sites through summary-statistics-based data aggregation. We show that under mild conditions, our method attains substantially lower estimation error rates than the supervised or local semi-supervised methods, as well as the asymptotic equivalence to the ideal individual patient data pooled estimator (IPD) only available in the absence of privacy constraints. Through simulation studies, we demonstrate that SASH outperforms all existing supervised or SS federated approaches and performs closely to IPD. Finally, we apply our method to develop a high dimensional genetic risk model for type II diabetes using large-scale biobank data sets from UK Biobank and Mass General Brigham, where only a small fraction of subjects from the latter has been labeled via chart reviewing.","created":"2023-02-09","meta":{"link":"http://arxiv.org/abs/2302.04970v1","tag":"data-quality"}}
{"title":"Dimension reduction and redundancy removal through successive Schmidt decompositions","abstract":"Quantum computers are believed to have the ability to process huge data sizes which can be seen in machine learning applications. In these applications, the data in general is classical. Therefore, to process them on a quantum computer, there is a need for efficient methods which can be used to map classical data on quantum states in a concise manner. On the other hand, to verify the results of quantum computers and study quantum algorithms, we need to be able to approximate quantum operations into forms that are easier to simulate on classical computers with some errors.   Motivated by these needs, in this paper we study the approximation of matrices and vectors by using their tensor products obtained through successive Schmidt decompositions. We show that data with distributions such as uniform, Poisson, exponential, or similar to these distributions can be approximated by using only a few terms which can be easily mapped onto quantum circuits. The examples include random data with different distributions, the Gram matrices of iris flower, handwritten digits, 20newsgroup, and labeled faces in the wild. And similarly, some quantum operations such as quantum Fourier transform and variational quantum circuits with a small depth also may be approximated with a few terms that are easier to simulate on classical computers. Furthermore, we show how the method can be used to simplify quantum Hamiltonians: In particular, we show the application to randomly generated transverse field Ising model Hamiltonians. The reduced Hamiltonians can be mapped into quantum circuits easily and therefore can be simulated more efficiently.","created":"2023-02-09","meta":{"link":"http://arxiv.org/abs/2302.04801v1","tag":"data-quality"}}
{"title":"On Fairness and Stability: Is Estimator Variance a Friend or a Foe?","abstract":"The error of an estimator can be decomposed into a (statistical) bias term, a variance term, and an irreducible noise term. When we do bias analysis, formally we are asking the question: \"how good are the predictions?\" The role of bias in the error decomposition is clear: if we trust the labels/targets, then we would want the estimator to have as low bias as possible, in order to minimize error. Fair machine learning is concerned with the question: \"Are the predictions equally good for different demographic/social groups?\" This has naturally led to a variety of fairness metrics that compare some measure of statistical bias on subsets corresponding to socially privileged and socially disadvantaged groups. In this paper we propose a new family of performance measures based on group-wise parity in variance. We demonstrate when group-wise statistical bias analysis gives an incomplete picture, and what group-wise variance analysis can tell us in settings that differ in the magnitude of statistical bias. We develop and release an open-source library that reconciles uncertainty quantification techniques with fairness analysis, and use it to conduct an extensive empirical analysis of our variance-based fairness measures on standard benchmarks.","created":"2023-02-09","meta":{"link":"http://arxiv.org/abs/2302.04525v1","tag":"data-quality"}}
{"title":"On the Richness of Calibration","abstract":"Probabilistic predictions can be evaluated through comparisons with observed label frequencies, that is, through the lens of calibration. Recent scholarship on algorithmic fairness has started to look at a growing variety of calibration-based objectives under the name of multi-calibration but has still remained fairly restricted. In this paper, we explore and analyse forms of evaluation through calibration by making explicit the choices involved in designing calibration scores. We organise these into three grouping choices and a choice concerning the agglomeration of group errors. This provides a framework for comparing previously proposed calibration scores and helps to formulate novel ones with desirable mathematical properties. In particular, we explore the possibility of grouping datapoints based on their input features rather than on predictions and formally demonstrate advantages of such approaches. We also characterise the space of suitable agglomeration functions for group errors, generalising previously proposed calibration scores. Complementary to such population-level scores, we explore calibration scores at the individual level and analyse their relationship to choices of grouping. We draw on these insights to introduce and axiomatise fairness deviation measures for population-level scores. We demonstrate that with appropriate choices of grouping, these novel global fairness scores can provide notions of (sub-)group or individual fairness.","created":"2023-02-08","meta":{"link":"http://arxiv.org/abs/2302.04118v1","tag":"data-quality"}}
{"title":"A Bipartite Ranking Approach to the Two-Sample Problem","abstract":"The two-sample problem, which consists in testing whether independent samples on $\\mathbb{R}^d$ are drawn from the same (unknown) distribution, finds applications in many areas. Its study in high-dimension is the subject of much attention, especially because the information acquisition processes at work in the Big Data era often involve various sources, poorly controlled, leading to datasets possibly exhibiting a strong sampling bias. While classic methods relying on the computation of a discrepancy measure between the empirical distributions face the curse of dimensionality, we develop an alternative approach based on statistical learning and extending rank tests, capable of detecting small departures from the null assumption in the univariate case when appropriately designed. Overcoming the lack of natural order on $\\mathbb{R}^d$ when $d\\geq 2$, it is implemented in two steps. Assigning to each of the samples a label (positive vs. negative) and dividing them into two parts, a preorder on $\\mathbb{R}^d$ defined by a real-valued scoring function is learned by means of a bipartite ranking algorithm applied to the first part and a rank test is applied next to the scores of the remaining observations to detect possible differences in distribution. Because it learns how to project the data onto the real line nearly like (any monotone transform of) the likelihood ratio between the original multivariate distributions would do, the approach is not much affected by the dimensionality, ignoring ranking model bias issues, and preserves the advantages of univariate rank tests. Nonasymptotic error bounds are proved based on recent concentration results for two-sample linear rank-processes and an experimental study shows that the approach promoted surpasses alternative methods standing as natural competitors.","created":"2023-02-07","meta":{"link":"http://arxiv.org/abs/2302.03592v2","tag":"data-quality"}}
{"title":"Speak, Read and Prompt: High-Fidelity Text-to-Speech with Minimal Supervision","abstract":"We introduce SPEAR-TTS, a multi-speaker text-to-speech (TTS) system that can be trained with minimal supervision. By combining two types of discrete speech representations, we cast TTS as a composition of two sequence-to-sequence tasks: from text to high-level semantic tokens (akin to \"reading\") and from semantic tokens to low-level acoustic tokens (\"speaking\"). Decoupling these two tasks enables training of the \"speaking\" module using abundant audio-only data, and unlocks the highly efficient combination of pretraining and backtranslation to reduce the need for parallel data when training the \"reading\" component. To control the speaker identity, we adopt example prompting, which allows SPEAR-TTS to generalize to unseen speakers using only a short sample of 3 seconds, without any explicit speaker representation or speaker-id labels. Our experiments demonstrate that SPEAR-TTS achieves a character error rate that is competitive with state-of-the-art methods using only 15 minutes of parallel data, while matching ground-truth speech in terms of naturalness and acoustic quality, as measured in subjective tests.","created":"2023-02-07","meta":{"link":"http://arxiv.org/abs/2302.03540v1","tag":"data-quality"}}
{"title":"Revisiting Discriminative vs. Generative Classifiers: Theory and Implications","abstract":"A large-scale deep model pre-trained on massive labeled or unlabeled data transfers well to downstream tasks. Linear evaluation freezes parameters in the pre-trained model and trains a linear classifier separately, which is efficient and attractive for transfer. However, little work has investigated the classifier in linear evaluation except for the default logistic regression. Inspired by the statistical efficiency of naive Bayes, the paper revisits the classical topic on discriminative vs. generative classifiers. Theoretically, the paper considers the surrogate loss instead of the zero-one loss in analyses and generalizes the classical results from binary cases to multiclass ones. We show that, under mild assumptions, multiclass naive Bayes requires $O(\\log n)$ samples to approach its asymptotic error while the corresponding multiclass logistic regression requires $O(n)$ samples, where $n$ is the feature dimension. To establish it, we present a multiclass $\\mathcal{H}$-consistency bound framework and an explicit bound for logistic loss, which are of independent interests. Simulation results on a mixture of Gaussian validate our theoretical findings. Experiments on various pre-trained deep vision models show that naive Bayes consistently converges faster as the number of data increases. Besides, naive Bayes shows promise in few-shot cases and we observe the ``two regimes'' phenomenon in pre-trained supervised models. Our code is available at https://github.com/ML-GSAI/Revisiting-Dis-vs-Gen-Classifiers.","created":"2023-02-05","meta":{"link":"http://arxiv.org/abs/2302.02334v1","tag":"data-quality"}}
{"title":"Recurrence With Correlation Network for Medical Image Registration","abstract":"We present Recurrence with Correlation Network (RWCNet), a medical image registration network with multi-scale features and a cost volume layer. We demonstrate that these architectural features improve medical image registration accuracy in two image registration datasets prepared for the MICCAI 2022 Learn2Reg Workshop Challenge. On the large-displacement National Lung Screening Test (NLST) dataset, RWCNet is able to achieve a total registration error (TRE) of 2.11mm between corresponding keypoints without instance fine-tuning. On the OASIS brain MRI dataset, RWCNet is able to achieve an average dice overlap of 81.7% for 35 different anatomical labels. It outperforms another multi-scale network, the Laplacian Image Registration Network (LapIRN), on both datasets. Ablation experiments are performed to highlight the contribution of the various architectural features. While multi-scale features improved validation accuracy for both datasets, the cost volume layer and number of recurrent steps only improved performance on the large-displacement NLST dataset. This result suggests that cost volume layer and iterative refinement using RNN provide good support for optimization and generalization in large-displacement medical image registration. The code for RWCNet is available at https://github.com/vigsivan/optimization-based-registration.","created":"2023-02-05","meta":{"link":"http://arxiv.org/abs/2302.02283v1","tag":"data-quality"}}
{"title":"NeuRI: Diversifying DNN Generation via Inductive Rule Inference","abstract":"Deep Learning (DL) is prevalently used in various industries to improve decision-making and automate processes, driven by the ever-evolving DL libraries and compilers. The correctness of DL systems is crucial for trust in DL applications. As such, the recent wave of research has been studying the automated synthesis of test-cases (i.e., DNN models and their inputs) for fuzzing DL systems. However, existing model generators only subsume a limited number of operators, for lacking the ability to pervasively model operator constraints. To address this challenge, we propose NeuRI, a fully automated approach for generating valid and diverse DL models composed of hundreds of types of operators. NeuRI adopts a three-step process: (i) collecting valid and invalid API traces from various sources; (ii) applying inductive program synthesis over the traces to infer the constraints for constructing valid models; and (iii) performing hybrid model generation by incorporating both symbolic and concrete operators concolically. Our evaluation shows that NeuRI improves branch coverage of TensorFlow and PyTorch by 51% and 15% over the state-of-the-art. Within four months, NeuRI finds 87 new bugs for PyTorch and TensorFlow, with 64 already fixed or confirmed, and 8 high-priority bugs labeled by PyTorch, constituting 10% of all high-priority bugs of the period. Additionally, open-source developers regard error-inducing models reported by us as \"high-quality\" and \"common in practice\".","created":"2023-02-04","meta":{"link":"http://arxiv.org/abs/2302.02261v1","tag":"data-quality"}}
{"title":"CLiNet: Joint Detection of Road Network Centerlines in 2D and 3D","abstract":"This work introduces a new approach for joint detection of centerlines based on image data by localizing the features jointly in 2D and 3D. In contrast to existing work that focuses on detection of visual cues, we explore feature extraction methods that are directly amenable to the urban driving task. To develop and evaluate our approach, a large urban driving dataset dubbed AV Breadcrumbs is automatically labeled by leveraging vector map representations and projective geometry to annotate over 900,000 images. Our results demonstrate potential for dynamic scene modeling across various urban driving scenarios. Our model achieves an F1 score of 0.684 and an average normalized depth error of 2.083. The code and data annotations are publicly available.","created":"2023-02-04","meta":{"link":"http://arxiv.org/abs/2302.02259v1","tag":"data-quality"}}
{"title":"Domain Adaptation via Rebalanced Sub-domain Alignment","abstract":"Unsupervised domain adaptation (UDA) is a technique used to transfer knowledge from a labeled source domain to a different but related unlabeled target domain. While many UDA methods have shown success in the past, they often assume that the source and target domains must have identical class label distributions, which can limit their effectiveness in real-world scenarios. To address this limitation, we propose a novel generalization bound that reweights source classification error by aligning source and target sub-domains. We prove that our proposed generalization bound is at least as strong as existing bounds under realistic assumptions, and we empirically show that it is much stronger on real-world data. We then propose an algorithm to minimize this novel generalization bound. We demonstrate by numerical experiments that this approach improves performance in shifted class distribution scenarios compared to state-of-the-art methods.","created":"2023-02-03","meta":{"link":"http://arxiv.org/abs/2302.02009v1","tag":"data-quality"}}
{"title":"Improving Rare Words Recognition through Homophone Extension and Unified Writing for Low-resource Cantonese Speech Recognition","abstract":"Homophone characters are common in tonal syllable-based languages, such as Mandarin and Cantonese. The data-intensive end-to-end Automatic Speech Recognition (ASR) systems are more likely to mis-recognize homophone characters and rare words under low-resource settings. For the problem of lowresource Cantonese speech recognition, this paper presents a novel homophone extension method to integrate human knowledge of the homophone lexicon into the beam search decoding process with language model re-scoring. Besides, we propose an automatic unified writing method to merge the variants of Cantonese characters and standardize speech annotation guidelines, which enables more efficient utilization of labeled utterances by providing more samples for the merged characters. We empirically show that both homophone extension and unified writing improve the recognition performance significantly on both in-domain and out-of-domain test sets, with an absolute Character Error Rate (CER) decrease of around 5% and 18%.","created":"2023-02-02","meta":{"link":"http://arxiv.org/abs/2302.00836v1","tag":"data-quality"}}
{"title":"SkinCon: A skin disease dataset densely annotated by domain experts for fine-grained model debugging and analysis","abstract":"For the deployment of artificial intelligence (AI) in high-risk settings, such as healthcare, methods that provide interpretability/explainability or allow fine-grained error analysis are critical. Many recent methods for interpretability/explainability and fine-grained error analysis use concepts, which are meta-labels that are semantically meaningful to humans. However, there are only a few datasets that include concept-level meta-labels and most of these meta-labels are relevant for natural images that do not require domain expertise. Densely annotated datasets in medicine focused on meta-labels that are relevant to a single disease such as melanoma. In dermatology, skin disease is described using an established clinical lexicon that allows clinicians to describe physical exam findings to one another. To provide a medical dataset densely annotated by domain experts with annotations useful across multiple disease processes, we developed SkinCon: a skin disease dataset densely annotated by dermatologists. SkinCon includes 3230 images from the Fitzpatrick 17k dataset densely annotated with 48 clinical concepts, 22 of which have at least 50 images representing the concept. The concepts used were chosen by two dermatologists considering the clinical descriptor terms used to describe skin lesions. Examples include \"plaque\", \"scale\", and \"erosion\". The same concepts were also used to label 656 skin disease images from the Diverse Dermatology Images dataset, providing an additional external dataset with diverse skin tone representations. We review the potential applications for the SkinCon dataset, such as probing models, concept-based explanations, and concept bottlenecks. Furthermore, we use SkinCon to demonstrate two of these use cases: debugging mistakes of an existing dermatology AI model with concepts and developing interpretable models with post-hoc concept bottleneck models.","created":"2023-02-01","meta":{"link":"http://arxiv.org/abs/2302.00785v1","tag":"data-quality"}}
{"title":"Learning from Stochastic Labels","abstract":"Annotating multi-class instances is a crucial task in the field of machine learning. Unfortunately, identifying the correct class label from a long sequence of candidate labels is time-consuming and laborious. To alleviate this problem, we design a novel labeling mechanism called stochastic label. In this setting, stochastic label includes two cases: 1) identify a correct class label from a small number of randomly given labels; 2) annotate the instance with None label when given labels do not contain correct class label. In this paper, we propose a novel suitable approach to learn from these stochastic labels. We obtain an unbiased estimator that utilizes less supervised information in stochastic labels to train a multi-class classifier. Additionally, it is theoretically justifiable by deriving the estimation error bound of the proposed method. Finally, we conduct extensive experiments on widely-used benchmark datasets to validate the superiority of our method by comparing it with existing state-of-the-art methods.","created":"2023-02-01","meta":{"link":"http://arxiv.org/abs/2302.00299v1","tag":"data-quality"}}
{"title":"Rethinking Soft Label in Label Distribution Learning Perspective","abstract":"The primary goal of training in early convolutional neural networks (CNN) is the higher generalization performance of the model. However, as the expected calibration error (ECE), which quantifies the explanatory power of model inference, was recently introduced, research on training models that can be explained is in progress. We hypothesized that a gap in supervision criteria during training and inference leads to overconfidence, and investigated that performing label distribution learning (LDL) would enhance the model calibration in CNN training. To verify this assumption, we used a simple LDL setting with recent data augmentation techniques. Based on a series of experiments, the following results are obtained: 1) State-of-the-art KD methods significantly impede model calibration. 2) Training using LDL with recent data augmentation can have excellent effects on model calibration and even in generalization performance. 3) Online LDL brings additional improvements in model calibration and accuracy with long training, especially in large-size models. Using the proposed approach, we simultaneously achieved a lower ECE and higher generalization performance for the image classification datasets CIFAR10, 100, STL10, and ImageNet. We performed several visualizations and analyses and witnessed several interesting behaviors in CNN training with the LDL.","created":"2023-01-31","meta":{"link":"http://arxiv.org/abs/2301.13444v1","tag":"data-quality"}}
{"title":"Demystifying Disagreement-on-the-Line in High Dimensions","abstract":"Evaluating the performance of machine learning models under distribution shift is challenging, especially when we only have unlabeled data from the shifted (target) domain, along with labeled data from the original (source) domain. Recent work suggests that the notion of disagreement, the degree to which two models trained with different randomness differ on the same input, is a key to tackle this problem. Experimentally, disagreement and prediction error have been shown to be strongly connected, which has been used to estimate model performance. Experiments have led to the discovery of the disagreement-on-the-line phenomenon, whereby the classification error under the target domain is often a linear function of the classification error under the source domain; and whenever this property holds, disagreement under the source and target domain follow the same linear relation. In this work, we develop a theoretical foundation for analyzing disagreement in high-dimensional random features regression; and study under what conditions the disagreement-on-the-line phenomenon occurs in our setting. Experiments on CIFAR-10-C, Tiny ImageNet-C, and Camelyon17 are consistent with our theory and support the universality of the theoretical findings.","created":"2023-01-31","meta":{"link":"http://arxiv.org/abs/2301.13371v2","tag":"data-quality"}}
{"title":"Understanding Self-Distillation in the Presence of Label Noise","abstract":"Self-distillation (SD) is the process of first training a \\enquote{teacher} model and then using its predictions to train a \\enquote{student} model with the \\textit{same} architecture. Specifically, the student's objective function is $\\big(\\xi*\\ell(\\text{teacher's predictions}, \\text{ student's predictions}) + (1-\\xi)*\\ell(\\text{given labels}, \\text{ student's predictions})\\big)$, where $\\ell$ is some loss function and $\\xi$ is some parameter $\\in [0,1]$. Empirically, SD has been observed to provide performance gains in several settings. In this paper, we theoretically characterize the effect of SD in two supervised learning problems with \\textit{noisy labels}. We first analyze SD for regularized linear regression and show that in the high label noise regime, the optimal value of $\\xi$ that minimizes the expected error in estimating the ground truth parameter is surprisingly greater than 1. Empirically, we show that $\\xi > 1$ works better than $\\xi \\leq 1$ even with the cross-entropy loss for several classification datasets when 50\\% or 30\\% of the labels are corrupted. Further, we quantify when optimal SD is better than optimal regularization. Next, we analyze SD in the case of logistic regression for binary classification with random label corruption and quantify the range of label corruption in which the student outperforms the teacher in terms of accuracy. To our knowledge, this is the first result of its kind for the cross-entropy loss.","created":"2023-01-30","meta":{"link":"http://arxiv.org/abs/2301.13304v1","tag":"data-quality"}}
{"title":"Edge-guided Multi-domain RGB-to-TIR image Translation for Training Vision Tasks with Challenging Labels","abstract":"The insufficient number of annotated thermal infrared (TIR) image datasets not only hinders TIR image-based deep learning networks to have comparable performances to that of RGB but it also limits the supervised learning of TIR image-based tasks with challenging labels. As a remedy, we propose a modified multidomain RGB to TIR image translation model focused on edge preservation to employ annotated RGB images with challenging labels. Our proposed method not only preserves key details in the original image but also leverages the optimal TIR style code to portray accurate TIR characteristics in the translated image, when applied on both synthetic and real world RGB images. Using our translation model, we have enabled the supervised learning of deep TIR image-based optical flow estimation and object detection that ameliorated in deep TIR optical flow estimation by reduction in end point error by 56.5\\% on average and the best object detection mAP of 23.9\\% respectively. Our code and supplementary materials are available at https://github.com/rpmsnu/sRGB-TIR.","created":"2023-01-30","meta":{"link":"http://arxiv.org/abs/2301.12689v1","tag":"data-quality"}}
{"title":"Neural Relation Graph for Identifying Problematic Data","abstract":"Diagnosing and cleaning datasets are crucial for building robust machine learning systems. However, identifying problems within large-scale datasets with real-world distributions is difficult due to the presence of complex issues, such as label errors or under-representation of certain types. In this paper, we propose a novel approach for identifying problematic data by utilizing a largely ignored source of information: a relational structure of data in the feature-embedded space. We develop an efficient algorithm for detecting label errors and outlier data points based on the relational graph structure of the dataset. We further introduce a visualization tool for contextualizing data points, which can serve as an effective tool for interactively diagnosing datasets. We evaluate label error and out-of-distribution detection performances on large-scale image and language domain tasks, including ImageNet and GLUE benchmarks, and demonstrate the effectiveness of our approach for debugging datasets and building robust machine learning systems.","created":"2023-01-29","meta":{"link":"http://arxiv.org/abs/2301.12321v1","tag":"data-quality"}}
{"title":"Towards Precise Model-free Robotic Grasping with Sim-to-Real Transfer Learning","abstract":"Precise robotic grasping of several novel objects is a huge challenge in manufacturing, automation, and logistics. Most of the current methods for model-free grasping are disadvantaged by the sparse data in grasping datasets and by errors in sensor data and contact models. This study combines data generation and sim-to-real transfer learning in a grasping framework that reduces the sim-to-real gap and enables precise and reliable model-free grasping. A large-scale robotic grasping dataset with dense grasp labels is generated using domain randomization methods and a novel data augmentation method for deep learning-based robotic grasping to solve data sparse problem. We present an end-to-end robotic grasping network with a grasp optimizer. The grasp policies are trained with sim-to-real transfer learning. The presented results suggest that our grasping framework reduces the uncertainties in grasping datasets, sensor data, and contact models. In physical robotic experiments, our grasping framework grasped single known objects and novel complex-shaped household objects with a success rate of 90.91%. In a complex scenario with multi-objects robotic grasping, the success rate was 85.71%. The proposed grasping framework outperformed two state-of-the-art methods in both known and unknown object robotic grasping.","created":"2023-01-28","meta":{"link":"http://arxiv.org/abs/2301.12249v1","tag":"data-quality"}}
{"title":"DALI: Dynamically Adjusted Label Importance for Noisy Partial Label Learning","abstract":"Noisy partial label learning (noisy PLL) is an important branch of weakly supervised learning. Unlike PLL where the ground-truth label must reside in the candidate set, noisy PLL relaxes this constraint and allows the ground-truth label may not be in the candidate set. To address this problem, existing works attempt to detect noisy samples and estimate the ground-truth label for each noisy sample. However, detection errors are inevitable, and these errors will accumulate during training and continuously affect model optimization. To address this challenge, we propose a novel framework for noisy PLL, called ``Dynamically Adjusted Label Importance (DALI)''. It aims to reduce the negative impact of detection errors by trading off the initial candidate set and model outputs with theoretical guarantees. Experimental results on multiple datasets demonstrate that our DALI succeeds over existing state-of-the-art approaches on noisy PLL. Our code will soon be publicly available.","created":"2023-01-28","meta":{"link":"http://arxiv.org/abs/2301.12077v1","tag":"data-quality"}}
{"title":"Deep Residual Compensation Convolutional Network without Backpropagation","abstract":"PCANet and its variants provided good accuracy results for classification tasks. However, despite the importance of network depth in achieving good classification accuracy, these networks were trained with a maximum of nine layers. In this paper, we introduce a residual compensation convolutional network, which is the first PCANet-like network trained with hundreds of layers while improving classification accuracy. The design of the proposed network consists of several convolutional layers, each followed by post-processing steps and a classifier. To correct the classification errors and significantly increase the network's depth, we train each layer with new labels derived from the residual information of all its preceding layers. This learning mechanism is accomplished by traversing the network's layers in a single forward pass without backpropagation or gradient computations. Our experiments on four distinct classification benchmarks (MNIST, CIFAR-10, CIFAR-100, and TinyImageNet) show that our deep network outperforms all existing PCANet-like networks and is competitive with several traditional gradient-based models.","created":"2023-01-27","meta":{"link":"http://arxiv.org/abs/2301.11663v1","tag":"data-quality"}}
{"title":"Adversarial Learning for Implicit Semantic-Aware Communications","abstract":"Semantic communication is a novel communication paradigm that focuses on recognizing and delivering the desired meaning of messages to the destination users. Most existing works in this area focus on delivering explicit semantics, labels or signal features that can be directly identified from the source signals. In this paper, we consider the implicit semantic communication problem in which hidden relations and closely related semantic terms that cannot be recognized from the source signals need to also be delivered to the destination user. We develop a novel adversarial learning-based implicit semantic-aware communication (iSAC) architecture in which the source user, instead of maximizing the total amount of information transmitted to the channel, aims to help the recipient learn an inference rule that can automatically generate implicit semantics based on limited clue information. We prove that by applying iSAC, the destination user can always learn an inference rule that matches the true inference rule of the source messages. Experimental results show that the proposed iSAC can offer up to a 19.69 dB improvement over existing non-inferential communication solutions, in terms of symbol error rate at the destination user.","created":"2023-01-27","meta":{"link":"http://arxiv.org/abs/2301.11589v1","tag":"data-quality"}}
{"title":"Revisiting Discriminative Entropy Clustering and its relation to K-means","abstract":"Maximization of mutual information between the model's input and output is formally related to \"decisiveness\" and \"fairness\" of the softmax predictions, motivating such unsupervised entropy-based losses for discriminative neural networks. Recent self-labeling methods based on such losses represent the state of the art in deep clustering. However, some important properties of entropy clustering are not well-known, or even misunderstood. For example, we provide a counterexample to prior claims about equivalence to variance clustering (K-means) and point out technical mistakes in such theories. We discuss the fundamental differences between these discriminative and generative clustering approaches. Moreover, we show the susceptibility of standard entropy clustering to narrow margins and motivate an explicit margin maximization term. We also propose an improved self-labeling loss; it is robust to pseudo-labeling errors and enforces stronger fairness. We develop an EM algorithm for our loss that is significantly faster than the standard alternatives. Our results improve the state-of-the-art on standard benchmarks.","created":"2023-01-26","meta":{"link":"http://arxiv.org/abs/2301.11405v1","tag":"data-quality"}}
{"title":"HAL3D: Hierarchical Active Learning for Fine-Grained 3D Part Labeling","abstract":"We present the first active learning tool for fine-grained 3D part labeling, a problem which challenges even the most advanced deep learning (DL) methods due to the significant structural variations among the small and intricate parts. For the same reason, the necessary data annotation effort is tremendous, motivating approaches to minimize human involvement. Our labeling tool iteratively verifies or modifies part labels predicted by a deep neural network, with human feedback continually improving the network prediction. To effectively reduce human efforts, we develop two novel features in our tool, hierarchical and symmetry-aware active labeling. Our human-in-the-loop approach, coined HAL3D, achieves 100% accuracy (barring human errors) on any test set with pre-defined hierarchical part labels, with 80% time-saving over manual effort.","created":"2023-01-25","meta":{"link":"http://arxiv.org/abs/2301.10460v1","tag":"data-quality"}}
{"title":"Mixed Effects Random Forests for Personalised Predictions of Clinical Depression Severity","abstract":"This work demonstrates how mixed effects random forests enable accurate predictions of depression severity using multimodal physiological and digital activity data collected from an 8-week study involving 31 patients with major depressive disorder. We show that mixed effects random forests outperform standard random forests and personal average baselines when predicting clinical Hamilton Depression Rating Scale scores (HDRS_17). Compared to the latter baseline, accuracy is significantly improved for each patient by an average of 0.199-0.276 in terms of mean absolute error (p<0.05). This is noteworthy as these simple baselines frequently outperform machine learning methods in mental health prediction tasks. We suggest that this improved performance results from the ability of the mixed effects random forest to personalise model parameters to individuals in the dataset. However, we find that these improvements pertain exclusively to scenarios where labelled patient data are available to the model at training time. Investigating methods that improve accuracy when generalising to new patients is left as important future work.","created":"2023-01-24","meta":{"link":"http://arxiv.org/abs/2301.09815v1","tag":"data-quality"}}
{"title":"Tracking the industrial growth of modern China with high-resolution panchromatic imagery: A sequential convolutional approach","abstract":"Due to insufficient or difficult to obtain data on development in inaccessible regions, remote sensing data is an important tool for interested stakeholders to collect information on economic growth. To date, no studies have utilized deep learning to estimate industrial growth at the level of individual sites. In this study, we harness high-resolution panchromatic imagery to estimate development over time at 419 industrial sites in the People's Republic of China using a multi-tier computer vision framework. We present two methods for approximating development: (1) structural area coverage estimated through a Mask R-CNN segmentation algorithm, and (2) imputing development directly with visible & infrared radiance from the Visible Infrared Imaging Radiometer Suite (VIIRS). Labels generated from these methods are comparatively evaluated and tested. On a dataset of 2,078 50 cm resolution images spanning 19 years, the results indicate that two dimensions of industrial development can be estimated using high-resolution daytime imagery, including (a) the total square meters of industrial development (average error of 0.021 $\\textrm{km}^2$), and (b) the radiance of lights (average error of 9.8 $\\mathrm{\\frac{nW}{cm^{2}sr}}$). Trend analysis of the techniques reveal estimates from a Mask R-CNN-labeled CNN-LSTM track ground truth measurements most closely. The Mask R-CNN estimates positive growth at every site from the oldest image to the most recent, with an average change of 4,084 $\\textrm{m}^2$.","created":"2023-01-23","meta":{"link":"http://arxiv.org/abs/2301.09620v2","tag":"data-quality"}}
{"title":"Fast and robust single particle reconstruction in 3D fluorescence microscopy","abstract":"Single particle reconstruction has recently emerged in 3D fluorescence microscopy as a powerful technique to improve the axial resolution and the degree of fluorescent labeling. It is based on the reconstruction of an average volume of a biological particle from the acquisition multiple views with unknown poses. Current methods are limited either by template bias, restriction to 2D data, high computational cost or a lack of robustness to low fluorescent labeling. In this work, we propose a single particle reconstruction method dedicated to convolutional models in 3D fluorescence microscopy that overcome these issues. We address the joint reconstruction and estimation of the poses of the particles, which translates into a challenging non-convex optimization problem. Our approach is based on a multilevel reformulation of this problem, and the development of efficient optimization techniques at each level. We demonstrate on synthetic data that our method outperforms the standard approaches in terms of resolution and reconstruction error, while achieving a low computational cost. We also perform successful reconstruction on real datasets of centrioles to show the potential of our method in concrete applications.","created":"2023-01-23","meta":{"link":"http://arxiv.org/abs/2301.09452v1","tag":"data-quality"}}
{"title":"Exploring Active 3D Object Detection from a Generalization Perspective","abstract":"To alleviate the high annotation cost in LiDAR-based 3D object detection, active learning is a promising solution that learns to select only a small portion of unlabeled data to annotate, without compromising model performance. Our empirical study, however, suggests that mainstream uncertainty-based and diversity-based active learning policies are not effective when applied in the 3D detection task, as they fail to balance the trade-off between point cloud informativeness and box-level annotation costs. To overcome this limitation, we jointly investigate three novel criteria in our framework Crb for point cloud acquisition - label conciseness}, feature representativeness and geometric balance, which hierarchically filters out the point clouds of redundant 3D bounding box labels, latent features and geometric characteristics (e.g., point cloud density) from the unlabeled sample pool and greedily selects informative ones with fewer objects to annotate. Our theoretical analysis demonstrates that the proposed criteria align the marginal distributions of the selected subset and the prior distributions of the unseen test set, and minimizes the upper bound of the generalization error. To validate the effectiveness and applicability of Crb, we conduct extensive experiments on the two benchmark 3D object detection datasets of KITTI and Waymo and examine both one-stage (i.e., Second) and two-stage 3D detectors (i.e., Pv-rcnn). Experiments evidence that the proposed approach outperforms existing active learning strategies and achieves fully supervised performance requiring $1\\%$ and $8\\%$ annotations of bounding boxes and point clouds, respectively. Source code: https://github.com/Luoyadan/CRB-active-3Ddet.","created":"2023-01-23","meta":{"link":"http://arxiv.org/abs/2301.09249v2","tag":"data-quality"}}
{"title":"Learning to Reject with a Fixed Predictor: Application to Decontextualization","abstract":"We study the problem of classification with a reject option for a fixed predictor, applicable in natural language processing. We introduce a new problem formulation for this scenario, and an algorithm minimizing a new surrogate loss function. We provide a complete theoretical analysis of the surrogate loss function with a strong $H$-consistency guarantee. For evaluation, we choose the decontextualization task, and provide a manually-labelled dataset of $2\\mathord,000$ examples. Our algorithm significantly outperforms the baselines considered, with a $\\sim\\!\\!25\\%$ improvement in coverage when halving the error rate, which is only $\\sim\\!\\! 3 \\%$ away from the theoretical limit.","created":"2023-01-22","meta":{"link":"http://arxiv.org/abs/2301.09044v2","tag":"data-quality"}}
{"title":"System $F^\u03bc_\u03c9$ with Context-free Session Types","abstract":"We study increasingly expressive type systems, from $F^\\mu$ -- an extension of the polymorphic lambda calculus with equirecursive types -- to $F^{\\mu;}_\\omega$ -- the higher-order polymorphic lambda calculus with equirecursive types and context-free session types. Type equivalence is given by a standard bisimulation defined over a novel labelled transition system for types. Our system subsumes the contractive fragment of $F^\\mu_\\omega$ as studied in the literature. Decidability results for type equivalence of the various type languages are obtained from the translation of types into objects of an appropriate computational model: finite-state automata, simple grammars and deterministic pushdown automata. We show that type equivalence is decidable for a significant fragment of the type language. We further propose a message-passing, concurrent functional language equipped with the expressive type language and show that it enjoys preservation and absence of runtime errors for typable processes.","created":"2023-01-20","meta":{"link":"http://arxiv.org/abs/2301.08659v1","tag":"data-quality"}}
{"title":"Unsupervised Light Field Depth Estimation via Multi-view Feature Matching with Occlusion Prediction","abstract":"Depth estimation from light field (LF) images is a fundamental step for some applications. Recently, learning-based methods have achieved higher accuracy and efficiency than the traditional methods. However, it is costly to obtain sufficient depth labels for supervised training. In this paper, we propose an unsupervised framework to estimate depth from LF images. First, we design a disparity estimation network (DispNet) with a coarse-to-fine structure to predict disparity maps from different view combinations by performing multi-view feature matching to learn the correspondences more effectively. As occlusions may cause the violation of photo-consistency, we design an occlusion prediction network (OccNet) to predict the occlusion maps, which are used as the element-wise weights of photometric loss to solve the occlusion issue and assist the disparity learning. With the disparity maps estimated by multiple input combinations, we propose a disparity fusion strategy based on the estimated errors with effective occlusion handling to obtain the final disparity map. Experimental results demonstrate that our method achieves superior performance on both the dense and sparse LF images, and also has better generalization ability to the real-world LF images.","created":"2023-01-20","meta":{"link":"http://arxiv.org/abs/2301.08433v1","tag":"data-quality"}}
{"title":"ETLP: Event-based Three-factor Local Plasticity for online learning with neuromorphic hardware","abstract":"Neuromorphic perception with event-based sensors, asynchronous hardware and spiking neurons is showing promising results for real-time and energy-efficient inference in embedded systems. The next promise of brain-inspired computing is to enable adaptation to changes at the edge with online learning. However, the parallel and distributed architectures of neuromorphic hardware based on co-localized compute and memory imposes locality constraints to the on-chip learning rules. We propose in this work the Event-based Three-factor Local Plasticity (ETLP) rule that uses (1) the pre-synaptic spike trace, (2) the post-synaptic membrane voltage and (3) a third factor in the form of projected labels with no error calculation, that also serve as update triggers. We apply ETLP with feedforward and recurrent spiking neural networks on visual and auditory event-based pattern recognition, and compare it to Back-Propagation Through Time (BPTT) and eProp. We show a competitive performance in accuracy with a clear advantage in the computational complexity for ETLP. We also show that when using local plasticity, threshold adaptation in spiking neurons and a recurrent topology are necessary to learn spatio-temporal patterns with a rich temporal structure. Finally, we provide a proof of concept hardware implementation of ETLP on FPGA to highlight the simplicity of its computational primitives and how they can be mapped into neuromorphic hardware for online learning with low-energy consumption and real-time interaction.","created":"2023-01-19","meta":{"link":"http://arxiv.org/abs/2301.08281v2","tag":"data-quality"}}
{"title":"Adapting Multilingual Speech Representation Model for a New, Underresourced Language through Multilingual Fine-tuning and Continued Pretraining","abstract":"In recent years, neural models learned through self-supervised pretraining on large scale multilingual text or speech data have exhibited promising results for underresourced languages, especially when a relatively large amount of data from related language(s) is available. While the technology has a potential for facilitating tasks carried out in language documentation projects, such as speech transcription, pretraining a multilingual model from scratch for every new language would be highly impractical. We investigate the possibility for adapting an existing multilingual wav2vec 2.0 model for a new language, focusing on actual fieldwork data from a critically endangered tongue: Ainu. Specifically, we (i) examine the feasibility of leveraging data from similar languages also in fine-tuning; (ii) verify whether the model's performance can be improved by further pretraining on target language data. Our results show that continued pretraining is the most effective method to adapt a wav2vec 2.0 model for a new language and leads to considerable reduction in error rates. Furthermore, we find that if a model pretrained on a related speech variety or an unrelated language with similar phonological characteristics is available, multilingual fine-tuning using additional data from that language can have positive impact on speech recognition performance when there is very little labeled data in the target language.","created":"2023-01-18","meta":{"link":"http://arxiv.org/abs/2301.07295v1","tag":"data-quality"}}
{"title":"Cross-domain Unsupervised Reconstruction with Equivariance for Photoacoustic Computed Tomography","abstract":"Accurate image reconstruction is crucial for photoacoustic (PA) computed tomography (PACT). Recently, deep learning has been used to reconstruct the PA image with a supervised scheme, which requires high-quality images as ground truth labels. In practice, there are inevitable trade-offs between cost and performance since the use of more channels is an expensive strategy to access more measurements. Here, we propose a cross-domain unsupervised reconstruction (CDUR) strategy with a pure transformer model, which overcomes the lack of ground truth labels from limited PA measurements. The proposed approach exploits the equivariance of PACT to achieve high performance with a smaller number of channels. We implement a self-supervised reconstruction in a model-based form. Meanwhile, we also leverage the self-supervision to enforce the measurement and image consistency on three partitions of measured PA data, by randomly masking different channels. We find that dynamically masking a high proportion of the channels, e.g., 80%, yields nontrivial self-supervisors in both image and signal domains, which decrease the multiplicity of the pseudo solution to efficiently reconstruct the image from fewer PA measurements with minimum error of the image. Experimental results on in-vivo PACT dataset of mice demonstrate the potential of our unsupervised framework. In addition, our method shows a high performance (0.83 structural similarity index (SSIM) in the extreme sparse case with 13 channels), which is close to that of supervised scheme (0.77 SSIM with 16 channels). On top of all the advantages, our method may be deployed on different trainable models in an end-to-end manner.","created":"2023-01-17","meta":{"link":"http://arxiv.org/abs/2301.06681v1","tag":"data-quality"}}
{"title":"Robust Remote Sensing Scene Classification with Multi-View Voting and Entropy Ranking","abstract":"Deep convolutional neural networks have been widely used in scene classification of remotely sensed images. In this work, we propose a robust learning method for the task that is secure against partially incorrect categorization of images. Specifically, we remove and correct errors in the labels progressively by iterative multi-view voting and entropy ranking. At each time step, we first divide the training data into disjoint parts for separate training and voting. The unanimity in the voting reveals the correctness of the labels, so that we can train a strong model with only the images with unanimous votes. In addition, we adopt entropy as an effective measure for prediction uncertainty, in order to partially recover labeling errors by ranking and selection. We empirically demonstrate the superiority of the proposed method on the WHU-RS19 dataset and the AID dataset.","created":"2023-01-14","meta":{"link":"http://arxiv.org/abs/2301.05858v1","tag":"data-quality"}}
{"title":"Universal Detection of Backdoor Attacks via Density-based Clustering and Centroids Analysis","abstract":"In this paper, we propose a Universal Defence based on Clustering and Centroids Analysis (CCA-UD) against backdoor attacks. The goal of the proposed defence is to reveal whether a Deep Neural Network model is subject to a backdoor attack by inspecting the training dataset. CCA-UD first clusters the samples of the training set by means of density-based clustering. Then, it applies a novel strategy to detect the presence of poisoned clusters. The proposed strategy is based on a general misclassification behaviour obtained when the features of a representative example of the analysed cluster are added to benign samples. The capability of inducing a misclassification error is a general characteristic of poisoned samples, hence the proposed defence is attack-agnostic. This mask a significant difference with respect to existing defences, that, either can defend against only some types of backdoor attacks, e.g., when the attacker corrupts the label of the poisoned samples, or are effective only when some conditions on the poisoning ratios adopted by the attacker or the kind of triggering pattern used by the attacker are satisfied. Experiments carried out on several classification tasks, considering different types of backdoor attacks and triggering patterns, including both local and global triggers, reveal that the proposed method is very effective to defend against backdoor attacks in all the cases, always outperforming the state of the art techniques.","created":"2023-01-11","meta":{"link":"http://arxiv.org/abs/2301.04554v1","tag":"data-quality"}}
{"title":"Reproducibility Signals in Science: A preliminary analysis","abstract":"Reproducibility is an important feature of science; experiments are retested, and analyses are repeated. Trust in the findings increases when consistent results are achieved. Despite the importance of reproducibility, significant work is often involved in these efforts, and some published findings may not be reproducible due to oversights or errors. In this paper, we examine a myriad of features in scholarly articles published in computer science conferences and journals and test how they correlate with reproducibility. We collected data from three different sources that labeled publications as either reproducible or irreproducible and employed statistical significance tests to identify features of those publications that hold clues about reproducibility. We found the readability of the scholarly article and accessibility of the software artifacts through hyperlinks to be strong signals noticeable amongst reproducible scholarly articles.","created":"2023-01-11","meta":{"link":"http://arxiv.org/abs/2301.04369v1","tag":"data-quality"}}
{"title":"Semi-Supervised Learning with Pseudo-Negative Labels for Image Classification","abstract":"Semi-supervised learning frameworks usually adopt mutual learning approaches with multiple submodels to learn from different perspectives. To avoid transferring erroneous pseudo labels between these submodels, a high threshold is usually used to filter out a large number of low-confidence predictions for unlabeled data. However, such filtering can not fully exploit unlabeled data with low prediction confidence. To overcome this problem, in this work, we propose a mutual learning framework based on pseudo-negative labels. Negative labels are those that a corresponding data item does not belong. In each iteration, one submodel generates pseudo-negative labels for each data item, and the other submodel learns from these labels. The role of the two submodels exchanges after each iteration until convergence. By reducing the prediction probability on pseudo-negative labels, the dual model can improve its prediction ability. We also propose a mechanism to select a few pseudo-negative labels to feed into submodels. In the experiments, our framework achieves state-of-the-art results on several main benchmarks. Specifically, with our framework, the error rates of the 13-layer CNN model are 9.35% and 7.94% for CIFAR-10 with 1000 and 4000 labels, respectively. In addition, for the non-augmented MNIST with only 20 labels, the error rate is 0.81% by our framework, which is much smaller than that of other approaches. Our approach also demonstrates a significant performance improvement in domain adaptation.","created":"2023-01-10","meta":{"link":"http://arxiv.org/abs/2301.03976v1","tag":"data-quality"}}
{"title":"FedDebug: Systematic Debugging for Federated Learning Applications","abstract":"In Federated Learning (FL), clients train a model locally and share it with a central aggregator to build a global model. Impermissibility to access client's data and collaborative training makes FL appealing for applications with data-privacy concerns such as medical imaging. However, these FL characteristics pose unprecedented challenges for debugging. When a global model's performance deteriorates, finding the round and the clients responsible is a major pain point. Developers resort to trial-and-error debugging with subsets of clients, hoping to increase the accuracy or let future FL rounds retune the model, which are time-consuming and costly.   We design a systematic fault localization framework, FedDebug, that advances the FL debugging on two novel fronts. First, FedDebug enables interactive debugging of realtime collaborative training in FL by leveraging record and replay techniques to construct a simulation that mirrors live FL. FedDebug's {\\em breakpoint} can help inspect an FL state (round, client, and global model) and seamlessly move between rounds and clients' models, enabling a fine-grained step-by-step inspection. Second, FedDebug automatically identifies the client responsible for lowering global model's performance without any testing data and labels--both are essential for existing debugging techniques. FedDebug's strengths come from adapting differential testing in conjunction with neurons activations to determine the precise client deviating from normal behavior. FedDebug achieves 100\\% to find a single client and 90.3\\% accuracy to find multiple faulty clients. FedDebug's interactive debugging incurs 1.2\\% overhead during training, while it localizes a faulty client in only 2.1\\% of a round's training time. With FedDebug, we bring effective debugging practices to federated learning, improving the quality and productivity of FL application developers.","created":"2023-01-09","meta":{"link":"http://arxiv.org/abs/2301.03553v1","tag":"data-quality"}}
{"title":"Determination of the top-quark mass from top-quark pair events with the matrix element method at next-to-leading order: Potential and prospects","abstract":"In 2004 the matrix element method was used in a pioneering work by the Tevatron experiment D0 to determine the top-quark mass from a handful of events. Since then the method has been matured into a powerful analysis tool. While the first applications were restricted to leading-order accuracy, in the meantime also the extension to next-to-leading order (NLO) accuracy has been studied. In this article we explore the potential of the matrix element method at NLO to determine the top-quark mass using events with pair-produced top quarks. We simulate a toy experiment by generating unweighted events with a fixed input mass and apply the matrix element method to construct an estimator for the top-quark mass. Two different setups are investigated: unweighted events obtained from the fixed-order cross section at NLO accuracy as well as events obtained using POWHEG matched to a parton shower. The latter lead to a more realistic simulation and allow to study the impact of higher-order corrections as well as the robustness of the approach. We find that the matrix element method in NLO accuracy leads to a significant reduction of the theoretical uncertainties compared to leading order. In view of the high luminosity phase of the LHC, this observation is especially relevant in analyses which are no longer dominated by statistical uncertainties.","created":"2023-01-09","meta":{"link":"http://arxiv.org/abs/2301.03280v2","tag":"data-quality"}}
{"title":"Mimicking non-ideal instrument behavior for hologram processing using neural style translation","abstract":"Holographic cloud probes provide unprecedented information on cloud particle density, size and position. Each laser shot captures particles within a large volume, where images can be computationally refocused to determine particle size and shape. However, processing these holograms, either with standard methods or with machine learning (ML) models, requires considerable computational resources, time and occasional human intervention. ML models are trained on simulated holograms obtained from the physical model of the probe since real holograms have no absolute truth labels. Using another processing method to produce labels would be subject to errors that the ML model would subsequently inherit. Models perform well on real holograms only when image corruption is performed on the simulated images during training, thereby mimicking non-ideal conditions in the actual probe (Schreck et. al, 2022). Optimizing image corruption requires a cumbersome manual labeling effort.   Here we demonstrate the application of the neural style translation approach (Gatys et. al, 2016) to the simulated holograms. With a pre-trained convolutional neural network (VGG-19), the simulated holograms are ``stylized'' to resemble the real ones obtained from the probe, while at the same time preserving the simulated image ``content'' (e.g. the particle locations and sizes). Two image similarity metrics concur that the stylized images are more like real holograms than the synthetic ones. With an ML model trained to predict particle locations and shapes on the stylized data sets, we observed comparable performance on both simulated and real holograms, obviating the need to perform manual labeling. The described approach is not specific to hologram images and could be applied in other domains for capturing noise and imperfections in observational instruments to make simulated data more like real world observations.","created":"2023-01-07","meta":{"link":"http://arxiv.org/abs/2301.02757v1","tag":"data-quality"}}
{"title":"Deep Learning for Short-Latency Epileptic Seizure Detection with Probabilistic Classification","abstract":"In this manuscript, we propose a novel deep learning (DL)-based framework intended for obtaining short latency in real-time electroencephalogram-based epileptic seizure detection using multiscale 3D convolutional neural networks. We pioneer converting seizure detection task from traditional binary classification of samples from ictal and interictal periods to probabilistic classification of samples from interictal, ictal, and crossing periods. We introduce a crossing period from seizure-oriented EEG recording and propose a labelling rule using soft-label for samples from the crossing period to build a probabilistic classification task. A novel multiscale short-time Fourier transform feature extraction method and 3D convolution neural network architecture are proposed to accurately capture predictive probabilities of samples. Furthermore, we also propose rectified weighting strategy to enhance predictive probabilities, and accumulative decision-making rule to achieve short detection latency. We implement leave-one-seizure-out cross validation on two prevalent datasets -- CHB-MIT scalp EEG dataset and SWEC-ETHZ intracranial EEG dataset. Eventually, the proposed algorithm achieved 94 out of 99 seizures detected during the crossing period, averaged 14.84% rectified predictive ictal probability (RPIP) errors of crossing samples, 2.3 s detection latency, 0.32/h false detection rate on CHB-MIT dataset, meanwhile 84 out of 89 detected seizures, 16.17% RPIP errors, 4.7 s detection latency, and 0.75/h FDR are achieved on SWEC-ETHZ dataset. The obtained detection latencies are at least 50% faster than state-of-the-art results reported in previous studies.","created":"2023-01-04","meta":{"link":"http://arxiv.org/abs/2301.03465v1","tag":"data-quality"}}
{"title":"Audio-Visual Efficient Conformer for Robust Speech Recognition","abstract":"End-to-end Automatic Speech Recognition (ASR) systems based on neural networks have seen large improvements in recent years. The availability of large scale hand-labeled datasets and sufficient computing resources made it possible to train powerful deep neural networks, reaching very low Word Error Rate (WER) on academic benchmarks. However, despite impressive performance on clean audio samples, a drop of performance is often observed on noisy speech. In this work, we propose to improve the noise robustness of the recently proposed Efficient Conformer Connectionist Temporal Classification (CTC)-based architecture by processing both audio and visual modalities. We improve previous lip reading methods using an Efficient Conformer back-end on top of a ResNet-18 visual front-end and by adding intermediate CTC losses between blocks. We condition intermediate block features on early predictions using Inter CTC residual modules to relax the conditional independence assumption of CTC-based models. We also replace the Efficient Conformer grouped attention by a more efficient and simpler attention mechanism that we call patch attention. We experiment with publicly available Lip Reading Sentences 2 (LRS2) and Lip Reading Sentences 3 (LRS3) datasets. Our experiments show that using audio and visual modalities allows to better recognize speech in the presence of environmental noise and significantly accelerate training, reaching lower WER with 4 times less training steps. Our Audio-Visual Efficient Conformer (AVEC) model achieves state-of-the-art performance, reaching WER of 2.3% and 1.8% on LRS2 and LRS3 test sets. Code and pretrained models are available at https://github.com/burchim/AVEC.","created":"2023-01-04","meta":{"link":"http://arxiv.org/abs/2301.01456v1","tag":"data-quality"}}
{"title":"Unsupervised Multivariate Time-Series Transformers for Seizure Identification on EEG","abstract":"Epilepsy is one of the most common neurological disorders, typically observed via seizure episodes. Epileptic seizures are commonly monitored through electroencephalogram (EEG) recordings due to their routine and low expense collection. The stochastic nature of EEG makes seizure identification via manual inspections performed by highly-trained experts a tedious endeavor, motivating the use of automated identification. The literature on automated identification focuses mostly on supervised learning methods requiring expert labels of EEG segments that contain seizures, which are difficult to obtain. Motivated by these observations, we pose seizure identification as an unsupervised anomaly detection problem. To this end, we employ the first unsupervised transformer-based model for seizure identification on raw EEG. We train an autoencoder involving a transformer encoder via an unsupervised loss function, incorporating a novel masking strategy uniquely designed for multivariate time-series data such as EEG. Training employs EEG recordings that do not contain any seizures, while seizures are identified with respect to reconstruction errors at inference time. We evaluate our method on three publicly available benchmark EEG datasets for distinguishing seizure vs. non-seizure windows. Our method leads to significantly better seizure identification performance than supervised learning counterparts, by up to 16% recall, 9% accuracy, and 9% Area under the Receiver Operating Characteristics Curve (AUC), establishing particular benefits on highly imbalanced data. Through accurate seizure identification, our method could facilitate widely accessible and early detection of epilepsy development, without needing expensive label collection or manual feature extraction.","created":"2023-01-03","meta":{"link":"http://arxiv.org/abs/2301.03470v1","tag":"data-quality"}}
{"title":"Digital Twin-Enabled Domain Adaptation for Zero-Touch UAV Networks: Survey and Challenges","abstract":"In existing wireless networks, the control programs have been designed manually and for certain predefined scenarios. This process is complicated and error-prone, and the resulting control programs are not resilient to disruptive changes. Data-driven control based on Artificial Intelligence and Machine Learning (AI/ML) has been envisioned as a key technique to automate the modeling, optimization and control of complex wireless systems. However, existing AI/ML techniques rely on sufficient well-labeled data and may suffer from slow convergence and poor generalizability. In this article, focusing on digital twin-assisted wireless unmanned aerial vehicle (UAV) systems, we provide a survey of emerging techniques that can enable fast-converging data-driven control of wireless systems with enhanced generalization capability to new environments. These include SLAM-based sensing and network softwarization for digital twin construction, robust reinforcement learning and system identification for domain adaptation, and testing facility sharing and federation. The corresponding research opportunities are also discussed.","created":"2022-12-31","meta":{"link":"http://arxiv.org/abs/2301.03359v1","tag":"data-quality"}}
{"title":"Tracking Passengers and Baggage Items using Multiple Overhead Cameras at Security Checkpoints","abstract":"We introduce a novel framework to track multiple objects in overhead camera videos for airport checkpoint security scenarios where targets correspond to passengers and their baggage items. We propose a Self-Supervised Learning (SSL) technique to provide the model information about instance segmentation uncertainty from overhead images. Our SSL approach improves object detection by employing a test-time data augmentation and a regression-based, rotation-invariant pseudo-label refinement technique. Our pseudo-label generation method provides multiple geometrically-transformed images as inputs to a Convolutional Neural Network (CNN), regresses the augmented detections generated by the network to reduce localization errors, and then clusters them using the mean-shift algorithm. The self-supervised detector model is used in a single-camera tracking algorithm to generate temporal identifiers for the targets. Our method also incorporates a multi-view trajectory association mechanism to maintain consistent temporal identifiers as passengers travel across camera views. An evaluation of detection, tracking, and association performances on videos obtained from multiple overhead cameras in a realistic airport checkpoint environment demonstrates the effectiveness of the proposed approach. Our results show that self-supervision improves object detection accuracy by up to $42\\%$ without increasing the inference time of the model. Our multi-camera association method achieves up to $89\\%$ multi-object tracking accuracy with an average computation time of less than $15$ ms.","created":"2022-12-31","meta":{"link":"http://arxiv.org/abs/2301.00190v1","tag":"data-quality"}}
{"title":"Unlearnable Clusters: Towards Label-agnostic Unlearnable Examples","abstract":"There is a growing interest in developing unlearnable examples (UEs) against visual privacy leaks on the Internet. UEs are training samples added with invisible but unlearnable noise, which have been found can prevent unauthorized training of machine learning models. UEs typically are generated via a bilevel optimization framework with a surrogate model to remove (minimize) errors from the original samples, and then applied to protect the data against unknown target models. However, existing UE generation methods all rely on an ideal assumption called label-consistency, where the hackers and protectors are assumed to hold the same label for a given sample. In this work, we propose and promote a more practical label-agnostic setting, where the hackers may exploit the protected data quite differently from the protectors. E.g., a m-class unlearnable dataset held by the protector may be exploited by the hacker as a n-class dataset. Existing UE generation methods are rendered ineffective in this challenging setting. To tackle this challenge, we present a novel technique called Unlearnable Clusters (UCs) to generate label-agnostic unlearnable examples with cluster-wise perturbations. Furthermore, we propose to leverage VisionandLanguage Pre-trained Models (VLPMs) like CLIP as the surrogate model to improve the transferability of the crafted UCs to diverse domains. We empirically verify the effectiveness of our proposed approach under a variety of settings with different datasets, target models, and even commercial platforms Microsoft Azure and Baidu PaddlePaddle. Code is available at \\url{https://github.com/jiamingzhang94/Unlearnable-Clusters}.","created":"2022-12-31","meta":{"link":"http://arxiv.org/abs/2301.01217v4","tag":"data-quality"}}
{"title":"An Analysis of Attention via the Lens of Exchangeability and Latent Variable Models","abstract":"With the attention mechanism, transformers achieve significant empirical successes. Despite the intuitive understanding that transformers perform relational inference over long sequences to produce desirable representations, we lack a rigorous theory on how the attention mechanism achieves it. In particular, several intriguing questions remain open: (a) What makes a desirable representation? (b) How does the attention mechanism infer the desirable representation within the forward pass? (c) How does a pretraining procedure learn to infer the desirable representation through the backward pass?   We observe that, as is the case in BERT and ViT, input tokens are often exchangeable since they already include positional encodings. The notion of exchangeability induces a latent variable model that is invariant to input sizes, which enables our theoretical analysis.   - To answer (a) on representation, we establish the existence of a sufficient and minimal representation of input tokens. In particular, such a representation instantiates the posterior distribution of the latent variable given input tokens, which plays a central role in predicting output labels and solving downstream tasks.   - To answer (b) on inference, we prove that attention with the desired parameter infers the latent posterior up to an approximation error, which is decreasing in input sizes. In detail, we quantify how attention approximates the conditional mean of the value given the key, which characterizes how it performs relational inference over long sequences.   - To answer (c) on learning, we prove that both supervised and self-supervised objectives allow empirical risk minimization to learn the desired parameter up to a generalization error, which is independent of input sizes. Particularly, in the self-supervised setting, we identify a condition number that is pivotal to solving downstream tasks.","created":"2022-12-30","meta":{"link":"http://arxiv.org/abs/2212.14852v2","tag":"data-quality"}}
{"title":"First Demonstration of 512-Color Shift Keying Signal Demodulation Using Neural Equalization for Optical Camera Communication","abstract":"This paper experimentally demonstrates 512 color shift keying (CSK) signal transmission for optical camera communication (OCC). We achieved error-free operation with a CMOS image sensor module and a multi-label classification neural network-based equalizer.","created":"2022-12-29","meta":{"link":"http://arxiv.org/abs/2301.01599v1","tag":"data-quality"}}
{"title":"AER: Auto-Encoder with Regression for Time Series Anomaly Detection","abstract":"Anomaly detection on time series data is increasingly common across various industrial domains that monitor metrics in order to prevent potential accidents and economic losses. However, a scarcity of labeled data and ambiguous definitions of anomalies can complicate these efforts. Recent unsupervised machine learning methods have made remarkable progress in tackling this problem using either single-timestamp predictions or time series reconstructions. While traditionally considered separately, these methods are not mutually exclusive and can offer complementary perspectives on anomaly detection. This paper first highlights the successes and limitations of prediction-based and reconstruction-based methods with visualized time series signals and anomaly scores. We then propose AER (Auto-encoder with Regression), a joint model that combines a vanilla auto-encoder and an LSTM regressor to incorporate the successes and address the limitations of each method. Our model can produce bi-directional predictions while simultaneously reconstructing the original time series by optimizing a joint objective function. Furthermore, we propose several ways of combining the prediction and reconstruction errors through a series of ablation studies. Finally, we compare the performance of the AER architecture against two prediction-based methods and three reconstruction-based methods on 12 well-known univariate time series datasets from NASA, Yahoo, Numenta, and UCR. The results show that AER has the highest averaged F1 score across all datasets (a 23.5% improvement compared to ARIMA) while retaining a runtime similar to its vanilla auto-encoder and regressor components. Our model is available in Orion, an open-source benchmarking tool for time series anomaly detection.","created":"2022-12-27","meta":{"link":"http://arxiv.org/abs/2212.13558v1","tag":"data-quality"}}
{"title":"Spacecraft Pose Estimation Based on Unsupervised Domain Adaptation and on a 3D-Guided Loss Combination","abstract":"Spacecraft pose estimation is a key task to enable space missions in which two spacecrafts must navigate around each other. Current state-of-the-art algorithms for pose estimation employ data-driven techniques. However, there is an absence of real training data for spacecraft imaged in space conditions due to the costs and difficulties associated with the space environment. This has motivated the introduction of 3D data simulators, solving the issue of data availability but introducing a large gap between the training (source) and test (target) domains. We explore a method that incorporates 3D structure into the spacecraft pose estimation pipeline to provide robustness to intensity domain shift and we present an algorithm for unsupervised domain adaptation with robust pseudo-labelling. Our solution has ranked second in the two categories of the 2021 Pose Estimation Challenge organised by the European Space Agency and the Stanford University, achieving the lowest average error over the two categories.","created":"2022-12-27","meta":{"link":"http://arxiv.org/abs/2212.13415v1","tag":"data-quality"}}
{"title":"Skit-S2I: An Indian Accented Speech to Intent dataset","abstract":"Conventional conversation assistants extract text transcripts from the speech signal using automatic speech recognition (ASR) and then predict intent from the transcriptions. Using end-to-end spoken language understanding (SLU), the intents of the speaker are predicted directly from the speech signal without requiring intermediate text transcripts. As a result, the model can optimize directly for intent classification and avoid cascading errors from ASR. The end-to-end SLU system also helps in reducing the latency of the intent prediction model. Although many datasets are available publicly for text-to-intent tasks, the availability of labeled speech-to-intent datasets is limited, and there are no datasets available in the Indian accent. In this paper, we release the Skit-S2I dataset, the first publicly available Indian-accented SLU dataset in the banking domain in a conversational tonality. We experiment with multiple baselines, compare different pretrained speech encoder's representations, and find that SSL pretrained representations perform slightly better than ASR pretrained representations lacking prosodic features for speech-to-intent classification. The dataset and baseline code is available at \\url{https://github.com/skit-ai/speech-to-intent-dataset}","created":"2022-12-26","meta":{"link":"http://arxiv.org/abs/2212.13015v1","tag":"data-quality"}}
{"title":"A Labelled Sample Compression Scheme of Size at Most Quadratic in the VC Dimension","abstract":"This paper presents a construction of a proper and stable labelled sample compression scheme of size $O(\\VCD^2)$ for any finite concept class, where $\\VCD$ denotes the Vapnik-Chervonenkis Dimension. The construction is based on a well-known model of machine teaching, referred to as recursive teaching dimension. This substantially improves on the currently best known bound on the size of sample compression schemes (due to Moran and Yehudayoff), which is exponential in $\\VCD$. The long-standing open question whether the smallest size of a sample compression scheme is in $O(\\VCD)$ remains unresolved, but our results show that research on machine teaching is a promising avenue for the study of this open problem.   As further evidence of the strong connections between machine teaching and sample compression, we prove that the model of no-clash teaching, introduced by Kirkpatrick et al., can be used to define a non-trivial lower bound on the size of stable sample compression schemes.","created":"2022-12-24","meta":{"link":"http://arxiv.org/abs/2212.12631v2","tag":"data-quality"}}
{"title":"Benchmark for Uncertainty & Robustness in Self-Supervised Learning","abstract":"Self-Supervised Learning (SSL) is crucial for real-world applications, especially in data-hungry domains such as healthcare and self-driving cars. In addition to a lack of labeled data, these applications also suffer from distributional shifts. Therefore, an SSL method should provide robust generalization and uncertainty estimation in the test dataset to be considered a reliable model in such high-stakes domains. However, existing approaches often focus on generalization, without evaluating the model's uncertainty. The ability to compare SSL techniques for improving these estimates is therefore critical for research on the reliability of self-supervision models. In this paper, we explore variants of SSL methods, including Jigsaw Puzzles, Context, Rotation, Geometric Transformations Prediction for vision, as well as BERT and GPT for language tasks. We train SSL in auxiliary learning for vision and pre-training for language model, then evaluate the generalization (in-out classification accuracy) and uncertainty (expected calibration error) across different distribution covariate shift datasets, including MNIST-C, CIFAR-10-C, CIFAR-10.1, and MNLI. Our goal is to create a benchmark with outputs from experiments, providing a starting point for new SSL methods in Reliable Machine Learning. All source code to reproduce results is available at https://github.com/hamanhbui/reliable_ssl_baselines.","created":"2022-12-23","meta":{"link":"http://arxiv.org/abs/2212.12411v1","tag":"data-quality"}}
{"title":"Alignment Entropy Regularization","abstract":"Existing training criteria in automatic speech recognition(ASR) permit the model to freely explore more than one time alignments between the feature and label sequences. In this paper, we use entropy to measure a model's uncertainty, i.e. how it chooses to distribute the probability mass over the set of allowed alignments. Furthermore, we evaluate the effect of entropy regularization in encouraging the model to distribute the probability mass only on a smaller subset of allowed alignments. Experiments show that entropy regularization enables a much simpler decoding method without sacrificing word error rate, and provides better time alignment quality.","created":"2022-12-22","meta":{"link":"http://arxiv.org/abs/2212.12442v1","tag":"data-quality"}}
{"title":"End-to-End Automatic Speech Recognition model for the Sudanese Dialect","abstract":"Designing a natural voice interface rely mostly on Speech recognition for interaction between human and their modern digital life equipment. In addition, speech recognition narrows the gap between monolingual individuals to better exchange communication. However, the field lacks wide support for several universal languages and their dialects, while most of the daily conversations are carried out using them. This paper comes to inspect the viability of designing an Automatic Speech Recognition model for the Sudanese dialect, which is one of the Arabic Language dialects, and its complexity is a product of historical and social conditions unique to its speakers. This condition is reflected in both the form and content of the dialect, so this paper gives an overview of the Sudanese dialect and the tasks of collecting represented resources and pre-processing performed to construct a modest dataset to overcome the lack of annotated data. Also proposed end- to-end speech recognition model, the design of the model was formed using Convolution Neural Networks. The Sudanese dialect dataset would be a stepping stone to enable future Natural Language Processing research targeting the dialect. The designed model provided some insights into the current recognition task and reached an average Label Error Rate of 73.67%.","created":"2022-12-21","meta":{"link":"http://arxiv.org/abs/2212.10826v1","tag":"data-quality"}}
{"title":"How Does Beam Search improve Span-Level Confidence Estimation in Generative Sequence Labeling?","abstract":"Text-to-text generation models have increasingly become the go-to solution for a wide variety of sequence labeling tasks (e.g., entity extraction and dialog slot filling). While most research has focused on the labeling accuracy, a key aspect -- of vital practical importance -- has slipped through the cracks: understanding model confidence. More specifically, we lack a principled understanding of how to reliably gauge the confidence of a model in its predictions for each labeled span. This paper aims to provide some empirical insights on estimating model confidence for generative sequence labeling. Most notably, we find that simply using the decoder's output probabilities is not the best in realizing well-calibrated confidence estimates. As verified over six public datasets of different tasks, we show that our proposed approach -- which leverages statistics from top-$k$ predictions by a beam search -- significantly reduces calibration errors of the predictions of a generative sequence labeling model.","created":"2022-12-21","meta":{"link":"http://arxiv.org/abs/2212.10767v1","tag":"data-quality"}}
{"title":"Extrinsic Evaluation of Machine Translation Metrics","abstract":"Automatic machine translation (MT) metrics are widely used to distinguish the translation qualities of machine translation systems across relatively large test sets (system-level evaluation). However, it is unclear if automatic metrics are reliable at distinguishing good translations from bad translations at the sentence level (segment-level evaluation). In this paper, we investigate how useful MT metrics are at detecting the success of a machine translation component when placed in a larger platform with a downstream task. We evaluate the segment-level performance of the most widely used MT metrics (chrF, COMET, BERTScore, etc.) on three downstream cross-lingual tasks (dialogue state tracking, question answering, and semantic parsing). For each task, we only have access to a monolingual task-specific model. We calculate the correlation between the metric's ability to predict a good/bad translation with the success/failure on the final task for the Translate-Test setup. Our experiments demonstrate that all metrics exhibit negligible correlation with the extrinsic evaluation of the downstream outcomes. We also find that the scores provided by neural metrics are not interpretable mostly because of undefined ranges. Our analysis suggests that future MT metrics be designed to produce error labels rather than scores to facilitate extrinsic evaluation.","created":"2022-12-20","meta":{"link":"http://arxiv.org/abs/2212.10297v1","tag":"data-quality"}}
{"title":"In and Out-of-Domain Text Adversarial Robustness via Label Smoothing","abstract":"Recently it has been shown that state-of-the-art NLP models are vulnerable to adversarial attacks, where the predictions of a model can be drastically altered by slight modifications to the input (such as synonym substitutions). While several defense techniques have been proposed, and adapted, to the discrete nature of text adversarial attacks, the benefits of general-purpose regularization methods such as label smoothing for language models, have not been studied. In this paper, we study the adversarial robustness provided by various label smoothing strategies in foundational models for diverse NLP tasks in both in-domain and out-of-domain settings. Our experiments show that label smoothing significantly improves adversarial robustness in pre-trained models like BERT, against various popular attacks. We also analyze the relationship between prediction confidence and robustness, showing that label smoothing reduces over-confident errors on adversarial examples.","created":"2022-12-20","meta":{"link":"http://arxiv.org/abs/2212.10258v1","tag":"data-quality"}}
{"title":"Lightweight integration of 3D features to improve 2D image segmentation","abstract":"Scene understanding is a major challenge of today's computer vision. Center to this task is image segmentation, since scenes are often provided as a set of pictures. Nowadays, many such datasets also provide 3D geometry information given as a 3D point cloud acquired by a laser scanner or a depth camera. To exploit this geometric information, many current approaches rely on both a 2D loss and 3D loss, requiring not only 2D per pixel labels but also 3D per point labels. However obtaining a 3D groundtruth is challenging, time-consuming and error-prone. In this paper, we show that image segmentation can benefit from 3D geometric information without requiring any 3D groundtruth, by training the geometric feature extraction with a 2D segmentation loss in an end-to-end fashion. Our method starts by extracting a map of 3D features directly from the point cloud by using a lightweight and simple 3D encoder neural network. The 3D feature map is then used as an additional input to a classical image segmentation network. During training, the 3D features extraction is optimized for the segmentation task by back-propagation through the entire pipeline. Our method exhibits state-of-the-art performance with much lighter input dataset requirements, since no 3D groundtruth is required.","created":"2022-12-16","meta":{"link":"http://arxiv.org/abs/2212.08334v1","tag":"data-quality"}}
{"title":"Text-to-speech synthesis based on latent variable conversion using diffusion probabilistic model and variational autoencoder","abstract":"Text-to-speech synthesis (TTS) is a task to convert texts into speech. Two of the factors that have been driving TTS are the advancements of probabilistic models and latent representation learning. We propose a TTS method based on latent variable conversion using a diffusion probabilistic model and the variational autoencoder (VAE). In our TTS method, we use a waveform model based on VAE, a diffusion model that predicts the distribution of latent variables in the waveform model from texts, and an alignment model that learns alignments between the text and speech latent sequences. Our method integrates diffusion with VAE by modeling both mean and variance parameters with diffusion, where the target distribution is determined by approximation from VAE. This latent variable conversion framework potentially enables us to flexibly incorporate various latent feature extractors. Our experiments show that our method is robust to linguistic labels with poor orthography and alignment errors.","created":"2022-12-16","meta":{"link":"http://arxiv.org/abs/2212.08329v1","tag":"data-quality"}}
{"title":"Ring That Bell: A Corpus and Method for Multimodal Metaphor Detection in Videos","abstract":"We present the first openly available multimodal metaphor annotated corpus. The corpus consists of videos including audio and subtitles that have been annotated by experts. Furthermore, we present a method for detecting metaphors in the new dataset based on the textual content of the videos. The method achieves a high F1-score (62\\%) for metaphorical labels. We also experiment with other modalities and multimodal methods; however, these methods did not out-perform the text-based model. In our error analysis, we do identify that there are cases where video could help in disambiguating metaphors, however, the visual cues are too subtle for our model to capture. The data is available on Zenodo.","created":"2022-12-15","meta":{"link":"http://arxiv.org/abs/2301.01134v1","tag":"data-quality"}}
{"title":"Automatic vehicle trajectory data reconstruction at scale","abstract":"Vehicle trajectory data has received increasing research attention over the past decades. With the technological sensing improvements such as high-resolution video cameras, in-vehicle radars and lidars, abundant individual and contextual traffic data is now available. However, though the data quantity is massive, it is by itself of limited utility for traffic research because of noise and systematic sensing errors, thus necessitates proper processing to ensure data quality. We draw particular attention to extracting high-resolution vehicle trajectory data from video cameras as traffic monitoring cameras are becoming increasingly ubiquitous. We explore methods for automatic trajectory data reconciliation, given \"raw\" vehicle detection and tracking information from automatic video processing algorithms. We propose a pipeline including a) an online data association algorithm to match fragments that are associated to the same object (vehicle), which is formulated as a min-cost network flow problem of a graph, and b) a trajectory reconciliation method formulated as a quadratic program to enhance raw detection data. The pipeline leverages vehicle dynamics and physical constraints to associate tracked objects when they become fragmented, remove measurement noise on trajectories and impute missing data due to fragmentations. The accuracy is benchmarked on a sample of manually-labeled data, which shows that the reconciled trajectories improve the accuracy on all the tested input data for a wide range of measures. An online version of the reconciliation pipeline is implemented and will be applied in a continuous video processing system running on a camera network covering a 4-mile stretch of Interstate-24 near Nashville, Tennessee.","created":"2022-12-15","meta":{"link":"http://arxiv.org/abs/2212.07907v1","tag":"data-quality"}}
{"title":"The Complexity of the Shapley Value for Regular Path Queries","abstract":"A path query extracts vertex tuples from a labeled graph, based on the words that are formed by the paths connecting the vertices. We study the computational complexity of measuring the contribution of edges and vertices to an answer to a path query, focusing on the class of conjunctive regular path queries. To measure this contribution, we adopt the traditional Shapley value from cooperative game theory. This value has been recently proposed and studied in the context of relational database queries and has uses in a plethora of other domains.   We first study the contribution of edges and show that the exact Shapley value is almost always hard to compute. Specifically, it is #P-hard to calculate the contribution of an edge whenever at least one (non-redundant) conjunct allows for a word of length three or more. In the case of regular path queries (i.e., no conjunction), the problem is tractable if the query has only words of length at most two; hence, this property fully characterizes the tractability of the problem. On the other hand, if we allow for an approximation error, then it is straightforward to obtain an efficient scheme (FPRAS) for an additive approximation. Yet, a multiplicative approximation is harder to obtain. We establish that in the case of conjunctive regular path queries, a multiplicative approximation of the Shapley value of an edge can be computed in polynomial time if and only if all query atoms are finite languages (assuming non-redundancy and conventional complexity limitations). We also study the analogous situation where we wish to determine the contribution of a vertex, rather than an edge, and establish complexity results of similar nature.","created":"2022-12-15","meta":{"link":"http://arxiv.org/abs/2212.07720v1","tag":"data-quality"}}
{"title":"Deep leakage from gradients","abstract":"With the development of artificial intelligence technology, Federated Learning (FL) model has been widely used in many industries for its high efficiency and confidentiality. Some researchers have explored its confidentiality and designed some algorithms to attack training data sets, but these algorithms all have their own limitations. Therefore, most people still believe that local machine learning gradient information is safe and reliable. In this paper, an algorithm based on gradient features is designed to attack the federated learning model in order to attract more attention to the security of federated learning systems. In federated learning system, gradient contains little information compared with the original training data set, but this project intends to restore the original training image data through gradient information. Convolutional Neural Network (CNN) has excellent performance in image processing. Therefore, the federated learning model of this project is equipped with Convolutional Neural Network structure, and the model is trained by using image data sets. The algorithm calculates the virtual gradient by generating virtual image labels. Then the virtual gradient is matched with the real gradient to restore the original image. This attack algorithm is written in Python language, uses cat and dog classification Kaggle data sets, and gradually extends from the full connection layer to the convolution layer, thus improving the universality. At present, the average squared error between the data recovered by this algorithm and the original image information is approximately 5, and the vast majority of images can be completely restored according to the gradient information given, indicating that the gradient of federated learning system is not absolutely safe and reliable.","created":"2022-12-15","meta":{"link":"http://arxiv.org/abs/2301.02621v1","tag":"data-quality"}}
{"title":"Sequential Labelling and DNABERT For Splice Site Prediction in Homo Sapiens DNA","abstract":"Genome sequencing technology has improved significantly in few last years and resulted in abundance genetic data. Artificial intelligence has been employed to analyze genetic data in response to its sheer size and variability. Gene prediction on single DNA has been conducted using various deep learning architectures to discover splice sites and therefore discover intron and exon region. Recent predictions are carried out with models trained on sequence with fixed splice site location which eliminates possibility of multiple splice sites existence in single sequence. This paper proposes sequential labelling to predict splice sites regardless their position in sequence. Sequential labelling is carried out on DNA to determine intron and exon region and thus discover splice sites. Sequential labelling models used are based on pretrained DNABERT-3 which has been trained on human genome. Both fine-tuning and feature-based approach are tested. Proposed model is benchmarked against latest sequential labelling model designed for mutation type and location prediction. While achieving high F1 scores on validation data, both baseline and proposed model perform poorly on test data. Error and test results analysis reveal that model experience overfitting and therefore, model is deemed not suitable for splice site prediction.","created":"2022-12-15","meta":{"link":"http://arxiv.org/abs/2212.07638v2","tag":"data-quality"}}
{"title":"Edema Estimation From Facial Images Taken Before and After Dialysis via Contrastive Multi-Patient Pre-Training","abstract":"Edema is a common symptom of kidney disease, and quantitative measurement of edema is desired. This paper presents a method to estimate the degree of edema from facial images taken before and after dialysis of renal failure patients. As tasks to estimate the degree of edema, we perform pre- and post-dialysis classification and body weight prediction. We develop a multi-patient pre-training framework for acquiring knowledge of edema and transfer the pre-trained model to a model for each patient. For effective pre-training, we propose a novel contrastive representation learning, called weight-aware supervised momentum contrast (WeightSupMoCo). WeightSupMoCo aims to make feature representations of facial images closer in similarity of patient weight when the pre- and post-dialysis labels are the same. Experimental results show that our pre-training approach improves the accuracy of pre- and post-dialysis classification by 15.1% and reduces the mean absolute error of weight prediction by 0.243 kg compared with training from scratch. The proposed method accurately estimate the degree of edema from facial images; our edema estimation system could thus be beneficial to dialysis patients.","created":"2022-12-15","meta":{"link":"http://arxiv.org/abs/2212.07582v1","tag":"data-quality"}}
{"title":"Man-recon: manifold learning for reconstruction with deep autoencoder for smart seismic interpretation","abstract":"Deep learning can extract rich data representations if provided sufficient quantities of labeled training data. For many tasks however, annotating data has significant costs in terms of time and money, owing to the high standards of subject matter expertise required, for example in medical and geophysical image interpretation tasks. Active Learning can identify the most informative training examples for the interpreter to train, leading to higher efficiency. We propose an Active learning method based on jointly learning representations for supervised and unsupervised tasks. The learned manifold structure is later utilized to identify informative training samples most dissimilar from the learned manifold from the error profiles on the unsupervised task. We verify the efficiency of the proposed method on a seismic facies segmentation dataset from the Netherlands F3 block survey, significantly outperforming contemporary methods to achieve the highest mean Intersection-Over-Union value of 0.773.","created":"2022-12-15","meta":{"link":"http://arxiv.org/abs/2212.07568v1","tag":"data-quality"}}
{"title":"Despite \"super-human\" performance, current LLMs are unsuited for decisions about ethics and safety","abstract":"Large language models (LLMs) have exploded in popularity in the past few years and have achieved undeniably impressive results on benchmarks as varied as question answering and text summarization. We provide a simple new prompting strategy that leads to yet another supposedly \"super-human\" result, this time outperforming humans at common sense ethical reasoning (as measured by accuracy on a subset of the ETHICS dataset). Unfortunately, we find that relying on average performance to judge capabilities can be highly misleading. LLM errors differ systematically from human errors in ways that make it easy to craft adversarial examples, or even perturb existing examples to flip the output label. We also observe signs of inverse scaling with model size on some examples, and show that prompting models to \"explain their reasoning\" often leads to alarming justifications of unethical actions. Our results highlight how human-like performance does not necessarily imply human-like understanding or reasoning.","created":"2022-12-13","meta":{"link":"http://arxiv.org/abs/2212.06295v1","tag":"data-quality"}}
{"title":"SRoUDA: Meta Self-training for Robust Unsupervised Domain Adaptation","abstract":"As acquiring manual labels on data could be costly, unsupervised domain adaptation (UDA), which transfers knowledge learned from a rich-label dataset to the unlabeled target dataset, is gaining increasing popularity. While extensive studies have been devoted to improving the model accuracy on target domain, an important issue of model robustness is neglected. To make things worse, conventional adversarial training (AT) methods for improving model robustness are inapplicable under UDA scenario since they train models on adversarial examples that are generated by supervised loss function. In this paper, we present a new meta self-training pipeline, named SRoUDA, for improving adversarial robustness of UDA models. Based on self-training paradigm, SRoUDA starts with pre-training a source model by applying UDA baseline on source labeled data and taraget unlabeled data with a developed random masked augmentation (RMA), and then alternates between adversarial target model training on pseudo-labeled target data and finetuning source model by a meta step. While self-training allows the direct incorporation of AT in UDA, the meta step in SRoUDA further helps in mitigating error propagation from noisy pseudo labels. Extensive experiments on various benchmark datasets demonstrate the state-of-the-art performance of SRoUDA where it achieves significant model robustness improvement without harming clean accuracy. Code is available at https://github.com/Vision.","created":"2022-12-12","meta":{"link":"http://arxiv.org/abs/2212.05917v1","tag":"data-quality"}}
{"title":"KonX: Cross-Resolution Image Quality Assessment","abstract":"Scale-invariance is an open problem in many computer vision subfields. For example, object labels should remain constant across scales, yet model predictions diverge in many cases. This problem gets harder for tasks where the ground-truth labels change with the presentation scale. In image quality assessment (IQA), downsampling attenuates impairments, e.g., blurs or compression artifacts, which can positively affect the impression evoked in subjective studies. To accurately predict perceptual image quality, cross-resolution IQA methods must therefore account for resolution-dependent errors induced by model inadequacies as well as for the perceptual label shifts in the ground truth. We present the first study of its kind that disentangles and examines the two issues separately via KonX, a novel, carefully crafted cross-resolution IQA database. This paper contributes the following: 1. Through KonX, we provide empirical evidence of label shifts caused by changes in the presentation resolution. 2. We show that objective IQA methods have a scale bias, which reduces their predictive performance. 3. We propose a multi-scale and multi-column DNN architecture that improves performance over previous state-of-the-art IQA models for this task, including recent transformers. We thus both raise and address a novel research problem in image quality assessment.","created":"2022-12-12","meta":{"link":"http://arxiv.org/abs/2212.05813v1","tag":"data-quality"}}
{"title":"MountNet: Learning an Inertial Sensor Mounting Angle with Deep Neural Networks","abstract":"Finding the mounting angle of a smartphone inside a car is crucial for navigation, motion detection, activity recognition, and other applications. It is a challenging task in several aspects: (i) the mounting angle at the drive start is unknown and may differ significantly between users; (ii) the user, or bad fixture, may change the mounting angle while driving; (iii) a rapid and computationally efficient real-time solution is required for most applications. To tackle these problems, a data-driven approach using deep neural networks (DNNs) is presented to learn the yaw mounting angle of a smartphone equipped with an inertial measurement unit (IMU) and strapped to a car. The proposed model, MountNet, uses only IMU readings as input and, in contrast to existing solutions, does not require inputs from global navigation satellite systems (GNSS). IMU data is collected for training and validation with the sensor mounted at a known yaw mounting angle and a range of ground truth labels is generated by applying a prescribed rotation to the measurements. Although the training data did not include recordings with real sensor rotations, tests on data with real and synthetic rotations show similar results. An algorithm is formulated for real-time deployment to detect and smooth transitions in device mounting angle estimated by MountNet. MountNet is shown to find the mounting angle rapidly which is critical in real-time applications. Our method converges in less than 30 seconds of driving to a mean error of 4 degrees allowing a fast calibration phase for other algorithms and applications. When the device is rotated in the middle of a drive, large changes converge in 5 seconds and small changes converge in less than 30 seconds.","created":"2022-12-10","meta":{"link":"http://arxiv.org/abs/2212.11120v1","tag":"data-quality"}}
{"title":"HieNet: Bidirectional Hierarchy Framework for Automated ICD Coding","abstract":"International Classification of Diseases (ICD) is a set of classification codes for medical records. Automated ICD coding, which assigns unique International Classification of Diseases codes with each medical record, is widely used recently for its efficiency and error-prone avoidance. However, there are challenges that remain such as heterogeneity, label unbalance, and complex relationships between ICD codes. In this work, we proposed a novel Bidirectional Hierarchy Framework(HieNet) to address the challenges. Specifically, a personalized PageRank routine is developed to capture the co-relation of codes, a bidirectional hierarchy passage encoder to capture the codes' hierarchical representations, and a progressive predicting method is then proposed to narrow down the semantic searching space of prediction. We validate our method on two widely used datasets. Experimental results on two authoritative public datasets demonstrate that our proposed method boosts state-of-the-art performance by a large margin.","created":"2022-12-09","meta":{"link":"http://arxiv.org/abs/2212.04891v1","tag":"data-quality"}}
{"title":"Weakly Supervised Semantic Segmentation for Large-Scale Point Cloud","abstract":"Existing methods for large-scale point cloud semantic segmentation require expensive, tedious and error-prone manual point-wise annotations. Intuitively, weakly supervised training is a direct solution to reduce the cost of labeling. However, for weakly supervised large-scale point cloud semantic segmentation, too few annotations will inevitably lead to ineffective learning of network. We propose an effective weakly supervised method containing two components to solve the above problem. Firstly, we construct a pretext task, \\textit{i.e.,} point cloud colorization, with a self-supervised learning to transfer the learned prior knowledge from a large amount of unlabeled point cloud to a weakly supervised network. In this way, the representation capability of the weakly supervised network can be improved by the guidance from a heterogeneous task. Besides, to generate pseudo label for unlabeled data, a sparse label propagation mechanism is proposed with the help of generated class prototypes, which is used to measure the classification confidence of unlabeled point. Our method is evaluated on large-scale point cloud datasets with different scenarios including indoor and outdoor. The experimental results show the large gain against existing weakly supervised and comparable results to fully supervised methods\\footnote{Code based on mindspore: https://github.com/dmcv-ecnu/MindSpore\\_ModelZoo/tree/main/WS3\\_MindSpore}.","created":"2022-12-09","meta":{"link":"http://arxiv.org/abs/2212.04744v1","tag":"data-quality"}}
{"title":"Occluded Person Re-Identification via Relational Adaptive Feature Correction Learning","abstract":"Occluded person re-identification (Re-ID) in images captured by multiple cameras is challenging because the target person is occluded by pedestrians or objects, especially in crowded scenes. In addition to the processes performed during holistic person Re-ID, occluded person Re-ID involves the removal of obstacles and the detection of partially visible body parts. Most existing methods utilize the off-the-shelf pose or parsing networks as pseudo labels, which are prone to error. To address these issues, we propose a novel Occlusion Correction Network (OCNet) that corrects features through relational-weight learning and obtains diverse and representative features without using external networks. In addition, we present a simple concept of a center feature in order to provide an intuitive solution to pedestrian occlusion scenarios. Furthermore, we suggest the idea of Separation Loss (SL) for focusing on different parts between global features and part features. We conduct extensive experiments on five challenging benchmark datasets for occluded and holistic Re-ID tasks to demonstrate that our method achieves superior performance to state-of-the-art methods especially on occluded scene.","created":"2022-12-09","meta":{"link":"http://arxiv.org/abs/2212.04712v1","tag":"data-quality"}}
{"title":"Decorate the Newcomers: Visual Domain Prompt for Continual Test Time Adaptation","abstract":"Continual Test-Time Adaptation (CTTA) aims to adapt the source model to continually changing unlabeled target domains without access to the source data. Existing methods mainly focus on model-based adaptation in a self-training manner, such as predicting pseudo labels for new domain datasets. Since pseudo labels are noisy and unreliable, these methods suffer from catastrophic forgetting and error accumulation when dealing with dynamic data distributions. Motivated by the prompt learning in NLP, in this paper, we propose to learn an image-level visual domain prompt for target domains while having the source model parameters frozen. During testing, the changing target datasets can be adapted to the source model by reformulating the input data with the learned visual prompts. Specifically, we devise two types of prompts, i.e., domains-specific prompts and domains-agnostic prompts, to extract current domain knowledge and maintain the domain-shared knowledge in the continual adaptation. Furthermore, we design a homeostasis-based prompt adaptation strategy to suppress domain-sensitive parameters in domain-invariant prompts to learn domain-shared knowledge more effectively. This transition from the model-dependent paradigm to the model-free one enables us to bypass the catastrophic forgetting and error accumulation problems. Experiments show that our proposed method achieves significant performance gains over state-of-the-art methods on four widely-used benchmarks, including CIFAR-10C, CIFAR-100C, ImageNet-C, and VLCS datasets.","created":"2022-12-08","meta":{"link":"http://arxiv.org/abs/2212.04145v2","tag":"data-quality"}}
{"title":"Utility-Based Communication Requirements for Stable Matching in Large Markets","abstract":"Results from the communication complexity literature have demonstrated that stable matching requires communication: one cannot find or verify a stable match without having access to essentially all of the ordinal preference information held privately by the agents in the market. Stated differently, these results show that stable matching mechanisms are not robust to even a small number of labeled inaccuracies in the input preferences. In practice, these results indicate that agents must go through the time-intensive process of accurately ranking each and every potential match candidate if they wish for the resulting match to be guaranteedly stable. Thus, in large markets, communication requirements for stable matching may be impractically high.   A natural question to ask, given this result, is whether some higher-order structure in the market can indicate which large markets have steeper communication requirements. In this paper, we perform such an analysis in a regime where agents have a utility-based notion of preference. We consider a dynamic model where agents only have access to an approximation of their utility that satisfies a universal multiplicative error bound. We apply guarantees from the theoretical computer science literature on low-distortion embeddings of finite metric spaces to understand the communication requirements of stable matching in large markets in terms of their structural properties. Our results show that for a broad family of markets, the error bound may not grow faster than $n^2\\log(n)$ while maintaining a deterministic guarantee on the behavior of stable matching mechanisms in the limit. We also show that a stronger probabilistic guarantee may be made so long as the bound grows at most logarithmically in the underlying topological complexity of the market.","created":"2022-12-08","meta":{"link":"http://arxiv.org/abs/2212.04024v1","tag":"data-quality"}}
{"title":"Discovering Latent Knowledge in Language Models Without Supervision","abstract":"Existing techniques for training language models can be misaligned with the truth: if we train models with imitation learning, they may reproduce errors that humans make; if we train them to generate text that humans rate highly, they may output errors that human evaluators can't detect. We propose circumventing this issue by directly finding latent knowledge inside the internal activations of a language model in a purely unsupervised way. Specifically, we introduce a method for accurately answering yes-no questions given only unlabeled model activations. It works by finding a direction in activation space that satisfies logical consistency properties, such as that a statement and its negation have opposite truth values. We show that despite using no supervision and no model outputs, our method can recover diverse knowledge represented in large language models: across 6 models and 10 question-answering datasets, it outperforms zero-shot accuracy by 4\\% on average. We also find that it cuts prompt sensitivity in half and continues to maintain high accuracy even when models are prompted to generate incorrect answers. Our results provide an initial step toward discovering what language models know, distinct from what they say, even when we don't have access to explicit ground truth labels.","created":"2022-12-07","meta":{"link":"http://arxiv.org/abs/2212.03827v1","tag":"data-quality"}}
{"title":"Reconciling a Centroid-Hypothesis Conflict in Source-Free Domain Adaptation","abstract":"Source-free domain adaptation (SFDA) aims to transfer knowledge learned from a source domain to an unlabeled target domain, where the source data is unavailable during adaptation. Existing approaches for SFDA focus on self-training usually including well-established entropy minimization techniques. One of the main challenges in SFDA is to reduce accumulation of errors caused by domain misalignment. A recent strategy successfully managed to reduce error accumulation by pseudo-labeling the target samples based on class-wise prototypes (centroids) generated by their clustering in the representation space. However, this strategy also creates cases for which the cross-entropy of a pseudo-label and the minimum entropy have a conflict in their objectives. We call this conflict the centroid-hypothesis conflict. We propose to reconcile this conflict by aligning the entropy minimization objective with that of the pseudo labels' cross entropy. We demonstrate the effectiveness of aligning the two loss objectives on three domain adaptation datasets. In addition, we provide state-of-the-art results using up-to-date architectures also showing the consistency of our method across these architectures.","created":"2022-12-07","meta":{"link":"http://arxiv.org/abs/2212.03795v1","tag":"data-quality"}}
{"title":"An Intuitive and Unconstrained 2D Cube Representation for Simultaneous Head Detection and Pose Estimation","abstract":"Most recent head pose estimation (HPE) methods are dominated by the Euler angle representation. To avoid its inherent ambiguity problem of rotation labels, alternative quaternion-based and vector-based representations are introduced. However, they both are not visually intuitive, and often derived from equivocal Euler angle labels. In this paper, we present a novel single-stage keypoint-based method via an {\\it intuitive} and {\\it unconstrained} 2D cube representation for joint head detection and pose estimation. The 2D cube is an orthogonal projection of the 3D regular hexahedron label roughly surrounding one head, and itself contains the head location. It can reflect the head orientation straightforwardly and unambiguously in any rotation angle. Unlike the general 6-DoF object pose estimation, our 2D cube ignores the 3-DoF of head size but retains the 3-DoF of head pose. Based on the prior of equal side length, we can effortlessly obtain the closed-form solution of Euler angles from predicted 2D head cube instead of applying the error-prone PnP algorithm. In experiments, our proposed method achieves comparable results with other representative methods on the public AFLW2000 and BIWI datasets. Besides, a novel test on the CMU panoptic dataset shows that our method can be seamlessly adapted to the unconstrained full-view HPE task without modification.","created":"2022-12-07","meta":{"link":"http://arxiv.org/abs/2212.03623v1","tag":"data-quality"}}
{"title":"ERNet: Unsupervised Collective Extraction and Registration in Neuroimaging Data","abstract":"Brain extraction and registration are important preprocessing steps in neuroimaging data analysis, where the goal is to extract the brain regions from MRI scans (i.e., extraction step) and align them with a target brain image (i.e., registration step). Conventional research mainly focuses on developing methods for the extraction and registration tasks separately under supervised settings. The performance of these methods highly depends on the amount of training samples and visual inspections performed by experts for error correction. However, in many medical studies, collecting voxel-level labels and conducting manual quality control in high-dimensional neuroimages (e.g., 3D MRI) are very expensive and time-consuming. Moreover, brain extraction and registration are highly related tasks in neuroimaging data and should be solved collectively. In this paper, we study the problem of unsupervised collective extraction and registration in neuroimaging data. We propose a unified end-to-end framework, called ERNet (Extraction-Registration Network), to jointly optimize the extraction and registration tasks, allowing feedback between them. Specifically, we use a pair of multi-stage extraction and registration modules to learn the extraction mask and transformation, where the extraction network improves the extraction accuracy incrementally and the registration network successively warps the extracted image until it is well-aligned with the target image. Experiment results on real-world datasets show that our proposed method can effectively improve the performance on extraction and registration tasks in neuroimaging data. Our code and data can be found at https://github.com/ERNetERNet/ERNet","created":"2022-12-06","meta":{"link":"http://arxiv.org/abs/2212.03306v1","tag":"data-quality"}}
{"title":"Adaptive Testing of Computer Vision Models","abstract":"Vision models often fail systematically on groups of data that share common semantic characteristics (e.g., rare objects or unusual scenes), but identifying these failure modes is a challenge. We introduce AdaVision, an interactive process for testing vision models which helps users identify and fix coherent failure modes. Given a natural language description of a coherent group, AdaVision retrieves relevant images from LAION-5B with CLIP. The user then labels a small amount of data for model correctness, which is used in successive retrieval rounds to hill-climb towards high-error regions, refining the group definition. Once a group is saturated, AdaVision uses GPT-3 to suggest new group descriptions for the user to explore. We demonstrate the usefulness and generality of AdaVision in user studies, where users find major bugs in state-of-the-art classification, object detection, and image captioning models. These user-discovered groups have failure rates 2-3x higher than those surfaced by automatic error clustering methods. Finally, finetuning on examples found with AdaVision fixes the discovered bugs when evaluated on unseen examples, without degrading in-distribution accuracy, and while also improving performance on out-of-distribution datasets.","created":"2022-12-06","meta":{"link":"http://arxiv.org/abs/2212.02774v1","tag":"data-quality"}}
{"title":"Sources of Noise in Dialogue and How to Deal with Them","abstract":"Training dialogue systems often entails dealing with noisy training examples and unexpected user inputs. Despite their prevalence, there currently lacks an accurate survey of dialogue noise, nor is there a clear sense of the impact of each noise type on task performance. This paper addresses this gap by first constructing a taxonomy of noise encountered by dialogue systems. In addition, we run a series of experiments to show how different models behave when subjected to varying levels of noise and types of noise. Our results reveal that models are quite robust to label errors commonly tackled by existing denoising algorithms, but that performance suffers from dialogue-specific noise. Driven by these observations, we design a data cleaning algorithm specialized for conversational settings and apply it as a proof-of-concept for targeted dialogue denoising.","created":"2022-12-06","meta":{"link":"http://arxiv.org/abs/2212.02745v1","tag":"data-quality"}}
{"title":"Improving machine learning-derived photometric redshifts and physical property estimates using unlabelled observations","abstract":"In the era of huge astronomical surveys, machine learning offers promising solutions for the efficient estimation of galaxy properties. The traditional, `supervised' paradigm for the application of machine learning involves training a model on labelled data, and using this model to predict the labels of previously unlabelled data. The semi-supervised `pseudo-labelling' technique offers an alternative paradigm, allowing the model training algorithm to learn from both labelled data and as-yet unlabelled data. We test the pseudo-labelling method on the problems of estimating redshift, stellar mass, and star formation rate, using COSMOS2015 broad band photometry and one of several publicly available machine learning algorithms, and we obtain significant improvements compared to purely supervised learning. We find that the gradient-boosting tree methods CatBoost, XGBoost, and LightGBM benefit the most, with reductions of up to ~15% in metrics of absolute error. We also find similar improvements in the photometric redshift catastrophic outlier fraction. We argue that the pseudo-labellng technique will be useful for the estimation of redshift and physical properties of galaxies in upcoming large imaging surveys such as Euclid and LSST, which will provide photometric data for billions of sources.","created":"2022-12-05","meta":{"link":"http://arxiv.org/abs/2212.02537v1","tag":"data-quality"}}
{"title":"A Transformer-Based User Satisfaction Prediction for Proactive Interaction Mechanism in DuerOS","abstract":"Recently, spoken dialogue systems have been widely deployed in a variety of applications, serving a huge number of end-users. A common issue is that the errors resulting from noisy utterances, semantic misunderstandings, or lack of knowledge make it hard for a real system to respond properly, possibly leading to an unsatisfactory user experience. To avoid such a case, we consider a proactive interaction mechanism where the system predicts the user satisfaction with the candidate response before giving it to the user. If the user is not likely to be satisfied according to the prediction, the system will ask the user a suitable question to determine the real intent of the user instead of providing the response directly. With such an interaction with the user, the system can give a better response to the user. Previous models that predict the user satisfaction are not applicable to DuerOS which is a large-scale commercial dialogue system. They are based on hand-crafted features and thus can hardly learn the complex patterns lying behind millions of conversations and temporal dependency in multiple turns of the conversation. Moreover, they are trained and evaluated on the benchmark datasets with adequate labels, which are expensive to obtain in a commercial dialogue system. To face these challenges, we propose a pipeline to predict the user satisfaction to help DuerOS decide whether to ask for clarification in each turn. Specifically, we propose to first generate a large number of weak labels and then train a transformer-based model to predict the user satisfaction with these weak labels. Empirically, we deploy and evaluate our model on DuerOS, and observe a 19% relative improvement on the accuracy of user satisfaction prediction and 2.3% relative improvement on user experience.","created":"2022-12-05","meta":{"link":"http://arxiv.org/abs/2212.03817v1","tag":"data-quality"}}
{"title":"Deep Learning Architectures for FSCV, a Comparison","abstract":"We examined multiple deep neural network (DNN) architectures for suitability in predicting neurotransmitter concentrations from labeled in vitro fast scan cyclic voltammetry (FSCV) data collected on carbon fiber electrodes. Suitability is determined by the predictive performance in the \"out-of-probe\" case, the response to artificially induced electrical noise, and the ability to predict when the model will be errant for a given probe. This work extends prior comparisons of time series classification models by focusing on this specific task. It extends previous applications of machine learning to FSCV task by using a much larger data set and by incorporating recent advancements in deep neural networks. The InceptionTime architecture, a deep convolutional neural network, has the best absolute predictive performance of the models tested but was more susceptible to noise. A naive multilayer perceptron architecture had the second lowest prediction error and was less affected by the artificial noise, suggesting that convolutions may not be as important for this task as one might suspect.","created":"2022-12-05","meta":{"link":"http://arxiv.org/abs/2212.01960v1","tag":"data-quality"}}
{"title":"Label Encoding for Regression Networks","abstract":"Deep neural networks are used for a wide range of regression problems. However, there exists a significant gap in accuracy between specialized approaches and generic direct regression in which a network is trained by minimizing the squared or absolute error of output labels. Prior work has shown that solving a regression problem with a set of binary classifiers can improve accuracy by utilizing well-studied binary classification algorithms. We introduce binary-encoded labels (BEL), which generalizes the application of binary classification to regression by providing a framework for considering arbitrary multi-bit values when encoding target values. We identify desirable properties of suitable encoding and decoding functions used for the conversion between real-valued and binary-encoded labels based on theoretical and empirical study. These properties highlight a tradeoff between classification error probability and error-correction capabilities of label encodings. BEL can be combined with off-the-shelf task-specific feature extractors and trained end-to-end. We propose a series of sample encoding, decoding, and training loss functions for BEL and demonstrate they result in lower error than direct regression and specialized approaches while being suitable for a diverse set of regression problems, network architectures, and evaluation metrics. BEL achieves state-of-the-art accuracies for several regression benchmarks. Code is available at https://github.com/ubc-aamodt-group/BEL_regression.","created":"2022-12-04","meta":{"link":"http://arxiv.org/abs/2212.01927v1","tag":"data-quality"}}
{"title":"Crowd Density Estimation using Imperfect Labels","abstract":"Density estimation is one of the most widely used methods for crowd counting in which a deep learning model learns from head-annotated crowd images to estimate crowd density in unseen images. Typically, the learning performance of the model is highly impacted by the accuracy of the annotations and inaccurate annotations may lead to localization and counting errors during prediction. A significant amount of works exist on crowd counting using perfectly labelled datasets but none of these explore the impact of annotation errors on the model accuracy. In this paper, we investigate the impact of imperfect labels (both noisy and missing labels) on crowd counting accuracy. We propose a system that automatically generates imperfect labels using a deep learning model (called annotator) which are then used to train a new crowd counting model (target model). Our analysis on two crowd counting models and two benchmark datasets shows that the proposed scheme achieves accuracy closer to that of the model trained with perfect labels showing the robustness of crowd models to annotation errors.","created":"2022-12-02","meta":{"link":"http://arxiv.org/abs/2212.01450v1","tag":"data-quality"}}
{"title":"Model and Data Agreement for Learning with Noisy Labels","abstract":"Learning with noisy labels is a vital topic for practical deep learning as models should be robust to noisy open-world datasets in the wild. The state-of-the-art noisy label learning approach JoCoR fails when faced with a large ratio of noisy labels. Moreover, selecting small-loss samples can also cause error accumulation as once the noisy samples are mistakenly selected as small-loss samples, they are more likely to be selected again. In this paper, we try to deal with error accumulation in noisy label learning from both model and data perspectives. We introduce mean point ensemble to utilize a more robust loss function and more information from unselected samples to reduce error accumulation from the model perspective. Furthermore, as the flip images have the same semantic meaning as the original images, we select small-loss samples according to the loss values of flip images instead of the original ones to reduce error accumulation from the data perspective. Extensive experiments on CIFAR-10, CIFAR-100, and large-scale Clothing1M show that our method outperforms state-of-the-art noisy label learning methods with different levels of label noise. Our method can also be seamlessly combined with other noisy label learning methods to further improve their performance and generalize well to other tasks. The code is available in https://github.com/zyh-uaiaaaa/MDA-noisy-label-learning.","created":"2022-12-02","meta":{"link":"http://arxiv.org/abs/2212.01054v2","tag":"data-quality"}}
{"title":"AGRO: Adversarial Discovery of Error-prone groups for Robust Optimization","abstract":"Models trained via empirical risk minimization (ERM) are known to rely on spurious correlations between labels and task-independent input features, resulting in poor generalization to distributional shifts. Group distributionally robust optimization (G-DRO) can alleviate this problem by minimizing the worst-case loss over a set of pre-defined groups over training data. G-DRO successfully improves performance of the worst-group, where the correlation does not hold. However, G-DRO assumes that the spurious correlations and associated worst groups are known in advance, making it challenging to apply it to new tasks with potentially multiple unknown spurious correlations. We propose AGRO -- Adversarial Group discovery for Distributionally Robust Optimization -- an end-to-end approach that jointly identifies error-prone groups and improves accuracy on them. AGRO equips G-DRO with an adversarial slicing model to find a group assignment for training examples which maximizes worst-case loss over the discovered groups. On the WILDS benchmark, AGRO results in 8% higher model performance on average on known worst-groups, compared to prior group discovery approaches used with G-DRO. AGRO also improves out-of-distribution performance on SST2, QQP, and MS-COCO -- datasets where potential spurious correlations are as yet uncharacterized. Human evaluation of ARGO groups shows that they contain well-defined, yet previously unstudied spurious correlations that lead to model errors.","created":"2022-12-02","meta":{"link":"http://arxiv.org/abs/2212.00921v2","tag":"data-quality"}}
{"title":"Improving Zero-Shot Models with Label Distribution Priors","abstract":"Labeling large image datasets with attributes such as facial age or object type is tedious and sometimes infeasible. Supervised machine learning methods provide a highly accurate solution, but require manual labels which are often unavailable. Zero-shot models (e.g., CLIP) do not require manual labels but are not as accurate as supervised ones, particularly when the attribute is numeric. We propose a new approach, CLIPPR (CLIP with Priors), which adapts zero-shot models for regression and classification on unlabelled datasets. Our method does not use any annotated images. Instead, we assume a prior over the label distribution in the dataset. We then train an adapter network on top of CLIP under two competing objectives: i) minimal change of predictions from the original CLIP model ii) minimal distance between predicted and prior distribution of labels. Additionally, we present a novel approach for selecting prompts for Vision & Language models using a distributional prior. Our method is effective and presents a significant improvement over the original model. We demonstrate an improvement of 28% in mean absolute error on the UTK age regression task. We also present promising results for classification benchmarks, improving the classification accuracy on the ImageNet dataset by 2.83%, without using any labels.","created":"2022-12-01","meta":{"link":"http://arxiv.org/abs/2212.00784v1","tag":"data-quality"}}
{"title":"Purifier: Defending Data Inference Attacks via Transforming Confidence Scores","abstract":"Neural networks are susceptible to data inference attacks such as the membership inference attack, the adversarial model inversion attack and the attribute inference attack, where the attacker could infer useful information such as the membership, the reconstruction or the sensitive attributes of a data sample from the confidence scores predicted by the target classifier. In this paper, we propose a method, namely PURIFIER, to defend against membership inference attacks. It transforms the confidence score vectors predicted by the target classifier and makes purified confidence scores indistinguishable in individual shape, statistical distribution and prediction label between members and non-members. The experimental results show that PURIFIER helps defend membership inference attacks with high effectiveness and efficiency, outperforming previous defense methods, and also incurs negligible utility loss. Besides, our further experiments show that PURIFIER is also effective in defending adversarial model inversion attacks and attribute inference attacks. For example, the inversion error is raised about 4+ times on the Facescrub530 classifier, and the attribute inference accuracy drops significantly when PURIFIER is deployed in our experiment.","created":"2022-12-01","meta":{"link":"http://arxiv.org/abs/2212.00612v1","tag":"data-quality"}}
{"title":"Direct-Effect Risk Minimization for Domain Generalization","abstract":"We study the problem of out-of-distribution (o.o.d.) generalization where spurious correlations of attributes vary across training and test domains. This is known as the problem of correlation shift and has posed concerns on the reliability of machine learning. In this work, we introduce the concepts of direct and indirect effects from causal inference to the domain generalization problem. We argue that models that learn direct effects minimize the worst-case risk across correlation-shifted domains. To eliminate the indirect effects, our algorithm consists of two stages: in the first stage, we learn an indirect-effect representation by minimizing the prediction error of domain labels using the representation and the class labels; in the second stage, we remove the indirect effects learned in the first stage by matching each data with another data of similar indirect-effect representation but of different class labels in the training and validation phase. Our approach is shown to be compatible with existing methods and improve the generalization performance of them on correlation-shifted datasets. Experiments on 5 correlation-shifted datasets and the DomainBed benchmark verify the effectiveness of our approach.","created":"2022-11-26","meta":{"link":"http://arxiv.org/abs/2211.14594v4","tag":"data-quality"}}
{"title":"Solving math word problems with process- and outcome-based feedback","abstract":"Recent work has shown that asking language models to generate reasoning steps improves performance on many reasoning tasks. When moving beyond prompting, this raises the question of how we should supervise such models: outcome-based approaches which supervise the final result, or process-based approaches which supervise the reasoning process itself? Differences between these approaches might naturally be expected not just in final-answer errors but also in reasoning errors, which can be difficult to detect and are problematic in many real-world domains such as education. We run the first comprehensive comparison between process- and outcome-based approaches trained on a natural language task, GSM8K. We find that pure outcome-based supervision produces similar final-answer error rates with less label supervision. However, for correct reasoning steps we find it necessary to use process-based supervision or supervision from learned reward models that emulate process-based feedback. In total, we improve the previous best results from 16.8% $\\to$ 12.7% final-answer error and 14.0% $\\to$ 3.4% reasoning error among final-answer-correct solutions.","created":"2022-11-25","meta":{"link":"http://arxiv.org/abs/2211.14275v1","tag":"data-quality"}}
{"title":"Combating noisy labels in object detection datasets","abstract":"The quality of training datasets for deep neural networks is a key factor contributing to the accuracy of resulting models. This is even more important in difficult tasks such as object detection. Dealing with errors in these datasets was in the past limited to accepting that some fraction of examples is incorrect or predicting their confidence and assigning appropriate weights during training. In this work, we propose a different approach. For the first time, we extended the confident learning algorithm to the object detection task. By focusing on finding incorrect labels in the original training datasets, we can eliminate erroneous examples in their root. Suspicious bounding boxes can be re-annotated in order to improve the quality of the dataset itself, thus leading to better models without complicating their already complex architectures. We can effectively point out 99\\% of artificially disturbed bounding boxes with FPR below 0.3. We see this method as a promising path to correcting well-known object detection datasets.","created":"2022-11-25","meta":{"link":"http://arxiv.org/abs/2211.13993v1","tag":"data-quality"}}
{"title":"Identifying Incorrect Annotations in Multi-Label Classification Data","abstract":"In multi-label classification, each example in a dataset may be annotated as belonging to one or more classes (or none of the classes). Example applications include image (or document) tagging where each possible tag either applies to a particular image (or document) or not. With many possible classes to consider, data annotators are likely to make errors when labeling such data in practice. Here we consider algorithms for finding mislabeled examples in multi-label classification datasets. We propose an extension of the Confident Learning framework to this setting, as well as a label quality score that ranks examples with label errors much higher than those which are correctly labeled. Both approaches can utilize any trained classifier. After demonstrating that our methodology empirically outperforms other algorithms for label error detection, we apply our approach to discover many label errors in the CelebA image tagging dataset.","created":"2022-11-25","meta":{"link":"http://arxiv.org/abs/2211.13895v1","tag":"data-quality"}}
{"title":"Cross-domain Transfer of defect features in technical domains based on partial target data","abstract":"A common challenge in real world classification scenarios with sequentially appending target domain data is insufficient training datasets during the training phase. Therefore, conventional deep learning and transfer learning classifiers are not applicable especially when individual classes are not represented or are severely underrepresented at the outset. In many technical domains, however, it is only the defect or worn reject classes that are insufficiently represented, while the non-defect class is often available from the beginning. The proposed classification approach addresses such conditions and is based on a CNN encoder. Following a contrastive learning approach, it is trained with a modified triplet loss function using two datasets: Besides the non-defective target domain class 1st dataset, a state-of-the-art labeled source domain dataset that contains highly related classes e.g., a related manufacturing error or wear defect but originates from a highly different domain e.g., different product, material, or appearance = 2nd dataset is utilized. The approach learns the classification features from the source domain dataset while at the same time learning the differences between the source and the target domain in a single training step, aiming to transfer the relevant features to the target domain. The classifier becomes sensitive to the classification features and by architecture robust against the highly domain-specific context. The approach is benchmarked in a technical and a non-technical domain and shows convincing classification results. In particular, it is shown that the domain generalization capabilities and classification results are improved by the proposed architecture, allowing for larger domain shifts between source and target domains.","created":"2022-11-24","meta":{"link":"http://arxiv.org/abs/2211.13662v1","tag":"data-quality"}}
{"title":"Mutual Information Learned Regressor: an Information-theoretic Viewpoint of Training Regression Systems","abstract":"As one of the central tasks in machine learning, regression finds lots of applications in different fields. An existing common practice for solving regression problems is the mean square error (MSE) minimization approach or its regularized variants which require prior knowledge about the models. Recently, Yi et al., proposed a mutual information based supervised learning framework where they introduced a label entropy regularization which does not require any prior knowledge. When applied to classification tasks and solved via a stochastic gradient descent (SGD) optimization algorithm, their approach achieved significant improvement over the commonly used cross entropy loss and its variants. However, they did not provide a theoretical convergence analysis of the SGD algorithm for the proposed formulation. Besides, applying the framework to regression tasks is nontrivial due to the potentially infinite support set of the label. In this paper, we investigate the regression under the mutual information based supervised learning framework. We first argue that the MSE minimization approach is equivalent to a conditional entropy learning problem, and then propose a mutual information learning formulation for solving regression problems by using a reparameterization technique. For the proposed formulation, we give the convergence analysis of the SGD algorithm for solving it in practice. Finally, we consider a multi-output regression data model where we derive the generalization performance lower bound in terms of the mutual information associated with the underlying data distribution. The result shows that the high dimensionality can be a bless instead of a curse, which is controlled by a threshold. We hope our work will serve as a good starting point for further research on the mutual information based regression.","created":"2022-11-23","meta":{"link":"http://arxiv.org/abs/2211.12685v1","tag":"data-quality"}}
{"title":"Out-of-Candidate Rectification for Weakly Supervised Semantic Segmentation","abstract":"Weakly supervised semantic segmentation is typically inspired by class activation maps, which serve as pseudo masks with class-discriminative regions highlighted. Although tremendous efforts have been made to recall precise and complete locations for each class, existing methods still commonly suffer from the unsolicited Out-of-Candidate (OC) error predictions that not belongs to the label candidates, which could be avoidable since the contradiction with image-level class tags is easy to be detected. In this paper, we develop a group ranking-based Out-of-Candidate Rectification (OCR) mechanism in a plug-and-play fashion. Firstly, we adaptively split the semantic categories into In-Candidate (IC) and OC groups for each OC pixel according to their prior annotation correlation and posterior prediction correlation. Then, we derive a differentiable rectification loss to force OC pixels to shift to the IC group. Incorporating our OCR with seminal baselines (e.g., AffinityNet, SEAM, MCTformer), we can achieve remarkable performance gains on both Pascal VOC (+3.2%, +3.3%, +0.8% mIoU) and MS COCO (+1.0%, +1.3%, +0.5% mIoU) datasets with negligible extra training overhead, which justifies the effectiveness and generality of our OCR.","created":"2022-11-22","meta":{"link":"http://arxiv.org/abs/2211.12268v3","tag":"data-quality"}}
{"title":"A Scope Sensitive and Result Attentive Model for Multi-Intent Spoken Language Understanding","abstract":"Multi-Intent Spoken Language Understanding (SLU), a novel and more complex scenario of SLU, is attracting increasing attention. Unlike traditional SLU, each intent in this scenario has its specific scope. Semantic information outside the scope even hinders the prediction, which tremendously increases the difficulty of intent detection. More seriously, guiding slot filling with these inaccurate intent labels suffers error propagation problems, resulting in unsatisfied overall performance. To solve these challenges, in this paper, we propose a novel Scope-Sensitive Result Attention Network (SSRAN) based on Transformer, which contains a Scope Recognizer (SR) and a Result Attention Network (RAN). Scope Recognizer assignments scope information to each token, reducing the distraction of out-of-scope tokens. Result Attention Network effectively utilizes the bidirectional interaction between results of slot filling and intent detection, mitigating the error propagation problem. Experiments on two public datasets indicate that our model significantly improves SLU performance (5.4\\% and 2.1\\% on Overall accuracy) over the state-of-the-art baseline.","created":"2022-11-22","meta":{"link":"http://arxiv.org/abs/2211.12220v1","tag":"data-quality"}}
{"title":"Event Causality Identification with Causal News Corpus -- Shared Task 3, CASE 2022","abstract":"The Event Causality Identification Shared Task of CASE 2022 involved two subtasks working on the Causal News Corpus. Subtask 1 required participants to predict if a sentence contains a causal relation or not. This is a supervised binary classification task. Subtask 2 required participants to identify the Cause, Effect and Signal spans per causal sentence. This could be seen as a supervised sequence labeling task. For both subtasks, participants uploaded their predictions for a held-out test set, and ranking was done based on binary F1 and macro F1 scores for Subtask 1 and 2, respectively. This paper summarizes the work of the 17 teams that submitted their results to our competition and 12 system description papers that were received. The best F1 scores achieved for Subtask 1 and 2 were 86.19% and 54.15%, respectively. All the top-performing approaches involved pre-trained language models fine-tuned to the targeted task. We further discuss these approaches and analyze errors across participants' systems in this paper.","created":"2022-11-22","meta":{"link":"http://arxiv.org/abs/2211.12154v1","tag":"data-quality"}}
{"title":"Uncertainty-aware Vision-based Metric Cross-view Geolocalization","abstract":"This paper proposes a novel method for vision-based metric cross-view geolocalization (CVGL) that matches the camera images captured from a ground-based vehicle with an aerial image to determine the vehicle's geo-pose. Since aerial images are globally available at low cost, they represent a potential compromise between two established paradigms of autonomous driving, i.e. using expensive high-definition prior maps or relying entirely on the sensor data captured at runtime.   We present an end-to-end differentiable model that uses the ground and aerial images to predict a probability distribution over possible vehicle poses. We combine multiple vehicle datasets with aerial images from orthophoto providers on which we demonstrate the feasibility of our method. Since the ground truth poses are often inaccurate w.r.t. the aerial images, we implement a pseudo-label approach to produce more accurate ground truth poses and make them publicly available.   While previous works require training data from the target region to achieve reasonable localization accuracy (i.e. same-area evaluation), our approach overcomes this limitation and outperforms previous results even in the strictly more challenging cross-area case. We improve the previous state-of-the-art by a large margin even without ground or aerial data from the test region, which highlights the model's potential for global-scale application. We further integrate the uncertainty-aware predictions in a tracking framework to determine the vehicle's trajectory over time resulting in a mean position error on KITTI-360 of 0.78m.","created":"2022-11-22","meta":{"link":"http://arxiv.org/abs/2211.12145v1","tag":"data-quality"}}
{"title":"UpCycling: Semi-supervised 3D Object Detection without Sharing Raw-level Unlabeled Scenes","abstract":"Semi-supervised Learning (SSL) has received increasing attention in autonomous driving to reduce the enormous burden of 3D annotation. In this paper, we propose UpCycling, a novel SSL framework for 3D object detection with zero additional raw-level point cloud: learning from unlabeled de-identified intermediate features (i.e., smashed data) to preserve privacy. Since these intermediate features are naturally produced by the inference pipeline, no additional computation is required on autonomous vehicles. However, generating effective consistency loss for unlabeled feature-level scene turns out to be a critical challenge. The latest SSL frameworks for 3D object detection that enforce consistency regularization between different augmentations of an unlabeled raw-point scene become detrimental when applied to intermediate features. To solve the problem, we introduce a novel combination of hybrid pseudo labels and feature-level Ground Truth sampling (F-GT), which safely augments unlabeled multi-type 3D scene features and provides high-quality supervision. We implement UpCycling on two representative 3D object detection models: SECOND-IoU and PV-RCNN. Experiments on widely-used datasets (Waymo, KITTI, and Lyft) verify that UpCycling outperforms other augmentation methods applied at the feature level. In addition, while preserving privacy, UpCycling performs better or comparably to the state-of-the-art methods that utilize raw-level unlabeled data in both domain adaptation and partial-label scenarios.","created":"2022-11-22","meta":{"link":"http://arxiv.org/abs/2211.11950v2","tag":"data-quality"}}
{"title":"SpeechNet: Weakly Supervised, End-to-End Speech Recognition at Industrial Scale","abstract":"End-to-end automatic speech recognition systems represent the state of the art, but they rely on thousands of hours of manually annotated speech for training, as well as heavyweight computation for inference. Of course, this impedes commercialization since most companies lack vast human and computational resources. In this paper, we explore training and deploying an ASR system in the label-scarce, compute-limited setting. To reduce human labor, we use a third-party ASR system as a weak supervision source, supplemented with labeling functions derived from implicit user feedback. To accelerate inference, we propose to route production-time queries across a pool of CUDA graphs of varying input lengths, the distribution of which best matches the traffic's. Compared to our third-party ASR, we achieve a relative improvement in word-error rate of 8% and a speedup of 600%. Our system, called SpeechNet, currently serves 12 million queries per day on our voice-enabled smart television. To our knowledge, this is the first time a large-scale, Wav2vec-based deployment has been described in the academic literature.","created":"2022-11-21","meta":{"link":"http://arxiv.org/abs/2211.11740v1","tag":"data-quality"}}
{"title":"An Optimal k Nearest Neighbours Ensemble for Classification Based on Extended Neighbourhood Rule with Features subspace","abstract":"To minimize the effect of outliers, kNN ensembles identify a set of closest observations to a new sample point to estimate its unknown class by using majority voting in the labels of the training instances in the neighbourhood. Ordinary kNN based procedures determine k closest training observations in the neighbourhood region (enclosed by a sphere) by using a distance formula. The k nearest neighbours procedure may not work in a situation where sample points in the test data follow the pattern of the nearest observations that lie on a certain path not contained in the given sphere of nearest neighbours. Furthermore, these methods combine hundreds of base kNN learners and many of them might have high classification errors thereby resulting in poor ensembles. To overcome these problems, an optimal extended neighbourhood rule based ensemble is proposed where the neighbours are determined in k steps. It starts from the first nearest sample point to the unseen observation. The second nearest data point is identified that is closest to the previously selected data point. This process is continued until the required number of the k observations are obtained. Each base model in the ensemble is constructed on a bootstrap sample in conjunction with a random subset of features. After building a sufficiently large number of base models, the optimal models are then selected based on their performance on out-of-bag (OOB) data.","created":"2022-11-21","meta":{"link":"http://arxiv.org/abs/2211.11278v1","tag":"data-quality"}}
{"title":"Self-Supervised 3D Traversability Estimation with Proxy Bank Guidance","abstract":"Traversability estimation for mobile robots in off-road environments requires more than conventional semantic segmentation used in constrained environments like on-road conditions. Recently, approaches to learning a traversability estimation from past driving experiences in a self-supervised manner are arising as they can significantly reduce human labeling costs and labeling errors. However, the self-supervised data only provide supervision for the actually traversed regions, inducing epistemic uncertainty according to the scarcity of negative information. Negative data are rarely harvested as the system can be severely damaged while logging the data. To mitigate the uncertainty, we introduce a deep metric learning-based method to incorporate unlabeled data with a few positive and negative prototypes in order to leverage the uncertainty, which jointly learns using semantic segmentation and traversability regression. To firmly evaluate the proposed framework, we introduce a new evaluation metric that comprehensively evaluates the segmentation and regression. Additionally, we construct a driving dataset `Dtrail' in off-road environments with a mobile robot platform, which is composed of a wide variety of negative data. We examine our method on Dtrail as well as the publicly available SemanticKITTI dataset.","created":"2022-11-21","meta":{"link":"http://arxiv.org/abs/2211.11201v2","tag":"data-quality"}}
{"title":"Overfreezing Meets Overparameterization: A Double Descent Perspective on Transfer Learning of Deep Neural Networks","abstract":"We study the generalization behavior of transfer learning of deep neural networks (DNNs). We adopt the overparameterization perspective -- featuring interpolation of the training data (i.e., approximately zero train error) and the double descent phenomenon -- to explain the delicate effect of the transfer learning setting on generalization performance. We study how the generalization behavior of transfer learning is affected by the dataset size in the source and target tasks, the number of transferred layers that are kept frozen in the target DNN training, and the similarity between the source and target tasks. We show that the test error evolution during the target DNN training has a more significant double descent effect when the target training dataset is sufficiently large with some label noise. In addition, a larger source training dataset can delay the arrival to interpolation and double descent peak in the target DNN training. Moreover, we demonstrate that the number of frozen layers can determine whether the transfer learning is effectively underparameterized or overparameterized and, in turn, this may affect the relative success or failure of learning. Specifically, we show that too many frozen layers may make a transfer from a less related source task better or on par with a transfer from a more related source task; we call this case overfreezing. We establish our results using image classification experiments with the residual network (ResNet) and vision transformer (ViT) architectures.","created":"2022-11-20","meta":{"link":"http://arxiv.org/abs/2211.11074v1","tag":"data-quality"}}
{"title":"Complementary Labels Learning with Augmented Classes","abstract":"Complementary Labels Learning (CLL) arises in many real-world tasks such as private questions classification and online learning, which aims to alleviate the annotation cost compared with standard supervised learning. Unfortunately, most previous CLL algorithms were in a stable environment rather than an open and dynamic scenarios, where data collected from unseen augmented classes in the training process might emerge in the testing phase. In this paper, we propose a novel problem setting called Complementary Labels Learning with Augmented Classes (CLLAC), which brings the challenge that classifiers trained by complementary labels should not only be able to classify the instances from observed classes accurately, but also recognize the instance from the Augmented Classes in the testing phase. Specifically, by using unlabeled data, we propose an unbiased estimator of classification risk for CLLAC, which is guaranteed to be provably consistent. Moreover, we provide generalization error bound for proposed method which shows that the optimal parametric convergence rate is achieved for estimation error. Finally, the experimental results on several benchmark datasets verify the effectiveness of the proposed method.","created":"2022-11-19","meta":{"link":"http://arxiv.org/abs/2211.10701v1","tag":"data-quality"}}
{"title":"Passivity and Immersion based-modified gradient estimator: A control perspective in parameter estimation","abstract":"In this paper, a constructive and systematic strategy with more apparent degrees of freedom to achieve the accurate estimation of unknown parameters via a control perspective is proposed. By adding a virtual control in the final equation of the gradient dynamics, the Gradient Estimator (GE) and Memory Regressor and Extension (MRE) approaches are extended. The solution of the virtual control law is identified by the P&I approach. The P&I approach is based on the choice of an appropriate implicit manifold and the generation of a suitable passive output and a related storage function. This facilitates the virtual control law being obtained in a way that the parametric error converges asymptotically to zero. Because the above ideas connect with the P&I approach and GE, the developed methodology is labeled the passivity and immersion-based modified gradient estimator (MGE). The proposed P&I-based modified gradient estimator is extended via the MRE approach. This modification provides improved transient response and fast convergence. Based on certain PE and non-PE examples, a comparative analysis is carried out to show the efficacy of the proposed approaches.","created":"2022-11-19","meta":{"link":"http://arxiv.org/abs/2211.10674v1","tag":"data-quality"}}
{"title":"A Light-weight, Effective and Efficient Model for Label Aggregation in Crowdsourcing","abstract":"Due to the noises in crowdsourced labels, label aggregation (LA) has emerged as a standard procedure to post-process crowdsourced labels. LA methods estimate true labels from crowdsourced labels by modeling worker qualities. Most existing LA methods are iterative in nature. They need to traverse all the crowdsourced labels multiple times in order to jointly and iteratively update true labels and worker qualities until convergence. Consequently, these methods have high space and time complexities. In this paper, we treat LA as a dynamic system and model it as a Dynamic Bayesian network. From the dynamic model we derive two light-weight algorithms, LA\\textsuperscript{onepass} and LA\\textsuperscript{twopass}, which can effectively and efficiently estimate worker qualities and true labels by traversing all the labels at most twice. Due to the dynamic nature, the proposed algorithms can also estimate true labels online without re-visiting historical data. We theoretically prove the convergence property of the proposed algorithms, and bound the error of estimated worker qualities. We also analyze the space and time complexities of the proposed algorithms and show that they are equivalent to those of majority voting. Experiments conducted on 20 real-world datasets demonstrate that the proposed algorithms can effectively and efficiently aggregate labels in both offline and online settings even if they traverse all the labels at most twice.","created":"2022-11-19","meta":{"link":"http://arxiv.org/abs/2212.00007v1","tag":"data-quality"}}
{"title":"Speaker Overlap-aware Neural Diarization for Multi-party Meeting Analysis","abstract":"Recently, hybrid systems of clustering and neural diarization models have been successfully applied in multi-party meeting analysis. However, current models always treat overlapped speaker diarization as a multi-label classification problem, where speaker dependency and overlaps are not well considered. To overcome the disadvantages, we reformulate overlapped speaker diarization task as a single-label prediction problem via the proposed power set encoding (PSE). Through this formulation, speaker dependency and overlaps can be explicitly modeled. To fully leverage this formulation, we further propose the speaker overlap-aware neural diarization (SOND) model, which consists of a context-independent (CI) scorer to model global speaker discriminability, a context-dependent scorer (CD) to model local discriminability, and a speaker combining network (SCN) to combine and reassign speaker activities. Experimental results show that using the proposed formulation can outperform the state-of-the-art methods based on target speaker voice activity detection, and the performance can be further improved with SOND, resulting in a 6.30% relative diarization error reduction.","created":"2022-11-18","meta":{"link":"http://arxiv.org/abs/2211.10243v1","tag":"data-quality"}}
{"title":"Why the pseudo label based semi-supervised learning algorithm is effective?","abstract":"Recently, pseudo label based semi-supervised learning has achieved great success in many fields. The core idea of the pseudo label based semi-supervised learning algorithm is to use the model trained on the labeled data to generate pseudo labels on the unlabeled data, and then train a model to fit the previously generated pseudo labels. We give a theory analysis for why pseudo label based semi-supervised learning is effective in this paper. We mainly compare the generalization error of the model trained under two settings: (1) There are N labeled data. (2) There are N unlabeled data and a suitable initial model. Our analysis shows that, firstly, when the amount of unlabeled data tends to infinity, the pseudo label based semi-supervised learning algorithm can obtain model which have the same generalization error upper bound as model obtained by normally training in the condition of the amount of labeled data tends to infinity. More importantly, we prove that when the amount of unlabeled data is large enough, the generalization error upper bound of the model obtained by pseudo label based semi-supervised learning algorithm can converge to the optimal upper bound with linear convergence rate. We also give the lower bound on sampling complexity to achieve linear convergence rate. Our analysis contributes to understanding the empirical successes of pseudo label-based semi-supervised learning.","created":"2022-11-18","meta":{"link":"http://arxiv.org/abs/2211.10039v2","tag":"data-quality"}}
{"title":"Contrastive Knowledge Graph Error Detection","abstract":"Knowledge Graph (KG) errors introduce non-negligible noise, severely affecting KG-related downstream tasks. Detecting errors in KGs is challenging since the patterns of errors are unknown and diverse, while ground-truth labels are rare or even unavailable. A traditional solution is to construct logical rules to verify triples, but it is not generalizable since different KGs have distinct rules with domain knowledge involved. Recent studies focus on designing tailored detectors or ranking triples based on KG embedding loss. However, they all rely on negative samples for training, which are generated by randomly replacing the head or tail entity of existing triples. Such a negative sampling strategy is not enough for prototyping practical KG errors, e.g., (Bruce_Lee, place_of_birth, China), in which the three elements are often relevant, although mismatched. We desire a more effective unsupervised learning mechanism tailored for KG error detection. To this end, we propose a novel framework - ContrAstive knowledge Graph Error Detection (CAGED). It introduces contrastive learning into KG learning and provides a novel way of modeling KG. Instead of following the traditional setting, i.e., considering entities as nodes and relations as semantic edges, CAGED augments a KG into different hyper-views, by regarding each relational triple as a node. After joint training with KG embedding and contrastive learning loss, CAGED assesses the trustworthiness of each triple based on two learning signals, i.e., the consistency of triple representations across multi-views and the self-consistency within the triple. Extensive experiments on three real-world KGs show that CAGED outperforms state-of-the-art methods in KG error detection. Our codes and datasets are available at https://github.com/Qing145/CAGED.git.","created":"2022-11-18","meta":{"link":"http://arxiv.org/abs/2211.10030v1","tag":"data-quality"}}
{"title":"Step Counting with Attention-based LSTM","abstract":"Physical activity is recognized as an essential component of overall health. One measure of physical activity, the step count, is well known as a predictor of long-term morbidity and mortality. Step Counting (SC) is the automated counting of the number of steps an individual takes over a specified period of time and space. Due to the ubiquity of smartphones and smartwatches, most current SC approaches rely on the built-in accelerometer sensors on these devices. The sensor signals are analyzed as multivariate time series, and the number of steps is calculated through a variety of approaches, such as time-domain, frequency-domain, machine-learning, and deep-learning approaches. Most of the existing approaches rely on dividing the input signal into windows, detecting steps in each window, and summing the detected steps. However, these approaches require the determination of multiple parameters, including the window size. Furthermore, most of the existing deep-learning SC approaches require ground-truth labels for every single step, which can be arduous and time-consuming to annotate. To circumvent these requirements, we present a novel SC approach utilizing many-to-one attention-based LSTM. With the proposed LSTM network, SC is solved as a regression problem, taking the entire sensor signal as input and the step count as the output. The analysis shows that the attention-based LSTM automatically learned the pattern of steps even in the absence of ground-truth labels. The experimental results on three publicly available SC datasets demonstrate that the proposed method successfully counts the number of steps with low values of mean absolute error and high values of SC accuracy.","created":"2022-11-18","meta":{"link":"http://arxiv.org/abs/2211.13114v1","tag":"data-quality"}}
{"title":"Contrastive Credibility Propagation for Reliable Semi-Supervised Learning","abstract":"Inferencing unlabeled data from labeled data is an error-prone process. Conventional neural network training is highly sensitive to supervision errors. These two realities make semi-supervised learning (SSL) troublesome. In practice, SSL approaches often fail to outperform their fully supervised baseline. Proposed is a novel framework for deep SSL via transductive pseudo-label refinement called Contrastive Credibility Propagation (CCP). Through an iterative process of refining soft pseudo-labels, CCP unifies a novel contrastive approach for generating pseudo-labels and a powerful technique to overcome instance-dependent label noise. The result is an SSL classification framework explicitly designed to overcome inevitable pseudo-label errors. Using standard text and image benchmark classification datasets, we show CCP reliably boosts or matches performance over a supervised baseline in four common real-world SSL scenarios: few-label, open-set, noisy-label, and class distribution misalignment.","created":"2022-11-17","meta":{"link":"http://arxiv.org/abs/2211.09929v2","tag":"data-quality"}}
{"title":"Data-Centric Debugging: mitigating model failures via targeted data collection","abstract":"Deep neural networks can be unreliable in the real world when the training set does not adequately cover all the settings where they are deployed. Focusing on image classification, we consider the setting where we have an error distribution $\\mathcal{E}$ representing a deployment scenario where the model fails. We have access to a small set of samples $\\mathcal{E}_{sample}$ from $\\mathcal{E}$ and it can be expensive to obtain additional samples. In the traditional model development framework, mitigating failures of the model in $\\mathcal{E}$ can be challenging and is often done in an ad hoc manner. In this paper, we propose a general methodology for model debugging that can systemically improve model performance on $\\mathcal{E}$ while maintaining its performance on the original test set. Our key assumption is that we have access to a large pool of weakly (noisily) labeled data $\\mathcal{F}$. However, naively adding $\\mathcal{F}$ to the training would hurt model performance due to the large extent of label noise. Our Data-Centric Debugging (DCD) framework carefully creates a debug-train set by selecting images from $\\mathcal{F}$ that are perceptually similar to the images in $\\mathcal{E}_{sample}$. To do this, we use the $\\ell_2$ distance in the feature space (penultimate layer activations) of various models including ResNet, Robust ResNet and DINO where we observe DINO ViTs are significantly better at discovering similar images compared to Resnets. Compared to LPIPS, we find that our method reduces compute and storage requirements by 99.58\\%. Compared to the baselines that maintain model performance on the test set, we achieve significantly (+9.45\\%) improved results on the debug-heldout sets.","created":"2022-11-17","meta":{"link":"http://arxiv.org/abs/2211.09859v1","tag":"data-quality"}}
{"title":"Unsupervised Model-based speaker adaptation of end-to-end lattice-free MMI model for speech recognition","abstract":"Modeling the speaker variability is a key challenge for automatic speech recognition (ASR) systems. In this paper, the learning hidden unit contributions (LHUC) based adaptation techniques with compact speaker dependent (SD) parameters are used to facilitate both speaker adaptive training (SAT) and unsupervised test-time speaker adaptation for end-to-end (E2E) lattice-free MMI (LF-MMI) models. An unsupervised model-based adaptation framework is proposed to estimate the SD parameters in E2E paradigm using LF-MMI and cross entropy (CE) criterions. Various regularization methods of the standard LHUC adaptation, e.g., the Bayesian LHUC (BLHUC) adaptation, are systematically investigated to mitigate the risk of overfitting, on E2E LF-MMI CNN-TDNN and CNN-TDNN-BLSTM models. Lattice-based confidence score estimation is used for adaptation data selection to reduce the supervision label uncertainty. Experiments on the 300-hour Switchboard task suggest that applying BLHUC in the proposed unsupervised E2E adaptation framework to byte pair encoding (BPE) based E2E LF-MMI systems consistently outperformed the baseline systems by relative word error rate (WER) reductions up to 10.5% and 14.7% on the NIST Hub5'00 and RT03 evaluation sets, and achieved the best performance in WERs of 9.0% and 9.7%, respectively. These results are comparable to the results of state-of-the-art adapted LF-MMI hybrid systems and adapted Conformer-based E2E systems.","created":"2022-11-17","meta":{"link":"http://arxiv.org/abs/2211.09313v2","tag":"data-quality"}}
{"title":"Region Proposal Network Pre-Training Helps Label-Efficient Object Detection","abstract":"Self-supervised pre-training, based on the pretext task of instance discrimination, has fueled the recent advance in label-efficient object detection. However, existing studies focus on pre-training only a feature extractor network to learn transferable representations for downstream detection tasks. This leads to the necessity of training multiple detection-specific modules from scratch in the fine-tuning phase. We argue that the region proposal network (RPN), a common detection-specific module, can additionally be pre-trained towards reducing the localization error of multi-stage detectors. In this work, we propose a simple pretext task that provides an effective pre-training for the RPN, towards efficiently improving downstream object detection performance. We evaluate the efficacy of our approach on benchmark object detection tasks and additional downstream tasks, including instance segmentation and few-shot detection. In comparison with multi-stage detectors without RPN pre-training, our approach is able to consistently improve downstream task performance, with largest gains found in label-scarce settings.","created":"2022-11-16","meta":{"link":"http://arxiv.org/abs/2211.09022v1","tag":"data-quality"}}
{"title":"A Basic Algorithm for Generating Individualized Numerical Scale (BAGINS)","abstract":"Linguistic labels are effective means of expressing qualitative assessments because they account for the uncertain nature of human preferences. However, to perform computations with linguistic labels, they must first be converted to numbers using a scale function. Within the context of the Analytic Hierarchy Process (AHP), the most popular scale used to represent linguistic labels numerically is the linear 1-9 scale, which was proposed by Saaty. However, this scale has been criticized by several researchers, and various alternatives are proposed in the literature. There is a growing interest in scale individualization rather than relying on a generic fixed scale since the perceptions of the decision maker regarding these linguistic labels are highly subjective. The methods proposed in the literature for scale individualization focus on minimizing the transitivity errors, i.e., consistency. In this research, we proposed a novel, easy-to-learn, easy-to-implement, and computationally less demanding scale individualization approach based on compatibility. We also developed an experimental setup and introduced two new metrics that can be used by researchers that contribute to the theory of AHP. To assess the value of scale individualization in general, and the performance of the proposed novel approach in particular, numerical and two empirical studies are conducted. The results of the analyses demonstrate that the scale individualization outperforms the conventional fixed scale approach and validates the benefit of the proposed novel heuristic.","created":"2022-11-16","meta":{"link":"http://arxiv.org/abs/2211.08740v1","tag":"data-quality"}}
{"title":"Type Information Utilized Event Detection via Multi-Channel GNNs in Electrical Power Systems","abstract":"Event detection in power systems aims to identify triggers and event types, which helps relevant personnel respond to emergencies promptly and facilitates the optimization of power supply strategies. However, the limited length of short electrical record texts causes severe information sparsity, and numerous domain-specific terminologies of power systems makes it difficult to transfer knowledge from language models pre-trained on general-domain texts. Traditional event detection approaches primarily focus on the general domain and ignore these two problems in the power system domain. To address the above issues, we propose a Multi-Channel graph neural network utilizing Type information for Event Detection in power systems, named MC-TED, leveraging a semantic channel and a topological channel to enrich information interaction from short texts. Concretely, the semantic channel refines textual representations with semantic similarity, building the semantic information interaction among potential event-related words. The topological channel generates a relation-type-aware graph modeling word dependencies, and a word-type-aware graph integrating part-of-speech tags. To further reduce errors worsened by professional terminologies in type analysis, a type learning mechanism is designed for updating the representations of both the word type and relation type in the topological channel. In this way, the information sparsity and professional term occurrence problems can be alleviated by enabling interaction between topological and semantic information. Furthermore, to address the lack of labeled data in power systems, we built a Chinese event detection dataset based on electrical Power Event texts, named PoE. In experiments, our model achieves compelling results not only on the PoE dataset, but on general-domain event detection datasets including ACE 2005 and MAVEN.","created":"2022-11-15","meta":{"link":"http://arxiv.org/abs/2211.08168v1","tag":"data-quality"}}
{"title":"An Automatic ICD Coding Network Using Partition-Based Label Attention","abstract":"International Classification of Diseases (ICD) is a global medical classification system which provides unique codes for diagnoses and procedures appropriate to a patient's clinical record. However, manual coding by human coders is expensive and error-prone. Automatic ICD coding has the potential to solve this problem. With the advancement of deep learning technologies, many deep learning-based methods for automatic ICD coding are being developed. In particular, a label attention mechanism is effective for multi-label classification, i.e., the ICD coding. It effectively obtains the label-specific representations from the input clinical records. However, because the existing label attention mechanism finds key tokens in the entire text at once, the important information dispersed in each paragraph may be omitted from the attention map. To overcome this, we propose a novel neural network architecture composed of two parts of encoders and two kinds of label attention layers. The input text is segmentally encoded in the former encoder and integrated by the follower. Then, the conventional and partition-based label attention mechanisms extract important global and local feature representations. Our classifier effectively integrates them to enhance the ICD coding performance. We verified the proposed method using the MIMIC-III, a benchmark dataset of the ICD coding. Our results show that our network improves the ICD coding performance based on the partition-based mechanism.","created":"2022-11-15","meta":{"link":"http://arxiv.org/abs/2211.08429v1","tag":"data-quality"}}
{"title":"Quantifying the Impact of Label Noise on Federated Learning","abstract":"Federated Learning (FL) is a distributed machine learning paradigm where clients collaboratively train a model using their local (human-generated) datasets. While existing studies focus on FL algorithm development to tackle data heterogeneity across clients, the important issue of data quality (e.g., label noise) in FL is overlooked. This paper aims to fill this gap by providing a quantitative study on the impact of label noise on FL. We derive an upper bound for the generalization error that is linear in the clients' label noise level. Then we conduct experiments on MNIST and CIFAR-10 datasets using various FL algorithms. Our empirical results show that the global model accuracy linearly decreases as the noise level increases, which is consistent with our theoretical analysis. We further find that label noise slows down the convergence of FL training, and the global model tends to overfit when the noise level is high.","created":"2022-11-15","meta":{"link":"http://arxiv.org/abs/2211.07816v7","tag":"data-quality"}}
{"title":"Elliptically-Contoured Tensor-variate Distributions with Application to Improved Image Learning","abstract":"Statistical analysis of tensor-valued data has largely used the tensor-variate normal (TVN) distribution that may be inadequate when data comes from distributions with heavier or lighter tails. We study a general family of elliptically contoured (EC) tensor-variate distributions and derive its characterizations, moments, marginal and conditional distributions, and the EC Wishart distribution. We describe procedures for maximum likelihood estimation from data that are (1) uncorrelated draws from an EC distribution, (2) from a scale mixture of the TVN distribution, and (3) from an underlying but unknown EC distribution, where we extend Tyler's robust estimator. A detailed simulation study highlights the benefits of choosing an EC distribution over the TVN for heavier-tailed data. We develop tensor-variate classification rules using discriminant analysis and EC errors and show that they better predict cats and dogs from images in the Animal Faces-HQ dataset than the TVN-based rules. A novel tensor-on-tensor regression and tensor-variate analysis of variance (TANOVA) framework under EC errors is also demonstrated to better characterize gender, age and ethnic origin than the usual TVN-based TANOVA in the celebrated Labeled Faces of the Wild dataset.","created":"2022-11-13","meta":{"link":"http://arxiv.org/abs/2211.06940v1","tag":"data-quality"}}
{"title":"Bead-Droplet Reactor for High-Fidelity Solid-Phase Enzymatic DNA Synthesis","abstract":"Solid-phase synthesis techniques underpin the synthesis of DNA, oligopeptides, oligosaccharides, and combinatorial libraries for drug discovery. State-of-the-art solid-phase synthesizers can produce oligonucleotides up to 200-300 nucleotides while using excess reagents. Accumulated errors over multiple reaction cycles prevent the synthesis of longer oligonucleotides for the genome scale engineering of synthetic biological systems. The sources of these errors in synthesis columns remains poorly understood. Here we show that bead-bead stacking significantly contributes to reaction errors in columns by analyzing enzymatic coupling of fluorescently labelled nucleotides onto the initiated beads along with porosity, particle tracking and diffusion calculations. To circumvent stacking, we introduce dielectrophoretic bead-droplet reactor (DBDR); a novel approach to synthesize on individual microbeads within microdroplets. Dielectrophoretic force overcomes the droplet-medium interfacial tension to encapsulate and eject individual beads from microdroplets in a droplet microfluidic device. Faster reagent diffusion in droplets, and non-uniform electric field induced enhancement in reagent concentration at its surface can improve reaction fidelities in DBDR. Fluorescence comparisons suggest around 3-fold enhancement of reaction fidelity compared to columns. DBDR can potentially enable the high-purity synthesis of arbitrarily long strands of DNA to meet the emerging demands in healthcare, environment, agriculture, materials, and computing.","created":"2022-11-13","meta":{"link":"http://arxiv.org/abs/2211.06799v1","tag":"data-quality"}}
{"title":"Sentence-Level Sign Language Recognition Framework","abstract":"We present two solutions to sentence-level SLR. Sentence-level SLR required mapping videos of sign language sentences to sequences of gloss labels. Connectionist Temporal Classification (CTC) has been used as the classifier level of both models. CTC is used to avoid pre-segmenting the sentences into individual words. The first model is an LRCN-based model, and the second model is a Multi-Cue Network. LRCN is a model in which a CNN as a feature extractor is applied to each frame before feeding them into an LSTM. In the first approach, no prior knowledge has been leveraged. Raw frames are fed into an 18-layer LRCN with a CTC on top. In the second approach, three main characteristics (hand shape, hand position, and hand movement information) associated with each sign have been extracted using Mediapipe. 2D landmarks of hand shape have been used to create the skeleton of the hands and then are fed to a CONV-LSTM model. Hand locations and hand positions as relative distance to head are fed to separate LSTMs. All three sources of information have been then integrated into a Multi-Cue network with a CTC classification layer. We evaluated the performance of proposed models on RWTH-PHOENIX-Weather. After performing an excessive search on model hyper-parameters such as the number of feature maps, input size, batch size, sequence length, LSTM memory cell, regularization, and dropout, we were able to achieve 35 Word Error Rate (WER).","created":"2022-11-13","meta":{"link":"http://arxiv.org/abs/2211.14447v1","tag":"data-quality"}}
{"title":"Lifelong and Continual Learning Dialogue Systems","abstract":"Dialogue systems, commonly known as chatbots, have gained escalating popularity in recent times due to their wide-spread applications in carrying out chit-chat conversations with users and task-oriented dialogues to accomplish various user tasks. Existing chatbots are usually trained from pre-collected and manually-labeled data and/or written with handcrafted rules. Many also use manually-compiled knowledge bases (KBs). Their ability to understand natural language is still limited, and they tend to produce many errors resulting in poor user satisfaction. Typically, they need to be constantly improved by engineers with more labeled data and more manually compiled knowledge. This book introduces the new paradigm of lifelong learning dialogue systems to endow chatbots the ability to learn continually by themselves through their own self-initiated interactions with their users and working environments to improve themselves. As the systems chat more and more with users or learn more and more from external sources, they become more and more knowledgeable and better and better at conversing. The book presents the latest developments and techniques for building such continual learning dialogue systems that continuously learn new language expressions and lexical and factual knowledge during conversation from users and off conversation from external sources, acquire new training examples during conversation, and learn conversational skills. Apart from these general topics, existing works on continual learning of some specific aspects of dialogue systems are also surveyed. The book concludes with a discussion of open challenges for future research.","created":"2022-11-12","meta":{"link":"http://arxiv.org/abs/2211.06553v1","tag":"data-quality"}}
{"title":"Gradient Imitation Reinforcement Learning for General Low-Resource Information Extraction","abstract":"Information Extraction (IE) aims to extract structured information from heterogeneous sources. IE from natural language texts include sub-tasks such as Named Entity Recognition (NER), Relation Extraction (RE), and Event Extraction (EE). Most IE systems require comprehensive understandings of sentence structure, implied semantics, and domain knowledge to perform well; thus, IE tasks always need adequate external resources and annotations. However, it takes time and effort to obtain more human annotations. Low-Resource Information Extraction (LRIE) strives to use unsupervised data, reducing the required resources and human annotation. In practice, existing systems either utilize self-training schemes to generate pseudo labels that will cause the gradual drift problem, or leverage consistency regularization methods which inevitably possess confirmation bias. To alleviate confirmation bias due to the lack of feedback loops in existing LRIE learning paradigms, we develop a Gradient Imitation Reinforcement Learning (GIRL) method to encourage pseudo-labeled data to imitate the gradient descent direction on labeled data, which can force pseudo-labeled data to achieve better optimization capabilities similar to labeled data. Based on how well the pseudo-labeled data imitates the instructive gradient descent direction obtained from labeled data, we design a reward to quantify the imitation process and bootstrap the optimization capability of pseudo-labeled data through trial and error. In addition to learning paradigms, GIRL is not limited to specific sub-tasks, and we leverage GIRL to solve all IE sub-tasks (named entity recognition, relation extraction, and event extraction) in low-resource settings (semi-supervised IE and few-shot IE).","created":"2022-11-11","meta":{"link":"http://arxiv.org/abs/2211.06014v2","tag":"data-quality"}}
{"title":"Semi-supervised Variational Autoencoder for Regression: Application on Soft Sensors","abstract":"We present the development of a semi-supervised regression method using variational autoencoders (VAE), which is customized for use in soft sensing applications. We motivate the use of semi-supervised learning considering the fact that process quality variables are not collected at the same frequency as other process variables leading to many unlabelled records in operational datasets. These unlabelled records are not possible to use for training quality variable predictions based on supervised learning methods. Use of VAEs for unsupervised learning is well established and recently they were used for regression applications based on variational inference procedures. We extend this approach of supervised VAEs for regression (SVAER) to make it learn from unlabelled data leading to semi-supervised VAEs for regression (SSVAER), then we make further modifications to their architecture using additional regularization components to make SSVAER well suited for learning from both labelled and unlabelled process data. The probabilistic regressor resulting from the variational approach makes it possible to estimate the variance of the predictions simultaneously, which provides an uncertainty quantification along with the generated predictions. We provide an extensive comparative study of SSVAER with other publicly available semi-supervised and supervised learning methods on two benchmark problems using fixed-size datasets, where we vary the percentage of labelled data available for training. In these experiments, SSVAER achieves the lowest test errors in 11 of the 20 studied cases, compared to other methods where the second best gets 4 lowest test errors out of the 20.","created":"2022-11-11","meta":{"link":"http://arxiv.org/abs/2211.05979v3","tag":"data-quality"}}
{"title":"Self-supervised learning with bi-label masked speech prediction for streaming multi-talker speech recognition","abstract":"Self-supervised learning (SSL), which utilizes the input data itself for representation learning, has achieved state-of-the-art results for various downstream speech tasks. However, most of the previous studies focused on offline single-talker applications, with limited investigations in multi-talker cases, especially for streaming scenarios. In this paper, we investigate SSL for streaming multi-talker speech recognition, which generates transcriptions of overlapping speakers in a streaming fashion. We first observe that conventional SSL techniques do not work well on this task due to the poor representation of overlapping speech. We then propose a novel SSL training objective, referred to as bi-label masked speech prediction, which explicitly preserves representations of all speakers in overlapping speech. We investigate various aspects of the proposed system including data configuration and quantizer selection. The proposed SSL setup achieves substantially better word error rates on the LibriSpeechMix dataset.","created":"2022-11-10","meta":{"link":"http://arxiv.org/abs/2211.05564v1","tag":"data-quality"}}
{"title":"IRNet: Iterative Refinement Network for Noisy Partial Label Learning","abstract":"Partial label learning (PLL) is a typical weakly supervised learning, where each sample is associated with a set of candidate labels. The basic assumption of PLL is that the ground-truth label must reside in the candidate set. However, this assumption may not be satisfied due to the unprofessional judgment of the annotators, thus limiting the practical application of PLL. In this paper, we relax this assumption and focus on a more general problem, noisy PLL, where the ground-truth label may not exist in the candidate set. To address this challenging problem, we propose a novel framework called \"Iterative Refinement Network (IRNet)\". It aims to purify the noisy samples by two key modules, i.e., noisy sample detection and label correction. Ideally, we can convert noisy PLL into traditional PLL if all noisy samples are corrected. To guarantee the performance of these modules, we start with warm-up training and exploit data augmentation to reduce prediction errors. Through theoretical analysis, we prove that IRNet is able to reduce the noise level of the dataset and eventually approximate the Bayes optimal classifier. Experimental results on multiple benchmark datasets demonstrate the effectiveness of our method. IRNet is superior to existing state-of-the-art approaches on noisy PLL.","created":"2022-11-09","meta":{"link":"http://arxiv.org/abs/2211.04774v5","tag":"data-quality"}}
{"title":"A Dynamic Graph Interactive Framework with Label-Semantic Injection for Spoken Language Understanding","abstract":"Multi-intent detection and slot filling joint models are gaining increasing traction since they are closer to complicated real-world scenarios. However, existing approaches (1) focus on identifying implicit correlations between utterances and one-hot encoded labels in both tasks while ignoring explicit label characteristics; (2) directly incorporate multi-intent information for each token, which could lead to incorrect slot prediction due to the introduction of irrelevant intent. In this paper, we propose a framework termed DGIF, which first leverages the semantic information of labels to give the model additional signals and enriched priors. Then, a multi-grain interactive graph is constructed to model correlations between intents and slots. Specifically, we propose a novel approach to construct the interactive graph based on the injection of label semantics, which can automatically update the graph to better alleviate error propagation. Experimental results show that our framework significantly outperforms existing approaches, obtaining a relative improvement of 13.7% over the previous best model on the MixATIS dataset in overall accuracy.","created":"2022-11-08","meta":{"link":"http://arxiv.org/abs/2211.04023v1","tag":"data-quality"}}
{"title":"A Semiparametric Efficient Approach To Label Shift Estimation and Quantification","abstract":"Transfer Learning is an area of statistics and machine learning research that seeks answers to the following question: how do we build successful learning algorithms when the data available for training our model is qualitatively different from the data we hope the model will perform well on? In this thesis, we focus on a specific area of Transfer Learning called label shift, also known as quantification. In quantification, the aforementioned discrepancy is isolated to a shift in the distribution of the response variable. In such a setting, accurately inferring the response variable's new distribution is both an important estimation task in its own right and a crucial step for ensuring that the learning algorithm can adapt to the new data. We make two contributions to this field. First, we present a new procedure called SELSE which estimates the shift in the response variable's distribution. Second, we prove that SELSE is semiparametric efficient among a large family of quantification algorithms, i.e., SELSE's normalized error has the smallest possible asymptotic variance matrix compared to any other algorithm in that family. This family includes nearly all existing algorithms, including ACC/PACC quantifiers and maximum likelihood based quantifiers such as EMQ and MLLS. Empirical experiments reveal that SELSE is competitive with, and in many cases outperforms, existing state-of-the-art quantification methods, and that this improvement is especially large when the number of test samples is far greater than the number of train samples.","created":"2022-11-07","meta":{"link":"http://arxiv.org/abs/2211.04274v1","tag":"data-quality"}}
{"title":"Learning to Annotate Part Segmentation with Gradient Matching","abstract":"The success of state-of-the-art deep neural networks heavily relies on the presence of large-scale labelled datasets, which are extremely expensive and time-consuming to annotate. This paper focuses on tackling semi-supervised part segmentation tasks by generating high-quality images with a pre-trained GAN and labelling the generated images with an automatic annotator. In particular, we formulate the annotator learning as a learning-to-learn problem. Given a pre-trained GAN, the annotator learns to label object parts in a set of randomly generated images such that a part segmentation model trained on these synthetic images with their predicted labels obtains low segmentation error on a small validation set of manually labelled images. We further reduce this nested-loop optimization problem to a simple gradient matching problem and efficiently solve it with an iterative algorithm. We show that our method can learn annotators from a broad range of labelled images including real images, generated images, and even analytically rendered images. Our method is evaluated with semi-supervised part segmentation tasks and significantly outperforms other semi-supervised competitors when the amount of labelled examples is extremely limited.","created":"2022-11-06","meta":{"link":"http://arxiv.org/abs/2211.03003v1","tag":"data-quality"}}
{"title":"Biased Self-supervised learning for ASR","abstract":"Self-supervised learning via masked prediction pre-training (MPPT) has shown impressive performance on a range of speech-processing tasks. This paper proposes a method to bias self-supervised learning towards a specific task. The core idea is to slightly finetune the model that is used to obtain the target sequence. This leads to better performance and a substantial increase in training speed. Furthermore, this paper proposes a variant of MPPT that allows low-footprint streaming models to be trained effectively by computing the MPPT loss on masked and unmasked frames. These approaches are evaluated for automatic speech recognition on the Librispeech corpus, where 100 hours of data served as the labelled data and 860 hours as the unlabelled data. The biased training outperforms the unbiased training by 15.5% after 250k updates and 23.8% after 100k updates on test-other. For the streaming models, the pre-training approach yields a reduction in word error rate of 44.1%.","created":"2022-11-04","meta":{"link":"http://arxiv.org/abs/2211.02536v1","tag":"data-quality"}}
{"title":"Towards Asteroid Detection in Microlensing Surveys with Deep Learning","abstract":"Asteroids are an indelible part of most astronomical surveys though only a few surveys are dedicated to their detection. Over the years, high cadence microlensing surveys have amassed several terabytes of data while scanning primarily the Galactic Bulge and Magellanic Clouds for microlensing events and thus provide a treasure trove of opportunities for scientific data mining. In particular, numerous asteroids have been observed by visual inspection of selected images. This paper presents novel deep learning-based solutions for the recovery and discovery of asteroids in the microlensing data gathered by the MOA project. Asteroid tracklets can be clearly seen by combining all the observations on a given night and these tracklets inform the structure of the dataset. Known asteroids were identified within these composite images and used for creating the labelled datasets required for supervised learning. Several custom CNN models were developed to identify images with asteroid tracklets. Model ensembling was then employed to reduce the variance in the predictions as well as to improve the generalisation error, achieving a recall of 97.67%. Furthermore, the YOLOv4 object detector was trained to localize asteroid tracklets, achieving a mean Average Precision (mAP) of 90.97%. These trained networks will be applied to 16 years of MOA archival data to find both known and unknown asteroids that have been observed by the survey over the years. The methodologies developed can be adapted for use by other surveys for asteroid recovery and discovery.","created":"2022-11-04","meta":{"link":"http://arxiv.org/abs/2211.02239v2","tag":"data-quality"}}
{"title":"Optimal Compression for Minimizing Classification Error Probability: an Information-Theoretic Approach","abstract":"We formulate the problem of performing optimal data compression under the constraints that compressed data can be used for accurate classification in machine learning. We show that this translates to a problem of minimizing the mutual information between data and its compressed version under the constraint on error probability of classification is small when using the compressed data for machine learning. We then provide analytical and computational methods to characterize the optimal trade-off between data compression and classification error probability. First, we provide an analytical characterization for the optimal compression strategy for data with binary labels. Second, for data with multiple labels, we formulate a set of convex optimization problems to characterize the optimal tradeoff, from which the optimal trade-off between the classification error and compression efficiency can be obtained by numerically solving the formulated optimization problems. We further show the improvements of our formulations over the information-bottleneck methods in classification performance.","created":"2022-11-03","meta":{"link":"http://arxiv.org/abs/2211.02012v1","tag":"data-quality"}}
{"title":"Joint Chinese Word Segmentation and Span-based Constituency Parsing","abstract":"In constituency parsing, span-based decoding is an important direction. However, for Chinese sentences, because of their linguistic characteristics, it is necessary to utilize other models to perform word segmentation first, which introduces a series of uncertainties and generally leads to errors in the computation of the constituency tree afterward. This work proposes a method for joint Chinese word segmentation and Span-based Constituency Parsing by adding extra labels to individual Chinese characters on the parse trees. Through experiments, the proposed algorithm outperforms the recent models for joint segmentation and constituency parsing on CTB 5.1.","created":"2022-11-03","meta":{"link":"http://arxiv.org/abs/2211.01638v2","tag":"data-quality"}}
{"title":"Defending with Errors: Approximate Computing for Robustness of Deep Neural Networks","abstract":"Machine-learning architectures, such as Convolutional Neural Networks (CNNs) are vulnerable to adversarial attacks: inputs crafted carefully to force the system output to a wrong label. Since machine-learning is being deployed in safety-critical and security-sensitive domains, such attacks may have catastrophic security and safety consequences. In this paper, we propose for the first time to use hardware-supported approximate computing to improve the robustness of machine-learning classifiers. We show that successful adversarial attacks against the exact classifier have poor transferability to the approximate implementation. Surprisingly, the robustness advantages also apply to white-box attacks where the attacker has unrestricted access to the approximate classifier implementation: in this case, we show that substantially higher levels of adversarial noise are needed to produce adversarial examples. Furthermore, our approximate computing model maintains the same level in terms of classification accuracy, does not require retraining, and reduces resource utilization and energy consumption of the CNN. We conducted extensive experiments on a set of strong adversarial attacks; We empirically show that the proposed implementation increases the robustness of a LeNet-5, Alexnet and VGG-11 CNNs considerably with up to 50% by-product saving in energy consumption due to the simpler nature of the approximate logic.","created":"2022-11-02","meta":{"link":"http://arxiv.org/abs/2211.01182v1","tag":"data-quality"}}
{"title":"Generative Poisoning Using Random Discriminators","abstract":"We introduce ShortcutGen, a new data poisoning attack that generates sample-dependent, error-minimizing perturbations by learning a generator. The key novelty of ShortcutGen is the use of a randomly-initialized discriminator, which provides spurious shortcuts needed for generating poisons. Different from recent, iterative methods, our ShortcutGen can generate perturbations with only one forward pass in a label-free manner, and compared to the only existing generative method, DeepConfuse, our ShortcutGen is faster and simpler to train while remaining competitive. We also demonstrate that integrating a simple augmentation strategy can further boost the robustness of ShortcutGen against early stopping, and combining augmentation and non-augmentation leads to new state-of-the-art results in terms of final validation accuracy, especially in the challenging, transfer scenario. Lastly, we speculate, through uncovering its working mechanism, that learning a more general representation space could allow ShortcutGen to work for unseen data.","created":"2022-11-02","meta":{"link":"http://arxiv.org/abs/2211.01086v1","tag":"data-quality"}}
{"title":"SpeechBlender: Speech Augmentation Framework for Mispronunciation Data Generation","abstract":"One of the biggest challenges in designing mispronunciation detection models is the unavailability of labeled L2 speech data. To overcome such data scarcity, we introduce SpeechBlender -- a fine-grained data augmentation pipeline for generating mispronunciation errors. The SpeechBlender utilizes varieties of masks to target different regions of a phonetic unit, and use the mixing factors to linearly interpolate raw speech signals while generating erroneous pronunciation instances. The masks facilitate smooth blending of the signals, thus generating more effective samples than the `Cut/Paste' method. We show the effectiveness of our augmentation technique in a phoneme-level pronunciation quality assessment task, leveraging only a good pronunciation dataset. With SpeechBlender augmentation, we observed a 3% and 2% increase in Pearson correlation coefficient (PCC) compared to no-augmentation and goodness of pronunciation augmentation scenarios respectively for Speechocean762 testset. Moreover, a 2% rise in PCC is observed when comparing our single-task phoneme-level mispronunciation detection model with a multi-task learning model using multiple-granularity information.","created":"2022-11-02","meta":{"link":"http://arxiv.org/abs/2211.00923v1","tag":"data-quality"}}
{"title":"Unsupervised Anomaly Detection of Paranasal Anomalies in the Maxillary Sinus","abstract":"Deep learning (DL) algorithms can be used to automate paranasal anomaly detection from Magnetic Resonance Imaging (MRI). However, previous works relied on supervised learning techniques to distinguish between normal and abnormal samples. This method limits the type of anomalies that can be classified as the anomalies need to be present in the training data. Further, many data points from normal and anomaly class are needed for the model to achieve satisfactory classification performance. However, experienced clinicians can segregate between normal samples (healthy maxillary sinus) and anomalous samples (anomalous maxillary sinus) after looking at a few normal samples. We mimic the clinicians ability by learning the distribution of healthy maxillary sinuses using a 3D convolutional auto-encoder (cAE) and its variant, a 3D variational autoencoder (VAE) architecture and evaluate cAE and VAE for this task. Concretely, we pose the paranasal anomaly detection as an unsupervised anomaly detection problem. Thereby, we are able to reduce the labelling effort of the clinicians as we only use healthy samples during training. Additionally, we can classify any type of anomaly that differs from the training distribution. We train our 3D cAE and VAE to learn a latent representation of healthy maxillary sinus volumes using L1 reconstruction loss. During inference, we use the reconstruction error to classify between normal and anomalous maxillary sinuses. We extract sub-volumes from larger head and neck MRIs and analyse the effect of different fields of view on the detection performance. Finally, we report which anomalies are easiest and hardest to classify using our approach. Our results demonstrate the feasibility of unsupervised detection of paranasal anomalies from MRIs with an AUPRC of 85% and 80% for cAE and VAE, respectively.","created":"2022-11-01","meta":{"link":"http://arxiv.org/abs/2211.01371v1","tag":"data-quality"}}
{"title":"GLINKX: A Scalable Unified Framework For Homophilous and Heterophilous Graphs","abstract":"In graph learning, there have been two predominant inductive biases regarding graph-inspired architectures: On the one hand, higher-order interactions and message passing work well on homophilous graphs and are leveraged by GCNs and GATs. Such architectures, however, cannot easily scale to large real-world graphs. On the other hand, shallow (or node-level) models using ego features and adjacency embeddings work well in heterophilous graphs. In this work, we propose a novel scalable shallow method -- GLINKX -- that can work both on homophilous and heterophilous graphs. GLINKX leverages (i) novel monophilous label propagations, (ii) ego/node features, (iii) knowledge graph embeddings as positional embeddings, (iv) node-level training, and (v) low-dimensional message passing. Formally, we prove novel error bounds and justify the components of GLINKX. Experimentally, we show its effectiveness on several homophilous and heterophilous datasets.","created":"2022-11-01","meta":{"link":"http://arxiv.org/abs/2211.00550v2","tag":"data-quality"}}
{"title":"Class Interference of Deep Neural Networks","abstract":"Recognizing and telling similar objects apart is even hard for human beings. In this paper, we show that there is a phenomenon of class interference with all deep neural networks. Class interference represents the learning difficulty in data, and it constitutes the largest percentage of generalization errors by deep networks. To understand class interference, we propose cross-class tests, class ego directions and interference models. We show how to use these definitions to study minima flatness and class interference of a trained model. We also show how to detect class interference during training through label dancing pattern and class dancing notes.","created":"2022-10-31","meta":{"link":"http://arxiv.org/abs/2211.01370v1","tag":"data-quality"}}
{"title":"The Importance of Accurate Alignments in End-to-End Speech Synthesis","abstract":"Unit selection synthesis systems required accurate segmentation and labeling of the speech signal owing to the concatenative nature. Hidden Markov model-based speech synthesis accommodates some transcription errors, but it was later shown that accurate transcriptions yield highly intelligible speech with smaller amounts of training data. With the arrival of end-to-end (E2E) systems, it was observed that very good quality speech could be synthesised with large amounts of data. As end-to-end synthesis progressed from Tacotron to FastSpeech2, it has become imminent that features that represent prosody are important for good-quality synthesis. In particular, durations of the sub-word units are important. Variants of FastSpeech use a teacher model or forced alignments to obtain good-quality synthesis. In this paper, we focus on duration prediction, using signal processing cues in tandem with forced alignment to produce accurate phone durations during training.   The current work aims to highlight the importance of accurate alignments for good-quality synthesis. An attempt is made to train the E2E systems with accurately labeled data, and compare the same with approximately labeled data.","created":"2022-10-31","meta":{"link":"http://arxiv.org/abs/2210.17153v1","tag":"data-quality"}}
{"title":"Predicting Multi-Codebook Vector Quantization Indexes for Knowledge Distillation","abstract":"Knowledge distillation(KD) is a common approach to improve model performance in automatic speech recognition (ASR), where a student model is trained to imitate the output behaviour of a teacher model. However, traditional KD methods suffer from teacher label storage issue, especially when the training corpora are large. Although on-the-fly teacher label generation tackles this issue, the training speed is significantly slower as the teacher model has to be evaluated every batch. In this paper, we reformulate the generation of teacher label as a codec problem. We propose a novel Multi-codebook Vector Quantization (MVQ) approach that compresses teacher embeddings to codebook indexes (CI). Based on this, a KD training framework (MVQ-KD) is proposed where a student model predicts the CI generated from the embeddings of a self-supervised pre-trained teacher model. Experiments on the LibriSpeech clean-100 hour show that MVQ-KD framework achieves comparable performance as traditional KD methods (l1, l2), while requiring 256 times less storage. When the full LibriSpeech dataset is used, MVQ-KD framework results in 13.8% and 8.2% relative word error rate reductions (WERRs) for non -streaming transducer on test-clean and test-other and 4.0% and 4.9% for streaming transducer. The implementation of this work is already released as a part of the open-source project icefall.","created":"2022-10-31","meta":{"link":"http://arxiv.org/abs/2211.00508v1","tag":"data-quality"}}
{"title":"Reformulating van Rijsbergen's $F_\u03b2$ metric for weighted binary cross-entropy","abstract":"The separation of performance metrics from gradient based loss functions may not always give optimal results and may miss vital aggregate information. This paper investigates incorporating a performance metric alongside differentiable loss functions to inform training outcomes. The goal is to guide model performance and interpretation by assuming statistical distributions on this performance metric for dynamic weighting. The focus is on van Rijsbergens $F_{\\beta}$ metric -- a popular choice for gauging classification performance. Through distributional assumptions on the $F_{\\beta}$, an intermediary link can be established to the standard binary cross-entropy via dynamic penalty weights. First, the $F_{\\beta}$ metric is reformulated to facilitate assuming statistical distributions with accompanying proofs for the cumulative density function. These probabilities are used within a knee curve algorithm to find an optimal $\\beta$ or $\\beta_{opt}$. This $\\beta_{opt}$ is used as a weight or penalty in the proposed weighted binary cross-entropy. Experimentation on publicly available data with imbalanced classes mostly yields better and interpretable results as compared to the baseline. For example, for the IMDB text data with known labeling errors, a 14% boost is shown. This methodology can accelerate training and provide better interpretation.","created":"2022-10-29","meta":{"link":"http://arxiv.org/abs/2210.16458v1","tag":"data-quality"}}
{"title":"A comprehensive study on self-supervised distillation for speaker representation learning","abstract":"In real application scenarios, it is often challenging to obtain a large amount of labeled data for speaker representation learning due to speaker privacy concerns. Self-supervised learning with no labels has become a more and more promising way to solve it. Compared with contrastive learning, self-distilled approaches use only positive samples in the loss function and thus are more attractive. In this paper, we present a comprehensive study on self-distilled self-supervised speaker representation learning, especially on critical data augmentation. Our proposed strategy of audio perturbation augmentation has pushed the performance of the speaker representation to a new limit. The experimental results show that our model can achieve a new SoTA on Voxceleb1 speaker verification evaluation benchmark ( i.e., equal error rate (EER) 2.505%, 2.473%, and 4.791% for trial Vox1-O, Vox1-E and Vox1-H , respectively), discarding any speaker labels in the training phase.","created":"2022-10-28","meta":{"link":"http://arxiv.org/abs/2210.15936v2","tag":"data-quality"}}
{"title":"Speaker recognition with two-step multi-modal deep cleansing","abstract":"Neural network-based speaker recognition has achieved significant improvement in recent years. A robust speaker representation learns meaningful knowledge from both hard and easy samples in the training set to achieve good performance. However, noisy samples (i.e., with wrong labels) in the training set induce confusion and cause the network to learn the incorrect representation. In this paper, we propose a two-step audio-visual deep cleansing framework to eliminate the effect of noisy labels in speaker representation learning. This framework contains a coarse-grained cleansing step to search for the peculiar samples, followed by a fine-grained cleansing step to filter out the noisy labels. Our study starts from an efficient audio-visual speaker recognition system, which achieves a close to perfect equal-error-rate (EER) of 0.01\\%, 0.07\\% and 0.13\\% on the Vox-O, E and H test sets. With the proposed multi-modal cleansing mechanism, four different speaker recognition networks achieve an average improvement of 5.9\\%. Code has been made available at: \\textcolor{magenta}{\\url{https://github.com/TaoRuijie/AVCleanse}}.","created":"2022-10-28","meta":{"link":"http://arxiv.org/abs/2210.15903v1","tag":"data-quality"}}
{"title":"Clustering High-dimensional Data via Feature Selection","abstract":"High-dimensional clustering analysis is a challenging problem in statistics and machine learning, with broad applications such as the analysis of microarray data and RNA-seq data. In this paper, we propose a new clustering procedure called Spectral Clustering with Feature Selection (SC-FS), where we first obtain an initial estimate of labels via spectral clustering, then select a small fraction of features with the largest R-squared with these labels, i.e., the proportion of variation explained by group labels, and conduct clustering again using selected features. Under mild conditions, we prove that the proposed method identifies all informative features with high probability and achieves minimax optimal clustering error rate for the sparse Gaussian mixture model. Applications of SC-FS to four real world data sets demonstrate its usefulness in clustering high-dimensional data.","created":"2022-10-27","meta":{"link":"http://arxiv.org/abs/2210.15801v1","tag":"data-quality"}}
{"title":"Token-level Sequence Labeling for Spoken Language Understanding using Compositional End-to-End Models","abstract":"End-to-end spoken language understanding (SLU) systems are gaining popularity over cascaded approaches due to their simplicity and ability to avoid error propagation. However, these systems model sequence labeling as a sequence prediction task causing a divergence from its well-established token-level tagging formulation. We build compositional end-to-end SLU systems that explicitly separate the added complexity of recognizing spoken mentions in SLU from the NLU task of sequence labeling. By relying on intermediate decoders trained for ASR, our end-to-end systems transform the input modality from speech to token-level representations that can be used in the traditional sequence labeling framework. This composition of ASR and NLU formulations in our end-to-end SLU system offers direct compatibility with pre-trained ASR and NLU systems, allows performance monitoring of individual components and enables the use of globally normalized losses like CRF, making them attractive in practical scenarios. Our models outperform both cascaded and direct end-to-end models on a labeling task of named entity recognition across SLU benchmarks.","created":"2022-10-27","meta":{"link":"http://arxiv.org/abs/2210.15734v1","tag":"data-quality"}}
{"title":"FedAudio: A Federated Learning Benchmark for Audio Tasks","abstract":"Federated learning (FL) has gained substantial attention in recent years due to the data privacy concerns related to the pervasiveness of consumer devices that continuously collect data from users. While a number of FL benchmarks have been developed to facilitate FL research, none of them include audio data and audio-related tasks. In this paper, we fill this critical gap by introducing a new FL benchmark for audio tasks which we refer to as FedAudio. FedAudio includes four representative and commonly used audio datasets from three important audio tasks that are well aligned with FL use cases. In particular, a unique contribution of FedAudio is the introduction of data noises and label errors to the datasets to emulate challenges when deploying FL systems in real-world settings. FedAudio also includes the benchmark results of the datasets and a PyTorch library with the objective of facilitating researchers to fairly compare their algorithms. We hope FedAudio could act as a catalyst to inspire new FL research for audio tasks and thus benefit the acoustic and speech research community. The datasets and benchmark results can be accessed at https://github.com/zhang-tuo-pdf/FedAudio.","created":"2022-10-27","meta":{"link":"http://arxiv.org/abs/2210.15707v4","tag":"data-quality"}}
{"title":"Joint Multi-Person Body Detection and Orientation Estimation via One Unified Embedding","abstract":"Human body orientation estimation (HBOE) is widely applied into various applications, including robotics, surveillance, pedestrian analysis and autonomous driving. Although many approaches have been addressing the HBOE problem from specific under-controlled scenes to challenging in-the-wild environments, they assume human instances are already detected and take a well cropped sub-image as the input. This setting is less efficient and prone to errors in real application, such as crowds of people. In the paper, we propose a single-stage end-to-end trainable framework for tackling the HBOE problem with multi-persons. By integrating the prediction of bounding boxes and direction angles in one embedding, our method can jointly estimate the location and orientation of all bodies in one image directly. Our key idea is to integrate the HBOE task into the multi-scale anchor channel predictions of persons for concurrently benefiting from engaged intermediate features. Therefore, our approach can naturally adapt to difficult instances involving low resolution and occlusion as in object detection. We validated the efficiency and effectiveness of our method in the recently presented benchmark MEBOW with extensive experiments. Besides, we completed ambiguous instances ignored by the MEBOW dataset, and provided corresponding weak body-orientation labels to keep the integrity and consistency of it for supporting studies toward multi-persons. Our work is available at https://github.com/hnuzhy/JointBDOE.","created":"2022-10-27","meta":{"link":"http://arxiv.org/abs/2210.15586v2","tag":"data-quality"}}
{"title":"Self-Supervised Training of Speaker Encoder with Multi-Modal Diverse Positive Pairs","abstract":"We study a novel neural architecture and its training strategies of speaker encoder for speaker recognition without using any identity labels. The speaker encoder is trained to extract a fixed-size speaker embedding from a spoken utterance of various length. Contrastive learning is a typical self-supervised learning technique. However, the quality of the speaker encoder depends very much on the sampling strategy of positive and negative pairs. It is common that we sample a positive pair of segments from the same utterance. Unfortunately, such poor-man's positive pairs (PPP) lack necessary diversity for the training of a robust encoder. In this work, we propose a multi-modal contrastive learning technique with novel sampling strategies. By cross-referencing between speech and face data, we study a method that finds diverse positive pairs (DPP) for contrastive learning, thus improving the robustness of the speaker encoder. We train the speaker encoder on the VoxCeleb2 dataset without any speaker labels, and achieve an equal error rate (EER) of 2.89\\%, 3.17\\% and 6.27\\% under the proposed progressive clustering strategy, and an EER of 1.44\\%, 1.77\\% and 3.27\\% under the two-stage learning strategy with pseudo labels, on the three test sets of VoxCeleb1. This novel solution outperforms the state-of-the-art self-supervised learning methods by a large margin, at the same time, achieves comparable results with the supervised learning counterpart. We also evaluate our self-supervised learning technique on LRS2 and LRW datasets, where the speaker information is unknown. All experiments suggest that the proposed neural architecture and sampling strategies are robust across datasets.","created":"2022-10-27","meta":{"link":"http://arxiv.org/abs/2210.15385v1","tag":"data-quality"}}
{"title":"Parsing linearizations appreciate PoS tags - but some are fussy about errors","abstract":"PoS tags, once taken for granted as a useful resource for syntactic parsing, have become more situational with the popularization of deep learning. Recent work on the impact of PoS tags on graph- and transition-based parsers suggests that they are only useful when tagging accuracy is prohibitively high, or in low-resource scenarios. However, such an analysis is lacking for the emerging sequence labeling parsing paradigm, where it is especially relevant as some models explicitly use PoS tags for encoding and decoding. We undertake a study and uncover some trends. Among them, PoS tags are generally more useful for sequence labeling parsers than for other paradigms, but the impact of their accuracy is highly encoding-dependent, with the PoS-based head-selection encoding being best only when both tagging accuracy and resource availability are high.","created":"2022-10-27","meta":{"link":"http://arxiv.org/abs/2210.15219v1","tag":"data-quality"}}
{"title":"Anonymized Histograms in Intermediate Privacy Models","abstract":"We study the problem of privately computing the anonymized histogram (a.k.a. unattributed histogram), which is defined as the histogram without item labels. Previous works have provided algorithms with $\\ell_1$- and $\\ell_2^2$-errors of $O_\\varepsilon(\\sqrt{n})$ in the central model of differential privacy (DP).   In this work, we provide an algorithm with a nearly matching error guarantee of $\\tilde{O}_\\varepsilon(\\sqrt{n})$ in the shuffle DP and pan-private models. Our algorithm is very simple: it just post-processes the discrete Laplace-noised histogram! Using this algorithm as a subroutine, we show applications in privately estimating symmetric properties of distributions such as entropy, support coverage, and support size.","created":"2022-10-27","meta":{"link":"http://arxiv.org/abs/2210.15178v1","tag":"data-quality"}}
{"title":"CLIP-FLow: Contrastive Learning by semi-supervised Iterative Pseudo labeling for Optical Flow Estimation","abstract":"Synthetic datasets are often used to pretrain end-to-end optical flow networks, due to the lack of a large amount of labeled, real-scene data. But major drops in accuracy occur when moving from synthetic to real scenes. How do we better transfer the knowledge learned from synthetic to real domains? To this end, we propose CLIP-FLow, a semi-supervised iterative pseudo-labeling framework to transfer the pretraining knowledge to the target real domain. We leverage large-scale, unlabeled real data to facilitate transfer learning with the supervision of iteratively updated pseudo-ground truth labels, bridging the domain gap between the synthetic and the real. In addition, we propose a contrastive flow loss on reference features and the warped features by pseudo ground truth flows, to further boost the accurate matching and dampen the mismatching due to motion, occlusion, or noisy pseudo labels. We adopt RAFT as the backbone and obtain an F1-all error of 4.11%, i.e. a 19% error reduction from RAFT (5.10%) and ranking 2$^{nd}$ place at submission on the KITTI 2015 benchmark. Our framework can also be extended to other models, e.g. CRAFT, reducing the F1-all error from 4.79% to 4.66% on KITTI 2015 benchmark.","created":"2022-10-25","meta":{"link":"http://arxiv.org/abs/2210.14383v3","tag":"data-quality"}}
{"title":"Influence Functions for Sequence Tagging Models","abstract":"Many language tasks (e.g., Named Entity Recognition, Part-of-Speech tagging, and Semantic Role Labeling) are naturally framed as sequence tagging problems. However, there has been comparatively little work on interpretability methods for sequence tagging models. In this paper, we extend influence functions - which aim to trace predictions back to the training points that informed them - to sequence tagging tasks. We define the influence of a training instance segment as the effect that perturbing the labels within this segment has on a test segment level prediction. We provide an efficient approximation to compute this, and show that it tracks with the true segment influence, measured empirically. We show the practical utility of segment influence by using the method to identify systematic annotation errors in two named entity recognition corpora. Code to reproduce our results is available at https://github.com/successar/Segment_Influence_Functions.","created":"2022-10-25","meta":{"link":"http://arxiv.org/abs/2210.14177v1","tag":"data-quality"}}
{"title":"Unsupervised Anomaly Detection for Auditing Data and Impact of Categorical Encodings","abstract":"In this paper, we introduce the Vehicle Claims dataset, consisting of fraudulent insurance claims for automotive repairs. The data belongs to the more broad category of Auditing data, which includes also Journals and Network Intrusion data. Insurance claim data are distinctively different from other auditing data (such as network intrusion data) in their high number of categorical attributes. We tackle the common problem of missing benchmark datasets for anomaly detection: datasets are mostly confidential, and the public tabular datasets do not contain relevant and sufficient categorical attributes. Therefore, a large-sized dataset is created for this purpose and referred to as Vehicle Claims (VC) dataset. The dataset is evaluated on shallow and deep learning methods. Due to the introduction of categorical attributes, we encounter the challenge of encoding them for the large dataset. As One Hot encoding of high cardinal dataset invokes the \"curse of dimensionality\", we experiment with GEL encoding and embedding layer for representing categorical attributes. Our work compares competitive learning, reconstruction-error, density estimation and contrastive learning approaches for Label, One Hot, GEL encoding and embedding layer to handle categorical values.","created":"2022-10-25","meta":{"link":"http://arxiv.org/abs/2210.14056v2","tag":"data-quality"}}
{"title":"Some Simulation and Empirical Results for Semi-Supervised Learning of the Bayes Rule of Allocation","abstract":"There has been increasing attention to semi-supervised learning (SSL) approaches in machine learning to forming a classifier in situations where the training data consists of some feature vectors that have their class labels missing. In this study, we consider the generative model approach proposed by Ahfock&McLachlan(2020) who introduced a framework with a missingness mechanism for the missing labels of the unclassified features. In the case of two multivariate normal classes with a common covariance matrix, they showed that the error rate of the estimated Bayes' rule formed by this SSL approach can actually have lower error rate than the one that could be formed from a completely classified sample. In this study we consider this rather surprising result in cases where there may be more than two normal classes with not necessarily common covariance matrices.","created":"2022-10-25","meta":{"link":"http://arxiv.org/abs/2210.13785v1","tag":"data-quality"}}
{"title":"PseudoAugment: Learning to Use Unlabeled Data for Data Augmentation in Point Clouds","abstract":"Data augmentation is an important technique to improve data efficiency and save labeling cost for 3D detection in point clouds. Yet, existing augmentation policies have so far been designed to only utilize labeled data, which limits the data diversity. In this paper, we recognize that pseudo labeling and data augmentation are complementary, thus propose to leverage unlabeled data for data augmentation to enrich the training data. In particular, we design three novel pseudo-label based data augmentation policies (PseudoAugments) to fuse both labeled and pseudo-labeled scenes, including frames (PseudoFrame), objecta (PseudoBBox), and background (PseudoBackground). PseudoAugments outperforms pseudo labeling by mitigating pseudo labeling errors and generating diverse fused training scenes. We demonstrate PseudoAugments generalize across point-based and voxel-based architectures, different model capacity and both KITTI and Waymo Open Dataset. To alleviate the cost of hyperparameter tuning and iterative pseudo labeling, we develop a population-based data augmentation framework for 3D detection, named AutoPseudoAugment. Unlike previous works that perform pseudo-labeling offline, our framework performs PseudoAugments and hyperparameter tuning in one shot to reduce computational cost. Experimental results on the large-scale Waymo Open Dataset show our method outperforms state-of-the-art auto data augmentation method (PPBA) and self-training method (pseudo labeling). In particular, AutoPseudoAugment is about 3X and 2X data efficient on vehicle and pedestrian tasks compared to prior arts. Notably, AutoPseudoAugment nearly matches the full dataset training results, with just 10% of the labeled run segments on the vehicle detection task.","created":"2022-10-24","meta":{"link":"http://arxiv.org/abs/2210.13428v1","tag":"data-quality"}}
{"title":"Additive Interventions Yield Robust Multi-Domain Machine Translation Models","abstract":"Additive interventions are a recently-proposed mechanism for controlling target-side attributes in neural machine translation. In contrast to tag-based approaches which manipulate the raw source sequence, interventions work by directly modulating the encoder representation of all tokens in the sequence. We examine the role of additive interventions in a large-scale multi-domain machine translation setting and compare its performance in various inference scenarios. We find that while the performance difference is small between intervention-based systems and tag-based systems when the domain label matches the test domain, intervention-based systems are robust to label error, making them an attractive choice under label uncertainty. Further, we find that the superiority of single-domain fine-tuning comes under question when training data size is scaled, contradicting previous findings.","created":"2022-10-23","meta":{"link":"http://arxiv.org/abs/2210.12727v1","tag":"data-quality"}}
{"title":"Conformal Predictor for Improving Zero-shot Text Classification Efficiency","abstract":"Pre-trained language models (PLMs) have been shown effective for zero-shot (0shot) text classification. 0shot models based on natural language inference (NLI) and next sentence prediction (NSP) employ cross-encoder architecture and infer by making a forward pass through the model for each label-text pair separately. This increases the computational cost to make inferences linearly in the number of labels. In this work, we improve the efficiency of such cross-encoder-based 0shot models by restricting the number of likely labels using another fast base classifier-based conformal predictor (CP) calibrated on samples labeled by the 0shot model. Since a CP generates prediction sets with coverage guarantees, it reduces the number of target labels without excluding the most probable label based on the 0shot model. We experiment with three intent and two topic classification datasets. With a suitable CP for each dataset, we reduce the average inference time for NLI- and NSP-based models by 25.6% and 22.2% respectively, without dropping performance below the predefined error rate of 1%.","created":"2022-10-23","meta":{"link":"http://arxiv.org/abs/2210.12619v1","tag":"data-quality"}}
{"title":"PcMSP: A Dataset for Scientific Action Graphs Extraction from Polycrystalline Materials Synthesis Procedure Text","abstract":"Scientific action graphs extraction from materials synthesis procedures is important for reproducible research, machine automation, and material prediction. But the lack of annotated data has hindered progress in this field. We demonstrate an effort to annotate Polycrystalline Materials Synthesis Procedures (PcMSP) from 305 open access scientific articles for the construction of synthesis action graphs. This is a new dataset for material science information extraction that simultaneously contains the synthesis sentences extracted from the experimental paragraphs, as well as the entity mentions and intra-sentence relations. A two-step human annotation and inter-annotator agreement study guarantee the high quality of the PcMSP corpus. We introduce four natural language processing tasks: sentence classification, named entity recognition, relation classification, and joint extraction of entities and relations. Comprehensive experiments validate the effectiveness of several state-of-the-art models for these challenges while leaving large space for improvement. We also perform the error analysis and point out some unique challenges that require further investigation. We will release our annotation scheme, the corpus, and codes to the research community to alleviate the scarcity of labeled data in this domain.","created":"2022-10-22","meta":{"link":"http://arxiv.org/abs/2210.12401v1","tag":"data-quality"}}
{"title":"On the Calibration of Massively Multilingual Language Models","abstract":"Massively Multilingual Language Models (MMLMs) have recently gained popularity due to their surprising effectiveness in cross-lingual transfer. While there has been much work in evaluating these models for their performance on a variety of tasks and languages, little attention has been paid on how well calibrated these models are with respect to the confidence in their predictions. We first investigate the calibration of MMLMs in the zero-shot setting and observe a clear case of miscalibration in low-resource languages or those which are typologically diverse from English. Next, we empirically show that calibration methods like temperature scaling and label smoothing do reasonably well towards improving calibration in the zero-shot scenario. We also find that few-shot examples in the language can further help reduce the calibration errors, often substantially. Overall, our work contributes towards building more reliable multilingual models by highlighting the issue of their miscalibration, understanding what language and model specific factors influence it, and pointing out the strategies to improve the same.","created":"2022-10-21","meta":{"link":"http://arxiv.org/abs/2210.12265v1","tag":"data-quality"}}
{"title":"A Non-Asymptotic Moreau Envelope Theory for High-Dimensional Generalized Linear Models","abstract":"We prove a new generalization bound that shows for any class of linear predictors in Gaussian space, the Rademacher complexity of the class and the training error under any continuous loss $\\ell$ can control the test error under all Moreau envelopes of the loss $\\ell$. We use our finite-sample bound to directly recover the \"optimistic rate\" of Zhou et al. (2021) for linear regression with the square loss, which is known to be tight for minimal $\\ell_2$-norm interpolation, but we also handle more general settings where the label is generated by a potentially misspecified multi-index model. The same argument can analyze noisy interpolation of max-margin classifiers through the squared hinge loss, and establishes consistency results in spiked-covariance settings. More generally, when the loss is only assumed to be Lipschitz, our bound effectively improves Talagrand's well-known contraction lemma by a factor of two, and we prove uniform convergence of interpolators (Koehler et al. 2021) for all smooth, non-negative losses. Finally, we show that application of our generalization bound using localized Gaussian width will generally be sharp for empirical risk minimizers, establishing a non-asymptotic Moreau envelope theory for generalization that applies outside of proportional scaling regimes, handles model misspecification, and complements existing asymptotic Moreau envelope theories for M-estimation.","created":"2022-10-21","meta":{"link":"http://arxiv.org/abs/2210.12082v1","tag":"data-quality"}}
{"title":"Cyclical Self-Supervision for Semi-Supervised Ejection Fraction Prediction from Echocardiogram Videos","abstract":"Left-ventricular ejection fraction (LVEF) is an important indicator of heart failure. Existing methods for LVEF estimation from video require large amounts of annotated data to achieve high performance, e.g. using 10,030 labeled echocardiogram videos to achieve mean absolute error (MAE) of 4.10. Labeling these videos is time-consuming however and limits potential downstream applications to other heart diseases. This paper presents the first semi-supervised approach for LVEF prediction. Unlike general video prediction tasks, LVEF prediction is specifically related to changes in the left ventricle (LV) in echocardiogram videos. By incorporating knowledge learned from predicting LV segmentations into LVEF regression, we can provide additional context to the model for better predictions. To this end, we propose a novel Cyclical Self-Supervision (CSS) method for learning video-based LV segmentation, which is motivated by the observation that the heartbeat is a cyclical process with temporal repetition. Prediction masks from our segmentation model can then be used as additional input for LVEF regression to provide spatial context for the LV region. We also introduce teacher-student distillation to distill the information from LV segmentation masks into an end-to-end LVEF regression model that only requires video inputs. Results show our method outperforms alternative semi-supervised methods and can achieve MAE of 4.17, which is competitive with state-of-the-art supervised performance, using half the number of labels. Validation on an external dataset also shows improved generalization ability from using our method. Our code is available at https://github.com/xmed-lab/CSS-SemiVideo.","created":"2022-10-20","meta":{"link":"http://arxiv.org/abs/2210.11291v2","tag":"data-quality"}}
{"title":"Pseudo-Label Noise Suppression Techniques for Semi-Supervised Semantic Segmentation","abstract":"Semi-supervised learning (SSL) can reduce the need for large labelled datasets by incorporating unlabelled data into the training. This is particularly interesting for semantic segmentation, where labelling data is very costly and time-consuming. Current SSL approaches use an initially supervised trained model to generate predictions for unlabelled images, called pseudo-labels, which are subsequently used for training a new model from scratch. Since the predictions usually do not come from an error-free neural network, they are naturally full of errors. However, training with partially incorrect labels often reduce the final model performance. Thus, it is crucial to manage errors/noise of pseudo-labels wisely. In this work, we use three mechanisms to control pseudo-label noise and errors: (1) We construct a solid base framework by mixing images with cow-patterns on unlabelled images to reduce the negative impact of wrong pseudo-labels. Nevertheless, wrong pseudo-labels still have a negative impact on the performance. Therefore, (2) we propose a simple and effective loss weighting scheme for pseudo-labels defined by the feedback of the model trained on these pseudo-labels. This allows us to soft-weight the pseudo-label training examples based on their determined confidence score during training. (3) We also study the common practice to ignore pseudo-labels with low confidence and empirically analyse the influence and effect of pseudo-labels with different confidence ranges on SSL and the contribution of pseudo-label filtering to the achievable performance gains. We show that our method performs superior to state of-the-art alternatives on various datasets. Furthermore, we show that our findings also transfer to other tasks such as human pose estimation. Our code is available at https://github.com/ChristmasFan/SSL_Denoising_Segmentation.","created":"2022-10-19","meta":{"link":"http://arxiv.org/abs/2210.10426v1","tag":"data-quality"}}
{"title":"Self-supervised Representations and Node Embedding Graph Neural Networks for Accurate and Multi-scale Analysis of Materials","abstract":"Supervised machine learning algorithms, such as graph neural networks (GNN), have successfully predicted material properties. However, the superior performance of GNN usually relies on end-to-end learning on large material datasets, which may lose the physical insight of multi-scale information about materials. And the process of labeling data consumes many resources and inevitably introduces errors, which constrains the accuracy of prediction. We propose to train the GNN model by self-supervised learning on the node and edge information of the crystal graph. Compared with the popular manually constructed material descriptors, the self-supervised atomic representation can reach better prediction performance on material properties. Furthermore, it may provide physical insights by tuning the range information. Applying the self-supervised atomic representation on the magnetic moment datasets, we show how they extract rules and information from the magnetic materials. To incorporate rich physical information into the GNN model, we develop the node-embedding graph neural networks (NEGNN) framework and show significant improvements in the prediction performance. The self-supervised material representation and the NEGNN framework may investigate in-depth information from materials and can be applied to small datasets with increased prediction accuracy.","created":"2022-10-19","meta":{"link":"http://arxiv.org/abs/2211.03563v2","tag":"data-quality"}}
{"title":"Leveraging a New Spanish Corpus for Multilingual and Crosslingual Metaphor Detection","abstract":"The lack of wide coverage datasets annotated with everyday metaphorical expressions for languages other than English is striking. This means that most research on supervised metaphor detection has been published only for that language. In order to address this issue, this work presents the first corpus annotated with naturally occurring metaphors in Spanish large enough to develop systems to perform metaphor detection. The presented dataset, CoMeta, includes texts from various domains, namely, news, political discourse, Wikipedia and reviews. In order to label CoMeta, we apply the MIPVU method, the guidelines most commonly used to systematically annotate metaphor on real data. We use our newly created dataset to provide competitive baselines by fine-tuning several multilingual and monolingual state-of-the-art large language models. Furthermore, by leveraging the existing VUAM English data in addition to CoMeta, we present the, to the best of our knowledge, first cross-lingual experiments on supervised metaphor detection. Finally, we perform a detailed error analysis that explores the seemingly high transfer of everyday metaphor across these two languages and datasets.","created":"2022-10-19","meta":{"link":"http://arxiv.org/abs/2210.10358v2","tag":"data-quality"}}
{"title":"SQ Lower Bounds for Learning Single Neurons with Massart Noise","abstract":"We study the problem of PAC learning a single neuron in the presence of Massart noise. Specifically, for a known activation function $f: \\mathbb{R} \\to \\mathbb{R}$, the learner is given access to labeled examples $(\\mathbf{x}, y) \\in \\mathbb{R}^d \\times \\mathbb{R}$, where the marginal distribution of $\\mathbf{x}$ is arbitrary and the corresponding label $y$ is a Massart corruption of $f(\\langle \\mathbf{w}, \\mathbf{x} \\rangle)$. The goal of the learner is to output a hypothesis $h: \\mathbb{R}^d \\to \\mathbb{R}$ with small squared loss. For a range of activation functions, including ReLUs, we establish super-polynomial Statistical Query (SQ) lower bounds for this learning problem. In more detail, we prove that no efficient SQ algorithm can approximate the optimal error within any constant factor. Our main technical contribution is a novel SQ-hard construction for learning $\\{ \\pm 1\\}$-weight Massart halfspaces on the Boolean hypercube that is interesting on its own right.","created":"2022-10-18","meta":{"link":"http://arxiv.org/abs/2210.09949v1","tag":"data-quality"}}
{"title":"Making Split Learning Resilient to Label Leakage by Potential Energy Loss","abstract":"As a practical privacy-preserving learning method, split learning has drawn much attention in academia and industry. However, its security is constantly being questioned since the intermediate results are shared during training and inference. In this paper, we focus on the privacy leakage problem caused by the trained split model, i.e., the attacker can use a few labeled samples to fine-tune the bottom model, and gets quite good performance. To prevent such kind of privacy leakage, we propose the potential energy loss to make the output of the bottom model become a more `complicated' distribution, by pushing outputs of the same class towards the decision boundary. Therefore, the adversary suffers a large generalization error when fine-tuning the bottom model with only a few leaked labeled samples. Experiment results show that our method significantly lowers the attacker's fine-tuning accuracy, making the split model more resilient to label leakage.","created":"2022-10-18","meta":{"link":"http://arxiv.org/abs/2210.09617v1","tag":"data-quality"}}
{"title":"Improving Contrastive Learning on Visually Homogeneous Mars Rover Images","abstract":"Contrastive learning has recently demonstrated superior performance to supervised learning, despite requiring no training labels. We explore how contrastive learning can be applied to hundreds of thousands of unlabeled Mars terrain images, collected from the Mars rovers Curiosity and Perseverance, and from the Mars Reconnaissance Orbiter. Such methods are appealing since the vast majority of Mars images are unlabeled as manual annotation is labor intensive and requires extensive domain knowledge. Contrastive learning, however, assumes that any given pair of distinct images contain distinct semantic content. This is an issue for Mars image datasets, as any two pairs of Mars images are far more likely to be semantically similar due to the lack of visual diversity on the planet's surface. Making the assumption that pairs of images will be in visual contrast - when they are in fact not - results in pairs that are falsely considered as negatives, impacting training performance. In this study, we propose two approaches to resolve this: 1) an unsupervised deep clustering step on the Mars datasets, which identifies clusters of images containing similar semantic content and corrects false negative errors during training, and 2) a simple approach which mixes data from different domains to increase visual diversity of the total training dataset. Both cases reduce the rate of false negative pairs, thus minimizing the rate in which the model is incorrectly penalized during contrastive training. These modified approaches remain fully unsupervised end-to-end. To evaluate their performance, we add a single linear layer trained to generate class predictions based on these contrastively-learned features and demonstrate increased performance compared to supervised models; observing an improvement in classification accuracy of 3.06% using only 10% of the labeled data.","created":"2022-10-17","meta":{"link":"http://arxiv.org/abs/2210.09234v1","tag":"data-quality"}}
{"title":"A Saccaded Visual Transformer for General Object Spotting","abstract":"This paper presents the novel combination of a visual transformer style patch classifier with saccaded local attention. A novel optimisation paradigm for training object models is also presented, rather than the optimisation function minimising class membership probability error the network is trained to estimate the normalised distance to the centroid of labelled objects. This approach builds a degree of transnational invariance directly into the model and allows fast saccaded search with gradient ascent to find object centroids. The resulting saccaded visual transformer is demonstrated on human faces.","created":"2022-10-17","meta":{"link":"http://arxiv.org/abs/2210.09220v1","tag":"data-quality"}}
{"title":"Adaptive Contrastive Learning with Dynamic Correlation for Multi-Phase Organ Segmentation","abstract":"Recent studies have demonstrated the superior performance of introducing ``scan-wise\" contrast labels into contrastive learning for multi-organ segmentation on multi-phase computed tomography (CT). However, such scan-wise labels are limited: (1) a coarse classification, which could not capture the fine-grained ``organ-wise\" contrast variations across all organs; (2) the label (i.e., contrast phase) is typically manually provided, which is error-prone and may introduce manual biases of defining phases. In this paper, we propose a novel data-driven contrastive loss function that adapts the similar/dissimilar contrast relationship between samples in each minibatch at organ-level. Specifically, as variable levels of contrast exist between organs, we hypothesis that the contrast differences in the organ-level can bring additional context for defining representations in the latent space. An organ-wise contrast correlation matrix is computed with mean organ intensities under one-hot attention maps. The goal of adapting the organ-driven correlation matrix is to model variable levels of feature separability at different phases. We evaluate our proposed approach on multi-organ segmentation with both non-contrast CT (NCCT) datasets and the MICCAI 2015 BTCV Challenge contrast-enhance CT (CECT) datasets. Compared to the state-of-the-art approaches, our proposed contrastive loss yields a substantial and significant improvement of 1.41% (from 0.923 to 0.936, p-value$<$0.01) and 2.02% (from 0.891 to 0.910, p-value$<$0.01) on mean Dice scores across all organs with respect to NCCT and CECT cohorts. We further assess the trained model performance with the MICCAI 2021 FLARE Challenge CECT datasets and achieve a substantial improvement of mean Dice score from 0.927 to 0.934 (p-value$<$0.01). The code is available at: https://github.com/MASILab/DCC_CL","created":"2022-10-16","meta":{"link":"http://arxiv.org/abs/2210.08652v1","tag":"data-quality"}}
{"title":"Fuzzy Positive Learning for Semi-supervised Semantic Segmentation","abstract":"Semi-supervised learning (SSL) essentially pursues class boundary exploration with less dependence on human annotations. Although typical attempts focus on ameliorating the inevitable error-prone pseudo-labeling, we think differently and resort to exhausting informative semantics from multiple probably correct candidate labels. In this paper, we introduce Fuzzy Positive Learning (FPL) for accurate SSL semantic segmentation in a plug-and-play fashion, targeting adaptively encouraging fuzzy positive predictions and suppressing highly-probable negatives. Being conceptually simple yet practically effective, FPL can remarkably alleviate interference from wrong pseudo labels and progressively achieve clear pixel-level semantic discrimination. Concretely, our FPL approach consists of two main components, including fuzzy positive assignment (FPA) to provide an adaptive number of labels for each pixel and fuzzy positive regularization (FPR) to restrict the predictions of fuzzy positive categories to be larger than the rest under different perturbations. Theoretical analysis and extensive experiments on Cityscapes and VOC 2012 with consistent performance gain justify the superiority of our approach.","created":"2022-10-16","meta":{"link":"http://arxiv.org/abs/2210.08519v2","tag":"data-quality"}}
{"title":"RoS-KD: A Robust Stochastic Knowledge Distillation Approach for Noisy Medical Imaging","abstract":"AI-powered Medical Imaging has recently achieved enormous attention due to its ability to provide fast-paced healthcare diagnoses. However, it usually suffers from a lack of high-quality datasets due to high annotation cost, inter-observer variability, human annotator error, and errors in computer-generated labels. Deep learning models trained on noisy labelled datasets are sensitive to the noise type and lead to less generalization on the unseen samples. To address this challenge, we propose a Robust Stochastic Knowledge Distillation (RoS-KD) framework which mimics the notion of learning a topic from multiple sources to ensure deterrence in learning noisy information. More specifically, RoS-KD learns a smooth, well-informed, and robust student manifold by distilling knowledge from multiple teachers trained on overlapping subsets of training data. Our extensive experiments on popular medical imaging classification tasks (cardiopulmonary disease and lesion classification) using real-world datasets, show the performance benefit of RoS-KD, its ability to distill knowledge from many popular large networks (ResNet-50, DenseNet-121, MobileNet-V2) in a comparatively small network, and its robustness to adversarial attacks (PGD, FSGM). More specifically, RoS-KD achieves >2% and >4% improvement on F1-score for lesion classification and cardiopulmonary disease classification tasks, respectively, when the underlying student is ResNet-18 against recent competitive knowledge distillation baseline. Additionally, on cardiopulmonary disease classification task, RoS-KD outperforms most of the SOTA baselines by ~1% gain in AUC score.","created":"2022-10-15","meta":{"link":"http://arxiv.org/abs/2210.08388v2","tag":"data-quality"}}
{"title":"Augmentation-Free Graph Contrastive Learning of Invariant-Discriminative Representations","abstract":"The pretasks are mainly built on mutual information estimation, which requires data augmentation to construct positive samples with similar semantics to learn invariant signals and negative samples with dissimilar semantics in order to empower representation discriminability. However, an appropriate data augmentation configuration depends heavily on lots of empirical trials such as choosing the compositions of data augmentation techniques and the corresponding hyperparameter settings. We propose an augmentation-free graph contrastive learning method, invariant-discriminative graph contrastive learning (iGCL), that does not intrinsically require negative samples. iGCL designs the invariant-discriminative loss (ID loss) to learn invariant and discriminative representations. On the one hand, ID loss learns invariant signals by directly minimizing the mean square error between the target samples and positive samples in the representation space. On the other hand, ID loss ensures that the representations are discriminative by an orthonormal constraint forcing the different dimensions of representations to be independent of each other. This prevents representations from collapsing to a point or subspace. Our theoretical analysis explains the effectiveness of ID loss from the perspectives of the redundancy reduction criterion, canonical correlation analysis, and information bottleneck principle. The experimental results demonstrate that iGCL outperforms all baselines on 5 node classification benchmark datasets. iGCL also shows superior performance for different label ratios and is capable of resisting graph attacks, which indicates that iGCL has excellent generalization and robustness. The source code is available at https://github.com/lehaifeng/T-GCN/tree/master/iGCL.","created":"2022-10-15","meta":{"link":"http://arxiv.org/abs/2210.08345v2","tag":"data-quality"}}
{"title":"Aplicaci\u00f3n de redes neuronales convolucionales profundas al diagn\u00f3stico asistido de la enfermedad de Alzheimer","abstract":"Currently, the diagnosis of Alzheimer's disease is a complex and error-prone process. Improving this diagnosis could allow earlier detection of the disease and improve the quality of life of patients and their families. For this work, we will use 249 brain images from two modalities: PET and MRI, taken from the ADNI database, and labelled into three classes according to the degree of development of Alzheimer's disease. We propose the development of a convolutional neural network to perform the classification of these images, during which, we will study the appropriate depth of the networks for this problem, the importance of pre-processing medical images, the use of transfer learning and data augmentation techniques as tools to reduce the effects of the problem of having too little data, and the simultaneous use of multiple medical imaging modalities. We also propose the application of an evaluation method that guarantees a good degree of repeatability of the results even when using a small dataset. Following this evaluation method, our best final model, which makes use of transfer learning with COVID-19 data, achieves an accuracy d 68\\%. In addition, in an independent test set, this same model achieves 70\\% accuracy, a promising result given the small size of our dataset. We further conclude that augmenting the depth of the networks helps with this problem, that image pre-processing is a fundamental process to address this type of medical problem, and that the use of data augmentation and the use of pre-trained networks with images of other diseases can provide significant improvements.","created":"2022-10-15","meta":{"link":"http://arxiv.org/abs/2210.08330v1","tag":"data-quality"}}
{"title":"Bidirectional Semi-supervised Dual-branch CNN for Robust 3D Reconstruction of Stereo Endoscopic Images via Adaptive Cross and Parallel Supervisions","abstract":"Semi-supervised learning via teacher-student network can train a model effectively on a few labeled samples. It enables a student model to distill knowledge from the teacher's predictions of extra unlabeled data. However, such knowledge flow is typically unidirectional, having the performance vulnerable to the quality of teacher model. In this paper, we seek to robust 3D reconstruction of stereo endoscopic images by proposing a novel fashion of bidirectional learning between two learners, each of which can play both roles of teacher and student concurrently. Specifically, we introduce two self-supervisions, i.e., Adaptive Cross Supervision (ACS) and Adaptive Parallel Supervision (APS), to learn a dual-branch convolutional neural network. The two branches predict two different disparity probability distributions for the same position, and output their expectations as disparity values. The learned knowledge flows across branches along two directions: a cross direction (disparity guides distribution in ACS) and a parallel direction (disparity guides disparity in APS). Moreover, each branch also learns confidences to dynamically refine its provided supervisions. In ACS, the predicted disparity is softened into a unimodal distribution, and the lower the confidence, the smoother the distribution. In APS, the incorrect predictions are suppressed by lowering the weights of those with low confidence. With the adaptive bidirectional learning, the two branches enjoy well-tuned supervisions, and eventually converge on a consistent and more accurate disparity estimation. The extensive and comprehensive experimental results on four public datasets demonstrate our superior performance over other state-of-the-arts with a relative decrease of averaged disparity error by at least 9.76%.","created":"2022-10-15","meta":{"link":"http://arxiv.org/abs/2210.08291v4","tag":"data-quality"}}
{"title":"How Does Pseudo-Labeling Affect the Generalization Error of the Semi-Supervised Gibbs Algorithm?","abstract":"This paper provides an exact characterization of the expected generalization error (gen-error) for semi-supervised learning (SSL) with pseudo-labeling via the Gibbs algorithm. This characterization is expressed in terms of the symmetrized KL information between the output hypothesis, the pseudo-labeled dataset, and the labeled dataset. It can be applied to obtain distribution-free upper and lower bounds on the gen-error. Our findings offer new insights that the generalization performance of SSL with pseudo-labeling is affected not only by the information between the output hypothesis and input training data but also by the information {\\em shared} between the {\\em labeled} and {\\em pseudo-labeled} data samples. To deepen our understanding, we further explore two examples -- mean estimation and logistic regression. In particular, we analyze how the ratio of the number of unlabeled to labeled data $\\lambda$ affects the gen-error under both scenarios. As $\\lambda$ increases, the gen-error for mean estimation decreases and then saturates at a value larger than when all the samples are labeled, and the gap can be quantified {\\em exactly} with our analysis, and is dependent on the \\emph{cross-covariance} between the labeled and pseudo-labeled data sample. In logistic regression, the gen-error and the variance component of the excess risk also decrease as $\\lambda$ increases.","created":"2022-10-15","meta":{"link":"http://arxiv.org/abs/2210.08188v1","tag":"data-quality"}}
{"title":"Generative Adversarial Learning for Trusted and Secure Clustering in Industrial Wireless Sensor Networks","abstract":"Traditional machine learning techniques have been widely used to establish the trust management systems. However, the scale of training dataset can significantly affect the security performances of the systems, while it is a great challenge to detect malicious nodes due to the absence of labeled data regarding novel attacks. To address this issue, this paper presents a generative adversarial network (GAN) based trust management mechanism for Industrial Wireless Sensor Networks (IWSNs). First, type-2 fuzzy logic is adopted to evaluate the reputation of sensor nodes while alleviating the uncertainty problem. Then, trust vectors are collected to train a GAN-based codec structure, which is used for further malicious node detection. Moreover, to avoid normal nodes being isolated from the network permanently due to error detections, a GAN-based trust redemption model is constructed to enhance the resilience of trust management. Based on the latest detection results, a trust model update method is developed to adapt to the dynamic industrial environment. The proposed trust management mechanism is finally applied to secure clustering for reliable and real-time data transmission, and simulation results show that it achieves a high detection rate up to 96%, as well as a low false positive rate below 8%.","created":"2022-10-14","meta":{"link":"http://arxiv.org/abs/2210.07707v1","tag":"data-quality"}}
{"title":"Autoencoder based Anomaly Detection and Explained Fault Localization in Industrial Cooling Systems","abstract":"Anomaly detection in large industrial cooling systems is very challenging due to the high data dimensionality, inconsistent sensor recordings, and lack of labels. The state of the art for automated anomaly detection in these systems typically relies on expert knowledge and thresholds. However, data is viewed isolated and complex, multivariate relationships are neglected. In this work, we present an autoencoder based end-to-end workflow for anomaly detection suitable for multivariate time series data in large industrial cooling systems, including explained fault localization and root cause analysis based on expert knowledge. We identify system failures using a threshold on the total reconstruction error (autoencoder reconstruction error including all sensor signals). For fault localization, we compute the individual reconstruction error (autoencoder reconstruction error for each sensor signal) allowing us to identify the signals that contribute most to the total reconstruction error. Expert knowledge is provided via look-up table enabling root-cause analysis and assignment to the affected subsystem. We demonstrated our findings in a cooling system unit including 34 sensors over a 8-months time period using 4-fold cross validation approaches and automatically created labels based on thresholds provided by domain experts. Using 4-fold cross validation, we reached a F1-score of 0.56, whereas the autoencoder results showed a higher consistency score (CS of 0.92) compared to the automatically created labels (CS of 0.62) -- indicating that the anomaly is recognized in a very stable manner. The main anomaly was found by the autoencoder and automatically created labels and was also recorded in the log files. Further, the explained fault localization highlighted the most affected component for the main anomaly in a very consistent manner.","created":"2022-10-14","meta":{"link":"http://arxiv.org/abs/2210.08011v1","tag":"data-quality"}}
{"title":"Noise Audits Improve Moral Foundation Classification","abstract":"Morality plays an important role in culture, identity, and emotion. Recent advances in natural language processing have shown that it is possible to classify moral values expressed in text at scale. Morality classification relies on human annotators to label the moral expressions in text, which provides training data to achieve state-of-the-art performance. However, these annotations are inherently subjective and some of the instances are hard to classify, resulting in noisy annotations due to error or lack of agreement. The presence of noise in training data harms the classifier's ability to accurately recognize moral foundations from text. We propose two metrics to audit the noise of annotations. The first metric is entropy of instance labels, which is a proxy measure of annotator disagreement about how the instance should be labeled. The second metric is the silhouette coefficient of a label assigned by an annotator to an instance. This metric leverages the idea that instances with the same label should have similar latent representations, and deviations from collective judgments are indicative of errors. Our experiments on three widely used moral foundations datasets show that removing noisy annotations based on the proposed metrics improves classification performance.","created":"2022-10-13","meta":{"link":"http://arxiv.org/abs/2210.07415v1","tag":"data-quality"}}
{"title":"Consistency and Accuracy of CelebA Attribute Values","abstract":"We report the first systematic analysis of the experimental foundations of facial attribute classification. Two annotators independently assigning attribute values shows that only 12 of 40 common attributes are assigned values with >= 95% consistency, and three (high cheekbones, pointed nose, oval face) have essentially random consistency. Of 5,068 duplicate face appearances in CelebA, attributes have contradicting values on from 10 to 860 of the 5,068 duplicates. Manual audit of a subset of CelebA estimates error rates as high as 40% for (no beard=false), even though the labeling consistency experiment indicates that no beard could be assigned with >= 95% consistency. Selecting the mouth slightly open (MSO) for deeper analysis, we estimate the error rate for (MSO=true) at about 20% and (MSO=false) at about 2%. A corrected version of the MSO attribute values enables learning a model that achieves higher accuracy than previously reported for MSO. Corrected values for CelebA MSO are available at https://github.com/HaiyuWu/CelebAMSO.","created":"2022-10-13","meta":{"link":"http://arxiv.org/abs/2210.07356v2","tag":"data-quality"}}
{"title":"Towards End-to-End Open Conversational Machine Reading","abstract":"In open-retrieval conversational machine reading (OR-CMR) task, machines are required to do multi-turn question answering given dialogue history and a textual knowledge base. Existing works generally utilize two independent modules to approach this problem's two successive sub-tasks: first with a hard-label decision making and second with a question generation aided by various entailment reasoning methods. Such usual cascaded modeling is vulnerable to error propagation and prevents the two sub-tasks from being consistently optimized. In this work, we instead model OR-CMR as a unified text-to-text task in a fully end-to-end style. Experiments on the OR-ShARC dataset show the effectiveness of our proposed end-to-end framework on both sub-tasks by a large margin, achieving new state-of-the-art results. Further ablation studies support that our framework can generalize to different backbone models.","created":"2022-10-13","meta":{"link":"http://arxiv.org/abs/2210.07113v1","tag":"data-quality"}}
{"title":"A Consistent and Differentiable Lp Canonical Calibration Error Estimator","abstract":"Calibrated probabilistic classifiers are models whose predicted probabilities can directly be interpreted as uncertainty estimates. It has been shown recently that deep neural networks are poorly calibrated and tend to output overconfident predictions. As a remedy, we propose a low-bias, trainable calibration error estimator based on Dirichlet kernel density estimates, which asymptotically converges to the true $L_p$ calibration error. This novel estimator enables us to tackle the strongest notion of multiclass calibration, called canonical (or distribution) calibration, while other common calibration methods are tractable only for top-label and marginal calibration. The computational complexity of our estimator is $\\mathcal{O}(n^2)$, the convergence rate is $\\mathcal{O}(n^{-1/2})$, and it is unbiased up to $\\mathcal{O}(n^{-2})$, achieved by a geometric series debiasing scheme. In practice, this means that the estimator can be applied to small subsets of data, enabling efficient estimation and mini-batch updates. The proposed method has a natural choice of kernel, and can be used to generate consistent estimates of other quantities based on conditional expectation, such as the sharpness of a probabilistic classifier. Empirical results validate the correctness of our estimator, and demonstrate its utility in canonical calibration error estimation and calibration error regularized risk minimization.","created":"2022-10-13","meta":{"link":"http://arxiv.org/abs/2210.07810v1","tag":"data-quality"}}
{"title":"Rebalanced Zero-shot Learning","abstract":"Zero-shot learning (ZSL) aims to identify unseen classes with zero samples during training. Broadly speaking, present ZSL methods usually adopt class-level semantic labels and compare them with instance-level semantic predictions to infer unseen classes. However, we find that such existing models mostly produce imbalanced semantic predictions, i.e. these models could perform precisely for some semantics, but may not for others. To address the drawback, we aim to introduce an imbalanced learning framework into ZSL. However, we find that imbalanced ZSL has two unique challenges: (1) Its imbalanced predictions are highly correlated with the value of semantic labels rather than the number of samples as typically considered in the traditional imbalanced learning; (2) Different semantics follow quite different error distributions between classes. To mitigate these issues, we first formalize ZSL as an imbalanced regression problem which offers theoretical foundations to interpret how semantic labels lead to imbalanced semantic predictions. We then propose a re-weighted loss termed Re-balanced Mean-Squared Error (ReMSE), which tracks the mean and variance of error distributions, thus ensuring rebalanced learning across classes. As a major contribution, we conduct a series of analyses showing that ReMSE is theoretically well established. Extensive experiments demonstrate that the proposed method effectively alleviates the imbalance in semantic prediction and outperforms many state-of-the-art ZSL methods.","created":"2022-10-13","meta":{"link":"http://arxiv.org/abs/2210.07031v1","tag":"data-quality"}}
{"title":"Multilingual Zero Resource Speech Recognition Base on Self-Supervise Pre-Trained Acoustic Models","abstract":"Labeled audio data is insufficient to build satisfying speech recognition systems for most of the languages in the world. There have been some zero-resource methods trying to perform phoneme or word-level speech recognition without labeled audio data of the target language, but the error rate of these methods is usually too high to be applied in real-world scenarios. Recently, the representation ability of self-supervise pre-trained models has been found to be extremely beneficial in zero-resource phoneme recognition. As far as we are concerned, this paper is the first attempt to extend the use of pre-trained models into word-level zero-resource speech recognition. This is done by fine-tuning the pre-trained models on IPA phoneme transcriptions and decoding with a language model trained on extra texts. Experiments on Wav2vec 2.0 and HuBERT models show that this method can achieve less than 20% word error rate on some languages, and the average error rate on 8 languages is 33.77%.","created":"2022-10-13","meta":{"link":"http://arxiv.org/abs/2210.06936v1","tag":"data-quality"}}
{"title":"PriMeSRL-Eval: A Practical Quality Metric for Semantic Role Labeling Systems Evaluation","abstract":"Semantic role labeling (SRL) identifies the predicate-argument structure in a sentence. This task is usually accomplished in four steps: predicate identification, predicate sense disambiguation, argument identification, and argument classification. Errors introduced at one step propagate to later steps. Unfortunately, the existing SRL evaluation scripts do not consider the full effect of this error propagation aspect. They either evaluate arguments independent of predicate sense (CoNLL09) or do not evaluate predicate sense at all (CoNLL05), yielding an inaccurate SRL model performance on the argument classification task. In this paper, we address key practical issues with existing evaluation scripts and propose a more strict SRL evaluation metric PriMeSRL. We observe that by employing PriMeSRL, the quality evaluation of all SoTA SRL models drops significantly, and their relative rankings also change. We also show that PriMeSRLsuccessfully penalizes actual failures in SoTA SRL models.","created":"2022-10-12","meta":{"link":"http://arxiv.org/abs/2210.06408v1","tag":"data-quality"}}
{"title":"CLEEGN: A Convolutional Neural Network for Plug-and-Play Automatic EEG Reconstruction","abstract":"Human electroencephalography (EEG) is a brain monitoring modality that senses cortical neuroelectrophysiological activity in high-temporal resolution. One of the greatest challenges posed in applications of EEG is the unstable signal quality susceptible to inevitable artifacts during recordings. To date, most existing techniques for EEG artifact removal and reconstruction are applicable to offline analysis solely, or require individualized training data to facilitate online reconstruction. We have proposed CLEEGN, a novel convolutional neural network for plug-and-play automatic EEG reconstruction. CLEEGN is based on a subject-independent pre-trained model using existing data and can operate on a new user without any further calibration. The performance of CLEEGN was validated using multiple evaluations including waveform observation, reconstruction error assessment, and decoding accuracy on well-studied labeled datasets. The results of simulated online validation suggest that, even without any calibration, CLEEGN can largely preserve inherent brain activity and outperforms leading online/offline artifact removal methods in the decoding accuracy of reconstructed EEG data. In addition, visualization of model parameters and latent features exhibit the model behavior and reveal explainable insights related to existing knowledge of neuroscience. We foresee pervasive applications of CLEEGN in prospective works of online plug-and-play EEG decoding and analysis.","created":"2022-10-12","meta":{"link":"http://arxiv.org/abs/2210.05988v1","tag":"data-quality"}}
{"title":"SEAL : Interactive Tool for Systematic Error Analysis and Labeling","abstract":"With the advent of Transformers, large language models (LLMs) have saturated well-known NLP benchmarks and leaderboards with high aggregate performance. However, many times these models systematically fail on tail data or rare groups not obvious in aggregate evaluation. Identifying such problematic data groups is even more challenging when there are no explicit labels (e.g., ethnicity, gender, etc.) and further compounded for NLP datasets due to the lack of visual features to characterize failure modes (e.g., Asian males, animals indoors, waterbirds on land, etc.). This paper introduces an interactive Systematic Error Analysis and Labeling (\\seal) tool that uses a two-step approach to first identify high error slices of data and then, in the second step, introduce methods to give human-understandable semantics to those underperforming slices. We explore a variety of methods for coming up with coherent semantics for the error groups using language models for semantic labeling and a text-to-image model for generating visual features. SEAL toolkit and demo screencast is available at https://huggingface.co/spaces/nazneen/seal.","created":"2022-10-11","meta":{"link":"http://arxiv.org/abs/2210.05839v1","tag":"data-quality"}}
{"title":"C-Mixup: Improving Generalization in Regression","abstract":"Improving the generalization of deep networks is an important open challenge, particularly in domains without plentiful data. The mixup algorithm improves generalization by linearly interpolating a pair of examples and their corresponding labels. These interpolated examples augment the original training set. Mixup has shown promising results in various classification tasks, but systematic analysis of mixup in regression remains underexplored. Using mixup directly on regression labels can result in arbitrarily incorrect labels. In this paper, we propose a simple yet powerful algorithm, C-Mixup, to improve generalization on regression tasks. In contrast with vanilla mixup, which picks training examples for mixing with uniform probability, C-Mixup adjusts the sampling probability based on the similarity of the labels. Our theoretical analysis confirms that C-Mixup with label similarity obtains a smaller mean square error in supervised regression and meta-regression than vanilla mixup and using feature similarity. Another benefit of C-Mixup is that it can improve out-of-distribution robustness, where the test distribution is different from the training distribution. By selectively interpolating examples with similar labels, it mitigates the effects of domain-associated information and yields domain-invariant representations. We evaluate C-Mixup on eleven datasets, ranging from tabular to video data. Compared to the best prior approach, C-Mixup achieves 6.56%, 4.76%, 5.82% improvements in in-distribution generalization, task generalization, and out-of-distribution robustness, respectively. Code is released at https://github.com/huaxiuyao/C-Mixup.","created":"2022-10-11","meta":{"link":"http://arxiv.org/abs/2210.05775v1","tag":"data-quality"}}
{"title":"Label Noise-Robust Learning using a Confidence-Based Sieving Strategy","abstract":"In learning tasks with label noise, boosting model robustness against overfitting is a pivotal challenge because the model eventually memorizes labels including the noisy ones. Identifying the samples with corrupted labels and preventing the model from learning them is a promising approach to address this challenge. Per-sample training loss is a previously studied metric that considers samples with small loss as clean samples on which the model should be trained. In this work, we first demonstrate the ineffectiveness of this small-loss trick. Then, we propose a novel discriminator metric called confidence error and a sieving strategy called CONFES to effectively differentiate between the clean and noisy samples. We experimentally illustrate the superior performance of our proposed approach compared to recent studies on various settings such as synthetic and real-world label noise. Moreover, we show CONFES can be combined with other approaches such as Co-teaching and DivideMix to further improve the model performance.","created":"2022-10-11","meta":{"link":"http://arxiv.org/abs/2210.05330v2","tag":"data-quality"}}
{"title":"Not All Errors are Equal: Learning Text Generation Metrics using Stratified Error Synthesis","abstract":"Is it possible to build a general and automatic natural language generation (NLG) evaluation metric? Existing learned metrics either perform unsatisfactorily or are restricted to tasks where large human rating data is already available. We introduce SESCORE, a model-based metric that is highly correlated with human judgements without requiring human annotation, by utilizing a novel, iterative error synthesis and severity scoring pipeline. This pipeline applies a series of plausible errors to raw text and assigns severity labels by simulating human judgements with entailment. We evaluate SESCORE against existing metrics by comparing how their scores correlate with human ratings. SESCORE outperforms all prior unsupervised metrics on multiple diverse NLG tasks including machine translation, image captioning, and WebNLG text generation. For WMT 20/21 En-De and Zh-En, SESCORE improve the average Kendall correlation with human judgement from 0.154 to 0.195. SESCORE even achieves comparable performance to the best supervised metric COMET, despite receiving no human-annotated training data.","created":"2022-10-10","meta":{"link":"http://arxiv.org/abs/2210.05035v2","tag":"data-quality"}}
{"title":"NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers","abstract":"Scaling text-to-speech (TTS) to large-scale, multi-speaker, and in-the-wild datasets is important to capture the diversity in human speech such as speaker identities, prosodies, and styles (e.g., singing). Current large TTS systems usually quantize speech into discrete tokens and use language models to generate these tokens one by one, which suffer from unstable prosody, word skipping/repeating issue, and poor voice quality. In this paper, we develop NaturalSpeech 2, a TTS system that leverages a neural audio codec with residual vector quantizers to get the quantized latent vectors and uses a diffusion model to generate these latent vectors conditioned on text input. To enhance the zero-shot capability that is important to achieve diverse speech synthesis, we design a speech prompting mechanism to facilitate in-context learning in the diffusion model and the duration/pitch predictor. We scale NaturalSpeech 2 to large-scale datasets with 44K hours of speech and singing data and evaluate its voice quality on unseen speakers. NaturalSpeech 2 outperforms previous TTS systems by a large margin in terms of prosody/timbre similarity, robustness, and voice quality in a zero-shot setting, and performs novel zero-shot singing synthesis with only a speech prompt. Audio samples are available at https://speechresearch.github.io/naturalspeech2.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09116v1","tag":"data-quality"}}
{"title":"Performance of GAN-based augmentation for deep learning COVID-19 image classification","abstract":"The biggest challenge in the application of deep learning to the medical domain is the availability of training data. Data augmentation is a typical methodology used in machine learning when confronted with a limited data set. In a classical approach image transformations i.e. rotations, cropping and brightness changes are used. In this work, a StyleGAN2-ADA model of Generative Adversarial Networks is trained on the limited COVID-19 chest X-ray image set. After assessing the quality of generated images they are used to increase the training data set improving its balance between classes. We consider the multi-class classification problem of chest X-ray images including the COVID-19 positive class that hasn't been yet thoroughly explored in the literature. Results of transfer learning-based classification of COVID-19 chest X-ray images are presented. The performance of several deep convolutional neural network models is compared. The impact on the detection performance of classical image augmentations i.e. rotations, cropping, and brightness changes are studied. Furthermore, classical image augmentation is compared with GAN-based augmentation. The most accurate model is an EfficientNet-B0 with an accuracy of 90.2 percent, trained on a dataset with a simple class balancing. The GAN augmentation approach is found to be subpar to classical methods for the considered dataset.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09067v1","tag":"data-quality"}}
{"title":"Incremental Image Labeling via Iterative Refinement","abstract":"Data quality is critical for multimedia tasks, while various types of systematic flaws are found in image benchmark datasets, as discussed in recent work. In particular, the existence of the semantic gap problem leads to a many-to-many mapping between the information extracted from an image and its linguistic description. This unavoidable bias further leads to poor performance on current computer vision tasks. To address this issue, we introduce a Knowledge Representation (KR)-based methodology to provide guidelines driving the labeling process, thereby indirectly introducing intended semantics in ML models. Specifically, an iterative refinement-based annotation method is proposed to optimize data labeling by organizing objects in a classification hierarchy according to their visual properties, ensuring that they are aligned with their linguistic descriptions. Preliminary results verify the effectiveness of the proposed method.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08989v1","tag":"data-quality"}}
{"title":"Fibroglandular Tissue Segmentation in Breast MRI using Vision Transformers -- A multi-institutional evaluation","abstract":"Accurate and automatic segmentation of fibroglandular tissue in breast MRI screening is essential for the quantification of breast density and background parenchymal enhancement. In this retrospective study, we developed and evaluated a transformer-based neural network for breast segmentation (TraBS) in multi-institutional MRI data, and compared its performance to the well established convolutional neural network nnUNet. TraBS and nnUNet were trained and tested on 200 internal and 40 external breast MRI examinations using manual segmentations generated by experienced human readers. Segmentation performance was assessed in terms of the Dice score and the average symmetric surface distance. The Dice score for nnUNet was lower than for TraBS on the internal testset (0.909$\\pm$0.069 versus 0.916$\\pm$0.067, P<0.001) and on the external testset (0.824$\\pm$0.144 versus 0.864$\\pm$0.081, P=0.004). Moreover, the average symmetric surface distance was higher (=worse) for nnUNet than for TraBS on the internal (0.657$\\pm$2.856 versus 0.548$\\pm$2.195, P=0.001) and on the external testset (0.727$\\pm$0.620 versus 0.584$\\pm$0.413, P=0.03). Our study demonstrates that transformer-based networks improve the quality of fibroglandular tissue segmentation in breast MRI compared to convolutional-based models like nnUNet. These findings might help to enhance the accuracy of breast density and parenchymal enhancement quantification in breast MRI screening.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08972v1","tag":"data-quality"}}
{"title":"Tailoring Domain Adaptation for Machine Translation Quality Estimation","abstract":"While quality estimation (QE) can play an important role in the translation process, its effectiveness relies on the availability and quality of training data. For QE in particular, high-quality labeled data is often lacking due to the high-cost and effort associated with labeling such data. Aside from the data scarcity challenge, QE models should also be generalizable, i.e., they should be able to handle data from different domains, both generic and specific. To alleviate these two main issues -- data scarcity and domain mismatch -- this paper combines domain adaptation and data augmentation within a robust QE system. Our method is to first train a generic QE model and then fine-tune it on a specific domain while retaining generic knowledge. Our results show a significant improvement for all the language pairs investigated, better cross-lingual inference, and a superior performance in zero-shot learning scenarios as compared to state-of-the-art baselines.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08891v1","tag":"data-quality"}}
{"title":"NPS: A Framework for Accurate Program Sampling Using Graph Neural Network","abstract":"With the end of Moore's Law, there is a growing demand for rapid architectural innovations in modern processors, such as RISC-V custom extensions, to continue performance scaling. Program sampling is a crucial step in microprocessor design, as it selects representative simulation points for workload simulation. While SimPoint has been the de-facto approach for decades, its limited expressiveness with Basic Block Vector (BBV) requires time-consuming human tuning, often taking months, which impedes fast innovation and agile hardware development. This paper introduces Neural Program Sampling (NPS), a novel framework that learns execution embeddings using dynamic snapshots of a Graph Neural Network. NPS deploys AssemblyNet for embedding generation, leveraging an application's code structures and runtime states. AssemblyNet serves as NPS's graph model and neural architecture, capturing a program's behavior in aspects such as data computation, code path, and data flow. AssemblyNet is trained with a data prefetch task that predicts consecutive memory addresses.   In the experiments, NPS outperforms SimPoint by up to 63%, reducing the average error by 38%. Additionally, NPS demonstrates strong robustness with increased accuracy, reducing the expensive accuracy tuning overhead. Furthermore, NPS shows higher accuracy and generality than the state-of-the-art GNN approach in code behavior learning, enabling the generation of high-quality execution embeddings.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08880v1","tag":"data-quality"}}
{"title":"Secured and Cooperative Publish/Subscribe Scheme in Autonomous Vehicular Networks","abstract":"In order to save computing power yet enhance safety, there is a strong intention for autonomous vehicles (AVs) in future to drive collaboratively by sharing sensory data and computing results among neighbors. However, the intense collaborative computing and data transmissions among unknown others will inevitably introduce severe security concerns. Aiming at addressing security concerns in future AVs, in this paper, we develop SPAD, a secured framework to forbid free-riders and {promote trustworthy data dissemination} in collaborative autonomous driving. Specifically, we first introduce a publish/subscribe framework for inter-vehicle data transmissions{. To defend against free-riding attacks,} we formulate the interactions between publisher AVs and subscriber AVs as a vehicular publish/subscribe game, {and incentivize AVs to deliver high-quality data by analyzing the Stackelberg equilibrium of the game. We also design a reputation evaluation mechanism in the game} to identify malicious AVs {in disseminating fake information}. {Furthermore, for} lack of sufficient knowledge on parameters of {the} network model and user cost model {in dynamic game scenarios}, a two-tier reinforcement learning based algorithm with hotbooting is developed to obtain the optimal {strategies of subscriber AVs and publisher AVs with free-rider prevention}. Extensive simulations are conducted, and the results validate that our SPAD can effectively {prevent free-riders and enhance the dependability of disseminated contents,} compared with conventional schemes.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08875v1","tag":"data-quality"}}
{"title":"Two-stage Denoising Diffusion Model for Source Localization in Graph Inverse Problems","abstract":"Source localization is the inverse problem of graph information dissemination and has broad practical applications.   However, the inherent intricacy and uncertainty in information dissemination pose significant challenges, and the ill-posed nature of the source localization problem further exacerbates these challenges. Recently, deep generative models, particularly diffusion models inspired by classical non-equilibrium thermodynamics, have made significant progress. While diffusion models have proven to be powerful in solving inverse problems and producing high-quality reconstructions, applying them directly to the source localization is infeasible for two reasons. Firstly, it is impossible to calculate the posterior disseminated results on a large-scale network for iterative denoising sampling, which would incur enormous computational costs. Secondly, in the existing methods for this field, the training data itself are ill-posed (many-to-one); thus simply transferring the diffusion model would only lead to local optima.   To address these challenges, we propose a two-stage optimization framework, the source localization denoising diffusion model (SL-Diff). In the coarse stage, we devise the source proximity degrees as the supervised signals to generate coarse-grained source predictions. This aims to efficiently initialize the next stage, significantly reducing its convergence time and calibrating the convergence process. Furthermore, the introduction of cascade temporal information in this training method transforms the many-to-one mapping relationship into a one-to-one relationship, perfectly addressing the ill-posed problem. In the fine stage, we design a diffusion model for the graph inverse problem that can quantify the uncertainty in the dissemination. The proposed SL-Diff yields excellent prediction results within a reasonable sampling time at extensive experiments.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08841v1","tag":"data-quality"}}
{"title":"Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models","abstract":"Latent Diffusion Models (LDMs) enable high-quality image synthesis while avoiding excessive compute demands by training a diffusion model in a compressed lower-dimensional latent space. Here, we apply the LDM paradigm to high-resolution video generation, a particularly resource-intensive task. We first pre-train an LDM on images only; then, we turn the image generator into a video generator by introducing a temporal dimension to the latent space diffusion model and fine-tuning on encoded image sequences, i.e., videos. Similarly, we temporally align diffusion model upsamplers, turning them into temporally consistent video super resolution models. We focus on two relevant real-world applications: Simulation of in-the-wild driving data and creative content creation with text-to-video modeling. In particular, we validate our Video LDM on real driving videos of resolution 512 x 1024, achieving state-of-the-art performance. Furthermore, our approach can easily leverage off-the-shelf pre-trained image LDMs, as we only need to train a temporal alignment model in that case. Doing so, we turn the publicly available, state-of-the-art text-to-image LDM Stable Diffusion into an efficient and expressive text-to-video model with resolution up to 1280 x 2048. We show that the temporal layers trained in this way generalize to different fine-tuned text-to-image LDMs. Utilizing this property, we show the first results for personalized text-to-video generation, opening exciting directions for future content creation. Project page: https://research.nvidia.com/labs/toronto-ai/VideoLDM/","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08818v1","tag":"data-quality"}}
{"title":"Deep Unrestricted Document Image Rectification","abstract":"In recent years, tremendous efforts have been made on document image rectification, but existing advanced algorithms are limited to processing restricted document images, i.e., the input images must incorporate a complete document. Once the captured image merely involves a local text region, its rectification quality is degraded and unsatisfactory. Our previously proposed DocTr, a transformer-assisted network for document image rectification, also suffers from this limitation. In this work, we present DocTr++, a novel unified framework for document image rectification, without any restrictions on the input distorted images. Our major technical improvements can be concluded in three aspects. Firstly, we upgrade the original architecture by adopting a hierarchical encoder-decoder structure for multi-scale representation extraction and parsing. Secondly, we reformulate the pixel-wise mapping relationship between the unrestricted distorted document images and the distortion-free counterparts. The obtained data is used to train our DocTr++ for unrestricted document image rectification. Thirdly, we contribute a real-world test set and metrics applicable for evaluating the rectification quality. To our best knowledge, this is the first learning-based method for the rectification of unrestricted document images. Extensive experiments are conducted, and the results demonstrate the effectiveness and superiority of our method. We hope our DocTr++ will serve as a strong baseline for generic document image rectification, prompting the further advancement and application of learning-based algorithms. The source code and the proposed dataset are publicly available at https://github.com/fh2019ustc/DocTr-Plus.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08796v1","tag":"data-quality"}}
{"title":"Are footpaths encroached by shared e-scooters? Spatio-temporal Analysis of Micro-mobility Services","abstract":"Micro-mobility services (e.g., e-bikes, e-scooters) are increasingly popular among urban communities, being a flexible transport option that brings both opportunities and challenges. As a growing mode of transportation, insights gained from micro-mobility usage data are valuable in policy formulation and improving the quality of services. Existing research analyses patterns and features associated with usage distributions in different localities, and focuses on either temporal or spatial aspects. In this paper, we employ a combination of methods that analyse both spatial and temporal characteristics related to e-scooter trips in a more granular level, enabling observations at different time frames and local geographical zones that prior analysis wasn't able to do. The insights obtained from anonymised, restricted data on shared e-scooter rides show the applicability of the employed method on regulated, privacy preserving micro-mobility trip data. Our results showed population density is the topmost important feature, and it associates with e-scooter usage positively. Population owning motor vehicles is negatively associated with shared e-scooter trips, suggesting a reduction in e-scooter usage among motor vehicle owners. Furthermore, we found that the effect of humidity is more important than precipitation in predicting hourly e-scooter trip count. Buffer analysis showed, nearly 29% trips were stopped, and 27% trips were started on the footpath, revealing higher utilisation of footpaths for parking e-scooters in Melbourne.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08721v1","tag":"data-quality"}}
{"title":"An end-to-end, interactive Deep Learning based Annotation system for cursive and print English handwritten text","abstract":"With the surging inclination towards carrying out tasks on computational devices and digital mediums, any method that converts a task that was previously carried out manually, to a digitized version, is always welcome. Irrespective of the various documentation tasks that can be done online today, there are still many applications and domains where handwritten text is inevitable, which makes the digitization of handwritten documents a very essential task. Over the past decades, there has been extensive research on offline handwritten text recognition. In the recent past, most of these attempts have shifted to Machine learning and Deep learning based approaches. In order to design more complex and deeper networks, and ensure stellar performances, it is essential to have larger quantities of annotated data. Most of the databases present for offline handwritten text recognition today, have either been manually annotated or semi automatically annotated with a lot of manual involvement. These processes are very time consuming and prone to human errors. To tackle this problem, we present an innovative, complete end-to-end pipeline, that annotates offline handwritten manuscripts written in both print and cursive English, using Deep Learning and User Interaction techniques. This novel method, which involves an architectural combination of a detection system built upon a state-of-the-art text detection model, and a custom made Deep Learning model for the recognition system, is combined with an easy-to-use interactive interface, aiming to improve the accuracy of the detection, segmentation, serialization and recognition phases, in order to ensure high quality annotated data with minimal human interaction.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08670v1","tag":"data-quality"}}
{"title":"On Uncertainty Calibration and Selective Generation in Probabilistic Neural Summarization: A Benchmark Study","abstract":"Modern deep models for summarization attains impressive benchmark performance, but they are prone to generating miscalibrated predictive uncertainty. This means that they assign high confidence to low-quality predictions, leading to compromised reliability and trustworthiness in real-world applications. Probabilistic deep learning methods are common solutions to the miscalibration problem. However, their relative effectiveness in complex autoregressive summarization tasks are not well-understood. In this work, we thoroughly investigate different state-of-the-art probabilistic methods' effectiveness in improving the uncertainty quality of the neural summarization models, across three large-scale benchmarks with varying difficulty. We show that the probabilistic methods consistently improve the model's generation and uncertainty quality, leading to improved selective generation performance (i.e., abstaining from low-quality summaries) in practice. We also reveal notable failure patterns of probabilistic methods widely-adopted in NLP community (e.g., Deep Ensemble and Monte Carlo Dropout), cautioning the importance of choosing appropriate method for the data setting.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08653v1","tag":"data-quality"}}
{"title":"UAV-based Maritime Communications: Relaying to Enhance the Link Quality","abstract":"Providing a stable connectivity in maritime communications is of utmost importance to unleash the full potential of smart ports. Nonetheless, due to the crowded nature of harbor environments, it is likely that some ships are shadowed by others, resulting in reduced received power that subsequently diminishes their data rates-even threatens basic connectivity requirements. Given that UAVs have been regarded as an integral part of future generations of wireless communication networks, they can be employed in maritime communications as well. In this paper, we investigate the use of UAV-mounted relays in order to help mitigate the reduced data rates of blocked links in maritime communications. Various communication architectures are considered based on the positioning mechanism of the UAV; in this regard, fixed, k-means algorithm-based, and landing spot-based positioning approaches are examined. On the other hand, since UAVs are predominantly battery-operated, the energy consumption performances of these approaches are also measured. Results reveal that the landing spot-based UAV relay positioning approach finds the best trade-off between the data rate and energy consumption.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08650v1","tag":"data-quality"}}
{"title":"An Evaluation on Large Language Model Outputs: Discourse and Memorization","abstract":"We present an empirical evaluation of various outputs generated by nine of the most widely-available large language models (LLMs). Our analysis is done with off-the-shelf, readily-available tools. We find a correlation between percentage of memorized text, percentage of unique text, and overall output quality, when measured with respect to output pathologies such as counterfactual and logically-flawed statements, and general failures like not staying on topic. Overall, 80.0% of the outputs evaluated contained memorized data, but outputs containing the most memorized content were also more likely to be considered of high quality. We discuss and evaluate mitigation strategies, showing that, in the models evaluated, the rate of memorized text being output is reduced. We conclude with a discussion on potential implications around what it means to learn, to memorize, and to evaluate quality text.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08637v1","tag":"data-quality"}}
{"title":"eTOP: Early Termination of Pipelines for Faster Training of AutoML Systems","abstract":"Recent advancements in software and hardware technologies have enabled the use of AI/ML models in everyday applications has significantly improved the quality of service rendered. However, for a given application, finding the right AI/ML model is a complex and costly process, that involves the generation, training, and evaluation of multiple interlinked steps (called pipelines), such as data pre-processing, feature engineering, selection, and model tuning. These pipelines are complex (in structure) and costly (both in compute resource and time) to execute end-to-end, with a hyper-parameter associated with each step. AutoML systems automate the search of these hyper-parameters but are slow, as they rely on optimizing the pipeline's end output. We propose the eTOP Framework which works on top of any AutoML system and decides whether or not to execute the pipeline to the end or terminate at an intermediate step. Experimental evaluation on 26 benchmark datasets and integration of eTOPwith MLBox4 reduces the training time of the AutoML system upto 40x than baseline MLBox.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08597v1","tag":"data-quality"}}
{"title":"A New Representation of Uniform-Block Matrix and Applications","abstract":"A covariance matrix with a special pattern (e.g., sparsity or block structure) is essential for conducting multivariate analysis on high-dimensional data. Recently, a block covariance or correlation pattern has been observed in various biological and biomedical studies, such as gene expression, proteomics, neuroimaging, exposome, and seed quality, among others. Specifically, this pattern partitions the population covariance matrix into uniform (i.e., equal variances and covariances) blocks. However, the unknown mathematical properties of matrices with this pattern limit the incorporation of this pre-determined covariance information into research. To address this gap, we propose a block Hadamard product representation that utilizes two lower-dimensional \"coordinate\" matrices and a pre-specific vector. This representation enables the explicit expressions of the square or power, determinant, inverse, eigendecomposition, canonical form, and the other matrix functions of the original larger-dimensional matrix on the basis of these \"coordinate\" matrices. By utilizing this representation, we construct null distributions of information test statistics for the population mean(s) in both single and multiple sample cases, which are extensions of Hotelling's $T^2$ and $T_0^2$, respectively.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08553v1","tag":"data-quality"}}
{"title":"Lossy Compressor preserving variant calling through Extended BWT","abstract":"A standard format used for storing the output of high-throughput sequencing experiments is the FASTQ format. It comprises three main components: (i) headers, (ii) bases (nucleotide sequences), and (iii) quality scores. FASTQ files are widely used for variant calling, where sequencing data are mapped into a reference genome to discover variants that may be used for further analysis. There are many specialized compressors that exploit redundancy in FASTQ data with the focus only on either the bases or the quality scores components. In this paper we consider the novel problem of lossy compressing, in a reference-free way, FASTQ data by modifying both components at the same time, while preserving the important information of the original FASTQ. We introduce a general strategy, based on the Extended Burrows-Wheeler Transform (EBWT) and positional clustering, and we present implementations in both internal memory and external memory. Experimental results show that the lossy compression performed by our tool is able to achieve good compression while preserving information relating to variant calling more than the competitors. Availability: the software is freely available at https://github.com/veronicaguerrini/BFQzip.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08534v1","tag":"data-quality"}}
{"title":"Deep Learning Criminal Networks","abstract":"Recent advances in deep learning methods have enabled researchers to develop and apply algorithms for the analysis and modeling of complex networks. These advances have sparked a surge of interest at the interface between network science and machine learning. Despite this, the use of machine learning methods to investigate criminal networks remains surprisingly scarce. Here, we explore the potential of graph convolutional networks to learn patterns among networked criminals and to predict various properties of criminal networks. Using empirical data from political corruption, criminal police intelligence, and criminal financial networks, we develop a series of deep learning models based on the GraphSAGE framework that are capable to recover missing criminal partnerships, distinguish among types of associations, predict the amount of money exchanged among criminal agents, and even anticipate partnerships and recidivism of criminals during the growth dynamics of corruption networks, all with impressive accuracy. Our deep learning models significantly outperform previous shallow learning approaches and produce high-quality embeddings for node and edge properties. Moreover, these models inherit all the advantages of the GraphSAGE framework, including the generalization to unseen nodes and scaling up to large graph structures.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08457v1","tag":"data-quality"}}
{"title":"The MiniPile Challenge for Data-Efficient Language Models","abstract":"The ever-growing diversity of pre-training text corpora has equipped language models with generalization capabilities across various downstream tasks. However, such diverse datasets are often too large for academic budgets; hence, most research on Transformer architectures, training procedures, optimizers, etc. gets conducted on smaller, homogeneous datasets. To this end, we present The MiniPile Challenge, where one pre-trains a language model on a diverse text corpus containing at most 1M documents. MiniPile is a 6GB subset of the deduplicated 825GB The Pile corpus. To curate MiniPile, we perform a simple, three-step data filtering process: we (1) infer embeddings for all documents of the Pile, (2) cluster the embedding space using $k$-means, and (3) filter out low-quality clusters. To verify MiniPile's suitability for language model pre-training, we use it to pre-train a BERT and T5 model, yielding a performance drop of only $1.9\\%$/$2.5\\%$ on the GLUE and SNI benchmarks compared to the original pre-trained checkpoints trained on $2.6$x/$745$x the amount of data. MiniPile is available at https://huggingface.co/datasets/JeanKaddour/minipile.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08442v1","tag":"data-quality"}}
{"title":"First Detection of the BAO Signal from Early DESI Data","abstract":"We present the first detection of the baryon acoustic oscillations (BAO) signal obtained using unblinded data collected during the initial two months of operations of the Stage-IV ground-based Dark Energy Spectroscopic Instrument (DESI). From a selected sample of 261,291 Luminous Red Galaxies spanning the redshift interval 0.4 < z < 1.1 and covering 1651 square degrees with a 57.9% completeness level, we report a ~5 sigma level BAO detection and the measurement of the BAO location at a precision of 1.7%. Using a Bright Galaxy Sample of 109,523 galaxies in the redshift range 0.1 < z < 0.5, over 3677 square degrees with a 50.0% completeness, we also detect the BAO feature at ~3 sigma significance with a 2.6% precision. These first BAO measurements represent an important milestone, acting as a quality control on the optimal performance of the complex robotically-actuated, fiber-fed DESI spectrograph, as well as an early validation of the DESI spectroscopic pipeline and data management system. Based on these first promising results, we forecast that DESI is on target to achieve a high-significance BAO detection at sub-percent precision with the completed 5-year survey data, meeting the top-level science requirements on BAO measurements. This exquisite level of precision will set new standards in cosmology and confirm DESI as the most competitive BAO experiment for the remainder of this decade.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08427v1","tag":"data-quality"}}
{"title":"Asymptotics of Caliper Matching Estimators for Average Treatment Effects","abstract":"Caliper matching is used to estimate causal effects of a binary treatment from observational data by comparing matched treated and control units. Units are matched when their propensity scores, the conditional probability of receiving treatment given pretreatment covariates, are within a certain distance called caliper. So far, theoretical results on caliper matching are lacking, leaving practitioners with ad-hoc caliper choices and inference procedures. We bridge this gap by proposing a caliper that balances the quality and the number of matches. We prove that the resulting estimator of the average treatment effect, and average treatment effect on the treated, is asymptotically unbiased and normal at parametric rate. We describe the conditions under which semiparametric efficiency is obtainable, and show that when the parametric propensity score is estimated, the variance is increased for both estimands. Finally, we construct asymptotic confidence intervals for the two estimands.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08373v1","tag":"data-quality"}}
{"title":"On approximating the temporal betweenness centrality through sampling","abstract":"We present a collection of sampling-based algorithms for approximating the temporal betweenness centrality of all nodes in a temporal graph. Our methods can compute probabilistically guaranteed high-quality temporal betweenness estimates (of nodes and temporal edges) under all the feasible temporal path optimalities presented in the work of Bu{\\ss} et al. (KDD, 2020). We provide a sample-complexity analysis of these methods and we speed up the temporal betweenness computation using progressive sampling techniques. Finally, we conduct an extensive experimental evaluation on real-world networks and we compare their performances in approximating the betweenness scores and rankings.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08356v1","tag":"data-quality"}}
{"title":"VALOR: Vision-Audio-Language Omni-Perception Pretraining Model and Dataset","abstract":"In this paper, we propose a Vision-Audio-Language Omni-peRception pretraining model (VALOR) for multi-modal understanding and generation. Different from widely-studied vision-language pretraining models, VALOR jointly models relationships of vision, audio and language in an end-to-end manner. It contains three separate encoders for single modality representations, and a decoder for multimodal conditional text generation. We design two pretext tasks to pretrain VALOR model, including Multimodal Grouping Alignment (MGA) and Multimodal Grouping Captioning (MGC). MGA projects vision, language and audio to the same common space, building vision-language, audio-language and audiovisual-language alignment simultaneously. MGC learns how to generate text tokens in conditions of vision, audio or their both. To promote vision-audio-language pretraining research, we construct a large-scale high-quality tri-modality dataset named VALOR-1M, which contains 1M audiable videos with human annotated audiovisual captions. Extensive experiments show that VALOR can learn strong multimodal correlations and be generalized to various downstream tasks (e.g., retrieval, captioning and question answering), with different input modalities (e.g., vision-language, audio-language and audiovisual-language). VALOR achieves new state-of-the-art performances on series of public cross-modality benchmarks. Code and data are available at project page https://casia-iva-group.github.io/projects/VALOR.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08345v1","tag":"data-quality"}}
{"title":"Computational Performance Aware Benchmarking of Unsupervised Concept Drift Detection","abstract":"For many AI systems, concept drift detection is crucial to ensure the systems reliability. These systems often have to deal with large amounts of data or react in real time. Thus, drift detectors must meet computational requirements or constraints with a comprehensive performance evaluation. However, so far, the focus of developing drift detectors is on detection quality, e.g.~accuracy, but not on computational performance, such as running time. We show that the previous works consider computational performance only as a secondary objective and do not have a benchmark for such evaluation. Hence, we propose a novel benchmark suite for drift detectors that accounts both detection quality and computational performance to ensure a detector's applicability in various AI systems. In this work, we focus on unsupervised drift detectors that are not restricted to the availability of labeled data and thus being widely applicable. Our benchmark suite supports configurable synthetic and real world data streams. Moreover, it provides means for simulating a machine learning model's output to unify the performance evaluation across different drift detectors. This allows a fair and comprehensive comparison of drift detectors proposed in related work. Our benchmark suite is integrated in the existing framework, Massive Online Analysis (MOA). To evaluate our benchmark suite's capability, we integrate two representative unsupervised drift detectors. Our work enables the scientific community to achieve a baseline for unsupervised drift detectors with respect to both detection quality and computational performance.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08319v1","tag":"data-quality"}}
{"title":"Predicting dynamic, motion-related changes in B0 field in the brain at a 7 T MRI using a subject-specific fine-tuned U-net","abstract":"Subject movement during the magnetic resonance examination is inevitable and causes not only image artefacts but also deteriorates the homogeneity of the main magnetic field (B0), which is a prerequisite for high quality data. Thus, characterization of changes to B0, e.g. induced by patient movement, is important for MR applications that are prone to B0 inhomogeneities. We propose a deep learning based method to predict such changes within the brain from the change of the head position to facilitate retrospective or even real-time correction. A 3D U-net was trained on in vivo brain 7T MRI data. The input consisted of B0 maps and anatomical images at an initial position, and anatomical images at a different head position (obtained by applying a rigid-body transformation on the initial anatomical image). The output consisted of B0 maps at the new head positions. We further fine-tuned the network weights to each subject by measuring a limited number of head positions of the given subject, and trained the U-net with these data. Our approach was compared to established dynamic B0 field mapping via interleaved navigators, which suffer from limited spatial resolution and the need for undesirable sequence modifications. Qualitative and quantitative comparison showed similar performance between an interleaved navigator-equivalent method and proposed method. We therefore conclude that it is feasible to predict B0 maps from rigid subject movement and, when combined with external tracking hardware, this information could be used to improve the quality of magnetic resonance acquisitions without the use of navigators.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08307v1","tag":"data-quality"}}
{"title":"Deep-Learning-based Vascularture Extraction for Single-Scan Optical Coherence Tomography Angiography","abstract":"Optical coherence tomography angiography (OCTA) is a non-invasive imaging modality that extends the functionality of OCT by extracting moving red blood cell signals from surrounding static biological tissues. OCTA has emerged as a valuable tool for analyzing skin microvasculature, enabling more accurate diagnosis and treatment monitoring. Most existing OCTA extraction algorithms, such as speckle variance (SV)- and eigen-decomposition (ED)-OCTA, implement a larger number of repeated (NR) OCT scans at the same position to produce high-quality angiography images. However, a higher NR requires a longer data acquisition time, leading to more unpredictable motion artifacts. In this study, we propose a vasculature extraction pipeline that uses only one-repeated OCT scan to generate OCTA images. The pipeline is based on the proposed Vasculature Extraction Transformer (VET), which leverages convolutional projection to better learn the spatial relationships between image patches. In comparison to OCTA images obtained via the SV-OCTA (PSNR: 17.809) and ED-OCTA (PSNR: 18.049) using four-repeated OCT scans, OCTA images extracted by VET exhibit moderate quality (PSNR: 17.515) and higher image contrast while reducing the required data acquisition time from ~8 s to ~2 s. Based on visual observations, the proposed VET outperforms SV and ED algorithms when using neck and face OCTA data in areas that are challenging to scan. This study represents that the VET has the capacity to extract vascularture images from a fast one-repeated OCT scan, facilitating accurate diagnosis for patients.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08282v1","tag":"data-quality"}}
{"title":"Spectroscopic age estimates for 180 000 APOGEE red-giant stars: Precise spatial and kinematic trends with age in the Galactic disc","abstract":"Over the last few years, many studies have found an empirical relationship between the abundance of a star and its age. Here we estimate spectroscopic stellar ages for 178 825 red-giant stars observed by the APOGEE survey with a median statistical uncertainty of 17%. To this end, we use the supervised machine learning technique XGBoost, trained on a high-quality dataset of 3 060 red-giant and red-clump stars with asteroseismic ages observed by both APOGEE and Kepler. After verifying the obtained age estimates with independent catalogues, we investigate some of the classical chemical, positional, and kinematic relationships of the stars as a function of their age. We find a very clear imprint of the outer-disc flare in the age maps and confirm the recently found split in the local age-metallicity relation. We present new and precise measurements of the Galactic radial metallicity gradient in small age bins between 0.5 and 12 Gyr, confirming a steeper metallicity gradient for 2-5 Gyr old populations and a subsequent flattening for older populations mostly produced by radial migration. In addition, we analyse the dispersion about the abundance gradient as a function of age. We find a clear power-law trend (with an exponent $\\beta\\approx0.15$) for this relation, indicating a smooth radial migration history in the Galactic disc over the past 7-9 Gyr. Departures from this power law are detected at ages of 8 Gyr (possibly related to the Gaia Sausage/Enceladus merger) and 2.75 Gyr (possibly related to an enhancement of the star-formation rate in the Galactic disc). Finally, we confirm previous measurements showing a steepening in the age-velocity dispersion relation at around 9 Gyr, but now extending it over a large extent of the Galactic disc (5 kpc < RGal < 13 kpc). [Abridged]","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08276v1","tag":"data-quality"}}
{"title":"Dumpy: A Compact and Adaptive Index for Large Data Series Collections","abstract":"Data series indexes are necessary for managing and analyzing the increasing amounts of data series collections that are nowadays available. These indexes support both exact and approximate similarity search, with approximate search providing high-quality results within milliseconds, which makes it very attractive for certain modern applications. Reducing the pre-processing (i.e., index building) time and improving the accuracy of search results are two major challenges. DSTree and the iSAX index family are state-of-the-art solutions for this problem. However, DSTree suffers from long index building times, while iSAX suffers from low search accuracy. In this paper, we identify two problems of the iSAX index family that adversely affect the overall performance. First, we observe the presence of a proximity-compactness trade-off related to the index structure design (i.e., the node fanout degree), significantly limiting the efficiency and accuracy of the resulting index. Second, a skewed data distribution will negatively affect the performance of iSAX. To overcome these problems, we propose Dumpy, an index that employs a novel multi-ary data structure with an adaptive node splitting algorithm and an efficient building workflow. Furthermore, we devise Dumpy-Fuzzy as a variant of Dumpy which further improves search accuracy by proper duplication of series. Experiments with a variety of large, real datasets demonstrate that the Dumpy solutions achieve considerably better efficiency, scalability and search accuracy than its competitors. This paper was published in SIGMOD'23.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08264v1","tag":"data-quality"}}
{"title":"Political corpus creation through automatic speech recognition on EU debates","abstract":"In this paper, we present a transcribed corpus of the LIBE committee of the EU parliament, totalling 3.6 Million running words. The meetings of parliamentary committees of the EU are a potentially valuable source of information for political scientists but the data is not readily available because only disclosed as speech recordings together with limited metadata. The meetings are in English, partly spoken by non-native speakers, and partly spoken by interpreters. We investigated the most appropriate Automatic Speech Recognition (ASR) model to create an accurate text transcription of the audio recordings of the meetings in order to make their content available for research and analysis. We focused on the unsupervised domain adaptation of the ASR pipeline. Building on the transformer-based Wav2vec2.0 model, we experimented with multiple acoustic models, language models and the addition of domain-specific terms. We found that a domain-specific acoustic model and a domain-specific language model give substantial improvements to the ASR output, reducing the word error rate (WER) from 28.22 to 17.95. The use of domain-specific terms in the decoding stage did not have a positive effect on the quality of the ASR in terms of WER. Initial topic modelling results indicated that the corpus is useful for downstream analysis tasks. We release the resulting corpus and our analysis pipeline for future research.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08137v1","tag":"data-quality"}}
{"title":"Leveraging Multi-view Data for Improved Detection Performance: An Industrial Use Case","abstract":"Printed circuit boards (PCBs) are essential components of electronic devices, and ensuring their quality is crucial in their production. However, the vast variety of components and PCBs manufactured by different companies makes it challenging to adapt to production lines with speed demands. To address this challenge, we present a multi-view object detection framework that offers a fast and precise solution. We introduce a novel multi-view dataset with semi-automatic ground-truth data, which results in significant labeling resource savings. Labeling PCB boards for object detection is a challenging task due to the high density of components and the small size of the objects, which makes it difficult to identify and label them accurately. By training an object detector model with multi-view data, we achieve improved performance over single-view images. To further enhance the accuracy, we develop a multi-view inference method that aggregates results from different viewpoints. Our experiments demonstrate a 15% improvement in mAP for detecting components that range in size from 0.5 to 27.0 mm.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08111v1","tag":"data-quality"}}
{"title":"Fast Random Approximation of Multi-channel Room Impulse Response","abstract":"Modern neural-network-based speech processing systems are typically required to be robust against reverberation, and the training of such systems thus needs a large amount of reverberant data. During the training of the systems, on-the-fly simulation pipeline is nowadays preferred as it allows the model to train on infinite number of data samples without pre-generating and saving them on harddisk. An RIR simulation method thus needs to not only generate more realistic artificial room impulse response (RIR) filters, but also generate them in a fast way to accelerate the training process. Existing RIR simulation tools have proven effective in a wide range of speech processing tasks and neural network architectures, but their usage in on-the-fly simulation pipeline remains questionable due to their computational complexity or the quality of the generated RIR filters. In this paper, we propose FRAM-RIR, a fast random approximation method of the widely-used image-source method (ISM), to efficiently generate realistic multi-channel RIR filters. FRAM-RIR bypasses the explicit calculation of sound propagation paths in ISM-based algorithms by randomly sampling the location and number of reflections of each virtual sound source based on several heuristic assumptions, while still maintains accurate direction-of-arrival (DOA) information of all sound sources. Visualization of oracle beampatterns and directional features shows that FRAM-RIR can generate more realistic RIR filters than existing widely-used ISM-based tools, and experiment results on multi-channel noisy speech separation and dereverberation tasks with a wide range of neural network architectures show that models trained with FRAM-RIR can also achieve on par or better performance on real RIRs compared to other RIR simulation tools with a significantly accelerated training procedure. A Python implementation of FRAM-RIR is released.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08052v1","tag":"data-quality"}}
{"title":"Reward-free Policy Imitation Learning for Conversational Search","abstract":"Existing conversational search studies mainly focused on asking better clarifying questions and/or improving search result quality. These works aim at retrieving better responses according to the search context, and their performances are evaluated on either single-turn tasks or multi-turn tasks under naive conversation policy settings. This leaves some questions about their applicability in real-world multi-turn conversations where realistically, each and every action needs to be made by the system itself, and search session efficiency is often an important concern of conversational search systems. While some recent works have identified the need for improving search efficiency in conversational search, they mostly require extensive data annotations and use hand-crafted rewards or heuristics to train systems that can achieve reasonable performance in a restricted number of turns, which has limited generalizability in practice.   In this paper, we propose a reward-free conversation policy imitation learning framework, which can train a conversation policy without annotated conversation data or manually designed rewards. The trained conversation policy can be used to guide the conversational retrieval models to balance conversational search quality and efficiency. To evaluate the proposed conversational search system, we propose a new multi-turn-multi-response conversational evaluation metric named Expected Conversational Reciprocal Rank (ECRR). ECRR is designed to evaluate entire multi-turn conversational search sessions towards comprehensively evaluating both search result quality and search efficiency.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07988v1","tag":"data-quality"}}
{"title":"Bent & Broken Bicycles: Leveraging synthetic data for damaged object re-identification","abstract":"Instance-level object re-identification is a fundamental computer vision task, with applications from image retrieval to intelligent monitoring and fraud detection. In this work, we propose the novel task of damaged object re-identification, which aims at distinguishing changes in visual appearance due to deformations or missing parts from subtle intra-class variations. To explore this task, we leverage the power of computer-generated imagery to create, in a semi-automatic fashion, high-quality synthetic images of the same bike before and after a damage occurs. The resulting dataset, Bent & Broken Bicycles (BBBicycles), contains 39,200 images and 2,800 unique bike instances spanning 20 different bike models. As a baseline for this task, we propose TransReI3D, a multi-task, transformer-based deep network unifying damage detection (framed as a multi-label classification task) with object re-identification. The BBBicycles dataset is available at https://huggingface.co/datasets/GrainsPolito/BBBicycles","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07883v1","tag":"data-quality"}}
{"title":"A Data-Centric Solution to NonHomogeneous Dehazing via Vision Transformer","abstract":"Recent years have witnessed an increased interest in image dehazing. Many deep learning methods have been proposed to tackle this challenge, and have made significant accomplishments dealing with homogeneous haze. However, these solutions cannot maintain comparable performance when they are applied to images with non-homogeneous haze, e.g., NH-HAZE23 dataset introduced by NTIRE challenges. One of the reasons for such failures is that non-homogeneous haze does not obey one of the assumptions that is required for modeling homogeneous haze. In addition, a large number of pairs of non-homogeneous hazy image and the clean counterpart is required using traditional end-to-end training approaches, while NH-HAZE23 dataset is of limited quantities. Although it is possible to augment the NH-HAZE23 dataset by leveraging other non-homogeneous dehazing datasets, we observe that it is necessary to design a proper data-preprocessing approach that reduces the distribution gaps between the target dataset and the augmented one. This finding indeed aligns with the essence of data-centric AI. With a novel network architecture and a principled data-preprocessing approach that systematically enhances data quality, we present an innovative dehazing method. Specifically, we apply RGB-channel-wise transformations on the augmented datasets, and incorporate the state-of-the-art transformers as the backbone in the two-branch framework. We conduct extensive experiments and ablation study to demonstrate the effectiveness of our proposed method.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07874v2","tag":"data-quality"}}
{"title":"Towards Better Instruction Following Language Models for Chinese: Investigating the Impact of Training Data and Evaluation","abstract":"Recently, significant public efforts have been directed towards developing low-cost models with capabilities akin to ChatGPT, thereby fostering the growth of open-source conversational models. However, there remains a scarcity of comprehensive and in-depth evaluations of these models' performance. In this study, we examine the influence of training data factors, including quantity, quality, and linguistic distribution, on model performance. Our analysis is grounded in several publicly accessible, high-quality instruction datasets, as well as our own Chinese multi-turn conversations. We assess various models using a evaluation set of 1,000 samples, encompassing nine real-world scenarios. Our goal is to supplement manual evaluations with quantitative analyses, offering valuable insights for the continued advancement of open-source chat models. Furthermore, to enhance the performance and training and inference efficiency of models in the Chinese domain, we extend the vocabulary of LLaMA - the model with the closest open-source performance to proprietary language models like GPT-3 - and conduct secondary pre-training on 3.4B Chinese words. We make our model, data, as well as code publicly available.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07854v1","tag":"data-quality"}}
{"title":"A Virtual Simulation-Pilot Agent for Training of Air Traffic Controllers","abstract":"In this paper we propose a novel virtual simulation-pilot engine for speeding up air traffic controller (ATCo) training by integrating different state-of-the-art artificial intelligence (AI) based tools. The virtual simulation-pilot engine receives spoken communications from ATCo trainees, and it performs automatic speech recognition and understanding. Thus, it goes beyond only transcribing the communication and can also understand its meaning. The output is subsequently sent to a response generator system, which resembles the spoken read back that pilots give to the ATCo trainees. The overall pipeline is composed of the following submodules: (i) automatic speech recognition (ASR) system that transforms audio into a sequence of words; (ii) high-level air traffic control (ATC) related entity parser that understands the transcribed voice communication; and (iii) a text-to-speech submodule that generates a spoken utterance that resembles a pilot based on the situation of the dialogue. Our system employs state-of-the-art AI-based tools such as Wav2Vec 2.0, Conformer, BERT and Tacotron models. To the best of our knowledge, this is the first work fully based on open-source ATC resources and AI tools. In addition, we have developed a robust and modular system with optional submodules that can enhance the system's performance by incorporating real-time surveillance data, metadata related to exercises (such as sectors or runways), or even introducing a deliberate read-back error to train ATCo trainees to identify them. Our ASR system can reach as low as 5.5% and 15.9% word error rates (WER) on high and low-quality ATC audio. We also demonstrate that adding surveillance data into the ASR can yield callsign detection accuracy of more than 96%.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07842v1","tag":"data-quality"}}
{"title":"JUMP: Joint communication and sensing with Unsynchronized transceivers Made Practical","abstract":"Wideband millimeter-wave communication systems can be extended to provide radar-like sensing capabilities on top of data communication, in a cost-effective manner. However, the development of joint communication and sensing technology is hindered by practical challenges, such as occlusions to the line-of-sight path and clock asynchrony between devices. The latter introduces time-varying timing and frequency offsets that prevent the estimation of sensing parameters and, in turn, the use of standard signal processing solutions. Existing approaches cannot be applied to commonly used phased-array receivers, as they build on stringent assumptions about the multipath environment, and are computationally complex. We present JUMP, the first system enabling practical bistatic and asynchronous joint communication and sensing, while achieving accurate target tracking and micro-Doppler extraction in realistic conditions. Our system compensates for the timing offset by exploiting the channel correlation across subsequent packets. Further, it tracks multipath reflections and eliminates frequency offsets by observing the phase of a dynamically-selected static reference path. JUMP has been implemented on a 60 GHz experimental platform, performing extensive evaluations of human motion sensing, including non-line-of-sight scenarios. In our results, JUMP attains comparable tracking performance to a full-duplex monostatic system and similar micro-Doppler quality with respect to a phase-locked bistatic receiver.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07766v1","tag":"data-quality"}}
{"title":"Meta-optimized Contrastive Learning for Sequential Recommendation","abstract":"Contrastive Learning (CL) performances as a rising approach to address the challenge of sparse and noisy recommendation data. Although having achieved promising results, most existing CL methods only perform either hand-crafted data or model augmentation for generating contrastive pairs to find a proper augmentation operation for different datasets, which makes the model hard to generalize. Additionally, since insufficient input data may lead the encoder to learn collapsed embeddings, these CL methods expect a relatively large number of training data (e.g., large batch size or memory bank) to contrast. However, not all contrastive pairs are always informative and discriminative enough for the training processing. Therefore, a more general CL-based recommendation model called Meta-optimized Contrastive Learning for sequential Recommendation (MCLRec) is proposed in this work. By applying both data augmentation and learnable model augmentation operations, this work innovates the standard CL framework by contrasting data and model augmented views for adaptively capturing the informative features hidden in stochastic data augmentation. Moreover, MCLRec utilizes a meta-learning manner to guide the updating of the model augmenters, which helps to improve the quality of contrastive pairs without enlarging the amount of input data. Finally, a contrastive regularization term is considered to encourage the augmentation model to generate more informative augmented views and avoid too similar contrastive pairs within the meta updating. The experimental results on commonly used datasets validate the effectiveness of MCLRec.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07763v1","tag":"data-quality"}}
{"title":"Framework for Quality Evaluation of Smart Roadside Infrastructure Sensors for Automated Driving Applications","abstract":"The use of smart roadside infrastructure sensors is highly relevant for future applications of connected and automated vehicles. External sensor technology in the form of intelligent transportation system stations (ITS-Ss) can provide safety-critical real-time information about road users in the form of a digital twin. The choice of sensor setups has a major influence on the downstream function as well as the data quality. To date, there is insufficient research on which sensor setups result in which levels of ITS-S data quality. We present a novel approach to perform detailed quality assessment for smart roadside infrastructure sensors. Our framework is multimodal across different sensor types and is evaluated on the DAIR-V2X dataset. We analyze the composition of different lidar and camera sensors and assess them in terms of accuracy, latency, and reliability. The evaluations show that the framework can be used reliably for several future ITS-S applications.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07745v1","tag":"data-quality"}}
{"title":"A Novel end-to-end Framework for Occluded Pixel Reconstruction with Spatio-temporal Features for Improved Person Re-identification","abstract":"Person re-identification is vital for monitoring and tracking crowd movement to enhance public security. However, re-identification in the presence of occlusion substantially reduces the performance of existing systems and is a challenging area. In this work, we propose a plausible solution to this problem by developing effective occlusion detection and reconstruction framework for RGB images/videos consisting of Deep Neural Networks. Specifically, a CNN-based occlusion detection model classifies individual input frames, followed by a Conv-LSTM and Autoencoder to reconstruct the occluded pixels corresponding to the occluded frames for sequential (video) and non-sequential (image) data, respectively. The quality of the reconstructed RGB frames is further refined and fine-tuned using a Conditional Generative Adversarial Network (cGAN). Our method is evaluated on four well-known public data sets of the domain, and the qualitative reconstruction results are indeed appealing. Quantitative evaluation in terms of re-identification accuracy of the Siamese network showed an exceptional Rank-1 accuracy after occluded pixel reconstruction on various datasets. A comparative analysis with state-of-the-art approaches also demonstrates the robustness of our work for use in real-life surveillance systems.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07721v1","tag":"data-quality"}}
{"title":"The Gaia-ESO Survey: homogenisation of stellar parameters and elemental abundances","abstract":"The Gaia-ESO Survey is a public spectroscopic survey that has targeted $\\gtrsim10^5$ stars covering all major components of the Milky Way from the end of 2011 to 2018, delivering its public final release in May 2022. Unlike other spectroscopic surveys, Gaia-ESO is the only survey that observed stars across all spectral types with dedicated, specialised analyses: from O ($T_\\mathrm{eff} \\sim 30,000-52,000$~K) all the way to K-M ($\\gtrsim$3,500~K). The physics throughout these stellar regimes varies significantly, which has previously prohibited any detailed comparisons between stars of significantly different type. In the final data release (internal data release 6) of the Gaia-ESO Survey, we provide the final database containing a large number of products such as radial velocities, stellar parameters and elemental abundances, rotational velocity, and also, e.g., activity and accretion indicators in young stars and membership probability in star clusters for more than 114,000 stars. The spectral analysis is coordinated by a number of Working Groups (WGs) within the Survey, which specialise in the various stellar samples. Common targets are analysed across WGs to allow for comparisons (and calibrations) amongst instrumental setups and spectral types. Here we describe the procedures employed to ensure all Survey results are placed on a common scale to arrive at a single set of recommended results for all Survey collaborators to use. We also present some general quality and consistency checks performed over all Survey results.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07720v1","tag":"data-quality"}}
{"title":"Development of Tools for the Classification of Peer Groups Geographies in the Analysis of Health Care Variation","abstract":"This dissertation is based on a project co-founded by the Health Market Quality Program (now Rozetta Institute) and the Australian Institute of Health and Welfare. The overall objective of this work is to provide a framework and a tool for classification and clustering of homogeneous geographic areas based on aggregated population data. Thus, to enable the presentation and reporting of comparable information of individual units with peers, I develop the Homogeneity and Location indices to measure respectively the dispersion and central tendency of a categorical ordinal distribution. The advantages of such indices include statistical efficiency and a simple presentation of results. Our approach is founded on the general theory of probability distributions, and our aim is to provide a natural benchmark for a homogeneity measure in terms of what is a \"high\" and \"low\" concentration of a probability distribution. Currently, there is no accepted benchmark that could be used to assess the homogeneity of a categorical ordinal variable. In this work, the proposed statistical indices are used to assess the socioeconomic homogeneity of the commonly used SA3 Australia census geography and analyse the variation of GP attenders in the metropolitan area of Sydney. The approach can be used to classify any geographic area and explore variation across any specified geographical boundaries. The SA3 dataset and scripts (R/Python) to develop these indices have been made available on my GitHub account: https://github.com/lpinzari/homogeneity-location-index","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07709v1","tag":"data-quality"}}
{"title":"USNID: A Framework for Unsupervised and Semi-supervised New Intent Discovery","abstract":"New intent discovery is of great value to natural language processing, allowing for a better understanding of user needs and providing friendly services. However, most existing methods struggle to capture the complicated semantics of discrete text representations when limited or no prior knowledge of labeled data is available. To tackle this problem, we propose a novel framework called USNID for unsupervised and semi-supervised new intent discovery, which has three key technologies. First, it takes full use of unsupervised or semi-supervised data to mine shallow semantic similarity relations and provide well-initialized representations for clustering. Second, it designs a centroid-guided clustering mechanism to address the issue of cluster allocation inconsistency and provide high-quality self-supervised targets for representation learning. Third, it captures high-level semantics in unsupervised or semi-supervised data to discover fine-grained intent-wise clusters by optimizing both cluster-level and instance-level objectives. We also propose an effective method for estimating the cluster number in open-world scenarios without knowing the number of new intents beforehand. USNID performs exceptionally well on several intent benchmark datasets, achieving new state-of-the-art results in unsupervised and semi-supervised new intent discovery and demonstrating robust performance with different cluster numbers.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07699v1","tag":"data-quality"}}
{"title":"Solving Math Word Problems by Combining Language Models With Symbolic Solvers","abstract":"Automatically generating high-quality step-by-step solutions to math word problems has many applications in education. Recently, combining large language models (LLMs) with external tools to perform complex reasoning and calculation has emerged as a promising direction for solving math word problems, but prior approaches such as Program-Aided Language model (PAL) are biased towards simple procedural problems and less effective for problems that require declarative reasoning. We propose an approach that combines an LLM that can incrementally formalize word problems as a set of variables and equations with an external symbolic solver that can solve the equations. Our approach achieves comparable accuracy to the original PAL on the GSM8K benchmark of math word problems and outperforms PAL by an absolute 20% on ALGEBRA, a new dataset of more challenging word problems extracted from Algebra textbooks. Our work highlights the benefits of using declarative and incremental representations when interfacing with an external tool for solving complex math word problems. Our data and prompts are publicly available at https://github.com/joyheyueya/declarative-math-word-problem.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.09102v1","tag":"data-quality"}}
{"title":"Using Geographic Location-based Public Health Features in Survival Analysis","abstract":"Time elapsed till an event of interest is often modeled using the survival analysis methodology, which estimates a survival score based on the input features. There is a resurgence of interest in developing more accurate prediction models for time-to-event prediction in personalized healthcare using modern tools such as neural networks. Higher quality features and more frequent observations improve the predictions for a patient, however, the impact of including a patient's geographic location-based public health statistics on individual predictions has not been studied. This paper proposes a complementary improvement to survival analysis models by incorporating public health statistics in the input features. We show that including geographic location-based public health information results in a statistically significant improvement in the concordance index evaluated on the Surveillance, Epidemiology, and End Results (SEER) dataset containing nationwide cancer incidence data. The improvement holds for both the standard Cox proportional hazards model and the state-of-the-art Deep Survival Machines model. Our results indicate the utility of geographic location-based public health features in survival analysis.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07679v1","tag":"data-quality"}}
{"title":"Privacy-Enhanced Living: A Local Differential Privacy Approach to Secure Smart Home Data","abstract":"The rapid expansion of Internet of Things (IoT) devices in smart homes has significantly improved the quality of life, offering enhanced convenience, automation, and energy efficiency. However, this proliferation of connected devices raises critical concerns regarding security and privacy of the user data. In this paper, we propose a differential privacy-based system to ensure comprehensive security for data generated by smart homes. We employ the randomized response technique for the data and utilize Local Differential Privacy (LDP) to achieve data privacy. The data is then transmitted to an aggregator, where an obfuscation method is applied to ensure individual anonymity. Furthermore, we implement the Hidden Markov Model (HMM) technique at the aggregator level and apply differential privacy to the private data received from smart homes. Consequently, our approach achieves a dual layer of privacy protection, addressing the security concerns associated with IoT devices in smart cities.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07676v1","tag":"data-quality"}}
{"title":"Data, Competition, and Digital Platforms","abstract":"We analyze digital markets where a monopolist platform uses data to match multiproduct sellers with heterogeneous consumers who can purchase both on and off the platform. The platform sells targeted ads to sellers that recommend their products to consumers and reveals information to consumers about their values. The revenue-optimal mechanism is a managed advertising campaign that matches products and preferences efficiently. In equilibrium, sellers offer higher qualities at lower unit prices on than off the platform. Privacy-respecting data-governance rules such as organic search results or federated learning can lead to welfare gains for consumers.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07653v1","tag":"data-quality"}}
{"title":"Compete to Win: Enhancing Pseudo Labels for Barely-supervised Medical Image Segmentation","abstract":"This study investigates barely-supervised medical image segmentation where only few labeled data, i.e., single-digit cases are available. We observe the key limitation of the existing state-of-the-art semi-supervised solution cross pseudo supervision is the unsatisfactory precision of foreground classes, leading to a degenerated result under barely-supervised learning. In this paper, we propose a novel Compete-to-Win method (ComWin) to enhance the pseudo label quality. In contrast to directly using one model's predictions as pseudo labels, our key idea is that high-quality pseudo labels should be generated by comparing multiple confidence maps produced by different networks to select the most confident one (a compete-to-win strategy). To further refine pseudo labels at near-boundary areas, an enhanced version of ComWin, namely, ComWin+, is proposed by integrating a boundary-aware enhancement module. Experiments show that our method can achieve the best performance on three public medical image datasets for cardiac structure segmentation, pancreas segmentation and colon tumor segmentation, respectively. The source code is now available at https://github.com/Huiimin5/comwin.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07519v1","tag":"data-quality"}}
{"title":"PI-FL: Personalized and Incentivized Federated Learning","abstract":"Personalized FL has been widely used to cater to heterogeneity challenges with non-IID data. A primary obstacle is considering the personalization process from the client's perspective to preserve their autonomy. Allowing the clients to participate in personalized FL decisions becomes significant due to privacy and security concerns, where the clients may not be at liberty to share private information necessary for producing good quality personalized models. Moreover, clients with high-quality data and resources are reluctant to participate in the FL process without reasonable incentive. In this paper, we propose PI-FL, a one-shot personalization solution complemented by a token-based incentive mechanism that rewards personalized training. PI-FL outperforms other state-of-the-art approaches and can generate good-quality personalized models while respecting clients' privacy.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07514v1","tag":"data-quality"}}
{"title":"Model-based Federated Learning for Accurate MR Image Reconstruction from Undersampled k-space Data","abstract":"Deep learning-based methods have achieved encouraging performances in the field of magnetic resonance (MR) image reconstruction. Nevertheless, to properly learn a powerful and robust model, these methods generally require large quantities of data, the collection of which from multiple centers may cause ethical and data privacy violation issues. Lately, federated learning has served as a promising solution to exploit multi-center data while getting rid of the data transfer between institutions. However, high heterogeneity exists in the data from different centers, and existing federated learning methods tend to use average aggregation methods to combine the client's information, which limits the performance and generalization capability of the trained models. In this paper, we propose a Model-based Federated learning framework (ModFed). ModFed has three major contributions: 1) Different from the existing data-driven federated learning methods, model-driven neural networks are designed to relieve each client's dependency on large data; 2) An adaptive dynamic aggregation scheme is proposed to address the data heterogeneity issue and improve the generalization capability and robustness the trained neural network models; 3) A spatial Laplacian attention mechanism and a personalized client-side loss regularization are introduced to capture the detailed information for accurate image reconstruction. ModFed is evaluated on three in-vivo datasets. Experimental results show that ModFed has strong capability in improving image reconstruction quality and enforcing model generalization capability when compared to the other five state-of-the-art federated learning approaches. Codes will be made available at https://github.com/ternencewu123/ModFed.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07502v1","tag":"data-quality"}}
{"title":"More Is Less: When Do Recommenders Underperform for Data-rich Users?","abstract":"Users of recommender systems tend to differ in their level of interaction with these algorithms, which may affect the quality of recommendations they receive and lead to undesirable performance disparity. In this paper we investigate under what conditions the performance for data-rich and data-poor users diverges for a collection of popular evaluation metrics applied to ten benchmark datasets. We find that Precision is consistently higher for data-rich users across all the datasets; Mean Average Precision is comparable across user groups but its variance is large; Recall yields a counter-intuitive result where the algorithm performs better for data-poor than for data-rich users, which bias is further exacerbated when negative item sampling is employed during evaluation. The final observation suggests that as users interact more with recommender systems, the quality of recommendations they receive degrades (when measured by Recall). Our insights clearly show the importance of an evaluation protocol and its influence on the reported results when studying recommender systems.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07487v1","tag":"data-quality"}}
{"title":"Learning To Optimize Quantum Neural Network Without Gradients","abstract":"Quantum Machine Learning is an emerging sub-field in machine learning where one of the goals is to perform pattern recognition tasks by encoding data into quantum states. This extension from classical to quantum domain has been made possible due to the development of hybrid quantum-classical algorithms that allow a parameterized quantum circuit to be optimized using gradient based algorithms that run on a classical computer. The similarities in training of these hybrid algorithms and classical neural networks has further led to the development of Quantum Neural Networks (QNNs). However, in the current training regime for QNNs, the gradients w.r.t objective function have to be computed on the quantum device. This computation is highly non-scalable and is affected by hardware and sampling noise present in the current generation of quantum hardware. In this paper, we propose a training algorithm that does not rely on gradient information. Specifically, we introduce a novel meta-optimization algorithm that trains a \\emph{meta-optimizer} network to output parameters for the quantum circuit such that the objective function is minimized. We empirically and theoretically show that we achieve a better quality minima in fewer circuit evaluations than existing gradient based algorithms on different datasets.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07442v1","tag":"data-quality"}}
{"title":"Spectrum-aware Multi-hop Task Routing in Vehicle-assisted Collaborative Edge Computing","abstract":"Multi-access edge computing (MEC) is a promising technology to enhance the quality of service, particularly for low-latency services, by enabling computing offloading to edge servers (ESs) in close proximity. To avoid network congestion, collaborative edge computing has become an emerging paradigm to enable different ESs to collaboratively share their data and computation resources. However, most papers in collaborative edge computing only allow one-hop offloading, which may limit computing resource sharing due to either poor channel conditions or computing workload at ESs one-hop away. By allowing ESs multi-hop away to also share the computing workload, a multi-hop MEC enables more ESs to share their computing resources. Inspired by this observation, in this paper, we propose to leverage omnipresent vehicles in a city to form a data transportation network for task delivery in a multi-hop fashion. Here, we propose a general multi-hop task offloading framework for vehicle-assisted MEC where tasks from users can be offloaded to powerful ESs via potentially multi-hop transmissions. Under the proposed framework, we develop a reinforcement learning based task offloading approach to address the curse of dimensionality problem due to vehicular mobility and channel variability, with the goal to maximize the aggregated service throughput under constraints on end-to-end latency, spectrum, and computing resources. Numerical results demonstrate that the proposed algorithm achieves excellent performance with low complexity and outperforms existing benchmark schemes.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07422v1","tag":"data-quality"}}
{"title":"An elaborated pattern-based method of identifying data oscillations from mobile device location data","abstract":"In recent years, passively collected GPS data have been popularly applied in various transportation studies, such as highway performance monitoring, travel behavior analysis, and travel demand estimation. Despite multiple advantages, one of the issues is data oscillations (aka outliers or data jumps), which are unneglectable since they may distort mobility patterns and lead to wrongly or biased conclusions. For transportation studies driven by GPS data, assuring the data quality by removing noises caused by data oscillations is undoubtedly important. Most GPS-based studies simply remove oscillations by checking the high speed. However, this method can mistakenly identify normal points as oscillations. Some other studies specifically discuss the removal of outliers in GPS data, but they all have limitations and do not fit passively collected GPS data. Many studies are well developed for addressing the ping-pong phenomenon in cellular data, or cellular tower data, but the oscillations in passively collected GPS data are very different for having much more various and complicated patterns and being more uncertain. Current methods are insufficient and inapplicable to passively collected GPS data. This paper aims to address the oscillated points in passively collected GPS data. A set of heuristics are proposed by identifying the abnormal movement patterns of oscillations. The proposed heuristics well fit the features of passively collected GPS data and are adaptable to studies of different scales, which are also computationally cost-effective in comparison to current methods.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07420v1","tag":"data-quality"}}
{"title":"PTW: Pivotal Tuning Watermarking for Pre-Trained Image Generators","abstract":"Deepfakes refer to content synthesized using deep generators, which, when \\emph{misused}, have the potential to erode trust in digital media. Synthesizing high-quality deepfakes requires access to large and complex generators only few entities can train and provide. The threat are malicious users that exploit access to the provided model and generate harmful deepfakes without risking detection. Watermarking makes deepfakes detectable by embedding an identifiable code into the generator that is later extractable from its generated images. We propose Pivotal Tuning Watermarking (PTW), a method for watermarking pre-trained generators (i) three orders of magnitude faster than watermarking from scratch and (ii) without the need for any training data. We improve existing watermarking methods and scale to generators $4 \\times$ larger than related work. PTW can embed longer codes than existing methods while better preserving the generator's image quality. We propose rigorous, game-based definitions for robustness and undetectability and our study reveals that watermarking is not robust against an adaptive white-box attacker who has control over the generator's parameters. We propose an adaptive attack that can successfully remove any watermarking with access to only $200$ non-watermarked images. Our work challenges the trustworthiness of watermarking for deepfake detection when the parameters of a generator are available.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07361v1","tag":"data-quality"}}
{"title":"Photon Field Networks for Dynamic Real-Time Volumetric Global Illumination","abstract":"Volume data is commonly found in many scientific disciplines, like medicine, physics, and biology. Experts rely on robust scientific visualization techniques to extract valuable insights from the data. Recent years have shown path tracing to be the preferred approach for volumetric rendering, given its high levels of realism. However, real-time volumetric path tracing often suffers from stochastic noise and long convergence times, limiting interactive exploration. In this paper, we present a novel method to enable real-time global illumination for volume data visualization. We develop Photon Field Networks -- a phase-function-aware, multi-light neural representation of indirect volumetric global illumination. The fields are trained on multi-phase photon caches that we compute a priori. Training can be done within seconds, after which the fields can be used in various rendering tasks. To showcase their potential, we develop a custom neural path tracer, with which our photon fields achieve interactive framerates even on large datasets. We conduct in-depth evaluations of the method's performance, including visual quality, stochastic noise, inference and rendering speeds, and accuracy regarding illumination and phase function awareness. Results are compared to ray marching, path tracing and photon mapping. Our findings show that Photon Field Networks can faithfully represent indirect global illumination across the phase spectrum while exhibiting less stochastic noise and rendering at a significantly faster rate than traditional methods.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07338v1","tag":"data-quality"}}
{"title":"OpenAssistant Conversations -- Democratizing Large Language Model Alignment","abstract":"Aligning large language models (LLMs) with human preferences has proven to drastically improve usability and has driven rapid adoption as demonstrated by ChatGPT. Alignment techniques such as supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) greatly reduce the required skill and domain knowledge to effectively harness the capabilities of LLMs, increasing their accessibility and utility across various domains. However, state-of-the-art alignment techniques like RLHF rely on high-quality human feedback data, which is expensive to create and often remains proprietary. In an effort to democratize research on large-scale alignment, we release OpenAssistant Conversations, a human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages distributed across 66,497 conversation trees, in 35 different languages, annotated with 461,292 quality ratings. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers. To demonstrate the OpenAssistant Conversations dataset's effectiveness, we present OpenAssistant, the first fully open-source large-scale instruction-tuned model to be trained on human data. A preference study revealed that OpenAssistant replies are comparably preferred to GPT-3.5-turbo (ChatGPT) with a relative winrate of 48.3% vs. 51.7% respectively. We release our code and data under fully permissive licenses.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07327v1","tag":"data-quality"}}
{"title":"Identifying Cluttering Edges in Near-Planar Graphs","abstract":"Planar drawings of graphs tend to be favored over non-planar drawings. Testing planarity and creating a planar layout of a planar graph can be done in linear time. However, creating readable drawings of nearly planar graphs remains a challenge. We therefore seek to answer which edges of nearly planar graphs create clutter in their drawings generated by mainstream graph drawing algorithms. We present a heuristic to identify problematic edges in nearly planar graphs and adjust their weights in order to produce higher quality layouts with spring-based drawing algorithms. Our experiments show that our heuristic produces significantly higher quality drawings for augmented grid graphs, augmented triangulations, and deep triangulations.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07274v2","tag":"data-quality"}}
{"title":"Repeatability of image quality in very low field MRI","abstract":"We investigated the repeatability of image quality metrics such as SNR, image uniformity, and geometrical distortion at 0.05T over ten days and three sessions per day. The measurements included temperature, humidity, transmit frequency, off-resonance maps, and 3D turbo spin echo (TSE) images of an in vitro phantom. This resulted in a protocol with nine pulse sequences. We also acquired a 3T data set for reference. The image quality metrics included computing SNR, image non-uniformity, and eccentricity (to assess geometrical distortion) to investigate the repeatability of 0.05T image quality. The image reconstruction included drift correction, k-space filtering, and off-resonance correction. We computed the coefficient of variation (CV) of the experimental parameters and the resulting image quality metrics to assess repeatability. The range of temperature measured during the study was within 1.50C. The off-resonance maps acquired before and after the 3D TSE showed similar hotspots and changed mainly by a global constant. The SNR measurements were highly repeatable across sessions and over the ten days, quantified by a CV of 4.9%. The magnetic field inhomogeneity effects quantified by eccentricity showed a CV of 13.7% but less than 5.1% in two of the three sessions over ten days. The use of conjugate phase reconstruction mitigated geometrical distortion artifacts. The repeatability of image uniformity was moderate at 10.6%, with two of three sessions resulting in a CV of less than 7.8%. Temperature and humidity did not significantly affect SNR and mean frequency drift within the ranges of these environmental factors investigated. We found that humidity and temperature in the range investigated did not impact SNR and frequency. Our findings indicate high repeatability for SNR and magnetic field homogeneity; and moderate repeatability for image uniformity.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07267v1","tag":"data-quality"}}
{"title":"Solar P-angle Alignment in GONG Dopplergrams","abstract":"In helioseismic studies, an observational parameter of primary concern is the P-angle, the angle along which lies the solar axis of rotation for a given image. For the six observing sites employed by The Global Oscillation Network Group (GONG), this angle acts additionally as a marker of relative image orientation, allowing concurrent images to be precisely aligned and merged to provide the highest possible quality data. In this report, we present and investigate two methods of determining the P-angle via the rotational signature embedded in solar Dopplergram images by examining the large-scale structure of the observed velocity field. As with other studies, we find that the Dopplergram produces a time-varying 'P-angle' signature according to the presentation of various physical phenomena across the solar surface, but with the potential for sub-degree identification of the axis of rotation. However, close agreement between separate P-angle-finding techniques also reveals current limitations to P-angle determination that are imposed by the calibration state of the GONG-site Dopplergrams, leaving these P-angle-finding methods for GONG with errors on the scale of less than a degree between two site.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07192v1","tag":"data-quality"}}
{"title":"A Comparative Study on Generative Models for High Resolution Solar Observation Imaging","abstract":"Solar activity is one of the main drivers of variability in our solar system and the key source of space weather phenomena that affect Earth and near Earth space. The extensive record of high resolution extreme ultraviolet (EUV) observations from the Solar Dynamics Observatory (SDO) offers an unprecedented, very large dataset of solar images. In this work, we make use of this comprehensive dataset to investigate capabilities of current state-of-the-art generative models to accurately capture the data distribution behind the observed solar activity states. Starting from StyleGAN-based methods, we uncover severe deficits of this model family in handling fine-scale details of solar images when training on high resolution samples, contrary to training on natural face images. When switching to the diffusion based generative model family, we observe strong improvements of fine-scale detail generation. For the GAN family, we are able to achieve similar improvements in fine-scale generation when turning to ProjectedGANs, which uses multi-scale discriminators with a pre-trained frozen feature extractor. We conduct ablation studies to clarify mechanisms responsible for proper fine-scale handling. Using distributed training on supercomputers, we are able to train generative models for up to 1024x1024 resolution that produce high quality samples indistinguishable to human experts, as suggested by the evaluation we conduct. We make all code, models and workflows used in this study publicly available at \\url{https://github.com/SLAMPAI/generative-models-for-highres-solar-images}.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07169v1","tag":"data-quality"}}
{"title":"Federated and distributed learning applications for electronic health records and structured medical data: A scoping review","abstract":"Federated learning (FL) has gained popularity in clinical research in recent years to facilitate privacy-preserving collaboration. Structured data, one of the most prevalent forms of clinical data, has experienced significant growth in volume concurrently, notably with the widespread adoption of electronic health records in clinical practice. This review examines FL applications on structured medical data, identifies contemporary limitations and discusses potential innovations. We searched five databases, SCOPUS, MEDLINE, Web of Science, Embase, and CINAHL, to identify articles that applied FL to structured medical data and reported results following the PRISMA guidelines. Each selected publication was evaluated from three primary perspectives, including data quality, modeling strategies, and FL frameworks. Out of the 1160 papers screened, 34 met the inclusion criteria, with each article consisting of one or more studies that used FL to handle structured clinical/medical data. Of these, 24 utilized data acquired from electronic health records, with clinical predictions and association studies being the most common clinical research tasks that FL was applied to. Only one article exclusively explored the vertical FL setting, while the remaining 33 explored the horizontal FL setting, with only 14 discussing comparisons between single-site (local) and FL (global) analysis. The existing FL applications on structured medical data lack sufficient evaluations of clinically meaningful benefits, particularly when compared to single-site analyses. Therefore, it is crucial for future FL applications to prioritize clinical motivations and develop designs and methodologies that can effectively support and aid clinical practice and research.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07310v1","tag":"data-quality"}}
{"title":"The Second Monocular Depth Estimation Challenge","abstract":"This paper discusses the results for the second edition of the Monocular Depth Estimation Challenge (MDEC). This edition was open to methods using any form of supervision, including fully-supervised, self-supervised, multi-task or proxy depth. The challenge was based around the SYNS-Patches dataset, which features a wide diversity of environments with high-quality dense ground-truth. This includes complex natural environments, e.g. forests or fields, which are greatly underrepresented in current benchmarks.   The challenge received eight unique submissions that outperformed the provided SotA baseline on any of the pointcloud- or image-based metrics. The top supervised submission improved relative F-Score by 27.62%, while the top self-supervised improved it by 16.61%. Supervised submissions generally leveraged large collections of datasets to improve data diversity. Self-supervised submissions instead updated the network architecture and pretrained backbones. These results represent a significant progress in the field, while highlighting avenues for future research, such as reducing interpolation artifacts at depth boundaries, improving self-supervised indoor performance and overall natural image accuracy.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07051v1","tag":"data-quality"}}
{"title":"Uncertainty-Aware Null Space Networks for Data-Consistent Image Reconstruction","abstract":"Reconstructing an image from noisy and incomplete measurements is a central task in several image processing applications. In recent years, state-of-the-art reconstruction methods have been developed based on recent advances in deep learning. Especially for highly underdetermined problems, maintaining data consistency is a key goal. This can be achieved either by iterative network architectures or by a subsequent projection of the network reconstruction. However, for such approaches to be used in safety-critical domains such as medical imaging, the network reconstruction should not only provide the user with a reconstructed image, but also with some level of confidence in the reconstruction. In order to meet these two key requirements, this paper combines deep null-space networks with uncertainty quantification. Evaluation of the proposed method includes image reconstruction from undersampled Radon measurements on a toy CT dataset and accelerated MRI reconstruction on the fastMRI dataset. This work is the first approach to solving inverse problems that additionally models data-dependent uncertainty by estimating an input-dependent scale map, providing a robust assessment of reconstruction quality.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.06955v1","tag":"data-quality"}}
{"title":"SMAE: Few-shot Learning for HDR Deghosting with Saturation-Aware Masked Autoencoders","abstract":"Generating a high-quality High Dynamic Range (HDR) image from dynamic scenes has recently been extensively studied by exploiting Deep Neural Networks (DNNs). Most DNNs-based methods require a large amount of training data with ground truth, requiring tedious and time-consuming work. Few-shot HDR imaging aims to generate satisfactory images with limited data. However, it is difficult for modern DNNs to avoid overfitting when trained on only a few images. In this work, we propose a novel semi-supervised approach to realize few-shot HDR imaging via two stages of training, called SSHDR. Unlikely previous methods, directly recovering content and removing ghosts simultaneously, which is hard to achieve optimum, we first generate content of saturated regions with a self-supervised mechanism and then address ghosts via an iterative semi-supervised learning framework. Concretely, considering that saturated regions can be regarded as masking Low Dynamic Range (LDR) input regions, we design a Saturated Mask AutoEncoder (SMAE) to learn a robust feature representation and reconstruct a non-saturated HDR image. We also propose an adaptive pseudo-label selection strategy to pick high-quality HDR pseudo-labels in the second stage to avoid the effect of mislabeled samples. Experiments demonstrate that SSHDR outperforms state-of-the-art methods quantitatively and qualitatively within and across different datasets, achieving appealing HDR visualization with few labeled samples.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.06914v1","tag":"data-quality"}}
{"title":"Machine Perception-Driven Image Compression: A Layered Generative Approach","abstract":"In this age of information, images are a critical medium for storing and transmitting information. With the rapid growth of image data amount, visual compression and visual data perception are two important research topics attracting a lot attention. However, those two topics are rarely discussed together and follow separate research path. Due to the compact compressed domain representation offered by learning-based image compression methods, there exists possibility to have one stream targeting both efficient data storage and compression, and machine perception tasks. In this paper, we propose a layered generative image compression model achieving high human vision-oriented image reconstructed quality, even at extreme compression ratios. To obtain analysis efficiency and flexibility, a task-agnostic learning-based compression model is proposed, which effectively supports various compressed domain-based analytical tasks while reserves outstanding reconstructed perceptual quality, compared with traditional and learning-based codecs. In addition, joint optimization schedule is adopted to acquire best balance point among compression ratio, reconstructed image quality, and downstream perception performance. Experimental results verify that our proposed compressed domain-based multi-task analysis method can achieve comparable analysis results against the RGB image-based methods with up to 99.6% bit rate saving (i.e., compared with taking original RGB image as the analysis model input). The practical ability of our model is further justified from model size and information fidelity aspects.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.06896v1","tag":"data-quality"}}
{"title":"PIE: Personalized Interest Exploration for Large-Scale Recommender Systems","abstract":"Recommender systems are increasingly successful in recommending personalized content to users. However, these systems often capitalize on popular content. There is also a continuous evolution of user interests that need to be captured, but there is no direct way to systematically explore users' interests. This also tends to affect the overall quality of the recommendation pipeline as training data is generated from the candidates presented to the user. In this paper, we present a framework for exploration in large-scale recommender systems to address these challenges. It consists of three parts, first the user-creator exploration which focuses on identifying the best creators that users are interested in, second the online exploration framework and third a feed composition mechanism that balances explore and exploit to ensure optimal prevalence of exploratory videos. Our methodology can be easily integrated into an existing large-scale recommender system with minimal modifications. We also analyze the value of exploration by defining relevant metrics around user-creator connections and understanding how this helps the overall recommendation pipeline with strong online gains in creator and ecosystem value. In contrast to the regression on user engagement metrics generally seen while exploring, our method is able to achieve significant improvements of 3.50% in strong creator connections and 0.85% increase in novel creator connections. Moreover, our work has been deployed in production on Facebook Watch, a popular video discovery and sharing platform serving billions of users.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06844v1","tag":"data-quality"}}
{"title":"Revisiting multiwavelength data on the supersoft X-ray source CAL 83","abstract":"In this study we revisit public data on the supersoft X-ray source CAL 83 in the Large Magellanic Cloud. A significant part of our analysis is focused on XMM-Newton X-ray observations, in which updated data reduction procedures and quality assessment were applied. We report on the capability of publicly available hot atmosphere models in describing the source's soft X-ray spectrum. By gathering historical flux measurements in multiple wavelengths and comparing them with the fluxes derived from the X-ray analysis, we find that a $\\sim$ 360 kK phenomenological blackbody model describes the spectral energy distribution of CAL 83 fairly well. We also retrieve data from the XMM-Newton UV/optical camera, which is co-alligned with the X-ray instruments and provides strictly simultaneous measurements. These observations demonstrate that the X-ray emission is definitely anti-correlated with emission at longer wavelengths in a time-scale of days to weeks. A closer look at simultaneous X-ray and UV count rates in single light curves reveals that the anti-correlated behaviour is actually present in time scales as short as minutes, suggesting that the origin of variable emission in the system is not unique.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06804v1","tag":"data-quality"}}
{"title":"RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment","abstract":"Generative foundation models are susceptible to implicit biases that can arise from extensive unsupervised training data. Such biases can produce suboptimal samples, skewed outcomes, and unfairness, with potentially significant repercussions. Consequently, aligning these models with human ethics and preferences is an essential step toward ensuring their responsible and effective deployment in real-world applications. Prior research has primarily employed Reinforcement Learning from Human Feedback (RLHF) as a means of addressing this problem, wherein generative models are fine-tuned using RL algorithms guided by a human-feedback-informed reward model. However, the inefficiencies and instabilities associated with RL algorithms frequently present substantial obstacles to the successful alignment of generative models, necessitating the development of a more robust and streamlined approach. To this end, we introduce a new framework, Reward rAnked FineTuning (RAFT), designed to align generative models more effectively. Utilizing a reward model and a sufficient number of samples, our approach selects the high-quality samples, discarding those that exhibit undesired behavior, and subsequently assembles a streaming dataset. This dataset serves as the basis for aligning the generative model and can be employed under both offline and online settings. Notably, the sample generation process within RAFT is gradient-free, rendering it compatible with black-box generators. Through extensive experiments, we demonstrate that our proposed algorithm exhibits strong performance in the context of both large language models and diffusion models.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06767v1","tag":"data-quality"}}
{"title":"A catalogue of cataclysmic variables from 20 years of the Sloan Digital Sky Survey with new classifications, periods, trends and oddities","abstract":"We present a catalogue of 507 cataclysmic variables (CVs) observed in SDSS I to IV including 70 new classifications collated from multiple archival data sets. This represents the largest sample of CVs with high-quality and homogeneous optical spectroscopy. We have used this sample to derive unbiased space densities and period distributions for the major sub-types of CVs. We also report on some peculiar CVs, period bouncers and also CVs exhibiting large changes in accretion rates. We report 70 new CVs, 59 new periods, 178 unpublished spectra and 262 new or updated classifications. From the SDSS spectroscopy, we also identified 18 systems incorrectly identified as CVs in the literature. We discuss the observed properties of 13 peculiar CVS, and we identify a small set of eight CVs that defy the standard classification scheme. We use this sample to investigate the distribution of different CV sub-types, and we estimate their individual space densities, as well as that of the entire CV population. The SDSS I to IV sample includes 14 period bounce CVs or candidates. We discuss the variability of CVs across the Hertzsprung-Russell diagram, highlighting selection biases of variability-based CV detection. Finally, we searched for, and found eight tertiary companions to the SDSS CVs. We anticipate that this catalogue and the extensive material included in the Supplementary Data will be useful for a range of observational population studies of CVs.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06749v1","tag":"data-quality"}}
{"title":"Improving novelty detection with generative adversarial networks on hand gesture data","abstract":"We propose a novel way of solving the issue of classification of out-of-vocabulary gestures using Artificial Neural Networks (ANNs) trained in the Generative Adversarial Network (GAN) framework. A generative model augments the data set in an online fashion with new samples and stochastic target vectors, while a discriminative model determines the class of the samples. The approach was evaluated on the UC2017 SG and UC2018 DualMyo data sets. The generative models performance was measured with a distance metric between generated and real samples. The discriminative models were evaluated by their accuracy on trained and novel classes. In terms of sample generation quality, the GAN is significantly better than a random distribution (noise) in mean distance, for all classes. In the classification tests, the baseline neural network was not capable of identifying untrained gestures. When the proposed methodology was implemented, we found that there is a trade-off between the detection of trained and untrained gestures, with some trained samples being mistaken as novelty. Nevertheless, a novelty detection accuracy of 95.4% or 90.2% (depending on the data set) was achieved with just 5% loss of accuracy on trained classes.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06696v1","tag":"data-quality"}}
{"title":"RadarGNN: Transformation Invariant Graph Neural Network for Radar-based Perception","abstract":"A reliable perception has to be robust against challenging environmental conditions. Therefore, recent efforts focused on the use of radar sensors in addition to camera and lidar sensors for perception applications. However, the sparsity of radar point clouds and the poor data availability remain challenging for current perception methods. To address these challenges, a novel graph neural network is proposed that does not just use the information of the points themselves but also the relationships between the points. The model is designed to consider both point features and point-pair features, embedded in the edges of the graph. Furthermore, a general approach for achieving transformation invariance is proposed which is robust against unseen scenarios and also counteracts the limited data availability. The transformation invariance is achieved by an invariant data representation rather than an invariant model architecture, making it applicable to other methods. The proposed RadarGNN model outperforms all previous methods on the RadarScenes dataset. In addition, the effects of different invariances on the object detection and semantic segmentation quality are investigated. The code is made available as open-source software under https://github.com/TUMFTM/RadarGNN.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06547v1","tag":"data-quality"}}
{"title":"Load Balanced Demand Distribution under Overload Penalties","abstract":"Input to the Load Balanced Demand Distribution (LBDD) consists of the following: (a) a set of public service centers (e.g., schools); (b) a set of demand (people) units and; (c) a cost matrix containing the cost of assignment for all demand unit-service center pairs. In addition, each service center is also associated with a notion of capacity and a penalty which is incurred if it gets overloaded. Given the input, the LBDD problem determines a mapping from the set of demand units to the set of service centers. The objective is to determine a mapping that minimizes the sum of the following two terms: (i) the total assignment cost between demand units and their allotted service centers and, (ii) total of penalties incurred. The problem of LBDD finds its application in the domain of urban planning. An instance of the LBDD problem can be reduced to an instance of the min-cost bi-partite matching problem. However, this approach cannot scale up to the real world large problem instances. The current state of the art related to LBDD makes simplifying assumptions such as infinite capacity or total capacity being equal to the total demand. This paper proposes a novel allotment subspace re-adjustment based approach (ASRAL) for the LBDD problem. We analyze ASRAL theoretically and present its asymptotic time complexity. We also evaluate ASRAL experimentally on large problem instances and compare with alternative approaches. Our results indicate that ASRAL is able to scale-up while maintaining significantly better solution quality over the alternative approaches. In addition, we also extend ASRAL to para-ASRAL which uses the GPU and CPU cores to speed-up the execution while maintaining the same solution quality as ASRAL.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06543v1","tag":"data-quality"}}
{"title":"Meta-Auxiliary Learning for Adaptive Human Pose Prediction","abstract":"Predicting high-fidelity future human poses, from a historically observed sequence, is decisive for intelligent robots to interact with humans. Deep end-to-end learning approaches, which typically train a generic pre-trained model on external datasets and then directly apply it to all test samples, emerge as the dominant solution to solve this issue. Despite encouraging progress, they remain non-optimal, as the unique properties (e.g., motion style, rhythm) of a specific sequence cannot be adapted. More generally, at test-time, once encountering unseen motion categories (out-of-distribution), the predicted poses tend to be unreliable. Motivated by this observation, we propose a novel test-time adaptation framework that leverages two self-supervised auxiliary tasks to help the primary forecasting network adapt to the test sequence. In the testing phase, our model can adjust the model parameters by several gradient updates to improve the generation quality. However, due to catastrophic forgetting, both auxiliary tasks typically tend to the low ability to automatically present the desired positive incentives for the final prediction performance. For this reason, we also propose a meta-auxiliary learning scheme for better adaptation. In terms of general setup, our approach obtains higher accuracy, and under two new experimental designs for out-of-distribution data (unseen subjects and categories), achieves significant improvements.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06411v1","tag":"data-quality"}}
{"title":"Leveraging triplet loss for unsupervised action segmentation","abstract":"In this paper, we propose a novel fully unsupervised framework that learns action representations suitable for the action segmentation task from the single input video itself, without requiring any training data. Our method is a deep metric learning approach rooted in a shallow network with a triplet loss operating on similarity distributions and a novel triplet selection strategy that effectively models temporal and semantic priors to discover actions in the new representational space. Under these circumstances, we successfully recover temporal boundaries in the learned action representations with higher quality compared with existing unsupervised approaches. The proposed method is evaluated on two widely used benchmark datasets for the action segmentation task and it achieves competitive performance by applying a generic clustering algorithm on the learned representations.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06403v1","tag":"data-quality"}}
{"title":"Sequential Monte Carlo applied to virtual flow meter calibration","abstract":"Soft-sensors are gaining popularity due to their ability to provide estimates of key process variables with little intervention required on the asset and at a low cost. In oil and gas production, virtual flow metering (VFM) is a popular soft-sensor that attempts to estimate multiphase flow rates in real time. VFMs are based on models, and these models require calibration. The calibration is highly dependent on the application, both due to the great diversity of the models, and in the available measurements. The most accurate calibration is achieved by careful tuning of the VFM parameters to well tests, but this can be work intensive, and not all wells have frequent well test data available. This paper presents a calibration method based on the measurement provided by the production separator, and the assumption that the observed flow should be equal to the sum of flow rates from each individual well. This allows us to jointly calibrate the VFMs continuously. The method applies Sequential Monte Carlo (SMC) to infer a tuning factor and the flow composition for each well. The method is tested on a case with ten wells, using both synthetic and real data. The results are promising and the method is able to provide reasonable estimates of the parameters without relying on well tests. However, some challenges are identified and discussed, particularly related to the process noise and how to manage varying data quality.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06310v1","tag":"data-quality"}}
{"title":"Language Instructed Reinforcement Learning for Human-AI Coordination","abstract":"One of the fundamental quests of AI is to produce agents that coordinate well with humans. This problem is challenging, especially in domains that lack high quality human behavioral data, because multi-agent reinforcement learning (RL) often converges to different equilibria from the ones that humans prefer. We propose a novel framework, instructRL, that enables humans to specify what kind of strategies they expect from their AI partners through natural language instructions. We use pretrained large language models to generate a prior policy conditioned on the human instruction and use the prior to regularize the RL objective. This leads to the RL agent converging to equilibria that are aligned with human preferences. We show that instructRL converges to human-like policies that satisfy the given instructions in a proof-of-concept environment as well as the challenging Hanabi benchmark. Finally, we show that knowing the language instruction significantly boosts human-AI coordination performance in human evaluations in Hanabi.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.07297v1","tag":"data-quality"}}
{"title":"Bus Ridership Prediction with Time Section, Weather, and Ridership Trend Aware Multiple LSTM","abstract":"Public transportation has been essential in people's lives in recent years. Bus ridership is a factor in people's choice to board the bus. Therefore, from the perspective of improving service quality, it is important to inform passengers who have not boarded the bus yet about future bus ridership. However, there is a concern that providing inaccurate information may cause a negative experience. Against this backdrop, there is a need to provide bus passengers who have not boarded yet with highly accurate predictions. Many researchers are working on studies on this. However, two issues summarize related studies. The first is that the correlation of bus ridership between consecutive bus stops should be considered for the prediction. The second is that the prediction has yet to be made using all of the features shown to be useful in each related study. This study proposes a prediction method that addresses both of these issues. We solve the first issue by designing an LSTM-based architecture for each bus stop and a single model for the entire bus stop. We solve the second issue by inputting all useful data, the past bus ridership, day of the week, time section, weather, and precipitation, as features. Bus ridership at each bus stop collected from buses operated by Minato Kanko Bus Inc, in Kobe city, Hyogo, Japan, from October 1, 2021, to September 30, 2022, were used to compare accuracy. The proposed method improved RMSE by 23% on average and up to 27% compared to existing methods.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.08233v1","tag":"data-quality"}}
{"title":"PALF: Pre-Annotation and Camera-LiDAR Late Fusion for the Easy Annotation of Point Clouds","abstract":"3D object detection has become indispensable in the field of autonomous driving. To date, gratifying breakthroughs have been recorded in 3D object detection research, attributed to deep learning. However, deep learning algorithms are data-driven and require large amounts of annotated point cloud data for training and evaluation. Unlike 2D image labels, annotating point cloud data is difficult due to the limitations of sparsity, irregularity, and low resolution, which requires more manual work, and the annotation efficiency is much lower than 2D image.Therefore, we propose an annotation algorithm for point cloud data, which is pre-annotation and camera-LiDAR late fusion algorithm to easily and accurately annotate. The contributions of this study are as follows. We propose (1) a pre-annotation algorithm that employs 3D object detection and auto fitting for the easy annotation of point clouds, (2) a camera-LiDAR late fusion algorithm using 2D and 3D results for easily error checking, which helps annotators easily identify missing objects, and (3) a point cloud annotation evaluation pipeline to evaluate our experiments. The experimental results show that the proposed algorithm improves the annotating speed by 6.5 times and the annotation quality in terms of the 3D Intersection over Union and precision by 8.2 points and 5.6 points, respectively; additionally, the miss rate is reduced by 31.9 points.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.08591v1","tag":"data-quality"}}
{"title":"Dynamic Voxel Grid Optimization for High-Fidelity RGB-D Supervised Surface Reconstruction","abstract":"Direct optimization of interpolated features on multi-resolution voxel grids has emerged as a more efficient alternative to MLP-like modules. However, this approach is constrained by higher memory expenses and limited representation capabilities. In this paper, we introduce a novel dynamic grid optimization method for high-fidelity 3D surface reconstruction that incorporates both RGB and depth observations. Rather than treating each voxel equally, we optimize the process by dynamically modifying the grid and assigning more finer-scale voxels to regions with higher complexity, allowing us to capture more intricate details. Furthermore, we develop a scheme to quantify the dynamic subdivision of voxel grid during optimization without requiring any priors. The proposed approach is able to generate high-quality 3D reconstructions with fine details on both synthetic and real-world data, while maintaining computational efficiency, which is substantially faster than the baseline method NeuralRGBD.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.06178v1","tag":"data-quality"}}
{"title":"Post-selection Inference for Conformal Prediction: Trading off Coverage for Precision","abstract":"Conformal inference has played a pivotal role in providing uncertainty quantification for black-box ML prediction algorithms with finite sample guarantees. Traditionally, conformal prediction inference requires a data-independent specification of miscoverage level. In practical applications, one might want to update the miscoverage level after computing the prediction set. For example, in the context of binary classification, the analyst might start with a $95\\%$ prediction sets and see that most prediction sets contain all outcome classes. Prediction sets with both classes being undesirable, the analyst might desire to consider, say $80\\%$ prediction set. Construction of prediction sets that guarantee coverage with data-dependent miscoverage level can be considered as a post-selection inference problem. In this work, we develop uniform conformal inference with finite sample prediction guarantee with arbitrary data-dependent miscoverage levels using distribution-free confidence bands for distribution functions. This allows practitioners to trade freely coverage probability for the quality of the prediction set by any criterion of their choice (say size of prediction set) while maintaining the finite sample guarantees similar to traditional conformal inference.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.06158v2","tag":"data-quality"}}
{"title":"AutoShot: A Short Video Dataset and State-of-the-Art Shot Boundary Detection","abstract":"The short-form videos have explosive popularity and have dominated the new social media trends. Prevailing short-video platforms,~\\textit{e.g.}, Kuaishou (Kwai), TikTok, Instagram Reels, and YouTube Shorts, have changed the way we consume and create content. For video content creation and understanding, the shot boundary detection (SBD) is one of the most essential components in various scenarios. In this work, we release a new public Short video sHot bOundary deTection dataset, named SHOT, consisting of 853 complete short videos and 11,606 shot annotations, with 2,716 high quality shot boundary annotations in 200 test videos. Leveraging this new data wealth, we propose to optimize the model design for video SBD, by conducting neural architecture search in a search space encapsulating various advanced 3D ConvNets and Transformers. Our proposed approach, named AutoShot, achieves higher F1 scores than previous state-of-the-art approaches, e.g., outperforming TransNetV2 by 4.2%, when being derived and evaluated on our newly constructed SHOT dataset. Moreover, to validate the generalizability of the AutoShot architecture, we directly evaluate it on another three public datasets: ClipShots, BBC and RAI, and the F1 scores of AutoShot outperform previous state-of-the-art approaches by 1.1%, 0.9% and 1.2%, respectively. The SHOT dataset and code can be found in https://github.com/wentaozhu/AutoShot.git .","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.06116v1","tag":"data-quality"}}
{"title":"UM 462, a local Green Pea galaxy analog under the MUSE magnifying glass","abstract":"[ABRIDGED] Stellar feedback in high-redshift galaxies plays an important role in the re-ionization epoch of the Universe. Green Pea galaxies (GPs) postulate as favorite local laboratories. However, at their typical redshift of $z\\sim0.2$, the most intimate interaction between stars and surrounding ISM cannot be disentangled. Detailed studies of Blue Compact Dwarf galaxies (BCDs) are necessary to anchor our investigations on them. We present here a study in detail UM 462, a BCD with similar properties to GPs uisng high quality optical IFS data with MUSE. Total oxygen abundance by means of the direct method is 12+$\\log$(O/H)$\\sim$8.02 and homogenous all over the galaxy, in stark contrast with the metallicities derived from several strong line methods. The velocity field for the ionised gas presents a velocity stratification in the area towards the north with redder velocities in the high ionisation lines and bluer velocities in the low ionisation lines. This is the only area with velocity dispersions clearly above the MUSE instrumental width, and it is surrounded by two $\\sim$1 kpc-long structures nicknamed \\emph{the horns}. We interpret the observational evidence in that area as a fragmented super-bubble fruit of the stellar feedback and it may constitute a preferred channel for LyC photons from the youngest generation of stars to escape. The most recent SF seems to propagate from the outer to the inner parts of the galaxy, and then from east to west. We identified a supernova remnant and Wolf-Rayet stars - as traced by the red bump - that support this picture. The direction of the propagation implies the presence of younger Wolf-Rayet stars at the maximum in H$\\alpha$. The ensemble of results exemplifies the potential of 2D detailed spectroscopic studies of dwarf star-forming galaxies at high spatial resolution as key reference for similar studies on primeval galaxies.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.06096v2","tag":"data-quality"}}
{"title":"Thermal Models of Asteroids with Two-band Combinations of Wide-field Infrared Survey Explorer Cryogenic Data","abstract":"We used the reparameterized Near-Earth Asteroid Thermal Model to model observations of a curated set of over 4000 asteroids from the Wide-field Infrared Survey Explorer in two wavelength bands (W2-3 or W3-4) and compared the results to previous results from all four wavelength bands (W1-4). This comparison was done with the goal of elucidating unique aspects of modeling two-band observations so that any potential biases or shortcomings for planned two-band surveys (e.g., the NASA Near-Earth Object Surveyor Mission) can be anticipated and quantified. The W2-3 two-band fits usually yielded slightly smaller diameters than the four-band fits, with a median diameter difference of -10%, with the 5% and 95% quantiles of the distribution at -32% and -1.5%, respectively. We conducted similar comparisons for W3-4, in part because the longest wavelength bands are expected to provide the best two-band results. We found that the W3-4 two-band diameters are slightly larger than the four-band results, with a median diameter difference of 11% and the 5% and 95% quantiles of the distribution at -2.1% and 26%, respectively. The diameter uncertainty, obtained with bootstrap analysis, is larger by 30% and 35% (median values) for the W2-3 and W3-4 fits, respectively, than for the corresponding four-band fits. Using 23 high-quality stellar occultation diameters as a benchmark, we found that the median errors of W2-3 and W3-4 diameter estimates are -15% and +12%, respectively, whereas the median error of the four-band fits is 9.3%. Although the W2-3 and W3-4 diameters appear to have greater systematic errors and uncertainties than their four-band counterparts, two-band estimates remain useful because they improve upon diameter estimates obtained from visible photometry alone.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.06085v1","tag":"data-quality"}}
{"title":"Continual Diffusion: Continual Customization of Text-to-Image Diffusion with C-LoRA","abstract":"Recent works demonstrate a remarkable ability to customize text-to-image diffusion models while only providing a few example images. What happens if you try to customize such models using multiple, fine-grained concepts in a sequential (i.e., continual) manner? In our work, we show that recent state-of-the-art customization of text-to-image models suffer from catastrophic forgetting when new concepts arrive sequentially. Specifically, when adding a new concept, the ability to generate high quality images of past, similar concepts degrade. To circumvent this forgetting, we propose a new method, C-LoRA, composed of a continually self-regularized low-rank adaptation in cross attention layers of the popular Stable Diffusion model. Furthermore, we use customization prompts which do not include the word of the customized object (i.e., \"person\" for a human face dataset) and are initialized as completely random embeddings. Importantly, our method induces only marginal additional parameter costs and requires no storage of user data for replay. We show that C-LoRA not only outperforms several baselines for our proposed setting of text-to-image continual customization, which we refer to as Continual Diffusion, but that we achieve a new state-of-the-art in the well-established rehearsal-free continual learning setting for image classification. The high achieving performance of C-LoRA in two separate domains positions it as a compelling solution for a wide range of applications, and we believe it has significant potential for practical impact.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.06027v1","tag":"data-quality"}}
{"title":"Generating Aligned Pseudo-Supervision from Non-Aligned Data for Image Restoration in Under-Display Camera","abstract":"Due to the difficulty in collecting large-scale and perfectly aligned paired training data for Under-Display Camera (UDC) image restoration, previous methods resort to monitor-based image systems or simulation-based methods, sacrificing the realness of the data and introducing domain gaps. In this work, we revisit the classic stereo setup for training data collection -- capturing two images of the same scene with one UDC and one standard camera. The key idea is to \"copy\" details from a high-quality reference image and \"paste\" them on the UDC image. While being able to generate real training pairs, this setting is susceptible to spatial misalignment due to perspective and depth of field changes. The problem is further compounded by the large domain discrepancy between the UDC and normal images, which is unique to UDC restoration. In this paper, we mitigate the non-trivial domain discrepancy and spatial misalignment through a novel Transformer-based framework that generates well-aligned yet high-quality target data for the corresponding UDC input. This is made possible through two carefully designed components, namely, the Domain Alignment Module (DAM) and Geometric Alignment Module (GAM), which encourage robust and accurate discovery of correspondence between the UDC and normal views. Extensive experiments show that high-quality and well-aligned pseudo UDC training pairs are beneficial for training a robust restoration network. Code and the dataset are available at https://github.com/jnjaby/AlignFormer.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.06019v1","tag":"data-quality"}}
{"title":"Regularizing Contrastive Predictive Coding for Speech Applications","abstract":"Self-supervised methods such as Contrastive predictive Coding (CPC) have greatly improved the quality of the unsupervised representations. These representations significantly reduce the amount of labeled data needed for downstream task performance, such as automatic speech recognition. CPC learns representations by learning to predict future frames given current frames. Based on the observation that the acoustic information, e.g., phones, changes slower than the feature extraction rate in CPC, we propose regularization techniques that impose slowness constraints on the features. Here we propose two regularization techniques: Self-expressing constraint and Left-or-right regularization. We evaluate the proposed model on ABX and linear phone classification tasks, acoustic unit discovery, and automatic speech recognition. The regularized CPC trained on 100 hours of unlabeled data matches the performance of the baseline CPC trained on 360 hours of unlabeled data. We also show that our regularization techniques are complementary to data augmentation and can further boost the system's performance. In monolingual, cross-lingual, or multilingual settings, with/without data augmentation, regardless of the amount of data used for training, our regularized models outperformed the baseline CPC models.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05974v1","tag":"data-quality"}}
{"title":"Angler: Helping Machine Translation Practitioners Prioritize Model Improvements","abstract":"Machine learning (ML) models can fail in unexpected ways in the real world, but not all model failures are equal. With finite time and resources, ML practitioners are forced to prioritize their model debugging and improvement efforts. Through interviews with 13 ML practitioners at Apple, we found that practitioners construct small targeted test sets to estimate an error's nature, scope, and impact on users. We built on this insight in a case study with machine translation models, and developed Angler, an interactive visual analytics tool to help practitioners prioritize model improvements. In a user study with 7 machine translation experts, we used Angler to understand prioritization practices when the input space is infinite, and obtaining reliable signals of model quality is expensive. Our study revealed that participants could form more interesting and user-focused hypotheses for prioritization by analyzing quantitative summary statistics and qualitatively assessing data by reading sentences.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05967v1","tag":"data-quality"}}
{"title":"A Phoneme-Informed Neural Network Model for Note-Level Singing Transcription","abstract":"Note-level automatic music transcription is one of the most representative music information retrieval (MIR) tasks and has been studied for various instruments to understand music. However, due to the lack of high-quality labeled data, transcription of many instruments is still a challenging task. In particular, in the case of singing, it is difficult to find accurate notes due to its expressiveness in pitch, timbre, and dynamics. In this paper, we propose a method of finding note onsets of singing voice more accurately by leveraging the linguistic characteristics of singing, which are not seen in other instruments. The proposed model uses mel-scaled spectrogram and phonetic posteriorgram (PPG), a frame-wise likelihood of phoneme, as an input of the onset detection network while PPG is generated by the pre-trained network with singing and speech data. To verify how linguistic features affect onset detection, we compare the evaluation results through the dataset with different languages and divide onset types for detailed analysis. Our approach substantially improves the performance of singing transcription and therefore emphasizes the importance of linguistic features in singing analysis.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05917v1","tag":"data-quality"}}
{"title":"How do physics students evaluate ChatGPT responses on comprehension questions? A study on the perceived scientific accuracy and linguistic quality","abstract":"This study aimed at evaluating how students perceive the linguistic quality and scientific accuracy of ChatGPT responses to physics comprehension questions. A total of 102 first- and second-year physics students were confronted with three questions of progressing affordance from introductory mechanics (rolling motion, waves, and fluid dynamics). Each question was presented with four different responses. All responses were attributed to ChatGPT, but in reality one sample solution was created by the researchers. All ChatGPT responses were wrong, imprecise, incomplete, or misleading. We found little differences in the perceived linguistic quality between ChatGPT responses and the sample solution. However, the students rated the overall scientific accuracy of the responses significantly differently, with the sample solution being rated best for the questions of low and medium affordance. The discrepancy between the sample solution and the ChatGPT responses increased with the level of self-assessed knowledge of the question content. For the question of highest affordance (fluid dynamics) that was unknown to most students, a ChatGPT response was rated just as good as the sample solution. Thus, this study provides data on the students' perception of ChatGPT responses and the factors influencing their perception. The results highlight the need for careful evaluation of ChatGPT responses both by instructors and students, particularly regarding scientific accuracy. Therefore, future research could explore the potential of similar \"spot the bot\"-activities in physics education to foster students' critical thinking skills.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05906v1","tag":"data-quality"}}
{"title":"FetMRQC: Automated Quality Control for fetal brain MRI","abstract":"Quality control (QC) has long been considered essential to guarantee the reliability of neuroimaging studies. It is particularly important for fetal brain MRI, where large and unpredictable fetal motion can lead to substantial artifacts in the acquired images. Existing methods for fetal brain quality assessment operate at the \\textit{slice} level, and fail to get a comprehensive picture of the quality of an image, that can only be achieved by looking at the \\textit{entire} brain volume. In this work, we propose FetMRQC, a machine learning framework for automated image quality assessment tailored to fetal brain MRI, which extracts an ensemble of quality metrics that are then used to predict experts' ratings. Based on the manual ratings of more than 1000 low-resolution stacks acquired across two different institutions, we show that, compared with existing quality metrics, FetMRQC is able to generalize out-of-domain, while being interpretable and data efficient. We also release a novel manual quality rating tool designed to facilitate and optimize quality rating of fetal brain images.   Our tool, along with all the code to generate, train and evaluate the model will be released upon acceptance of the paper.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05879v1","tag":"data-quality"}}
{"title":"Using Multiple RDF Knowledge Graphs for Enriching ChatGPT Responses","abstract":"There is a recent trend for using the novel Artificial Intelligence ChatGPT chatbox, which provides detailed responses and articulate answers across many domains of knowledge. However, in many cases it returns plausible-sounding but incorrect or inaccurate responses, whereas it does not provide evidence. Therefore, any user has to further search for checking the accuracy of the answer or/and for finding more information about the entities of the response. At the same time there is a high proliferation of RDF Knowledge Graphs (KGs) over any real domain, that offer high quality structured data. For enabling the combination of ChatGPT and RDF KGs, we present a research prototype, called GPToLODS, which is able to enrich any ChatGPT response with more information from hundreds of RDF KGs. In particular, it identifies and annotates each entity of the response with statistics and hyperlinks to LODsyndesis KG (which contains integrated data from 400 RDF KGs and over 412 million entities). In this way, it is feasible to enrich the content of entities and to perform fact checking and validation for the facts of the response at real time.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05774v1","tag":"data-quality"}}
{"title":"Discovery and optimization of cell-type-specific DNA methylation markers for in silico deconvolution","abstract":"DNA methylation is a significant driver of cell-type heterogeneity and has been implicated in various regulatory processes ranging from cell differentiation to imprinting. As the methyl group is embedded in the DNA molecule, assessing DNA methylation is particularly promising in liquid-biopsy-based approaches, as cell-free DNA retains information related to its cell of origin. In this work, I leverage a recently profiled collection of cell-sorted whole genome bisulfite profiles of 44 healthy cell types. The high quality and purity of such data provide an ideal basis for discovering and characterizing discriminative DNA methylation regions that could serve as a reference for computational deconvolution. First, I characterize differentially methylated regions between every pair of cell types, obtaining a meaningful measure of divergence. Pairwise differences were then aggregated to identify a set of uniquely (de)methylated regions (UMRs) for each cell type. Identified UMRs are predominantly hypomethylated and their numbers vary significantly across cell types. They are mostly located in enhancer regions and strongly support cell-type-specific characteristics. As mapping onto UMRs has proven unsuitable for deconvolution, I developed a novel approach utilizing the set cover algorithm to select discriminative regions for this purpose. Based on these regions, deconvolution was performed in two distinct approaches: a beta-value-based and a read-level one. Both approaches outperform an existing deconvolution software modeled on the same data 3-fold in terms of total deconvolution error. Surprisingly, the beta-based approach slightly outperformed the read-level one. Overall, I present an adaptable, end-to-end software solution (methylcover) for obtaining accurate cell type deconvolution, with possible future applications to non-invasive assays for disease detection and monitoring.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05756v1","tag":"data-quality"}}
{"title":"Self-Supervised Learning with Cluster-Aware-DINO for High-Performance Robust Speaker Verification","abstract":"Automatic speaker verification task has made great achievements using deep learning approaches with the large-scale manually annotated dataset. However, it's very difficult and expensive to collect a large amount of well-labeled data for system building. In this paper, we propose a novel and advanced self-supervised learning framework which can construct a high performance speaker verification system without using any labeled data. To avoid the impact of false negative pairs, we adopt the self-distillation with no labels (DINO) framework as the initial model, which can be trained without exploiting negative pairs. Then, we introduce a cluster-aware training strategy for DINO to improve the diversity of data. In the iteration learning stage, due to a mass of unreliable labels from clustering, the quality of pseudo labels is important for the system training. This motivates us to propose dynamic loss-gate and label correction (DLG-LC) methods to alleviate the performance degradation caused by unreliable labels. More specifically, we model the loss distribution with GMM and obtain the loss-gate threshold dynamically to distinguish the reliable and unreliable labels. Besides, we adopt the model predictions to correct the unreliable label, for better utilizing the unreliable data rather than dropping them directly. Moreover, we extend the DLG-LC to multi-modality to further improve the performance. The experiments are performed on the commonly used Voxceleb dataset. Compared to the best-known self-supervised speaker verification system, our proposed method obtain 22.17%, 27.94% and 25.56% relative EER improvement on Vox-O, Vox-E and Vox-H test sets, even with fewer iterations, smaller models, and simpler clustering methods. More importantly, the newly proposed system even achieves comparable results with the fully supervised system, but without using any human labeled data.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05754v1","tag":"data-quality"}}
{"title":"Multisensor fusion-based digital twin in additive manufacturing for in-situ quality monitoring and defect correction","abstract":"Early detection and correction of defects are critical in additive manufacturing (AM) to avoid build failures. In this paper, we present a multisensor fusion-based digital twin for in-situ quality monitoring and defect correction in a robotic laser direct energy deposition process. Multisensor fusion sources consist of an acoustic sensor, an infrared thermal camera, a coaxial vision camera, and a laser line scanner. The key novelty and contribution of this work are to develop a spatiotemporal data fusion method that synchronizes and registers the multisensor features within the part's 3D volume. The fused dataset can be used to predict location-specific quality using machine learning. On-the-fly identification of regions requiring material addition or removal is feasible. Robot toolpath and auto-tuned process parameters are generated for defecting correction. In contrast to traditional single-sensor-based monitoring, multisensor fusion allows for a more in-depth understanding of underlying process physics, such as pore formation and laser-material interactions. The proposed methods pave the way for self-adaptation AM with higher efficiency, less waste, and cleaner production.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05685v1","tag":"data-quality"}}
{"title":"Precise localization of corneal reflections in eye images using deep learning trained on synthetic data","abstract":"We present a deep learning method for accurately localizing the center of a single corneal reflection (CR) in an eye image. Unlike previous approaches, we use a convolutional neural network (CNN) that was trained solely using simulated data. Using only simulated data has the benefit of completely sidestepping the time-consuming process of manual annotation that is required for supervised training on real eye images. To systematically evaluate the accuracy of our method, we first tested it on images with simulated CRs placed on different backgrounds and embedded in varying levels of noise. Second, we tested the method on high-quality videos captured from real eyes. Our method outperformed state-of-the-art algorithmic methods on real eye images with a 35% reduction in terms of spatial precision, and performed on par with state-of-the-art on simulated images in terms of spatial accuracy.We conclude that our method provides a precise method for CR center localization and provides a solution to the data availability problem which is one of the important common roadblocks in the development of deep learning models for gaze estimation. Due to the superior CR center localization and ease of application, our method has the potential to improve the accuracy and precision of CR-based eye trackers","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05673v1","tag":"data-quality"}}
{"title":"Grant-free Massive Random Access with Retransmission: Receiver Optimization and Performance Analysis","abstract":"There is an increasing demand of massive machine-type communication (mMTC) to provide scalable access for a large number of devices, which has prompted extensive investigation on grant-free massive random access (RA) in 5G and beyond wireless networks. Although many efficient signal processing algorithms have been developed, the limited radio resource for pilot transmission in grant-free massive RA systems makes accurate user activity detection and channel estimation challenging, which thereby compromises the communication reliability. In this paper, we adopt retransmission as a means to improve the quality of service (QoS) for grant-free massive RA. Specifically, by jointly leveraging the user activity correlation between adjacent transmission blocks and the historical channel estimation results, we first develop an activity-correlation-aware receiver for grant-free massive RA systems with retransmission based on the correlated approximate message passing (AMP) algorithm. Then, we analyze the performance of the proposed receiver, including the user activity detection, channel estimation, and data error, by resorting to the state evolution of the correlated AMP algorithm and the random matrix theory (RMT). Our analysis admits a tight closed-form approximation for frame error rate (FER) evaluation. Simulation results corroborate our theoretical analysis and demonstrate the effectiveness of the proposed receiver for grant-free massive RA with retransmission, compared with a conventional design that disregards the critical user activity correlation.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05648v1","tag":"data-quality"}}
{"title":"NutritionVerse-Thin: An Optimized Strategy for Enabling Improved Rendering of 3D Thin Food Models","abstract":"With the growth in capabilities of generative models, there has been growing interest in using photo-realistic renders of common 3D food items to improve downstream tasks such as food printing, nutrition prediction, or management of food wastage. Despite 3D modelling capabilities being more accessible than ever due to the success of NeRF based view-synthesis, such rendering methods still struggle to correctly capture thin food objects, often generating meshes with significant holes. In this study, we present an optimized strategy for enabling improved rendering of thin 3D food models, and demonstrate qualitative improvements in rendering quality. Our method generates the 3D model mesh via a proposed thin-object-optimized differentiable reconstruction method and tailors the strategy at both the data collection and training stages to better handle thin objects. While simple, we find that this technique can be employed for quick and highly consistent capturing of thin 3D objects.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05620v1","tag":"data-quality"}}
{"title":"CAvity DEtection Tool (CADET): Pipeline for automatic detection of X-ray cavities in hot galactic and cluster atmospheres","abstract":"The study of jet-inflated X-ray cavities provides a powerful insight into the energetics of hot galactic atmospheres and radio-mechanical AGN feedback. By estimating the volumes of X-ray cavities, the total energy and thus also the corresponding mechanical jet power required for their inflation can be derived. Properly estimating their total extent is, however, non-trivial, prone to biases, nearly impossible for poor-quality data, and so far has been done manually by scientists. We present a novel and automated machine-learning pipeline called Cavity Detection Tool (CADET), developed to detect and estimate the sizes of X-ray cavities from raw Chandra images. The pipeline consists of a convolutional neural network trained for producing pixel-wise cavity predictions and a DBSCAN clustering algorithm, which decomposes the predictions into individual cavities. The convolutional network was trained using mock observations of early-type galaxies simulated to resemble real noisy Chandra-like images. The network's performance has been tested on simulated data obtaining an average cavity volume error of 14 % at an 89 % true-positive rate. For simulated images without any X-ray cavities inserted, we obtain a 5 % false-positive rate. When applied to real Chandra images, the pipeline recovered 91 out of 100 previously known X-ray cavities in nearby early-type galaxies and all 14 cavities in chosen galaxy clusters. Besides that, the CADET pipeline discovered 8 new cavity pairs in atmospheres of early-type galaxies and galaxy clusters (IC4765, NGC533, NGC2300, NGC3091, NGC4073, NGC4125, NGC4472, NGC5129) and a number of potential cavity candidates.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05457v1","tag":"data-quality"}}
{"title":"Collaborative Machine Learning Model Building with Families Using Co-ML","abstract":"Existing novice-friendly machine learning (ML) modeling tools center around a solo user experience, where a single user collects only their own data to build a model. However, solo modeling experiences limit valuable opportunities for encountering alternative ideas and approaches that can arise when learners work together; consequently, it often precludes encountering critical issues in ML around data representation and diversity that can surface when different perspectives are manifested in a group-constructed data set. To address this issue, we created Co-ML -- a tablet-based app for learners to collaboratively build ML image classifiers through an end-to-end, iterative model-building process. In this paper, we illustrate the feasibility and potential richness of collaborative modeling by presenting an in-depth case study of a family (two children 11 and 14-years-old working with their parents) using Co-ML in a facilitated introductory ML activity at home. We share the Co-ML system design and contribute a discussion of how using Co-ML in a collaborative activity enabled beginners to collectively engage with dataset design considerations underrepresented in prior work such as data diversity, class imbalance, and data quality. We discuss how a distributed collaborative process, in which individuals can take on different model-building responsibilities, provides a rich context for children and adults to learn ML dataset design.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05444v1","tag":"data-quality"}}
{"title":"Data-driven Distributionally Robust Optimization over Time","abstract":"Stochastic Optimization (SO) is a classical approach for optimization under uncertainty that typically requires knowledge about the probability distribution of uncertain parameters. As the latter is often unknown, Distributionally Robust Optimization (DRO) provides a strong alternative that determines the best guaranteed solution over a set of distributions (ambiguity set). In this work, we present an approach for DRO over time that uses online learning and scenario observations arriving as a data stream to learn more about the uncertainty. Our robust solutions adapt over time and reduce the cost of protection with shrinking ambiguity. For various kinds of ambiguity sets, the robust solutions converge to the SO solution. Our algorithm achieves the optimization and learning goals without solving the DRO problem exactly at any step. We also provide a regret bound for the quality of the online strategy which converges at a rate of $\\mathcal{O}(\\log T / \\sqrt{T})$, where $T$ is the number of iterations. Furthermore, we illustrate the effectiveness of our procedure by numerical experiments on mixed-integer optimization instances from popular benchmark libraries and give practical examples stemming from telecommunications and routing. Our algorithm is able to solve the DRO over time problem significantly faster than standard reformulations.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05377v1","tag":"data-quality"}}
{"title":"RRHF: Rank Responses to Align Language Models with Human Feedback without tears","abstract":"Reinforcement Learning from Human Feedback (RLHF) facilitates the alignment of large language models with human preferences, significantly enhancing the quality of interactions between humans and these models. InstructGPT implements RLHF through several stages, including Supervised Fine-Tuning (SFT), reward model training, and Proximal Policy Optimization (PPO). PPO, however, is sensitive to hyperparameters and requires a minimum of four models in its standard implementation, which makes it hard to train. In contrast, we propose a novel learning paradigm called RRHF, which scores responses generated by different sampling policies and learns to align them with human preferences through ranking loss. RRHF can efficiently align language model output probabilities with human preferences as robust as fine-tuning and it only needs 1 to 2 models during tuning. In addition, RRHF can be considered an extension of SFT and reward models while being simpler than PPO in terms of coding, model counts, and hyperparameters. The entire alignment process can be accomplished within a single RRHF training session. We evaluate RRHF using LLaMA and Alpaca on Helpful and Harmless data, demonstrating performance comparable to PPO.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05302v1","tag":"data-quality"}}
{"title":"Evaluating AIGC Detectors on Code Content","abstract":"Artificial Intelligence Generated Content (AIGC) has garnered considerable attention for its impressive performance, with ChatGPT emerging as a leading AIGC model that produces high-quality responses across various applications, including software development and maintenance. Despite its potential, the misuse of ChatGPT poses significant concerns, especially in education and safetycritical domains. Numerous AIGC detectors have been developed and evaluated on natural language data. However, their performance on code-related content generated by ChatGPT remains unexplored. To fill this gap, in this paper, we present the first empirical study on evaluating existing AIGC detectors in the software domain. We created a comprehensive dataset including 492.5K samples comprising code-related content produced by ChatGPT, encompassing popular software activities like Q&A (115K), code summarization (126K), and code generation (226.5K). We evaluated six AIGC detectors, including three commercial and three open-source solutions, assessing their performance on this dataset. Additionally, we conducted a human study to understand human detection capabilities and compare them with the existing AIGC detectors. Our results indicate that AIGC detectors demonstrate lower performance on code-related data compared to natural language data. Fine-tuning can enhance detector performance, especially for content within the same domain; but generalization remains a challenge. The human evaluation reveals that detection by humans is quite challenging.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05193v1","tag":"data-quality"}}
{"title":"From research activities to institutional piloting: the challenges of modernizing interfaces and data interoperability","abstract":"Research activities are generally observed and evaluated through the prism of their production and financial elements or team composition. In addition to standardized management indicators and bibliometrics, the French National Research Institute for Sustainable Development (IRD) has been building new indicators for the last ten years, based on the annual regulatory declarations of the Institute's researchers. Different quality management tools allow the evolution of the different interfaces. This source of data, more ''open'' and more ''useful'' through its integration into the Institute's information system, is adapted to the needs of the multi-year management of research at the IRD. The aim is twofold: (1) to make progress in the evaluation of research and in the mastery of information by all actors, (2) to enlighten as many actors as possible via more efficient digital circuits and tools. The purpose of this article is to explain how the IRD is changing the entire production chain and the indicators of researchers' activities to better map scientific activities.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05180v1","tag":"data-quality"}}
{"title":"Exploring and Exploiting Uncertainty for Incomplete Multi-View Classification","abstract":"Classifying incomplete multi-view data is inevitable since arbitrary view missing widely exists in real-world applications. Although great progress has been achieved, existing incomplete multi-view methods are still difficult to obtain a trustworthy prediction due to the relatively high uncertainty nature of missing views. First, the missing view is of high uncertainty, and thus it is not reasonable to provide a single deterministic imputation. Second, the quality of the imputed data itself is of high uncertainty. To explore and exploit the uncertainty, we propose an Uncertainty-induced Incomplete Multi-View Data Classification (UIMC) model to classify the incomplete multi-view data under a stable and reliable framework. We construct a distribution and sample multiple times to characterize the uncertainty of missing views, and adaptively utilize them according to the sampling quality. Accordingly, the proposed method realizes more perceivable imputation and controllable fusion. Specifically, we model each missing data with a distribution conditioning on the available views and thus introducing uncertainty. Then an evidence-based fusion strategy is employed to guarantee the trustworthy integration of the imputed views. Extensive experiments are conducted on multiple benchmark data sets and our method establishes a state-of-the-art performance in terms of both performance and trustworthiness.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05165v1","tag":"data-quality"}}
{"title":"NeAT: Neural Artistic Tracing for Beautiful Style Transfer","abstract":"Style transfer is the task of reproducing the semantic contents of a source image in the artistic style of a second target image. In this paper, we present NeAT, a new state-of-the art feed-forward style transfer method. We re-formulate feed-forward style transfer as image editing, rather than image generation, resulting in a model which improves over the state-of-the-art in both preserving the source content and matching the target style. An important component of our model's success is identifying and fixing \"style halos\", a commonly occurring artefact across many style transfer techniques. In addition to training and testing on standard datasets, we introduce the BBST-4M dataset, a new, large scale, high resolution dataset of 4M images. As a component of curating this data, we present a novel model able to classify if an image is stylistic. We use BBST-4M to improve and measure the generalization of NeAT across a huge variety of styles. Not only does NeAT offer state-of-the-art quality and generalization, it is designed and trained for fast inference at high resolution.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05139v1","tag":"data-quality"}}
{"title":"Cyber Physical Aquaponic System (CyPhA): a CPS Testbed","abstract":"Aquaponics system promises a sustainable urban development and food production by combining vegetable and fish farming in a single water loop. However, traditional aquaponics suffers from a significant amount of manual intervention with regard to decision-making in the water circulation and water quality control. In this work, we design, build and deploy a laboratory-scale real aquaponics system by considering this system as a cyber physical system, and we call it as Cyber Physical Aquaponics (CyPhA) system. The design of our CyPhA system has five stages, Stage-1 contains a vertical vegetable farming unit, Stage-2 contains fish farming unit, Stage-3 contains natural nitrification system, Stage-4 contains bio-filtration system and Stage-5 contains water accumulation and release system. Water transfer from one stage to the next is done using water pumps, and oxygen mixing in the water in any stage is achieved using aeration pumps. CyPhA system uses sensors for pH, dissolved oxygen (DO), total dissolved solid (TDS), water temperature, air temperature and humidity. A critical level of any of the water parameters in any stage is indicated using a LED-based alert indicator. Sensor data and actuator control commands among the stagewise edge devices and the CyPhA Controller are exchanged over Message Queue Telemetry Transport (MQTT) protocol. Overall, CyPhA system is housed within an area of about 80 sq. ft. We have been successfully operating CyPhA system for the last 75 days and maintaining a good quality of water for both fish and vegetable farming units.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05132v1","tag":"data-quality"}}
{"title":"Improving Performance of Private Federated Models in Medical Image Analysis","abstract":"Federated learning (FL) is a distributed machine learning (ML) approach that allows data to be trained without being centralized. This approach is particularly beneficial for medical applications because it addresses some key challenges associated with medical data, such as privacy, security, and data ownership. On top of that, FL can improve the quality of ML models used in medical applications. Medical data is often diverse and can vary significantly depending on the patient population, making it challenging to develop ML models that are accurate and generalizable. FL allows medical data to be used from multiple sources, which can help to improve the quality and generalizability of ML models. Differential privacy (DP) is a go-to algorithmic tool to make this process secure and private. In this work, we show that the model performance can be further improved by employing local steps, a popular approach to improving the communication efficiency of FL, and tuning the number of communication rounds. Concretely, given the privacy budget, we show an optimal number of local steps and communications rounds. We provide theoretical motivations further corroborated with experimental evaluations on real-world medical imaging tasks.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05127v1","tag":"data-quality"}}
{"title":"SPIRiT-Diffusion: Self-Consistency Driven Diffusion Model for Accelerated MRI","abstract":"Diffusion models are a leading method for image generation and have been successfully applied in magnetic resonance imaging (MRI) reconstruction. Current diffusion-based reconstruction methods rely on coil sensitivity maps (CSM) to reconstruct multi-coil data. However, it is difficult to accurately estimate CSMs in practice use, resulting in degradation of the reconstruction quality. To address this issue, we propose a self-consistency-driven diffusion model inspired by the iterative self-consistent parallel imaging (SPIRiT), namely SPIRiT-Diffusion. Specifically, the iterative solver of the self-consistent term in SPIRiT is utilized to design a novel stochastic differential equation (SDE) for diffusion process. Then $\\textit{k}$-space data can be interpolated directly during the reverse diffusion process, instead of using CSM to separate and combine individual coil images. This method indicates that the optimization model can be used to design SDE in diffusion models, driving the diffusion process strongly conforming with the physics involved in the optimization model, dubbed model-driven diffusion. The proposed SPIRiT-Diffusion method was evaluated on a 3D joint Intracranial and Carotid Vessel Wall imaging dataset. The results demonstrate that it outperforms the CSM-based reconstruction methods, and achieves high reconstruction quality at a high acceleration rate of 10.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05060v1","tag":"data-quality"}}
{"title":"Human-machine cooperation for semantic feature listing","abstract":"Semantic feature norms, lists of features that concepts do and do not possess, have played a central role in characterizing human conceptual knowledge, but require extensive human labor. Large language models (LLMs) offer a novel avenue for the automatic generation of such feature lists, but are prone to significant error. Here, we present a new method for combining a learned model of human lexical-semantics from limited data with LLM-generated data to efficiently generate high-quality feature norms.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05012v1","tag":"data-quality"}}
{"title":"Partitioner Selection with EASE to Optimize Distributed Graph Processing","abstract":"For distributed graph processing on massive graphs, a graph is partitioned into multiple equally-sized parts which are distributed among machines in a compute cluster. In the last decade, many partitioning algorithms have been developed which differ from each other with respect to the partitioning quality, the run-time of the partitioning and the type of graph for which they work best. The plethora of graph partitioning algorithms makes it a challenging task to select a partitioner for a given scenario. Different studies exist that provide qualitative insights into the characteristics of graph partitioning algorithms that support a selection. However, in order to enable automatic selection, a quantitative prediction of the partitioning quality, the partitioning run-time and the run-time of subsequent graph processing jobs is needed. In this paper, we propose a machine learning-based approach to provide such a quantitative prediction for different types of edge partitioning algorithms and graph processing workloads. We show that training based on generated graphs achieves high accuracy, which can be further improved when using real-world data. Based on the predictions, the automatic selection reduces the end-to-end run-time on average by 11.1% compared to a random selection, by 17.4% compared to selecting the partitioner that yields the lowest cut size, and by 29.1% compared to the worst strategy, respectively. Furthermore, in 35.7% of the cases, the best strategy was selected.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.04976v1","tag":"data-quality"}}
{"title":"Computer Vision-Aided Intelligent Monitoring of Coffee: Towards Sustainable Coffee Production","abstract":"Coffee which is prepared from the grinded roasted seeds of harvested coffee cherries, is one of the most consumed beverage and traded commodity, globally. To manually monitor the coffee field regularly, and inform about plant and soil health, as well as estimate yield and harvesting time, is labor-intensive, time-consuming and error-prone. Some recent studies have developed sensors for estimating coffee yield at the time of harvest, however a more inclusive and applicable technology to remotely monitor multiple parameters of the field and estimate coffee yield and quality even at pre-harvest stage, was missing. Following precision agriculture approach, we employed machine learning algorithm YOLO, for image processing of coffee plant. In this study, the latest version of the state-of-the-art algorithm YOLOv7 was trained with 324 annotated images followed by its evaluation with 82 unannotated images as test data. Next, as an innovative approach for annotating the training data, we trained K-means models which led to machine-generated color classes of coffee fruit and could thus characterize the informed objects in the image. Finally, we attempted to develop an AI-based handy mobile application which would not only efficiently predict harvest time, estimate coffee yield and quality, but also inform about plant health. Resultantly, the developed model efficiently analyzed the test data with a mean average precision of 0.89. Strikingly, our innovative semi-supervised method with an mean average precision of 0.77 for multi-class mode surpassed the supervised method with mean average precision of only 0.60, leading to faster and more accurate annotation. The mobile application we designed based on the developed code, was named CoffeApp, which possesses multiple features of analyzing fruit from the image taken by phone camera with in field and can thus track fruit ripening in real time.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.04966v1","tag":"data-quality"}}
{"title":"Data-Efficient Image Quality Assessment with Attention-Panel Decoder","abstract":"Blind Image Quality Assessment (BIQA) is a fundamental task in computer vision, which however remains unresolved due to the complex distortion conditions and diversified image contents. To confront this challenge, we in this paper propose a novel BIQA pipeline based on the Transformer architecture, which achieves an efficient quality-aware feature representation with much fewer data. More specifically, we consider the traditional fine-tuning in BIQA as an interpretation of the pre-trained model. In this way, we further introduce a Transformer decoder to refine the perceptual information of the CLS token from different perspectives. This enables our model to establish the quality-aware feature manifold efficiently while attaining a strong generalization capability. Meanwhile, inspired by the subjective evaluation behaviors of human, we introduce a novel attention panel mechanism, which improves the model performance and reduces the prediction uncertainty simultaneously. The proposed BIQA method maintains a lightweight design with only one layer of the decoder, yet extensive experiments on eight standard BIQA datasets (both synthetic and authentic) demonstrate its superior performance to the state-of-the-art BIQA methods, i.e., achieving the SRCC values of 0.875 (vs. 0.859 in LIVEC) and 0.980 (vs. 0.969 in LIVE).","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.04952v1","tag":"data-quality"}}
{"title":"Explicit and Implicit Semantic Ranking Framework","abstract":"The core challenge in numerous real-world applications is to match an inquiry to the best document from a mutable and finite set of candidates. Existing industry solutions, especially latency-constrained services, often rely on similarity algorithms that sacrifice quality for speed. In this paper we introduce a generic semantic learning-to-rank framework, Self-training Semantic Cross-attention Ranking (sRank). This transformer-based framework uses linear pairwise loss with mutable training batch sizes and achieves quality gains and high efficiency, and has been applied effectively to show gains on two industry tasks at Microsoft over real-world large-scale data sets: Smart Reply (SR) and Ambient Clinical Intelligence (ACI). In Smart Reply, $sRank$ assists live customers with technical support by selecting the best reply from predefined solutions based on consumer and support agent messages. It achieves 11.7% gain in offline top-one accuracy on the SR task over the previous system, and has enabled 38.7% time reduction in composing messages in telemetry recorded since its general release in January 2021. In the ACI task, sRank selects relevant historical physician templates that serve as guidance for a text summarization model to generate higher quality medical notes. It achieves 35.5% top-one accuracy gain, along with 46% relative ROUGE-L gain in generated medical notes.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.04918v1","tag":"data-quality"}}
{"title":"SNIPS: Succinct Proof of Storage for Efficient Data Synchronization in Decentralized Storage Systems","abstract":"Data synchronization in decentralized storage systems is essential to guarantee sufficient redundancy to prevent data loss. We present SNIPS, the first succinct proof of storage algorithm for synchronizing storage peers. A peer constructs a proof for its stored chunks and sends it to verifier peers. A verifier queries the proof to identify and subsequently requests missing chunks. The proof is succinct, supports membership queries, and requires only a few bits per chunk.   We evaluated our SNIPS algorithm on a cluster of 1000 peers running Ethereum Swarm. Our results show that SNIPS reduces the amount of synchronization data by three orders of magnitude compared to the state-of-the-art. Additionally, creating and verifying a proof is linear with the number of chunks and typically requires only tens of microseconds per chunk. These qualities are vital for our use case, as we envision running SNIPS frequently to maintain sufficient redundancy consistently.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04891v1","tag":"data-quality"}}
{"title":"A Cheaper and Better Diffusion Language Model with Soft-Masked Noise","abstract":"Diffusion models that are based on iterative denoising have been recently proposed and leveraged in various generation tasks like image generation. Whereas, as a way inherently built for continuous data, existing diffusion models still have some limitations in modeling discrete data, e.g., languages. For example, the generally used Gaussian noise can not handle the discrete corruption well, and the objectives in continuous spaces fail to be stable for textual data in the diffusion process especially when the dimension is high. To alleviate these issues, we introduce a novel diffusion model for language modeling, Masked-Diffuse LM, with lower training cost and better performances, inspired by linguistic features in languages. Specifically, we design a linguistic-informed forward process which adds corruptions to the text through strategically soft-masking to better noise the textual data. Also, we directly predict the categorical distribution with cross-entropy loss function in every diffusion step to connect the continuous space and discrete space in a more efficient and straightforward way. Through experiments on 5 controlled generation tasks, we demonstrate that our Masked-Diffuse LM can achieve better generation quality than the state-of-the-art diffusion models with better efficiency.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04746v1","tag":"data-quality"}}
{"title":"SAM vs BET: A Comparative Study for Brain Extraction and Segmentation of Magnetic Resonance Images using Deep Learning","abstract":"Brain extraction is a critical preprocessing step in neuroimaging studies, involving the separation of brain tissue from non-brain tissue using MRI data. FSL's Brain Extraction Tool (BET) is the current gold standard but is prone to errors due to image quality issues. The Segment Anything Model (SAM) by Meta AI has shown promising zero-shot segmentation potential. This paper compares SAM with BET for brain extraction on diverse brain scans, considering image quality, MRI sequences, and lesion locations. Results demonstrate that SAM outperforms BET in various evaluation parameters, particularly in cases with signal inhomogeneities, non-isotropic voxel resolutions, or lesions near the brain's outer regions and meninges. SAM's superior performance indicates its potential as a more accurate, robust, and versatile tool for brain extraction and segmentation applications.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04738v2","tag":"data-quality"}}
{"title":"Let's Stop Building at the Feet of Giants: Recovering unavailable Requirements Quality Artifacts","abstract":"Requirements quality literature abounds with publications presenting artifacts, such as data sets and tools. However, recent systematic studies show that more than 80% of these artifacts have become unavailable or were never made public, limiting reproducibility and reusability. In this work, we report on an attempt to recover those artifacts. To that end, we requested corresponding authors of unavailable artifacts to recover and disclose them according to open science principles. Our results, based on 19 answers from 35 authors (54% response rate), include an assessment of the availability of requirements quality artifacts and a breakdown of authors' reasons for their continued unavailability. Overall, we improved the availability of seven data sets and seven implementations.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04670v1","tag":"data-quality"}}
{"title":"SELFormer: Molecular Representation Learning via SELFIES Language Models","abstract":"Automated computational analysis of the vast chemical space is critical for numerous fields of research such as drug discovery and material science. Representation learning techniques have recently been employed with the primary objective of generating compact and informative numerical expressions of complex data. One approach to efficiently learn molecular representations is processing string-based notations of chemicals via natural language processing (NLP) algorithms. Majority of the methods proposed so far utilize SMILES notations for this purpose; however, SMILES is associated with numerous problems related to validity and robustness, which may prevent the model from effectively uncovering the knowledge hidden in the data. In this study, we propose SELFormer, a transformer architecture-based chemical language model that utilizes a 100% valid, compact and expressive notation, SELFIES, as input, in order to learn flexible and high-quality molecular representations. SELFormer is pre-trained on two million drug-like compounds and fine-tuned for diverse molecular property prediction tasks. Our performance evaluation has revealed that, SELFormer outperforms all competing methods, including graph learning-based approaches and SMILES-based chemical language models, on predicting aqueous solubility of molecules and adverse drug reactions. We also visualized molecular representations learned by SELFormer via dimensionality reduction, which indicated that even the pre-trained model can discriminate molecules with differing structural properties. We shared SELFormer as a programmatic tool, together with its datasets and pre-trained models. Overall, our research demonstrates the benefit of using the SELFIES notations in the context of chemical language modeling and opens up new possibilities for the design and discovery of novel drug candidates with desired features.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04662v1","tag":"data-quality"}}
{"title":"ECG-CL: A Comprehensive Electrocardiogram Interpretation Method Based on Continual Learning","abstract":"Electrocardiogram (ECG) monitoring is one of the most powerful technique of cardiovascular disease (CVD) early identification, and the introduction of intelligent wearable ECG devices has enabled daily monitoring. However, due to the need for professional expertise in the ECGs interpretation, general public access has once again been restricted, prompting the need for the development of advanced diagnostic algorithms. Classic rule-based algorithms are now completely outperformed by deep learning based methods. But the advancement of smart diagnostic algorithms is hampered by issues like small dataset, inconsistent data labeling, inefficient use of local and global ECG information, memory and inference time consuming deployment of multiple models, and lack of information transfer between tasks. We propose a multi-resolution model that can sustain high-resolution low-level semantic information throughout, with the help of the development of low-resolution high-level semantic information, by capitalizing on both local morphological information and global rhythm information. From the perspective of effective data leverage and inter-task knowledge transfer, we develop a parameter isolation based ECG continual learning (ECG-CL) approach. We evaluated our model's performance on four open-access datasets by designing segmentation-to-classification for cross-domain incremental learning, minority-to-majority class for category incremental learning, and small-to-large sample for task incremental learning. Our approach is shown to successfully extract informative morphological and rhythmic features from ECG segmentation, leading to higher quality classification results. From the perspective of intelligent wearable applications, the possibility of a comprehensive ECG interpretation algorithm based on single-lead ECGs is also confirmed.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04646v1","tag":"data-quality"}}
{"title":"Hyperspectral Image Super-Resolution via Dual-domain Network Based on Hybrid Convolution","abstract":"Since the number of incident energies is limited, it is difficult to directly acquire hyperspectral images (HSI) with high spatial resolution. Considering the high dimensionality and correlation of HSI, super-resolution (SR) of HSI remains a challenge in the absence of auxiliary high-resolution images. Furthermore, it is very important to extract the spatial features effectively and make full use of the spectral information. This paper proposes a novel HSI super-resolution algorithm, termed dual-domain network based on hybrid convolution (SRDNet). Specifically, a dual-domain network is designed to fully exploit the spatial-spectral and frequency information among the hyper-spectral data. To capture inter-spectral self-similarity, a self-attention learning mechanism (HSL) is devised in the spatial domain. Meanwhile the pyramid structure is applied to increase the acceptance field of attention, which further reinforces the feature representation ability of the network. Moreover, to further improve the perceptual quality of HSI, a frequency loss(HFL) is introduced to optimize the model in the frequency domain. The dynamic weighting mechanism drives the network to gradually refine the generated frequency and excessive smoothing caused by spatial loss. Finally, In order to better fully obtain the mapping relationship between high-resolution space and low-resolution space, a hybrid module of 2D and 3D units with progressive upsampling strategy is utilized in our method. Experiments on a widely used benchmark dataset illustrate that the proposed SRDNet method enhances the texture information of HSI and is superior to state-of-the-art methods.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04589v3","tag":"data-quality"}}
{"title":"Interior Point Methods with a Gradient Oracle","abstract":"We provide an interior point method based on quasi-Newton iterations, which only requires first-order access to a strongly self-concordant barrier function. To achieve this, we extend the techniques of Dunagan-Harvey [STOC '07] to maintain a preconditioner, while using only first-order information. We measure the quality of this preconditioner in terms of its relative excentricity to the unknown Hessian matrix, and we generalize these techniques to convex functions with a slowly-changing Hessian. We combine this with an interior point method to show that, given first-order access to an appropriate barrier function for a convex set $K$, we can solve well-conditioned linear optimization problems over $K$ to $\\varepsilon$ precision in time $\\widetilde{O}\\left(\\left(\\mathcal{T}+n^{2}\\right)\\sqrt{n\\nu}\\log\\left(1/\\varepsilon\\right)\\right)$, where $\\nu$ is the self-concordance parameter of the barrier function, and $\\mathcal{T}$ is the time required to make a gradient query. As a consequence we show that:   $\\bullet$ Linear optimization over $n$-dimensional convex sets can be solved in time $\\widetilde{O}\\left(\\left(\\mathcal{T}n+n^{3}\\right)\\log\\left(1/\\varepsilon\\right)\\right)$. This parallels the running time achieved by state of the art algorithms for cutting plane methods, when replacing separation oracles with first-order oracles for an appropriate barrier function.   $\\bullet$ We can solve semidefinite programs involving $m\\geq n$ matrices in $\\mathbb{R}^{n\\times n}$ in time $\\widetilde{O}\\left(mn^{4}+m^{1.25}n^{3.5}\\log\\left(1/\\varepsilon\\right)\\right)$, improving over the state of the art algorithms, in the case where $m=\\Omega\\left(n^{\\frac{3.5}{\\omega-1.25}}\\right)$.   Along the way we develop a host of tools allowing us to control the evolution of our potential functions, using techniques from matrix analysis and Schur convexity.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04550v1","tag":"data-quality"}}
{"title":"Sustainable Edge Computing: Challenges and Future Directions","abstract":"An increasing amount of data is being injected into the network from IoT (Internet of Things) applications. Many of these applications, developed to improve society's quality of life, are latency-critical and inject large amounts of data into the network. These requirements of IoT applications trigger the emergence of Edge computing paradigm. Currently, data centers are responsible for a global energy use between 2% and 3%. However, this trend is difficult to maintain, as bringing computing infrastructures closer to the edge of the network comes with its own set of challenges for energy efficiency. In this paper, we propose our approach for the sustainability of future computing infrastructures to provide (i) an energy-efficient and economically viable deployment, (ii) a fault-tolerant automated operation, and (iii) a collaborative resource management to improve resource efficiency. We identify the main limitations of applying Cloud-based approaches close to the data sources and present the research challenges to Edge sustainability arising from these constraints. We propose two-phase immersion cooling, formal modeling, machine learning, and energy-centric federated management as Edge-enabling technologies. We present our early results towards the sustainability of an Edge infrastructure to demonstrate the benefits of our approach for future computing environments and deployments.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04450v1","tag":"data-quality"}}
{"title":"H2RBox-v2: Boosting HBox-supervised Oriented Object Detection via Symmetric Learning","abstract":"With the increasing demand for oriented object detection e.g. in autonomous driving and remote sensing, the oriented annotation has become a labor-intensive work. To make full use of existing horizontally annotated datasets and reduce the annotation cost, a weakly-supervised detector H2RBox for learning the rotated box (RBox) from the horizontal box (HBox) has been proposed and received great attention. This paper presents a new version, H2RBox-v2, to further bridge the gap between HBox-supervised and RBox-supervised oriented object detection. While exploiting axisymmetry via flipping and rotating consistencies is available through our theoretical analysis, H2RBox-v2, using a weakly-supervised branch similar to H2RBox, is embedded with a novel self-supervised branch that learns orientations from the symmetry inherent in the image of objects. Complemented by modules to cope with peripheral issues, e.g. angular periodicity, a stable and effective solution is achieved. To our knowledge, H2RBox-v2 is the first symmetry-supervised paradigm for oriented object detection. Compared to H2RBox, our method is less susceptible to low annotation quality and insufficient training data, which in such cases is expected to give a competitive performance much closer to fully-supervised oriented object detectors. Specifically, the performance comparison between H2RBox-v2 and Rotated FCOS on DOTA-v1.0/1.5/2.0 is 72.31%/64.76%/50.33% vs. 72.44%/64.53%/51.77%, 89.66% vs. 88.99% on HRSC, and 42.27% vs. 41.25% on FAIR1M.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04403v2","tag":"data-quality"}}
{"title":"Filling out the missing gaps: Time Series Imputation with Semi-Supervised Learning","abstract":"Missing data in time series is a challenging issue affecting time series analysis. Missing data occurs due to problems like data drops or sensor malfunctioning. Imputation methods are used to fill in these values, with quality of imputation having a significant impact on downstream tasks like classification. In this work, we propose a semi-supervised imputation method, ST-Impute, that uses both unlabeled data along with downstream task's labeled data. ST-Impute is based on sparse self-attention and trains on tasks that mimic the imputation process. Our results indicate that the proposed method outperforms the existing supervised and unsupervised time series imputation methods measured on the imputation quality as well as on the downstream tasks ingesting imputed time series.","created":"2023-04-09","meta":{"link":"http://arxiv.org/abs/2304.04275v1","tag":"data-quality"}}
{"title":"Editable User Profiles for Controllable Text Recommendation","abstract":"Methods for making high-quality recommendations often rely on learning latent representations from interaction data. These methods, while performant, do not provide ready mechanisms for users to control the recommendation they receive. Our work tackles this problem by proposing LACE, a novel concept value bottleneck model for controllable text recommendations. LACE represents each user with a succinct set of human-readable concepts through retrieval given user-interacted documents and learns personalized representations of the concepts based on user documents. This concept based user profile is then leveraged to make recommendations. The design of our model affords control over the recommendations through a number of intuitive interactions with a transparent user profile. We first establish the quality of recommendations obtained from LACE in an offline evaluation on three recommendation tasks spanning six datasets in warm-start, cold-start, and zero-shot setups. Next, we validate the controllability of LACE under simulated user interactions. Finally, we implement LACE in an interactive controllable recommender system and conduct a user study to demonstrate that users are able to improve the quality of recommendations they receive through interactions with an editable user profile.","created":"2023-04-09","meta":{"link":"http://arxiv.org/abs/2304.04250v1","tag":"data-quality"}}
{"title":"OpenDriver: an open-road driver state detection dataset","abstract":"In modern society, road safety relies heavily on the psychological and physiological state of drivers. Negative factors such as fatigue, drowsiness, and stress can impair drivers' reaction time and decision making abilities, leading to an increased incidence of traffic accidents. Among the numerous studies for impaired driving detection, wearable physiological measurement is a real-time approach to monitoring a driver's state. However, currently, there are few driver physiological datasets in open road scenarios and the existing datasets suffer from issues such as poor signal quality, small sample sizes, and short data collection periods. Therefore, in this paper, a large-scale multimodal driving dataset for driver impairment detection and biometric data recognition is designed and described. The dataset contains two modalities of driving signals: six-axis inertial signals and electrocardiogram (ECG) signals, which were recorded while over one hundred drivers were following the same route through open roads during several months. Both the ECG signal sensor and the six-axis inertial signal sensor are installed on a specially designed steering wheel cover, allowing for data collection without disturbing the driver. Additionally, electrodermal activity (EDA) signals were also recorded during the driving process and will be integrated into the presented dataset soon. Future work can build upon this dataset to advance the field of driver impairment detection. New methods can be explored for integrating other types of biometric signals, such as eye tracking, to further enhance the understanding of driver states. The insights gained from this dataset can also inform the development of new driver assistance systems, promoting safer driving practices and reducing the risk of traffic accidents. The OpenDriver dataset will be publicly available soon.","created":"2023-04-09","meta":{"link":"http://arxiv.org/abs/2304.04203v1","tag":"data-quality"}}
{"title":"HyperINR: A Fast and Predictive Hypernetwork for Implicit Neural Representations via Knowledge Distillation","abstract":"Implicit Neural Representations (INRs) have recently exhibited immense potential in the field of scientific visualization for both data generation and visualization tasks. However, these representations often consist of large multi-layer perceptrons (MLPs), necessitating millions of operations for a single forward pass, consequently hindering interactive visual exploration. While reducing the size of the MLPs and employing efficient parametric encoding schemes can alleviate this issue, it compromises generalizability for unseen parameters, rendering it unsuitable for tasks such as temporal super-resolution. In this paper, we introduce HyperINR, a novel hypernetwork architecture capable of directly predicting the weights for a compact INR. By harnessing an ensemble of multiresolution hash encoding units in unison, the resulting INR attains state-of-the-art inference performance (up to 100x higher inference bandwidth) and can support interactive photo-realistic volume visualization. Additionally, by incorporating knowledge distillation, exceptional data and visualization generation quality is achieved, making our method valuable for real-time parameter exploration. We validate the effectiveness of the HyperINR architecture through a comprehensive ablation study. We showcase the versatility of HyperINR across three distinct scientific domains: novel view synthesis, temporal super-resolution of volume data, and volume rendering with dynamic global shadows. By simultaneously achieving efficiency and generalizability, HyperINR paves the way for applying INR in a wider array of scientific visualization applications.","created":"2023-04-09","meta":{"link":"http://arxiv.org/abs/2304.04188v1","tag":"data-quality"}}
{"title":"A Deep Learning Approach Towards Generating High-fidelity Diverse Synthetic Battery Datasets","abstract":"Recent surge in the number of Electric Vehicles have created a need to develop inexpensive energy-dense Battery Storage Systems. Many countries across the planet have put in place concrete measures to reduce and subsequently limit the number of vehicles powered by fossil fuels. Lithium-ion based batteries are presently dominating the electric automotive sector. Energy research efforts are also focussed on accurate computation of State-of-Charge of such batteries to provide reliable vehicle range estimates. Although such estimation algorithms provide precise estimates, all such techniques available in literature presume availability of superior quality battery datasets. In reality, gaining access to proprietary battery usage datasets is very tough for battery scientists. Moreover, open access datasets lack the diverse battery charge/discharge patterns needed to build generalized models. Curating battery measurement data is time consuming and needs expensive equipment. To surmount such limited data scenarios, we introduce few Deep Learning-based methods to synthesize high-fidelity battery datasets, these augmented synthetic datasets will help battery researchers build better estimation models in the presence of limited data. We have released the code and dataset used in the present approach to generate synthetic data. The battery data augmentation techniques introduced here will alleviate limited battery dataset challenges.","created":"2023-04-09","meta":{"link":"http://arxiv.org/abs/2304.06043v1","tag":"data-quality"}}
{"title":"Continual Graph Convolutional Network for Text Classification","abstract":"Graph convolutional network (GCN) has been successfully applied to capture global non-consecutive and long-distance semantic information for text classification. However, while GCN-based methods have shown promising results in offline evaluations, they commonly follow a seen-token-seen-document paradigm by constructing a fixed document-token graph and cannot make inferences on new documents. It is a challenge to deploy them in online systems to infer steaming text data. In this work, we present a continual GCN model (ContGCN) to generalize inferences from observed documents to unobserved documents. Concretely, we propose a new all-token-any-document paradigm to dynamically update the document-token graph in every batch during both the training and testing phases of an online system. Moreover, we design an occurrence memory module and a self-supervised contrastive learning objective to update ContGCN in a label-free manner. A 3-month A/B test on Huawei public opinion analysis system shows ContGCN achieves 8.86% performance gain compared with state-of-the-art methods. Offline experiments on five public datasets also show ContGCN can improve inference quality. The source code will be released at https://github.com/Jyonn/ContGCN.","created":"2023-04-09","meta":{"link":"http://arxiv.org/abs/2304.04152v1","tag":"data-quality"}}
{"title":"FedPNN: One-shot Federated Classification via Evolving Clustering Method and Probabilistic Neural Network hybrid","abstract":"Protecting data privacy is paramount in the fields such as finance, banking, and healthcare. Federated Learning (FL) has attracted widespread attention due to its decentralized, distributed training and the ability to protect the privacy while obtaining a global shared model. However, FL presents challenges such as communication overhead, and limited resource capability. This motivated us to propose a two-stage federated learning approach toward the objective of privacy protection, which is a first-of-its-kind study as follows: (i) During the first stage, the synthetic dataset is generated by employing two different distributions as noise to the vanilla conditional tabular generative adversarial neural network (CTGAN) resulting in modified CTGAN, and (ii) In the second stage, the Federated Probabilistic Neural Network (FedPNN) is developed and employed for building globally shared classification model. We also employed synthetic dataset metrics to check the quality of the generated synthetic dataset. Further, we proposed a meta-clustering algorithm whereby the cluster centers obtained from the clients are clustered at the server for training the global model. Despite PNN being a one-pass learning classifier, its complexity depends on the training data size. Therefore, we employed a modified evolving clustering method (ECM), another one-pass algorithm to cluster the training data thereby increasing the speed further. Moreover, we conducted sensitivity analysis by varying Dthr, a hyperparameter of ECM at the server and client, one at a time. The effectiveness of our approach is validated on four finance and medical datasets.","created":"2023-04-09","meta":{"link":"http://arxiv.org/abs/2304.04147v1","tag":"data-quality"}}
{"title":"RD-DPP: Rate-Distortion Theory Meets Determinantal Point Process to Diversify Learning Data Samples","abstract":"In some practical learning tasks, such as traffic video analysis, the number of available training samples is restricted by different factors, such as limited communication bandwidth and computation power; therefore, it is imperative to select diverse data samples that contribute the most to the quality of the learning system. One popular approach to selecting diverse samples is Determinantal Point Process (DPP). However, it suffers from a few known drawbacks, such as restriction of the number of samples to the rank of the similarity matrix, and not being customizable for specific learning tasks (e.g., multi-level classification tasks). In this paper, we propose a new way of measuring task-oriented diversity based on the Rate-Distortion (RD) theory, appropriate for multi-level classification. To this end, we establish a fundamental relationship between DPP and RD theory, which led to designing RD-DPP, an RD-based value function to evaluate the diversity gain of data samples. We also observe that the upper bound of the diversity of data selected by DPP has a universal trend of phase transition that quickly approaches its maximum point, then slowly converges to its final limits, meaning that DPP is beneficial only at the beginning of sample accumulation. We use this fact to design a bi-modal approach for sequential data selection.","created":"2023-04-09","meta":{"link":"http://arxiv.org/abs/2304.04137v1","tag":"data-quality"}}
{"title":"NeBLa: Neural Beer-Lambert for 3D Reconstruction of Oral Structures from Panoramic Radiographs","abstract":"Panoramic radiography (panoramic X-ray, PX) is a widely used imaging modality for dental examination. However, its applicability is limited as compared to 3D Cone-beam computed tomography (CBCT), because PX only provides 2D flattened images of the oral structure. In this paper, we propose a new framework which estimates 3D oral structure from real-world PX images. Since there are not many matching PX and CBCT data, we used simulated PX from CBCT for training, however, we used real-world panoramic radiographs at the inference time. We propose a new ray-sampling method to make simulated panoramic radiographs inspired by the principle of panoramic radiography along with the rendering function derived from the Beer-Lambert law. Our model consists of three parts: translation module, generation module, and refinement module. The translation module changes the real-world panoramic radiograph to the simulated training image style. The generation module makes the 3D structure from the input image without any prior information such as a dental arch. Our ray-based generation approach makes it possible to reverse the process of generating PX from oral structure in order to reconstruct CBCT data. Lastly, the refinement module enhances the quality of the 3D output. Results show that our approach works better for simulated and real-world images compared to other state-of-the-art methods.","created":"2023-04-08","meta":{"link":"http://arxiv.org/abs/2304.04027v1","tag":"data-quality"}}
{"title":"Attack is Good Augmentation: Towards Skeleton-Contrastive Representation Learning","abstract":"Contrastive learning, relying on effective positive and negative sample pairs, is beneficial to learn informative skeleton representations in unsupervised skeleton-based action recognition. To achieve these positive and negative pairs, existing weak/strong data augmentation methods have to randomly change the appearance of skeletons for indirectly pursuing semantic perturbations. However, such approaches have two limitations: 1) solely perturbing appearance cannot well capture the intrinsic semantic information of skeletons, and 2) randomly perturbation may change the original positive/negative pairs to soft positive/negative ones. To address the above dilemma, we start the first attempt to explore an attack-based augmentation scheme that additionally brings in direct semantic perturbation, for constructing hard positive pairs and further assisting in constructing hard negative pairs. In particular, we propose a novel Attack-Augmentation Mixing-Contrastive learning (A$^2$MC) to contrast hard positive features and hard negative features for learning more robust skeleton representations. In A$^2$MC, Attack-Augmentation (Att-Aug) is designed to collaboratively perform targeted and untargeted perturbations of skeletons via attack and augmentation respectively, for generating high-quality hard positive features. Meanwhile, Positive-Negative Mixer (PNM) is presented to mix hard positive features and negative features for generating hard negative features, which are adopted for updating the mixed memory banks. Extensive experiments on three public datasets demonstrate that A$^2$MC is competitive with the state-of-the-art methods.","created":"2023-04-08","meta":{"link":"http://arxiv.org/abs/2304.04023v1","tag":"data-quality"}}
{"title":"RIDCP: Revitalizing Real Image Dehazing via High-Quality Codebook Priors","abstract":"Existing dehazing approaches struggle to process real-world hazy images owing to the lack of paired real data and robust priors. In this work, we present a new paradigm for real image dehazing from the perspectives of synthesizing more realistic hazy data and introducing more robust priors into the network. Specifically, (1) instead of adopting the de facto physical scattering model, we rethink the degradation of real hazy images and propose a phenomenological pipeline considering diverse degradation types. (2) We propose a Real Image Dehazing network via high-quality Codebook Priors (RIDCP). Firstly, a VQGAN is pre-trained on a large-scale high-quality dataset to obtain the discrete codebook, encapsulating high-quality priors (HQPs). After replacing the negative effects brought by haze with HQPs, the decoder equipped with a novel normalized feature alignment module can effectively utilize high-quality features and produce clean results. However, although our degradation pipeline drastically mitigates the domain gap between synthetic and real data, it is still intractable to avoid it, which challenges HQPs matching in the wild. Thus, we re-calculate the distance when matching the features to the HQPs by a controllable matching operation, which facilitates finding better counterparts. We provide a recommendation to control the matching based on an explainable solution. Users can also flexibly adjust the enhancement degree as per their preference. Extensive experiments verify the effectiveness of our data synthesis pipeline and the superior performance of RIDCP in real image dehazing.","created":"2023-04-08","meta":{"link":"http://arxiv.org/abs/2304.03994v1","tag":"data-quality"}}
{"title":"Block-regularized 5$\\times$2 Cross-validated McNemar's Test for Comparing Two Classification Algorithms","abstract":"In the task of comparing two classification algorithms, the widely-used McNemar's test aims to infer the presence of a significant difference between the error rates of the two classification algorithms. However, the power of the conventional McNemar's test is usually unpromising because the hold-out (HO) method in the test merely uses a single train-validation split that usually produces a highly varied estimation of the error rates. In contrast, a cross-validation (CV) method repeats the HO method in multiple times and produces a stable estimation. Therefore, a CV method has a great advantage to improve the power of McNemar's test. Among all types of CV methods, a block-regularized 5$\\times$2 CV (BCV) has been shown in many previous studies to be superior to the other CV methods in the comparison task of algorithms because the 5$\\times$2 BCV can produce a high-quality estimator of the error rate by regularizing the numbers of overlapping records between all training sets. In this study, we compress the 10 correlated contingency tables in the 5$\\times$2 BCV to form an effective contingency table. Then, we define a 5$\\times$2 BCV McNemar's test on the basis of the effective contingency table. We demonstrate the reasonable type I error and the promising power of the proposed 5$\\times$2 BCV McNemar's test on multiple simulated and real-world data sets.","created":"2023-04-08","meta":{"link":"http://arxiv.org/abs/2304.03990v1","tag":"data-quality"}}
{"title":"Model-Agnostic Decentralized Collaborative Learning for On-Device POI Recommendation","abstract":"As an indispensable personalized service in Location-based Social Networks (LBSNs), the next Point-of-Interest (POI) recommendation aims to help people discover attractive and interesting places. Currently, most POI recommenders are based on the conventional centralized paradigm that heavily relies on the cloud to train the recommendation models with large volumes of collected users' sensitive check-in data. Although a few recent works have explored on-device frameworks for resilient and privacy-preserving POI recommendations, they invariably hold the assumption of model homogeneity for parameters/gradients aggregation and collaboration. However, users' mobile devices in the real world have various hardware configurations (e.g., compute resources), leading to heterogeneous on-device models with different architectures and sizes. In light of this, We propose a novel on-device POI recommendation framework, namely Model-Agnostic Collaborative learning for on-device POI recommendation (MAC), allowing users to customize their own model structures (e.g., dimension \\& number of hidden layers). To counteract the sparsity of on-device user data, we propose to pre-select neighbors for collaboration based on physical distances, category-level preferences, and social networks. To assimilate knowledge from the above-selected neighbors in an efficient and secure way, we adopt the knowledge distillation framework with mutual information maximization. Instead of sharing sensitive models/gradients, clients in MAC only share their soft decisions on a preloaded reference dataset. To filter out low-quality neighbors, we propose two sampling strategies, performance-triggered sampling and similarity-based sampling, to speed up the training process and obtain optimal recommenders. In addition, we design two novel approaches to generate more effective reference datasets while protecting users' privacy.","created":"2023-04-08","meta":{"link":"http://arxiv.org/abs/2304.03947v1","tag":"data-quality"}}
{"title":"Improving Spectral Efficiency via Pilot Assignment and Subarray Selection Under Realistic XL-MIMO Channels","abstract":"The main requirements for 5G and beyond connectivity include a uniform high quality of service, which can be attained in crowded scenarios by extra-large MIMO (XL-MIMO) systems. Another requirement is to support increasing connected users in (over)crowded machine-type communication (mMTC). In such scenarios, pilot assignment (PA) becomes paramount to reduce pilot contamination and consequently improve spectral efficiency (SE). We propose a novel quasi-optimal low-complexity iterative pilot assignment strategy for XL-MIMO systems based on a genetic algorithm (GA). The proposed GA-based PA procedure turns the quality of service more uniform, taking into account the normalized mean-square error (NMSE) of channel estimation from each candidate of the population. The simulations reveal that the proposed iterative procedure minimizes the channel estimation NMSE averaged over the UEs. The second procedure is the subarray (SA) selection. In XL-MIMO systems, commonly, a UE is close to a SA antenna subset such that a sufficient data rate can be achieved if only a specific SA serves that UE. Thus, a SA selection procedure is investigated to make the system scalable by defining the maximum number of UEs each SA can help. Hence, the SA clusters are formatted based on the PA decision. Furthermore, we introduce an appropriate channel model for XL-MIMO, which considers a deterministic LoS component with a distance-dependent probability of existence combined with a stochastic spatially correlated Rayleigh NLoS fading component. The developed simulations and analyses rely on this suitable channel model under realistic assumptions of pilot contamination and correlated channels.","created":"2023-04-08","meta":{"link":"http://arxiv.org/abs/2304.03873v1","tag":"data-quality"}}
{"title":"WOMD-LiDAR: Raw Sensor Dataset Benchmark for Motion Forecasting","abstract":"Widely adopted motion forecasting datasets substitute the observed sensory inputs with higher-level abstractions such as 3D boxes and polylines. These sparse shapes are inferred through annotating the original scenes with perception systems' predictions. Such intermediate representations tie the quality of the motion forecasting models to the performance of computer vision models. Moreover, the human-designed explicit interfaces between perception and motion forecasting typically pass only a subset of the semantic information present in the original sensory input. To study the effect of these modular approaches, design new paradigms that mitigate these limitations, and accelerate the development of end-to-end motion forecasting models, we augment the Waymo Open Motion Dataset (WOMD) with large-scale, high-quality, diverse LiDAR data for the motion forecasting task.   The new augmented dataset WOMD-LiDAR consists of over 100,000 scenes that each spans 20 seconds, consisting of well-synchronized and calibrated high quality LiDAR point clouds captured across a range of urban and suburban geographies (https://waymo.com/open/data/motion/). Compared to Waymo Open Dataset (WOD), WOMD-LiDAR dataset contains 100x more scenes. Furthermore, we integrate the LiDAR data into the motion forecasting model training and provide a strong baseline. Experiments show that the LiDAR data brings improvement in the motion forecasting task. We hope that WOMD-LiDAR will provide new opportunities for boosting end-to-end motion forecasting models.","created":"2023-04-07","meta":{"link":"http://arxiv.org/abs/2304.03834v1","tag":"data-quality"}}
{"title":"Digitization of the Australian Parliamentary Debates, 1998-2022","abstract":"Public knowledge of what is said in parliament is a tenet of democracy, and a critical resource for political science research. In Australia, following the British tradition, the written record of what is said in parliament is known as Hansard. While the Australian Hansard has always been publicly available, it has been difficult to use for the purpose of large-scale macro- and micro-level text analysis because it has only been available as PDFs or XMLs. Following the lead of the Linked Parliamentary Data project which achieved this for Canada, we provide a new, comprehensive, high-quality, rectangular database that captures proceedings of the Australian parliamentary debates from 1998 to 2022. The database is publicly available and can be linked to other datasets such as election results. The creation and accessibility of this database enables the exploration of new questions and serves as a valuable resource for both researchers and policymakers.","created":"2023-04-07","meta":{"link":"http://arxiv.org/abs/2304.04561v1","tag":"data-quality"}}
{"title":"Compressed Regression over Adaptive Networks","abstract":"In this work we derive the performance achievable by a network of distributed agents that solve, adaptively and in the presence of communication constraints, a regression problem. Agents employ the recently proposed ACTC (adapt-compress-then-combine) diffusion strategy, where the signals exchanged locally by neighboring agents are encoded with randomized differential compression operators. We provide a detailed characterization of the mean-square estimation error, which is shown to comprise a term related to the error that agents would achieve without communication constraints, plus a term arising from compression. The analysis reveals quantitative relationships between the compression loss and fundamental attributes of the distributed regression problem, in particular, the stochastic approximation error caused by the gradient noise and the network topology (through the Perron eigenvector). We show that knowledge of such relationships is critical to allocate optimally the communication resources across the agents, taking into account their individual attributes, such as the quality of their data or their degree of centrality in the network topology. We devise an optimized allocation strategy where the parameters necessary for the optimization can be learned online by the agents. Illustrative examples show that a significant performance improvement, as compared to a blind (i.e., uniform) resource allocation, can be achieved by optimizing the allocation by means of the provided mean-square-error formulas.","created":"2023-04-07","meta":{"link":"http://arxiv.org/abs/2304.03638v1","tag":"data-quality"}}
{"title":"ChatPipe: Orchestrating Data Preparation Program by Optimizing Human-ChatGPT Interactions","abstract":"Orchestrating a high-quality data preparation program is essential for successful machine learning (ML), but it is known to be time and effort consuming. Despite the impressive capabilities of large language models like ChatGPT in generating programs by interacting with users through natural language prompts, there are still limitations. Specifically, a user must provide specific prompts to iteratively guide ChatGPT in improving data preparation programs, which requires a certain level of expertise in programming, the dataset used and the ML task. Moreover, once a program has been generated, it is non-trivial to revisit a previous version or make changes to the program without starting the process over again. In this paper, we present ChatPipe, a novel system designed to facilitate seamless interaction between users and ChatGPT. ChatPipe provides users with effective recommendation on next data preparation operations, and guides ChatGPT to generate program for the operations. Also, ChatPipe enables users to easily roll back to previous versions of the program, which facilitates more efficient experimentation and testing. We have developed a web application for ChatPipe and prepared several real-world ML tasks from Kaggle. These tasks can showcase the capabilities of ChatPipe and enable VLDB attendees to easily experiment with our novel features to rapidly orchestrate a high-quality data preparation program.","created":"2023-04-07","meta":{"link":"http://arxiv.org/abs/2304.03540v1","tag":"data-quality"}}
{"title":"Multispectral Imaging for Differential Face Morphing Attack Detection: A Preliminary Study","abstract":"Face morphing attack detection is emerging as an increasingly challenging problem owing to advancements in high-quality and realistic morphing attack generation. Reliable detection of morphing attacks is essential because these attacks are targeted for border control applications. This paper presents a multispectral framework for differential morphing-attack detection (D-MAD). The D-MAD methods are based on using two facial images that are captured from the ePassport (also called the reference image) and the trusted device (for example, Automatic Border Control (ABC) gates) to detect whether the face image presented in ePassport is morphed. The proposed multispectral D-MAD framework introduce a multispectral image captured as a trusted capture to capture seven different spectral bands to detect morphing attacks. Extensive experiments were conducted on the newly created datasets with 143 unique data subjects that were captured using both visible and multispectral cameras in multiple sessions. The results indicate the superior performance of the proposed multispectral framework compared to visible images.","created":"2023-04-07","meta":{"link":"http://arxiv.org/abs/2304.03510v1","tag":"data-quality"}}
{"title":"Iterative Soft Decoding Algorithm for DNA Storage Using Quality Score and Redecoding","abstract":"Ever since deoxyribonucleic acid (DNA) was considered as a next-generation data-storage medium, lots of research efforts have been made to correct errors occurred during the synthesis, storage, and sequencing processes using error correcting codes (ECCs). Previous works on recovering the data from the sequenced DNA pool with errors have utilized hard decoding algorithms based on a majority decision rule. To improve the correction capability of ECCs and robustness of the DNA storage system, we propose a new iterative soft decoding algorithm, where soft information is obtained from FASTQ files and channel statistics. In particular, we propose a new formula for log-likelihood ratio (LLR) calculation using quality scores (Q-scores) and a redecoding method which may be suitable for the error correction and detection in the DNA sequencing area. Based on the widely adopted encoding scheme of the fountain code structure proposed by Erlich et al., we use three different sets of sequenced data to show consistency for the performance evaluation. The proposed soft decoding algorithm gives 2.3% ~ 7.0% improvement of the reading number reduction compared to the state-of-the-art decoding method and it is shown that it can deal with erroneous sequenced oligo reads with insertion and deletion errors.","created":"2023-04-07","meta":{"link":"http://arxiv.org/abs/2304.03502v1","tag":"data-quality"}}
{"title":"Opinion Mining from YouTube Captions Using ChatGPT: A Case Study of Street Interviews Polling the 2023 Turkish Elections","abstract":"Opinion mining plays a critical role in understanding public sentiment and preferences, particularly in the context of political elections. Traditional polling methods, while useful, can be expensive and less scalable. Social media offers an alternative source of data for opinion mining but presents challenges such as noise, biases, and platform limitations in data collection. In this paper, we propose a novel approach for opinion mining, utilizing YouTube's auto-generated captions from public interviews as a data source, specifically focusing on the 2023 Turkish elections as a case study. We introduce an opinion mining framework using ChatGPT to mass-annotate voting intentions and motivations that represent the stance and frames prior to the election. We report that ChatGPT can predict the preferred candidate with 97\\% accuracy and identify the correct voting motivation out of 13 possible choices with 71\\% accuracy based on the data collected from 325 interviews. We conclude by discussing the robustness of our approach, accounting for factors such as captions quality, interview length, and channels. This new method will offer a less noisy and cost-effective alternative for opinion mining using social media data.","created":"2023-04-07","meta":{"link":"http://arxiv.org/abs/2304.03434v1","tag":"data-quality"}}
{"title":"RoSteALS: Robust Steganography using Autoencoder Latent Space","abstract":"Data hiding such as steganography and invisible watermarking has important applications in copyright protection, privacy-preserved communication and content provenance. Existing works often fall short in either preserving image quality, or robustness against perturbations or are too complex to train. We propose RoSteALS, a practical steganography technique leveraging frozen pretrained autoencoders to free the payload embedding from learning the distribution of cover images. RoSteALS has a light-weight secret encoder of just 300k parameters, is easy to train, has perfect secret recovery performance and comparable image quality on three benchmarks. Additionally, RoSteALS can be adapted for novel cover-less steganography applications in which the cover image can be sampled from noise or conditioned on text prompts via a denoising diffusion process. Our model and code are available at \\url{https://github.com/TuBui/RoSteALS}.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.03400v1","tag":"data-quality"}}
{"title":"$\\text{DC}^2$: Dual-Camera Defocus Control by Learning to Refocus","abstract":"Smartphone cameras today are increasingly approaching the versatility and quality of professional cameras through a combination of hardware and software advancements. However, fixed aperture remains a key limitation, preventing users from controlling the depth of field (DoF) of captured images. At the same time, many smartphones now have multiple cameras with different fixed apertures -- specifically, an ultra-wide camera with wider field of view and deeper DoF and a higher resolution primary camera with shallower DoF. In this work, we propose $\\text{DC}^2$, a system for defocus control for synthetically varying camera aperture, focus distance and arbitrary defocus effects by fusing information from such a dual-camera system. Our key insight is to leverage real-world smartphone camera dataset by using image refocus as a proxy task for learning to control defocus. Quantitative and qualitative evaluations on real-world data demonstrate our system's efficacy where we outperform state-of-the-art on defocus deblurring, bokeh rendering, and image refocus. Finally, we demonstrate creative post-capture defocus control enabled by our method, including tilt-shift and content-based defocus effects.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.03285v1","tag":"data-quality"}}
{"title":"Diffusion Models as Masked Autoencoders","abstract":"There has been a longstanding belief that generation can facilitate a true understanding of visual data. In line with this, we revisit generatively pre-training visual representations in light of recent interest in denoising diffusion models. While directly pre-training with diffusion models does not produce strong representations, we condition diffusion models on masked input and formulate diffusion models as masked autoencoders (DiffMAE). Our approach is capable of (i) serving as a strong initialization for downstream recognition tasks, (ii) conducting high-quality image inpainting, and (iii) being effortlessly extended to video where it produces state-of-the-art classification accuracy. We further perform a comprehensive study on the pros and cons of design choices and build connections between diffusion models and masked autoencoders.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.03283v1","tag":"data-quality"}}
{"title":"Expert-Independent Generalization of Well and Seismic Data Using Machine Learning Methods for Complex Reservoirs Predicting During Early-Stage Geological Exploration","abstract":"The aim of this study is to develop and apply an autonomous approach for predicting the probability of hydrocarbon reservoirs spreading in the studied area. Autonomy means that after preparing and inputting geological-geophysical information, the influence of an expert on the algorithms is minimized. The study was made based on the 3D seismic survey data and well information on the early exploration stage of the studied field. As a result, a forecast of the probability of spatial distribution of reservoirs was made for two sets of input data: the base set and the set after reverse-calibration, and three-dimensional cubes of calibrated probabilities of belonging of the studied space to the identified classes were obtained. The approach presented in the paper allows for expert-independent generalization of geological and geophysical data, and to use this generalization for hypothesis testing and creating geological models based on a probabilistic representation of the reservoir. The quality of the probabilistic representation depends on the quality and quantity of the input data. Depending on the input data, the approach can be a useful tool for exploration and prospecting of geological objects, identifying potential resources, optimizing and designing field development.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.03048v1","tag":"data-quality"}}
{"title":"TagGPT: Large Language Models are Zero-shot Multimodal Taggers","abstract":"Tags are pivotal in facilitating the effective distribution of multimedia content in various applications in the contemporary Internet era, such as search engines and recommendation systems. Recently, large language models (LLMs) have demonstrated impressive capabilities across a wide range of tasks. In this work, we propose TagGPT, a fully automated system capable of tag extraction and multimodal tagging in a completely zero-shot fashion. Our core insight is that, through elaborate prompt engineering, LLMs are able to extract and reason about proper tags given textual clues of multimodal data, e.g., OCR, ASR, title, etc. Specifically, to automatically build a high-quality tag set that reflects user intent and interests for a specific application, TagGPT predicts large-scale candidate tags from a series of raw data via prompting LLMs, filtered with frequency and semantics. Given a new entity that needs tagging for distribution, TagGPT introduces two alternative options for zero-shot tagging, i.e., a generative method with late semantic matching with the tag set, and another selective method with early matching in prompts. It is well noticed that TagGPT provides a system-level solution based on a modular framework equipped with a pre-trained LLM (GPT-3.5 used here) and a sentence embedding model (SimCSE used here), which can be seamlessly replaced with any more advanced one you want. TagGPT is applicable for various modalities of data in modern social media and showcases strong generalization ability to a wide range of applications. We evaluate TagGPT on publicly available datasets, i.e., Kuaishou and Food.com, and demonstrate the effectiveness of TagGPT compared to existing hashtags and off-the-shelf taggers. Project page: https://github.com/TencentARC/TagGPT.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.03022v1","tag":"data-quality"}}
{"title":"Spectral Energy Distribution profiles from AGN accretion disc in multi-gap setup","abstract":"Spectral Energy Distribution (SED) of the broad-band continuum emission from black-hole accretion discs can serve as a tool to measure parameters of the central body and constrain the geometry of the inner accretion flow. We focus on the case of an active galactic nucleus (AGN), with an accretion disc dominating the UV/optical bands. We parameterize the changes in the thermal and power-law components, which can reveal the diminution of the emissivity. To this end we explore the effects of gaps in the accretion disc and the emerging SED that can be caused by the presence of either (i) the inner, optically thin, radiatively inefficient hot flow; (ii) a secondary black hole embedded within the accretion disc; or (iii) a combination of both components. We suggest that the resulting changes in the SED of the underlying continuum can help us to understand some departures from the standard-disc scenario. We estimate that the data required for such a project must be sampled in detail over the far-UV to soft X-ray bands during the interval of about a month corresponding to the characteristic variability timescale of an AGN. Detecting a gap at intermediate radii of a few 100 gravitational radii would require quality photometry with uncertainties up to $\\sim$ 1%. The presence of the central cavity in the standard disc can be recovered in UV photometric data with an accuracy of 5% and better. We show the effect of the intrinsic reddening of the source and demonstrate when it can be disentangled.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.03015v1","tag":"data-quality"}}
{"title":"A Closer Look at Audio-Visual Semantic Segmentation","abstract":"Audio-visual segmentation (AVS) is a complex task that involves accurately segmenting the corresponding sounding object based on audio-visual queries. Successful audio-visual learning requires two essential components: 1) an unbiased dataset with high-quality pixel-level multi-class labels, and 2) a model capable of effectively linking audio information with its corresponding visual object. However, these two requirements are only partially addressed by current methods, with training sets containing biased audio-visual data, and models that generalise poorly beyond this biased training set. In this work, we propose a new strategy to build cost-effective and relatively unbiased audio-visual semantic segmentation benchmarks. Our strategy, called Visual Post-production (VPO), explores the observation that it is not necessary to have explicit audio-visual pairs extracted from single video sources to build such benchmarks. We also refine the previously proposed AVSBench to transform it into the audio-visual semantic segmentation benchmark AVSBench-Single+. Furthermore, this paper introduces a new pixel-wise audio-visual contrastive learning method to enable a better generalisation of the model beyond the training set. We verify the validity of the VPO strategy by showing that state-of-the-art (SOTA) models trained with datasets built by matching audio and visual data from different sources or with datasets containing audio and visual data from the same video source produce almost the same accuracy. Then, using the proposed VPO benchmarks and AVSBench-Single+, we show that our method produces more accurate audio-visual semantic segmentation than SOTA models. Code and dataset will be available.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.02970v2","tag":"data-quality"}}
{"title":"Learning Cautiously in Federated Learning with Noisy and Heterogeneous Clients","abstract":"Federated learning (FL) is a distributed framework for collaboratively training with privacy guarantees. In real-world scenarios, clients may have Non-IID data (local class imbalance) with poor annotation quality (label noise). The co-existence of label noise and class imbalance in FL's small local datasets renders conventional FL methods and noisy-label learning methods both ineffective. To address the challenges, we propose FedCNI without using an additional clean proxy dataset. It includes a noise-resilient local solver and a robust global aggregator. For the local solver, we design a more robust prototypical noise detector to distinguish noisy samples. Further to reduce the negative impact brought by the noisy samples, we devise a curriculum pseudo labeling method and a denoise Mixup training strategy. For the global aggregator, we propose a switching re-weighted aggregation method tailored to different learning periods. Extensive experiments demonstrate our method can substantially outperform state-of-the-art solutions in mix-heterogeneous FL environments.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.02892v1","tag":"data-quality"}}
{"title":"MULLER: Multilayer Laplacian Resizer for Vision","abstract":"Image resizing operation is a fundamental preprocessing module in modern computer vision. Throughout the deep learning revolution, researchers have overlooked the potential of alternative resizing methods beyond the commonly used resizers that are readily available, such as nearest-neighbors, bilinear, and bicubic. The key question of our interest is whether the front-end resizer affects the performance of deep vision models? In this paper, we present an extremely lightweight multilayer Laplacian resizer with only a handful of trainable parameters, dubbed MULLER resizer. MULLER has a bandpass nature in that it learns to boost details in certain frequency subbands that benefit the downstream recognition models. We show that MULLER can be easily plugged into various training pipelines, and it effectively boosts the performance of the underlying vision task with little to no extra cost. Specifically, we select a state-of-the-art vision Transformer, MaxViT, as the baseline, and show that, if trained with MULLER, MaxViT gains up to 0.6% top-1 accuracy, and meanwhile enjoys 36% inference cost saving to achieve similar top-1 accuracy on ImageNet-1k, as compared to the standard training scheme. Notably, MULLER's performance also scales with model size and training data size such as ImageNet-21k and JFT, and it is widely applicable to multiple vision tasks, including image classification, object detection and segmentation, as well as image quality assessment.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.02859v1","tag":"data-quality"}}
{"title":"Deep Reinforcement Learning Based Vehicle Selection for Asynchronous Federated Learning Enabled Vehicular Edge Computing","abstract":"In the traditional vehicular network, computing tasks generated by the vehicles are usually uploaded to the cloud for processing. However, since task offloading toward the cloud will cause a large delay, vehicular edge computing (VEC) is introduced to avoid such a problem and improve the whole system performance, where a roadside unit (RSU) with certain computing capability is used to process the data of vehicles as an edge entity. Owing to the privacy and security issues, vehicles are reluctant to upload local data directly to the RSU, and thus federated learning (FL) becomes a promising technology for some machine learning tasks in VEC, where vehicles only need to upload the local model hyperparameters instead of transferring their local data to the nearby RSU. Furthermore, as vehicles have different local training time due to various sizes of local data and their different computing capabilities, asynchronous federated learning (AFL) is employed to facilitate the RSU to update the global model immediately after receiving a local model to reduce the aggregation delay. However, in AFL of VEC, different vehicles may have different impact on the global model updating because of their various local training delay, transmission delay and local data sizes. Also, if there are bad nodes among the vehicles, it will affect the global aggregation quality at the RSU. To solve the above problem, we shall propose a deep reinforcement learning (DRL) based vehicle selection scheme to improve the accuracy of the global model in AFL of vehicular network. In the scheme, we present the model including the state, action and reward in the DRL based to the specific problem. Simulation results demonstrate our scheme can effectively remove the bad nodes and improve the aggregation accuracy of the global model.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.02832v1","tag":"data-quality"}}
{"title":"Zero-shot Medical Image Translation via Frequency-Guided Diffusion Models","abstract":"Recently, the diffusion model has emerged as a superior generative model that can produce high-quality images with excellent realism. There is a growing interest in applying diffusion models to image translation tasks. However, for medical image translation, the existing diffusion models are deficient in accurately retaining structural information since the structure details of source domain images are lost during the forward diffusion process and cannot be fully recovered through learned reverse diffusion, while the integrity of anatomical structures is extremely important in medical images. Training and conditioning diffusion models using paired source and target images with matching anatomy can help. However, such paired data are very difficult and costly to obtain, and may also reduce the robustness of the developed model to out-of-distribution testing data. We propose a frequency-guided diffusion model (FGDM) that employs frequency-domain filters to guide the diffusion model for structure-preserving image translation. Based on its design, FGDM allows zero-shot learning, as it can be trained solely on the data from the target domain, and used directly for source-to-target domain translation without any exposure to the source-domain data during training. We trained FGDM solely on the head-and-neck CT data, and evaluated it on both head-and-neck and lung cone-beam CT (CBCT)-to-CT translation tasks. FGDM outperformed the state-of-the-art methods (GAN-based, VAE-based, and diffusion-based) in all metrics, showing its significant advantages in zero-shot medical image translation.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02742v1","tag":"data-quality"}}
{"title":"Image Stabilization for Hololens Camera in Remote Collaboration","abstract":"With the advent of new technologies, Augmented Reality (AR) has become an effective tool in remote collaboration. Narrow field-of-view (FoV) and motion blur can offer an unpleasant experience with limited cognition for remote viewers of AR headsets. In this article, we propose a two-stage pipeline to tackle this issue and ensure a stable viewing experience with a larger FoV. The solution involves an offline 3D reconstruction of the indoor environment, followed by enhanced rendering using only the live poses of AR device. We experiment with and evaluate the two different 3D reconstruction methods, RGB-D geometric approach and Neural Radiance Fields (NeRF), based on their data requirements, reconstruction quality, rendering, and training times. The generated sequences from these methods had smoother transitions and provided a better perspective of the environment. The geometry-based enhanced FoV method had better renderings as it lacked blurry outputs making it better than the other attempted approaches. Structural Similarity Index (SSIM) and Peak Signal to Noise Ratio (PSNR) metrics were used to quantitatively show that the rendering quality using the geometry-based enhanced FoV method is better. Link to the code repository - https://github.com/MixedRealityETHZ/ImageStabilization.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02736v1","tag":"data-quality"}}
{"title":"Human Error Management in Requirements Engineering: Should We Fix the People, the Processes, or the Environment?","abstract":"Context: Software development is human-centric and vulnerable to human error. Human errors are errors in the human thought process. To ensure software quality, practitioners must understand how to manage these human errors. Organizations often change the requirements engineering process to prevent human errors from occurring or to mitigate the harm caused when those errors do occur. While there are studies on human error management in other disciplines, research on the prevention and mitigation of human errors in software engineering, and requirements engineering specifically, are limited. The software engineering studies do not provide strong results about the types of changes that are most effective in requirements engineering. Objective: The goal of this paper is to develop a taxonomy of human error prevention and mitigation strategies based on data from requirements engineering professionals. Method: We performed a qualitative analysis of two practitioner surveys on requirements engineering practices to identify and classify strategies for the prevention and mitigation of human errors. Results: We organized the human error management strategies into a taxonomy based on whether they primarily affect People, Processes, or the Environment. Inside each high-level category, we further organized the strategies into low-level classes. More than 50% of the reported strategies require a change in Process, 23% require a change in Environment, 21% require a change in People, with the remaining 5% too ambiguous to classify. In addition, more than 50\\% of the strategies focus on Management activities. Conclusions: The Human Error Management Taxonomy provides a systematic classification and organization of strategies for prevention and mitigation of human errors in requirements engineering. This systematic organization provides a foundation upon which research can build.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02702v1","tag":"data-quality"}}
{"title":"High-fidelity Pseudo-labels for Boosting Weakly-Supervised Segmentation","abstract":"The task of image-level weakly-supervised semantic segmentation (WSSS) has gained popularity in recent years, as it reduces the vast data annotation cost for training segmentation models. The typical approach for WSSS involves training an image classification network using global average pooling (GAP) on convolutional feature maps. This enables the estimation of object locations based on class activation maps (CAMs), which identify the importance of image regions. The CAMs are then used to generate pseudo-labels, in the form of segmentation masks, to supervise a segmentation model in the absence of pixel-level ground truth. In case of the SEAM baseline, a previous work proposed to improve CAM learning in two ways: (1) Importance sampling, which is a substitute for GAP, and (2) the feature similarity loss, which utilizes a heuristic that object contours almost exclusively align with color edges in images. In this work, we propose a different probabilistic interpretation of CAMs for these techniques, rendering the likelihood more appropriate than the multinomial posterior. As a result, we propose an add-on method that can boost essentially any previous WSSS method, improving both the region similarity and contour quality of all implemented state-of-the-art baselines. This is demonstrated on a wide variety of baselines on the PASCAL VOC dataset. Experiments on the MS COCO dataset show that performance gains can also be achieved in a large-scale setting. Our code is available at https://github.com/arvijj/hfpl.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02621v1","tag":"data-quality"}}
{"title":"Efficient Gradient-based Optimization for Reconstructing Binary Images in Applications to Electrical Impedance Tomography","abstract":"A novel and highly efficient computational framework for reconstructing binary-type images suitable for models of various complexity seen in diverse biomedical applications is developed and validated. Efficiency in computational speed and accuracy is achieved by combining the advantages of recently developed optimization methods that use sample solutions with customized geometry and multiscale control space reduction, all paired with gradient-based techniques. The control space is effectively reduced based on the geometry of the samples and their individual contributions. The entire 3-step computational procedure has an easy-to-follow design due to a nominal number of tuning parameters making the approach simple for practical implementation in various settings. Fairly straightforward methods for computing gradients make the framework compatible with any optimization software, including black-box ones. The performance of the complete computational framework is tested in applications to 2D inverse problems of cancer detection by electrical impedance tomography (EIT) using data from models generated synthetically and obtained from medical images showing the natural development of cancerous regions of various sizes and shapes. The results demonstrate the superior performance of the new method and its high potential for improving the overall quality of the EIT-based procedures.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02601v1","tag":"data-quality"}}
{"title":"Adaptive Data Augmentation for Contrastive Learning","abstract":"In computer vision, contrastive learning is the most advanced unsupervised learning framework. Yet most previous methods simply apply fixed composition of data augmentations to improve data efficiency, which ignores the changes in their optimal settings over training. Thus, the pre-determined parameters of augmentation operations cannot always fit well with an evolving network during the whole training period, which degrades the quality of the learned representations. In this work, we propose AdDA, which implements a closed-loop feedback structure to a generic contrastive learning network. AdDA works by allowing the network to adaptively adjust the augmentation compositions according to the real-time feedback. This online adjustment helps maintain the dynamic optimal composition and enables the network to acquire more generalizable representations with minimal computational overhead. AdDA achieves competitive results under the common linear protocol on ImageNet-100 classification (+1.11% on MoCo v2).","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02451v1","tag":"data-quality"}}
{"title":"ParroT: Translating During Chat Using Large Language Models","abstract":"Large language models (LLMs) like ChatGPT and GPT-4 have exhibited remarkable abilities on a wide range of natural language processing (NLP) tasks, including various machine translation abilities accomplished during chat. However, these models are only accessible through restricted APIs, which creates barriers to new research and advancements in the field. Therefore, we propose the $\\mathbf{ParroT}$ framework to enhance and regulate the translation abilities during chat based on open-sourced LLMs (i.e., LLaMA-7b) and human written translation and evaluation data. Specifically, ParroT reformulates translation data into the instruction-following style, and introduces a \"Hint\" field for incorporating extra requirements to regulate the translation process. Accordingly, we propose three instruction types for finetuning ParroT models, including translation instruction, contrastive instruction, and error-guided instruction. Experiments on Flores subsets and WMT22 test sets suggest that translation instruction improves the translation performance of vanilla LLMs significantly while error-guided instruction can lead to a further improvement, which demonstrates the importance of learning from low-quality translations annotated by human. Meanwhile, the ParroT models can also preserve the ability on general tasks with the Alpaca multi-task dataset involved in finetuning. Codes: https://github.com/wxjiao/ParroT","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02426v2","tag":"data-quality"}}
{"title":"TM2D: Bimodality Driven 3D Dance Generation via Music-Text Integration","abstract":"We propose a novel task for generating 3D dance movements that simultaneously incorporate both text and music modalities. Unlike existing works that generate dance movements using a single modality such as music, our goal is to produce richer dance movements guided by the instructive information provided by the text. However, the lack of paired motion data with both music and text modalities limits the ability to generate dance movements that integrate both. To alleviate this challenge, we propose to utilize a 3D human motion VQ-VAE to project the motions of the two datasets into a latent space consisting of quantized vectors, which effectively mix the motion tokens from the two datasets with different distributions for training. Additionally, we propose a cross-modal transformer to integrate text instructions into motion generation architecture for generating 3D dance movements without degrading the performance of music-conditioned dance generation. To better evaluate the quality of the generated motion, we introduce two novel metrics, namely Motion Prediction Distance (MPD) and Freezing Score, to measure the coherence and freezing percentage of the generated motion. Extensive experiments show that our approach can generate realistic and coherent dance movements conditioned on both text and music while maintaining comparable performance with the two single modalities. Code will be available at: https://garfield-kh.github.io/TM2D/.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02419v1","tag":"data-quality"}}
{"title":"Ultra-high quality factor of a levitated nanomechanical oscillator","abstract":"A levitated nanomechanical oscillator under ultra-high vacuum (UHV) is highly isolated from its environment, and this isolation is expected to enable very low mechanical dissipation rates. However, a gap persists between predictions and experimental data. Here, we levitate a silica nanoparticle in a linear Paul trap at room temperature, at pressures as low as $7\\times 10^{-11}~\\text{mbar}$. We measure a dissipation rate of $2\\pi\\times80(20)~\\text{nHz}$, corresponding to a quality factor exceeding $10^{10}$, more than two orders of magnitude higher than previously shown. A study of the pressure dependence of the particle's damping and heating rates provides insight into the relevant dissipation mechanisms. Our results confirm that levitated nanoparticles are indeed promising candidates for ultrasensitive detectors and for tests of quantum physics at macroscopic scales.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02408v1","tag":"data-quality"}}
{"title":"DRAC: Diabetic Retinopathy Analysis Challenge with Ultra-Wide Optical Coherence Tomography Angiography Images","abstract":"Computer-assisted automatic analysis of diabetic retinopathy (DR) is of great importance in reducing the risks of vision loss and even blindness. Ultra-wide optical coherence tomography angiography (UW-OCTA) is a non-invasive and safe imaging modality in DR diagnosis system, but there is a lack of publicly available benchmarks for model development and evaluation. To promote further research and scientific benchmarking for diabetic retinopathy analysis using UW-OCTA images, we organized a challenge named \"DRAC - Diabetic Retinopathy Analysis Challenge\" in conjunction with the 25th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2022). The challenge consists of three tasks: segmentation of DR lesions, image quality assessment and DR grading. The scientific community responded positively to the challenge, with 11, 12, and 13 teams from geographically diverse institutes submitting different solutions in these three tasks, respectively. This paper presents a summary and analysis of the top-performing solutions and results for each task of the challenge. The obtained results from top algorithms indicate the importance of data augmentation, model architecture and ensemble of networks in improving the performance of deep learning models. These findings have the potential to enable new developments in diabetic retinopathy analysis. The challenge remains open for post-challenge registrations and submissions for benchmarking future methodology developments.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02389v1","tag":"data-quality"}}
{"title":"Semantic Communications for Image Recovery and Classification via Deep Joint Source and Channel Coding","abstract":"With the recent advancements in edge artificial intelligence (AI), future sixth-generation (6G) networks need to support new AI tasks such as classification and clustering apart from data recovery. Motivated by the success of deep learning, the semantic-aware and task-oriented communications with deep joint source and channel coding (JSCC) have emerged as new paradigm shifts in 6G from the conventional data-oriented communications with separate source and channel coding (SSCC). However, most existing works focused on the deep JSCC designs for one task of data recovery or AI task execution independently, which cannot be transferred to other unintended tasks. Differently, this paper investigates the JSCC semantic communications to support multi-task services, by performing the image data recovery and classification task execution simultaneously. First, we propose a new end-to-end deep JSCC framework by unifying the coding rate reduction maximization and the mean square error (MSE) minimization in the loss function. Here, the coding rate reduction maximization facilitates the learning of discriminative features for enabling to perform classification tasks directly in the feature space, and the MSE minimization helps the learning of informative features for high-quality image data recovery. Next, to further improve the robustness against variational wireless channels, we propose a new gated deep JSCC design, in which a gated net is incorporated for adaptively pruning the output features to adjust their dimensions based on channel conditions. Finally, we present extensive numerical experiments to validate the performance of our proposed deep JSCC designs as compared to various benchmark schemes.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02317v1","tag":"data-quality"}}
{"title":"Efficient Deduplication and Leakage Detection in Large Scale Image Datasets with a focus on the CrowdAI Mapping Challenge Dataset","abstract":"Recent advancements in deep learning and computer vision have led to widespread use of deep neural networks to extract building footprints from remote-sensing imagery. The success of such methods relies on the availability of large databases of high-resolution remote sensing images with high-quality annotations. The CrowdAI Mapping Challenge Dataset is one of these datasets that has been used extensively in recent years to train deep neural networks. This dataset consists of $ \\sim\\ $280k training images and $ \\sim\\ $60k testing images, with polygonal building annotations for all images. However, issues such as low-quality and incorrect annotations, extensive duplication of image samples, and data leakage significantly reduce the utility of deep neural networks trained on the dataset. Therefore, it is an imperative pre-condition to adopt a data validation pipeline that evaluates the quality of the dataset prior to its use. To this end, we propose a drop-in pipeline that employs perceptual hashing techniques for efficient de-duplication of the dataset and identification of instances of data leakage between training and testing splits. In our experiments, we demonstrate that nearly 250k($ \\sim\\ $90%) images in the training split were identical. Moreover, our analysis on the validation split demonstrates that roughly 56k of the 60k images also appear in the training split, resulting in a data leakage of 93%. The source code used for the analysis and de-duplication of the CrowdAI Mapping Challenge dataset is publicly available at https://github.com/yeshwanth95/CrowdAI_Hash_and_search .","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02296v1","tag":"data-quality"}}
{"title":"Topology-Guided Multi-Class Cell Context Generation for Digital Pathology","abstract":"In digital pathology, the spatial context of cells is important for cell classification, cancer diagnosis and prognosis. To model such complex cell context, however, is challenging. Cells form different mixtures, lineages, clusters and holes. To model such structural patterns in a learnable fashion, we introduce several mathematical tools from spatial statistics and topological data analysis. We incorporate such structural descriptors into a deep generative model as both conditional inputs and a differentiable loss. This way, we are able to generate high quality multi-class cell layouts for the first time. We show that the topology-rich cell layouts can be used for data augmentation and improve the performance of downstream tasks such as cell classification.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02255v1","tag":"data-quality"}}
{"title":"Industrial Anomaly Detection with Domain Shift: A Real-world Dataset and Masked Multi-scale Reconstruction","abstract":"Industrial anomaly detection (IAD) is crucial for automating industrial quality inspection. The diversity of the datasets is the foundation for developing comprehensive IAD algorithms. Existing IAD datasets focus on the diversity of data categories, overlooking the diversity of domains within the same data category. In this paper, to bridge this gap, we propose the Aero-engine Blade Anomaly Detection (AeBAD) dataset, consisting of two sub-datasets: the single-blade dataset and the video anomaly detection dataset of blades. Compared to existing datasets, AeBAD has the following two characteristics: 1.) The target samples are not aligned and at different scales. 2.) There is a domain shift between the distribution of normal samples in the test set and the training set, where the domain shifts are mainly caused by the changes in illumination and view. Based on this dataset, we observe that current state-of-the-art (SOTA) IAD methods exhibit limitations when the domain of normal samples in the test set undergoes a shift. To address this issue, we propose a novel method called masked multi-scale reconstruction (MMR), which enhances the model's capacity to deduce causality among patches in normal samples by a masked reconstruction task. MMR achieves superior performance compared to SOTA methods on the AeBAD dataset. Furthermore, MMR achieves competitive performance with SOTA methods to detect the anomalies of different types on the MVTec AD dataset. Code and dataset are available at https://github.com/zhangzilongc/MMR.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02216v1","tag":"data-quality"}}
{"title":"Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT","abstract":"The amount of data has growing significance in exploring cutting-edge materials and a number of datasets have been generated either by hand or automated approaches. However, the materials science field struggles to effectively utilize the abundance of data, especially in applied disciplines where materials are evaluated based on device performance rather than their properties. This article presents a new natural language processing (NLP) task called structured information inference (SII) to address the complexities of information extraction at the device level in materials science. We accomplished this task by tuning GPT-3 on an existing perovskite solar cell FAIR (Findable, Accessible, Interoperable, Reusable) dataset with 91.8% F1-score and extended the dataset with data published since its release. The produced data is formatted and normalized, enabling its direct utilization as input in subsequent data analysis. This feature empowers materials scientists to develop models by selecting high-quality review articles within their domain. Additionally, we designed experiments to predict the electrical performance of solar cells and design materials or devices with targeted parameters using large language models (LLMs). Our results demonstrate comparable performance to traditional machine learning methods without feature selection, highlighting the potential of LLMs to acquire scientific knowledge and design new materials akin to materials scientists.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02213v5","tag":"data-quality"}}
{"title":"MoocRadar: A Fine-grained and Multi-aspect Knowledge Repository for Improving Cognitive Student Modeling in MOOCs","abstract":"Student modeling, the task of inferring a student's learning characteristics through their interactions with coursework, is a fundamental issue in intelligent education. Although the recent attempts from knowledge tracing and cognitive diagnosis propose several promising directions for improving the usability and effectiveness of current models, the existing public datasets are still insufficient to meet the need for these potential solutions due to their ignorance of complete exercising contexts, fine-grained concepts, and cognitive labels. In this paper, we present MoocRadar, a fine-grained, multi-aspect knowledge repository consisting of 2,513 exercise questions, 5,600 knowledge concepts, and over 12 million behavioral records. Specifically, we propose a framework to guarantee a high-quality and comprehensive annotation of fine-grained concepts and cognitive labels. The statistical and experimental results indicate that our dataset provides the basis for the future improvements of existing methods. Moreover, to support the convenient usage for researchers, we release a set of tools for data querying, model adaption, and even the extension of our repository, which are now available at https://github.com/THU-KEG/MOOC-Radar.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02205v1","tag":"data-quality"}}
{"title":"Towards Self-Explainability of Deep Neural Networks with Heatmap Captioning and Large-Language Models","abstract":"Heatmaps are widely used to interpret deep neural networks, particularly for computer vision tasks, and the heatmap-based explainable AI (XAI) techniques are a well-researched topic. However, most studies concentrate on enhancing the quality of the generated heatmap or discovering alternate heatmap generation techniques, and little effort has been devoted to making heatmap-based XAI automatic, interactive, scalable, and accessible. To address this gap, we propose a framework that includes two modules: (1) context modelling and (2) reasoning. We proposed a template-based image captioning approach for context modelling to create text-based contextual information from the heatmap and input data. The reasoning module leverages a large language model to provide explanations in combination with specialised knowledge. Our qualitative experiments demonstrate the effectiveness of our framework and heatmap captioning approach. The code for the proposed template-based heatmap captioning approach will be publicly available.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02202v1","tag":"data-quality"}}
{"title":"Synthesize Extremely High-dimensional Longitudinal Electronic Health Records via Hierarchical Autoregressive Language Model","abstract":"Synthetic electronic health records (EHRs) that are both realistic and preserve privacy can serve as an alternative to real EHRs for machine learning (ML) modeling and statistical analysis. However, generating high-fidelity and granular electronic health record (EHR) data in its original, highly-dimensional form poses challenges for existing methods due to the complexities inherent in high-dimensional data. In this paper, we propose Hierarchical Autoregressive Language mOdel (HALO) for generating longitudinal high-dimensional EHR, which preserve the statistical properties of real EHR and can be used to train accurate ML models without privacy concerns. Our HALO method, designed as a hierarchical autoregressive model, generates a probability density function of medical codes, clinical visits, and patient records, allowing for the generation of realistic EHR data in its original, unaggregated form without the need for variable selection or aggregation. Additionally, our model also produces high-quality continuous variables in a longitudinal and probabilistic manner. We conducted extensive experiments and demonstrate that HALO can generate high-fidelity EHR data with high-dimensional disease code probabilities (d > 10,000), disease co-occurrence probabilities within visits (d > 1,000,000), and conditional probabilities across consecutive visits (d > 5,000,000) and achieve above 0.9 R2 correlation in comparison to real EHR data. This performance then enables downstream ML models trained on its synthetic data to achieve comparable accuracy to models trained on real data (0.938 AUROC with HALO data vs. 0.943 with real data). Finally, using a combination of real and synthetic data enhances the accuracy of ML models beyond that achieved by using only real EHR data.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.02169v1","tag":"data-quality"}}
{"title":"GINA-3D: Learning to Generate Implicit Neural Assets in the Wild","abstract":"Modeling the 3D world from sensor data for simulation is a scalable way of developing testing and validation environments for robotic learning problems such as autonomous driving. However, manually creating or re-creating real-world-like environments is difficult, expensive, and not scalable. Recent generative model techniques have shown promising progress to address such challenges by learning 3D assets using only plentiful 2D images -- but still suffer limitations as they leverage either human-curated image datasets or renderings from manually-created synthetic 3D environments. In this paper, we introduce GINA-3D, a generative model that uses real-world driving data from camera and LiDAR sensors to create realistic 3D implicit neural assets of diverse vehicles and pedestrians. Compared to the existing image datasets, the real-world driving setting poses new challenges due to occlusions, lighting-variations and long-tail distributions. GINA-3D tackles these challenges by decoupling representation learning and generative modeling into two stages with a learned tri-plane latent structure, inspired by recent advances in generative modeling of images. To evaluate our approach, we construct a large-scale object-centric dataset containing over 520K images of vehicles and pedestrians from the Waymo Open Dataset, and a new set of 80K images of long-tail instances such as construction equipment, garbage trucks, and cable cars. We compare our model with existing approaches and demonstrate that it achieves state-of-the-art performance in quality and diversity for both generated images and geometries.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.02163v1","tag":"data-quality"}}
{"title":"Initialization Approach for Nonlinear State-Space Identification via the Subspace Encoder Approach","abstract":"The SUBNET neural network architecture has been developed to identify nonlinear state-space models from input-output data. To achieve this, it combines the rolled-out nonlinear state-space equations and a state encoder function, both parameterised as neural networks The encoder function is introduced to reconstruct the current state from past input-output data. Hence, it enables the forward simulation of the rolled-out state-space model. While this approach has shown to provide high-accuracy and consistent model estimation, its convergence can be significantly improved by efficient initialization of the training process. This paper focuses on such an initialisation of the subspace encoder approach using the Best Linear Approximation (BLA). Using the BLA provided state-space matrices and its associated reconstructability map, both the state-transition part of the network and the encoder are initialized. The performance of the improved initialisation scheme is evaluated on a Wiener-Hammerstein simulation example and a benchmark dataset. The results show that for a weakly nonlinear system, the proposed initialisation based on the linear reconstructability map results in a faster convergence and a better model quality.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.02119v2","tag":"data-quality"}}
{"title":"Statistics of extreme events in coarse-scale climate simulations via machine learning correction operators trained on nudged datasets","abstract":"This work presents a systematic framework for improving the predictions of statistical quantities for turbulent systems, with a focus on correcting climate simulations obtained by coarse-scale models. While high resolution simulations or reanalysis data are available, they cannot be directly used as training datasets to machine learn a correction for the coarse-scale climate model outputs, since chaotic divergence, inherent in the climate dynamics, makes datasets from different resolutions incompatible. To overcome this fundamental limitation we employ coarse-resolution model simulations nudged towards high quality climate realizations, here in the form of ERA5 reanalysis data. The nudging term is sufficiently small to not pollute the coarse-scale dynamics over short time scales, but also sufficiently large to keep the coarse-scale simulations close to the ERA5 trajectory over larger time scales. The result is a compatible pair of the ERA5 trajectory and the weakly nudged coarse-resolution E3SM output that is used as input training data to machine learn a correction operator. Once training is complete, we perform free-running coarse-scale E3SM simulations without nudging and use those as input to the machine-learned correction operator to obtain high-quality (corrected) outputs. The model is applied to atmospheric climate data with the purpose of predicting global and local statistics of various quantities of a time-period of a decade. Using datasets that are not employed for training, we demonstrate that the produced datasets from the ML-corrected coarse E3SM model have statistical properties that closely resemble the observations. Furthermore, the corrected coarse-scale E3SM output for the frequency of occurrence of extreme events, such as tropical cyclones and atmospheric rivers are presented. We present thorough comparisons and discuss limitations of the approach.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.02117v1","tag":"data-quality"}}
{"title":"Scalable Online Learning of Approximate Stackelberg Solutions in Energy Trading Games with Demand Response Aggregators","abstract":"In this work, a Stackelberg game theoretic framework is proposed for trading energy bidirectionally between the demand-response (DR) aggregator and the prosumers. This formulation allows for flexible energy arbitrage and additional monetary rewards while ensuring that the prosumers' desired daily energy demand is met. Then, a scalable (with the number of prosumers) approach is proposed to find approximate equilibria based on online sampling and learning of the prosumers' cumulative best response. Moreover, bounds are provided on the quality of the approximate equilibrium solution. Last, real-world data from the California day-ahead energy market and the University of California at Davis building energy demands are utilized to demonstrate the efficacy of the proposed framework and the online scalable solution.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.02086v1","tag":"data-quality"}}
{"title":"Scalable and Accurate Self-supervised Multimodal Representation Learning without Aligned Video and Text Data","abstract":"Scaling up weakly-supervised datasets has shown to be highly effective in the image-text domain and has contributed to most of the recent state-of-the-art computer vision and multimodal neural networks. However, existing large-scale video-text datasets and mining techniques suffer from several limitations, such as the scarcity of aligned data, the lack of diversity in the data, and the difficulty of collecting aligned data. Currently popular video-text data mining approach via automatic speech recognition (ASR) used in HowTo100M provides low-quality captions that often do not refer to the video content. Other mining approaches do not provide proper language descriptions (video tags) and are biased toward short clips (alt text). In this work, we show how recent advances in image captioning allow us to pre-train high-quality video models without any parallel video-text data. We pre-train several video captioning models that are based on an OPT language model and a TimeSformer visual backbone. We fine-tune these networks on several video captioning datasets. First, we demonstrate that image captioning pseudolabels work better for pre-training than the existing HowTo100M ASR captions. Second, we show that pre-training on both images and videos produces a significantly better network (+4 CIDER on MSR-VTT) than pre-training on a single modality. Our methods are complementary to the existing pre-training or data mining approaches and can be used in a variety of settings. Given the efficacy of the pseudolabeling method, we are planning to publicly release the generated captions.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.02080v1","tag":"data-quality"}}
{"title":"Albatross: A scalable simulation-based inference pipeline for analysing stellar streams in the Milky Way","abstract":"Stellar streams are potentially a very sensitive observational probe of galactic astrophysics, as well as the dark matter population in the Milky Way. On the other hand, performing a detailed, high-fidelity statistical analysis of these objects is challenging for a number of key reasons. Firstly, the modelling of streams across their (potentially billions of years old) dynamical age is complex and computationally costly. Secondly, their detection and classification in large surveys such as Gaia renders a robust statistical description regarding e.g., the stellar membership probabilities, challenging. As a result, the majority of current analyses must resort to simplified models that use only subsets or summaries of the high quality data. In this work, we develop a new analysis framework that takes advantage of advances in simulation-based inference techniques to perform complete analysis on complex stream models. To facilitate this, we develop a new, modular dynamical modelling code sstrax for stellar streams that is highly accelerated using jax. We test our analysis pipeline on a mock observation that resembles the GD1 stream, and demonstrate that we can perform robust inference on all relevant parts of the stream model simultaneously. Finally, we present some outlook as to how this approach can be developed further to perform more complete and accurate statistical analyses of current and future data.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.02032v1","tag":"data-quality"}}
{"title":"Cross-modulated Few-shot Image Generation for Colorectal Tissue Classification","abstract":"In this work, we propose a few-shot colorectal tissue image generation method for addressing the scarcity of histopathological training data for rare cancer tissues. Our few-shot generation method, named XM-GAN, takes one base and a pair of reference tissue images as input and generates high-quality yet diverse images. Within our XM-GAN, a novel controllable fusion block densely aggregates local regions of reference images based on their similarity to those in the base image, resulting in locally consistent features. To the best of our knowledge, we are the first to investigate few-shot generation in colorectal tissue images. We evaluate our few-shot colorectral tissue image generation by performing extensive qualitative, quantitative and subject specialist (pathologist) based evaluations. Specifically, in specialist-based evaluation, pathologists could differentiate between our XM-GAN generated tissue images and real images only 55% time. Moreover, we utilize these generated images as data augmentation to address the few-shot tissue image classification task, achieving a gain of 4.4% in terms of mean accuracy over the vanilla few-shot classifier. Code: \\url{https://github.com/VIROBO-15/XM-GAN}","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01992v1","tag":"data-quality"}}
{"title":"Model-corrected learned primal-dual models for fast limited-view photoacoustic tomography","abstract":"Learned iterative reconstructions hold great promise to accelerate tomographic imaging with empirical robustness to model perturbations. Nevertheless, an adoption for photoacoustic tomography is hindered by the need to repeatedly evaluate the computational expensive forward model. Computational feasibility can be obtained by the use of fast approximate models, but a need to compensate model errors arises. In this work we advance the methodological and theoretical basis for model corrections in learned image reconstructions by embedding the model correction in a learned primal-dual framework. Here, the model correction is jointly learned in data space coupled with a learned updating operator in image space within an unrolled end-to-end learned iterative reconstruction approach. The proposed formulation allows an extension to a primal-dual deep equilibrium model providing fixed-point convergence as well as reduced memory requirements for training. We provide theoretical and empirical insights into the proposed models with numerical validation in a realistic 2D limited-view setting. The model-corrected learned primal-dual methods show excellent reconstruction quality with fast inference times and thus providing a methodological basis for real-time capable and scalable iterative reconstructions in photoacoustic tomography.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01963v1","tag":"data-quality"}}
{"title":"Online Time-Windows TSP with Predictions","abstract":"In the Time-Windows TSP (TW-TSP) we are given requests at different locations on a network; each request is endowed with a reward and an interval of time; the goal is to find a tour that visits as much reward as possible during the corresponding time window. For the online version of this problem, where each request is revealed at the start of its time window, no finite competitive ratio can be obtained. We consider a version of the problem where the algorithm is presented with predictions of where and when the online requests will appear, without any knowledge of the quality of this side information.   Vehicle routing problems such as the TW-TSP can be very sensitive to errors or changes in the input due to the hard time-window constraints, and it is unclear whether imperfect predictions can be used to obtain a finite competitive ratio. We show that good performance can be achieved by explicitly building slack into the solution. Our main result is an online algorithm that achieves a competitive ratio logarithmic in the diameter of the underlying network, matching the performance of the best offline algorithm to within factors that depend on the quality of the provided predictions. The competitive ratio degrades smoothly as a function of the quality and we show that this dependence is tight within constant factors.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01958v1","tag":"data-quality"}}
{"title":"PODIA-3D: Domain Adaptation of 3D Generative Model Across Large Domain Gap Using Pose-Preserved Text-to-Image Diffusion","abstract":"Recently, significant advancements have been made in 3D generative models, however training these models across diverse domains is challenging and requires an huge amount of training data and knowledge of pose distribution. Text-guided domain adaptation methods have allowed the generator to be adapted to the target domains using text prompts, thereby obviating the need for assembling numerous data. Recently, DATID-3D presents impressive quality of samples in text-guided domain, preserving diversity in text by leveraging text-to-image diffusion. However, adapting 3D generators to domains with significant domain gaps from the source domain still remains challenging due to issues in current text-to-image diffusion models as following: 1) shape-pose trade-off in diffusion-based translation, 2) pose bias, and 3) instance bias in the target domain, resulting in inferior 3D shapes, low text-image correspondence, and low intra-domain diversity in the generated samples. To address these issues, we propose a novel pipeline called PODIA-3D, which uses pose-preserved text-to-image diffusion-based domain adaptation for 3D generative models. We construct a pose-preserved text-to-image diffusion model that allows the use of extremely high-level noise for significant domain changes. We also propose specialized-to-general sampling strategies to improve the details of the generated samples. Moreover, to overcome the instance bias, we introduce a text-guided debiasing method that improves intra-domain diversity. Consequently, our method successfully adapts 3D generators across significant domain gaps. Our qualitative results and user study demonstrates that our approach outperforms existing 3D text-guided domain adaptation methods in terms of text-image correspondence, realism, diversity of rendered images, and sense of depth of 3D shapes in the generated samples","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01900v1","tag":"data-quality"}}
{"title":"A Practical Framework for Unsupervised Structure Preservation Medical Image Enhancement","abstract":"Medical images are extremely valuable for supporting medical diagnoses. However, in practice, low-quality (LQ) medical images, such as images that are hazy/blurry, have uneven illumination, or are out of focus, among others, are often obtained during data acquisition. This leads to difficulties in the screening and diagnosis of medical diseases. Several generative adversarial networks (GAN)-based image enhancement methods have been proposed and have shown promising results. However, there is a quality-originality trade-off among these methods in the sense that they produce visually pleasing results but lose the ability to preserve originality, especially the structural inputs. Moreover, to our knowledge, there is no objective metric in evaluating the structure preservation of medical image enhancement methods in unsupervised settings due to the unavailability of paired ground-truth data. In this study, we propose a framework for practical unsupervised medical image enhancement that includes (1) a non-reference objective evaluation of structure preservation for medical image enhancement tasks called Laplacian structural similarity index measure (LaSSIM), which is based on SSIM and the Laplacian pyramid, and (2) a novel unsupervised GAN-based method called Laplacian medical image enhancement (LaMEGAN) to support the improvement of both originality and quality from LQ images. The LaSSIM metric does not require clean reference images and has been shown to be superior to SSIM in capturing image structural changes under image degradations, such as strong blurring on different datasets. The experiments demonstrated that our LaMEGAN achieves a satisfactory balance between quality and originality, with robust structure preservation performance while generating compelling visual results with very high image quality scores. The code will be made available at https://github.com/AillisInc/USPMIE.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01864v1","tag":"data-quality"}}
{"title":"HyperCUT: Video Sequence from a Single Blurry Image using Unsupervised Ordering","abstract":"We consider the challenging task of training models for image-to-video deblurring, which aims to recover a sequence of sharp images corresponding to a given blurry image input. A critical issue disturbing the training of an image-to-video model is the ambiguity of the frame ordering since both the forward and backward sequences are plausible solutions. This paper proposes an effective self-supervised ordering scheme that allows training high-quality image-to-video deblurring models. Unlike previous methods that rely on order-invariant losses, we assign an explicit order for each video sequence, thus avoiding the order-ambiguity issue. Specifically, we map each video sequence to a vector in a latent high-dimensional space so that there exists a hyperplane such that for every video sequence, the vectors extracted from it and its reversed sequence are on different sides of the hyperplane. The side of the vectors will be used to define the order of the corresponding sequence. Last but not least, we propose a real-image dataset for the image-to-video deblurring problem that covers a variety of popular domains, including face, hand, and street. Extensive experimental results confirm the effectiveness of our method. Code and data are available at https://github.com/VinAIResearch/HyperCUT.git","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01686v2","tag":"data-quality"}}
{"title":"Analysis of Software Engineering Practices in General Software and Machine Learning Startups","abstract":"Context: On top of the inherent challenges startup software companies face applying proper software engineering practices, the non-deterministic nature of machine learning techniques makes it even more difficult for machine learning (ML) startups.   Objective: Therefore, the objective of our study is to understand the whole picture of software engineering practices followed by ML startups and identify additional needs.   Method: To achieve our goal, we conducted a systematic literature review study on 37 papers published in the last 21 years. We selected papers on both general software startups and ML startups. We collected data to understand software engineering (SE) practices in five phases of the software development life-cycle: requirement engineering, design, development, quality assurance, and deployment.   Results: We find some interesting differences in software engineering practices in ML startups and general software startups. The data management and model learning phases are the most prominent among them.   Conclusion: While ML startups face many similar challenges to general software startups, the additional difficulties of using stochastic ML models require different strategies in using software engineering practices to produce high-quality products.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01523v1","tag":"data-quality"}}
{"title":"End-to-End Latency Optimization of Multi-view 3D Reconstruction for Disaster Response","abstract":"In order to plan rapid response during disasters, first responder agencies often adopt `bring your own device' (BYOD) model with inexpensive mobile edge devices (e.g., drones, robots, tablets) for complex video analytics applications, e.g., 3D reconstruction of a disaster scene. Unlike simpler video applications, widely used Multi-view Stereo (MVS) based 3D reconstruction applications (e.g., openMVG/openMVS) are exceedingly time consuming, especially when run on such computationally constrained mobile edge devices. Additionally, reducing the reconstruction latency of such inherently sequential algorithms is challenging as unintelligent, application-agnostic strategies can drastically degrade the reconstruction (i.e., application outcome) quality making them useless. In this paper, we aim to design a latency optimized MVS algorithm pipeline, with the objective to best balance the end-to-end latency and reconstruction quality by running the pipeline on a collaborative mobile edge environment. The overall optimization approach is two-pronged where: (a) application optimizations introduce data-level parallelism by splitting the pipeline into high frequency and low frequency reconstruction components and (b) system optimizations incorporate task-level parallelism to the pipelines by running them opportunistically on available resources with online quality control in order to balance both latency and quality. Our evaluation on a hardware testbed using publicly available datasets shows upto ~54% reduction in latency with negligible loss (~4-7%) in reconstruction quality.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01488v1","tag":"data-quality"}}
{"title":"Hierarchical Supervision and Shuffle Data Augmentation for 3D Semi-Supervised Object Detection","abstract":"State-of-the-art 3D object detectors are usually trained on large-scale datasets with high-quality 3D annotations. However, such 3D annotations are often expensive and time-consuming, which may not be practical for real applications. A natural remedy is to adopt semi-supervised learning (SSL) by leveraging a limited amount of labeled samples and abundant unlabeled samples. Current pseudolabeling-based SSL object detection methods mainly adopt a teacher-student framework, with a single fixed threshold strategy to generate supervision signals, which inevitably brings confused supervision when guiding the student network training. Besides, the data augmentation of the point cloud in the typical teacher-student framework is too weak, and only contains basic down sampling and flip-and-shift (i.e., rotate and scaling), which hinders the effective learning of feature information. Hence, we address these issues by introducing a novel approach of Hierarchical Supervision and Shuffle Data Augmentation (HSSDA), which is a simple yet effective teacher-student framework. The teacher network generates more reasonable supervision for the student network by designing a dynamic dual-threshold strategy. Besides, the shuffle data augmentation strategy is designed to strengthen the feature representation ability of the student network. Extensive experiments show that HSSDA consistently outperforms the recent state-of-the-art methods on different datasets. The code will be released at https://github.com/azhuantou/HSSDA.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01464v1","tag":"data-quality"}}
{"title":"Matched Machine Learning: A Generalized Framework for Treatment Effect Inference With Learned Metrics","abstract":"We introduce Matched Machine Learning, a framework that combines the flexibility of machine learning black boxes with the interpretability of matching, a longstanding tool in observational causal inference. Interpretability is paramount in many high-stakes application of causal inference. Current tools for nonparametric estimation of both average and individualized treatment effects are black-boxes that do not allow for human auditing of estimates. Our framework uses machine learning to learn an optimal metric for matching units and estimating outcomes, thus achieving the performance of machine learning black-boxes, while being interpretable. Our general framework encompasses several published works as special cases. We provide asymptotic inference theory for our proposed framework, enabling users to construct approximate confidence intervals around estimates of both individualized and average treatment effects. We show empirically that instances of Matched Machine Learning perform on par with black-box machine learning methods and better than existing matching methods for similar problems. Finally, in our application we show how Matched Machine Learning can be used to perform causal inference even when covariate data are highly complex: we study an image dataset, and produce high quality matches and estimates of treatment effects.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.01316v1","tag":"data-quality"}}
{"title":"PEACH: Pre-Training Sequence-to-Sequence Multilingual Models for Translation with Semi-Supervised Pseudo-Parallel Document Generation","abstract":"Multilingual pre-training significantly improves many multilingual NLP tasks, including machine translation. Most existing methods are based on some variants of masked language modeling and text-denoising objectives on monolingual data. Multilingual pre-training on monolingual data ignores the availability of parallel data in many language pairs. Also, some other works integrate the available human-generated parallel translation data in their pre-training. This kind of parallel data is definitely helpful, but it is limited even in high-resource language pairs. This paper introduces a novel semi-supervised method, SPDG, that generates high-quality pseudo-parallel data for multilingual pre-training. First, a denoising model is pre-trained on monolingual data to reorder, add, remove, and substitute words, enhancing the pre-training documents' quality. Then, we generate different pseudo-translations for each pre-training document using dictionaries for word-by-word translation and applying the pre-trained denoising model. The resulting pseudo-parallel data is then used to pre-train our multilingual sequence-to-sequence model, PEACH. Our experiments show that PEACH outperforms existing approaches used in training mT5 and mBART on various translation tasks, including supervised, zero- and few-shot scenarios. Moreover, PEACH's ability to transfer knowledge between similar languages makes it particularly useful for low-resource languages. Our results demonstrate that with high-quality dictionaries for generating accurate pseudo-parallel, PEACH can be valuable for low-resource languages.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.01282v2","tag":"data-quality"}}
{"title":"Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data","abstract":"Chat models, such as ChatGPT, have shown impressive capabilities and have been rapidly adopted across numerous domains. However, these models are only accessible through a restricted API, creating barriers for new research and progress in the field. We propose a pipeline that can automatically generate a high-quality multi-turn chat corpus by leveraging ChatGPT to engage in a conversation with itself. Subsequently, we employ parameter-efficient tuning to enhance LLaMA, an open-source large language model. The resulting model, named Baize, demonstrates good performance in multi-turn dialogues with guardrails that minimize potential risks. The Baize models and data are released for research purposes only at https://github.com/project-baize/baize. An online demo is also available at https://huggingface.co/spaces/project-baize/baize-lora-7B.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.01196v2","tag":"data-quality"}}
{"title":"Distance-based Analysis of Machine Learning Prediction Reliability for Datasets in Materials Science and Other Fields","abstract":"Despite successful use in a wide variety of disciplines for data analysis and prediction, machine learning (ML) methods suffer from a lack of understanding of the reliability of predictions due to the lack of transparency and black-box nature of ML models. In materials science and other fields, typical ML model results include a significant number of low-quality predictions. This problem is known to be particularly acute for target systems which differ significantly from the data used for ML model training. However, to date, a general method for characterization of the difference between the predicted and training system has not been available. Here, we show that a simple metric based on Euclidean feature space distance and sampling density allows effective separation of the accurately predicted data points from data points with poor prediction accuracy. We show that the metric effectiveness is enhanced by the decorrelation of the features using Gram-Schmidt orthogonalization. To demonstrate the generality of the method, we apply it to support vector regression models for various small data sets in materials science and other fields. Our method is computationally simple, can be used with any ML learning method and enables analysis of the sources of the ML prediction errors. Therefore, it is suitable for use as a standard technique for the estimation of ML prediction reliability for small data sets and as a tool for data set design.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.01146v1","tag":"data-quality"}}
{"title":"Measurement of Dielectric Loss in Silicon Nitride at Centimeter and Millimeter Wavelengths","abstract":"This work presents a suite of measurement techniques for characterizing the dielectric loss tangent across a wide frequency range from $\\sim$1 GHz to 150 GHz using the same test chip. In the first method, we fit data from a microwave resonator at different temperatures to a model that captures the two-level system (TLS) response to extract and characterize both the real and imaginary components of the dielectric loss. The inverse of the internal quality factor is a second measure of the overall loss of the resonator, where TLS loss through the dielectric material is typically the dominant source. The third technique is a differential optical measurement at 150 GHz. The same antenna feeds two microstrip lines with different lengths that terminate in two microwave kinetic inductance detectors (MKIDs). The difference in the detector response is used to estimate the loss per unit length of the microstrip line. Our results suggest a larger loss for SiN$_x$ at 150 GHz of ${\\mathrm{\\tan \\delta\\sim 4\\times10^{-3}}}$ compared to ${\\mathrm{2.0\\times10^{-3}}}$ and ${\\mathrm{\\gtrsim 1\\times10^{-3}}}$ measured at $\\sim$1 GHz using the other two methods. {These measurement techniques can be applied to other dielectrics by adjusting the microstrip lengths to provide enough optical efficiency contrast and other mm/sub-mm frequency ranges by tuning the antenna and feedhorn accordingly.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.01103v1","tag":"data-quality"}}
{"title":"Knowledge-Distilled Graph Neural Networks for Personalized Epileptic Seizure Detection","abstract":"Wearable devices for seizure monitoring detection could significantly improve the quality of life of epileptic patients. However, existing solutions that mostly rely on full electrode set of electroencephalogram (EEG) measurements could be inconvenient for every day use. In this paper, we propose a novel knowledge distillation approach to transfer the knowledge from a sophisticated seizure detector (called the teacher) trained on data from the full set of electrodes to learn new detectors (called the student). They are both providing lightweight implementations and significantly reducing the number of electrodes needed for recording the EEG. We consider the case where the teacher and the student seizure detectors are graph neural networks (GNN), since these architectures actively use the connectivity information. We consider two cases (a) when a single student is learnt for all the patients using preselected channels; and (b) when personalized students are learnt for every individual patient, with personalized channel selection using a Gumbelsoftmax approach. Our experiments on the publicly available Temple University Hospital EEG Seizure Data Corpus (TUSZ) show that both knowledge-distillation and personalization play significant roles in improving performance of seizure detection, particularly for patients with scarce EEG data. We observe that using as few as two channels, we are able to obtain competitive seizure detection performance. This, in turn, shows the potential of our approach in more realistic scenario of wearable devices for personalized monitoring of seizures, even with few recordings.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.06038v1","tag":"data-quality"}}
{"title":"ViT-DAE: Transformer-driven Diffusion Autoencoder for Histopathology Image Analysis","abstract":"Generative AI has received substantial attention in recent years due to its ability to synthesize data that closely resembles the original data source. While Generative Adversarial Networks (GANs) have provided innovative approaches for histopathological image analysis, they suffer from limitations such as mode collapse and overfitting in discriminator. Recently, Denoising Diffusion models have demonstrated promising results in computer vision. These models exhibit superior stability during training, better distribution coverage, and produce high-quality diverse images. Additionally, they display a high degree of resilience to noise and perturbations, making them well-suited for use in digital pathology, where images commonly contain artifacts and exhibit significant variations in staining. In this paper, we present a novel approach, namely ViT-DAE, which integrates vision transformers (ViT) and diffusion autoencoders for high-quality histopathology image synthesis. This marks the first time that ViT has been introduced to diffusion autoencoders in computational pathology, allowing the model to better capture the complex and intricate details of histopathology images. We demonstrate the effectiveness of ViT-DAE on three publicly available datasets. Our approach outperforms recent GAN-based and vanilla DAE methods in generating realistic images.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.01053v1","tag":"data-quality"}}
{"title":"AMGC: Adaptive match-based genomic compression algorithm","abstract":"Motivation: Despite significant advances in Third-Generation Sequencing (TGS) technologies, Next-Generation Sequencing (NGS) technologies remain dominant in the current sequencing market. This is due to the lower error rates and richer analytical software of NGS than that of TGS. NGS technologies generate vast amounts of genomic data including short reads, quality values and read identifiers. As a result, efficient compression of such data has become a pressing need, leading to extensive research efforts focused on designing FASTQ compressors. Previous researches show that lossless compression of quality values seems to reach its limits. But there remain lots of room for the compression of the reads part. Results: By investigating the characters of the sequencing process, we present a new algorithm for compressing reads in FASTQ files, which can be integrated into various genomic compression tools. We first reviewed the pipeline of reference-based algorithms and identified three key components that heavily impact storage: the matching positions of reads on the reference sequence(refpos), the mismatched positions of bases on reads(mispos) and the matching failed reads(unmapseq). To reduce their sizes, we conducted a detailed analysis of the distribution of matching positions and sequencing errors and then developed the three modules of AMGC. According to the experiment results, AMGC outperformed the current state-of-the-art methods, achieving an 81.23% gain in compression ratio on average compared with the second-best-performing compressor.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.01031v1","tag":"data-quality"}}
{"title":"Efficient human-in-loop deep learning model training with iterative refinement and statistical result validation","abstract":"Annotation and labeling of images are some of the biggest challenges in applying deep learning to medical data. Current processes are time and cost-intensive and, therefore, a limiting factor for the wide adoption of the technology. Additionally validating that measured performance improvements are significant is important to select the best model. In this paper, we demonstrate a method for creating segmentations, a necessary part of a data cleaning for ultrasound imaging machine learning pipelines. We propose a four-step method to leverage automatically generated training data and fast human visual checks to improve model accuracy while keeping the time/effort and cost low. We also showcase running experiments multiple times to allow the usage of statistical analysis. Poor quality automated ground truth data and quick visual inspections efficiently train an initial base model, which is refined using a small set of more expensive human-generated ground truth data. The method is demonstrated on a cardiac ultrasound segmentation task, removing background data, including static PHI. Significance is shown by running the experiments multiple times and using the student's t-test on the performance distributions. The initial segmentation accuracy of a simple thresholding algorithm of 92% was improved to 98%. The performance of models trained on complicated algorithms can be matched or beaten by pre-training with the poorer performing algorithms and a small quantity of high-quality data. The introduction of statistic significance analysis for deep learning models helps to validate the performance improvements measured. The method offers a cost-effective and fast approach to achieving high-accuracy models while minimizing the cost and effort of acquiring high-quality training data.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.00990v1","tag":"data-quality"}}
{"title":"Autonomous Power Line Inspection with Drones via Perception-Aware MPC","abstract":"Drones have the potential to revolutionize power line inspection by increasing productivity, reducing inspection time, improving data quality, and eliminating the risks for human operators. Current state-of-the-art systems for power line inspection have two shortcomings: (i) control is decoupled from perception and needs accurate information about the location of the power lines and masts; (ii) collision avoidance is decoupled from the power line tracking, which results in poor tracking in the vicinity of the power masts, and, consequently, in decreased data quality for visual inspection. In this work, we propose a model predictive controller (MPC) that overcomes these limitations by tightly coupling perception and action. Our controller generates commands that maximize the visibility of the power lines while, at the same time, safely avoiding the power masts. For power line detection, we propose a lightweight learning-based detector that is trained only on synthetic data and is able to transfer zero-shot to real-world power line images. We validate our system in simulation and real-world experiments on a mock-up power line infrastructure.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.00959v1","tag":"data-quality"}}
{"title":"Semi-Automated Computer Vision based Tracking of Multiple Industrial Entities -- A Framework and Dataset Creation Approach","abstract":"This contribution presents the TOMIE framework (Tracking Of Multiple Industrial Entities), a framework for the continuous tracking of industrial entities (e.g., pallets, crates, barrels) over a network of, in this example, six RGB cameras. This framework, makes use of multiple sensors, data pipelines and data annotation procedures, and is described in detail in this contribution. With the vision of a fully automated tracking system for industrial entities in mind, it enables researchers to efficiently capture high quality data in an industrial setting. Using this framework, an image dataset, the TOMIE dataset, is created, which at the same time is used to gauge the framework's validity. This dataset contains annotation files for 112,860 frames and 640,936 entity instances that are captured from a set of six cameras that perceive a large indoor space. This dataset out-scales comparable datasets by a factor of four and is made up of scenarios, drawn from industrial applications from the sector of warehousing. Three tracking algorithms, namely ByteTrack, Bot-Sort and SiamMOT are applied to this dataset, serving as a proof-of-concept and providing tracking results that are comparable to the state of the art.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.00950v1","tag":"data-quality"}}
{"title":"Knowledge Accumulation in Continually Learned Representations and the Issue of Feature Forgetting","abstract":"By default, neural networks learn on all training data at once. When such a model is trained on sequential chunks of new data, it tends to catastrophically forget how to handle old data. In this work we investigate how continual learners learn and forget representations. We observe two phenomena: knowledge accumulation, i.e. the improvement of a representation over time, and feature forgetting, i.e. the loss of task-specific representations. To better understand both phenomena, we introduce a new analysis technique called task exclusion comparison. If a model has seen a task and it has not forgotten all the task-specific features, then its representation for that task should be better than that of a model that was trained on similar tasks, but not that exact one. Our image classification experiments show that most task-specific features are quickly forgotten, in contrast to what has been suggested in the past. Further, we demonstrate how some continual learning methods, like replay, and ideas from representation learning affect a continually learned representation. We conclude by observing that representation quality is tightly correlated with continual learning performance.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.00933v1","tag":"data-quality"}}
{"title":"Diffusion Bridge Mixture Transports, Schr\u00f6dinger Bridge Problems and Generative Modeling","abstract":"The dynamic Schr\\\"odinger bridge problem seeks a stochastic process that defines a transport between two target probability measures, while optimally satisfying the criteria of being closest, in terms of Kullback-Leibler divergence, to a reference process.   We propose a novel sampling-based iterative algorithm, the iterated diffusion bridge mixture transport (IDBM), aimed at solving the dynamic Schr\\\"odinger bridge problem. The IDBM procedure exhibits the attractive property of realizing a valid coupling between the target measures at each step. We perform an initial theoretical investigation of the IDBM procedure, establishing its convergence properties. The theoretical findings are complemented by numerous numerical experiments illustrating the competitive performance of the IDBM procedure across various applications.   Recent advancements in generative modeling employ the time-reversal of a diffusion process to define a generative process that approximately transports a simple distribution to the data distribution. As an alternative, we propose using the first iteration of the IDBM procedure as an approximation-free method for realizing this transport. This approach offers greater flexibility in selecting the generative process dynamics and exhibits faster training and superior sample quality over longer discretization intervals. In terms of implementation, the necessary modifications are minimally intrusive, being limited to the training loss computation, with no changes necessary for generative sampling.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.00917v1","tag":"data-quality"}}
{"title":"Adoption of Artificial Intelligence in Schools: Unveiling Factors Influencing Teachers Engagement","abstract":"Albeit existing evidence about the impact of AI-based adaptive learning platforms, their scaled adoption in schools is slow at best. In addition, AI tools adopted in schools may not always be the considered and studied products of the research community. Therefore, there have been increasing concerns about identifying factors influencing adoption, and studying the extent to which these factors can be used to predict teachers engagement with adaptive learning platforms. To address this, we developed a reliable instrument to measure more holistic factors influencing teachers adoption of adaptive learning platforms in schools. In addition, we present the results of its implementation with school teachers (n=792) sampled from a large country-level population and use this data to predict teachers real-world engagement with the adaptive learning platform in schools. Our results show that although teachers knowledge, confidence and product quality are all important factors, they are not necessarily the only, may not even be the most important factors influencing the teachers engagement with AI platforms in schools. Not generating any additional workload, in-creasing teacher ownership and trust, generating support mechanisms for help, and assuring that ethical issues are minimised, are also essential for the adoption of AI in schools and may predict teachers engagement with the platform better. We conclude the paper with a discussion on the value of factors identified to increase the real-world adoption and effectiveness of adaptive learning platforms by increasing the dimensions of variability in prediction models and decreasing the implementation variability in practice.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.00903v2","tag":"data-quality"}}
{"title":"Accuracy is not the only Metric that matters: Estimating the Energy Consumption of Deep Learning Models","abstract":"Modern machine learning models have started to consume incredible amounts of energy, thus incurring large carbon footprints (Strubell et al., 2019). To address this issue, we have created an energy estimation pipeline1, which allows practitioners to estimate the energy needs of their models in advance, without actually running or training them. We accomplished this, by collecting high-quality energy data and building a first baseline model, capable of predicting the energy consumption of DL models by accumulating their estimated layer-wise energies.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.00897v1","tag":"data-quality"}}
{"title":"Population size estimation with capture-recapture in presence of individual misidentification and low recapture","abstract":"While non-invasive sampling is more and more commonly used in capture-recapture (CR) experiments, it carries a higher risk of misidentifications than direct observations. As a consequence, one must screen the data to retain only the reliable data before applying a classical CR model. This procedure is unacceptable when too few data would remain. Models able to deal with misidentifications have been proposed but are barely used. Three objectives are pursued in this paper. First, we present the Latent Multinomial Model of Link et al. (2010) where estimates of the model are obtained from a Monte Carlo Markov Chain (MCMC). Second we show the impact of the use of an informative prior over the estimations when the capture rate is low. Finally we extend the model to the multistate paradigm as an example of its flexibility.   We showed that, without prior information, with capture rate at 0.2 or lower, parameters of the model are difficult to estimate i.e. either the MCMC does not converge or the estimates are biased. In that case, we show that adding an informative prior on the identification probability solves the identifiability problem of the model and allow for convergence. It also allows for good quality estimates of population size, although when the capture rate is 0.1 it underestimates it of about 10%. A similar approach on the multistate extension show good quality estimates of the population size and transition probabilities with a capture rate of 0.3 or more.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.00885v1","tag":"data-quality"}}
{"title":"MetaHead: An Engine to Create Realistic Digital Head","abstract":"Collecting and labeling training data is one important step for learning-based methods because the process is time-consuming and biased. For face analysis tasks, although some generative models can be used to generate face data, they can only achieve a subset of generation diversity, reconstruction accuracy, 3D consistency, high-fidelity visual quality, and easy editability. One recent related work is the graphics-based generative method, but it can only render low realism head with high computation cost. In this paper, we propose MetaHead, a unified and full-featured controllable digital head engine, which consists of a controllable head radiance field(MetaHead-F) to super-realistically generate or reconstruct view-consistent 3D controllable digital heads and a generic top-down image generation framework LabelHead to generate digital heads consistent with the given customizable feature labels. Experiments validate that our controllable digital head engine achieves the state-of-the-art generation visual quality and reconstruction accuracy. Moreover, the generated labeled data can assist real training data and significantly surpass the labeled data generated by graphics-based methods in terms of training effect.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.00838v1","tag":"data-quality"}}
{"title":"Disentangled Pre-training for Image Matting","abstract":"Image matting requires high-quality pixel-level human annotations to support the training of a deep model in recent literature. Whereas such annotation is costly and hard to scale, significantly holding back the development of the research. In this work, we make the first attempt towards addressing this problem, by proposing a self-supervised pre-training approach that can leverage infinite numbers of data to boost the matting performance. The pre-training task is designed in a similar manner as image matting, where random trimap and alpha matte are generated to achieve an image disentanglement objective. The pre-trained model is then used as an initialisation of the downstream matting task for fine-tuning. Extensive experimental evaluations show that the proposed approach outperforms both the state-of-the-art matting methods and other alternative self-supervised initialisation approaches by a large margin. We also show the robustness of the proposed approach over different backbone architectures. The code and models will be publicly available.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.00784v1","tag":"data-quality"}}
{"title":"CG-3DSRGAN: A classification guided 3D generative adversarial network for image quality recovery from low-dose PET images","abstract":"Positron emission tomography (PET) is the most sensitive molecular imaging modality routinely applied in our modern healthcare. High radioactivity caused by the injected tracer dose is a major concern in PET imaging and limits its clinical applications. However, reducing the dose leads to inadequate image quality for diagnostic practice. Motivated by the need to produce high quality images with minimum low-dose, Convolutional Neural Networks (CNNs) based methods have been developed for high quality PET synthesis from its low-dose counterparts. Previous CNNs-based studies usually directly map low-dose PET into features space without consideration of different dose reduction level. In this study, a novel approach named CG-3DSRGAN (Classification-Guided Generative Adversarial Network with Super Resolution Refinement) is presented. Specifically, a multi-tasking coarse generator, guided by a classification head, allows for a more comprehensive understanding of the noise-level features present in the low-dose data, resulting in improved image synthesis. Moreover, to recover spatial details of standard PET, an auxiliary super resolution network - Contextual-Net - is proposed as a second-stage training to narrow the gap between coarse prediction and standard PET. We compared our method to the state-of-the-art methods on whole-body PET with different dose reduction factors (DRFs). Experiments demonstrate our method can outperform others on all DRF.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.00725v1","tag":"data-quality"}}
{"title":"D-Score: A White-Box Diagnosis Score for CNNs Based on Mutation Operators","abstract":"Convolutional neural networks (CNNs) have been widely applied in many safety-critical domains, such as autonomous driving and medical diagnosis. However, concerns have been raised with respect to the trustworthiness of these models: The standard testing method evaluates the performance of a model on a test set, while low-quality and insufficient test sets can lead to unreliable evaluation results, which can have unforeseeable consequences. Therefore, how to comprehensively evaluate CNNs and, based on the evaluation results, how to enhance their trustworthiness are the key problems to be urgently addressed. Prior work has used mutation tests to evaluate the test sets of CNNs. However, the evaluation scores are black boxes and not explicit enough for what is being tested. In this paper, we propose a white-box diagnostic approach that uses mutation operators and image transformation to calculate the feature and attention distribution of the model and further present a diagnosis score, namely D-Score, to reflect the model's robustness and fitness to a dataset. We also propose a D-Score based data augmentation method to enhance the CNN's performance to translations and rescalings. Comprehensive experiments on two widely used datasets and three commonly adopted CNNs demonstrate the effectiveness of our approach.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.00697v1","tag":"data-quality"}}
{"title":"Accuracy Improvement of Object Detection in VVC Coded Video Using YOLO-v7 Features","abstract":"With advances in image recognition technology based on deep learning, automatic video analysis by Artificial Intelligence is becoming more widespread. As the amount of video used for image recognition increases, efficient compression methods for such video data are necessary. In general, when the image quality deteriorates due to image encoding, the image recognition accuracy also falls. Therefore, in this paper, we propose a neural-network-based approach to improve image recognition accuracy, especially the object detection accuracy by applying post-processing to the encoded video. Versatile Video Coding (VVC) will be used for the video compression method, since it is the latest video coding method with the best encoding performance. The neural network is trained using the features of YOLO-v7, the latest object detection model. By using VVC as the video coding method and YOLO-v7 as the detection model, high object detection accuracy is achieved even at low bit rates. Experimental results show that the combination of the proposed method and VVC achieves better coding performance than regular VVC in object detection accuracy.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.00689v1","tag":"data-quality"}}
{"title":"DNN-based Denial of Quality of Service Attack on Software-defined Hybrid Edge-Cloud Systems","abstract":"In order to satisfy diverse quality-of-service (QoS) requirements of complex real-time video applications, civilian and tactical use cases are employing software-defined hybrid edge-cloud systems. One of the primary QoS requirements of such applications is ultra-low end-to-end latency for video applications that necessitates rapid frame transfer between end-devices and edge servers using software-defined networking (SDN). Failing to guarantee such strict requirements leads to quality degradation of video applications and subsequently mission failure. In this paper, we show how a collaborative group of attackers can exploit SDN's control communications to launch Denial of Quality of Service (DQoS) attack that artificially increases end-to-end latency of video frames and yet evades detection. In particular, we show how Deep Neural Network (DNN) model training on all or partial network state information can help predict network packet drop rates with reasonable accuracy. We also show how such predictions can help design an attack model that can inflict just the right amount of added latency to the end-to-end video processing that is enough to cause considerable QoS degradation but not too much to raise suspicion. We use a realistic edge-cloud testbed on GENI platform for training data collection and demonstration of high model accuracy and attack success rate.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.00677v1","tag":"data-quality"}}
{"title":"FedFTN: Personalized Federated Learning with Deep Feature Transformation Network for Multi-institutional Low-count PET Denoising","abstract":"Low-count PET is an efficient way to reduce radiation exposure and acquisition time, but the reconstructed images often suffer from low signal-to-noise ratio (SNR), thus affecting diagnosis and other downstream tasks. Recent advances in deep learning have shown great potential in improving low-count PET image quality, but acquiring a large, centralized, and diverse dataset from multiple institutions for training a robust model is difficult due to privacy and security concerns of patient data. Moreover, low-count PET data at different institutions may have different data distribution, thus requiring personalized models. While previous federated learning (FL) algorithms enable multi-institution collaborative training without the need of aggregating local data, addressing the large domain shift in the application of multi-institutional low-count PET denoising remains a challenge and is still highly under-explored. In this work, we propose FedFTN, a personalized federated learning strategy that addresses these challenges. FedFTN uses a local deep feature transformation network (FTN) to modulate the feature outputs of a globally shared denoising network, enabling personalized low-count PET denoising for each institution. During the federated learning process, only the denoising network's weights are communicated and aggregated, while the FTN remains at the local institutions for feature transformation. We evaluated our method using a large-scale dataset of multi-institutional low-count PET imaging data from three medical centers located across three continents, and showed that FedFTN provides high-quality low-count PET images, outperforming previous baseline FL reconstruction methods across all low-count levels at all three institutions.","created":"2023-04-02","meta":{"link":"http://arxiv.org/abs/2304.00570v1","tag":"data-quality"}}
{"title":"Semi-supervised Neural Machine Translation with Consistency Regularization for Low-Resource Languages","abstract":"The advent of deep learning has led to a significant gain in machine translation. However, most of the studies required a large parallel dataset which is scarce and expensive to construct and even unavailable for some languages. This paper presents a simple yet effective method to tackle this problem for low-resource languages by augmenting high-quality sentence pairs and training NMT models in a semi-supervised manner. Specifically, our approach combines the cross-entropy loss for supervised learning with KL Divergence for unsupervised fashion given pseudo and augmented target sentences derived from the model. We also introduce a SentenceBERT-based filter to enhance the quality of augmenting data by retaining semantically similar sentence pairs. Experimental results show that our approach significantly improves NMT baselines, especially on low-resource datasets with 0.46--2.03 BLEU scores. We also demonstrate that using unsupervised training for augmented data is more efficient than reusing the ground-truth target sentences for supervised learning.","created":"2023-04-02","meta":{"link":"http://arxiv.org/abs/2304.00557v1","tag":"data-quality"}}
{"title":"FANS: Fast Non-Autoregressive Sequence Generation for Item List Continuation","abstract":"User-curated item lists, such as video-based playlists on Youtube and book-based lists on Goodreads, have become prevalent for content sharing on online platforms. Item list continuation is proposed to model the overall trend of a list and predict subsequent items. Recently, Transformer-based models have shown promise in comprehending contextual information and capturing item relationships in a list. However, deploying them in real-time industrial applications is challenging, mainly because the autoregressive generation mechanism used in them is time-consuming. In this paper, we propose a novel fast non-autoregressive sequence generation model, namely FANS, to enhance inference efficiency and quality for item list continuation. First, we use a non-autoregressive generation mechanism to decode next $K$ items simultaneously instead of one by one in existing models. Then, we design a two-stage classifier to replace the vanilla classifier used in current transformer-based models to further reduce the decoding time. Moreover, to improve the quality of non-autoregressive generation, we employ a curriculum learning strategy to optimize training. Experimental results on four real-world item list continuation datasets including Zhihu, Spotify, AotM, and Goodreads show that our FANS model can significantly improve inference efficiency (up to 8.7x) while achieving competitive or better generation quality for item list continuation compared with the state-of-the-art autoregressive models. We also validate the efficiency of FANS in an industrial setting. Our source code and data will be available at MindSpore/models and Github.","created":"2023-04-02","meta":{"link":"http://arxiv.org/abs/2304.00545v1","tag":"data-quality"}}
{"title":"A Survey on Federated Learning for the Healthcare Metaverse: Concepts, Applications, Challenges, and Future Directions","abstract":"Recent technological advancements have considerately improved healthcare systems to provide various intelligent healthcare services and improve the quality of life. Federated learning (FL), a new branch of artificial intelligence (AI), opens opportunities to deal with privacy issues in healthcare systems and exploit data and computing resources available at distributed devices. Additionally, the Metaverse, through integrating emerging technologies, such as AI, cloud edge computing, Internet of Things (IoT), blockchain, and semantic communications, has transformed many vertical domains in general and the healthcare sector in particular. Obviously, FL shows many benefits and provides new opportunities for conventional and Metaverse healthcare, motivating us to provide a survey on the usage of FL for Metaverse healthcare systems. First, we present preliminaries to IoT-based healthcare systems, FL in conventional healthcare, and Metaverse healthcare. The benefits of FL in Metaverse healthcare are then discussed, from improved privacy and scalability, better interoperability, better data management, and extra security to automation and low-latency healthcare services. Subsequently, we discuss several applications pertaining to FL-enabled Metaverse healthcare, including medical diagnosis, patient monitoring, medical education, infectious disease, and drug discovery. Finally, we highlight significant challenges and potential solutions toward the realization of FL in Metaverse healthcare.","created":"2023-04-02","meta":{"link":"http://arxiv.org/abs/2304.00524v2","tag":"data-quality"}}
{"title":"Rotating labeling of entropy coders for synthetic DNA data storage","abstract":"Over the past years, the ever-growing trend on data storage demand, more specifically for \"cold\" data (i.e. rarely accessed), has motivated research for alternative systems of data storage. Because of its biochemical characteristics, synthetic DNA molecules are considered as potential candidates for a new storage paradigm. Because of this trend, several coding solutions have been proposed over the past years for the storage of digital information into DNA. Despite being a promising solution, DNA storage faces two major obstacles: the large cost of synthesis and the noise introduced during sequencing. Additionally, this noise increases when biochemically defined coding constraints are not respected: avoiding homopolymers and patterns, as well as balancing the GC content. This paper describes a novel entropy coder which can be embedded to any block-based image-coding schema and aims to robustify the decoded results. Our proposed solution introduces variability in the generated quaternary streams, reduces the amount of homopolymers and repeated patterns to reduce the probability of errors occurring. In this paper, we integrate the proposed entropy coder into four existing JPEG-inspired DNA coders. We then evaluate the quality -- in terms of biochemical constraints -- of the encoded data for all the different methods.","created":"2023-04-02","meta":{"link":"http://arxiv.org/abs/2304.00493v1","tag":"data-quality"}}
{"title":"A Data-centric Framework for Improving Domain-specific Machine Reading Comprehension Datasets","abstract":"Low-quality data can cause downstream problems in high-stakes applications. Data-centric approach emphasizes on improving dataset quality to enhance model performance. High-quality datasets are needed for general-purpose Large Language Models (LLMs) training, as well as for domain-specific models, which are usually small in size as it is costly to engage a large number of domain experts for their creation. Thus, it is vital to ensure high-quality domain-specific training data. In this paper, we propose a framework for enhancing the data quality of original datasets. We applied the proposed framework to four biomedical datasets and showed relative improvement of up to 33%/40% for fine-tuning of retrieval/reader models on the BioASQ dataset when using back translation to enhance the original dataset quality.","created":"2023-04-02","meta":{"link":"http://arxiv.org/abs/2304.00483v1","tag":"data-quality"}}
{"title":"Mini-batch $k$-means terminates within $O(d/\u03b5)$ iterations","abstract":"We answer the question: \"Does local progress (on batches) imply global progress (on the entire dataset) for mini-batch $k$-means?\". Specifically, we consider mini-batch $k$-means which terminates only when the improvement in the quality of the clustering on the sampled batch is below some threshold.   Although at first glance it appears that this algorithm might execute forever, we answer the above question in the affirmative and show that if the batch is of size $\\tilde{\\Omega}((d/\\epsilon)^2)$, it must terminate within $O(d/\\epsilon)$ iterations with high probability, where $d$ is the dimension of the input, and $\\epsilon$ is a threshold parameter for termination. This is true regardless of how the centers are initialized. When the algorithm is initialized with the $k$-means++ initialization scheme, it achieves an approximation ratio of $O(\\log k)$ (the same as the full-batch version).   Finally, we show the applicability of our results to the mini-batch $k$-means algorithm implemented in the scikit-learn (sklearn) python library.","created":"2023-04-02","meta":{"link":"http://arxiv.org/abs/2304.00419v1","tag":"data-quality"}}
{"title":"NeuroDAVIS: A neural network model for data visualization","abstract":"The task of dimensionality reduction and visualization of high-dimensional datasets remains a challenging problem since long. Modern high-throughput technologies produce newer high-dimensional datasets having multiple views with relatively new data types. Visualization of these datasets require proper methodology that can uncover hidden patterns in the data without affecting the local and global structures within the data. To this end, however, very few such methodology exist, which can realise this task. In this work, we have introduced a novel unsupervised deep neural network model, called NeuroDAVIS, for data visualization. NeuroDAVIS is capable of extracting important features from the data, without assuming any data distribution, and visualize effectively in lower dimension. It has been shown theoritically that neighbourhood relationship of the data in high dimension remains preserved in lower dimension. The performance of NeuroDAVIS has been evaluated on a wide variety of synthetic and real high-dimensional datasets including numeric, textual, image and biological data. NeuroDAVIS has been highly competitive against both t-Distributed Stochastic Neighbor Embedding (t-SNE) and Uniform Manifold Approximation and Projection (UMAP) with respect to visualization quality, and preservation of data size, shape, and both local and global structure. It has outperformed Fast interpolation-based t-SNE (Fit-SNE), a variant of t-SNE, for most of the high-dimensional datasets as well. For the biological datasets, besides t-SNE, UMAP and Fit-SNE, NeuroDAVIS has also performed well compared to other state-of-the-art algorithms, like Potential of Heat-diffusion for Affinity-based Trajectory Embedding (PHATE) and the siamese neural network-based method, called IVIS. Downstream classification and clustering analyses have also revealed favourable results for NeuroDAVIS-generated embeddings.","created":"2023-04-01","meta":{"link":"http://arxiv.org/abs/2304.01222v1","tag":"data-quality"}}
{"title":"HaLP: Hallucinating Latent Positives for Skeleton-based Self-Supervised Learning of Actions","abstract":"Supervised learning of skeleton sequence encoders for action recognition has received significant attention in recent times. However, learning such encoders without labels continues to be a challenging problem. While prior works have shown promising results by applying contrastive learning to pose sequences, the quality of the learned representations is often observed to be closely tied to data augmentations that are used to craft the positives. However, augmenting pose sequences is a difficult task as the geometric constraints among the skeleton joints need to be enforced to make the augmentations realistic for that action. In this work, we propose a new contrastive learning approach to train models for skeleton-based action recognition without labels. Our key contribution is a simple module, HaLP - to Hallucinate Latent Positives for contrastive learning. Specifically, HaLP explores the latent space of poses in suitable directions to generate new positives. To this end, we present a novel optimization formulation to solve for the synthetic positives with an explicit control on their hardness. We propose approximations to the objective, making them solvable in closed form with minimal overhead. We show via experiments that using these generated positives within a standard contrastive learning framework leads to consistent improvements across benchmarks such as NTU-60, NTU-120, and PKU-II on tasks like linear evaluation, transfer learning, and kNN evaluation. Our code will be made available at https://github.com/anshulbshah/HaLP.","created":"2023-04-01","meta":{"link":"http://arxiv.org/abs/2304.00387v1","tag":"data-quality"}}
{"title":"Human-Centric Resource Allocation in the Metaverse over Wireless Communications","abstract":"The Metaverse will provide numerous immersive applications for human users, by consolidating technologies like extended reality (XR), video streaming, and cellular networks. Optimizing wireless communications to enable the human-centric Metaverse is important to satisfy the demands of mobile users. In this paper, we formulate the optimization of the system utility-cost ratio (UCR) for the Metaverse over wireless networks. Our human-centric utility measure for virtual reality (VR) applications of the Metaverse represents users' perceptual assessment of the VR video quality as a function of the data rate and the video resolution, and is learnt from real datasets. The variables jointly optimized in our problem include the allocation of both communication and computation resources as well as VR video resolutions. The system cost in our problem comprises the energy consumption and delay, and is non-convex with respect to the optimization variables due to fractions in the mathematical expressions. To solve the non-convex optimization, we develop a novel fractional programming technique, which contributes to optimization theory and has broad applicability beyond our paper. Our proposed algorithm for the system UCR optimization is computationally efficient and finds a stationary point to the constrained optimization. Through extensive simulations, our algorithm is demonstrated to outperform other approaches.","created":"2023-04-01","meta":{"link":"http://arxiv.org/abs/2304.00355v1","tag":"data-quality"}}
{"title":"Medical Pathologies Prediction : Systematic Review and Proposed Approach","abstract":"The healthcare sector is an important pillar of every community, numerous research studies have been carried out in this context to optimize medical processes and improve care quality and facilitate patient management. In this article we have analyzed and examined different works concerning the exploitation of the most recent technologies such as big data, artificial intelligence, machine learning, and deep learning for the improvement of health care, which enabled us to propose our general approach concentrating on the collection, preprocessing and clustering of medical data to facilitate access, after analysis, to the patients and health professionals to predict the most frequent pathologies with better precision within a notable timeframe.   keywords: Healthcare, big data, artificial intelligence, automatic language processing, data mining, predictive models.","created":"2023-04-01","meta":{"link":"http://arxiv.org/abs/2304.00311v1","tag":"data-quality"}}
{"title":"BioSequence2Vec: Efficient Embedding Generation For Biological Sequences","abstract":"Representation learning is an important step in the machine learning pipeline. Given the current biological sequencing data volume, learning an explicit representation is prohibitive due to the dimensionality of the resulting feature vectors. Kernel-based methods, e.g., SVM, are a proven efficient and useful alternative for several machine learning (ML) tasks such as sequence classification. Three challenges with kernel methods are (i) the computation time, (ii) the memory usage (storing an $n\\times n$ matrix), and (iii) the usage of kernel matrices limited to kernel-based ML methods (difficult to generalize on non-kernel classifiers). While (i) can be solved using approximate methods, challenge (ii) remains for typical kernel methods. Similarly, although non-kernel-based ML methods can be applied to kernel matrices by extracting principal components (kernel PCA), it may result in information loss, while being computationally expensive. In this paper, we propose a general-purpose representation learning approach that embodies kernel methods' qualities while avoiding computation, memory, and generalizability challenges. This involves computing a low-dimensional embedding of each sequence, using random projections of its $k$-mer frequency vectors, significantly reducing the computation needed to compute the dot product and the memory needed to store the resulting representation. Our proposed fast and alignment-free embedding method can be used as input to any distance (e.g., $k$ nearest neighbors) and non-distance (e.g., decision tree) based ML method for classification and clustering tasks. Using different forms of biological sequences as input, we perform a variety of real-world classification tasks, such as SARS-CoV-2 lineage and gene family classification, outperforming several state-of-the-art embedding and kernel methods in predictive performance.","created":"2023-04-01","meta":{"link":"http://arxiv.org/abs/2304.00291v1","tag":"data-quality"}}
{"title":"Cluster aggregates surrounding Pismis 5 in the Vela Molecular Ridge","abstract":"Context. In the Gaia era, the precision of astrometric data is unprecedented. High-quality data make it easier to find more cluster aggregates and support further confirmation of these open clusters. Aims. We use Gaia DR3 to redetermine the open clusters surrounding Pismis 5 in the Vela Molecular Ridge. We also investigate the basic properties of these clusters. Methods. We apply two clustering algorithms (StarGO and pyUPMASK) to identify the open cluster members in a five-dimensional space with Gaia DR3. Results. We identify eight open clusters surrounding Pismis 5 in the Vela Molecular Ridge. The open cluster QZ 1 is newly discovered. Through investigating the comprehensive properties of the clusters, one open binary cluster candidate (Alessi 43 and Collinder 197) and one triple open cluster candidate (Pismis 5, Pismis 5A, and Pismis 5B) are discussed. Conclusions. Binary and triple open cluster candidates have been identified as potential primordial aggregates based on their similar age, position, and motion. According to kinematic speculations, the two aggregate candidates will gradually separate, and their interiors will slowly disintegrate.","created":"2023-04-01","meta":{"link":"http://arxiv.org/abs/2304.00226v1","tag":"data-quality"}}
{"title":"Subject-driven Text-to-Image Generation via Apprenticeship Learning","abstract":"Recent text-to-image generation models like DreamBooth have made remarkable progress in generating highly customized images of a target subject, by fine-tuning an ``expert model'' for a given subject from a few examples. However, this process is expensive, since a new expert model must be learned for each subject. In this paper, we present SuTI, a Subject-driven Text-to-Image generator that replaces subject-specific fine tuning with \\emph{in-context} learning. Given a few demonstrations of a new subject, SuTI can instantly generate novel renditions of the subject in different scenes, without any subject-specific optimization. SuTI is powered by {\\em apprenticeship learning}, where a single apprentice model is learned from data generated by massive amount of subject-specific expert models. Specifically, we mine millions of image clusters from the Internet, each centered around a specific visual subject. We adopt these clusters to train massive amount of expert models specialized on different subjects. The apprentice model SuTI then learns to mimic the behavior of these experts through the proposed apprenticeship learning algorithm. SuTI can generate high-quality and customized subject-specific images 20x faster than optimization-based SoTA methods. On the challenging DreamBench and DreamBench-v2, our human evaluation shows that SuTI can significantly outperform existing approaches like InstructPix2Pix, Textual Inversion, Imagic, Prompt2Prompt, Re-Imagen while performing on par with DreamBooth.","created":"2023-04-01","meta":{"link":"http://arxiv.org/abs/2304.00186v2","tag":"data-quality"}}
{"title":"Reconstructing firm-level input-output networks from partial information","abstract":"There is a large consensus on the fundamental role of firm-level supply chain networks in macroeconomics. However, data on supply chains at the fine-grained, firm level are scarce and frequently incomplete. For listed firms, some commercial datasets exist but only contain information about the existence of a trade relationship between two companies, not the value of the monetary transaction. We use a recently developed maximum entropy method to reconstruct the values of the transactions based on information about their existence and aggregate information disclosed by firms in financial statements. We test the method on the administrative dataset of Ecuador and reconstruct a commercial dataset (FactSet). We test the method's performance on the weights, the technical and allocation coefficients (microscale quantities), two measures of firms' systemic importance and GDP volatility. The method reconstructs the distribution of microscale quantities reasonably well but shows diverging results for the measures of firms' systemic importance. Due to the network structure of supply chains and the sampling process of firms and links, quantities relying on the number of customers firms have (out-degrees) are harder to reconstruct. We also reconstruct the input-output table of globally listed firms and merge it with a global input-output table at the sector level (the WIOD). Differences in accounting standards between national accounts and firms' financial statements significantly reduce the quality of the reconstruction.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2304.00081v1","tag":"data-quality"}}
{"title":"A 1.3% distance to M33 from HST Cepheid photometry","abstract":"We present a low-dispersion period-luminosity relation (PL) based on 154 Cepheids in Messier 33 (M33) with Hubble Space Telescope (HST) photometry from the PHATTER survey. Using high-quality ground-based light curves, we recover Cepheid phases and amplitudes for multi-epoch HST data and we perform template fitting to derive intensity-averaged mean magnitudes. HST observations in the SH0ES near-infrared Wesenheit system significantly reduce the effect of crowding relative to ground-based data, as seen in the final PL scatter of $\\sigma$ = 0.11 mag. We adopt the absolute calibration of the PL based on HST observations in the Large Magellanic Cloud (LMC) and a distance derived using late-type detached eclipsing binaries to obtain a distance modulus for M33 of $\\mu$ = 24.622 $\\pm$ 0.030 mag (d = 840 $\\pm$ 11 kpc), a best-to-date precision of 1.3%. We find very good agreement with past Cepheid-based measurements. Several TRGB estimates bracket our result while disagreeing with each other. Finally, we show that the flux contribution from star clusters hosting Cepheids in M33 does not impact the distance measurement and we find only 3.7% of the sample is located in (or nearby) young clusters. M33 offers one of the best sites for the cross-calibration of many primary distance indicators. Thus, a precise independent geometric determination of its distance would provide a valuable new anchor to measure the Hubble constant.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2304.00037v1","tag":"data-quality"}}
{"title":"$\\infty$-Diff: Infinite Resolution Diffusion with Subsampled Mollified States","abstract":"We introduce $\\infty$-Diff, a generative diffusion model which directly operates on infinite resolution data. By randomly sampling subsets of coordinates during training and learning to denoise the content at those coordinates, a continuous function is learned that allows sampling at arbitrary resolutions. In contrast to other recent infinite resolution generative models, our approach operates directly on the raw data, not requiring latent vector compression for context, using hypernetworks, nor relying on discrete components. As such, our approach achieves significantly higher sample quality, as evidenced by lower FID scores, as well as being able to effectively scale to higher resolutions than the training data while retaining detail.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.18242v1","tag":"data-quality"}}
{"title":"SemHint-MD: Learning from Noisy Semantic Labels for Self-Supervised Monocular Depth Estimation","abstract":"Without ground truth supervision, self-supervised depth estimation can be trapped in a local minimum due to the gradient-locality issue of the photometric loss. In this paper, we present a framework to enhance depth by leveraging semantic segmentation to guide the network to jump out of the local minimum. Prior works have proposed to share encoders between these two tasks or explicitly align them based on priors like the consistency between edges in the depth and segmentation maps. Yet, these methods usually require ground truth or high-quality pseudo labels, which may not be easily accessible in real-world applications. In contrast, we investigate self-supervised depth estimation along with a segmentation branch that is supervised with noisy labels provided by models pre-trained with limited data. We extend parameter sharing from the encoder to the decoder and study the influence of different numbers of shared decoder parameters on model performance. Also, we propose to use cross-task information to refine current depth and segmentation predictions to generate pseudo-depth and semantic labels for training. The advantages of the proposed method are demonstrated through extensive experiments on the KITTI benchmark and a downstream task for endoscopic tissue deformation tracking.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.18219v1","tag":"data-quality"}}
{"title":"The Many Qualities of a New Directly Accessible Compression Scheme","abstract":"We present a new variable-length computation-friendly encoding scheme, named SFDC (Succinct Format with Direct aCcesibility), that supports direct and fast accessibility to any element of the compressed sequence and achieves compression ratios often higher than those offered by other solutions in the literature. The SFDC scheme provides a flexible and simple representation geared towards either practical efficiency or compression ratios, as required. For a text of length $n$ over an alphabet of size $\\sigma$ and a fixed parameter $\\lambda$, the access time of the proposed encoding is proportional to the length of the character's code-word, plus an expected $\\mathcal{O}((F_{\\sigma - \\lambda + 3} - 3)/F_{\\sigma+1})$ overhead, where $F_j$ is the $j$-th number of the Fibonacci sequence. In the overall it uses $N+\\mathcal{O}\\big(n \\left(\\lambda - (F_{\\sigma+3}-3)/F_{\\sigma+1}\\big) \\right) = N + \\mathcal{O}(n)$ bits, where $N$ is the length of the encoded string. Experimental results show that the performance of our scheme is, in some respects, comparable with the performance of DACs and Wavelet Tees, which are among of the most efficient schemes. In addition our scheme is configured as a \\emph{computation-friendly compression} scheme, as it counts several features that make it very effective in text processing tasks. In the string matching problem, that we take as a case study, we experimentally prove that the new scheme enables results that are up to 29 times faster than standard string-matching techniques on plain texts.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.18063v1","tag":"data-quality"}}
{"title":"No Place to Hide: Dual Deep Interaction Channel Network for Fake News Detection based on Data Augmentation","abstract":"Online Social Network (OSN) has become a hotbed of fake news due to the low cost of information dissemination. Although the existing methods have made many attempts in news content and propagation structure, the detection of fake news is still facing two challenges: one is how to mine the unique key features and evolution patterns, and the other is how to tackle the problem of small samples to build the high-performance model. Different from popular methods which take full advantage of the propagation topology structure, in this paper, we propose a novel framework for fake news detection from perspectives of semantic, emotion and data enhancement, which excavates the emotional evolution patterns of news participants during the propagation process, and a dual deep interaction channel network of semantic and emotion is designed to obtain a more comprehensive and fine-grained news representation with the consideration of comments. Meanwhile, the framework introduces a data enhancement module to obtain more labeled data with high quality based on confidence which further improves the performance of the classification model. Experiments show that the proposed approach outperforms the state-of-the-art methods.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.18049v1","tag":"data-quality"}}
{"title":"A versatile and reproducible cryo-sample preparation methodology for atom probe studies","abstract":"Repeatable and reliable site-specific preparation of specimens for atom probe tomography (APT) at cryogenic temperatures has proven challenging. A generalized workflow is required for cryogenic-specimen preparation including lift-out via focused-ion beam and in-situ deposition of capping layers, to strengthen specimens that will be exposed to high electric field and stresses during field evaporation in APT, and protect them from environment during transfer into the atom probe. Here, we build on existing protocols, and showcase preparation and analysis of a variety of metals, oxides and supported frozen liquids and battery materials. We demonstrate reliable in-situ deposition of a metallic capping layer that significantly improve the atom probe data quality for challenging material systems, particularly battery cathode materials which are subjected to delithiation during the atom probe analysis itself. Our workflow designed is versatile and transferable widely to other instruments.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.18048v1","tag":"data-quality"}}
{"title":"Online dynamic flat-field correction for MHz Microscopy data at European XFEL","abstract":"The X-ray microscopy technique at the European X-ray free-electron laser (EuXFEL), operating at a MHz repetition rate, provides superior contrast and spatial-temporal resolution compared to typical microscopy techniques at other X-ray sources. In both online visualization and offline data analysis for microscopy experiments, baseline normalization is essential for further processing steps such as phase retrieval and modal decomposition. In addition, access to normalized projections during data acquisition can play an important role in decision-making and improve the quality of the data. However, the stochastic nature of XFEL sources hinders the use of existing flat-flied normalization methods during MHz X-ray microscopy experiments. Here, we present an online dynamic flat-field correction method based on principal component analysis of dynamically evolving flat-field images. The method is used for the normalization of individual X-ray projections and has been implemented as an online analysis tool at the Single Particles, Clusters, and Biomolecules and Serial Femtosecond Crystallography (SPB/SFX) instrument of EuXFEL.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.18043v1","tag":"data-quality"}}
{"title":"Artificial Intelligence in Ovarian Cancer Histopathology: A Systematic Review","abstract":"Purpose - To characterise and assess the quality of published research evaluating artificial intelligence (AI) methods for ovarian cancer diagnosis or prognosis using histopathology data. Methods - A search of 5 sources was conducted up to 01/12/2022. The inclusion criteria required that research evaluated AI on histopathology images for diagnostic or prognostic inferences in ovarian cancer, including tubo-ovarian and peritoneal tumours. Reviews and non-English language articles were excluded. The risk of bias was assessed for every included model using PROBAST. Results - A total of 1434 research articles were identified, of which 36 were eligible for inclusion. These studies reported 62 models of interest, including 35 classifiers, 14 survival prediction models, 7 segmentation models, and 6 regression models. Models were developed using 1-1375 slides from 1-664 ovarian cancer patients. A wide array of outcomes were predicted, including overall survival (9/62), histological subtypes (7/62), stain quantity (6/62) and malignancy (5/62). Older studies used traditional machine learning (ML) models with hand-crafted features, while newer studies typically employed deep learning (DL) to automatically learn features and predict the outcome(s) of interest. All models were found to be at high or unclear risk of bias overall. Research was frequently limited by insufficient reporting, small sample sizes, and insufficient validation. Conclusion - Limited research has been conducted and none of the associated models have been demonstrated to be ready for real-world implementation. Recommendations are provided addressing underlying biases and flaws in study design, which should help inform higher-quality reproducible future research. Key aspects include more transparent and comprehensive reporting, and improved performance evaluation using cross-validation and external validations.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.18005v1","tag":"data-quality"}}
{"title":"VDN-NeRF: Resolving Shape-Radiance Ambiguity via View-Dependence Normalization","abstract":"We propose VDN-NeRF, a method to train neural radiance fields (NeRFs) for better geometry under non-Lambertian surface and dynamic lighting conditions that cause significant variation in the radiance of a point when viewed from different angles. Instead of explicitly modeling the underlying factors that result in the view-dependent phenomenon, which could be complex yet not inclusive, we develop a simple and effective technique that normalizes the view-dependence by distilling invariant information already encoded in the learned NeRFs. We then jointly train NeRFs for view synthesis with view-dependence normalization to attain quality geometry. Our experiments show that even though shape-radiance ambiguity is inevitable, the proposed normalization can minimize its effect on geometry, which essentially aligns the optimal capacity needed for explaining view-dependent variations. Our method applies to various baselines and significantly improves geometry without changing the volume rendering pipeline, even if the data is captured under a moving light source. Code is available at: https://github.com/BoifZ/VDN-NeRF.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.17968v1","tag":"data-quality"}}
{"title":"DoE2Vec: Deep-learning Based Features for Exploratory Landscape Analysis","abstract":"We propose DoE2Vec, a variational autoencoder (VAE)-based methodology to learn optimization landscape characteristics for downstream meta-learning tasks, e.g., automated selection of optimization algorithms. Principally, using large training data sets generated with a random function generator, DoE2Vec self-learns an informative latent representation for any design of experiments (DoE). Unlike the classical exploratory landscape analysis (ELA) method, our approach does not require any feature engineering and is easily applicable for high dimensional search spaces. For validation, we inspect the quality of latent reconstructions and analyze the latent representations using different experiments. The latent representations not only show promising potentials in identifying similar (cheap-to-evaluate) surrogate functions, but also can significantly boost performances when being used complementary to the classical ELA features in classification tasks.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2304.01219v1","tag":"data-quality"}}
{"title":"CIRCLE: Capture In Rich Contextual Environments","abstract":"Synthesizing 3D human motion in a contextual, ecological environment is important for simulating realistic activities people perform in the real world. However, conventional optics-based motion capture systems are not suited for simultaneously capturing human movements and complex scenes. The lack of rich contextual 3D human motion datasets presents a roadblock to creating high-quality generative human motion models. We propose a novel motion acquisition system in which the actor perceives and operates in a highly contextual virtual world while being motion captured in the real world. Our system enables rapid collection of high-quality human motion in highly diverse scenes, without the concern of occlusion or the need for physical scene construction in the real world. We present CIRCLE, a dataset containing 10 hours of full-body reaching motion from 5 subjects across nine scenes, paired with ego-centric information of the environment represented in various forms, such as RGBD videos. We use this dataset to train a model that generates human motion conditioned on scene information. Leveraging our dataset, the model learns to use ego-centric scene information to achieve nontrivial reaching tasks in the context of complex 3D scenes. To download the data please visit https://stanford-tml.github.io/circle_dataset/.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.17912v1","tag":"data-quality"}}
{"title":"Selective Knowledge Distillation for Non-Autoregressive Neural Machine Translation","abstract":"Benefiting from the sequence-level knowledge distillation, the Non-Autoregressive Transformer (NAT) achieves great success in neural machine translation tasks. However, existing knowledge distillation has side effects, such as propagating errors from the teacher to NAT students, which may limit further improvements of NAT models and are rarely discussed in existing research. In this paper, we introduce selective knowledge distillation by introducing an NAT evaluator to select NAT-friendly targets that are of high quality and easy to learn. In addition, we introduce a simple yet effective progressive distillation method to boost NAT performance. Experiment results on multiple WMT language directions and several representative NAT models show that our approach can realize a flexible trade-off between the quality and complexity of training data for NAT models, achieving strong performances. Further analysis shows that distilling only 5% of the raw translations can help an NAT outperform its counterpart trained on raw data by about 2.4 BLEU.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.17910v1","tag":"data-quality"}}
{"title":"3D-aware Image Generation using 2D Diffusion Models","abstract":"In this paper, we introduce a novel 3D-aware image generation method that leverages 2D diffusion models. We formulate the 3D-aware image generation task as multiview 2D image set generation, and further to a sequential unconditional-conditional multiview image generation process. This allows us to utilize 2D diffusion models to boost the generative modeling power of the method. Additionally, we incorporate depth information from monocular depth estimators to construct the training data for the conditional diffusion model using only still images. We train our method on a large-scale dataset, i.e., ImageNet, which is not addressed by previous methods. It produces high-quality images that significantly outperform prior methods. Furthermore, our approach showcases its capability to generate instances with large view angles, even though the training images are diverse and unaligned, gathered from \"in-the-wild\" real-world environments.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.17905v1","tag":"data-quality"}}
{"title":"Improved clinical data imputation via classical and quantum determinantal point processes","abstract":"Imputing data is a critical issue for machine learning practitioners, including in the life sciences domain, where missing clinical data is a typical situation and the reliability of the imputation is of great importance. Currently, there is no canonical approach for imputation of clinical data and widely used algorithms introduce variance in the downstream classification. Here we propose novel imputation methods based on determinantal point processes that enhance popular techniques such as the Multivariate Imputation by Chained Equations (MICE) and MissForest. Their advantages are two-fold: improving the quality of the imputed data demonstrated by increased accuracy of the downstream classification; and providing deterministic and reliable imputations that remove the variance from the classification results. We experimentally demonstrate the advantages of our methods by performing extensive imputations on synthetic and real clinical data. We also develop quantum circuits for implementing determinantal point processes, since such quantum algorithms provide a computational advantage with respect to classical ones. We demonstrate competitive results with up to ten qubits for small-scale imputation tasks on a state-of-the-art IBM quantum processor. Our classical and quantum methods improve the effectiveness and robustness of clinical data prediction modeling by providing better and more reliable data imputations. These improvements can add significant value in settings where where high precision is critical, such as in pharmaceutical drug trials where our approach can provide higher confidence in the predictions made.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.17893v1","tag":"data-quality"}}
{"title":"WebQAmGaze: A Multilingual Webcam Eye-Tracking-While-Reading Dataset","abstract":"We create WebQAmGaze, a multilingual low-cost eye-tracking-while-reading dataset, designed to support the development of fair and transparent NLP models. WebQAmGaze includes webcam eye-tracking data from 332 participants naturally reading English, Spanish, and German texts. Each participant performs two reading tasks composed of five texts, a normal reading and an information-seeking task. After preprocessing the data, we find that fixations on relevant spans seem to indicate correctness when answering the comprehension questions. Additionally, we perform a comparative analysis of the data collected to high-quality eye-tracking data. The results show a moderate correlation between the features obtained with the webcam-ET compared to those of a commercial ET device. We believe this data can advance webcam-based reading studies and open a way to cheaper and more accessible data collection. WebQAmGaze is useful to learn about the cognitive processes behind question answering (QA) and to apply these insights to computational models of language understanding.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.17876v2","tag":"data-quality"}}
{"title":"Architecture Smells vs. Concurrency Bugs: an Exploratory Study and Negative Results","abstract":"Technical debt occurs in many different forms across software artifacts. One such form is connected to software architectures where debt emerges in the form of structural anti-patterns across architecture elements, namely, architecture smells. As defined in the literature, ``Architecture smells are recurrent architectural decisions that negatively impact internal system quality\", thus increasing technical debt. In this paper, we aim at exploring whether there exist manifestations of architectural technical debt beyond decreased code or architectural quality, namely, whether there is a relation between architecture smells (which primarily reflect structural characteristics) and the occurrence of concurrency bugs (which primarily manifest at runtime). We study 125 releases of 5 large data-intensive software systems to reveal that (1) several architecture smells may in fact indicate the presence of concurrency problems likely to manifest at runtime but (2) smells are not correlated with concurrency in general -- rather, for specific concurrency bugs they must be combined with an accompanying articulation of specific project characteristics such as project distribution. As an example, a cyclic dependency could be present in the code, but the specific execution-flow could be never executed at runtime.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.17862v1","tag":"data-quality"}}
{"title":"WSense: A Robust Feature Learning Module for Lightweight Human Activity Recognition","abstract":"In recent times, various modules such as squeeze-and-excitation, and others have been proposed to improve the quality of features learned from wearable sensor signals. However, these modules often cause the number of parameters to be large, which is not suitable for building lightweight human activity recognition models which can be easily deployed on end devices. In this research, we propose a feature learning module, termed WSense, which uses two 1D CNN and global max pooling layers to extract similar quality features from wearable sensor data while ignoring the difference in activity recognition models caused by the size of the sliding window. Experiments were carried out using CNN and ConvLSTM feature learning pipelines on a dataset obtained with a single accelerometer (WISDM) and another obtained using the fusion of accelerometers, gyroscopes, and magnetometers (PAMAP2) under various sliding window sizes. A total of nine hundred sixty (960) experiments were conducted to validate the WSense module against baselines and existing methods on the two datasets. The results showed that the WSense module aided pipelines in learning similar quality features and outperformed the baselines and existing models with a minimal and uniform model size across all sliding window segmentations. The code is available at https://github.com/AOige/WSense.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.17845v1","tag":"data-quality"}}
{"title":"A Benchmark Generative Probabilistic Model for Weak Supervised Learning","abstract":"Finding relevant and high-quality datasets to train machine learning models is a major bottleneck for practitioners. Furthermore, to address ambitious real-world use-cases there is usually the requirement that the data come labelled with high-quality annotations that can facilitate the training of a supervised model. Manually labelling data with high-quality labels is generally a time-consuming and challenging task and often this turns out to be the bottleneck in a machine learning project. Weak Supervised Learning (WSL) approaches have been developed to alleviate the annotation burden by offering an automatic way of assigning approximate labels (pseudo-labels) to unlabelled data based on heuristics, distant supervision and knowledge bases. We apply probabilistic generative latent variable models (PLVMs), trained on heuristic labelling representations of the original dataset, as an accurate, fast and cost-effective way to generate pseudo-labels. We show that the PLVMs achieve state-of-the-art performance across four datasets. For example, they achieve 22% points higher F1 score than Snorkel in the class-imbalanced Spouse dataset. PLVMs are plug-and-playable and are a drop-in replacement to existing WSL frameworks (e.g. Snorkel) or they can be used as benchmark models for more complicated algorithms, giving practitioners a compelling accuracy boost.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.17841v1","tag":"data-quality"}}
{"title":"Improved Difference Images for Change Detection Classifiers in SAR Imagery Using Deep Learning","abstract":"Satellite-based Synthetic Aperture Radar (SAR) images can be used as a source of remote sensed imagery regardless of cloud cover and day-night cycle. However, the speckle noise and varying image acquisition conditions pose a challenge for change detection classifiers. This paper proposes a new method of improving SAR image processing to produce higher quality difference images for the classification algorithms. The method is built on a neural network-based mapping transformation function that produces artificial SAR images from a location in the requested acquisition conditions. The inputs for the model are: previous SAR images from the location, imaging angle information from the SAR images, digital elevation model, and weather conditions. The method was tested with data from a location in North-East Finland by using Sentinel-1 SAR images from European Space Agency, weather data from Finnish Meteorological Institute, and a digital elevation model from National Land Survey of Finland. In order to verify the method, changes to the SAR images were simulated, and the performance of the proposed method was measured using experimentation where it gave substantial improvements to performance when compared to a more conventional method of creating difference images.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.17835v1","tag":"data-quality"}}
{"title":"Lower and upper bounds for the joint batching, routing and sequencing problem","abstract":"Warehouses are nowadays the scene of complex logistic problems integrating different decision layers. This paper addresses the Joint Order Batching, Picker Routing and Sequencing Problem with Deadlines (JOBPRSP-D) in rectangular warehouses. To tackle the problem an exponential linear programming formulation is proposed. It is solved with a column generation heuristic able to provide valid lower and upper bounds on the optimal value. We start by showing that the JOBPRSP-D is related to the bin packing problem rather than the scheduling problem. We take advantage of this aspect to derive a number of valid inequalities that enhance the resolution of the master problem. The proposed algorithm is evaluated on publicly available data-sets. It is able to optimally solve instances with up to 18 orders in few minutes. It is also able to prove optimality or to provide high-quality lower bounds on larger instances with 100 orders. To the best of our knowledge this is the first paper that provides optimality guarantee on large size instances for the JOBPRSP-D, thus the results can be used to assert the quality of heuristics proposed for the same problem.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.17834v1","tag":"data-quality"}}
{"title":"LabelVizier: Interactive Validation and Relabeling for Technical Text Annotations","abstract":"With the rapid accumulation of text data produced by data-driven techniques, the task of extracting \"data annotations\"--concise, high-quality data summaries from unstructured raw text--has become increasingly important. The recent advances in weak supervision and crowd-sourcing techniques provide promising solutions to efficiently create annotations (labels) for large-scale technical text data. However, such annotations may fail in practice because of the change in annotation requirements, application scenarios, and modeling goals, where label validation and relabeling by domain experts are required. To approach this issue, we present LabelVizier, a human-in-the-loop workflow that incorporates domain knowledge and user-specific requirements to reveal actionable insights into annotation flaws, then produce better-quality labels for large-scale multi-label datasets. We implement our workflow as an interactive notebook to facilitate flexible error profiling, in-depth annotation validation for three error types, and efficient annotation relabeling on different data scales. We evaluated the efficiency and generalizability of our workflow with two use cases and four expert reviews. The results indicate that LabelVizier is applicable in various application scenarios and assist domain experts with different knowledge backgrounds to efficiently improve technical text annotation quality.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.17820v1","tag":"data-quality"}}
{"title":"A Novel Two-level Causal Inference Framework for On-road Vehicle Quality Issues Diagnosis","abstract":"In the automotive industry, the full cycle of managing in-use vehicle quality issues can take weeks to investigate. The process involves isolating root causes, defining and implementing appropriate treatments, and refining treatments if needed. The main pain-point is the lack of a systematic method to identify causal relationships, evaluate treatment effectiveness, and direct the next actionable treatment if the current treatment was deemed ineffective. This paper will show how we leverage causal Machine Learning (ML) to speed up such processes. A real-word data set collected from on-road vehicles will be used to demonstrate the proposed framework. Open challenges for vehicle quality applications will also be discussed.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2304.04755v1","tag":"data-quality"}}
{"title":"Label Propagation via Random Walk for Training Robust Thalamus Nuclei Parcellation Model from Noisy Annotations","abstract":"Data-driven thalamic nuclei parcellation depends on high-quality manual annotations. However, the small size and low contrast changes among thalamic nuclei, yield annotations that are often incomplete, noisy, or ambiguously labelled. To train a robust thalamic nuclei parcellation model with noisy annotations, we propose a label propagation algorithm based on random walker to refine the annotations before model training. A two-step model was trained to generate first the whole thalamus and then the nuclei masks. We conducted experiments on a mild traumatic brain injury~(mTBI) dataset with noisy thalamic nuclei annotations. Our model outperforms current state-of-the-art thalamic nuclei parcellations by a clear margin. We believe our method can also facilitate the training of other parcellation models with noisy labels.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17706v1","tag":"data-quality"}}
{"title":"Learning Garment DensePose for Robust Warping in Virtual Try-On","abstract":"Virtual try-on, i.e making people virtually try new garments, is an active research area in computer vision with great commercial applications. Current virtual try-on methods usually work in a two-stage pipeline. First, the garment image is warped on the person's pose using a flow estimation network. Then in the second stage, the warped garment is fused with the person image to render a new try-on image. Unfortunately, such methods are heavily dependent on the quality of the garment warping which often fails when dealing with hard poses (e.g., a person lifting or crossing arms). In this work, we propose a robust warping method for virtual try-on based on a learned garment DensePose which has a direct correspondence with the person's DensePose. Due to the lack of annotated data, we show how to leverage an off-the-shelf person DensePose model and a pretrained flow model to learn the garment DensePose in a weakly supervised manner. The garment DensePose allows a robust warping to any person's pose without any additional computation. Our method achieves the state-of-the-art equivalent on virtual try-on benchmarks and shows warping robustness on in-the-wild person images with hard poses, making it more suited for real-world virtual try-on applications.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17688v1","tag":"data-quality"}}
{"title":"Scalable High-Quality Hypergraph Partitioning","abstract":"Balanced hypergraph partitioning is an NP-hard problem with many applications, e.g., optimizing communication in distributed data placement problems. The goal is to place all nodes across $k$ different blocks of bounded size, such that hyperedges span as few parts as possible. This problem is well-studied in sequential and distributed settings, but not in shared-memory. We close this gap by devising efficient and scalable shared-memory algorithms for all components employed in the best sequential solvers without compromises with regards to solution quality.   This work presents the scalable and high-quality hypergraph partitioning framework Mt-KaHyPar. Its most important components are parallel improvement algorithms based on the FM algorithm and maximum flows, as well as a parallel clustering algorithm for coarsening - which are used in a multilevel scheme with $\\log(n)$ levels. As additional components, we parallelize the $n$-level partitioning scheme, devise a deterministic version of our algorithm, and present optimizations for plain graphs.   We evaluate our solver on more than 800 graphs and hypergraphs, and compare it with 25 different algorithms from the literature. Our fastest configuration outperforms almost all existing hypergraph partitioners with regards to both solution quality and running time. Our highest-quality configuration achieves the same solution quality as the best sequential partitioner KaHyPar, while being an order of magnitude faster with ten threads. Thus, two of our configurations occupy all fronts of the Pareto curve for hypergraph partitioning. Furthermore, our solvers exhibit good speedups, e.g., 29.6x in the geometric mean on 64 cores (deterministic), 22.3x ($\\log(n)$-level), and 25.9x ($n$-level).","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17679v1","tag":"data-quality"}}
{"title":"Iterative Prompt Learning for Unsupervised Backlit Image Enhancement","abstract":"We propose a novel unsupervised backlit image enhancement method, abbreviated as CLIP-LIT, by exploring the potential of Contrastive Language-Image Pre-Training (CLIP) for pixel-level image enhancement. We show that the open-world CLIP prior not only aids in distinguishing between backlit and well-lit images, but also in perceiving heterogeneous regions with different luminance, facilitating the optimization of the enhancement network. Unlike high-level and image manipulation tasks, directly applying CLIP to enhancement tasks is non-trivial, owing to the difficulty in finding accurate prompts. To solve this issue, we devise a prompt learning framework that first learns an initial prompt pair by constraining the text-image similarity between the prompt (negative/positive sample) and the corresponding image (backlit image/well-lit image) in the CLIP latent space. Then, we train the enhancement network based on the text-image similarity between the enhanced result and the initial prompt pair. To further improve the accuracy of the initial prompt pair, we iteratively fine-tune the prompt learning framework to reduce the distribution gaps between the backlit images, enhanced results, and well-lit images via rank learning, boosting the enhancement performance. Our method alternates between updating the prompt learning framework and enhancement network until visually pleasing results are achieved. Extensive experiments demonstrate that our method outperforms state-of-the-art methods in terms of visual quality and generalization ability, without requiring any paired data.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17569v1","tag":"data-quality"}}
{"title":"DAE-Talker: High Fidelity Speech-Driven Talking Face Generation with Diffusion Autoencoder","abstract":"While recent research has made significant progress in speech-driven talking face generation, the quality of the generated video still lags behind that of real recordings. One reason for this is the use of handcrafted intermediate representations like facial landmarks and 3DMM coefficients, which are designed based on human knowledge and are insufficient to precisely describe facial movements. Additionally, these methods require an external pretrained model for extracting these representations, whose performance sets an upper bound on talking face generation. To address these limitations, we propose a novel method called DAE-Talker that leverages data-driven latent representations obtained from a diffusion autoencoder (DAE). DAE contains an image encoder that encodes an image into a latent vector and a DDIM image decoder that reconstructs the image from it. We train our DAE on talking face video frames and then extract their latent representations as the training target for a Conformer-based speech2latent model. This allows DAE-Talker to synthesize full video frames and produce natural head movements that align with the content of speech, rather than relying on a predetermined head pose from a template video. We also introduce pose modelling in speech2latent for pose controllability. Additionally, we propose a novel method for generating continuous video frames with the DDIM image decoder trained on individual frames, eliminating the need for modelling the joint distribution of consecutive frames directly. Our experiments show that DAE-Talker outperforms existing popular methods in lip-sync, video fidelity, and pose naturalness. We also conduct ablation studies to analyze the effectiveness of the proposed techniques and demonstrate the pose controllability of DAE-Talker.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17550v1","tag":"data-quality"}}
{"title":"Whose Opinions Do Language Models Reflect?","abstract":"Language models (LMs) are increasingly being used in open-ended contexts, where the opinions reflected by LMs in response to subjective queries can have a profound impact, both on user satisfaction, as well as shaping the views of society at large. In this work, we put forth a quantitative framework to investigate the opinions reflected by LMs -- by leveraging high-quality public opinion polls and their associated human responses. Using this framework, we create OpinionsQA, a new dataset for evaluating the alignment of LM opinions with those of 60 US demographic groups over topics ranging from abortion to automation. Across topics, we find substantial misalignment between the views reflected by current LMs and those of US demographic groups: on par with the Democrat-Republican divide on climate change. Notably, this misalignment persists even after explicitly steering the LMs towards particular demographic groups. Our analysis not only confirms prior observations about the left-leaning tendencies of some human feedback-tuned LMs, but also surfaces groups whose opinions are poorly reflected by current LMs (e.g., 65+ and widowed individuals). Our code and data are available at https://github.com/tatsu-lab/opinions_qa.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17548v1","tag":"data-quality"}}
{"title":"Can I Trust My Simulation Model? Measuring the Quality of Business Process Simulation Models","abstract":"Business Process Simulation (BPS) is an approach to analyze the performance of business processes under different scenarios. For example, BPS allows us to estimate what would be the cycle time of a process if one or more resources became unavailable. The starting point of BPS is a process model annotated with simulation parameters (a BPS model). BPS models may be manually designed, based on information collected from stakeholders and empirical observations, or automatically discovered from execution data. Regardless of its origin, a key question when using a BPS model is how to assess its quality. In this paper, we propose a collection of measures to evaluate the quality of a BPS model w.r.t. its ability to replicate the observed behavior of the process. We advocate an approach whereby different measures tackle different process perspectives. We evaluate the ability of the proposed measures to discern the impact of modifications to a BPS model, and their ability to uncover the relative strengths and weaknesses of two approaches for automated discovery of BPS models. The evaluation shows that the measures not only capture how close a BPS model is to the observed behavior, but they also help us to identify sources of discrepancies.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17463v1","tag":"data-quality"}}
{"title":"Prediction of cancer driver genes and mutations: the potential of integrative computational frameworks","abstract":"The vast amount of sequencing data presently available allow the scientific community to explore a range of genetic variables that may drive and progress cancer. A myriad of predictive tools has been proposed, allowing researchers and clinicians to compare and prioritize driver genes and mutations and their relative pathogenicity. However, there is little consensus on the computational approach or a golden standard for comparison. Hence, benchmarking the different tools depends highly on the input data, indicating that overfitting is still a massive problem. One of the solutions is to limit the scope and usage of specific tool. However, such limitations forces researchers to walk on a tightrope between creating and using high-quality tools for a specific purpose and describing the complex alterations driving cancer. While the knowledge of cancer development increases every day, many bioinformatic pipelines rely on single nucleotide variants or alterations in a vacuum without accounting for cellular compartment, mutational burden, or disease progression. Even within bioinformatics and computational cancer biology, the research fields work in silos, risking overlooking potential synergies or breakthroughs. Here, we provide an overview of databases and datasets for building or testing predictive tools for discovery of cancer drivers. We introduce predictive tools for driver genes, driver mutations, and the impact of these based on structural analysis. Additionally, we suggest and recommend directions in the field to avoid silo-research, moving in the direction of integrative frameworks.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17402v1","tag":"data-quality"}}
{"title":"WavCaps: A ChatGPT-Assisted Weakly-Labelled Audio Captioning Dataset for Audio-Language Multimodal Research","abstract":"The advancement of audio-language (AL) multimodal learning tasks has been significant in recent years. However, researchers face challenges due to the costly and time-consuming collection process of existing audio-language datasets, which are limited in size. To address this data scarcity issue, we introduce WavCaps, the first large-scale weakly-labelled audio captioning dataset, comprising approximately 400k audio clips with paired captions. We sourced audio clips and their raw descriptions from web sources and a sound event detection dataset. However, the online-harvested raw descriptions are highly noisy and unsuitable for direct use in tasks such as automated audio captioning. To overcome this issue, we propose a three-stage processing pipeline for filtering noisy data and generating high-quality captions, where ChatGPT, a large language model, is leveraged to filter and transform raw descriptions automatically. We conduct a comprehensive analysis of the characteristics of WavCaps dataset and evaluate it on multiple downstream audio-language multimodal learning tasks. The systems trained on WavCaps outperform previous state-of-the-art (SOTA) models by a significant margin. Our aspiration is for the WavCaps dataset we have proposed to facilitate research in audio-language multimodal learning and demonstrate the potential of utilizing ChatGPT to enhance academic research. Our dataset and codes are available at https://github.com/XinhaoMei/WavCaps.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17395v1","tag":"data-quality"}}
{"title":"Joint Rate Allocation and Power Control for RSMA-Based Communication and Radar Coexistence Systems","abstract":"We consider a rate-splitting multiple access (RSMA)-based communication and radar coexistence (CRC) system. The proposed system allows an RSMA-based communication system to share spectrum with multiple radars. Furthermore, RSMA enables flexible and powerful interference management by splitting messages into common parts and private parts to partially decode interference and partially treat interference as noise. The RSMA-based CRC system thus significantly improves spectral efficiency, energy efficiency and quality of service (QoS) of communication users (CUs). However, the RSMA-based CRC system raises new challenges. Due to the spectrum sharing, the communication network and the radars cause interference to each other, which reduces the signal-to-interference-plus-noise ratio (SINR) of the radars as well as the data rate of the CUs in the communication network. Therefore, a major problem is to maximize the sum rate of the CUs while guaranteeing their QoS requirements of data transmissions and the SINR requirements of multiple radars. To achieve these objectives, we formulate a problem that optimizes i) the common rate allocation to the CUs, transmit power of common messages and transmit power of private messages of the CUs, and ii) transmit power of the radars. The problem is non-convex with multiple decision parameters, which is challenging to be solved. We propose two algorithms. The first sequential quadratic programming (SQP) can quickly return a local optimal solution, and has been known to be the state-of-the-art in nonlinear programming methods. The second is an additive approximation scheme (AAS) which solves the problem globally in a reasonable amount of time, based on the technique of applying exhaustive enumeration to a modified instance. The simulation results show the improvement of the AAS compared with the SQP in terms of sum rate.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17392v1","tag":"data-quality"}}
{"title":"SynBody: Synthetic Dataset with Layered Human Models for 3D Human Perception and Modeling","abstract":"Synthetic data has emerged as a promising source for 3D human research as it offers low-cost access to large-scale human datasets. To advance the diversity and annotation quality of human models, we introduce a new synthetic dataset, Synbody, with three appealing features: 1) a clothed parametric human model that can generate a diverse range of subjects; 2) the layered human representation that naturally offers high-quality 3D annotations to support multiple tasks; 3) a scalable system for producing realistic data to facilitate real-world tasks. The dataset comprises 1.7M images with corresponding accurate 3D annotations, covering 10,000 human body models, 1000 actions, and various viewpoints. The dataset includes two subsets for human mesh recovery as well as human neural rendering. Extensive experiments on SynBody indicate that it substantially enhances both SMPL and SMPL-X estimation. Furthermore, the incorporation of layered annotations offers a valuable training resource for investigating the Human Neural Radiance Fields (NeRF).","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17368v1","tag":"data-quality"}}
{"title":"Humans in Humans Out: On GPT Converging Toward Common Sense in both Success and Failure","abstract":"Increase in computational scale and fine-tuning has seen a dramatic improvement in the quality of outputs of large language models (LLMs) like GPT. Given that both GPT-3 and GPT-4 were trained on large quantities of human-generated text, we might ask to what extent their outputs reflect patterns of human thinking, both for correct and incorrect cases. The Erotetic Theory of Reason (ETR) provides a symbolic generative model of both human success and failure in thinking, across propositional, quantified, and probabilistic reasoning, as well as decision-making. We presented GPT-3, GPT-3.5, and GPT-4 with 61 central inference and judgment problems from a recent book-length presentation of ETR, consisting of experimentally verified data-points on human judgment and extrapolated data-points predicted by ETR, with correct inference patterns as well as fallacies and framing effects (the ETR61 benchmark). ETR61 includes classics like Wason's card task, illusory inferences, the decoy effect, and opportunity-cost neglect, among others. GPT-3 showed evidence of ETR-predicted outputs for 59% of these examples, rising to 77% in GPT-3.5 and 75% in GPT-4. Remarkably, the production of human-like fallacious judgments increased from 18% in GPT-3 to 33% in GPT-3.5 and 34% in GPT-4. This suggests that larger and more advanced LLMs may develop a tendency toward more human-like mistakes, as relevant thought patterns are inherent in human-produced training data. According to ETR, the same fundamental patterns are involved both in successful and unsuccessful ordinary reasoning, so that the \"bad\" cases could paradoxically be learned from the \"good\" cases. We further present preliminary evidence that ETR-inspired prompt engineering could reduce instances of these mistakes.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17276v1","tag":"data-quality"}}
{"title":"TPMCF: Temporal QoS Prediction using Multi-Source Collaborative Features","abstract":"Recently, with the rapid deployment of service APIs, personalized service recommendations have played a paramount role in the growth of the e-commerce industry. Quality-of-Service (QoS) parameters determining the service performance, often used for recommendation, fluctuate over time. Thus, the QoS prediction is essential to identify a suitable service among functionally equivalent services over time. The contemporary temporal QoS prediction methods hardly achieved the desired accuracy due to various limitations, such as the inability to handle data sparsity and outliers and capture higher-order temporal relationships among user-service interactions. Even though some recent recurrent neural-network-based architectures can model temporal relationships among QoS data, prediction accuracy degrades due to the absence of other features (e.g., collaborative features) to comprehend the relationship among the user-service interactions. This paper addresses the above challenges and proposes a scalable strategy for Temporal QoS Prediction using Multi-source Collaborative-Features (TPMCF), achieving high prediction accuracy and faster responsiveness. TPMCF combines the collaborative-features of users/services by exploiting user-service relationship with the spatio-temporal auto-extracted features by employing graph convolution and transformer encoder with multi-head self-attention. We validated our proposed method on WS-DREAM-2 datasets. Extensive experiments showed TPMCF outperformed major state-of-the-art approaches regarding prediction accuracy while ensuring high scalability and reasonably faster responsiveness.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.18201v1","tag":"data-quality"}}
{"title":"The Nordic Pile: A 1.2TB Nordic Dataset for Language Modeling","abstract":"Pre-training Large Language Models (LLMs) require massive amounts of text data, and the performance of the LLMs typically correlates with the scale and quality of the datasets. This means that it may be challenging to build LLMs for smaller languages such as Nordic ones, where the availability of text corpora is limited. In order to facilitate the development of the LLMS in the Nordic languages, we curate a high-quality dataset consisting of 1.2TB of text, in all of the major North Germanic languages (Danish, Icelandic, Norwegian, and Swedish), as well as some high-quality English data. This paper details our considerations and processes for collecting, cleaning, and filtering the dataset.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17183v1","tag":"data-quality"}}
{"title":"Thermodynamic and Transport Properties Modeling of Deep Eutectic Solvents: A review on gE-models, equations of state and molecular dynamics","abstract":"Deep eutectic solvents (DESs) have gained attention in recent years as attractive alternatives to traditional solvents. There is a growing number of publications dealing with the thermodynamic modeling of DESs highlighting the importance of modeling the solutions' properties. In this review, we summarize the state-of-the-art in DES modeling as well as its current challenges. We also summarize the various modeling approaches to phase equilibria and properties of DESs with gE-models, EOS and molecular dynamics (MD) simulations. The current gE-model and EOS-based approaches handle DESs as pseudo-components in order to simplify the parameterizations and calculation strategies. However, for the models to become more transferable and predictive, it would be preferable to model the individual DES constituents instead of using the pseudo-components. This implies that validation with more detailed experimental data that includes the distribution of the DES components is also required. MD simulations, in contrast to gE-models and EOS, are capable of providing information about the liquid structure and can predict dynamic properties although, the latter quantities still show some imprecisions. Therefore, insights into the liquid structure of DES systems from MD could also aid in improving present modeling strategies in addition to a better understanding. Finally, the latest developments for DES force fields are discussed as the quality of the applied force fields determine the results of MD simulations.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17159v1","tag":"data-quality"}}
{"title":"KD-DLGAN: Data Limited Image Generation via Knowledge Distillation","abstract":"Generative Adversarial Networks (GANs) rely heavily on large-scale training data for training high-quality image generation models. With limited training data, the GAN discriminator often suffers from severe overfitting which directly leads to degraded generation especially in generation diversity. Inspired by the recent advances in knowledge distillation (KD), we propose KD-DLGAN, a knowledge-distillation based generation framework that introduces pre-trained vision-language models for training effective data-limited generation models. KD-DLGAN consists of two innovative designs. The first is aggregated generative KD that mitigates the discriminator overfitting by challenging the discriminator with harder learning tasks and distilling more generalizable knowledge from the pre-trained models. The second is correlated generative KD that improves the generation diversity by distilling and preserving the diverse image-text correlation within the pre-trained models. Extensive experiments over multiple benchmarks show that KD-DLGAN achieves superior image generation with limited training data. In addition, KD-DLGAN complements the state-of-the-art with consistent and substantial performance gains.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17158v1","tag":"data-quality"}}
{"title":"Social Biases through the Text-to-Image Generation Lens","abstract":"Text-to-Image (T2I) generation is enabling new applications that support creators, designers, and general end users of productivity software by generating illustrative content with high photorealism starting from a given descriptive text as a prompt. Such models are however trained on massive amounts of web data, which surfaces the peril of potential harmful biases that may leak in the generation process itself. In this paper, we take a multi-dimensional approach to studying and quantifying common social biases as reflected in the generated images, by focusing on how occupations, personality traits, and everyday situations are depicted across representations of (perceived) gender, age, race, and geographical location. Through an extensive set of both automated and human evaluation experiments we present findings for two popular T2I models: DALLE-v2 and Stable Diffusion. Our results reveal that there exist severe occupational biases of neutral prompts majorly excluding groups of people from results for both models. Such biases can get mitigated by increasing the amount of specification in the prompt itself, although the prompting mitigation will not address discrepancies in image quality or other usages of the model or its representations in other scenarios. Further, we observe personality traits being associated with only a limited set of people at the intersection of race, gender, and age. Finally, an analysis of geographical location representations on everyday situations (e.g., park, food, weddings) shows that for most situations, images generated through default location-neutral prompts are closer and more similar to images generated for locations of United States and Germany.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2304.06034v1","tag":"data-quality"}}
{"title":"MAHALO: Unifying Offline Reinforcement Learning and Imitation Learning from Observations","abstract":"We study a new paradigm for sequential decision making, called offline Policy Learning from Observation (PLfO). Offline PLfO aims to learn policies using datasets with substandard qualities: 1) only a subset of trajectories is labeled with rewards, 2) labeled trajectories may not contain actions, 3) labeled trajectories may not be of high quality, and 4) the overall data may not have full coverage. Such imperfection is common in real-world learning scenarios, so offline PLfO encompasses many existing offline learning setups, including offline imitation learning (IL), ILfO, and reinforcement learning (RL). In this work, we present a generic approach, called Modality-agnostic Adversarial Hypothesis Adaptation for Learning from Observations (MAHALO), for offline PLfO. Built upon the pessimism concept in offline RL, MAHALO optimizes the policy using a performance lower bound that accounts for uncertainty due to the dataset's insufficient converge. We implement this idea by adversarially training data-consistent critic and reward functions in policy optimization, which forces the learned policy to be robust to the data deficiency. We show that MAHALO consistently outperforms or matches specialized algorithms across a variety of offline PLfO tasks in theory and experiments.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17156v1","tag":"data-quality"}}
{"title":"Discriminative Class Tokens for Text-to-Image Diffusion Models","abstract":"Recent advances in text-to-image diffusion models have enabled the generation of diverse and high-quality images. However, generated images often fall short of depicting subtle details and are susceptible to errors due to ambiguity in the input text. One way of alleviating these issues is to train diffusion models on class-labeled datasets. This comes with a downside, doing so limits their expressive power: (i) supervised datasets are generally small compared to large-scale scraped text-image datasets on which text-to-image models are trained, and so the quality and diversity of generated images are severely affected, or (ii) the input is a hard-coded label, as opposed to free-form text, which limits the control over the generated images.   In this work, we propose a non-invasive fine-tuning technique that capitalizes on the expressive potential of free-form text while achieving high accuracy through discriminative signals from a pretrained classifier, which guides the generation. This is done by iteratively modifying the embedding of a single input token of a text-to-image diffusion model, using the classifier, by steering generated images toward a given target class. Our method is fast compared to prior fine-tuning methods and does not require a collection of in-class images or retraining of a noise-tolerant classifier. We evaluate our method extensively, showing that the generated images are: (i) more accurate and of higher quality than standard diffusion models, (ii) can be used to augment training data in a low-resource setting, and (iii) reveal information about the data used to train the guiding classifier. The code is available at \\url{https://github.com/idansc/discriminative_class_tokens}","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17155v1","tag":"data-quality"}}
{"title":"Ideal Abstractions for Decision-Focused Learning","abstract":"We present a methodology for formulating simplifying abstractions in machine learning systems by identifying and harnessing the utility structure of decisions. Machine learning tasks commonly involve high-dimensional output spaces (e.g., predictions for every pixel in an image or node in a graph), even though a coarser output would often suffice for downstream decision-making (e.g., regions of an image instead of pixels). Developers often hand-engineer abstractions of the output space, but numerous abstractions are possible and it is unclear how the choice of output space for a model impacts its usefulness in downstream decision-making. We propose a method that configures the output space automatically in order to minimize the loss of decision-relevant information. Taking a geometric perspective, we formulate a step of the algorithm as a projection of the probability simplex, termed fold, that minimizes the total loss of decision-related information in the H-entropy sense. Crucially, learning in the abstracted outcome space requires less data, leading to a net improvement in decision quality. We demonstrate the method in two domains: data acquisition for deep neural network training and a closed-loop wildfire management task.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.17062v1","tag":"data-quality"}}
{"title":"A comparative evaluation of image-to-image translation methods for stain transfer in histopathology","abstract":"Image-to-image translation (I2I) methods allow the generation of artificial images that share the content of the original image but have a different style. With the advances in Generative Adversarial Networks (GANs)-based methods, I2I methods enabled the generation of artificial images that are indistinguishable from natural images. Recently, I2I methods were also employed in histopathology for generating artificial images of in silico stained tissues from a different type of staining. We refer to this process as stain transfer. The number of I2I variants is constantly increasing, which makes a well justified choice of the most suitable I2I methods for stain transfer challenging. In our work, we compare twelve stain transfer approaches, three of which are based on traditional and nine on GAN-based image processing methods. The analysis relies on complementary quantitative measures for the quality of image translation, the assessment of the suitability for deep learning-based tissue grading, and the visual evaluation by pathologists. Our study highlights the strengths and weaknesses of the stain transfer approaches, thereby allowing a rational choice of the underlying I2I algorithms. Code, data, and trained models for stain transfer between H&E and Masson's Trichrome staining will be made available online.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.17009v2","tag":"data-quality"}}
{"title":"ContraSim -- A Similarity Measure Based on Contrastive Learning","abstract":"Recent work has compared neural network representations via similarity-based analyses, shedding light on how different aspects (architecture, training data, etc.) affect models' internal representations. The quality of a similarity measure is typically evaluated by its success in assigning a high score to representations that are expected to be matched. However, existing similarity measures perform mediocrely on standard benchmarks. In this work, we develop a new similarity measure, dubbed ContraSim, based on contrastive learning. In contrast to common closed-form similarity measures, ContraSim learns a parameterized measure by using both similar and dissimilar examples. We perform an extensive experimental evaluation of our method, with both language and vision models, on the standard layer prediction benchmark and two new benchmarks that we introduce: the multilingual benchmark and the image-caption benchmark. In all cases, ContraSim achieves much higher accuracy than previous similarity measures, even when presented with challenging examples, and reveals new insights not captured by previous measures.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16992v1","tag":"data-quality"}}
{"title":"Fairness-Aware Data Valuation for Supervised Learning","abstract":"Data valuation is a ML field that studies the value of training instances towards a given predictive task. Although data bias is one of the main sources of downstream model unfairness, previous work in data valuation does not consider how training instances may influence both performance and fairness of ML models. Thus, we propose Fairness-Aware Data vauatiOn (FADO), a data valuation framework that can be used to incorporate fairness concerns into a series of ML-related tasks (e.g., data pre-processing, exploratory data analysis, active learning). We propose an entropy-based data valuation metric suited to address our two-pronged goal of maximizing both performance and fairness, which is more computationally efficient than existing metrics. We then show how FADO can be applied as the basis for unfairness mitigation pre-processing techniques. Our methods achieve promising results -- up to a 40 p.p. improvement in fairness at a less than 1 p.p. loss in performance compared to a baseline -- and promote fairness in a data-centric way, where a deeper understanding of data quality takes center stage.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16963v1","tag":"data-quality"}}
{"title":"AutoAD: Movie Description in Context","abstract":"The objective of this paper is an automatic Audio Description (AD) model that ingests movies and outputs AD in text form. Generating high-quality movie AD is challenging due to the dependency of the descriptions on context, and the limited amount of training data available. In this work, we leverage the power of pretrained foundation models, such as GPT and CLIP, and only train a mapping network that bridges the two models for visually-conditioned text generation. In order to obtain high-quality AD, we make the following four contributions: (i) we incorporate context from the movie clip, AD from previous clips, as well as the subtitles; (ii) we address the lack of training data by pretraining on large-scale datasets, where visual or contextual information is unavailable, e.g. text-only AD without movies or visual captioning datasets without context; (iii) we improve on the currently available AD datasets, by removing label noise in the MAD dataset, and adding character naming information; and (iv) we obtain strong results on the movie AD task compared with previous methods.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16899v1","tag":"data-quality"}}
{"title":"Highly-Anisotropic Even-Denominator Fractional Quantum Hall State in an Orbitally-Coupled Half-Filled Landau Level","abstract":"The even-denominator fractional quantum Hall states (FQHSs) in half-filled Landau levels are generally believed to host non-Abelian quasiparticles and be of potential use in topological quantum computing. Of particular interest is the competition and interplay between the even-denominator FQHSs and other ground states, such as anisotropic phases and composite fermion Fermi seas. Here we report the observation of an even-denominator fractional quantum Hall state with highly-anisotropic in-plane transport coefficients at Landau level filling factor $\\nu=3/2$. We observe this state in an ultra-high-quality GaAs two-dimensional hole system when a large in-plane magnetic field is applied. By increasing the in-plane field, we observe a sharp transition from an isotropic composite fermion Fermi sea to an anisotropic even-denominator FQHS. Our data and calculations suggest that a unique feature of two-dimensional holes, namely the coupling between heavy-hole and light-hole states, combines different orbital components in the wavefunction of one Landau level, and leads to the emergence of a highly-anisotropic even-denominator fractional quantum Hall state. Our results demonstrate that the GaAs two-dimensional hole system is a unique platform for the exploration of exotic, many-body ground states.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16791v1","tag":"data-quality"}}
{"title":"RusTitW: Russian Language Text Dataset for Visual Text in-the-Wild Recognition","abstract":"Information surrounds people in modern life. Text is a very efficient type of information that people use for communication for centuries. However, automated text-in-the-wild recognition remains a challenging problem. The major limitation for a DL system is the lack of training data. For the competitive performance, training set must contain many samples that replicate the real-world cases. While there are many high-quality datasets for English text recognition; there are no available datasets for Russian language. In this paper, we present a large-scale human-labeled dataset for Russian text recognition in-the-wild. We also publish a synthetic dataset and code to reproduce the generation process","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16531v1","tag":"data-quality"}}
{"title":"Importance Sampling for Stochastic Gradient Descent in Deep Neural Networks","abstract":"Stochastic gradient descent samples uniformly the training set to build an unbiased gradient estimate with a limited number of samples. However, at a given step of the training process, some data are more helpful than others to continue learning. Importance sampling for training deep neural networks has been widely studied to propose sampling schemes yielding better performance than the uniform sampling scheme. After recalling the theory of importance sampling for deep learning, this paper reviews the challenges inherent to this research area. In particular, we propose a metric allowing the assessment of the quality of a given sampling scheme; and we study the interplay between the sampling scheme and the optimizer used.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16529v1","tag":"data-quality"}}
{"title":"Fair Federated Medical Image Segmentation via Client Contribution Estimation","abstract":"How to ensure fairness is an important topic in federated learning (FL). Recent studies have investigated how to reward clients based on their contribution (collaboration fairness), and how to achieve uniformity of performance across clients (performance fairness). Despite achieving progress on either one, we argue that it is critical to consider them together, in order to engage and motivate more diverse clients joining FL to derive a high-quality global model. In this work, we propose a novel method to optimize both types of fairness simultaneously. Specifically, we propose to estimate client contribution in gradient and data space. In gradient space, we monitor the gradient direction differences of each client with respect to others. And in data space, we measure the prediction error on client data using an auxiliary model. Based on this contribution estimation, we propose a FL method, federated training via contribution estimation (FedCE), i.e., using estimation as global model aggregation weights. We have theoretically analyzed our method and empirically evaluated it on two real-world medical datasets. The effectiveness of our approach has been validated with significant performance improvements, better collaboration fairness, better performance fairness, and comprehensive analytical studies.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16520v1","tag":"data-quality"}}
{"title":"Seeing What You Said: Talking Face Generation Guided by a Lip Reading Expert","abstract":"Talking face generation, also known as speech-to-lip generation, reconstructs facial motions concerning lips given coherent speech input. The previous studies revealed the importance of lip-speech synchronization and visual quality. Despite much progress, they hardly focus on the content of lip movements i.e., the visual intelligibility of the spoken words, which is an important aspect of generation quality. To address the problem, we propose using a lip-reading expert to improve the intelligibility of the generated lip regions by penalizing the incorrect generation results. Moreover, to compensate for data scarcity, we train the lip-reading expert in an audio-visual self-supervised manner. With a lip-reading expert, we propose a novel contrastive learning to enhance lip-speech synchronization, and a transformer to encode audio synchronically with video, while considering global temporal dependency of audio. For evaluation, we propose a new strategy with two different lip-reading experts to measure intelligibility of the generated videos. Rigorous experiments show that our proposal is superior to other State-of-the-art (SOTA) methods, such as Wav2Lip, in reading intelligibility i.e., over 38% Word Error Rate (WER) on LRS2 dataset and 27.8% accuracy on LRW dataset. We also achieve the SOTA performance in lip-speech synchronization and comparable performances in visual quality.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.17480v1","tag":"data-quality"}}
{"title":"HOLODIFFUSION: Training a 3D Diffusion Model using 2D Images","abstract":"Diffusion models have emerged as the best approach for generative modeling of 2D images. Part of their success is due to the possibility of training them on millions if not billions of images with a stable learning objective. However, extending these models to 3D remains difficult for two reasons. First, finding a large quantity of 3D training data is much more complex than for 2D images. Second, while it is conceptually trivial to extend the models to operate on 3D rather than 2D grids, the associated cubic growth in memory and compute complexity makes this infeasible. We address the first challenge by introducing a new diffusion setup that can be trained, end-to-end, with only posed 2D images for supervision; and the second challenge by proposing an image formation model that decouples model memory from spatial memory. We evaluate our method on real-world data, using the CO3D dataset which has not been used to train 3D generative models before. We show that our diffusion models are scalable, train robustly, and are competitive in terms of sample quality and fidelity to existing approaches for 3D generative modeling.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16509v1","tag":"data-quality"}}
{"title":"Global Adaptation meets Local Generalization: Unsupervised Domain Adaptation for 3D Human Pose Estimation","abstract":"When applying a pre-trained 2D-to-3D human pose lifting model to a target unseen dataset, large performance degradation is commonly encountered due to domain shift issues. We observe that the degradation is caused by two factors: 1) the large distribution gap over global positions of poses between the source and target datasets due to variant camera parameters and settings, and 2) the deficient diversity of local structures of poses in training. To this end, we combine \\textbf{global adaptation} and \\textbf{local generalization} in \\textit{PoseDA}, a simple yet effective framework of unsupervised domain adaptation for 3D human pose estimation. Specifically, global adaptation aims to align global positions of poses from the source domain to the target domain with a proposed global position alignment (GPA) module. And local generalization is designed to enhance the diversity of 2D-3D pose mapping with a local pose augmentation (LPA) module. These modules bring significant performance improvement without introducing additional learnable parameters. In addition, we propose local pose augmentation (LPA) to enhance the diversity of 3D poses following an adversarial training scheme consisting of 1) a augmentation generator that generates the parameters of pre-defined pose transformations and 2) an anchor discriminator to ensure the reality and quality of the augmented data. Our approach can be applicable to almost all 2D-3D lifting models. \\textit{PoseDA} achieves 61.3 mm of MPJPE on MPI-INF-3DHP under a cross-dataset evaluation setup, improving upon the previous state-of-the-art method by 10.2\\%.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16456v1","tag":"data-quality"}}
{"title":"ARMBench: An Object-centric Benchmark Dataset for Robotic Manipulation","abstract":"This paper introduces Amazon Robotic Manipulation Benchmark (ARMBench), a large-scale, object-centric benchmark dataset for robotic manipulation in the context of a warehouse. Automation of operations in modern warehouses requires a robotic manipulator to deal with a wide variety of objects, unstructured storage, and dynamically changing inventory. Such settings pose challenges in perceiving the identity, physical characteristics, and state of objects during manipulation. Existing datasets for robotic manipulation consider a limited set of objects or utilize 3D models to generate synthetic scenes with limitation in capturing the variety of object properties, clutter, and interactions. We present a large-scale dataset collected in an Amazon warehouse using a robotic manipulator performing object singulation from containers with heterogeneous contents. ARMBench contains images, videos, and metadata that corresponds to 235K+ pick-and-place activities on 190K+ unique objects. The data is captured at different stages of manipulation, i.e., pre-pick, during transfer, and after placement. Benchmark tasks are proposed by virtue of high-quality annotations and baseline performance evaluation are presented on three visual perception challenges, namely 1) object segmentation in clutter, 2) object identification, and 3) defect detection. ARMBench can be accessed at http://armbench.com","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16382v1","tag":"data-quality"}}
{"title":"Understanding How Low Vision People Read Using Eye Tracking","abstract":"While being able to read with screen magnifiers, low vision people have slow and unpleasant reading experiences. Eye tracking has the potential to improve their experience by recognizing fine-grained gaze behaviors and providing more targeted enhancements. To inspire gaze-based low vision technology, we investigate the suitable method to collect low vision users' gaze data via commercial eye trackers and thoroughly explore their challenges in reading based on their gaze behaviors. With an improved calibration interface, we collected the gaze data of 20 low vision participants and 20 sighted controls who performed reading tasks on a computer screen; low vision participants were also asked to read with different screen magnifiers. We found that, with an accessible calibration interface and data collection method, commercial eye trackers can collect gaze data of comparable quality from low vision and sighted people. Our study identified low vision people's unique gaze patterns during reading, building upon which, we propose design implications for gaze-based low vision technology.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.16346v1","tag":"data-quality"}}
{"title":"Rethinking CycleGAN: Improving Quality of GANs for Unpaired Image-to-Image Translation","abstract":"An unpaired image-to-image (I2I) translation technique seeks to find a mapping between two domains of data in a fully unsupervised manner. While the initial solutions to the I2I problem were provided by the generative adversarial neural networks (GANs), currently, diffusion models (DM) hold the state-of-the-art status on the I2I translation benchmarks in terms of FID. Yet, they suffer from some limitations, such as not using data from the source domain during the training, or maintaining consistency of the source and translated images only via simple pixel-wise errors. This work revisits the classic CycleGAN model and equips it with recent advancements in model architectures and model training procedures. The revised model is shown to significantly outperform other advanced GAN- and DM-based competitors on a variety of benchmarks. In the case of Male2Female translation of CelebA, the model achieves over 40% improvement in FID score compared to the state-of-the-art results. This work also demonstrates the ineffectiveness of the pixel-wise I2I translation faithfulness metrics and suggests their revision. The code and trained models are available at https://github.com/LS4GAN/uvcgan2","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.16280v1","tag":"data-quality"}}
{"title":"CryoFormer: Continuous Reconstruction of 3D Structures from Cryo-EM Data using Transformer-based Neural Representations","abstract":"High-resolution heterogeneous reconstruction of 3D structures of proteins and other biomolecules using cryo-electron microscopy (cryo-EM) is essential for understanding fundamental processes of life. However, it is still challenging to reconstruct the continuous motions of 3D structures from hundreds of thousands of noisy and randomly oriented 2D cryo-EM images. Existing methods based on coordinate-based neural networks show compelling results to model continuous conformations of 3D structures in the Fourier domain, but they suffer from a limited ability to model local flexible regions and lack interpretability. We propose a novel approach, cryoFormer, that utilizes a transformer-based network architecture for continuous heterogeneous cryo-EM reconstruction. We for the first time directly reconstruct continuous conformations of 3D structures using an implicit feature volume in the 3D spatial domain. A novel deformation transformer decoder further improves reconstruction quality and, more importantly, locates and robustly tackles flexible 3D regions caused by conformations. In experiments, our method outperforms current approaches on three public datasets (1 synthetic and 2 experimental) and a new synthetic dataset of PEDV spike protein. The code and new synthetic dataset will be released for better reproducibility of our results. Project page: https://cryoformer.github.io.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.16254v1","tag":"data-quality"}}
{"title":"Search for lithium-rich giants in 32 open clusters with high-resolution spectroscopy","abstract":"Lithium-rich giant stars are rare and their existence challenges our understanding of stellar structure and evolution. We profit from the high-quality sample gathered with HARPS and UVES, in order to search for Li-rich giants and to identify the Li enrichment mechanisms responsible. We derive stellar parameters for 247 stars belonging to 32 open clusters, with 0.07 Ga < ages < 3.6 Ga. We employed the spectral synthesis technique code FASMA for the abundance analysis of 228 stars from our sample. We also determined ages, distances, and extinction using astrometry and photometry from Gaia and PARSEC isochrones to constrain their evolutionary stage. Our sample covers a wide range of stellar masses from 1 to more than 6 solar masses where the majority of the masses are above 2 solar masses. We have found 14 canonical Li-rich giant stars which have experienced the first dredge-up. This corresponds to 6% of our total sample, which is higher than what is typically found for field stars. Apart from the canonical limit, we use the maximum Li abundance of the progenitor stars as a criterion for Li enrichment. We find Li enhancement also among eight stars which have passed the first dredge up and show strong Li lines based on the fact that stars at the same evolutionary stage in the same cluster have significantly different Li abundances. We confirm that giants with higher Li abundance correspond to a higher fraction of fast-rotating giants, suggesting a connection between Li enhancement and stellar rotation as predicted by stellar models. Our Li-rich giants are found in various evolutionary stages implying that no unique Li production mechanism is responsible for Li enrichment but rather different intrinsic or external mechanisms can be simultaneously at play.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.16124v1","tag":"data-quality"}}
{"title":"Wafer-scale Graphene Electro-absorption Modulators Fabricated in a 300mm CMOS Platform","abstract":"Graphene-based devices have shown great promise for several applications. For graphene devices to be used in real-world systems, it is necessary to demonstrate competitive device performance, repeatability of results, reliability, and a path to large-scale manufacturing with high yield at low cost. Here, we select single-layer graphene electro-absorption modulators as test vehicle and establish their wafer-scale integration in a 300mm pilot CMOS foundry environment. A hardmask is used to shape graphene, while tungsten-based contacts are fabricated using the damascene approach to enable CMOS-compatible fabrication. By analyzing data from hundreds of devices per wafer, the impact of specific processing steps on the performance could be identified and optimized. After optimization, modulation depth of 50 $\\pm$ 4 dB/mm is demonstrated on 400 devices measured using 6 V peak-to-peak voltage. The electro-optical bandwidth is up to 15.1 $\\pm$ 1 1.8 GHz for 25$\\mu$m-long devices. The results achieved are comparable to lab-based record-setting graphene devices of similar design and CVD graphene quality. By demonstrating the reproducibility of the results across hundreds of devices, this work resolves the bottleneck of graphene wafer-scale integration. Furthermore, CMOS-compatible processing enables co-integration of graphene-based devices with other photonics and electronics building blocks on the same chip, and for high-volume low-cost manufacturing.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2304.02646v1","tag":"data-quality"}}
{"title":"Cluster-Guided Unsupervised Domain Adaptation for Deep Speaker Embedding","abstract":"Recent studies have shown that pseudo labels can contribute to unsupervised domain adaptation (UDA) for speaker verification. Inspired by the self-training strategies that use an existing classifier to label the unlabeled data for retraining, we propose a cluster-guided UDA framework that labels the target domain data by clustering and combines the labeled source domain data and pseudo-labeled target domain data to train a speaker embedding network. To improve the cluster quality, we train a speaker embedding network dedicated for clustering by minimizing the contrastive center loss. The goal is to reduce the distance between an embedding and its assigned cluster center while enlarging the distance between the embedding and the other cluster centers. Using VoxCeleb2 as the source domain and CN-Celeb1 as the target domain, we demonstrate that the proposed method can achieve an equal error rate (EER) of 8.10% on the CN-Celeb1 evaluation set without using any labels from the target domain. This result outperforms the supervised baseline by 39.6% and is the state-of-the-art UDA performance on this corpus.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15944v1","tag":"data-quality"}}
{"title":"Physics-guided adversarial networks for artificial digital image correlation data generation","abstract":"Digital image correlation (DIC) has become a valuable tool in the evaluation of mechanical experiments, particularly fatigue crack growth experiments. The evaluation requires accurate information of the crack path and crack tip position, which is difficult to obtain due to inherent noise and artefacts. Machine learning models have been extremely successful in recognizing this relevant information given labelled DIC displacement data. For the training of robust models, which generalize well, big data is needed. However, data is typically scarce in the field of material science and engineering because experiments are expensive and time-consuming. We present a method to generate synthetic DIC displacement data using generative adversarial networks with a physics-guided discriminator. To decide whether data samples are real or fake, this discriminator additionally receives the derived von Mises equivalent strain. We show that this physics-guided approach leads to improved results in terms of visual quality of samples, sliced Wasserstein distance, and geometry score.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15939v1","tag":"data-quality"}}
{"title":"Efficient Quality Diversity Optimization of 3D Buildings through 2D Pre-optimization","abstract":"Quality diversity algorithms can be used to efficiently create a diverse set of solutions to inform engineers' intuition. But quality diversity is not efficient in very expensive problems, needing 100.000s of evaluations. Even with the assistance of surrogate models, quality diversity needs 100s or even 1000s of evaluations, which can make it use infeasible. In this study we try to tackle this problem by using a pre-optimization strategy on a lower-dimensional optimization problem and then map the solutions to a higher-dimensional case. For a use case to design buildings that minimize wind nuisance, we show that we can predict flow features around 3D buildings from 2D flow features around building footprints. For a diverse set of building designs, by sampling the space of 2D footprints with a quality diversity algorithm, a predictive model can be trained that is more accurate than when trained on a set of footprints that were selected with a space-filling algorithm like the Sobol sequence. Simulating only 16 buildings in 3D, a set of 1024 building designs with low predicted wind nuisance is created. We show that we can produce better machine learning models by producing training data with quality diversity instead of using common sampling techniques. The method can bootstrap generative design in a computationally expensive 3D domain and allow engineers to sweep the design space, understanding wind nuisance in early design phases.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15896v1","tag":"data-quality"}}
{"title":"Head3D: Complete 3D Head Generation via Tri-plane Feature Distillation","abstract":"Head generation with diverse identities is an important task in computer vision and computer graphics, widely used in multimedia applications. However, current full head generation methods require a large number of 3D scans or multi-view images to train the model, resulting in expensive data acquisition cost. To address this issue, we propose Head3D, a method to generate full 3D heads with limited multi-view images. Specifically, our approach first extracts facial priors represented by tri-planes learned in EG3D, a 3D-aware generative model, and then proposes feature distillation to deliver the 3D frontal faces into complete heads without compromising head integrity. To mitigate the domain gap between the face and head models, we present dual-discriminators to guide the frontal and back head generation, respectively. Our model achieves cost-efficient and diverse complete head generation with photo-realistic renderings and high-quality geometry representations. Extensive experiments demonstrate the effectiveness of our proposed Head3D, both qualitatively and quantitatively.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15892v1","tag":"data-quality"}}
{"title":"The transformative potential of machine learning for experiments in fluid mechanics","abstract":"The field of machine learning has rapidly advanced the state of the art in many fields of science and engineering, including experimental fluid dynamics, which is one of the original big-data disciplines. This perspective will highlight several aspects of experimental fluid mechanics that stand to benefit from progress advances in machine learning, including: 1) augmenting the fidelity and quality of measurement techniques, 2) improving experimental design and surrogate digital-twin models and 3) enabling real-time estimation and control. In each case, we discuss recent success stories and ongoing challenges, along with caveats and limitations, and outline the potential for new avenues of ML-augmented and ML-enabled experimental fluid mechanics.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15832v2","tag":"data-quality"}}
{"title":"PDExplain: Contextual Modeling of PDEs in the Wild","abstract":"We propose an explainable method for solving Partial Differential Equations by using a contextual scheme called PDExplain. During the training phase, our method is fed with data collected from an operator-defined family of PDEs accompanied by the general form of this family. In the inference phase, a minimal sample collected from a phenomenon is provided, where the sample is related to the PDE family but not necessarily to the set of specific PDEs seen in the training phase. We show how our algorithm can predict the PDE solution for future timesteps. Moreover, our method provides an explainable form of the PDE, a trait that can assist in modelling phenomena based on data in physical sciences. To verify our method, we conduct extensive experimentation, examining its quality both in terms of prediction error and explainability.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15827v1","tag":"data-quality"}}
{"title":"IoT-Based Remote Health Monitoring System Employing Smart Sensors for Asthma Patients during COVID-19 Pandemic","abstract":"COVID19 and asthma are respiratory diseases that can be life threatening in uncontrolled circumstances and require continuous monitoring. A poverty stricken South Asian country like Bangladesh has been bearing the brunt of the COVID19 pandemic since its beginning. The majority of the country's population resides in rural areas, where proper healthcare is difficult to access. This emphasizes the necessity of telemedicine, implementing the concept of the Internet of Things (IoT), which is still under development in Bangladesh. This paper demonstrates how the current challenges in the healthcare system are resolvable through the design of a remote health and environment monitoring system, specifically for asthma patients who are at an increased risk of COVID19. Since on-time treatment is essential, this system will allow doctors and medical staff to receive patient information in real time and deliver their services immediately to the patient regardless of their location. The proposed system consists of various sensors collecting heart rate, body temperature, ambient temperature, humidity, and air quality data and processing them through the Arduino Microcontroller. It is integrated with a mobile application. All this data is sent to the mobile application via a Bluetooth module and updated every few seconds so that the medical staff can instantly track patients' conditions and emergencies. The developed prototype is portable and easily usable by anyone. The system has been applied to five people of different ages and medical histories over a particular period. Upon analyzing all their data, it became clear which participants were particularly vulnerable to health deterioration and needed constant observation. Through this research, awareness about asthmatic symptoms will improve and help prevent their severity through effective treatment anytime, anywhere.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2304.06511v1","tag":"data-quality"}}
{"title":"System-status-aware Adaptive Network for Online Streaming Video Understanding","abstract":"Recent years have witnessed great progress in deep neural networks for real-time applications. However, most existing works do not explicitly consider the general case where the device's state and the available resources fluctuate over time, and none of them investigate or address the impact of varying computational resources for online video understanding tasks. This paper proposes a System-status-aware Adaptive Network (SAN) that considers the device's real-time state to provide high-quality predictions with low delay. Usage of our agent's policy improves efficiency and robustness to fluctuations of the system status. On two widely used video understanding tasks, SAN obtains state-of-the-art performance while constantly keeping processing delays low. Moreover, training such an agent on various types of hardware configurations is not easy as the labeled training data might not be available, or can be computationally prohibitive. To address this challenging problem, we propose a Meta Self-supervised Adaptation (MSA) method that adapts the agent's policy to new hardware configurations at test-time, allowing for easy deployment of the model onto other unseen hardware platforms.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15742v2","tag":"data-quality"}}
{"title":"Smart Handover with Predicted User Behavior using Convolutional Neural Networks for WiGig Systems","abstract":"WiGig networks and 60 GHz frequency communications have a lot of potential for commercial and personal use. They can offer extremely high transmission rates but at the cost of low range and penetration. Due to these issues, WiGig systems are unstable and need to rely on frequent handovers to maintain high-quality connections. However, this solution is problematic as it forces users into bad connections and downtime before they are switched to a better access point. In this work, we use Machine Learning to identify patterns in user behaviors and predict user actions. This prediction is used to do proactive handovers, switching users to access points with better future transmission rates and a more stable environment based on the future state of the user. Results show that not only the proposal is effective at predicting channel data, but the use of such predictions improves system performance and avoids unnecessary handovers.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15731v1","tag":"data-quality"}}
{"title":"Distributed Graph Embedding with Information-Oriented Random Walks","abstract":"Graph embedding maps graph nodes to low-dimensional vectors, and is widely adopted in machine learning tasks. The increasing availability of billion-edge graphs underscores the importance of learning efficient and effective embeddings on large graphs, such as link prediction on Twitter with over one billion edges. Most existing graph embedding methods fall short of reaching high data scalability. In this paper, we present a general-purpose, distributed, information-centric random walk-based graph embedding framework, DistGER, which can scale to embed billion-edge graphs. DistGER incrementally computes information-centric random walks. It further leverages a multi-proximity-aware, streaming, parallel graph partitioning strategy, simultaneously achieving high local partition quality and excellent workload balancing across machines. DistGER also improves the distributed Skip-Gram learning model to generate node embeddings by optimizing the access locality, CPU throughput, and synchronization efficiency. Experiments on real-world graphs demonstrate that compared to state-of-the-art distributed graph embedding frameworks, including KnightKing, DistDGL, and Pytorch-BigGraph, DistGER exhibits 2.33x-129x acceleration, 45% reduction in cross-machines communication, and > 10% effectiveness improvement in downstream tasks.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15702v1","tag":"data-quality"}}
{"title":"Efficient Deep Learning of Robust, Adaptive Policies using Tube MPC-Guided Data Augmentation","abstract":"The deployment of agile autonomous systems in challenging, unstructured environments requires adaptation capabilities and robustness to uncertainties. Existing robust and adaptive controllers, such as the ones based on MPC, can achieve impressive performance at the cost of heavy online onboard computations. Strategies that efficiently learn robust and onboard-deployable policies from MPC have emerged, but they still lack fundamental adaptation capabilities. In this work, we extend an existing efficient IL algorithm for robust policy learning from MPC with the ability to learn policies that adapt to challenging model/environment uncertainties. The key idea of our approach consists in modifying the IL procedure by conditioning the policy on a learned lower-dimensional model/environment representation that can be efficiently estimated online. We tailor our approach to the task of learning an adaptive position and attitude control policy to track trajectories under challenging disturbances on a multirotor. Our evaluation is performed in a high-fidelity simulation environment and shows that a high-quality adaptive policy can be obtained in about $1.3$ hours. We additionally empirically demonstrate rapid adaptation to in- and out-of-training-distribution uncertainties, achieving a $6.1$ cm average position error under a wind disturbance that corresponds to about $50\\%$ of the weight of the robot and that is $36\\%$ larger than the maximum wind seen during training.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15688v1","tag":"data-quality"}}
{"title":"Predicting Thermoelectric Power Factor of Bismuth Telluride During Laser Powder Bed Fusion Additive Manufacturing","abstract":"An additive manufacturing (AM) process, like laser powder bed fusion, allows for the fabrication of objects by spreading and melting powder in layers until a freeform part shape is created. In order to improve the properties of the material involved in the AM process, it is important to predict the material characterization property as a function of the processing conditions. In thermoelectric materials, the power factor is a measure of how efficiently the material can convert heat to electricity. While earlier works have predicted the material characterization properties of different thermoelectric materials using various techniques, implementation of machine learning models to predict the power factor of bismuth telluride (Bi2Te3) during the AM process has not been explored. This is important as Bi2Te3 is a standard material for low temperature applications. Thus, we used data about manufacturing processing parameters involved and in-situ sensor monitoring data collected during AM of Bi2Te3, to train different machine learning models in order to predict its thermoelectric power factor. We implemented supervised machine learning techniques using 80% training and 20% test data and further used the permutation feature importance method to identify important processing parameters and in-situ sensor features which were best at predicting power factor of the material. Ensemble-based methods like random forest, AdaBoost classifier, and bagging classifier performed the best in predicting power factor with the highest accuracy of 90% achieved by the bagging classifier model. Additionally, we found the top 15 processing parameters and in-situ sensor features to characterize the material manufacturing property like power factor. These features could further be optimized to maximize power factor of the thermoelectric material and improve the quality of the products built using this material.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15663v1","tag":"data-quality"}}
{"title":"Randomized rounding algorithms for large scale unsplittable flow problems","abstract":"Unsplittable flow problems cover a wide range of telecommunication and transportation problems and their efficient resolution is key to a number of applications. In this work, we study algorithms that can scale up to large graphs and important numbers of commodities. We present and analyze in detail a heuristic based on the linear relaxation of the problem and randomized rounding. We provide empirical evidence that this approach is competitive with state-of-the-art resolution methods either by its scaling performance or by the quality of its solutions. We provide a variation of the heuristic which has the same approximation factor as the state-of-the-art approximation algorithm. We also derive a tighter analysis for the approximation factor of both the variation and the state-of-the-art algorithm. We introduce a new objective function for the unsplittable flow problem and discuss its differences with the classical congestion objective function. Finally, we discuss the gap in practical performance and theoretical guarantees between all the aforementioned algorithms.","created":"2023-03-27","meta":{"link":"http://arxiv.org/abs/2303.15550v1","tag":"data-quality"}}
{"title":"Few-Shot Domain Adaptation for Low Light RAW Image Enhancement","abstract":"Enhancing practical low light raw images is a difficult task due to severe noise and color distortions from short exposure time and limited illumination. Despite the success of existing Convolutional Neural Network (CNN) based methods, their performance is not adaptable to different camera domains. In addition, such methods also require large datasets with short-exposure and corresponding long-exposure ground truth raw images for each camera domain, which is tedious to compile. To address this issue, we present a novel few-shot domain adaptation method to utilize the existing source camera labeled data with few labeled samples from the target camera to improve the target domain's enhancement quality in extreme low-light imaging. Our experiments show that only ten or fewer labeled samples from the target camera domain are sufficient to achieve similar or better enhancement performance than training a model with a large labeled target camera dataset. To support research in this direction, we also present a new low-light raw image dataset captured with a Nikon camera, comprising short-exposure and their corresponding long-exposure ground truth images.","created":"2023-03-27","meta":{"link":"http://arxiv.org/abs/2303.15528v1","tag":"data-quality"}}
{"title":"Exploring Continual Learning of Diffusion Models","abstract":"Diffusion models have achieved remarkable success in generating high-quality images thanks to their novel training procedures applied to unprecedented amounts of data. However, training a diffusion model from scratch is computationally expensive. This highlights the need to investigate the possibility of training these models iteratively, reusing computation while the data distribution changes. In this study, we take the first step in this direction and evaluate the continual learning (CL) properties of diffusion models. We begin by benchmarking the most common CL methods applied to Denoising Diffusion Probabilistic Models (DDPMs), where we note the strong performance of the experience replay with the reduced rehearsal coefficient. Furthermore, we provide insights into the dynamics of forgetting, which exhibit diverse behavior across diffusion timesteps. We also uncover certain pitfalls of using the bits-per-dimension metric for evaluating CL.","created":"2023-03-27","meta":{"link":"http://arxiv.org/abs/2303.15342v1","tag":"data-quality"}}
{"title":"The MiniPile Challenge for Data-Efficient Language Models","abstract":"The ever-growing diversity of pre-training text corpora has equipped language models with generalization capabilities across various downstream tasks. However, such diverse datasets are often too large for academic budgets; hence, most research on Transformer architectures, training procedures, optimizers, etc. gets conducted on smaller, homogeneous datasets. To this end, we present The MiniPile Challenge, where one pre-trains a language model on a diverse text corpus containing at most 1M documents. MiniPile is a 6GB subset of the deduplicated 825GB The Pile corpus. To curate MiniPile, we perform a simple, three-step data filtering process: we (1) infer embeddings for all documents of the Pile, (2) cluster the embedding space using $k$-means, and (3) filter out low-quality clusters. To verify MiniPile's suitability for language model pre-training, we use it to pre-train a BERT and T5 model, yielding a performance drop of only $1.9\\%$/$2.5\\%$ on the GLUE and SNI benchmarks compared to the original pre-trained checkpoints trained on $2.6$x/$745$x the amount of data. MiniPile is available at https://huggingface.co/datasets/JeanKaddour/minipile.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08442v1","tag":"data-quality"}}
{"title":"GreedyGD: Enhanced Generalized Deduplication for Direct Analytics in IoT","abstract":"Exponential growth in the amount of data generated by the Internet of Things currently pose significant challenges for data communication, storage and analytics and leads to high costs for organisations hoping to leverage their data. Novel techniques are therefore needed to holistically improve the efficiency of data storage and analytics in IoT systems. The emerging compression technique Generalized Deduplication (GD) has been shown to deliver high compression and enable direct compressed data analytics with low storage and memory requirements. In this paper, we propose a new GD-based data compression algorithm called GreedyGD that is designed for analytics. Compared to existing versions of GD, GreedyGD enables more reliable analytics with less data, while running 11.2x faster and delivering even better compression.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07240v1","tag":"data-quality"}}
{"title":"Efficient Deduplication and Leakage Detection in Large Scale Image Datasets with a focus on the CrowdAI Mapping Challenge Dataset","abstract":"Recent advancements in deep learning and computer vision have led to widespread use of deep neural networks to extract building footprints from remote-sensing imagery. The success of such methods relies on the availability of large databases of high-resolution remote sensing images with high-quality annotations. The CrowdAI Mapping Challenge Dataset is one of these datasets that has been used extensively in recent years to train deep neural networks. This dataset consists of $ \\sim\\ $280k training images and $ \\sim\\ $60k testing images, with polygonal building annotations for all images. However, issues such as low-quality and incorrect annotations, extensive duplication of image samples, and data leakage significantly reduce the utility of deep neural networks trained on the dataset. Therefore, it is an imperative pre-condition to adopt a data validation pipeline that evaluates the quality of the dataset prior to its use. To this end, we propose a drop-in pipeline that employs perceptual hashing techniques for efficient de-duplication of the dataset and identification of instances of data leakage between training and testing splits. In our experiments, we demonstrate that nearly 250k($ \\sim\\ $90%) images in the training split were identical. Moreover, our analysis on the validation split demonstrates that roughly 56k of the 60k images also appear in the training split, resulting in a data leakage of 93%. The source code used for the analysis and de-duplication of the CrowdAI Mapping Challenge dataset is publicly available at https://github.com/yeshwanth95/CrowdAI_Hash_and_search .","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02296v1","tag":"data-quality"}}
{"title":"Turn the Rudder: A Beacon of Reentrancy Detection for Smart Contracts on Ethereum","abstract":"Smart contracts are programs deployed on a blockchain and are immutable once deployed. Reentrancy, one of the most important vulnerabilities in smart contracts, has caused millions of dollars in financial loss. Many reentrancy detection approaches have been proposed. It is necessary to investigate the performance of these approaches to provide useful guidelines for their application. In this work, we conduct a large-scale empirical study on the capability of five well-known or recent reentrancy detection tools such as Mythril and Sailfish. We collect 230,548 verified smart contracts from Etherscan and use detection tools to analyze 139,424 contracts after deduplication, which results in 21,212 contracts with reentrancy issues. Then, we manually examine the defective functions located by the tools in the contracts. From the examination results, we obtain 34 true positive contracts with reentrancy and 21,178 false positive contracts without reentrancy. We also analyze the causes of the true and false positives. Finally, we evaluate the tools based on the two kinds of contracts. The results show that more than 99.8% of the reentrant contracts detected by the tools are false positives with eight types of causes, and the tools can only detect the reentrancy issues caused by call.value(), 58.8% of which can be revealed by the Ethereum's official IDE, Remix. Furthermore, we collect real-world reentrancy attacks reported in the past two years and find that the tools fail to find any issues in the corresponding contracts. Based on the findings, existing works on reentrancy detection appear to have very limited capability, and researchers should turn the rudder to discover and detect new reentrancy patterns except those related to call.value().","created":"2023-03-24","meta":{"link":"http://arxiv.org/abs/2303.13770v1","tag":"data-quality"}}
{"title":"SemDeDup: Data-efficient learning at web-scale through semantic deduplication","abstract":"Progress in machine learning has been driven in large part by massive increases in data. However, large web-scale datasets such as LAION are largely uncurated beyond searches for exact duplicates, potentially leaving much redundancy. Here, we introduce SemDeDup, a method which leverages embeddings from pre-trained models to identify and remove semantic duplicates: data pairs which are semantically similar, but not exactly identical. Removing semantic duplicates preserves performance and speeds up learning. Analyzing a subset of LAION, we show that SemDeDup can remove 50% of the data with minimal performance loss, effectively halving training time. Moreover, performance increases out of distribution. Also, analyzing language models trained on C4, a partially curated dataset, we show that SemDeDup improves over prior approaches while providing efficiency gains. SemDeDup provides an example of how simple ways of leveraging quality embeddings can be used to make models learn faster with less data.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09540v3","tag":"data-quality"}}
{"title":"MEDBERT.de: A Comprehensive German BERT Model for the Medical Domain","abstract":"This paper presents medBERTde, a pre-trained German BERT model specifically designed for the German medical domain. The model has been trained on a large corpus of 4.7 Million German medical documents and has been shown to achieve new state-of-the-art performance on eight different medical benchmarks covering a wide range of disciplines and medical document types. In addition to evaluating the overall performance of the model, this paper also conducts a more in-depth analysis of its capabilities. We investigate the impact of data deduplication on the model's performance, as well as the potential benefits of using more efficient tokenization methods. Our results indicate that domain-specific models such as medBERTde are particularly useful for longer texts, and that deduplication of training data does not necessarily lead to improved performance. Furthermore, we found that efficient tokenization plays only a minor role in improving model performance, and attribute most of the improved performance to the large amount of training data. To encourage further research, the pre-trained model weights and new benchmarks based on radiological data are made publicly available for use by the scientific community.","created":"2023-03-14","meta":{"link":"http://arxiv.org/abs/2303.08179v2","tag":"data-quality"}}
{"title":"HunSum-1: an Abstractive Summarization Dataset for Hungarian","abstract":"We introduce HunSum-1: a dataset for Hungarian abstractive summarization, consisting of 1.14M news articles. The dataset is built by collecting, cleaning and deduplicating data from 9 major Hungarian news sites through CommonCrawl. Using this dataset, we build abstractive summarizer models based on huBERT and mT5. We demonstrate the value of the created dataset by performing a quantitative and qualitative analysis on the models' results. The HunSum-1 dataset, all models used in our experiments and our code are available open source.","created":"2023-02-01","meta":{"link":"http://arxiv.org/abs/2302.00455v1","tag":"data-quality"}}
{"title":"FLAME: A small language model for spreadsheet formulas","abstract":"The widespread use of spreadsheet environments by billions of users presents a unique opportunity for formula-authoring assistance. Although large language models, such as Codex, can assist in general-purpose languages, they are expensive to train and challenging to deploy due to their large model sizes (up to billions of parameters). Moreover, they require hundreds of gigabytes of training data. We present FLAME, a T5-based model trained on Excel formulas that leverages domain insights to achieve competitive performance with a substantially smaller model (60M parameters) and two orders of magnitude less training data. We curate a training dataset using sketch deduplication, introduce an Excel-specific formula tokenizer for our model, and use domain-specific versions of masked span prediction and noisy auto-encoding as pretraining objectives. We evaluate FLAME on formula repair, formula auto-completion, and a novel task called syntax reconstruction. FLAME (60M) can outperform much larger models, such as Codex-Davinci (175B), Codex-Cushman (12B), and CodeT5 (220M), in 6 out of 10 settings.","created":"2023-01-31","meta":{"link":"http://arxiv.org/abs/2301.13779v1","tag":"data-quality"}}
{"title":"Bayesian Graphical Entity Resolution Using Exchangeable Random Partition Priors","abstract":"Entity resolution (record linkage or deduplication) is the process of identifying and linking duplicate records in databases. In this paper, we propose a Bayesian graphical approach for entity resolution that links records to latent entities, where the prior representation on the linkage structure is exchangeable. First, we adopt a flexible and tractable set of priors for the linkage structure, which corresponds to a special class of random partition models. Second, we propose a more realistic distortion model for categorical/discrete record attributes, which corrects a logical inconsistency with the standard hit-miss model. Third, we incorporate hyperpriors to improve flexibility. Fourth, we employ a partially collapsed Gibbs sampler for inferential speedups. Using a selection of private and nonprivate data sets, we investigate the impact of our modeling contributions and compare our model with two alternative Bayesian models. In addition, we conduct a simulation study for household survey data, where we vary distortion, duplication rates and data set size. We find that our model performs more consistently than the alternatives across a variety of scenarios and typically achieves the highest entity resolution accuracy (F1 score). Open source software is available for our proposed methodology, and we provide a discussion regarding our work and future directions.","created":"2023-01-08","meta":{"link":"http://arxiv.org/abs/2301.02962v1","tag":"data-quality"}}
{"title":"Extending Source Code Pre-Trained Language Models to Summarise Decompiled Binaries","abstract":"Reverse engineering binaries is required to understand and analyse programs for which the source code is unavailable. Decompilers can transform the largely unreadable binaries into a more readable source code-like representation. However, reverse engineering is time-consuming, much of which is taken up by labelling the functions with semantic information.   While the automated summarisation of decompiled code can help Reverse Engineers understand and analyse binaries, current work mainly focuses on summarising source code, and no suitable dataset exists for this task.   In this work, we extend large pre-trained language models of source code to summarise decompiled binary functions. Furthermore, we investigate the impact of input and data properties on the performance of such models. Our approach consists of two main components; the data and the model.   We first build CAPYBARA, a dataset of 214K decompiled function-documentation pairs across various compiler optimisations. We extend CAPYBARA further by generating synthetic datasets and deduplicating the data.   Next, we fine-tune the CodeT5 base model with CAPYBARA to create BinT5. BinT5 achieves the state-of-the-art BLEU-4 score of 60.83, 58.82, and 44.21 for summarising source, decompiled, and synthetically stripped decompiled code, respectively. This indicates that these models can be extended to decompiled binaries successfully.   Finally, we found that the performance of BinT5 is not heavily dependent on the dataset size and compiler optimisation level. We recommend future research to further investigate transferring knowledge when working with less expressive input formats such as stripped binaries.","created":"2023-01-04","meta":{"link":"http://arxiv.org/abs/2301.01701v2","tag":"data-quality"}}
{"title":"The Stack: 3 TB of permissively licensed source code","abstract":"Large Language Models (LLMs) play an ever-increasing role in the field of Artificial Intelligence (AI)--not only for natural language processing but also for code understanding and generation. To stimulate open and responsible research on LLMs for code, we introduce The Stack, a 3.1 TB dataset consisting of permissively licensed source code in 30 programming languages. We describe how we collect the full dataset, construct a permissively licensed subset, present a data governance plan, discuss limitations, and show promising results on text2code benchmarks by training 350M-parameter decoders on different Python subsets. We find that (1) near-deduplicating the data significantly boosts performance across all experiments, and (2) it is possible to match previously reported HumanEval and MBPP performance using only permissively licensed data. We make the dataset available at https://hf.co/BigCode, provide a tool called \"Am I in The Stack\" (https://hf.co/spaces/bigcode/in-the-stack) for developers to search The Stack for copies of their code, and provide a process for code to be removed from the dataset by following the instructions at https://www.bigcode-project.org/docs/about/the-stack/.","created":"2022-11-20","meta":{"link":"http://arxiv.org/abs/2211.15533v1","tag":"data-quality"}}
{"title":"Summarizing Community-based Question-Answer Pairs","abstract":"Community-based Question Answering (CQA), which allows users to acquire their desired information, has increasingly become an essential component of online services in various domains such as E-commerce, travel, and dining. However, an overwhelming number of CQA pairs makes it difficult for users without particular intent to find useful information spread over CQA pairs. To help users quickly digest the key information, we propose the novel CQA summarization task that aims to create a concise summary from CQA pairs. To this end, we first design a multi-stage data annotation process and create a benchmark dataset, CoQASUM, based on the Amazon QA corpus. We then compare a collection of extractive and abstractive summarization methods and establish a strong baseline approach DedupLED for the CQA summarization task. Our experiment further confirms two key challenges, sentence-type transfer and deduplication removal, towards the CQA summarization task. Our data and code are publicly available.","created":"2022-11-17","meta":{"link":"http://arxiv.org/abs/2211.09892v1","tag":"data-quality"}}
{"title":"RecD: Deduplication for End-to-End Deep Learning Recommendation Model Training Infrastructure","abstract":"We present RecD (Recommendation Deduplication), a suite of end-to-end infrastructure optimizations across the Deep Learning Recommendation Model (DLRM) training pipeline. RecD addresses immense storage, preprocessing, and training overheads caused by feature duplication inherent in industry-scale DLRM training datasets. Feature duplication arises because DLRM datasets are generated from interactions. While each user session can generate multiple training samples, many features' values do not change across these samples. We demonstrate how RecD exploits this property, end-to-end, across a deployed training pipeline. RecD optimizes data generation pipelines to decrease dataset storage and preprocessing resource demands and to maximize duplication within a training batch. RecD introduces a new tensor format, InverseKeyedJaggedTensors (IKJTs), to deduplicate feature values in each batch. We show how DLRM model architectures can leverage IKJTs to drastically increase training throughput. RecD improves the training and preprocessing throughput and storage efficiency by up to 2.49x, 1.79x, and 3.71x, respectively, in an industry-scale DLRM training system.","created":"2022-11-09","meta":{"link":"http://arxiv.org/abs/2211.05239v2","tag":"data-quality"}}
{"title":"Crossing Roads of Federated Learning and Smart Grids: Overview, Challenges, and Perspectives","abstract":"Consumer's privacy is a main concern in Smart Grids (SGs) due to the sensitivity of energy data, particularly when used to train machine learning models for different services. These data-driven models often require huge amounts of data to achieve acceptable performance leading in most cases to risks of privacy leakage. By pushing the training to the edge, Federated Learning (FL) offers a good compromise between privacy preservation and the predictive performance of these models. The current paper presents an overview of FL applications in SGs while discussing their advantages and drawbacks, mainly in load forecasting, electric vehicles, fault diagnoses, load disaggregation and renewable energies. In addition, an analysis of main design trends and possible taxonomies is provided considering data partitioning, the communication topology, and security mechanisms. Towards the end, an overview of main challenges facing this technology and potential future directions is presented.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08602v1","tag":"data-quality"}}
{"title":"A Randomized Approach for Tight Privacy Accounting","abstract":"Bounding privacy leakage over compositions, i.e., privacy accounting, is a key challenge in differential privacy (DP). However, the privacy parameter ($\\varepsilon$ or $\\delta$) is often easy to estimate but hard to bound. In this paper, we propose a new differential privacy paradigm called estimate-verify-release (EVR), which addresses the challenges of providing a strict upper bound for privacy parameter in DP compositions by converting an estimate of privacy parameter into a formal guarantee. The EVR paradigm first estimates the privacy parameter of a mechanism, then verifies whether it meets this guarantee, and finally releases the query output based on the verification result. The core component of the EVR is privacy verification. We develop a randomized privacy verifier using Monte Carlo (MC) technique. Furthermore, we propose an MC-based DP accountant that outperforms existing DP accounting techniques in terms of accuracy and efficiency. Our empirical evaluation shows the newly proposed EVR paradigm improves the utility-privacy tradeoff for privacy-preserving machine learning.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07927v1","tag":"data-quality"}}
{"title":"Shuffled Transformer for Privacy-Preserving Split Learning","abstract":"In conventional split learning, training and testing data often face severe privacy leakage threats. Existing solutions often have to trade learning accuracy for data privacy, or the other way around. We propose a lossless privacy-preserving split learning framework, on the basis of the permutation equivalence properties which are inherent to many neural network modules. We adopt Transformer as the example building block to the framework. It is proved that the Transformer encoder block is permutation equivalent, and thus training/testing could be done equivalently on permuted data. We further introduce shuffling-based privacy guarantee and enhance it by mix-up training. All properties are verified by conducted experiments, which also show strong defence against privacy attacks compared to the state-of-the-art, yet without any accuracy decline.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07735v1","tag":"data-quality"}}
{"title":"A Survey of Access Control Misconfiguration Detection Techniques","abstract":"Access control mechanisms have been adopted in many real-world systems to control resource sharing for the principals in the system. An error in the access control policy (misconfiguration) can easily cause severe data leakage and system exploitation. Researchers have developed several methodologies to detect the access control misconfigurations through data mining, testing, and verification for various applications. This survey will study the line of works to detect access control misconfigurations and discuss some future research directions.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07704v1","tag":"data-quality"}}
{"title":"$(\u03b1,\u03b2)$-Leakage: A Unified Privacy Leakage Measure","abstract":"We introduce a family of information leakage measures called maximal $(\\alpha,\\beta)$-leakage, parameterized by non-negative real numbers $\\alpha$ and $\\beta$. The measure is formalized via an operational definition involving an adversary guessing an unknown (randomized) function of the data given the released data. We obtain a simplified computable expression for the measure and show that it satisfies several basic properties such as monotonicity in $\\beta$ for a fixed $\\alpha$, non-negativity, data processing inequalities, and additivity over independent releases. We highlight the relevance of this family by showing that it bridges several known leakage measures, including maximal $\\alpha$-leakage $(\\beta=1)$, maximal leakage $(\\alpha=\\infty,\\beta=1)$, local differential privacy [LDP] $(\\alpha=\\infty,\\beta=\\infty)$, and local Renyi differential privacy [LRDP] $(\\alpha=\\beta)$, thereby giving an operational interpretation to local Renyi differential privacy. We also study a conditional version of maximal $(\\alpha,\\beta)$-leakage on leveraging which we recover differential privacy and Renyi differential privacy. A new variant of LRDP, which we call maximal Renyi leakage, appears as a special case of maximal $(\\alpha,\\beta)$-leakage for $\\alpha=\\infty$ that smoothly tunes between maximal leakage ($\\beta=1$) and LDP ($\\beta=\\infty$). Finally, we show that a vector form of the maximal Renyi leakage relaxes differential privacy under Gaussian and Laplacian mechanisms.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07456v1","tag":"data-quality"}}
{"title":"Medical Question Summarization with Entity-driven Contrastive Learning","abstract":"By summarizing longer consumer health questions into shorter and essential ones, medical question answering (MQA) systems can more accurately understand consumer intentions and retrieve suitable answers. However, medical question summarization is very challenging due to obvious distinctions in health trouble descriptions from patients and doctors. Although existing works have attempted to utilize Seq2Seq, reinforcement learning, or contrastive learning to solve the problem, two challenges remain: how to correctly capture question focus to model its semantic intention, and how to obtain reliable datasets to fairly evaluate performance. To address these challenges, this paper proposes a novel medical question summarization framework using entity-driven contrastive learning (ECL). ECL employs medical entities in frequently asked questions (FAQs) as focuses and devises an effective mechanism to generate hard negative samples. This approach forces models to pay attention to the crucial focus information and generate more ideal question summarization. Additionally, we find that some MQA datasets suffer from serious data leakage problems, such as the iCliniq dataset's 33% duplicate rate. To evaluate the related methods fairly, this paper carefully checks leaked samples to reorganize more reasonable datasets. Extensive experiments demonstrate that our ECL method outperforms state-of-the-art methods by accurately capturing question focus and generating medical question summaries. The code and datasets are available at https://github.com/yrbobo/MQS-ECL.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07437v1","tag":"data-quality"}}
{"title":"Scale Federated Learning for Label Set Mismatch in Medical Image Classification","abstract":"Federated learning (FL) has been introduced to the healthcare domain as a decentralized learning paradigm that allows multiple parties to train a model collaboratively without privacy leakage. However, most previous studies have assumed that every client holds an identical label set. In reality, medical specialists tend to annotate only diseases within their knowledge domain or interest. This implies that label sets in each client can be different and even disjoint. In this paper, we propose the framework FedLSM to solve the problem Label Set Mismatch. FedLSM adopts different training strategies on data with different uncertainty levels to efficiently utilize unlabeled or partially labeled data as well as class-wise adaptive aggregation in the classification layer to avoid inaccurate aggregation when clients have missing labels. We evaluate FedLSM on two public real-world medical image datasets, including chest x-ray (CXR) diagnosis with 112,120 CXR images and skin lesion diagnosis with 10,015 dermoscopy images, and show that it significantly outperforms other state-of-the-art FL algorithms. Code will be made available upon acceptance.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.06931v1","tag":"data-quality"}}
{"title":"A Low-cost Through-metal Communication System for Sensors in Metallic Pipes","abstract":"Metallic pipes and other containers are widely used to store and transport toxic gases and liquids. Various sensors have been designed to monitor the environment inside metallic pipes and containers, such as pressure, liquid-level, and chemical sensors. Moreover, sensors are also used to inspect and detect pipe leakages. However, sensors are usually placed outside of metallic pipes and containers and use ultrasound to monitor the internal unseen environment. This is mainly due to the fact that internal sensors cannot communicate with external data sinks without cables, but using cables can dramatically affect the metal-sealed structure. Wireless communication is desirable to communicate with internal sensors, but it experiences high attenuation losses since metal can block wireless signals due to its high conductivity. This paper develops a low-cost through-metal communication system prototype using off-the-shelf electronic components. The system is fully reconfigurable, and arbitrary modulation and coding schemes can be implemented. We design the transmit module which includes a signal processing microcontroller, an amplifier, and a transmit coil, and the receive module which includes a receive coil, an amplifier, and a microcontroller with demodulation algorithms and bit-error-rate (BER) calculations. The performance of the prototype is evaluated using various symbol rates, distances, and transmission power. The results show that the communication system can achieve a 500 bps data rate with 0.01 BER and 3.4 cm communication range when penetrating an Aluminum pipe with 7 mm thickness.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.06890v1","tag":"data-quality"}}
{"title":"Rethinking Dense Retrieval's Few-Shot Ability","abstract":"Few-shot dense retrieval (DR) aims to effectively generalize to novel search scenarios by learning a few samples. Despite its importance, there is little study on specialized datasets and standardized evaluation protocols. As a result, current methods often resort to random sampling from supervised datasets to create \"few-data\" setups and employ inconsistent training strategies during evaluations, which poses a challenge in accurately comparing recent progress. In this paper, we propose a customized FewDR dataset and a unified evaluation benchmark. Specifically, FewDR employs class-wise sampling to establish a standardized \"few-shot\" setting with finely-defined classes, reducing variability in multiple sampling rounds. Moreover, the dataset is disjointed into base and novel classes, allowing DR models to be continuously trained on ample data from base classes and a few samples in novel classes. This benchmark eliminates the risk of novel class leakage, providing a reliable estimation of the DR model's few-shot ability. Our extensive empirical results reveal that current state-of-the-art DR models still face challenges in the standard few-shot scene. Our code and data will be open-sourced at https://github.com/OpenMatch/ANCE-Tele.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05845v1","tag":"data-quality"}}
{"title":"Zero-Knowledge Proof-based Practical Federated Learning on Blockchain","abstract":"Since the concern of privacy leakage extremely discourages user participation in sharing data, federated learning has gradually become a promising technique for both academia and industry for achieving collaborative learning without leaking information about the local data. Unfortunately, most federated learning solutions cannot efficiently verify the execution of each participant's local machine learning model and protect the privacy of user data, simultaneously. In this article, we first propose a Zero-Knowledge Proof-based Federated Learning (ZKP-FL) scheme on blockchain. It leverages zero-knowledge proof for both the computation of local data and the aggregation of local model parameters, aiming to verify the computation process without requiring the plaintext of the local data. We further propose a Practical ZKP-FL (PZKP-FL) scheme to support fraction and non-linear operations. Specifically, we explore a Fraction-Integer mapping function, and use Taylor expansion to efficiently handle non-linear operations while maintaining the accuracy of the federated learning model. We also analyze the security of PZKP-FL. Performance analysis demonstrates that the whole running time of the PZKP-FL scheme is approximately less than one minute in parallel execution.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05590v1","tag":"data-quality"}}
{"title":"RecUP-FL: Reconciling Utility and Privacy in Federated Learning via User-configurable Privacy Defense","abstract":"Federated learning (FL) provides a variety of privacy advantages by allowing clients to collaboratively train a model without sharing their private data. However, recent studies have shown that private information can still be leaked through shared gradients. To further minimize the risk of privacy leakage, existing defenses usually require clients to locally modify their gradients (e.g., differential privacy) prior to sharing with the server. While these approaches are effective in certain cases, they regard the entire data as a single entity to protect, which usually comes at a large cost in model utility. In this paper, we seek to reconcile utility and privacy in FL by proposing a user-configurable privacy defense, RecUP-FL, that can better focus on the user-specified sensitive attributes while obtaining significant improvements in utility over traditional defenses. Moreover, we observe that existing inference attacks often rely on a machine learning model to extract the private information (e.g., attributes). We thus formulate such a privacy defense as an adversarial learning problem, where RecUP-FL generates slight perturbations that can be added to the gradients before sharing to fool adversary models. To improve the transferability to un-queryable black-box adversary models, inspired by the idea of meta-learning, RecUP-FL forms a model zoo containing a set of substitute models and iteratively alternates between simulations of the white-box and the black-box adversarial attack scenarios to generate perturbations. Extensive experiments on four datasets under various adversarial settings (both attribute inference attack and data reconstruction attack) show that RecUP-FL can meet user-specified privacy constraints over the sensitive attributes while significantly improving the model utility compared with state-of-the-art privacy defenses.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05135v1","tag":"data-quality"}}
{"title":"Gradient Sparsification for Efficient Wireless Federated Learning with Differential Privacy","abstract":"Federated learning (FL) enables distributed clients to collaboratively train a machine learning model without sharing raw data with each other. However, it suffers the leakage of private information from uploading models. In addition, as the model size grows, the training latency increases due to limited transmission bandwidth and the model performance degrades while using differential privacy (DP) protection. In this paper, we propose a gradient sparsification empowered FL framework over wireless channels, in order to improve training efficiency without sacrificing convergence performance. Specifically, we first design a random sparsification algorithm to retain a fraction of the gradient elements in each client's local training, thereby mitigating the performance degradation induced by DP and and reducing the number of transmission parameters over wireless channels. Then, we analyze the convergence bound of the proposed algorithm, by modeling a non-convex FL problem. Next, we formulate a time-sequential stochastic optimization problem for minimizing the developed convergence bound, under the constraints of transmit power, the average transmitting delay, as well as the client's DP requirement. Utilizing the Lyapunov drift-plus-penalty framework, we develop an analytical solution to the optimization problem. Extensive experiments have been implemented on three real life datasets to demonstrate the effectiveness of our proposed algorithm. We show that our proposed algorithms can fully exploit the interworking between communication and computation to outperform the baselines, i.e., random scheduling, round robin and delay-minimization algorithms.","created":"2023-04-09","meta":{"link":"http://arxiv.org/abs/2304.04164v1","tag":"data-quality"}}
{"title":"Efficient Secure Aggregation for Privacy-Preserving Federated Machine Learning","abstract":"Federated learning introduces a novel approach to training machine learning (ML) models on distributed data while preserving user's data privacy. This is done by distributing the model to clients to perform training on their local data and computing the final model at a central server. To prevent any data leakage from the local model updates, various works with focus on secure aggregation for privacy preserving federated learning have been proposed. Despite their merits, most of the existing protocols still incur high communication and computation overhead on the participating entities and might not be optimized to efficiently handle the large update vectors for ML models. In this paper, we present E-seaML, a novel secure aggregation protocol with high communication and computation efficiency. E-seaML only requires one round of communication in the aggregation phase and it is up to 318x and 1224x faster for the user and the server (respectively) as compared to its most efficient counterpart. E-seaML also allows for efficiently verifying the integrity of the final model by allowing the aggregation server to generate a proof of honest aggregation for the participating users. This high efficiency and versatility is achieved by extending (and weakening) the assumption of the existing works on the set of honest parties (i.e., users) to a set of assisting nodes. Therefore, we assume a set of assisting nodes which assist the aggregation server in the aggregation process. We also discuss, given the minimal computation and communication overhead on the assisting nodes, how one could assume a set of rotating users to as assisting nodes in each iteration. We provide the open-sourced implementation of E-seaML for public verifiability and testing.","created":"2023-04-07","meta":{"link":"http://arxiv.org/abs/2304.03841v2","tag":"data-quality"}}
{"title":"Efficient Deduplication and Leakage Detection in Large Scale Image Datasets with a focus on the CrowdAI Mapping Challenge Dataset","abstract":"Recent advancements in deep learning and computer vision have led to widespread use of deep neural networks to extract building footprints from remote-sensing imagery. The success of such methods relies on the availability of large databases of high-resolution remote sensing images with high-quality annotations. The CrowdAI Mapping Challenge Dataset is one of these datasets that has been used extensively in recent years to train deep neural networks. This dataset consists of $ \\sim\\ $280k training images and $ \\sim\\ $60k testing images, with polygonal building annotations for all images. However, issues such as low-quality and incorrect annotations, extensive duplication of image samples, and data leakage significantly reduce the utility of deep neural networks trained on the dataset. Therefore, it is an imperative pre-condition to adopt a data validation pipeline that evaluates the quality of the dataset prior to its use. To this end, we propose a drop-in pipeline that employs perceptual hashing techniques for efficient de-duplication of the dataset and identification of instances of data leakage between training and testing splits. In our experiments, we demonstrate that nearly 250k($ \\sim\\ $90%) images in the training split were identical. Moreover, our analysis on the validation split demonstrates that roughly 56k of the 60k images also appear in the training split, resulting in a data leakage of 93%. The source code used for the analysis and de-duplication of the CrowdAI Mapping Challenge dataset is publicly available at https://github.com/yeshwanth95/CrowdAI_Hash_and_search .","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02296v1","tag":"data-quality"}}
{"title":"Polarization aberrations in next-generation giant segmented mirror telescopes (GSMTs) I. Effect on the coronagraphic performance","abstract":"Next-generation large segmented mirror telescopes are expected to perform direct imaging and characterization of Earth-like rocky planets, which requires contrast limits of $10^{-7}$ to $10^{-8}$ at wavelengths from I to J band. One critical aspect affecting the raw on-sky contrast are polarization aberrations arising from the reflection from the telescope's mirror surfaces and instrument optics. We simulate the polarization aberrations and estimate their effect on the achievable contrast for three next-generation ground-based large segmented mirror telescopes. We performed ray-tracing in Zemax and computed the polarization aberrations and Jones pupil maps using the polarization ray-tracing algorithm. The impact of these aberrations on the contrast is estimated by propagating the Jones pupil maps through a set of idealized coronagraphs using hcipy, a physical optics-based simulation framework. The optical modeling of the giant segmented mirror telescopes (GSMTs) shows that polarization aberrations create significant leakage through a coronagraphic system. The dominant aberration is retardance defocus, which originates from the steep angles on the primary and secondary mirrors. The retardance defocus limits the contrast to $10^{-5}$ to $10^{-4}$ at 1 $\\lambda/D$ at visible wavelengths, and $10^{-5}$ to $10^{-6}$ at infrared wavelengths. The simulations also show that the coating plays a major role in determining the strength of the aberrations. Polarization aberrations will need to be considered during the design of high-contrast imaging instruments for the next generation of extremely large telescopes. This can be achieved either through compensation optics, robust coronagraphs, specialized coatings, calibration, and data analysis approaches or by incorporating polarimetry with high-contrast imaging to measure these effects.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.02079v1","tag":"data-quality"}}
{"title":"Side Channel-Assisted Inference Leakage from Machine Learning-based ECG Classification","abstract":"The Electrocardiogram (ECG) measures the electrical cardiac activity generated by the heart to detect abnormal heartbeat and heart attack. However, the irregular occurrence of the abnormalities demands continuous monitoring of heartbeats. Machine learning techniques are leveraged to automate the task to reduce labor work needed during monitoring. In recent years, many companies have launched products with ECG monitoring and irregular heartbeat alert. Among all classification algorithms, the time series-based algorithm dynamic time warping (DTW) is widely adopted to undertake the ECG classification task. Though progress has been achieved, the DTW-based ECG classification also brings a new attacking vector of leaking the patients' diagnosis results. This paper shows that the ECG input samples' labels can be stolen via a side-channel attack, Flush+Reload. In particular, we first identify the vulnerability of DTW for ECG classification, i.e., the correlation between warping path choice and prediction results. Then we implement an attack that leverages Flush+Reload to monitor the warping path selection with known ECG data and then build a predictor for constructing the relation between warping path selection and labels of input ECG samples. Based on experiments, we find that the Flush+Reload-based inference leakage can achieve an 84.0\\% attacking success rate to identify the labels of the two samples in DTW.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01990v1","tag":"data-quality"}}
{"title":"Privacy-Preserving Federated Discovery of DNA Motifs with Differential Privacy","abstract":"DNA motif discovery is an important issue in gene research, which aims to identify transcription factor binding sites (i.e., motifs) in DNA sequences to reveal the mechanisms that regulate gene expression. However, the phenomenon of data silos and the problem of privacy leakage have seriously hindered the development of DNA motif discovery. On the one hand, the phenomenon of data silos makes data collection difficult. On the other hand, the collection and use of DNA data become complicated and difficult because DNA is sensitive private information. In this context, how discovering DNA motifs under the premise of ensuring privacy and security and alleviating data silos has become a very important issue. Therefore, this paper proposes a novel method, namely DP-FLMD, to address this problem. Note that this is the first application of federated learning to the field of genetics research. The federated learning technique is used to solve the problem of data silos. It has the advantage of enabling multiple participants to train models together and providing privacy protection services. To address the challenges of federated learning in terms of communication costs, this paper applies a sampling method and a strategy for reducing communication costs to DP-FLMD. In addition, differential privacy, a privacy protection technique with rigorous mathematical proof, is also applied to DP-FLMD. Experiments on the DNA datasets show that DP-FLMD has high mining accuracy and runtime efficiency, and the performance of the algorithm is affected by some parameters.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01689v1","tag":"data-quality"}}
{"title":"PEOPL: Characterizing Privately Encoded Open Datasets with Public Labels","abstract":"Allowing organizations to share their data for training of machine learning (ML) models without unintended information leakage is an open problem in practice. A promising technique for this still-open problem is to train models on the encoded data. Our approach, called Privately Encoded Open Datasets with Public Labels (PEOPL), uses a certain class of randomly constructed transforms to encode sensitive data. Organizations publish their randomly encoded data and associated raw labels for ML training, where training is done without knowledge of the encoding realization. We investigate several important aspects of this problem: We introduce information-theoretic scores for privacy and utility, which quantify the average performance of an unfaithful user (e.g., adversary) and a faithful user (e.g., model developer) that have access to the published encoded data. We then theoretically characterize primitives in building families of encoding schemes that motivate the use of random deep neural networks. Empirically, we compare the performance of our randomized encoding scheme and a linear scheme to a suite of computational attacks, and we also show that our scheme achieves competitive prediction accuracy to raw-sample baselines. Moreover, we demonstrate that multiple institutions, using independent random encoders, can collaborate to train improved ML models.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2304.00047v1","tag":"data-quality"}}
{"title":"EMShepherd: Detecting Adversarial Samples via Side-channel Leakage","abstract":"Deep Neural Networks (DNN) are vulnerable to adversarial perturbations-small changes crafted deliberately on the input to mislead the model for wrong predictions. Adversarial attacks have disastrous consequences for deep learning-empowered critical applications. Existing defense and detection techniques both require extensive knowledge of the model, testing inputs, and even execution details. They are not viable for general deep learning implementations where the model internal is unknown, a common 'black-box' scenario for model users. Inspired by the fact that electromagnetic (EM) emanations of a model inference are dependent on both operations and data and may contain footprints of different input classes, we propose a framework, EMShepherd, to capture EM traces of model execution, perform processing on traces and exploit them for adversarial detection. Only benign samples and their EM traces are used to train the adversarial detector: a set of EM classifiers and class-specific unsupervised anomaly detectors. When the victim model system is under attack by an adversarial example, the model execution will be different from executions for the known classes, and the EM trace will be different. We demonstrate that our air-gapped EMShepherd can effectively detect different adversarial attacks on a commonly used FPGA deep learning accelerator for both Fashion MNIST and CIFAR-10 datasets. It achieves a 100% detection rate on most types of adversarial samples, which is comparable to the state-of-the-art 'white-box' software-based detectors.","created":"2023-03-27","meta":{"link":"http://arxiv.org/abs/2303.15571v1","tag":"data-quality"}}
{"title":"The Resource Problem of Using Linear Layer Leakage Attack in Federated Learning","abstract":"Secure aggregation promises a heightened level of privacy in federated learning, maintaining that a server only has access to a decrypted aggregate update. Within this setting, linear layer leakage methods are the only data reconstruction attacks able to scale and achieve a high leakage rate regardless of the number of clients or batch size. This is done through increasing the size of an injected fully-connected (FC) layer. However, this results in a resource overhead which grows larger with an increasing number of clients. We show that this resource overhead is caused by an incorrect perspective in all prior work that treats an attack on an aggregate update in the same way as an individual update with a larger batch size. Instead, by attacking the update from the perspective that aggregation is combining multiple individual updates, this allows the application of sparsity to alleviate resource overhead. We show that the use of sparsity can decrease the model size overhead by over 327$\\times$ and the computation time by 3.34$\\times$ compared to SOTA while maintaining equivalent total leakage rate, 77% even with $1000$ clients in aggregation.","created":"2023-03-27","meta":{"link":"http://arxiv.org/abs/2303.14868v1","tag":"data-quality"}}
{"title":"A Generalized Look at Federated Learning: Survey and Perspectives","abstract":"Federated learning (FL) refers to a distributed machine learning framework involving learning from several decentralized edge clients without sharing local dataset. This distributed strategy prevents data leakage and enables on-device training as it updates the global model based on the local model updates. Despite offering several advantages, including data privacy and scalability, FL poses challenges such as statistical and system heterogeneity of data in federated networks, communication bottlenecks, privacy and security issues. This survey contains a systematic summarization of previous work, studies, and experiments on FL and presents a list of possibilities for FL across a range of applications and use cases. Other than that, various challenges of implementing FL and promising directions revolving around the corresponding challenges are provided.","created":"2023-03-26","meta":{"link":"http://arxiv.org/abs/2303.14787v1","tag":"data-quality"}}
{"title":"Federated Learning for Metaverse: A Survey","abstract":"The metaverse, which is at the stage of innovation and exploration, faces the dilemma of data collection and the problem of private data leakage in the process of development. This can seriously hinder the widespread deployment of the metaverse. Fortunately, federated learning (FL) is a solution to the above problems. FL is a distributed machine learning paradigm with privacy-preserving features designed for a large number of edge devices. Federated learning for metaverse (FL4M) will be a powerful tool. Because FL allows edge devices to participate in training tasks locally using their own data, computational power, and model-building capabilities. Applying FL to the metaverse not only protects the data privacy of participants but also reduces the need for high computing power and high memory on servers. Until now, there have been many studies about FL and the metaverse, respectively. In this paper, we review some of the early advances of FL4M, which will be a research direction with unlimited development potential. We first introduce the concepts of metaverse and FL, respectively. Besides, we discuss the convergence of key metaverse technologies and FL in detail, such as big data, communication technology, the Internet of Things, edge computing, blockchain, and extended reality. Finally, we discuss some key challenges and promising directions of FL4M in detail. In summary, we hope that our up-to-date brief survey can help people better understand FL4M and build a fair, open, and secure metaverse.","created":"2023-03-23","meta":{"link":"http://arxiv.org/abs/2303.17987v1","tag":"data-quality"}}
{"title":"Online search is more likely to lead students to validate true news than to refute false ones","abstract":"With the spread of high-speed Internet and portable smart devices, the way people access and consume information has drastically changed. However, this presents many challenges, including information overload, personal data leakage, and misinformation diffusion. Across the spectrum of risks that Internet users can face nowadays, this work focuses on understanding how young people perceive and deal with false information. Within an experimental campaign involving 261 students, we presented to the participants six different news items and invited them to browse the Internet to assess the veracity of the presented information. Our results suggest that online search is more likely to lead students to validate true news than to refute false ones. We found that students change their opinion related to a specific piece of information more often than their global idea about a broader topic. Also, our experiment reflected that the majority of participants rely on online sources to obtain information and access the news, and those getting information from books and Internet browsing are the most accurate in assessing the veracity of a news item. This work provides a principled understanding of how young people perceive and distinguish true and false pieces of information, identifying strengths and weaknesses amidst young subjects and contributing to build tailored digital information literacy strategies for youth.","created":"2023-03-23","meta":{"link":"http://arxiv.org/abs/2303.13138v1","tag":"data-quality"}}
{"title":"When Evolutionary Computation Meets Privacy","abstract":"Recently, evolutionary computation (EC) has been promoted by machine learning, distributed computing, and big data technologies, resulting in new research directions of EC like distributed EC and surrogate-assisted EC. These advances have significantly improved the performance and the application scope of EC, but also trigger privacy leakages, such as the leakage of optimal results and surrogate model. Accordingly, evolutionary computation combined with privacy protection is becoming an emerging topic. However, privacy concerns in evolutionary computation lack a systematic exploration, especially for the object, motivation, position, and method of privacy protection. To this end, in this paper, we discuss three typical optimization paradigms (i.e., \\textit{centralized optimization, distributed optimization, and data-driven optimization}) to characterize optimization modes of evolutionary computation and propose BOOM to sort out privacy concerns in evolutionary computation. Specifically, the centralized optimization paradigm allows clients to outsource optimization problems to the centralized server and obtain optimization solutions from the server. While the distributed optimization paradigm exploits the storage and computational power of distributed devices to solve optimization problems. Also, the data-driven optimization paradigm utilizes data collected in history to tackle optimization problems lacking explicit objective functions. Particularly, this paper adopts BOOM to characterize the object and motivation of privacy protection in three typical optimization paradigms and discusses potential privacy-preserving technologies balancing optimization performance and privacy guarantees in three typical optimization paradigms. Furthermore, this paper attempts to foresee some new research directions of privacy-preserving evolutionary computation.","created":"2023-03-22","meta":{"link":"http://arxiv.org/abs/2304.01205v1","tag":"data-quality"}}
{"title":"Do the CMB Temperature Fluctuations Conserve Parity?","abstract":"Observations of the Cosmic Microwave Background (CMB) have cemented the notion that the large-scale Universe is both statistically homogeneous and isotropic. But is it invariant also under mirror reflections? To probe this we require parity-sensitive statistics: for scalar observables, the simplest is the four-point function. We make the first measurements of the parity-odd CMB trispectrum, focusing on the large-scale ($2<\\ell<510$) temperature anisotropies measured by Planck. This is facilitated by new maximum-likelihood estimators for binned correlators, which account for mask convolution and leakage between even- and odd-parity components, and achieve optimal variances within $\\approx 20\\%$. We perform a blind test for parity violation by comparing a $\\chi^2$ statistic from Planck to theoretical expectations, using two suites of simulations to account for the possible likelihood non-Gaussianity and residual foregrounds. We find consistency at the $\\approx 0.5\\sigma$ level, yielding no evidence for parity violation, with roughly $250\\times$ the squared sensitivity of large scale structure measurements (according to mode-counting arguments), and with the advantage of linear physics, Gaussian statistics, and accurate mocks. The measured trispectra can be used to constrain physical models of inflationary parity violation, including Ghost Inflation, Cosmological Collider scenarios, and Chern-Simons gauge fields. Considering eight such models, we find no evidence for new physics, with a maximal detection significance of $2.0\\sigma$. These results suggest that the recent parity excesses seen in the BOSS galaxy survey are not primordial in origin. Tighter constraints can be wrought by including smaller scales (though rotational invariance washes out the flat-sky limit) and adding polarization data.","created":"2023-03-21","meta":{"link":"http://arxiv.org/abs/2303.12106v2","tag":"data-quality"}}
{"title":"End-to-End Integration of Speech Separation and Voice Activity Detection for Low-Latency Diarization of Telephone Conversations","abstract":"Recent works show that speech separation guided diarization (SSGD) is an increasingly promising direction, mainly thanks to the recent progress in speech separation. It performs diarization by first separating the speakers and then applying voice activity detection (VAD) on each separated stream. In this work we conduct an in-depth study of SSGD in the conversational telephone speech (CTS) domain, focusing mainly on low-latency streaming diarization applications. We consider three state-of-the-art speech separation (SSep) algorithms and study their performance both in online and offline scenarios, considering non-causal and causal implementations as well as continuous SSep (CSS) windowed inference. We compare different SSGD algorithms on two widely used CTS datasets: CALLHOME and Fisher Corpus (Part 1 and 2) and evaluate both separation and diarization performance. To improve performance, a novel, causal and computationally efficient leakage removal algorithm is proposed, which significantly decreases false alarms. We also explore, for the first time, fully end-to-end SSGD integration between SSep and VAD modules. Crucially, this enables fine-tuning on real-world data for which oracle speakers sources are not available. In particular, our best model achieves 8.8% DER on CALLHOME, which outperforms the current state-of-the-art end-to-end neural diarization model, despite being trained on an order of magnitude less data and having significantly lower latency, i.e., 0.1 vs. 1 seconds. Finally, we also show that the separated signals can be readily used also for automatic speech recognition, reaching performance close to using oracle sources in some configurations.","created":"2023-03-21","meta":{"link":"http://arxiv.org/abs/2303.12002v1","tag":"data-quality"}}
{"title":"Report of the Medical Image De-Identification (MIDI) Task Group -- Best Practices and Recommendations","abstract":"This report addresses the technical aspects of de-identification of medical images of human subjects and biospecimens, such that re-identification risk of ethical, moral, and legal concern is sufficiently reduced to allow unrestricted public sharing for any purpose, regardless of the jurisdiction of the source and distribution sites. All medical images, regardless of the mode of acquisition, are considered, though the primary emphasis is on those with accompanying data elements, especially those encoded in formats in which the data elements are embedded, particularly Digital Imaging and Communications in Medicine (DICOM). These images include image-like objects such as Segmentations, Parametric Maps, and Radiotherapy (RT) Dose objects. The scope also includes related non-image objects, such as RT Structure Sets, Plans and Dose Volume Histograms, Structured Reports, and Presentation States. Only de-identification of publicly released data is considered, and alternative approaches to privacy preservation, such as federated learning for artificial intelligence (AI) model development, are out of scope, as are issues of privacy leakage from AI model sharing. Only technical issues of public sharing are addressed.","created":"2023-03-18","meta":{"link":"http://arxiv.org/abs/2303.10473v2","tag":"data-quality"}}
{"title":"Efficient and Secure Federated Learning for Financial Applications","abstract":"The conventional machine learning (ML) and deep learning approaches need to share customers' sensitive information with an external credit bureau to generate a prediction model that opens the door to privacy leakage. This leakage risk makes financial companies face an enormous challenge in their cooperation. Federated learning is a machine learning setting that can protect data privacy, but the high communication cost is often the bottleneck of the federated systems, especially for large neural networks. Limiting the number and size of communications is necessary for the practical training of large neural structures. Gradient sparsification has received increasing attention as a method to reduce communication cost, which only updates significant gradients and accumulates insignificant gradients locally. However, the secure aggregation framework cannot directly use gradient sparsification. This article proposes two sparsification methods to reduce communication cost in federated learning. One is a time-varying hierarchical sparsification method for model parameter update, which solves the problem of maintaining model accuracy after high ratio sparsity. It can significantly reduce the cost of a single communication. The other is to apply the sparsification method to the secure aggregation framework. We sparse the encryption mask matrix to reduce the cost of communication while protecting privacy. Experiments show that under different Non-IID experiment settings, our method can reduce the upload communication cost to about 2.9% to 18.9% of the conventional federated learning algorithm when the sparse rate is 0.01.","created":"2023-03-15","meta":{"link":"http://arxiv.org/abs/2303.08355v1","tag":"data-quality"}}
{"title":"Inferential Privacy: From Impossibility to Database Privacy","abstract":"We investigate the possibility of guaranteeing inferential privacy for mechanisms that release useful information about some data containing sensitive information, denoted by $X$. We describe a general model of utility and privacy in which utility is achieved by disclosing the value of low-entropy features of $X$, while privacy is maintained by keeping high-entropy features of $X$ secret. Adopting this model, we prove that meaningful inferential privacy guarantees can be obtained, even though this is commonly considered to be impossible by the well-known result of Dwork and Naor. Then, we specifically discuss a privacy measure called pointwise maximal leakage (PML) whose guarantees are of the inferential type. We use PML to show that differential privacy admits an inferential formulation: it describes the information leaking about a single entry in a database assuming that every other entry is known, and considering the worst-case distribution on the data. Moreover, we define inferential instance privacy (IIP) as a bound on the (non-conditional) information leaking about a single entry in the database under the worst-case distribution, and show that it is equivalent to free-lunch privacy. Overall, our approach to privacy unifies, formalizes, and explains many existing ideas, e.g., why the informed adversary assumption may lead to underestimating the information leaking about each entry in the database. Furthermore, insights obtained from our results suggest general methods for improving privacy analyses; for example, we argue that smaller privacy parameters can be obtained by excluding low-entropy prior distributions from protection.","created":"2023-03-14","meta":{"link":"http://arxiv.org/abs/2303.07782v1","tag":"data-quality"}}
{"title":"Automated Vulnerability Detection in Source Code Using Quantum Natural Language Processing","abstract":"One of the most important challenges in the field of software code audit is the presence of vulnerabilities in software source code. These flaws are highly likely ex-ploited and lead to system compromise, data leakage, or denial of ser-vice. C and C++ open source code are now available in order to create a large-scale, classical machine-learning and quantum machine-learning system for function-level vulnerability identification. We assembled a siz-able dataset of millions of open-source functions that point to poten-tial exploits. We created an efficient and scalable vulnerability detection method based on a deep neural network model Long Short Term Memory (LSTM), and quantum machine learning model Long Short Term Memory (QLSTM), that can learn features extracted from the source codes. The source code is first converted into a minimal intermediate representation to remove the pointless components and shorten the de-pendency. Therefore, We keep the semantic and syntactic information using state of the art word embedding algorithms such as Glove and fastText. The embedded vectors are subsequently fed into the classical and quantum convolutional neural networks to classify the possible vulnerabilities. To measure the performance, we used evaluation metrics such as F1 score, precision, re-call, accuracy, and total execution time. We made a comparison between the results derived from the classical LSTM and quantum LSTM using basic feature representation as well as semantic and syntactic represen-tation. We found that the QLSTM with semantic and syntactic features detects significantly accurate vulnerability and runs faster than its classical counterpart.","created":"2023-03-13","meta":{"link":"http://arxiv.org/abs/2303.07525v1","tag":"data-quality"}}
{"title":"Model Extraction Attacks on Split Federated Learning","abstract":"Federated Learning (FL) is a popular collaborative learning scheme involving multiple clients and a server. FL focuses on protecting clients' data but turns out to be highly vulnerable to Intellectual Property (IP) threats. Since FL periodically collects and distributes the model parameters, a free-rider can download the latest model and thus steal model IP. Split Federated Learning (SFL), a recent variant of FL that supports training with resource-constrained clients, splits the model into two, giving one part of the model to clients (client-side model), and the remaining part to the server (server-side model). Thus SFL prevents model leakage by design. Moreover, by blocking prediction queries, it can be made resistant to advanced IP threats such as traditional Model Extraction (ME) attacks. While SFL is better than FL in terms of providing IP protection, it is still vulnerable. In this paper, we expose the vulnerability of SFL and show how malicious clients can launch ME attacks by querying the gradient information from the server side. We propose five variants of ME attack which differs in the gradient usage as well as in the data assumptions. We show that under practical cases, the proposed ME attacks work exceptionally well for SFL. For instance, when the server-side model has five layers, our proposed ME attack can achieve over 90% accuracy with less than 2% accuracy degradation with VGG-11 on CIFAR-10.","created":"2023-03-13","meta":{"link":"http://arxiv.org/abs/2303.08581v1","tag":"data-quality"}}
{"title":"VMCDL: Vulnerability Mining Based on Cascaded Deep Learning Under Source Control Flow","abstract":"With the rapid development of the computer industry and computer software, the risk of software vulnerabilities being exploited has greatly increased. However, there are still many shortcomings in the existing mining techniques for leakage source research, such as high false alarm rate, coarse-grained detection, and dependence on expert experience. In this paper, we mainly use the c/c++ source code data of the SARD dataset, process the source code of CWE476, CWE469, CWE516 and CWE570 vulnerability types, test the Joern vulnerability scanning function of the cutting-edge tool, and propose a new cascading deep learning model VMCDL based on source code control flow to effectively detect vulnerabilities. First, this paper uses joern to locate and extract sensitive functions and statements to form a sensitive statement library of vulnerable code. Then, the CFG flow vulnerability code snippets are generated by bidirectional breadth-first traversal, and then vectorized by Doc2vec. Finally, the cascade deep learning model based on source code control flow is used for classification to obtain the classification results. In the experimental evaluation, we give the test results of Joern on specific vulnerabilities, and give the confusion matrix and label data of the binary classification results of the model algorithm on single vulnerability type source code, and compare and verify the five indicators of FPR, FNR, ACC, P and F1, respectively reaching 10.30%, 5.20%, 92.50%,85.10% and 85.40%,which shows that it can effectively reduce the false alarm rate of static analysis.","created":"2023-03-13","meta":{"link":"http://arxiv.org/abs/2303.07128v2","tag":"data-quality"}}
{"title":"A Novel Method Combines Moving Fronts, Data Decomposition and Deep Learning to Forecast Intricate Time Series","abstract":"A univariate time series with high variability can pose a challenge even to Deep Neural Network (DNN). To overcome this, a univariate time series is decomposed into simpler constituent series, whose sum equals the original series. As demonstrated in this article, the conventional one-time decomposition technique suffers from a leak of information from the future, referred to as a data leak. In this work, a novel Moving Front (MF) method is proposed to prevent data leakage, so that the decomposed series can be treated like other time series. Indian Summer Monsoon Rainfall (ISMR) is a very complex time series, which poses a challenge to DNN and is therefore selected as an example. From the many signal processing tools available, Empirical Wavelet Transform (EWT) was chosen for decomposing the ISMR into simpler constituent series, as it was found to be more effective than the other popular algorithm, Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN). The proposed MF method was used to generate the constituent leakage-free time series. Predictions and forecasts were made by state-of-the-art Long and Short-Term Memory (LSTM) network architecture, especially suitable for making predictions of sequential patterns. The constituent MF series has been divided into training, testing, and forecasting. It has been found that the model (EWT-MF-LSTM) developed here made exceptionally good train and test predictions, as well as Walk-Forward Validation (WFV), forecasts with Performance Parameter ($PP$) values of 0.99, 0.86, and 0.95, respectively, where $PP$ = 1.0 signifies perfect reproduction of the data.","created":"2023-03-11","meta":{"link":"http://arxiv.org/abs/2303.06394v1","tag":"data-quality"}}
{"title":"Importance of Aligning Training Strategy with Evaluation for Diffusion Models in 3D Multiclass Segmentation","abstract":"Recently, denoising diffusion probabilistic models (DDPM) have been applied to image segmentation by generating segmentation masks conditioned on images, while the applications were mainly limited to 2D networks without exploiting potential benefits from the 3D formulation. In this work, for the first time, DDPMs are used for 3D multiclass image segmentation. We make three key contributions that all focus on aligning the training strategy with the evaluation methodology, and improving efficiency. Firstly, the model predicts segmentation masks instead of sampled noise and is optimised directly via Dice loss. Secondly, the predicted mask in the previous time step is recycled to generate noise-corrupted masks to reduce information leakage. Finally, the diffusion process during training was reduced to five steps, the same as the evaluation. Through studies on two large multiclass data sets (prostate MR and abdominal CT), we demonstrated significantly improved performance compared to existing DDPMs, and reached competitive performance with non-diffusion segmentation models, based on U-net, within the same compute budget. The JAX-based diffusion framework has been released on https://github.com/mathpluscode/ImgX-DiffSeg.","created":"2023-03-10","meta":{"link":"http://arxiv.org/abs/2303.06040v1","tag":"data-quality"}}
{"title":"Considerations on the Theory of Training Models with Differential Privacy","abstract":"In federated learning collaborative learning takes place by a set of clients who each want to remain in control of how their local training data is used, in particular, how can each client's local training data remain private? Differential privacy is one method to limit privacy leakage. We provide a general overview of its framework and provable properties, adopt the more recent hypothesis based definition called Gaussian DP or $f$-DP, and discuss Differentially Private Stochastic Gradient Descent (DP-SGD). We stay at a meta level and attempt intuitive explanations and insights \\textit{in this book chapter}.","created":"2023-03-08","meta":{"link":"http://arxiv.org/abs/2303.04676v1","tag":"data-quality"}}
{"title":"Privacy-preserving and Uncertainty-aware Federated Trajectory Prediction for Connected Autonomous Vehicles","abstract":"Deep learning is the method of choice for trajectory prediction for autonomous vehicles. Unfortunately, its data-hungry nature implicitly requires the availability of sufficiently rich and high-quality centralized datasets, which easily leads to privacy leakage. Besides, uncertainty-awareness becomes increasingly important for safety-crucial cyber physical systems whose prediction module heavily relies on machine learning tools. In this paper, we relax the data collection requirement and enhance uncertainty-awareness by using Federated Learning on Connected Autonomous Vehicles with an uncertainty-aware global objective. We name our algorithm as FLTP. We further introduce ALFLTP which boosts FLTP via using active learning techniques in adaptatively selecting participating clients. We consider both negative log-likelihood (NLL) and aleatoric uncertainty (AU) as client selection metrics. Experiments on Argoverse dataset show that FLTP significantly outperforms the model trained on local data. In addition, ALFLTP-AU converges faster in training regression loss and performs better in terms of NLL, minADE and MR than FLTP in most rounds, and has more stable round-wise performance than ALFLTP-NLL.","created":"2023-03-08","meta":{"link":"http://arxiv.org/abs/2303.04340v1","tag":"data-quality"}}
{"title":"Private Read-Update-Write with Controllable Information Leakage for Storage-Efficient Federated Learning with Top $r$ Sparsification","abstract":"In federated learning (FL), a machine learning (ML) model is collectively trained by a large number of users, using their private data in their local devices. With top $r$ sparsification in FL, the users only upload the most significant $r$ fraction of updates, and the servers only send the most significant $r'$ fraction of parameters to the users in order to reduce the communication cost. However, the values and the indices of the sparse updates leak information about the users' private data. In this work, we consider an FL setting where $N$ non-colluding databases store the model to be trained, from which the users download and update sparse parameters privately, without revealing the values of the updates or their indices to the databases. We propose four schemes with different properties to perform this task while achieving the minimum communication costs, and show that the information theoretic privacy of both values and positions of the sparse updates can be guaranteed. This is achieved at a considerable storage cost, though. To alleviate this, we generalize the schemes in such a way that the storage cost is reduced at the expense of a certain amount of information leakage, using a model segmentation mechanism. In general, we provide the tradeoff between communication cost, storage cost and information leakage in private FL with top $r$ sparsification.","created":"2023-03-07","meta":{"link":"http://arxiv.org/abs/2303.04123v1","tag":"data-quality"}}
{"title":"Bootstrap The Original Latent: Learning a Private Model from a Black-box Model","abstract":"In this paper, considering the balance of data/model privacy of model owners and user needs, we propose a new setting called Back-Propagated Black-Box Adaptation (BPBA) for users to better train their private models via the guidance of the back-propagated results of a Black-box foundation/source model. Our setting can ease the usage of foundation/source models as well as prevent the leakage and misuse of foundation/source models. Moreover, we also propose a new training strategy called Bootstrap The Original Latent (BTOL) to fully utilize the foundation/source models. Our strategy consists of a domain adapter and a freeze-and-thaw strategy. We apply our BTOL under BPBA and Black-box UDA settings on three different datasets. Experiments show that our strategy is efficient and robust in various settings without manual augmentations.","created":"2023-03-07","meta":{"link":"http://arxiv.org/abs/2303.03709v4","tag":"data-quality"}}
{"title":"Can Membership Inferencing be Refuted?","abstract":"Membership inference (MI) attack is currently the most popular test for measuring privacy leakage in machine learning models. Given a machine learning model, a data point and some auxiliary information, the goal of an MI attack is to determine whether the data point was used to train the model. In this work, we study the reliability of membership inference attacks in practice. Specifically, we show that a model owner can plausibly refute the result of a membership inference test on a data point $x$ by constructing a proof of repudiation that proves that the model was trained without $x$. We design efficient algorithms to construct proofs of repudiation for all data points of the training dataset. Our empirical evaluation demonstrates the practical feasibility of our algorithm by constructing proofs of repudiation for popular machine learning models on MNIST and CIFAR-10. Consequently, our results call for a re-evaluation of the implications of membership inference attacks in practice.","created":"2023-03-07","meta":{"link":"http://arxiv.org/abs/2303.03648v2","tag":"data-quality"}}
{"title":"Students Parrot Their Teachers: Membership Inference on Model Distillation","abstract":"Model distillation is frequently proposed as a technique to reduce the privacy leakage of machine learning. These empirical privacy defenses rely on the intuition that distilled ``student'' models protect the privacy of training data, as they only interact with this data indirectly through a ``teacher'' model. In this work, we design membership inference attacks to systematically study the privacy provided by knowledge distillation to both the teacher and student training sets. Our new attacks show that distillation alone provides only limited privacy across a number of domains. We explain the success of our attacks on distillation by showing that membership inference attacks on a private dataset can succeed even if the target model is *never* queried on any actual training points, but only on inputs whose predictions are highly influenced by training data. Finally, we show that our attacks are strongest when student and teacher sets are similar, or when the attacker can poison the teacher set.","created":"2023-03-06","meta":{"link":"http://arxiv.org/abs/2303.03446v1","tag":"data-quality"}}
{"title":"Monitoring Fluid Saturation in Reservoirs Using Time-Lapse Full-Waveform Inversion","abstract":"Monitoring the rock-physics properties of the subsurface is of great importance for reservoir management. For either oil and gas applications or CO2 storage, seismic data are a valuable source of information for tracking changes in elastic properties which can be related to fluids saturation and pressure changes within the reservoir. Changes in elastic properties can be estimated with time-lapse full-waveform inversion. Monitoring rock-physics properties, such as saturation, with time-lapse full-waveform inversion is usually a two-step process: first, elastic properties are estimated with full-waveform inversion, then, the rock-physics properties are estimated with rock-physics inversion. However, multiparameter time-lapse full-waveform inversion is prone to crosstalk between parameter classes across different vintages. This leads to leakage from one parameter class to another, which, in turn, can introduce large errors in the estimated rock-physics parameters. To avoid inaccuracies caused by crosstalk and the two-step inversion strategy, we reformulate time-lapse full-waveform inversion to estimate directly the changes in the rock-physics properties. Using Gassmann's model, we adopt a new parameterization containing porosity, clay content, and water saturation. In the context of reservoir monitoring, changes are assumed to be induced by fluid substitution only. The porosity and clay content can thus be kept constant during time-lapse inversion. We compare this parameterization with the usual density-velocity parameterization for different benchmark models. Results indicate that the proposed parameterization eliminates crosstalk between parameters of different vintages, leading to more accurate estimation of saturation changes. We also show that using the parameterization based on porosity, clay content, and water saturation, the elastic changes can be monitored more accurately.","created":"2023-03-06","meta":{"link":"http://arxiv.org/abs/2303.03136v3","tag":"data-quality"}}
{"title":"Data Portraits: Recording Foundation Model Training Data","abstract":"Foundation models are trained on increasingly immense and opaque datasets. Even while these models are now key in AI system building, it can be difficult to answer the straightforward question: has the model already encountered a given example during training? We therefore propose a widespread adoption of Data Portraits: artifacts that record training data and allow for downstream inspection. First we outline the properties of such an artifact and discuss how existing solutions can be used to increase transparency. We then propose and implement a solution based on data sketching, stressing fast and space efficient querying. Using our tool, we document a popular large language modeling corpus (the Pile) and show that our solution enables answering questions about test set leakage and model plagiarism. Our tool is lightweight and fast, costing only 3% of the dataset size in overhead. We release a demo of our tools at dataportraits.org and call on dataset and model creators to release Data Portraits as a complement to current documentation practices.","created":"2023-03-06","meta":{"link":"http://arxiv.org/abs/2303.03919v1","tag":"data-quality"}}
{"title":"Synthetic Misinformers: Generating and Combating Multimodal Misinformation","abstract":"With the expansion of social media and the increasing dissemination of multimedia content, the spread of misinformation has become a major concern. This necessitates effective strategies for multimodal misinformation detection (MMD) that detect whether the combination of an image and its accompanying text could mislead or misinform. Due to the data-intensive nature of deep neural networks and the labor-intensive process of manual annotation, researchers have been exploring various methods for automatically generating synthetic multimodal misinformation - which we refer to as Synthetic Misinformers - in order to train MMD models. However, limited evaluation on real-world misinformation and a lack of comparisons with other Synthetic Misinformers makes difficult to assess progress in the field. To address this, we perform a comparative study on existing and new Synthetic Misinformers that involves (1) out-of-context (OOC) image-caption pairs, (2) cross-modal named entity inconsistency (NEI) as well as (3) hybrid approaches and we evaluate them against real-world misinformation; using the COSMOS benchmark. The comparative study showed that our proposed CLIP-based Named Entity Swapping can lead to MMD models that surpass other OOC and NEI Misinformers in terms of multimodal accuracy and that hybrid approaches can lead to even higher detection accuracy. Nevertheless, after alleviating information leakage from the COSMOS evaluation protocol, low Sensitivity scores indicate that the task is significantly more challenging than previous studies suggested. Finally, our findings showed that NEI-based Synthetic Misinformers tend to suffer from a unimodal bias, where text-only MMDs can outperform multimodal ones.","created":"2023-03-02","meta":{"link":"http://arxiv.org/abs/2303.01217v1","tag":"data-quality"}}
{"title":"On the Lift, Related Privacy Measures, and Applications to Privacy-Utility Tradeoffs","abstract":"This paper investigates lift, the likelihood ratio between the posterior and prior belief about sensitive features in a dataset. Maximum and minimum lifts over sensitive features quantify the adversary's knowledge gain and should be bounded to protect privacy. We demonstrate that max and min lifts have a distinct range of values and probability of appearance in the dataset, referred to as \\emph{lift asymmetry}. We propose asymmetric local information privacy (ALIP) as a compatible privacy notion with lift asymmetry, where different bounds can be applied to min and max lifts. We use ALIP in the watchdog and optimal random response (ORR) mechanisms, the main methods to achieve lift-based privacy. It is shown that ALIP enhances utility in these methods compared to existing local information privacy, which ensures the same (symmetric) bounds on both max and min lifts. We propose subset merging for the watchdog mechanism to improve data utility and subset random response for the ORR to reduce complexity. We then investigate the related lift-based measures, including $\\ell_1$-norm, $\\chi^2$-privacy criterion, and $\\alpha$-lift. We reveal that they can only restrict max-lift, resulting in significant min-lift leakage. To overcome this problem, we propose corresponding lift-inverse measures to restrict the min-lift. We apply these lift-based and lift-inverse measures in the watchdog mechanism. We show that they can be considered as relaxations of ALIP, where a higher utility can be achieved by bounding only average max and min lifts.","created":"2023-03-02","meta":{"link":"http://arxiv.org/abs/2303.01017v1","tag":"data-quality"}}
{"title":"Applying Plain Transformers to Real-World Point Clouds","abstract":"Due to the lack of inductive bias, transformer-based models usually require a large amount of training data. The problem is especially concerning in 3D vision, as 3D data are harder to acquire and annotate. To overcome this problem, previous works modify the architecture of transformers to incorporate inductive biases by applying, e.g., local attention and down-sampling. Although they have achieved promising results, earlier works on transformers for point clouds have two issues. First, the power of plain transformers is still under-explored. Second, they focus on simple and small point clouds instead of complex real-world ones. This work revisits the plain transformers in real-world point cloud understanding. We first take a closer look at some fundamental components of plain transformers, e.g., patchifier and positional embedding, for both efficiency and performance. To close the performance gap due to the lack of inductive bias and annotated data, we investigate self-supervised pre-training with masked autoencoder (MAE). Specifically, we propose drop patch, which prevents information leakage and significantly improves the effectiveness of MAE. Our models achieve SOTA results in semantic segmentation on the S3DIS dataset and object detection on the ScanNet dataset with lower computational costs. Our work provides a new baseline for future research on transformers for point clouds.","created":"2023-02-28","meta":{"link":"http://arxiv.org/abs/2303.00086v2","tag":"data-quality"}}
{"title":"Collaborative Mean Estimation over Intermittently Connected Networks with Peer-To-Peer Privacy","abstract":"This work considers the problem of Distributed Mean Estimation (DME) over networks with intermittent connectivity, where the goal is to learn a global statistic over the data samples localized across distributed nodes with the help of a central server. To mitigate the impact of intermittent links, nodes can collaborate with their neighbors to compute local consensus which they forward to the central server. In such a setup, the communications between any pair of nodes must satisfy local differential privacy constraints. We study the tradeoff between collaborative relaying and privacy leakage due to the additional data sharing among nodes and, subsequently, propose a novel differentially private collaborative algorithm for DME to achieve the optimal tradeoff. Finally, we present numerical simulations to substantiate our theoretical findings.","created":"2023-02-28","meta":{"link":"http://arxiv.org/abs/2303.00035v1","tag":"data-quality"}}
{"title":"Time Series Anomaly Detection in Smart Homes: A Deep Learning Approach","abstract":"Fixing energy leakage caused by different anomalies can result in significant energy savings and extended appliance life. Further, it assists grid operators in scheduling their resources to meet the actual needs of end users, while helping end users reduce their energy costs. In this paper, we analyze the patterns pertaining to the power consumption of dishwashers used in two houses of the REFIT dataset. Then two autoencoder (AEs) with 1D-CNN and TCN as backbones are trained to differentiate the normal patterns from the abnormal ones. Our results indicate that TCN outperforms CNN1D in detecting anomalies in energy consumption. Finally, the data from the Fridge_Freezer and the Freezer of house No. 3 in REFIT is also used to evaluate our approach.","created":"2023-02-28","meta":{"link":"http://arxiv.org/abs/2302.14781v1","tag":"data-quality"}}
{"title":"Revisiting Variable Ordering for Real Quantifier Elimination using Machine Learning","abstract":"Cylindrical Algebraic Decomposition (CAD) is a key proof technique for formal verification of cyber-physical systems. CAD is computationally expensive, with worst-case doubly-exponential complexity. Selecting an optimal variable ordering is paramount to efficient use of CAD. Prior work has demonstrated that machine learning can be useful in determining efficient variable orderings. Much of this work has been driven by CAD problems extracted from applications of the MetiTarski theorem prover. In this paper, we revisit this prior work and consider issues of bias in existing training and test data. We observe that the classical MetiTarski benchmarks are heavily biased towards particular variable orderings. To address this, we apply symmetries to create a new dataset containing more than 41K MetiTarski challenges designed to remove bias. Furthermore, we evaluate issues of information leakage, and test the generalizability of our models on the new dataset.","created":"2023-02-27","meta":{"link":"http://arxiv.org/abs/2302.14038v1","tag":"data-quality"}}
{"title":"Do as You Say: Consistency Detection of Data Practice in Program Code and Privacy Policy in Mini-App","abstract":"Mini-app is an emerging form of mobile application that combines web technology with native capabilities. Its features, e.g., no need to download and no installation, have made it popular rapidly. However, privacy issues that violate the laws or regulations are breeding in the swiftly expanding mini-app ecosystem. The consistency between what the mini-app does about the data in the program code and what it declares in its privacy policy description is important. But no work has systematically investigated the privacy problem of the mini-app before. In this paper, to our best knowledge, we are the first to conduct the compliance detection of data practice and policy description in mini-apps. In this paper, we first customize a taint analysis method based on data entity dependency network to adapt to the characteristics of the JavaScript language in the mini-apps. Then, we transform data types and data operations to data practices in program codes and privacy policies, so as to finish a fine-grained consistency matching model.We crawl 100,000 mini-apps on WeChat client in the wild and extract 2,998 with a privacy policy. Among them, only 318 meet the consistency requirements, 2,680 are inconsistent, and the proportion of inconsistencies is as high as 89.4%. The inconsistency in the mini-app is very serious. Based on 6 real-world cases analyzed, in order to reduce this potential data leakage risk, we suggest that the developer should reduce the collection of irrelevant information and the straightforward use of templates, and the platform should provide data flow detection tools and privacy policy writing support.","created":"2023-02-27","meta":{"link":"http://arxiv.org/abs/2302.13860v1","tag":"data-quality"}}
{"title":"FLAG: Fast Label-Adaptive Aggregation for Multi-label Classification in Federated Learning","abstract":"Federated learning aims to share private data to maximize the data utility without privacy leakage. Previous federated learning research mainly focuses on multi-class classification problems. However, multi-label classification is a crucial research problem close to real-world data properties. Nevertheless, a limited number of federated learning studies explore this research problem. Existing studies of multi-label federated learning did not consider the characteristics of multi-label data, i.e., they used the concept of multi-class classification to verify their methods' performance, which means it will not be feasible to apply their methods to real-world applications. Therefore, this study proposed a new multi-label federated learning framework with a Clustering-based Multi-label Data Allocation (CMDA) and a novel aggregation method, Fast Label-Adaptive Aggregation (FLAG), for multi-label classification in the federated learning environment. The experimental results demonstrate that our methods only need less than 50\\% of training epochs and communication rounds to surpass the performance of state-of-the-art federated learning methods.","created":"2023-02-27","meta":{"link":"http://arxiv.org/abs/2302.13571v1","tag":"data-quality"}}
{"title":"Don't be fooled: label leakage in explanation methods and the importance of their quantitative evaluation","abstract":"Feature attribution methods identify which features of an input most influence a model's output. Most widely-used feature attribution methods (such as SHAP, LIME, and Grad-CAM) are \"class-dependent\" methods in that they generate a feature attribution vector as a function of class. In this work, we demonstrate that class-dependent methods can \"leak\" information about the selected class, making that class appear more likely than it is. Thus, an end user runs the risk of drawing false conclusions when interpreting an explanation generated by a class-dependent method. In contrast, we introduce \"distribution-aware\" methods, which favor explanations that keep the label's distribution close to its distribution given all features of the input. We introduce SHAP-KL and FastSHAP-KL, two baseline distribution-aware methods that compute Shapley values. Finally, we perform a comprehensive evaluation of seven class-dependent and three distribution-aware methods on three clinical datasets of different high-dimensional data types: images, biosignals, and text.","created":"2023-02-24","meta":{"link":"http://arxiv.org/abs/2302.12893v1","tag":"data-quality"}}
{"title":"FedDBL: Communication and Data Efficient Federated Deep-Broad Learning for Histopathological Tissue Classification","abstract":"Histopathological tissue classification is a fundamental task in computational pathology. Deep learning-based models have achieved superior performance but centralized training with data centralization suffers from the privacy leakage problem. Federated learning (FL) can safeguard privacy by keeping training samples locally, but existing FL-based frameworks require a large number of well-annotated training samples and numerous rounds of communication which hinder their practicability in the real-world clinical scenario. In this paper, we propose a universal and lightweight federated learning framework, named Federated Deep-Broad Learning (FedDBL), to achieve superior classification performance with limited training samples and only one-round communication. By simply associating a pre-trained deep learning feature extractor, a fast and lightweight broad learning inference system and a classical federated aggregation approach, FedDBL can dramatically reduce data dependency and improve communication efficiency. Five-fold cross-validation demonstrates that FedDBL greatly outperforms the competitors with only one-round communication and limited training samples, while it even achieves comparable performance with the ones under multiple-round communications. Furthermore, due to the lightweight design and one-round communication, FedDBL reduces the communication burden from 4.6GB to only 276.5KB per client using the ResNet-50 backbone at 50-round training. Since no data or deep model sharing across different clients, the privacy issue is well-solved and the model security is guaranteed with no model inversion attack risk. Code is available at https://github.com/tianpeng-deng/FedDBL.","created":"2023-02-24","meta":{"link":"http://arxiv.org/abs/2302.12662v1","tag":"data-quality"}}
{"title":"Data leakage in cross-modal retrieval training: A case study","abstract":"The recent progress in text-based audio retrieval was largely propelled by the release of suitable datasets. Since the manual creation of such datasets is a laborious task, obtaining data from online resources can be a cheap solution to create large-scale datasets. We study the recently proposed SoundDesc benchmark dataset, which was automatically sourced from the BBC Sound Effects web page. In our analysis, we find that SoundDesc contains several duplicates that cause leakage of training data to the evaluation data. This data leakage ultimately leads to overly optimistic retrieval performance estimates in previous benchmarks. We propose new training, validation, and testing splits for the dataset that we make available online. To avoid weak contamination of the test data, we pool audio files that share similar recording setups. In our experiments, we find that the new splits serve as a more challenging benchmark.","created":"2023-02-23","meta":{"link":"http://arxiv.org/abs/2302.12258v1","tag":"data-quality"}}
{"title":"A critical look at the evaluation of GNNs under heterophily: are we really making progress?","abstract":"Node classification is a classical graph representation learning task on which Graph Neural Networks (GNNs) have recently achieved strong results. However, it is often believed that standard GNNs only work well for homophilous graphs, i.e., graphs where edges tend to connect nodes of the same class. Graphs without this property are called heterophilous, and it is typically assumed that specialized methods are required to achieve strong performance on such graphs. In this work, we challenge this assumption. First, we show that the standard datasets used for evaluating heterophily-specific models have serious drawbacks, making results obtained by using them unreliable. The most significant of these drawbacks is the presence of a large number of duplicate nodes in the datsets Squirrel and Chameleon, which leads to train-test data leakage. We show that removing duplicate nodes strongly affects GNN performance on these datasets. Then, we propose a set of heterophilous graphs of varying properties that we believe can serve as a better benchmark for evaluating the performance of GNNs under heterophily. We show that standard GNNs achieve strong results on these heterophilous graphs, almost always outperforming specialized models. Our datasets and the code for reproducing our experiments are available at https://github.com/yandex-research/heterophilous-graphs","created":"2023-02-22","meta":{"link":"http://arxiv.org/abs/2302.11640v1","tag":"data-quality"}}
{"title":"Using Cryogenic CMOS Control Electronics To Enable A Two-Qubit Cross-Resonance Gate","abstract":"Qubit control electronics composed of CMOS circuits are of critical interest for next generation quantum computing systems. A CMOS-based application specific integrated circuit (ASIC) fabricated in 14nm FinFET technology was used to generate and sequence qubit control waveforms and demonstrate a two-qubit cross resonance gate between fixed frequency transmons. The controller was thermally anchored to the T = 4K stage of a dilution refrigerator and the measured power was 23 mW per qubit under active control. The chip generated single--side banded output frequencies between 4.5 and 5.5 GHz with a maximum power output of -18 dBm. Randomized benchmarking (RB) experiments revealed an average number of 1.71 instructions per Clifford (IPC) for single-qubit gates, and 17.51 IPC for two-qubit gates. A single-qubit error per gate of $\\epsilon_{\\text{1Q}}$=8e-4 and two-qubit error per gate of $\\epsilon_\\text{2Q}$=1.4e-2 is shown. A drive-induced Z-rotation is observed by way of a rotary echo experiment; this observation is consistent with expected qubit behavior given measured excess local oscillator (LO) leakage from the CMOS chip. The effect of spurious drive induced Z-errors is numerically evaluated with a two-qubit model Hamiltonian, and shown to be in good agreement with measured RB data. The modeling results suggest the Z-error varies linearly with pulse amplitude.","created":"2023-02-22","meta":{"link":"http://arxiv.org/abs/2302.11538v1","tag":"data-quality"}}
{"title":"Neural Network Analytic Continuation for Monte Carlo: Improvement by Statistical Errors","abstract":"This study explores the use of neural network-based analytic continuation to extract spectra from Monte Carlo data. We apply this technique to both synthetic and Monte Carlo-generated data. The training sets for neural networks are carefully synthesized without ``data leakage\". We found that the training set should match the input correlation functions in terms of statistical error properties, such as noise level, noise dependence on imaginary time, and imaginary time-displaced correlations. We have developed a systematic method to synthesize such training datasets. Our improved algorithm outperform the widely used maximum entropy method in highly noisy situations. As an example, our method successfully extracted the dynamic structure factor of the spin-1/2 Heisenberg chain from quantum Monte Carlo simulations.","created":"2023-02-22","meta":{"link":"http://arxiv.org/abs/2302.11317v1","tag":"data-quality"}}
{"title":"Speech Privacy Leakage from Shared Gradients in Distributed Learning","abstract":"Distributed machine learning paradigms, such as federated learning, have been recently adopted in many privacy-critical applications for speech analysis. However, such frameworks are vulnerable to privacy leakage attacks from shared gradients. Despite extensive efforts in the image domain, the exploration of speech privacy leakage from gradients is quite limited. In this paper, we explore methods for recovering private speech/speaker information from the shared gradients in distributed learning settings. We conduct experiments on a keyword spotting model with two different types of speech features to quantify the amount of leaked information by measuring the similarity between the original and recovered speech signals. We further demonstrate the feasibility of inferring various levels of side-channel information, including speech content and speaker identity, under the distributed learning framework without accessing the user's data.","created":"2023-02-21","meta":{"link":"http://arxiv.org/abs/2302.10441v1","tag":"data-quality"}}
{"title":"Byzantine-Resistant Secure Aggregation for Federated Learning Based on Coded Computing and Vector Commitment","abstract":"In this paper, we propose an efficient secure aggregation scheme for federated learning that is protected against Byzantine attacks and privacy leakages. Processing individual updates to manage adversarial behavior, while preserving privacy of data against colluding nodes, requires some sort of secure secret sharing. However, communication load for secret sharing of long vectors of updates can be very high. To resolve this issue, in the proposed scheme, local updates are partitioned into smaller sub-vectors and shared using ramp secret sharing. However, this sharing method does not admit bi-linear computations, such as pairwise distance calculations, needed by outlier-detection algorithms. To overcome this issue, each user runs another round of ramp sharing, with different embedding of data in the sharing polynomial. This technique, motivated by ideas from coded computing, enables secure computation of pairwise distance. In addition, to maintain the integrity and privacy of the local update, the proposed scheme also uses a vector commitment method, in which the commitment size remains constant (i.e. does not increase with the length of the local update), while simultaneously allowing verification of the secret sharing process.","created":"2023-02-20","meta":{"link":"http://arxiv.org/abs/2302.09913v1","tag":"data-quality"}}
{"title":"All-microwave leakage reduction units for quantum error correction with superconducting transmon qubits","abstract":"Minimizing leakage from computational states is a challenge when using many-level systems like superconducting quantum circuits as qubits. We realize and extend the quantum-hardware-efficient, all-microwave leakage reduction unit (LRU) for transmons in a circuit QED architecture proposed by Battistel et al. This LRU effectively reduces leakage in the second- and third-excited transmon states with up to $99\\% $ efficacy in $220~\\mathrm{ns}$, with minimum impact on the qubit subspace. As a first application in the context of quantum error correction, we demonstrate the ability of multiple simultaneous LRUs to reduce the error detection rate and to suppress leakage buildup within $1\\%$ in data and ancilla qubits over 50 cycles of a weight-2 parity measurement.","created":"2023-02-20","meta":{"link":"http://arxiv.org/abs/2302.09876v2","tag":"data-quality"}}
{"title":"Personalized and privacy-preserving federated heterogeneous medical image analysis with PPPML-HMI","abstract":"Heterogeneous data is endemic due to the use of diverse models and settings of devices by hospitals in the field of medical imaging. However, there are few open-source frameworks for federated heterogeneous medical image analysis with personalization and privacy protection simultaneously without the demand to modify the existing model structures or to share any private data. In this paper, we proposed PPPML-HMI, an open-source learning paradigm for personalized and privacy-preserving federated heterogeneous medical image analysis. To our best knowledge, personalization and privacy protection were achieved simultaneously for the first time under the federated scenario by integrating the PerFedAvg algorithm and designing our novel cyclic secure aggregation with the homomorphic encryption algorithm. To show the utility of PPPML-HMI, we applied it to a simulated classification task namely the classification of healthy people and patients from the RAD-ChestCT Dataset, and one real-world segmentation task namely the segmentation of lung infections from COVID-19 CT scans. For the real-world task, PPPML-HMI achieved $\\sim$5\\% higher Dice score on average compared to conventional FL under the heterogeneous scenario. Meanwhile, we applied the improved deep leakage from gradients to simulate adversarial attacks and showed the solid privacy-preserving capability of PPPML-HMI. By applying PPPML-HMI to both tasks with different neural networks, a varied number of users, and sample sizes, we further demonstrated the strong robustness of PPPML-HMI.","created":"2023-02-20","meta":{"link":"http://arxiv.org/abs/2302.11571v1","tag":"data-quality"}}
{"title":"On the $f$-Differential Privacy Guarantees of Discrete-Valued Mechanisms","abstract":"We consider a federated data analytics problem in which a server coordinates the collaborative data analysis of multiple users with privacy concerns and limited communication capability. The commonly adopted compression schemes introduce information loss into local data while improving communication efficiency, and it remains an open question whether such discrete-valued mechanisms provide any privacy protection. Considering that differential privacy has become the gold standard for privacy measures due to its simple implementation and rigorous theoretical foundation, in this paper, we study the privacy guarantees of discrete-valued mechanisms with finite output space in the lens of $f$-differential privacy (DP). By interpreting the privacy leakage as a hypothesis testing problem, we derive the closed-form expression of the tradeoff between type I and type II error rates, based on which the $f$-DP guarantees of a variety of discrete-valued mechanisms, including binomial mechanisms, sign-based methods, and ternary-based compressors, are characterized. We further investigate the Byzantine resilience of binomial mechanisms and ternary compressors and characterize the tradeoff among differential privacy, Byzantine resilience, and communication efficiency. Finally, we discuss the application of the proposed method to differentially private stochastic gradient descent in federated learning.","created":"2023-02-19","meta":{"link":"http://arxiv.org/abs/2302.09624v1","tag":"data-quality"}}
{"title":"Dynamic Private Task Assignment under Differential Privacy","abstract":"Data collection is indispensable for spatial crowdsourcing services, such as resource allocation, policymaking, and scientific explorations. However, privacy issues make it challenging for users to share their information unless receiving sufficient compensation. Differential Privacy (DP) is a promising mechanism to release helpful information while protecting individuals' privacy. However, most DP mechanisms only consider a fixed compensation for each user's privacy loss. In this paper, we design a task assignment scheme that allows workers to dynamically improve their utility with dynamic distance privacy leakage. Specifically, we propose two solutions to improve the total utility of task assignment results, namely Private Utility Conflict-Elimination (PUCE) approach and Private Game Theory (PGT) approach, respectively. We prove that PUCE achieves higher utility than the state-of-the-art works. We demonstrate the efficiency and effectiveness of our PUCE and PGT approaches on both real and synthetic data sets compared with the recent distance-based approach, Private Distance Conflict-Elimination (PDCE). PUCE is always better than PDCE slightly. PGT is 50% to 63% faster than PDCE and can improve 16% utility on average when worker range is large enough.","created":"2023-02-19","meta":{"link":"http://arxiv.org/abs/2302.09511v1","tag":"data-quality"}}
{"title":"Online Spatio-Temporal Correlation-Based Federated Learning for Traffic Flow Forecasting","abstract":"Traffic flow forecasting (TFF) is of great importance to the construction of Intelligent Transportation Systems (ITS). To mitigate communication burden and tackle with the problem of privacy leakage aroused by centralized forecasting methods, Federated Learning (FL) has been applied to TFF. However, existing FL-based approaches employ batch learning manner, which makes the pre-trained models inapplicable to subsequent traffic data, thus exhibiting subpar prediction performance. In this paper, we perform the first study of forecasting traffic flow adopting Online Learning (OL) manner in FL framework and then propose a novel prediction method named Online Spatio-Temporal Correlation-based Federated Learning (FedOSTC), aiming to guarantee performance gains regardless of traffic fluctuation. Specifically, clients employ Gated Recurrent Unit (GRU)-based encoders to obtain the internal temporal patterns inside traffic data sequences. Then, the central server evaluates spatial correlation among clients via Graph Attention Network (GAT), catering to the dynamic changes of spatial closeness caused by traffic fluctuation. Furthermore, to improve the generalization of the global model for upcoming traffic data, a period-aware aggregation mechanism is proposed to aggregate the local models which are optimized using Online Gradient Descent (OGD) algorithm at clients. We perform comprehensive experiments on two real-world datasets to validate the efficiency and effectiveness of our proposed method and the numerical results demonstrate the superiority of FedOSTC.","created":"2023-02-17","meta":{"link":"http://arxiv.org/abs/2302.08658v1","tag":"data-quality"}}
{"title":"Balancing Privacy Protection and Interpretability in Federated Learning","abstract":"Federated learning (FL) aims to collaboratively train the global model in a distributed manner by sharing the model parameters from local clients to a central server, thereby potentially protecting users' private information. Nevertheless, recent studies have illustrated that FL still suffers from information leakage as adversaries try to recover the training data by analyzing shared parameters from local clients. To deal with this issue, differential privacy (DP) is adopted to add noise to the gradients of local models before aggregation. It, however, results in the poor performance of gradient-based interpretability methods, since some weights capturing the salient region in feature map will be perturbed. To overcome this problem, we propose a simple yet effective adaptive differential privacy (ADP) mechanism that selectively adds noisy perturbations to the gradients of client models in FL. We also theoretically analyze the impact of gradient perturbation on the model interpretability. Finally, extensive experiments on both IID and Non-IID data demonstrate that the proposed ADP can achieve a good trade-off between privacy and interpretability in FL.","created":"2023-02-16","meta":{"link":"http://arxiv.org/abs/2302.08044v1","tag":"data-quality"}}
{"title":"BLIAM: Literature-based Data Synthesis for Synergistic Drug Combination Prediction","abstract":"Language models pre-trained on scientific literature corpora have substantially advanced scientific discovery by offering high-quality feature representations for downstream applications. However, these features are often not interpretable, and thus can reveal limited insights to domain experts. Instead of obtaining features from language models, we propose BLIAM, a literature-based data synthesis approach to directly generate training data points that are interpretable and model-agnostic to downstream applications. The key idea of BLIAM is to create prompts using existing training data and then use these prompts to synthesize new data points. BLIAM performs these two steps iteratively as new data points will define more informative prompts and new prompts will in turn synthesize more accurate data points. Notably, literature-based data augmentation might introduce data leakage since labels of test data points in downstream applications might have already been mentioned in the language model corpus. To prevent such leakage, we introduce GDSC-combo, a large-scale drug combination discovery dataset that was published after the biomedical language model was trained. We found that BLIAM substantially outperforms a non-augmented approach and manual prompting in this rigorous data split setting. BLIAM can be further used to synthesize data points for novel drugs and cell lines that were not even measured in biomedical experiments. In addition to the promising prediction performance, the data points synthesized by BLIAM are interpretable and model-agnostic, enabling in silico augmentation for in vitro experiments.","created":"2023-02-14","meta":{"link":"http://arxiv.org/abs/2302.06860v2","tag":"data-quality"}}
{"title":"Federated contrastive learning models for prostate cancer diagnosis and Gleason grading","abstract":"The application effect of artificial intelligence (AI) in the field of medical imaging is remarkable. Robust AI model training requires large datasets, but data collection faces communication, ethics, and privacy protection constraints. Fortunately, federated learning can solve the above problems by coordinating multiple clients to train the model without sharing the original data. In this study, we design a federated contrastive learning framework (FCL) for large-scale pathology images and the heterogeneity challenges. It enhances the model's generalization ability by maximizing the attention consistency between the local client and server models. To alleviate the privacy leakage problem when transferring parameters and verify the robustness of FCL, we use differential privacy to further protect the model by adding noise. We evaluate the effectiveness of FCL on the cancer diagnosis task and Gleason grading task on 19,635 prostate cancer WSIs from multiple clients. In the diagnosis task, the average AUC of 7 clients is 95% when the categories are relatively balanced, and our FCL achieves 97%. In the Gleason grading task, the average Kappa of 6 clients is 0.74, and the Kappa of FCL reaches 0.84. Furthermore, we also validate the robustness of the model on external datasets(one public dataset and two private datasets). In addition, to better explain the classification effect of the model, we show whether the model focuses on the lesion area by drawing a heatmap. Finally, FCL brings a robust, accurate, low-cost AI training model to biomedical research, effectively protecting medical data privacy.","created":"2023-02-13","meta":{"link":"http://arxiv.org/abs/2302.06089v2","tag":"data-quality"}}
{"title":"On Differential Privacy and Adaptive Data Analysis with Bounded Space","abstract":"We study the space complexity of the two related fields of differential privacy and adaptive data analysis. Specifically,   (1) Under standard cryptographic assumptions, we show that there exists a problem P that requires exponentially more space to be solved efficiently with differential privacy, compared to the space needed without privacy. To the best of our knowledge, this is the first separation between the space complexity of private and non-private algorithms.   (2) The line of work on adaptive data analysis focuses on understanding the number of samples needed for answering a sequence of adaptive queries. We revisit previous lower bounds at a foundational level, and show that they are a consequence of a space bottleneck rather than a sampling bottleneck.   To obtain our results, we define and construct an encryption scheme with multiple keys that is built to withstand a limited amount of key leakage in a very particular way.","created":"2023-02-11","meta":{"link":"http://arxiv.org/abs/2302.05707v1","tag":"data-quality"}}
{"title":"Cyber-Resilience Approaches for Cyber-Physical Systems","abstract":"Concerns for the resilience of Cyber-Physical Systems (CPS) in critical infrastructure are growing. CPS integrate sensing, computation, control and networking into physical objects and mission-critical services, connecting traditional infrastructure to internet technologies. While this integration increases service efficiency, it has to face the possibility of new threats posed by the new functionalities. This leads to cyber-threats, such as denial-of-service, modification of data, information leakage, spreading of malware, and many others. Cyber-resilience refers to the ability of a CPS to prepare, absorb, recover, and adapt to the adverse effects associated with cyber-threats, e.g., physical degradation of the CPS performance resulting from a cyber-attack. Cyber-resilience aims at ensuring CPS survival, by keeping the core functionalities of the CPS in case of extreme events. The literature on cyber-resilience is rapidly increasing, leading to a broad variety of research works addressing this new topic. In this article, we create a systematization of knowledge about existing scientific efforts of making CPS cyber-resilient. We systematically survey recent literature addressing cyber-resilience with a focus on techniques that may be used on CPS. We first provide preliminaries and background on CPS and threats, and subsequently survey state-of-the-art approaches that have been proposed by recent research work applicable to CPS. In particular, we aim at differentiating research work from traditional risk management approaches, based on the general acceptance that it is unfeasible to prevent and mitigate all possible risks threatening a CPS. We also discuss questions and research challenges, with a focus on the practical aspects of cyber-resilience, such as the use of metrics and evaluation methods, as well as testing and validation environments.","created":"2023-02-10","meta":{"link":"http://arxiv.org/abs/2302.05402v1","tag":"data-quality"}}
{"title":"XFL: A High Performace, Lightweighted Federated Learning Framework","abstract":"This paper introduces XFL, an industrial-grade federated learning project. XFL supports training AI models collaboratively on multiple devices, while utilizes homomorphic encryption, differential privacy, secure multi-party computation and other security technologies ensuring no leakage of data. XFL provides an abundant algorithms library, integrating a large number of pre-built, secure and outstanding federated learning algorithms, covering both the horizontally and vertically federated learning scenarios. Numerical experiments have shown the prominent performace of these algorithms. XFL builds a concise configuration interfaces with presettings for all federation algorithms, and supports the rapid deployment via docker containers.Therefore, we believe XFL is the most user-friendly and easy-to-develop federated learning framework. XFL is open-sourced, and both the code and documents are available at https://github.com/paritybit-ai/XFL.","created":"2023-02-10","meta":{"link":"http://arxiv.org/abs/2302.05076v1","tag":"data-quality"}}
{"title":"Semi-decentralized Federated Ego Graph Learning for Recommendation","abstract":"Collaborative filtering (CF) based recommender systems are typically trained based on personal interaction data (e.g., clicks and purchases) that could be naturally represented as ego graphs. However, most existing recommendation methods collect these ego graphs from all users to compose a global graph to obtain high-order collaborative information between users and items, and these centralized CF recommendation methods inevitably lead to a high risk of user privacy leakage. Although recently proposed federated recommendation systems can mitigate the privacy problem, they either restrict the on-device local training to an isolated ego graph or rely on an additional third-party server to access other ego graphs resulting in a cumbersome pipeline, which is hard to work in practice. In addition, existing federated recommendation systems require resource-limited devices to maintain the entire embedding tables resulting in high communication costs.   In light of this, we propose a semi-decentralized federated ego graph learning framework for on-device recommendations, named SemiDFEGL, which introduces new device-to-device collaborations to improve scalability and reduce communication costs and innovatively utilizes predicted interacted item nodes to connect isolated ego graphs to augment local subgraphs such that the high-order user-item collaborative information could be used in a privacy-preserving manner. Furthermore, the proposed framework is model-agnostic, meaning that it could be seamlessly integrated with existing graph neural network-based recommendation methods and privacy protection techniques. To validate the effectiveness of the proposed SemiDFEGL, extensive experiments are conducted on three public datasets, and the results demonstrate the superiority of the proposed SemiDFEGL compared to other federated recommendation methods.","created":"2023-02-10","meta":{"link":"http://arxiv.org/abs/2302.10900v1","tag":"data-quality"}}
{"title":"Bag of Tricks for Training Data Extraction from Language Models","abstract":"With the advance of language models, privacy protection is receiving more attention. Training data extraction is therefore of great importance, as it can serve as a potential tool to assess privacy leakage. However, due to the difficulty of this task, most of the existing methods are proof-of-concept and still not effective enough. In this paper, we investigate and benchmark tricks for improving training data extraction using a publicly available dataset. Because most existing extraction methods use a pipeline of generating-then-ranking, i.e., generating text candidates as potential training data and then ranking them based on specific criteria, our research focuses on the tricks for both text generation (e.g., sampling strategy) and text ranking (e.g., token-level criteria). The experimental results show that several previously overlooked tricks can be crucial to the success of training data extraction. Based on the GPT-Neo 1.3B evaluation results, our proposed tricks outperform the baseline by a large margin in most cases, providing a much stronger baseline for future research.","created":"2023-02-09","meta":{"link":"http://arxiv.org/abs/2302.04460v1","tag":"data-quality"}}
{"title":"Exploratory Analysis of Federated Learning Methods with Differential Privacy on MIMIC-III","abstract":"Background: Federated learning methods offer the possibility of training machine learning models on privacy-sensitive data sets, which cannot be easily shared. Multiple regulations pose strict requirements on the storage and usage of healthcare data, leading to data being in silos (i.e. locked-in at healthcare facilities). The application of federated algorithms on these datasets could accelerate disease diagnostic, drug development, as well as improve patient care.   Methods: We present an extensive evaluation of the impact of different federation and differential privacy techniques when training models on the open-source MIMIC-III dataset. We analyze a set of parameters influencing a federated model performance, namely data distribution (homogeneous and heterogeneous), communication strategies (communication rounds vs. local training epochs), federation strategies (FedAvg vs. FedProx). Furthermore, we assess and compare two differential privacy (DP) techniques during model training: a stochastic gradient descent-based differential privacy algorithm (DP-SGD), and a sparse vector differential privacy technique (DP-SVT).   Results: Our experiments show that extreme data distributions across sites (imbalance either in the number of patients or the positive label ratios between sites) lead to a deterioration of model performance when trained using the FedAvg strategy. This issue is resolved when using FedProx with the use of appropriate hyperparameter tuning. Furthermore, the results show that both differential privacy techniques can reach model performances similar to those of models trained without DP, however at the expense of a large quantifiable privacy leakage.   Conclusions: We evaluate empirically the benefits of two federation strategies and propose optimal strategies for the choice of parameters when using differential privacy techniques.","created":"2023-02-08","meta":{"link":"http://arxiv.org/abs/2302.04208v1","tag":"data-quality"}}
{"title":"Improving the Model Consistency of Decentralized Federated Learning","abstract":"To mitigate the privacy leakages and communication burdens of Federated Learning (FL), decentralized FL (DFL) discards the central server and each client only communicates with its neighbors in a decentralized communication network. However, existing DFL suffers from high inconsistency among local clients, which results in severe distribution shift and inferior performance compared with centralized FL (CFL), especially on heterogeneous data or sparse communication topology. To alleviate this issue, we propose two DFL algorithms named DFedSAM and DFedSAM-MGS to improve the performance of DFL. Specifically, DFedSAM leverages gradient perturbation to generate local flat models via Sharpness Aware Minimization (SAM), which searches for models with uniformly low loss values. DFedSAM-MGS further boosts DFedSAM by adopting Multiple Gossip Steps (MGS) for better model consistency, which accelerates the aggregation of local flat models and better balances communication complexity and generalization. Theoretically, we present improved convergence rates $\\small \\mathcal{O}\\big(\\frac{1}{\\sqrt{KT}}+\\frac{1}{T}+\\frac{1}{K^{1/2}T^{3/2}(1-\\lambda)^2}\\big)$ and $\\small \\mathcal{O}\\big(\\frac{1}{\\sqrt{KT}}+\\frac{1}{T}+\\frac{\\lambda^Q+1}{K^{1/2}T^{3/2}(1-\\lambda^Q)^2}\\big)$ in non-convex setting for DFedSAM and DFedSAM-MGS, respectively, where $1-\\lambda$ is the spectral gap of gossip matrix and $Q$ is the number of MGS. Empirically, our methods can achieve competitive performance compared with CFL methods and outperform existing DFL methods.","created":"2023-02-08","meta":{"link":"http://arxiv.org/abs/2302.04083v1","tag":"data-quality"}}
{"title":"Lyman continuum leaker candidates among highly ionised, low-redshift dwarf galaxies selected from HeII","abstract":"Contemporary research suggests that the reionisation of the intergalactic medium (IGM) in the early Universe was predominantly realised by star-forming (proto-)galaxies (SFGs). Due to observational constraints, our knowledge on the origins of sufficient amounts of ionising Lyman continuum (LyC) photons and the mechanisms facilitating their transport into the IGM remains sparse. Recent efforts have thus focussed on the study of local analogues to these high-redshift objects.   We used archival spectroscopic SDSS DR12 data to select a sample of low-z He II 4686 emitters and restricted it to a set of SFGs with an emission line diagnostic sensitive to the presence of an AGN, which serves as our only selection criterion. Our final sample consists of eighteen low-mass, low-metallicity dwarf galaxies which appear to be predominantly ionised by stellar sources. We find large O32 ratios and [S II] deficiencies, which provide strong indications for these galaxies to be LyC Emitters (LCEs). At least 40% of these objects are candidates for featuring cosmologically significant LyC escape fractions >10%. Their SFHs exhibit strong similarities and almost all galaxies appear to contain an old (>1 Gyr) stellar component, while also harbouring a young, two-stage (~10 Myr and <1 Myr) starburst, which we speculate might be related to LyC escape.   The properties of the compact emission line galaxies presented here align well with those observed in many local LCEs. In fact, our sample may prove as an extension to the rather small catalogue of local LCEs, as the extreme interstellar medium (ISM) conditions we find are assumed to facilitate LyC leakage. Notably, all of our eighteen candidates are significantly closer (z<0.1) than most established LCEs. If the inferred LyC photon loss is genuine, this demonstrates that selecting SFGs from He II 4686 is a powerful selection criterion in the search for LCEs.","created":"2023-02-06","meta":{"link":"http://arxiv.org/abs/2302.02868v1","tag":"data-quality"}}
{"title":"Federated Privacy-preserving Collaborative Filtering for On-Device Next App Prediction","abstract":"In this study, we propose a novel SeqMF model to solve the problem of predicting the next app launch during mobile device usage. Although this problem can be represented as a classical collaborative filtering problem, it requires proper modification since the data are sequential, the user feedback is distributed among devices and the transmission of users' data to aggregate common patterns must be protected against leakage. According to such requirements, we modify the structure of the classical matrix factorization model and update the training procedure to sequential learning. Since the data about user experience are distributed among devices, the federated learning setup is used to train the proposed sequential matrix factorization model. One more ingredient of the proposed approach is a new privacy mechanism that guarantees the protection of the sent data from the users to the remote server. To demonstrate the efficiency of the proposed model we use publicly available mobile user behavior data. We compare our model with sequential rules and models based on the frequency of app launches. The comparison is conducted in static and dynamic environments. The static environment evaluates how our model processes sequential data compared to competitors. Therefore, the standard train-validation-test evaluation procedure is used. The dynamic environment emulates the real-world scenario, where users generate new data by running apps on devices, and evaluates our model in this case. Our experiments show that the proposed model provides comparable quality with other methods in the static environment. However, more importantly, our method achieves a better privacy-utility trade-off than competitors in the dynamic environment, which provides more accurate simulations of real-world usage.","created":"2023-02-05","meta":{"link":"http://arxiv.org/abs/2303.04744v1","tag":"data-quality"}}
{"title":"GAN-based federated learning for label protection in binary classification","abstract":"As an emerging technique, vertical federated learning collaborates with different data sources to jointly train a machine learning model without data exchange. However, federated learning is computationally expensive and inefficient in modeling due to complex encryption algorithms and secure computation protocols. Split learning offers an alternative solution to circumvent these challenges. Despite this, vanilla split learning still suffers privacy leakage. Here, we propose the Generative Adversarial Federated Model (GAFM), which integrates the vanilla split learning framework with the Generative Adversarial Network (GAN) for protection against label leakage from gradients in binary classification tasks. We compare our proposal to existing models, including Marvell, Max Norm, and SplitNN, on three publicly available datasets, where GAFM shows significant improvement regarding the trade-off between classification accuracy and label privacy protection. We also provide heuristic justification for why GAFM can improve over baselines and demonstrate that GAFM offers label protection through gradient perturbation compared to SplitNN.","created":"2023-02-04","meta":{"link":"http://arxiv.org/abs/2302.02245v1","tag":"data-quality"}}
{"title":"Relating EEG to continuous speech using deep neural networks: a review","abstract":"Objective. When a person listens to continuous speech, a corresponding response is elicited in the brain and can be recorded using electroencephalography (EEG). Linear models are presently used to relate the EEG recording to the corresponding speech signal. The ability of linear models to find a mapping between these two signals is used as a measure of neural tracking of speech. Such models are limited as they assume linearity in the EEG-speech relationship, which omits the nonlinear dynamics of the brain. As an alternative, deep learning models have recently been used to relate EEG to continuous speech, especially in auditory attention decoding (AAD) and single-speech-source paradigms. Approach. This paper reviews and comments on deep-learning-based studies that relate EEG to continuous speech in AAD and single-speech-source paradigms. We point out recurrent methodological pitfalls and the need for a standard benchmark of model analysis. Main results. We gathered 28 studies. The main methodological issues we found are biased cross-validations, data leakage leading to over-fitted models, or disproportionate data size compared to the model's complexity. In addition, we address requirements for a standard benchmark model analysis, such as public datasets, common evaluation metrics, and good practices for the match-mismatch task. Significance. We are the first to present a review paper summarizing the main deep-learning-based studies that relate EEG to speech while addressing methodological pitfalls and important considerations for this newly expanding field. Our study is particularly relevant given the growing application of deep learning in EEG-speech decoding.","created":"2023-02-03","meta":{"link":"http://arxiv.org/abs/2302.01736v2","tag":"data-quality"}}
{"title":"GTV: Generating Tabular Data via Vertical Federated Learning","abstract":"Generative Adversarial Networks (GANs) have achieved state-of-the-art results in tabular data synthesis, under the presumption of direct accessible training data. Vertical Federated Learning (VFL) is a paradigm which allows to distributedly train machine learning model with clients possessing unique features pertaining to the same individuals, where the tabular data learning is the primary use case. However, it is unknown if tabular GANs can be learned in VFL. Demand for secure data transfer among clients and GAN during training and data synthesizing poses extra challenge. Conditional vector for tabular GANs is a valuable tool to control specific features of generated data. But it contains sensitive information from real data - risking privacy guarantees. In this paper, we propose GTV, a VFL framework for tabular GANs, whose key components are generator, discriminator and the conditional vector. GTV proposes an unique distributed training architecture for generator and discriminator to access training data in a privacy-preserving manner. To accommodate conditional vector into training without privacy leakage, GTV designs a mechanism training-with-shuffling to ensure that no party can reconstruct training data with conditional vector. We evaluate the effectiveness of GTV in terms of synthetic data quality, and overall training scalability. Results show that GTV can consistently generate high-fidelity synthetic tabular data of comparable quality to that generated by centralized GAN algorithm. The difference on machine learning utility can be as low as to 2.7%, even under extremely imbalanced data distributions across clients and different number of clients.","created":"2023-02-03","meta":{"link":"http://arxiv.org/abs/2302.01706v1","tag":"data-quality"}}
{"title":"FCB-SwinV2 Transformer for Polyp Segmentation","abstract":"Polyp segmentation within colonoscopy video frames using deep learning models has the potential to automate the workflow of clinicians. This could help improve the early detection rate and characterization of polyps which could progress to colorectal cancer. Recent state-of-the-art deep learning polyp segmentation models have combined the outputs of Fully Convolutional Network architectures and Transformer Network architectures which work in parallel. In this paper we propose modifications to the current state-of-the-art polyp segmentation model FCBFormer. The transformer architecture of the FCBFormer is replaced with a SwinV2 Transformer-UNET and minor changes to the Fully Convolutional Network architecture are made to create the FCB-SwinV2 Transformer. The performance of the FCB-SwinV2 Transformer is evaluated on the popular colonoscopy segmentation bench-marking datasets Kvasir-SEG and CVC-ClinicDB. Generalizability tests are also conducted. The FCB-SwinV2 Transformer is able to consistently achieve higher mDice scores across all tests conducted and therefore represents new state-of-the-art performance. Issues found with how colonoscopy segmentation model performance is evaluated within literature are also re-ported and discussed. One of the most important issues identified is that when evaluating performance on the CVC-ClinicDB dataset it would be preferable to ensure no data leakage from video sequences occurs during the training/validation/test data partition.","created":"2023-02-02","meta":{"link":"http://arxiv.org/abs/2302.01027v1","tag":"data-quality"}}
{"title":"Analyzing Leakage of Personally Identifiable Information in Language Models","abstract":"Language Models (LMs) have been shown to leak information about training data through sentence-level membership inference and reconstruction attacks. Understanding the risk of LMs leaking Personally Identifiable Information (PII) has received less attention, which can be attributed to the false assumption that dataset curation techniques such as scrubbing are sufficient to prevent PII leakage. Scrubbing techniques reduce but do not prevent the risk of PII leakage: in practice scrubbing is imperfect and must balance the trade-off between minimizing disclosure and preserving the utility of the dataset. On the other hand, it is unclear to which extent algorithmic defenses such as differential privacy, designed to guarantee sentence- or user-level privacy, prevent PII disclosure. In this work, we introduce rigorous game-based definitions for three types of PII leakage via black-box extraction, inference, and reconstruction attacks with only API access to an LM. We empirically evaluate the attacks against GPT-2 models fine-tuned with and without defenses in three domains: case law, health care, and e-mails. Our main contributions are (i) novel attacks that can extract up to 10$\\times$ more PII sequences than existing attacks, (ii) showing that sentence-level differential privacy reduces the risk of PII disclosure but still leaks about 3% of PII sequences, and (iii) a subtle connection between record-level membership inference and PII reconstruction. Code to reproduce all experiments in the paper is available at https://github.com/microsoft/analysing_pii_leakage.","created":"2023-02-01","meta":{"link":"http://arxiv.org/abs/2302.00539v3","tag":"data-quality"}}
{"title":"CATFL: Certificateless Authentication-based Trustworthy Federated Learning for 6G Semantic Communications","abstract":"Federated learning (FL) provides an emerging approach for collaboratively training semantic encoder/decoder models of semantic communication systems, without private user data leaving the devices. Most existing studies on trustworthy FL aim to eliminate data poisoning threats that are produced by malicious clients, but in many cases, eliminating model poisoning attacks brought by fake servers is also an important objective. In this paper, a certificateless authentication-based trustworthy federated learning (CATFL) framework is proposed, which mutually authenticates the identity of clients and server. In CATFL, each client verifies the server's signature information before accepting the delivered global model to ensure that the global model is not delivered by false servers. On the contrary, the server also verifies the server's signature information before accepting the delivered model updates to ensure that they are submitted by authorized clients. Compared to PKI-based methods, the CATFL can avoid too high certificate management overheads. Meanwhile, the anonymity of clients shields data poisoning attacks, while real-name registration may suffer from user-specific privacy leakage risks. Therefore, a pseudonym generation strategy is also presented in CATFL to achieve a trade-off between identity traceability and user anonymity, which is essential to conditionally prevent from user-specific privacy leakage. Theoretical security analysis and evaluation results validate the superiority of CATFL.","created":"2023-02-01","meta":{"link":"http://arxiv.org/abs/2302.00271v1","tag":"data-quality"}}
{"title":"Gas Leak detection using airborne US Sensors","abstract":"Gas leakage is a critical problem in the industrial sector, residential structures, and gas-powered vehicles; installing gas leakage detection systems is one of the preventative strategies for reducing hazards caused by gas leakage. Conventional gas sensors, such as electrochemical, infrared point, and MOS sensors, have traditionally been used to detect leaks. The challenge with these sensors is their versatility in settings involving many gases, as well as their exorbitant cost and scalability. As a result, several gas detection approaches were explored. Our approach utilizes 40 KHz ultrasound signal for gas detection. Here, the reflected signal has been analyzed to detect gas leaks and identify gas in real-time, providing a quick, reliable solution for gas leak detection in industrial environments. The electronics and sensors used are both low-cost and easily scalable. The system incorporates commonly accessible materials and off-the-shelf components, making it suitable for use in a variety of contexts. They are also more effective at detecting numerous gas leaks and has a longer lifetime. Butane was used to test our system. The breaches were identified in 0.01 seconds after permitting gas to flow from a broken pipe, whereas identifying the gas took 0.8 seconds","created":"2023-01-31","meta":{"link":"http://arxiv.org/abs/2301.13849v2","tag":"data-quality"}}
{"title":"Equivariant Differentially Private Deep Learning","abstract":"The formal privacy guarantee provided by Differential Privacy (DP) bounds the leakage of sensitive information from deep learning models. In practice, however, this comes at a severe computation and accuracy cost. The recently established state of the art (SOTA) results in image classification under DP are due to the use of heavy data augmentation and large batch sizes, leading to a drastically increased computation overhead. In this work, we propose to use more efficient models with improved feature quality by introducing steerable equivariant convolutional networks for DP training. We demonstrate that our models are able to outperform the current SOTA performance on CIFAR-10 by up to $9\\%$ across different $\\varepsilon$-values while reducing the number of model parameters by a factor of $35$ and decreasing the computation time by more than $90 \\%$. Our results are a large step towards efficient model architectures that make optimal use of their parameters and bridge the privacy-utility gap between private and non-private deep learning for computer vision.","created":"2023-01-30","meta":{"link":"http://arxiv.org/abs/2301.13104v1","tag":"data-quality"}}
{"title":"M3FAS: An Accurate and Robust MultiModal Mobile Face Anti-Spoofing System","abstract":"Face presentation attacks (FPA), also known as face spoofing, have brought increasing concerns to the public through various malicious applications, such as financial fraud and privacy leakage. Therefore, safeguarding face recognition systems against FPA is of utmost importance. Although existing learning-based face anti-spoofing (FAS) models can achieve outstanding detection performance, they lack generalization capability and suffer significant performance drops in unforeseen environments. Many methodologies seek to use auxiliary modality data (e.g., depth and infrared maps) during the presentation attack detection (PAD) to address this limitation. However, these methods can be limited since (1) they require specific sensors such as depth and infrared cameras for data capture, which are rarely available on commodity mobile devices, and (2) they cannot work properly in practical scenarios when either modality is missing or of poor quality. In this paper, we devise an accurate and robust MultiModal Mobile Face Anti-Spoofing system named M3FAS to overcome the issues above. The innovation of this work mainly lies in the following aspects: (1) To achieve robust PAD, our system combines visual and auditory modalities using three pervasively available sensors: camera, speaker, and microphone; (2) We design a novel two-branch neural network with three hierarchical feature aggregation modules to perform cross-modal feature fusion; (3). We propose a multi-head training strategy. The model outputs three predictions from the vision, acoustic, and fusion heads, enabling a more flexible PAD. Extensive experiments have demonstrated the accuracy, robustness, and flexibility of M3FAS under various challenging experimental settings.","created":"2023-01-30","meta":{"link":"http://arxiv.org/abs/2301.12831v2","tag":"data-quality"}}
{"title":"The Secure CEO Problem With Physical Identifiers Under Logarithmic Loss and Quadratic Distortion Measures","abstract":"In this paper, we investigate the fundamental limits of the chief executive officer (CEO) problem in which physical identifiers are treated as information sources. To make the information leakage of the identifiers to the eavesdropper via helper data negligible, private keys, uniformly and independently chosen, are bonded to measurements of the identifiers at the encoders to generate the helper data. The CEO problem is renowned for the difficulty in characterizing the tight rate-distortion region, which is still an open question for the general case. In this study, we characterize the tight rate-key-distortion regions of such a problem under two specific distortion measures, namely logarithmic loss (both discrete and Gaussian settings) and quadratic distortion measures. We also provide numerical calculations of the characterized regions, and the calculated results show that when a larger distortion is permitted, smaller storage and private-key rates are achievable. For special cases where the constraints of private-key rates and negligible leakage are not imposed, our characterizations naturally reduce to the rate-distortion regions provided by Courtade and Weissman (2014) for logarithmic loss distortion, and Prabhakaran et al. (2004), Chen et al. (2004), and Oohama (2005) for quadratic distortion measure.","created":"2023-01-29","meta":{"link":"http://arxiv.org/abs/2301.12526v2","tag":"data-quality"}}
{"title":"Context-Aware Differential Privacy for Language Modeling","abstract":"The remarkable ability of language models (LMs) has also brought challenges at the interface of AI and security. A critical challenge pertains to how much information these models retain and leak about the training data. This is particularly urgent as the typical development of LMs relies on huge, often highly sensitive data, such as emails and chat logs. To contrast this shortcoming, this paper introduces Context-Aware Differentially Private Language Model (CADP-LM) , a privacy-preserving LM framework that relies on two key insights: First, it utilizes the notion of \\emph{context} to define and audit the potentially sensitive information. Second, it adopts the notion of Differential Privacy to protect sensitive information and characterize the privacy leakage. A unique characteristic of CADP-LM is its ability to target the protection of sensitive sentences and contexts only, providing a highly accurate private model. Experiments on a variety of datasets and settings demonstrate these strengths of CADP-LM.","created":"2023-01-28","meta":{"link":"http://arxiv.org/abs/2301.12288v1","tag":"data-quality"}}
{"title":"SplitGNN: Splitting GNN for Node Classification with Heterogeneous Attention","abstract":"With the frequent happening of privacy leakage and the enactment of privacy laws across different countries, data owners are reluctant to directly share their raw data and labels with any other party. In reality, a lot of these raw data are stored in the graph database, especially for finance. For collaboratively building graph neural networks(GNNs), federated learning(FL) may not be an ideal choice for the vertically partitioned setting where privacy and efficiency are the main concerns. Moreover, almost all the existing federated GNNs are mainly designed for homogeneous graphs, which simplify various types of relations as the same type, thus largely limits their performance. We bridge this gap by proposing a split learning-based GNN(SplitGNN), where this model is divided into two sub-models: the local GNN model includes all the private data related computation to generate local node embeddings, whereas the global model calculates global embeddings by aggregating all the participants' local embeddings. Our SplitGNN allows the isolated heterogeneous neighborhood to be collaboratively utilized. To better capture representations, we propose a novel Heterogeneous Attention(HAT) algorithm and use both node-based and path-based attention mechanisms to learn various types of nodes and edges with multi-hop relation features. We demonstrate the effectiveness of our SplitGNN on node classification tasks for two standard public datasets and the real-world dataset. Extensive experimental results validate that our proposed SplitGNN significantly outperforms the state-of-the-art(SOTA) methods.","created":"2023-01-27","meta":{"link":"http://arxiv.org/abs/2301.12885v1","tag":"data-quality"}}
{"title":"Privacy-Preserving Joint Edge Association and Power Optimization for the Internet of Vehicles via Federated Multi-Agent Reinforcement Learning","abstract":"Proactive edge association is capable of improving wireless connectivity at the cost of increased handover (HO) frequency and energy consumption, while relying on a large amount of private information sharing required for decision making. In order to improve the connectivity-cost trade-off without privacy leakage, we investigate the privacy-preserving joint edge association and power allocation (JEAPA) problem in the face of the environmental uncertainty and the infeasibility of individual learning. Upon modelling the problem by a decentralized partially observable Markov Decision Process (Dec-POMDP), it is solved by federated multi-agent reinforcement learning (FMARL) through only sharing encrypted training data for federatively learning the policy sought. Our simulation results show that the proposed solution strikes a compelling trade-off, while preserving a higher privacy level than the state-of-the-art solutions.","created":"2023-01-26","meta":{"link":"http://arxiv.org/abs/2301.11014v1","tag":"data-quality"}}
{"title":"Huff-DP: Huffman Coding based Differential Privacy Mechanism for Real-Time Data","abstract":"With the advancements in connected devices, a huge amount of real-time data is being generated. Efficient storage, transmission, and analysation of this real-time big data is important, as it serves a number of purposes ranging from decision making to fault prediction, etc. Alongside this, real-time big data has rigorous utility and privacy requirements, therefore, it is also significantly important to choose the handling strategies meticulously. One of the optimal way to store and transmit data in the form of lossless compression is Huffman coding, which compresses the data into a variable length binary stream. Similarly, in order to protect the privacy of such big data, differential privacy is being used nowadays, which perturbs the data on the basis of privacy budget and sensitivity. Nevertheless, traditional differential privacy mechanisms provide privacy guarantees. However, on the other hand, real-time data cannot be dealt as an ordinary set of records, because it usually has certain underlying patterns and cycles, which can be used for forming a link to a specific individuals private information that can lead to severe privacy leakages (e.g., analysing smart metering data can lead to classification of individuals daily routine). Thus, it is equally important to develop a privacy preservation model, which preserves the privacy on the basis of occurrences and patterns in the data. In this paper, we design a novel Huff-DP mechanism, which selects the optimal privacy budget on the basis of privacy requirement for that specific record. In order to further enhance the budget determination, we propose static, sine, and fuzzy logic based decision algorithms. From the experimental evaluations, it can be concluded that our proposed Huff-DP mechanism provides effective privacy protection alongside reducing the privacy budget computational cost.","created":"2023-01-25","meta":{"link":"http://arxiv.org/abs/2301.10395v1","tag":"data-quality"}}
{"title":"Neuromorphic-P2M: Processing-in-Pixel-in-Memory Paradigm for Neuromorphic Image Sensors","abstract":"Edge devices equipped with computer vision must deal with vast amounts of sensory data with limited computing resources. Hence, researchers have been exploring different energy-efficient solutions such as near-sensor processing, in-sensor processing, and in-pixel processing, bringing the computation closer to the sensor. In particular, in-pixel processing embeds the computation capabilities inside the pixel array and achieves high energy efficiency by generating low-level features instead of the raw data stream from CMOS image sensors. Many different in-pixel processing techniques and approaches have been demonstrated on conventional frame-based CMOS imagers, however, the processing-in-pixel approach for neuromorphic vision sensors has not been explored so far. In this work, we for the first time, propose an asynchronous non-von-Neumann analog processing-in-pixel paradigm to perform convolution operations by integrating in-situ multi-bit multi-channel convolution inside the pixel array performing analog multiply and accumulate (MAC) operations that consume significantly less energy than their digital MAC alternative. To make this approach viable, we incorporate the circuit's non-ideality, leakage, and process variations into a novel hardware-algorithm co-design framework that leverages extensive HSpice simulations of our proposed circuit using the GF22nm FD-SOI technology node. We verified our framework on state-of-the-art neuromorphic vision sensor datasets and show that our solution consumes ~2x lower backend-processor energy while maintaining almost similar front-end (sensor) energy on the IBM DVS128-Gesture dataset than the state-of-the-art while maintaining a high test accuracy of 88.36%.","created":"2023-01-22","meta":{"link":"http://arxiv.org/abs/2301.09111v1","tag":"data-quality"}}
{"title":"Split Ways: Privacy-Preserving Training of Encrypted Data Using Split Learning","abstract":"Split Learning (SL) is a new collaborative learning technique that allows participants, e.g. a client and a server, to train machine learning models without the client sharing raw data. In this setting, the client initially applies its part of the machine learning model on the raw data to generate activation maps and then sends them to the server to continue the training process. Previous works in the field demonstrated that reconstructing activation maps could result in privacy leakage of client data. In addition to that, existing mitigation techniques that overcome the privacy leakage of SL prove to be significantly worse in terms of accuracy. In this paper, we improve upon previous works by constructing a protocol based on U-shaped SL that can operate on homomorphically encrypted data. More precisely, in our approach, the client applies Homomorphic Encryption (HE) on the activation maps before sending them to the server, thus protecting user privacy. This is an important improvement that reduces privacy leakage in comparison to other SL-based works. Finally, our results show that, with the optimum set of parameters, training with HE data in the U-shaped SL setting only reduces accuracy by 2.65% compared to training on plaintext. In addition, raw training data privacy is preserved.","created":"2023-01-20","meta":{"link":"http://arxiv.org/abs/2301.08778v1","tag":"data-quality"}}
{"title":"On the Relationship Between Information-Theoretic Privacy Metrics And Probabilistic Information Privacy","abstract":"Information-theoretic (IT) measures based on $f$-divergences have recently gained interest as a measure of privacy leakage as they allow for trading off privacy against utility using only a single-value characterization. However, their operational interpretations in the privacy context are unclear. In this paper, we relate the notion of probabilistic information privacy (IP) to several IT privacy metrics based on $f$-divergences. We interpret probabilistic IP under both the detection and estimation frameworks and link it to differential privacy, thus allowing a precise operational interpretation of these IT privacy metrics. We show that the $\\chi^2$-divergence privacy metric is stronger than those based on total variation distance and Kullback-Leibler divergence. Therefore, we further develop a data-driven empirical risk framework based on the $\\chi^2$-divergence privacy metric and realized using deep neural networks. This framework is agnostic to the adversarial attack model. Empirical experiments demonstrate the efficacy of our approach.","created":"2023-01-20","meta":{"link":"http://arxiv.org/abs/2301.08401v1","tag":"data-quality"}}
{"title":"Label Inference Attack against Split Learning under Regression Setting","abstract":"As a crucial building block in vertical Federated Learning (vFL), Split Learning (SL) has demonstrated its practice in the two-party model training collaboration, where one party holds the features of data samples and another party holds the corresponding labels. Such method is claimed to be private considering the shared information is only the embedding vectors and gradients instead of private raw data and labels. However, some recent works have shown that the private labels could be leaked by the gradients. These existing attack only works under the classification setting where the private labels are discrete. In this work, we step further to study the leakage in the scenario of the regression model, where the private labels are continuous numbers (instead of discrete labels in classification). This makes previous attacks harder to infer the continuous labels due to the unbounded output range. To address the limitation, we propose a novel learning-based attack that integrates gradient information and extra learning regularization objectives in aspects of model training properties, which can infer the labels under regression settings effectively. The comprehensive experiments on various datasets and models have demonstrated the effectiveness of our proposed attack. We hope our work can pave the way for future analyses that make the vFL framework more secure.","created":"2023-01-18","meta":{"link":"http://arxiv.org/abs/2301.07284v2","tag":"data-quality"}}
{"title":"Contrast with Major Classifier Vectors for Federated Medical Relation Extraction with Heterogeneous Label Distribution","abstract":"Federated medical relation extraction enables multiple clients to train a deep network collaboratively without sharing their raw medical data. In order to handle the heterogeneous label distribution across clients, most of the existing works only involve enforcing regularization between local and global models during optimization. In this paper, we fully utilize the models of all clients and propose a novel concept of \\textit{major classifier vectors}, where a group of class vectors is obtained in an ensemble rather than the weighted average method on the server. The major classifier vectors are then distributed to all clients and the local training of each client is Contrasted with Major Classifier vectors (FedCMC), so the local model is not prone to overfitting to the local label distribution. FedCMC requires only a small amount of additional transfer of classifier parameters without any leakage of raw data, extracted representations, and label distributions. Our extensive experiments show that FedCMC outperforms the other state-of-the-art FL algorithms on three medical relation extraction datasets.","created":"2023-01-13","meta":{"link":"http://arxiv.org/abs/2301.05376v1","tag":"data-quality"}}
{"title":"CO2 storage in deep saline aquifers: evaluation of geomechanical risks using integrated modeling workflow","abstract":"CO2 injection into a saline aquifer crossed by a tectonic fault is studied with coupled fluid mechanics - geomechanics modeling. The model is based on reservoir simulator MUFITS and mechanical simulator FLAC3D linked by the in-house algorithm of the data exchange. MUFITS simulates the non-isothermal multiphase flow of CO2 and brine in rock formation accounting for phase transitions and thermal effects. The modeling workflow is sequential, so that hydrodynamical simulations are carried out at a certain time interval, after which pressure, temperature, and density distributions are passed to FLAC3D, which calculates the equilibrium mechanical state. Computed deformations and stresses are utilized to update the porosity and permeability fields for the subsequent hydrodynamic modeling. In particular, we focus on the tectonic fault and its behavior during CO2 injection. We distinguish the damage zone and core inside the fault and derive the closure relations for their permeability alteration analytically. The developed coupled approach is applied to simulate CO2 injection into synthetic and realistic reservoir models. For the former one, we study the effect of formation depth and presence of the tectonic stresses at the initial mechanical state, while for the latter, we consider different injection modes (bottomhole pressure). In each numerical experiment, we describe the evolution of the fault permeability due to the slip along its plane and the development of plastic deformations leading to the loss of reservoir integrity and CO2 leakage. Sensitivity analysis of the coupled model to realistic values of input parameters to assess the fault stability is carried out.","created":"2023-01-12","meta":{"link":"http://arxiv.org/abs/2301.04931v1","tag":"data-quality"}}
{"title":"Objective Evaluation-based High-efficiency Learning Framework for Hyperspectral Image Classification","abstract":"Deep learning methods have been successfully applied to hyperspectral image (HSI) classification with remarkable performance. Because of limited labelled HSI data, earlier studies primarily adopted a patch-based classification framework, which divides images into overlapping patches for training and testing. However, this approach results in redundant computations and possible information leakage. In this study, we propose an objective evaluation-based high-efficiency learning framework for tiny HSI classification. This framework comprises two main parts: (i) a leakage-free balanced sampling strategy, and (ii) a modified end-to-end fully convolutional network (FCN) architecture that optimizes the trade-off between accuracy and efficiency. The leakage-free balanced sampling strategy generates balanced and non-overlapping training and testing data by partitioning an HSI and the ground truth image into small windows, each of which corresponds to one training or testing sample. The proposed high-efficiency FCN exhibits a pixel-to-pixel architecture with modifications aimed at faster inference speed and improved parameter efficiency. Experiments conducted on four representative datasets demonstrated that the proposed sampling strategy can provide objective performance evaluation and that the proposed network outperformed many state-of-the-art approaches with respect to the speed/accuracy tradeoff. Our source code is available at https://github.com/xmzhang2018.","created":"2023-01-10","meta":{"link":"http://arxiv.org/abs/2302.05297v1","tag":"data-quality"}}
{"title":"Why People Skip Music? On Predicting Music Skips using Deep Reinforcement Learning","abstract":"Music recommender systems are an integral part of our daily life. Recent research has seen a significant effort around black-box recommender based approaches such as Deep Reinforcement Learning (DRL). These advances have led, together with the increasing concerns around users' data collection and privacy, to a strong interest in building responsible recommender systems. A key element of a successful music recommender system is modelling how users interact with streamed content. By first understanding these interactions, insights can be drawn to enable the construction of more transparent and responsible systems. An example of these interactions is skipping behaviour, a signal that can measure users' satisfaction, dissatisfaction, or lack of interest. In this paper, we study the utility of users' historical data for the task of sequentially predicting users' skipping behaviour. To this end, we adapt DRL for this classification task, followed by a post-hoc explainability (SHAP) and ablation analysis of the input state representation. Experimental results from a real-world music streaming dataset (Spotify) demonstrate the effectiveness of our approach in this task by outperforming state-of-the-art models. A comprehensive analysis of our approach and of users' historical data reveals a temporal data leakage problem in the dataset. Our findings indicate that, overall, users' behaviour features are the most discriminative in how our proposed DRL model predicts music skips. Content and contextual features have a lesser effect. This suggests that a limited amount of user data should be collected and leveraged to predict skipping behaviour.","created":"2023-01-10","meta":{"link":"http://arxiv.org/abs/2301.03881v1","tag":"data-quality"}}
{"title":"Precise certification of a qubit space","abstract":"We demonstrate an implementation of the precise test of dimension on the qubit, using the public IBM quantum computer, using the determinant dimension witness. The accuracy is below $10^{-3}$ comparing to maximal possible value of the witness in higher dimension. The test involving minimal independent sets of preparation and measurement operations (gates) is applied both for specific configurations and parametric ones. The test is be robust against nonidealities such as incoherent leakage and erroneous gate execution. Two of the IBM devices failed the test by more than $5$ standard deviations, which has no simple explanation.","created":"2023-01-09","meta":{"link":"http://arxiv.org/abs/2301.03296v1","tag":"data-quality"}}
{"title":"Transceiver Cooperative Learning-aided Semantic Communications Against Mismatched Background Knowledge Bases","abstract":"Semantic communications learned on background knowledge bases (KBs) have been identified as a promising technology for communications between intelligent agents. Existing works assume that transceivers of semantic communications share the same KB. However, intelligent transceivers may suffer from the communication burden or worry about privacy leakage to exchange data in KBs. Besides, the transceivers may independently learn from the environment and dynamically update their KBs, leading to timely sharing of the KBs infeasible. All these cause the mismatch between the KBs, which may result in a semantic-level misunderstanding on the receiver side. To address this issue, we propose a transceiver cooperative learning-assisted semantic communication (TCL-SC) scheme against mismatched KBs. In TCL-SC, the transceivers cooperatively train semantic encoder and decoder neuron networks (NNs) of the same structure based on their own KBs. They periodically share the parameters of NNs. To reduce the communication overhead of parameter sharing, parameter quantization is adopted. Moreover, we discuss the impacts of the number of communication rounds on the performance of semantic communication systems. Experiments on real-world data demonstrate that our proposed TCL-SC can reduce the semantic-level misunderstanding on the receiver side caused by the mismatch between the KBs, especially at the low signal-to-noise (SNR) ratio regime.","created":"2023-01-09","meta":{"link":"http://arxiv.org/abs/2301.03133v1","tag":"data-quality"}}
{"title":"Detection of He++ ion in the star-forming ring of the Cartwheel using MUSE data and ionizing mechanisms","abstract":"We here report the detection of the nebular HeII4686 line in 32 HII regions in the metal-poor collisional ring galaxy Cartwheel using the Multi-Unit Spectroscopic Explorer (MUSE) dataset. The measured I(HeII4686)/I(Hbeta) ratio varies from 0.004 to 0.07, with a mean value of 0.010+/-0.003. Ten of these 32 HII regions are coincident with the location of an Ultra Luminous X-ray (ULX) source. We used the flux ratios of important diagnostic lines and results of photoionization by Simple Stellar Populations (SSPs) to investigate the likely physical mechanisms responsible for the ionization of He+. We find that the majority of the regions (27) are consistent with photoionization by star clusters in their Wolf-Rayet (WR) phase with initial ionization parameter -3.5<logU<-2.0. Blue Bump (BB), the characteristic feature of the WR stars, however, is not detected in any of the spectra. We demonstrate that this non-detection is due to the relatively low equivalent width (EW) of the BB in metal-poor SSPs, in spite of containing sufficient number of WR stars to reproduce the observed I(HeII4686)/I(Hbeta) ratio of 1.5% at the Cartwheel metallicity of Z=0.004. The HII regions in the WR phase that are coincident with a ULX source do not show line ratios characteristic of ionization by X-ray sources. However, the ULX sources may have a role to play in the ionization of He+ in two (#99, 144) of the five regions that are not in the WR phase. Ionization by radiative shocks along with the presence of channels for the selective leakage of ionizing photons are the likely scenarios in #17 and #148, the two regions with the highest observed I(HeII4686)/I(Hbeta) ratio.","created":"2023-01-08","meta":{"link":"http://arxiv.org/abs/2301.03073v1","tag":"data-quality"}}
{"title":"Characterization of a half-wave plate for CMB circular polarization measurement with POLARBEAR","abstract":"A half-wave plate (HWP) is often used as a modulator to suppress systematic error in the measurements of cosmic microwave background (CMB) polarization. An HWP can also be used to measure circular polarization (CP) through its optical leakage from CP to linear polarization. The CP of the CMB is predicted to be produced by interactions in the Universe, such as interactions with supernova remnants of population III stars. Thus, the observation of the CP of CMB is a new tool for searching for population III stars. In this paper, we demonstrate the improved measurement of the leakage coefficient using the transmission spectrum measurement of an actual HWP in the laboratory. We measured the transmittance of linearly polarized light through the HWP used in the \\textsc{Polarbear} experiment in the frequency range of \\SIrange{120}{160}{GHz}. We evaluate properties of the HWP by fitting the data with a physical model using the Markov Chain Monte Carlo method. We then estimate the band-averaged CP leakage coefficient using the physical model. We find that the leakage coefficient strongly depends on the spectra of CP sources. We thus calculate the maximum rate of leakage from CP to linear polarization as $0.133 \\pm 0.009$ in the Rayleigh--Jeans spectrum. The nonzero value shows that \\textsc{Polarbear} would have sensitivity to the CP. Additionally, because we use the bandpass of detectors installed in the telescope to calculate the band-averaged values, we also consider systematic effects in the experiment.","created":"2023-01-05","meta":{"link":"http://arxiv.org/abs/2301.01983v1","tag":"data-quality"}}
{"title":"PMP: Privacy-Aware Matrix Profile against Sensitive Pattern Inference for Time Series","abstract":"Recent rapid development of sensor technology has allowed massive fine-grained time series (TS) data to be collected and set the foundation for the development of data-driven services and applications. During the process, data sharing is often involved to allow the third-party modelers to perform specific time series data mining (TSDM) tasks based on the need of data owner. The high resolution of TS brings new challenges in protecting privacy. While meaningful information in high-resolution TS shifts from concrete point values to local shape-based segments, numerous research have found that long shape-based patterns could contain more sensitive information and may potentially be extracted and misused by a malicious third party. However, the privacy issue for TS patterns is surprisingly seldom explored in privacy-preserving literature. In this work, we consider a new privacy-preserving problem: preventing malicious inference on long shape-based patterns while preserving short segment information for the utility task performance. To mitigate the challenge, we investigate an alternative approach by sharing Matrix Profile (MP), which is a non-linear transformation of original data and a versatile data structure that supports many data mining tasks. We found that while MP can prevent concrete shape leakage, the canonical correlation in MP index can still reveal the location of sensitive long pattern. Based on this observation, we design two attacks named Location Attack and Entropy Attack to extract the pattern location from MP. To further protect MP from these two attacks, we propose a Privacy-Aware Matrix Profile (PMP) via perturbing the local correlation and breaking the canonical correlation in MP index vector. We evaluate our proposed PMP against baseline noise-adding methods through quantitative analysis and real-world case studies to show the effectiveness of the proposed method.","created":"2023-01-04","meta":{"link":"http://arxiv.org/abs/2301.01838v1","tag":"data-quality"}}
{"title":"One-Time Universal Hashing Quantum Digital Signatures without Perfect Keys","abstract":"Quantum digital signatures (QDS), generating correlated bit strings among three remote parties for signatures through quantum law, can guarantee non-repudiation, authenticity, and integrity of messages. Recently, one-time universal hashing QDS framework, exploiting the quantum asymmetric encryption and universal hash functions, has been proposed to significantly improve the signature rate and ensure unconditional security by directly signing the hash value of long messages. However, similar to quantum key distribution, this framework utilizes keys with perfect secrecy by performing privacy amplification that introduces cumbersome matrix operations, thereby consuming large computational resources, causing delays and increasing failure probability. Here, we prove that, different from private communication, imperfect quantum keys with limited information leakage can be used for digital signatures and authentication without compromising the security while having eight orders of magnitude improvement on signature rate for signing a megabit message compared with conventional single-bit schemes. This study significantly reduces the delay for data postprocessing and is compatible with any quantum key generation protocols. In our simulation, taking two-photon twin-field key generation protocol as an example, QDS can be practically implemented over a fiber distance of 650 km between the signer and receiver. For the first time, this study offers a cryptographic application of quantum keys with imperfect secrecy and paves a way for the practical and agile implementation of digital signatures in a future quantum network.","created":"2023-01-03","meta":{"link":"http://arxiv.org/abs/2301.01132v2","tag":"data-quality"}}
{"title":"Packing Privacy Budget Efficiently","abstract":"Machine learning (ML) models can leak information about users, and differential privacy (DP) provides a rigorous way to bound that leakage under a given budget. This DP budget can be regarded as a new type of compute resource in workloads of multiple ML models training on user data. Once it is used, the DP budget is forever consumed. Therefore, it is crucial to allocate it most efficiently to train as many models as possible. This paper presents the scheduler for privacy that optimizes for efficiency. We formulate privacy scheduling as a new type of multidimensional knapsack problem, called privacy knapsack, which maximizes DP budget efficiency. We show that privacy knapsack is NP-hard, hence practical algorithms are necessarily approximate. We develop an approximation algorithm for privacy knapsack, DPK, and evaluate it on microbenchmarks and on a new, synthetic private-ML workload we developed from the Alibaba ML cluster trace. We show that DPK: (1) often approaches the efficiency-optimal schedule, (2) consistently schedules more tasks compared to a state-of-the-art privacy scheduling algorithm that focused on fairness (1.3-1.7x in Alibaba, 1.0-2.6x in microbenchmarks), but (3) sacrifices some level of fairness for efficiency. Therefore, using DPK, DP ML operators should be able to train more models on the same amount of user data while offering the same privacy guarantee to their users.","created":"2022-12-26","meta":{"link":"http://arxiv.org/abs/2212.13228v1","tag":"data-quality"}}
{"title":"Social-Aware Clustered Federated Learning with Customized Privacy Preservation","abstract":"A key feature of federated learning (FL) is to preserve the data privacy of end users. However, there still exist potential privacy leakage in exchanging gradients under FL. As a result, recent research often explores the differential privacy (DP) approaches to add noises to the computing results to address privacy concerns with low overheads, which however degrade the model performance. In this paper, we strike the balance of data privacy and efficiency by utilizing the pervasive social connections between users. Specifically, we propose SCFL, a novel Social-aware Clustered Federated Learning scheme, where mutually trusted individuals can freely form a social cluster and aggregate their raw model updates (e.g., gradients) inside each cluster before uploading to the cloud for global aggregation. By mixing model updates in a social group, adversaries can only eavesdrop the social-layer combined results, but not the privacy of individuals. We unfold the design of SCFL in three steps. \\emph{i) Stable social cluster formation. Considering users' heterogeneous training samples and data distributions, we formulate the optimal social cluster formation problem as a federation game and devise a fair revenue allocation mechanism to resist free-riders. ii) Differentiated trust-privacy mapping}. For the clusters with low mutual trust, we design a customizable privacy preservation mechanism to adaptively sanitize participants' model updates depending on social trust degrees. iii) Distributed convergence}. A distributed two-sided matching algorithm is devised to attain an optimized disjoint partition with Nash-stable convergence. Experiments on Facebook network and MNIST/CIFAR-10 datasets validate that our SCFL can effectively enhance learning utility, improve user payoff, and enforce customizable privacy protection.","created":"2022-12-25","meta":{"link":"http://arxiv.org/abs/2212.13992v1","tag":"data-quality"}}
{"title":"On the Privacy-Utility Trade-off With and Without Direct Access to the Private Data","abstract":"We study an information theoretic privacy mechanism design problem for two scenarios where the private data is either observable or hidden. In each scenario, we first consider bounded mutual information as privacy leakage criterion, then we use two different per-letter privacy constraints. In the first scenario, an agent observes useful data $Y$ that is correlated with private data $X$, and wishes to disclose the useful information to a user. A privacy mechanism is designed to generate disclosed data $U$ which maximizes the revealed information about $Y$ while satisfying a bounded privacy leakage constraint. In the second scenario, the agent has additionally access to the private data. To this end, we first extend the Functional Representation Lemma and Strong Functional Representation Lemma by relaxing the independence condition and thereby allowing a certain leakage to find lower bounds for the second scenario with different privacy leakage constraints. Furthermore, upper and lower bounds are derived in the first scenario considering different privacy constraints. In particular, for the case where no leakage is allowed, our upper and lower bounds improve previous bounds. Moreover, considering bounded mutual information as privacy constraint we show that if the common information and mutual information between $X$ and $Y$ are equal, then the attained upper bound in the second scenario is tight. Finally, the privacy-utility trade-off with prioritized private data is studied where part of $X$, i.e., $X_1$, is more private than the remaining part, i.e., $X_2$, and we provide lower and upper bounds.","created":"2022-12-23","meta":{"link":"http://arxiv.org/abs/2212.12475v1","tag":"data-quality"}}
{"title":"Model Segmentation for Storage Efficient Private Federated Learning with Top $r$ Sparsification","abstract":"In federated learning (FL) with top $r$ sparsification, millions of users collectively train a machine learning (ML) model locally, using their personal data by only communicating the most significant $r$ fraction of updates to reduce the communication cost. It has been shown that the values as well as the indices of these selected (sparse) updates leak information about the users' personal data. In this work, we investigate different methods to carry out user-database communications in FL with top $r$ sparsification efficiently, while guaranteeing information theoretic privacy of users' personal data. These methods incur considerable storage cost. As a solution, we present two schemes with different properties that use MDS coded storage along with a model segmentation mechanism to reduce the storage cost at the expense of a controllable amount of information leakage, to perform private FL with top $r$ sparsification.","created":"2022-12-22","meta":{"link":"http://arxiv.org/abs/2212.11947v1","tag":"data-quality"}}
{"title":"Physics-Based and Closed-Form Model for Cryo-CMOS Subthreshold Swing","abstract":"Cryogenic semiconductor device models are instrumental in designing control systems for quantum devices and in benchmarking the benefits of cryogenic cooling for high-performance computing. In particular, the saturation of subthreshold swing due to band tails is an important phenomenon to include in low-temperature analytical MOSFET models as it predicts theoretical lower bounds on the leakage power and supply voltage in tailored cryogenic CMOS technologies with tuned threshold voltages. Previous physics-based modeling required to evaluate functions with no closed-form solutions, defeating the purpose of fast and efficient model evaluation. Thus far, only the empirically proposed expressions are in closed form. This article bridges this gap by deriving a physics-based and closed-form model for the full saturating trend of the subthreshold swing from room down to low temperature. The proposed model is compared against experimental data taken on long nMOS and pMOS devices from a commercial 28-nm bulk CMOS technology from 300 down to 4.2 K.","created":"2022-12-22","meta":{"link":"http://arxiv.org/abs/2212.11943v1","tag":"data-quality"}}
{"title":"Secure Aggregation of Semi-Honest Clients and Servers in Federated Learning with Secret-Shared Homomorphism","abstract":"Privacy-preserving distributed machine learning has been recognized as one of the most promising paradigms for the collaboration of multiple or many clients who cannot disclose their local data -- neither the training data set nor the model parameters. One popular approach to preserving the confidentiality of local data is homomorphic encryption (HE): the clients send encrypted model parameters to the server, which aggregates the models into a global model and broadcasts it to the clients. Evidently, the security of the above HE-based approach depends on the assumption that the clients are honest and cannot obtain the encrypted models from others (otherwise the models can be immediately decrypted because all clients share the same private key); this is indeed the case since the encrypted models are transmitted through protocols like Transport Layer Security (TLS). However, it is often overlooked that the leakage of encrypted models does not necessarily happen on the network channel; for example, if a semi-honest client colludes with a semi-honest server (the former having the private key and the latter having the ciphertext), possibly offline in another session, they can surely recover the model parameters in question. This paper presents a new protocol for secure aggregation under the mild, in our opinion more practical, assumption that all parties are semi-honest. As a starting point, we construct a new security primitive, called \\textit{asymmetric threshold secret sharing} (ATSS), which works with homomorphic encryption to constitute an aggregation protocol to achieve the desired security. We demonstrate that the ATSS-based protocol is provably secure and delivers reasonable performance in practice.","created":"2022-12-21","meta":{"link":"http://arxiv.org/abs/2212.11394v1","tag":"data-quality"}}
{"title":"Learned Systems Security","abstract":"A learned system uses machine learning (ML) internally to improve performance. We can expect such systems to be vulnerable to some adversarial-ML attacks. Often, the learned component is shared between mutually-distrusting users or processes, much like microarchitectural resources such as caches, potentially giving rise to highly-realistic attacker models. However, compared to attacks on other ML-based systems, attackers face a level of indirection as they cannot interact directly with the learned model. Additionally, the difference between the attack surface of learned and non-learned versions of the same system is often subtle. These factors obfuscate the de-facto risks that the incorporation of ML carries. We analyze the root causes of potentially-increased attack surface in learned systems and develop a framework for identifying vulnerabilities that stem from the use of ML. We apply our framework to a broad set of learned systems under active development. To empirically validate the many vulnerabilities surfaced by our framework, we choose 3 of them and implement and evaluate exploits against prominent learned-system instances. We show that the use of ML caused leakage of past queries in a database, enabled a poisoning attack that causes exponential memory blowup in an index structure and crashes it in seconds, and enabled index users to snoop on each others' key distributions by timing queries over their own keys. We find that adversarial ML is a universal threat against learned systems, point to open research gaps in our understanding of learned-systems security, and conclude by discussing mitigations, while noting that data leakage is inherent in systems whose learned component is shared between multiple parties.","created":"2022-12-20","meta":{"link":"http://arxiv.org/abs/2212.10318v3","tag":"data-quality"}}
{"title":"V-LoTSS: The Circularly-Polarised LOFAR Two-metre Sky Survey","abstract":"We present the detection of 68 sources from the most sensitive radio survey in circular polarisation conducted to date. We use the second data release of the 144 MHz LOFAR Two-metre Sky Survey to produce circularly-polarised maps with median 140 $\\mu$Jy beam$^{-1}$ noise and resolution of 20$''$ for $\\approx$27% of the northern sky (5634 deg$^{2}$). The leakage of total intensity into circular polarisation is measured to be $\\approx$0.06%, and our survey is complete at flux densities $\\geq1$ mJy. A detection is considered reliable when the circularly-polarised fraction exceeds 1%. We find the population of circularly-polarised sources is composed of four distinct classes: stellar systems, pulsars, active galactic nuclei, and sources unidentified in the literature. The stellar systems can be further separated into chromospherically-active stars, M dwarfs, and brown dwarfs. Based on the circularly-polarised fraction and lack of an optical counterpart, we show it is possible to infer whether the unidentified sources are likely unknown pulsars or brown dwarfs. By the completion of this survey of the northern sky, we expect to detect 300$\\pm$100 circularly-polarised sources.","created":"2022-12-19","meta":{"link":"http://arxiv.org/abs/2212.09815v1","tag":"data-quality"}}
{"title":"Increasing Physical Layer Security through Hyperchaos in VLC Systems","abstract":"Visible Light Communication (VLC) systems have relatively higher security compared with traditional Radio Frequency (RF) channels due to line-of-sight (LOS) propagation. However, they still are susceptible to eavesdropping. The proposed solution of the papers have been built on existing work on hyperchaos-based security measure to increase physical layer security from eavesdroppers. A fourth-order Henon map is used to scramble the constellation diagrams of the transmitted signals. The scramblers change the constellation symbol of the system using a key. That key on the receiver side de-scrambles the received data. The presented modulation scheme takes advantage of a higher degree of the map to isolate the data transmission to a single dimension, allowing for better scrambling and synchronization. A sliding mode controller is used at the receiver in a master-slave configuration for projective synchronization of the two Henon maps, which helps de-scramble the received data. The data is only isolated for the users aware of the key for synchronization, providing security against eavesdroppers. The proposed VLC system is compared against various existing approaches based on various metrics. An improved Bit Error Rate and a lower information leakage are achieved for a variety of modulation schemes at an acceptable Signal-to-Noise Ratio.","created":"2022-12-17","meta":{"link":"http://arxiv.org/abs/2212.08927v1","tag":"data-quality"}}
{"title":"Modeling Global Distribution for Federated Learning with Label Distribution Skew","abstract":"Federated learning achieves joint training of deep models by connecting decentralized data sources, which can significantly mitigate the risk of privacy leakage. However, in a more general case, the distributions of labels among clients are different, called ``label distribution skew''. Directly applying conventional federated learning without consideration of label distribution skew issue significantly hurts the performance of the global model. To this end, we propose a novel federated learning method, named FedMGD, to alleviate the performance degradation caused by the label distribution skew issue. It introduces a global Generative Adversarial Network to model the global data distribution without access to local datasets, so the global model can be trained using the global information of data distribution without privacy leakage. The experimental results demonstrate that our proposed method significantly outperforms the state-of-the-art on several public benchmarks. Code is available at \\url{https://github.com/Sheng-T/FedMGD}.","created":"2022-12-17","meta":{"link":"http://arxiv.org/abs/2212.08883v1","tag":"data-quality"}}
{"title":"Planting and Mitigating Memorized Content in Predictive-Text Language Models","abstract":"Language models are widely deployed to provide automatic text completion services in user products. However, recent research has revealed that language models (especially large ones) bear considerable risk of memorizing private training data, which is then vulnerable to leakage and extraction by adversaries. In this study, we test the efficacy of a range of privacy-preserving techniques to mitigate unintended memorization of sensitive user text, while varying other factors such as model size and adversarial conditions. We test both \"heuristic\" mitigations (those without formal privacy guarantees) and Differentially Private training, which provides provable levels of privacy at the cost of some model performance. Our experiments show that (with the exception of L2 regularization), heuristic mitigations are largely ineffective in preventing memorization in our test suite, possibly because they make too strong of assumptions about the characteristics that define \"sensitive\" or \"private\" text. In contrast, Differential Privacy reliably prevents memorization in our experiments, despite its computational and model-performance costs.","created":"2022-12-16","meta":{"link":"http://arxiv.org/abs/2212.08619v1","tag":"data-quality"}}
{"title":"De-risking Carbon Capture and Sequestration with Explainable CO2 Leakage Detection in Time-lapse Seismic Monitoring Images","abstract":"With the growing global deployment of carbon capture and sequestration technology to combat climate change, monitoring and detection of potential CO2 leakage through existing or storage induced faults are critical to the safe and long-term viability of the technology. Recent work on time-lapse seismic monitoring of CO2 storage has shown promising results in its ability to monitor the growth of the CO2 plume from surface recorded seismic data. However, due to the low sensitivity of seismic imaging to CO2 concentration, additional developments are required to efficiently interpret the seismic images for leakage. In this work, we introduce a binary classification of time-lapse seismic images to delineate CO2 plumes (leakage) using state-of-the-art deep learning models. Additionally, we localize the leakage region of CO2 plumes by leveraging Class Activation Mapping methods.","created":"2022-12-16","meta":{"link":"http://arxiv.org/abs/2212.08596v1","tag":"data-quality"}}
{"title":"Swing Distillation: A Privacy-Preserving Knowledge Distillation Framework","abstract":"Knowledge distillation (KD) has been widely used for model compression and knowledge transfer. Typically, a big teacher model trained on sufficient data transfers knowledge to a small student model. However, despite the success of KD, little effort has been made to study whether KD leaks the training data of the teacher model. In this paper, we experimentally reveal that KD suffers from the risk of privacy leakage. To alleviate this issue, we propose a novel knowledge distillation method, swing distillation, which can effectively protect the private information of the teacher model from flowing to the student model. In our framework, the temperature coefficient is dynamically and adaptively adjusted according to the degree of private information contained in the data, rather than a predefined constant hyperparameter. It assigns different temperatures to tokens according to the likelihood that a token in a position contains private information. In addition, we inject noise into soft targets provided to the student model, in order to avoid unshielded knowledge transfer. Experiments on multiple datasets and tasks demonstrate that the proposed swing distillation can significantly reduce (by over 80% in terms of canary exposure) the risk of privacy leakage in comparison to KD with competitive or better performance. Furthermore, swing distillation is robust against the increasing privacy budget.","created":"2022-12-16","meta":{"link":"http://arxiv.org/abs/2212.08349v1","tag":"data-quality"}}
{"title":"Deep leakage from gradients","abstract":"With the development of artificial intelligence technology, Federated Learning (FL) model has been widely used in many industries for its high efficiency and confidentiality. Some researchers have explored its confidentiality and designed some algorithms to attack training data sets, but these algorithms all have their own limitations. Therefore, most people still believe that local machine learning gradient information is safe and reliable. In this paper, an algorithm based on gradient features is designed to attack the federated learning model in order to attract more attention to the security of federated learning systems. In federated learning system, gradient contains little information compared with the original training data set, but this project intends to restore the original training image data through gradient information. Convolutional Neural Network (CNN) has excellent performance in image processing. Therefore, the federated learning model of this project is equipped with Convolutional Neural Network structure, and the model is trained by using image data sets. The algorithm calculates the virtual gradient by generating virtual image labels. Then the virtual gradient is matched with the real gradient to restore the original image. This attack algorithm is written in Python language, uses cat and dog classification Kaggle data sets, and gradually extends from the full connection layer to the convolution layer, thus improving the universality. At present, the average squared error between the data recovered by this algorithm and the original image information is approximately 5, and the vast majority of images can be completely restored according to the gradient information given, indicating that the gradient of federated learning system is not absolutely safe and reliable.","created":"2022-12-15","meta":{"link":"http://arxiv.org/abs/2301.02621v1","tag":"data-quality"}}
{"title":"White-box Inference Attacks against Centralized Machine Learning and Federated Learning","abstract":"With the development of information science and technology, various industries have generated massive amounts of data, and machine learning is widely used in the analysis of big data. However, if the privacy of machine learning applications' customers cannot be guaranteed, it will cause security threats and losses to users' personal privacy information and service providers. Therefore, the issue of privacy protection of machine learning has received wide attention. For centralized machine learning models, we evaluate the impact of different neural network layers, gradient, gradient norm, and fine-tuned models on member inference attack performance with prior knowledge; For the federated learning model, we discuss the location of the attacker in the target model and its attack mode. The results show that the centralized machine learning model shows more serious member information leakage in all aspects, and the accuracy of the attacker in the central parameter server is significantly higher than the local Inference attacks as participants.","created":"2022-12-15","meta":{"link":"http://arxiv.org/abs/2301.03595v1","tag":"data-quality"}}
{"title":"A Survey on Privacy of Personal and Non-Personal Data in B5G/6G Networks","abstract":"The upcoming Beyond 5G (B5G) and 6G networks are expected to provide enhanced capabilities such as ultra-high data rates, dense connectivity, and high scalability. It opens many possibilities for a new generation of services driven by Artificial Intelligence (AI) and billions of interconnected smart devices. However, with this expected massive upgrade, the privacy of people, organizations, and states is becoming a rising concern. The recent introduction of privacy laws and regulations for personal and non-personal data signals that global awareness is emerging in the current privacy landscape. Yet, many gaps need to be identified in the case of two data types. If not detected, they can lead to significant privacy leakages and attacks that will affect billions of people and organizations who utilize B5G/6G. This survey is a comprehensive study of personal and non-personal data privacy in B5G/6G to identify the current progress and future directions to ensure data privacy. We provide a detailed comparison of the two data types and a set of related privacy goals for B5G/6G. Next, we bring data privacy issues with possible solutions. This paper also provides future directions to preserve personal and non-personal data privacy in future networks.","created":"2022-12-14","meta":{"link":"http://arxiv.org/abs/2212.06987v1","tag":"data-quality"}}
{"title":"Style-Label-Free: Cross-Speaker Style Transfer by Quantized VAE and Speaker-wise Normalization in Speech Synthesis","abstract":"Cross-speaker style transfer in speech synthesis aims at transferring a style from source speaker to synthesised speech of a target speaker's timbre. Most previous approaches rely on data with style labels, but manually-annotated labels are expensive and not always reliable. In response to this problem, we propose Style-Label-Free, a cross-speaker style transfer method, which can realize the style transfer from source speaker to target speaker without style labels. Firstly, a reference encoder structure based on quantized variational autoencoder (Q-VAE) and style bottleneck is designed to extract discrete style representations. Secondly, a speaker-wise batch normalization layer is proposed to reduce the source speaker leakage. In order to improve the style extraction ability of the reference encoder, a style invariant and contrastive data augmentation method is proposed. Experimental results show that the method outperforms the baseline. We provide a website with audio samples.","created":"2022-12-13","meta":{"link":"http://arxiv.org/abs/2212.06397v1","tag":"data-quality"}}
{"title":"Privacy-Preserving Collaborative Learning through Feature Extraction","abstract":"We propose a framework in which multiple entities collaborate to build a machine learning model while preserving privacy of their data. The approach utilizes feature embeddings from shared/per-entity feature extractors transforming data into a feature space for cooperation between entities. We propose two specific methods and compare them with a baseline method. In Shared Feature Extractor (SFE) Learning, the entities use a shared feature extractor to compute feature embeddings of samples. In Locally Trained Feature Extractor (LTFE) Learning, each entity uses a separate feature extractor and models are trained using concatenated features from all entities. As a baseline, in Cooperatively Trained Feature Extractor (CTFE) Learning, the entities train models by sharing raw data. Secure multi-party algorithms are utilized to train models without revealing data or features in plain text. We investigate the trade-offs among SFE, LTFE, and CTFE in regard to performance, privacy leakage (using an off-the-shelf membership inference attack), and computational cost. LTFE provides the most privacy, followed by SFE, and then CTFE. Computational cost is lowest for SFE and the relative speed of CTFE and LTFE depends on network architecture. CTFE and LTFE provide the best accuracy. We use MNIST, a synthetic dataset, and a credit card fraud detection dataset for evaluations.","created":"2022-12-13","meta":{"link":"http://arxiv.org/abs/2212.06322v1","tag":"data-quality"}}
{"title":"Data Leakage via Access Patterns of Sparse Features in Deep Learning-based Recommendation Systems","abstract":"Online personalized recommendation services are generally hosted in the cloud where users query the cloud-based model to receive recommended input such as merchandise of interest or news feed. State-of-the-art recommendation models rely on sparse and dense features to represent users' profile information and the items they interact with. Although sparse features account for 99% of the total model size, there was not enough attention paid to the potential information leakage through sparse features. These sparse features are employed to track users' behavior, e.g., their click history, object interactions, etc., potentially carrying each user's private information. Sparse features are represented as learned embedding vectors that are stored in large tables, and personalized recommendation is performed by using a specific user's sparse feature to index through the tables. Even with recently-proposed methods that hides the computation happening in the cloud, an attacker in the cloud may be able to still track the access patterns to the embedding tables. This paper explores the private information that may be learned by tracking a recommendation model's sparse feature access patterns. We first characterize the types of attacks that can be carried out on sparse features in recommendation models in an untrusted cloud, followed by a demonstration of how each of these attacks leads to extracting users' private information or tracking users by their behavior over time.","created":"2022-12-12","meta":{"link":"http://arxiv.org/abs/2212.06264v1","tag":"data-quality"}}
{"title":"A Bargaining Game for Personalized, Energy Efficient Split Learning over Wireless Networks","abstract":"Split learning (SL) is an emergent distributed learning framework which can mitigate the computation and wireless communication overhead of federated learning. It splits a machine learning model into a device-side model and a server-side model at a cut layer. Devices only train their allocated model and transmit the activations of the cut layer to the server. However, SL can lead to data leakage as the server can reconstruct the input data using the correlation between the input and intermediate activations. Although allocating more layers to a device-side model can reduce the possibility of data leakage, this will lead to more energy consumption for resource-constrained devices and more training time for the server. Moreover, non-iid datasets across devices will reduce the convergence rate leading to increased training time. In this paper, a new personalized SL framework is proposed. For this framework, a novel approach for choosing the cut layer that can optimize the tradeoff between the energy consumption for computation and wireless transmission, training time, and data privacy is developed. In the considered framework, each device personalizes its device-side model to mitigate non-iid datasets while sharing the same server-side model for generalization. To balance the energy consumption for computation and wireless transmission, training time, and data privacy, a multiplayer bargaining problem is formulated to find the optimal cut layer between devices and the server. To solve the problem, the Kalai-Smorodinsky bargaining solution (KSBS) is obtained using the bisection method with the feasibility test. Simulation results show that the proposed personalized SL framework with the cut layer from the KSBS can achieve the optimal sum utilities by balancing the energy consumption, training time, and data privacy, and it is also robust to non-iid datasets.","created":"2022-12-12","meta":{"link":"http://arxiv.org/abs/2212.06107v1","tag":"data-quality"}}
{"title":"Eliminating Leakage in Volatile Memory with Anti-Ferroelectric Transistors","abstract":"Cache serves as a temporary data memory module in many general-purpose processors and domain-specific accelerators. Its density, power, speed, and reliability play a critical role in enhancing the overall system performance and quality of service. Conventional volatile memories, including static random-access memory (SRAM) and embedded dynamic random-access memory (eDRAM) in the complementary metal-oxide-semiconductor technology, have high performance and good reliability. However, the inherent leakage in both SRAM and eDRAM hinders further improvement towards smaller feature sizes and higher energy efficiency. Although the emerging nonvolatile memories can eliminate the leakage efficiently, the penalties of lower speed and degraded reliability are significant. This article reveals a new opportunity towards leakage-free volatile static memory beyond the known paradigms of existing volatile and nonvolatile memories. By engineering a double-well energy landscape with the assistance of a clamping voltage bias, leakage-free and refresh-free state retention of volatile memory is achieved for the first time. This new memory is highlighted by both the ultra-low leakage of nonvolatile memories and the speed, energy, and reliability advantages of volatile memories. A proof-of-concept memory is demonstrated using in-house anti-ferroelectric field-effect transistors (AFeFETs), delivering an extrapolated endurance of about 1012 cycles, a retention time of over 10 years, and no subthreshold channel leakage current. Such a new concept of AFeFET-based memory enables an improved balance between density, power, and reliability beyond all existing memory solutions.","created":"2022-12-09","meta":{"link":"http://arxiv.org/abs/2212.04973v4","tag":"data-quality"}}
{"title":"Skellam Mixture Mechanism: a Novel Approach to Federated Learning with Differential Privacy","abstract":"Deep neural networks have strong capabilities of memorizing the underlying training data, which can be a serious privacy concern. An effective solution to this problem is to train models with differential privacy, which provides rigorous privacy guarantees by injecting random noise to the gradients. This paper focuses on the scenario where sensitive data are distributed among multiple participants, who jointly train a model through federated learning (FL), using both secure multiparty computation (MPC) to ensure the confidentiality of each gradient update, and differential privacy to avoid data leakage in the resulting model. A major challenge in this setting is that common mechanisms for enforcing DP in deep learning, which inject real-valued noise, are fundamentally incompatible with MPC, which exchanges finite-field integers among the participants. Consequently, most existing DP mechanisms require rather high noise levels, leading to poor model utility. Motivated by this, we propose Skellam mixture mechanism (SMM), an approach to enforce DP on models built via FL. Compared to existing methods, SMM eliminates the assumption that the input gradients must be integer-valued, and, thus, reduces the amount of noise injected to preserve DP. Further, SMM allows tight privacy accounting due to the nice composition and sub-sampling properties of the Skellam distribution, which are key to accurate deep learning with DP. The theoretical analysis of SMM is highly non-trivial, especially considering (i) the complicated math of differentially private deep learning in general and (ii) the fact that the mixture of two Skellam distributions is rather complex, and to our knowledge, has not been studied in the DP literature. Extensive experiments on various practical settings demonstrate that SMM consistently and significantly outperforms existing solutions in terms of the utility of the resulting model.","created":"2022-12-08","meta":{"link":"http://arxiv.org/abs/2212.04371v1","tag":"data-quality"}}
{"title":"MOB-FL: Mobility-Aware Federated Learning for Intelligent Connected Vehicles","abstract":"Federated learning (FL) is a promising approach to enable the future Internet of vehicles consisting of intelligent connected vehicles (ICVs) with powerful sensing, computing and communication capabilities. We consider a base station (BS) coordinating nearby ICVs to train a neural network in a collaborative yet distributed manner, in order to limit data traffic and privacy leakage. However, due to the mobility of vehicles, the connections between the BS and ICVs are short-lived, which affects the resource utilization of ICVs, and thus, the convergence speed of the training process. In this paper, we propose an accelerated FL-ICV framework, by optimizing the duration of each training round and the number of local iterations, for better convergence performance of FL. We propose a mobility-aware optimization algorithm called MOB-FL, which aims at maximizing the resource utilization of ICVs under short-lived wireless connections, so as to increase the convergence speed. Simulation results based on the beam selection and the trajectory prediction tasks verify the effectiveness of the proposed solution.","created":"2022-12-07","meta":{"link":"http://arxiv.org/abs/2212.03519v1","tag":"data-quality"}}
{"title":"Non-interactive Multi-client Searchable Symmetric Encryption with Small Client Storage","abstract":"Considerable attention has been paid to dynamic searchable symmetric encryption (DSSE) which allows users to search on dynamically updated encrypted databases. To improve the performance of real-world applications, recent non-interactive multi-client DSSE schemes are targeted at avoiding per-query interaction between data owners and data users. However, existing non-interactive multi-client DSSE schemes do not consider forward privacy or backward privacy, making them exposed to leakage abuse attacks. Besides, most existing DSSE schemes with forward and backward privacy rely on keeping a keyword operation counter or an inverted index, resulting in a heavy storage burden on the data owner side. To address these issues, we propose a non-interactive multi-client DSSE scheme with small client storage, and our proposed scheme can provide both forward privacy and backward privacy. Specifically, we first design a lightweight storage chain structure that binds all keywords to a single state to reduce the storage cost. Then, we present a Hidden Key technique, which preserves non-interactive forward privacy through time range queries, ensuring that data with newer timestamps cannot match earlier time ranges. We conduct extensive experiments to validate our methods, which demonstrate computational efficiency. Moreover, security analysis proves the privacy-preserving property of our methods.","created":"2022-12-06","meta":{"link":"http://arxiv.org/abs/2212.02859v1","tag":"data-quality"}}
{"title":"On the Discredibility of Membership Inference Attacks","abstract":"With the wide-spread application of machine learning models, it has become critical to study the potential data leakage of models trained on sensitive data. Recently, various membership inference (MI) attacks are proposed that determines if a sample was part of the training set or not. Although the first generation of MI attacks has been proven to be ineffective in practice, a few recent studies proposed practical MI attacks that achieve reasonable true positive rate at low false positive rate. The question is whether these attacks can be reliably used in practice. We showcase a practical application of membership inference attacks where it is used by an auditor (investigator) to prove to a judge/jury that an auditee unlawfully used sensitive data during training. Then, we show that the auditee can provide a dataset (with potentially unlimited number of samples) to a judge where MI attacks catastrophically fail. Hence, the auditee challenges the credibility of the auditor and can get the case dismissed. More importantly, we show that the auditee does not need to know anything about the MI attack neither a query access to it. In other words, all currently SOTA MI attacks in literature suffer from the same issue. Through comprehensive experimental evaluation, we show that our algorithms can increase the false positive rate from ten to thousands times larger than what auditor claim to the judge. Lastly, we argue that the implication of our algorithms is beyond discredibility: Current membership inference attacks can identify the memorized subpopulations, but they cannot reliably identify which exact sample in the subpopulation was used during training.","created":"2022-12-06","meta":{"link":"http://arxiv.org/abs/2212.02701v1","tag":"data-quality"}}
{"title":"Refiner: Data Refining against Gradient Leakage Attacks in Federated Learning","abstract":"Federated Learning (FL) is pervasive in privacy-focused IoT environments since it enables avoiding privacy leakage by training models with gradients instead of data. Recent works show the uploaded gradients can be employed to reconstruct data, i.e., gradient leakage attacks, and several defenses are designed to alleviate the risk by tweaking the gradients. However, these defenses exhibit weak resilience against threatening attacks, as the effectiveness builds upon the unrealistic assumptions that deep neural networks are simplified as linear models. In this paper, without such unrealistic assumptions, we present a novel defense, called Refiner, instead of perturbing gradients, which refines ground-truth data to craft robust data that yields sufficient utility but with the least amount of privacy information, and then the gradients of robust data are uploaded. To craft robust data, Refiner promotes the gradients of critical parameters associated with robust data to close ground-truth ones while leaving the gradients of trivial parameters to safeguard privacy. Moreover, to exploit the gradients of trivial parameters, Refiner utilizes a well-designed evaluation network to steer robust data far away from ground-truth data, thereby alleviating privacy leakage risk. Extensive experiments across multiple benchmark datasets demonstrate the superior defense effectiveness of Refiner at defending against state-of-the-art threats.","created":"2022-12-05","meta":{"link":"http://arxiv.org/abs/2212.02042v1","tag":"data-quality"}}
{"title":"PGFed: Personalize Each Client's Global Objective for Federated Learning","abstract":"The mediocre performance of conventional federated learning (FL) over heterogeneous data has been facilitating personalized FL solutions, where, unlike conventional FL which trains a single global consensus model, different models are allowed for different clients. However, in most existing personalized FL algorithms, the collaborative knowledge across the federation was only implicitly passed to the clients in ways such as model aggregation or regularization. We observed that this implicit knowledge transfer fails to maximize the potential value of each client's empirical risk toward other clients. Based on our observation, in this work, we propose Personalized Global Federated Learning (PGFed), a novel personalized FL framework that enables each client to personalize its own global objective by explicitly and adaptively aggregating the empirical risks of itself and other clients. To avoid massive ($O(N^2)$) communication overhead and potential privacy leakage, each client's risk is estimated through a first-order approximation for other clients' adaptive risk aggregation. On top of PGFed, we develop a momentum upgrade, dubbed PGFedMo, to more efficiently utilize clients' empirical risks. Our extensive experiments under different federated settings with benchmark datasets show consistent improvements of PGFed over the compared state-of-the-art alternatives.","created":"2022-12-02","meta":{"link":"http://arxiv.org/abs/2212.01448v1","tag":"data-quality"}}
{"title":"All You Need Is Hashing: Defending Against Data Reconstruction Attack in Vertical Federated Learning","abstract":"Vertical federated learning is a trending solution for multi-party collaboration in training machine learning models. Industrial frameworks adopt secure multi-party computation methods such as homomorphic encryption to guarantee data security and privacy. However, a line of work has revealed that there are still leakage risks in VFL. The leakage is caused by the correlation between the intermediate representations and the raw data. Due to the powerful approximation ability of deep neural networks, an adversary can capture the correlation precisely and reconstruct the data. To deal with the threat of the data reconstruction attack, we propose a hashing-based VFL framework, called \\textit{HashVFL}, to cut off the reversibility directly. The one-way nature of hashing allows our framework to block all attempts to recover data from hash codes. However, integrating hashing also brings some challenges, e.g., the loss of information. This paper proposes and addresses three challenges to integrating hashing: learnability, bit balance, and consistency. Experimental results demonstrate \\textit{HashVFL}'s efficiency in keeping the main task's performance and defending against data reconstruction attacks. Furthermore, we also analyze its potential value in detecting abnormal inputs. In addition, we conduct extensive experiments to prove \\textit{HashVFL}'s generalization in various settings. In summary, \\textit{HashVFL} provides a new perspective on protecting multi-party's data security and privacy in VFL. We hope our study can attract more researchers to expand the application domains of \\textit{HashVFL}.","created":"2022-12-01","meta":{"link":"http://arxiv.org/abs/2212.00325v1","tag":"data-quality"}}
{"title":"Decentralized Matrix Factorization with Heterogeneous Differential Privacy","abstract":"Conventional matrix factorization relies on centralized collection of users' data for recommendation, which might introduce an increased risk of privacy leakage especially when the recommender is untrusted. Existing differentially private matrix factorization methods either assume the recommender is trusted, or can only provide a uniform level of privacy protection for all users and items with untrusted recommender. In this paper, we propose a novel Heterogeneous Differentially Private Matrix Factorization algorithm (denoted as HDPMF) for untrusted recommender. To the best of our knowledge, we are the first to achieve heterogeneous differential privacy for decentralized matrix factorization in untrusted recommender scenario. Specifically, our framework uses modified stretching mechanism with an innovative rescaling scheme to achieve better trade off between privacy and accuracy. Meanwhile, by allocating privacy budget properly, we can capture homogeneous privacy preference within a user/item but heterogeneous privacy preference across different users/items. Theoretical analysis confirms that HDPMF renders rigorous privacy guarantee, and exhaustive experiments demonstrate its superiority especially in strong privacy guarantee, high dimension model and sparse dataset scenario.","created":"2022-12-01","meta":{"link":"http://arxiv.org/abs/2212.00306v1","tag":"data-quality"}}
{"title":"Split Learning without Local Weight Sharing to Enhance Client-side Data Privacy","abstract":"Split learning (SL) aims to protect user data privacy by splitting deep models between client-server and keeping private data locally. SL has been demonstrated to achieve similar accuracy as the centralized learning model. In SL with multiple clients, the local training weights are shared between clients for local model aggregation. This paper investigates the potential of data leakage due to local weight sharing among the clients in SL by performing model inversion attacks. To mitigate the identified leakage issue, we propose and analyze privacy-enhancement SL (P-SL), e.g., SL without local weight sharing, to boost client-side data privacy. We also propose paralleled P-SL to speed up the training process by employing multiple servers without accuracy reduction. Finally, we investigate P-SL with late participating clients and develop a server-based cache-based training to address the forgetting phenomenon in SL. Experimental results demonstrate that P-SL helps reduce up to 50% of client-side data leakage compared to SL. Moreover, P-SL and its cache-based version achieve comparable accuracy to SL under various data distributions with lower computation and communications costs. Also, caching in P-SL reduces the negative effect of forgetting, stabilizes the learning, and enables effective and low-complexity training in a dynamic environment with late-arriving clients.","created":"2022-12-01","meta":{"link":"http://arxiv.org/abs/2212.00250v1","tag":"data-quality"}}
{"title":"Wireless Image Transmission with Semantic and Security Awareness","abstract":"Semantic communication is an increasingly popular framework for wireless image transmission due to its high communication efficiency. With the aid of the joint-source-and-channel (JSC) encoder implemented by neural network, semantic communication directly maps original images into symbol sequences containing semantic information. Compared with the traditional separate source and channel coding design used in bitlevel communication systems, semantic communication systems are known to be more efficient and accurate especially in the low signal-to-the-noise ratio (SNR) regime. This thus prompts an critical while yet to be tackled issue of security in semantic communication: it makes the eavesdropper more easier to crack the semantic information as it can be decoded even in a quite noisy channel. In this letter, we develop a semantic communication framework that accounts for both semantic meaning decoding efficiency and its risk of privacy leakage. To achieve this, targeting wireless image transmission, we on the one hand propose an JSC autoencoder featuring residual for efficient semantic meaning extraction and transmission, and on the other hand, propose a data-driven scheme that balances the efficiency-privacy tradeoff. Extensive experimental results are provided to show the effectiveness and robustness of the proposed scheme.","created":"2022-12-01","meta":{"link":"http://arxiv.org/abs/2212.00227v1","tag":"data-quality"}}
{"title":"Data Privacy Protection in DeFi Protocols","abstract":"With the development of decentralized finance (DeFi), the inherent limitations caused by the blockchain system have come to the surface. Because recorded data on the blockchain is available to system participants, DeFi protocols may not collect the private data of users. Otherwise, the information leakage may result in serious financial losses or cause legal issues. Therefore, DeFi protocols could hardly offer different users customized solutions, and the capital utilization is limited. To address this challenge in DeFi, we propose a solution, which is a trustful protocol that allows users to provide personal private data to DeFi protocols without worrying that such information would be disclosed. By implementing asymmetric encryption, zero-knowledge proof, and homomorphic encryption, we ensure that users' data will not be controlled by any centralized authorities and avoid potential financial losses or legal disputes due to information leakage. We further discuss the application scenarios of financial data privacy protection in public blockchain DeFi ecosystems and cross-border financial applications, such as credit aggregation.","created":"2022-11-29","meta":{"link":"http://arxiv.org/abs/2211.16082v1","tag":"data-quality"}}
{"title":"Abstract Interpretation-Based Data Leakage Static Analysis","abstract":"Data leakage is a well-known problem in machine learning. Data leakage occurs when information from outside the training dataset is used to create a model. This phenomenon renders a model excessively optimistic or even useless in the real world since the model tends to leverage greatly on the unfairly acquired information. To date, detection of data leakages occurs post-mortem using run-time methods. However, due to the insidious nature of data leakage, it may not be apparent to a data scientist that a data leakage has occurred in the first place. For this reason, it is advantageous to detect data leakages as early as possible in the development life cycle. In this paper, we propose a novel static analysis to detect several instances of data leakages during development time. We define our analysis using the framework of abstract interpretation: we define a concrete semantics that is sound and complete, from which we derive a sound and computable abstract semantics. We implement our static analysis inside the open-source NBLyzer static analysis framework and demonstrate its utility by evaluating its performance and precision on over 2000 Kaggle competition notebooks.","created":"2022-11-29","meta":{"link":"http://arxiv.org/abs/2211.16073v1","tag":"data-quality"}}
{"title":"Multi-User Privacy Mechanism Design with Non-zero Leakage","abstract":"A privacy mechanism design problem is studied through the lens of information theory. In this work, an agent observes useful data $Y=(Y_1,...,Y_N)$ that is correlated with private data $X=(X_1,...,X_N)$ which is assumed to be also accessible by the agent. Here, we consider $K$ users where user $i$ demands a sub-vector of $Y$, denoted by $C_{i}$. The agent wishes to disclose $C_{i}$ to user $i$. Since $C_{i}$ is correlated with $X$ it can not be disclosed directly. A privacy mechanism is designed to generate disclosed data $U$ which maximizes a linear combinations of the users utilities while satisfying a bounded privacy constraint in terms of mutual information. In a similar work it has been assumed that $X_i$ is a deterministic function of $Y_i$, however in this work we let $X_i$ and $Y_i$ be arbitrarily correlated. First, an upper bound on the privacy-utility trade-off is obtained by using a specific transformation, Functional Representation Lemma and Strong Functional Representaion Lemma, then we show that the upper bound can be decomposed into $N$ parallel problems. Next, lower bounds on privacy-utility trade-off are derived using Functional Representation Lemma and Strong Functional Representaion Lemma. The upper bound is tight within a constant and the lower bounds assert that the disclosed data is independent of all $\\{X_j\\}_{i=1}^N$ except one which we allocate the maximum allowed leakage to it. Finally, the obtained bounds are studied in special cases.","created":"2022-11-28","meta":{"link":"http://arxiv.org/abs/2211.15525v1","tag":"data-quality"}}
{"title":"An Alphabet of Leakage Measures","abstract":"We introduce a family of information leakage measures called maximal $\\alpha,\\beta$-leakage, parameterized by real numbers $\\alpha$ and $\\beta$. The measure is formalized via an operational definition involving an adversary guessing an unknown function of the data given the released data. We obtain a simple, computable expression for the measure and show that it satisfies several basic properties such as monotonicity in $\\beta$ for a fixed $\\alpha$, non-negativity, data processing inequalities, and additivity over independent releases. Finally, we highlight the relevance of this family by showing that it bridges several known leakage measures, including maximal $\\alpha$-leakage $(\\beta=1)$, maximal leakage $(\\alpha=\\infty,\\beta=1)$, local differential privacy $(\\alpha=\\infty,\\beta=\\infty)$, and local Renyi differential privacy $(\\alpha=\\beta)$.","created":"2022-11-28","meta":{"link":"http://arxiv.org/abs/2211.15453v1","tag":"data-quality"}}
{"title":"Incentive-boosted Federated Crowdsourcing","abstract":"Crowdsourcing is a favorable computing paradigm for processing computer-hard tasks by harnessing human intelligence. However, generic crowdsourcing systems may lead to privacy-leakage through the sharing of worker data. To tackle this problem, we propose a novel approach, called iFedCrowd (incentive-boosted Federated Crowdsourcing), to manage the privacy and quality of crowdsourcing projects. iFedCrowd allows participants to locally process sensitive data and only upload encrypted training models, and then aggregates the model parameters to build a shared server model to protect data privacy. To motivate workers to build a high-quality global model in an efficacy way, we introduce an incentive mechanism that encourages workers to constantly collect fresh data to train accurate client models and boosts the global model training. We model the incentive-based interaction between the crowdsourcing platform and participating workers as a Stackelberg game, in which each side maximizes its own profit. We derive the Nash Equilibrium of the game to find the optimal solutions for the two sides. Experimental results confirm that iFedCrowd can complete secure crowdsourcing projects with high quality and efficiency.","created":"2022-11-28","meta":{"link":"http://arxiv.org/abs/2211.14439v2","tag":"data-quality"}}
{"title":"ILSGAN: Independent Layer Synthesis for Unsupervised Foreground-Background Segmentation","abstract":"Unsupervised foreground-background segmentation aims at extracting salient objects from cluttered backgrounds, where Generative Adversarial Network (GAN) approaches, especially layered GANs, show great promise. However, without human annotations, they are typically prone to produce foreground and background layers with non-negligible semantic and visual confusion, dubbed \"information leakage\", resulting in notable degeneration of the generated segmentation mask. To alleviate this issue, we propose a simple-yet-effective explicit layer independence modeling approach, termed Independent Layer Synthesis GAN (ILSGAN), pursuing independent foreground-background layer generation by encouraging their discrepancy. Specifically, it targets minimizing the mutual information between visible and invisible regions of the foreground and background to spur interlayer independence. Through in-depth theoretical and experimental analyses, we justify that explicit layer independence modeling is critical to suppressing information leakage and contributes to impressive segmentation performance gains. Also, our ILSGAN achieves strong state-of-the-art generation quality and segmentation performance on complex real-world data.","created":"2022-11-25","meta":{"link":"http://arxiv.org/abs/2211.13974v3","tag":"data-quality"}}
{"title":"Microarchitectural Leakage Templates and Their Application to Cache-Based Side Channels","abstract":"The complexity of modern processor architectures has given rise to sophisticated interactions among their components. Such interactions may result in potential attack vectors in terms of side channels, possibly available to user-land exploits to leak secret data. Exploitation and countering of such side channels require a detailed understanding of the target component. However, such detailed information is commonly unpublished for many CPUs.   In this paper, we introduce the concept of Leakage Templates to abstractly describe specific side channels and identify their occurrences in binary applications. We design and implement Plumber, a framework to derive the generic Leakage Templates from individual code sequences that are known to cause leakage (e.g., found by prior work). Plumber uses a combination of instruction fuzzing, instructions' operand mutation and statistical analysis to explore undocumented behavior of microarchitectural optimizations and derive sufficient conditions on vulnerable code inputs that, if hold can trigger a distinguishing behavior. Using Plumber we identified novel leakage primitives based on Leakage Templates (for ARM Cortex-A53 and -A72 cores), in particular related to previction (a new premature cache eviction), and prefetching behavior. We show the utility of Leakage Templates by re-identifying a prefetcher-based vulnerability in OpenSSL 1.1.0g first reported by Shin et al. [40].","created":"2022-11-25","meta":{"link":"http://arxiv.org/abs/2211.13958v1","tag":"data-quality"}}
{"title":"Removal of point source leakage from time-order data filtering","abstract":"Time-ordered data (TOD) from ground-based CMB experiments are generally filtered before map-making to remove or reduce the contamination from the ground and the atmospheric emissions. However, when the observation region contains strong point sources, the filtering process will result in considerable leakage around the point sources in a measured CMB map, and leave spurious polarization signals. Therefore, such signals need to be assessed and removed before CMB science exploitation. In this work, we present a new method that we call \"template fitting\" and can effectively remove these leakage signals in pixel domain, not only satisfying the requirement for measuring primordial gravitational waves from CMB-$B$ modes, but also avoiding time-consuming operations on TOD.","created":"2022-11-25","meta":{"link":"http://arxiv.org/abs/2211.13870v1","tag":"data-quality"}}
{"title":"Privacy in Practice: Private COVID-19 Detection in X-Ray Images","abstract":"Machine learning (ML) can help fight pandemics like COVID-19 by enabling rapid screening of large volumes of images. To perform data analysis while maintaining patient privacy, we create ML models that satisfy Differential Privacy (DP). Previous works exploring private COVID-19 models are in part based on small datasets, provide weaker or unclear privacy guarantees, and do not investigate practical privacy. We suggest improvements to address these open gaps. We account for inherent class imbalances and evaluate the utility-privacy trade-off more extensively and over stricter privacy budgets. Our evaluation is supported by empirically estimating practical privacy through black-box Membership Inference Attacks (MIAs). The introduced DP should help limit leakage threats posed by MIAs, and our practical analysis is the first to test this hypothesis on the COVID-19 classification task. Our results indicate that needed privacy levels might differ based on the task-dependent practical threat from MIAs. The results further suggest that with increasing DP guarantees, empirical privacy leakage only improves marginally, and DP therefore appears to have a limited impact on practical MIA defense. Our findings identify possibilities for better utility-privacy trade-offs, and we believe that empirical attack-specific privacy estimation can play a vital role in tuning for practical privacy.","created":"2022-11-21","meta":{"link":"http://arxiv.org/abs/2211.11434v2","tag":"data-quality"}}
{"title":"Data Leakage and Evaluation Issues in Micro-Expression Analysis","abstract":"Micro-expressions have drawn increasing interest lately due to various potential applications. The task is, however, difficult as it incorporates many challenges from the fields of computer vision, machine learning and emotional sciences. Due to the spontaneous and subtle characteristics of micro-expressions, the available training and testing data are limited, which make evaluation complex. We show that data leakage and fragmented evaluation protocols are issues among the micro-expression literature. We find that fixing data leaks can drastically reduce model performance, in some cases even making the models perform similarly to a random classifier. To this end, we go through common pitfalls, propose a new standardized evaluation protocol using facial action units with over 2000 micro-expression samples, and provide an open source library that implements the evaluation protocols in a standardized manner. Code is publicly available in \\url{https://github.com/tvaranka/meb}.","created":"2022-11-21","meta":{"link":"http://arxiv.org/abs/2211.11425v2","tag":"data-quality"}}
{"title":"A Unified Framework for Quantifying Privacy Risk in Synthetic Data","abstract":"Synthetic data is often presented as a method for sharing sensitive information in a privacy-preserving manner by reproducing the global statistical properties of the original data without disclosing sensitive information about any individual. In practice, as with other anonymization methods, privacy risks cannot be entirely eliminated. The residual privacy risks need instead to be ex-post assessed. We present Anonymeter, a statistical framework to jointly quantify different types of privacy risks in synthetic tabular datasets. We equip this framework with attack-based evaluations for the singling out, linkability, and inference risks, the three key indicators of factual anonymization according to the European General Data Protection Regulation (GDPR). To the best of our knowledge, we are the first to introduce a coherent and legally aligned evaluation of these three privacy risks for synthetic data, and to design privacy attacks which model directly the singling out and linkability risks. We demonstrate the effectiveness of our methods by conducting an extensive set of experiments that measure the privacy risks of data with deliberately inserted privacy leakages, and of synthetic data generated with and without differential privacy. Our results highlight that the three privacy risks reported by our framework scale linearly with the amount of privacy leakage in the data. Furthermore, we observe that synthetic data exhibits the lowest vulnerability against linkability, indicating one-to-one relationships between real and synthetic data records are not preserved. Finally, we demonstrate quantitatively that Anonymeter outperforms existing synthetic data privacy evaluation frameworks both in terms of detecting privacy leaks, as well as computation speed. To contribute to a privacy-conscious usage of synthetic data, we open source Anonymeter at https://github.com/statice/anonymeter.","created":"2022-11-18","meta":{"link":"http://arxiv.org/abs/2211.10459v1","tag":"data-quality"}}
{"title":"Social Networks are Divulging Your Identity behind Crypto Addresses","abstract":"Cryptocurrencies, such as Bitcoin and Ethereum, are becoming increasingly prevalent mainly due to their anonymity, decentralization, transparency, and security. However, the completely public ledger makes the trace and analysis of each account possible as long as the identity behind the public address is revealed. Theoretically, social networks could make that happen when addresses are posted on social network platforms using accounts containing personal information. To verify such a possibility, we have collected public data from two major platforms, i.e. Twitter and Reddit, aiming to find potential privacy leakage behind the ETH public address. In the end, an easy-to-use retrieval application is also built for a better illustration.","created":"2022-11-17","meta":{"link":"http://arxiv.org/abs/2211.09656v1","tag":"data-quality"}}
{"title":"Personal Privacy Protection Problems in the Digital Age","abstract":"With the development of Internet technology, the issue of privacy leakage has attracted more and more attention from the public. In our daily life, mobile phone applications and identity documents that we use may bring the risk of privacy leakage, which had increasingly aroused public concern. The path of privacy protection in the digital age remains to be explored. To explore the source of this risk and how it can be reduced, we conducted this study by using personal experience, collecting data and applying the theory.","created":"2022-11-17","meta":{"link":"http://arxiv.org/abs/2211.09591v2","tag":"data-quality"}}
{"title":"Federated Learning for Healthcare Domain - Pipeline, Applications and Challenges","abstract":"Federated learning is the process of developing machine learning models over datasets distributed across data centers such as hospitals, clinical research labs, and mobile devices while preventing data leakage. This survey examines previous research and studies on federated learning in the healthcare sector across a range of use cases and applications. Our survey shows what challenges, methods, and applications a practitioner should be aware of in the topic of federated learning. This paper aims to lay out existing research and list the possibilities of federated learning for healthcare industries.","created":"2022-11-15","meta":{"link":"http://arxiv.org/abs/2211.07893v2","tag":"data-quality"}}
{"title":"Impact of spiking neurons leakages and network recurrences on event-based spatio-temporal pattern recognition","abstract":"Spiking neural networks coupled with neuromorphic hardware and event-based sensors are getting increased interest for low-latency and low-power inference at the edge. However, multiple spiking neuron models have been proposed in the literature with different levels of biological plausibility and different computational features and complexities. Consequently, there is a need to define the right level of abstraction from biology in order to get the best performance in accurate, efficient and fast inference in neuromorphic hardware. In this context, we explore the impact of synaptic and membrane leakages in spiking neurons. We confront three neural models with different computational complexities using feedforward and recurrent topologies for event-based visual and auditory pattern recognition. Our results show that, in terms of accuracy, leakages are important when there are both temporal information in the data and explicit recurrence in the network. In addition, leakages do not necessarily increase the sparsity of spikes flowing in the network. We also investigate the impact of heterogeneity in the time constant of leakages, and the results show a slight improvement in accuracy when using data with a rich temporal structure. These results advance our understanding of the computational role of the neural leakages and network recurrences, and provide valuable insights for the design of compact and energy-efficient neuromorphic hardware for embedded systems.","created":"2022-11-14","meta":{"link":"http://arxiv.org/abs/2211.07761v1","tag":"data-quality"}}
{"title":"Differentially Private Methods for Compositional Data","abstract":"Protecting individuals' private information while still allowing modelers to draw inferences from confidential data sets is a concern of many data producers. Differential privacy is a framework that enables statistical analyses while controlling the potential leakage of private information. Prior work has focused on proposing differentially private statistical methods for various types of confidential data. However, almost no existing work has focused on the analysis of compositional data. In this article, we investigate differentially private approaches for analyzing compositional data using the Dirichlet distribution as the statistical model. We consider several methods, including frequentist and Bayesian procedures, along with computational strategies. We assess the approaches' performance using simulated data and illustrate their usefulness by applying them to data from the American Time Use Survey.","created":"2022-11-11","meta":{"link":"http://arxiv.org/abs/2211.06337v1","tag":"data-quality"}}
{"title":"Heterogeneous Randomized Response for Differential Privacy in Graph Neural Networks","abstract":"Graph neural networks (GNNs) are susceptible to privacy inference attacks (PIAs), given their ability to learn joint representation from features and edges among nodes in graph data. To prevent privacy leakages in GNNs, we propose a novel heterogeneous randomized response (HeteroRR) mechanism to protect nodes' features and edges against PIAs under differential privacy (DP) guarantees without an undue cost of data and model utility in training GNNs. Our idea is to balance the importance and sensitivity of nodes' features and edges in redistributing the privacy budgets since some features and edges are more sensitive or important to the model utility than others. As a result, we derive significantly better randomization probabilities and tighter error bounds at both levels of nodes' features and edges departing from existing approaches, thus enabling us to maintain high data utility for training GNNs. An extensive theoretical and empirical analysis using benchmark datasets shows that HeteroRR significantly outperforms various baselines in terms of model utility under rigorous privacy protection for both nodes' features and edges. That enables us to defend PIAs in DP-preserving GNNs effectively.","created":"2022-11-10","meta":{"link":"http://arxiv.org/abs/2211.05766v1","tag":"data-quality"}}
{"title":"Privacy-Utility Balanced Voice De-Identification Using Adversarial Examples","abstract":"Faced with the threat of identity leakage during voice data publishing, users are engaged in a privacy-utility dilemma when enjoying convenient voice services. Existing studies employ direct modification or text-based re-synthesis to de-identify users' voices, but resulting in inconsistent audibility in the presence of human participants. In this paper, we propose a voice de-identification system, which uses adversarial examples to balance the privacy and utility of voice services. Instead of typical additive examples inducing perceivable distortions, we design a novel convolutional adversarial example that modulates perturbations into real-world room impulse responses. Benefit from this, our system could preserve user identity from exposure by Automatic Speaker Identification (ASI) while remaining the voice perceptual quality for non-intrusive de-identification. Moreover, our system learns a compact speaker distribution through a conditional variational auto-encoder to sample diverse target embeddings on demand. Combining diverse target generation and input-specific perturbation construction, our system enables any-to-any identify transformation for adaptive de-identification. Experimental results show that our system could achieve 98% and 79% successful de-identification on mainstream ASIs and commercial systems with an objective Mel cepstral distortion of 4.31dB and a subjective mean opinion score of 4.48.","created":"2022-11-10","meta":{"link":"http://arxiv.org/abs/2211.05446v1","tag":"data-quality"}}
{"title":"On the Privacy Risks of Algorithmic Recourse","abstract":"As predictive models are increasingly being employed to make consequential decisions, there is a growing emphasis on developing techniques that can provide algorithmic recourse to affected individuals. While such recourses can be immensely beneficial to affected individuals, potential adversaries could also exploit these recourses to compromise privacy. In this work, we make the first attempt at investigating if and how an adversary can leverage recourses to infer private information about the underlying model's training data. To this end, we propose a series of novel membership inference attacks which leverage algorithmic recourse. More specifically, we extend the prior literature on membership inference attacks to the recourse setting by leveraging the distances between data instances and their corresponding counterfactuals output by state-of-the-art recourse methods. Extensive experimentation with real world and synthetic datasets demonstrates significant privacy leakage through recourses. Our work establishes unintended privacy leakage as an important risk in the widespread adoption of recourse methods.","created":"2022-11-10","meta":{"link":"http://arxiv.org/abs/2211.05427v1","tag":"data-quality"}}
{"title":"Grid-free Harmonic Retrieval and Model Order Selection using Deep Convolutional Neural Networks","abstract":"Harmonic retrieval techniques are the foundation of radio channel sounding, estimation and modeling. This paper introduces a Deep Learning approach for two-dimensional spectral estimation from frequency and time samples of a radio channel transfer function.   Our work can estimate two-dimensional parameters from a signal containing an unknown number of paths. In contrast to existing deep learning-based methods, the signal parameters are not estimated via classification but instead in a quasi-grid-free manner. This alleviates the bias, spectral leakage, and ghost targets that grid-based approaches inherently produce. The proposed architecture also reliably estimates the number of spectral components in the measurement. Hence, the architecture jointly solves the model order selection problem and the parameter estimation task. Additionally, we propose a multi-channel windowing of the data during preprocessing, increasing the resulting estimator's robustness.   We verify the performance compared to existing harmonic retrieval methods and also show how it can be integrated into an existing maximum likelihood estimator for efficient initialization of a gradient-based iteration.","created":"2022-11-09","meta":{"link":"http://arxiv.org/abs/2211.04846v2","tag":"data-quality"}}
{"title":"Overcoming leakage in scalable quantum error correction","abstract":"Leakage of quantum information out of computational states into higher energy states represents a major challenge in the pursuit of quantum error correction (QEC). In a QEC circuit, leakage builds over time and spreads through multi-qubit interactions. This leads to correlated errors that degrade the exponential suppression of logical error with scale, challenging the feasibility of QEC as a path towards fault-tolerant quantum computation. Here, we demonstrate the execution of a distance-3 surface code and distance-21 bit-flip code on a Sycamore quantum processor where leakage is removed from all qubits in each cycle. This shortens the lifetime of leakage and curtails its ability to spread and induce correlated errors. We report a ten-fold reduction in steady-state leakage population on the data qubits encoding the logical state and an average leakage population of less than $1 \\times 10^{-3}$ throughout the entire device. The leakage removal process itself efficiently returns leakage population back to the computational basis, and adding it to a code circuit prevents leakage from inducing correlated error across cycles, restoring a fundamental assumption of QEC. With this demonstration that leakage can be contained, we resolve a key challenge for practical QEC at scale.","created":"2022-11-09","meta":{"link":"http://arxiv.org/abs/2211.04728v1","tag":"data-quality"}}
{"title":"Efficacy of MRI data harmonization in the age of machine learning. A multicenter study across 36 datasets","abstract":"Pooling publicly-available MRI data from multiple sites allows to assemble extensive groups of subjects, increase statistical power, and promote data reuse with machine learning techniques. The harmonization of multicenter data is necessary to reduce the confounding effect associated with non-biological sources of variability in the data. However, when applied to the entire dataset before machine learning, the harmonization leads to data leakage, because information outside the training set may affect model building, and potentially falsely overestimate performance. We propose a 1) measurement of the efficacy of data harmonization; 2) harmonizer transformer, i.e., an implementation of the ComBat harmonization allowing its encapsulation among the preprocessing steps of a machine learning pipeline, avoiding data leakage. We tested these tools using brain T1-weighted MRI data from 1740 healthy subjects acquired at 36 sites. After harmonization, the site effect was removed or reduced, and we measured the data leakage effect in predicting individual age from MRI data, highlighting that introducing the harmonizer transformer into a machine learning pipeline allows for avoiding data leakage.","created":"2022-11-08","meta":{"link":"http://arxiv.org/abs/2211.04125v1","tag":"data-quality"}}
{"title":"Towards learning to explain with concept bottleneck models: mitigating information leakage","abstract":"Concept bottleneck models perform classification by first predicting which of a list of human provided concepts are true about a datapoint. Then a downstream model uses these predicted concept labels to predict the target label. The predicted concepts act as a rationale for the target prediction. Model trust issues emerge in this paradigm when soft concept labels are used: it has previously been observed that extra information about the data distribution leaks into the concept predictions. In this work we show how Monte-Carlo Dropout can be used to attain soft concept predictions that do not contain leaked information.","created":"2022-11-07","meta":{"link":"http://arxiv.org/abs/2211.03656v1","tag":"data-quality"}}
{"title":"Decentralized Complete Dictionary Learning via $\\ell^{4}$-Norm Maximization","abstract":"With the rapid development of information technologies, centralized data processing is subject to many limitations, such as computational overheads, communication delays, and data privacy leakage. Decentralized data processing over networked terminal nodes becomes an important technology in the era of big data. Dictionary learning is a powerful representation learning method to exploit the low-dimensional structure from the high-dimensional data. By exploiting the low-dimensional structure, the storage and the processing overhead of data can be effectively reduced. In this paper, we propose a novel decentralized complete dictionary learning algorithm, which is based on $\\ell^{4}$-norm maximization. Compared with existing decentralized dictionary learning algorithms, comprehensive numerical experiments show that the novel algorithm has significant advantages in terms of per-iteration computational complexity, communication cost, and convergence rate in many scenarios. Moreover, a rigorous theoretical analysis shows that the dictionaries learned by the proposed algorithm can converge to the one learned by a centralized dictionary learning algorithm at a linear rate with high probability under certain conditions.","created":"2022-11-07","meta":{"link":"http://arxiv.org/abs/2211.03628v2","tag":"data-quality"}}
{"title":"Haven't I Seen You Before? Assessing Identity Leakage in Synthetic Irises","abstract":"Generative Adversarial Networks (GANs) have proven to be a preferred method of synthesizing fake images of objects, such as faces, animals, and automobiles. It is not surprising these models can also generate ISO-compliant, yet synthetic iris images, which can be used to augment training data for iris matchers and liveness detectors. In this work, we trained one of the most recent GAN models (StyleGAN3) to generate fake iris images with two primary goals: (i) to understand the GAN's ability to produce \"never-before-seen\" irises, and (ii) to investigate the phenomenon of identity leakage as a function of the GAN's training time. Previous work has shown that personal biometric data can inadvertently flow from training data into synthetic samples, raising a privacy concern for subjects who accidentally appear in the training dataset. This paper presents analysis for three different iris matchers at varying points in the GAN training process to diagnose where and when authentic training samples are in jeopardy of leaking through the generative process. Our results show that while most synthetic samples do not show signs of identity leakage, a handful of generated samples match authentic (training) samples nearly perfectly, with consensus across all matchers. In order to prioritize privacy, security, and trust in the machine learning model development process, the research community must strike a delicate balance between the benefits of using synthetic data and the corresponding threats against privacy from potential identity leakage.","created":"2022-11-03","meta":{"link":"http://arxiv.org/abs/2211.05629v1","tag":"data-quality"}}
{"title":"Privacy Induces Robustness: Information-Computation Gaps and Sparse Mean Estimation","abstract":"We establish a simple connection between robust and differentially-private algorithms: private mechanisms which perform well with very high probability are automatically robust in the sense that they retain accuracy even if a constant fraction of the samples they receive are adversarially corrupted. Since optimal mechanisms typically achieve these high success probabilities, our results imply that optimal private mechanisms for many basic statistics problems are robust.   We investigate the consequences of this observation for both algorithms and computational complexity across different statistical problems. Assuming the Brennan-Bresler secret-leakage planted clique conjecture, we demonstrate a fundamental tradeoff between computational efficiency, privacy leakage, and success probability for sparse mean estimation. Private algorithms which match this tradeoff are not yet known -- we achieve that (up to polylogarithmic factors) in a polynomially-large range of parameters via the Sum-of-Squares method.   To establish an information-computation gap for private sparse mean estimation, we also design new (exponential-time) mechanisms using fewer samples than efficient algorithms must use. Finally, we give evidence for privacy-induced information-computation gaps for several other statistics and learning problems, including PAC learning parity functions and estimation of the mean of a multivariate Gaussian.","created":"2022-11-01","meta":{"link":"http://arxiv.org/abs/2211.00724v2","tag":"data-quality"}}
{"title":"Amplifying Membership Exposure via Data Poisoning","abstract":"As in-the-wild data are increasingly involved in the training stage, machine learning applications become more susceptible to data poisoning attacks. Such attacks typically lead to test-time accuracy degradation or controlled misprediction. In this paper, we investigate the third type of exploitation of data poisoning - increasing the risks of privacy leakage of benign training samples. To this end, we demonstrate a set of data poisoning attacks to amplify the membership exposure of the targeted class. We first propose a generic dirty-label attack for supervised classification algorithms. We then propose an optimization-based clean-label attack in the transfer learning scenario, whereby the poisoning samples are correctly labeled and look \"natural\" to evade human moderation. We extensively evaluate our attacks on computer vision benchmarks. Our results show that the proposed attacks can substantially increase the membership inference precision with minimum overall test-time model performance degradation. To mitigate the potential negative impacts of our attacks, we also investigate feasible countermeasures.","created":"2022-11-01","meta":{"link":"http://arxiv.org/abs/2211.00463v1","tag":"data-quality"}}
{"title":"LinkFormer: Automatic Contextualised Link Recovery of Software Artifacts in both Project-based and Transfer Learning Settings","abstract":"Software artifacts often interact with each other throughout the software development cycle. Associating related artifacts is a common practice for effective documentation and maintenance of software projects. Conventionally, to register the link between an issue report and its associated commit, developers manually include the issue identifier in the message of the relevant commit. Research has shown that developers tend to forget to connect said artifacts manually, resulting in a loss of links. Hence, several link recovery techniques were proposed to discover and revive such links automatically. However, the literature mainly focuses on improving the prediction accuracy on a randomly-split test set, while neglecting other important aspects of this problem, including the effect of time and generalizability of the predictive models. In this paper, we propose LinkFormer to address this problem from three aspects; 1) Accuracy: To better utilize contextual information for prediction, we employ the Transformer architecture and fine-tune multiple pre-trained models on textual and metadata of issues and commits. 2) Data leakage: To empirically assess the impact of time through the splitting policy, we train and test our proposed model along with several existing approaches on both randomly- and temporally split data. 3) Generalizability: To provide a generic model that can perform well across different projects, we further fine-tune LinkFormer in two transfer learning settings. We empirically show that researchers should preserve the temporal flow of data when training learning-based models to resemble the real-world setting. In addition, LinkFormer significantly outperforms the state-of-the-art by large margins. LinkFormer is also capable of extending the knowledge it learned to unseen projects with little to no historical data.","created":"2022-11-01","meta":{"link":"http://arxiv.org/abs/2211.00381v1","tag":"data-quality"}}
{"title":"Preventing Verbatim Memorization in Language Models Gives a False Sense of Privacy","abstract":"Studying data memorization in neural language models helps us understand the risks (e.g., to privacy or copyright) associated with models regurgitating training data, and aids in the evaluation of potential countermeasures. Many prior works -- and some recently deployed defenses -- focus on \"verbatim memorization\", defined as a model generation that exactly matches a substring from the training set. We argue that verbatim memorization definitions are too restrictive and fail to capture more subtle forms of memorization. Specifically, we design and implement an efficient defense based on Bloom filters that perfectly prevents all verbatim memorization. And yet, we demonstrate that this \"perfect\" filter does not prevent the leakage of training data. Indeed, it is easily circumvented by plausible and minimally modified \"style-transfer\" prompts -- and in some cases even the non-modified original prompts -- to extract memorized information. For example, instructing the model to output ALL-CAPITAL texts bypasses memorization checks based on verbatim matching. We conclude by discussing potential alternative definitions and why defining memorization is a difficult yet crucial open question for neural language models.","created":"2022-10-31","meta":{"link":"http://arxiv.org/abs/2210.17546v1","tag":"data-quality"}}
{"title":"BEPHAP: A Blockchain-Based Efficient Privacy-Preserving Handover Authentication Protocol with Key Agreement for Internet of Vehicles","abstract":"The Internet of Vehicles (IoV) can significantly improve transportation efficiency and ensure traffic safety. Authentication is regarded as the fundamental defense line against attacks in IoV. However, the state-of-the-art approaches suffer from several drawbacks, including bottlenecks of the single cloud server model, high computational overhead of operations, excessive trust in cloud servers and roadside units (RSUs), and leakage of vehicle trajectory privacy. In this paper, BEPHAP, a Blockchain-based Efficient Privacy-preserving Handover Authentication Protocol with key agreement for internet of vehicles, is introduced to address these problems. BEPHAP achieves anonymous cross-domain mutual handover authentication with key agreement based on the tamper-proof blockchain, symmetric cryptography, and the chameleon hash function under a security model that cloud servers and RSUs may launch attacks. BEPHAP is particularly well suited for IoV since it allows vehicles only need to perform lightweight cryptographic operations during the authentication phase. BEPHAP also achieves data confidentiality, unlinkability, traceability, non-repudiation, non-frameability, and key escrow freeness. Formal verification based on ProVerif and formal security proofs based on the BAN logic indicates that BEPHAP is resistant to various typical attacks, such as man-in-the-middle attacks, impersonation attacks, and replay attacks. Performance analysis demonstrates that BEPHAP surpasses existing works in both computation and communication efficiencies. And the message loss rate remains 0 at 5000 requests per second, which meets the requirement of IoV.","created":"2022-10-29","meta":{"link":"http://arxiv.org/abs/2210.16595v1","tag":"data-quality"}}
{"title":"LAKEE: A Lightweight Authenticated Key Exchange Protocol for Power Constrained Devices","abstract":"The rapid development of IoT networks has led to a research trend in designing effective security features for them. Due to the power-constrained nature of IoT devices, the security features should remain as lightweight as possible. Currently, most of the IoT network traffic is unencrypted. The leakage of smart devices' unencrypted data can come with the significant cost of a privacy breach. To have a secure channel with encrypted traffic, two endpoints in a network have to authenticate each other and calculate a short-term key. They can then communicate through an authenticated and secure channel. This process is referred to as authenticated key exchange (AKE). Although Datagram Transport Layer Security (DTLS) offers an AKE protocol for IoT networks, research has proposed more efficient and case-specific alternatives. This paper presents LAKEE, a straightforward, lightweight AKE protocol for IoT networks. Our protocol employs elliptic curve cryptography for generating a short-term session key. It reduces the communication and computational overhead of its alternatives while maintaining or improving their security strength. The simplicity and low overhead of our protocol make it a fit for a network of constrained devices.","created":"2022-10-28","meta":{"link":"http://arxiv.org/abs/2210.16367v1","tag":"data-quality"}}
{"title":"Differentially Private CutMix for Split Learning with Vision Transformer","abstract":"Recently, vision transformer (ViT) has started to outpace the conventional CNN in computer vision tasks. Considering privacy-preserving distributed learning with ViT, federated learning (FL) communicates models, which becomes ill-suited due to ViT' s large model size and computing costs. Split learning (SL) detours this by communicating smashed data at a cut-layer, yet suffers from data privacy leakage and large communication costs caused by high similarity between ViT' s smashed data and input data. Motivated by this problem, we propose DP-CutMixSL, a differentially private (DP) SL framework by developing DP patch-level randomized CutMix (DP-CutMix), a novel privacy-preserving inter-client interpolation scheme that replaces randomly selected patches in smashed data. By experiment, we show that DP-CutMixSL not only boosts privacy guarantees and communication efficiency, but also achieves higher accuracy than its Vanilla SL counterpart. Theoretically, we analyze that DP-CutMix amplifies R\\'enyi DP (RDP), which is upper-bounded by its Vanilla Mixup counterpart.","created":"2022-10-28","meta":{"link":"http://arxiv.org/abs/2210.15986v1","tag":"data-quality"}}
{"title":"Dynamic Event-Triggered Discrete-Time Linear Time-Varying System with Privacy-Preservation","abstract":"This paper focuses on discrete-time wireless sensor networks with privacy-preservation. In practical applications, information exchange between sensors is subject to attacks. For the information leakage caused by the attack during the information transmission process, privacy-preservation is introduced for system states. To make communication resources more effectively utilized, a dynamic event-triggered set-membership estimator is designed. Moreover, the privacy of the system is analyzed to ensure the security of the real data. As a result, the set-membership estimator with differential privacy is analyzed using recursive convex optimization. Then the steady-state performance of the system is studied. Finally, one example is presented to demonstrate the feasibility of the proposed distributed filter containing privacy-preserving analysis.","created":"2022-10-28","meta":{"link":"http://arxiv.org/abs/2210.15875v1","tag":"data-quality"}}
{"title":"Partially Oblivious Neural Network Inference","abstract":"Oblivious inference is the task of outsourcing a ML model, like neural-networks, without disclosing critical and sensitive information, like the model's parameters. One of the most prominent solutions for secure oblivious inference is based on a powerful cryptographic tools, like Homomorphic Encryption (HE) and/or multi-party computation (MPC). Even though the implementation of oblivious inference systems schemes has impressively improved the last decade, there are still significant limitations on the ML models that they can practically implement. Especially when both the ML model and the input data's confidentiality must be protected. In this paper, we introduce the notion of partially oblivious inference. We empirically show that for neural network models, like CNNs, some information leakage can be acceptable. We therefore propose a novel trade-off between security and efficiency. In our research, we investigate the impact on security and inference runtime performance from the CNN model's weights partial leakage. We experimentally demonstrate that in a CIFAR-10 network we can leak up to $80\\%$ of the model's weights with practically no security impact, while the necessary HE-mutliplications are performed four times faster.","created":"2022-10-27","meta":{"link":"http://arxiv.org/abs/2210.15189v1","tag":"data-quality"}}
{"title":"Short Paper: Static and Microarchitectural ML-Based Approaches For Detecting Spectre Vulnerabilities and Attacks","abstract":"Spectre intrusions exploit speculative execution design vulnerabilities in modern processors. The attacks violate the principles of isolation in programs to gain unauthorized private user information. Current state-of-the-art detection techniques utilize micro-architectural features or vulnerable speculative code to detect these threats. However, these techniques are insufficient as Spectre attacks have proven to be more stealthy with recently discovered variants that bypass current mitigation mechanisms. Side-channels generate distinct patterns in processor cache, and sensitive information leakage is dependent on source code vulnerable to Spectre attacks, where an adversary uses these vulnerabilities, such as branch prediction, which causes a data breach. Previous studies predominantly approach the detection of Spectre attacks using the microarchitectural analysis, a reactive approach. Hence, in this paper, we present the first comprehensive evaluation of static and microarchitectural analysis-assisted machine learning approaches to detect Spectre vulnerable code snippets (preventive) and Spectre attacks (reactive). We evaluate the performance trade-offs in employing classifiers for detecting Spectre vulnerabilities and attacks.","created":"2022-10-26","meta":{"link":"http://arxiv.org/abs/2210.14452v1","tag":"data-quality"}}
{"title":"Synthetic Text Generation with Differential Privacy: A Simple and Practical Recipe","abstract":"Privacy concerns have attracted increasing attention in data-driven products and services. Existing legislation forbids arbitrary processing of personal data collected from individuals. Generating synthetic versions of such data with a formal privacy guarantee such as differential privacy (DP) is considered to be a solution to address privacy concerns. In this direction, we show a simple, practical, and effective recipe in the text domain: simply fine-tuning a generative language model with DP allows us to generate useful synthetic text while mitigating privacy concerns. Through extensive empirical analyses, we demonstrate that our method produces synthetic data that is competitive in terms of utility with its non-private counterpart and meanwhile provides strong protection against potential privacy leakages.","created":"2022-10-25","meta":{"link":"http://arxiv.org/abs/2210.14348v1","tag":"data-quality"}}
{"title":"Analyzing Privacy Leakage in Machine Learning via Multiple Hypothesis Testing: A Lesson From Fano","abstract":"Differential privacy (DP) is by far the most widely accepted framework for mitigating privacy risks in machine learning. However, exactly how small the privacy parameter $\\epsilon$ needs to be to protect against certain privacy risks in practice is still not well-understood. In this work, we study data reconstruction attacks for discrete data and analyze it under the framework of multiple hypothesis testing. We utilize different variants of the celebrated Fano's inequality to derive upper bounds on the inferential power of a data reconstruction adversary when the model is trained differentially privately. Importantly, we show that if the underlying private data takes values from a set of size $M$, then the target privacy parameter $\\epsilon$ can be $O(\\log M)$ before the adversary gains significant inferential power. Our analysis offers theoretical evidence for the empirical effectiveness of DP against data reconstruction attacks even at relatively large values of $\\epsilon$.","created":"2022-10-24","meta":{"link":"http://arxiv.org/abs/2210.13662v1","tag":"data-quality"}}
{"title":"Cipherfix: Mitigating Ciphertext Side-Channel Attacks in Software","abstract":"Trusted execution environments (TEEs) provide an environment for running workloads in the cloud without having to trust cloud service providers, by offering additional hardware-assisted security guarantees. However, main memory encryption as a key mechanism to protect against system-level attackers trying to read the TEE's content and physical, off-chip attackers, is insufficient. The recent Cipherleaks attacks infer secret data from TEE-protected implementations by analyzing ciphertext patterns exhibited due to deterministic memory encryption. The underlying vulnerability, dubbed the ciphertext side-channel, is neither protected by state-of-the-art countermeasures like constant-time code nor by hardware fixes.   Thus, in this paper, we present a software-based, drop-in solution that can harden existing binaries such that they can be safely executed under TEEs vulnerable to ciphertext side-channels, without requiring recompilation. We combine taint tracking with both static and dynamic binary instrumentation to find sensitive memory locations, and mitigate the leakage by masking secret data before it gets written to memory. This way, although the memory encryption remains deterministic, we destroy any secret-dependent patterns in encrypted memory. We show that our proof-of-concept implementation protects various constant-time implementations against ciphertext side-channels with reasonable overhead.","created":"2022-10-24","meta":{"link":"http://arxiv.org/abs/2210.13124v2","tag":"data-quality"}}
{"title":"Hypothesis Test Procedures for Detecting Leakage Signals in Water Pipeline Channels","abstract":"We design statistical hypothesis tests for performing leak detection in water pipeline channels. By applying an appropriate model for signal propagation, we show that the detection problem becomes one of distinguishing signal from noise, with the noise being described by a multivariate Gaussian distribution with unknown covariance matrix. We first design a test procedure based on the generalized likelihood ratio test, which we show through simulations to offer appreciable leak detection performance gain over conventional approaches designed in an analogous context (for radar detection). Our proposed method requires estimation of the noise covariance matrix, which can become inaccurate under high-dimensional settings, and when the measurement data is scarce. To deal with this, we present a second leak detection method, which employs a regularized covariance matrix estimate. The regularization parameter is optimized for the leak detection application by applying results from large dimensional random matrix theory. This second proposed approach is shown to yield improved performance in leak detection compared with the first approach, at the expense of requiring higher computational complexity.","created":"2022-10-24","meta":{"link":"http://arxiv.org/abs/2210.13032v1","tag":"data-quality"}}
{"title":"Unsupervised Graph Outlier Detection: Problem Revisit, New Insight, and Superior Method","abstract":"A large number of studies on Graph Outlier Detection (GOD) have emerged in recent years due to its wide applications, in which Unsupervised Node Outlier Detection (UNOD) on attributed networks is an important area. UNOD focuses on detecting two kinds of typical outliers in graphs: the structural outlier and the contextual outlier. Most existing works conduct experiments based on datasets with injected outliers. However, we find that the most widely-used outlier injection approach has a serious data leakage issue. By only utilizing such data leakage, a simple approach can achieve state-of-the-art performance in detecting outliers. In addition, we observe that existing algorithms have a performance drop with the mitigated data leakage issue. The other major issue is on balanced detection performance between the two types of outliers, which has not been considered by existing studies. In this paper, we analyze the cause of the data leakage issue in depth since the injection approach is a building block to advance UNOD. Moreover, we devise a novel variance-based model to detect structural outliers, which outperforms existing algorithms significantly and is more robust at kinds of injection settings. On top of this, we propose a new framework, Variance based Graph Outlier Detection (VGOD), which combines our variance-based model and attribute reconstruction model to detect outliers in a balanced way. Finally, we conduct extensive experiments to demonstrate the effectiveness and efficiency of VGOD. The results on 5 real-world datasets validate that VGOD achieves not only the best performance in detecting outliers but also a balanced detection performance between structural and contextual outliers.","created":"2022-10-24","meta":{"link":"http://arxiv.org/abs/2210.12941v3","tag":"data-quality"}}
{"title":"Mixed Precision Quantization to Tackle Gradient Leakage Attacks in Federated Learning","abstract":"Federated Learning (FL) enables collaborative model building among a large number of participants without the need for explicit data sharing. But this approach shows vulnerabilities when privacy inference attacks are applied to it. In particular, in the event of a gradient leakage attack, which has a higher success rate in retrieving sensitive data from the model gradients, FL models are at higher risk due to the presence of communication in their inherent architecture. The most alarming thing about this gradient leakage attack is that it can be performed in such a covert way that it does not hamper the training performance while the attackers backtrack from the gradients to get information about the raw data. Two of the most common approaches proposed as solutions to this issue are homomorphic encryption and adding noise with differential privacy parameters. These two approaches suffer from two major drawbacks. They are: the key generation process becomes tedious with the increasing number of clients, and noise-based differential privacy suffers from a significant drop in global model accuracy. As a countermeasure, we propose a mixed-precision quantized FL scheme, and we empirically show that both of the issues addressed above can be resolved. In addition, our approach can ensure more robustness as different layers of the deep model are quantized with different precision and quantization modes. We empirically proved the validity of our method with three benchmark datasets and found a minimal accuracy drop in the global model after applying quantization.","created":"2022-10-22","meta":{"link":"http://arxiv.org/abs/2210.13457v1","tag":"data-quality"}}
{"title":"Extracted BERT Model Leaks More Information than You Think!","abstract":"The collection and availability of big data, combined with advances in pre-trained models (e.g. BERT), have revolutionized the predictive performance of natural language processing tasks. This allows corporations to provide machine learning as a service (MLaaS) by encapsulating fine-tuned BERT-based models as APIs. Due to significant commercial interest, there has been a surge of attempts to steal re mote services via model extraction. Although previous works have made progress in defending against model extraction attacks, there has been little discussion on their performance in preventing privacy leakage. This work bridges this gap by launching an attribute inference attack against the extracted BERT model. Our extensive experiments reveal that model extraction can cause severe privacy leakage even when victim models are facilitated with advanced defensive strategies.","created":"2022-10-21","meta":{"link":"http://arxiv.org/abs/2210.11735v2","tag":"data-quality"}}
{"title":"Sparse Dynamical Features generation, application to Parkinson's Disease diagnosis","abstract":"In this study we focus on the diagnosis of Parkinson's Disease (PD) based on electroencephalogram (EEG) signals. We propose a new approach inspired by the functioning of the brain that uses the dynamics, frequency and temporal content of EEGs to extract new demarcating features of the disease. The method was evaluated on a publicly available dataset containing EEG signals recorded during a 3-oddball auditory task involving N = 50 subjects, of whom 25 suffer from PD. By extracting two features, and separating them with a straight line using a Linear Discriminant Analysis (LDA) classifier, we can separate the healthy from the unhealthy subjects with an accuracy of 90 % $(p < 0.03)$ using a single channel. By aggregating the information from three channels and making them vote, we obtain an accuracy of 94 %, a sensitivity of 96 % and a specificity of 92 %. The evaluation was carried out using a nested Leave-One-Out cross-validation procedure, thus preventing data leakage problems and giving a less biased evaluation. Several tests were carried out to assess the validity and robustness of our approach, including the test where we use only half the available data for training. Under this constraint, the model achieves an accuracy of 83.8 %.","created":"2022-10-20","meta":{"link":"http://arxiv.org/abs/2210.11624v2","tag":"data-quality"}}
{"title":"Analysing Training-Data Leakage from Gradients through Linear Systems and Gradient Matching","abstract":"Recent works have demonstrated that it is possible to reconstruct training images and their labels from gradients of an image-classification model when its architecture is known. Unfortunately, there is still an incomplete theoretical understanding of the efficacy and failure of these gradient-leakage attacks. In this paper, we propose a novel framework to analyse training-data leakage from gradients that draws insights from both analytic and optimisation-based gradient-leakage attacks. We formulate the reconstruction problem as solving a linear system from each layer iteratively, accompanied by corrections using gradient matching. Under this framework, we claim that the solubility of the reconstruction problem is primarily determined by that of the linear system at each layer. As a result, we are able to partially attribute the leakage of the training data in a deep network to its architecture. We also propose a metric to measure the level of security of a deep learning model against gradient-based attacks on the training data.","created":"2022-10-20","meta":{"link":"http://arxiv.org/abs/2210.13231v1","tag":"data-quality"}}
{"title":"How to solve the mass-discrepancy problem of SESNe -- I. Testing model approximations","abstract":"Here, we present a systematic study of 59 stripped-envelope supernovae (SESNe) (including Type IIb, Ib, Ic, and transitional events) to map a possible reason for the so-called mass-discrepancy problem. In this scenario, we assume the tension between the estimated ejected masses from early- and late-time light curves (LC) is due to approximations generally used in analytical models. First, we examine the assumption that the R-band light curve is indeed a good approximation of the bolometric light curve. Next, we test the generally used assumption that rise-time to maximum brightness is equal to the effective diffusion time-scale that can be used to derive the ejecta mass from the early LC. In addition, we analyze the effect of gamma-ray and positron-leakage, which play an important role in forming the shape of the tails of SESNe, and also can be crucial to gaining the ejecta masses from the late-time LC data. Finally, we consider the effect of the different definitions of velocity that are needed for the ejecta mass calculations.","created":"2022-10-19","meta":{"link":"http://arxiv.org/abs/2210.10458v2","tag":"data-quality"}}
{"title":"Study on the filters of atmospheric contamination in ground based CMB observation","abstract":"The atmosphere is one of the most important contamination sources in the ground-based Cosmic Microwave Background (CMB) observations. In this paper, we study three kinds of filters, which are polynomial filter, high-pass filter, and Wiener filter, to investigate their ability for removing atmospheric noise, as well as their impact on the data analysis process through the end-to-end simulations of CMB experiment. We track their performance by analyzing the response of different components of the data, including both signals and noise. In the time domain, the calculation shows that the high-pass filter has the smallest root mean square error and can achieve high filtering efficiency, followed by the Wiener filter and polynomial filter. We then perform map-making with the filtered time ordered data (TOD) to trace the effects from filters on the map domain, and the results show that the polynomial filter gives high noise residual at low frequency, which gives rise to serious leakage to small scales in map domain during the map-making process, while the high-pass filter and Wiener filter do not have such significant leakage. Then we estimate the angular power spectra of residual noise, as well as those of the input signal for comparing the filter effects in the power spectra domain. Finally, we estimate the standard deviation of the filter corrected power spectra to compare the effects from different filters, and the results show that, at low noise level, the three filters give almost comparable standard deviations on the medium and small scales, but at high noise level, the standard deviation of the polynomial filter is significantly larger. These studies can be used for the reduction of atmospheric noise in future ground-based CMB data processing.","created":"2022-10-18","meta":{"link":"http://arxiv.org/abs/2210.09711v2","tag":"data-quality"}}
{"title":"Confound-leakage: Confound Removal in Machine Learning Leads to Leakage","abstract":"Machine learning (ML) approaches to data analysis are now widely adopted in many fields including epidemiology and medicine. To apply these approaches, confounds must first be removed as is commonly done by featurewise removal of their variance by linear regression before applying ML. Here, we show this common approach to confound removal biases ML models, leading to misleading results. Specifically, this common deconfounding approach can leak information such that what are null or moderate effects become amplified to near-perfect prediction when nonlinear ML approaches are subsequently applied. We identify and evaluate possible mechanisms for such confound-leakage and provide practical guidance to mitigate its negative impact. We demonstrate the real-world importance of confound-leakage by analyzing a clinical dataset where accuracy is overestimated for predicting attention deficit hyperactivity disorder (ADHD) with depression as a confound. Our results have wide-reaching implications for implementation and deployment of ML workflows and beg caution against na\\\"ive use of standard confound removal approaches.","created":"2022-10-17","meta":{"link":"http://arxiv.org/abs/2210.09232v2","tag":"data-quality"}}
{"title":"Federated Learning with Privacy-Preserving Ensemble Attention Distillation","abstract":"Federated Learning (FL) is a machine learning paradigm where many local nodes collaboratively train a central model while keeping the training data decentralized. This is particularly relevant for clinical applications since patient data are usually not allowed to be transferred out of medical facilities, leading to the need for FL. Existing FL methods typically share model parameters or employ co-distillation to address the issue of unbalanced data distribution. However, they also require numerous rounds of synchronized communication and, more importantly, suffer from a privacy leakage risk. We propose a privacy-preserving FL framework leveraging unlabeled public data for one-way offline knowledge distillation in this work. The central model is learned from local knowledge via ensemble attention distillation. Our technique uses decentralized and heterogeneous local data like existing FL approaches, but more importantly, it significantly reduces the risk of privacy leakage. We demonstrate that our method achieves very competitive performance with more robust privacy preservation based on extensive experiments on image classification, segmentation, and reconstruction tasks.","created":"2022-10-16","meta":{"link":"http://arxiv.org/abs/2210.08464v1","tag":"data-quality"}}
{"title":"On the User Behavior Leakage from Recommender System Exposure","abstract":"Modern recommender systems are trained to predict users potential future interactions from users historical behavior data. During the interaction process, despite the data coming from the user side recommender systems also generate exposure data to provide users with personalized recommendation slates. Compared with the sparse user behavior data, the system exposure data is much larger in volume since only very few exposed items would be clicked by the user. Besides, the users historical behavior data is privacy sensitive and is commonly protected with careful access authorization. However, the large volume of recommender exposure data usually receives less attention and could be accessed within a relatively larger scope of various information seekers. In this paper, we investigate the problem of user behavior leakage in recommender systems. We show that the privacy sensitive user past behavior data can be inferred through the modeling of system exposure. Besides, one can infer which items the user have clicked just from the observation of current system exposure for this user. Given the fact that system exposure data could be widely accessed from a relatively larger scope, we believe that the user past behavior privacy has a high risk of leakage in recommender systems. More precisely, we conduct an attack model whose input is the current recommended item slate (i.e., system exposure) for the user while the output is the user's historical behavior. Experimental results on two real-world datasets indicate a great danger of user behavior leakage. To address the risk, we propose a two-stage privacy-protection mechanism which firstly selects a subset of items from the exposure slate and then replaces the selected items with uniform or popularity-based exposure. Experimental evaluation reveals a trade-off effect between the recommendation accuracy and the privacy disclosure risk.","created":"2022-10-16","meta":{"link":"http://arxiv.org/abs/2210.08435v2","tag":"data-quality"}}
{"title":"Sketching for First Order Method: Efficient Algorithm for Low-Bandwidth Channel and Vulnerability","abstract":"Sketching is one of the most fundamental tools in large-scale machine learning. It enables runtime and memory saving via randomly compressing the original large problem onto lower dimensions. In this paper, we propose a novel sketching scheme for the first order method in large-scale distributed learning setting, such that the communication costs between distributed agents are saved while the convergence of the algorithms is still guaranteed. Given gradient information in a high dimension $d$, the agent passes the compressed information processed by a sketching matrix $R\\in \\R^{s\\times d}$ with $s\\ll d$, and the receiver de-compressed via the de-sketching matrix $R^\\top$ to ``recover'' the information in original dimension. Using such a framework, we develop algorithms for federated learning with lower communication costs. However, such random sketching does not protect the privacy of local data directly. We show that the gradient leakage problem still exists after applying the sketching technique by showing a specific gradient attack method. As a remedy, we prove rigorously that the algorithm will be differentially private by adding additional random noises in gradient information, which results in a both communication-efficient and differentially private first order approach for federated learning tasks. Our sketching scheme can be further generalized to other learning settings and might be of independent interest itself.","created":"2022-10-15","meta":{"link":"http://arxiv.org/abs/2210.08371v1","tag":"data-quality"}}
{"title":"BICEP / Keck XVII: Line of Sight Distortion Analysis: Estimates of Gravitational Lensing, Anisotropic Cosmic Birefringence, Patchy Reionization, and Systematic Errors","abstract":"We present estimates of line-of-sight distortion fields derived from the 95 GHz and 150 GHz data taken by BICEP2, BICEP3, and Keck Array up to the 2018 observing season, leading to cosmological constraints and a study of instrumental and astrophysical systematics. Cosmological constraints are derived from three of the distortion fields concerning gravitational lensing from large-scale structure, polarization rotation from magnetic fields or an axion-like field, and the screening effect of patchy reionization. We measure an amplitude of the lensing power spectrum $A_L^{\\phi\\phi}=0.95 \\pm 0.20$. We constrain polarization rotation, expressed as the coupling constant of a Chern-Simons electromagnetic term $g_{a\\gamma} \\leq 2.6 \\times 10^{-2}/H_I$, where $H_I$ is the inflationary Hubble parameter, and an amplitude of primordial magnetic fields smoothed over 1 Mpc $B_{1\\text{Mpc}} \\leq 6.6 \\;\\text{nG}$ at 95 GHz. We constrain the root mean square of optical-depth fluctuations in a simple \"crinkly surface\" model of patchy reionization, finding $A^\\tau<0.19$ ($2\\sigma$) for the coherence scale of $L_c=100$. We show that all of the distortion fields of the 95 GHz and 150 GHz polarization maps are consistent with simulations including lensed-$\\Lambda$CDM, dust, and noise, with no evidence for instrumental systematics. In some cases, the EB and TB quadratic estimators presented here are more sensitive than our previous map-based null tests at identifying and rejecting spurious B-modes that might arise from instrumental effects. Finally, we verify that the standard deprojection filtering in the BICEP/Keck data processing is effective at removing temperature to polarization leakage.","created":"2022-10-14","meta":{"link":"http://arxiv.org/abs/2210.08038v1","tag":"data-quality"}}
{"title":"Will Emerging Millimeter-Wave Cellular Networks Cause Harmful Interference to Weather Satellites?","abstract":"We study whether realistic 5G mm-wave cellular networks would cause harmful out-of-band interference to weather satellites sensing in the 23.8 GHz band. We estimate uplink and downlink interference from a single interferer and a network of interferers in New York City, using real 3D building data and realistic antenna patterns. We perform detailed ray-tracing propagation simulations, for locations of the MetOp-B weather satellite and its scanning orientations and ground interferer antenna orientations for representative urban cell sites. In addition to the ITU-R threshold of -136 dBm/200 MHz, we propose an alternative set of harmful interference thresholds directly related to the sensitivity of the satellite sensor. Our results show that the 3GPP power leakage limits are sufficient to ensure that interference from a single 5G device is not harmful if considering the ITU-R threshold, but not if the weather prediction software can tolerate only very low interference levels. Importantly, aggregate interference resulting in practice from a 5G network with realistic network densities is often harmful, even considering the least conservative ITU-R threshold. Overall, our comprehensive coexistence study thus strongly suggests that additional engineering and/or regulatory solutions will be necessary to protect weather satellite passive sensing from mm-wave cellular network interference.","created":"2022-10-14","meta":{"link":"http://arxiv.org/abs/2210.07994v1","tag":"data-quality"}}
{"title":"A Lightweight Moving Target Defense Framework for Multi-purpose Malware Affecting IoT Devices","abstract":"Malware affecting Internet of Things (IoT) devices is rapidly growing due to the relevance of this paradigm in real-world scenarios. Specialized literature has also detected a trend towards multi-purpose malware able to execute different malicious actions such as remote control, data leakage, encryption, or code hiding, among others. Protecting IoT devices against this kind of malware is challenging due to their well-known vulnerabilities and limitation in terms of CPU, memory, and storage. To improve it, the moving target defense (MTD) paradigm was proposed a decade ago and has shown promising results, but there is a lack of IoT MTD solutions dealing with multi-purpose malware. Thus, this work proposes four MTD mechanisms changing IoT devices' network, data, and runtime environment to mitigate multi-purpose malware. Furthermore, it presents a lightweight and IoT-oriented MTD framework to decide what, when, and how the MTD mechanisms are deployed. Finally, the efficiency and effectiveness of the framework and MTD mechanisms are evaluated in a real-world scenario with one IoT spectrum sensor affected by multi-purpose malware.","created":"2022-10-14","meta":{"link":"http://arxiv.org/abs/2210.07719v1","tag":"data-quality"}}
{"title":"Toward Secure and Private Over-the-Air Federated Learning","abstract":"In this paper, a novel secure and private over-the-air federated learning (SP-OTA-FL) framework is studied where noise is employed to protect data privacy and system security. Specifically, the privacy leakage of user data and the security level of the system are measured by differential privacy (DP) and mean square error security (MSE-security), respectively. To mitigate the impact of noise on learning accuracy, we propose a channel-weighted post-processing (CWPP) mechanism, which assigns a smaller weight to the gradient of the device with poor channel conditions. Furthermore, employing CWPP can avoid the issue that the signal-to-noise ratio (SNR) of the overall system is limited by the device with the worst channel condition in aligned over-the-air federated learning (OTA-FL). We theoretically analyze the effect of noise on privacy and security protection and also illustrate the adverse impact of noise on learning performance by conducting convergence analysis. Based on these analytical results, we propose device scheduling policies considering privacy and security protection in different cases of channel noise. In particular, we formulate an integer nonlinear fractional programming problem aiming to minimize the negative impact of noise on the learning process. We obtain the closed-form solution to the optimization problem when the model is with high dimension. For the general case, we propose a secure and private algorithm (SPA) based on the branch-and-bound (BnB) method, which can obtain an optimal solution with low complexity. The effectiveness of the proposed CWPP mechanism and the policies for device selection are validated through simulations.","created":"2022-10-14","meta":{"link":"http://arxiv.org/abs/2210.07669v1","tag":"data-quality"}}
{"title":"Robustness of cosmic birefringence measurement against Galactic foreground emission and instrumental systematics","abstract":"The polarization of the cosmic microwave background (CMB) can be used to search for parity-violating processes like that predicted by a Chern-Simons coupling to a light pseudoscalar field. Such an interaction rotates $E$ modes into $B$ modes in the observed CMB signal by an effect known as cosmic birefringence. Even though isotropic birefringence can be confused with the rotation produced by a miscalibration of the detectors' polarization angles the degeneracy between both effects is broken when Galactic foreground emission is used as a calibrator. In this work, we use realistic simulations of the High-Frequency Instrument of the Planck mission to test the impact that Galactic foreground emission and instrumental systematics have on the recent birefringence measurements obtained through this technique. Our results demonstrate the robustness of the methodology against the miscalibration of polarization angles and other systematic effects, like intensity-to-polarization leakage, beam leakage, or cross-polarization effects. However, our estimator is sensitive to the $EB$ correlation of polarized foreground emission. Here we propose to correct the bias induced by dust $EB$ by modeling the foreground signal with templates produced in Bayesian component-separation analyses that fit parametric models to CMB data. Acknowledging the limitations of currently available dust templates like that of the Commander sky model, high-precision CMB data and a characterization of dust beyond the modified blackbody paradigm are needed to obtain a definitive measurement of cosmic birefringence in the future.","created":"2022-10-14","meta":{"link":"http://arxiv.org/abs/2210.07655v2","tag":"data-quality"}}
{"title":"Federated Learning for Tabular Data: Exploring Potential Risk to Privacy","abstract":"Federated Learning (FL) has emerged as a potentially powerful privacy-preserving machine learning methodology, since it avoids exchanging data between participants, but instead exchanges model parameters. FL has traditionally been applied to image, voice and similar data, but recently it has started to draw attention from domains including financial services where the data is predominantly tabular. However, the work on tabular data has not yet considered potential attacks, in particular attacks using Generative Adversarial Networks (GANs), which have been successfully applied to FL for non-tabular data. This paper is the first to explore leakage of private data in Federated Learning systems that process tabular data. We design a Generative Adversarial Networks (GANs)-based attack model which can be deployed on a malicious client to reconstruct data and its properties from other participants. As a side-effect of considering tabular data, we are able to statistically assess the efficacy of the attack (without relying on human observation such as done for FL for images). We implement our attack model in a recently developed generic FL software framework for tabular data processing. The experimental results demonstrate the effectiveness of the proposed attack model, thus suggesting that further research is required to counter GAN-based privacy attacks.","created":"2022-10-13","meta":{"link":"http://arxiv.org/abs/2210.06856v1","tag":"data-quality"}}
{"title":"An Experimental Study on Private Aggregation of Teacher Ensemble Learning for End-to-End Speech Recognition","abstract":"Differential privacy (DP) is one data protection avenue to safeguard user information used for training deep models by imposing noisy distortion on privacy data. Such a noise perturbation often results in a severe performance degradation in automatic speech recognition (ASR) in order to meet a privacy budget $\\varepsilon$. Private aggregation of teacher ensemble (PATE) utilizes ensemble probabilities to improve ASR accuracy when dealing with the noise effects controlled by small values of $\\varepsilon$. We extend PATE learning to work with dynamic patterns, namely speech utterances, and perform a first experimental demonstration that it prevents acoustic data leakage in ASR training. We evaluate three end-to-end deep models, including LAS, hybrid CTC/attention, and RNN transducer, on the open-source LibriSpeech and TIMIT corpora. PATE learning-enhanced ASR models outperform the benchmark DP-SGD mechanisms, especially under strict DP budgets, giving relative word error rate reductions between 26.2% and 27.5% for an RNN transducer model evaluated with LibriSpeech. We also introduce a DP-preserving ASR solution for pretraining on public speech corpora.","created":"2022-10-11","meta":{"link":"http://arxiv.org/abs/2210.05614v2","tag":"data-quality"}}
{"title":"Estimation of Doubly-Dispersive Channels in Linearly Precoded Multicarrier Systems Using Smoothness Regularization","abstract":"In this paper, we propose a novel channel estimation scheme for pulse-shaped multicarrier systems using smoothness regularization for ultra-reliable low-latency communication (URLLC). It can be applied to any multicarrier system with or without linear precoding to estimate challenging doubly-dispersive channels. A recently proposed modulation scheme using orthogonal precoding is orthogonal time-frequency and space modulation (OTFS). In OTFS, pilot and data symbols are placed in delay-Doppler (DD) domain and are jointly precoded to the time-frequency (TF) domain. On the one hand, such orthogonal precoding increases the achievable channel estimation accuracy and enables high TF diversity at the receiver. On the other hand, it introduces leakage effects which requires extensive leakage suppression when the piloting is jointly precoded with the data. To avoid this, we propose to precode the data symbols only, place pilot symbols without precoding into the TF domain, and estimate the channel coefficients by interpolating smooth functions from the pilot samples. Furthermore, we present a piloting scheme enabling a smooth control of the number and position of the pilot symbols. Our numerical results suggest that the proposed scheme provides accurate channel estimation with reduced signaling overhead compared to standard estimators using Wiener filtering in the discrete DD domain.","created":"2022-10-11","meta":{"link":"http://arxiv.org/abs/2210.05233v1","tag":"data-quality"}}
{"title":"FedBA: Non-IID Federated Learning Framework in UAV Networks","abstract":"With the development and progress of science and technology, the Internet of Things(IoT) has gradually entered people's lives, bringing great convenience to our lives and improving people's work efficiency. Specifically, the IoT can replace humans in jobs that they cannot perform. As a new type of IoT vehicle, the current status and trend of research on Unmanned Aerial Vehicle(UAV) is gratifying, and the development prospect is very promising. However, privacy and communication are still very serious issues in drone applications. This is because most drones still use centralized cloud-based data processing, which may lead to leakage of data collected by drones. At the same time, the large amount of data collected by drones may incur greater communication overhead when transferred to the cloud. Federated learning as a means of privacy protection can effectively solve the above two problems. However, federated learning when applied to UAV networks also needs to consider the heterogeneity of data, which is caused by regional differences in UAV regulation. In response, this paper proposes a new algorithm FedBA to optimize the global model and solves the data heterogeneity problem. In addition, we apply the algorithm to some real datasets, and the experimental results show that the algorithm outperforms other algorithms and improves the accuracy of the local model for UAVs.","created":"2022-10-10","meta":{"link":"http://arxiv.org/abs/2210.04699v2","tag":"data-quality"}}
{"title":"From Counter-intuitive Observations to a Fresh Look at Recommender System","abstract":"Recently, a few papers report counter-intuitive observations made from experiments on recommender system (RecSys). One observation is that users who spend more time and users who have many interactions with a recommendation system receive poorer recommendations. Another observation is that models trained by using only the more recent parts of a dataset show significant performance improvement. In this opinion paper, we interpret these counter-intuitive observations from two perspectives. First, the observations are made with respect to the global timeline of user-item interactions. Second, the observations are considered counter-intuitive because they contradict our expectation on a recommender: the more interactions a user has, the higher chance that the recommender better learns the user preference. For the first perspective, we discuss the importance of the global timeline by using the simplest baseline Popularity as a starting point. We answer two questions: (i) why the simplest model popularity is often ill-defined in academic research? and (ii) why the popularity baseline is evaluated in this way? The questions lead to a detailed discussion on the data leakage issue in many offline evaluations. As the result, model accuracies reported in many academic papers are less meaningful and incomparable. For the second perspective, we try to answer two more questions: (i) why models trained by using only the more recent parts of data demonstrate better performance? and (ii) why more interactions from users lead to poorer recommendations? The key to both questions is user preference modeling. We then propose to have a fresh look at RecSys. We discuss how to conduct more practical offline evaluations and possible ways to effectively model user preferences. The discussion and opinions in this paper are on top-N recommendation only, not on rating prediction.","created":"2022-10-09","meta":{"link":"http://arxiv.org/abs/2210.04149v1","tag":"data-quality"}}
{"title":"FedDef: Defense Against Gradient Leakage in Federated Learning-based Network Intrusion Detection Systems","abstract":"Deep learning (DL) methods have been widely applied to anomaly-based network intrusion detection system (NIDS) to detect malicious traffic. To expand the usage scenarios of DL-based methods, the federated learning (FL) framework allows multiple users to train a global model on the basis of respecting individual data privacy. However, it has not yet been systematically evaluated how robust FL-based NIDSs are against existing privacy attacks under existing defenses. To address this issue, we propose two privacy evaluation metrics designed for FL-based NIDSs, including (1) privacy score that evaluates the similarity between the original and recovered traffic features using reconstruction attacks, and (2) evasion rate against NIDSs using Generative Adversarial Network-based adversarial attack with the reconstructed benign traffic. We conduct experiments to show that existing defenses provide little protection that the corresponding adversarial traffic can even evade the SOTA NIDS Kitsune. To defend against such attacks and build a more robust FL-based NIDS, we further propose FedDef, a novel optimization-based input perturbation defense strategy with theoretical guarantee. It achieves both high utility by minimizing the gradient distance and strong privacy protection by maximizing the input distance. We experimentally evaluate four existing defenses on four datasets and show that our defense outperforms all the baselines in terms of privacy protection with up to 7 times higher privacy score, while maintaining model accuracy loss within 3% under optimal parameter combination.","created":"2022-10-08","meta":{"link":"http://arxiv.org/abs/2210.04052v2","tag":"data-quality"}}
{"title":"Multi-mode Jaynes-Cummings model results for the collapse and the revival of the quantum Rabi oscillations in a lossy resonant cavity","abstract":"We have numerically obtained theoretical results for the collapse and the revival of the quantum Rabi oscillations for low average number of coherent photons injected on a two-level system in a lossy resonant cavity. We have adopted the multimode Jaynes-Cummings model for the same and especially treated the ``Ohmic\" loss to the walls of the cavity, the leakage from the cavity, and the loss due to the spontaneous emission through the open surface of the cavity. We have compared our results with the experimental data obtained by Brune et al [Phys. Rev. Lett. 76, 1800 (1996)] in this regard.","created":"2022-10-08","meta":{"link":"http://arxiv.org/abs/2210.04039v1","tag":"data-quality"}}
{"title":"Impact of instrument and data characteristics in the interferometric reconstruction of the 21 cm power spectrum","abstract":"Combining the visibilities measured by an interferometer to form a cosmological power spectrum is a complicated process. In a delay-based analysis, the mapping between instrumental and cosmological space is not a one-to-one relation. Instead, neighbouring modes contribute to the power measured at one point, with their respective contributions encoded in the window functions. To better understand the power measured by an interferometer, we assess the impact of instrument characteristics and analysis choices on these window functions. Focusing on the Hydrogen Epoch of Reionization Array (HERA) as a case study, we find that long-baseline observations correspond to enhanced low-k tails of the window functions, which facilitate foreground leakage, whilst an informed choice of bandwidth and frequency taper can reduce said tails. With simple test cases and realistic simulations, we show that, apart from tracing mode mixing, the window functions help accurately reconstruct the power spectrum estimator of simulated visibilities. The window functions depend strongly on the beam chromaticity, and less on its spatial structure - a Gaussian approximation, ignoring side lobes, is sufficient. Finally, we investigate the potential of asymmetric window functions, down-weighting the contribution of low-k power to avoid foreground leakage. The window functions presented here correspond to the latest HERA upper limits for the full Phase I data. They allow an accurate reconstruction of the power spectrum measured by the instrument and will be used in future analyses to confront theoretical models and data directly in cylindrical space.","created":"2022-10-07","meta":{"link":"http://arxiv.org/abs/2210.03721v3","tag":"data-quality"}}
{"title":"De-risking geological carbon storage from high resolution time-lapse seismic to explainable leakage detection","abstract":"Geological carbon storage represents one of the few truly scalable technologies capable of reducing the CO2 concentration in the atmosphere. While this technology has the potential to scale, its success hinges on our ability to mitigate its risks. An important aspect of risk mitigation concerns assurances that the injected CO2 remains within the storage complex. Amongst the different monitoring modalities, seismic imaging stands out with its ability to attain high resolution and high fidelity images. However, these superior features come, unfortunately, at prohibitive costs and time-intensive efforts potentially rendering extensive seismic monitoring undesirable. To overcome this shortcoming, we present a methodology where time-lapse images are created by inverting non-replicated time-lapse monitoring data jointly. By no longer insisting on replication of the surveys to obtain high fidelity time-lapse images and differences, extreme costs and time-consuming labor are averted. To demonstrate our approach, hundreds of noisy time-lapse seismic datasets are simulated that contain imprints of regular CO2 plumes and irregular plumes that leak. These time-lapse datasets are subsequently inverted to produce time-lapse difference images used to train a deep neural classifier. The testing results show that the classifier is capable of detecting CO2 leakage automatically on unseen data and with a reasonable accuracy.","created":"2022-10-07","meta":{"link":"http://arxiv.org/abs/2211.03527v1","tag":"data-quality"}}
{"title":"PAC Security: Automatic Privacy Measurement and Control of Data Processing","abstract":"We propose and study a new privacy definition, termed Probably Approximately Correct (PAC) Security. PAC security characterizes the information-theoretic hardness to recover sensitive data given arbitrary information disclosure/leakage during/after any processing. Unlike the classic cryptographic definition and Differential Privacy (DP), which consider the adversarial (input-independent) worst case, PAC security is a simulatable metric that quantifies the instance-based impossibility of inference. A fully automatic analysis and proof generation framework is proposed: security parameters can be produced with arbitrarily high confidence via Monte-Carlo simulation for any black-box data processing oracle. This appealing automation property enables analysis of complicated data processing, where the worst-case proof in the classic privacy regime could be loose or even intractable. Moreover, we show that the produced PAC security guarantees enjoy simple composition bounds and the automatic analysis framework can be implemented in an online fashion to analyze the composite PAC security loss even under correlated randomness. On the utility side, the magnitude of (necessary) perturbation required in PAC security is not lower bounded by $\\Theta(\\sqrt{d})$ for a $d$-dimensional release but could be O(1) for many practical data processing tasks, which is in contrast to the input-independent worst-case information-theoretic lower bound. Example applications of PAC security are included with comparisons to existing works.","created":"2022-10-07","meta":{"link":"http://arxiv.org/abs/2210.03458v2","tag":"data-quality"}}
{"title":"CANIFE: Crafting Canaries for Empirical Privacy Measurement in Federated Learning","abstract":"Federated Learning (FL) is a setting for training machine learning models in distributed environments where the clients do not share their raw data but instead send model updates to a server. However, model updates can be subject to attacks and leak private information. Differential Privacy (DP) is a leading mitigation strategy which involves adding noise to clipped model updates, trading off performance for strong theoretical privacy guarantees. Previous work has shown that the threat model of DP is conservative and that the obtained guarantees may be vacuous or may overestimate information leakage in practice. In this paper, we aim to achieve a tighter measurement of the model exposure by considering a realistic threat model. We propose a novel method, CANIFE, that uses canaries - carefully crafted samples by a strong adversary to evaluate the empirical privacy of a training round. We apply this attack to vision models trained on CIFAR-10 and CelebA and to language models trained on Sent140 and Shakespeare. In particular, in realistic FL scenarios, we demonstrate that the empirical per-round epsilon obtained with CANIFE is 4-5x lower than the theoretical bound.","created":"2022-10-06","meta":{"link":"http://arxiv.org/abs/2210.02912v2","tag":"data-quality"}}
{"title":"Cyber-Resilient Privacy Preservation and Secure Billing Approach for Smart Energy Metering Devices","abstract":"Most of the smart applications, such as smart energy metering devices, demand strong privacy preservation to strengthen data privacy. However, it is difficult to protect the privacy of the smart device data, especially on the client side. It is mainly because payment for billing is computed by the server deployed at the client's side, and it is highly challenging to prevent the leakage of client's information to unauthorised users. Various researchers have discussed this problem and have proposed different privacy preservation techniques. Conventional techniques suffer from the problem of high computational and communication overload on the client side. In addition, the performance of these techniques deteriorates due to computational complexity and their inability to handle the security of large-scale data. Due to these limitations, it becomes easy for the attackers to introduce malicious attacks on the server, posing a significant threat to data security. In this context, this proposal intends to design novel privacy preservation and secure billing framework using deep learning techniques to ensure data security in smart energy metering devices. This research aims to overcome the limitations of the existing techniques to achieve robust privacy preservation in smart devices and increase the cyber resilience of these devices.","created":"2022-10-06","meta":{"link":"http://arxiv.org/abs/2210.02760v1","tag":"data-quality"}}
{"title":"Fine-Tuning with Differential Privacy Necessitates an Additional Hyperparameter Search","abstract":"Models need to be trained with privacy-preserving learning algorithms to prevent leakage of possibly sensitive information contained in their training data. However, canonical algorithms like differentially private stochastic gradient descent (DP-SGD) do not benefit from model scale in the same way as non-private learning. This manifests itself in the form of unappealing tradeoffs between privacy and utility (accuracy) when using DP-SGD on complex tasks. To remediate this tension, a paradigm is emerging: fine-tuning with differential privacy from a model pretrained on public (i.e., non-sensitive) training data.   In this work, we identify an oversight of existing approaches for differentially private fine tuning. They do not tailor the fine-tuning approach to the specifics of learning with privacy. Our main result is to show how carefully selecting the layers being fine-tuned in the pretrained neural network allows us to establish new state-of-the-art tradeoffs between privacy and accuracy. For instance, we achieve 77.9% accuracy for $(\\varepsilon, \\delta)=(2, 10^{-5})$ on CIFAR-100 for a model pretrained on ImageNet. Our work calls for additional hyperparameter search to configure the differentially private fine-tuning procedure itself.","created":"2022-10-05","meta":{"link":"http://arxiv.org/abs/2210.02156v1","tag":"data-quality"}}
{"title":"Data Leakage in Tabular Federated Learning","abstract":"While federated learning (FL) promises to preserve privacy in distributed training of deep learning models, recent work in the image and NLP domains showed that training updates leak private data of participating clients. At the same time, most high-stakes applications of FL (e.g., legal and financial) use tabular data. Compared to the NLP and image domains, reconstruction of tabular data poses several unique challenges: (i) categorical features introduce a significantly more difficult mixed discrete-continuous optimization problem, (ii) the mix of categorical and continuous features causes high variance in the final reconstructions, and (iii) structured data makes it difficult for the adversary to judge reconstruction quality. In this work, we tackle these challenges and propose the first comprehensive reconstruction attack on tabular data, called TabLeak. TabLeak is based on three key ingredients: (i) a softmax structural prior, implicitly converting the mixed discrete-continuous optimization problem into an easier fully continuous one, (ii) a way to reduce the variance of our reconstructions through a pooled ensembling scheme exploiting the structure of tabular data, and (iii) an entropy measure which can successfully assess reconstruction quality. Our experimental evaluation demonstrates the effectiveness of TabLeak, reaching a state-of-the-art on four popular tabular datasets. For instance, on the Adult dataset, we improve attack accuracy by 10% compared to the baseline on the practically relevant batch size of 32 and further obtain non-trivial reconstructions for batch sizes as large as 128. Our findings are important as they show that performing FL on tabular data, which often poses high privacy risks, is highly vulnerable.","created":"2022-10-04","meta":{"link":"http://arxiv.org/abs/2210.01785v1","tag":"data-quality"}}
{"title":"Fundamental Investigation of Reactive-Convective Transport: Implications for Long-Term Carbon dioxide (CO2) Sequestration","abstract":"The density-driven convection coupled with chemical reaction is the preferred mechanism for permanently storing CO2 in saline aquifers. This study uses a 2D visual Hele-Shaw cell to evaluate and visualize the density-driven convection formed due to gravitational instabilities, also known as Rayleigh-Taylor instability. The primary goal of the experiments is to understand the various mechanisms for the mass transfer of gaseous CO2 into brine with different initial ionic concentrations and flow permeability. Moreover, the impact of CO2 flow rates, injection locations, reservoir dipping angle, and permeability heterogeneity is also investigated. We observed that the presence of salts resulted in earlier onset of convection and a larger convective finger wavelength than the case with no dissolved salts. In addition, experimental data showed a higher lateral mixing between CO2 fingers when dipping is involved. The visual investigation also revealed that the CO2 dissolution rate, measured by the rate of the convective fingers advance, depends on the type and concentration of the ions present in the brine. The CO2 dissolution for solutions with varying salt dissolved, indicated by the area of the pH-depressed region, is observed to be 0.38-0.77 times compared to when no salt is present. Although convective flow is slowed down in the presence of salts, the diffusive flux is enhanced, as observed from both qualitative and quantitative results. Moreover, the reduced formation permeability, introduced by using a flow barrier, resulted in numerous regions not being swept by the dissolved CO2, indicating an inefficient dissolution. We also investigated the effect of discrete high conductivity fractures within the flow barriers, which showed an uneven vertical sweep and enhanced flow channeling. Lastly, the parameters regarding CO2 leakage risk during storage are identified and discussed.","created":"2022-10-04","meta":{"link":"http://arxiv.org/abs/2210.01756v1","tag":"data-quality"}}
{"title":"OpBoost: A Vertical Federated Tree Boosting Framework Based on Order-Preserving Desensitization","abstract":"Vertical Federated Learning (FL) is a new paradigm that enables users with non-overlapping attributes of the same data samples to jointly train a model without directly sharing the raw data. Nevertheless, recent works show that it's still not sufficient to prevent privacy leakage from the training process or the trained model. This paper focuses on studying the privacy-preserving tree boosting algorithms under the vertical FL. The existing solutions based on cryptography involve heavy computation and communication overhead and are vulnerable to inference attacks. Although the solution based on Local Differential Privacy (LDP) addresses the above problems, it leads to the low accuracy of the trained model.   This paper explores to improve the accuracy of the widely deployed tree boosting algorithms satisfying differential privacy under vertical FL. Specifically, we introduce a framework called OpBoost. Three order-preserving desensitization algorithms satisfying a variant of LDP called distance-based LDP (dLDP) are designed to desensitize the training data. In particular, we optimize the dLDP definition and study efficient sampling distributions to further improve the accuracy and efficiency of the proposed algorithms. The proposed algorithms provide a trade-off between the privacy of pairs with large distance and the utility of desensitized values. Comprehensive evaluations show that OpBoost has a better performance on prediction accuracy of trained models compared with existing LDP approaches on reasonable settings. Our code is open source.","created":"2022-10-04","meta":{"link":"http://arxiv.org/abs/2210.01318v1","tag":"data-quality"}}
{"title":"Distributed Non-Convex Optimization with One-Bit Compressors on Heterogeneous Data: Efficient and Resilient Algorithms","abstract":"Federated Learning (FL) is a nascent decentralized learning framework under which a massive collection of heterogeneous clients collaboratively train a model without revealing their local data. Scarce communication, privacy leakage, and Byzantine attacks are the key bottlenecks of system scalability. In this paper, we focus on communication-efficient distributed (stochastic) gradient descent for non-convex optimization, a driving force of FL. We propose two algorithms, named {\\em Adaptive Stochastic Sign SGD (Ada-StoSign)} and {\\em $\\beta$-Stochastic Sign SGD ($\\beta$-StoSign)}, each of which compresses the local gradients into bit vectors.   To handle unbounded gradients, Ada-StoSign uses a novel norm tracking function that adaptively adjusts a coarse estimation on the $\\ell_{\\infty}$ of the local gradients - a key parameter used in gradient compression. We show that Ada-StoSign converges in expectation with a rate $O(\\log T/\\sqrt{T} + 1/\\sqrt{M})$, where $M$ is the number of clients. To the best of our knowledge, when $M$ is sufficiently large, Ada-StoSign outperforms the state-of-the-art sign-based method whose convergence rate is $O(T^{-1/4})$. Under bounded gradient assumption, $\\beta$-StoSign achieves quantifiable Byzantine resilience and privacy assurances, and works with partial client participation and mini-batch gradients which could be unbounded. We corroborate and complement our theories by experiments on MNIST and CIFAR-10 datasets.","created":"2022-10-03","meta":{"link":"http://arxiv.org/abs/2210.00665v2","tag":"data-quality"}}
{"title":"Heterogeneous Graph Neural Network for Privacy-Preserving Recommendation","abstract":"Social networks are considered to be heterogeneous graph neural networks (HGNNs) with deep learning technological advances. HGNNs, compared to homogeneous data, absorb various aspects of information about individuals in the training stage. That means more information has been covered in the learning result, especially sensitive information. However, the privacy-preserving methods on homogeneous graphs only preserve the same type of node attributes or relationships, which cannot effectively work on heterogeneous graphs due to the complexity. To address this issue, we propose a novel heterogeneous graph neural network privacy-preserving method based on a differential privacy mechanism named HeteDP, which provides a double guarantee on graph features and topology. In particular, we first define a new attack scheme to reveal privacy leakage in the heterogeneous graphs. Specifically, we design a two-stage pipeline framework, which includes the privacy-preserving feature encoder and the heterogeneous link reconstructor with gradients perturbation based on differential privacy to tolerate data diversity and against the attack. To better control the noise and promote model performance, we utilize a bi-level optimization pattern to allocate a suitable privacy budget for the above two modules. Our experiments on four public benchmarks show that the HeteDP method is equipped to resist heterogeneous graph privacy leakage with admirable model generalization.","created":"2022-10-02","meta":{"link":"http://arxiv.org/abs/2210.00538v2","tag":"data-quality"}}
{"title":"Detection and Classification of Glioblastoma Brain Tumor","abstract":"Glioblastoma brain tumors are highly malignant and often require early detection and accurate segmentation for effective treatment. We are proposing two deep learning models in this paper, namely UNet and Deeplabv3, for the detection and segmentation of glioblastoma brain tumors using preprocessed brain MRI images. The performance evaluation is done for these models in terms of accuracy and computational efficiency. Our experimental results demonstrate that both UNet and Deeplabv3 models achieve accurate detection and segmentation of glioblastoma brain tumors. However, Deeplabv3 outperforms UNet in terms of accuracy, albeit at the cost of requiring more computational resources. Our proposed models offer a promising approach for the early detection and segmentation of glioblastoma brain tumors, which can aid in effective treatment strategies. Further research can focus on optimizing the computational efficiency of the Deeplabv3 model while maintaining its high accuracy for real-world clinical applications. Overall, our approach works and contributes to the field of medical image analysis and deep learning-based approaches for brain tumor detection and segmentation. Our suggested models can have a major influence on the prognosis and treatment of people with glioblastoma, a fatal form of brain cancer. It is necessary to conduct more research to examine the practical use of these models in real-life healthcare settings.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09133v1","tag":"medical-cv"}}
{"title":"Frequency Regularization: Restricting Information Redundancy of Convolutional Neural Networks","abstract":"Convolutional neural networks have demonstrated impressive results in many computer vision tasks. However, the increasing size of these networks raises concerns about the information redundancy within the network parameters. In this paper, we proposed the Frequency Regularization to restrict the non-zero elements of the network parameters in frequency domain. The proposed approach operates at the tensor level, and can be applied to almost any kind of network architectures. Specifically, the tensors of parameters are maintained in the frequency domain, where high frequency components can be eliminated by zigzag setting tensor elements to zero. Then, the inverse discrete cosine transform (IDCT) is used to reconstruct the spatial tensors for matrix operations during network training. Since high frequency components of images are known to be non-critical, a large proportion of the parameters can be set to zero when networks are trained with proposed frequency regularization. Comprehensive evaluations on various state-of-the-art network architectures, including LeNet, Alexnet, VGG, Resnet, UNet, GAN, and VAE, demonstrate the effectiveness of the proposed frequency regularization. Under the condition with tiny accuracy decrease (less than 2\\%), a LeNet5 with 0.4M parameters can be represented by 776 float16 numbers(over 1100$\\times$), a UNet with 34M parameters can be represented by 2936 float16 numbers (over 20000$\\times$).","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.07973v1","tag":"medical-cv"}}
{"title":"LitCall: Learning Implicit Topology for CNN-based Aortic Landmark Localization","abstract":"Landmark detection is a critical component of the image processing pipeline for automated aortic size measurements. Given that the thoracic aorta has a relatively conserved topology across the population and that a human annotator with minimal training can estimate the location of unseen landmarks from limited examples, we proposed an auxiliary learning task to learn the implicit topology of aortic landmarks through a CNN-based network. Specifically, we created a network to predict the location of missing landmarks from the visible ones by minimizing the Implicit Topology loss in an end-to-end manner. The proposed learning task can be easily adapted and combined with Unet-style backbones. To validate our method, we utilized a dataset consisting of 207 CTAs, labeling four landmarks on each aorta. Our method outperforms the state-of-the-art Unet-style architectures (ResUnet, UnetR) in terms of localization accuracy, with only a light (#params=0.4M) overhead. We also demonstrate our approach in two clinically meaningful applications: aortic sub-region division and automatic centerline generation.","created":"2023-04-15","meta":{"link":"http://arxiv.org/abs/2304.07607v1","tag":"medical-cv"}}
{"title":"Certified Zeroth-order Black-Box Defense with Robust UNet Denoiser","abstract":"Certified defense methods against adversarial perturbations have been recently investigated in the black-box setting with a zeroth-order (ZO) perspective. However, these methods suffer from high model variance with low performance on high-dimensional datasets due to the ineffective design of the denoiser and are limited in their utilization of ZO techniques. To this end, we propose a certified ZO preprocessing technique for removing adversarial perturbations from the attacked image in the black-box setting using only model queries. We propose a robust UNet denoiser (RDUNet) that ensures the robustness of black-box models trained on high-dimensional datasets. We propose a novel black-box denoised smoothing (DS) defense mechanism, ZO-RUDS, by prepending our RDUNet to the black-box model, ensuring black-box defense. We further propose ZO-AE-RUDS in which RDUNet followed by autoencoder (AE) is prepended to the black-box model. We perform extensive experiments on four classification datasets, CIFAR-10, CIFAR-10, Tiny Imagenet, STL-10, and the MNIST dataset for image reconstruction tasks. Our proposed defense methods ZO-RUDS and ZO-AE-RUDS beat SOTA with a huge margin of $35\\%$ and $9\\%$, for low dimensional (CIFAR-10) and with a margin of $20.61\\%$ and $23.51\\%$ for high-dimensional (STL-10) datasets, respectively.","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06430v1","tag":"medical-cv"}}
{"title":"Scale-Equivariant UNet for Histopathology Image Segmentation","abstract":"Digital histopathology slides are scanned and viewed under different magnifications and stored as images at different resolutions. Convolutional Neural Networks (CNNs) trained on such images at a given scale fail to generalise to those at different scales. This inability is often addressed by augmenting training data with re-scaled images, allowing a model with sufficient capacity to learn the requisite patterns. Alternatively, designing CNN filters to be scale-equivariant frees up model capacity to learn discriminative features. In this paper, we propose the Scale-Equivariant UNet (SEUNet) for image segmentation by building on scale-space theory. The SEUNet contains groups of filters that are linear combinations of Gaussian basis filters, whose scale parameters are trainable but constrained to span disjoint scales through the layers of the network. Extensive experiments on a nuclei segmentation dataset and a tissue type segmentation dataset demonstrate that our method outperforms other approaches, with much fewer trainable parameters.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04595v1","tag":"medical-cv"}}
{"title":"ADS_UNet: A Nested UNet for Histopathology Image Segmentation","abstract":"The UNet model consists of fully convolutional network (FCN) layers arranged as contracting encoder and upsampling decoder maps. Nested arrangements of these encoder and decoder maps give rise to extensions of the UNet model, such as UNete and UNet++. Other refinements include constraining the outputs of the convolutional layers to discriminate between segment labels when trained end to end, a property called deep supervision. This reduces feature diversity in these nested UNet models despite their large parameter space. Furthermore, for texture segmentation, pixel correlations at multiple scales contribute to the classification task; hence, explicit deep supervision of shallower layers is likely to enhance performance. In this paper, we propose ADS UNet, a stage-wise additive training algorithm that incorporates resource-efficient deep supervision in shallower layers and takes performance-weighted combinations of the sub-UNets to create the segmentation model. We provide empirical evidence on three histopathology datasets to support the claim that the proposed ADS UNet reduces correlations between constituent features and improves performance while being more resource efficient. We demonstrate that ADS_UNet outperforms state-of-the-art Transformer-based models by 1.08 and 0.6 points on CRAG and BCSS datasets, and yet requires only 37% of GPU consumption and 34% of training time as that required by Transformers.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04567v1","tag":"medical-cv"}}
{"title":"DDRF: Denoising Diffusion Model for Remote Sensing Image Fusion","abstract":"Denosing diffusion model, as a generative model, has received a lot of attention in the field of image generation recently, thanks to its powerful generation capability. However, diffusion models have not yet received sufficient research in the field of image fusion. In this article, we introduce diffusion model to the image fusion field, treating the image fusion task as image-to-image translation and designing two different conditional injection modulation modules (i.e., style transfer modulation and wavelet modulation) to inject coarse-grained style information and fine-grained high-frequency and low-frequency information into the diffusion UNet, thereby generating fused images. In addition, we also discussed the residual learning and the selection of training objectives of the diffusion model in the image fusion task. Extensive experimental results based on quantitative and qualitative assessments compared with benchmarks demonstrates state-of-the-art results and good generalization performance in image fusion tasks. Finally, it is hoped that our method can inspire other works and gain insight into this field to better apply the diffusion model to image fusion tasks. Code shall be released for better reproducibility.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04774v1","tag":"medical-cv"}}
{"title":"NUMSnet: Nested-U Multi-class Segmentation network for 3D Medical Image Stacks","abstract":"Semantic segmentation for medical 3D image stacks enables accurate volumetric reconstructions, computer-aided diagnostics and follow up treatment planning. In this work, we present a novel variant of the Unet model called the NUMSnet that transmits pixel neighborhood features across scans through nested layers to achieve accurate multi-class semantic segmentations with minimal training data. We analyze the semantic segmentation performance of the NUMSnet model in comparison with several Unet model variants to segment 3-7 regions of interest using only 10% of images for training per Lung-CT and Heart-CT volumetric image stacks. The proposed NUMSnet model achieves up to 20% improvement in segmentation recall with 4-9% improvement in Dice scores for Lung-CT stacks and 2.5-10% improvement in Dice scores for Heart-CT stacks when compared to the Unet++ model. The NUMSnet model needs to be trained by ordered images around the central scan of each volumetric stack. Propagation of image feature information from the 6 nested layers of the Unet++ model are found to have better computation and segmentation performances than propagation of all up-sampling layers in a Unet++ model. The NUMSnet model achieves comparable segmentation performances to existing works, while being trained on as low as 5\\% of the training images. Also, transfer learning allows faster convergence of the NUMSnet model for multi-class semantic segmentation from pathology in Lung-CT images to cardiac segmentations in Heart-CT stacks. Thus, the proposed model can standardize multi-class semantic segmentation on a variety of volumetric image stacks with minimal training dataset. This can significantly reduce the cost, time and inter-observer variabilities associated with computer-aided detections and treatment.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02713v1","tag":"medical-cv"}}
{"title":"Learning Agreement from Multi-source Annotations for Medical Image Segmentation","abstract":"In medical image analysis, it is typical to merge multiple independent annotations as ground truth to mitigate the bias caused by individual annotation preference. However, arbitrating the final annotation is not always effective because new biases might be produced during the process, especially when there are significant variations among annotations. This paper proposes a novel Uncertainty-guided Multi-source Annotation Network (UMA-Net) to learn medical image segmentation directly from multiple annotations. UMA-Net consists of a UNet with two quality-specific predictors, an Annotation Uncertainty Estimation Module (AUEM) and a Quality Assessment Module (QAM). Specifically, AUEM estimates pixel-wise uncertainty maps of each annotation and encourages them to reach an agreement on reliable pixels/voxels. The uncertainty maps then guide the UNet to learn from the reliable pixels/voxels by weighting the segmentation loss. QAM grades the uncertainty maps into high-quality or low-quality groups based on assessment scores. The UNet is further implemented to contain a high-quality learning head (H-head) and a low-quality learning head (L-head). H-head purely learns with high-quality uncertainty maps to avoid error accumulation and keeps strong prediction ability, while L-head leverages the low-quality uncertainty maps to assist the backbone to learn maximum representation knowledge. UNet with H-head will be reserved during the inference stage, and the rest of the modules can be removed freely for computational efficiency. We conduct extensive experiments on an unsupervised 3D segmentation task and a supervised 2D segmentation task, respectively. The results show that our proposed UMA-Net outperforms state-of-the-art approaches, demonstrating its generality and effectiveness.","created":"2023-04-02","meta":{"link":"http://arxiv.org/abs/2304.00466v1","tag":"medical-cv"}}
{"title":"A Closer Look at Parameter-Efficient Tuning in Diffusion Models","abstract":"Large-scale diffusion models like Stable Diffusion are powerful and find various real-world applications while customizing such models by fine-tuning is both memory and time inefficient. Motivated by the recent progress in natural language processing, we investigate parameter-efficient tuning in large diffusion models by inserting small learnable modules (termed adapters). In particular, we decompose the design space of adapters into orthogonal factors -- the input position, the output position as well as the function form, and perform Analysis of Variance (ANOVA), a classical statistical approach for analyzing the correlation between discrete (design options) and continuous variables (evaluation metrics). Our analysis suggests that the input position of adapters is the critical factor influencing the performance of downstream tasks. Then, we carefully study the choice of the input position, and we find that putting the input position after the cross-attention block can lead to the best performance, validated by additional visualization analyses. Finally, we provide a recipe for parameter-efficient tuning in diffusion models, which is comparable if not superior to the fully fine-tuned baseline (e.g., DreamBooth) with only 0.75 \\% extra parameters, across various customized tasks.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.18181v2","tag":"medical-cv"}}
{"title":"Learning with Explicit Shape Priors for Medical Image Segmentation","abstract":"Medical image segmentation is considered as the basic step for medical image analysis and surgical intervention. And many previous works attempted to incorporate shape priors for designing segmentation models, which is beneficial to attain finer masks with anatomical shape information. Here in our work, we detailedly discuss three types of segmentation models with shape priors, which consist of atlas-based models, statistical-based models and UNet-based models. On the ground that the former two kinds of methods show a poor generalization ability, UNet-based models have dominated the field of medical image segmentation in recent years. However, existing UNet-based models tend to employ implicit shape priors, which do not have a good interpretability and generalization ability on different organs with distinctive shapes. Thus, we proposed a novel shape prior module (SPM), which could explicitly introduce shape priors to promote the segmentation performance of UNet-based models. To evaluate the effectiveness of SPM, we conduct experiments on three challenging public datasets. And our proposed model achieves state-of-the-art performance. Furthermore, SPM shows an outstanding generalization ability on different classic convolution-neural-networks (CNNs) and recent Transformer-based backbones, which can serve as a plug-and-play structure for the segmentation task of different datasets.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.17967v1","tag":"medical-cv"}}
{"title":"Whole-body PET image denoising for reduced acquisition time","abstract":"This paper evaluates the performance of supervised and unsupervised deep learning models for denoising positron emission tomography (PET) images in the presence of reduced acquisition times. Our experiments consider 212 studies (56908 images), and evaluate the models using 2D (RMSE, SSIM) and 3D (SUVpeak and SUVmax error for the regions of interest) metrics. It was shown that, in contrast to previous studies, supervised models (ResNet, Unet, SwinIR) outperform unsupervised models (pix2pix GAN and CycleGAN with ResNet backbone and various auxiliary losses) in the reconstruction of 2D PET images. Moreover, a hybrid approach of supervised CycleGAN shows the best results in SUVmax estimation for denoised images, and the SUVmax estimation error for denoised images is comparable with the PET reproducibility error.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.16085v1","tag":"medical-cv"}}
{"title":"D-TrAttUnet: Dual-Decoder Transformer-Based Attention Unet Architecture for Binary and Multi-classes Covid-19 Infection Segmentation","abstract":"In the last three years, the world has been facing a global crisis caused by Covid-19 pandemic. Medical imaging has been playing a crucial role in the fighting against this disease and saving the human lives. Indeed, CT-scans has proved their efficiency in diagnosing, detecting, and following-up the Covid-19 infection. In this paper, we propose a new Transformer-CNN based approach for Covid-19 infection segmentation from the CT slices. The proposed D-TrAttUnet architecture has an Encoder-Decoder structure, where compound Transformer-CNN encoder and Dual-Decoders are proposed. The Transformer-CNN encoder is built using Transformer layers, UpResBlocks, ResBlocks and max-pooling layers. The Dual-Decoder consists of two identical CNN decoders with attention gates. The two decoders are used to segment the infection and the lung regions simultaneously and the losses of the two tasks are joined. The proposed D-TrAttUnet architecture is evaluated for both Binary and Multi-classes Covid-19 infection segmentation. The experimental results prove the efficiency of the proposed approach to deal with the complexity of Covid-19 segmentation task from limited data. Furthermore, D-TrAttUnet architecture outperforms three baseline CNN segmentation architectures (Unet, AttUnet and Unet++) and three state-of-the-art architectures (AnamNet, SCOATNet and CopleNet), in both Binary and Mutli-classes segmentation tasks.","created":"2023-03-27","meta":{"link":"http://arxiv.org/abs/2303.15576v1","tag":"medical-cv"}}
{"title":"Conditional Image-to-Video Generation with Latent Flow Diffusion Models","abstract":"Conditional image-to-video (cI2V) generation aims to synthesize a new plausible video starting from an image (e.g., a person's face) and a condition (e.g., an action class label like smile). The key challenge of the cI2V task lies in the simultaneous generation of realistic spatial appearance and temporal dynamics corresponding to the given image and condition. In this paper, we propose an approach for cI2V using novel latent flow diffusion models (LFDM) that synthesize an optical flow sequence in the latent space based on the given condition to warp the given image. Compared to previous direct-synthesis-based works, our proposed LFDM can better synthesize spatial details and temporal motion by fully utilizing the spatial content of the given image and warping it in the latent space according to the generated temporally-coherent flow. The training of LFDM consists of two separate stages: (1) an unsupervised learning stage to train a latent flow auto-encoder for spatial content generation, including a flow predictor to estimate latent flow between pairs of video frames, and (2) a conditional learning stage to train a 3D-UNet-based diffusion model (DM) for temporal latent flow generation. Unlike previous DMs operating in pixel space or latent feature space that couples spatial and temporal information, the DM in our LFDM only needs to learn a low-dimensional latent flow space for motion generation, thus being more computationally efficient. We conduct comprehensive experiments on multiple datasets, where LFDM consistently outperforms prior arts. Furthermore, we show that LFDM can be easily adapted to new domains by simply finetuning the image decoder. Our code is available at https://github.com/nihaomiao/CVPR23_LFDM.","created":"2023-03-24","meta":{"link":"http://arxiv.org/abs/2303.13744v1","tag":"medical-cv"}}
{"title":"3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers","abstract":"Accurate 3D mitochondria instance segmentation in electron microscopy (EM) is a challenging problem and serves as a prerequisite to empirically analyze their distributions and morphology. Most existing approaches employ 3D convolutions to obtain representative features. However, these convolution-based approaches struggle to effectively capture long-range dependencies in the volume mitochondria data, due to their limited local receptive field. To address this, we propose a hybrid encoder-decoder framework based on a split spatio-temporal attention module that efficiently computes spatial and temporal self-attentions in parallel, which are later fused through a deformable convolution. Further, we introduce a semantic foreground-background adversarial loss during training that aids in delineating the region of mitochondria instances from the background clutter. Our extensive experiments on three benchmarks, Lucchi, MitoEM-R and MitoEM-H, reveal the benefits of the proposed contributions achieving state-of-the-art results on all three datasets. Our code and models are available at https://github.com/OmkarThawakar/STT-UNET.","created":"2023-03-21","meta":{"link":"http://arxiv.org/abs/2303.12073v1","tag":"medical-cv"}}
{"title":"Emulating radiation transport on cosmological scale using a denoising Unet","abstract":"Semi-numerical simulations are the leading candidates for evolving reionization on cosmological scales. These semi-numerical models are efficient in generating large-scale maps of the 21cm signal, but they are too slow to enable inference at the field level. We present different strategies to train a U-Net to accelerate these simulations. We derive the ionization field directly from the initial density field without using the ionizing sources' location, and hence emulating the radiative transfer process. We find that the U-Net achieves higher accuracy in reconstructing the ionization field if the input includes either white noise or a noisy version of the ionization map beside the density field during training. Our model reconstructs the power spectrum over all scales perfectly well. This work represents a step towards generating large-scale ionization maps with a minimal cost and hence enabling rapid parameter inference at the field level.","created":"2023-03-21","meta":{"link":"http://arxiv.org/abs/2303.12065v1","tag":"medical-cv"}}
{"title":"Probabilistic Domain Adaptation for Biomedical Image Segmentation","abstract":"Segmentation is a key analysis tasks in biomedical imaging. Given the many different experimental settings in this field, the lack of generalization limits the use of deep learning in practice. Domain adaptation is a promising remedy: it trains a model for a given task on a source dataset with labels and adapts it to a target dataset without additional labels. We introduce a probabilistic domain adaptation method, building on self-training approaches and the Probabilistic UNet. We use the latter to sample multiple segmentation hypothesis to implement better pseudo-label filtering. We further study joint and separate source-target training strategies and evaluate our method on three challenging domain adaptation tasks for biomedical segmentation.","created":"2023-03-21","meta":{"link":"http://arxiv.org/abs/2303.11790v1","tag":"medical-cv"}}
{"title":"Diff-UNet: A Diffusion Embedded Network for Volumetric Segmentation","abstract":"In recent years, Denoising Diffusion Models have demonstrated remarkable success in generating semantically valuable pixel-wise representations for image generative modeling. In this study, we propose a novel end-to-end framework, called Diff-UNet, for medical volumetric segmentation. Our approach integrates the diffusion model into a standard U-shaped architecture to extract semantic information from the input volume effectively, resulting in excellent pixel-level representations for medical volumetric segmentation. To enhance the robustness of the diffusion model's prediction results, we also introduce a Step-Uncertainty based Fusion (SUF) module during inference to combine the outputs of the diffusion models at each step. We evaluate our method on three datasets, including multimodal brain tumors in MRI, liver tumors, and multi-organ CT volumes, and demonstrate that Diff-UNet outperforms other state-of-the-art methods significantly. Our experimental results also indicate the universality and effectiveness of the proposed model. The proposed framework has the potential to facilitate the accurate diagnosis and treatment of medical conditions by enabling more precise segmentation of anatomical structures. The codes of Diff-UNet are available at https://github.com/ge-xing/Diff-UNet","created":"2023-03-18","meta":{"link":"http://arxiv.org/abs/2303.10326v1","tag":"medical-cv"}}
{"title":"Segmentation of Retinal Blood Vessels Using Deep Learning","abstract":"The morphology of retinal blood vessels can indicate various diseases in the human body, and researchers have been working on automatic scanning and segmentation of retinal images to aid diagnosis. This project compares the performance of four neural network architectures in segmenting retinal images, using a combined dataset from different databases, namely the UNet, DR-VNet, UNet-ResNet and UNet-VGG.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09679v1","tag":"medical-cv"}}
{"title":"FateZero: Fusing Attentions for Zero-shot Text-based Video Editing","abstract":"The diffusion-based generative models have achieved remarkable success in text-based image generation. However, since it contains enormous randomness in generation progress, it is still challenging to apply such models for real-world visual content editing, especially in videos. In this paper, we propose FateZero, a zero-shot text-based editing method on real-world videos without per-prompt training or use-specific mask. To edit videos consistently, we propose several techniques based on the pre-trained models. Firstly, in contrast to the straightforward DDIM inversion technique, our approach captures intermediate attention maps during inversion, which effectively retain both structural and motion information. These maps are directly fused in the editing process rather than generated during denoising. To further minimize semantic leakage of the source video, we then fuse self-attentions with a blending mask obtained by cross-attention features from the source prompt. Furthermore, we have implemented a reform of the self-attention mechanism in denoising UNet by introducing spatial-temporal attention to ensure frame consistency. Yet succinct, our method is the first one to show the ability of zero-shot text-driven video style and local attribute editing from the trained text-to-image model. We also have a better zero-shot shape-aware editing ability based on the text-to-video model. Extensive experiments demonstrate our superior temporal consistency and editing capability than previous works.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09535v2","tag":"medical-cv"}}
{"title":"A Generative Model for Digital Camera Noise Synthesis","abstract":"Noise synthesis is a challenging low-level vision task aiming to generate realistic noise given a clean image along with the camera settings. To this end, we propose an effective generative model which utilizes clean features as guidance followed by noise injections into the network. Specifically, our generator follows a UNet-like structure with skip connections but without downsampling and upsampling layers. Firstly, we extract deep features from a clean image as the guidance and concatenate a Gaussian noise map to the transition point between the encoder and decoder as the noise source. Secondly, we propose noise synthesis blocks in the decoder in each of which we inject Gaussian noise to model the noise characteristics. Thirdly, we propose to utilize an additional Style Loss and demonstrate that this allows better noise characteristics supervision in the generator. Through a number of new experiments, we evaluate the temporal variance and the spatial correlation of the generated noise which we hope can provide meaningful insights for future works. Finally, we show that our proposed approach outperforms existing methods for synthesizing camera noise.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09199v2","tag":"medical-cv"}}
{"title":"Enhancing COVID-19 Severity Analysis through Ensemble Methods","abstract":"Computed Tomography (CT) scans provide a detailed image of the lungs, allowing clinicians to observe the extent of damage caused by COVID-19. The CT severity score (CTSS) based scoring method is used to identify the extent of lung involvement observed on a CT scan. This paper presents a domain knowledge-based pipeline for extracting regions of infection in COVID-19 patients using a combination of image-processing algorithms and a pre-trained UNET model. The severity of the infection is then classified into different categories using an ensemble of three machine-learning models: Extreme Gradient Boosting, Extremely Randomized Trees, and Support Vector Machine. The proposed system was evaluated on a validation dataset in the AI-Enabled Medical Image Analysis Workshop and COVID-19 Diagnosis Competition (AI-MIA-COV19D) and achieved a macro F1 score of 64%. These results demonstrate the potential of combining domain knowledge with machine learning techniques for accurate COVID-19 diagnosis using CT scans. The implementation of the proposed system for severity analysis is available at \\textit{https://github.com/aanandt/Enhancing-COVID-19-Severity-Analysis-through-Ensemble-Methods.git }","created":"2023-03-13","meta":{"link":"http://arxiv.org/abs/2303.07130v3","tag":"medical-cv"}}
{"title":"SAR-UNet: Small Attention Residual UNet for Explainable Nowcasting Tasks","abstract":"The accuracy and explainability of data-driven nowcasting models are of great importance in many socio-economic sectors reliant on weather-dependent decision making. This paper proposes a novel architecture called Small Attention Residual UNet (SAR-UNet) for precipitation and cloud cover nowcasting. Here, SmaAt-UNet is used as a core model and is further equipped with residual connections, parallel to the depthwise separable convolutions. The proposed SAR-UNet model is evaluated on two datasets, i.e., Dutch precipitation maps ranging from 2016 to 2019 and French cloud cover binary images from 2017 to 2018. The obtained results show that SAR-UNet outperforms other examined models in precipitation nowcasting from 30 to 180 minutes in the future as well as cloud cover nowcasting in the next 90 minutes. Furthermore, we provide additional insights on the nowcasts made by our proposed model using Grad-CAM, a visual explanation technique, which is employed on different levels of the encoder and decoder paths of the SAR-UNet model and produces heatmaps highlighting the critical regions in the input image as well as intermediate representations to the precipitation. The heatmaps generated by Grad-CAM reveal the interactions between the residual connections and the depthwise separable convolutions inside of the multiple depthwise separable blocks placed throughout the network architecture.","created":"2023-03-12","meta":{"link":"http://arxiv.org/abs/2303.06663v1","tag":"medical-cv"}}
{"title":"Generalized Diffusion MRI Denoising and Super-Resolution using Swin Transformers","abstract":"Diffusion MRI is a non-invasive, in-vivo medical imaging method able to map tissue microstructure and structural connectivity of the human brain, as well as detect changes, such as brain development and injury, not visible by other clinical neuroimaging techniques. However, acquiring high signal-to-noise ratio (SNR) datasets with high angular and spatial sampling requires prohibitively long scan times, limiting usage in many important clinical settings, especially children, the elderly, and emergency patients with acute neurological disorders who might not be able to cooperate with the MRI scan without conscious sedation or general anesthesia. Here, we propose to use a Swin UNEt TRansformers (Swin UNETR) model, trained on augmented Human Connectome Project (HCP) data and conditioned on registered T1 scans, to perform generalized denoising and super-resolution of diffusion MRI invariant to acquisition parameters, patient populations, scanners, and sites. We qualitatively demonstrate super-resolution with artificially downsampled HCP data in normal adult volunteers. Our experiments on two other unrelated datasets, one of children with neurodevelopmental disorders and one of traumatic brain injury patients, show that our method demonstrates superior denoising despite wide data distribution shifts. Further improvement can be achieved via finetuning with just one additional subject. We apply our model to diffusion tensor (2nd order spherical harmonic) and higher-order spherical harmonic coefficient estimation and show results superior to current state-of-the-art methods. Our method can be used out-of-the-box or minimally finetuned to denoise and super-resolve a wide variety of diffusion MRI datasets. The code and model are publicly available at https://github.com/ucsfncl/dmri-swin.","created":"2023-03-10","meta":{"link":"http://arxiv.org/abs/2303.05686v1","tag":"medical-cv"}}
{"title":"Deep Reinforcement Learning for Beam Angle Optimization of Intensity-Modulated Radiation Therapy","abstract":"Objective: Intensity-modulated radiation therapy (IMRT) beam angle optimization (BAO) is a challenging combinatorial optimization problem that is NP-hard. In this study, we aim to develop a personalized BAO algorithm for IMRT that improves the quality of the final treatment. Methods: To improve the quality of IMRT treatment planning, we propose a deep reinforcement learning (DRL)-based approach for IMRT BAO. We consider the task as a sequential decision-making problem and formulate it as a Markov Decision Process. To facilitate the training process, a 3D-Unet is designed to predict the dose distribution for the different number of beam angles, ranging from 1 to 9, to simulate the IMRT environment. By leveraging the simulation model, double deep-Q network (DDQN) and proximal policy optimization (PPO) are used to train agents to select the personalized beam angle sequentially within a few seconds. Results: The treatment plans with beam angles selected by DRL outperform those with clinically used evenly distributed beam angles. For DDQN, the overall average improvement of the CIs is 0.027, 0.032, and 0.03 for 5, 7, and 9 beam angles respectively. For PPO, the overall average improvement of CIs is 0.045, 0.051, and 0.025 for 5, 7, and 9 beam angles respectively. Conclusion: The proposed DRL-based beam angle selection strategy can generate personalized beam angles within a few seconds, and the resulting treatment plan is superior to that obtained using evenly distributed angles. Significance: A fast and automated personalized beam angle selection approach is been proposed for IMRT BAO.","created":"2023-03-07","meta":{"link":"http://arxiv.org/abs/2303.03812v1","tag":"medical-cv"}}
{"title":"Deep Learning Based Dominant Index Lesion Segmentation for MR-guided Radiation Therapy of Prostate Cancer","abstract":"Dose escalation radiotherapy allows increased control of prostate cancer (PCa) but requires segmentation of dominant index lesions (DIL), motivating the development of automated methods for fast, accurate, and consistent segmentation of PCa DIL. We evaluated five deep-learning networks on apparent diffusion coefficient (ADC) MRI from 500 lesions in 365 patients arising from internal training Dataset 1 (1.5Tesla GE MR with endorectal coil), external ProstateX Dataset 2 (3Tesla Siemens MR), and internal inter-rater Dataset 3 (3Tesla Philips MR). The networks include: multiple resolution residually connected network (MRRN) and MRRN regularized in training with deep supervision (MRRN-DS), Unet, Unet++, ResUnet, and fast panoptic segmentation (FPSnet) as well as fast panoptic segmentation with smoothed labels (FPSnet-SL). Models were evaluated by volumetric DIL segmentation accuracy using Dice similarity coefficient (DSC) and detection accuracy, as a function of lesion aggressiveness, size, and location (Dataset 1 and 2), and accuracy with respect to two-raters (on Dataset 3). In general MRRN-DS more accurately segmented tumors than other methods on the testing datasets. MRRN-DS significantly outperformed ResUnet in Dataset2 (DSC of 0.54 vs. 0.44, p<0.001) and the Unet++ in Dataset3 (DSC of 0.45 vs. p=0.04). FPSnet-SL was similarly accurate as MRRN-DS in Dataset2 (p = 0.30), but MRRN-DS significantly outperformed FPSnet and FPSnet-SL in both Dataset1 (0.60 vs 0.51 [p=0.01] and 0.54 [p=0.049] respectively) and Dataset3 (0.45 vs 0.06 [p=0.002] and 0.24 [p=0.004] respectively). Finally, MRRN-DS produced slightly higher agreement with experienced radiologist than two radiologists in Dataset 3 (DSC of 0.45 vs. 0.41).","created":"2023-03-06","meta":{"link":"http://arxiv.org/abs/2303.03494v1","tag":"medical-cv"}}
{"title":"Meta-information-aware Dual-path Transformer for Differential Diagnosis of Multi-type Pancreatic Lesions in Multi-phase CT","abstract":"Pancreatic cancer is one of the leading causes of cancer-related death. Accurate detection, segmentation, and differential diagnosis of the full taxonomy of pancreatic lesions, i.e., normal, seven major types of lesions, and other lesions, is critical to aid the clinical decision-making of patient management and treatment. However, existing works focus on segmentation and classification for very specific lesion types (PDAC) or groups. Moreover, none of the previous work considers using lesion prevalence-related non-imaging patient information to assist the differential diagnosis. To this end, we develop a meta-information-aware dual-path transformer and exploit the feasibility of classification and segmentation of the full taxonomy of pancreatic lesions. Specifically, the proposed method consists of a CNN-based segmentation path (S-path) and a transformer-based classification path (C-path). The S-path focuses on initial feature extraction by semantic segmentation using a UNet-based network. The C-path utilizes both the extracted features and meta-information for patient-level classification based on stacks of dual-path transformer blocks that enhance the modeling of global contextual information. A large-scale multi-phase CT dataset of 3,096 patients with pathology-confirmed pancreatic lesion class labels, voxel-wise manual annotations of lesions from radiologists, and patient meta-information, was collected for training and evaluations. Our results show that our method can enable accurate classification and segmentation of the full taxonomy of pancreatic lesions, approaching the accuracy of the radiologist's report and significantly outperforming previous baselines. Results also show that adding the common meta-information, i.e., gender and age, can boost the model's performance, thus demonstrating the importance of meta-information for aiding pancreatic disease diagnosis.","created":"2023-03-02","meta":{"link":"http://arxiv.org/abs/2303.00942v1","tag":"medical-cv"}}
{"title":"Opto-UNet: Optimized UNet for Segmentation of Varicose Veins in Optical Coherence Tomography","abstract":"Human veins are important for carrying the blood from the body-parts to the heart. The improper functioning of the human veins may arise from several venous diseases. Varicose vein is one such disease wherein back flow of blood can occur, often resulting in increased venous pressure or restricted blood flow due to changes in the structure of vein. To examine the functional characteristics of the varicose vein, it is crucial to study the physical and bio mechanical properties of the vein. This work proposes a segmentation model Opto-UNet, for segmenting the venous wall structure. Optical Coherence Tomography system is used to acquire images of varicose vein. As the extracted vein is not uniform in shape, hence adequate method of segmentation is required to segment the venous wall. Opto-UNet model is based on the U-Net architecture wherein a new block is integrated into the architecture, employing atrous and separable convolution to extract spatially wide-range and separable features maps for attaining advanced performance. Furthermore, the depth wise separable convolution significantly reduces the complexity of the network by optimizing the number of parameters. The model achieves accuracy of 0.9830, sensitivity of 0.8425 and specificity of 0.9980 using 8.54 million number of parameters. These results indicate that model is highly adequate in segmenting the varicose vein wall without deteriorating the segmentation quality along with reduced complexity","created":"2023-02-28","meta":{"link":"http://arxiv.org/abs/2302.14808v2","tag":"medical-cv"}}
{"title":"3D Coronary Vessel Reconstruction from Bi-Plane Angiography using Graph Convolutional Networks","abstract":"X-ray coronary angiography (XCA) is used to assess coronary artery disease and provides valuable information on lesion morphology and severity. However, XCA images are 2D and therefore limit visualisation of the vessel. 3D reconstruction of coronary vessels is possible using multiple views, however lumen border detection in current software is performed manually resulting in limited reproducibility and slow processing time. In this study we propose 3DAngioNet, a novel deep learning (DL) system that enables rapid 3D vessel mesh reconstruction using 2D XCA images from two views. Our approach learns a coarse mesh template using an EfficientB3-UNet segmentation network and projection geometries, and deforms it using a graph convolutional network. 3DAngioNet outperforms similar automated reconstruction methods, offers improved efficiency, and enables modelling of bifurcated vessels. The approach was validated using state-of-the-art software verified by skilled cardiologists.","created":"2023-02-28","meta":{"link":"http://arxiv.org/abs/2302.14795v1","tag":"medical-cv"}}
{"title":"A Unified BEV Model for Joint Learning of 3D Local Features and Overlap Estimation","abstract":"Pairwise point cloud registration is a critical task for many applications, which heavily depends on finding correct correspondences from the two point clouds. However, the low overlap between input point clouds causes the registration to fail easily, leading to mistaken overlapping and mismatched correspondences, especially in scenes where non-overlapping regions contain similar structures. In this paper, we present a unified bird's-eye view (BEV) model for jointly learning of 3D local features and overlap estimation to fulfill pairwise registration and loop closure. Feature description is performed by a sparse UNet-like network based on BEV representation, and 3D keypoints are extracted by a detection head for 2D locations, and a regression head for heights. For overlap detection, a cross-attention module is applied for interacting contextual information of input point clouds, followed by a classification head to estimate the overlapping region. We evaluate our unified model extensively on the KITTI dataset and Apollo-SouthBay dataset. The experiments demonstrate that our method significantly outperforms existing methods on overlap estimation, especially in scenes with small overlaps. It also achieves top registration performance on both datasets in terms of translation and rotation errors.","created":"2023-02-28","meta":{"link":"http://arxiv.org/abs/2302.14511v2","tag":"medical-cv"}}
{"title":"Swin Deformable Attention Hybrid U-Net for Medical Image Segmentation","abstract":"How to harmonize convolution and multi-head self-attention mechanisms has recently emerged as a significant area of research in the field of medical image segmentation. Various combination methods have been proposed. However, there is a common flaw in these works: failed to provide a direct explanation for their hybrid model, which is crucial in clinical scenarios. Deformable Attention can improve the segmentation performance and provide an explanation based on the deformation field. Incorporating Deformable Attention into a hybrid model could result in a synergistic effect to boost segmentation performance while enhancing the explainability. In this study, we propose the incorporation of Swin Deformable Attention with hybrid architecture to improve the segmentation performance while establishing explainability. In the experiment section, our proposed Swin Deformable Attention Hybrid UNet (SDAH-UNet) demonstrates state-of-the-art performance on both anatomical and lesion segmentation tasks.","created":"2023-02-28","meta":{"link":"http://arxiv.org/abs/2302.14450v1","tag":"medical-cv"}}
{"title":"Contrast-PLC: Contrastive Learning for Packet Loss Concealment","abstract":"Packet loss concealment (PLC) is challenging in concealing missing contents both plausibly and naturally when there are only limited available context to use. Recently deep-learning based PLC algorithms have demonstrated their superiority over traditional counterparts; but their concealment ability is still mostly limited to a maximum of 120ms loss. Even with strong GAN-based generative models, it is still very challenging to predict long burst losses that could happen within/in-between phonemes. In this paper, we propose to use contrastive learning to learn a loss-robust semantic representation for PLC. A hybrid neural PLC architecture combining the semantic prediction and GAN-based generative model is designed to verify its effectiveness. Results on the blind test set of Interspeech2022 PLC Challenge show its superiority over commonly used UNet-style framework and the one without contrastive learning, especially for the longer burst loss at (120, 220] ms.","created":"2023-02-26","meta":{"link":"http://arxiv.org/abs/2302.13284v1","tag":"medical-cv"}}
{"title":"Evaluating the Efficacy of Skincare Product: A Realistic Short-Term Facial Pore Simulation","abstract":"Simulating the effects of skincare products on face is a potential new way to communicate the efficacy of skincare products in skin diagnostics and product recommendations. Furthermore, such simulations enable one to anticipate his/her skin conditions and better manage skin health. However, there is a lack of effective simulations today. In this paper, we propose the first simulation model to reveal facial pore changes after using skincare products. Our simulation pipeline consists of 2 steps: training data establishment and facial pore simulation. To establish training data, we collect face images with various pore quality indexes from short-term (8-weeks) clinical studies. People often experience significant skin fluctuations (due to natural rhythms, external stressors, etc.,), which introduces large perturbations in clinical data. To address this problem, we propose a sliding window mechanism to clean data and select representative index(es) to represent facial pore changes. Facial pore simulation stage consists of 3 modules: UNet-based segmentation module to localize facial pores; regression module to predict time-dependent warping hyperparameters; and deformation module, taking warping hyperparameters and pore segmentation labels as inputs, to precisely deform pores accordingly. The proposed simulation is able to render realistic facial pore changes. And this work will pave the way for future research in facial skin simulation and skincare product developments.","created":"2023-02-23","meta":{"link":"http://arxiv.org/abs/2302.11950v1","tag":"medical-cv"}}
{"title":"Video-SwinUNet: Spatio-temporal Deep Learning Framework for VFSS Instance Segmentation","abstract":"This paper presents a deep learning framework for medical video segmentation. Convolution neural network (CNN) and transformer-based methods have achieved great milestones in medical image segmentation tasks due to their incredible semantic feature encoding and global information comprehension abilities. However, most existing approaches ignore a salient aspect of medical video data - the temporal dimension. Our proposed framework explicitly extracts features from neighbouring frames across the temporal dimension and incorporates them with a temporal feature blender, which then tokenises the high-level spatio-temporal feature to form a strong global feature encoded via a Swin Transformer. The final segmentation results are produced via a UNet-like encoder-decoder architecture. Our model outperforms other approaches by a significant margin and improves the segmentation benchmarks on the VFSS2022 dataset, achieving a dice coefficient of 0.8986 and 0.8186 for the two datasets tested. Our studies also show the efficacy of the temporal feature blending scheme and cross-dataset transferability of learned capabilities. Code and models are fully available at https://github.com/SimonZeng7108/Video-SwinUNet.","created":"2023-02-22","meta":{"link":"http://arxiv.org/abs/2302.11325v1","tag":"medical-cv"}}
{"title":"Learning 3D Photography Videos via Self-supervised Diffusion on Single Images","abstract":"3D photography renders a static image into a video with appealing 3D visual effects. Existing approaches typically first conduct monocular depth estimation, then render the input frame to subsequent frames with various viewpoints, and finally use an inpainting model to fill those missing/occluded regions. The inpainting model plays a crucial role in rendering quality, but it is normally trained on out-of-domain data. To reduce the training and inference gap, we propose a novel self-supervised diffusion model as the inpainting module. Given a single input image, we automatically construct a training pair of the masked occluded image and the ground-truth image with random cycle-rendering. The constructed training samples are closely aligned to the testing instances, without the need of data annotation. To make full use of the masked images, we design a Masked Enhanced Block (MEB), which can be easily plugged into the UNet and enhance the semantic conditions. Towards real-world animation, we present a novel task: out-animation, which extends the space and time of input objects. Extensive experiments on real datasets show that our method achieves competitive results with existing SOTA methods.","created":"2023-02-21","meta":{"link":"http://arxiv.org/abs/2302.10781v1","tag":"medical-cv"}}
{"title":"Climate Model Driven Seasonal Forecasting Approach with Deep Learning","abstract":"Understanding seasonal climatic conditions is critical for better management of resources such as water, energy and agriculture. Recently, there has been a great interest in utilizing the power of artificial intelligence methods in climate studies. This paper presents a cutting-edge deep learning model (UNet++) trained by state-of-the-art global CMIP6 models to forecast global temperatures a month ahead using the ERA5 reanalysis dataset. ERA5 dataset was also used for finetuning as well performance analysis in the validation dataset. Three different setups (CMIP6; CMIP6 + elevation; CMIP6 + elevation + ERA5 finetuning) were used with both UNet and UNet++ algorithms resulting in six different models. For each model 14 different sequential and non-sequential temporal settings were used. The Mean Absolute Error (MAE) analysis revealed that UNet++ with CMIP6 with elevation and ERA5 finetuning model with \"Year 3 Month 2\" temporal case provided the best outcome with an MAE of 0.7. Regression analysis over the validation dataset between the ERA5 data values and the corresponding AI model predictions revealed slope and $R^2$ values close to 1 suggesting a very good agreement. The AI model predicts significantly better than the mean CMIP6 ensemble between 2016 and 2021. Both models predict the summer months more accurately than the winter months.","created":"2023-02-21","meta":{"link":"http://arxiv.org/abs/2302.10480v1","tag":"medical-cv"}}
{"title":"Self-supervised Registration and Segmentation of the Ossicles with A Single Ground Truth Label","abstract":"AI-assisted surgeries have drawn the attention of the medical image research community due to their real-world impact on improving surgery success rates. For image-guided surgeries, such as Cochlear Implants (CIs), accurate object segmentation can provide useful information for surgeons before an operation. Recently published image segmentation methods that leverage machine learning usually rely on a large number of manually predefined ground truth labels. However, it is a laborious and time-consuming task to prepare the dataset. This paper presents a novel technique using a self-supervised 3D-UNet that produces a dense deformation field between an atlas and a target image that can be used for atlas-based segmentation of the ossicles. Our results show that our method outperforms traditional image segmentation methods and generates a more accurate boundary around the ossicles based on Dice similarity coefficient and point-to-point error comparison. The mean Dice coefficient is improved by 8.51% with our proposed method.","created":"2023-02-15","meta":{"link":"http://arxiv.org/abs/2302.07967v1","tag":"medical-cv"}}
{"title":"Plug-and-Play Deep Energy Model for Inverse problems","abstract":"We introduce a novel energy formulation for Plug- and-Play (PnP) image recovery. Traditional PnP methods that use a convolutional neural network (CNN) do not have an energy based formulation. The primary focus of this work is to introduce an energy-based PnP formulation, which relies on a CNN that learns the log of the image prior from training data. The score function is evaluated as the gradient of the energy model, which resembles a UNET with shared encoder and decoder weights. The proposed score function is thus constrained to a conservative vector field, which is the key difference with classical PnP models. The energy-based formulation offers algorithms with convergence guarantees, even when the learned score model is not a contraction. The relaxation of the contraction constraint allows the proposed model to learn more complex priors, thus offering improved performance over traditional PnP schemes. Our experiments in magnetic resonance image reconstruction demonstrates the improved performance offered by the proposed energy model over traditional PnP methods.","created":"2023-02-15","meta":{"link":"http://arxiv.org/abs/2302.11570v1","tag":"medical-cv"}}
{"title":"Take a Prior from Other Tasks for Severe Blur Removal","abstract":"Recovering clear structures from severely blurry inputs is a challenging problem due to the large movements between the camera and the scene. Although some works apply segmentation maps on human face images for deblurring, they cannot handle natural scenes because objects and degradation are more complex, and inaccurate segmentation maps lead to a loss of details. For general scene deblurring, the feature space of the blurry image and corresponding sharp image under the high-level vision task is closer, which inspires us to rely on other tasks (e.g. classification) to learn a comprehensive prior in severe blur removal cases. We propose a cross-level feature learning strategy based on knowledge distillation to learn the priors, which include global contexts and sharp local structures for recovering potential details. In addition, we propose a semantic prior embedding layer with multi-level aggregation and semantic attention transformation to integrate the priors effectively. We introduce the proposed priors to various models, including the UNet and other mainstream deblurring baselines, leading to better performance on severe blur removal. Extensive experiments on natural image deblurring benchmarks and real-world images, such as GoPro and RealBlur datasets, demonstrate our method's effectiveness and generalization ability.","created":"2023-02-14","meta":{"link":"http://arxiv.org/abs/2302.06898v1","tag":"medical-cv"}}
{"title":"Liver Segmentation in Time-resolved C-arm CT Volumes Reconstructed from Dynamic Perfusion Scans using Time Separation Technique","abstract":"Perfusion imaging is a valuable tool for diagnosing and treatment planning for liver tumours. The time separation technique (TST) has been successfully used for modelling C-arm cone-beam computed tomography (CBCT) perfusion data. The reconstruction can be accompanied by the segmentation of the liver - for better visualisation and for generating comprehensive perfusion maps. Recently introduced Turbolift learning has been seen to perform well while working with TST reconstructions, but has not been explored for the time-resolved volumes (TRV) estimated out of TST reconstructions. The segmentation of the TRVs can be useful for tracking the movement of the liver over time. This research explores this possibility by training the multi-scale attention UNet of Turbolift learning at its third stage on the TRVs and shows the robustness of Turbolift learning since it can even work efficiently with the TRVs, resulting in a Dice score of 0.864$\\pm$0.004.","created":"2023-02-09","meta":{"link":"http://arxiv.org/abs/2302.04585v1","tag":"medical-cv"}}
{"title":"WF-UNet: Weather Fusion UNet for Precipitation Nowcasting","abstract":"Designing early warning systems for harsh weather and its effects, such as urban flooding or landslides, requires accurate short-term forecasts (nowcasts) of precipitation. Nowcasting is a significant task with several environmental applications, such as agricultural management or increasing flight safety. In this study, we investigate the use of a UNet core-model and its extension for precipitation nowcasting in western Europe for up to 3 hours ahead. In particular, we propose the Weather Fusion UNet (WF-UNet) model, which utilizes the Core 3D-UNet model and integrates precipitation and wind speed variables as input in the learning process and analyze its influences on the precipitation target task. We have collected six years of precipitation and wind radar images from Jan 2016 to Dec 2021 of 14 European countries, with 1-hour temporal resolution and 31 square km spatial resolution based on the ERA5 dataset, provided by Copernicus, the European Union's Earth observation programme. We compare the proposed WF-UNet model to persistence model as well as other UNet based architectures that are trained only using precipitation radar input data. The obtained results show that WF-UNet outperforms the other examined best-performing architectures by 22%, 8% and 6% lower MSE at a horizon of 1, 2 and 3 hours respectively.","created":"2023-02-08","meta":{"link":"http://arxiv.org/abs/2302.04102v2","tag":"medical-cv"}}
{"title":"Med-NCA: Robust and Lightweight Segmentation with Neural Cellular Automata","abstract":"Access to the proper infrastructure is critical when performing medical image segmentation with Deep Learning. This requirement makes it difficult to run state-of-the-art segmentation models in resource-constrained scenarios like primary care facilities in rural areas and during crises. The recently emerging field of Neural Cellular Automata (NCA) has shown that locally interacting one-cell models can achieve competitive results in tasks such as image generation or segmentations in low-resolution inputs. However, they are constrained by high VRAM requirements and the difficulty of reaching convergence for high-resolution images. To counteract these limitations we propose Med-NCA, an end-to-end NCA training pipeline for high-resolution image segmentation. Our method follows a two-step process. Global knowledge is first communicated between cells across the downscaled image. Following that, patch-based segmentation is performed. Our proposed Med-NCA outperforms the classic UNet by 2% and 3% Dice for hippocampus and prostate segmentation, respectively, while also being 500 times smaller. We also show that Med-NCA is by design invariant with respect to image scale, shape and translation, experiencing only slight performance degradation even with strong shifts; and is robust against MRI acquisition artefacts. Med-NCA enables high-resolution medical image segmentation even on a Raspberry Pi B+, arguably the smallest device able to run PyTorch and that can be powered by a standard power bank.","created":"2023-02-07","meta":{"link":"http://arxiv.org/abs/2302.03473v1","tag":"medical-cv"}}
{"title":"Visual Watermark Removal Based on Deep Learning","abstract":"In recent years as the internet age continues to grow, sharing images on social media has become a common occurrence. In certain cases, watermarks are used as protection for the ownership of the image, however, in more cases, one may wish to remove these watermark images to get the original image without obscuring. In this work, we proposed a deep learning method based technique for visual watermark removal. Inspired by the strong image translation performance of the U-structure, an end-to-end deep neural network model named AdvancedUnet is proposed to extract and remove the visual watermark simultaneously. On the other hand, we embed some effective RSU module instead of the common residual block used in UNet, which increases the depth of the whole architecture without significantly increasing the computational cost. The deep-supervised hybrid loss guides the network to learn the transformation between the input image and the ground truth in a multi-scale and three-level hierarchy. Comparison experiments demonstrate the effectiveness of our method.","created":"2023-02-07","meta":{"link":"http://arxiv.org/abs/2302.11338v1","tag":"medical-cv"}}
{"title":"FCB-SwinV2 Transformer for Polyp Segmentation","abstract":"Polyp segmentation within colonoscopy video frames using deep learning models has the potential to automate the workflow of clinicians. This could help improve the early detection rate and characterization of polyps which could progress to colorectal cancer. Recent state-of-the-art deep learning polyp segmentation models have combined the outputs of Fully Convolutional Network architectures and Transformer Network architectures which work in parallel. In this paper we propose modifications to the current state-of-the-art polyp segmentation model FCBFormer. The transformer architecture of the FCBFormer is replaced with a SwinV2 Transformer-UNET and minor changes to the Fully Convolutional Network architecture are made to create the FCB-SwinV2 Transformer. The performance of the FCB-SwinV2 Transformer is evaluated on the popular colonoscopy segmentation bench-marking datasets Kvasir-SEG and CVC-ClinicDB. Generalizability tests are also conducted. The FCB-SwinV2 Transformer is able to consistently achieve higher mDice scores across all tests conducted and therefore represents new state-of-the-art performance. Issues found with how colonoscopy segmentation model performance is evaluated within literature are also re-ported and discussed. One of the most important issues identified is that when evaluating performance on the CVC-ClinicDB dataset it would be preferable to ensure no data leakage from video sequences occurs during the training/validation/test data partition.","created":"2023-02-02","meta":{"link":"http://arxiv.org/abs/2302.01027v1","tag":"medical-cv"}}
{"title":"Ring Artifact Correction in Photon-Counting Spectral CT Using a Convolutional Neural Network With Spectral Loss","abstract":"Photon-counting spectral computed tomography is now clinically available. These new detectors come with the promise of higher contrast-to-noise ratio and spatial resolution and improved low-dose imaging. However, one important design consideration is to build detector elements that are sufficiently homogeneous. In practice, there will always be a degree of inhomogeneity in the detector elements, which will materialize as variations in the energy bin thresholds. Without proper detector calibration, this will lead to streak artifacts in the sinograms and corresponding ring artifacts in the reconstructed images, which limit their clinical usefulness. Since detector calibration is a time-consuming process, having access to a fast ring correction technique may greatly improve workflow. In this paper, we propose a deep learning-based post-processing technique for ring artifact correction in photon-counting spectral CT. We train a UNet with a custom loss to correct for ring artifacts in the material basis images. Our proposed loss is made ``task-aware'' by explicitly incorporating the fact that we are working with spectral CT by combining a L1-loss operating on the material basis images with a perceptual loss, using VGG16 as feature extractor, operating on 70 keV virtual monoenergetic images. Our results indicate that using this novel loss greatly improves performance. We demonstrate that our proposed method can successfully produce ring corrected 40, 70, and 100 keV virtual monoenergetic images.","created":"2023-02-02","meta":{"link":"http://arxiv.org/abs/2302.00921v1","tag":"medical-cv"}}
{"title":"Towards Learned Emulation of Interannual Water Isotopologue Variations in General Circulation Models","abstract":"Simulating abundances of stable water isotopologues, i.e. molecules differing in their isotopic composition, within climate models allows for comparisons with proxy data and, thus, for testing hypotheses about past climate and validating climate models under varying climatic conditions. However, many models are run without explicitly simulating water isotopologues. We investigate the possibility to replace the explicit physics-based simulation of oxygen isotopic composition in precipitation using machine learning methods. These methods estimate isotopic composition at each time step for given fields of surface temperature and precipitation amount. We implement convolutional neural networks (CNNs) based on the successful UNet architecture and test whether a spherical network architecture outperforms the naive approach of treating Earth's latitude-longitude grid as a flat image. Conducting a case study on a last millennium run with the iHadCM3 climate model, we find that roughly 40\\% of the temporal variance in the isotopic composition is explained by the emulations on interannual and monthly timescale, with spatially varying emulation quality. A modified version of the standard UNet architecture for flat images yields results that are equally good as the predictions by the spherical CNN. We test generalization to last millennium runs of other climate models and find that while the tested deep learning methods yield the best results on iHadCM3 data, the performance drops when predicting on other models and is comparable to simple pixel-wise linear regression. An extended choice of predictor variables and improving the robustness of learned climate--oxygen isotope relationships should be explored in future work.","created":"2023-01-31","meta":{"link":"http://arxiv.org/abs/2301.13462v1","tag":"medical-cv"}}
{"title":"DiffusionCT: Latent Diffusion Model for CT Image Standardization","abstract":"Computed tomography (CT) is one of the modalities for effective lung cancer screening, diagnosis, treatment, and prognosis. The features extracted from CT images are now used to quantify spatial and temporal variations in tumors. However, CT images obtained from various scanners with customized acquisition protocols may introduce considerable variations in texture features, even for the same patient. This presents a fundamental challenge to downstream studies that require consistent and reliable feature analysis. Existing CT image harmonization models rely on GAN-based supervised or semi-supervised learning, with limited performance. This work addresses the issue of CT image harmonization using a new diffusion-based model, named DiffusionCT, to standardize CT images acquired from different vendors and protocols. DiffusionCT operates in the latent space by mapping a latent non-standard distribution into a standard one. DiffusionCT incorporates an Unet-based encoder-decoder, augmented by a diffusion model integrated into the bottleneck part. The model is designed in two training phases. The encoder-decoder is first trained, without embedding the diffusion model, to learn the latent representation of the input data. The latent diffusion model is then trained in the next training phase while fixing the encoder-decoder. Finally, the decoder synthesizes a standardized image with the transformed latent representation. The experimental results demonstrate a significant improvement in the performance of the standardization task using DiffusionCT.","created":"2023-01-20","meta":{"link":"http://arxiv.org/abs/2301.08815v2","tag":"medical-cv"}}
{"title":"MedSegDiff-V2: Diffusion based Medical Image Segmentation with Transformer","abstract":"The Diffusion Probabilistic Model (DPM) has recently gained popularity in the field of computer vision, thanks to its image generation applications, such as Imagen, Latent Diffusion Models, and Stable Diffusion, which have demonstrated impressive capabilities and sparked much discussion within the community. Recent studies have also found DPM to be useful in the field of medical image analysis, as evidenced by the strong performance of the medical image segmentation model MedSegDiff in various tasks. While these models were originally designed with a UNet backbone, they may also potentially benefit from the incorporation of vision transformer techniques. However, we discovered that simply combining these two approaches resulted in subpar performance. In this paper, we propose a novel transformer-based conditional UNet framework, as well as a new Spectrum-Space Transformer (SS-Former) to model the interaction between noise and semantic features. This architectural improvement leads to a new diffusion-based medical image segmentation method called MedSegDiff-V2, which significantly improves the performance of MedSegDiff. We have verified the effectiveness of MedSegDiff-V2 on eighteen organs of five segmentation datasets with different image modalities. Our experimental results demonstrate that MedSegDiff-V2 outperforms state-of-the-art (SOTA) methods by a considerable margin, further proving the generalizability and effectiveness of the proposed model.","created":"2023-01-19","meta":{"link":"http://arxiv.org/abs/2301.11798v1","tag":"medical-cv"}}
{"title":"FPANet: Frequency-based Video Demoireing using Frame-level Post Alignment","abstract":"Interference between overlapping gird patterns creates moire patterns, degrading the visual quality of an image that captures a screen of a digital display device by an ordinary digital camera. Removing such moire patterns is challenging due to their complex patterns of diverse sizes and color distortions. Existing approaches mainly focus on filtering out in the spatial domain, failing to remove a large-scale moire pattern. In this paper, we propose a novel model called FPANet that learns filters in both frequency and spatial domains, improving the restoration quality by removing various sizes of moire patterns. To further enhance, our model takes multiple consecutive frames, learning to extract frame-invariant content features and outputting better quality temporally consistent images. We demonstrate the effectiveness of our proposed method with a publicly available large-scale dataset, observing that ours outperforms the state-of-the-art approaches, including ESDNet, VDmoire, MBCNN, WDNet, UNet, and DMCNN, in terms of the image and video quality metrics, such as PSNR, SSIM, LPIPS, FVD, and FSIM.","created":"2023-01-18","meta":{"link":"http://arxiv.org/abs/2301.07330v1","tag":"medical-cv"}}
{"title":"Multi Kernel Positional Embedding ConvNeXt for Polyp Segmentation","abstract":"Medical image segmentation is the technique that helps doctor view and has a precise diagnosis, particularly in Colorectal Cancer. Specifically, with the increase in cases, the diagnosis and identification need to be faster and more accurate for many patients; in endoscopic images, the segmentation task has been vital to helping the doctor identify the position of the polyps or the ache in the system correctly. As a result, many efforts have been made to apply deep learning to automate polyp segmentation, mostly to ameliorate the U-shape structure. However, the simple skip connection scheme in UNet leads to deficient context information and the semantic gap between feature maps from the encoder and decoder. To deal with this problem, we propose a novel framework composed of ConvNeXt backbone and Multi Kernel Positional Embedding block. Thanks to the suggested module, our method can attain better accuracy and generalization in the polyps segmentation task. Extensive experiments show that our model achieves the Dice coefficient of 0.8818 and the IOU score of 0.8163 on the Kvasir-SEG dataset. Furthermore, on various datasets, we make competitive achievement results with other previous state-of-the-art methods.","created":"2023-01-17","meta":{"link":"http://arxiv.org/abs/2301.06673v1","tag":"medical-cv"}}
{"title":"Reinforcement Learning for Protocol Synthesis in Resource-Constrained Wireless Sensor and IoT Networks","abstract":"This article explores the concepts of online protocol synthesis using Reinforcement Learning (RL). The study is performed in the context of sensor and IoT networks with ultra low complexity wireless transceivers. The paper introduces the use of RL and Multi Armed Bandit (MAB), a specific type of RL, for Medium Access Control (MAC) under different network and traffic conditions. It then introduces a novel learning based protocol synthesis framework that addresses specific difficulties and limitations in medium access for both random access and time slotted networks. The mechanism does not rely on carrier sensing, network time-synchronization, collision detection, and other low level complex operations, thus making it ideal for ultra simple transceiver hardware used in resource constrained sensor and IoT networks. Additionally, the ability of independent protocol learning by the nodes makes the system robust and adaptive to the changes in network and traffic conditions. It is shown that the nodes can be trained to learn to avoid collisions, and to achieve network throughputs that are comparable to ALOHA based access protocols in sensor and IoT networks with simplest transceiver hardware. It is also shown that using RL, it is feasible to synthesize access protocols that can sustain network throughput at high traffic loads, which is not feasible in the ALOHA-based systems. The ability of the system to provide throughput fairness under network and traffic heterogeneities are also experimentally demonstrated.","created":"2023-01-14","meta":{"link":"http://arxiv.org/abs/2302.05300v1","tag":"medical-cv"}}
{"title":"Visual deep learning-based explanation for neuritic plaques segmentation in Alzheimer's Disease using weakly annotated whole slide histopathological images","abstract":"Quantifying the distribution and morphology of tau protein structures in brain tissues is key to diagnosing Alzheimer's Disease (AD) and its subtypes. Recently, deep learning (DL) models such as UNet have been successfully used for automatic segmentation of histopathological whole slide images (WSI) of biological tissues. In this study, we propose a DL-based methodology for semantic segmentation of tau lesions (i.e., neuritic plaques) in WSI of postmortem patients with AD. The state of the art in semantic segmentation of neuritic plaques in human WSI is very limited. Our study proposes a baseline able to generate a significant advantage for morphological analysis of these tauopathies for further stratification of AD patients. Essential discussions concerning biomarkers (ALZ50 versus AT8 tau antibodies), the imaging modality (different slide scanner resolutions), and the challenge of weak annotations are addressed within this seminal study. The analysis of the impact of context in plaque segmentation is important to understand the role of the micro-environment for reliable tau protein segmentation. In addition, by integrating visual interpretability, we are able to explain how the network focuses on a region of interest (ROI), giving additional insights to pathologists. Finally, the release of a new expert-annotated database and the code (\\url{https://github.com/aramis-lab/miccai2022-stratifiad.git}) will be helpful for the scientific community to accelerate the development of new pipelines for human WSI processing in AD.","created":"2023-01-13","meta":{"link":"http://arxiv.org/abs/2302.08511v1","tag":"medical-cv"}}
{"title":"AI-assisted reconstruction of cosmic velocity field from redshift-space spatial distribution of halos","abstract":"The peculiar velocities of dark matter halos are crucial to study many issues in cosmology and galaxy evolution. In this study, by using the state-of-the-art deep learning technique, a UNet-based neural network, we propose to reconstruct the peculiar velocity field from the redshift-space distribution of dark matter halos. Through a point-to-point comparison and examination of various statistical properties, we demonstrate that, the reconstructed velocity field is in good agreement with the ground truth. The power spectra of various velocity field components, including velocity magnitude, divergence and vorticity, can be successfully recovered when $k\\lesssim 1.1$ $h/\\rm Mpc$ (the Nyquist frequency of the simulations) at about 80% accuracy. This approach is very promising and presents an alternative method to correct the redshift-space distortions using the measured 3D spatial information of halos. Additionally, for the reconstruction of the momentum field of halos, UNet achieves similar good results. Hence the applications in various aspects of cosmology are very broad, such as correcting redshift errors and improving measurements in the structure of the cosmic web, the kinetic Sunyaev-Zel'dovich effect, BAO reconstruction, etc.","created":"2023-01-11","meta":{"link":"http://arxiv.org/abs/2301.04586v3","tag":"medical-cv"}}
{"title":"Does image resolution impact chest X-ray based fine-grained Tuberculosis-consistent lesion segmentation?","abstract":"Deep learning (DL) models are state-of-the-art in segmenting anatomical and disease regions of interest (ROIs) in medical images. Particularly, a large number of DL-based techniques have been reported using chest X-rays (CXRs). However, these models are reportedly trained on reduced image resolutions for reasons related to the lack of computational resources. Literature is sparse in discussing the optimal image resolution to train these models for segmenting the Tuberculosis (TB)-consistent lesions in CXRs. In this study, we investigated the performance variations using an Inception-V3 UNet model using various image resolutions with/without lung ROI cropping and aspect ratio adjustments, and (ii) identified the optimal image resolution through extensive empirical evaluations to improve TB-consistent lesion segmentation performance. We used the Shenzhen CXR dataset for the study which includes 326 normal patients and 336 TB patients. We proposed a combinatorial approach consisting of storing model snapshots, optimizing segmentation threshold and test-time augmentation (TTA), and averaging the snapshot predictions, to further improve performance with the optimal resolution. Our experimental results demonstrate that higher image resolutions are not always necessary, however, identifying the optimal image resolution is critical to achieving superior performance.","created":"2023-01-10","meta":{"link":"http://arxiv.org/abs/2301.04032v2","tag":"medical-cv"}}
{"title":"Multiclass Semantic Segmentation to Identify Anatomical Sub-Regions of Brain and Measure Neuronal Health in Parkinson's Disease","abstract":"Automated segmentation of anatomical sub-regions with high precision has become a necessity to enable the quantification and characterization of cells/ tissues in histology images. Currently, a machine learning model to analyze sub-anatomical regions of the brain to analyze 2D histological images is not available. The scientists rely on manually segmenting anatomical sub-regions of the brain which is extremely time-consuming and prone to labeler-dependent bias. One of the major challenges in accomplishing such a task is the lack of high-quality annotated images that can be used to train a generic artificial intelligence model. In this study, we employed a UNet-based architecture, compared model performance with various combinations of encoders, image sizes, and sample selection techniques. Additionally, to increase the sample set we resorted to data augmentation which provided data diversity and robust learning. In this study, we trained our best fit model on approximately one thousand annotated 2D brain images stained with Nissl/ Haematoxylin and Tyrosine Hydroxylase enzyme (TH, indicator of dopaminergic neuron viability). The dataset comprises of different animal studies enabling the model to be trained on different datasets. The model effectively is able to detect two sub-regions compacta (SNCD) and reticulata (SNr) in all the images. In spite of limited training data, our best model achieves a mean intersection over union (IOU) of 79% and a mean dice coefficient of 87%. In conclusion, the UNet-based model with EffiecientNet as an encoder outperforms all other encoders, resulting in a first of its kind robust model for multiclass segmentation of sub-brain regions in 2D images.","created":"2023-01-07","meta":{"link":"http://arxiv.org/abs/2301.02925v1","tag":"medical-cv"}}
{"title":"Image To Tree with Recursive Prompting","abstract":"Extracting complex structures from grid-based data is a common key step in automated medical image analysis. The conventional solution to recovering tree-structured geometries typically involves computing the minimal cost path through intermediate representations derived from segmentation masks. However, this methodology has significant limitations in the context of projective imaging of tree-structured 3D anatomical data such as coronary arteries, since there are often overlapping branches in the 2D projection. In this work, we propose a novel approach to predicting tree connectivity structure which reformulates the task as an optimization problem over individual steps of a recursive process. We design and train a two-stage model which leverages the UNet and Transformer architectures and introduces an image-based prompting technique. Our proposed method achieves compelling results on a pair of synthetic datasets, and outperforms a shortest-path baseline.","created":"2023-01-01","meta":{"link":"http://arxiv.org/abs/2301.00447v1","tag":"medical-cv"}}
{"title":"Foreground Removal of CO Intensity Mapping Using Deep Learning","abstract":"Line intensity mapping (LIM) is a promising probe to study star formation, the large-scale structure of the Universe, and the epoch of reionization (EoR). Since carbon monoxide (CO) is the second most abundant molecule in the Universe except for molecular hydrogen ${\\rm H}_2$, it is suitable as a tracer for LIM surveys. However, just like other LIM surveys, CO intensity mapping also suffers strong foreground contamination that needs to be eliminated for extracting valuable astrophysical and cosmological information. In this work, we take $^{12}$CO($\\it J$=1-0) emission line as an example to investigate whether deep learning method can effectively recover the signal by removing the foregrounds. The CO(1-0) intensity maps are generated by N-body simulations considering CO luminosity and halo mass relation, and we discuss two cases with median and low CO signals by comparing different relations. We add foregrounds generated from real observations, including thermal dust, spinning dust, free-free, synchrotron emission and CMB anisotropy. The beam with sidelobe effect is also considered. Our deep learning model is built upon ResUNet, which combines image generation algorithm UNet with the state-of-the-art architecture of deep learning, ResNet. The principal component analysis (PCA) method is employed to preprocess data before feeding it to the ResUNet. We find that, in the case of low instrumental noise, our UNet can efficiently reconstruct the CO signal map with correct line power spectrum by removing the foregrounds and recovering PCA signal loss and beam effects. Our method also can be applied to other intensity mappings like neutral hydrogen 21cm surveys.","created":"2022-12-30","meta":{"link":"http://arxiv.org/abs/2212.14712v2","tag":"medical-cv"}}
{"title":"Efficient Semantic Segmentation on Edge Devices","abstract":"Semantic segmentation works on the computer vision algorithm for assigning each pixel of an image into a class. The task of semantic segmentation should be performed with both accuracy and efficiency. Most of the existing deep FCNs yield to heavy computations and these networks are very power hungry, unsuitable for real-time applications on portable devices. This project analyzes current semantic segmentation models to explore the feasibility of applying these models for emergency response during catastrophic events. We compare the performance of real-time semantic segmentation models with non-real-time counterparts constrained by aerial images under oppositional settings. Furthermore, we train several models on the Flood-Net dataset, containing UAV images captured after Hurricane Harvey, and benchmark their execution on special classes such as flooded buildings vs. non-flooded buildings or flooded roads vs. non-flooded roads. In this project, we developed a real-time UNet based model and deployed that network on Jetson AGX Xavier module.","created":"2022-12-28","meta":{"link":"http://arxiv.org/abs/2212.13691v2","tag":"medical-cv"}}
{"title":"Exploring Transformer Backbones for Image Diffusion Models","abstract":"We present an end-to-end Transformer based Latent Diffusion model for image synthesis. On the ImageNet class conditioned generation task we show that a Transformer based Latent Diffusion model achieves a 14.1FID which is comparable to the 13.1FID score of a UNet based architecture. In addition to showing the application of Transformer models for Diffusion based image synthesis this simplification in architecture allows easy fusion and modeling of text and image data. The multi-head attention mechanism of Transformers enables simplified interaction between the image and text features which removes the requirement for crossattention mechanism in UNet based Diffusion models.","created":"2022-12-27","meta":{"link":"http://arxiv.org/abs/2212.14678v1","tag":"medical-cv"}}
{"title":"Lightweight Monocular Depth Estimation","abstract":"Monocular depth estimation can play an important role in addressing the issue of deriving scene geometry from 2D images. It has been used in a variety of industries, including robots, self-driving cars, scene comprehension, 3D reconstructions, and others. The goal of our method is to create a lightweight machine-learning model in order to predict the depth value of each pixel given only a single RGB image as input with the Unet structure of the image segmentation network. We use the NYU Depth V2 dataset to test the structure and compare the result with other methods. The proposed method achieves relatively high accuracy and low rootmean-square error.","created":"2022-12-21","meta":{"link":"http://arxiv.org/abs/2212.11363v1","tag":"medical-cv"}}
{"title":"Focal-UNet: UNet-like Focal Modulation for Medical Image Segmentation","abstract":"Recently, many attempts have been made to construct a transformer base U-shaped architecture, and new methods have been proposed that outperformed CNN-based rivals. However, serious problems such as blockiness and cropped edges in predicted masks remain because of transformers' patch partitioning operations. In this work, we propose a new U-shaped architecture for medical image segmentation with the help of the newly introduced focal modulation mechanism. The proposed architecture has asymmetric depths for the encoder and decoder. Due to the ability of the focal module to aggregate local and global features, our model could simultaneously benefit the wide receptive field of transformers and local viewing of CNNs. This helps the proposed method balance the local and global feature usage to outperform one of the most powerful transformer-based U-shaped models called Swin-UNet. We achieved a 1.68% higher DICE score and a 0.89 better HD metric on the Synapse dataset. Also, with extremely limited data, we had a 4.25% higher DICE score on the NeoPolyp dataset. Our implementations are available at: https://github.com/givkashi/Focal-UNet","created":"2022-12-19","meta":{"link":"http://arxiv.org/abs/2212.09263v1","tag":"medical-cv"}}
{"title":"Full Contextual Attention for Multi-resolution Transformers in Semantic Segmentation","abstract":"Transformers have proved to be very effective for visual recognition tasks. In particular, vision transformers construct compressed global representations through self-attention and learnable class tokens. Multi-resolution transformers have shown recent successes in semantic segmentation but can only capture local interactions in high-resolution feature maps. This paper extends the notion of global tokens to build GLobal Attention Multi-resolution (GLAM) transformers. GLAM is a generic module that can be integrated into most existing transformer backbones. GLAM includes learnable global tokens, which unlike previous methods can model interactions between all image regions, and extracts powerful representations during training. Extensive experiments show that GLAM-Swin or GLAM-Swin-UNet exhibit substantially better performances than their vanilla counterparts on ADE20K and Cityscapes. Moreover, GLAM can be used to segment large 3D medical images, and GLAM-nnFormer achieves new state-of-the-art performance on the BCV dataset.","created":"2022-12-15","meta":{"link":"http://arxiv.org/abs/2212.07890v1","tag":"medical-cv"}}
{"title":"OmniHorizon: In-the-Wild Outdoors Depth and Normal Estimation from Synthetic Omnidirectional Dataset","abstract":"Understanding the ambient scene is imperative for several applications such as autonomous driving and navigation. While obtaining real-world image data with per-pixel labels is challenging, existing accurate synthetic image datasets primarily focus on indoor spaces with fixed lighting and scene participants, thereby severely limiting their application to outdoor scenarios. In this work we introduce OmniHorizon, a synthetic dataset with 24,335 omnidirectional views comprising of a broad range of indoor and outdoor spaces consisting of buildings, streets, and diverse vegetation. Our dataset also accounts for dynamic scene components including lighting, different times of a day settings, pedestrians, and vehicles. Furthermore, we also demonstrate a learned synthetic-to-real cross-domain inference method for in-the-wild 3D scene depth and normal estimation method using our dataset. To this end, we propose UBotNet, an architecture based on a UNet and a Bottleneck Transformer, to estimate scene-consistent normals. We show that UBotNet achieves significantly improved depth accuracy (4.6%) and normal estimation (5.75%) compared to several existing networks such as U-Net with skip-connections. Finally, we demonstrate in-the-wild depth and normal estimation on real-world images with UBotNet trained purely on our OmniHorizon dataset, showing the promise of proposed dataset and network for scene understanding.","created":"2022-12-09","meta":{"link":"http://arxiv.org/abs/2212.05040v2","tag":"medical-cv"}}
{"title":"UNet Based Pipeline for Lung Segmentation from Chest X-Ray Images","abstract":"Biomedical image segmentation is one of the fastest growing fields which has seen extensive automation through the use of Artificial Intelligence. This has enabled widespread adoption of accurate techniques to expedite the screening and diagnostic processes which would otherwise take several days to finalize. In this paper, we present an end-to-end pipeline to segment lungs from chest X-ray images, training the neural network model on the Japanese Society of Radiological Technology (JSRT) dataset, using UNet to enable faster processing of initial screening for various lung disorders. The pipeline developed can be readily used by medical centers with just the provision of X-Ray images as input. The model will perform the preprocessing, and provide a segmented image as the final output. It is expected that this will drastically reduce the manual effort involved and lead to greater accessibility in resource-constrained locations.","created":"2022-12-09","meta":{"link":"http://arxiv.org/abs/2212.04617v1","tag":"medical-cv"}}
{"title":"A new eye segmentation method based on improved U2Net in TCM eye diagnosis","abstract":"For the diagnosis of Chinese medicine, tongue segmentation has reached a fairly mature point, but it has little application in the eye diagnosis of Chinese medicine.First, this time we propose Res-UNet based on the architecture of the U2Net network, and use the Data Enhancement Toolkit based on small datasets, Finally, the feature blocks after noise reduction are fused with the high-level features.Finally, the number of network parameters and inference time are used as evaluation indicators to evaluate the model. At the same time, different eye data segmentation frames were compared using Miou, Precision, Recall, F1-Score and FLOPS. To convince people, we cite the UBIVIS. V1 public dataset this time, in which Miou reaches 97.8%, S-measure reaches 97.7%, F1-Score reaches 99.09% and for 320*320 RGB input images, the total parameter volume is 167.83 MB,Due to the excessive number of parameters, we experimented with a small-scale U2Net combined with a Res module with a parameter volume of 4.63 MB, which is similar to U2Net in related indicators, which verifies the effectiveness of our structure.which achieves the best segmentation effect in all the comparison networks and lays a foundation for the application of subsequent visual apparatus recognition symptoms.","created":"2022-12-06","meta":{"link":"http://arxiv.org/abs/2212.02989v1","tag":"medical-cv"}}
{"title":"FedUKD: Federated UNet Model with Knowledge Distillation for Land Use Classification from Satellite and Street Views","abstract":"Federated Deep Learning frameworks can be used strategically to monitor Land Use locally and infer environmental impacts globally. Distributed data from across the world would be needed to build a global model for Land Use classification. The need for a Federated approach in this application domain would be to avoid transfer of data from distributed locations and save network bandwidth to reduce communication cost. We use a Federated UNet model for Semantic Segmentation of satellite and street view images. The novelty of the proposed architecture is the integration of Knowledge Distillation to reduce communication cost and response time. The accuracy obtained was above 95% and we also brought in a significant model compression to over 17 times and 62 times for street View and satellite images respectively. Our proposed framework has the potential to be a game-changer in real-time tracking of climate change across the planet.","created":"2022-12-05","meta":{"link":"http://arxiv.org/abs/2212.02196v1","tag":"medical-cv"}}
{"title":"Supervised machine learning on Galactic filaments Revealing the filamentary structure of the Galactic interstellar medium","abstract":"Context. Filaments are ubiquitous in the Galaxy, and they host star formation. Detecting them in a reliable way is therefore key towards our understanding of the star formation process.   Aims. We explore whether supervised machine learning can identify filamentary structures on the whole Galactic plane.   Methods. We used two versions of UNet-based networks for image segmentation.We used H2 column density images of the Galactic plane obtained with Herschel Hi-GAL data as input data. We trained the UNet-based networks with skeletons (spine plus branches) of filaments that were extracted from these images, together with background and missing data masks that we produced. We tested eight training scenarios to determine the best scenario for our astrophysical purpose of classifying pixels as filaments.   Results. The training of the UNets allows us to create a new image of the Galactic plane by segmentation in which pixels belonging to filamentary structures are identified. With this new method, we classify more pixels (more by a factor of 2 to 7, depending on the classification threshold used) as belonging to filaments than the spine plus branches structures we used as input. New structures are revealed, which are mainly low-contrast filaments that were not detected before.We use standard metrics to evaluate the performances of the different training scenarios. This allows us to demonstrate the robustness of the method and to determine an optimal threshold value that maximizes the recovery of the input labelled pixel classification.   Conclusions. This proof-of-concept study shows that supervised machine learning can reveal filamentary structures that are present throughout the Galactic plane. The detection of these structures, including low-density and low-contrast structures that have never been seen before, offers important perspectives for the study of these filaments.","created":"2022-12-01","meta":{"link":"http://arxiv.org/abs/2212.00463v1","tag":"medical-cv"}}
{"title":"A Novel Semisupervised Contrastive Regression Framework for Forest Inventory Mapping with Multisensor Satellite Data","abstract":"Accurate mapping of forests is critical for forest management and carbon stocks monitoring. Deep learning is becoming more popular in Earth Observation (EO), however, the availability of reference data limits its potential in wide-area forest mapping. To overcome those limitations, here we introduce contrastive regression into EO based forest mapping and develop a novel semisupervised regression framework for wall-to-wall mapping of continuous forest variables. It combines supervised contrastive regression loss and semi-supervised Cross-Pseudo Regression loss. The framework is demonstrated over a boreal forest site using Copernicus Sentinel-1 and Sentinel-2 imagery for mapping forest tree height. Achieved prediction accuracies are strongly better compared to using vanilla UNet or traditional regression models, with relative RMSE of 15.1% on stand level. We expect that developed framework can be used for modeling other forest variables and EO datasets.","created":"2022-12-01","meta":{"link":"http://arxiv.org/abs/2212.00246v1","tag":"medical-cv"}}
{"title":"PlasmoID: A dataset for Indonesian malaria parasite detection and segmentation in thin blood smear","abstract":"Indonesia holds the second-highest-ranking country for the highest number of malaria cases in Southeast Asia. A different malaria parasite semantic segmentation technique based on a deep learning approach is an alternative to reduce the limitations of traditional methods. However, the main problem of the semantic segmentation technique is raised since large parasites are dominant, and the tiny parasites are suppressed. In addition, the amount and variance of data are important influences in establishing their models. In this study, we conduct two contributions. First, we collect 559 microscopic images containing 691 malaria parasites of thin blood smears. The dataset is named PlasmoID, and most data comes from rural Indonesia. PlasmoID also provides ground truth for parasite detection and segmentation purposes. Second, this study proposes a malaria parasite segmentation and detection scheme by combining Faster RCNN and a semantic segmentation technique. The proposed scheme has been evaluated on the PlasmoID dataset. It has been compared with recent studies of semantic segmentation techniques, namely UNet, ResFCN-18, DeepLabV3, DeepLabV3plus and ResUNet-18. The result shows that our proposed scheme can improve the segmentation and detection of malaria parasite performance compared to original semantic segmentation techniques.","created":"2022-11-28","meta":{"link":"http://arxiv.org/abs/2211.15105v1","tag":"medical-cv"}}
{"title":"Affine Transformation Edited and Refined Deep Neural Network for Quantitative Susceptibility Mapping","abstract":"Deep neural networks have demonstrated great potential in solving dipole inversion for Quantitative Susceptibility Mapping (QSM). However, the performances of most existing deep learning methods drastically degrade with mismatched sequence parameters such as acquisition orientation and spatial resolution. We propose an end-to-end AFfine Transformation Edited and Refined (AFTER) deep neural network for QSM, which is robust against arbitrary acquisition orientation and spatial resolution up to 0.6 mm isotropic at the finest. The AFTER-QSM neural network starts with a forward affine transformation layer, followed by an Unet for dipole inversion, then an inverse affine transformation layer, followed by a Residual Dense Network (RDN) for QSM refinement. Simulation and in-vivo experiments demonstrated that the proposed AFTER-QSM network architecture had excellent generalizability. It can successfully reconstruct susceptibility maps from highly oblique and anisotropic scans, leading to the best image quality assessments in simulation tests and suppressed streaking artifacts and noise levels for in-vivo experiments compared with other methods. Furthermore, ablation studies showed that the RDN refinement network significantly reduced image blurring and susceptibility underestimation due to affine transformations. In addition, the AFTER-QSM network substantially shortened the reconstruction time from minutes using conventional methods to only a few seconds.","created":"2022-11-25","meta":{"link":"http://arxiv.org/abs/2211.13942v1","tag":"medical-cv"}}
{"title":"Artificial Intelligence-based Eosinophil Counting in Gastrointestinal Biopsies","abstract":"Normally eosinophils are present in the gastrointestinal (GI) tract of healthy individuals. When the eosinophils increase beyond their usual amount in the GI tract, a patient gets varied symptoms. Clinicians find it difficult to diagnose this condition called eosinophilia. Early diagnosis can help in treating patients. Histopathology is the gold standard in the diagnosis for this condition. As this is an under-diagnosed condition, counting eosinophils in the GI tract biopsies is important. In this study, we trained and tested a deep neural network based on UNet to detect and count eosinophils in GI tract biopsies. We used connected component analysis to extract the eosinophils. We studied correlation of eosinophilic infiltration counted by AI with a manual count. GI tract biopsy slides were stained with H&E stain. Slides were scanned using a camera attached to a microscope and five high-power field images were taken per slide. Pearson correlation coefficient was 85% between the machine-detected and manual eosinophil counts on 300 held-out (test) images.","created":"2022-11-25","meta":{"link":"http://arxiv.org/abs/2211.15667v1","tag":"medical-cv"}}
{"title":"Mediastinal Lymph Node Detection and Segmentation Using Deep Learning","abstract":"Automatic lymph node (LN) segmentation and detection for cancer staging are critical. In clinical practice, computed tomography (CT) and positron emission tomography (PET) imaging detect abnormal LNs. Despite its low contrast and variety in nodal size and form, LN segmentation remains a challenging task. Deep convolutional neural networks frequently segment items in medical photographs. Most state-of-the-art techniques destroy image's resolution through pooling and convolution. As a result, the models provide unsatisfactory results. Keeping the issues in mind, a well-established deep learning technique UNet was modified using bilinear interpolation and total generalized variation (TGV) based upsampling strategy to segment and detect mediastinal lymph nodes. The modified UNet maintains texture discontinuities, selects noisy areas, searches appropriate balance points through backpropagation, and recreates image resolution. Collecting CT image data from TCIA, 5-patients, and ELCAP public dataset, a dataset was prepared with the help of experienced medical experts. The UNet was trained using those datasets, and three different data combinations were utilized for testing. Utilizing the proposed approach, the model achieved 94.8% accuracy, 91.9% Jaccard, 94.1% recall, and 93.1% precision on COMBO_3. The performance was measured on different datasets and compared with state-of-the-art approaches. The UNet++ model with hybridized strategy performed better than others.","created":"2022-11-24","meta":{"link":"http://arxiv.org/abs/2212.11956v1","tag":"medical-cv"}}
{"title":"ISIM: Iterative Self-Improved Model for Weakly Supervised Segmentation","abstract":"Weakly Supervised Semantic Segmentation (WSSS) is a challenging task aiming to learn the segmentation labels from class-level labels. In the literature, exploiting the information obtained from Class Activation Maps (CAMs) is widely used for WSSS studies. However, as CAMs are obtained from a classification network, they are interested in the most discriminative parts of the objects, producing non-complete prior information for segmentation tasks. In this study, to obtain more coherent CAMs with segmentation labels, we propose a framework that employs an iterative approach in a modified encoder-decoder-based segmentation model, which simultaneously supports classification and segmentation tasks. As no ground-truth segmentation labels are given, the same model also generates the pseudo-segmentation labels with the help of dense Conditional Random Fields (dCRF). As a result, the proposed framework becomes an iterative self-improved model. The experiments performed with DeepLabv3 and UNet models show a significant gain on the Pascal VOC12 dataset, and the DeepLabv3 application increases the current state-of-the-art metric by %2.5. The implementation associated with the experiments can be found: https://github.com/cenkbircanoglu/isim.","created":"2022-11-22","meta":{"link":"http://arxiv.org/abs/2211.12455v2","tag":"medical-cv"}}
{"title":"PMNet: Robust Pathloss Map Prediction via Supervised Learning","abstract":"Pathloss prediction is an essential component of wireless network planning. While ray-tracing based methods have been successfully used for many years, they require significant computational effort that may become prohibitive with the increased network densification and/or use of higher frequencies in 5G/B5G (beyond 5 G) systems. In this paper, we propose and evaluate a data-driven and model-free pathloss prediction method, dubbed PMNet. This method uses a supervised learning approach: training a neural network (NN) with a limited amount of ray tracing (or channel measurement) data and map data and then predicting the pathloss over location with no ray tracing data with a high level of accuracy. Our proposed pathloss map prediction-oriented NN architecture, which is empowered by state-of-the-art computer vision techniques, outperforms other architectures that have been previously proposed (e.g., UNet, RadioUNet) in terms of accuracy while showing generalization capability. Moreover, PMNet trained on a 4-fold smaller dataset surpasses the other baselines (trained on a 4-fold larger dataset), corroborating the potential of PMNet.","created":"2022-11-18","meta":{"link":"http://arxiv.org/abs/2211.10527v1","tag":"medical-cv"}}
{"title":"Deep Learning-based galaxy image deconvolution","abstract":"With the onset of large-scale astronomical surveys capturing millions of images, there is an increasing need to develop fast and accurate deconvolution algorithms that generalize well to different images. A powerful and accessible deconvolution method would allow for the reconstruction of a cleaner estimation of the sky. The deconvolved images would be helpful to perform photometric measurements to help make progress in the fields of galaxy formation and evolution. We propose a new deconvolution method based on the Learnlet transform. Eventually, we investigate and compare the performance of different Unet architectures and Learnlet for image deconvolution in the astrophysical domain by following a two-step approach: a Tikhonov deconvolution with a closed-form solution, followed by post-processing with a neural network. To generate our training dataset, we extract HST cutouts from the CANDELS survey in the F606W filter (V-band) and corrupt these images to simulate their blurred-noisy versions. Our numerical results based on these simulations show a detailed comparison between the considered methods for different noise levels.","created":"2022-11-17","meta":{"link":"http://arxiv.org/abs/2211.09597v1","tag":"medical-cv"}}
{"title":"Enabling Collagen Quantification on HE-stained Slides Through Stain Deconvolution and Restained HE-HES","abstract":"In histology, the presence of collagen in the extra-cellular matrix has both diagnostic and prognostic value for cancer malignancy, and can be highlighted by adding Saffron (S) to a routine Hematoxylin and Eosin (HE) staining. However, Saffron is not usually added because of the additional cost and because pathologists are accustomed to HE, with the exception of France-based laboratories. In this paper, we show that it is possible to quantify the collagen content from the HE image alone and to digitally create an HES image. To do so, we trained a UNet to predict the Saffron densities from HE images. We created a dataset of registered, restained HE-HES slides and we extracted the Saffron concentrations as ground truth using stain deconvolution on the HES images. Our model reached a Mean Absolute Error of 0.0668 $\\pm$ 0.0002 (Saffron values between 0 and 1) on a 3-fold testing set. We hope our approach can aid in improving the clinical workflow while reducing reagent costs for laboratories.","created":"2022-11-17","meta":{"link":"http://arxiv.org/abs/2211.09566v1","tag":"medical-cv"}}
{"title":"Prompt Tuning for Parameter-efficient Medical Image Segmentation","abstract":"Neural networks pre-trained on a self-supervision scheme have become the standard when operating in data rich environments with scarce annotations. As such, fine-tuning a model to a downstream task in a parameter-efficient but effective way, e.g. for a new set of classes in the case of semantic segmentation, is of increasing importance. In this work, we propose and investigate several contributions to achieve a parameter-efficient but effective adaptation for semantic segmentation on two medical imaging datasets. Relying on the recently popularized prompt tuning approach, we provide a prompt-able UNet (PUNet) architecture, that is frozen after pre-training, but adaptable throughout the network by class-dependent learnable prompt tokens. We pre-train this architecture with a dedicated dense self-supervision scheme based on assignments to online generated prototypes (contrastive prototype assignment, CPA) of a student teacher combination alongside a concurrent segmentation loss on a subset of classes. We demonstrate that the resulting neural network model is able to attenuate the gap between fully fine-tuned and parameter-efficiently adapted models on CT imaging datasets. As such, the difference between fully fine-tuned and prompt-tuned variants amounts to only 3.83 pp for the TCIA/BTCV dataset and 2.67 pp for the CT-ORG dataset in the mean Dice Similarity Coefficient (DSC, in %) while only prompt tokens, corresponding to 0.85% of the pre-trained backbone model with 6.8M frozen parameters, are adjusted. The code for this work is available on https://github.com/marcdcfischer/PUNet .","created":"2022-11-16","meta":{"link":"http://arxiv.org/abs/2211.09233v1","tag":"medical-cv"}}
{"title":"Deep Learning for Rapid Landslide Detection using Synthetic Aperture Radar (SAR) Datacubes","abstract":"With climate change predicted to increase the likelihood of landslide events, there is a growing need for rapid landslide detection technologies that help inform emergency responses. Synthetic Aperture Radar (SAR) is a remote sensing technique that can provide measurements of affected areas independent of weather or lighting conditions. Usage of SAR, however, is hindered by domain knowledge that is necessary for the pre-processing steps and its interpretation requires expert knowledge. We provide simplified, pre-processed, machine-learning ready SAR datacubes for four globally located landslide events obtained from several Sentinel-1 satellite passes before and after a landslide triggering event together with segmentation maps of the landslides. From this dataset, using the Hokkaido, Japan datacube, we study the feasibility of SAR-based landslide detection with supervised deep learning (DL). Our results demonstrate that DL models can be used to detect landslides from SAR data, achieving an Area under the Precision-Recall curve exceeding 0.7. We find that additional satellite visits enhance detection performance, but that early detection is possible when SAR data is combined with terrain information from a digital elevation model. This can be especially useful for time-critical emergency interventions. Code is made publicly available at https://github.com/iprapas/landslide-sar-unet.","created":"2022-11-05","meta":{"link":"http://arxiv.org/abs/2211.02869v1","tag":"medical-cv"}}
{"title":"NLP Inspired Training Mechanics For Modeling Transient Dynamics","abstract":"In recent years, Machine learning (ML) techniques developed for Natural Language Processing (NLP) have permeated into developing better computer vision algorithms. In this work, we use such NLP-inspired techniques to improve the accuracy, robustness and generalizability of ML models for simulating transient dynamics. We introduce teacher forcing and curriculum learning based training mechanics to model vortical flows and show an enhancement in accuracy for ML models, such as FNO and UNet by more than 50%.","created":"2022-11-04","meta":{"link":"http://arxiv.org/abs/2211.02716v1","tag":"medical-cv"}}
{"title":"MALUNet: A Multi-Attention and Light-weight UNet for Skin Lesion Segmentation","abstract":"Recently, some pioneering works have preferred applying more complex modules to improve segmentation performances. However, it is not friendly for actual clinical environments due to limited computing resources. To address this challenge, we propose a light-weight model to achieve competitive performances for skin lesion segmentation at the lowest cost of parameters and computational complexity so far. Briefly, we propose four modules: (1) DGA consists of dilated convolution and gated attention mechanisms to extract global and local feature information; (2) IEA, which is based on external attention to characterize the overall datasets and enhance the connection between samples; (3) CAB is composed of 1D convolution and fully connected layers to perform a global and local fusion of multi-stage features to generate attention maps at channel axis; (4) SAB, which operates on multi-stage features by a shared 2D convolution to generate attention maps at spatial axis. We combine four modules with our U-shape architecture and obtain a light-weight medical image segmentation model dubbed as MALUNet. Compared with UNet, our model improves the mIoU and DSC metrics by 2.39% and 1.49%, respectively, with a 44x and 166x reduction in the number of parameters and computational complexity. In addition, we conduct comparison experiments on two skin lesion segmentation datasets (ISIC2017 and ISIC2018). Experimental results show that our model achieves state-of-the-art in balancing the number of parameters, computational complexity and segmentation performances. Code is available at https://github.com/JCruan519/MALUNet.","created":"2022-11-03","meta":{"link":"http://arxiv.org/abs/2211.01784v1","tag":"medical-cv"}}
{"title":"Fourier Disentangled Multimodal Prior Knowledge Fusion for Red Nucleus Segmentation in Brain MRI","abstract":"Early and accurate diagnosis of parkinsonian syndromes is critical to provide appropriate care to patients and for inclusion in therapeutic trials. The red nucleus is a structure of the midbrain that plays an important role in these disorders. It can be visualized using iron-sensitive magnetic resonance imaging (MRI) sequences. Different iron-sensitive contrasts can be produced with MRI. Combining such multimodal data has the potential to improve segmentation of the red nucleus. Current multimodal segmentation algorithms are computationally consuming, cannot deal with missing modalities and need annotations for all modalities. In this paper, we propose a new model that integrates prior knowledge from different contrasts for red nucleus segmentation. The method consists of three main stages. First, it disentangles the image into high-level information representing the brain structure, and low-frequency information representing the contrast. The high-frequency information is then fed into a network to learn anatomical features, while the list of multimodal low-frequency information is processed by another module. Finally, feature fusion is performed to complete the segmentation task. The proposed method was used with several iron-sensitive contrasts (iMag, QSM, R2*, SWI). Experiments demonstrate that our proposed model substantially outperforms a baseline UNet model when the training set size is very small.","created":"2022-11-02","meta":{"link":"http://arxiv.org/abs/2211.01353v1","tag":"medical-cv"}}
{"title":"Comparison of two artificial neural networks trained for the surrogate modeling of stress in materially heterogeneous elastoplastic solids","abstract":"The purpose of this work is the systematic comparison of the application of two artificial neural networks (ANNs) to the surrogate modeling of the stress field in materially heterogeneous periodic polycrystalline microstructures. The first ANN is a UNet-based convolutional neural network (CNN) for periodic data, and the second is based on Fourier neural operators (FNO). Both of these were trained, validated, and tested with results from the numerical solution of the boundary-value problem (BVP) for quasi-static mechanical equilibrium in periodic grain microstructures with square domains. More specifically, these ANNs were trained to correlate the spatial distribution of material properties with the equilibrium stress field under uniaxial tensile loading. The resulting trained ANNs (tANNs) calculate the stress field for a given microstructure on the order of 1000 (UNet) to 2500 (FNO) times faster than the numerical solution of the corresponding BVP.   For microstructures in the test dataset, the FNO-based tANN, or simply FNO, is more accurate than its UNet-based counterpart; the normalized mean absolute error of different stress components for the former is 0.25-0.40% as compared to 1.41-2.15% for the latter. Errors in FNO are restricted to grain boundary regions, whereas the error in U-Net also comes from within the grain. In comparison to U-Net, errors in FNO are more robust to large variations in spatial resolution as well as small variations in grain density. On other hand, errors in U-Net are robust to variations in boundary box aspect ratio, whereas errors in FNO increase as the domain becomes rectangular. Both tANNs are however unable to reproduce strong stress gradients, especially around regions of stress concentration.","created":"2022-10-31","meta":{"link":"http://arxiv.org/abs/2210.16994v1","tag":"medical-cv"}}
{"title":"Self-Supervised Learning with Multi-View Rendering for 3D Point Cloud Analysis","abstract":"Recently, great progress has been made in 3D deep learning with the emergence of deep neural networks specifically designed for 3D point clouds. These networks are often trained from scratch or from pre-trained models learned purely from point cloud data. Inspired by the success of deep learning in the image domain, we devise a novel pre-training technique for better model initialization by utilizing the multi-view rendering of the 3D data. Our pre-training is self-supervised by a local pixel/point level correspondence loss computed from perspective projection and a global image/point cloud level loss based on knowledge distillation, thus effectively improving upon popular point cloud networks, including PointNet, DGCNN and SR-UNet. These improved models outperform existing state-of-the-art methods on various datasets and downstream tasks. We also analyze the benefits of synthetic and real data for pre-training, and observe that pre-training on synthetic data is also useful for high-level downstream tasks. Code and pre-trained models are available at https://github.com/VinAIResearch/selfsup_pcd.","created":"2022-10-28","meta":{"link":"http://arxiv.org/abs/2210.15904v1","tag":"medical-cv"}}
{"title":"UNet-2022: Exploring Dynamics in Non-isomorphic Architecture","abstract":"Recent medical image segmentation models are mostly hybrid, which integrate self-attention and convolution layers into the non-isomorphic architecture. However, one potential drawback of these approaches is that they failed to provide an intuitive explanation of why this hybrid combination manner is beneficial, making it difficult for subsequent work to make improvements on top of them. To address this issue, we first analyze the differences between the weight allocation mechanisms of the self-attention and convolution. Based on this analysis, we propose to construct a parallel non-isomorphic block that takes the advantages of self-attention and convolution with simple parallelization. We name the resulting U-shape segmentation model as UNet-2022. In experiments, UNet-2022 obviously outperforms its counterparts in a range segmentation tasks, including abdominal multi-organ segmentation, automatic cardiac diagnosis, neural structures segmentation, and skin lesion segmentation, sometimes surpassing the best performing baseline by 4%. Specifically, UNet-2022 surpasses nnUNet, the most recognized segmentation model at present, by large margins. These phenomena indicate the potential of UNet-2022 to become the model of choice for medical image segmentation.","created":"2022-10-27","meta":{"link":"http://arxiv.org/abs/2210.15566v1","tag":"medical-cv"}}
{"title":"2T-UNET: A Two-Tower UNet with Depth Clues for Robust Stereo Depth Estimation","abstract":"Stereo correspondence matching is an essential part of the multi-step stereo depth estimation process. This paper revisits the depth estimation problem, avoiding the explicit stereo matching step using a simple two-tower convolutional neural network. The proposed algorithm is entitled as 2T-UNet. The idea behind 2T-UNet is to replace cost volume construction with twin convolution towers. These towers have an allowance for different weights between them. Additionally, the input for twin encoders in 2T-UNet are different compared to the existing stereo methods. Generally, a stereo network takes a right and left image pair as input to determine the scene geometry. However, in the 2T-UNet model, the right stereo image is taken as one input and the left stereo image along with its monocular depth clue information, is taken as the other input. Depth clues provide complementary suggestions that help enhance the quality of predicted scene geometry. The 2T-UNet surpasses state-of-the-art monocular and stereo depth estimation methods on the challenging Scene flow dataset, both quantitatively and qualitatively. The architecture performs incredibly well on complex natural scenes, highlighting its usefulness for various real-time applications. Pretrained weights and code will be made readily available.","created":"2022-10-27","meta":{"link":"http://arxiv.org/abs/2210.15374v1","tag":"medical-cv"}}
{"title":"FAS-UNet: A Novel FAS-driven Unet to Learn Variational Image Segmentation","abstract":"Solving variational image segmentation problems with hidden physics is often expensive and requires different algorithms and manually tunes model parameter. The deep learning methods based on the U-Net structure have obtained outstanding performances in many different medical image segmentation tasks, but designing such networks requires a lot of parameters and training data, not always available for practical problems. In this paper, inspired by traditional multi-phase convexity Mumford-Shah variational model and full approximation scheme (FAS) solving the nonlinear systems, we propose a novel variational-model-informed network (denoted as FAS-Unet) that exploits the model and algorithm priors to extract the multi-scale features. The proposed model-informed network integrates image data and mathematical models, and implements them through learning a few convolution kernels. Based on the variational theory and FAS algorithm, we first design a feature extraction sub-network (FAS-Solution module) to solve the model-driven nonlinear systems, where a skip-connection is employed to fuse the multi-scale features. Secondly, we further design a convolution block to fuse the extracted features from the previous stage, resulting in the final segmentation possibility. Experimental results on three different medical image segmentation tasks show that the proposed FAS-Unet is very competitive with other state-of-the-art methods in qualitative, quantitative and model complexity evaluations. Moreover, it may also be possible to train specialized network architectures that automatically satisfy some of the mathematical and physical laws in other image problems for better accuracy, faster training and improved generalization.The code is available at \\url{https://github.com/zhuhui100/FASUNet}.","created":"2022-10-27","meta":{"link":"http://arxiv.org/abs/2210.15164v2","tag":"medical-cv"}}
{"title":"Reconstruction from edge image combined with color and gradient difference for industrial surface anomaly detection","abstract":"Reconstruction-based methods are widely explored in industrial visual anomaly detection. Such methods commonly require the model to well reconstruct the normal patterns but fail in the anomalies, and thus the anomalies can be detected by evaluating the reconstruction errors. However, in practice, it's usually difficult to control the generalization boundary of the model. The model with an overly strong generalization capability can even well reconstruct the abnormal regions, making them less distinguishable, while the model with a poor generalization capability can not reconstruct those changeable high-frequency components in the normal regions, which ultimately leads to false positives. To tackle the above issue, we propose a new reconstruction network where we reconstruct the original RGB image from its gray value edges (EdgRec). Specifically, this is achieved by an UNet-type denoising autoencoder with skip connections. The input edge and skip connections can well preserve the high-frequency information in the original image. Meanwhile, the proposed restoration task can force the network to memorize the normal low-frequency and color information. Besides, the denoising design can prevent the model from directly copying the original high-frequent components. To evaluate the anomalies, we further propose a new interpretable hand-crafted evaluation function that considers both the color and gradient differences. Our method achieves competitive results on the challenging benchmark MVTec AD (97.8\\% for detection and 97.7\\% for localization, AUROC). In addition, we conduct experiments on the MVTec 3D-AD dataset and show convincing results using RGB images only. Our code will be available at https://github.com/liutongkun/EdgRec.","created":"2022-10-26","meta":{"link":"http://arxiv.org/abs/2210.14485v1","tag":"medical-cv"}}
{"title":"MEW-UNet: Multi-axis representation learning in frequency domain for medical image segmentation","abstract":"Recently, Visual Transformer (ViT) has been widely used in various fields of computer vision due to applying self-attention mechanism in the spatial domain to modeling global knowledge. Especially in medical image segmentation (MIS), many works are devoted to combining ViT and CNN, and even some works directly utilize pure ViT-based models. However, recent works improved models in the aspect of spatial domain while ignoring the importance of frequency domain information. Therefore, we propose Multi-axis External Weights UNet (MEW-UNet) for MIS based on the U-shape architecture by replacing self-attention in ViT with our Multi-axis External Weights block. Specifically, our block performs a Fourier transform on the three axes of the input feature and assigns the external weight in the frequency domain, which is generated by our Weights Generator. Then, an inverse Fourier transform is performed to change the features back to the spatial domain. We evaluate our model on four datasets and achieve state-of-the-art performances. In particular, on the Synapse dataset, our method outperforms MT-UNet by 10.15mm in terms of HD95. Code is available at https://github.com/JCruan519/MEW-UNet.","created":"2022-10-25","meta":{"link":"http://arxiv.org/abs/2210.14007v1","tag":"medical-cv"}}
{"title":"Aboveground carbon biomass estimate with Physics-informed deep network","abstract":"The global carbon cycle is a key process to understand how our climate is changing. However, monitoring the dynamics is difficult because a high-resolution robust measurement of key state parameters including the aboveground carbon biomass (AGB) is required. Here, we use deep neural network to generate a wall-to-wall map of AGB within the Continental USA (CONUS) with 30-meter spatial resolution for the year 2021. We combine radar and optical hyperspectral imagery, with a physical climate parameter of SIF-based GPP. Validation results show that a masked variation of UNet has the lowest validation RMSE of 37.93 $\\pm$ 1.36 Mg C/ha, as compared to 52.30 $\\pm$ 0.03 Mg C/ha for random forest algorithm. Furthermore, models that learn from SIF-based GPP in addition to radar and optical imagery reduce validation RMSE by almost 10% and the standard deviation by 40%. Finally, we apply our model to measure losses in AGB from the recent 2021 Caldor wildfire in California, and validate our analysis with Sentinel-based burn index.","created":"2022-10-25","meta":{"link":"http://arxiv.org/abs/2210.13752v1","tag":"medical-cv"}}
{"title":"ConnectedUNets++: Mass Segmentation from Whole Mammographic Images","abstract":"Deep learning has made a breakthrough in medical image segmentation in recent years due to its ability to extract high-level features without the need for prior knowledge. In this context, U-Net is one of the most advanced medical image segmentation models, with promising results in mammography. Despite its excellent overall performance in segmenting multimodal medical images, the traditional U-Net structure appears to be inadequate in various ways. There are certain U-Net design modifications, such as MultiResUNet, Connected-UNets, and AU-Net, that have improved overall performance in areas where the conventional U-Net architecture appears to be deficient. Following the success of UNet and its variants, we have presented two enhanced versions of the Connected-UNets architecture: ConnectedUNets+ and ConnectedUNets++. In ConnectedUNets+, we have replaced the simple skip connections of Connected-UNets architecture with residual skip connections, while in ConnectedUNets++, we have modified the encoder-decoder structure along with employing residual skip connections. We have evaluated our proposed architectures on two publicly available datasets, the Curated Breast Imaging Subset of Digital Database for Screening Mammography (CBIS-DDSM) and INbreast.","created":"2022-10-25","meta":{"link":"http://arxiv.org/abs/2210.13668v3","tag":"medical-cv"}}
{"title":"Large Batch and Patch Size Training for Medical Image Segmentation","abstract":"Multi-organ segmentation enables organ evaluation, accounts the relationship between multiple organs, and facilitates accurate diagnosis and treatment decisions. However, only few models can perform segmentation accurately because of the lack of datasets and computational resources. On AMOS2022 challenge, which is a large-scale, clinical, and diverse abdominal multiorgan segmentation benchmark, we trained a 3D-UNet model with large batch and patch sizes using multi-GPU distributed training. Segmentation performance tended to increase for models with large batch and patch sizes compared with the baseline settings. The accuracy was further improved by using ensemble models that were trained with different settings. These results provide a reference for parameter selection in organ segmentation.","created":"2022-10-24","meta":{"link":"http://arxiv.org/abs/2210.13364v1","tag":"medical-cv"}}
{"title":"MS-DCANet: A MLP-based Multi-Scale Feature Framework For COVID-19 Infection Segmentation From Medical Images","abstract":"Coronavirus Disease 2019(COVID-19) spread rapidly around the world, causing a series of severe health crises. Automated segmentation of lung infections based on Deep Convolutional Neural Network(DCNN) from medical images such as CT, X-ray, etc, displayed a huge potential for accurate diagnosis and quantitative analysis. Most COVID-19 medical images show blurred boundaries, dense noise points, low contrast, and significant variation in the shape and size of lesions. Although various models based on UNet have been proposed, more optimisation is required to obtain accurate segmentation and meet complex computational needs. Furthermore, the existing COVID-19 infections segmentation DCNN based methods are only suitable for single modality medical images. To solve these problems, this paper proposes a symmetric Encoder-Decoder segmentation framework named MS-DCANet. We introduce Tokenized MLP block, a novel attention scheme that uses a shift-window mechanism similar to the Transformer to acquire self-attention and achieve local-to-global semantic dependency. MS-DCANet also uses several Dual Channel blocks and a Res-ASPP block to expand the receptive field and extract multi-scale features. In a large number of experiments on COVID-19 datasets using both X-ray and CT images, MS-DCANet achieved state-of-the-art performance compared with other UNet models. MS-DCANet can also improve trade-off accuracy and complexity. To prove the proposed model's strong generalisability, we also apply MS-DCANet to the segmentation of skin tumours from dermoscopy images and hand bone from X-ray images with satisfactory results.","created":"2022-10-22","meta":{"link":"http://arxiv.org/abs/2210.12361v2","tag":"medical-cv"}}
{"title":"MGTUNet: An new UNet for colon nuclei instance segmentation and quantification","abstract":"Colorectal cancer (CRC) is among the top three malignant tumor types in terms of morbidity and mortality. Histopathological images are the gold standard for diagnosing colon cancer. Cellular nuclei instance segmentation and classification, and nuclear component regression tasks can aid in the analysis of the tumor microenvironment in colon tissue. Traditional methods are still unable to handle both types of tasks end-to-end at the same time, and have poor prediction accuracy and high application costs. This paper proposes a new UNet model for handling nuclei based on the UNet framework, called MGTUNet, which uses Mish, Group normalization and transposed convolution layer to improve the segmentation model, and a ranger optimizer to adjust the SmoothL1Loss values. Secondly, it uses different channels to segment and classify different types of nucleus, ultimately completing the nuclei instance segmentation and classification task, and the nuclei component regression task simultaneously. Finally, we did extensive comparison experiments using eight segmentation models. By comparing the three evaluation metrics and the parameter sizes of the models, MGTUNet obtained 0.6254 on PQ, 0.6359 on mPQ, and 0.8695 on R2. Thus, the experiments demonstrated that MGTUNet is now a state-of-the-art method for quantifying histopathological images of colon cancer.","created":"2022-10-20","meta":{"link":"http://arxiv.org/abs/2210.10981v1","tag":"medical-cv"}}
{"title":"Motion correction in MRI using deep learning and a novel hybrid loss function","abstract":"Purpose To develop and evaluate a deep learning-based method (MC-Net) to suppress motion artifacts in brain magnetic resonance imaging (MRI). Methods MC-Net was derived from a UNet combined with a two-stage multi-loss function. T1-weighted axial brain images contaminated with synthetic motions were used to train the network. Evaluation used simulated T1 and T2-weighted axial, coronal, and sagittal images unseen during training, as well as T1-weighted images with motion artifacts from real scans. Performance indices included the peak signal to noise ratio (PSNR), structural similarity index measure (SSIM), and visual reading scores. Two clinical readers scored the images. Results The MC-Net outperformed other methods implemented in terms of PSNR and SSIM on the T1 axial test set. The MC-Net significantly improved the quality of all T1-weighted images (for all directions and for simulated as well as real motion artifacts), both on quantitative measures and visual scores. However, the MC-Net performed poorly on images of untrained contrast (T2-weighted). Conclusion The proposed two-stage multi-loss MC-Net can effectively suppress motion artifacts in brain MRI without compromising image context. Given the efficiency of the MC-Net (single image processing time ~40ms), it can potentially be used in real clinical settings. To facilitate further research, the code and trained model are available at https://github.com/MRIMoCo/DL_Motion_Correction.","created":"2022-10-19","meta":{"link":"http://arxiv.org/abs/2210.14156v1","tag":"medical-cv"}}
{"title":"Swinv2-Imagen: Hierarchical Vision Transformer Diffusion Models for Text-to-Image Generation","abstract":"Recently, diffusion models have been proven to perform remarkably well in text-to-image synthesis tasks in a number of studies, immediately presenting new study opportunities for image generation. Google's Imagen follows this research trend and outperforms DALLE2 as the best model for text-to-image generation. However, Imagen merely uses a T5 language model for text processing, which cannot ensure learning the semantic information of the text. Furthermore, the Efficient UNet leveraged by Imagen is not the best choice in image processing. To address these issues, we propose the Swinv2-Imagen, a novel text-to-image diffusion model based on a Hierarchical Visual Transformer and a Scene Graph incorporating a semantic layout. In the proposed model, the feature vectors of entities and relationships are extracted and involved in the diffusion model, effectively improving the quality of generated images. On top of that, we also introduce a Swin-Transformer-based UNet architecture, called Swinv2-Unet, which can address the problems stemming from the CNN convolution operations. Extensive experiments are conducted to evaluate the performance of the proposed model by using three real-world datasets, i.e., MSCOCO, CUB and MM-CelebA-HQ. The experimental results show that the proposed Swinv2-Imagen model outperforms several popular state-of-the-art methods.","created":"2022-10-18","meta":{"link":"http://arxiv.org/abs/2210.09549v1","tag":"medical-cv"}}
{"title":"spatial-dccrn: dccrn equipped with frame-level angle feature and hybrid filtering for multi-channel speech enhancement","abstract":"Recently, multi-channel speech enhancement has drawn much interest due to the use of spatial information to distinguish target speech from interfering signal. To make full use of spatial information and neural network based masking estimation, we propose a multi-channel denoising neural network -- Spatial DCCRN. Firstly, we extend S-DCCRN to multi-channel scenario, aiming at performing cascaded sub-channel and full-channel processing strategy, which can model different channels separately. Moreover, instead of only adopting multi-channel spectrum or concatenating first-channel's magnitude and IPD as the model's inputs, we apply an angle feature extraction module (AFE) to extract frame-level angle feature embeddings, which can help the model to apparently perceive spatial information. Finally, since the phenomenon of residual noise will be more serious when the noise and speech exist in the same time frequency (TF) bin, we particularly design a masking and mapping filtering method to substitute the traditional filter-and-sum operation, with the purpose of cascading coarsely denoising, dereverberation and residual noise suppression. The proposed model, Spatial-DCCRN, has surpassed EaBNet, FasNet as well as several competitive models on the L3DAS22 Challenge dataset. Not only the 3D scenario, Spatial-DCCRN outperforms state-of-the-art (SOTA) model MIMO-UNet by a large margin in multiple evaluation metrics on the multi-channel ConferencingSpeech2021 Challenge dataset. Ablation studies also demonstrate the effectiveness of different contributions.","created":"2022-10-17","meta":{"link":"http://arxiv.org/abs/2210.08802v1","tag":"medical-cv"}}
{"title":"ResAttUNet: Detecting Marine Debris using an Attention activated Residual UNet","abstract":"Currently, a significant amount of research has been done in field of Remote Sensing with the use of deep learning techniques. The introduction of Marine Debris Archive (MARIDA), an open-source dataset with benchmark results, for marine debris detection opened new pathways to use deep learning techniques for the task of debris detection and segmentation. This paper introduces a novel attention based segmentation technique that outperforms the existing state-of-the-art results introduced with MARIDA. The paper presents a novel spatial aware encoder and decoder architecture to maintain the contextual information and structure of sparse ground truth patches present in the images. The attained results are expected to pave the path for further research involving deep learning using remote sensing images. The code is available at https://github.com/sheikhazhanmohammed/SADMA.git","created":"2022-10-16","meta":{"link":"http://arxiv.org/abs/2210.08506v1","tag":"medical-cv"}}
{"title":"Combining band-frequency separation and deep neural networks for optoacoustic imaging","abstract":"In this paper we consider the problem of image reconstruction in optoacoustic tomography. In particular, we devise a deep neural architecture that can explicitly take into account the band-frequency information contained in the sinogram. This is accomplished by two means. First, we jointly use a linear filtered back-projection method and a fully dense UNet for the generation of the images corresponding to each one of the frequency bands considered in the separation. Secondly, in order to train the model, we introduce a special loss function consisting of three terms: (i) a separating frequency bands term; (ii) a sinogram-based consistency term and (iii) a term that directly measures the quality of image reconstruction and which takes advantage of the presence of ground-truth images present in training dataset. Numerical experiments show that the proposed model, which can be easily trainable by standard optimization methods, presents an excellent generalization performance quantified by a number of metrics commonly used in practice. Also, in the testing phase, our solution has a comparable (in some cases lower) computational complexity, which is a desirable feature for real-time implementation of optoacoustic imaging.","created":"2022-10-14","meta":{"link":"http://arxiv.org/abs/2210.08099v2","tag":"medical-cv"}}
{"title":"Whole-body tumor segmentation of 18F -FDG PET/CT using a cascaded and ensembled convolutional neural networks","abstract":"Background: A crucial initial processing step for quantitative PET/CT analysis is the segmentation of tumor lesions enabling accurate feature ex-traction, tumor characterization, oncologic staging, and image-based therapy response assessment. Manual lesion segmentation is however associated with enormous effort and cost and is thus infeasible in clinical routine. Goal: The goal of this study was to report the performance of a deep neural network designed to automatically segment regions suspected of cancer in whole-body 18F-FDG PET/CT images in the context of the AutoPET challenge. Method: A cascaded approach was developed where a stacked ensemble of 3D UNET CNN processed the PET/CT images at a fixed 6mm resolution. A refiner network composed of residual layers enhanced the 6mm segmentation mask to the original resolution. Results: 930 cases were used to train the model. 50% were histologically proven cancer patients and 50% were healthy controls. We obtained a dice=0.68 on 84 stratified test cases. Manual and automatic Metabolic Tumor Volume (MTV) were highly correlated (R2 = 0.969,Slope = 0.947). Inference time was 89.7 seconds on average. Conclusion: The proposed algorithm accurately segmented regions suspicious for cancer in whole-body 18F -FDG PET/CT images.","created":"2022-10-14","meta":{"link":"http://arxiv.org/abs/2210.08068v1","tag":"medical-cv"}}
{"title":"Optimizing Vision Transformers for Medical Image Segmentation","abstract":"For medical image semantic segmentation (MISS), Vision Transformers have emerged as strong alternatives to convolutional neural networks thanks to their inherent ability to capture long-range correlations. However, existing research uses off-the-shelf vision Transformer blocks based on linear projections and feature processing which lack spatial and local context to refine organ boundaries. Furthermore, Transformers do not generalize well on small medical imaging datasets and rely on large-scale pre-training due to limited inductive biases. To address these problems, we demonstrate the design of a compact and accurate Transformer network for MISS, CS-Unet, which introduces convolutions in a multi-stage design for hierarchically enhancing spatial and local modeling ability of Transformers. This is mainly achieved by our well-designed Convolutional Swin Transformer (CST) block which merges convolutions with Multi-Head Self-Attention and Feed-Forward Networks for providing inherent localized spatial context and inductive biases. Experiments demonstrate CS-Unet without pre-training outperforms other counterparts by large margins on multi-organ and cardiac datasets with fewer parameters and achieves state-of-the-art performance. Our code is available at Github.","created":"2022-10-14","meta":{"link":"http://arxiv.org/abs/2210.08066v2","tag":"medical-cv"}}
{"title":"Towards Transformer-based Homogenization of Satellite Imagery for Landsat-8 and Sentinel-2","abstract":"Landsat-8 (NASA) and Sentinel-2 (ESA) are two prominent multi-spectral imaging satellite projects that provide publicly available data. The multi-spectral imaging sensors of the satellites capture images of the earth's surface in the visible and infrared region of the electromagnetic spectrum. Since the majority of the earth's surface is constantly covered with clouds, which are not transparent at these wavelengths, many images do not provide much information. To increase the temporal availability of cloud-free images of a certain area, one can combine the observations from multiple sources. However, the sensors of satellites might differ in their properties, making the images incompatible. This work provides a first glance at the possibility of using a transformer-based model to reduce the spectral and spatial differences between observations from both satellite projects. We compare the results to a model based on a fully convolutional UNet architecture. Somewhat surprisingly, we find that, while deep models outperform classical approaches, the UNet significantly outperforms the transformer in our experiments.","created":"2022-10-14","meta":{"link":"http://arxiv.org/abs/2210.07654v1","tag":"medical-cv"}}
{"title":"Neural Network Compression by Joint Sparsity Promotion and Redundancy Reduction","abstract":"Compression of convolutional neural network models has recently been dominated by pruning approaches. A class of previous works focuses solely on pruning the unimportant filters to achieve network compression. Another important direction is the design of sparsity-inducing constraints which has also been explored in isolation. This paper presents a novel training scheme based on composite constraints that prune redundant filters and minimize their effect on overall network learning via sparsity promotion. Also, as opposed to prior works that employ pseudo-norm-based sparsity-inducing constraints, we propose a sparse scheme based on gradient counting in our framework. Our tests on several pixel-wise segmentation benchmarks show that the number of neurons and the memory footprint of networks in the test phase are significantly reduced without affecting performance. MobileNetV3 and UNet, two well-known architectures, are used to test the proposed scheme. Our network compression method not only results in reduced parameters but also achieves improved performance compared to MobileNetv3, which is an already optimized architecture.","created":"2022-10-14","meta":{"link":"http://arxiv.org/abs/2210.07451v1","tag":"medical-cv"}}
{"title":"Corneal endothelium assessment in specular microscopy images with Fuchs' dystrophy via deep regression of signed distance maps","abstract":"Specular microscopy assessment of the human corneal endothelium (CE) in Fuchs' dystrophy is challenging due to the presence of dark image regions called guttae. This paper proposes a UNet-based segmentation approach that requires minimal post-processing and achieves reliable CE morphometric assessment and guttae identification across all degrees of Fuchs' dystrophy. We cast the segmentation problem as a regression task of the cell and gutta signed distance maps instead of a pixel-level classification task as typically done with UNets. Compared to the conventional UNet classification approach, the distance-map regression approach converges faster in clinically relevant parameters. It also produces morphometric parameters that agree with the manually-segmented ground-truth data, namely the average cell density difference of -41.9 cells/mm2 (95% confidence interval (CI) [-306.2, 222.5]) and the average difference of mean cell area of 14.8 um2 (95% CI [-41.9, 71.5]). These results suggest a promising alternative for CE assessment.","created":"2022-10-13","meta":{"link":"http://arxiv.org/abs/2210.07102v2","tag":"medical-cv"}}
{"title":"Digitization of Raster Logs: A Deep Learning Approach","abstract":"Raster well-log images are digital representations of well-logs data generated over the years. Raster digital well logs represent bitmaps of the log image in a rectangular array of black (zeros) and white dots (ones) called pixels. Experts study the raster logs manually or with software applications that still require a tremendous amount of manual input. Besides the loss of thousands of person-hours, this process is erroneous and tedious. To digitize these raster logs, one must buy a costly digitizer that is not only manual and time-consuming but also a hidden technical debt since enterprises stand to lose more money in additional servicing and consulting charges. We propose a deep neural network architecture called VeerNet to semantically segment the raster images from the background grid and classify and digitize the well-log curves. Raster logs have a substantially greater resolution than images traditionally consumed by image segmentation pipelines. Since the input has a low signal-to-resolution ratio, we require rapid downsampling to alleviate unnecessary computation. We thus employ a modified UNet-inspired architecture that balances retaining key signals and reducing result dimensionality. We use attention augmented read-process-write architecture. This architecture efficiently classifies and digitizes the curves with an overall F1 score of 35% and IoU of 30%. When compared to the actual las values for Gamma-ray and derived value of Gamma-ray from VeerNet, a high Pearson coefficient score of 0.62 was achieved.","created":"2022-10-11","meta":{"link":"http://arxiv.org/abs/2210.05597v1","tag":"medical-cv"}}
{"title":"Improved Abdominal Multi-Organ Segmentation via 3D Boundary-Constrained Deep Neural Networks","abstract":"Quantitative assessment of the abdominal region from clinically acquired CT scans requires the simultaneous segmentation of abdominal organs. Thanks to the availability of high-performance computational resources, deep learning-based methods have resulted in state-of-the-art performance for the segmentation of 3D abdominal CT scans. However, the complex characterization of organs with fuzzy boundaries prevents the deep learning methods from accurately segmenting these anatomical organs. Specifically, the voxels on the boundary of organs are more vulnerable to misprediction due to the highly-varying intensity of inter-organ boundaries. This paper investigates the possibility of improving the abdominal image segmentation performance of the existing 3D encoder-decoder networks by leveraging organ-boundary prediction as a complementary task. To address the problem of abdominal multi-organ segmentation, we train the 3D encoder-decoder network to simultaneously segment the abdominal organs and their corresponding boundaries in CT scans via multi-task learning. The network is trained end-to-end using a loss function that combines two task-specific losses, i.e., complete organ segmentation loss and boundary prediction loss. We explore two different network topologies based on the extent of weights shared between the two tasks within a unified multi-task framework. To evaluate the utilization of complementary boundary prediction task in improving the abdominal multi-organ segmentation, we use three state-of-the-art encoder-decoder networks: 3D UNet, 3D UNet++, and 3D Attention-UNet. The effectiveness of utilizing the organs' boundary information for abdominal multi-organ segmentation is evaluated on two publically available abdominal CT datasets. A maximum relative improvement of 3.5% and 3.6% is observed in Mean Dice Score for Pancreas-CT and BTCV datasets, respectively.","created":"2022-10-09","meta":{"link":"http://arxiv.org/abs/2210.04285v1","tag":"medical-cv"}}
{"title":"Text detection and recognition based on a lensless imaging system","abstract":"Lensless cameras are characterized by several advantages (e.g., miniaturization, ease of manufacture, and low cost) as compared with conventional cameras. However, they have not been extensively employed due to their poor image clarity and low image resolution, especially for tasks that have high requirements on image quality and details such as text detection and text recognition. To address the problem, a framework of deep-learning-based pipeline structure was built to recognize text with three steps from raw data captured by employing lensless cameras. This pipeline structure consisted of the lensless imaging model U-Net, the text detection model connectionist text proposal network (CTPN), and the text recognition model convolutional recurrent neural network (CRNN). Compared with the method focusing only on image reconstruction, UNet in the pipeline was able to supplement the imaging details by enhancing factors related to character categories in the reconstruction process, so the textual information can be more effectively detected and recognized by CTPN and CRNN with fewer artifacts and high-clarity reconstructed lensless images. By performing experiments on datasets of different complexities, the applicability to text detection and recognition on lensless cameras was verified. This study reasonably demonstrates text detection and recognition tasks in the lensless camera system,and develops a basic method for novel applications.","created":"2022-10-09","meta":{"link":"http://arxiv.org/abs/2210.04244v1","tag":"medical-cv"}}
{"title":"COVID-19 Detection Using Segmentation, Region Extraction and Classification Pipeline","abstract":"The main purpose of this study is to develop a pipeline for COVID-19 detection from a big and challenging database of Computed Tomography (CT) images. The proposed pipeline includes a segmentation part, a lung extraction part, and a classifier part. Optional slice removal techniques after UNet-based segmentation of slices were also tried. The methodologies tried in the segmentation part are traditional segmentation methods as well as UNet-based methods. In the classification part, a Convolutional Neural Network (CNN) was used to take the final diagnosis decisions. In terms of the results: in the segmentation part, the proposed segmentation methods show high dice scores on a publicly available dataset. In the classification part, the results were compared at slice-level and at patient-level as well. At slice-level, methods were compared and showed high validation accuracy indicating efficiency in predicting 2D slices. At patient level, the proposed methods were also compared in terms of validation accuracy and macro F1 score on the validation set. The dataset used for classification is COV-19CT Database. The method proposed here showed improvement from our precious results on the same dataset. In Conclusion, the improved work in this paper has potential clinical usages for COVID-19 detection and diagnosis via CT images. The code is on github at https://github.com/IDU-CVLab/COV19D_3rd","created":"2022-10-06","meta":{"link":"http://arxiv.org/abs/2210.02992v4","tag":"medical-cv"}}
{"title":"Inharmonious Region Localization via Recurrent Self-Reasoning","abstract":"Synthetic images created by image editing operations are prevalent, but the color or illumination inconsistency between the manipulated region and background may make it unrealistic. Thus, it is important yet challenging to localize the inharmonious region to improve the quality of synthetic image. Inspired by the classic clustering algorithm, we aim to group pixels into two clusters: inharmonious cluster and background cluster by inserting a novel Recurrent Self-Reasoning (RSR) module into the bottleneck of UNet structure. The mask output from RSR module is provided for the decoder as attention guidance. Finally, we adaptively combine the masks from RSR and the decoder to form our final mask. Experimental results on the image harmonization dataset demonstrate that our method achieves competitive performance both quantitatively and qualitatively.","created":"2022-10-05","meta":{"link":"http://arxiv.org/abs/2210.02036v1","tag":"medical-cv"}}
{"title":"Adaptively Weighted Data Augmentation Consistency Regularization for Robust Optimization under Concept Shift","abstract":"Concept shift is a prevailing problem in natural tasks like medical image segmentation where samples usually come from different subpopulations with variant correlations between features and labels. One common type of concept shift in medical image segmentation is the \"information imbalance\" between label-sparse samples with few (if any) segmentation labels and label-dense samples with plentiful labeled pixels. Existing distributionally robust algorithms have focused on adaptively truncating/down-weighting the \"less informative\" (i.e., label-sparse in our context) samples. To exploit data features of label-sparse samples more efficiently, we propose an adaptively weighted online optimization algorithm -- AdaWAC -- to incorporate data augmentation consistency regularization in sample reweighting. Our method introduces a set of trainable weights to balance the supervised loss and unsupervised consistency regularization of each sample separately. At the saddle point of the underlying objective, the weights assign label-dense samples to the supervised loss and label-sparse samples to the unsupervised consistency regularization. We provide a convergence guarantee by recasting the optimization as online mirror descent on a saddle point problem. Our empirical results demonstrate that AdaWAC not only enhances the segmentation performance and sample efficiency but also improves the robustness to concept shift on various medical image segmentation tasks with different UNet-style backbones.","created":"2022-10-04","meta":{"link":"http://arxiv.org/abs/2210.01891v2","tag":"medical-cv"}}
{"title":"APAUNet: Axis Projection Attention UNet for Small Target in 3D Medical Segmentation","abstract":"In 3D medical image segmentation, small targets segmentation is crucial for diagnosis but still faces challenges. In this paper, we propose the Axis Projection Attention UNet, named APAUNet, for 3D medical image segmentation, especially for small targets. Considering the large proportion of the background in the 3D feature space, we introduce a projection strategy to project the 3D features into three orthogonal 2D planes to capture the contextual attention from different views. In this way, we can filter out the redundant feature information and mitigate the loss of critical information for small lesions in 3D scans. Then we utilize a dimension hybridization strategy to fuse the 3D features with attention from different axes and merge them by a weighted summation to adaptively learn the importance of different perspectives. Finally, in the APA Decoder, we concatenate both high and low resolution features in the 2D projection process, thereby obtaining more precise multi-scale information, which is vital for small lesion segmentation. Quantitative and qualitative experimental results on two public datasets (BTCV and MSD) demonstrate that our proposed APAUNet outperforms the other methods. Concretely, our APAUNet achieves an average dice score of 87.84 on BTCV, 84.48 on MSD-Liver and 69.13 on MSD-Pancreas, and significantly surpass the previous SOTA methods on small targets.","created":"2022-10-04","meta":{"link":"http://arxiv.org/abs/2210.01485v1","tag":"medical-cv"}}
{"title":"Deep-OCTA: Ensemble Deep Learning Approaches for Diabetic Retinopathy Analysis on OCTA Images","abstract":"The ultra-wide optical coherence tomography angiography (OCTA) has become an important imaging modality in diabetic retinopathy (DR) diagnosis. However, there are few researches focusing on automatic DR analysis using ultra-wide OCTA. In this paper, we present novel and practical deep-learning solutions based on ultra-wide OCTA for the Diabetic Retinopathy Analysis Challenge (DRAC). In the segmentation of DR lesions task, we utilize UNet and UNet++ to segment three lesions with strong data augmentation and model ensemble. In the image quality assessment task, we create an ensemble of InceptionV3, SE-ResNeXt, and Vision Transformer models. Pre-training on the large dataset as well as the hybrid MixUp and CutMix strategy are both adopted to boost the generalization ability of our model. In the DR grading task, we build a Vision Transformer (ViT) and fnd that the ViT model pre-trained on color fundus images serves as a useful substrate for OCTA images. Our proposed methods ranked 4th, 3rd, and 5th on the three leaderboards of DRAC, respectively. The source code will be made available at https://github.com/FDU-VTS/DRAC.","created":"2022-10-02","meta":{"link":"http://arxiv.org/abs/2210.00515v1","tag":"medical-cv"}}
{"title":"Softening of a flat phonon mode in the kagome ScV$_6$Sn$_6$","abstract":"The long range electronic modulations recently discovered in the geometrically frustrated kagome lattice have opened new avenues to explore the effect of correlations in materials with topological electron flat bands. The observation of the lattice response to the emergent new phases of matter, a soft phonon mode, has remained elusive and the microscopic origin of charge density waves (CDWs) is still unknown. Here, we show, for the first time, a complete melting of the ScV$_ 6$Sn$_ 6$ (166) kagome lattice. The low energy phonon with propagation vector $\\frac{1}{3} \\frac{1}{3} \\frac{1}{2}$ collapses at 98 K, without the emergence of long-range charge order, which sets in with a propagation vector $\\frac{1}{3} \\frac{1}{3} \\frac{1}{3}$. The CDW is driven (but locks at a different vector) by the softening of an overdamped phonon flat plane at k$_z$=$\\pi$. We observe broad phonon anomalies in momentum space, pointing to (1) the existence of approximately flat phonon bands which gain some dispersion due to electron renormalization, and (2) the effects of the momentum dependent electron-phonon interaction in the CDW formation. Ab initio and analytical calculations corroborate the experimental findings to indicate that the weak leading order phonon instability is located at the wave vector $\\frac{1}{3} \\frac{1}{3} \\frac{1}{2}$ of a rather flat collapsed mode. We analytically compute the phonon frequency renormalization from high temperatures to the soft mode, and relate it to a peak in the orbital-resolved susceptibility, obtaining an excellent match with both ab initio and experimental results, and explaining the origin of the approximately flat phonon dispersion. Our data report the first example of the collapse of a softening of a flat phonon plane and promote the 166 compounds of the kagome family as primary candidates to explore correlated flat phonon-topological flat electron physics.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09173v1","tag":"medical-cv"}}
{"title":"Hyperbolic Image-Text Representations","abstract":"Visual and linguistic concepts naturally organize themselves in a hierarchy, where a textual concept ``dog'' entails all images that contain dogs. Despite being intuitive, current large-scale vision and language models such as CLIP do not explicitly capture such hierarchy. We propose MERU, a contrastive model that yields hyperbolic representations of images and text. Hyperbolic spaces have suitable geometric properties to embed tree-like data, so MERU can better capture the underlying hierarchy in image-text data. Our results show that MERU learns a highly interpretable representation space while being competitive with CLIP's performance on multi-modal tasks like image classification and image-text retrieval.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09172v1","tag":"medical-cv"}}
{"title":"A bilevel approach for compensation and routing decisions in last-mile delivery","abstract":"In last-mile delivery logistics, peer-to-peer logistic platforms play an important role in connecting senders, customers, and independent carriers to fulfill delivery requests. Since the carriers are not under the platform's control, the platform has to anticipate their reactions, while deciding how to allocate the delivery operations. Indeed, carriers' decisions largely affect the platform's revenue. In this paper, we model this problem using bilevel programming. At the upper level, the platform decides how to assign the orders to the carriers; at the lower level, each carrier solves a profitable tour problem to determine which offered requests to accept, based on her own profit maximization. Possibly, the platform can influence carriers' decisions by determining also the compensation paid for each accepted request. The two considered settings result in two different formulations: the bilevel profitable tour problem with fixed compensation margins and with margin decisions, respectively. For each of them, we propose single-level reformulations and alternative formulations where the lower-level routing variables are projected out. A branch-and-cut algorithm is proposed to solve the bilevel models, with a tailored warm-start heuristic used to speed up the solution process. Extensive computational tests are performed to compare the proposed formulations and analyze solution characteristics.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09170v1","tag":"medical-cv"}}
{"title":"A Cross-Internal Linear Combination Approach to Probe the Secondary CMB Anisotropies: Kinematic Sunyaev-Zel{'}dovich Effect and CMB Lensing","abstract":"We propose a cross-internal linear combination (cross-ILC) approach to measure the small-scale cosmic microwave background (CMB) anisotropies robustly against the contamination from astrophysical signals. In particular, we focus on the mitigation of systematics from cosmic infrared background (CIB) and thermal Sunyaev-Zeldovich (tSZ) signals in kinematic SZ (kSZ) power spectrum and CMB lensing. We show the cross-spectrum measurement between two CMB maps created by nulling the contributions from CIB (CIB-free map) and tSZ (tSZ-free map) to be robust for kSZ as the approach significantly suppresses the total contribution of CIB and tSZ signals. Similarly, for CMB lensing, we use the approach introduced by Madhavacheril & Hill (2018) but with a slight modification by using the tSZ-free and CIB-free maps in the two legs of the quadratic estimator. By cross-correlating the CMB lensing map created using this technique with galaxy surveys, we show that the biases from both CIB/tSZ are negligible. We also compute the impact of unmodeled CIB/tSZ residuals on kSZ and cosmological parameters finding that the kSZ measured using the standard ILC to be significantly biased. The kSZ estimate from the cross-ILC remains less affected by CIB/tSZ making it crucial for CMB surveys such as the South Pole Telescope (SPT), Simons Observatory (SO) and CMB-S4. With the cross-ILC method, we find the total kSZ power spectrum can be measured at very high significance: $35\\sigma$ by SPT, $22\\sigma$ by SO, and $80\\sigma$ by CMB-S4. We forecast constraints on the epoch of reionization using the kSZ power spectrum and find that the duration of reionization, currently unconstrained by {\\it Planck}, can be constrained to $\\sigma(z_{\\rm dur})$= 1.5 (or) 0.5 depending on the choice of $\\tau_{\\rm re}$ prior. The data products and codes can be downloaded from this https://github.com/sriniraghunathan/cross_ilc_methods_paper.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09166v1","tag":"medical-cv"}}
{"title":"Structure Preserving Cycle-GAN for Unsupervised Medical Image Domain Adaptation","abstract":"The presence of domain shift in medical imaging is a common issue, which can greatly impact the performance of segmentation models when dealing with unseen image domains. Adversarial-based deep learning models, such as Cycle-GAN, have become a common model for approaching unsupervised domain adaptation of medical images. These models however, have no ability to enforce the preservation of structures of interest when translating medical scans, which can lead to potentially poor results for unsupervised domain adaptation within the context of segmentation. This work introduces the Structure Preserving Cycle-GAN (SP Cycle-GAN), which promotes medical structure preservation during image translation through the enforcement of a segmentation loss term in the overall Cycle-GAN training process. We demonstrate the structure preserving capability of the SP Cycle-GAN both visually and through comparison of Dice score segmentation performance for the unsupervised domain adaptation models. The SP Cycle-GAN is able to outperform baseline approaches and standard Cycle-GAN domain adaptation for binary blood vessel segmentation in the STARE and DRIVE datasets, and multi-class Left Ventricle and Myocardium segmentation in the multi-modal MM-WHS dataset. SP Cycle-GAN achieved a state of the art Myocardium segmentation Dice score (DSC) of 0.7435 for the MR to CT MM-WHS domain adaptation problem, and excelled in nearly all categories for the MM-WHS dataset. SP Cycle-GAN also demonstrated a strong ability to preserve blood vessel structure in the DRIVE to STARE domain adaptation problem, achieving a 4% DSC increase over a default Cycle-GAN implementation.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09164v1","tag":"medical-cv"}}
{"title":"Neural networks for geospatial data","abstract":"Analysis of geospatial data has traditionally been model-based, with a mean model, customarily specified as a linear regression on the covariates, and a covariance model, encoding the spatial dependence. We relax the strong assumption of linearity and propose embedding neural networks directly within the traditional geostatistical models to accommodate non-linear mean functions while retaining all other advantages including use of Gaussian Processes to explicitly model the spatial covariance, enabling inference on the covariate effect through the mean and on the spatial dependence through the covariance, and offering predictions at new locations via kriging. We propose NN-GLS, a new neural network estimation algorithm for the non-linear mean in GP models that explicitly accounts for the spatial covariance through generalized least squares (GLS), the same loss used in the linear case. We show that NN-GLS admits a representation as a special type of graph neural network (GNN). This connection facilitates use of standard neural network computational techniques for irregular geospatial data, enabling novel and scalable mini-batching, backpropagation, and kriging schemes. Theoretically, we show that NN-GLS will be consistent for irregularly observed spatially correlated data processes. To our knowledge this is the first asymptotic consistency result for any neural network algorithm for spatial data. We demonstrate the methodology through simulated and real datasets.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09157v1","tag":"medical-cv"}}
{"title":"Monte-Carlo method for incompressible fluid flows past obstacles","abstract":"We establish stochastic functional integral representations for incompressible fluid flows occupying wall-bounded domains using the conditional law duality for a class of diffusion processes. These representations are used to derive a Monte-Carlo scheme based on the corresponding exact random vortex formulation. We implement several numerical experiments based on the Monte-Carlo method without appealing to the boundary layer flow computations, to demonstrate the methodology.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09152v1","tag":"medical-cv"}}
{"title":"UniMax: Fairer and more Effective Language Sampling for Large-Scale Multilingual Pretraining","abstract":"Pretrained multilingual large language models have typically used heuristic temperature-based sampling to balance between different languages. However previous work has not systematically evaluated the efficacy of different pretraining language distributions across model scales. In this paper, we propose a new sampling method, UniMax, that delivers more uniform coverage of head languages while mitigating overfitting on tail languages by explicitly capping the number of repeats over each language's corpus. We perform an extensive series of ablations testing a range of sampling strategies on a suite of multilingual benchmarks, while varying model scale. We find that UniMax outperforms standard temperature-based sampling, and the benefits persist as scale increases. As part of our contribution, we release: (i) an improved and refreshed mC4 multilingual corpus consisting of 29 trillion characters across 107 languages, and (ii) a suite of pretrained umT5 model checkpoints trained with UniMax sampling.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09151v1","tag":"medical-cv"}}
{"title":"SAM Fails to Segment Anything? -- SAM-Adapter: Adapting SAM in Underperformed Scenes: Camouflage, Shadow, and More","abstract":"The emergence of large models, also known as foundation models, has brought significant advancements to AI research. One such model is Segment Anything (SAM), which is designed for image segmentation tasks. However, as with other foundation models, our experimental findings suggest that SAM may fail or perform poorly in certain segmentation tasks, such as shadow detection and camouflaged object detection (concealed object detection). This study first paves the way for applying the large pre-trained image segmentation model SAM to these downstream tasks, even in situations where SAM performs poorly. Rather than fine-tuning the SAM network, we propose \\textbf{SAM-Adapter}, which incorporates domain-specific information or visual prompts into the segmentation network by using simple yet effective adapters. Our extensive experiments show that SAM-Adapter can significantly elevate the performance of SAM in challenging tasks and we can even outperform task-specific network models and achieve state-of-the-art performance in the task we tested: camouflaged object detection and shadow detection. We believe our work opens up opportunities for utilizing SAM in downstream tasks, with potential applications in various fields, including medical image processing, agriculture, remote sensing, and more.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09148v1","tag":"medical-cv"}}
{"title":"Outlier Suppression+: Accurate quantization of large language models by equivalent and optimal shifting and scaling","abstract":"Quantization of transformer language models faces significant challenges due to the existence of detrimental outliers in activations. We observe that these outliers are asymmetric and concentrated in specific channels. To address this issue, we propose the Outlier Suppression+ framework. First, we introduce channel-wise shifting and scaling operations to eliminate asymmetric presentation and scale down problematic channels. We demonstrate that these operations can be seamlessly migrated into subsequent modules while maintaining equivalence. Second, we quantitatively analyze the optimal values for shifting and scaling, taking into account both the asymmetric property and quantization errors of weights in the next layer. Our lightweight framework can incur minimal performance degradation under static and standard post-training quantization settings. Comprehensive results across various tasks and models reveal that our approach achieves near-floating-point performance on both small models, such as BERT, and large language models (LLMs) including OPTs, BLOOM, and BLOOMZ at 8-bit and 6-bit settings. Furthermore, we establish a new state of the art for 4-bit BERT.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09145v1","tag":"medical-cv"}}
{"title":"Exploring the Trade-Offs: Unified Large Language Models vs Local Fine-Tuned Models for Highly-Specific Radiology NLI Task","abstract":"Recently, ChatGPT and GPT-4 have emerged and gained immense global attention due to their unparalleled performance in language processing. Despite demonstrating impressive capability in various open-domain tasks, their adequacy in highly specific fields like radiology remains untested. Radiology presents unique linguistic phenomena distinct from open-domain data due to its specificity and complexity. Assessing the performance of large language models (LLMs) in such specific domains is crucial not only for a thorough evaluation of their overall performance but also for providing valuable insights into future model design directions: whether model design should be generic or domain-specific. To this end, in this study, we evaluate the performance of ChatGPT/GPT-4 on a radiology NLI task and compare it to other models fine-tuned specifically on task-related data samples. We also conduct a comprehensive investigation on ChatGPT/GPT-4's reasoning ability by introducing varying levels of inference difficulty. Our results show that 1) GPT-4 outperforms ChatGPT in the radiology NLI task; 2) other specifically fine-tuned models require significant amounts of data samples to achieve comparable performance to ChatGPT/GPT-4. These findings demonstrate that constructing a generic model that is capable of solving various tasks across different domains is feasible.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09138v1","tag":"medical-cv"}}
{"title":"In and out-of-equilibrium features of hadronic layers in the low-energy limit of quantum chromodynamics","abstract":"The entanglement entropy dynamics of baryonic layers in $3+1$ dimensions in the low-energy limit of quantum chromodynamics is computed. The evolution after quantum quenches can be described explicitly. In particular, it is shown analytically that the von Neumann and R\\'{e}nyi entropies may display undamped oscillations in time, whose frequencies can be calculated in terms of the baryonic distribution of the hadronic matter in the cavity. Moreover, the Loschmidt amplitude and the fidelity and work distribution can be derived as well. These results, which are entirely unexpected in non-integrable theories such as the Skyrme model, are achieved thanks to a remarkable mapping from any $(3+1)$-dimensional hadronic distribution of matter in a cavity close to its boundary to the sine-Gordon theory in $1+1$ dimensions. In the attractive regime, such results are valid for low-enough energy scales.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09137v1","tag":"medical-cv"}}
{"title":"Detection and Classification of Glioblastoma Brain Tumor","abstract":"Glioblastoma brain tumors are highly malignant and often require early detection and accurate segmentation for effective treatment. We are proposing two deep learning models in this paper, namely UNet and Deeplabv3, for the detection and segmentation of glioblastoma brain tumors using preprocessed brain MRI images. The performance evaluation is done for these models in terms of accuracy and computational efficiency. Our experimental results demonstrate that both UNet and Deeplabv3 models achieve accurate detection and segmentation of glioblastoma brain tumors. However, Deeplabv3 outperforms UNet in terms of accuracy, albeit at the cost of requiring more computational resources. Our proposed models offer a promising approach for the early detection and segmentation of glioblastoma brain tumors, which can aid in effective treatment strategies. Further research can focus on optimizing the computational efficiency of the Deeplabv3 model while maintaining its high accuracy for real-world clinical applications. Overall, our approach works and contributes to the field of medical image analysis and deep learning-based approaches for brain tumor detection and segmentation. Our suggested models can have a major influence on the prognosis and treatment of people with glioblastoma, a fatal form of brain cancer. It is necessary to conduct more research to examine the practical use of these models in real-life healthcare settings.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09133v1","tag":"medical-cv"}}
{"title":"Independence testing for inhomogeneous random graphs","abstract":"Testing for independence between graphs is a problem that arises naturally in social network analysis and neuroscience. In this paper, we address independence testing for inhomogeneous Erd\\H{o}s-R\\'{e}nyi random graphs on the same vertex set. We first formulate a notion of pairwise correlations between the edges of these graphs and derive a necessary condition for their detectability. We next show that the problem can exhibit a statistical vs. computational tradeoff, i.e., there are regimes for which the correlations are statistically detectable but may require algorithms whose running time is exponential in n, the number of vertices. Finally, we consider a special case of correlation testing when the graphs are sampled from a latent space model (graphon) and propose an asymptotically valid and consistent test procedure that also runs in time polynomial in n.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09132v1","tag":"medical-cv"}}
{"title":"Variational Relational Point Completion Network for Robust 3D Classification","abstract":"Real-scanned point clouds are often incomplete due to viewpoint, occlusion, and noise, which hampers 3D geometric modeling and perception. Existing point cloud completion methods tend to generate global shape skeletons and hence lack fine local details. Furthermore, they mostly learn a deterministic partial-to-complete mapping, but overlook structural relations in man-made objects. To tackle these challenges, this paper proposes a variational framework, Variational Relational point Completion Network (VRCNet) with two appealing properties: 1) Probabilistic Modeling. In particular, we propose a dual-path architecture to enable principled probabilistic modeling across partial and complete clouds. One path consumes complete point clouds for reconstruction by learning a point VAE. The other path generates complete shapes for partial point clouds, whose embedded distribution is guided by distribution obtained from the reconstruction path during training. 2) Relational Enhancement. Specifically, we carefully design point self-attention kernel and point selective kernel module to exploit relational point features, which refines local shape details conditioned on the coarse completion. In addition, we contribute multi-view partial point cloud datasets (MVP and MVP-40 dataset) containing over 200,000 high-quality scans, which render partial 3D shapes from 26 uniformly distributed camera poses for each 3D CAD model. Extensive experiments demonstrate that VRCNet outperforms state-of-the-art methods on all standard point cloud completion benchmarks. Notably, VRCNet shows great generalizability and robustness on real-world point cloud scans. Moreover, we can achieve robust 3D classification for partial point clouds with the help of VRCNet, which can highly increase classification accuracy.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09131v1","tag":"medical-cv"}}
{"title":"Implementation and evaluation of a dynamic contrast enhanced mr perfusion protocol for glioblastoma using a 0.35T mri-Linac system","abstract":"MRI-linear accelerator (MRI-Linac) systems allow for daily tracking of MRI changes during radiotherapy (RT). Since one common MRI-Linac operates at 0.35T, there are efforts towards developing protocols at that field strength. In this study we demonstrate the implementation of a post-contrast 3DT1-weighted (3DT1w) and dynamic contrast enhancement (DCE) protocol to assess glioblastoma response to RT using a 0.35T MRI-Linac. The protocol implemented was used to acquire 3DT1w and DCE data from a flow phantom and two patients with glioblastoma (a responder and a non-responder) who underwent RT on a 0.35T-MRI-Linac. The detection of post-contrast enhanced volumes was evaluated by comparing the 3DT1w images from the 0.35T-MRI-Linac to images obtained using a 3T-standalone scanner. The DCE data were tested temporally and spatially using data from the flow phantom and patients. K-trans maps were derived from DCE at three time points (a week before treatment: Pre RT, four weeks through treatment: Mid RT, and three weeks after treatment: Post RT) and were validated with patients treatment outcomes. The 3D-T1 contrast enhancement volumes were visually and volumetrically similar (+/- 0.6-3.6%) between 0.35T MRI-Linac and 3T. DCE images showed temporal stability, and associated K-trans maps were consistent with patient response to treatment. On average, K-trans values showed a 54% decrease and 8.6% increase for a responder and non-responder respectively when Pre RT and Mid RT images were compared. Our findings support the feasibility of obtaining post-contrast 3DT1w and DCE data from patients with glioblastoma using a 0.35T MRI-Linac system.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09128v1","tag":"medical-cv"}}
{"title":"A Concrete Model for the Quantum Permutation Group on 4 Points","abstract":"In 2019, Jung-Weber gave an example of a concrete magic unitary $M$, which defines a $C^*$-algebraic model of the quantum permutation group $S_4^+$. We show with the help of a computer that there exist no polynomials up to degree $50$ separating the entries of $M$ from the generators of $C(S_4^+)$. This indicates that the magic unitary $M$ might already define a faithful model of $S_4^+$.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09124v1","tag":"medical-cv"}}
{"title":"Fast Neural Scene Flow","abstract":"Scene flow is an important problem as it provides low-level motion cues for many downstream tasks. State-of-the-art learning methods are usually fast and can achieve impressive performance on in-domain data, but usually fail to generalize to out-of-the-distribution (OOD) data or handle dense point clouds. In this paper, we focus on a runtime optimization-based neural scene flow pipeline. In (a) one can see its application in the densification of lidar. However, in (c) one sees that the major drawback is the extensive computation time. We identify that the common speedup strategy in network architectures for coordinate networks has little effect on scene flow acceleration [see green (b)] unlike image reconstruction [see pink (b)]. With the dominant computational burden stemming instead from the Chamfer loss function, we propose to use a distance transform-based loss function to accelerate [see purple (b)], which achieves up to 30x speedup and on-par estimation performance compared to NSFP [see (c)]. When tested on 8k points, it is as efficient [see (c)] as leading learning methods, achieving real-time performance.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09121v1","tag":"medical-cv"}}
{"title":"NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers","abstract":"Scaling text-to-speech (TTS) to large-scale, multi-speaker, and in-the-wild datasets is important to capture the diversity in human speech such as speaker identities, prosodies, and styles (e.g., singing). Current large TTS systems usually quantize speech into discrete tokens and use language models to generate these tokens one by one, which suffer from unstable prosody, word skipping/repeating issue, and poor voice quality. In this paper, we develop NaturalSpeech 2, a TTS system that leverages a neural audio codec with residual vector quantizers to get the quantized latent vectors and uses a diffusion model to generate these latent vectors conditioned on text input. To enhance the zero-shot capability that is important to achieve diverse speech synthesis, we design a speech prompting mechanism to facilitate in-context learning in the diffusion model and the duration/pitch predictor. We scale NaturalSpeech 2 to large-scale datasets with 44K hours of speech and singing data and evaluate its voice quality on unseen speakers. NaturalSpeech 2 outperforms previous TTS systems by a large margin in terms of prosody/timbre similarity, robustness, and voice quality in a zero-shot setting, and performs novel zero-shot singing synthesis with only a speech prompt. Audio samples are available at https://speechresearch.github.io/naturalspeech2.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09116v1","tag":"medical-cv"}}
{"title":"CDFI: Cross Domain Feature Interaction for Robust Bronchi Lumen Detection","abstract":"Endobronchial intervention is increasingly used as a minimally invasive means for the treatment of pulmonary diseases. In order to reduce the difficulty of manipulation in complex airway networks, robust lumen detection is essential for intraoperative guidance. However, these methods are sensitive to visual artifacts which are inevitable during the surgery. In this work, a cross domain feature interaction (CDFI) network is proposed to extract the structural features of lumens, as well as to provide artifact cues to characterize the visual features. To effectively extract the structural and artifact features, the Quadruple Feature Constraints (QFC) module is designed to constrain the intrinsic connections of samples with various imaging-quality. Furthermore, we design a Guided Feature Fusion (GFF) module to supervise the model for adaptive feature fusion based on different types of artifacts. Results show that the features extracted by the proposed method can preserve the structural information of lumen in the presence of large visual variations, bringing much-improved lumen detection accuracy.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09115v1","tag":"medical-cv"}}
{"title":"Consensus-based rare event estimation","abstract":"In this paper, we introduce a new algorithm for rare event estimation based on adaptive importance sampling. We consider a smoothed version of the optimal importance sampling density, which is approximated by an ensemble of interacting particles. The particle dynamics is governed by a McKean-Vlasov stochastic differential equation, which was introduced and analyzed in (Carrillo et al., Stud. Appl. Math. 148:1069-1140, 2022) for consensus-based sampling and optimization of posterior distributions arising in the context of Bayesian inverse problems. We develop automatic updates for the internal parameters of our algorithm. This includes a novel time step size controller for the exponential Euler method, which discretizes the particle dynamics. The behavior of all parameter updates depends on easy to interpret accuracy criteria specified by the user. We show in numerical experiments that our method is competitive to state-of-the-art adaptive importance sampling algorithms for rare event estimation, namely a sequential importance sampling method and the ensemble Kalman filter for rare event estimation.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09077v1","tag":"medical-cv"}}
{"title":"Multi-User Matching and Resource Allocation in Vision Aided Communications","abstract":"Visual perception is an effective way to obtain the spatial characteristics of wireless channels and to reduce the overhead for communications system. A critical problem for the visual assistance is that the communications system needs to match the radio signal with the visual information of the corresponding user, i.e., to identify the visual user that corresponds to the target radio signal from all the environmental objects. In this paper, we propose a user matching method for environment with a variable number of objects. Specifically, we apply 3D detection to extract all the environmental objects from the images taken by multiple cameras. Then, we design a deep neural network (DNN) to estimate the location distribution of users by the images and beam pairs at multiple moments, and thereby identify the users from all the extracted environmental objects. Moreover, we present a resource allocation method based on the taken images to reduce the time and spectrum overhead compared to traditional resource allocation methods. Simulation results show that the proposed user matching method outperforms the existing methods, and the proposed resource allocation method can achieve $92\\%$ transmission rate of the traditional resource allocation method but with the time and spectrum overhead significantly reduced.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09075v1","tag":"medical-cv"}}
{"title":"Electrical Impedance Tomography with Deep Calder\u00f3n Method","abstract":"Electrical impedance tomography (EIT) is a noninvasive medical imaging modality utilizing the current-density/voltage data measured on the surface of the subject. Calder\\'on's method is a relatively recent EIT imaging algorithm that is non-iterative, fast, and capable of reconstructing complex-valued electric impedances. However, due to the regularization via low-pass filtering and linearization, the reconstructed images suffer from severe blurring and underestimation of the exact conductivity values. In this work, we develop an enhanced version of Calder\\'on's method, using convolution neural networks (i.e., U-net) via a postprocessing step. Specifically, we learn a U-net to postprocess the EIT images generated by Calder\\'on's method so as to have better resolutions and more accurate estimates of conductivity values. We simulate chest configurations with which we generate the current-density/voltage boundary measurements and the corresponding reconstructed images by Calder\\'on's method. With the paired training data, we learn the neural network and evaluate its performance on real tank measurement data. The experimental results indicate that the proposed approach indeed provides a fast and direct (complex-valued) impedance tomography imaging technique, and substantially improves the capability of the standard Calder\\'on's method.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09074v1","tag":"medical-cv"}}
{"title":"First computation of Mueller Tang processes using the full NLL BFKL approach","abstract":"We present the full next-to-leading order (NLO) prediction for the jet-gap-jet cross section at the LHC within the BFKL approach. We implement, for the first time, the NLO impact factors in the calculation of the cross section. We provide results for differential cross sections as a function of the difference in rapidity and azimuthal angle betwen the two jets and the second leading jet transverse momentum. The NLO corrections of the impact factors induce an overall reduction of the cross section with respect to the corresponding predictions with only LO impact factors.   We note that NLO impact factors feature a logarithmic dependence of the cross section on the total center of mass energy which formally violates BFKL factorization. We show that such term is one order of magnitude smaller than the total contribution, and thus can be safely included in the current prediction without a need of further resummation of such logarithmic terms.   Fixing the renormalization scale $\\mu_R$ according to the principle of minimal sensitivity, suggests $\\mu_R$ about 4 times the sum of the transverse jet energies and provides smaller theroretical uncertainties with respect to the leading order case.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09073v1","tag":"medical-cv"}}
{"title":"Controllable Strain-driven Topological Phase Transition and Dominant Surface State Transport in High-Quality HfTe5 Samples","abstract":"Controlling materials to create and tune topological phases of matter could potentially be used to explore new phases of topological quantum matter and to create novel devices where the carriers are topologically protected. It has been demonstrated that a trivial insulator can be converted into a topological state by modulating the spin-orbit interaction or the crystal lattice. However, there are limited methods to controllably and efficiently tune the crystal lattice and at the same time perform electronic measurements at cryogenic temperatures. Here, we use large controllable strain to demonstrate the topological phase transition from a weak topological insulator phase to a strong topological insulator phase in high-quality HfTe5 samples. After applying high strain to HfTe5 and converting it into a strong topological insulator, we found that the sample's resistivity increased by more than two orders of magnitude (24,000%) and that the electronic transport is dominated by the topological surface states at cryogenic temperatures. Our findings show that HfTe5 is an ideal material for engineering topological properties, and it could be generalized to study topological phase transitions in van der Waals materials and heterostructures. These results can pave the way to create novel devices with applications ranging from spintronics to fault-tolerant topologically protected quantum computers.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09072v1","tag":"medical-cv"}}
{"title":"M-ENIAC: A machine learning recreation of the first successful numerical weather forecasts","abstract":"In 1950 the first successful numerical weather forecast was obtained by solving the barotropic vorticity equation using the Electronic Numerical Integrator and Computer (ENIAC), which marked the beginning of the age of numerical weather prediction. Here, we ask the question of how these numerical forecasts would have turned out, if machine learning based solvers had been used instead of standard numerical discretizations. Specifically, we recreate these numerical forecasts using physics-informed neural networks. We show that physics-informed neural networks provide an easier and more accurate methodology for solving meteorological equations on the sphere, as compared to the ENIAC solver.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09070v1","tag":"medical-cv"}}
{"title":"Robustness and complexity","abstract":"When a biological system robustly corrects component-level errors, the direct pressure on component performance declines. Components may become less reliable, maintain more genetic variability, or drift neutrally in design, creating the basis for new forms of organismal complexity. This article links the protection-decay dynamic to other aspects of robust and complex systems. Examples include the hourglass pattern of biological development and Doyle's hourglass architecture for robustly complex systems in engineering. The deeply and densely connected wiring architecture in biology's cellular controls and in machine learning's computational neural networks provide another link. By unifying these seemingly different aspects into a unified framework, we gain a new perspective on robust and complex systems.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09069v1","tag":"medical-cv"}}
{"title":"Performance of GAN-based augmentation for deep learning COVID-19 image classification","abstract":"The biggest challenge in the application of deep learning to the medical domain is the availability of training data. Data augmentation is a typical methodology used in machine learning when confronted with a limited data set. In a classical approach image transformations i.e. rotations, cropping and brightness changes are used. In this work, a StyleGAN2-ADA model of Generative Adversarial Networks is trained on the limited COVID-19 chest X-ray image set. After assessing the quality of generated images they are used to increase the training data set improving its balance between classes. We consider the multi-class classification problem of chest X-ray images including the COVID-19 positive class that hasn't been yet thoroughly explored in the literature. Results of transfer learning-based classification of COVID-19 chest X-ray images are presented. The performance of several deep convolutional neural network models is compared. The impact on the detection performance of classical image augmentations i.e. rotations, cropping, and brightness changes are studied. Furthermore, classical image augmentation is compared with GAN-based augmentation. The most accurate model is an EfficientNet-B0 with an accuracy of 90.2 percent, trained on a dataset with a simple class balancing. The GAN augmentation approach is found to be subpar to classical methods for the considered dataset.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09067v1","tag":"medical-cv"}}
{"title":"Crepant resolutions, mutations, and the space of potentials","abstract":"The McKay correspondence has had much success in studying resolutions of 3-fold quotient singularities through a wide range of tools coming from geometry, combinatorics, and representation theory. We develop a computational perspective in this setting primarily realised through a web application to explore mutations of quivers with potential and crepant triangulations. We use this to study flops between different crepant resolutions of Gorenstein toric quotient singularities and find many situations in which the mutations of a quiver with potential classifies them. The application also implements key constructions of the McKay correspondence, including the Craw--Reid procedure and the process of associating a quiver to a toric resolution.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09063v1","tag":"medical-cv"}}
{"title":"Coupling Global Context and Local Contents for Weakly-Supervised Semantic Segmentation","abstract":"Thanks to the advantages of the friendly annotations and the satisfactory performance, Weakly-Supervised Semantic Segmentation (WSSS) approaches have been extensively studied. Recently, the single-stage WSSS was awakened to alleviate problems of the expensive computational costs and the complicated training procedures in multi-stage WSSS. However, results of such an immature model suffer from problems of \\emph{background incompleteness} and \\emph{object incompleteness}. We empirically find that they are caused by the insufficiency of the global object context and the lack of the local regional contents, respectively. Under these observations, we propose a single-stage WSSS model with only the image-level class label supervisions, termed as \\textbf{W}eakly-\\textbf{S}upervised \\textbf{F}eature \\textbf{C}oupling \\textbf{N}etwork (\\textbf{WS-FCN}), which can capture the multi-scale context formed from the adjacent feature grids, and encode the fine-grained spatial information from the low-level features into the high-level ones. Specifically, a flexible context aggregation module is proposed to capture the global object context in different granular spaces. Besides, a semantically consistent feature fusion module is proposed in a bottom-up parameter-learnable fashion to aggregate the fine-grained local contents. Based on these two modules, \\textbf{WS-FCN} lies in a self-supervised end-to-end training fashion. Extensive experimental results on the challenging PASCAL VOC 2012 and MS COCO 2014 demonstrate the effectiveness and efficiency of \\textbf{WS-FCN}, which can achieve state-of-the-art results by $65.02\\%$ and $64.22\\%$ mIoU on PASCAL VOC 2012 \\emph{val} set and \\emph{test} set, $34.12\\%$ mIoU on MS COCO 2014 \\emph{val} set, respectively. The code and weight have been released at:~\\href{https://github.com/ChunyanWang1/ws-fcn}{WS-FCN}.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09059v1","tag":"medical-cv"}}
{"title":"Revisiting k-NN for Pre-trained Language Models","abstract":"Pre-trained Language Models (PLMs), as parametric-based eager learners, have become the de-facto choice for current paradigms of Natural Language Processing (NLP). In contrast, k-Nearest-Neighbor (k-NN) classifiers, as the lazy learning paradigm, tend to mitigate over-fitting and isolated noise. In this paper, we revisit k-NN classifiers for augmenting the PLMs-based classifiers. From the methodological level, we propose to adopt k-NN with textual representations of PLMs in two steps: (1) Utilize k-NN as prior knowledge to calibrate the training process. (2) Linearly interpolate the probability distribution predicted by k-NN with that of the PLMs' classifier. At the heart of our approach is the implementation of k-NN-calibrated training, which treats predicted results as indicators for easy versus hard examples during the training process. From the perspective of the diversity of application scenarios, we conduct extensive experiments on fine-tuning, prompt-tuning paradigms and zero-shot, few-shot and fully-supervised settings, respectively, across eight diverse end-tasks. We hope our exploration will encourage the community to revisit the power of classical methods for efficient NLP\\footnote{Code and datasets are available in https://github.com/zjunlp/Revisit-KNN.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09058v1","tag":"medical-cv"}}
{"title":"Orbital-Free Quasi-Density Functional Theory","abstract":"Wigner functions are broadly used to probe non-classical effects in the macroscopic world. Here we develop an orbital-free functional framework to compute the 1-body Wigner quasi-probability for both fermionic and bosonic systems. Since the key variable is a quasi-density, this theory is particularly well suited to circumvent the problem of finding the Pauli potential or approximating the kinetic energy in orbital-free density functional theory. As proof of principle, we find that the universal functional for the building block of optical lattices results from a translation, a contraction, and a rotation of the corresponding functional of the 1-body reduced density matrix, indicating a strong connection between these functional theories. Furthermore, we relate the concepts of Wigner negativity and $v$-representability, and find a manifold of ground states with negative Wigner functions.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09056v1","tag":"medical-cv"}}
{"title":"Stable intermediate phase of secondary structures for semiflexible polymers","abstract":"Systematic microcanonical inflection-point analysis of precise numerical results obtained in extensive generalized-ensemble Monte Carlo simulations reveals a bifurcation of the coil-globule transition line for polymers with a bending stiffness exceeding a threshold value. The region, enclosed by the toroidal and random-coil phases, is dominated by structures crossing over from hairpins to loops upon lowering the energy. Conventional canonical statistical analysis is not sufficiently sensitive to allow for the identification of these separate phases.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09054v1","tag":"medical-cv"}}
{"title":"Bayes Hilbert Spaces for Posterior Approximation","abstract":"Performing inference in Bayesian models requires sampling algorithms to draw samples from the posterior. This becomes prohibitively expensive as the size of data sets increase. Constructing approximations to the posterior which are cheap to evaluate is a popular approach to circumvent this issue. This begs the question of what is an appropriate space to perform approximation of Bayesian posterior measures. This manuscript studies the application of Bayes Hilbert spaces to the posterior approximation problem. Bayes Hilbert spaces are studied in functional data analysis in the context where observed functions are probability density functions and their application to computational Bayesian problems is in its infancy. This manuscript shall outline Bayes Hilbert spaces and their connection to Bayesian computation, in particular novel connections between Bayes Hilbert spaces, Bayesian coreset algorithms and kernel-based distances.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09053v1","tag":"medical-cv"}}
{"title":"Gravitational scattering upto third post-Newtonian approximation for conservative dynamics: Scalar-Tensor theories","abstract":"We compute the scattering angle $\\chi$ for hyperboliclike encounters in massless Scalar-Tensor (ST) theories up to third post-Newtonian (PN) order for the conservative part of the dynamics. To calculate the gauge-invariant scattering angle as a function of energy and orbital angular momentum, we use the approach of Effective-One-Body formalism as introduced in [Phys.Rev.D 96 (2017) 6, 064021]. We then compute the nonlocal-in-time contribution to the scattering angle by using the strategy of order-reduction of nonlocal dynamics introduced for small-eccentricity orbits.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09052v1","tag":"medical-cv"}}
{"title":"Decoding Neural Activity to Assess Individual Latent State in Ecologically Valid Contexts","abstract":"There exist very few ways to isolate cognitive processes, historically defined via highly controlled laboratory studies, in more ecologically valid contexts. Specifically, it remains unclear as to what extent patterns of neural activity observed under such constraints actually manifest outside the laboratory in a manner that can be used to make an accurate inference about the latent state, associated cognitive process, or proximal behavior of the individual. Improving our understanding of when and how specific patterns of neural activity manifest in ecologically valid scenarios would provide validation for laboratory-based approaches that study similar neural phenomena in isolation and meaningful insight into the latent states that occur during complex tasks. We argue that domain generalization methods from the brain-computer interface community have the potential to address this challenge. We previously used such an approach to decode phasic neural responses associated with visual target discrimination. Here, we extend that work to more tonic phenomena such as internal latent states. We use data from two highly controlled laboratory paradigms to train two separate domain-generalized models. We apply the trained models to an ecologically valid paradigm in which participants performed multiple, concurrent driving-related tasks. Using the pretrained models, we derive estimates of the underlying latent state and associated patterns of neural activity. Importantly, as the patterns of neural activity change along the axis defined by the original training data, we find changes in behavior and task performance consistent with the observations from the original, laboratory paradigms. We argue that these results lend ecological validity to those experimental designs and provide a methodology for understanding the relationship between observed neural activity and behavior during complex tasks.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09050v1","tag":"medical-cv"}}
{"title":"CodeKGC: Code Language Model for Generative Knowledge Graph Construction","abstract":"Current generative knowledge graph construction approaches usually fail to capture structural knowledge by simply flattening natural language into serialized texts or a specification language. However, large generative language model trained on structured data such as code has demonstrated impressive capability in understanding natural language for structural prediction and reasoning tasks. Intuitively, we address the task of generative knowledge graph construction with code language model: given a code-format natural language input, the target is to generate triples which can be represented as code completion tasks. Specifically, we develop schema-aware prompts that effectively utilize the semantic structure within the knowledge graph. As code inherently possesses structure, such as class and function definitions, it serves as a useful model for prior semantic structural knowledge. Furthermore, we employ a rationale-enhanced generation method to boost the performance. Rationales provide intermediate steps, thereby improving knowledge extraction abilities. Experimental results indicate that the proposed approach can obtain better performance on benchmark datasets compared with baselines. Code and datasets are available in https://github.com/zjunlp/DeepKE/tree/main/example/llm.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09048v1","tag":"medical-cv"}}
{"title":"Neural Lumped Parameter Differential Equations with Application in Friction-Stir Processing","abstract":"Lumped parameter methods aim to simplify the evolution of spatially-extended or continuous physical systems to that of a \"lumped\" element representative of the physical scales of the modeled system. For systems where the definition of a lumped element or its associated physics may be unknown, modeling tasks may be restricted to full-fidelity simulations of the physics of a system. In this work, we consider data-driven modeling tasks with limited point-wise measurements of otherwise continuous systems. We build upon the notion of the Universal Differential Equation (UDE) to construct data-driven models for reducing dynamics to that of a lumped parameter and inferring its properties. The flexibility of UDEs allow for composing various known physical priors suitable for application-specific modeling tasks, including lumped parameter methods. The motivating example for this work is the plunge and dwell stages for friction-stir welding; specifically, (i) mapping power input into the tool to a point-measurement of temperature and (ii) using this learned mapping for process control.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09047v1","tag":"medical-cv"}}
{"title":"Construction of coarse-grained molecular dynamics with many-body non-Markovian memory","abstract":"We introduce a machine-learning-based coarse-grained molecular dynamics (CGMD) model that faithfully retains the many-body nature of the inter-molecular dissipative interactions. Unlike common empirical CG models, the present model is constructed based on the Mori-Zwanzig formalism and naturally inherits the heterogeneous state-dependent memory term rather than matching the mean-field metrics such as the velocity auto-correlation function. Numerical results show that preserving the many-body nature of the memory term is crucial for predicting the collective transport and diffusion processes, where empirical forms generally show limitations.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09044v1","tag":"medical-cv"}}
{"title":"Adapter Learning in Pretrained Feature Extractor for Continual Learning of Diseases","abstract":"Currently intelligent diagnosis systems lack the ability of continually learning to diagnose new diseases once deployed, under the condition of preserving old disease knowledge. In particular, updating an intelligent diagnosis system with training data of new diseases would cause catastrophic forgetting of old disease knowledge. To address the catastrophic forgetting issue, a novel adapter-based strategy is proposed to help effectively learn a set of new diseases at each round (or task) of continual learning, without changing the shared feature extractor. The learnable lightweight task-specific adapter(s) can be flexibly designed (e.g., two convolutional layers) and then added to the pretrained and fixed feature extractor. Together with a specially designed task-specific head which absorbs all previously learned old diseases as a single 'out-of-distribution' category, task-specific adapter(s) can help the pretrained feature extractor more effectively extract discriminative features between diseases. In addition, a simple yet effective fine-tuning is applied to collaboratively fine-tune multiple task-specific heads such that outputs from different heads are comparable and consequently the appropriate classifier head can be more accurately selected during model inference. Extensive empirical evaluations on three image datasets demonstrate the superior performance of the proposed method in continual learning of new diseases. The source code will be released publicly.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09042v1","tag":"medical-cv"}}
{"title":"Comparison of effective and stable Langevin dynamics integrators","abstract":"In silico simulations via Langevin and Brownian stochastic dynamics have a prominent role in computational research. In the literature, there are plenty of modern algorithms providing accurate trajectories each one with its pros and cons, such as different stability regions and levels of accuracy in reproducing statistical results. The practical usability of integrators is an important aspect of each integrator: the ability to choose large time steps while ensuring numerical instability, the usage of dimensionless models, and securing numerical efficiency are at the core of stochastic integrators. In this work, several important use cases and practical features are selected in order to perform a cumulative benchmark. The most effective integrators are identified and their results are compared to previous studies.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09030v1","tag":"medical-cv"}}
{"title":"Towards a Benchmark for Fog Data Processing","abstract":"Fog data processing systems provide key abstractions to manage data and event processing in the geo-distributed and heterogeneous fog environment. The lack of standardized benchmarks for such systems, however, hinders their development and deployment, as different approaches cannot be compared quantitatively. Existing cloud data benchmarks are inadequate for fog computing, as their focus on workload specification ignores the tight integration of application and infrastructure inherent in fog computing.   In this paper, we outline an approach to a fog-native data processing benchmark that combines workload specifications with infrastructure specifications. This holistic approach allows researchers and engineers to quantify how a software approach performs for a given workload on given infrastructure. Further, by basing our benchmark in a realistic IoT sensor network scenario, we can combine paradigms such as low-latency event processing, machine learning inference, and offline data analytics, and analyze the performance impact of their interplay in a fog data processing system.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09026v1","tag":"medical-cv"}}
{"title":"Look ATME: The Discriminator Mean Entropy Needs Attention","abstract":"Generative adversarial networks (GANs) are successfully used for image synthesis but are known to face instability during training. In contrast, probabilistic diffusion models (DMs) are stable and generate high-quality images, at the cost of an expensive sampling procedure. In this paper, we introduce a simple method to allow GANs to stably converge to their theoretical optimum, while bringing in the denoising machinery from DMs. These models are combined into a simpler model (ATME) that only requires a forward pass during inference, making predictions cheaper and more accurate than DMs and popular GANs. ATME breaks an information asymmetry existing in most GAN models in which the discriminator has spatial knowledge of where the generator is failing. To restore the information symmetry, the generator is endowed with knowledge of the entropic state of the discriminator, which is leveraged to allow the adversarial game to converge towards equilibrium. We demonstrate the power of our method in several image-to-image translation tasks, showing superior performance than state-of-the-art methods at a lesser cost. Code is available at https://github.com/DLR-MI/atme","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09024v1","tag":"medical-cv"}}
{"title":"Consequences of laser transverse imperfections on laser wakefield acceleration at the Apollon facility","abstract":"With the currently available laser powers, it is possible to reach the blowout regime in the Laser WakeField Acceleration (LWFA) where the electrons are completely expelled off-axis behind the laser pulse. This regime is particularly interesting thanks to its linear focusing forces and to its accelerating forces that are independent of the transverse coordinates. In fact, these features ensure a quite stable propagation of electron bunches with low phase-space volume. In this context, the Apollon laser is designed to reach an exceptional multi-petawatt laser peak power, thus aiming at achieving unprecedented accelerating gradients and bringing a scientific breakthrough in the field of LWFA.   Since the quality of the self-injected electron bunches is very sensitive to the condition of the laser, it is very important to take into account realistic laser features when performing LWFA simulations. In this paper, we aim at understanding the implications of laser imperfections on the electrons produced with the self-injection scheme in the bubble regime. For this purpose, we carry on a numerical study of LWFA where we include experimentally measured laser profiles from the Apollon facility in full three dimensional Particle-In-Cell simulations.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09020v1","tag":"medical-cv"}}
{"title":"Hardware-Impaired Rician-Faded Cell-Free Massive MIMO Systems With Channel Aging","abstract":"We study the impact of channel aging on the uplink of a cell-free (CF) massive multiple-input multiple-output (mMIMO) system by considering i) spatially-correlated Rician-faded channels; ii) hardware impairments at the access points and user equipments (UEs); and iii) two-layer large-scale fading decoding (LSFD). We first derive a closed-form spectral efficiency (SE) expression for this system, and later propose two novel optimization techniques to optimize the non-convex SE metric by exploiting the minorization-maximization (MM) method. The first one requires a numerical optimization solver, and has a high computation complexity. The second one with closed-form transmit power updates, has a trivial computation complexity. We numerically show that i) the two-layer LSFD scheme effectively mitigates the interference due to channel aging for both low- and high-velocity UEs; and ii) increasing the number of AP antennas does not mitigate the SE deterioration due to channel aging. We numerically characterize the optimal pilot length required to maximize the SE for various UE speeds. We also numerically show that the proposed closed-form MM optimization yields the same SE as that of the first technique, which requires numerical solver, and that too with a much reduced time-complexity.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09019v1","tag":"medical-cv"}}
{"title":"GUILGET: GUI Layout GEneration with Transformer","abstract":"Sketching out Graphical User Interface (GUI) layout is part of the pipeline of designing a GUI and a crucial task for the success of a software application. Arranging all components inside a GUI layout manually is a time-consuming task. In order to assist designers, we developed a method named GUILGET to automatically generate GUI layouts from positional constraints represented as GUI arrangement graphs (GUI-AGs). The goal is to support the initial step of GUI design by producing realistic and diverse GUI layouts. The existing image layout generation techniques often cannot incorporate GUI design constraints. Thus, GUILGET needs to adapt existing techniques to generate GUI layouts that obey to constraints specific to GUI designs. GUILGET is based on transformers in order to capture the semantic in relationships between elements from GUI-AG. Moreover, the model learns constraints through the minimization of losses responsible for placing each component inside its parent layout, for not letting components overlap if they are inside the same parent, and for component alignment. Our experiments, which are conducted on the CLAY dataset, reveal that our model has the best understanding of relationships from GUI-AG and has the best performances in most of evaluation metrics. Therefore, our work contributes to improved GUI layout generation by proposing a novel method that effectively accounts for the constraints on GUI elements and paves the road for a more efficient GUI design pipeline.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09012v1","tag":"medical-cv"}}
{"title":"Calculating the many-potential vacuum polarization density of the Dirac equation in the finite-basis approximation","abstract":"In this work, we propose an efficient and accurate computational method to evaluate the many-potential $\\alpha\\left(Z\\alpha\\right)^{n\\ge3}$ vacuum polarization density of hydrogen-like atoms within the finite-basis approximation of the Dirac equation. To prove the performance of our computational method, we choose to work with the one-electron $_{\\,\\,\\,92}^{238}\\text{U}$ atom. In summary, we find that compliance with charge conjugation symmetry is a priori required to obtain physical results that are in line with our knowledge of the analytical problem. We also note that the final numerical results are found to be in excellent agreement with previous formal analytical (and numerical) evaluations that are limited to a few simple nuclear distribution models. Our technique can be efficiently implemented and evaluated in codes that solve the radial Dirac equation in the finite basis set framework and allows the use of arbitrary (radial) nuclear charge distribution. The obtained numerical results of the non-perturbative vacuum polarization density automatically account for the extended nuclear size effect. This method is hence of special importance for atomic Dirac problems whose analytical Green's functions expressions are not at hand or have relatively complicated analytical forms. Furthermore, we propose a vacuum polarization density formula that forces compliance with charge conjugation symmetry and can be used in cases where the relativistic basis violates this symmetry, as is the case in most relativistic basis set programs. In addition, we have shown that vector components of the vacuum polarization four-current vanish in the case where the Dirac Hamiltonian is symmetric under time-reversal symmetry.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09008v1","tag":"medical-cv"}}
{"title":"A Biomedical Entity Extraction Pipeline for Oncology Health Records in Portuguese","abstract":"Textual health records of cancer patients are usually protracted and highly unstructured, making it very time-consuming for health professionals to get a complete overview of the patient's therapeutic course. As such limitations can lead to suboptimal and/or inefficient treatment procedures, healthcare providers would greatly benefit from a system that effectively summarizes the information of those records. With the advent of deep neural models, this objective has been partially attained for English clinical texts, however, the research community still lacks an effective solution for languages with limited resources. In this paper, we present the approach we developed to extract procedures, drugs, and diseases from oncology health records written in European Portuguese. This project was conducted in collaboration with the Portuguese Institute for Oncology which, besides holding over $10$ years of duly protected medical records, also provided oncologist expertise throughout the development of the project. Since there is no annotated corpus for biomedical entity extraction in Portuguese, we also present the strategy we followed in annotating the corpus for the development of the models. The final models, which combined a neural architecture with entity linking, achieved $F_1$ scores of $88.6$, $95.0$, and $55.8$ per cent in the mention extraction of procedures, drugs, and diseases, respectively.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08999v1","tag":"medical-cv"}}
{"title":"Parcel3D: Shape Reconstruction from Single RGB Images for Applications in Transportation Logistics","abstract":"We focus on enabling damage and tampering detection in logistics and tackle the problem of 3D shape reconstruction of potentially damaged parcels. As input we utilize single RGB images, which corresponds to use-cases where only simple handheld devices are available, e.g. for postmen during delivery or clients on delivery. We present a novel synthetic dataset, named Parcel3D, that is based on the Google Scanned Objects (GSO) dataset and consists of more than 13,000 images of parcels with full 3D annotations. The dataset contains intact, i.e. cuboid-shaped, parcels and damaged parcels, which were generated in simulations. We work towards detecting mishandling of parcels by presenting a novel architecture called CubeRefine R-CNN, which combines estimating a 3D bounding box with an iterative mesh refinement. We benchmark our approach on Parcel3D and an existing dataset of cuboid-shaped parcels in real-world scenarios. Our results show, that while training on Parcel3D enables transfer to the real world, enabling reliable deployment in real-world scenarios is still challenging. CubeRefine R-CNN yields competitive performance in terms of Mesh AP and is the only model that directly enables deformation assessment by 3D mesh comparison and tampering detection by comparing viewpoint invariant parcel side surface representations. Dataset and code are available at https://a-nau.github.io/parcel3d.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08994v1","tag":"medical-cv"}}
{"title":"Learning to Fuse Monocular and Multi-view Cues for Multi-frame Depth Estimation in Dynamic Scenes","abstract":"Multi-frame depth estimation generally achieves high accuracy relying on the multi-view geometric consistency. When applied in dynamic scenes, e.g., autonomous driving, this consistency is usually violated in the dynamic areas, leading to corrupted estimations. Many multi-frame methods handle dynamic areas by identifying them with explicit masks and compensating the multi-view cues with monocular cues represented as local monocular depth or features. The improvements are limited due to the uncontrolled quality of the masks and the underutilized benefits of the fusion of the two types of cues. In this paper, we propose a novel method to learn to fuse the multi-view and monocular cues encoded as volumes without needing the heuristically crafted masks. As unveiled in our analyses, the multi-view cues capture more accurate geometric information in static areas, and the monocular cues capture more useful contexts in dynamic areas. To let the geometric perception learned from multi-view cues in static areas propagate to the monocular representation in dynamic areas and let monocular cues enhance the representation of multi-view cost volume, we propose a cross-cue fusion (CCF) module, which includes the cross-cue attention (CCA) to encode the spatially non-local relative intra-relations from each source to enhance the representation of the other. Experiments on real-world datasets prove the significant effectiveness and generalization ability of the proposed method.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08993v1","tag":"medical-cv"}}
{"title":"D2CSE: Difference-aware Deep continuous prompts for Contrastive Sentence Embeddings","abstract":"This paper describes Difference-aware Deep continuous prompt for Contrastive Sentence Embeddings (D2CSE) that learns sentence embeddings. Compared to state-of-the-art approaches, D2CSE computes sentence vectors that are exceptional to distinguish a subtle difference in similar sentences by employing a simple neural architecture for continuous prompts. Unlike existing architectures that require multiple pretrained language models (PLMs) to process a pair of the original and corrupted (subtly modified) sentences, D2CSE avoids cumbersome fine-tuning of multiple PLMs by only optimizing continuous prompts by performing multiple tasks -- i.e., contrastive learning and conditional replaced token detection all done in a self-guided manner. D2CSE overloads a single PLM on continuous prompts and greatly saves memory consumption as a result. The number of training parameters in D2CSE is reduced to about 1\\% of existing approaches while substantially improving the quality of sentence embeddings. We evaluate D2CSE on seven Semantic Textual Similarity (STS) benchmarks, using three different metrics, namely, Spearman's rank correlation, recall@K for a retrieval task, and the anisotropy of an embedding space measured in alignment and uniformity. Our empirical results suggest that shallow (not too meticulously devised) continuous prompts can be honed effectively for multiple NLP tasks and lead to improvements upon existing state-of-the-art approaches.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08991v1","tag":"medical-cv"}}
{"title":"A Comparison of Image Denoising Methods","abstract":"The advancement of imaging devices and countless images generated everyday pose an increasingly high demand on image denoising, which still remains a challenging task in terms of both effectiveness and efficiency. To improve denoising quality, numerous denoising techniques and approaches have been proposed in the past decades, including different transforms, regularization terms, algebraic representations and especially advanced deep neural network (DNN) architectures. Despite their sophistication, many methods may fail to achieve desirable results for simultaneous noise removal and fine detail preservation. In this paper, to investigate the applicability of existing denoising techniques, we compare a variety of denoising methods on both synthetic and real-world datasets for different applications. We also introduce a new dataset for benchmarking, and the evaluations are performed from four different perspectives including quantitative metrics, visual effects, human ratings and computational cost. Our experiments demonstrate: (i) the effectiveness and efficiency of representative traditional denoisers for various denoising tasks, (ii) a simple matrix-based algorithm may be able to produce similar results compared with its tensor counterparts, and (iii) the notable achievements of DNN models, which exhibit impressive generalization ability and show state-of-the-art performance on various datasets. In spite of the progress in recent years, we discuss shortcomings and possible extensions of existing techniques. Datasets, code and results are made publicly available and will be continuously updated at https://github.com/ZhaomingKong/Denoising-Comparison.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08990v1","tag":"medical-cv"}}
{"title":"Incremental Image Labeling via Iterative Refinement","abstract":"Data quality is critical for multimedia tasks, while various types of systematic flaws are found in image benchmark datasets, as discussed in recent work. In particular, the existence of the semantic gap problem leads to a many-to-many mapping between the information extracted from an image and its linguistic description. This unavoidable bias further leads to poor performance on current computer vision tasks. To address this issue, we introduce a Knowledge Representation (KR)-based methodology to provide guidelines driving the labeling process, thereby indirectly introducing intended semantics in ML models. Specifically, an iterative refinement-based annotation method is proposed to optimize data labeling by organizing objects in a classification hierarchy according to their visual properties, ensuring that they are aligned with their linguistic descriptions. Preliminary results verify the effectiveness of the proposed method.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08989v1","tag":"medical-cv"}}
{"title":"Robustness of Visual Explanations to Common Data Augmentation","abstract":"As the use of deep neural networks continues to grow, understanding their behaviour has become more crucial than ever. Post-hoc explainability methods are a potential solution, but their reliability is being called into question. Our research investigates the response of post-hoc visual explanations to naturally occurring transformations, often referred to as augmentations. We anticipate explanations to be invariant under certain transformations, such as changes to the colour map while responding in an equivariant manner to transformations like translation, object scaling, and rotation. We have found remarkable differences in robustness depending on the type of transformation, with some explainability methods (such as LRP composites and Guided Backprop) being more stable than others. We also explore the role of training with data augmentation. We provide evidence that explanations are typically less robust to augmentation than classification performance, regardless of whether data augmentation is used in training or not.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08984v1","tag":"medical-cv"}}
{"title":"Complexity reduction for resilient state estimation of uniformly observable nonlinear systems","abstract":"A resilient state estimation scheme for uniformly observable nonlinear systems, based on a method for local identification of sensor attacks, is presented. The estimation problem is combinatorial in nature, and so many methods require substantial computational and storage resources as the number of sensors increases. To reduce the complexity, the proposed method performs the attack identification with local subsets of the measurements, not with the set of all measurements. A condition for nonlinear attack identification is introduced as a relaxed version of existing redundant observability condition. It is shown that an attack identification can be performed even when the state cannot be recovered from the measurements. As a result, although a portion of measurements are compromised, they can be locally identified and excluded from the state estimation, and thus the true state can be recovered. Simulation results demonstrate the effectiveness of the proposed scheme.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08983v1","tag":"medical-cv"}}
{"title":"MER 2023: Multi-label Learning, Modality Robustness, and Semi-Supervised Learning","abstract":"Over the past few decades, multimodal emotion recognition has made remarkable progress with the development of deep learning. However, existing technologies are difficult to meet the demand for practical applications. To improve the robustness, we launch a Multimodal Emotion Recognition Challenge (MER 2023) to motivate global researchers to build innovative technologies that can further accelerate and foster research. For this year's challenge, we present three distinct sub-challenges: (1) MER-MULTI, in which participants recognize both discrete and dimensional emotions; (2) MER-NOISE, in which noise is added to test videos for modality robustness evaluation; (3) MER-SEMI, which provides large amounts of unlabeled samples for semi-supervised learning. In this paper, we test a variety of multimodal features and provide a competitive baseline for each sub-challenge. Our system achieves 77.57% on the F1 score and 0.82 on the mean squared error (MSE) for MER-MULTI, 69.82% on the F1 score and 1.12 on MSE for MER-NOISE, and 86.75% on the F1 score for MER-SEMI, respectively. Baseline code is available at https://github.com/zeroQiaoba/MER2023-Baseline.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08981v1","tag":"medical-cv"}}
{"title":"Electron correlation effects in paramagnetic cobalt","abstract":"We study the influence of Coulomb correlations on spectral and magnetic properties of fcc cobalt using a combination of density functional theory and dynamical mean-field theory. The computed uniform and local magnetic susceptibilities obey the Curie-Weiss law, which, as we demonstrate, occurs due to the partial formation of local magnetic moments. We find that the lifetime of these moments in cobalt is significantly less than in bcc iron, suggesting a more itinerant magnetism in cobalt. In contrast to the bcc iron, the obtained electronic self-energies exhibit a quasiparticle shape with the quasiparticle mass enhancement factor ${m^*/m}\\sim$1.8, corresponding to moderately correlated metal. Finally, our calculations reveal that the static magnetic susceptibility of cobalt is dominated by ferromagnetic correlations, as evidenced by its momentum dependence.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08980v1","tag":"medical-cv"}}
{"title":"Visual-LiDAR Odometry and Mapping with Monocular Scale Correction and Motion Compensation","abstract":"This paper presents a novel visual-LiDAR odometry and mapping method with low-drift characteristics. The proposed method is based on two popular approaches, ORB-SLAM and A-LOAM, with monocular scale correction and visual-assisted LiDAR motion compensation modifications. The scale corrector calculates the proportion between the depth of image keypoints recovered by triangulation and that provided by LiDAR, using an outlier rejection process for accuracy improvement. Concerning LiDAR motion compensation, the visual odometry approach gives the initial guesses of LiDAR motions for better performance. This methodology is not only applicable to high-resolution LiDAR but can also adapt to low-resolution LiDAR. To evaluate the proposed SLAM system's robustness and accuracy, we conducted experiments on the KITTI Odometry and S3E datasets. Experimental results illustrate that our method significantly outperforms standalone ORB-SLAM2 and A-LOAM. Furthermore, regarding the accuracy of visual odometry with scale correction, our method performs similarly to the stereo-mode ORB-SLAM2.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08978v1","tag":"medical-cv"}}
{"title":"Neural Architecture Search for Visual Anomaly Segmentation","abstract":"This paper presents AutoPatch, the first application of neural architecture search to the complex task of segmenting visual anomalies. Measurement of anomaly segmentation quality is challenging due to imbalanced anomaly pixels, varying region areas, and various types of anomalies. First, the weighted average precision (wAP) metric is proposed as an alternative to AUROC and AUPRO, which does not need to be limited to a specific maximum FPR. Second, a novel neural architecture search method is proposed, which enables efficient segmentation of visual anomalies without any training. By leveraging a pre-trained supernet, a black-box optimization algorithm can directly minimize FLOPS and maximize wAP on a small validation set of anomalous examples. Finally, compelling results on the widely studied MVTec [3] dataset are presented, demonstrating that AutoPatch outperforms the current state-of-the-art method PatchCore [12] with more than 18x fewer FLOPS, using only one example per anomaly type. These results highlight the potential of automated machine learning to optimize throughput in industrial quality control. The code for AutoPatch is available at: https://github.com/tommiekerssies/AutoPatch","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08975v1","tag":"medical-cv"}}
{"title":"Fibroglandular Tissue Segmentation in Breast MRI using Vision Transformers -- A multi-institutional evaluation","abstract":"Accurate and automatic segmentation of fibroglandular tissue in breast MRI screening is essential for the quantification of breast density and background parenchymal enhancement. In this retrospective study, we developed and evaluated a transformer-based neural network for breast segmentation (TraBS) in multi-institutional MRI data, and compared its performance to the well established convolutional neural network nnUNet. TraBS and nnUNet were trained and tested on 200 internal and 40 external breast MRI examinations using manual segmentations generated by experienced human readers. Segmentation performance was assessed in terms of the Dice score and the average symmetric surface distance. The Dice score for nnUNet was lower than for TraBS on the internal testset (0.909$\\pm$0.069 versus 0.916$\\pm$0.067, P<0.001) and on the external testset (0.824$\\pm$0.144 versus 0.864$\\pm$0.081, P=0.004). Moreover, the average symmetric surface distance was higher (=worse) for nnUNet than for TraBS on the internal (0.657$\\pm$2.856 versus 0.548$\\pm$2.195, P=0.001) and on the external testset (0.727$\\pm$0.620 versus 0.584$\\pm$0.413, P=0.03). Our study demonstrates that transformer-based networks improve the quality of fibroglandular tissue segmentation in breast MRI compared to convolutional-based models like nnUNet. These findings might help to enhance the accuracy of breast density and parenchymal enhancement quantification in breast MRI screening.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08972v1","tag":"medical-cv"}}
{"title":"SurfelNeRF: Neural Surfel Radiance Fields for Online Photorealistic Reconstruction of Indoor Scenes","abstract":"Online reconstructing and rendering of large-scale indoor scenes is a long-standing challenge. SLAM-based methods can reconstruct 3D scene geometry progressively in real time but can not render photorealistic results. While NeRF-based methods produce promising novel view synthesis results, their long offline optimization time and lack of geometric constraints pose challenges to efficiently handling online input. Inspired by the complementary advantages of classical 3D reconstruction and NeRF, we thus investigate marrying explicit geometric representation with NeRF rendering to achieve efficient online reconstruction and high-quality rendering. We introduce SurfelNeRF, a variant of neural radiance field which employs a flexible and scalable neural surfel representation to store geometric attributes and extracted appearance features from input images. We further extend the conventional surfel-based fusion scheme to progressively integrate incoming input frames into the reconstructed global neural scene representation. In addition, we propose a highly-efficient differentiable rasterization scheme for rendering neural surfel radiance fields, which helps SurfelNeRF achieve $10\\times$ speedups in training and inference time, respectively. Experimental results show that our method achieves the state-of-the-art 23.82 PSNR and 29.58 PSNR on ScanNet in feedforward inference and per-scene optimization settings, respectively.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08971v1","tag":"medical-cv"}}
{"title":"Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to Detect with other LLMs","abstract":"The self-attention revolution allowed generative language models to scale and achieve increasingly impressive abilities. Such models - commonly referred to as Large Language Models (LLMs) - have recently gained prominence with the general public, thanks to conversational fine-tuning, putting their behavior in line with public expectations regarding AI. This prominence amplified prior concerns regarding the misuse of LLMs and led to the emergence of numerous tools to detect LLMs in the wild.   Unfortunately, most such tools are critically flawed. While major publications in the LLM detectability field suggested that LLMs were easy to detect with fine-tuned autoencoders, the limitations of their results are easy to overlook. Specifically, they assumed publicly available generative models without fine-tunes or non-trivial prompts. While the importance of these assumptions has been demonstrated, until now, it remained unclear how well such detection could be countered.   Here, we show that an attacker with access to such detectors' reference human texts and output not only evades detection but can fully frustrate the detector training - with a reasonable budget and all its outputs labeled as such. Achieving it required combining common \"reinforcement from critic\" loss function modification and AdamW optimizer, which led to surprisingly good fine-tuning generalization. Finally, we warn against the temptation to transpose the conclusions obtained in RNN-driven text GANs to LLMs due to their better representative ability.   These results have critical implications for the detection and prevention of malicious use of generative language models, and we hope they will aid the designers of generative models and detectors.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08968v1","tag":"medical-cv"}}
{"title":"All a-board: sharing educational data science research with school districts","abstract":"Educational data scientists often conduct research with the hopes of translating findings into lasting change through policy, civil society, or other channels. However, the bridge from research to practice can be fraught with sociopolitical frictions that impede, or altogether block, such translations -- especially when they are contentious or otherwise difficult to achieve. Focusing on one entrenched educational equity issue in US public schools -- racial and ethnic segregation -- we conduct randomized email outreach experiments and surveys to explore how local school districts respond to algorithmically-generated school catchment areas (\"attendance boundaries\") designed to foster more diverse and integrated schools. Cold email outreach to approximately 4,320 elected school board members across over 800 school districts informing them of potential boundary changes reveals a large average open rate of nearly 40%, but a relatively small click-through rate of 2.5% to an interactive dashboard depicting such changes. Board members, however, appear responsive to different messaging techniques -- particularly those that dovetail issues of racial and ethnic diversity with other top-of-mind issues (like school capacity planning). On the other hand, media coverage of the research drives more dashboard engagement, especially in more segregated districts. A small but rich set of survey responses from school board and community members across several districts identify data and operational bottlenecks to implementing boundary changes to foster more diverse schools, but also share affirmative comments on the potential viability of such changes. Together, our findings may support educational data scientists in more effectively disseminating research that aims to bridge educational inequalities through systems-level change.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08967v1","tag":"medical-cv"}}
{"title":"Predicting the Charge Density Response in Metal Electrodes","abstract":"The computational study of energy storage and conversion processes call for simulation techniques that can reproduce the electronic response of metal electrodes under electric fields. Despite recent advancements in machine-learning methods applied to electronic-structure properties, predicting the non-local behaviour of the charge density in electronic conductors remains a major open challenge. We combine long-range and equivariant kernel methods to predict the Kohn-Sham electron density of metal electrodes decomposed on an atom-centered basis. By taking slabs of gold as an example, we show that including long-range correlations into the learning model is essential to accurately reproduce the charge density and potential in bare electrodes of increasing size. A finite-field extension of the method is then introduced, which allows us to predict the charge transfer and the electrostatic potential drop induced by the application of an external electric field. Finally, we demonstrate the capability of the method to extrapolate the non-local electronic polarization generated by the interaction with an ionic species for electrodes of arbitrary thickness. Our study represents an important step forward in the accurate simulation of energy materials that include metallic interfaces.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08966v1","tag":"medical-cv"}}
{"title":"Unsupervised Semantic Segmentation of 3D Point Clouds via Cross-modal Distillation and Super-Voxel Clustering","abstract":"Semantic segmentation of point clouds usually requires exhausting efforts of human annotations, hence it attracts wide attention to the challenging topic of learning from unlabeled or weaker forms of annotations. In this paper, we take the first attempt for fully unsupervised semantic segmentation of point clouds, which aims to delineate semantically meaningful objects without any form of annotations. Previous works of unsupervised pipeline on 2D images fails in this task of point clouds, due to: 1) Clustering Ambiguity caused by limited magnitude of data and imbalanced class distribution; 2) Irregularity Ambiguity caused by the irregular sparsity of point cloud. Therefore, we propose a novel framework, PointDC, which is comprised of two steps that handle the aforementioned problems respectively: Cross-Modal Distillation (CMD) and Super-Voxel Clustering (SVC). In the first stage of CMD, multi-view visual features are back-projected to the 3D space and aggregated to a unified point feature to distill the training of the point representation. In the second stage of SVC, the point features are aggregated to super-voxels and then fed to the iterative clustering process for excavating semantic classes. PointDC yields a significant improvement over the prior state-of-the-art unsupervised methods, on both the ScanNet-v2 (+18.4 mIoU) and S3DIS (+11.5 mIoU) semantic segmentation benchmarks.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08965v1","tag":"medical-cv"}}
{"title":"The heavy quark expansion for lifetimes: Towards the QCD corrections to power suppressed terms","abstract":"We consider the Heavy Quark Expansion (HQE) for the nonleptonic decay rates of heavy hadrons, and compute the NLO QCD corrections to power terms up to order $1/m_Q^2$. We neglect the masses of the final-state quarks, so the application of our result is mainly for charmed hadrons. Our result can be applied also to bottomed hadrons as they constitute the main effect to this order up to corrections of $\\mathcal{O}(m_c/m_b)$ and contributions due to penguin operators. We discuss the impact of our result for the lifetimes of heavy hadrons.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08964v1","tag":"medical-cv"}}
{"title":"A personal discussion on conservation, and how to formulate it","abstract":"Since the celebrated theorem of Lax and Wendroff, we know a necessary condition that any numerical scheme for hyperbolic problem should satisfy: it should be written in flux form. A variant can also be formulated for the entropy. Even though some schemes, as for example those using continuous finite element, do not formally cast into this framework, it is a very convenient one. In this paper, we revisit this, introduce a different notion of local conservation which contains the previous one in one space dimension, and explore its consequences. This gives a more flexible framework that allows to get, systematically, entropy stable schemes, entropy dissipative ones, or accomodate more constraints. In particular, we can show that continuous finite element method can be rewritten in the finite volume framework, and all the quantities involved are explicitly computable. We end by presenting the only counter example we are aware of, i.e a scheme that seems not to be rewritten as a finite volume scheme.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08961v1","tag":"medical-cv"}}
{"title":"Generative modeling of living cells with SO(3)-equivariant implicit neural representations","abstract":"Data-driven cell tracking and segmentation methods in biomedical imaging require diverse and information-rich training data. In cases where the number of training samples is limited, synthetic computer-generated data sets can be used to improve these methods. This requires the synthesis of cell shapes as well as corresponding microscopy images using generative models. To synthesize realistic living cell shapes, the shape representation used by the generative model should be able to accurately represent fine details and changes in topology, which are common in cells. These requirements are not met by 3D voxel masks, which are restricted in resolution, and polygon meshes, which do not easily model processes like cell growth and mitosis. In this work, we propose to represent living cell shapes as level sets of signed distance functions (SDFs) which are estimated by neural networks. We optimize a fully-connected neural network to provide an implicit representation of the SDF value at any point in a 3D+time domain, conditioned on a learned latent code that is disentangled from the rotation of the cell shape. We demonstrate the effectiveness of this approach on cells that exhibit rapid deformations (Platynereis dumerilii), cells that grow and divide (C. elegans), and cells that have growing and branching filopodial protrusions (A549 human lung carcinoma cells). A quantitative evaluation using shape features, Hausdorff distance, and Dice similarity coefficients of real and synthetic cell shapes shows that our model can generate topologically plausible complex cell shapes in 3D+time with high similarity to real living cell shapes. Finally, we show how microscopy images of living cells that correspond to our generated cell shapes can be synthesized using an image-to-image model.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08960v1","tag":"medical-cv"}}
{"title":"How robust are particle physics predictions in asymptotic safety?","abstract":"The framework of trans-Planckian asymptotic safety has been shown to generate phenomenological predictions in the Standard Model and in some of its simple new physics extensions. A heuristic approach is often adopted, which bypasses the functional renormalization group by relying on a parametric description of quantum gravity with universal coefficients that are eventually obtained from low-energy observations. Within this approach, a few simplifying approximations are typically introduced, including the computation of matter renormalization group equations at 1~loop, an arbitrary definition of the position of the Planck scale at $10^{19}$ GeV, and an instantaneous decoupling of gravitational interactions below the Planck scale. In this work we systematically investigate, both analytically and numerically, the impact of dropping each of those approximations on the predictions for certain particle physics scenarios. In particular we study two extensions of the Standard Model, the gauged $B-L$ model and the leptoquark $S_3$ model, for which we determine a set of irrelevant gauge and Yukawa couplings. In each model, we present numerical and analytical estimates of the uncertainties associated with the predictions from asymptotic safety.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08959v1","tag":"medical-cv"}}
{"title":"PG-VTON: A Novel Image-Based Virtual Try-On Method via Progressive Inference Paradigm","abstract":"Virtual try-on is a promising computer vision topic with a high commercial value wherein a new garment is visually worn on a person with a photo-realistic effect. Previous studies conduct their shape and content inference at one stage, employing a single-scale warping mechanism and a relatively unsophisticated content inference mechanism. These approaches have led to suboptimal results in terms of garment warping and skin reservation under challenging try-on scenarios. To address these limitations, we propose a novel virtual try-on method via progressive inference paradigm (PGVTON) that leverages a top-down inference pipeline and a general garment try-on strategy. Specifically, we propose a robust try-on parsing inference method by disentangling semantic categories and introducing consistency. Exploiting the try-on parsing as the shape guidance, we implement the garment try-on via warping-mapping-composition. To facilitate adaptation to a wide range of try-on scenarios, we adopt a covering more and selecting one warping strategy and explicitly distinguish tasks based on alignment. Additionally, we regulate StyleGAN2 to implement re-naked skin inpainting, conditioned on the target skin shape and spatial-agnostic skin features. Experiments demonstrate that our method has state-of-the-art performance under two challenging scenarios. The code will be available at https://github.com/NerdFNY/PGVTON.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08956v1","tag":"medical-cv"}}
{"title":"Disentangling the gravity dual of Yang-Mills theory","abstract":"A construction of a gravity dual to a physical gauge theory requires confronting data. We establish a proof-of-concept for precision holography, i.e., the explicit reconstruction of the dual background metric functions directly from the entanglement entropy (EE) of strip subregions that we extract from pure glue Yang-Mills theory discretized on a lattice. Our main focus is on a three-dimensional Euclidean SU(2) theory in the deconfining phase. We find that the dependencies of the EE on the strip width come with fractional power laws, behaviors innate to a geometry induced by a stack of D2-branes. Holographic EE further suggests, and we find evidence for, that the scaling of the thermal entropy with temperature is to power 7/3 and that it approaches smoothly the critical point, consistent with black hole thermodynamics and that the theory belongs in the same universality class as the two-dimensional critical Ising model, respectively. In addition, we provide frugal results on the potential between quenched quarks by the computation of the Polyakov loop correlators on the lattice. Holographic arguments pique curiosity in the substratum of Debye screening at strong coupling.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08949v1","tag":"medical-cv"}}
{"title":"Audio-Driven Talking Face Generation with Diverse yet Realistic Facial Animations","abstract":"Audio-driven talking face generation, which aims to synthesize talking faces with realistic facial animations (including accurate lip movements, vivid facial expression details and natural head poses) corresponding to the audio, has achieved rapid progress in recent years. However, most existing work focuses on generating lip movements only without handling the closely correlated facial expressions, which degrades the realism of the generated faces greatly. This paper presents DIRFA, a novel method that can generate talking faces with diverse yet realistic facial animations from the same driving audio. To accommodate fair variation of plausible facial animations for the same audio, we design a transformer-based probabilistic mapping network that can model the variational facial animation distribution conditioned upon the input audio and autoregressively convert the audio signals into a facial animation sequence. In addition, we introduce a temporally-biased mask into the mapping network, which allows to model the temporal dependency of facial animations and produce temporally smooth facial animation sequence. With the generated facial animation sequence and a source image, photo-realistic talking faces can be synthesized with a generic generation network. Extensive experiments show that DIRFA can generate talking faces with realistic facial animations effectively.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08945v1","tag":"medical-cv"}}
{"title":"Early detection of hip periprosthetic joint infections through CNN on Computed Tomography images","abstract":"Early detection of an infection prior to prosthesis removal (e.g., hips, knees or other areas) would provide significant benefits to patients. Currently, the detection task is carried out only retrospectively with a limited number of methods relying on biometric or other medical data. The automatic detection of a periprosthetic joint infection from tomography imaging is a task never addressed before. This study introduces a novel method for early detection of the hip prosthesis infections analyzing Computed Tomography images. The proposed solution is based on a novel ResNeSt Convolutional Neural Network architecture trained on samples from more than 100 patients. The solution showed exceptional performance in detecting infections with an experimental high level of accuracy and F-score.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08942v1","tag":"medical-cv"}}
{"title":"POCE: Pose-Controllable Expression Editing","abstract":"Facial expression editing has attracted increasing attention with the advance of deep neural networks in recent years. However, most existing methods suffer from compromised editing fidelity and limited usability as they either ignore pose variations (unrealistic editing) or require paired training data (not easy to collect) for pose controls. This paper presents POCE, an innovative pose-controllable expression editing network that can generate realistic facial expressions and head poses simultaneously with just unpaired training images. POCE achieves the more accessible and realistic pose-controllable expression editing by mapping face images into UV space, where facial expressions and head poses can be disentangled and edited separately. POCE has two novel designs. The first is self-supervised UV completion that allows to complete UV maps sampled under different head poses, which often suffer from self-occlusions and missing facial texture. The second is weakly-supervised UV editing that allows to generate new facial expressions with minimal modification of facial identity, where the synthesized expression could be controlled by either an expression label or directly transplanted from a reference UV map via feature transfer. Extensive experiments show that POCE can learn from unpaired face images effectively, and the learned model can generate realistic and high-fidelity facial expressions under various new poses.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08938v1","tag":"medical-cv"}}
{"title":"Hamiltonian simulation using quantum singular value transformation: complexity analysis and application to the linearized Vlasov-Poisson equation","abstract":"Quantum computing can be used to speed up the simulation time (more precisely, the number of queries of the algorithm) for physical systems; one such promising approach is the Hamiltonian simulation (HS) algorithm. Recently, it was proven that the quantum singular value transformation (QSVT) achieves the minimum simulation time for HS. An important subroutine of the QSVT-based HS algorithm is the amplitude amplification operation, which can be realized via the oblivious amplitude amplification or the fixed-point amplitude amplification in the QSVT framework. In this work, we execute a detailed analysis of the error and number of queries of the QSVT-based HS and show that the oblivious method is better than the fixed-point one in the sense of simulation time for a given error tolerance. Based on this finding, we apply the QSVT-based HS to the one-dimensional linearized Vlasov-Poisson equation and demonstrate that the linear Landau damping can be successfully simulated.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08937v1","tag":"medical-cv"}}
{"title":"Enhancing Textbooks with Visuals from the Web for Improved Learning","abstract":"Textbooks are the primary vehicle for delivering quality education to students. It has been shown that explanatory or illustrative visuals play a key role in the retention, comprehension and the general transfer of knowledge. However, many textbooks, especially in the developing world, are low quality and lack interesting visuals to support student learning. In this paper, we investigate the effectiveness of vision-language models to automatically enhance textbooks with images from the web. Specifically, we collect a dataset of e-textbooks from one of the largest free online publishers in the world. We rigorously analyse the dataset, and use the resulting analysis to motivate a task that involves retrieving and appropriately assigning web images to textbooks, which we frame as a novel optimization problem. Through a crowd-sourced evaluation, we verify that (1) while the original textbook images are rated higher, automatically assigned ones are not far behind, and (2) the choice of the optimization problem matters. We release the dataset of textbooks with an associated image bank to spur further research in this area.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08931v1","tag":"medical-cv"}}
{"title":"SDFReg: Learning Signed Distance Functions for Point Cloud Registration","abstract":"Learning-based point cloud registration methods can handle clean point clouds well, while it is still challenging to generalize to noisy and partial point clouds. To this end, we propose a novel framework for noisy and partial point cloud registration. By introducing a neural implicit function representation, we replace the problem of rigid registration between point clouds with a registration problem between the point cloud and the neural implicit function. We then alternately optimize the implicit function representation and the registration between the implicit function and point cloud. In this way, point cloud registration can be performed in a coarse-to-fine manner. Since our method avoids computing point correspondences, it is robust to the noise and incompleteness of point clouds. Compared with the registration methods based on global features, our method can deal with surfaces with large density variations and achieve higher registration accuracy. Experimental results and comparisons demonstrate the effectiveness of the proposed framework.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08929v1","tag":"medical-cv"}}
{"title":"Multitenant Containers as a Service (CaaS) for Clouds and Edge Clouds","abstract":"Cloud computing, offering on-demand access to computing resources through the Internet and the pay-as-you-go model, has marked the last decade with its three main service models; Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS). The lightweight nature of containers compared to virtual machines has led to the rapid uptake of another in recent years, called Containers as a Service (CaaS), which falls between IaaS and PaaS regarding control abstraction. However, when CaaS is offered to multiple independent users, or tenants, a multi-instance approach is used, in which each tenant receives its own separate cluster, which reimposes significant overhead due to employing virtual machines for isolation. If CaaS is to be offered not just at the cloud, but also at the edge cloud, where resources are limited, another solution is required. We introduce a native CaaS multitenancy framework, meaning that tenants share a cluster, which is more efficient than the one tenant per cluster model. Whenever there are shared resources, isolation of multitenant workloads is an issue. Such workloads can be isolated by Kata Containers today. Besides, our framework esteems the application requirements that compel complete isolation and a fully customized environment. Node-level slicing empowers tenants to programmatically reserve isolated subclusters where they can choose the container runtime that suits application needs. The framework is publicly available as liberally-licensed, free, open-source software that extends Kubernetes, the de facto standard container orchestration system. It is in production use within the EdgeNet testbed for researchers.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08927v1","tag":"medical-cv"}}
{"title":"Quantum Annealing for Single Image Super-Resolution","abstract":"This paper proposes a quantum computing-based algorithm to solve the single image super-resolution (SISR) problem. One of the well-known classical approaches for SISR relies on the well-established patch-wise sparse modeling of the problem. Yet, this field's current state of affairs is that deep neural networks (DNNs) have demonstrated far superior results than traditional approaches. Nevertheless, quantum computing is expected to become increasingly prominent for machine learning problems soon. As a result, in this work, we take the privilege to perform an early exploration of applying a quantum computing algorithm to this important image enhancement problem, i.e., SISR. Among the two paradigms of quantum computing, namely universal gate quantum computing and adiabatic quantum computing (AQC), the latter has been successfully applied to practical computer vision problems, in which quantum parallelism has been exploited to solve combinatorial optimization efficiently. This work demonstrates formulating quantum SISR as a sparse coding optimization problem, which is solved using quantum annealers accessed via the D-Wave Leap platform. The proposed AQC-based algorithm is demonstrated to achieve improved speed-up over a classical analog while maintaining comparable SISR accuracy.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08924v1","tag":"medical-cv"}}
{"title":"Questioning the impact of AI and interdisciplinarity in science: Lessons from COVID-19","abstract":"Artificial intelligence (AI) has emerged as one of the most promising technologies to support COVID-19 research, with interdisciplinary collaborations between medical professionals and AI specialists being actively encouraged since the early stages of the pandemic. Yet, our analysis of more than 10,000 papers at the intersection of COVID-19 and AI suggest that these collaborations have largely resulted in science of low visibility and impact. We show that scientific impact was not determined by the overall interdisciplinarity of author teams, but rather by the diversity of knowledge they actually harnessed in their research. Our results provide insights into the ways in which team and knowledge structure may influence the successful integration of new computational technologies in the sciences.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08923v1","tag":"medical-cv"}}
{"title":"Networking quantum networks with minimum cost aggregation","abstract":"A quantum internet holds promise for accomplishing distributed quantum sensing and large-scale quantum computer networks, as well as quantum communication among arbitrary clients all over the globe. The main building block is efficient distribution of entanglement, entangled bits (ebits), across quantum networks. This could be achieved by aggregating quantum repeater protocols. However, the existing protocol is not practical as it requires point-to-point entanglement generation, the first step of the protocol, not only to suppress the error, depending on the whole size of the networks, but also to be run more than necessary. Here we present a practical recipe on how to aggregate quantum networks in order to present ebits to clients with minimum cost. This is combined with a conception of concatenation to enable arbitrary clients to have arbitrary long-distance communication with fixed error across quantum networks, regardless of the overall size. Our recipe forms the basis of designing a quantum internet protocol to control a self-organizing large-scale quantum network.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08921v1","tag":"medical-cv"}}
{"title":"Coefficient Synthesis for Threshold Automata","abstract":"Threshold automata are a formalism for modeling fault-tolerant distributed algorithms. The main feature of threshold automata is the notion of a threshold guard, which allows us to compare the number of received messages with the total number of different types of processes. In this paper, we consider the coefficient synthesis problem for threshold automata, in which we are given a sketch of a threshold automaton (with the constants in the threshold guards left unspecified) and a specification and we want to synthesize a set of constants which when plugged into the sketch, gives a threshold automaton satisfying the specification. Our main result is that this problem is undecidable, even when the specification is a coverability specification and the underlying sketch is acyclic.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08917v1","tag":"medical-cv"}}
{"title":"Pose Constraints for Consistent Self-supervised Monocular Depth and Ego-motion","abstract":"Self-supervised monocular depth estimation approaches suffer not only from scale ambiguity but also infer temporally inconsistent depth maps w.r.t. scale. While disambiguating scale during training is not possible without some kind of ground truth supervision, having scale consistent depth predictions would make it possible to calculate scale once during inference as a post-processing step and use it over-time. With this as a goal, a set of temporal consistency losses that minimize pose inconsistencies over time are introduced. Evaluations show that introducing these constraints not only reduces depth inconsistencies but also improves the baseline performance of depth and ego-motion prediction.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08916v1","tag":"medical-cv"}}
{"title":"Differentiable Genetic Programming for High-dimensional Symbolic Regression","abstract":"Symbolic regression (SR) is the process of discovering hidden relationships from data with mathematical expressions, which is considered an effective way to reach interpretable machine learning (ML). Genetic programming (GP) has been the dominator in solving SR problems. However, as the scale of SR problems increases, GP often poorly demonstrates and cannot effectively address the real-world high-dimensional problems. This limitation is mainly caused by the stochastic evolutionary nature of traditional GP in constructing the trees. In this paper, we propose a differentiable approach named DGP to construct GP trees towards high-dimensional SR for the first time. Specifically, a new data structure called differentiable symbolic tree is proposed to relax the discrete structure to be continuous, thus a gradient-based optimizer can be presented for the efficient optimization. In addition, a sampling method is proposed to eliminate the discrepancy caused by the above relaxation for valid symbolic expressions. Furthermore, a diversification mechanism is introduced to promote the optimizer escaping from local optima for globally better solutions. With these designs, the proposed DGP method can efficiently search for the GP trees with higher performance, thus being capable of dealing with high-dimensional SR. To demonstrate the effectiveness of DGP, we conducted various experiments against the state of the arts based on both GP and deep neural networks. The experiment results reveal that DGP can outperform these chosen peer competitors on high-dimensional regression benchmarks with dimensions varying from tens to thousands. In addition, on the synthetic SR problems, the proposed DGP method can also achieve the best recovery rate even with different noisy levels. It is believed this work can facilitate SR being a powerful alternative to interpretable ML for a broader range of real-world problems.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08915v1","tag":"medical-cv"}}
{"title":"Computational and Exploratory Landscape Analysis of the GKLS Generator","abstract":"The GKLS generator is one of the most used testbeds for benchmarking global optimization algorithms. In this paper, we conduct both a computational analysis and the Exploratory Landscape Analysis (ELA) of the GKLS generator. We utilize both canonically used and newly generated classes of GKLS-generated problems and show their use in benchmarking three state-of-the-art methods (from evolutionary and deterministic communities) in dimensions 5 and 10. We show that the GKLS generator produces ``needle in a haystack'' type problems that become extremely difficult to optimize in higher dimensions. Furthermore, we conduct the ELA on the GKLS generator and then compare it to the ELA of two other widely used benchmark sets (BBOB and CEC 2014), and discuss the meaningfulness of the results.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08913v1","tag":"medical-cv"}}
{"title":"Towards Zero-Shot Personalized Table-to-Text Generation with Contrastive Persona Distillation","abstract":"Existing neural methods have shown great potentials towards generating informative text from structured tabular data as well as maintaining high content fidelity. However, few of them shed light on generating personalized expressions, which often requires well-aligned persona-table-text datasets that are difficult to obtain. To overcome these obstacles, we explore personalized table-to-text generation under a zero-shot setting, by assuming no well-aligned persona-table-text triples are required during training. To this end, we firstly collect a set of unpaired persona information and then propose a semi-supervised approach with contrastive persona distillation (S2P-CPD) to generate personalized context. Specifically, tabular data and persona information are firstly represented as latent variables separately. Then, we devise a latent space fusion technique to distill persona information into the table representation. Besides, a contrastive-based discriminator is employed to guarantee the style consistency between the generated context and its corresponding persona. Experimental results on two benchmarks demonstrate S2P-CPD's ability on keeping both content fidelity and personalized expressions.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08911v1","tag":"medical-cv"}}
{"title":"Curvature estimation for meshes via algebraic quadric fitting","abstract":"We introduce the novel method for estimation of mean and Gaussian curvature and several related quantities for polygonal meshes. The algebraic quadric fitting curvature (AQFC) is based on local approximation of the mesh vertices and associated normals by a quadratic surface. The quadric is computed as an implicit surface, so it minimizes algebraic distances and normal deviations from the approximated point-normal neighbourhood of the processed vertex. Its mean and Gaussian curvature estimate is then obtained as the respective curvature of its orthogonal projection onto the fitted quadratic surface. Experimental results for both sampled parametric surfaces and arbitrary meshes are provided. The proposed method AQFC approaches the true curvatures of the reference smooth surfaces with increasing density of sampling, regardless of its regularity. It is resilient to irregular sampling of the mesh, compared to the contemporary curvature estimators. In the case of arbitrary meshes, obtained from scanning, AQFC provides robust curvature estimation.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08909v1","tag":"medical-cv"}}
{"title":"Event Camera and LiDAR based Human Tracking for Adverse Lighting Conditions in Subterranean Environments","abstract":"In this article, we propose a novel LiDAR and event camera fusion modality for subterranean (SubT) environments for fast and precise object and human detection in a wide variety of adverse lighting conditions, such as low or no light, high-contrast zones and in the presence of blinding light sources. In the proposed approach, information from the event camera and LiDAR are fused to localize a human or an object-of-interest in a robot's local frame. The local detection is then transformed into the inertial frame and used to set references for a Nonlinear Model Predictive Controller (NMPC) for reactive tracking of humans or objects in SubT environments. The proposed novel fusion uses intensity filtering and K-means clustering on the LiDAR point cloud and frequency filtering and connectivity clustering on the events induced in an event camera by the returning LiDAR beams. The centroids of the clusters in the event camera and LiDAR streams are then paired to localize reflective markers present on safety vests and signs in SubT environments. The efficacy of the proposed scheme has been experimentally validated in a real SubT environment (a mine) with a Pioneer 3AT mobile robot. The experimental results show real-time performance for human detection and the NMPC-based controller allows for reactive tracking of a human or object of interest, even in complete darkness.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08908v1","tag":"medical-cv"}}
{"title":"Functional Limit Theorems for Dynamical Systems with Correlated Maximal Sets","abstract":"In order to obtain functional limit theorems for heavy tailed stationary processes arising from dynamical systems, one needs to understand the clustering patterns of the tail observations of the process. These patterns are well described by means of a structure called the pilling process introduced recently in the context of dynamical systems. So far, the pilling process has been computed only for observable functions maximised at a single repelling fixed point. Here, we study richer clustering behaviours by considering correlated maximal sets, in the sense that the observable is maximised in multiple points belonging to the same orbit, and we work out explicit expressions for the pilling process when the dynamics is piecewise linear and expanding ($1$-dimensional and $2$-dimensional).","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08903v1","tag":"medical-cv"}}
{"title":"Parallel Greedy Spanners","abstract":"A $t$-spanner of a graph is a subgraph that $t$-approximates pairwise distances. The greedy algorithm is one of the simplest and most well-studied algorithms for constructing a sparse spanner: it computes a $t$-spanner with $n^{1+O(1/t)}$ edges by repeatedly choosing any edge which does not close a cycle of chosen edges with $t+1$ or fewer edges.   We demonstrate that the greedy algorithm computes a $t$-spanner with $n^{1 + O(1/t)}$ edges even when a matching of such edges are added in parallel. In particular, it suffices to repeatedly add any matching where each individual edge does not close a cycle with $t +1$ or fewer edges but where adding the entire matching might. Our analysis makes use of and illustrates the power of new advances in length-constrained expander decompositions.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08892v1","tag":"medical-cv"}}
{"title":"Tailoring Domain Adaptation for Machine Translation Quality Estimation","abstract":"While quality estimation (QE) can play an important role in the translation process, its effectiveness relies on the availability and quality of training data. For QE in particular, high-quality labeled data is often lacking due to the high-cost and effort associated with labeling such data. Aside from the data scarcity challenge, QE models should also be generalizable, i.e., they should be able to handle data from different domains, both generic and specific. To alleviate these two main issues -- data scarcity and domain mismatch -- this paper combines domain adaptation and data augmentation within a robust QE system. Our method is to first train a generic QE model and then fine-tune it on a specific domain while retaining generic knowledge. Our results show a significant improvement for all the language pairs investigated, better cross-lingual inference, and a superior performance in zero-shot learning scenarios as compared to state-of-the-art baselines.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08891v1","tag":"medical-cv"}}
{"title":"SOStab: a Matlab Toolbox for Approximating Regions of Attraction of Nonlinear Systems","abstract":"This paper presents a novel Matlab toolbox, aimed at facilitating the use of polynomial optimization for stability analysis of nonlinear systems. Indeed, in the past decade several decisive contributions made it possible to recast the difficult problem of computing stability regions of nonlinear systems, under the form of convex optimization problems that are tractable in modest dimensions. However, these techniques combine sophisticated frameworks such as algebraic geometry, measure theory and mathematical programming, and existing software still requires their user to be fluent in Sum-of-Squares and Moment programming, preventing these techniques from being used more widely in the control community. To address this issue, SOStab entirely automates the writing and solving of optimization problems, and directly outputs relevant data for the user, while requiring minimal input. In particular, no specific knowledge of optimization is needed to use it.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08889v1","tag":"medical-cv"}}
{"title":"Additively manufactured polyethylene terephthalate scaffolds for Scapholunate Interosseous Ligament Reconstruction","abstract":"The regeneration of the ruptured scapholunate interosseous ligament (SLIL) represents a clinical challenge. Here, we propose the use of a Bone-Ligament-Bone (BLB) 3D-printed polyethylene terephthalate (PET) scaffold for achieving mechanical stabilisation of the scaphoid and lunate following SLIL rupture. The BLB scaffold featured two bone compartments bridged by aligned fibres (ligament compartment) mimicking the architecture of the native tissue. The scaffold presented tensile stiffness in the range of 260+/-38 N/mm and ultimate load of 113+/-13 N, which would support physiological loading. A finite element analysis, using inverse finite element analysis for material property identification, showed an adequate fit between simulation and experimental data. The scaffold was then biofunctionalized using two different methods: injected with a Gelatin Methacryloyl solution containing human mesenchymal stem cell spheroids or seeded with tendon-derived stem cells and placed in a bioreactor to undergo cyclic deformation. The first approach demonstrated high cell viability, as cells migrated out of the spheroid and colonised the interstitial space of the scaffold. These cells adopted an elongated morphology suggesting the internal architecture of the scaffold exerted topographical guidance. The second method demonstrated the high resilience of the scaffold to cyclic deformation and the secretion of a fibroblastic related protein was enhanced by the mechanical stimulation. This process promoted the expression of relevant proteins, such as Tenomodulin, indicating mechanical stimulation may enhance cell differentiation and be useful prior to surgical implantation. In conclusion, the PET scaffold presented several promising characteristics for the immediate mechanical stabilisation of disassociated scaphoid and lunate and, in the longer-term, the regeneration of the ruptured SLIL.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08886v1","tag":"medical-cv"}}
{"title":"Segmentation of glioblastomas in early post-operative multi-modal MRI with deep neural networks","abstract":"Extent of resection after surgery is one of the main prognostic factors for patients diagnosed with glioblastoma. To achieve this, accurate segmentation and classification of residual tumor from post-operative MR images is essential. The current standard method for estimating it is subject to high inter- and intra-rater variability, and an automated method for segmentation of residual tumor in early post-operative MRI could lead to a more accurate estimation of extent of resection. In this study, two state-of-the-art neural network architectures for pre-operative segmentation were trained for the task. The models were extensively validated on a multicenter dataset with nearly 1000 patients, from 12 hospitals in Europe and the United States. The best performance achieved was a 61\\% Dice score, and the best classification performance was about 80\\% balanced accuracy, with a demonstrated ability to generalize across hospitals. In addition, the segmentation performance of the best models was on par with human expert raters. The predicted segmentations can be used to accurately classify the patients into those with residual tumor, and those with gross total resection.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08881v1","tag":"medical-cv"}}
{"title":"NPS: A Framework for Accurate Program Sampling Using Graph Neural Network","abstract":"With the end of Moore's Law, there is a growing demand for rapid architectural innovations in modern processors, such as RISC-V custom extensions, to continue performance scaling. Program sampling is a crucial step in microprocessor design, as it selects representative simulation points for workload simulation. While SimPoint has been the de-facto approach for decades, its limited expressiveness with Basic Block Vector (BBV) requires time-consuming human tuning, often taking months, which impedes fast innovation and agile hardware development. This paper introduces Neural Program Sampling (NPS), a novel framework that learns execution embeddings using dynamic snapshots of a Graph Neural Network. NPS deploys AssemblyNet for embedding generation, leveraging an application's code structures and runtime states. AssemblyNet serves as NPS's graph model and neural architecture, capturing a program's behavior in aspects such as data computation, code path, and data flow. AssemblyNet is trained with a data prefetch task that predicts consecutive memory addresses.   In the experiments, NPS outperforms SimPoint by up to 63%, reducing the average error by 38%. Additionally, NPS demonstrates strong robustness with increased accuracy, reducing the expensive accuracy tuning overhead. Furthermore, NPS shows higher accuracy and generality than the state-of-the-art GNN approach in code behavior learning, enabling the generation of high-quality execution embeddings.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08880v1","tag":"medical-cv"}}
{"title":"Deep Collective Knowledge Distillation","abstract":"Many existing studies on knowledge distillation have focused on methods in which a student model mimics a teacher model well.   Simply imitating the teacher's knowledge, however, is not sufficient for the student to surpass that of the teacher.   We explore a method to harness the knowledge of other students to complement the knowledge of the teacher.   We propose deep collective knowledge distillation for model compression, called DCKD, which is a method for training student models with rich information to acquire knowledge from not only their teacher model but also other student models.   The knowledge collected from several student models consists of a wealth of information about the correlation between classes.   Our DCKD considers how to increase the correlation knowledge of classes during training.   Our novel method enables us to create better performing student models for collecting knowledge.   This simple yet powerful method achieves state-of-the-art performances in many experiments.   For example, for ImageNet, ResNet18 trained with DCKD achieves 72.27\\%, which outperforms the pretrained ResNet18 by 2.52\\%.   For CIFAR-100, the student model of ShuffleNetV1 with DCKD achieves 6.55\\% higher top-1 accuracy than the pretrained ShuffleNetV1.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08878v1","tag":"medical-cv"}}
{"title":"Dynamic Coarse-to-Fine Learning for Oriented Tiny Object Detection","abstract":"Detecting arbitrarily oriented tiny objects poses intense challenges to existing detectors, especially for label assignment. Despite the exploration of adaptive label assignment in recent oriented object detectors, the extreme geometry shape and limited feature of oriented tiny objects still induce severe mismatch and imbalance issues. Specifically, the position prior, positive sample feature, and instance are mismatched, and the learning of extreme-shaped objects is biased and unbalanced due to little proper feature supervision. To tackle these issues, we propose a dynamic prior along with the coarse-to-fine assigner, dubbed DCFL. For one thing, we model the prior, label assignment, and object representation all in a dynamic manner to alleviate the mismatch issue. For another, we leverage the coarse prior matching and finer posterior constraint to dynamically assign labels, providing appropriate and relatively balanced supervision for diverse instances. Extensive experiments on six datasets show substantial improvements to the baseline. Notably, we obtain the state-of-the-art performance for one-stage detectors on the DOTA-v1.5, DOTA-v2.0, and DIOR-R datasets under single-scale training and testing. Codes are available at https://github.com/Chasel-Tsui/mmrotate-dcfl.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08876v1","tag":"medical-cv"}}
{"title":"Secured and Cooperative Publish/Subscribe Scheme in Autonomous Vehicular Networks","abstract":"In order to save computing power yet enhance safety, there is a strong intention for autonomous vehicles (AVs) in future to drive collaboratively by sharing sensory data and computing results among neighbors. However, the intense collaborative computing and data transmissions among unknown others will inevitably introduce severe security concerns. Aiming at addressing security concerns in future AVs, in this paper, we develop SPAD, a secured framework to forbid free-riders and {promote trustworthy data dissemination} in collaborative autonomous driving. Specifically, we first introduce a publish/subscribe framework for inter-vehicle data transmissions{. To defend against free-riding attacks,} we formulate the interactions between publisher AVs and subscriber AVs as a vehicular publish/subscribe game, {and incentivize AVs to deliver high-quality data by analyzing the Stackelberg equilibrium of the game. We also design a reputation evaluation mechanism in the game} to identify malicious AVs {in disseminating fake information}. {Furthermore, for} lack of sufficient knowledge on parameters of {the} network model and user cost model {in dynamic game scenarios}, a two-tier reinforcement learning based algorithm with hotbooting is developed to obtain the optimal {strategies of subscriber AVs and publisher AVs with free-rider prevention}. Extensive simulations are conducted, and the results validate that our SPAD can effectively {prevent free-riders and enhance the dependability of disseminated contents,} compared with conventional schemes.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08875v1","tag":"medical-cv"}}
{"title":"A Simple Rewrite System for the Normalization of Linear Temporal Logic","abstract":"In the mid 80s, Lichtenstein, Pnueli, and Zuck showed that every formula of Past LTL (the extension of Linear Temporal Logic with past operators) is equivalent to a conjunction of formulas of the form $\\mathbf{G}\\mathbf{F} \\varphi \\vee \\mathbf{F}\\mathbf{G} \\psi$, where $\\varphi$ and $\\psi$ contain only past operators. Some years later, Chang, Manna, and Pnueli derived a similar normal form for LTL. Both normalization procedures have a non-elementary worst-case blow-up, and follow an involved path from formulas to counter-free automata to star-free regular expressions and back to formulas. In 2020, Sickert and Esparza presented a direct and purely syntactic normalization procedure for LTL yielding a normal form similar to the one by Chang, Manna, and Pnueli, with a single exponential blow-up, and applied it to the problem of constructing a succinct deterministic $\\omega$-automaton for a given formula. However, their procedure had exponential time complexity in the best case. In particular, it does not perform better for formulas that are almost in normal form. In this paper we present an alternative normalization procedure based on a simple set of rewrite rules.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08872v1","tag":"medical-cv"}}
{"title":"UPGPT: Universal Diffusion Model for Person Image Generation, Editing and Pose Transfer","abstract":"Existing person image generative models can do either image generation or pose transfer but not both. We propose a unified diffusion model, UPGPT to provide a universal solution to perform all the person image tasks - generative, pose transfer, and editing. With fine-grained multimodality and disentanglement capabilities, our approach offers fine-grained control over the generation and the editing process of images using a combination of pose, text, and image, all without needing a semantic segmentation mask which can be challenging to obtain or edit. We also pioneer the parameterized body SMPL model in pose-guided person image generation to demonstrate new capability - simultaneous pose and camera view interpolation while maintaining a person's appearance. Results on the benchmark DeepFashion dataset show that UPGPT is the new state-of-the-art while simultaneously pioneering new capabilities of edit and pose transfer in human image generation.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08870v1","tag":"medical-cv"}}
{"title":"Soft-Output Deep Neural Network-Based Decoding","abstract":"Deep neural network (DNN)-based channel decoding is widely considered in the literature. The existing solutions are investigated for the case of hard output, i.e. when the decoder returns the estimated information word. At the same time, soft-output decoding is of critical importance for iterative receivers and decoders. In this paper, we focus on the soft-output DNN-based decoding problem. We start with the syndrome-based approach proposed by Bennatan et al. (2018) and modify it to provide soft output in the AWGN channel. The new decoder can be considered as an approximation of the MAP decoder with smaller computation complexity. We discuss various regularization functions for joint DNN-MAP training and compare the resulting distributions for [64, 45] BCH code. Finally, to demonstrate the soft-output quality we consider the turbo-product code with [64, 45] BCH codes as row and column codes. We show that the resulting DNN-based scheme is very close to the MAP-based performance and significantly outperforms the solution based on the Chase decoder. We come to the conclusion that the new method is prospective for the challenging problem of DNN-based decoding of long codes consisting of short component codes.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08868v1","tag":"medical-cv"}}
{"title":"Romanization-based Large-scale Adaptation of Multilingual Language Models","abstract":"Large multilingual pretrained language models (mPLMs) have become the de facto state of the art for cross-lingual transfer in NLP. However, their large-scale deployment to many languages, besides pretraining data scarcity, is also hindered by the increase in vocabulary size and limitations in their parameter budget. In order to boost the capacity of mPLMs to deal with low-resource and unseen languages, we explore the potential of leveraging transliteration on a massive scale. In particular, we explore the UROMAN transliteration tool, which provides mappings from UTF-8 to Latin characters for all the writing systems, enabling inexpensive romanization for virtually any language. We first focus on establishing how UROMAN compares against other language-specific and manually curated transliterators for adapting multilingual PLMs. We then study and compare a plethora of data- and parameter-efficient strategies for adapting the mPLMs to romanized and non-romanized corpora of 14 diverse low-resource languages. Our results reveal that UROMAN-based transliteration can offer strong performance for many languages, with particular gains achieved in the most challenging setups: on languages with unseen scripts and with limited training data without any vocabulary augmentation. Further analyses reveal that an improved tokenizer based on romanized data can even outperform non-transliteration-based methods in the majority of languages.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08865v1","tag":"medical-cv"}}
{"title":"Online fair division with arbitrary entitlements","abstract":"The division of goods in the online realm poses opportunities and challenges. While innovative mechanisms can be developed, uncertainty about the future may hinder effective solutions. This project aims to explore fair distribution models for goods among agents with arbitrary entitlements, specifically addressing food charity challenges in the real world. Building upon prior work in [AAGW15], which focuses on equal entitlements, our project seeks to better understand the proofs of the theorems mentioned in that paper, which currently only provide proof sketches. Our approach employs different proof techniques from those presented in [AAGW15]","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08864v1","tag":"medical-cv"}}
{"title":"Approximate Nearest Neighbour Phrase Mining for Contextual Speech Recognition","abstract":"This paper presents an extension to train end-to-end Context-Aware Transformer Transducer ( CATT ) models by using a simple, yet efficient method of mining hard negative phrases from the latent space of the context encoder. During training, given a reference query, we mine a number of similar phrases using approximate nearest neighbour search. These sampled phrases are then used as negative examples in the context list alongside random and ground truth contextual information. By including approximate nearest neighbour phrases (ANN-P) in the context list, we encourage the learned representation to disambiguate between similar, but not identical, biasing phrases. This improves biasing accuracy when there are several similar phrases in the biasing inventory. We carry out experiments in a large-scale data regime obtaining up to 7% relative word error rate reductions for the contextual portion of test data. We also extend and evaluate CATT approach in streaming applications.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08862v1","tag":"medical-cv"}}
{"title":"Revisiting Fast Fourier multiplication algorithms on quotient rings","abstract":"This work formalizes efficient Fast Fourier-based multiplication algorithms for polynomials in quotient rings such as $\\mathbb{Z}_{m}[x]/\\left<x^{n}-a\\right>$, with $n$ a power of 2 and $m$ a non necessarily prime integer. We also present a meticulous study on the necessary and/or sufficient conditions required for the applicability of these multiplication algorithms. This paper allows us to unify the different approaches to the problem of efficiently computing the product of two polynomials in these quotient rings.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08860v1","tag":"medical-cv"}}
{"title":"Unveiling and unraveling aggregation and dispersion fallacies in group MCDM","abstract":"Priorities in multi-criteria decision-making (MCDM) convey the relevance preference of one criterion over another, which is usually reflected by imposing the non-negativity and unit-sum constraints. The processing of such priorities is different than other unconstrained data, but this point is often neglected by researchers, which results in fallacious statistical analysis. This article studies three prevalent fallacies in group MCDM along with solutions based on compositional data analysis to avoid misusing statistical operations. First, we use a compositional approach to aggregate the priorities of a group of DMs and show that the outcome of the compositional analysis is identical to the normalized geometric mean, meaning that the arithmetic mean should be avoided. Furthermore, a new aggregation method is developed, which is a robust surrogate for the geometric mean. We also discuss the errors in computing measures of dispersion, including standard deviation and distance functions. Discussing the fallacies in computing the standard deviation, we provide a probabilistic criteria ranking by developing proper Bayesian tests, where we calculate the extent to which a criterion is more important than another. Finally, we explain the errors in computing the distance between priorities, and a clustering algorithm is specially tailored based on proper distance metrics.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08859v1","tag":"medical-cv"}}
{"title":"Stochastic spin-orbit-torque device as the STDP synapse for spiking neural networks","abstract":"Neuromorphic hardware as a non-Von Neumann architecture has better energy efficiency and parallelism than the conventional computer. Here, with numerical modeling spin-orbit torque (SOT) device using current-induced SOT and Joule heating effects, we acquire its magnetization switching probability as a function of the input current pulses and use it to mimic the spike-timing-dependent plasticity learning behavior like actual brain working. We further demonstrate that the artificial spiking neural network (SNN) built by this SOT device can perform unsupervised handwritten digit recognition with the accuracy of 80% and logic operation learning. Our work provides a new clue to achieving SNN-based neuromorphic hardware using high-energy efficiency and nonvolatile spintronics nanodevices","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08856v1","tag":"medical-cv"}}
{"title":"Saliency-aware Stereoscopic Video Retargeting","abstract":"Stereo video retargeting aims to resize an image to a desired aspect ratio. The quality of retargeted videos can be significantly impacted by the stereo videos spatial, temporal, and disparity coherence, all of which can be impacted by the retargeting process. Due to the lack of a publicly accessible annotated dataset, there is little research on deep learning-based methods for stereo video retargeting. This paper proposes an unsupervised deep learning-based stereo video retargeting network. Our model first detects the salient objects and shifts and warps all objects such that it minimizes the distortion of the salient parts of the stereo frames. We use 1D convolution for shifting the salient objects and design a stereo video Transformer to assist the retargeting process. To train the network, we use the parallax attention mechanism to fuse the left and right views and feed the retargeted frames to a reconstruction module that reverses the retargeted frames to the input frames. Therefore, the network is trained in an unsupervised manner. Extensive qualitative and quantitative experiments and ablation studies on KITTI stereo 2012 and 2015 datasets demonstrate the efficiency of the proposed method over the existing state-of-the-art methods. The code is available at https://github.com/z65451/SVR/.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08852v1","tag":"medical-cv"}}
{"title":"Boosting entanglement growth of many-body localization by superpositions of disorder","abstract":"Many-body localization (MBL) can occur when strong disorders prevent an interacting system from thermalization. To study the dynamics of such systems, it is typically necessary to perform an ensemble average over many different disorder configurations. Previous works have utilized an algorithm in which different disorder profiles are mapped into a quantum ancilla. By preparing the ancilla in a quantum superposition state, quantum parallelism can be harnessed to obtain the ensemble average in a single computation run. In this work, we modify this algorithm by performing a measurement on the ancilla. This enables the determination of conditional dynamics not only by the ensemble average but also by the quantum interference effect. Using a phenomenological analysis based on local integrals of motion, we demonstrate that this protocol can lead to an enhancement of the dephasing effect and a boost in the entanglement growth for systems in the deep MBL phase. We also present numerical simulations of the random XXZ model where this enhancement is also present in a smaller disorder strength, beyond the deep MBL regime.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08849v1","tag":"medical-cv"}}
{"title":"Proof-Producing Symbolic Execution for Binary Code Verification","abstract":"We propose a proof-producing symbolic execution for verification of machine-level programs. The analysis is based on a set of core inference rules that are designed to give control over the tradeoff between preservation of precision and the introduction of overapproximation to make the application to real world code useful and tractable. We integrate our symbolic execution in a binary analysis platform that features a low-level intermediate language enabling the application of analyses to many different processor architectures. The overall framework is implemented in the theorem prover HOL4 to be able to obtain highly trustworthy verification results. We demonstrate our approach to establish sound execution time bounds for a control loop program implemented for an ARM Cortex-M0 processor.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08848v1","tag":"medical-cv"}}
{"title":"UDTIRI: An Open-Source Road Pothole Detection Benchmark Suite","abstract":"It is seen that there is enormous potential to leverage powerful deep learning methods in the emerging field of urban digital twins. It is particularly in the area of intelligent road inspection where there is currently limited research and data available. To facilitate progress in this field, we have developed a well-labeled road pothole dataset named Urban Digital Twins Intelligent Road Inspection (UDTIRI) dataset. We hope this dataset will enable the use of powerful deep learning methods in urban road inspection, providing algorithms with a more comprehensive understanding of the scene and maximizing their potential. Our dataset comprises 1000 images of potholes, captured in various scenarios with different lighting and humidity conditions. Our intention is to employ this dataset for object detection, semantic segmentation, and instance segmentation tasks. Our team has devoted significant effort to conducting a detailed statistical analysis, and benchmarking a selection of representative algorithms from recent years. We also provide a multi-task platform for researchers to fully exploit the performance of various algorithms with the support of UDTIRI dataset.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08842v1","tag":"medical-cv"}}
{"title":"Two-stage Denoising Diffusion Model for Source Localization in Graph Inverse Problems","abstract":"Source localization is the inverse problem of graph information dissemination and has broad practical applications.   However, the inherent intricacy and uncertainty in information dissemination pose significant challenges, and the ill-posed nature of the source localization problem further exacerbates these challenges. Recently, deep generative models, particularly diffusion models inspired by classical non-equilibrium thermodynamics, have made significant progress. While diffusion models have proven to be powerful in solving inverse problems and producing high-quality reconstructions, applying them directly to the source localization is infeasible for two reasons. Firstly, it is impossible to calculate the posterior disseminated results on a large-scale network for iterative denoising sampling, which would incur enormous computational costs. Secondly, in the existing methods for this field, the training data itself are ill-posed (many-to-one); thus simply transferring the diffusion model would only lead to local optima.   To address these challenges, we propose a two-stage optimization framework, the source localization denoising diffusion model (SL-Diff). In the coarse stage, we devise the source proximity degrees as the supervised signals to generate coarse-grained source predictions. This aims to efficiently initialize the next stage, significantly reducing its convergence time and calibrating the convergence process. Furthermore, the introduction of cascade temporal information in this training method transforms the many-to-one mapping relationship into a one-to-one relationship, perfectly addressing the ill-posed problem. In the fine stage, we design a diffusion model for the graph inverse problem that can quantify the uncertainty in the dissemination. The proposed SL-Diff yields excellent prediction results within a reasonable sampling time at extensive experiments.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08841v1","tag":"medical-cv"}}
{"title":"GoferBot: A Visual Guided Human-Robot Collaborative Assembly System","abstract":"The current transformation towards smart manufacturing has led to a growing demand for human-robot collaboration (HRC) in the manufacturing process. Perceiving and understanding the human co-worker's behaviour introduces challenges for collaborative robots to efficiently and effectively perform tasks in unstructured and dynamic environments. Integrating recent data-driven machine vision capabilities into HRC systems is a logical next step in addressing these challenges. However, in these cases, off-the-shelf components struggle due to generalisation limitations. Real-world evaluation is required in order to fully appreciate the maturity and robustness of these approaches. Furthermore, understanding the pure-vision aspects is a crucial first step before combining multiple modalities in order to understand the limitations. In this paper, we propose GoferBot, a novel vision-based semantic HRC system for a real-world assembly task. It is composed of a visual servoing module that reaches and grasps assembly parts in an unstructured multi-instance and dynamic environment, an action recognition module that performs human action prediction for implicit communication, and a visual handover module that uses the perceptual understanding of human behaviour to produce an intuitive and efficient collaborative assembly experience. GoferBot is a novel assembly system that seamlessly integrates all sub-modules by utilising implicit semantic information purely from visual perception.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08840v1","tag":"medical-cv"}}
{"title":"Sensor Fault Detection and Isolation in Autonomous Nonlinear Systems Using Neural Network-Based Observers","abstract":"This paper presents a new observer-based approach to detect and isolate faulty sensors in industrial systems. Two types of sensor faults are considered: complete failure and sensor deterioration. The proposed method is applicable to general autonomous nonlinear systems without making any assumptions about its triangular and/or normal form, which is usually considered in the observer design literature. The key aspect of our approach is a learning-based design of the Luenberger observer, which involves using a neural network to approximate the injective map that transforms the nonlinear system into a stable linear system with output injection. This learning-based Luenberger observer accurately estimates the system's state, allowing for the detection of sensor faults through residual generation. The residual is computed as the norm of the difference between the system's measured output and the observer's predicted output vectors. Fault isolation is achieved by comparing each sensor's measurement with its corresponding predicted value. We demonstrate the effectiveness of our approach in capturing and isolating sensor faults while remaining robust in the presence of measurement noise and system uncertainty. We validate our method through numerical simulations of sensor faults in a network of Kuramoto oscillators.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08837v1","tag":"medical-cv"}}
{"title":"Perceive, Excavate and Purify: A Novel Object Mining Framework for Instance Segmentation","abstract":"Recently, instance segmentation has made great progress with the rapid development of deep neural networks. However, there still exist two main challenges including discovering indistinguishable objects and modeling the relationship between instances. To deal with these difficulties, we propose a novel object mining framework for instance segmentation. In this framework, we first introduce the semantics perceiving subnetwork to capture pixels that may belong to an obvious instance from the bottom up. Then, we propose an object excavating mechanism to discover indistinguishable objects. In the mechanism, preliminary perceived semantics are regarded as original instances with classifications and locations, and then indistinguishable objects around these original instances are mined, which ensures that hard objects are fully excavated. Next, an instance purifying strategy is put forward to model the relationship between instances, which pulls the similar instances close and pushes away different instances to keep intra-instance similarity and inter-instance discrimination. In this manner, the same objects are combined as the one instance and different objects are distinguished as independent instances. Extensive experiments on the COCO dataset show that the proposed approach outperforms state-of-the-art methods, which validates the effectiveness of the proposed object mining framework.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08826v1","tag":"medical-cv"}}
{"title":"Transfer to a Low-Resource Language via Close Relatives: The Case Study on Faroese","abstract":"Multilingual language models have pushed state-of-the-art in cross-lingual NLP transfer. The majority of zero-shot cross-lingual transfer, however, use one and the same massively multilingual transformer (e.g., mBERT or XLM-R) to transfer to all target languages, irrespective of their typological, etymological, and phylogenetic relations to other languages. In particular, readily available data and models of resource-rich sibling languages are often ignored. In this work, we empirically show, in a case study for Faroese -- a low-resource language from a high-resource language family -- that by leveraging the phylogenetic information and departing from the 'one-size-fits-all' paradigm, one can improve cross-lingual transfer to low-resource languages. In particular, we leverage abundant resources of other Scandinavian languages (i.e., Danish, Norwegian, Swedish, and Icelandic) for the benefit of Faroese. Our evaluation results show that we can substantially improve the transfer performance to Faroese by exploiting data and models of closely-related high-resource languages. Further, we release a new web corpus of Faroese and Faroese datasets for named entity recognition (NER), semantic text similarity (STS), and new language models trained on all Scandinavian languages.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08823v1","tag":"medical-cv"}}
{"title":"TTIDA: Controllable Generative Data Augmentation via Text-to-Text and Text-to-Image Models","abstract":"Data augmentation has been established as an efficacious approach to supplement useful information for low-resource datasets. Traditional augmentation techniques such as noise injection and image transformations have been widely used. In addition, generative data augmentation (GDA) has been shown to produce more diverse and flexible data. While generative adversarial networks (GANs) have been frequently used for GDA, they lack diversity and controllability compared to text-to-image diffusion models. In this paper, we propose TTIDA (Text-to-Text-to-Image Data Augmentation) to leverage the capabilities of large-scale pre-trained Text-to-Text (T2T) and Text-to-Image (T2I) generative models for data augmentation. By conditioning the T2I model on detailed descriptions produced by T2T models, we are able to generate photo-realistic labeled images in a flexible and controllable manner. Experiments on in-domain classification, cross-domain classification, and image captioning tasks show consistent improvements over other data augmentation baselines. Analytical studies in varied settings, including few-shot, long-tail, and adversarial, further reinforce the effectiveness of TTIDA in enhancing performance and increasing robustness.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08821v1","tag":"medical-cv"}}
{"title":"Motion-state Alignment for Video Semantic Segmentation","abstract":"In recent years, video semantic segmentation has made great progress with advanced deep neural networks. However, there still exist two main challenges \\ie, information inconsistency and computation cost. To deal with the two difficulties, we propose a novel motion-state alignment framework for video semantic segmentation to keep both motion and state consistency. In the framework, we first construct a motion alignment branch armed with an efficient decoupled transformer to capture dynamic semantics, guaranteeing region-level temporal consistency. Then, a state alignment branch composed of a stage transformer is designed to enrich feature spaces for the current frame to extract static semantics and achieve pixel-level state consistency. Next, by a semantic assignment mechanism, the region descriptor of each semantic category is gained from dynamic semantics and linked with pixel descriptors from static semantics. Benefiting from the alignment of these two kinds of effective information, the proposed method picks up dynamic and static semantics in a targeted way, so that video semantic regions are consistently segmented to obtain precise locations with low computational complexity. Extensive experiments on Cityscapes and CamVid datasets show that the proposed approach outperforms state-of-the-art methods and validates the effectiveness of the motion-state alignment framework.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08820v1","tag":"medical-cv"}}
{"title":"Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models","abstract":"Latent Diffusion Models (LDMs) enable high-quality image synthesis while avoiding excessive compute demands by training a diffusion model in a compressed lower-dimensional latent space. Here, we apply the LDM paradigm to high-resolution video generation, a particularly resource-intensive task. We first pre-train an LDM on images only; then, we turn the image generator into a video generator by introducing a temporal dimension to the latent space diffusion model and fine-tuning on encoded image sequences, i.e., videos. Similarly, we temporally align diffusion model upsamplers, turning them into temporally consistent video super resolution models. We focus on two relevant real-world applications: Simulation of in-the-wild driving data and creative content creation with text-to-video modeling. In particular, we validate our Video LDM on real driving videos of resolution 512 x 1024, achieving state-of-the-art performance. Furthermore, our approach can easily leverage off-the-shelf pre-trained image LDMs, as we only need to train a temporal alignment model in that case. Doing so, we turn the publicly available, state-of-the-art text-to-image LDM Stable Diffusion into an efficient and expressive text-to-video model with resolution up to 1280 x 2048. We show that the temporal layers trained in this way generalize to different fine-tuned text-to-image LDMs. Utilizing this property, we show the first results for personalized text-to-video generation, opening exciting directions for future content creation. Project page: https://research.nvidia.com/labs/toronto-ai/VideoLDM/","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08818v1","tag":"medical-cv"}}
{"title":"DILI: A Distribution-Driven Learned Index","abstract":"Targeting in-memory one-dimensional search keys, we propose a novel DIstribution-driven Learned Index tree (DILI), where a concise and computation-efficient linear regression model is used for each node. An internal node's key range is equally divided by its child nodes such that a key search enjoys perfect model prediction accuracy to find the relevant leaf node. A leaf node uses machine learning models to generate searchable data layout and thus accurately predicts the data record position for a key. To construct DILI, we first build a bottom-up tree with linear regression models according to global and local key distributions. Using the bottom-up tree, we build DILI in a top-down manner, individualizing the fanouts for internal nodes according to local distributions. DILI strikes a good balance between the number of leaf nodes and the height of the tree, two critical factors of key search time. Moreover, we design flexible algorithms for DILI to efficiently insert and delete keys and automatically adjust the tree structure when necessary. Extensive experimental results show that DILI outperforms the state-of-the-art alternatives on different kinds of workloads.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08817v1","tag":"medical-cv"}}
{"title":"Physical cool-core condensation radius in massive galaxy clusters","abstract":"We investigate the properties of cool cores in an optimally selected sample of 37 massive and X-ray-bright galaxy clusters, with regular morphologies, observed with Chandra. We measured the density, temperature, and abundance radial profiles of their intracluster medium (ICM). From these independent quantities, we computed the cooling (tcool) free-fall (tff), and turbulence (teddy) timescales as a function of radius. By requiring the profile-crossing condition, tcool=teddy=1, we measured the cool-core condensation radius Rccc, within which the balancing feeding and feedback processes generate the turbulent condensation rain and related chaotic cold accretion (CCA). We also constrained the complementary (quenched) cooling flow radius Rqcf, obtained via the condition tcool=25Xtff, that encompasses the region of thermally unstable cooling. We find that in our cluster sample and in the limited redshift range considered (1.3E14<M500<16.6E14 Msun, 0.03<z<0.29), the distribution of Rccc peaks at 0.01r500 and the entire range remains below 0.07r500, with a very weak increase with redshift and no dependence on the cluster mass. We find that Rqcf is typically 3 times larger than Rccc, with a wider distribution, and growing more slowly along Rccc, according to an average relation Rqcf~Rccc^(0.46), with a large intrinsic scatter. We suggest that this sublinear relation can be understood as an effect of the micro rain of pockets of cooled gas flickering in the turbulent ICM, whose dynamical and thermodynamical properties are referred to as \"macro weather\". Substituting the classical cool-core radius R(7.7Gyr), we propose that Rqcf is an indicator of the size of the global cores tied to the long-term macro weather, with the inner Rccc closely tracing the effective condensation rain and chaotic cold accretion (CCA) zone that feeds the central supermassive black hole.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08810v1","tag":"medical-cv"}}
{"title":"SViTT: Temporal Learning of Sparse Video-Text Transformers","abstract":"Do video-text transformers learn to model temporal relationships across frames? Despite their immense capacity and the abundance of multimodal training data, recent work has revealed the strong tendency of video-text models towards frame-based spatial representations, while temporal reasoning remains largely unsolved. In this work, we identify several key challenges in temporal learning of video-text transformers: the spatiotemporal trade-off from limited network size; the curse of dimensionality for multi-frame modeling; and the diminishing returns of semantic information by extending clip length. Guided by these findings, we propose SViTT, a sparse video-text architecture that performs multi-frame reasoning with significantly lower cost than naive transformers with dense attention. Analogous to graph-based networks, SViTT employs two forms of sparsity: edge sparsity that limits the query-key communications between tokens in self-attention, and node sparsity that discards uninformative visual tokens. Trained with a curriculum which increases model sparsity with the clip length, SViTT outperforms dense transformer baselines on multiple video-text retrieval and question answering benchmarks, with a fraction of computational cost. Project page: http://svcl.ucsd.edu/projects/svitt.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08809v1","tag":"medical-cv"}}
{"title":"A True Random Number Generator for Probabilistic Computing using Stochastic Magnetic Actuated Random Transducer Devices","abstract":"Magnetic tunnel junctions (MTJs), which are the fundamental building blocks of spintronic devices, have been used to build true random number generators (TRNGs) with different trade-offs between throughput, power, and area requirements. MTJs with high-barrier magnets (HBMs) have been used to generate random bitstreams with $\\lesssim$ 200~Mb/s throughput and pJ/bit energy consumption. A high temperature sensitivity, however, adversely affects their performance as a TRNG. Superparamagnetic MTJs employing low-barrier magnets (LBMs) have also been used for TRNG operation. Although LBM-based MTJs can operate at low energy, they suffer from slow dynamics, sensitivity to process variations, and low fabrication yield. In this paper, we model a TRNG based on medium-barrier magnets (MBMs) with perpendicular magnetic anisotropy. The proposed MBM-based TRNG is driven with short voltage pulses to induce ballistic, yet stochastic, magnetization switching. We show that the proposed TRNG can operate at frequencies of about 500~MHz while consuming less than 100~fJ/bit of energy. In the short-pulse ballistic limit, the switching probability of our device shows robustness to variations in temperature and material parameters relative to LBMs and HBMs. Our results suggest that MBM-based MTJs are suitable candidates for building fast and energy-efficient TRNG hardware units for probabilistic computing.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08808v1","tag":"medical-cv"}}
{"title":"Revisiting the Role of Similarity and Dissimilarity inBest Counter Argument Retrieval","abstract":"This paper studies the task of best counter-argument retrieval given an input argument. Following the definition that the best counter-argument addresses the same aspects as the input argument while having the opposite stance, we aim to develop an efficient and effective model for scoring counter-arguments based on similarity and dissimilarity metrics. We first conduct an experimental study on the effectiveness of available scoring methods, including traditional Learning-To-Rank (LTR) and recent neural scoring models. We then propose Bipolar-encoder, a novel BERT-based model to learn an optimal representation for simultaneous similarity and dissimilarity. Experimental results show that our proposed method can achieve the accuracy@1 of 88.9\\%, which significantly outperforms other baselines by a large margin. When combined with an appropriate caching technique, Bipolar-encoder is comparably efficient at prediction time.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08807v1","tag":"medical-cv"}}
{"title":"MLP-AIR: An Efficient MLP-Based Method for Actor Interaction Relation Learning in Group Activity Recognition","abstract":"The task of Group Activity Recognition (GAR) aims to predict the activity category of the group by learning the actor spatial-temporal interaction relation in the group. Therefore, an effective actor relation learning method is crucial for the GAR task. The previous works mainly learn the interaction relation by the well-designed GCNs or Transformers. For example, to infer the actor interaction relation, GCNs need a learnable adjacency, and Transformers need to calculate the self-attention. Although the above methods can model the interaction relation effectively, they also increase the complexity of the model (the number of parameters and computations). In this paper, we design a novel MLP-based method for Actor Interaction Relation learning (MLP-AIR) in GAR. Compared with GCNs and Transformers, our method has a competitive but conceptually and technically simple alternative, significantly reducing the complexity. Specifically, MLP-AIR includes three sub-modules: MLP-based Spatial relation modeling module (MLP-S), MLP-based Temporal relation modeling module (MLP-T), and MLP-based Relation refining module (MLP-R). MLP-S is used to model the spatial relation between different actors in each frame. MLP-T is used to model the temporal relation between different frames for each actor. MLP-R is used further to refine the relation between different dimensions of relation features to improve the feature's expression ability. To evaluate the MLP-AIR, we conduct extensive experiments on two widely used benchmarks, including the Volleyball and Collective Activity datasets. Experimental results demonstrate that MLP-AIR can get competitive results but with low complexity.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08803v1","tag":"medical-cv"}}
{"title":"Neuromorphic computing for attitude estimation onboard quadrotors","abstract":"Compelling evidence has been given for the high energy efficiency and update rates of neuromorphic processors, with performance beyond what standard Von Neumann architectures can achieve. Such promising features could be advantageous in critical embedded systems, especially in robotics. To date, the constraints inherent in robots (e.g., size and weight, battery autonomy, available sensors, computing resources, processing time, etc.), and particularly in aerial vehicles, severely hamper the performance of fully-autonomous on-board control, including sensor processing and state estimation. In this work, we propose a spiking neural network (SNN) capable of estimating the pitch and roll angles of a quadrotor in highly dynamic movements from 6-degree of freedom Inertial Measurement Unit (IMU) data. With only 150 neurons and a limited training dataset obtained using a quadrotor in a real world setup, the network shows competitive results as compared to state-of-the-art, non-neuromorphic attitude estimators. The proposed architecture was successfully tested on the Loihi neuromorphic processor on-board a quadrotor to estimate the attitude when flying. Our results show the robustness of neuromorphic attitude estimation and pave the way towards energy-efficient, fully autonomous control of quadrotors with dedicated neuromorphic computing systems.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08802v1","tag":"medical-cv"}}
{"title":"Speaker Profiling in Multiparty Conversations","abstract":"In conversational settings, individuals exhibit unique behaviors, rendering a one-size-fits-all approach insufficient for generating responses by dialogue agents. Although past studies have aimed to create personalized dialogue agents using speaker persona information, they have relied on the assumption that the speaker's persona is already provided. However, this assumption is not always valid, especially when it comes to chatbots utilized in industries like banking, hotel reservations, and airline bookings. This research paper aims to fill this gap by exploring the task of Speaker Profiling in Conversations (SPC). The primary objective of SPC is to produce a summary of persona characteristics for each individual speaker present in a dialogue. To accomplish this, we have divided the task into three subtasks: persona discovery, persona-type identification, and persona-value extraction. Given a dialogue, the first subtask aims to identify all utterances that contain persona information. Subsequently, the second task evaluates these utterances to identify the type of persona information they contain, while the third subtask identifies the specific persona values for each identified type. To address the task of SPC, we have curated a new dataset named SPICE, which comes with specific labels. We have evaluated various baselines on this dataset and benchmarked it with a new neural model, SPOT, which we introduce in this paper. Furthermore, we present a comprehensive analysis of SPOT, examining the limitations of individual modules both quantitatively and qualitatively.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08801v1","tag":"medical-cv"}}
{"title":"Self-Supervised 3D Action Representation Learning with Skeleton Cloud Colorization","abstract":"3D Skeleton-based human action recognition has attracted increasing attention in recent years. Most of the existing work focuses on supervised learning which requires a large number of labeled action sequences that are often expensive and time-consuming to annotate. In this paper, we address self-supervised 3D action representation learning for skeleton-based action recognition. We investigate self-supervised representation learning and design a novel skeleton cloud colorization technique that is capable of learning spatial and temporal skeleton representations from unlabeled skeleton sequence data. We represent a skeleton action sequence as a 3D skeleton cloud and colorize each point in the cloud according to its temporal and spatial orders in the original (unannotated) skeleton sequence. Leveraging the colorized skeleton point cloud, we design an auto-encoder framework that can learn spatial-temporal features from the artificial color labels of skeleton joints effectively. Specifically, we design a two-steam pretraining network that leverages fine-grained and coarse-grained colorization to learn multi-scale spatial-temporal features.In addition, we design a Masked Skeleton Cloud Repainting task that can pretrain the designed auto-encoder framework to learn informative representations. We evaluate our skeleton cloud colorization approach with linear classifiers trained under different configurations, including unsupervised, semi-supervised, fully-supervised, and transfer learning settings. Extensive experiments on NTU RGB+D, NTU RGB+D 120, PKU-MMD, NW-UCLA, and UWA3D datasets show that the proposed method outperforms existing unsupervised and semi-supervised 3D action recognition methods by large margins and achieves competitive performance in supervised 3D action recognition as well.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08799v1","tag":"medical-cv"}}
{"title":"Deep Unrestricted Document Image Rectification","abstract":"In recent years, tremendous efforts have been made on document image rectification, but existing advanced algorithms are limited to processing restricted document images, i.e., the input images must incorporate a complete document. Once the captured image merely involves a local text region, its rectification quality is degraded and unsatisfactory. Our previously proposed DocTr, a transformer-assisted network for document image rectification, also suffers from this limitation. In this work, we present DocTr++, a novel unified framework for document image rectification, without any restrictions on the input distorted images. Our major technical improvements can be concluded in three aspects. Firstly, we upgrade the original architecture by adopting a hierarchical encoder-decoder structure for multi-scale representation extraction and parsing. Secondly, we reformulate the pixel-wise mapping relationship between the unrestricted distorted document images and the distortion-free counterparts. The obtained data is used to train our DocTr++ for unrestricted document image rectification. Thirdly, we contribute a real-world test set and metrics applicable for evaluating the rectification quality. To our best knowledge, this is the first learning-based method for the rectification of unrestricted document images. Extensive experiments are conducted, and the results demonstrate the effectiveness and superiority of our method. We hope our DocTr++ will serve as a strong baseline for generic document image rectification, prompting the further advancement and application of learning-based algorithms. The source code and the proposed dataset are publicly available at https://github.com/fh2019ustc/DocTr-Plus.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08796v1","tag":"medical-cv"}}
{"title":"A Systematic Literature Review of User Trust in AI-Enabled Systems: An HCI Perspective","abstract":"User trust in Artificial Intelligence (AI) enabled systems has been increasingly recognized and proven as a key element to fostering adoption. It has been suggested that AI-enabled systems must go beyond technical-centric approaches and towards embracing a more human centric approach, a core principle of the human-computer interaction (HCI) field. This review aims to provide an overview of the user trust definitions, influencing factors, and measurement methods from 23 empirical studies to gather insight for future technical and design strategies, research, and initiatives to calibrate the user AI relationship. The findings confirm that there is more than one way to define trust. Selecting the most appropriate trust definition to depict user trust in a specific context should be the focus instead of comparing definitions. User trust in AI-enabled systems is found to be influenced by three main themes, namely socio-ethical considerations, technical and design features, and user characteristics. User characteristics dominate the findings, reinforcing the importance of user involvement from development through to monitoring of AI enabled systems. In conclusion, user trust needs to be addressed directly in every context where AI-enabled systems are being used or discussed. In addition, calibrating the user-AI relationship requires finding the optimal balance that works for not only the user but also the system.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08795v1","tag":"medical-cv"}}
{"title":"Automated Function Implementation via Conditional Parameterized Quantum Circuits with Applications to Finance","abstract":"Classical Monte Carlo algorithms can theoretically be sped up on a quantum computer by employing amplitude estimation (AE). To realize this, an efficient implementation of state-dependent functions is crucial. We develop a straightforward approach based on pre-training parameterized quantum circuits, and show how they can be transformed into their conditional variant, making them usable as a subroutine in an AE algorithm. To identify a suitable circuit, we propose a genetic optimization approach that combines variable ansatzes and data encoding. We apply our algorithm to the problem of pricing financial derivatives. At the expense of a costly pre-training process, this results in a quantum circuit implementing the derivatives' payoff function more efficiently than previously existing quantum algorithms. In particular, we compare the performance for European vanilla and basket options.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08793v1","tag":"medical-cv"}}
{"title":"A probabilistic reduced basis method for parameter-dependent problems","abstract":"Probabilistic variants of Model Order Reduction (MOR) methods have recently emerged for improving stability and computational performance of classical approaches. In this paper, we propose a probabilistic Reduced Basis Method (RBM) for the approximation of a family of parameter-dependent functions. It relies on a probabilistic greedy algorithm with an error indicator that can be written as an expectation of some parameter-dependent random variable. Practical algorithms relying on Monte Carlo estimates of this error indicator are discussed. In particular, when using Probably Approximately Correct (PAC) bandit algorithm, the resulting procedure is proven to be a weak greedy algorithm with high probability. Intended applications concern the approximation of a parameter-dependent family of functions for which we only have access to (noisy) pointwise evaluations. As a particular application, we consider the approximation of solution manifolds of   linear parameter-dependent partial differential equations with a probabilistic interpretation through the Feynman-Kac formula.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08784v1","tag":"medical-cv"}}
{"title":"Connectivity in the presence of an opponent","abstract":"The paper introduces two player connectivity games played on finite bipartite graphs. Algorithms that solve these connectivity games can be used as subroutines for solving M\\\"uller games. M\\\"uller games constitute a well established class of games in model checking and verification. In connectivity games, the objective of one of the players is to visit every node of the game graph infinitely often. The first contribution of this paper is our proof that solving connectivity games can be reduced to the incremental strongly connected component maintenance (ISCCM) problem, an important problem in graph algorithms and data structures. The second contribution is that we non-trivially adapt two known algorithms for the ISCCM problem to provide two efficient algorithms that solve the connectivity games problem. Finally, based on the techniques developed, we recast Horn's polynomial time algorithm that solves explicitly given M\\\"uller games and provide an alternative proof of its correctness. Our algorithms are more efficient than that of Horn's algorithm. Our solution for connectivity games is used as a subroutine in the algorithm.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08783v1","tag":"medical-cv"}}
{"title":"Sparks of GPTs in Edge Intelligence for Metaverse: Caching and Inference for Mobile AIGC Services","abstract":"Aiming at achieving artificial general intelligence (AGI) for Metaverse, pretrained foundation models (PFMs), e.g., generative pretrained transformers (GPTs), can effectively provide various AI services, such as autonomous driving, digital twins, and AI-generated content (AIGC) for extended reality. With the advantages of low latency and privacy-preserving, serving PFMs of mobile AI services in edge intelligence is a viable solution for caching and executing PFMs on edge servers with limited computing resources and GPU memory. However, PFMs typically consist of billions of parameters that are computation and memory-intensive for edge servers during loading and execution. In this article, we investigate edge PFM serving problems for mobile AIGC services of Metaverse. First, we introduce the fundamentals of PFMs and discuss their characteristic fine-tuning and inference methods in edge intelligence. Then, we propose a novel framework of joint model caching and inference for managing models and allocating resources to satisfy users' requests efficiently. Furthermore, considering the in-context learning ability of PFMs, we propose a new metric to evaluate the freshness and relevance between examples in demonstrations and executing tasks, namely the Age of Context (AoC). Finally, we propose a least context algorithm for managing cached models at edge servers by balancing the tradeoff among latency, energy consumption, and accuracy.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08782v1","tag":"medical-cv"}}
{"title":"Revisiting the Design Agenda for Privacy Notices and Security Warnings","abstract":"System-generated user-facing notices, dialogs, and warnings in privacy and security interventions present the opportunity to support users in making informed decisions about identified risks. However, too often, they are bypassed, ignored, and mindlessly clicked through, mainly in connection to the well-studied effect of user fatigue and habituation. The contribution of this position paper is to provide a summarized review of established and emergent design dimensions and principles to limit such risk-prone behavior, and to identify three emergent research and design directions for privacy-enhancing dialogs.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08780v1","tag":"medical-cv"}}
{"title":"Error bounds for maxout neural network approximations of model predictive control","abstract":"Neural network (NN) approximations of model predictive control (MPC) are a versatile approach if the online solution of the underlying optimal control problem (OCP) is too demanding and if an exact computation of the explicit MPC law is intractable. The drawback of such approximations is that they typically do not preserve stability and performance guarantees of the original MPC. However, such guarantees can be recovered if the maximum error with respect to the optimal control law and the Lipschitz constant of that error are known. We show in this work how to compute both values exactly when the control law is approximated by a maxout NN. We build upon related results for ReLU NN approximations and derive mixed-integer (MI) linear constraints that allow a computation of the output and the local gain of a maxout NN by solving an MI feasibility problem. Furthermore, we show theoretically and experimentally that maxout NN exist for which the maximum error is zero.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08779v1","tag":"medical-cv"}}
{"title":"Neuromorphic Control using Input-Weighted Threshold Adaptation","abstract":"Neuromorphic processing promises high energy efficiency and rapid response rates, making it an ideal candidate for achieving autonomous flight of resource-constrained robots. It will be especially beneficial for complex neural networks as are involved in high-level visual perception. However, fully neuromorphic solutions will also need to tackle low-level control tasks. Remarkably, it is currently still challenging to replicate even basic low-level controllers such as proportional-integral-derivative (PID) controllers. Specifically, it is difficult to incorporate the integral and derivative parts. To address this problem, we propose a neuromorphic controller that incorporates proportional, integral, and derivative pathways during learning. Our approach includes a novel input threshold adaptation mechanism for the integral pathway. This Input-Weighted Threshold Adaptation (IWTA) introduces an additional weight per synaptic connection, which is used to adapt the threshold of the post-synaptic neuron. We tackle the derivative term by employing neurons with different time constants. We first analyze the performance and limits of the proposed mechanisms and then put our controller to the test by implementing it on a microcontroller connected to the open-source tiny Crazyflie quadrotor, replacing the innermost rate controller. We demonstrate the stability of our bio-inspired algorithm with flights in the presence of disturbances. The current work represents a substantial step towards controlling highly dynamic systems with neuromorphic algorithms, thus advancing neuromorphic processing and robotics. In addition, integration is an important part of any temporal task, so the proposed Input-Weighted Threshold Adaptation (IWTA) mechanism may have implications well beyond control tasks.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08778v1","tag":"medical-cv"}}
{"title":"3-Objective Pareto Optimization for Problems with Chance Constraints","abstract":"Evolutionary multi-objective algorithms have successfully been used in the context of Pareto optimization where a given constraint is relaxed into an additional objective. In this paper, we explore the use of 3-objective formulations for problems with chance constraints. Our formulation trades off the expected cost and variance of the stochastic component as well as the given deterministic constraint. We point out benefits that this 3-objective formulation has compared to a bi-objective one recently investigated for chance constraints with Normally distributed stochastic components. Our analysis shows that the 3-objective formulation allows to compute all required trade-offs using 1-bit flips only, when dealing with a deterministic cardinality constraint. Furthermore, we carry out experimental investigations for the chance constrained dominating set problem and show the benefit for this classical NP-hard problem.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08774v1","tag":"medical-cv"}}
{"title":"Cooperative Multi-Agent Reinforcement Learning for Inventory Management","abstract":"With Reinforcement Learning (RL) for inventory management (IM) being a nascent field of research, approaches tend to be limited to simple, linear environments with implementations that are minor modifications of off-the-shelf RL algorithms. Scaling these simplistic environments to a real-world supply chain comes with a few challenges such as: minimizing the computational requirements of the environment, specifying agent configurations that are representative of dynamics at real world stores and warehouses, and specifying a reward framework that encourages desirable behavior across the whole supply chain. In this work, we present a system with a custom GPU-parallelized environment that consists of one warehouse and multiple stores, a novel architecture for agent-environment dynamics incorporating enhanced state and action spaces, and a shared reward specification that seeks to optimize for a large retailer's supply chain needs. Each vertex in the supply chain graph is an independent agent that, based on its own inventory, able to place replenishment orders to the vertex upstream. The warehouse agent, aside from placing orders from the supplier, has the special property of also being able to constrain replenishment to stores downstream, which results in it learning an additional allocation sub-policy. We achieve a system that outperforms standard inventory control policies such as a base-stock policy and other RL-based specifications for 1 product, and lay out a future direction of work for multiple products.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08769v1","tag":"medical-cv"}}
{"title":"Anomalous impact of thermal fluctuations on spintransfer torque induced ferrimagnetic switching","abstract":"The dynamics of a spin torque driven ferrimagnetic (FiM) system is investigated using the two-sublattice macrospin model. We demonstrate an ultrafast switching in the picosecond range. However, we find that the excessive current leads to the magnetic oscillation. Therefore, faster switching cannot be achieved by unlimitedly increasing the current. By systematically studying the impact of thermal fluctuations, we find the dynamics of FiMs can also be distinguished into the precessional region, the thermally activated region, and the cross-over region. However, in the precessional region, there is a significant deviation between FiM and ferromagnet (FM), i.e., the FM is insensitive to thermal fluctuations since its switching is only determined by the amount of net charge. In contrast, we find that the thermal effect is pronounced even a very short current pulse is applied to the FiM. We attribute this anomalous effect to the complex relation between the anisotropy and overdrive current. By controlling the magnetic anisotropy, we demonstrate that the FiM can also be configured to be insensitive to thermal fluctuations. This controllable thermal property makes the FiM promising in many emerging applications such as the implementation of tunable activation functions in the neuromorphic computing.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08765v1","tag":"medical-cv"}}
{"title":"A Survey on Biomedical Text Summarization with Pre-trained Language Model","abstract":"The exponential growth of biomedical texts such as biomedical literature and electronic health records (EHRs), provides a big challenge for clinicians and researchers to access clinical information efficiently. To address the problem, biomedical text summarization has been proposed to support clinical information retrieval and management, aiming at generating concise summaries that distill key information from single or multiple biomedical documents. In recent years, pre-trained language models (PLMs) have been the de facto standard of various natural language processing tasks in the general domain. Most recently, PLMs have been further investigated in the biomedical field and brought new insights into the biomedical text summarization task. In this paper, we systematically summarize recent advances that explore PLMs for biomedical text summarization, to help understand recent progress, challenges, and future directions. We categorize PLMs-based approaches according to how they utilize PLMs and what PLMs they use. We then review available datasets, recent approaches and evaluation metrics of the task. We finally discuss existing challenges and promising future directions. To facilitate the research community, we line up open resources including available datasets, recent approaches, codes, evaluation metrics, and the leaderboard in a public project: https://github.com/KenZLuo/Biomedical-Text-Summarization-Survey/tree/master.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08763v1","tag":"medical-cv"}}
{"title":"Exoskeleton for the Mind: Exploring Strategies Against Misinformation with a Metacognitive Agent","abstract":"Misinformation is a global problem in modern social media platforms with few solutions known to be effective. Social media platforms have offered tools to raise awareness of information, but these are closed systems that have not been empirically evaluated. Others have developed novel tools and strategies, but most have been studied out of context using static stimuli, researcher prompts, or low fidelity prototypes. We offer a new anti-misinformation agent grounded in theories of metacognition that was evaluated within Twitter. We report on a pilot study (n=17) and multi-part experimental study (n=57, n=49) where participants experienced three versions of the agent, each deploying a different strategy. We found that no single strategy was superior over the control. We also confirmed the necessity of transparency and clarity about the agent's underlying logic, as well as concerns about repeated exposure to misinformation and lack of user engagement.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08759v1","tag":"medical-cv"}}
{"title":"Characterization, synthesis, and optimization of quantum circuits over multiple-control $\\textit{Z}$-rotation gates: A systematic study","abstract":"We conduct a systematic study of quantum circuits composed of multiple-control $Z$-rotation (MCZR) gates as primitives, since they are widely-used components in quantum algorithms and also have attracted much experimental interest in recent years. Herein, we establish a circuit-polynomial correspondence to characterize the functionality of quantum circuits over the MCZR gate set with continuous parameters. An analytic method for exactly synthesizing such quantum circuit to implement any given diagonal unitary matrix with an optimal gate count is proposed, which also enables the circuit depth optimal for specific cases with pairs of complementary gates. Furthermore, we present a gate-exchange strategy together with a flexible iterative algorithm for effectively optimizing the depth of any MCZR circuit, which can also be applied to quantum circuits over any other commuting gate set.   Besides the theoretical analysis, the practical performances of our circuit synthesis and optimization techniques are further evaluated by numerical experiments on two typical examples in quantum computing, including diagonal Hermitian operators and Quantum Approximate Optimization Algorithm (QAOA) circuits with tens of qubits, which can demonstrate a reduction in circuit depth by 33.40\\% and 15.55\\% on average over relevant prior works, respectively. Therefore, our methods and results provide a pathway for implementing quantum circuits and algorithms on recently developed devices.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08758v1","tag":"medical-cv"}}
{"title":"NeAI: A Pre-convoluted Representation for Plug-and-Play Neural Ambient Illumination","abstract":"Recent advances in implicit neural representation have demonstrated the ability to recover detailed geometry and material from multi-view images. However, the use of simplified lighting models such as environment maps to represent non-distant illumination, or using a network to fit indirect light modeling without a solid basis, can lead to an undesirable decomposition between lighting and material. To address this, we propose a fully differentiable framework named neural ambient illumination (NeAI) that uses Neural Radiance Fields (NeRF) as a lighting model to handle complex lighting in a physically based way. Together with integral lobe encoding for roughness-adaptive specular lobe and leveraging the pre-convoluted background for accurate decomposition, the proposed method represents a significant step towards integrating physically based rendering into the NeRF representation. The experiments demonstrate the superior performance of novel-view rendering compared to previous works, and the capability to re-render objects under arbitrary NeRF-style environments opens up exciting possibilities for bridging the gap between virtual and real-world scenes. The project and supplementary materials are available at https://yiyuzhuang.github.io/NeAI/.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08757v1","tag":"medical-cv"}}
{"title":"AutoTaskFormer: Searching Vision Transformers for Multi-task Learning","abstract":"Vision Transformers have shown great performance in single tasks such as classification and segmentation. However, real-world problems are not isolated, which calls for vision transformers that can perform multiple tasks concurrently. Existing multi-task vision transformers are handcrafted and heavily rely on human expertise. In this work, we propose a novel one-shot neural architecture search framework, dubbed AutoTaskFormer (Automated Multi-Task Vision TransFormer), to automate this process. AutoTaskFormer not only identifies the weights to share across multiple tasks automatically, but also provides thousands of well-trained vision transformers with a wide range of parameters (e.g., number of heads and network depth) for deployment under various resource constraints. Experiments on both small-scale (2-task Cityscapes and 3-task NYUv2) and large-scale (16-task Taskonomy) datasets show that AutoTaskFormer outperforms state-of-the-art handcrafted vision transformers in multi-task learning. The entire code and models will be open-sourced.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08756v1","tag":"medical-cv"}}
{"title":"W-MAE: Pre-trained weather model with masked autoencoder for multi-variable weather forecasting","abstract":"Weather forecasting is a long-standing computational challenge with direct societal and economic impacts. This task involves a large amount of continuous data collection and exhibits rich spatiotemporal dependencies over long periods, making it highly suitable for deep learning models. In this paper, we apply pre-training techniques to weather forecasting and propose W-MAE, a Weather model with Masked AutoEncoder pre-training for multi-variable weather forecasting. W-MAE is pre-trained in a self-supervised manner to reconstruct spatial correlations within meteorological variables. On the temporal scale, we fine-tune the pre-trained W-MAE to predict the future states of meteorological variables, thereby modeling the temporal dependencies present in weather data. We pre-train W-MAE using the fifth-generation ECMWF Reanalysis (ERA5) data, with samples selected every six hours and using only two years of data. Under the same training data conditions, we compare W-MAE with FourCastNet, and W-MAE outperforms FourCastNet in precipitation forecasting. In the setting where the training data is far less than that of FourCastNet, our model still performs much better in precipitation prediction (0.80 vs. 0.98). Additionally, experiments show that our model has a stable and significant advantage in short-to-medium-range forecasting (i.e., forecasting time ranges from 6 hours to one week), and the longer the prediction time, the more evident the performance advantage of W-MAE, further proving its robustness.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08754v1","tag":"medical-cv"}}
{"title":"Not Only WEIRD but \"Uncanny\"? A Systematic Review of Diversity in Human-Robot Interaction Research","abstract":"Critical voices within and beyond the scientific community have pointed to a grave matter of concern regarding who is included in research and who is not. Subsequent investigations have revealed an extensive form of sampling bias across a broad range of disciplines that conduct human subjects research called \"WEIRD\": Western, Educated, Industrial, Rich, and Democratic. Recent work has indicated that this pattern exists within human-computer interaction (HCI) research, as well. How then does human-robot interaction (HRI) fare? And could there be other patterns of sampling bias at play, perhaps those especially relevant to this field of study? We conducted a systematic review of the premier ACM/IEEE International Conference on Human-Robot Interaction (2006-2022) to discover whether and how WEIRD HRI research is. Importantly, we expanded our purview to other factors of representation highlighted by critical work on inclusion and intersectionality as potentially underreported, overlooked, and even marginalized factors of human diversity. Findings from 827 studies across 749 papers confirm that participants in HRI research also tend to be drawn from WEIRD populations. Moreover, we find evidence of limited, obscured, and possible misrepresentation in participant sampling and reporting along key axes of diversity: sex and gender, race and ethnicity, age, sexuality and family configuration, disability, body type, ideology, and domain expertise. We discuss methodological and ethical implications for recruitment, analysis, and reporting, as well as the significance for HRI as a base of knowledge.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08750v1","tag":"medical-cv"}}
{"title":"On Approximate Reconfigurability of Label Cover","abstract":"Given a two-prover game $G$ and its two satisfying labelings $\\psi_\\mathsf{s}$ and $\\psi_\\mathsf{t}$, the Label Cover Reconfiguration problem asks whether $\\psi_\\mathsf{s}$ can be transformed into $\\psi_\\mathsf{t}$ by repeatedly changing the value of a vertex while preserving any intermediate labeling satisfying $G$. We consider an optimization variant of Label Cover Reconfiguration by relaxing the feasibility of labelings, referred to as Maxmin Label Cover Reconfiguration: we are allowed to transform by passing through any non-satisfying labelings, but required to maximize the minimum fraction of satisfied edges during transformation from $\\psi_\\mathsf{s}$ to $\\psi_\\mathsf{t}$. Since the parallel repetition theorem of Raz (SIAM J. Comput., 1998), which implies NP-hardness of Label Cover within any constant factor, produces strong inapproximability results for many NP-hard problems, one may think of using Maxmin Label Cover Reconfiguration to derive inapproximability results for reconfiguration problems. We prove the following results on Maxmin Label Cover Reconfiguration, which display different trends from those of Label Cover and the parallel repetition theorem:   (1) Maxmin Label Cover Reconfiguration can be approximated within a factor of nearly $\\frac{1}{4}$ for restricted graph classes, including slightly dense graphs and balanced bipartite graphs.   (2) A naive parallel repetition of Maxmin Label Cover Reconfiguration does not decrease the optimal objective value.   (3) Label Cover Reconfiguration on projection games can be decided in polynomial time.   The above results suggest that a reconfiguration analogue of the parallel repetition theorem is unlikely.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08746v1","tag":"medical-cv"}}
{"title":"Super-Logarithmic Lower Bounds for Dynamic Graph Problems","abstract":"In this work, we prove a $\\tilde{\\Omega}(\\lg^{3/2} n )$ unconditional lower bound on the maximum of the query time and update time for dynamic data structures supporting reachability queries in $n$-node directed acyclic graphs under edge insertions. This is the first super-logarithmic lower bound for any natural graph problem. In proving the lower bound, we also make novel contributions to the state-of-the-art data structure lower bound techniques that we hope may lead to further progress in proving lower bounds.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08745v1","tag":"medical-cv"}}
{"title":"Do humans and machines have the same eyes? Human-machine perceptual differences on image classification","abstract":"Trained computer vision models are assumed to solve vision tasks by imitating human behavior learned from training labels. Most efforts in recent vision research focus on measuring the model task performance using standardized benchmarks. Limited work has been done to understand the perceptual difference between humans and machines. To fill this gap, our study first quantifies and analyzes the statistical distributions of mistakes from the two sources. We then explore human vs. machine expertise after ranking tasks by difficulty levels. Even when humans and machines have similar overall accuracies, the distribution of answers may vary. Leveraging the perceptual difference between humans and machines, we empirically demonstrate a post-hoc human-machine collaboration that outperforms humans or machines alone.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08733v1","tag":"medical-cv"}}
{"title":"Some Symmetry and Duality Theorems on Multiple Zeta(-star) Values","abstract":"In this paper, we provide a symmetric formula and a duality formula relating multiple zeta values and zeta-star values. Leveraging Zagier's formula for computing $\\zeta^\\star(\\{2\\}^p,3,\\{2\\}^q)$, we employ our theorems to establish a formula for computing $\\zeta^\\star(\\{2\\}^p,1,\\{2\\}^q)$ for any positive integers $p$ and $q$, along with other formulas of interest.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08722v1","tag":"medical-cv"}}
{"title":"Are footpaths encroached by shared e-scooters? Spatio-temporal Analysis of Micro-mobility Services","abstract":"Micro-mobility services (e.g., e-bikes, e-scooters) are increasingly popular among urban communities, being a flexible transport option that brings both opportunities and challenges. As a growing mode of transportation, insights gained from micro-mobility usage data are valuable in policy formulation and improving the quality of services. Existing research analyses patterns and features associated with usage distributions in different localities, and focuses on either temporal or spatial aspects. In this paper, we employ a combination of methods that analyse both spatial and temporal characteristics related to e-scooter trips in a more granular level, enabling observations at different time frames and local geographical zones that prior analysis wasn't able to do. The insights obtained from anonymised, restricted data on shared e-scooter rides show the applicability of the employed method on regulated, privacy preserving micro-mobility trip data. Our results showed population density is the topmost important feature, and it associates with e-scooter usage positively. Population owning motor vehicles is negatively associated with shared e-scooter trips, suggesting a reduction in e-scooter usage among motor vehicle owners. Furthermore, we found that the effect of humidity is more important than precipitation in predicting hourly e-scooter trip count. Buffer analysis showed, nearly 29% trips were stopped, and 27% trips were started on the footpath, revealing higher utilisation of footpaths for parking e-scooters in Melbourne.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08721v1","tag":"medical-cv"}}
{"title":"A conjectural chain model for positive $S^1$-equivariant symplectic homology of star-shaped toric domains in $\\mathbb{C}^2$","abstract":"For any star-shaped toric domain in $\\mathbb{C}^2$, we define a filtered chain complex which conjecturally computes positive $S^1$-equivariant symplectic homology of the domain. Assuming this conjecture, we show that the limit $\\lim_{k \\to \\infty} c^{\\mathrm{GH}}_k(X)/k$ exists for any star-shaped toric domain $X \\subset \\mathbb{C}^2$, where $c^{\\mathrm{GH}}_k$ denotes the $k$-th Gutt-Hutchings capacity.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08720v1","tag":"medical-cv"}}
{"title":"InversOS: Efficient Control-Flow Protection for AArch64 Applications with Privilege Inversion","abstract":"With the increasing popularity of AArch64 processors in general-purpose computing, securing software running on AArch64 systems against control-flow hijacking attacks has become a critical part toward secure computation. Shadow stacks keep shadow copies of function return addresses and, when protected from illegal modifications and coupled with forward-edge control-flow integrity, form an effective and proven defense against such attacks. However, AArch64 lacks native support for write-protected shadow stacks, while software alternatives either incur prohibitive performance overhead or provide weak security guarantees.   We present InversOS, the first hardware-assisted write-protected shadow stacks for AArch64 user-space applications, utilizing commonly available features of AArch64 to achieve efficient intra-address space isolation (called Privilege Inversion) required to protect shadow stacks. Privilege Inversion adopts unconventional design choices that run protected applications in the kernel mode and mark operating system (OS) kernel memory as user-accessible; InversOS therefore uses a novel combination of OS kernel modifications, compiler transformations, and another AArch64 feature to ensure the safety of doing so and to support legacy applications. We show that InversOS is secure by design, effective against various control-flow hijacking attacks, and performant on selected benchmarks and applications (incurring overhead of 7.0% on LMBench, 7.1% on SPEC CPU 2017, and 3.0% on Nginx web server).","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08717v1","tag":"medical-cv"}}
{"title":"EfficientNet Algorithm for Classification of Different Types of Cancer","abstract":"Accurate and efficient classification of different types of cancer is critical for early detection and effective treatment. In this paper, we present the results of our experiments using the EfficientNet algorithm for classification of brain tumor, breast cancer mammography, chest cancer, and skin cancer. We used publicly available datasets and preprocessed the images to ensure consistency and comparability. Our experiments show that the EfficientNet algorithm achieved high accuracy, precision, recall, and F1 scores on each of the cancer datasets, outperforming other state-of-the-art algorithms in the literature. We also discuss the strengths and weaknesses of the EfficientNet algorithm and its potential applications in clinical practice. Our results suggest that the EfficientNet algorithm is well-suited for classification of different types of cancer and can be used to improve the accuracy and efficiency of cancer diagnosis.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08715v1","tag":"medical-cv"}}
{"title":"FlexiChain 2.0: NodeChain Assisting Integrated Decentralized Vault for Effective Data Authentication and Device Integrity in Complex Cyber-Physical Systems","abstract":"Distributed Ledger Technology (DLT) has been introduced using the most common consensus algorithm either for an electronic cash system or a decentralized programmable assets platform which provides general services. Most established reliable networks are unsuitable for all applications such as smart cities applications, and, in particular, Internet of Things (IoT) and Cyber Physical Systems (CPS) applications. The purpose of this paper is to provide a suitable DLT for IoT and CPS that could satisfy their requirements. The proposed work has been designed based on the requirements of Cyber Physical Systems. FlexiChain is proposed as a layer zero network that could be formed from independent blockchains. Also, NodeChain has been introduced to be a distributed (Unique ID) UID aggregation vault to secure all nodes' UIDs. Moreover, NodeChain is proposed to serve mainly FlexiChain for all node security requirements. NodeChain targets the security and integrity of each node. Also, the linked UIDs create a chain of narration that keeps track not merely for assets but also for who authenticated the assets. The security results present a higher resistance against four types of attacks. Furthermore, the strength of the network is presented from the early stages compared to blockchain and central authority. FlexiChain technology has been introduced to be a layer zero network for all CPS decentralized applications taking into accounts their requirements. FlexiChain relies on lightweight processing mechanisms and creates other methods to increase security.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08713v1","tag":"medical-cv"}}
{"title":"Self-learning mechanical circuits","abstract":"Computation, mechanics and materials merge in biological systems, which can continually self-optimize through internal adaptivity across length scales, from cytoplasm and biofilms to animal herds. Recent interest in such material-based computation uses the principles of energy minimization, inertia and dissipation to solve optimization problems. Although specific computations can be performed using dynamical systems, current implementations of material computation lack the ability to self-learn. In particular, the inverse problem of designing self-learning mechanical systems which can use physical computations to continuously self-optimize remains poorly understood. Here we introduce the concept of self-learning mechanical circuits, capable of taking mechanical inputs from changing environments and constantly updating their internal state in response, thus representing an entirely mechanical information processing unit. Our circuits are composed of a new mechanical construct: an adaptive directed spring (ADS), which changes its stiffness in a directional manner, enabling neural network-like computations. We provide both a theoretical foundation and experimental realization of these elastic learning units and demonstrate their ability to autonomously uncover patterns hidden in environmental inputs. By implementing computations in an embodied physical manner, the system directly interfaces with its environment, thus broadening the scope of its learning behavior. Our results pave the way towards the construction of energy-harvesting, adaptive materials which can autonomously and continuously sense and self-optimize to gain function in different environments.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08711v1","tag":"medical-cv"}}
{"title":"Quantum Algorithm for Unsupervised Anomaly Detection","abstract":"Anomaly detection, an important branch of machine learning, plays a critical role in fraud detection, health care, intrusion detection, military surveillance, etc. As one of the most commonly used unsupervised anomaly detection algorithms, the Local Outlier Factor algorithm (LOF algorithm) has been extensively studied. This algorithm contains three steps, i.e., determining the k-distance neighborhood for each data point x, computing the local reachability density of x, and calculating the local outlier factor of x to judge whether x is abnormal. The LOF algorithm is computationally expensive when processing big data sets. Here we present a quantum LOF algorithm consisting of three parts corresponding to the classical algorithm. Specifically, the k-distance neighborhood of x is determined by amplitude estimation and minimum search; the local reachability density of each data point is calculated in parallel based on the quantum multiply-adder; the local outlier factor of each data point is obtained in parallel using amplitude estimation. It is shown that our quantum algorithm achieves exponential speedup on the dimension of the data points and polynomial speedup on the number of data points compared to its classical counterpart. This work demonstrates the advantage of quantum computing in unsupervised anomaly detection.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08710v1","tag":"medical-cv"}}
{"title":"You Only Need Two Detectors to Achieve Multi-Modal 3D Multi-Object Tracking","abstract":"Firstly, a new multi-object tracking framework is proposed in this paper based on multi-modal fusion. By integrating object detection and multi-object tracking into the same model, this framework avoids the complex data association process in the classical TBD paradigm, and requires no additional training. Secondly, confidence of historical trajectory regression is explored, possible states of a trajectory in the current frame (weak object or strong object) are analyzed and a confidence fusion module is designed to guide non-maximum suppression of trajectory and detection for ordered association. Finally, extensive experiments are conducted on the KITTI and Waymo datasets. The results show that the proposed method can achieve robust tracking by using only two modal detectors and it is more accurate than many of the latest TBD paradigm-based multi-modal tracking methods. The source codes of the proposed method are available at https://github.com/wangxiyang2022/YONTD-MOT","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08709v1","tag":"medical-cv"}}
{"title":"A Voice Disease Detection Method Based on MFCCs and Shallow CNN","abstract":"The incidence rate of voice diseases is increasing year by year. The use of software for remote diagnosis is a technical development trend and has important practical value. Among voice diseases, common diseases that cause hoarseness include spasmodic dysphonia, vocal cord paralysis, vocal nodule, and vocal cord polyp. This paper presents a voice disease detection method that can be applied in a wide range of clinical. We cooperated with Xiangya Hospital of Central South University to collect voice samples from sixty-one different patients. The Mel Frequency Cepstrum Coefficient (MFCC) parameters are extracted as input features to describe the voice in the form of data. An innovative model combining MFCC parameters and single convolution layer CNN is proposed for fast calculation and classification. The highest accuracy we achieved was 92%, it is fully ahead of the original research results and internationally advanced. And we use Advanced Voice Function Assessment Databases (AVFAD) to evaluate the generalization ability of the method we proposed, which achieved an accuracy rate of 98%. Experiments on clinical and standard datasets show that for the pathological detection of voice diseases, our method has greatly improved in accuracy and computational efficiency.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08708v1","tag":"medical-cv"}}
{"title":"Looking Through the Glass: Neural Surface Reconstruction Against High Specular Reflections","abstract":"Neural implicit methods have achieved high-quality 3D object surfaces under slight specular highlights. However, high specular reflections (HSR) often appear in front of target objects when we capture them through glasses. The complex ambiguity in these scenes violates the multi-view consistency, then makes it challenging for recent methods to reconstruct target objects correctly. To remedy this issue, we present a novel surface reconstruction framework, NeuS-HSR, based on implicit neural rendering. In NeuS-HSR, the object surface is parameterized as an implicit signed distance function (SDF). To reduce the interference of HSR, we propose decomposing the rendered image into two appearances: the target object and the auxiliary plane. We design a novel auxiliary plane module by combining physical assumptions and neural networks to generate the auxiliary plane appearance. Extensive experiments on synthetic and real-world datasets demonstrate that NeuS-HSR outperforms state-of-the-art approaches for accurate and robust target surface reconstruction against HSR. Code is available at https://github.com/JiaxiongQ/NeuS-HSR.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08706v1","tag":"medical-cv"}}
{"title":"Learning Sim-to-Real Dense Object Descriptors for Robotic Manipulation","abstract":"It is crucial to address the following issues for ubiquitous robotics manipulation applications: (a) vision-based manipulation tasks require the robot to visually learn and understand the object with rich information like dense object descriptors; and (b) sim-to-real transfer in robotics aims to close the gap between simulated and real data. In this paper, we present Sim-to-Real Dense Object Nets (SRDONs), a dense object descriptor that not only understands the object via appropriate representation but also maps simulated and real data to a unified feature space with pixel consistency. We proposed an object-to-object matching method for image pairs from different scenes and different domains. This method helps reduce the effort of training data from real-world by taking advantage of public datasets, such as GraspNet. With sim-to-real object representation consistency, our SRDONs can serve as a building block for a variety of sim-to-real manipulation tasks. We demonstrate in experiments that pre-trained SRDONs significantly improve performances on unseen objects and unseen visual environments for various robotic tasks with zero real-world training.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08703v1","tag":"medical-cv"}}
{"title":"On the cohomology of the classifying spaces of $SO(n)$-gauge groups over $S^2$","abstract":"Let $\\mathcal{G}_{\\alpha}(X, G)$ be the $G$-gauge group over a space $X$ corresponding to a map $\\alpha \\colon X \\to BG$. We compute the integral cohomology of $B\\mathcal{G}_{1}(S^2, SO(n))$ for $n = 3,4$. We also show that the homology of $B\\mathcal{G}_{1}(S^2, SO(n))$ is torsion free if and only if $n\\le 4$. As an application, we classify the homotopy types of $SO(n)$-gauge groups over a Riemann surface for $n\\le 4$.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08702v1","tag":"medical-cv"}}
{"title":"Wizundry: A Cooperative Wizard of Oz Platform for Simulating Future Speech-based Interfaces with Multiple Wizards","abstract":"Wizard of Oz (WoZ) as a prototyping method has been used to simulate intelligent user interfaces, particularly for speech-based systems. However, as our societies' expectations on artificial intelligence (AI) grows, the question remains whether a single Wizard is sufficient for it to simulate smarter systems and more complex interactions. Optimistic visions of 'what artificial intelligence (AI) can do' places demands on WoZ platforms to simulate smarter systems and more complex interactions. This raises the question of whether the typical approach of employing a single Wizard is sufficient. Moreover, while existing work has employed multiple Wizards in WoZ studies, a multi-Wizard approach has not been systematically studied in terms of feasibility, effectiveness, and challenges. We offer Wizundry, a real-time, web-based WoZ platform that allows multiple Wizards to collaboratively operate a speech-to-text based system remotely. We outline the design and technical specifications of our open-source platform, which we iterated over two design phases. We report on two studies in which participant-Wizards were tasked with negotiating how to cooperatively simulate an interface that can handle natural speech for dictation and text editing as well as other intelligent text processing tasks. We offer qualitative findings on the Multi-Wizard experience for Dyads and Triads of Wizards. Our findings reveal the promises and challenges of the multi-Wizard approach and open up new research questions.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08693v1","tag":"medical-cv"}}
{"title":"RPDP: An Efficient Data Placement based on Residual Performance for P2P Storage Systems","abstract":"Storage systems using Peer-to-Peer (P2P) architecture are an alternative to the traditional client-server systems. They offer better scalability and fault tolerance while at the same time eliminate the single point of failure. The nature of P2P storage systems (which consist of heterogeneous nodes) introduce however data placement challenges that create implementation trade-offs (e.g., between performance and scalability). Existing Kademlia-based DHT data placement method stores data at closest node, where the distance is measured by bit-wise XOR operation between data and a given node. This approach is highly scalable because it does not require global knowledge for placing data nor for the data retrieval. It does not however consider the heterogeneous performance of the nodes, which can result in imbalanced resource usage affecting the overall latency of the system. Other works implement criteria-based selection that addresses heterogeneity of nodes, however often cause subsequent data retrieval to require global knowledge of where the data stored. This paper introduces Residual Performance-based Data Placement (RPDP), a novel data placement method based on dynamic temporal residual performance of data nodes. RPDP places data to most appropriate selected nodes based on their throughput and latency with the aim to achieve lower overall latency by balancing data distribution with respect to the individual performance of nodes. RPDP relies on Kademlia-based DHT with modified data structure to allow data subsequently retrieved without the need of global knowledge. The experimental results indicate that RPDP reduces the overall latency of the baseline Kademlia-based P2P storage system (by 4.87%) and it also reduces the variance of latency among the nodes, with minimal impact to the data retrieval complexity.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08692v1","tag":"medical-cv"}}
{"title":"LTC-SE: Expanding the Potential of Liquid Time-Constant Neural Networks for Scalable AI and Embedded Systems","abstract":"We present LTC-SE, an improved version of the Liquid Time-Constant (LTC) neural network algorithm originally proposed by Hasani et al. in 2021. This algorithm unifies the Leaky-Integrate-and-Fire (LIF) spiking neural network model with Continuous-Time Recurrent Neural Networks (CTRNNs), Neural Ordinary Differential Equations (NODEs), and bespoke Gated Recurrent Units (GRUs). The enhancements in LTC-SE focus on augmenting flexibility, compatibility, and code organization, targeting the unique constraints of embedded systems with limited computational resources and strict performance requirements. The updated code serves as a consolidated class library compatible with TensorFlow 2.x, offering comprehensive configuration options for LTCCell, CTRNN, NODE, and CTGRU classes. We evaluate LTC-SE against its predecessors, showcasing the advantages of our optimizations in user experience, Keras function compatibility, and code clarity. These refinements expand the applicability of liquid neural networks in diverse machine learning tasks, such as robotics, causality analysis, and time-series prediction, and build on the foundational work of Hasani et al.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08691v1","tag":"medical-cv"}}
{"title":"Surface pressure impact on nitrogen-dominated USP super-Earth atmospheres","abstract":"In this paper, we compare the chemistry and the emission spectra of nitrogen-dominated cool, warm, and hot ultra-short-period (USP) super-Earth atmospheres in and out of chemical equilibrium at various surface pressure scenarios ranging from 0.1 to 10 bar. We link the one-dimensional VULCAN chemical kinetic code, in which thermochemical kinetic and vertical transport and photochemistry are taken into account, to the one-dimensional radiative transfer model, PETITRADTRANS, to predict the emission spectra of these planets. The radiative-convective temperature-pressure profiles were computed with the HELIOS code. Then, using PANDEXO noise simulator, we explore the observability of the differences produced by disequilibrium processes with the JWST. Our grids show how different surface pressures can significantly affect the temperature profiles, the atmospheric abundances, and consequently the emission spectra of these planets. We find that the divergences due to disequilibrium processes would be possible to observe in cooler planets by targeting HCN, C2H4, and CO, and in warmer planets by targeting CH4 with HCN, using the NIRSpec and MIRI LRS JWST instruments. These species are also found to be sensitive indicators of the existence of surfaces on nitrogen-dominated USP super-Earths, providing information regarding the thickness of these atmospheres.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08690v1","tag":"medical-cv"}}
{"title":"Reproducibility and FAIR Principles: The Case of a Segment Polarity Network Model","abstract":"The issue of reproducibility of computational models and the related FAIR principles (findable, accessible, interoperable, and reusable) are examined in a specific test case. I analyze a computational model of the segment polarity network in Drosophila embryos published in 2000. Despite the high number of citations to this publication, 23 years later the model is barely accessible, and consequently not interoperable. Following the text of the original publication allowed successfully encoding the model for the open source software COPASI. Subsequently saving the model in the SBML format allowed it to be reused in other open source software packages. Submission of this SBML encoding of the model to the BioModels database enables its findability and accessibility. This demonstrates how the FAIR principles can be successfully enabled by using open source software, widely adopted standards, and public repositories, facilitating reproducibility and reuse of computational cell biology models that will outlive the specific software used.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08688v1","tag":"medical-cv"}}
{"title":"GlobalMind: Global Multi-head Interactive Self-attention Network for Hyperspectral Change Detection","abstract":"High spectral resolution imagery of the Earth's surface enables users to monitor changes over time in fine-grained scale, playing an increasingly important role in agriculture, defense, and emergency response. However, most current algorithms are still confined to describing local features and fail to incorporate a global perspective, which limits their ability to capture interactions between global features, thus usually resulting in incomplete change regions. In this paper, we propose a Global Multi-head INteractive self-attention change Detection network (GlobalMind) to explore the implicit correlation between different surface objects and variant land cover transformations, acquiring a comprehensive understanding of the data and accurate change detection result. Firstly, a simple but effective Global Axial Segmentation (GAS) strategy is designed to expand the self-attention computation along the row space or column space of hyperspectral images, allowing the global connection with high efficiency. Secondly, with GAS, the global spatial multi-head interactive self-attention (Global-M) module is crafted to mine the abundant spatial-spectral feature involving potential correlations between the ground objects from the entire rich and complex hyperspectral space. Moreover, to acquire the accurate and complete cross-temporal changes, we devise a global temporal interactive multi-head self-attention (GlobalD) module which incorporates the relevance and variation of bi-temporal spatial-spectral features, deriving the integrate potential same kind of changes in the local and global range with the combination of GAS. We perform extensive experiments on five mostly used hyperspectral datasets, and our method outperforms the state-of-the-art algorithms with high accuracy and efficiency.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08687v1","tag":"medical-cv"}}
{"title":"Learning Situation Hyper-Graphs for Video Question Answering","abstract":"Answering questions about complex situations in videos requires not only capturing the presence of actors, objects, and their relations but also the evolution of these relationships over time. A situation hyper-graph is a representation that describes situations as scene sub-graphs for video frames and hyper-edges for connected sub-graphs and has been proposed to capture all such information in a compact structured form. In this work, we propose an architecture for Video Question Answering (VQA) that enables answering questions related to video content by predicting situation hyper-graphs, coined Situation Hyper-Graph based Video Question Answering (SHG-VQA). To this end, we train a situation hyper-graph decoder to implicitly identify graph representations with actions and object/human-object relationships from the input video clip. and to use cross-attention between the predicted situation hyper-graphs and the question embedding to predict the correct answer. The proposed method is trained in an end-to-end manner and optimized by a VQA loss with the cross-entropy function and a Hungarian matching loss for the situation graph prediction. The effectiveness of the proposed architecture is extensively evaluated on two challenging benchmarks: AGQA and STAR. Our results show that learning the underlying situation hyper-graphs helps the system to significantly improve its performance for novel challenges of video question-answering tasks.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08682v1","tag":"medical-cv"}}
{"title":"Quantum Error Correction For Dummies","abstract":"In the current Noisy Intermediate Scale Quantum (NISQ) era of quantum computing, qubit technologies are prone to imperfections, giving rise to various errors such as gate errors, decoherence/dephasing, measurement errors, leakage, and crosstalk. These errors present challenges in achieving error-free computation within NISQ devices. A proposed solution to this issue is Quantum Error Correction (QEC), which aims to rectify the corrupted qubit state through a three-step process: (i) detection: identifying the presence of an error, (ii) decoding: pinpointing the location(s) of the affected qubit(s), and (iii) correction: restoring the faulty qubits to their original states. QEC is an expanding field of research that encompasses intricate concepts. In this paper, we aim to provide a comprehensive review of the historical context, current state, and future prospects of Quantum Error Correction, tailored to cater to computer scientists with limited familiarity with quantum physics and its associated mathematical concepts. In this work, we, (a) explain the foundational principles of QEC and explore existing Quantum Error Correction Codes (QECC) designed to correct errors in qubits, (b) explore the practicality of these QECCs concerning implementation and error correction quality, and (c) highlight the challenges associated with implementing QEC within the context of the current landscape of NISQ computers.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08678v1","tag":"medical-cv"}}
{"title":"An end-to-end, interactive Deep Learning based Annotation system for cursive and print English handwritten text","abstract":"With the surging inclination towards carrying out tasks on computational devices and digital mediums, any method that converts a task that was previously carried out manually, to a digitized version, is always welcome. Irrespective of the various documentation tasks that can be done online today, there are still many applications and domains where handwritten text is inevitable, which makes the digitization of handwritten documents a very essential task. Over the past decades, there has been extensive research on offline handwritten text recognition. In the recent past, most of these attempts have shifted to Machine learning and Deep learning based approaches. In order to design more complex and deeper networks, and ensure stellar performances, it is essential to have larger quantities of annotated data. Most of the databases present for offline handwritten text recognition today, have either been manually annotated or semi automatically annotated with a lot of manual involvement. These processes are very time consuming and prone to human errors. To tackle this problem, we present an innovative, complete end-to-end pipeline, that annotates offline handwritten manuscripts written in both print and cursive English, using Deep Learning and User Interaction techniques. This novel method, which involves an architectural combination of a detection system built upon a state-of-the-art text detection model, and a custom made Deep Learning model for the recognition system, is combined with an easy-to-use interactive interface, aiming to improve the accuracy of the detection, segmentation, serialization and recognition phases, in order to ensure high quality annotated data with minimal human interaction.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08670v1","tag":"medical-cv"}}
{"title":"Insta(nt) Pet Therapy: GAN-generated Images for Therapeutic Social Media Content","abstract":"The positive therapeutic effect of viewing pet images online has been well-studied. However, it is difficult to obtain large-scale production of such content since it relies on pet owners to capture photographs and upload them. I use a Generative Adversarial Network-based framework for the creation of fake pet images at scale. These images are uploaded on an Instagram account where they drive user engagement at levels comparable to those seen with images from accounts with traditional pet photographs, underlining the applicability of the framework to be used for pet-therapy social media content.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08665v1","tag":"medical-cv"}}
{"title":"Space Efficient Sequence Alignment for SRAM-Based Computing: X-Drop on the Graphcore IPU","abstract":"Dedicated accelerator hardware has become essential for processing AI-based workloads, leading to the rise of novel accelerator architectures. Furthermore, fundamental differences in memory architecture and parallelism have made these accelerators targets for scientific computing.   The sequence alignment problem is fundamental in bioinformatics; we have implemented the $X$-Drop algorithm, a heuristic method for pairwise alignment that reduces search space, on the Graphcore Intelligence Processor Unit (IPU) accelerator. The $X$-Drop algorithm has an irregular computational pattern, which makes it difficult to accelerate due to load balancing.   Here, we introduce a graph-based partitioning and queue-based batch system to improve load balancing. Our implementation achieves $10\\times$ speedup over a state-of-the-art GPU implementation and up to $4.65\\times$ compared to CPU. In addition, we introduce a memory-restricted $X$-Drop algorithm that reduces memory footprint by $55\\times$ and efficiently uses the IPU's limited low-latency SRAM. This optimization further improves the strong scaling performance by $3.6\\times$.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08662v1","tag":"medical-cv"}}
{"title":"An Ethereum-compatible blockchain that explicates and ensures design-level safety properties for smart contracts","abstract":"Smart contracts are crucial elements of decentralized technologies, but they face significant obstacles to trustworthiness due to security bugs and trapdoors. To address the core issue, we propose a technology that enables programmers to focus on design-level properties rather than specific low-level attack patterns. Our proposed technology, called Theorem-Carrying-Transaction (TCT), combines the benefits of runtime checking and symbolic proof. Under the TCT protocol, every transaction must carry a theorem that proves its adherence to the safety properties in the invoked contracts, and the blockchain checks the proof before executing the transaction. The unique design of TCT ensures that the theorems are provable and checkable in an efficient manner. We believe that TCT holds a great promise for enabling provably secure smart contracts in the future. As such, we call for collaboration toward this vision.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08655v1","tag":"medical-cv"}}
{"title":"On Uncertainty Calibration and Selective Generation in Probabilistic Neural Summarization: A Benchmark Study","abstract":"Modern deep models for summarization attains impressive benchmark performance, but they are prone to generating miscalibrated predictive uncertainty. This means that they assign high confidence to low-quality predictions, leading to compromised reliability and trustworthiness in real-world applications. Probabilistic deep learning methods are common solutions to the miscalibration problem. However, their relative effectiveness in complex autoregressive summarization tasks are not well-understood. In this work, we thoroughly investigate different state-of-the-art probabilistic methods' effectiveness in improving the uncertainty quality of the neural summarization models, across three large-scale benchmarks with varying difficulty. We show that the probabilistic methods consistently improve the model's generation and uncertainty quality, leading to improved selective generation performance (i.e., abstaining from low-quality summaries) in practice. We also reveal notable failure patterns of probabilistic methods widely-adopted in NLP community (e.g., Deep Ensemble and Monte Carlo Dropout), cautioning the importance of choosing appropriate method for the data setting.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08653v1","tag":"medical-cv"}}
{"title":"Classification of US Supreme Court Cases using BERT-Based Techniques","abstract":"Models based on bidirectional encoder representations from transformers (BERT) produce state of the art (SOTA) results on many natural language processing (NLP) tasks such as named entity recognition (NER), part-of-speech (POS) tagging etc. An interesting phenomenon occurs when classifying long documents such as those from the US supreme court where BERT-based models can be considered difficult to use on a first-pass or out-of-the-box basis. In this paper, we experiment with several BERT-based classification techniques for US supreme court decisions or supreme court database (SCDB) and compare them with the previous SOTA results. We then compare our results specifically with SOTA models for long documents. We compare our results for two classification tasks: (1) a broad classification task with 15 categories and (2) a fine-grained classification task with 279 categories. Our best result produces an accuracy of 80\\% on the 15 broad categories and 60\\% on the fine-grained 279 categories which marks an improvement of 8\\% and 28\\% respectively from previously reported SOTA results.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08649v1","tag":"medical-cv"}}
{"title":"ProPanDL: A Modular Architecture for Uncertainty-Aware Panoptic Segmentation","abstract":"We introduce ProPanDL, a family of networks capable of uncertainty-aware panoptic segmentation. Unlike existing segmentation methods, ProPanDL is capable of estimating full probability distributions for both the semantic and spatial aspects of panoptic segmentation. We implement and evaluate ProPanDL variants capable of estimating both parametric (Variance Network) and parameter-free (SampleNet) distributions quantifying pixel-wise spatial uncertainty. We couple these approaches with two methods (Temperature Scaling and Evidential Deep Learning) for semantic uncertainty estimation. To evaluate the uncertainty-aware panoptic segmentation task, we address limitations with existing approaches by proposing new metrics that enable separate evaluation of spatial and semantic uncertainty. We additionally propose the use of the energy score, a proper scoring rule, for more robust evaluation of spatial output distributions. Using these metrics, we conduct an extensive evaluation of ProPanDL variants. Our results demonstrate that ProPanDL is capable of estimating well-calibrated and meaningful output distributions while still retaining strong performance on the base panoptic segmentation task.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08645v1","tag":"medical-cv"}}
{"title":"Comparison of methods for curvature estimation from volume fractions","abstract":"This paper evaluates and compares the accuracy and robustness of curvature estimation methods for three-dimensional interfaces represented implicitly by discrete volume fractions on a Cartesian mesh. The height function (HF) method is compared to three paraboloid fitting methods: fitting to the piecewise linear interface reconstruction centroids (PC), fitting to the piecewise linear interface reconstruction volumetrically (PV), and volumetrically fitting (VF) the paraboloid directly to the volume fraction field. The numerical studies presented in this work find that while the curvature error from the VF method converges with second-order accuracy as with the HF method for static interfaces represented by exact volume fractions, the PV method best balances low curvature errors with low computational cost for dynamic interfaces when the interface reconstruction and advection are coupled to a two-phase Navier-Stokes solver.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08643v1","tag":"medical-cv"}}
{"title":"An Evaluation on Large Language Model Outputs: Discourse and Memorization","abstract":"We present an empirical evaluation of various outputs generated by nine of the most widely-available large language models (LLMs). Our analysis is done with off-the-shelf, readily-available tools. We find a correlation between percentage of memorized text, percentage of unique text, and overall output quality, when measured with respect to output pathologies such as counterfactual and logically-flawed statements, and general failures like not staying on topic. Overall, 80.0% of the outputs evaluated contained memorized data, but outputs containing the most memorized content were also more likely to be considered of high quality. We discuss and evaluate mitigation strategies, showing that, in the models evaluated, the rate of memorized text being output is reduced. We conclude with a discussion on potential implications around what it means to learn, to memorize, and to evaluate quality text.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08637v1","tag":"medical-cv"}}
{"title":"Subcubic algorithm for (Unweighted) Unrooted Tree Edit Distance","abstract":"The tree edit distance problem is a natural generalization of the classic string edit distance problem. Given two ordered, edge-labeled trees $T_1$ and $T_2$, the edit distance between $T_1$ and $T_2$ is defined as the minimum total cost of operations that transform $T_1$ into $T_2$. In one operation, we can contract an edge, split a vertex into two or change the label of an edge. For the weighted version of the problem, where the cost of each operation depends on the type of the operation and the label on the edge involved, $\\mathcal{O}(n^3)$ time algorithms are known for both rooted and unrooted trees. The existence of a truly subcubic $\\mathcal{O}(n^{3-\\epsilon})$ time algorithm is unlikely, as it would imply a truly subcubic algorithm for the APSP problem. However, recently Mao (FOCS'21) showed that if we assume that each operation has a unit cost, then the tree edit distance between two rooted trees can be computed in truly subcubic time. In this paper, we show how to adapt Mao's algorithm to make it work for unrooted trees and we show an $\\widetilde{\\mathcal{O}}(n^{(7\\omega + 15)/(2\\omega + 6)}) \\leq \\mathcal{O}(n^{2.9417})$ time algorithm for the unweighted tree edit distance between two unrooted trees, where $\\omega \\leq 2.373$ is the matrix multiplication exponent. It is the first known subcubic algorithm for unrooted trees. The main idea behind our algorithm is the fact that to compute the tree edit distance between two unrooted trees, it is enough to compute the tree edit distance between an arbitrary rooting of the first tree and every rooting of the second tree.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08632v1","tag":"medical-cv"}}
{"title":"MFGLib: A Library for Mean-Field Games","abstract":"Mean-field games (MFGs) are limiting models to approximate $N$-player games, with a number of applications. Despite the ever-growing numerical literature on computation of MFGs, there is no library that allows researchers and practitioners to easily create and solve their own MFG problems. The purpose of this document is to introduce MFGLib, an open-source Python library for solving general MFGs with a user-friendly and customizable interface. It serves as a handy tool for creating and analyzing generic MFG environments, along with embedded auto-tuners for all implemented algorithms. The package is distributed under the MIT license and the source code and documentation can be found at https://github.com/radar-research-lab/MFGLib/.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08630v1","tag":"medical-cv"}}
{"title":"Identification and Mitigation of Conducting Package Losses for Quantum Superconducting Devices","abstract":"Low-loss superconducting microwave devices are required for quantum computation. Here, we present a series of measurements and simulations showing that conducting losses in the packaging of our superconducting resonator devices affect the maximum achievable internal quality factors (Qi) for a series of thin-film Al quarter-wave resonators with fundamental resonant frequencies varying between 4.9 and 5.8 GHz. By utilizing resonators with different widths and gaps, we sampled different electromagnetic energy volumes for the resonators affecting Qi. When the backside of the sapphire substrate of the resonator device is adhered to a Cu package with a conducting silver glue, a monotonic decrease in the maximum achievable Qi is found as the electromagnetic sampling volume is increased. This is a result of induced currents in large surface resistance regions and dissipation underneath the substrate. By placing a hole underneath the substrate and using superconducting material for the package, we decrease the ohmic losses and increase the maximum Qi for the larger size resonators.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08629v1","tag":"medical-cv"}}
{"title":"A sparse optimization approach to infinite infimal convolution regularization","abstract":"In this paper we introduce the class of infinite infimal convolution functionals and apply these functionals to the regularization of ill-posed inverse problems. The proposed regularization involves an infimal convolution of a continuously parametrized family of convex, positively one-homogeneous functionals defined on a common Banach space $X$. We show that, under mild assumptions, this functional admits an equivalent convex lifting in the space of measures with values in $X$. This reformulation allows us to prove well-posedness of a Tikhonov regularized inverse problem and opens the door to a sparse analysis of the solutions. In the case of finite-dimensional measurements we prove a representer theorem, showing that there exists a solution of the inverse problem that is sparse, in the sense that it can be represented as a linear combination of the extremal points of the ball of the lifted infinite infimal convolution functional. Then, we design a generalized conditional gradient method for computing solutions of the inverse problem without relying on an a priori discretization of the parameter space and of the Banach space $X$. The iterates are constructed as linear combinations of the extremal points of the lifted infinite infimal convolution functional. We prove a sublinear rate of convergence for our algorithm and apply it to denoising of signals and images using, as regularizer, infinite infimal convolutions of fractional-Laplacian-type operators with adaptive orders of smoothness and anisotropies.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08628v1","tag":"medical-cv"}}
{"title":"How human-derived brain organoids are built differently from brain organoids derived of genetically-close relatives: A multi-scale hypothesis","abstract":"How genes affect tissue scale organization remains a longstanding biological puzzle. As experimental efforts are underway to solve this puzzle via quantification of gene expression and sub-cellular, cellular and tissue structure, computational efforts remain far behind. To potentially help accelerate the computational efforts, we review two recent publications, the first on a cellular-based model for tissues and the second on a cell nucleus model consisting of chromatin and a lamina shell. We then give a perspective on how the two models can be combined to test multiscale hypotheses linking the chromatin scale and the tissue scale. To be concrete, we turn to an in vitro system for the brain known as a brain organoid. We provide a multiscale hypothesis to distinguish structural differences between brain organoids built from induced-pluripotent human stem cells and from induced-pluripotent gorilla and chimpanzee stem cells. Recent experiments discover that a cell fate transition from neuroepithelial cells to radial glial cells includes a new intermediate state that is delayed in human-derived brain organoids as compared to their genetically-close relatives, which significantly narrows and lengthens the cells on the apical side [1]. Additional experiments revealed that the protein ZEB2 plays a major role in the emergence of this new intermediate state with ZEB2 mRNA levels peaking at the onset of the emergence [1]. We postulate that the enhancement of ZEB2 expression driving this intermediate state is potentially due to chromatin reorganization. More precisely, there exists critical strain triggering the reorganization that is higher for human-derived stem cells, thereby resulting in a delay. Such a hypothesis can readily be tested experimentally within individual cells and within brain organoids as well as computationally to work towards solving the gene-to-tissue organization puzzle.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08622v1","tag":"medical-cv"}}
{"title":"Neutron Spectroscopy and Computational Methods in investigation of Na ion Battery Materials: A Perspective","abstract":"Adoption of renewable energy is essential to address the challenge of climate change, but that necessitates energy storage technologies. Lithium-ion batteries, the most ubiquitous solution, are insufficient for large-scale applications, so sodium-ion batteries (SIBs), an alternative, are of great current interest. To design and synthesise a commercially viable SIB with required performance, a fundamental understanding of the materials is imperative. Neutron diffraction and spectroscopy provide a unique insight of atomistic understanding of structure and dynamics in materials, therefore in this perspective we have explored how these techniques have been used in SIB research. As neutrons have high penetrability in materials and neutron-matter interaction probabilities are independent of the atomic number, they can provide unique information about motion of particles in bulk materials in the pico- to nanosecond time scales. This makes neutron scattering techniques important tools in battery research. Sodium has a low neutron cross section, which makes computational simulations essential for analysing neutron scattering data of SIB materials. With the availability of high flux neutron sources, high resolution instruments and high performance computers and simulations tools, neutron spectroscopy has been an emerging technique in the last decade for SIB research. In this perspective, we have shown that neutron diffraction is the most popular, while neutron spectroscopies, are just emerging. Computational simulation methods, both force field based and from first principles, are common but still are mostly used independent of neutron experiments. We have identified that suitable improvements of instrumentation, sample environments and simulations methodology will allow these techniques to be more accessible in future.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08621v1","tag":"medical-cv"}}
{"title":"Exploring exotic configurations with anomalous features with deep learning: Application of classical and quantum-classical hybrid anomaly detection","abstract":"In this paper we present the application of classical and quantum-classical hybrid anomaly detection schemes to explore exotic configuration with anomalous features. We consider the Anderson model as a prototype where we define two types of anomalies - a high conductance in presence of strong impurity and low conductance in presence of weak impurity - as a function of random impurity distribution. Such anomalous outcome constitutes less than 10% of a data set and is not a part of the training process. The anomaly detection is therefore more suitable to detect unknown features which is not possible with conventional classification or regression methods. We also present a systematic study of the performance of the classical and the hybrid method and show that the inclusion of a quantum circuit significantly enhances the performance of anomaly detection which we quantify with suitable performance metrics. Our approach is quite generic in nature and can be used for any system that relies on a large number of parameters to find their new configurations which can hold exotic new features.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08616v1","tag":"medical-cv"}}
{"title":"Revisiting Block-Diagonal SDP Relaxations for the Clique Number of the Paley Graphs","abstract":"This work addresses the block-diagonal semidefinite program (SDP) relaxations for the clique number of the Paley graphs. The size of the maximal clique (clique number) of a graph is a classic NP-complete problem; a Paley graph is a deterministic graph where two vertices are connected if their difference is a quadratic residue modulo certain prime powers. Improving the upper bound for the Paley graph clique number for odd prime powers is an open problem in combinatorics. Moreover, since quadratic residues exhibit pseudorandom properties, Paley graphs are related to the construction of deterministic restricted isometries, an open problem in compressed sensing and sparse recovery. Recent work provides evidence that the current upper bounds can be improved by the sum-of-squares (SOS) relaxations. In particular the bounds given by the SOS relaxations of degree 4 (SOS-4) are asymptotically growing at an order smaller than square root of the prime. However computations of SOS-4 become intractable with respect to large graphs. Gvozdenovic et al. introduced a more computationally efficient block-diagonal hierarchy of SDPs that refines the SOS hierarchy. They computed the values of these SDPs of degrees 2 and 3 (L2 and L3 respectively) for the Paley graph clique numbers associated with primes p less or equal to 809. These values bound from the above the values of the corresponding SOS-4 and SOS-6 relaxations respectively. We revisit these computations and determine the values of the L2 relaxation for larger p's. Our results provide additional numerical evidence that the L2 relaxations, and therefore also the SOS-4 relaxations, are asymptotically growing at an order smaller than the square root of p.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08615v1","tag":"medical-cv"}}
{"title":"Bridging Discrete and Backpropagation: Straight-Through and Beyond","abstract":"Backpropagation, the cornerstone of deep learning, is limited to computing gradients solely for continuous variables. This limitation hinders various research on problems involving discrete latent variables. To address this issue, we propose a novel approach for approximating the gradient of parameters involved in generating discrete latent variables. First, we examine the widely used Straight-Through (ST) heuristic and demonstrate that it works as a first-order approximation of the gradient. Guided by our findings, we propose a novel method called ReinMax, which integrates Heun's Method, a second-order numerical method for solving ODEs, to approximate the gradient. Our method achieves second-order accuracy without requiring Hessian or other second-order derivatives. We conduct experiments on structured output prediction and unsupervised generative modeling tasks. Our results show that \\ours brings consistent improvements over the state of the art, including ST and Straight-Through Gumbel-Softmax. Implementations are released at https://github.com/microsoft/ReinMax.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08612v1","tag":"medical-cv"}}
{"title":"Effects of Clutter on Egocentric Distance Perception in Virtual Reality","abstract":"To assess the impact of clutter on egocentric distance perception, we performed a mixed-design study with 60 participants in four different virtual environments (VEs) with three levels of clutter. Additionally, we compared the indoor/outdoor VE characteristics and the HMD's FOV. The participants wore a backpack computer and a wide FOV head-mounted display (HMD) as they blind-walked towards three distinct targets at distances of 3m, 4.5m, and 6m. The HMD's field of view (FOV) was programmatically limited to 165{\\deg}$\\times$110{\\deg}, 110{\\deg}$\\times$110{\\deg}, or 45{\\deg}$\\times$35{\\deg}. The results showed that increased clutter in the environment led to more precise distance judgment and less underestimation, independent of the FOV. In comparison to outdoor VEs, indoor VEs showed more accurate distance judgment. Additionally, participants made more accurate judgements while looking at the VEs through wider FOVs.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08604v1","tag":"medical-cv"}}
{"title":"Crossing Roads of Federated Learning and Smart Grids: Overview, Challenges, and Perspectives","abstract":"Consumer's privacy is a main concern in Smart Grids (SGs) due to the sensitivity of energy data, particularly when used to train machine learning models for different services. These data-driven models often require huge amounts of data to achieve acceptable performance leading in most cases to risks of privacy leakage. By pushing the training to the edge, Federated Learning (FL) offers a good compromise between privacy preservation and the predictive performance of these models. The current paper presents an overview of FL applications in SGs while discussing their advantages and drawbacks, mainly in load forecasting, electric vehicles, fault diagnoses, load disaggregation and renewable energies. In addition, an analysis of main design trends and possible taxonomies is provided considering data partitioning, the communication topology, and security mechanisms. Towards the end, an overview of main challenges facing this technology and potential future directions is presented.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08602v1","tag":"medical-cv"}}
{"title":"RS2G: Data-Driven Scene-Graph Extraction and Embedding for Robust Autonomous Perception and Scenario Understanding","abstract":"Human drivers naturally reason about interactions between road users to understand and safely navigate through traffic. Thus, developing autonomous vehicles necessitates the ability to mimic such knowledge and model interactions between road users to understand and navigate unpredictable, dynamic environments. However, since real-world scenarios often differ from training datasets, effectively modeling the behavior of various road users in an environment remains a significant research challenge. This reality necessitates models that generalize to a broad range of domains and explicitly model interactions between road users and the environment to improve scenario understanding. Graph learning methods address this problem by modeling interactions using graph representations of scenarios. However, existing methods cannot effectively transfer knowledge gained from the training domain to real-world scenarios. This constraint is caused by the domain-specific rules used for graph extraction that can vary in effectiveness across domains, limiting generalization ability. To address these limitations, we propose RoadScene2Graph (RS2G): a data-driven graph extraction and modeling approach that learns to extract the best graph representation of a road scene for solving autonomous scene understanding tasks. We show that RS2G enables better performance at subjective risk assessment than rule-based graph extraction methods and deep-learning-based models. RS2G also improves generalization and Sim2Real transfer learning, which denotes the ability to transfer knowledge gained from simulation datasets to unseen real-world scenarios. We also present ablation studies showing how RS2G produces a more useful graph representation for downstream classifiers. Finally, we show how RS2G can identify the relative importance of rule-based graph edges and enables intelligent graph sparsity tuning.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08600v1","tag":"medical-cv"}}
{"title":"A stratified polyhedral homotopy method for sampling positive dimensional zero sets of polynomial systems","abstract":"Numerical algebraic geometry revolves around the study of solutions to polynomial systems via numerical method. The polyhedral homotopy of Huber and Sturmfels for computing isolated solutions and the concept of witness sets for as numerical representations of non-isolated solution components, put forth by Sommese and Wampler, are two of the fundamental tools in this field. In this paper, we show that a modified polyhedral homotopy can reveal sample sets of non-isolated solution components, akin to witness sets, as by-products from the process of computing isolated solutions.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08598v1","tag":"medical-cv"}}
{"title":"eTOP: Early Termination of Pipelines for Faster Training of AutoML Systems","abstract":"Recent advancements in software and hardware technologies have enabled the use of AI/ML models in everyday applications has significantly improved the quality of service rendered. However, for a given application, finding the right AI/ML model is a complex and costly process, that involves the generation, training, and evaluation of multiple interlinked steps (called pipelines), such as data pre-processing, feature engineering, selection, and model tuning. These pipelines are complex (in structure) and costly (both in compute resource and time) to execute end-to-end, with a hyper-parameter associated with each step. AutoML systems automate the search of these hyper-parameters but are slow, as they rely on optimizing the pipeline's end output. We propose the eTOP Framework which works on top of any AutoML system and decides whether or not to execute the pipeline to the end or terminate at an intermediate step. Experimental evaluation on 26 benchmark datasets and integration of eTOPwith MLBox4 reduces the training time of the AutoML system upto 40x than baseline MLBox.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08597v1","tag":"medical-cv"}}
{"title":"AdaMTL: Adaptive Input-dependent Inference for Efficient Multi-Task Learning","abstract":"Modern Augmented reality applications require performing multiple tasks on each input frame simultaneously. Multi-task learning (MTL) represents an effective approach where multiple tasks share an encoder to extract representative features from the input frame, followed by task-specific decoders to generate predictions for each task. Generally, the shared encoder in MTL models needs to have a large representational capacity in order to generalize well to various tasks and input data, which has a negative effect on the inference latency. In this paper, we argue that due to the large variations in the complexity of the input frames, some computations might be unnecessary for the output. Therefore, we introduce AdaMTL, an adaptive framework that learns task-aware inference policies for the MTL models in an input-dependent manner. Specifically, we attach a task-aware lightweight policy network to the shared encoder and co-train it alongside the MTL model to recognize unnecessary computations. During runtime, our task-aware policy network decides which parts of the model to activate depending on the input frame and the target computational complexity. Extensive experiments on the PASCAL dataset demonstrate that AdaMTL reduces the computational complexity by 43% while improving the accuracy by 1.32% compared to single-task models. Combined with SOTA MTL methodologies, AdaMTL boosts the accuracy by 7.8% while improving the efficiency by 3.1X. When deployed on Vuzix M4000 smart glasses, AdaMTL reduces the inference latency and the energy consumption by up to 21.8% and 37.5%, respectively, compared to the static MTL model. Our code is publicly available at https://github.com/scale-lab/AdaMTL.git.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08594v1","tag":"medical-cv"}}
{"title":"Fast and Straggler-Tolerant Distributed SGD with Reduced Computation Load","abstract":"In distributed machine learning, a central node outsources computationally expensive calculations to external worker nodes. The properties of optimization procedures like stochastic gradient descent (SGD) can be leveraged to mitigate the effect of unresponsive or slow workers called stragglers, that otherwise degrade the benefit of outsourcing the computation. This can be done by only waiting for a subset of the workers to finish their computation at each iteration of the algorithm. Previous works proposed to adapt the number of workers to wait for as the algorithm evolves to optimize the speed of convergence. In contrast, we model the communication and computation times using independent random variables. Considering this model, we construct a novel scheme that adapts both the number of workers and the computation load throughout the run-time of the algorithm. Consequently, we improve the convergence speed of distributed SGD while significantly reducing the computation load, at the expense of a slight increase in communication load.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08589v1","tag":"medical-cv"}}
{"title":"Designing Policies for Truth: Combating Misinformation with Transparency and Information Design","abstract":"Misinformation has become a growing issue on online social platforms (OSPs), especially during elections or pandemics. To combat this, OSPs have implemented various policies, such as tagging, to notify users about potentially misleading information. However, these policies are often transparent and therefore susceptible to being exploited by content creators, who may not be willing to invest effort into producing authentic content, causing the viral spread of misinformation. Instead of mitigating the reach of existing misinformation, this work focuses on a solution of prevention, aiming to stop the spread of misinformation before it has a chance to gain momentum. We propose a Bayesian persuaded branching process ($\\operatorname{BP}^2$) to model the strategic interactions among the OSP, the content creator, and the user. The misinformation spread on OSP is modeled by a multi-type branching process, where users' positive and negative comments influence the misinformation spreading. Using a Lagrangian induced by Bayesian plausibility, we characterize the OSP's optimal policy under the perfect Bayesian equilibrium. The convexity of the Lagrangian implies that the OSP's optimal policy is simply the fully informative tagging policy: revealing the content's accuracy to the user. Such a tagging policy solicits the best effort from the content creator in reducing misinformation, even though the OSP exerts no direct control over the content creator. We corroborate our findings using numerical simulations.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08588v1","tag":"medical-cv"}}
{"title":"Grounding Classical Task Planners via Vision-Language Models","abstract":"Classical planning systems have shown great advances in utilizing rule-based human knowledge to compute accurate plans for service robots, but they face challenges due to the strong assumptions of perfect perception and action executions. To tackle these challenges, one solution is to connect the symbolic states and actions generated by classical planners to the robot's sensory observations, thus closing the perception-action loop. This research proposes a visually-grounded planning framework, named TPVQA, which leverages Vision-Language Models (VLMs) to detect action failures and verify action affordances towards enabling successful plan execution. Results from quantitative experiments show that TPVQA surpasses competitive baselines from previous studies in task completion rate.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08587v1","tag":"medical-cv"}}
{"title":"Safe Navigation and Obstacle Avoidance Using Differentiable Optimization Based Control Barrier Functions","abstract":"Control barrier functions (CBFs) have been widely applied to safety-critical robotic applications. However, the construction of control barrier functions for robotic systems remains a challenging task. Recently, collision detection using differentiable optimization has provided a way to compute the minimum uniform scaling factor that results in an intersection between two convex shapes and to also compute the Jacobian of the scaling factor. In this paper, we propose a framework that uses this scaling factor, with an offset, to systematically define a CBF for obstacle avoidance tasks. We provide a theoretical analysis that proves the continuity of the proposed CBF. Empirically, we show that the proposed CBF is continuously differentiable, and the resulting optimal control problem is computationally efficient, which makes it applicable for real-time robotic control. We validate our approach, first using a 2D mobile robot example, then on the Franka-Emika Research~3 (FR3) robot manipulator both in simulation and experiment.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08586v1","tag":"medical-cv"}}
{"title":"Radiometry for Nighttime Sub-Cloud Imaging of Venus' Surface in the Near-InfraRed Spectrum","abstract":"Does radiometry (e.g., signal-to-noise ratio) limit the performance of near-IR subcloud imaging of our sister planet's surface at night? It does not. We compute subcloud radiometry using above-cloud observations, an assumed ground temperature, sub-cloud absorption and emission modeling, and Rayleigh scattering simulations. We thus confirm both archival and recent studies that deployment of a modest subcloud camera does enable high-resolution surface imaging.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08585v1","tag":"medical-cv"}}
{"title":"Researchers eye-view of sarcasm detection in social media textual content","abstract":"The enormous use of sarcastic text in all forms of communication in social media will have a physiological effect on target users. Each user has a different approach to misusing and recognising sarcasm. Sarcasm detection is difficult even for users, and this will depend on many things such as perspective, context, special symbols. So, that will be a challenging task for machines to differentiate sarcastic sentences from non-sarcastic sentences. There are no exact rules based on which model will accurately detect sarcasm from many text corpus in the current situation. So, one needs to focus on optimistic and forthcoming approaches in the sarcasm detection domain. This paper discusses various sarcasm detection techniques and concludes with some approaches, related datasets with optimal features, and the researcher's challenges.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08582v1","tag":"medical-cv"}}
{"title":"Graph Sparsification by Approximate Matrix Multiplication","abstract":"Graphs arising in statistical problems, signal processing, large networks, combinatorial optimization, and data analysis are often dense, which causes both computational and storage bottlenecks. One way of \\textit{sparsifying} a \\textit{weighted} graph, while sharing the same vertices as the original graph but reducing the number of edges, is through \\textit{spectral sparsification}. We study this problem through the perspective of RandNLA. Specifically, we utilize randomized matrix multiplication to give a clean and simple analysis of how sampling according to edge weights gives a spectral approximation to graph Laplacians. Through the $CR$-MM algorithm, we attain a simple and computationally efficient sparsifier whose resulting Laplacian estimate is unbiased and of minimum variance. Furthermore, we define a new notion of \\textit{additive spectral sparsifiers}, which has not been considered in the literature.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08581v1","tag":"medical-cv"}}
{"title":"U2RLE: Uncertainty-Guided 2-Stage Room Layout Estimation","abstract":"While the existing deep learning-based room layout estimation techniques demonstrate good overall accuracy, they are less effective for distant floor-wall boundary. To tackle this problem, we propose a novel uncertainty-guided approach for layout boundary estimation introducing new two-stage CNN architecture termed U2RLE. The initial stage predicts both floor-wall boundary and its uncertainty and is followed by the refinement of boundaries with high positional uncertainty using a different, distance-aware loss. Finally, outputs from the two stages are merged to produce the room layout. Experiments using ZInD and Structure3D datasets show that U2RLE improves over current state-of-the-art, being able to handle both near and far walls better. In particular, U2RLE outperforms current state-of-the-art techniques for the most distant walls.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08580v1","tag":"medical-cv"}}
{"title":"Fake degrees of classical Weyl groups","abstract":"We compute the fake degrees of representations of classical Weyl groups in terms of domino tableaux.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08579v1","tag":"medical-cv"}}
{"title":"Avatars Grow Legs: Generating Smooth Human Motion from Sparse Tracking Inputs with Diffusion Model","abstract":"With the recent surge in popularity of AR/VR applications, realistic and accurate control of 3D full-body avatars has become a highly demanded feature. A particular challenge is that only a sparse tracking signal is available from standalone HMDs (Head Mounted Devices), often limited to tracking the user's head and wrists. While this signal is resourceful for reconstructing the upper body motion, the lower body is not tracked and must be synthesized from the limited information provided by the upper body joints. In this paper, we present AGRoL, a novel conditional diffusion model specifically designed to track full bodies given sparse upper-body tracking signals. Our model is based on a simple multi-layer perceptron (MLP) architecture and a novel conditioning scheme for motion data. It can predict accurate and smooth full-body motion, particularly the challenging lower body movement. Unlike common diffusion architectures, our compact architecture can run in real-time, making it suitable for online body-tracking applications. We train and evaluate our model on AMASS motion capture dataset, and demonstrate that our approach outperforms state-of-the-art methods in generated motion accuracy and smoothness. We further justify our design choices through extensive experiments and ablation studies.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08577v1","tag":"medical-cv"}}
{"title":"Optimal Robust Network Design: Formulations and Algorithms for Maximizing Algebraic Connectivity","abstract":"This paper focuses on the design of edge-weighted networks, whose robustness is characterized by maximizing algebraic connectivity, or the smallest non-zero eigenvalue of the Laplacian matrix. This problem is motivated by the application of cooperative localization for accurately estimating positions of autonomous vehicles by choosing a set of relative position measurements and establishing associated communication links. We also examine an associated problem where every robot is limited by payload, budget, and communication to pick no more than a specified number of relative position measurements. The basic underlying formulation for these problems is nonlinear and is known to be NP-hard. We solve this network design problem by formulating it as a mixed-integer semi-definite program (MISDP) and reformulating it into a mixed-integer linear program to obtain optimal solutions using cutting plane algorithms. We propose a novel upper-bounding algorithm based on the hierarchy of principal minor characterization of positive semi-definite matrices. We further discuss a degree-constrained lower bounding formulation, inspired by robust network structures. In addition, we propose a maximum-cost heuristic with low computational complexity to find high-quality feasible solutions. We show extensive computational results corroborating our proposed methods.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08571v1","tag":"medical-cv"}}
{"title":"Quantum Many-body Theory from a Solution of the $N$-representability Problem","abstract":"Here we present a many-body theory based on a solution of the $N$-representability problem in which the ground-state two-particle reduced density matrix (2-RDM) is determined directly without the many-particle wave function. We derive an equation that re-expresses physical constraints on higher-order RDMs to generate direct constraints on the 2-RDM, which are required for its derivation from an $N$-particle density matrix, known as $N$-representability conditions. The approach produces a complete hierarchy of 2-RDM constraints that do not depend explicitly upon the higher RDMs or the wave function. By using the two-particle part of a unitary decomposition of higher-order constraint matrices, we can solve the energy minimization by semidefinite programming in a form where the low-rank structure of these matrices can be potentially exploited. We illustrate by computing the ground-state electronic energy and properties of the H$_{8}$ ring.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08570v1","tag":"medical-cv"}}
{"title":"Diagnosing applications' I/O behavior through system call observability","abstract":"We present DIO, a generic tool for observing inefficient and erroneous I/O interactions between applications and in-kernel storage systems that lead to performance, dependability, and correctness issues. DIO facilitates the analysis and enables near real-time visualization of complex I/O patterns for data-intensive applications generating millions of storage requests. This is achieved by non-intrusively intercepting system calls, enriching collected data with relevant context, and providing timely analysis and visualization for traced events. We demonstrate its usefulness by analyzing two production-level applications. Results show that DIO enables diagnosing resource contention in multi-threaded I/O that leads to high tail latency and erroneous file accesses that cause data loss.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08569v1","tag":"medical-cv"}}
{"title":"Traversing combinatorial 0/1-polytopes via optimization","abstract":"In this paper, we present a new framework that exploits combinatorial optimization for efficiently generating a large variety of combinatorial objects based on graphs, matroids, posets and polytopes. Our method relies on a simple and versatile algorithm for computing a Hamilton path on the skeleton of any 0/1-polytope ${\\rm conv}(X)$, where $X\\subseteq \\{0,1\\}^n$. The algorithm uses as a black box any algorithm that solves a variant of the classical linear optimization problem $\\min\\{w\\cdot x\\mid x\\in X\\}$, and the resulting delay, i.e., the running time per visited vertex on the Hamilton path, is only by a factor of $\\log n$ larger than the running time of the optimization algorithm. When $X$ encodes a particular class of combinatorial objects, then traversing the skeleton of the polytope ${\\rm conv}(X)$ along a Hamilton path corresponds to listing the combinatorial objects by local change operations, i.e., we obtain Gray code listings. As concrete results of our general framework, we obtain efficient algorithms for generating all ($c$-optimal) bases in a matroid; ($c$-optimal) spanning trees, forests, ($c$-optimal) matchings in a general graph; ($c$-optimal) vertex covers, ($c$-optimal) stable sets in a bipartite graph; as well as ($c$-optimal) antichains and ideals of a poset. The delay and space required by these algorithms are polynomial in the size of the matroid, graph, or poset, respectively, and these listings correspond to Hamilton paths on the corresponding combinatorial polytopes. We also obtain an $O(t_{\\rm LP} \\log n)$ delay algorithm for the vertex enumeration problem on 0/1-polytopes $\\{x\\in\\mathbb{R}^n\\mid Ax\\leq b\\}$, where $A\\in \\mathbb{R}^{m\\times n}$ and $b\\in\\mathbb{R}^m$, and $t_{\\rm LP}$ is the time needed to solve the linear program $\\min\\{w\\cdot x\\mid Ax\\leq b\\}$. This improves upon the 25-year old $O(t_{\\rm LP}\\,n)$ delay algorithm of Bussieck and L\\\"ubbecke.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08567v1","tag":"medical-cv"}}
{"title":"A Decentralized Authorization and Security Framework for Distributed Research Workflows","abstract":"Research challenges such as climate change and the search for habitable planets increasingly use academic and commercial computing resources distributed across different institutions and physical sites. Furthermore, such analyses often require a level of automation that precludes direct human interaction, and securing these workflows involves adherence to security policies across institutions. In this paper, we present a decentralized authorization and security framework that enables researchers to utilize resources across different sites while allowing service providers to maintain autonomy over their secrets and authorization policies. We describe this framework as part of the Tapis platform, a web-based, hosted API used by researchers from multiple institutions, and we measure the performance of various authorization and security queries, including cross-site queries. We conclude with two use case studies -- a project at the University of Hawaii to study climate change and the NASA NEID telescope project that searches the galaxy for exoplanets.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08557v1","tag":"medical-cv"}}
{"title":"Stochastic Subgraph Neighborhood Pooling for Subgraph Classification","abstract":"Subgraph classification is an emerging field in graph representation learning where the task is to classify a group of nodes (i.e., a subgraph) within a graph. Subgraph classification has applications such as predicting the cellular function of a group of proteins or identifying rare diseases given a collection of phenotypes. Graph neural networks (GNNs) are the de facto solution for node, link, and graph-level tasks but fail to perform well on subgraph classification tasks. Even GNNs tailored for graph classification are not directly transferable to subgraph classification as they ignore the external topology of the subgraph, thus failing to capture how the subgraph is located within the larger graph. The current state-of-the-art models for subgraph classification address this shortcoming through either labeling tricks or multiple message-passing channels, both of which impose a computation burden and are not scalable to large graphs. To address the scalability issue while maintaining generalization, we propose Stochastic Subgraph Neighborhood Pooling (SSNP), which jointly aggregates the subgraph and its neighborhood (i.e., external topology) information without any computationally expensive operations such as labeling tricks. To improve scalability and generalization further, we also propose a simple data augmentation pre-processing step for SSNP that creates multiple sparse views of the subgraph neighborhood. We show that our model is more expressive than GNNs without labeling tricks. Our extensive experiments demonstrate that our models outperform current state-of-the-art methods (with a margin of up to 2%) while being up to 3X faster in training.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08556v1","tag":"medical-cv"}}
{"title":"Hybrid Materialization in a Disk-Based Column-Store","abstract":"In column-oriented query processing, a materialization strategy determines when lightweight positions (row IDs) are translated into tuples. It is an important part of column-store architecture, since it defines the class of supported query plans, and, therefore, impacts the overall system performance.   In this paper we continue investigating materialization strategies for a distributed disk-based column-store. We start with demonstrating cases when existing approaches impose fundamental limitations on the resulting system performance. Then, in order to address them, we propose a new hybrid materialization model. The main feature of hybrid materialization is the ability to manipulate both positions and values at the same time. This way, query engine can flexibly combine advantages of all the existing strategies and support a new class of query plans. Moreover, hybrid materialization allows the query engine to flexibly customize the materialization policy of individual attributes.   We describe our vision of how hybrid materialization can be implemented in a columnar system. As an example, we use PosDB~ -- a distributed, disk-based column-store. We present necessary data structures, the internals of a hybrid operator, and describe the algebra of such operators. Based on this implementation, we evaluate performance of late, ultra-late, and hybrid materialization strategies in several scenarios based on TPC-H queries. Our experiments demonstrate that hybrid materialization is almost two times faster than its counterparts, while providing a more flexible query model.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08532v1","tag":"medical-cv"}}
{"title":"Popular Support for Balancing Equity and Efficiency in Resource Allocation: A Case Study in Online Advertising to Increase Welfare Program Awareness","abstract":"Algorithmically optimizing the provision of limited resources is commonplace across domains from healthcare to lending. Optimization can lead to efficient resource allocation, but, if deployed without additional scrutiny, can also exacerbate inequality. Little is known about popular preferences regarding acceptable efficiency-equity trade-offs, making it difficult to design algorithms that are responsive to community needs and desires. Here we examine this trade-off and concomitant preferences in the context of GetCalFresh, an online service that streamlines the application process for California's Supplementary Nutrition Assistance Program (SNAP, formerly known as food stamps). GetCalFresh runs online advertisements to raise awareness of their multilingual SNAP application service. We first demonstrate that when ads are optimized to garner the most enrollments per dollar, a disproportionately small number of Spanish speakers enroll due to relatively higher costs of non-English language advertising. Embedding these results in a survey (N = 1,532) of a diverse set of Americans, we find broad popular support for valuing equity in addition to efficiency: respondents generally preferred reducing total enrollments to facilitate increased enrollment of Spanish speakers. These results buttress recent calls to reevaluate the efficiency-centric paradigm popular in algorithmic resource allocation.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08530v1","tag":"medical-cv"}}
{"title":"Enhancing Quantum Computation via Superposition of Quantum Gates","abstract":"Overcoming the influence of noise and imperfections in quantum devices is one of the main challenges for viable quantum applications. In this article, we present different protocols, which we denote as \"superposed quantum error mitigation\" (SQEM), that enhance the fidelity of single gates or entire computations by performing them in coherent superposition. Our results demonstrate that via our methods, significant noise suppression can be achieved for most kinds of decoherence and standard experimental parameter regimes. Our protocols can be either deterministic, such that the outcome is never post-selected, or probabilistic, in which case the resulting state must be discarded unless a well-specified condition is met. By using sufficiently many resources and working under broad assumptions, our methods can yield the desired output state with unit fidelity. Finally, we analyze our approach for gate-based, measurement-based and interferometric-based models, demonstrating the applicability in all cases and investigating the fundamental mechanisms they rely upon.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08529v1","tag":"medical-cv"}}
{"title":"SQEM: Superposed Quantum Error Mitigation","abstract":"Overcoming the influence of noise and imperfections is one of the main challenges in quantum computing. Here, we present an approach based on applying a desired unitary computation in superposition, either on the system of interest or some auxiliary states. We demonstrate that parallel applications of the same operation lead to significant noise mitigation when arbitrary noise processes are considered. We first design probabilistic implementations of our scheme. These are plug-and-play, are independent of the noise characteristic and require no post-processing. We then show that the success probability can be enhanced (up to deterministic) using adaptive corrections. We provide an analytical study of our protocol performance and demonstrate that unit fidelity can be achieved asymptotically. The approaches introduced are suitable to both standard gate-based (GB) and measurement-based (MB) computational models.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08528v1","tag":"medical-cv"}}
{"title":"An Updated Dust-to-Star Geometry: Dust Attenuation Does Not Depend on Inclination in $1.3\\leq z\\leq 2.6$ Star-Forming Galaxies from MOSDEF","abstract":"We investigate dust attenuation and its dependence on viewing angle for 308 star-forming galaxies at $1.3\\leq z\\leq2.6$ from the MOSFIRE Deep Evolution Field (MOSDEF) survey. We divide galaxies with a detected H$\\alpha$ emission line and coverage of H$\\beta$ into eight groups by stellar mass, star formation rate (SFR), and inclination (i.e., axis ratio), then stack their spectra. From each stack, we measure Balmer decrement and gas-phase metallicity, then we compute median \\AV and UV continuum spectral slope ($\\beta$). First, we find that none of the dust properties (Balmer decrement, \\AV, $\\beta$) vary with axis ratio. Second, both stellar and nebular attenuation increase with increasing galaxy mass, showing little residual dependence on SFR or metallicity. Third, nebular emission is more attenuated than stellar emission, and this difference grows even larger at higher galaxy masses and SFRs. Based on these results, we propose a three-component dust model where attenuation predominantly occurs in star-forming regions and large, dusty star-forming clumps, with minimal attenuation in the diffuse ISM. In this model, nebular attenuation primarily originates in clumps, while stellar attenuation is dominated by star-forming regions. Clumps become larger and more common with increasing galaxy mass, creating the above mass trends. Finally, we argue that a fixed metal yield naturally leads to mass regulating dust attenuation. Infall of low-metallicity gas increases SFR and lowers metallicity, but leaves dust column density mostly unchanged. We quantify this idea using the Kennicutt-Schmidt and fundamental metallicity relations, showing that galaxy mass is indeed the primary driver of dust attenuation.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08521v1","tag":"medical-cv"}}
{"title":"Persistent and occasional: searching for the variable population of the ZTF/4MOST sky using ZTF data release 11","abstract":"We present a variability, color and morphology based classifier, designed to identify transients, persistently variable, and non-variable sources, from the Zwicky Transient Facility (ZTF) Data Release 11 (DR11) light curves of extended and point sources. The main motivation to develop this model was to identify active galactic nuclei (AGN) at different redshift ranges to be observed by the 4MOST ChANGES project. Still, it serves as a more general time-domain astronomy study. The model uses nine colors computed from CatWISE and PS1, a morphology score from PS1, and 61 single-band variability features computed from the ZTF DR11 g and r light curves. We trained two versions of the model, one for each ZTF band. We used a hierarchical local classifier per parent node approach, where each node was composed of a balanced random forest model. We adopted a 17-class taxonomy, including non-variable stars and galaxies, three transient classes, five classes of stochastic variables, and seven classes of periodic variables. The macro averaged precision, recall and F1-score are 0.61, 0.75, and 0.62 for the g-band model, and 0.60, 0.74, and 0.61, for the r-band model. When grouping the four AGN classes into one single class, its precision, recall, and F1-score are 1.00, 0.95, and 0.97, respectively, for both the g and r bands. We applied the model to all the sources in the ZTF/4MOST overlapping sky, avoiding ZTF fields covering the Galactic bulge, including 86,576,577 light curves in the g-band and 140,409,824 in the r-band. Only 0.73\\% of the g-band light curves and 2.62\\% of the r-band light curves were classified as stochastic, periodic, or transient with high probability ($P_{init}\\geq0.9$). We found that, in general, more reliable results are obtained when using the g-band model. Using the latter, we identified 384,242 AGN candidates, 287,156 of which have $P_{init}\\geq0.9$.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08519v1","tag":"medical-cv"}}
{"title":"STRAP: Structured Object Affordance Segmentation with Point Supervision","abstract":"With significant annotation savings, point supervision has been proven effective for numerous 2D and 3D scene understanding problems. This success is primarily attributed to the structured output space; i.e., samples with high spatial affinity tend to share the same labels. Sharing this spirit, we study affordance segmentation with point supervision, wherein the setting inherits an unexplored dual affinity-spatial affinity and label affinity. By label affinity, we refer to affordance segmentation as a multi-label prediction problem: A plate can be both holdable and containable. By spatial affinity, we refer to a universal prior that nearby pixels with similar visual features should share the same point annotation. To tackle label affinity, we devise a dense prediction network that enhances label relations by effectively densifying labels in a new domain (i.e., label co-occurrence). To address spatial affinity, we exploit a Transformer backbone for global patch interaction and a regularization loss. In experiments, we benchmark our method on the challenging CAD120 dataset, showing significant performance gains over prior methods.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08492v1","tag":"medical-cv"}}
{"title":"Delving into Shape-aware Zero-shot Semantic Segmentation","abstract":"Thanks to the impressive progress of large-scale vision-language pretraining, recent recognition models can classify arbitrary objects in a zero-shot and open-set manner, with a surprisingly high accuracy. However, translating this success to semantic segmentation is not trivial, because this dense prediction task requires not only accurate semantic understanding but also fine shape delineation and existing vision-language models are trained with image-level language descriptions. To bridge this gap, we pursue \\textbf{shape-aware} zero-shot semantic segmentation in this study. Inspired by classical spectral methods in the image segmentation literature, we propose to leverage the eigen vectors of Laplacian matrices constructed with self-supervised pixel-wise features to promote shape-awareness. Despite that this simple and effective technique does not make use of the masks of seen classes at all, we demonstrate that it out-performs a state-of-the-art shape-aware formulation that aligns ground truth and predicted edges during training. We also delve into the performance gains achieved on different datasets using different backbones and draw several interesting and conclusive observations: the benefits of promoting shape-awareness highly relates to mask compactness and language embedding locality. Finally, our method sets new state-of-the-art performance for zero-shot semantic segmentation on both Pascal and COCO, with significant margins. Code and models will be accessed at https://github.com/Liuxinyv/SAZS.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08491v1","tag":"medical-cv"}}
{"title":"Conditional Generation of Audio from Video via Foley Analogies","abstract":"The sound effects that designers add to videos are designed to convey a particular artistic effect and, thus, may be quite different from a scene's true sound. Inspired by the challenges of creating a soundtrack for a video that differs from its true sound, but that nonetheless matches the actions occurring on screen, we propose the problem of conditional Foley. We present the following contributions to address this problem. First, we propose a pretext task for training our model to predict sound for an input video clip using a conditional audio-visual clip sampled from another time within the same source video. Second, we propose a model for generating a soundtrack for a silent input video, given a user-supplied example that specifies what the video should \"sound like\". We show through human studies and automated evaluation metrics that our model successfully generates sound from video, while varying its output according to the content of a supplied example. Project site: https://xypb.github.io/CondFoleyGen/","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08490v1","tag":"medical-cv"}}
{"title":"A statistical model of stellar variability. I. FENRIR: a physics-based model of stellar activity, and its fast Gaussian process approximation","abstract":"The detection of terrestrial planets by radial velocity and photometry is hindered by the presence of stellar signals. Those are often modeled as stationary Gaussian processes, whose kernels are based on qualitative considerations, which do not fully leverage the existing physical understanding of stars. Our aim is to build a formalism which allows to transfer the knowledge of stellar activity into practical data analysis methods. In particular, we aim at obtaining kernels with physical parameters. This has two purposes: better modelling signals of stellar origin to find smaller exoplanets, and extracting information about the star from the statistical properties of the data. We consider several observational channels such as photometry, radial velocity, activity indicators, and build a model called FENRIR to represent their stochastic variations due to stellar surface inhomogeneities. We compute analytically the covariance of this multi-channel stochastic process, and implement it in the S+LEAF framework to reduce the cost of likelihood evaluations from $O(N^3)$ to $O(N)$. We also compute analytically higher order cumulants of our FENRIR model, which quantify its non-Gaussianity. We obtain a fast Gaussian process framework with physical parameters, which we apply to the HARPS-N and SORCE observations of the Sun, and constrain a solar inclination compatible with the viewing geometry. We then discuss the application of our formalism to granulation. We exhibit non-Gaussianity in solar HARPS radial velocities, and argue that information is lost when stellar activity signals are assumed to be Gaussian. We finally discuss the origin of phase shifts between RVs and indicators, and how to build relevant activity indicators. We provide an open-source implementation of the FENRIR Gaussian process model with a Python interface.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08489v1","tag":"medical-cv"}}
{"title":"Affordances from Human Videos as a Versatile Representation for Robotics","abstract":"Building a robot that can understand and learn to interact by watching humans has inspired several vision problems. However, despite some successful results on static datasets, it remains unclear how current models can be used on a robot directly. In this paper, we aim to bridge this gap by leveraging videos of human interactions in an environment centric manner. Utilizing internet videos of human behavior, we train a visual affordance model that estimates where and how in the scene a human is likely to interact. The structure of these behavioral affordances directly enables the robot to perform many complex tasks. We show how to seamlessly integrate our affordance model with four robot learning paradigms including offline imitation learning, exploration, goal-conditioned learning, and action parameterization for reinforcement learning. We show the efficacy of our approach, which we call VRB, across 4 real world environments, over 10 different tasks, and 2 robotic platforms operating in the wild. Results, visualizations and videos at https://robo-affordances.github.io/","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08488v1","tag":"medical-cv"}}
{"title":"Hyper-Decision Transformer for Efficient Online Policy Adaptation","abstract":"Decision Transformers (DT) have demonstrated strong performances in offline reinforcement learning settings, but quickly adapting to unseen novel tasks remains challenging. To address this challenge, we propose a new framework, called Hyper-Decision Transformer (HDT), that can generalize to novel tasks from a handful of demonstrations in a data- and parameter-efficient manner. To achieve such a goal, we propose to augment the base DT with an adaptation module, whose parameters are initialized by a hyper-network. When encountering unseen tasks, the hyper-network takes a handful of demonstrations as inputs and initializes the adaptation module accordingly. This initialization enables HDT to efficiently adapt to novel tasks by only fine-tuning the adaptation module. We validate HDT's generalization capability on object manipulation tasks. We find that with a single expert demonstration and fine-tuning only 0.5% of DT parameters, HDT adapts faster to unseen tasks than fine-tuning the whole DT model. Finally, we explore a more challenging setting where expert actions are not available, and we show that HDT outperforms state-of-the-art baselines in terms of task success rates by a large margin.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08487v1","tag":"medical-cv"}}
{"title":"BenchMD: A Benchmark for Modality-Agnostic Learning on Medical Images and Sensors","abstract":"Medical data poses a daunting challenge for AI algorithms: it exists in many different modalities, experiences frequent distribution shifts, and suffers from a scarcity of examples and labels. Recent advances, including transformers and self-supervised learning, promise a more universal approach that can be applied flexibly across these diverse conditions. To measure and drive progress in this direction, we present BenchMD: a benchmark that tests how modality-agnostic methods, including architectures and training techniques (e.g. self-supervised learning, ImageNet pretraining), perform on a diverse array of clinically-relevant medical tasks. BenchMD combines 19 publicly available datasets for 7 medical modalities, including 1D sensor data, 2D images, and 3D volumetric scans. Our benchmark reflects real-world data constraints by evaluating methods across a range of dataset sizes, including challenging few-shot settings that incentivize the use of pretraining. Finally, we evaluate performance on out-of-distribution data collected at different hospitals than the training data, representing naturally-occurring distribution shifts that frequently degrade the performance of medical AI models. Our baseline results demonstrate that no modality-agnostic technique achieves strong performance across all modalities, leaving ample room for improvement on the benchmark. Code is released at https://github.com/rajpurkarlab/BenchMD .","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08486v1","tag":"medical-cv"}}
{"title":"Visual Instruction Tuning","abstract":"Instruction tuning large language models (LLMs) using machine-generated instruction-following data has improved zero-shot capabilities on new tasks, but the idea is less explored in the multimodal field. In this paper, we present the first attempt to use language-only GPT-4 to generate multimodal language-image instruction-following data. By instruction tuning on such generated data, we introduce LLaVA: Large Language and Vision Assistant, an end-to-end trained large multimodal model that connects a vision encoder and LLM for general-purpose visual and language understanding.Our early experiments show that LLaVA demonstrates impressive multimodel chat abilities, sometimes exhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and yields a 85.1% relative score compared with GPT-4 on a synthetic multimodal instruction-following dataset. When fine-tuned on Science QA, the synergy of LLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53%. We make GPT-4 generated visual instruction tuning data, our model and code base publicly available.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08485v1","tag":"medical-cv"}}
{"title":"Text2Performer: Text-Driven Human Video Generation","abstract":"Text-driven content creation has evolved to be a transformative technique that revolutionizes creativity. Here we study the task of text-driven human video generation, where a video sequence is synthesized from texts describing the appearance and motions of a target performer. Compared to general text-driven video generation, human-centric video generation requires maintaining the appearance of synthesized human while performing complex motions. In this work, we present Text2Performer to generate vivid human videos with articulated motions from texts. Text2Performer has two novel designs: 1) decomposed human representation and 2) diffusion-based motion sampler. First, we decompose the VQVAE latent space into human appearance and pose representation in an unsupervised manner by utilizing the nature of human videos. In this way, the appearance is well maintained along the generated frames. Then, we propose continuous VQ-diffuser to sample a sequence of pose embeddings. Unlike existing VQ-based methods that operate in the discrete space, continuous VQ-diffuser directly outputs the continuous pose embeddings for better motion modeling. Finally, motion-aware masking strategy is designed to mask the pose embeddings spatial-temporally to enhance the temporal coherence. Moreover, to facilitate the task of text-driven human video generation, we contribute a Fashion-Text2Video dataset with manually annotated action labels and text descriptions. Extensive experiments demonstrate that Text2Performer generates high-quality human videos (up to 512x256 resolution) with diverse appearances and flexible motions.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08483v1","tag":"medical-cv"}}
{"title":"On Learning Time Series Summary DAGs: A Frequency Domain Approach","abstract":"The fields of time series and graphical models emerged and advanced separately. Previous work on the structure learning of continuous and real-valued time series utilizes the time domain, with a focus on either structural autoregressive models or linear (non-)Gaussian Bayesian Networks. In contrast, we propose a novel frequency domain approach to identify a topological ordering and learn the structure of both real and complex-valued multivariate time series. In particular, we define a class of complex-valued Structural Causal Models (cSCM) at each frequency of the Fourier transform of the time series. Assuming that the time series is generated from the transfer function model, we show that the topological ordering and corresponding summary directed acyclic graph can be uniquely identified from cSCM. The performance of our algorithm is investigated using simulation experiments and real datasets.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08482v1","tag":"medical-cv"}}
{"title":"Neural Map Prior for Autonomous Driving","abstract":"High-definition (HD) semantic maps are crucial for autonomous vehicles navigating urban environments. Traditional offline HD maps, created through labor-intensive manual annotation processes, are both costly and incapable of accommodating timely updates. Recently, researchers have proposed inferring local maps based on online sensor observations; however, this approach is constrained by the sensor perception range and is susceptible to occlusions. In this work, we propose Neural Map Prior (NMP), a neural representation of global maps that facilitates automatic global map updates and improves local map inference performance. To incorporate the strong map prior into local map inference, we employ cross-attention that dynamically captures correlations between current features and prior features. For updating the global neural map prior, we use a learning-based fusion module to guide the network in fusing features from previous traversals. This design allows the network to capture a global neural map prior during sequential online map predictions. Experimental results on the nuScenes dataset demonstrate that our framework is highly compatible with various map segmentation and detection architectures and considerably strengthens map prediction performance, even under adverse weather conditions and across longer horizons. To the best of our knowledge, this represents the first learning-based system for constructing a global map prior.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08481v1","tag":"medical-cv"}}
{"title":"DisCo-CLIP: A Distributed Contrastive Loss for Memory Efficient CLIP Training","abstract":"We propose DisCo-CLIP, a distributed memory-efficient CLIP training approach, to reduce the memory consumption of contrastive loss when training contrastive learning models. Our approach decomposes the contrastive loss and its gradient computation into two parts, one to calculate the intra-GPU gradients and the other to compute the inter-GPU gradients. According to our decomposition, only the intra-GPU gradients are computed on the current GPU, while the inter-GPU gradients are collected via all_reduce from other GPUs instead of being repeatedly computed on every GPU. In this way, we can reduce the GPU memory consumption of contrastive loss computation from $\\bigO(B^2)$ to $\\bigO(\\frac{B^2}{N})$, where $B$ and $N$ are the batch size and the number of GPUs used for training. Such a distributed solution is mathematically equivalent to the original non-distributed contrastive loss computation, without sacrificing any computation accuracy. It is particularly efficient for large-batch CLIP training. For instance, DisCo-CLIP can enable contrastive training of a ViT-B/32 model with a batch size of 32K or 196K using 8 or 64 A100 40GB GPUs, compared with the original CLIP solution which requires 128 A100 40GB GPUs to train a ViT-B/32 model with a batch size of 32K. The code will be released at https://github.com/IDEA-Research/DisCo-CLIP","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08480v1","tag":"medical-cv"}}
{"title":"Towards Robust Prompts on Vision-Language Models","abstract":"With the advent of vision-language models (VLMs) that can perform in-context and prompt-based learning, how can we design prompting approaches that robustly generalize to distribution shift and can be used on novel classes outside the support set of the prompts? In this work, we first define two types of robustness to distribution shift on VLMs, namely, robustness on base classes (the classes included in the support set of prompts) and robustness on novel classes. Then, we study the robustness of existing in-context learning and prompt learning approaches, where we find that prompt learning performs robustly on test images from base classes, while it does not generalize well on images from novel classes. We propose robust prompt learning by integrating multiple-scale image features into the prompt, which improves both types of robustness. Comprehensive experiments are conducted to study the defined robustness on six benchmarks and show the effectiveness of our proposal.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08479v1","tag":"medical-cv"}}
{"title":"Wave Packets in AdS/CFT Correspondence","abstract":"In this paper, we construct a general bulk wave packet in the AdS/CFT correspondence. This wave packet can be described both in bulk and CFT descriptions. Then, we compute the time evolution of the energy density of this wave packet state on the vacuum in the CFT picture of $AdS_3/CFT_2$. We find that the energy density of the wave packet is localized in two points, which means that the bulk wave packet corresponds to two light-like particle-like objects in the CFT picture. Our result implies that the entanglement wedge reconstruction is invalid.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08478v1","tag":"medical-cv"}}
{"title":"Latent-Shift: Latent Diffusion with Temporal Shift for Efficient Text-to-Video Generation","abstract":"We propose Latent-Shift -- an efficient text-to-video generation method based on a pretrained text-to-image generation model that consists of an autoencoder and a U-Net diffusion model. Learning a video diffusion model in the latent space is much more efficient than in the pixel space. The latter is often limited to first generating a low-resolution video followed by a sequence of frame interpolation and super-resolution models, which makes the entire pipeline very complex and computationally expensive. To extend a U-Net from image generation to video generation, prior work proposes to add additional modules like 1D temporal convolution and/or temporal attention layers. In contrast, we propose a parameter-free temporal shift module that can leverage the spatial U-Net as is for video generation. We achieve this by shifting two portions of the feature map channels forward and backward along the temporal dimension. The shifted features of the current frame thus receive the features from the previous and the subsequent frames, enabling motion learning without additional parameters. We show that Latent-Shift achieves comparable or better results while being significantly more efficient. Moreover, Latent-Shift can generate images despite being finetuned for T2V generation.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08477v2","tag":"medical-cv"}}
{"title":"Symmetry Fractionalized (Irrationalized) Fusion Rules and Two Domain-Wall Verlinde Formulae","abstract":"We investigate interdomain excitations in composite systems of topological orders separated by gapped domain walls. We derive two domain-wall Verlinde formulae that relate the braiding between interdomain excitations and domain-wall quasiparticles to the fusion rules of interdomain excitations and the fusion rules of domain-wall quasiparticles. We show how to compute such braiding and fusion with explicit non-Abelian examples and find that the fusion rules of interdomain excitations are generally fractional or irrational. By exploring the correspondence between composite systems and anyon condensation, we uncover why such fusion rules should be called symmetry fractionalized (irrationalized) fusion rules. Our domain-wall Verlinde formulae generalize the Verlinde formula of a single topological order and the defect Verlinde formula found in [C. Shen and L.-Y. Hung, Phys. Rev. Lett. 123, 051602 (2019)]. Our results may find applications in topological quantum computing, topological field theories, and conformal field theories.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08475v1","tag":"medical-cv"}}
{"title":"Signatures of Fractional Quantum Anomalous Hall States in Twisted MoTe2 Bilayer","abstract":"The interplay between spontaneous symmetry breaking and topology can result in exotic quantum states of matter. A celebrated example is the quantum anomalous Hall (QAH) state, which exhibits an integer quantum Hall effect at zero magnetic field thanks to its intrinsic ferromagnetism. In the presence of strong electron-electron interactions, exotic fractional-QAH (FQAH) states at zero magnetic field can emerge. These states could host fractional excitations, including non-Abelian anyons - crucial building blocks for topological quantum computation. Flat Chern bands are widely considered as a desirable venue to realize the FQAH state. For this purpose, twisted transition metal dichalcogenide homobilayers in rhombohedral stacking have recently been predicted to be a promising material platform. Here, we report experimental signatures of FQAH states in 3.7-degree twisted MoTe2 bilayer. Magnetic circular dichroism measurements reveal robust ferromagnetic states at fractionally hole filled moir\\'e minibands. Using trion photoluminescence as a sensor, we obtain a Landau fan diagram which shows linear shifts in carrier densities corresponding to the v=-2/3 and -3/5 ferromagnetic states with applied magnetic field. These shifts match the Streda formula dispersion of FQAH states with fractionally quantized Hall conductance of -2/3$e^2/h$ and -3/5$e^2/h$, respectively. Moreover, the v=-1 state exhibits a dispersion corresponding to Chern number -1, consistent with the predicted QAH state. In comparison, several non-ferromagnetic states on the electron doping side do not disperse, i.e., are trivial correlated insulators. The observed topological states can be further electrically driven into topologically trivial states. Our findings provide clear evidence of the long-sought FQAH states, putting forward MoTe2 moir\\'e superlattices as a fascinating platform for exploring fractional excitations.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08470v1","tag":"medical-cv"}}
{"title":"Learning to Compress Prompts with Gist Tokens","abstract":"Prompting is now the primary way to utilize the multitask capabilities of language models (LMs), but prompts occupy valuable space in the input context window, and re-encoding the same prompt is computationally inefficient. Finetuning and distillation methods allow for specialization of LMs without prompting, but require retraining the model for each task. To avoid this trade-off entirely, we present gisting, which trains an LM to compress prompts into smaller sets of \"gist\" tokens which can be reused for compute efficiency. Gist models can be easily trained as part of instruction finetuning via a restricted attention mask that encourages prompt compression. On decoder (LLaMA-7B) and encoder-decoder (FLAN-T5-XXL) LMs, gisting enables up to 26x compression of prompts, resulting in up to 40% FLOPs reductions, 4.2% wall time speedups, storage savings, and minimal loss in output quality.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08467v1","tag":"medical-cv"}}
{"title":"Synthetic Data from Diffusion Models Improves ImageNet Classification","abstract":"Deep generative models are becoming increasingly powerful, now generating diverse high fidelity photo-realistic samples given text prompts. Have they reached the point where models of natural images can be used for generative data augmentation, helping to improve challenging discriminative tasks? We show that large-scale text-to image diffusion models can be fine-tuned to produce class conditional models with SOTA FID (1.76 at 256x256 resolution) and Inception Score (239 at 256x256). The model also yields a new SOTA in Classification Accuracy Scores (64.96 for 256x256 generative samples, improving to 69.24 for 1024x1024 samples). Augmenting the ImageNet training set with samples from the resulting models yields significant improvements in ImageNet classification accuracy over strong ResNet and Vision Transformer baselines.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08466v1","tag":"medical-cv"}}
{"title":"MasaCtrl: Tuning-Free Mutual Self-Attention Control for Consistent Image Synthesis and Editing","abstract":"Despite the success in large-scale text-to-image generation and text-conditioned image editing, existing methods still struggle to produce consistent generation and editing results. For example, generation approaches usually fail to synthesize multiple images of the same objects/characters but with different views or poses. Meanwhile, existing editing methods either fail to achieve effective complex non-rigid editing while maintaining the overall textures and identity, or require time-consuming fine-tuning to capture the image-specific appearance. In this paper, we develop MasaCtrl, a tuning-free method to achieve consistent image generation and complex non-rigid image editing simultaneously. Specifically, MasaCtrl converts existing self-attention in diffusion models into mutual self-attention, so that it can query correlated local contents and textures from source images for consistency. To further alleviate the query confusion between foreground and background, we propose a mask-guided mutual self-attention strategy, where the mask can be easily extracted from the cross-attention maps. Extensive experiments show that the proposed MasaCtrl can produce impressive results in both consistent image generation and complex non-rigid real image editing.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08465v1","tag":"medical-cv"}}
{"title":"Learning to Render Novel Views from Wide-Baseline Stereo Pairs","abstract":"We introduce a method for novel view synthesis given only a single wide-baseline stereo image pair. In this challenging regime, 3D scene points are regularly observed only once, requiring prior-based reconstruction of scene geometry and appearance. We find that existing approaches to novel view synthesis from sparse observations fail due to recovering incorrect 3D geometry and due to the high cost of differentiable rendering that precludes their scaling to large-scale training. We take a step towards resolving these shortcomings by formulating a multi-view transformer encoder, proposing an efficient, image-space epipolar line sampling scheme to assemble image features for a target ray, and a lightweight cross-attention-based renderer. Our contributions enable training of our method on a large-scale real-world dataset of indoor and outdoor scenes. We demonstrate that our method learns powerful multi-view geometry priors while reducing the rendering time. We conduct extensive comparisons on held-out test scenes across two real-world datasets, significantly outperforming prior work on novel view synthesis from sparse image observations and achieving multi-view-consistent novel view synthesis.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08463v1","tag":"medical-cv"}}
{"title":"LongForm: Optimizing Instruction Tuning for Long Text Generation with Corpus Extraction","abstract":"Instruction tuning enables language models to generalize more effectively and better follow user intent. However, obtaining instruction data can be costly and challenging. Prior works employ methods such as expensive human annotation, crowd-sourced datasets with alignment issues, or generating noisy examples via LLMs. We introduce the LongForm dataset, which is created by leveraging English corpus examples with augmented instructions. We select a diverse set of human-written documents from existing corpora such as C4 and Wikipedia and generate instructions for the given documents via LLMs. This approach provides a cheaper and cleaner instruction-tuning dataset and one suitable for long text generation. We finetune T5, OPT, and LLaMA models on our dataset and show that even smaller LongForm models have good generalization capabilities for text generation. Our models outperform 10x larger language models without instruction tuning on various tasks such as story/recipe generation and long-form question answering. Moreover, LongForm models outperform prior instruction-tuned models such as FLAN-T5 and Alpaca by a large margin. Finally, our models can effectively follow and answer multilingual instructions; we demonstrate this for news generation. We publicly release our data and models: https://github.com/akoksal/LongForm.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08460v1","tag":"medical-cv"}}
{"title":"Secrecy Design of Indoor Visible Light Communication Network under Downlink NOMA Transmission","abstract":"In this work, we investigate the transmission sum rate as well as the secrecy sum rate of indoor visible light communication (VLC) networks for mobile devices with the power domain non-orthogonal multiple access (NOMA) transmission, where multiple legitimate users are equipped with photodiodes (PDs). We introduce a body blockage model of the legitimate users as well as the eavesdropper to focus on the case where the communications from transmitting light-emitting diodes (LEDs) to receiving devices are blocked by the bodies of receiving users. Furthermore, in order to improve the secrecy without any knowledge of the channel state information (CSI) of the eavesdropper, a novel LED arrangement is introduced to reduce the overlapping area covered by LED units supporting different users. We also propose two LED operation strategies, called simple and smart LED linking, and evaluate their performance against the conventional broadcasting in terms of transmission sum rate and secrecy sum rate. Through computer simulations, the superiority of our proposed strategies is demonstrated.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08458v2","tag":"medical-cv"}}
{"title":"Improving Autoregressive NLP Tasks via Modular Linearized Attention","abstract":"Various natural language processing (NLP) tasks necessitate models that are efficient and small based on their ultimate application at the edge or in other resource-constrained environments. While prior research has reduced the size of these models, increasing computational efficiency without considerable performance impacts remains difficult, especially for autoregressive tasks. This paper proposes \\textit{modular linearized attention (MLA)}, which combines multiple efficient attention mechanisms, including cosFormer \\cite{zhen2022cosformer}, to maximize inference quality while achieving notable speedups. We validate this approach on several autoregressive NLP tasks, including speech-to-text neural machine translation (S2T NMT), speech-to-text simultaneous translation (SimulST), and autoregressive text-to-spectrogram, noting efficiency gains on TTS and competitive performance for NMT and SimulST during training and inference.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08453v1","tag":"medical-cv"}}
{"title":"Efficient Video Action Detection with Token Dropout and Context Refinement","abstract":"Streaming video clips with large-scale video tokens impede vision transformers (ViTs) for efficient recognition, especially in video action detection where sufficient spatiotemporal representations are required for precise actor identification. In this work, we propose an end-to-end framework for efficient video action detection (EVAD) based on vanilla ViTs. Our EVAD consists of two specialized designs for video action detection. First, we propose a spatiotemporal token dropout from a keyframe-centric perspective. In a video clip, we maintain all tokens from its keyframe, preserve tokens relevant to actor motions from other frames, and drop out the remaining tokens in this clip. Second, we refine scene context by leveraging remaining tokens for better recognizing actor identities. The region of interest (RoI) in our action detector is expanded into temporal domain. The captured spatiotemporal actor identity representations are refined via scene context in a decoder with the attention mechanism. These two designs make our EVAD efficient while maintaining accuracy, which is validated on three benchmark datasets (i.e., AVA, UCF101-24, JHMDB). Compared to the vanilla ViT backbone, our EVAD reduces the overall GFLOPs by 43% and improves real-time inference speed by 40% with no performance degradation. Moreover, even at similar computational costs, our EVAD can improve the performance by 1.0 mAP with higher resolution inputs. Code is available at https://github.com/MCG-NJU/EVAD.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08451v1","tag":"medical-cv"}}
{"title":"ImpressionGPT: An Iterative Optimizing Framework for Radiology Report Summarization with ChatGPT","abstract":"The 'Impression' section of a radiology report is a critical basis for communication between radiologists and other physicians, and it is typically written by radiologists based on the 'Findings' section. However, writing numerous impressions can be laborious and error-prone for radiologists. Although recent studies have achieved promising results in automatic impression generation using large-scale medical text data for pre-training and fine-tuning pre-trained language models, such models often require substantial amounts of medical text data and have poor generalization performance. While large language models (LLMs) like ChatGPT have shown strong generalization capabilities and performance, their performance in specific domains, such as radiology, remains under-investigated and potentially limited. To address this limitation, we propose ImpressionGPT, which leverages the in-context learning capability of LLMs by constructing dynamic contexts using domain-specific, individualized data. This dynamic prompt approach enables the model to learn contextual knowledge from semantically similar examples from existing data. Additionally, we design an iterative optimization algorithm that performs automatic evaluation on the generated impression results and composes the corresponding instruction prompts to further optimize the model. The proposed ImpressionGPT model achieves state-of-the-art performance on both MIMIC-CXR and OpenI datasets without requiring additional training data or fine-tuning the LLMs. This work presents a paradigm for localizing LLMs that can be applied in a wide range of similar application scenarios, bridging the gap between general-purpose LLMs and the specific language processing needs of various domains.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08448v1","tag":"medical-cv"}}
{"title":"RadarFormer: Lightweight and Accurate Real-Time Radar Object Detection Model","abstract":"The performance of perception systems developed for autonomous driving vehicles has seen significant improvements over the last few years. This improvement was associated with the increasing use of LiDAR sensors and point cloud data to facilitate the task of object detection and recognition in autonomous driving. However, LiDAR and camera systems show deteriorating performances when used in unfavorable conditions like dusty and rainy weather. Radars on the other hand operate on relatively longer wavelengths which allows for much more robust measurements in these conditions. Despite that, radar-centric data sets do not get a lot of attention in the development of deep learning techniques for radar perception. In this work, we consider the radar object detection problem, in which the radar frequency data is the only input into the detection framework. We further investigate the challenges of using radar-only data in deep learning models. We propose a transformers-based model, named RadarFormer, that utilizes state-of-the-art developments in vision deep learning. Our model also introduces a channel-chirp-time merging module that reduces the size and complexity of our models by more than 10 times without compromising accuracy. Comprehensive experiments on the CRUW radar dataset demonstrate the advantages of the proposed method. Our RadarFormer performs favorably against the state-of-the-art methods while being 2x faster during inference and requiring only one-tenth of their model parameters. The code associated with this paper is available at https://github.com/YahiDar/RadarFormer.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08447v1","tag":"medical-cv"}}
{"title":"Inverse design of next-generation superconductors using data-driven deep generative models","abstract":"Over the past few decades, finding new superconductors with a high critical temperature ($T_c$) has been a challenging task due to computational and experimental costs. In this work, we present a diffusion model inspired by the computer vision community to generate new superconductors with unique structures and chemical compositions. Specifically, we used a crystal diffusion variational autoencoder (CDVAE) along with atomistic line graph neural network (ALIGNN) pretrained models and the Joint Automated Repository for Various Integrated Simulations (JARVIS) superconducting database of density functional theory (DFT) calculations to generate new superconductors with a high success rate. We started with a DFT dataset of $\\approx$1000 superconducting materials to train the diffusion model. We used the model to generate 3000 new structures, which along with pre-trained ALIGNN screening results in 62 candidates. For the top candidate structures, we carried out further DFT calculations to validate our findings. Such approaches go beyond the typical funnel-like materials design approaches and allow for the inverse design of next-generation materials.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08446v2","tag":"medical-cv"}}
{"title":"SCANet: Self-Paced Semi-Curricular Attention Network for Non-Homogeneous Image Dehazing","abstract":"The presence of non-homogeneous haze can cause scene blurring, color distortion, low contrast, and other degradations that obscure texture details. Existing homogeneous dehazing methods struggle to handle the non-uniform distribution of haze in a robust manner. The crucial challenge of non-homogeneous dehazing is to effectively extract the non-uniform distribution features and reconstruct the details of hazy areas with high quality. In this paper, we propose a novel self-paced semi-curricular attention network, called SCANet, for non-homogeneous image dehazing that focuses on enhancing haze-occluded regions. Our approach consists of an attention generator network and a scene reconstruction network. We use the luminance differences of images to restrict the attention map and introduce a self-paced semi-curricular learning strategy to reduce learning ambiguity in the early stages of training. Extensive quantitative and qualitative experiments demonstrate that our SCANet outperforms many state-of-the-art methods. The code is publicly available at https://github.com/gy65896/SCANet.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08444v1","tag":"medical-cv"}}
{"title":"The MiniPile Challenge for Data-Efficient Language Models","abstract":"The ever-growing diversity of pre-training text corpora has equipped language models with generalization capabilities across various downstream tasks. However, such diverse datasets are often too large for academic budgets; hence, most research on Transformer architectures, training procedures, optimizers, etc. gets conducted on smaller, homogeneous datasets. To this end, we present The MiniPile Challenge, where one pre-trains a language model on a diverse text corpus containing at most 1M documents. MiniPile is a 6GB subset of the deduplicated 825GB The Pile corpus. To curate MiniPile, we perform a simple, three-step data filtering process: we (1) infer embeddings for all documents of the Pile, (2) cluster the embedding space using $k$-means, and (3) filter out low-quality clusters. To verify MiniPile's suitability for language model pre-training, we use it to pre-train a BERT and T5 model, yielding a performance drop of only $1.9\\%$/$2.5\\%$ on the GLUE and SNI benchmarks compared to the original pre-trained checkpoints trained on $2.6$x/$745$x the amount of data. MiniPile is available at https://huggingface.co/datasets/JeanKaddour/minipile.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08442v1","tag":"medical-cv"}}
{"title":"Comment on Mark Textor: Brentano's Positing Theory of Existence","abstract":"This article is the text of a commentary on a talk delivered by Mark Textor entitled 'Brentano's Positing Theory of Existence' in December 2015. It contains ideas on implementing Textor's Neo-Brentanian theory of existence in a natural deduction proof system for negative free logic.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08441v1","tag":"medical-cv"}}
{"title":"Morph-SSL: Self-Supervision with Longitudinal Morphing to Predict AMD Progression from OCT","abstract":"The lack of reliable biomarkers makes predicting the conversion from intermediate to neovascular age-related macular degeneration (iAMD, nAMD) a challenging task. We develop a Deep Learning (DL) model to predict the future risk of conversion of an eye from iAMD to nAMD from its current OCT scan. Although eye clinics generate vast amounts of longitudinal OCT scans to monitor AMD progression, only a small subset can be manually labeled for supervised DL. To address this issue, we propose Morph-SSL, a novel Self-supervised Learning (SSL) method for longitudinal data. It uses pairs of unlabelled OCT scans from different visits and involves morphing the scan from the previous visit to the next. The Decoder predicts the transformation for morphing and ensures a smooth feature manifold that can generate intermediate scans between visits through linear interpolation. Next, the Morph-SSL trained features are input to a Classifier which is trained in a supervised manner to model the cumulative probability distribution of the time to conversion with a sigmoidal function. Morph-SSL was trained on unlabelled scans of 399 eyes (3570 visits). The Classifier was evaluated with a five-fold cross-validation on 2418 scans from 343 eyes with clinical labels of the conversion date. The Morph-SSL features achieved an AUC of 0.766 in predicting the conversion to nAMD within the next 6 months, outperforming the same network when trained end-to-end from scratch or pre-trained with popular SSL methods. Automated prediction of the future risk of nAMD onset can enable timely treatment and individualized AMD management.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08439v1","tag":"medical-cv"}}
{"title":"Can a virtual conductor create its own interpretation of a music orchestra?","abstract":"Having a computer do the work for you has become more and more common over time. But in the entertainment area, where a human is a creator, we want to avoid having too much influence on technology. On the other hand, inspiration is still important; we developed a virtual conductor that can generate an emotionally associated interpretation of known music work. This was done by surveying a set number of people to determine, which emotions were associated with a specific interpretation and instruments. As a result of machine learning this conductor was then able to achieve his goal. Unlike earlier studies of virtual conductors, which would replace the role of a human conductor, this new one is supposed to be an assisting tool for conductors. As a result, starting on a new interpretation will be easier because it streamlines research time and provides a technical perspective that can inspire new ideas. By using this technology as a supplement to human creativity, we can create richer, more nuanced interpretations of musical works.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08434v1","tag":"medical-cv"}}
{"title":"Managed Campaigns and Data-Augmented Auctions for Digital Advertising","abstract":"We develop an auction model for digital advertising. A monopoly platform has access to data on the value of the match between advertisers and consumers. The platform support bidding with additional information and increase the feasible surplus for on-platform matches. Advertisers jointly determine their pricing strategy both on and off the platform, as well as their bidding for digital advertising on the platform. We compare a data-augmented second-price auction and a managed campaign mechanism. In the data-augmented auction, the bids by the advertisers are informed by the data of the platform regarding the value of the match. This results in a socially efficient allocation on the platform, but the advertisers increase their product prices off the platform to be more competitive on the platform. In consequence, the allocation off the platform is inefficient due to excessively high product prices. The managed campaign mechanism allows advertisers to submit budgets that are then transformed into matches and prices through an autobidding algorithm. Compared to the data-augmented second-price auction, the optimal managed campaign mechanism increases the revenue of the digital platform. The product prices off the platform increase and the consumer surplus decreases.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08432v1","tag":"medical-cv"}}
{"title":"Prak: An automatic phonetic alignment tool for Czech","abstract":"Labeling speech down to the identity and time boundaries of phones is a labor-intensive part of phonetic research. To simplify this work, we created a free open-source tool generating phone sequences from Czech text and time-aligning them with audio.   Low architecture complexity makes the design approachable for students of phonetics. Acoustic model ReLU NN with 56k weights was trained using PyTorch on small CommonVoice data. Alignment and variant selection decoder is implemented in Python with matrix library.   A Czech pronunciation generator is composed of simple rule-based blocks capturing the logic of the language where possible, allowing modification of transcription approach details.   Compared to tools used until now, data preparation efficiency improved, the tool is usable on Mac, Linux and Windows in Praat GUI or command line, achieves mostly correct pronunciation variant choice including glottal stop detection, algorithmically captures most of Czech assimilation logic and is both didactic and practical.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08431v1","tag":"medical-cv"}}
{"title":"Two-loop Vilkovisky-DeWitt effective action for scalar field minimally coupled with gravity","abstract":"It is known that Vilkovisky-DeWitt's effective action is gauge invariant off-shell and independent of quantum field parametrization. In this work, we perform the calculation of the divergences in two-loop Vilkovisky-DeWitt's effective action for the theory of a massive scalar field minimally coupled to gravity. We quantize both gravity and scalar field around a flat Minkowski metric and a constant scalar field background. The quantum corrections are computed up to second order in the background scalar field for the purpose of mass renormalization.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08425v1","tag":"medical-cv"}}
{"title":"A quantum advantage over classical for local max cut","abstract":"We compare the performance of a quantum local algorithm to a similar classical counterpart on a well-established combinatorial optimization problem LocalMaxCut. We show that a popular quantum algorithm first discovered by Farhi, Goldstone, and Gutmannn [1] called the quantum optimization approximation algorithm (QAOA) has a computational advantage over comparable local classical techniques on degree-3 graphs. These results hint that even small-scale quantum computation, which is relevant to the current state-of the art quantum hardware, could have significant advantages over comparably simple classical computation.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08420v2","tag":"medical-cv"}}
{"title":"Topology, dynamics, and control of an octopus-analog muscular hydrostat","abstract":"Muscular hydrostats, such as octopus arms or elephant trunks, lack bones entirely, endowing them with exceptional dexterity and reconfigurability. Key to their unmatched ability to control nearly infinite degrees of freedom is the architecture into which muscle fibers are weaved. Their arrangement is, effectively, the instantiation of a sophisticated mechanical program that mediates, and likely facilitates, the control and realization of complex, dynamic morphological reconfigurations. Here, by combining medical imaging, biomechanical data, live behavioral experiments and numerical simulations, we synthesize a model octopus arm entailing ~200 continuous muscles groups, and begin to unravel its complexity. We show how 3D arm motions can be understood in terms of storage, transport, and conversion of topological quantities, effected by simple muscle activation templates. These, in turn, can be composed into higher-level control strategies that, compounded by the arm's compliance, are demonstrated in a range of object manipulation tasks rendered additionally challenging by the need to appropriately align suckers, to sense and grasp. Overall, our work exposes broad design and algorithmic principles pertinent to muscular hydrostats, robotics, and dynamics, while significantly advancing our ability to model muscular structures from medical imaging, with potential implications for human health and care.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08413v1","tag":"medical-cv"}}
{"title":"About the Expressive Power and Complexity of Order-Invariance with Two Variables","abstract":"Order-invariant first-order logic is an extension of first-order logic (FO) where formulae can make use of a linear order on the structures, under the proviso that they are order-invariant, i.e. that their truth value is the same for all linear orders. We continue the study of the two-variable fragment of order-invariant first-order logic initiated by Zeume and Harwath, and study its complexity and expressive power. We first establish coNExpTime-completeness for the problem of deciding if a given two-variable formula is order-invariant, which tightens and significantly simplifies the coN2ExpTime proof by Zeume and Harwath. Second, we address the question of whether every property expressible in order-invariant two-variable logic is also expressible in first-order logic without the use of a linear order. While we were not able to provide a satisfactory answer to the question, we suspect that the answer is ``no''. To justify our claim, we present a class of finite tree-like structures (of unbounded degree) in which a relaxed variant of order-invariant two-variable FO expresses properties that are not definable in plain FO. On the other hand, we show that if one restricts their attention to classes of structures of bounded degree, then the expressive power of order-invariant two-variable FO is contained within FO.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08410v1","tag":"medical-cv"}}
{"title":"OVTrack: Open-Vocabulary Multiple Object Tracking","abstract":"The ability to recognize, localize and track dynamic objects in a scene is fundamental to many real-world applications, such as self-driving and robotic systems. Yet, traditional multiple object tracking (MOT) benchmarks rely only on a few object categories that hardly represent the multitude of possible objects that are encountered in the real world. This leaves contemporary MOT methods limited to a small set of pre-defined object categories. In this paper, we address this limitation by tackling a novel task, open-vocabulary MOT, that aims to evaluate tracking beyond pre-defined training categories. We further develop OVTrack, an open-vocabulary tracker that is capable of tracking arbitrary object classes. Its design is based on two key ingredients: First, leveraging vision-language models for both classification and association via knowledge distillation; second, a data hallucination strategy for robust appearance feature learning from denoising diffusion probabilistic models. The result is an extremely data-efficient open-vocabulary tracker that sets a new state-of-the-art on the large-scale, large-vocabulary TAO benchmark, while being trained solely on static images. Project page: https://www.vis.xyz/pub/ovtrack/","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08408v1","tag":"medical-cv"}}
{"title":"Laser Systems for High Fidelity Control and Entanglement of Neutral Atomic Qubits","abstract":"We present new photonics and electronics packages recently developed by M Squared Lasers specifically tailored for scalable neutral atom quantum computing; a high power 1064 nm system for scalable qubit number, a phase locked system for high fidelity single qubit control, and robust cavity locked systems for high fidelity Rydberg operations. We attain driven coherence times competitive with current state-of-the-art for both ground state Raman and ground-Rydberg transitions without cavity filtering, providing an excellent platform for neutral atom quantum computing. These systems are benchmarked by creating entangled Bell states across 7 atom pairs, where we measure a peak raw fidelity of $F\\ge0.88(2)$ and a peak SPAM corrected of $F_C\\ge0.93(3)$ via a two-qubit $CZ$ gate.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08402v1","tag":"medical-cv"}}
{"title":"Multimodal Short Video Rumor Detection System Based on Contrastive Learning","abstract":"With short video platforms becoming one of the important channels for news sharing, major short video platforms in China have gradually become new breeding grounds for fake news. However, it is not easy to distinguish short video rumors due to the great amount of information and features contained in short videos, as well as the serious homogenization and similarity of features among videos. In order to mitigate the spread of short video rumors, our group decides to detect short video rumors by constructing multimodal feature fusion and introducing external knowledge after considering the advantages and disadvantages of each algorithm. The ideas of detection are as follows: (1) dataset creation: to build a short video dataset with multiple features; (2) multimodal rumor detection model: firstly, we use TSN (Temporal Segment Networks) video coding model to extract video features; then, we use OCR (Optical Character Recognition) and ASR (Automatic Character Recognition) to extract video features. Recognition) and ASR (Automatic Speech Recognition) fusion to extract text, and then use the BERT model to fuse text features with video features (3) Finally, use contrast learning to achieve distinction: first crawl external knowledge, then use the vector database to achieve the introduction of external knowledge and the final structure of the classification output. Our research process is always oriented to practical needs, and the related knowledge results will play an important role in many practical scenarios such as short video rumor identification and social opinion control.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08401v2","tag":"medical-cv"}}
{"title":"ATHEENA: A Toolflow for Hardware Early-Exit Network Automation","abstract":"The continued need for improvements in accuracy, throughput, and efficiency of Deep Neural Networks has resulted in a multitude of methods that make the most of custom architectures on FPGAs. These include the creation of hand-crafted networks and the use of quantization and pruning to reduce extraneous network parameters. However, with the potential of static solutions already well exploited, we propose to shift the focus to using the varying difficulty of individual data samples to further improve efficiency and reduce average compute for classification. Input-dependent computation allows for the network to make runtime decisions to finish a task early if the result meets a confidence threshold. Early-Exit network architectures have become an increasingly popular way to implement such behaviour in software.   We create: A Toolflow for Hardware Early-Exit Network Automation (ATHEENA), an automated FPGA toolflow that leverages the probability of samples exiting early from such networks to scale the resources allocated to different sections of the network. The toolflow uses the data-flow model of fpgaConvNet, extended to support Early-Exit networks as well as Design Space Exploration to optimize the generated streaming architecture hardware with the goal of increasing throughput/reducing area while maintaining accuracy. Experimental results on three different networks demonstrate a throughput increase of $2.00\\times$ to $2.78\\times$ compared to an optimized baseline network implementation with no early exits. Additionally, the toolflow can achieve a throughput matching the same baseline with as low as $46\\%$ of the resources the baseline requires.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08400v1","tag":"medical-cv"}}
{"title":"Code-centric Learning-based Just-In-Time Vulnerability Detection","abstract":"Attacks against computer systems exploiting software vulnerabilities can cause substantial damage to the cyber-infrastructure of our modern society and economy. To minimize the consequences, it is vital to detect and fix vulnerabilities as soon as possible. Just-in-time vulnerability detection (JIT-VD) discovers vulnerability-prone (\"dangerous\") commits to prevent them from being merged into source code and causing vulnerabilities. By JIT-VD, the commits' authors, who understand the commits properly, can review these dangerous commits and fix them if necessary while the relevant modifications are still fresh in their minds. In this paper, we propose CodeJIT, a novel code-centric learning-based approach for just-in-time vulnerability detection. The key idea of CodeJIT is that the meaning of the code changes of a commit is the direct and deciding factor for determining if the commit is dangerous for the code. Based on that idea, we design a novel graph-based representation to represent the semantics of code changes in terms of both code structures and program dependencies. A graph neural network model is developed to capture the meaning of the code changes represented by our graph-based representation and learn to discriminate between dangerous and safe commits. We conducted experiments to evaluate the JIT-VD performance of CodeJIT on a dataset of 20K+ dangerous and safe commits in 506 real-world projects from 1998 to 2022. Our results show that CodeJIT significantly improves the state-of-the-art JIT-VD methods by up to 66% in Recall, 136% in Precision, and 68% in F1. Moreover, CodeJIT correctly classifies nearly 9/10 of dangerous/safe (benign) commits and even detects 69 commits that fix a vulnerability yet produce other issues in source code","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08396v1","tag":"medical-cv"}}
{"title":"When SAM Meets Medical Images: An Investigation of Segment Anything Model (SAM) on Multi-phase Liver Tumor Segmentation","abstract":"Learning to segmentation without large-scale samples is an inherent capability of human. Recently, Segment Anything Model (SAM) performs the significant zero-shot image segmentation, attracting considerable attention from the computer vision community. Here, we investigate the capability of SAM for medical image analysis, especially for multi-phase liver tumor segmentation (MPLiTS), in terms of prompts, data resolution, phases. Experimental results demonstrate that there might be a large gap between SAM and expected performance. Fortunately, the qualitative results show that SAM is a powerful annotation tool for the community of interactive medical image segmentation.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08506v1","tag":"medical-cv"}}
{"title":"Evolution of dislocation loops in irradiated \u03b1-Uranium: An atomistically-informed cluster dynamics investigation","abstract":"An atomistically informed mean field cluster dynamics model has been presented to investigate the nucleation and growth of defect loops in irradiated {\\alpha}-U. TEM analysis of neutron irradiated {\\alpha}-U shows the evolution of SIA and vacancy loops on (010) and (100) crystallographic planes respectively, resulting in an anisotropic swelling of the face-centered orthorhombic crystal. The accumulation of such loops, on irradiation, has been closely estimated using the cluster dynamics model. Parameters of the model, namely, the binding energy of point defects, i.e., Ui and VU, to SIA and vacancy loops respectively and the diffusivity of point defects govern the energetics and kinetics of the defect clustering phenomenon. We have studied the crystallography of defect loops and computed the binding energy of point defects to such loops using an angular dependent EAM potential in classical MD simulations. Using bond-boost hyperdynamics in LAMMPS, the anisotropic diffusion of Ui and VU in {\\alpha}-U has been investigated. The mechanisms of point defect diffusion and the associated migration energies have also been reported and compared with previous DFT studies. Our CD model uses the computed parameters, within their error ranges, to predict the population of defect clusters with a dose-rate and temperature similar to the neutron irradiation experiments. The predictions show an accumulation of small sized vacancy loops along with a population of large and growing SIA loops which closely corresponds to the TEM observations.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08387v1","tag":"medical-cv"}}
{"title":"Progressive Visual Prompt Learning with Contrastive Feature Re-formation","abstract":"Prompt learning has been designed as an alternative to fine-tuning for adapting Vision-language (V-L) models to the downstream tasks. Previous works mainly focus on text prompt while visual prompt works are limited for V-L models. The existing visual prompt methods endure either mediocre performance or unstable training process, indicating the difficulty of visual prompt learning. In this paper, we propose a new Progressive Visual Prompt (ProVP) structure to strengthen the interactions among prompts of different layers. More importantly, our ProVP could effectively propagate the image embeddings to deep layers and behave partially similar to an instance adaptive prompt method. To alleviate generalization deterioration, we further propose a new contrastive feature re-formation, which prevents the serious deviation of the prompted visual feature from the fixed CLIP visual feature distribution. Combining both, our method (ProVP-Ref) is evaluated on 11 image benchmark datasets and achieves 7/11 state-of-theart results on both few-shot and base-to-novel settings. To the best of our knowledge, we are the first to demonstrate the superior performance of visual prompts in V-L models to previous prompt-based methods in downstream tasks. Meanwhile, it implies that our ProVP-Ref shows the best capability to adapt and to generalize.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08386v1","tag":"medical-cv"}}
{"title":"Unsupervised Image Denoising with Score Function","abstract":"Though achieving excellent performance in some cases, current unsupervised learning methods for single image denoising usually have constraints in applications. In this paper, we propose a new approach which is more general and applicable to complicated noise models. Utilizing the property of score function, the gradient of logarithmic probability, we define a solving system for denoising. Once the score function of noisy images has been estimated, the denoised result can be obtained through the solving system. Our approach can be applied to multiple noise models, such as the mixture of multiplicative and additive noise combined with structured correlation. Experimental results show that our method is comparable when the noise model is simple, and has good performance in complicated cases where other methods are not applicable or perform poorly.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08384v1","tag":"medical-cv"}}
{"title":"Physics-inspired Neuroacoustic Computing Based on Tunable Nonlinear Multiple-scattering","abstract":"Waves, such as light and sound, inherently bounce and mix due to multiple scattering induced by the complex material objects that surround us. This scattering process severely scrambles the information carried by waves, challenging conventional communication systems, sensing paradigms, and wave-based computing schemes. Here, we show that instead of being a hindrance, multiple scattering can be beneficial to enable and enhance analog nonlinear information mapping, allowing for the direct physical implementation of computational paradigms such as reservoir computing and extreme learning machines. We propose a physics-inspired version of such computational architectures for speech and vowel recognition that operate directly in the native domain of the input signal, namely on real-sounds, without any digital pre-processing or encoding conversion and backpropagation training computation. We first implement it in a proof-of-concept prototype, a nonlinear chaotic acoustic cavity containing multiple tunable and power-efficient nonlinear meta-scatterers. We prove the efficiency of the acoustic-based computing system for vowel recognition tasks with high testing classification accuracy (91.4%). Finally, we demonstrate the high performance of vowel recognition in the natural environment of a reverberation room. Our results open the way for efficient acoustic learning machines that operate directly on the input sound, and leverage physics to enable Natural Language Processing (NLP).","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08380v1","tag":"medical-cv"}}
{"title":"Robust human position estimation in cooperative robotic cells","abstract":"Robots are increasingly present in our lives, sharing the workspace and tasks with human co-workers. However, existing interfaces for human-robot interaction / cooperation (HRI/C) have limited levels of intuitiveness to use and safety is a major concern when humans and robots share the same workspace. Many times, this is due to the lack of a reliable estimation of the human pose in space which is the primary input to calculate the human-robot minimum distance (required for safety and collision avoidance) and HRI/C featuring machine learning algorithms classifying human behaviours / gestures. Each sensor type has its own characteristics resulting in problems such as occlusions (vision) and drift (inertial) when used in an isolated fashion. In this paper, it is proposed a combined system that merges the human tracking provided by a 3D vision sensor with the pose estimation provided by a set of inertial measurement units (IMUs) placed in human body limbs. The IMUs compensate the gaps in occluded areas to have tracking continuity. To mitigate the lingering effects of the IMU offset we propose a continuous online calculation of the offset value. Experimental tests were designed to simulate human motion in a human-robot collaborative environment where the robot moves away to avoid unexpected collisions with de human. Results indicate that our approach is able to capture the human\\textsc's position, for example the forearm, with a precision in the millimetre range and robustness to occlusions.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08379v1","tag":"medical-cv"}}
{"title":"Zero sum subsequences and hidden subgroups","abstract":"We propose a method for solving the hidden subgroup problem in nilpotent groups. The main idea is iteratively transforming the hidden subgroup to its images in the quotient groups by the members of a central series, eventually to its image in the commutative quotient of the original group; and then using an abelian hidden subgroup algorithm to determine this image. Knowing this image allows one to descend to a proper subgroup unless the hidden subgroup is the full group. The transformation relies on finding zero sum subsequences of sufficiently large sequences of vectors over finite prime fields. We present a new deterministic polynomial time algorithm for the latter problem in the case when the size of the field is constant. The consequence is a polynomial time exact quantum algorithm for the hidden subgroup problem in nilpotent groups having constant nilpotency class and whose order only have prime factors also bounded by a constant.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08376v1","tag":"medical-cv"}}
{"title":"New Product Development (NPD) through Social Media-based Analysis by Comparing Word2Vec and BERT Word Embeddings","abstract":"This study introduces novel methods for sentiment and opinion classification of tweets to support the New Product Development (NPD) process. Two popular word embedding techniques, Word2Vec and BERT, were evaluated as inputs for classic Machine Learning and Deep Learning algorithms to identify the best-performing approach in sentiment analysis and opinion detection with limited data. The results revealed that BERT word embeddings combined with Balanced Random Forest yielded the most accurate single model for both sentiment analysis and opinion detection on a use case. Additionally, the paper provides feedback for future product development performing word graph analysis of the tweets with same sentiment to highlight potential areas of improvement.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08369v1","tag":"medical-cv"}}
{"title":"Human Gesture and Gait Analysis for Autism Detection","abstract":"Autism diagnosis presents a major challenge due to the vast heterogeneity of the condition and the elusive nature of early detection. Atypical gait and gesture patterns are dominant behavioral characteristics of autism and can provide crucial insights for diagnosis. Furthermore, these data can be collected efficiently in a non-intrusive way, facilitating early intervention to optimize positive outcomes. Existing research mainly focuses on associating facial and eye-gaze features with autism. However, very few studies have investigated movement and gesture patterns which can reveal subtle variations and characteristics that are specific to autism. To address this gap, we present an analysis of gesture and gait activity in videos to identify children with autism and quantify the severity of their condition by regressing autism diagnostic observation schedule scores. Our proposed architecture addresses two key factors: (1) an effective feature representation to manifest irregular gesture patterns and (2) a two-stream co-learning framework to enable a comprehensive understanding of its relation to autism from diverse perspectives without explicitly using additional data modality. Experimental results demonstrate the efficacy of utilizing gesture and gait-activity videos for autism analysis.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08368v1","tag":"medical-cv"}}
{"title":"Some thoughts and experiments on Bergman's compact amalgamation problem","abstract":"We study the question whether copies of $S^1$ in $\\mathrm{SU}(3)$ can be amalgamated in a compact group. This is the simplest instance of a fundamental open problem in the theory of compact groups raised by George Bergman in 1987. Considerable computational experiments suggest that the answer is positive in this case. We obtain a positive answer for a relaxed problem using theoretical considerations.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08365v1","tag":"medical-cv"}}
{"title":"Transformer with Selective Shuffled Position Embedding using ROI-Exchange Strategy for Early Detection of Knee Osteoarthritis","abstract":"Knee OsteoArthritis (KOA) is a prevalent musculoskeletal disorder that causes decreased mobility in seniors. The lack of sufficient data in the medical field is always a challenge for training a learning model due to the high cost of labelling. At present, deep neural network training strongly depends on data augmentation to improve the model's generalization capability and avoid over-fitting. However, existing data augmentation operations, such as rotation, gamma correction, etc., are designed based on the data itself, which does not substantially increase the data diversity. In this paper, we proposed a novel approach based on the Vision Transformer (ViT) model with Selective Shuffled Position Embedding (SSPE) and a ROI-exchange strategy to obtain different input sequences as a method of data augmentation for early detection of KOA (KL-0 vs KL-2). More specifically, we fixed and shuffled the position embedding of ROI and non-ROI patches, respectively. Then, for the input image, we randomly selected other images from the training set to exchange their ROI patches and thus obtained different input sequences. Finally, a hybrid loss function was derived using different loss functions with optimized weights. Experimental results show that our proposed approach is a valid method of data augmentation as it can significantly improve the model's classification performance.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08364v1","tag":"medical-cv"}}
{"title":"A ZX-Calculus Approach to Concatenated Graph Codes","abstract":"Quantum Error-Correcting Codes (QECCs) are vital for ensuring the reliability of quantum computing and quantum communication systems. Among QECCs, stabilizer codes, particularly graph codes, have attracted considerable attention due to their unique properties and potential applications. Concatenated codes, whichcombine multiple layers of quantum codes, offer a powerful technique for achieving high levels of error correction with a relatively low resource overhead. In this paper, we examine the concatenation of graph codes using the powerful and versatile graphical language of ZX-calculus. We establish a correspondence between the encoding map and ZX-diagrams, and provide a simple proof of the equivalence between encoding maps in the Pauli X basis and the graphic operation \"generalized local complementation\" (GLC) as previously demonstrated in [J. Math. Phys. 52, 022201]. Our analysis reveals that the resulting concatenated code remains a graph code only when the encoding qubits of the same inner code are not directly connected. When they are directly connected, additional Clifford operations are necessary to transform the concatenated code into a graphcode, thus generalizing the results in [J. Math. Phys. 52, 022201]. We further explore concatenated graph codesin different bases, including the examination of holographic codes as concatenated graph codes. Our findings showcase the potential of ZX-calculus in advancing the field of quantum error correction.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08363v1","tag":"medical-cv"}}
{"title":"Spectral flow and the exact AdS$_3/$CFT$_2$ chiral ring","abstract":"We compute all worldsheet three-point functions involving spectrally-flowed operators in chiral multiplets of the space-time theory for strings in AdS$_3\\times$S$^3\\times$T$^4$, thus completing the analysis of the full AdS$_3$/CFT$_2$ chiral ring. We make use of techniques recently developed for the bosonic sector, based on holomorphic covering maps from the worldsheet to the AdS$_3$ boundary. We highlight the role of the so-called series identifications when dealing with the complications originated by picture-changing spectrally-flowed states. We find an exact agreement with the predictions from the holographic CFT at the symmetric orbifold point, including both extremal and non-extremal correlators.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08361v1","tag":"medical-cv"}}
{"title":"Covariant spin-parity decomposition of the Torsion and Path Integrals","abstract":"We propose a functional measure over the torsion tensor. We discuss two completely equivalent choices for the Wheeler-DeWitt supermetric for this field, the first one being based on its algebraic decomposition, the other inspired by teleparallel theories of gravity. The measure is formally defined by requiring the normalization of the Gaussian integral. To achieve such a result we split the torsion tensor into its spin-parity eigenstates by constructing a new, York-like, decomposition. Of course, such a decomposition has a wider range of applicability to any kind of tensor sharing the symmetries of the torsion. As a result of this procedure a functional Jacobian naturally arises, whose formal expression is given exactly in the phenomenologically interesting limit of maximally symmetric spaces. We also discuss the explicit computation of this Jacobian in the case of a $4$-dimensional sphere $S^4$ with particular emphasis on its logarithmic divergences.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08360v1","tag":"medical-cv"}}
{"title":"On approximating the temporal betweenness centrality through sampling","abstract":"We present a collection of sampling-based algorithms for approximating the temporal betweenness centrality of all nodes in a temporal graph. Our methods can compute probabilistically guaranteed high-quality temporal betweenness estimates (of nodes and temporal edges) under all the feasible temporal path optimalities presented in the work of Bu{\\ss} et al. (KDD, 2020). We provide a sample-complexity analysis of these methods and we speed up the temporal betweenness computation using progressive sampling techniques. Finally, we conduct an extensive experimental evaluation on real-world networks and we compare their performances in approximating the betweenness scores and rankings.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08356v1","tag":"medical-cv"}}
{"title":"Tool Learning with Foundation Models","abstract":"Humans possess an extraordinary ability to create and utilize tools, allowing them to overcome physical limitations and explore new frontiers. With the advent of foundation models, AI systems have the potential to be equally adept in tool use as humans. This paradigm, i.e., tool learning with foundation models, combines the strengths of specialized tools and foundation models to achieve enhanced accuracy, efficiency, and automation in problem-solving. Despite its immense potential, there is still a lack of a comprehensive understanding of key challenges, opportunities, and future endeavors in this field. To this end, we present a systematic investigation of tool learning in this paper. We first introduce the background of tool learning, including its cognitive origins, the paradigm shift of foundation models, and the complementary roles of tools and models. Then we recapitulate existing tool learning research into tool-augmented and tool-oriented learning. We formulate a general tool learning framework: starting from understanding the user instruction, models should learn to decompose a complex task into several subtasks, dynamically adjust their plan through reasoning, and effectively conquer each sub-task by selecting appropriate tools. We also discuss how to train models for improved tool-use capabilities and facilitate the generalization in tool learning. Considering the lack of a systematic tool learning evaluation in prior works, we experiment with 17 representative tools and show the potential of current foundation models in skillfully utilizing tools. Finally, we discuss several open problems that require further investigation for tool learning. Overall, we hope this paper could inspire future research in integrating tools with foundation models.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08354v1","tag":"medical-cv"}}
{"title":"What Makes a Good Dataset for Symbol Description Reading?","abstract":"The usage of mathematical formulas as concise representations of a document's key ideas is common practice. Correctly interpreting these formulas, by identifying mathematical symbols and extracting their descriptions, is an important task in document understanding. This paper makes the following contributions to the mathematical identifier description reading (MIDR) task:   (i) introduces the Math Formula Question Answering Dataset (MFQuAD) with $7508$ annotated identifier occurrences;   (ii) describes novel variations of the noun phrase ranking approach for the MIDR task;   (iii) reports experimental results for the SOTA noun phrase ranking approach and our novel variations of the approach, providing problem insights and a performance baseline;   (iv) provides a position on the features that make an effective dataset for the MIDR task.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08352v1","tag":"medical-cv"}}
{"title":"Symmetry group at future null infinity II : vector theory","abstract":"In this paper, we reduce the electromagnetic theory to future null infinity and obtain a vector theory at the boundary. We compute the Poincar\\'e flux operators which could be extended. We quantize the vector theory, and impose normal order to the extended flux operators. It is shown that the flux operators generate the supertranslation and superrotation. When work out the commutators of these operators, we find that a generalized electromagnetic duality operator should be included as the generators to form a closed symmetry algebra. We also work out the antipodal matching condition with two different methods.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08347v1","tag":"medical-cv"}}
{"title":"VALOR: Vision-Audio-Language Omni-Perception Pretraining Model and Dataset","abstract":"In this paper, we propose a Vision-Audio-Language Omni-peRception pretraining model (VALOR) for multi-modal understanding and generation. Different from widely-studied vision-language pretraining models, VALOR jointly models relationships of vision, audio and language in an end-to-end manner. It contains three separate encoders for single modality representations, and a decoder for multimodal conditional text generation. We design two pretext tasks to pretrain VALOR model, including Multimodal Grouping Alignment (MGA) and Multimodal Grouping Captioning (MGC). MGA projects vision, language and audio to the same common space, building vision-language, audio-language and audiovisual-language alignment simultaneously. MGC learns how to generate text tokens in conditions of vision, audio or their both. To promote vision-audio-language pretraining research, we construct a large-scale high-quality tri-modality dataset named VALOR-1M, which contains 1M audiable videos with human annotated audiovisual captions. Extensive experiments show that VALOR can learn strong multimodal correlations and be generalized to various downstream tasks (e.g., retrieval, captioning and question answering), with different input modalities (e.g., vision-language, audio-language and audiovisual-language). VALOR achieves new state-of-the-art performances on series of public cross-modality benchmarks. Code and data are available at project page https://casia-iva-group.github.io/projects/VALOR.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08345v1","tag":"medical-cv"}}
{"title":"NF-ULA: Langevin Monte Carlo with Normalizing Flow Prior for Imaging Inverse Problems","abstract":"Bayesian methods for solving inverse problems are a powerful alternative to classical methods since the Bayesian approach gives a probabilistic description of the problems and offers the ability to quantify the uncertainty in the solution. Meanwhile, solving inverse problems by data-driven techniques also proves to be successful, due to the increasing representation ability of data-based models. In this work, we try to incorporate the data-based models into a class of Langevin-based sampling algorithms in Bayesian inference. Loosely speaking, we introduce NF-ULA (Unadjusted Langevin algorithms by Normalizing Flows), which involves learning a normalizing flow as the prior. In particular, our algorithm only requires a pre-trained normalizing flow, which is independent of the considered inverse problem and the forward operator. We perform theoretical analysis by investigating the well-posedness of the Bayesian solution and the non-asymptotic convergence of the NF-ULA algorithm. The efficacy of the proposed NF-ULA algorithm is demonstrated in various imaging problems, including image deblurring, image inpainting, and limited-angle X-ray computed tomography (CT) reconstruction.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08342v1","tag":"medical-cv"}}
{"title":"Use of social media and Natural Language Processing (NLP) in natural hazard research","abstract":"Twitter is a microblogging service for sending short, public text messages (tweets) that has recently received more attention in scientific comunity. In the works of Sasaki et al. (2010) and Earle et al., (2011) the authors explored the real-time interaction on Twitter for detecting natural hazards (e.g., earthquakes, typhoons) baed on users' tweets. An inherent challenge for such an application is the natural language processing (NLP), which basically consists in converting the words in number (vectors and tensors) in order to (mathematically/ computationally) make predictions and classifications. Recently advanced computational tools have been made available for dealing with text computationally. In this report we implement a NLP machine learning with TensorFlow, an end-to-end open source plataform for machine learning applications, to process and classify evenct based on files containing only text.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08341v1","tag":"medical-cv"}}
{"title":"Magnitude of arithmetic scalar and matrix categories","abstract":"We develop tools for explicitly constructing categories enriched over generating data and that compose via ordinary scalar and matrix arithmetic arithmetic operations. We characterize meaningful size maps, weightings, and magnitude that reveal features analogous to outliers that these same notions have previously been shown to reveal in the context of metric spaces. Throughout, we provide examples of such \"outlier detection\" relevant to the analysis of computer programs, neural networks, cyber-physical systems, and networks of communications channels.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08334v1","tag":"medical-cv"}}
{"title":"Scenario Approach for Parametric Markov Models","abstract":"In this paper, we propose an approximating framework for analyzing parametric Markov models. Instead of computing complex rational functions encoding the reachability probability and the reward values of the parametric model, we exploit the scenario approach to synthesize a relatively simple polynomial approximation. The approximation is probably approximately correct (PAC), meaning that with high confidence, the approximating function is close to the actual function with an allowable error. With the PAC approximations, one can check properties of the parametric Markov models. We show that the scenario approach can also be used to check PRCTL properties directly, without synthesizing the polynomial at first hand. We have implemented our algorithm in a prototype tool and conducted thorough experiments. The experimental results demonstrate that our tool is able to compute polynomials for more benchmarks than state of the art tools such as PRISM and Storm, confirming the efficacy of our PAC-based synthesis.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08330v2","tag":"medical-cv"}}
{"title":"Computing the Weil representation of a superelliptic curve","abstract":"We study the Weil representation $\\rho$ of a curve over a $p$-adic field with potential reduction of compact type. We show that $\\rho$ can be reconstructed from its stable reduction. For superelliptic curves of the form $y^n=f(x)$ at primes $p$ whose residue characteristic is prime to the exponent $n$ we make this explicit.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08329v1","tag":"medical-cv"}}
{"title":"LED: A Dataset for Life Event Extraction from Dialogs","abstract":"Lifelogging has gained more attention due to its wide applications, such as personalized recommendations or memory assistance. The issues of collecting and extracting personal life events have emerged. People often share their life experiences with others through conversations. However, extracting life events from conversations is rarely explored. In this paper, we present Life Event Dialog, a dataset containing fine-grained life event annotations on conversational data. In addition, we initiate a novel conversational life event extraction task and differentiate the task from the public event extraction or the life event extraction from other sources like microblogs. We explore three information extraction (IE) frameworks to address the conversational life event extraction task: OpenIE, relation extraction, and event extraction. A comprehensive empirical analysis of the three baselines is established. The results suggest that the current event extraction model still struggles with extracting life events from human daily conversations. Our proposed life event dialog dataset and in-depth analysis of IE frameworks will facilitate future research on life event extraction from conversations.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08327v1","tag":"medical-cv"}}
{"title":"Density Elicitation with applications in Probabilistic Loops","abstract":"Probabilistic loops can be employed to implement and to model different processes ranging from software to cyber-physical systems. One main challenge is how to automatically estimate the distribution of the underlying continuous random variables symbolically and without sampling. We develop an approach, which we call K-series estimation, to approximate statically the joint and marginal distributions of a vector of random variables updated in a probabilistic non-nested loop with polynomial and non-polynomial assignments. Our approach is a general estimation method for an unknown probability density function with bounded support. It naturally complements algorithms for automatic derivation of moments in probabilistic loops such as~\\cite{BartocciKS19,Moosbruggeretal2022}. Its only requirement is a finite number of moments of the unknown density. We show that Gram-Charlier (GC) series, a widely used estimation method, is a special case of K-series when the normal probability density function is used as reference distribution. We provide also a formulation suitable for estimating both univariate and multivariate distributions. We demonstrate the feasibility of our approach using multiple examples from the literature.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.09094v1","tag":"medical-cv"}}
{"title":"Goal-oriented Uncertainty Quantification for Inverse Problems via Variational Encoder-Decoder Networks","abstract":"In this work, we describe a new approach that uses variational encoder-decoder (VED) networks for efficient goal-oriented uncertainty quantification for inverse problems. Contrary to standard inverse problems, these approaches are \\emph{goal-oriented} in that the goal is to estimate some quantities of interest (QoI) that are functions of the solution of an inverse problem, rather than the solution itself. Moreover, we are interested in computing uncertainty metrics associated with the QoI, thus utilizing a Bayesian approach for inverse problems that incorporates the prediction operator and techniques for exploring the posterior. This may be particularly challenging, especially for nonlinear, possibly unknown, operators and nonstandard prior assumptions. We harness recent advances in machine learning, i.e., VED networks, to describe a data-driven approach to large-scale inverse problems. This enables a real-time goal-oriented uncertainty quantification for the QoI. One of the advantages of our approach is that we avoid the need to solve challenging inversion problems by training a network to approximate the mapping from observations to QoI. Another main benefit is that we enable uncertainty quantification for the QoI by leveraging probability distributions in the latent space. This allows us to efficiently generate QoI samples and circumvent complicated or even unknown forward models and prediction operators. Numerical results from medical tomography reconstruction and nonlinear hydraulic tomography demonstrate the potential and broad applicability of the approach.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08324v1","tag":"medical-cv"}}
{"title":"Decentralized Learning Made Easy with DecentralizePy","abstract":"Decentralized learning (DL) has gained prominence for its potential benefits in terms of scalability, privacy, and fault tolerance. It consists of many nodes that coordinate without a central server and exchange millions of parameters in the inherently iterative process of machine learning (ML) training. In addition, these nodes are connected in complex and potentially dynamic topologies. Assessing the intricate dynamics of such networks is clearly not an easy task. Often in literature, researchers resort to simulated environments that do not scale and fail to capture practical and crucial behaviors, including the ones associated to parallelism, data transfer, network delays, and wall-clock time. In this paper, we propose DecentralizePy, a distributed framework for decentralized ML, which allows for the emulation of large-scale learning networks in arbitrary topologies. We demonstrate the capabilities of DecentralizePy by deploying techniques such as sparsification and secure aggregation on top of several topologies, including dynamic networks with more than one thousand nodes.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08322v1","tag":"medical-cv"}}
{"title":"Computational Performance Aware Benchmarking of Unsupervised Concept Drift Detection","abstract":"For many AI systems, concept drift detection is crucial to ensure the systems reliability. These systems often have to deal with large amounts of data or react in real time. Thus, drift detectors must meet computational requirements or constraints with a comprehensive performance evaluation. However, so far, the focus of developing drift detectors is on detection quality, e.g.~accuracy, but not on computational performance, such as running time. We show that the previous works consider computational performance only as a secondary objective and do not have a benchmark for such evaluation. Hence, we propose a novel benchmark suite for drift detectors that accounts both detection quality and computational performance to ensure a detector's applicability in various AI systems. In this work, we focus on unsupervised drift detectors that are not restricted to the availability of labeled data and thus being widely applicable. Our benchmark suite supports configurable synthetic and real world data streams. Moreover, it provides means for simulating a machine learning model's output to unify the performance evaluation across different drift detectors. This allows a fair and comprehensive comparison of drift detectors proposed in related work. Our benchmark suite is integrated in the existing framework, Massive Online Analysis (MOA). To evaluate our benchmark suite's capability, we integrate two representative unsupervised drift detectors. Our work enables the scientific community to achieve a baseline for unsupervised drift detectors with respect to both detection quality and computational performance.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08319v1","tag":"medical-cv"}}
{"title":"Thorny Roses: Investigating the Dual Use Dilemma in Natural Language Processing","abstract":"Dual use, the intentional, harmful reuse of technology and scientific artefacts, is a problem yet to be well-defined within the context of Natural Language Processing (NLP). However, as NLP technologies continue to advance and become increasingly widespread in society, their inner workings have become increasingly opaque. Therefore, understanding dual use concerns and potential ways of limiting them is critical to minimising the potential harms of research and development. In this paper, we conduct a survey of NLP researchers and practitioners to understand the depth and their perspective of the problem as well as to assess existing available support. Based on the results of our survey, we offer a definition of dual use that is tailored to the needs of the NLP community. The survey revealed that a majority of researchers are concerned about the potential dual use of their research but only take limited action toward it. In light of the survey results, we discuss the current state and potential means for mitigating dual use in NLP and propose a checklist that can be integrated into existing conference ethics-frameworks, e.g., the ACL ethics checklist.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08315v1","tag":"medical-cv"}}
{"title":"The Hilbert Polynomial of Quandles and Colorings of Random Links","abstract":"Given a finite quandle $Q$, we study the average number of $Q$-colorings of the closure of a random braid in $B_n$ as $n$ varies. In particular we show that this number coincides with some polynomial $P_Q\\in \\mathbb{Q}[x]$ for $n\\gg 0$. The degree of this polynomial is readily computed in terms of $Q$ as a quandle and these invariants are computed for all quandles with $|Q|\\le 4$. Additionally we show that the methods in this paper allow to improve on the stability results of arXiv:0912.0325 from \"periodic stability\" to \"stability\".","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08314v1","tag":"medical-cv"}}
{"title":"POD-ROMs for incompressible flows including snapshots of the temporal derivative of the full order solution: Error bounds for the pressure","abstract":"Reduced order methods (ROMs) for the incompressible Navier--Stokes equations, based on proper orthogonal decomposition (POD), are studied that include snapshots which approach the temporal derivative of the velocity from a full order mixed finite element method (FOM). In addition, the set of snapshots contains the mean velocity of the FOM. Both the FOM and the POD-ROM are equipped with a grad-div stabilization. A velocity error analysis for this method can be found already in the literature. The present paper studies two different procedures to compute approximations to the pressure and proves error bounds for the pressure that are independent of inverse powers of the viscosity. Numerical studies support the analytic results and compare both methods.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08313v1","tag":"medical-cv"}}
{"title":"TreeC: a method to generate interpretable energy management systems using a metaheuristic algorithm","abstract":"Energy management systems (EMS) have classically been implemented based on rule-based control (RBC) and model predictive control (MPC) methods. Recent research are investigating reinforcement learning (RL) as a new promising approach. This paper introduces TreeC, a machine learning method that uses the metaheuristic algorithm covariance matrix adaptation evolution strategy (CMA-ES) to generate an interpretable EMS modeled as a decision tree. This method learns the decision strategy of the EMS based on historical data contrary to RBC and MPC approaches that are typically considered as non adaptive solutions. The decision strategy of the EMS is modeled as a decision tree and is thus interpretable contrary to RL which mainly uses black-box models (e.g. neural networks). The TreeC method is compared to RBC, MPC and RL strategies in two study cases taken from literature: (1) an electric grid case and (2) a household heating case. The results show that TreeC obtains close performances than MPC with perfect forecast in both cases and obtains similar performances to RL in the electrical grid case and outperforms RL in the household heating case. TreeC demonstrates a performant application of machine learning for energy management systems that is also fully interpretable.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08310v1","tag":"medical-cv"}}
{"title":"Search-Space Pruning with Int-Splits for Faster QBF Solving","abstract":"In many QBF encodings, sequences of Boolean variables stand for binary representations of integer variables. Examples are state labels in bounded model checking or actions in planning problems. Often not the full possible range is used, e.g., for representing six different states, three Boolean variables are required, rendering two of the eight possible assignments irrelevant for the solution of the problem. As QBF solvers do not have any domain-specific knowledge on the formula they process, they are not able to detect this pruning opportunity.   In this paper, we introduce the idea of int-splits, which provide domain-specific information on integer variables to QBF solvers. This is particularly appealing for parallel Divide-and-Conquer solving which partitions the search space into independently solvable sub-problems. Using this technique, we reduce the number of generated sub-problems from a full expansion to only the required subset. We then evaluate how many resources int-splits save in problems already well suited for D&C. In that context, we provide a reference implementation that splits QBF formulas into many sub-problems with or without int-splits and merges results. We finally propose a comment-based optional syntax extension to (Q)DIMACS that includes int-splits and is suited for supplying proposed guiding paths natively to D&C solvers.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08308v1","tag":"medical-cv"}}
{"title":"Predicting dynamic, motion-related changes in B0 field in the brain at a 7 T MRI using a subject-specific fine-tuned U-net","abstract":"Subject movement during the magnetic resonance examination is inevitable and causes not only image artefacts but also deteriorates the homogeneity of the main magnetic field (B0), which is a prerequisite for high quality data. Thus, characterization of changes to B0, e.g. induced by patient movement, is important for MR applications that are prone to B0 inhomogeneities. We propose a deep learning based method to predict such changes within the brain from the change of the head position to facilitate retrospective or even real-time correction. A 3D U-net was trained on in vivo brain 7T MRI data. The input consisted of B0 maps and anatomical images at an initial position, and anatomical images at a different head position (obtained by applying a rigid-body transformation on the initial anatomical image). The output consisted of B0 maps at the new head positions. We further fine-tuned the network weights to each subject by measuring a limited number of head positions of the given subject, and trained the U-net with these data. Our approach was compared to established dynamic B0 field mapping via interleaved navigators, which suffer from limited spatial resolution and the need for undesirable sequence modifications. Qualitative and quantitative comparison showed similar performance between an interleaved navigator-equivalent method and proposed method. We therefore conclude that it is feasible to predict B0 maps from rigid subject movement and, when combined with external tracking hardware, this information could be used to improve the quality of magnetic resonance acquisitions without the use of navigators.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08307v1","tag":"medical-cv"}}
{"title":"SDVRF: Sparse-to-Dense Voxel Region Fusion for Multi-modal 3D Object Detection","abstract":"In the perception task of autonomous driving, multi-modal methods have become a trend due to the complementary characteristics of LiDAR point clouds and image data. However, the performance of previous methods is usually limited by the sparsity of the point cloud or the noise problem caused by the misalignment between LiDAR and the camera. To solve these two problems, we present a new concept, Voxel Region (VR), which is obtained by projecting the sparse local point clouds in each voxel dynamically. And we propose a novel fusion method, named Sparse-to-Dense Voxel Region Fusion (SDVRF). Specifically, more pixels of the image feature map inside the VR are gathered to supplement the voxel feature extracted from sparse points and achieve denser fusion. Meanwhile, different from prior methods, which project the size-fixed grids, our strategy of generating dynamic regions achieves better alignment and avoids introducing too much background noise. Furthermore, we propose a multi-scale fusion framework to extract more contextual information and capture the features of objects of different sizes. Experiments on the KITTI dataset show that our method improves the performance of different baselines, especially on classes of small size, including Pedestrian and Cyclist.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08304v1","tag":"medical-cv"}}
{"title":"Interactive and Explainable Region-guided Radiology Report Generation","abstract":"The automatic generation of radiology reports has the potential to assist radiologists in the time-consuming task of report writing. Existing methods generate the full report from image-level features, failing to explicitly focus on anatomical regions in the image. We propose a simple yet effective region-guided report generation model that detects anatomical regions and then describes individual, salient regions to form the final report. While previous methods generate reports without the possibility of human intervention and with limited explainability, our method opens up novel clinical use cases through additional interactive capabilities and introduces a high degree of transparency and explainability. Comprehensive experiments demonstrate our method's effectiveness in report generation, outperforming previous state-of-the-art models, and highlight its interactive capabilities. The code and checkpoints are available at https://github.com/ttanida/rgrg .","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08295v1","tag":"medical-cv"}}
{"title":"Refusion: Enabling Large-Size Realistic Image Restoration with Latent-Space Diffusion Models","abstract":"This work aims to improve the applicability of diffusion models in realistic image restoration. Specifically, we enhance the diffusion model in several aspects such as network architecture, noise level, denoising steps, training image size, and optimizer/scheduler. We show that tuning these hyperparameters allows us to achieve better performance on both distortion and perceptual scores. We also propose a U-Net based latent diffusion model which performs diffusion in a low-resolution latent space while preserving high-resolution information from the original input for the decoding process. Compared to the previous latent-diffusion model which trains a VAE-GAN to compress the image, our proposed U-Net compression strategy is significantly more stable and can recover highly accurate images without relying on adversarial optimization. Importantly, these modifications allow us to apply diffusion models to various image restoration tasks, including real-world shadow removal, HR non-homogeneous dehazing, stereo super-resolution, and bokeh effect transformation. By simply replacing the datasets and slightly changing the noise network, our model, named Refusion, is able to deal with large-size images (e.g., 6000 x 4000 x 3 in HR dehazing) and produces good results on all the above restoration problems. Our Refusion achieves the best perceptual performance in the NTIRE 2023 Image Shadow Removal Challenge and wins 2nd place overall.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08291v1","tag":"medical-cv"}}
{"title":"Solving stiff ordinary differential equations using physics informed neural networks (PINNs): simple recipes to improve training of vanilla-PINNs","abstract":"Physics informed neural networks (PINNs) are nowadays used as efficient machine learning methods for solving differential equations. However, vanilla-PINNs fail to learn complex problems as ones involving stiff ordinary differential equations (ODEs). This is the case of some initial value problems (IVPs) when the amount of training data is too small and/or the integration interval (for the variable like the time) is too large. We propose very simple recipes to improve the training process in cases where only prior knowledge at initial time of training data is known for IVPs. For example, more physics can be easily embedded in the loss function in problems for which the total energy is conserved. A better definition of the training data loss taking into account all the initial conditions can be done. In a progressive learning approach, it is also possible to use a growing time interval with a moving grid (of collocation points) where the differential equation residual is minimized. These improvements are also shown to be efficient in PINNs modeling for solving boundary value problems (BVPs) as for the high Reynolds steady-state solution of advection-diffusion equation.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08289v1","tag":"medical-cv"}}
{"title":"Detection and Classification of Glioblastoma Brain Tumor","abstract":"Glioblastoma brain tumors are highly malignant and often require early detection and accurate segmentation for effective treatment. We are proposing two deep learning models in this paper, namely UNet and Deeplabv3, for the detection and segmentation of glioblastoma brain tumors using preprocessed brain MRI images. The performance evaluation is done for these models in terms of accuracy and computational efficiency. Our experimental results demonstrate that both UNet and Deeplabv3 models achieve accurate detection and segmentation of glioblastoma brain tumors. However, Deeplabv3 outperforms UNet in terms of accuracy, albeit at the cost of requiring more computational resources. Our proposed models offer a promising approach for the early detection and segmentation of glioblastoma brain tumors, which can aid in effective treatment strategies. Further research can focus on optimizing the computational efficiency of the Deeplabv3 model while maintaining its high accuracy for real-world clinical applications. Overall, our approach works and contributes to the field of medical image analysis and deep learning-based approaches for brain tumor detection and segmentation. Our suggested models can have a major influence on the prognosis and treatment of people with glioblastoma, a fatal form of brain cancer. It is necessary to conduct more research to examine the practical use of these models in real-life healthcare settings.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09133v1","tag":"medical-cv"}}
{"title":"Implementation and evaluation of a dynamic contrast enhanced mr perfusion protocol for glioblastoma using a 0.35T mri-Linac system","abstract":"MRI-linear accelerator (MRI-Linac) systems allow for daily tracking of MRI changes during radiotherapy (RT). Since one common MRI-Linac operates at 0.35T, there are efforts towards developing protocols at that field strength. In this study we demonstrate the implementation of a post-contrast 3DT1-weighted (3DT1w) and dynamic contrast enhancement (DCE) protocol to assess glioblastoma response to RT using a 0.35T MRI-Linac. The protocol implemented was used to acquire 3DT1w and DCE data from a flow phantom and two patients with glioblastoma (a responder and a non-responder) who underwent RT on a 0.35T-MRI-Linac. The detection of post-contrast enhanced volumes was evaluated by comparing the 3DT1w images from the 0.35T-MRI-Linac to images obtained using a 3T-standalone scanner. The DCE data were tested temporally and spatially using data from the flow phantom and patients. K-trans maps were derived from DCE at three time points (a week before treatment: Pre RT, four weeks through treatment: Mid RT, and three weeks after treatment: Post RT) and were validated with patients treatment outcomes. The 3D-T1 contrast enhancement volumes were visually and volumetrically similar (+/- 0.6-3.6%) between 0.35T MRI-Linac and 3T. DCE images showed temporal stability, and associated K-trans maps were consistent with patient response to treatment. On average, K-trans values showed a 54% decrease and 8.6% increase for a responder and non-responder respectively when Pre RT and Mid RT images were compared. Our findings support the feasibility of obtaining post-contrast 3DT1w and DCE data from patients with glioblastoma using a 0.35T MRI-Linac system.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.09128v1","tag":"medical-cv"}}
{"title":"Fibroglandular Tissue Segmentation in Breast MRI using Vision Transformers -- A multi-institutional evaluation","abstract":"Accurate and automatic segmentation of fibroglandular tissue in breast MRI screening is essential for the quantification of breast density and background parenchymal enhancement. In this retrospective study, we developed and evaluated a transformer-based neural network for breast segmentation (TraBS) in multi-institutional MRI data, and compared its performance to the well established convolutional neural network nnUNet. TraBS and nnUNet were trained and tested on 200 internal and 40 external breast MRI examinations using manual segmentations generated by experienced human readers. Segmentation performance was assessed in terms of the Dice score and the average symmetric surface distance. The Dice score for nnUNet was lower than for TraBS on the internal testset (0.909$\\pm$0.069 versus 0.916$\\pm$0.067, P<0.001) and on the external testset (0.824$\\pm$0.144 versus 0.864$\\pm$0.081, P=0.004). Moreover, the average symmetric surface distance was higher (=worse) for nnUNet than for TraBS on the internal (0.657$\\pm$2.856 versus 0.548$\\pm$2.195, P=0.001) and on the external testset (0.727$\\pm$0.620 versus 0.584$\\pm$0.413, P=0.03). Our study demonstrates that transformer-based networks improve the quality of fibroglandular tissue segmentation in breast MRI compared to convolutional-based models like nnUNet. These findings might help to enhance the accuracy of breast density and parenchymal enhancement quantification in breast MRI screening.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08972v1","tag":"medical-cv"}}
{"title":"Segmentation of glioblastomas in early post-operative multi-modal MRI with deep neural networks","abstract":"Extent of resection after surgery is one of the main prognostic factors for patients diagnosed with glioblastoma. To achieve this, accurate segmentation and classification of residual tumor from post-operative MR images is essential. The current standard method for estimating it is subject to high inter- and intra-rater variability, and an automated method for segmentation of residual tumor in early post-operative MRI could lead to a more accurate estimation of extent of resection. In this study, two state-of-the-art neural network architectures for pre-operative segmentation were trained for the task. The models were extensively validated on a multicenter dataset with nearly 1000 patients, from 12 hospitals in Europe and the United States. The best performance achieved was a 61\\% Dice score, and the best classification performance was about 80\\% balanced accuracy, with a demonstrated ability to generalize across hospitals. In addition, the segmentation performance of the best models was on par with human expert raters. The predicted segmentations can be used to accurately classify the patients into those with residual tumor, and those with gross total resection.","created":"2023-04-18","meta":{"link":"http://arxiv.org/abs/2304.08881v1","tag":"medical-cv"}}
{"title":"Predicting dynamic, motion-related changes in B0 field in the brain at a 7 T MRI using a subject-specific fine-tuned U-net","abstract":"Subject movement during the magnetic resonance examination is inevitable and causes not only image artefacts but also deteriorates the homogeneity of the main magnetic field (B0), which is a prerequisite for high quality data. Thus, characterization of changes to B0, e.g. induced by patient movement, is important for MR applications that are prone to B0 inhomogeneities. We propose a deep learning based method to predict such changes within the brain from the change of the head position to facilitate retrospective or even real-time correction. A 3D U-net was trained on in vivo brain 7T MRI data. The input consisted of B0 maps and anatomical images at an initial position, and anatomical images at a different head position (obtained by applying a rigid-body transformation on the initial anatomical image). The output consisted of B0 maps at the new head positions. We further fine-tuned the network weights to each subject by measuring a limited number of head positions of the given subject, and trained the U-net with these data. Our approach was compared to established dynamic B0 field mapping via interleaved navigators, which suffer from limited spatial resolution and the need for undesirable sequence modifications. Qualitative and quantitative comparison showed similar performance between an interleaved navigator-equivalent method and proposed method. We therefore conclude that it is feasible to predict B0 maps from rigid subject movement and, when combined with external tracking hardware, this information could be used to improve the quality of magnetic resonance acquisitions without the use of navigators.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08307v1","tag":"medical-cv"}}
{"title":"Two-stage MR Image Segmentation Method for Brain Tumors based on Attention Mechanism","abstract":"Multimodal magnetic resonance imaging (MRI) can reveal different patterns of human tissue and is crucial for clinical diagnosis. However, limited by cost, noise and manual labeling, obtaining diverse and reliable multimodal MR images remains a challenge. For the same lesion, different MRI manifestations have great differences in background information, coarse positioning and fine structure. In order to obtain better generation and segmentation performance, a coordination-spatial attention generation adversarial network (CASP-GAN) based on the cycle-consistent generative adversarial network (CycleGAN) is proposed. The performance of the generator is optimized by introducing the Coordinate Attention (CA) module and the Spatial Attention (SA) module. The two modules can make full use of the captured location information, accurately locating the interested region, and enhancing the generator model network structure. The ability to extract the structure information and the detailed information of the original medical image can help generate the desired image with higher quality. There exist some problems in the original CycleGAN that the training time is long, the parameter amount is too large, and it is difficult to converge. In response to this problem, we introduce the Coordinate Attention (CA) module to replace the Res Block to reduce the number of parameters, and cooperate with the spatial information extraction network above to strengthen the information extraction ability. On the basis of CASP-GAN, an attentional generative cross-modality segmentation (AGCMS) method is further proposed. This method inputs the modalities generated by CASP-GAN and the real modalities into the segmentation network for brain tumor segmentation. Experimental results show that CASP-GAN outperforms CycleGAN and some state-of-the-art methods in PSNR, SSMI and RMSE in most tasks.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08072v1","tag":"medical-cv"}}
{"title":"One-Class SVM on siamese neural network latent space for Unsupervised Anomaly Detection on brain MRI White Matter Hyperintensities","abstract":"Anomaly detection remains a challenging task in neuroimaging when little to no supervision is available and when lesions can be very small or with subtle contrast. Patch-based representation learning has shown powerful representation capacities when applied to industrial or medical imaging and outlier detection methods have been applied successfully to these images. In this work, we propose an unsupervised anomaly detection (UAD) method based on a latent space constructed by a siamese patch-based auto-encoder and perform the outlier detection with a One-Class SVM training paradigm tailored to the lesion detection task in multi-modality neuroimaging. We evaluate performances of this model on a public database, the White Matter Hyperintensities (WMH) challenge and show in par performance with the two best performing state-of-the-art methods reported so far.","created":"2023-04-17","meta":{"link":"http://arxiv.org/abs/2304.08058v1","tag":"medical-cv"}}
{"title":"Brain Tumor classification and Segmentation using Deep Learning","abstract":"Brain tumors are a complex and potentially life-threatening medical condition that requires accurate diagnosis and timely treatment. In this paper, we present a machine learning-based system designed to assist healthcare professionals in the classification and diagnosis of brain tumors using MRI images. Our system provides a secure login, where doctors can upload or take a photo of MRI and our app can classify the model and segment the tumor, providing the doctor with a folder of each patient's history, name, and results. Our system can also add results or MRI to this folder, draw on the MRI to send it to another doctor, and save important results in a saved page in the app. Furthermore, our system can classify in less than 1 second and allow doctors to chat with a community of brain tumor doctors.   To achieve these objectives, our system uses a state-of-the-art machine learning algorithm that has been trained on a large dataset of MRI images. The algorithm can accurately classify different types of brain tumors and provide doctors with detailed information on the size, location, and severity of the tumor. Additionally, our system has several features to ensure its security and privacy, including secure login and data encryption.   We evaluated our system using a dataset of real-world MRI images and compared its performance to other existing systems. Our results demonstrate that our system is highly accurate, efficient, and easy to use. We believe that our system has the potential to revolutionize the field of brain tumor diagnosis and treatment and provide healthcare professionals with a powerful tool for improving patient outcomes.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07901v1","tag":"medical-cv"}}
{"title":"The Segment Anything foundation model achieves favorable brain tumor autosegmentation accuracy on MRI to support radiotherapy treatment planning","abstract":"Background: Tumor segmentation in MRI is crucial in radiotherapy (RT) treatment planning for brain tumor patients. Segment anything (SA), a novel promptable foundation model for autosegmentation, has shown high accuracy for multiple segmentation tasks but was not evaluated on medical datasets yet. Methods: SA was evaluated in a point-to-mask task for glioma brain tumor autosegmentation on 16744 transversal slices from 369 MRI datasets (BraTS 2020). Up to 9 point prompts were placed per slice. Tumor core (enhancing tumor + necrotic core) was segmented on contrast-enhanced T1w sequences. Out of the 3 masks predicted by SA, accuracy was evaluated for the mask with the highest calculated IoU (oracle mask) and with highest model predicted IoU (suggested mask). In addition to assessing SA on whole MRI slices, SA was also evaluated on images cropped to the tumor (max. 3D extent + 2 cm). Results: Mean best IoU (mbIoU) using oracle mask on full MRI slices was 0.762 (IQR 0.713-0.917). Best 2D mask was achieved after a mean of 6.6 point prompts (IQR 5-9). Segmentation accuracy was significantly better for high- compared to low-grade glioma cases (mbIoU 0.789 vs. 0.668). Accuracy was worse using MRI slices cropped to the tumor (mbIoU 0.759) and was much worse using suggested mask (full slices 0.572). For all experiments, accuracy was low on peripheral slices with few tumor voxels (mbIoU, <300: 0.537 vs. >=300: 0.841). Stacking best oracle segmentations from full axial MRI slices, mean 3D DSC for tumor core was 0.872, which was improved to 0.919 by combining axial, sagittal and coronal masks. Conclusions: The Segment Anything foundation model, while trained on photos, can achieve high zero-shot accuracy for glioma brain tumor segmentation on MRI slices. The results suggest that Segment Anything can accelerate and facilitate RT treatment planning, when properly integrated in a clinical application.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07875v1","tag":"medical-cv"}}
{"title":"Arbitrary Reduction of MRI Inter-slice Spacing Using Hierarchical Feature Conditional Diffusion","abstract":"Magnetic resonance (MR) images collected in 2D scanning protocols typically have large inter-slice spacing, resulting in high in-plane resolution but reduced through-plane resolution. Super-resolution techniques can reduce the inter-slice spacing of 2D scanned MR images, facilitating the downstream visual experience and computer-aided diagnosis. However, most existing super-resolution methods are trained at a fixed scaling ratio, which is inconvenient in clinical settings where MR scanning may have varying inter-slice spacings. To solve this issue, we propose Hierarchical Feature Conditional Diffusion (HiFi-Diff)} for arbitrary reduction of MR inter-slice spacing. Given two adjacent MR slices and the relative positional offset, HiFi-Diff can iteratively convert a Gaussian noise map into any desired in-between MR slice. Furthermore, to enable fine-grained conditioning, the Hierarchical Feature Extraction (HiFE) module is proposed to hierarchically extract conditional features and conduct element-wise modulation. Our experimental results on the publicly available HCP-1200 dataset demonstrate the high-fidelity super-resolution capability of HiFi-Diff and its efficacy in enhancing downstream segmentation performance.","created":"2023-04-16","meta":{"link":"http://arxiv.org/abs/2304.07756v2","tag":"medical-cv"}}
{"title":"Effect of magnetic fields on the dynamics and gravitational wave emission of PPI-saturated self-gravitating accretion disks: simulations in full GR","abstract":"We explore the effect magnetic fields have on self-gravitating accretion disks around spinning black holes via numerical evolutions in full dynamical magnetohydrodynamic spacetimes. The configurations we study are unstable to the Papaloizou-Pringle Instability (PPI). PPI-saturated accretion tori have been shown to produce gravitational waves, detectable to cosmological distances by third-generation gravitational wave (GW) observatories. While the PPI operates strongly for purely hydrodynamic disks, the situation can be different for disks hosting initially small magnetic fields. Evolutions of disks without self-gravity in fixed BH spacetimes have shown that small seed fields can initiate the rapid growth of the magneto-rotational instability (MRI), which then strongly suppresses the PPI. Since realistic astrophysical disks are expected to be magnetized, PPI-generated GW signals may be suppressed as well. However, it is unclear what happens when the disk self-gravity is restored. Here, we study the impact of magnetic fields on the PPI-saturated state of a self-gravitating accretion disk around a spinning BH ($\\chi = 0.7$) aligned with the disk angular momentum, as well as one around a non-spinning BH. We find the MRI is effective at reducing the amplitude of PPI modes and their associated GWs, but the systems still generate GWs. Estimating the detectability of these systems accross a wide range of masses, we show that magnetic fields reduce the maximum detection distance by Cosmic Explorer from 300Mpc (in the pure hydrodynamic case) to 45Mpc for a $10 M_{\\odot}$ system, by LISA from 11500Mpc to 2700Mpc for a $2 \\times 10^{5} M_{\\odot}$ system, and by DECIGO from $z \\approx 5$ down to $z \\approx 2$ for a $1000 M_{\\odot}$ system.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07282v1","tag":"medical-cv"}}
{"title":"Repeatability of image quality in very low field MRI","abstract":"We investigated the repeatability of image quality metrics such as SNR, image uniformity, and geometrical distortion at 0.05T over ten days and three sessions per day. The measurements included temperature, humidity, transmit frequency, off-resonance maps, and 3D turbo spin echo (TSE) images of an in vitro phantom. This resulted in a protocol with nine pulse sequences. We also acquired a 3T data set for reference. The image quality metrics included computing SNR, image non-uniformity, and eccentricity (to assess geometrical distortion) to investigate the repeatability of 0.05T image quality. The image reconstruction included drift correction, k-space filtering, and off-resonance correction. We computed the coefficient of variation (CV) of the experimental parameters and the resulting image quality metrics to assess repeatability. The range of temperature measured during the study was within 1.50C. The off-resonance maps acquired before and after the 3D TSE showed similar hotspots and changed mainly by a global constant. The SNR measurements were highly repeatable across sessions and over the ten days, quantified by a CV of 4.9%. The magnetic field inhomogeneity effects quantified by eccentricity showed a CV of 13.7% but less than 5.1% in two of the three sessions over ten days. The use of conjugate phase reconstruction mitigated geometrical distortion artifacts. The repeatability of image uniformity was moderate at 10.6%, with two of three sessions resulting in a CV of less than 7.8%. Temperature and humidity did not significantly affect SNR and mean frequency drift within the ranges of these environmental factors investigated. We found that humidity and temperature in the range investigated did not impact SNR and frequency. Our findings indicate high repeatability for SNR and magnetic field homogeneity; and moderate repeatability for image uniformity.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07267v1","tag":"medical-cv"}}
{"title":"The University of California San Francisco, Brain Metastases Stereotactic Radiosurgery (UCSF-BMSR) MRI Dataset","abstract":"The University of California San Francisco Brain Metastases Stereotactic Radiosurgery (UCSF-BMSR) dataset is a public, clinical, multimodal brain MRI dataset consisting of 560 brain MRIs from 412 patients with expert annotations of 5136 brain metastases. Data consists of registered and skull stripped T1 post-contrast, T1 pre-contrast, FLAIR and subtraction (T1 pre-contrast - T1 post-contrast) images and voxelwise segmentations of enhancing brain metastases in NifTI format. The dataset also includes patient demographics, surgical status and primary cancer types. The UCSF-BSMR has been made publicly available in the hopes that researchers will use these data to push the boundaries of AI applications for brain metastases.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07248v1","tag":"medical-cv"}}
{"title":"Robust thalamic nuclei segmentation from T1-weighted MRI","abstract":"Accurate segmentation of thalamic nuclei, crucial for understanding their role in healthy cognition and in pathologies, is challenging to achieve on standard T1-weighted (T1w) magnetic resonance imaging (MRI) due to poor image contrast. White-matter-nulled (WMn) MRI sequences improve intrathalamic contrast but are not part of clinical protocols or extant databases. Here, we introduce Histogram-based polynomial synthesis (HIPS), a fast preprocessing step that synthesizes WMn-like image contrast from standard T1w MRI using a polynomial approximation. HIPS was incorporated into our Thalamus Optimized Multi-Atlas Segmentation (THOMAS) pipeline, developed and optimized for WMn MRI. HIPS-THOMAS was compared to a convolutional neural network (CNN)-based segmentation method and THOMAS modified for T1w images (T1w-THOMAS). The robustness and accuracy of the three methods were tested across different image contrasts, scanner manufacturers, and field strength. HIPS-synthesized images improved intra-thalamic contrast and thalamic boundaries, and their segmentations yielded significantly better mean Dice, lower percentage of volume error, and lower standard deviations compared to both the CNN method and T1w-THOMAS. Finally, using THOMAS, HIPS-synthesized images were as effective as WMn images for identifying thalamic nuclei atrophy in alcohol use disorders subjects relative to healthy controls, with a higher area under the ROC curve compared to T1w-THOMAS (0.79 vs 0.73).","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07167v1","tag":"medical-cv"}}
{"title":"Weighted Siamese Network to Predict the Time to Onset of Alzheimer's Disease from MRI Images","abstract":"Alzheimer's Disease (AD), which is the most common cause of dementia, is a progressive disease preceded by Mild Cognitive Impairment (MCI). Early detection of the disease is crucial for making treatment decisions. However, most of the literature on computer-assisted detection of AD focuses on classifying brain images into one of three major categories: healthy, MCI, and AD; or categorising MCI patients into one of (1) progressive: those who progress from MCI to AD at a future examination time during a given study period, and (2) stable: those who stay as MCI and never progress to AD. This misses the opportunity to accurately identify the trajectory of progressive MCI patients. In this paper, we revisit the brain image classification task for AD identification and re-frame it as an ordinal classification task to predict how close a patient is to the severe AD stage. To this end, we select progressive MCI patients from the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset and construct an ordinal dataset with a prediction target that indicates the time to progression to AD. We train a siamese network model to predict the time to onset of AD based on MRI brain images. We also propose a weighted variety of siamese networks and compare its performance to a baseline model. Our evaluations show that incorporating a weighting factor to siamese networks brings considerable performance gain at predicting how close input brain MRI images are to progressing to AD.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.07097v1","tag":"medical-cv"}}
{"title":"Uncertainty-Aware Null Space Networks for Data-Consistent Image Reconstruction","abstract":"Reconstructing an image from noisy and incomplete measurements is a central task in several image processing applications. In recent years, state-of-the-art reconstruction methods have been developed based on recent advances in deep learning. Especially for highly underdetermined problems, maintaining data consistency is a key goal. This can be achieved either by iterative network architectures or by a subsequent projection of the network reconstruction. However, for such approaches to be used in safety-critical domains such as medical imaging, the network reconstruction should not only provide the user with a reconstructed image, but also with some level of confidence in the reconstruction. In order to meet these two key requirements, this paper combines deep null-space networks with uncertainty quantification. Evaluation of the proposed method includes image reconstruction from undersampled Radon measurements on a toy CT dataset and accelerated MRI reconstruction on the fastMRI dataset. This work is the first approach to solving inverse problems that additionally models data-dependent uncertainty by estimating an input-dependent scale map, providing a robust assessment of reconstruction quality.","created":"2023-04-14","meta":{"link":"http://arxiv.org/abs/2304.06955v1","tag":"medical-cv"}}
{"title":"Generalizable Deep Learning Method for Suppressing Unseen and Multiple MRI Artifacts Using Meta-learning","abstract":"Magnetic Resonance (MR) images suffer from various types of artifacts due to motion, spatial resolution, and under-sampling. Conventional deep learning methods deal with removing a specific type of artifact, leading to separately trained models for each artifact type that lack the shared knowledge generalizable across artifacts. Moreover, training a model for each type and amount of artifact is a tedious process that consumes more training time and storage of models. On the other hand, the shared knowledge learned by jointly training the model on multiple artifacts might be inadequate to generalize under deviations in the types and amounts of artifacts. Model-agnostic meta-learning (MAML), a nested bi-level optimization framework is a promising technique to learn common knowledge across artifacts in the outer level of optimization, and artifact-specific restoration in the inner level. We propose curriculum-MAML (CMAML), a learning process that integrates MAML with curriculum learning to impart the knowledge of variable artifact complexity to adaptively learn restoration of multiple artifacts during training. Comparative studies against Stochastic Gradient Descent and MAML, using two cardiac datasets reveal that CMAML exhibits (i) better generalization with improved PSNR for 83% of unseen types and amounts of artifacts and improved SSIM in all cases, and (ii) better artifact suppression in 4 out of 5 cases of composite artifacts (scans with multiple artifacts).","created":"2023-04-13","meta":{"link":"http://arxiv.org/abs/2304.06378v1","tag":"medical-cv"}}
{"title":"Potential Major Improvement in Superconductors for High-Field Magnets","abstract":"Fusion reactors are limited by the magnetic field available to confine their plasma. The commercial fusion industry uses the larger magnetic field and higher operating temperature of the cuprate superconductor $\\mathbf{YBa_{2}Cu_{3}O_{7-\\delta}}$ (YBCO) in order to confine their plasma into a dense volume. A superconductor is a macroscopic quantum state that is protected from the metallic (resistive) state by an energy gap. Unfortunately, YBCO has an anisotropic gap, known as D-wave because it has the shape of a $\\mathbf{d_{x^2-y^2}}$ chemical orbital. This D-wave gap means that poly-crystalline wire cannot be made because a few degree misalignment between grains in the wire leads to a drastic loss in its supercurrent carrying ability, and thereby its magnetic field limit. The superconductor industry has responded by growing nearly-single-crystal superconducting YBCO films on carefully prepared substrate tapes kilometers in length. Heroic development programs have made such tapes commercially available, but they are very expensive and delicate. MRI magnet superconductors, such as $\\mathbf{NbTi}$ and $\\mathbf{Nb_{3}Sn}$, are formed into poly-crystalline wires because they have an isotropic gap in the shape of an s chemical orbital (called S-wave) that makes them insensitive to grain misalignment. However, these materials are limited to lower magnetic fields and liquid-He temperatures. Here, we modified YBCO by doping the Y site with Ca and Ce atoms to form $\\mathbf{(Y_{1-x-y}Ca_{x}Ce_{y})Ba_{2}Cu_{3}O_{7-\\delta}}$, and show evidence that it changes to an S-wave gap. Its superconducting transition temperature, $\\mathbf{T_c}$, of $\\mathbf{\\sim 70K}$, while lower than that of D-wave YBCO at $\\mathbf{\\sim 90K}$, is easily maintained using common, economic cryogenic equipment.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.06171v1","tag":"medical-cv"}}
{"title":"$E(3) \\times SO(3)$-Equivariant Networks for Spherical Deconvolution in Diffusion MRI","abstract":"We present Roto-Translation Equivariant Spherical Deconvolution (RT-ESD), an $E(3)\\times SO(3)$ equivariant framework for sparse deconvolution of volumes where each voxel contains a spherical signal. Such 6D data naturally arises in diffusion MRI (dMRI), a medical imaging modality widely used to measure microstructure and structural connectivity. As each dMRI voxel is typically a mixture of various overlapping structures, there is a need for blind deconvolution to recover crossing anatomical structures such as white matter tracts. Existing dMRI work takes either an iterative or deep learning approach to sparse spherical deconvolution, yet it typically does not account for relationships between neighboring measurements. This work constructs equivariant deep learning layers which respect to symmetries of spatial rotations, reflections, and translations, alongside the symmetries of voxelwise spherical rotations. As a result, RT-ESD improves on previous work across several tasks including fiber recovery on the DiSCo dataset, deconvolution-derived partial volume estimation on real-world \\textit{in vivo} human brain dMRI, and improved downstream reconstruction of fiber tractograms on the Tractometer dataset. Our implementation is available at https://github.com/AxelElaldi/e3so3_conv","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.06103v1","tag":"medical-cv"}}
{"title":"Altered Topological Structure of the Brain White Matter in Maltreated Children through Topological Data Analysis","abstract":"Childhood maltreatment may adversely affect brain development and consequently behavioral, emotional, and psychological patterns during adulthood. In this study, we propose an analytical pipeline for modeling the altered topological structure of brain white matter structure in maltreated and typically developing children. We perform topological data analysis (TDA) to assess the alteration in global topology of the brain white-matter structural covariance network for child participants. We use persistent homology, an algebraic technique in TDA, to analyze topological features in the brain covariance networks constructed from structural magnetic resonance imaging (MRI) and diffusion tensor imaging (DTI). We develop a novel framework for statistical inference based on the Wasserstein distance to assess the significance of the observed topological differences. Using these methods in comparing maltreated children to a typically developing sample, we find that maltreatment may increase homogeneity in white matter structures and thus induce higher correlations in the structural covariance; this is reflected in the topological profile. Our findings strongly demonstrates that TDA can be used as a baseline framework to model altered topological structures of the brain.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05908v1","tag":"medical-cv"}}
{"title":"Cancer-Net BCa-S: Breast Cancer Grade Prediction using Volumetric Deep Radiomic Features from Synthetic Correlated Diffusion Imaging","abstract":"The prevalence of breast cancer continues to grow, affecting about 300,000 females in the United States in 2023. However, there are different levels of severity of breast cancer requiring different treatment strategies, and hence, grading breast cancer has become a vital component of breast cancer diagnosis and treatment planning. Specifically, the gold-standard Scarff-Bloom-Richardson (SBR) grade has been shown to consistently indicate a patient's response to chemotherapy. Unfortunately, the current method to determine the SBR grade requires removal of some cancer cells from the patient which can lead to stress and discomfort along with costly expenses. In this paper, we study the efficacy of deep learning for breast cancer grading based on synthetic correlated diffusion (CDI$^s$) imaging, a new magnetic resonance imaging (MRI) modality and found that it achieves better performance on SBR grade prediction compared to those learnt using gold-standard imaging modalities. Hence, we introduce Cancer-Net BCa-S, a volumetric deep radiomics approach for predicting SBR grade based on volumetric CDI$^s$ data. Given the promising results, this proposed method to identify the severity of the cancer would allow for better treatment decisions without the need for a biopsy. Cancer-Net BCa-S has been made publicly available as part of a global open-source initiative for advancing machine learning for cancer care.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05899v1","tag":"medical-cv"}}
{"title":"Automatic Aortic Valve Pathology Detection from 3-Chamber Cine MRI with Spatio-Temporal Attention Maps","abstract":"The assessment of aortic valve pathology using magnetic resonance imaging (MRI) typically relies on blood velocity estimates acquired using phase contrast (PC) MRI. However, abnormalities in blood flow through the aortic valve often manifest by the dephasing of blood signal in gated balanced steady-state free precession (bSSFP) scans (Cine MRI). We propose a 3D classification neural network (NN) to automatically identify aortic valve pathology (aortic regurgitation, aortic stenosis, mixed valve disease) from Cine MR images. We train and test our approach on a retrospective clinical dataset from three UK hospitals, using single-slice 3-chamber cine MRI from N = 576 patients. Our classification model accurately predicts the presence of aortic valve pathology (AVD) with an accuracy of 0.85 +/- 0.03 and can also correctly discriminate the type of AVD pathology (accuracy: 0.75 +/- 0.03). Gradient-weighted class activation mapping (Grad-CAM) confirms that the blood pool voxels close to the aortic root contribute the most to the classification. Our approach can be used to improve the diagnosis of AVD and optimise clinical CMR protocols for accurate and efficient AVD detection.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05885v2","tag":"medical-cv"}}
{"title":"FetMRQC: Automated Quality Control for fetal brain MRI","abstract":"Quality control (QC) has long been considered essential to guarantee the reliability of neuroimaging studies. It is particularly important for fetal brain MRI, where large and unpredictable fetal motion can lead to substantial artifacts in the acquired images. Existing methods for fetal brain quality assessment operate at the \\textit{slice} level, and fail to get a comprehensive picture of the quality of an image, that can only be achieved by looking at the \\textit{entire} brain volume. In this work, we propose FetMRQC, a machine learning framework for automated image quality assessment tailored to fetal brain MRI, which extracts an ensemble of quality metrics that are then used to predict experts' ratings. Based on the manual ratings of more than 1000 low-resolution stacks acquired across two different institutions, we show that, compared with existing quality metrics, FetMRQC is able to generalize out-of-domain, while being interpretable and data efficient. We also release a novel manual quality rating tool designed to facilitate and optimize quality rating of fetal brain images.   Our tool, along with all the code to generate, train and evaluate the model will be released upon acceptance of the paper.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05879v1","tag":"medical-cv"}}
{"title":"A Multi-Institutional Open-Source Benchmark Dataset for Breast Cancer Clinical Decision Support using Synthetic Correlated Diffusion Imaging Data","abstract":"Recently, a new form of magnetic resonance imaging (MRI) called synthetic correlated diffusion (CDI$^s$) imaging was introduced and showed considerable promise for clinical decision support for cancers such as prostate cancer when compared to current gold-standard MRI techniques. However, the efficacy for CDI$^s$ for other forms of cancers such as breast cancer has not been as well-explored nor have CDI$^s$ data been previously made publicly available. Motivated to advance efforts in the development of computer-aided clinical decision support for breast cancer using CDI$^s$, we introduce Cancer-Net BCa, a multi-institutional open-source benchmark dataset of volumetric CDI$^s$ imaging data of breast cancer patients. Cancer-Net BCa contains CDI$^s$ volumetric images from a pre-treatment cohort of 253 patients across ten institutions, along with detailed annotation metadata (the lesion type, genetic subtype, longest diameter on the MRI (MRLD), the Scarff-Bloom-Richardson (SBR) grade, and the post-treatment breast cancer pathologic complete response (pCR) to neoadjuvant chemotherapy). We further examine the demographic and tumour diversity of the Cancer-Net BCa dataset to gain deeper insights into potential biases. Cancer-Net BCa is publicly available as a part of a global open-source initiative dedicated to accelerating advancement in machine learning to aid clinicians in the fight against cancer.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05623v1","tag":"medical-cv"}}
{"title":"Virtual Scanner Games: expanding access to Magnetic Resonance (MR) education through interactive web tutorials","abstract":"Background: Magnetic Resonance Imaging (MRI) is a medical imaging technique that combines principles of physics, math, and engineering to look inside humans and animals, hence delivering a lifesaving technology. However, resource-poor regions aiming to expand access to MRI suffer from a lack of imaging expertise. Education of a new generation of MRI technicians and researchers in these regions is needed to make this technology more equitable and sustainable around the world. Results: We developed Virtual Scanner Games, an open-source web application that allows students to explore fundamental concepts in MRI. Four modules illustrated imaging basics, imaging biology, imaging physics, and imaging design. Feedback was collected from high school and early college students along with faculty, postdoctoral fellows, and doctoral students working in the field of MRI. Conclusions: We have shown a collection of games that can be used independently by high school students and people with no imaging background; they could also be used as demonstration tools in formal courses. Further assessment of their educational value through longer term usage is needed.","created":"2023-04-12","meta":{"link":"http://arxiv.org/abs/2304.05582v1","tag":"medical-cv"}}
{"title":"A comparison of 7 Tesla MR spectroscopic imaging and 3 Tesla MR fingerprinting for tumor localization in glioma patients","abstract":"This paper investigates the correlation between magnetic resonance spectroscopic imaging (MRSI) and magnetic resonance fingerprinting (MRF) in glioma patients by comparing neuro-oncological markers obtained from MRSI to T1/T2 maps from MRF.   Data from 12 consenting patients with gliomas were analyzed by defining hotspots for T1, T2 and various metabolic ratios, and comparing them using S{\\o}rensen-Dice Similarity Coefficients (DSCs) and the distances between their centers of intensity (COIDs).   Median DSCs between MRF and the tumor segmentation were 0.73 (T1) and 0.79 (T2). The DSCs between MRSI and MRF were highest for Gln/tNAA (T1: 0.75, T2: 0.80, tumor: 0.78), followed by Gly/tNAA (T1: 0.57, T2: 0.62, tumor: 0.54) and tCho/tNAA (T1: 0.61, T2: 0.58, tumor: 0.45). The median values in the tumor hotspot were T1=1724 ms, T2=86 ms, Gln/tNAA=0.61, Gly/tNAA=0.28, Ins/tNAA=1.15, and tCho/tNAA=0.48, and, in the peritumoral region, were T1=1756 ms, T2=102ms, Gln/tNAA=0.38, Gly/tNAA=0.20, Ins/tNAA=1.06, and tCho/tNAA=0.38, and, in the NAWM, were T1=950 ms, T2=43 ms, Gln/tNAA=0.16, Gly/tNAA=0.07, Ins/tNAA=0.54, and tCho/tNAA=0.20.   The results of this study constitute the first comparison of 7T MRSI and 3T MRF, showing a good correspondence between these methods.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05254v1","tag":"medical-cv"}}
{"title":"SPIRiT-Diffusion: Self-Consistency Driven Diffusion Model for Accelerated MRI","abstract":"Diffusion models are a leading method for image generation and have been successfully applied in magnetic resonance imaging (MRI) reconstruction. Current diffusion-based reconstruction methods rely on coil sensitivity maps (CSM) to reconstruct multi-coil data. However, it is difficult to accurately estimate CSMs in practice use, resulting in degradation of the reconstruction quality. To address this issue, we propose a self-consistency-driven diffusion model inspired by the iterative self-consistent parallel imaging (SPIRiT), namely SPIRiT-Diffusion. Specifically, the iterative solver of the self-consistent term in SPIRiT is utilized to design a novel stochastic differential equation (SDE) for diffusion process. Then $\\textit{k}$-space data can be interpolated directly during the reverse diffusion process, instead of using CSM to separate and combine individual coil images. This method indicates that the optimization model can be used to design SDE in diffusion models, driving the diffusion process strongly conforming with the physics involved in the optimization model, dubbed model-driven diffusion. The proposed SPIRiT-Diffusion method was evaluated on a 3D joint Intracranial and Carotid Vessel Wall imaging dataset. The results demonstrate that it outperforms the CSM-based reconstruction methods, and achieves high reconstruction quality at a high acceleration rate of 10.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05060v1","tag":"medical-cv"}}
{"title":"SFT-KD-Recon: Learning a Student-friendly Teacher for Knowledge Distillation in Magnetic Resonance Image Reconstruction","abstract":"Deep cascaded architectures for magnetic resonance imaging (MRI) acceleration have shown remarkable success in providing high-quality reconstruction. However, as the number of cascades increases, the improvements in reconstruction tend to become marginal, indicating possible excess model capacity. Knowledge distillation (KD) is an emerging technique to compress these models, in which a trained deep teacher network is used to distill knowledge to a smaller student network such that the student learns to mimic the behavior of the teacher. Most KD methods focus on effectively training the student with a pre-trained teacher unaware of the student model. We propose SFT-KD-Recon, a student-friendly teacher training approach along with the student as a prior step to KD to make the teacher aware of the structure and capacity of the student and enable aligning the representations of the teacher with the student. In SFT, the teacher is jointly trained with the unfolded branch configurations of the student blocks using three loss terms - teacher-reconstruction loss, student-reconstruction loss, and teacher-student imitation loss, followed by KD of the student. We perform extensive experiments for MRI acceleration in 4x and 5x under-sampling on the brain and cardiac datasets on five KD methods using the proposed approach as a prior step. We consider the DC-CNN architecture and setup teacher as D5C5 (141765 parameters), and student as D3C5 (49285 parameters), denoting a compression of 2.87:1. Results show that (i) our approach consistently improves the KD methods with improved reconstruction performance and image quality, and (ii) the student distilled using our approach is competitive with the teacher, with the performance gap reduced from 0.53 dB to 0.03 dB.","created":"2023-04-11","meta":{"link":"http://arxiv.org/abs/2304.05057v1","tag":"medical-cv"}}
{"title":"Ambiguous Medical Image Segmentation using Diffusion Models","abstract":"Collective insights from a group of experts have always proven to outperform an individual's best diagnostic for clinical tasks. For the task of medical image segmentation, existing research on AI-based alternatives focuses more on developing models that can imitate the best individual rather than harnessing the power of expert groups. In this paper, we introduce a single diffusion model-based approach that produces multiple plausible outputs by learning a distribution over group insights. Our proposed model generates a distribution of segmentation masks by leveraging the inherent stochastic sampling process of diffusion using only minimal additional learning. We demonstrate on three different medical image modalities- CT, ultrasound, and MRI that our model is capable of producing several possible variants while capturing the frequencies of their occurrences. Comprehensive results show that our proposed approach outperforms existing state-of-the-art ambiguous segmentation networks in terms of accuracy while preserving naturally occurring variation. We also propose a new metric to evaluate the diversity as well as the accuracy of segmentation predictions that aligns with the interest of clinical practice of collective insights.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04745v1","tag":"medical-cv"}}
{"title":"SAM vs BET: A Comparative Study for Brain Extraction and Segmentation of Magnetic Resonance Images using Deep Learning","abstract":"Brain extraction is a critical preprocessing step in neuroimaging studies, involving the separation of brain tissue from non-brain tissue using MRI data. FSL's Brain Extraction Tool (BET) is the current gold standard but is prone to errors due to image quality issues. The Segment Anything Model (SAM) by Meta AI has shown promising zero-shot segmentation potential. This paper compares SAM with BET for brain extraction on diverse brain scans, considering image quality, MRI sequences, and lesion locations. Results demonstrate that SAM outperforms BET in various evaluation parameters, particularly in cases with signal inhomogeneities, non-isotropic voxel resolutions, or lesions near the brain's outer regions and meninges. SAM's superior performance indicates its potential as a more accurate, robust, and versatile tool for brain extraction and segmentation applications.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04738v2","tag":"medical-cv"}}
{"title":"Regional Deep Atrophy: a Self-Supervised Learning Method to Automatically Identify Regions Associated With Alzheimer's Disease Progression From Longitudinal MRI","abstract":"Longitudinal assessment of brain atrophy, particularly in the hippocampus, is a well-studied biomarker for neurodegenerative diseases, such as Alzheimer's disease (AD). In clinical trials, estimation of brain progressive rates can be applied to track therapeutic efficacy of disease modifying treatments. However, most state-of-the-art measurements calculate changes directly by segmentation and/or deformable registration of MRI images, and may misreport head motion or MRI artifacts as neurodegeneration, impacting their accuracy. In our previous study, we developed a deep learning method DeepAtrophy that uses a convolutional neural network to quantify differences between longitudinal MRI scan pairs that are associated with time. DeepAtrophy has high accuracy in inferring temporal information from longitudinal MRI scans, such as temporal order or relative inter-scan interval. DeepAtrophy also provides an overall atrophy score that was shown to perform well as a potential biomarker of disease progression and treatment efficacy. However, DeepAtrophy is not interpretable, and it is unclear what changes in the MRI contribute to progression measurements. In this paper, we propose Regional Deep Atrophy (RDA), which combines the temporal inference approach from DeepAtrophy with a deformable registration neural network and attention mechanism that highlights regions in the MRI image where longitudinal changes are contributing to temporal inference. RDA has similar prediction accuracy as DeepAtrophy, but its additional interpretability makes it more acceptable for use in clinical settings, and may lead to more sensitive biomarkers for disease monitoring in clinical trials of early AD.","created":"2023-04-10","meta":{"link":"http://arxiv.org/abs/2304.04673v1","tag":"medical-cv"}}
{"title":"MedGen3D: A Deep Generative Framework for Paired 3D Image and Mask Generation","abstract":"Acquiring and annotating sufficient labeled data is crucial in developing accurate and robust learning-based models, but obtaining such data can be challenging in many medical image segmentation tasks. One promising solution is to synthesize realistic data with ground-truth mask annotations. However, no prior studies have explored generating complete 3D volumetric images with masks. In this paper, we present MedGen3D, a deep generative framework that can generate paired 3D medical images and masks. First, we represent the 3D medical data as 2D sequences and propose the Multi-Condition Diffusion Probabilistic Model (MC-DPM) to generate multi-label mask sequences adhering to anatomical geometry. Then, we use an image sequence generator and semantic diffusion refiner conditioned on the generated mask sequences to produce realistic 3D medical images that align with the generated masks. Our proposed framework guarantees accurate alignment between synthetic images and segmentation maps. Experiments on 3D thoracic CT and brain MRI datasets show that our synthetic data is both diverse and faithful to the original data, and demonstrate the benefits for downstream segmentation tasks. We anticipate that MedGen3D's ability to synthesize paired 3D medical images and masks will prove valuable in training deep learning models for medical imaging tasks.","created":"2023-04-08","meta":{"link":"http://arxiv.org/abs/2304.04106v1","tag":"medical-cv"}}
{"title":"Complementary structural and functional abnormalities to localise epileptogenic tissue","abstract":"When investigating suitability for surgery, people with drug-refractory focal epilepsy may have intracranial EEG (iEEG) electrodes implanted to localise seizure onset. Diffusion-weighted magnetic resonance imaging (dMRI) may be acquired to identify key white matter tracts for surgical avoidance. Here, we investigate whether structural connectivity abnormalities, inferred from dMRI, may be used in conjunction with functional iEEG abnormalities to aid localisation and resection of the epileptogenic zone (EZ), and improve surgical outcomes in epilepsy.   We retrospectively investigated data from 43 patients with epilepsy who had surgery following iEEG. Twenty five patients (58%) were free from disabling seizures (ILAE 1 or 2) at one year. For all patients, T1-weighted and diffusion-weighted MRIs were acquired prior to iEEG implantation. Interictal iEEG functional, and dMRI structural connectivity abnormalities were quantified by comparison to a normative map and healthy controls respectively.   First, we explored whether the resection of maximal (dMRI and iEEG) abnormalities related to improved surgical outcomes. Second, we investigated whether the modalities provided complementary information for improved prediction of surgical outcome. Third, we suggest how dMRI abnormalities may be useful to inform the placement of iEEG electrodes as part of the pre-surgical evaluation using a patient case study.   Seizure freedom was 15 times more likely in those patients with resection of maximal dMRI and iEEG abnormalities (p=0.008). Both modalities were separately able to distinguish patient outcome groups and when combined, a decision tree correctly separated 36 out of 43 (84%) patients based on surgical outcome.   Structural dMRI could be used in pre-surgical evaluations, particularly when localisation of the EZ is uncertain, to inform personalised iEEG implantation and resection.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.03192v2","tag":"medical-cv"}}
{"title":"GA-HQS: MRI reconstruction via a generically accelerated unfolding approach","abstract":"Deep unfolding networks (DUNs) are the foremost methods in the realm of compressed sensing MRI, as they can employ learnable networks to facilitate interpretable forward-inference operators. However, several daunting issues still exist, including the heavy dependency on the first-order optimization algorithms, the insufficient information fusion mechanisms, and the limitation of capturing long-range relationships. To address the issues, we propose a Generically Accelerated Half-Quadratic Splitting (GA-HQS) algorithm that incorporates second-order gradient information and pyramid attention modules for the delicate fusion of inputs at the pixel level. Moreover, a multi-scale split transformer is also designed to enhance the global feature representation. Comprehensive experiments demonstrate that our method surpasses previous ones on single-coil MRI acceleration tasks.","created":"2023-04-06","meta":{"link":"http://arxiv.org/abs/2304.02883v1","tag":"medical-cv"}}
{"title":"Diffusion MRI with free gradient waveforms on a high-performance gradient system: Probing restriction and exchange in the human brain","abstract":"The dependence of the diffusion MRI signal on the diffusion time carries signatures of restricted diffusion and exchange. Here we seek to highlight these signatures in the human brain by performing experiments using free gradient waveforms that are selectively sensitive to the two effects. We examine six healthy volunteers using both strong and ultra-strong gradients (80, 200 and 300 mT/m). In an experiment featuring a large set of gradient waveforms with different sensitivities to restricted diffusion and exchange (150 samples), our results reveal unique time-dependence signatures in grey and white matter, where the former is characterised by both restricted diffusion and exchange and the latter predominantly exhibits restricted diffusion. Furthermore, we show that gradient waveforms with independently varying sensitivities to restricted diffusion and exchange can be used to map exchange in the human brain. We consistently find that exchange in grey matter is at least twice as fast as in white matter, across all subjects and all gradient strengths. The shortest exchange times observed in this study were in the cerebellar cortex (115 ms). We also assess the feasibility of future clinical applications of the method used in this work, where we find that the grey-white matter exchange contrast obtained with a 25-minute 300 mT/m protocol is preserved by a 4-minute 300 mT/m and a 10-minute 80 mT/m protocol. Our work underlines the utility of free waveforms for detecting time-dependence signatures due to restricted diffusion and exchange in vivo, which may potentially serve as a tool for studying diseased tissue.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02764v1","tag":"medical-cv"}}
{"title":"Domain Generalization with Adversarial Intensity Attack for Medical Image Segmentation","abstract":"Most statistical learning algorithms rely on an over-simplified assumption, that is, the train and test data are independent and identically distributed. In real-world scenarios, however, it is common for models to encounter data from new and different domains to which they were not exposed to during training. This is often the case in medical imaging applications due to differences in acquisition devices, imaging protocols, and patient characteristics. To address this problem, domain generalization (DG) is a promising direction as it enables models to handle data from previously unseen domains by learning domain-invariant features robust to variations across different domains. To this end, we introduce a novel DG method called Adversarial Intensity Attack (AdverIN), which leverages adversarial training to generate training data with an infinite number of styles and increase data diversity while preserving essential content information. We conduct extensive evaluation experiments on various multi-domain segmentation datasets, including 2D retinal fundus optic disc/cup and 3D prostate MRI. Our results demonstrate that AdverIN significantly improves the generalization ability of the segmentation models, achieving significant improvement on these challenging datasets. Code is available upon publication.","created":"2023-04-05","meta":{"link":"http://arxiv.org/abs/2304.02720v1","tag":"medical-cv"}}
{"title":"Optimal operating MR contrast for brain ventricle parcellation","abstract":"Development of MR harmonization has enabled different contrast MRIs to be synthesized while preserving the underlying anatomy. In this paper, we use image harmonization to explore the impact of different T1-w MR contrasts on a state-of-the-art ventricle parcellation algorithm VParNet. We identify an optimal operating contrast (OOC) for ventricle parcellation; by showing that the performance of a pretrained VParNet can be boosted by adjusting contrast to the OOC.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.02056v1","tag":"medical-cv"}}
{"title":"Primitive Simultaneous Optimization of Similarity Metrics for Image Registration","abstract":"Even though simultaneous optimization of similarity metrics represents a standard procedure in the field of semantic segmentation, surprisingly, this does not hold true for image registration. To close this unexpected gap in the literature, we investigate in a complex multi-modal 3D setting whether simultaneous optimization of registration metrics, here implemented by means of primitive summation, can benefit image registration. We evaluate two challenging datasets containing collections of pre- to post-operative and pre- to intra-operative Magnetic Resonance Imaging (MRI) of glioma. Employing the proposed optimization we demonstrate improved registration accuracy in terms of Target Registration Error (TRE) on expert neuroradiologists' landmark annotations.","created":"2023-04-04","meta":{"link":"http://arxiv.org/abs/2304.01601v1","tag":"medical-cv"}}
{"title":"U-Netmer: U-Net meets Transformer for medical image segmentation","abstract":"The combination of the U-Net based deep learning models and Transformer is a new trend for medical image segmentation. U-Net can extract the detailed local semantic and texture information and Transformer can learn the long-rang dependencies among pixels in the input image. However, directly adapting the Transformer for segmentation has ``token-flatten\" problem (flattens the local patches into 1D tokens which losses the interaction among pixels within local patches) and ``scale-sensitivity\" problem (uses a fixed scale to split the input image into local patches). Compared to directly combining U-Net and Transformer, we propose a new global-local fashion combination of U-Net and Transformer, named U-Netmer, to solve the two problems. The proposed U-Netmer splits an input image into local patches. The global-context information among local patches is learnt by the self-attention mechanism in Transformer and U-Net segments each local patch instead of flattening into tokens to solve the `token-flatten\" problem. The U-Netmer can segment the input image with different patch sizes with the identical structure and the same parameter. Thus, the U-Netmer can be trained with different patch sizes to solve the ``scale-sensitivity\" problem. We conduct extensive experiments in 7 public datasets on 7 organs (brain, heart, breast, lung, polyp, pancreas and prostate) and 4 imaging modalities (MRI, CT, ultrasound, and endoscopy) to show that the proposed U-Netmer can be generally applied to improve accuracy of medical image segmentation. These experimental results show that U-Netmer provides state-of-the-art performance compared to baselines and other models. In addition, the discrepancy among the outputs of U-Netmer with different scales is linearly correlated to the segmentation accuracy which can be considered as a confidence score to rank test images by difficulty without ground-truth.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.01401v1","tag":"medical-cv"}}
{"title":"Accelerated parallel MRI using memory efficient and robust monotone operator learning (MOL)","abstract":"Model-based deep learning methods that combine imaging physics with learned regularization priors have been emerging as powerful tools for parallel MRI acceleration. The main focus of this paper is to determine the utility of the monotone operator learning (MOL) framework in the parallel MRI setting. The MOL algorithm alternates between a gradient descent step using a monotone convolutional neural network (CNN) and a conjugate gradient algorithm to encourage data consistency. The benefits of this approach include similar guarantees as compressive sensing algorithms including uniqueness, convergence, and stability, while being significantly more memory efficient than unrolled methods. We validate the proposed scheme by comparing it with different unrolled algorithms in the context of accelerated parallel MRI for static and dynamic settings.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.01351v1","tag":"medical-cv"}}
{"title":"MGMT promoter methylation status prediction using MRI scans? An extensive experimental evaluation of deep learning models","abstract":"The number of studies on deep learning for medical diagnosis is expanding, and these systems are often claimed to outperform clinicians. However, only a few systems have shown medical efficacy. From this perspective, we examine a wide range of deep learning algorithms for the assessment of glioblastoma - a common brain tumor in older adults that is lethal. Surgery, chemotherapy, and radiation are the standard treatments for glioblastoma patients. The methylation status of the MGMT promoter, a specific genetic sequence found in the tumor, affects chemotherapy's effectiveness. MGMT promoter methylation improves chemotherapy response and survival in several cancers. MGMT promoter methylation is determined by a tumor tissue biopsy, which is then genetically tested. This lengthy and invasive procedure increases the risk of infection and other complications. Thus, researchers have used deep learning models to examine the tumor from brain MRI scans to determine the MGMT promoter's methylation state. We employ deep learning models and one of the largest public MRI datasets of 585 participants to predict the methylation status of the MGMT promoter in glioblastoma tumors using MRI scans. We test these models using Grad-CAM, occlusion sensitivity, feature visualizations, and training loss landscapes. Our results show no correlation between these two, indicating that external cohort data should be used to verify these models' performance to assure the accuracy and reliability of deep learning systems in cancer diagnosis.","created":"2023-04-03","meta":{"link":"http://arxiv.org/abs/2304.00774v1","tag":"medical-cv"}}
{"title":"DrDisco: Deep Registration for Distortion Correction of Diffusion MRI with single phase-encoding","abstract":"Diffusion-weighted magnetic resonance imaging (DW-MRI) is a non-invasive way of imaging white matter tracts in the human brain. DW-MRIs are usually acquired using echo-planar imaging (EPI) with high gradient fields, which could introduce severe geometric distortions that interfere with further analyses. Most tools for correcting distortion require two minimally weighted DW-MRI images (B0) acquired with different phase-encoding directions, and they can take hours to process per subject. Since a great amount of diffusion data are only acquired with a single phase-encoding direction, the application of existing approaches is limited. We propose a deep learning-based registration approach to correct distortion using only the B0 acquired from a single phase-encoding direction. Specifically, we register undistorted T1-weighted images and distorted B0 to remove the distortion through a deep learning model. We apply a differentiable mutual information loss during training to improve inter-modality alignment. Experiments on the Human Connectome Project dataset show the proposed method outperforms SyN and VoxelMorph on several metrics, and only takes a few seconds to process one subject.","created":"2023-04-01","meta":{"link":"http://arxiv.org/abs/2304.00217v1","tag":"medical-cv"}}
{"title":"A Surface-Based Federated Chow Test Model for Integrating APOE Status, Tau Deposition Measure, and Hippocampal Surface Morphometry","abstract":"Background: Alzheimer's Disease (AD) is the most common type of age-related dementia, affecting 6.2 million people aged 65 or older according to CDC data. It is commonly agreed that discovering an effective AD diagnosis biomarker could have enormous public health benefits, potentially preventing or delaying up to 40% of dementia cases. Tau neurofibrillary tangles are the primary driver of downstream neurodegeneration and subsequent cognitive impairment in AD, resulting in structural deformations such as hippocampal atrophy that can be observed in magnetic resonance imaging (MRI) scans. Objective: To build a surface-based model to 1) detect differences between APOE subgroups in patterns of tau deposition and hippocampal atrophy, and 2) use the extracted surface-based features to predict cognitive decline. Methods: Using data obtained from different institutions, we develop a surface-based federated Chow test model to study the synergistic effects of APOE, a previously reported significant risk factor of AD, and tau on hippocampal surface morphometry. Results: We illustrate that the APOE-specific morphometry features correlate with AD progression and better predict future AD conversion than other MRI biomarkers. For example, a strong association between atrophy and abnormal tau was identified in hippocampal subregion cornu ammonis 1 (CA1 subfield) and subiculum in e4 homozygote cohort. Conclusion: Our model allows for identifying MRI biomarkers for AD and cognitive decline prediction and may uncover a corner of the neural mechanism of the influence of APOE and tau deposition on hippocampal morphology.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2304.00134v1","tag":"medical-cv"}}
{"title":"Deep Factor Model: A Novel Approach for Motion Compensated Multi-Dimensional MRI","abstract":"Recent quantitative parameter mapping methods including MR fingerprinting (MRF) collect a time series of images that capture the evolution of magnetization. The focus of this work is to introduce a novel approach termed as Deep Factor Model(DFM), which offers an efficient representation of the multi-contrast image time series. The higher efficiency of the representation enables the acquisition of the images in a highly undersampled fashion, which translates to reduced scan time in 3D high-resolution multi-contrast applications. The approach integrates motion estimation and compensation, making the approach robust to subject motion during the scan.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2304.00102v1","tag":"medical-cv"}}
{"title":"Optimal density compensation factors for the reconstruction of the Fourier transform of bandlimited functions","abstract":"An inverse nonequispaced fast Fourier transform (iNFFT) is a fast algorithm to compute the Fourier coefficients of a trigonometric polynomial from nonequispaced sampling data. However, various applications such as magnetic resonance imaging (MRI) are concerned with the analogous problem for bandlimited functions, i.e., the reconstruction of point evaluations of the Fourier transform from given measurements of the bandlimited function. In this paper, we review an approach yielding exact reconstruction for trigonometric polynomials up to a certain degree, and extend this technique to the setting of bandlimited functions. Here we especially focus on methods computing a diagonal matrix of weights needed for sampling density compensation.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2304.00094v1","tag":"medical-cv"}}
{"title":"Deep Learning-based Diffusion Tensor Cardiac Magnetic Resonance Reconstruction: A Comparison Study","abstract":"In vivo cardiac diffusion tensor imaging (cDTI) is a promising Magnetic Resonance Imaging (MRI) technique for evaluating the micro-structure of myocardial tissue in the living heart, providing insights into cardiac function and enabling the development of innovative therapeutic strategies. However, the integration of cDTI into routine clinical practice is challenging due to the technical obstacles involved in the acquisition, such as low signal-to-noise ratio and long scanning times. In this paper, we investigate and implement three different types of deep learning-based MRI reconstruction models for cDTI reconstruction. We evaluate the performance of these models based on reconstruction quality assessment and diffusion tensor parameter assessment. Our results indicate that the models we discussed in this study can be applied for clinical use at an acceleration factor (AF) of $\\times 2$ and $\\times 4$, with the D5C5 model showing superior fidelity for reconstruction and the SwinMR model providing higher perceptual scores. There is no statistical difference with the reference for all diffusion tensor parameters at AF $\\times 2$ or most DT parameters at AF $\\times 4$, and the quality of most diffusion tensor parameter maps are visually acceptable. SwinMR is recommended as the optimal approach for reconstruction at AF $\\times 2$ and AF $\\times 4$. However, we believed the models discussed in this studies are not prepared for clinical use at a higher AF. At AF $\\times 8$, the performance of all models discussed remains limited, with only half of the diffusion tensor parameters being recovered to a level with no statistical difference from the reference. Some diffusion tensor parameter maps even provide wrong and misleading information.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2304.00996v2","tag":"medical-cv"}}
{"title":"Live image-based neurosurgical guidance and roadmap generation using unsupervised embedding","abstract":"Advanced minimally invasive neurosurgery navigation relies mainly on Magnetic Resonance Imaging (MRI) guidance. MRI guidance, however, only provides pre-operative information in the majority of the cases. Once the surgery begins, the value of this guidance diminishes to some extent because of the anatomical changes due to surgery. Guidance with live image feedback coming directly from the surgical device, e.g., endoscope, can complement MRI-based navigation or be an alternative if MRI guidance is not feasible. With this motivation, we present a method for live image-only guidance leveraging a large data set of annotated neurosurgical videos.First, we report the performance of a deep learning-based object detection method, YOLO, on detecting anatomical structures in neurosurgical images. Second, we present a method for generating neurosurgical roadmaps using unsupervised embedding without assuming exact anatomical matches between patients, presence of an extensive anatomical atlas, or the need for simultaneous localization and mapping. A generated roadmap encodes the common anatomical paths taken in surgeries in the training set. At inference, the roadmap can be used to map a surgeon's current location using live image feedback on the path to provide guidance by being able to predict which structures should appear going forward or backward, much like a mapping application. Even though the embedding is not supervised by position information, we show that it is correlated to the location inside the brain and on the surgical path. We trained and evaluated the proposed method with a data set of 166 transsphenoidal adenomectomy procedures.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.18019v1","tag":"medical-cv"}}
{"title":"Multiple Instance Ensembling For Paranasal Anomaly Classification In The Maxillary Sinus","abstract":"Paranasal anomalies are commonly discovered during routine radiological screenings and can present with a wide range of morphological features. This diversity can make it difficult for convolutional neural networks (CNNs) to accurately classify these anomalies, especially when working with limited datasets. Additionally, current approaches to paranasal anomaly classification are constrained to identifying a single anomaly at a time. These challenges necessitate the need for further research and development in this area.   In this study, we investigate the feasibility of using a 3D convolutional neural network (CNN) to classify healthy maxillary sinuses (MS) and MS with polyps or cysts. The task of accurately identifying the relevant MS volume within larger head and neck Magnetic Resonance Imaging (MRI) scans can be difficult, but we develop a straightforward strategy to tackle this challenge. Our end-to-end solution includes the use of a novel sampling technique that not only effectively localizes the relevant MS volume, but also increases the size of the training dataset and improves classification results. Additionally, we employ a multiple instance ensemble prediction method to further boost classification performance. Finally, we identify the optimal size of MS volumes to achieve the highest possible classification performance on our dataset.   With our multiple instance ensemble prediction strategy and sampling strategy, our 3D CNNs achieve an F1 of 0.85 whereas without it, they achieve an F1 of 0.70.   We demonstrate the feasibility of classifying anomalies in the MS. We propose a data enlarging strategy alongside a novel ensembling strategy that proves to be beneficial for paranasal anomaly classification in the MS.","created":"2023-03-31","meta":{"link":"http://arxiv.org/abs/2303.17915v1","tag":"medical-cv"}}
{"title":"Thermal instability as a constraint for warm X-ray corona in AGN","abstract":"Context. Warm corona is a possible explanation for Soft X-ray Excess in Active Galactic Nuclei (AGN). This paper contains self consistent modeling of both: accretion disk with optically thick corona, where the gas is heated by magneto-rotational instability dynamo (MRI), and cooled by radiation which undergoes free-free absorption and Compton scattering. Aims. We determine the parameters of warm corona in AGN using disk-corona structure model that takes into account magnetic and radiation pressure. We aim to show the role of thermal instability (TI) as a constraint for warm, optically thick X-ray corona in AGN. Methods. With the use of relaxation code, the vertical solution of the disk driven by MRI together with radiative transfer in hydrostatic and radiative equilibrium is calculated, which allows us to point out how TI affects the corona for wide range of global parameters. Results. We show that magnetic heating is strong enough to heat upper layers of the accretion disk atmosphere, which form the warm corona covering the disk. Magnetic pressure does not remove TI caused by radiative processes operating in X-ray emitting plasma. TI disappears only in case of accretion rates higher than 0.2 of Eddington, and high magnetic field parameter $\\alpha_{\\rm B}$ > 0.1. Conclusions. TI plays the major role in the formation of the warm corona above magnetically driven accretion disk in AGN. The warm, Compton cooled corona, responsible for soft X-ray excess, resulted from our model has typical temperature in the range of 0.01 - 2 keV and optical depth even up to 50, which agrees with recent observations.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17384v1","tag":"medical-cv"}}
{"title":"Retrospective Motion Correction in Gradient Echo MRI by Explicit Motion Estimation Using Deep CNNs","abstract":"Magnetic Resonance Imaging allows high resolution data acquisition with the downside of motion sensitivity due to relatively long acquisition times. Even during the acquisition of a single 2D slice, motion can severely corrupt the image. Retrospective motion correction strategies do not interfere during acquisition time but operate on the motion affected data. Known methods suited to this scenario are compressed sensing (CS), generative adversarial networks (GANs), and motion estimation. In this paper we propose a strategy to correct for motion artifacts using Deep Convolutional Neuronal Networks (Deep CNNs) in a reliable and verifiable manner by explicit motion estimation. The sensitivity encoding (SENSE) redundancy that multiple receiver coils provide, has in the past been used for acceleration, noise reduction and rigid motion compensation. We show that using Deep CNNs the concepts of rigid motion compensation can be generalized to more complex motion fields. Using a simulated synthetic data set, our proposed supervised network is evaluated on motion corrupted MRIs of abdomen and head. We compare our results with rigid motion compensation and GANs.","created":"2023-03-30","meta":{"link":"http://arxiv.org/abs/2303.17239v1","tag":"medical-cv"}}
{"title":"Hybrid-space reconstruction with add-on distortion correction for simultaneous multi-slab diffusion MRI","abstract":"Purpose: This study aims to propose a model-based reconstruction algorithm for simultaneous multi-slab diffusion MRI acquired with blipped-CAIPI gradients (blipped-SMSlab), which can also incorporate distortion correction.   Methods: We formulate blipped-SMSlab in a 4D k-space with kz gradients for the intra-slab slice encoding and km (blipped-CAIPI) gradients for the inter-slab encoding. Because kz and km gradients share the same physical axis, the blipped-CAIPI gradients introduce phase interference in the z-km domain while motion induces phase variations in the kz-m domain. Thus, our previous k-space-based reconstruction would need multiple steps to transform data back and forth between k-space and image space for phase correction. Here we propose a model-based hybrid-space reconstruction algorithm to correct the phase errors simultaneously. Moreover, the proposed algorithm is combined with distortion correction, and jointly reconstructs data acquired with the blip-up/down acquisition to reduce the g-factor penalty.   Results: The blipped-CAIPI-induced phase interference is corrected by the hybrid-space reconstruction. Blipped-CAIPI can reduce the g-factor penalty compared to the non-blipped acquisition in the basic reconstruction. Additionally, the joint reconstruction simultaneously corrects the image distortions and improves the 1/g-factors by around 50%. Furthermore, through the joint reconstruction, SMSlab acquisitions without the blipped-CAIPI gradients also show comparable correction performance with blipped-SMSlab.   Conclusion: The proposed model-based hybrid-space reconstruction can reconstruct blipped-SMSlab diffusion MRI successfully. Its extension to a joint reconstruction of the blip-up/down acquisition can correct EPI distortions and further reduce the g-factor penalty compared with the separate reconstruction.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16442v2","tag":"medical-cv"}}
{"title":"A Unified Single-stage Learning Model for Estimating Fiber Orientation Distribution Functions on Heterogeneous Multi-shell Diffusion-weighted MRI","abstract":"Diffusion-weighted (DW) MRI measures the direction and scale of the local diffusion process in every voxel through its spectrum in q-space, typically acquired in one or more shells. Recent developments in micro-structure imaging and multi-tissue decomposition have sparked renewed attention to the radial b-value dependence of the signal. Applications in tissue classification and micro-architecture estimation, therefore, require a signal representation that extends over the radial as well as angular domain. Multiple approaches have been proposed that can model the non-linear relationship between the DW-MRI signal and biological microstructure. In the past few years, many deep learning-based methods have been developed towards faster inference speed and higher inter-scan consistency compared with traditional model-based methods (e.g., multi-shell multi-tissue constrained spherical deconvolution). However, a multi-stage learning strategy is typically required since the learning process relied on various middle representations, such as simple harmonic oscillator reconstruction (SHORE) representation. In this work, we present a unified dynamic network with a single-stage spherical convolutional neural network, which allows efficient fiber orientation distribution function (fODF) estimation through heterogeneous multi-shell diffusion MRI sequences. We study the Human Connectome Project (HCP) young adults with test-retest scans. From the experimental results, the proposed single-stage method outperforms prior multi-stage approaches in repeated fODF estimation with shell dropoff and single-shell DW-MRI sequences.","created":"2023-03-29","meta":{"link":"http://arxiv.org/abs/2303.16376v1","tag":"medical-cv"}}
{"title":"SynthRAD2023 Grand Challenge dataset: generating synthetic CT for radiotherapy","abstract":"Purpose: Medical imaging has become increasingly important in diagnosing and treating oncological patients, particularly in radiotherapy. Recent advances in synthetic computed tomography (sCT) generation have increased interest in public challenges to provide data and evaluation metrics for comparing different approaches openly. This paper describes a dataset of brain and pelvis computed tomography (CT) images with rigidly registered CBCT and MRI images to facilitate the development and evaluation of sCT generation for radiotherapy planning.   Acquisition and validation methods: The dataset consists of CT, CBCT, and MRI of 540 brains and 540 pelvic radiotherapy patients from three Dutch university medical centers. Subjects' ages ranged from 3 to 93 years, with a mean age of 60. Various scanner models and acquisition settings were used across patients from the three data-providing centers. Details are available in CSV files provided with the datasets.   Data format and usage notes: The data is available on Zenodo (https://doi.org/10.5281/zenodo.7260705) under the SynthRAD2023 collection. The images for each subject are available in nifti format.   Potential applications: This dataset will enable the evaluation and development of image synthesis algorithms for radiotherapy purposes on a realistic multi-center dataset with varying acquisition protocols. Synthetic CT generation has numerous applications in radiation therapy, including diagnosis, treatment planning, treatment monitoring, and surgical planning.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.16320v1","tag":"medical-cv"}}
{"title":"CuNeRF: Cube-Based Neural Radiance Field for Zero-Shot Medical Image Arbitrary-Scale Super Resolution","abstract":"Medical image arbitrary-scale super-resolution (MIASSR) has recently gained widespread attention, aiming to super sample medical volumes at arbitrary scales via a single model. However, existing MIASSR methods face two major limitations: (i) reliance on high-resolution (HR) volumes and (ii) limited generalization ability, which restricts their application in various scenarios. To overcome these limitations, we propose Cube-based Neural Radiance Field (CuNeRF), a zero-shot MIASSR framework that can yield medical images at arbitrary scales and viewpoints in a continuous domain. Unlike existing MIASSR methods that fit the mapping between low-resolution (LR) and HR volumes, CuNeRF focuses on building a coordinate-intensity continuous representation from LR volumes without the need for HR references. This is achieved by the proposed differentiable modules: including cube-based sampling, isotropic volume rendering, and cube-based hierarchical rendering. Through extensive experiments on magnetic resource imaging (MRI) and computed tomography (CT) modalities, we demonstrate that CuNeRF outperforms state-of-the-art MIASSR methods. CuNeRF yields better visual verisimilitude and reduces aliasing artifacts at various upsampling factors. Moreover, our CuNeRF does not need any LR-HR training pairs, which is more flexible and easier to be used than others. Our code will be publicly available soon.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.16242v2","tag":"medical-cv"}}
{"title":"Learning Federated Visual Prompt in Null Space for MRI Reconstruction","abstract":"Federated Magnetic Resonance Imaging (MRI) reconstruction enables multiple hospitals to collaborate distributedly without aggregating local data, thereby protecting patient privacy. However, the data heterogeneity caused by different MRI protocols, insufficient local training data, and limited communication bandwidth inevitably impair global model convergence and updating. In this paper, we propose a new algorithm, FedPR, to learn federated visual prompts in the null space of global prompt for MRI reconstruction. FedPR is a new federated paradigm that adopts a powerful pre-trained model while only learning and communicating the prompts with few learnable parameters, thereby significantly reducing communication costs and achieving competitive performance on limited local data. Moreover, to deal with catastrophic forgetting caused by data heterogeneity, FedPR also updates efficient federated visual prompts that project the local prompts into an approximate null space of the global prompt, thereby suppressing the interference of gradients on the server performance. Extensive experiments on federated MRI show that FedPR significantly outperforms state-of-the-art FL algorithms with <6% of communication costs when given the limited amount of local training data.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.16181v2","tag":"medical-cv"}}
{"title":"Cellular EXchange Imaging (CEXI): Evaluation of a diffusion model including water exchange in cells using numerical phantoms of permeable spheres","abstract":"Purpose: Biophysical models of diffusion MRI have been developed to characterize microstructure in various tissues, but existing models are not suitable for tissue composed of permeable spherical cells. In this study we introduce Cellular Exchange Imaging (CEXI), a model tailored for permeable spherical cells, and compares its performance to a related Ball \\& Sphere (BS) model that neglects permeability. Methods: We generated DW-MRI signals using Monte-Carlo simulations with a PGSE sequence in numerical substrates made of spherical cells and their extracellular space for a range of membrane permeability. From these signals, the properties of the substrates were inferred using both BS and CEXI models. Results: CEXI outperformed the impermeable model by providing more stable estimates cell size and intracellular volume fraction that were diffusion time-independent. Notably, CEXI accurately estimated the exchange time for low to moderate permeability levels previously reported in other studies ($\\kappa<25\\mu m/s$). However, in highly permeable substrates ($\\kappa=50\\mu m/s$), the estimated parameters were less stable, particularly the diffusion coefficients. Conclusion: This study highlights the importance of modeling the exchange time to accurately quantify microstructure properties in permeable cellular substrates. Future studies should evaluate CEXI in clinical applications such as lymph nodes, investigate exchange time as a potential biomarker of tumor severity, and develop more appropriate tissue models that account for anisotropic diffusion and highly permeable membranes.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.16112v2","tag":"medical-cv"}}
{"title":"SFHarmony: Source Free Domain Adaptation for Distributed Neuroimaging Analysis","abstract":"To represent the biological variability of clinical neuroimaging populations, it is vital to be able to combine data across scanners and studies. However, different MRI scanners produce images with different characteristics, resulting in a domain shift known as the `harmonisation problem'. Additionally, neuroimaging data is inherently personal in nature, leading to data privacy concerns when sharing the data. To overcome these barriers, we propose an Unsupervised Source-Free Domain Adaptation (SFDA) method, SFHarmony. Through modelling the imaging features as a Gaussian Mixture Model and minimising an adapted Bhattacharyya distance between the source and target features, we can create a model that performs well for the target data whilst having a shared feature representation across the data domains, without needing access to the source data for adaptation or target labels. We demonstrate the performance of our method on simulated and real domain shifts, showing that the approach is applicable to classification, segmentation and regression tasks, requiring no changes to the algorithm. Our method outperforms existing SFDA approaches across a range of realistic data scenarios, demonstrating the potential utility of our approach for MRI harmonisation and general SFDA problems. Our code is available at \\url{https://github.com/nkdinsdale/SFHarmony}.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15965v1","tag":"medical-cv"}}
{"title":"fRegGAN with K-space Loss Regularization for Medical Image Translation","abstract":"Generative adversarial networks (GANs) have shown remarkable success in generating realistic images and are increasingly used in medical imaging for image-to-image translation tasks. However, GANs tend to suffer from a frequency bias towards low frequencies, which can lead to the removal of important structures in the generated images. To address this issue, we propose a novel frequency-aware image-to-image translation framework based on the supervised RegGAN approach, which we call fRegGAN. The framework employs a K-space loss to regularize the frequency content of the generated images and incorporates well-known properties of MRI K-space geometry to guide the network training process. By combine our method with the RegGAN approach, we can mitigate the effect of training with misaligned data and frequency bias at the same time. We evaluate our method on the public BraTS dataset and outperform the baseline methods in terms of both quantitative and qualitative metrics when synthesizing T2-weighted from T1-weighted MR images. Detailed ablation studies are provided to understand the effect of each modification on the final performance. The proposed method is a step towards improving the performance of image-to-image translation and synthesis in the medical domain and shows promise for other applications in the field of image processing and generation.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15938v1","tag":"medical-cv"}}
{"title":"DDMM-Synth: A Denoising Diffusion Model for Cross-modal Medical Image Synthesis with Sparse-view Measurement Embedding","abstract":"Reducing the radiation dose in computed tomography (CT) is important to mitigate radiation-induced risks. One option is to employ a well-trained model to compensate for incomplete information and map sparse-view measurements to the CT reconstruction. However, reconstruction from sparsely sampled measurements is insufficient to uniquely characterize an object in CT, and a learned prior model may be inadequate for unencountered cases. Medical modal translation from magnetic resonance imaging (MRI) to CT is an alternative but may introduce incorrect information into the synthesized CT images in addition to the fact that there exists no explicit transformation describing their relationship. To address these issues, we propose a novel framework called the denoising diffusion model for medical image synthesis (DDMM-Synth) to close the performance gaps described above. This framework combines an MRI-guided diffusion model with a new CT measurement embedding reverse sampling scheme. Specifically, the null-space content of the one-step denoising result is refined by the MRI-guided data distribution prior, and its range-space component derived from an explicit operator matrix and the sparse-view CT measurements is directly integrated into the inference stage. DDMM-Synth can adjust the projection number of CT a posteriori for a particular clinical application and its modified version can even improve the results significantly for noisy cases. Our results show that DDMM-Synth outperforms other state-of-the-art supervised-learning-based baselines under fair experimental conditions.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15770v1","tag":"medical-cv"}}
{"title":"The impact of dust evolution on the dead zone outer edge in magnetized protoplanetary disks","abstract":"[Abridged] Aims. We provide an important step toward a better understanding of the magnetorotational instability (MRI)-dust coevolution in protoplanetary disks by presenting a proof of concept that dust evolution ultimately plays a crucial role in the MRI activity. Methods. First, we study how a fixed power-law dust size distribution with varying parameters impacts the MRI activity, especially the steady-state MRI-driven accretion, by employing and improving our previous 1+1D MRI-driven turbulence model. Second, we relax the steady-state accretion assumption in this disk accretion model, and partially couple it to a dust evolution model in order to investigate how the evolution of dust (dynamics and grain growth processes combined) and MRI-driven accretion are intertwined on million-year timescales. Results. Dust coagulation and settling lead to a higher gas ionization degree in the protoplanetary disk, resulting in stronger MRI-driven turbulence as well as a more compact dead zone. On the other hand, fragmentation has an opposite effect because it replenishes the disk in small dust particles. Since the dust content of the disk decreases over million years of evolution due to radial drift, the MRI-driven turbulence overall becomes stronger and the dead zone more compact until the disk dust-gas mixture eventually behaves as a grain-free plasma. Furthermore, our results show that dust evolution alone does not lead to a complete reactivation of the dead zone. Conclusions. The MRI activity evolution (hence the temporal evolution of the MRI-induced $\\alpha$-parameter) is controlled by dust evolution and occurs on a timescale of local dust growth, as long as there is enough dust particles in the disk to dominate the recombination process for the ionization chemistry. Once it is no longer the case, it is expected to be controlled by gas evolution and occurs on a viscous evolution timescale.","created":"2023-03-28","meta":{"link":"http://arxiv.org/abs/2303.15675v1","tag":"medical-cv"}}
{"title":"MoViT: Memorizing Vision Transformers for Medical Image Analysis","abstract":"The synergy of long-range dependencies from transformers and local representations of image content from convolutional neural networks (CNNs) has led to advanced architectures and increased performance for various medical image analysis tasks due to their complementary benefits. However, compared with CNNs, transformers require considerably more training data, due to a larger number of parameters and an absence of inductive bias. The need for increasingly large datasets continues to be problematic, particularly in the context of medical imaging, where both annotation efforts and data protection result in limited data availability. In this work, inspired by the human decision-making process of correlating new ``evidence'' with previously memorized ``experience'', we propose a Memorizing Vision Transformer (MoViT) to alleviate the need for large-scale datasets to successfully train and deploy transformer-based architectures. MoViT leverages an external memory structure to cache history attention snapshots during the training stage. To prevent overfitting, we incorporate an innovative memory update scheme, attention temporal moving average, to update the stored external memories with the historical moving average. For inference speedup, we design a prototypical attention learning method to distill the external memory into smaller representative subsets. We evaluate our method on a public histology image dataset and an in-house MRI dataset, demonstrating that MoViT applied to varied medical image analysis tasks, can outperform vanilla transformer models across varied data regimes, especially in cases where only a small amount of annotated data is available. More importantly, MoViT can reach a competitive performance of ViT with only 3.0% of the training data.","created":"2023-03-27","meta":{"link":"http://arxiv.org/abs/2303.15553v2","tag":"medical-cv"}}
{"title":"Joint Multi-Echo/Respiratory Motion-Resolved Compressed Sensing Reconstruction of Free-Breathing Non-Cartesian Abdominal MRI","abstract":"We propose a novel respiratory motion-resolved MR image reconstruction method that jointly treats multi-echo k-space raw data. Continuously acquired non-Cartesian multi-echo/multi-coil k-space data with free breathing are sorted/binned into the motion states from end-expiratory to end-inspiratory phases based on a respiratory motion signal. Temporal total variation applied to the motion state dimension of each echo is then coupled in the $\\ell_2$ sense for joint reconstruction of the multiple echoes. Reconstructed source images of the proposed method are compared with conventional echo-by-echo motion-resolved reconstruction, and R2* of the proposed and echo-by-echo methods are compared with respect to a clinical reference. We demonstrate that inconsistency between echoes is successfully suppressed in the proposed joint reconstruction method, producing high-quality source images and R2* measurements compared to clinical reference.","created":"2023-03-27","meta":{"link":"http://arxiv.org/abs/2303.15144v2","tag":"medical-cv"}}
{"title":"Blind Inpainting with Object-aware Discrimination for Artificial Marker Removal","abstract":"Medical images often contain artificial markers added by doctors, which can negatively affect the accuracy of AI-based diagnosis. To address this issue and recover the missing visual contents, inpainting techniques are highly needed. However, existing inpainting methods require manual mask input, limiting their application scenarios. In this paper, we introduce a novel blind inpainting method that automatically completes visual contents without specifying masks for target areas in an image. Our proposed model includes a mask-free reconstruction network and an object-aware discriminator. The reconstruction network consists of two branches that predict the corrupted regions with artificial markers and simultaneously recover the missing visual contents. The object-aware discriminator relies on the powerful recognition capabilities of the dense object detector to ensure that the markers of reconstructed images cannot be detected in any local regions. As a result, the reconstructed image can be close to the clean one as much as possible. Our proposed method is evaluated on different medical image datasets, covering multiple imaging modalities such as ultrasound (US), magnetic resonance imaging (MRI), and electron microscopy (EM), demonstrating that our method is effective and robust against various unknown missing region patterns.","created":"2023-03-27","meta":{"link":"http://arxiv.org/abs/2303.15124v1","tag":"medical-cv"}}
{"title":"Multi-contrast MRI Super-resolution via Implicit Neural Representations","abstract":"Clinical routine and retrospective cohorts commonly include multi-parametric Magnetic Resonance Imaging; however, they are mostly acquired in different anisotropic 2D views due to signal-to-noise-ratio and scan-time constraints. Thus acquired views suffer from poor out-of-plane resolution and affect downstream volumetric image analysis that typically requires isotropic 3D scans. Combining different views of multi-contrast scans into high-resolution isotropic 3D scans is challenging due to the lack of a large training cohort, which calls for a subject-specific framework.This work proposes a novel solution to this problem leveraging Implicit Neural Representations (INR). Our proposed INR jointly learns two different contrasts of complementary views in a continuous spatial function and benefits from exchanging anatomical information between them. Trained within minutes on a single commodity GPU, our model provides realistic super-resolution across different pairs of contrasts in our experiments with three datasets. Using Mutual Information (MI) as a metric, we find that our model converges to an optimum MI amongst sequences, achieving anatomically faithful reconstruction. Code is available at: https://github.com/jqmcginnis/multi_contrast_inr.","created":"2023-03-27","meta":{"link":"http://arxiv.org/abs/2303.15065v1","tag":"medical-cv"}}
{"title":"Conditional Score-Based Reconstructions for Multi-contrast MRI","abstract":"Magnetic resonance imaging (MRI) exam protocols consist of multiple contrast-weighted images of the same anatomy to emphasize different tissue properties. Due to the long acquisition times required to collect fully sampled k-space measurements, it is common to only collect a fraction of k-space for some, or all, of the scans and subsequently solve an inverse problem for each contrast to recover the desired image from sub-sampled measurements. Recently, there has been a push to further accelerate MRI exams using data-driven priors, and generative models in particular, to regularize the ill-posed inverse problem of image reconstruction. These methods have shown promising improvements over classical methods. However, many of the approaches neglect the multi-contrast nature of clinical MRI exams and treat each scan as an independent reconstruction. In this work we show that by learning a joint Bayesian prior over multi-contrast data with a score-based generative model we are able to leverage the underlying structure between multi-contrast images and thus improve image reconstruction fidelity over generative models that only reconstruct images of a single contrast.","created":"2023-03-26","meta":{"link":"http://arxiv.org/abs/2303.14795v1","tag":"medical-cv"}}
{"title":"CoLa-Diff: Conditional Latent Diffusion Model for Multi-Modal MRI Synthesis","abstract":"MRI synthesis promises to mitigate the challenge of missing MRI modality in clinical practice. Diffusion model has emerged as an effective technique for image synthesis by modelling complex and variable data distributions. However, most diffusion-based MRI synthesis models are using a single modality. As they operate in the original image domain, they are memory-intensive and less feasible for multi-modal synthesis. Moreover, they often fail to preserve the anatomical structure in MRI. Further, balancing the multiple conditions from multi-modal MRI inputs is crucial for multi-modal synthesis. Here, we propose the first diffusion-based multi-modality MRI synthesis model, namely Conditioned Latent Diffusion Model (CoLa-Diff). To reduce memory consumption, we design CoLa-Diff to operate in the latent space. We propose a novel network architecture, e.g., similar cooperative filtering, to solve the possible compression and noise in latent space. To better maintain the anatomical structure, brain region masks are introduced as the priors of density distributions to guide diffusion process. We further present auto-weight adaptation to employ multi-modal information effectively. Our experiments demonstrate that CoLa-Diff outperforms other state-of-the-art MRI synthesis methods, promising to serve as an effective tool for multi-modal MRI synthesis.","created":"2023-03-24","meta":{"link":"http://arxiv.org/abs/2303.14081v1","tag":"medical-cv"}}
{"title":"DisC-Diff: Disentangled Conditional Diffusion Model for Multi-Contrast MRI Super-Resolution","abstract":"Multi-contrast magnetic resonance imaging (MRI) is the most common management tool used to characterize neurological disorders based on brain tissue contrasts. However, acquiring high-resolution MRI scans is time-consuming and infeasible under specific conditions. Hence, multi-contrast super-resolution methods have been developed to improve the quality of low-resolution contrasts by leveraging complementary information from multi-contrast MRI. Current deep learning-based super-resolution methods have limitations in estimating restoration uncertainty and avoiding mode collapse. Although the diffusion model has emerged as a promising approach for image enhancement, capturing complex interactions between multiple conditions introduced by multi-contrast MRI super-resolution remains a challenge for clinical applications. In this paper, we propose a disentangled conditional diffusion model, DisC-Diff, for multi-contrast brain MRI super-resolution. It utilizes the sampling-based generation and simple objective function of diffusion models to estimate uncertainty in restorations effectively and ensure a stable optimization process. Moreover, DisC-Diff leverages a disentangled multi-stream network to fully exploit complementary information from multi-contrast MRI, improving model interpretation under multiple conditions of multi-contrast inputs. We validated the effectiveness of DisC-Diff on two datasets: the IXI dataset, which contains 578 normal brains, and a clinical dataset with 316 pathological brains. Our experimental results demonstrate that DisC-Diff outperforms other state-of-the-art methods both quantitatively and visually.","created":"2023-03-24","meta":{"link":"http://arxiv.org/abs/2303.13933v1","tag":"medical-cv"}}
{"title":"A Three-Player GAN for Super-Resolution in Magnetic Resonance Imaging","abstract":"Learning based single image super resolution (SISR) task is well investigated in 2D images. However, SISR for 3D Magnetics Resonance Images (MRI) is more challenging compared to 2D, mainly due to the increased number of neural network parameters, the larger memory requirement and the limited amount of available training data. Current SISR methods for 3D volumetric images are based on Generative Adversarial Networks (GANs), especially Wasserstein GANs due to their training stability. Other common architectures in the 2D domain, e.g. transformer models, require large amounts of training data and are therefore not suitable for the limited 3D data. However, Wasserstein GANs can be problematic because they may not converge to a global optimum and thus produce blurry results. Here, we propose a new method for 3D SR based on the GAN framework. Specifically, we use instance noise to balance the GAN training. Furthermore, we use a relativistic GAN loss function and an updating feature extractor during the training process. We show that our method produces highly accurate results. We also show that we need very few training samples. In particular, we need less than 30 samples instead of thousands of training samples that are typically required in previous studies. Finally, we show improved out-of-sample results produced by our model.","created":"2023-03-24","meta":{"link":"http://arxiv.org/abs/2303.13900v1","tag":"medical-cv"}}
{"title":"Few Shot Medical Image Segmentation with Cross Attention Transformer","abstract":"Medical image segmentation has made significant progress in recent years. Deep learning-based methods are recognized as data-hungry techniques, requiring large amounts of data with manual annotations. However, manual annotation is expensive in the field of medical image analysis, which requires domain-specific expertise. To address this challenge, few-shot learning has the potential to learn new classes from only a few examples. In this work, we propose a novel framework for few-shot medical image segmentation, termed CAT-Net, based on cross masked attention Transformer. Our proposed network mines the correlations between the support image and query image, limiting them to focus only on useful foreground information and boosting the representation capacity of both the support prototype and query features. We further design an iterative refinement framework that refines the query image segmentation iteratively and promotes the support feature in turn. We validated the proposed method on three public datasets: Abd-CT, Abd-MRI, and Card-MRI. Experimental results demonstrate the superior performance of our method compared to state-of-the-art methods and the effectiveness of each component. we will release the source codes of our method upon acceptance.","created":"2023-03-24","meta":{"link":"http://arxiv.org/abs/2303.13867v1","tag":"medical-cv"}}
{"title":"Bayesian Reconstruction of Magnetic Resonance Images using Gaussian Processes","abstract":"A central goal of modern magnetic resonance imaging (MRI) is to reduce the time required to produce high-quality images. Efforts have included hardware and software innovations such as parallel imaging, compressed sensing, and deep learning-based reconstruction. Here, we propose and demonstrate a Bayesian method to build statistical libraries of magnetic resonance (MR) images in k-space and use these libraries to identify optimal subsampling paths and reconstruction processes. Specifically, we compute a multivariate normal distribution based upon Gaussian processes using a publicly available library of T1-weighted images of healthy brains. We combine this library with physics-informed envelope functions to only retain meaningful correlations in k-space. This covariance function is then used to select a series of ring-shaped subsampling paths using Bayesian optimization such that they optimally explore space while remaining practically realizable in commercial MRI systems. Combining optimized subsampling paths found for a range of images, we compute a generalized sampling path that, when used for novel images, produces superlative structural similarity and error in comparison to previously reported reconstruction processes (i.e. 96.3% structural similarity and <0.003 normalized mean squared error from sampling only 12.5% of the k-space data). Finally, we use this reconstruction process on pathological data without retraining to show that reconstructed images are clinically useful for stroke identification.","created":"2023-03-23","meta":{"link":"http://arxiv.org/abs/2303.13700v1","tag":"medical-cv"}}
{"title":"Hemodynamic Effects of Entry and Exit Tear Size in Aortic Dissection Evaluated with In Vitro Magnetic Resonance Imaging and Fluid-Structure Interaction Simulation","abstract":"Understanding the complex interplay between morphologic and hemodynamic features in aortic dissection is critical for risk stratification and for the development of individualized therapy. This work evaluates the effects of entry and exit tear size on the hemodynamics in type B aortic dissection by comparing fluid-structure interaction (FSI) simulations with in vitro 4D-flow magnetic resonance imaging (MRI). A baseline patient-specific 3D-printed model and two variants with modified tear size (smaller entry tear, smaller exit tear) were embedded into a flow- and pressure-controlled setup to perform MRI as well as 12-point catheter-based pressure measurements. The same models defined the wall and fluid domains for FSI simulations, for which boundary conditions were matched with measured data. Results showed exceptionally well matched complex flow patterns between 4D-flow MRI and FSI simulations. Compared to the baseline model, false lumen flow volume decreased with either a smaller entry tear (-17.8 and -18.5 %, for FSI simulation and 4D-flow MRI, respectively) or smaller exit tear (-16.0 and -17.3 %). True to false lumen pressure difference (initially 11.0 and 7.9 mmHg, for FSI simulation and catheter-based pressure measurements, respectively) increased with a smaller entry tear (28.9 and 14.6 mmHg), and became negative with a smaller exit tear (-20.6 and -13.2 mmHg). This work establishes quantitative and qualitative effects of entry or exit tear size on hemodynamics in aortic dissection, with particularly notable impact observed on FL pressurization. FSI simulations demonstrate acceptable qualitative and quantitative agreement with flow imaging, supporting its deployment in clinical studies.","created":"2023-03-23","meta":{"link":"http://arxiv.org/abs/2303.13639v1","tag":"medical-cv"}}
{"title":"Medical diffusion on a budget: textual inversion for medical image generation","abstract":"Diffusion-based models for text-to-image generation have gained immense popularity due to recent advancements in efficiency, accessibility, and quality. Although it is becoming increasingly feasible to perform inference with these systems using consumer-grade GPUs, training them from scratch still requires access to large datasets and significant computational resources. In the case of medical image generation, the availability of large, publicly accessible datasets that include text reports is limited due to legal and ethical concerns. While training a diffusion model on a private dataset may address this issue, it is not always feasible for institutions lacking the necessary computational resources. This work demonstrates that pre-trained Stable Diffusion models, originally trained on natural images, can be adapted to various medical imaging modalities by training text embeddings with textual inversion. In this study, we conducted experiments using medical datasets comprising only 100 samples from three medical modalities. Embeddings were trained in a matter of hours, while still retaining diagnostic relevance in image generation. Experiments were designed to achieve several objectives. Firstly, we fine-tuned the training and inference processes of textual inversion, revealing that larger embeddings and more examples are required. Secondly, we validated our approach by demonstrating a 2\\% increase in the diagnostic accuracy (AUC) for detecting prostate cancer on MRI, which is a challenging multi-modal imaging modality, from 0.78 to 0.80. Thirdly, we performed simulations by interpolating between healthy and diseased states, combining multiple pathologies, and inpainting to show embedding flexibility and control of disease appearance. Finally, the embeddings trained in this study are small (less than 1 MB), which facilitates easy sharing of medical data with reduced privacy concerns.","created":"2023-03-23","meta":{"link":"http://arxiv.org/abs/2303.13430v1","tag":"medical-cv"}}
{"title":"MEDIMP: Medical Images and Prompts for renal transplant representation learning","abstract":"Renal transplantation emerges as the most effective solution for end-stage renal disease. Occurring from complex causes, a substantial risk of transplant chronic dysfunction persists and may lead to graft loss. Medical imaging plays a substantial role in renal transplant monitoring in clinical practice. However, graft supervision is multi-disciplinary, notably joining nephrology, urology, and radiology, while identifying robust biomarkers from such high-dimensional and complex data for prognosis is challenging. In this work, taking inspiration from the recent success of Large Language Models (LLMs), we propose MEDIMP -- Medical Images and Prompts -- a model to learn meaningful multi-modal representations of renal transplant Dynamic Contrast-Enhanced Magnetic Resonance Imaging (DCE MRI) by incorporating structural clinicobiological data after translating them into text prompts. MEDIMP is based on contrastive learning from joint text-image paired embeddings to perform this challenging task. Moreover, we propose a framework that generates medical prompts using automatic textual data augmentations from LLMs. Our goal is to learn meaningful manifolds of renal transplant DCE MRI, interesting for the prognosis of the transplant or patient status (2, 3, and 4 years after the transplant), fully exploiting the available multi-modal data in the most efficient way. Extensive experiments and comparisons with other renal transplant representation learning methods with limited data prove the effectiveness of MEDIMP in a relevant clinical setting, giving new directions toward medical prompts. Our code is available at https://github.com/leomlck/MEDIMP.","created":"2023-03-22","meta":{"link":"http://arxiv.org/abs/2303.12445v1","tag":"medical-cv"}}
{"title":"Automated deep learning segmentation of high-resolution 7 T ex vivo MRI for quantitative analysis of structure-pathology correlations in neurodegenerative diseases","abstract":"Ex vivo MRI of the brain provides remarkable advantages over in vivo MRI for visualizing and characterizing detailed neuroanatomy, and helps to link microscale histology studies with morphometric measurements. However, automated segmentation methods for brain mapping in ex vivo MRI are not well developed, primarily due to limited availability of labeled datasets, and heterogeneity in scanner hardware and acquisition protocols. In this work, we present a high resolution dataset of 37 ex vivo post-mortem human brain tissue specimens scanned on a 7T whole-body MRI scanner. We developed a deep learning pipeline to segment the cortical mantle by benchmarking the performance of nine deep neural architectures. We then segment the four subcortical structures: caudate, putamen, globus pallidus, and thalamus; white matter hyperintensities, and the normal appearing white matter. We show excellent generalizing capabilities across whole brain hemispheres in different specimens, and also on unseen images acquired at different magnetic field strengths and different imaging sequence. We then compute volumetric and localized cortical thickness measurements across key regions, and link them with semi-quantitative neuropathological ratings. Our code, containerized executables, and the processed datasets are publicly available at: https://github.com/Pulkit-Khandelwal/upenn-picsl-brain-ex-vivo.","created":"2023-03-21","meta":{"link":"http://arxiv.org/abs/2303.12237v1","tag":"medical-cv"}}
{"title":"Neural Pre-Processing: A Learning Framework for End-to-end Brain MRI Pre-processing","abstract":"Head MRI pre-processing involves converting raw images to an intensity-normalized, skull-stripped brain in a standard coordinate space. In this paper, we propose an end-to-end weakly supervised learning approach, called Neural Pre-processing (NPP), for solving all three sub-tasks simultaneously via a neural network, trained on a large dataset without individual sub-task supervision. Because the overall objective is highly under-constrained, we explicitly disentangle geometric-preserving intensity mapping (skull-stripping and intensity normalization) and spatial transformation (spatial normalization). Quantitative results show that our model outperforms state-of-the-art methods which tackle only a single sub-task. Our ablation experiments demonstrate the importance of the architecture design we chose for NPP. Furthermore, NPP affords the user the flexibility to control each of these tasks at inference time. The code and model are freely-available at \\url{https://github.com/Novestars/Neural-Pre-processing}.","created":"2023-03-21","meta":{"link":"http://arxiv.org/abs/2303.12148v1","tag":"medical-cv"}}
{"title":"GLADE: Gradient Loss Augmented Degradation Enhancement for Unpaired Super-Resolution of Anisotropic MRI","abstract":"We present a novel approach to synthesise high-resolution isotropic 3D abdominal MR images, from anisotropic 3D images in an unpaired fashion. Using a modified CycleGAN architecture with a gradient mapping loss, we leverage disjoint patches from the high-resolution (in-plane) data of an anisotropic volume to enforce the network generator to increase the resolution of the low-resolution (through-plane) slices. This will enable accelerated whole-abdomen scanning with high-resolution isotropic images within short breath-hold times.","created":"2023-03-21","meta":{"link":"http://arxiv.org/abs/2303.11831v1","tag":"medical-cv"}}
{"title":"Convolutions, Transformers, and their Ensembles for the Segmentation of Organs at Risk in Radiation Treatment of Cervical Cancer","abstract":"Segmentation of regions of interest in images of patients, is a crucial step in many medical procedures. Deep neural networks have proven to be particularly adept at this task. However, a key question is what type of deep neural network to choose, and whether making a certain choice makes a difference. In this work, we will answer this question for the task of segmentation of the Organs At Risk (OARs) in radiation treatment of cervical cancer (i.e., bladder, bowel, rectum, sigmoid) in Magnetic Resonance Imaging (MRI) scans. We compare several state-of-the-art models belonging to different architecture categories, as well as a few new models that combine aspects of several state-of-the-art models, to see if the results one gets are markedly different. We visualize model predictions, create all possible ensembles of models by averaging their output probabilities, and calculate the Dice Coefficient between predictions of models, in order to understand the differences between them and the potential of possible combinations. The results show that small improvements in metrics can be achieved by advancing and merging architectures, but the predictions of the models are quite similar (most models achieve on average more than 0.8 Dice Coefficient when compared to the outputs of other models). However, the results from the ensemble experiments indicate that the best results are obtained when the best performing models from every category of the architectures are combined.","created":"2023-03-20","meta":{"link":"http://arxiv.org/abs/2303.11501v1","tag":"medical-cv"}}
{"title":"Deep Learning in MRI-guided Radiation Therapy: A Systematic Review","abstract":"MRI-guided radiation therapy (MRgRT) offers a precise and adaptive approach to treatment planning. Deep learning applications which augment the capabilities of MRgRT are systematically reviewed. MRI-guided radiation therapy offers a precise, adaptive approach to treatment planning. Deep learning applications which augment the capabilities of MRgRT are systematically reviewed with emphasis placed on underlying methods. Studies are further categorized into the areas of segmentation, synthesis, radiomics, and real time MRI. Finally, clinical implications, current challenges, and future directions are discussed.","created":"2023-03-20","meta":{"link":"http://arxiv.org/abs/2303.11378v2","tag":"medical-cv"}}
{"title":"Deep Learning-Based Detection of Motion-Affected k-Space Lines for T2*-Weighted MRI","abstract":"T2*-weighted gradient echo MR imaging is strongly impacted by subject head motion due to motion-related changes in B0 inhomogeneities. Within the oxygenation-sensitive mqBOLD protocol, even mild motion during the acquisition of the T2*-weighted data propagates into errors in derived quantitative parameter maps. In order to correct these images without the need of repeated measurements, we propose to learn a classification of motion-affected k-space lines. To test this, we perform realistic motion simulations including motion-induced field inhomogeneity changes for supervised training. To detect the presence of motion in each phase encoding line, we train a convolutional neural network, leveraging the multi-echo information of the T2*-weighted images. The proposed network accurately detects motion-affected k-space lines for simulated displacements of $\\geq$ 0.5mm (accuracy on test set: 92.5%). Finally, we show example reconstructions where we include these classification labels as weights in the data consistency term of an iterative reconstruction procedure, opening up exciting opportunities of k-space line detection in combination with more powerful reconstruction methods.","created":"2023-03-20","meta":{"link":"http://arxiv.org/abs/2303.10987v1","tag":"medical-cv"}}
{"title":"DuDoRNeXt: A hybrid model for dual-domain undersampled MRI reconstruction","abstract":"Undersampled MRI reconstruction is crucial for accelerating clinical scanning procedures. Recent deep learning methods for MRI reconstruction adopt CNN or ViT as backbone, which lack in utilizing the complementary properties of CNN and ViT. In this paper, we propose DuDoRNeXt, whose backbone hybridizes CNN and ViT in an domain-specific, intra-stage way. Besides our hybrid vertical layout design, we introduce domain-specific modules for dual-domain reconstruction, namely image-domain parallel local detail enhancement and k-space global initialization. We evaluate different conventions of MRI reconstruction including image-domain, k-space-domain, and dual-domain reconstruction with a reference protocol on the IXI dataset and an in-house multi-contrast dataset. DuDoRNeXt achieves significant improvements over competing deep learning methods.","created":"2023-03-19","meta":{"link":"http://arxiv.org/abs/2303.10611v1","tag":"medical-cv"}}
{"title":"A Radiomics-Incorporated Deep Ensemble Learning Model for Multi-Parametric MRI-based Glioma Segmentation","abstract":"We developed a deep ensemble learning model with a radiomics spatial encoding execution for improved glioma segmentation accuracy using multi-parametric MRI (mp-MRI). This model was developed using 369 glioma patients with a 4-modality mp-MRI protocol: T1, contrast-enhanced T1 (T1-Ce), T2, and FLAIR. In each modality volume, a 3D sliding kernel was implemented across the brain to capture image heterogeneity: fifty-six radiomic features were extracted within the kernel, resulting in a 4th order tensor. Each radiomic feature can then be encoded as a 3D image volume, namely a radiomic feature map (RFM). PCA was employed for data dimension reduction and the first 4 PCs were selected. Four deep neural networks as sub-models following the U-Net architecture were trained for the segmenting of a region-of-interest (ROI): each sub-model utilizes the mp-MRI and 1 of the 4 PCs as a 5-channel input for a 2D execution. The 4 softmax probability results given by the U-net ensemble were superimposed and binarized by Otsu method as the segmentation result. Three ensemble models were trained to segment enhancing tumor (ET), tumor core (TC), and whole tumor (WT). The adopted radiomics spatial encoding execution enriches the image heterogeneity information that leads to the successful demonstration of the proposed deep ensemble model, which offers a new tool for mp-MRI based medical image segmentation.","created":"2023-03-19","meta":{"link":"http://arxiv.org/abs/2303.10533v1","tag":"medical-cv"}}
{"title":"Diff-UNet: A Diffusion Embedded Network for Volumetric Segmentation","abstract":"In recent years, Denoising Diffusion Models have demonstrated remarkable success in generating semantically valuable pixel-wise representations for image generative modeling. In this study, we propose a novel end-to-end framework, called Diff-UNet, for medical volumetric segmentation. Our approach integrates the diffusion model into a standard U-shaped architecture to extract semantic information from the input volume effectively, resulting in excellent pixel-level representations for medical volumetric segmentation. To enhance the robustness of the diffusion model's prediction results, we also introduce a Step-Uncertainty based Fusion (SUF) module during inference to combine the outputs of the diffusion models at each step. We evaluate our method on three datasets, including multimodal brain tumors in MRI, liver tumors, and multi-organ CT volumes, and demonstrate that Diff-UNet outperforms other state-of-the-art methods significantly. Our experimental results also indicate the universality and effectiveness of the proposed model. The proposed framework has the potential to facilitate the accurate diagnosis and treatment of medical conditions by enabling more precise segmentation of anatomical structures. The codes of Diff-UNet are available at https://github.com/ge-xing/Diff-UNet","created":"2023-03-18","meta":{"link":"http://arxiv.org/abs/2303.10326v1","tag":"medical-cv"}}
{"title":"MRIS: A Multi-modal Retrieval Approach for Image Synthesis on Diverse Modalities","abstract":"Multiple imaging modalities are often used for disease diagnosis, prediction, or population-based analyses. However, not all modalities might be available due to cost, different study designs, or changes in imaging technology. If the differences between the types of imaging are small, data harmonization approaches can be used; for larger changes, direct image synthesis approaches have been explored. In this paper, we develop an approach based on multi-modal metric learning to synthesize images of diverse modalities. We use metric learning via multi-modal image retrieval, resulting in embeddings that can relate images of different modalities. Given a large image database, the learned image embeddings allow us to use k-nearest neighbor (k-NN) regression for image synthesis. Our driving medical problem is knee osteoarthritis (KOA), but our developed method is general after proper image alignment. We test our approach by synthesizing cartilage thickness maps obtained from 3D magnetic resonance (MR) images using 2D radiographs. Our experiments show that the proposed method outperforms direct image synthesis and that the synthesized thickness maps retain information relevant to downstream tasks such as progression prediction and Kellgren-Lawrence grading (KLG). Our results suggest that retrieval approaches can be used to obtain high-quality and meaningful image synthesis results given large image databases.","created":"2023-03-17","meta":{"link":"http://arxiv.org/abs/2303.10249v1","tag":"medical-cv"}}
{"title":"Exploring contrast generalisation in deep learning-based brain MRI-to-CT synthesis","abstract":"Background: Synthetic computed tomography (sCT) has been proposed and increasingly clinically adopted to enable magnetic resonance imaging (MRI)-based radiotherapy. Deep learning (DL) has recently demonstrated the ability to generate accurate sCT from fixed MRI acquisitions. However, MRI protocols may change over time or differ between centres resulting in low-quality sCT due to poor model generalisation. Purpose: investigating domain randomisation (DR) to increase the generalisation of a DL model for brain sCT generation. Methods: CT and corresponding T1-weighted MRI with/without contrast, T2-weighted, and FLAIR MRI from 95 patients undergoing RT were collected, considering FLAIR the unseen sequence where to investigate generalisation. A ``Baseline'' generative adversarial network was trained with/without the FLAIR sequence to test how a model performs without DR. Image similarity and accuracy of sCT-based dose plans were assessed against CT to select the best-performing DR approach against the Baseline. Results: The Baseline model had the poorest performance on FLAIR, with mean absolute error (MAE)=106$\\pm$20.7 HU (mean$\\pm\\sigma$). Performance on FLAIR significantly improved for the DR model with MAE=99.0$\\pm$14.9 HU, but still inferior to the performance of the Baseline+FLAIR model (MAE=72.6$\\pm$10.1 HU). Similarly, an improvement in $\\gamma$-pass rate was obtained for DR vs Baseline. Conclusions: DR improved image similarity and dose accuracy on the unseen sequence compared to training only on acquired MRI. DR makes the model more robust, reducing the need for re-training when applying a model on sequences unseen and unavailable for retraining.","created":"2023-03-17","meta":{"link":"http://arxiv.org/abs/2303.10202v1","tag":"medical-cv"}}
{"title":"Reliability of Tumour Classification from Multi-Dimensional DCE-MRI Variables using Data Transformations","abstract":"Summary mean DCE-MRI variables show a clear dependency between signal and noise variance, which can be shown to reduce the effectiveness of difference assessments. Appropriate transformation of these variables supports statistically efficient and robust comparisons. The capabilities of DCE-MRI based descriptions of hepatic colorectal tumour classification was assessed, with regard to their potential for use as imaging biomarkers. Four DCE-MRI parameters were extracted from 102 selected tumour regions. A multi-dimensional statistical distance metric was assessed for the challenging task of comparing intra- and inter- subject tumour differences. Statistical errors were estimated using bootstrap resampling. The potential for tumour classification was assessed via Monte Carlo simulation. Transformation of the variables and fusion into a single chi-squared statistic shows that inter subject variation in hepatic tumours is measurable and significantly greater than intra-subject variation at the group level. However, reliability analysis shows that, at current noise levels, individual tumour assessment is not possible. Appropriate data transforms for DCE-MRI derived parameters produce an improvement in statistical sensitivity compared to conventional approaches. Reliability analysis shows, that even with data transformation, DCI-MRI variables do not currently facilitate good tumour discrimination and a doubling of SNR is needed to support non-trivial levels of classification","created":"2023-03-17","meta":{"link":"http://arxiv.org/abs/2303.10014v1","tag":"medical-cv"}}
{"title":"MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation","abstract":"There has been exploding interest in embracing Transformer-based architectures for medical image segmentation. However, the lack of large-scale annotated medical datasets make achieving performances equivalent to those in natural images challenging. Convolutional networks, in contrast, have higher inductive biases and consequently, are easily trainable to high performance. Recently, the ConvNeXt architecture attempted to modernize the standard ConvNet by mirroring Transformer blocks. In this work, we improve upon this to design a modernized and scalable convolutional architecture customized to challenges of data-scarce medical settings. We introduce MedNeXt, a Transformer-inspired large kernel segmentation network which introduces - 1) A fully ConvNeXt 3D Encoder-Decoder Network for medical image segmentation, 2) Residual ConvNeXt up and downsampling blocks to preserve semantic richness across scales, 3) A novel technique to iteratively increase kernel sizes by upsampling small kernel networks, to prevent performance saturation on limited medical data, 4) Compound scaling at multiple levels (depth, width, kernel size) of MedNeXt. This leads to state-of-the-art performance on 4 tasks on CT and MRI modalities and varying dataset sizes, representing a modernized deep architecture for medical image segmentation.","created":"2023-03-17","meta":{"link":"http://arxiv.org/abs/2303.09975v2","tag":"medical-cv"}}
{"title":"Fast 3D Volumetric Image Reconstruction from 2D MRI Slices by Parallel Processing","abstract":"Magnetic Resonance Imaging (MRI) is a technology for non-invasive imaging of anatomical features in detail. It can help in functional analysis of organs of a specimen but it is very costly. In this work, methods for (i) virtual three-dimensional (3D) reconstruction from a single sequence of two-dimensional (2D) slices of MR images of a human spine and brain along a single axis, and (ii) generation of missing inter-slice data are proposed. Our approach helps in preserving the edges, shape, size, as well as the internal tissue structures of the object being captured. The sequence of original 2D slices along a single axis is divided into smaller equal sub-parts which are then reconstructed using edge preserved kriging interpolation to predict the missing slice information. In order to speed up the process of interpolation, we have used multiprocessing by carrying out the initial interpolation on parallel cores. From the 3D matrix thus formed, shearlet transform is applied to estimate the edges considering the 2D blocks along the $Z$ axis, and to minimize the blurring effect using a proposed mean-median logic. Finally, for visualization, the sub-matrices are merged into a final 3D matrix. Next, the newly formed 3D matrix is split up into voxels and marching cubes method is applied to get the approximate 3D image for viewing. To the best of our knowledge it is a first of its kind approach based on kriging interpolation and multiprocessing for 3D reconstruction from 2D slices, and approximately 98.89\\% accuracy is achieved with respect to similarity metrics for image comparison. The time required for reconstruction has also been reduced by approximately 70\\% with multiprocessing even for a large input data set compared to that with single core processing.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09523v1","tag":"medical-cv"}}
{"title":"Knowledge Distillation for Adaptive MRI Prostate Segmentation Based on Limit-Trained Multi-Teacher Models","abstract":"With numerous medical tasks, the performance of deep models has recently experienced considerable improvements. These models are often adept learners. Yet, their intricate architectural design and high computational complexity make deploying them in clinical settings challenging, particularly with devices with limited resources. To deal with this issue, Knowledge Distillation (KD) has been proposed as a compression method and an acceleration technology. KD is an efficient learning strategy that can transfer knowledge from a burdensome model (i.e., teacher model) to a lightweight model (i.e., student model). Hence we can obtain a compact model with low parameters with preserving the teacher's performance. Therefore, we develop a KD-based deep model for prostate MRI segmentation in this work by combining features-based distillation with Kullback-Leibler divergence, Lovasz, and Dice losses. We further demonstrate its effectiveness by applying two compression procedures: 1) distilling knowledge to a student model from a single well-trained teacher, and 2) since most of the medical applications have a small dataset, we train multiple teachers that each one trained with a small set of images to learn an adaptive student model as close to the teachers as possible considering the desired accuracy and fast inference time. Extensive experiments were conducted on a public multi-site prostate tumor dataset, showing that the proposed adaptation KD strategy improves the dice similarity score by 9%, outperforming all tested well-established baseline models.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09494v1","tag":"medical-cv"}}
{"title":"A Novel Autoencoders-LSTM Model for Stroke Outcome Prediction using Multimodal MRI Data","abstract":"Patient outcome prediction is critical in management of ischemic stroke. In this paper, a novel machine learning model is proposed for stroke outcome prediction using multimodal Magnetic Resonance Imaging (MRI). The proposed model consists of two serial levels of Autoencoders (AEs), where different AEs at level 1 are used for learning unimodal features from different MRI modalities and a AE at level 2 is used to combine the unimodal features into compressed multimodal features. The sequences of multimodal features of a given patient are then used by an LSTM network for predicting outcome score. The proposed AE2-LSTM model is proved to be an effective approach for better addressing the multimodality and volumetric nature of MRI data. Experimental results show that the proposed AE2-LSTM outperforms the existing state-of-the art models by achieving highest AUC=0.71 and lowest MAE=0.34.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09484v1","tag":"medical-cv"}}
{"title":"3D Masked Autoencoding and Pseudo-labeling for Domain Adaptive Segmentation of Heterogeneous Infant Brain MRI","abstract":"Robust segmentation of infant brain MRI across multiple ages, modalities, and sites remains challenging due to the intrinsic heterogeneity caused by different MRI scanners, vendors, or acquisition sequences, as well as varying stages of neurodevelopment. To address this challenge, previous studies have explored domain adaptation (DA) algorithms from various perspectives, including feature alignment, entropy minimization, contrast synthesis (style transfer), and pseudo-labeling. This paper introduces a novel framework called MAPSeg (Masked Autoencoding and Pseudo-labelling Segmentation) to address the challenges of cross-age, cross-modality, and cross-site segmentation of subcortical regions in infant brain MRI. Utilizing 3D masked autoencoding as well as masked pseudo-labeling, the model is able to jointly learn from labeled source domain data and unlabeled target domain data. We evaluated our framework on expert-annotated datasets acquired from different ages and sites. MAPSeg consistently outperformed other methods, including previous state-of-the-art supervised baselines, domain generalization, and domain adaptation frameworks in segmenting subcortical regions regardless of age, modality, or acquisition site. The code and pretrained encoder will be publicly available at https://github.com/XuzheZ/MAPSeg","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09373v1","tag":"medical-cv"}}
{"title":"Portable MRI for major sporting events -- a case study on the MotoGP World Championship","abstract":"The goal of this work is to showcase the clinical value that portable MRI can provide in crowded events and major sports competitions. We temporarily installed a low-field and low-cost portable MRI system for extremity imaging in the medical facilities of the Ricardo Tormo Motor Racing Circuit during the four days of the Motorcycle Grand Prix held in Valencia (Spain), which closed the 2022 season of the MotoGP. During this time, we scanned 14 subjects, running a total of 21 protocols for wrist, knee and ankle imaging. Each protocol included a minimum of one T1-weighted 3D-RARE sequence for general anatomical information, and one 3D-STIR sequence to highlight fluid accumulation and inflammation. The circuit medical staff were able to visualize a number of lesions and conditions in the low-field reconstructions, including gonarthrosis, effusion, or Haglund's syndrome, as well as metallic implants and tissue changes due to surgical interventions. Out of eight low-field acquisitions on previously diagnosed lesions, only two (a meniscus tear and a Baker cyst) were not detected by the experts that evaluated our images. The main highlight was that a low-field MRI scan on a subject reporting pain in a wrist revealed a traumatic arthritis which an X-ray radiograph and visual inspection had missed. We have operated in a scenario where high-field MRI is unlikely to play a role but where a low-field system can lead to improved medical attention. In the case reported here, system transport, installation in the circuit facilities and calibration were all uncomplicated. The images presented to the medical staff were mostly unprocessed and there is thus room for improvement. In conclusion, this work supports the claim that low-field MRI can likely provide added value whenever concepts such as accessibility, portability and low-cost outweigh exquisite detail in images.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09264v2","tag":"medical-cv"}}
{"title":"Fiber Tract Shape Measures Inform Prediction of Non-Imaging Phenotypes","abstract":"Neuroimaging measures of the brain's white matter connections can enable the prediction of non-imaging phenotypes, such as demographic and cognitive measures. Existing works have investigated traditional microstructure and connectivity measures from diffusion MRI tractography, without considering the shape of the connections reconstructed by tractography. In this paper, we investigate the potential of fiber tract shape features for predicting non-imaging phenotypes, both individually and in combination with traditional features. We focus on three basic shape features: length, diameter, and elongation. Two different prediction methods are used, including a traditional regression method and a deep-learning-based prediction method. Experiments use an efficient two-stage fusion strategy for prediction using microstructure, connectivity, and shape measures. To reduce predictive bias due to brain size, normalized shape features are also investigated. Experimental results on the Human Connectome Project (HCP) young adult dataset (n=1065) demonstrate that individual shape features are predictive of non-imaging phenotypes. When combined with microstructure and connectivity features, shape features significantly improve performance for predicting the cognitive score TPVT (NIH Toolbox picture vocabulary test). Overall, this study demonstrates that the shape of fiber tracts contains useful information for the description and study of the living human brain using machine learning.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09124v1","tag":"medical-cv"}}
{"title":"Translating Radiology Reports into Plain Language using ChatGPT and GPT-4 with Prompt Learning: Promising Results, Limitations, and Potential","abstract":"The large language model called ChatGPT has drawn extensively attention because of its human-like expression and reasoning abilities. In this study, we investigate the feasibility of using ChatGPT in experiments on using ChatGPT to translate radiology reports into plain language for patients and healthcare providers so that they are educated for improved healthcare. Radiology reports from 62 low-dose chest CT lung cancer screening scans and 76 brain MRI metastases screening scans were collected in the first half of February for this study. According to the evaluation by radiologists, ChatGPT can successfully translate radiology reports into plain language with an average score of 4.27 in the five-point system with 0.08 places of information missing and 0.07 places of misinformation. In terms of the suggestions provided by ChatGPT, they are general relevant such as keeping following-up with doctors and closely monitoring any symptoms, and for about 37% of 138 cases in total ChatGPT offers specific suggestions based on findings in the report. ChatGPT also presents some randomness in its responses with occasionally over-simplified or neglected information, which can be mitigated using a more detailed prompt. Furthermore, ChatGPT results are compared with a newly released large model GPT-4, showing that GPT-4 can significantly improve the quality of translated reports. Our results show that it is feasible to utilize large language models in clinical education, and further efforts are needed to address limitations and maximize their potential.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09038v3","tag":"medical-cv"}}
{"title":"Exploring the Power of Generative Deep Learning for Image-to-Image Translation and MRI Reconstruction: A Cross-Domain Review","abstract":"Deep learning has become a prominent computational modeling tool in the areas of computer vision and image processing in recent years. This research comprehensively analyzes the different deep-learning methods used for image-to-image translation and reconstruction in the natural and medical imaging domains. We examine the famous deep learning frameworks, such as convolutional neural networks and generative adversarial networks, and their variants, delving into the fundamental principles and difficulties of each. In the field of natural computer vision, we investigate the development and extension of various deep-learning generative models. In comparison, we investigate the possible applications of deep learning to generative medical imaging problems, including medical image translation, MRI reconstruction, and multi-contrast MRI synthesis. This thorough review provides scholars and practitioners in the areas of generative computer vision and medical imaging with useful insights for summarizing past works and getting insight into future research paths.","created":"2023-03-16","meta":{"link":"http://arxiv.org/abs/2303.09012v1","tag":"medical-cv"}}
{"title":"Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly Detection","abstract":"Early and accurate disease detection is crucial for patient management and successful treatment outcomes. However, the automatic identification of anomalies in medical images can be challenging. Conventional methods rely on large labeled datasets which are difficult to obtain. To overcome these limitations, we introduce a novel unsupervised approach, called PHANES (Pseudo Healthy generative networks for ANomaly Segmentation). Our method has the capability of reversing anomalies, i.e., preserving healthy tissue and replacing anomalous regions with pseudo-healthy (PH) reconstructions. Unlike recent diffusion models, our method does not rely on a learned noise distribution nor does it introduce random alterations to the entire image. Instead, we use latent generative networks to create masks around possible anomalies, which are refined using inpainting generative networks. We demonstrate the effectiveness of PHANES in detecting stroke lesions in T1w brain MRI datasets and show significant improvements over state-of-the-art (SOTA) methods. We believe that our proposed framework will open new avenues for interpretable, fast, and accurate anomaly segmentation with the potential to support various clinical-oriented downstream tasks.","created":"2023-03-15","meta":{"link":"http://arxiv.org/abs/2303.08452v1","tag":"medical-cv"}}
{"title":"Improving 3D Imaging with Pre-Trained Perpendicular 2D Diffusion Models","abstract":"Diffusion models have become a popular approach for image generation and reconstruction due to their numerous advantages. However, most diffusion-based inverse problem-solving methods only deal with 2D images, and even recently published 3D methods do not fully exploit the 3D distribution prior. To address this, we propose a novel approach using two perpendicular pre-trained 2D diffusion models to solve the 3D inverse problem. By modeling the 3D data distribution as a product of 2D distributions sliced in different directions, our method effectively addresses the curse of dimensionality. Our experimental results demonstrate that our method is highly effective for 3D medical image reconstruction tasks, including MRI Z-axis super-resolution, compressed sensing MRI, and sparse-view CT. Our method can generate high-quality voxel volumes suitable for medical applications.","created":"2023-03-15","meta":{"link":"http://arxiv.org/abs/2303.08440v1","tag":"medical-cv"}}
{"title":"Few-Shot Classification of Autism Spectrum Disorder using Site-Agnostic Meta-Learning and Brain MRI","abstract":"For machine learning applications in medical imaging, the availability of training data is often limited, which hampers the design of radiological classifiers for subtle conditions such as autism spectrum disorder (ASD). Transfer learning is one method to counter this problem of low training data regimes. Here we explore the use of meta-learning for very low data regimes in the context of having prior data from multiple sites - an approach we term site-agnostic meta-learning. Inspired by the effectiveness of meta-learning for optimizing a model across multiple tasks, here we propose a framework to adapt it to learn across multiple sites. We tested our meta-learning model for classifying ASD versus typically developing controls in 2,201 T1-weighted (T1-w) MRI scans collected from 38 imaging sites as part of Autism Brain Imaging Data Exchange (ABIDE) [age: 5.2-64.0 years]. The method was trained to find a good initialization state for our model that can quickly adapt to data from new unseen sites by fine-tuning on the limited data that is available. The proposed method achieved an ROC-AUC=0.857 on 370 scans from 7 unseen sites in ABIDE using a few-shot setting of 2-way 20-shot i.e., 20 training samples per site. Our results outperformed a transfer learning baseline by generalizing across a wider range of sites as well as other related prior work. We also tested our model in a zero-shot setting on an independent test site without any additional fine-tuning. Our experiments show the promise of the proposed site-agnostic meta-learning framework for challenging neuroimaging tasks involving multi-site heterogeneity with limited availability of training data.","created":"2023-03-14","meta":{"link":"http://arxiv.org/abs/2303.08224v1","tag":"medical-cv"}}
{"title":"Efficiently Training Vision Transformers on Structural MRI Scans for Alzheimer's Disease Detection","abstract":"Neuroimaging of large populations is valuable to identify factors that promote or resist brain disease, and to assist diagnosis, subtyping, and prognosis. Data-driven models such as convolutional neural networks (CNNs) have increasingly been applied to brain images to perform diagnostic and prognostic tasks by learning robust features. Vision transformers (ViT) - a new class of deep learning architectures - have emerged in recent years as an alternative to CNNs for several computer vision applications. Here we tested variants of the ViT architecture for a range of desired neuroimaging downstream tasks based on difficulty, in this case for sex and Alzheimer's disease (AD) classification based on 3D brain MRI. In our experiments, two vision transformer architecture variants achieved an AUC of 0.987 for sex and 0.892 for AD classification, respectively. We independently evaluated our models on data from two benchmark AD datasets. We achieved a performance boost of 5% and 9-10% upon fine-tuning vision transformer models pre-trained on synthetic (generated by a latent diffusion model) and real MRI scans, respectively. Our main contributions include testing the effects of different ViT training strategies including pre-training, data augmentation and learning rate warm-ups followed by annealing, as pertaining to the neuroimaging domain. These techniques are essential for training ViT-like models for neuroimaging applications where training data is usually limited. We also analyzed the effect of the amount of training data utilized on the test-time performance of the ViT via data-model scaling curves.","created":"2023-03-14","meta":{"link":"http://arxiv.org/abs/2303.08216v1","tag":"medical-cv"}}
{"title":"Freehand 2D Ultrasound Probe Calibration for Image Fusion with 3D MRI/CT","abstract":"The aim of this work is to implement a simple freehand ultrasound (US) probe calibration technique. This will enable us to visualize US image data during surgical procedures using augmented reality. The performance of the system was evaluated with different experiments using two different pose estimation techniques. A near-millimeter accuracy can be achieved with the proposed approach. The developed system is cost-effective, simple and rapid with low calibration error","created":"2023-03-14","meta":{"link":"http://arxiv.org/abs/2303.07714v1","tag":"medical-cv"}}
{"title":"An optimal transport regularized model to image reconstruction problems","abstract":"Optimal transport problem has gained much attention in image processing field, such as computer vision, image interpolation and medical image registration. In this paper, we incorporate optimal transport into linear inverse problems as a regularization technique. We establish a new variational model based on Benamou-Brenier energy to regularize the evolution path from a template to latent image dynamically. The initial state of the continuity equation can be regarded as a template, which can provide priors for the reconstructed images. Also, we analyze the existence of solutions of such variational problem in Radon measure space. Moreover, the first-order primal-dual algorithm is constructed for solving this general imaging problem in a special grid strategy. Finally, numerical experiments for undersampled MRI reconstruction are presented which show that our proposed model can recover images well with high quality and structure preservation.","created":"2023-03-14","meta":{"link":"http://arxiv.org/abs/2303.07713v1","tag":"medical-cv"}}
{"title":"Uncertainty-weighted Multi-tasking for $T_{1\u03c1}$ and T$_2$ Mapping in the Liver with Self-supervised Learning","abstract":"Multi-parametric mapping of MRI relaxations in liver has the potential of revealing pathological information of the liver. A self-supervised learning based multi-parametric mapping method is proposed to map T$T_{1\\rho}$ and T$_2$ simultaneously, by utilising the relaxation constraint in the learning process. Data noise of different mapping tasks is utilised to make the model uncertainty-aware, which adaptively weight different mapping tasks during learning. The method was examined on a dataset of 51 patients with non-alcoholic fatter liver disease. Results showed that the proposed method can produce comparable parametric maps to the traditional multi-contrast pixel wise fitting method, with a reduced number of images and less computation time. The uncertainty weighting also improves the model performance. It has the potential of accelerating MRI quantitative imaging.","created":"2023-03-14","meta":{"link":"http://arxiv.org/abs/2303.07623v1","tag":"medical-cv"}}
{"title":"SMUG: Towards robust MRI reconstruction by smoothed unrolling","abstract":"Although deep learning (DL) has gained much popularity for accelerated magnetic resonance imaging (MRI), recent studies have shown that DL-based MRI reconstruction models could be oversensitive to tiny input perturbations (that are called 'adversarial perturbations'), which cause unstable, low-quality reconstructed images. This raises the question of how to design robust DL methods for MRI reconstruction. To address this problem, we propose a novel image reconstruction framework, termed SMOOTHED UNROLLING (SMUG), which advances a deep unrolling-based MRI reconstruction model using a randomized smoothing (RS)-based robust learning operation. RS, which improves the tolerance of a model against input noises, has been widely used in the design of adversarial defense for image classification. Yet, we find that the conventional design that applies RS to the entire DL process is ineffective for MRI reconstruction. We show that SMUG addresses the above issue by customizing the RS operation based on the unrolling architecture of the DL-based MRI reconstruction model. Compared to the vanilla RS approach and several variants of SMUG, we show that SMUG improves the robustness of MRI reconstruction with respect to a diverse set of perturbation sources, including perturbations to the input measurements, different measurement sampling rates, and different unrolling steps. Code for SMUG will be available at https://github.com/LGM70/SMUG.","created":"2023-03-14","meta":{"link":"http://arxiv.org/abs/2303.12735v1","tag":"medical-cv"}}
{"title":"Tensor-based Multimodal Learning for Prediction of Pulmonary Arterial Wedge Pressure from Cardiac MRI","abstract":"Heart failure is a serious and life-threatening condition that can lead to elevated pressure in the left ventricle. Pulmonary Arterial Wedge Pressure (PAWP) is an important surrogate marker indicating high pressure in the left ventricle. PAWP is determined by Right Heart Catheterization (RHC) but it is an invasive procedure. A non-invasive method is useful in quickly identifying high-risk patients from a large population. In this work, we develop a tensor learning-based pipeline for identifying PAWP from multimodal cardiac Magnetic Resonance Imaging (MRI). This pipeline extracts spatial and temporal features from high-dimensional scans. For quality control, we incorporate an epistemic uncertainty-based binning strategy to identify poor-quality training samples. To improve the performance, we learn complementary information by integrating features from multimodal data: cardiac MRI with short-axis and four-chamber views, and Electronic Health Records. The experimental analysis on a large cohort of $1346$ subjects who underwent the RHC procedure for PAWP estimation indicates that the proposed pipeline has a diagnostic value and can produce promising performance with significant improvement over the baseline in clinical practice (i.e., $\\Delta$AUC $=0.10$, $\\Delta$Accuracy $=0.06$, and $\\Delta$MCC $=0.39$). The decision curve analysis further confirms the clinical utility of our method.","created":"2023-03-14","meta":{"link":"http://arxiv.org/abs/2303.07540v1","tag":"medical-cv"}}
{"title":"SuperMask: Generating High-resolution object masks from multi-view, unaligned low-resolution MRIs","abstract":"Three-dimensional segmentation in magnetic resonance images (MRI), which reflects the true shape of the objects, is challenging since high-resolution isotropic MRIs are rare and typical MRIs are anisotropic, with the out-of-plane dimension having a much lower resolution. A potential remedy to this issue lies in the fact that often multiple sequences are acquired on different planes. However, in practice, these sequences are not orthogonal to each other, limiting the applicability of many previous solutions to reconstruct higher-resolution images from multiple lower-resolution ones. We propose a weakly-supervised deep learning-based solution to generating high-resolution masks from multiple low-resolution images. Our method combines segmentation and unsupervised registration networks by introducing two new regularizations to make registration and segmentation reinforce each other. Finally, we introduce a multi-view fusion method to generate high-resolution target object masks. The experimental results on two datasets show the superiority of our methods. Importantly, the advantage of not using high-resolution images in the training process makes our method applicable to a wide variety of MRI segmentation tasks.","created":"2023-03-13","meta":{"link":"http://arxiv.org/abs/2303.07517v1","tag":"medical-cv"}}
{"title":"Towards a unified picture of polarization transfer -- equivalence of DNP and PHIP","abstract":"Hyperpolarization, the elevation of nuclear spin polarization beyond its value in thermal equilibrium, is a leading method for enhancing the sensitivity of nuclear magnetic resonance (NMR) and magnetic resonance imaging (MRI). In this approach, a readily available source of higher spin order, either from electron spins in dynamic nuclear polarization (DNP) or singlet states in hydrogen for PHIP / SABRE, is placed in close contact with the nuclear spin of interest to allow for efficient transfer of the spin order. However, the physics of polarization transfer from electron spins and nuclear singlet states appears to differ substantially due to the marked difference in energy scale between electron and nuclear spins and due to the different physical origin and strength of the interaction with the target nuclei. Nevertheless, utilizing a pseudo-spin formalism we show that a critical regime of PHIP / SABRE, namely the low-field polarization transfer regime can be mapped to an equivalent system, where the heteronuclear target spin takes a role analogous to that of the DNP-electron and the pseudospin of the parahydrogen takes the role of the nuclear spin in DNP. Using this equivalence we provide a detailed mapping between some of the most important polarization transfer sequences in PHIP and DNP and we show how one can transfer sequences that have been developed in one field to the other. Building on this mapping we foresee new insights generated and potentially a strong cross-pollination between polarization sequence developers in the two fields.","created":"2023-03-13","meta":{"link":"http://arxiv.org/abs/2303.07478v1","tag":"medical-cv"}}
{"title":"End-to-end Deformable Attention Graph Neural Network for Single-view Liver Mesh Reconstruction","abstract":"Intensity modulated radiotherapy (IMRT) is one of the most common modalities for treating cancer patients. One of the biggest challenges is precise treatment delivery that accounts for varying motion patterns originating from free-breathing. Currently, image-guided solutions for IMRT is limited to 2D guidance due to the complexity of 3D tracking solutions. We propose a novel end-to-end attention graph neural network model that generates in real-time a triangular shape of the liver based on a reference segmentation obtained at the preoperative phase and a 2D MRI coronal slice taken during the treatment. Graph neural networks work directly with graph data and can capture hidden patterns in non-Euclidean domains. Furthermore, contrary to existing methods, it produces the shape entirely in a mesh structure and correctly infers mesh shape and position based on a surrogate image. We define two on-the-fly approaches to make the correspondence of liver mesh vertices with 2D images obtained during treatment. Furthermore, we introduce a novel task-specific identity loss to constrain the deformation of the liver in the graph neural network to limit phenomenons such as flying vertices or mesh holes. The proposed method achieves results with an average error of 3.06 +- 0.7 mm and Chamfer distance with L2 norm of 63.14 +- 27.28.","created":"2023-03-13","meta":{"link":"http://arxiv.org/abs/2303.07432v1","tag":"medical-cv"}}
{"title":"Multi PILOT: Learned Feasible Multiple Acquisition Trajectories for Dynamic MRI","abstract":"Dynamic Magnetic Resonance Imaging (MRI) is known to be a powerful and reliable technique for the dynamic imaging of internal organs and tissues, making it a leading diagnostic tool. A major difficulty in using MRI in this setting is the relatively long acquisition time (and, hence, increased cost) required for imaging in high spatio-temporal resolution, leading to the appearance of related motion artifacts and decrease in resolution. Compressed Sensing (CS) techniques have become a common tool to reduce MRI acquisition time by subsampling images in the k-space according to some acquisition trajectory. Several studies have particularly focused on applying deep learning techniques to learn these acquisition trajectories in order to attain better image reconstruction, rather than using some predefined set of trajectories. To the best of our knowledge, learning acquisition trajectories has been only explored in the context of static MRI. In this study, we consider acquisition trajectory learning in the dynamic imaging setting. We design an end-to-end pipeline for the joint optimization of multiple per-frame acquisition trajectories along with a reconstruction neural network, and demonstrate improved image reconstruction quality in shorter acquisition times. The code for reproducing all experiments is accessible at https://github.com/tamirshor7/MultiPILOT.","created":"2023-03-13","meta":{"link":"http://arxiv.org/abs/2303.07150v2","tag":"medical-cv"}}
{"title":"NeurEPDiff: Neural Operators to Predict Geodesics in Deformation Spaces","abstract":"This paper presents NeurEPDiff, a novel network to fast predict the geodesics in deformation spaces generated by a well known Euler-Poincar\\'e differential equation (EPDiff). To achieve this, we develop a neural operator that for the first time learns the evolving trajectory of geodesic deformations parameterized in the tangent space of diffeomorphisms(a.k.a velocity fields). In contrast to previous methods that purely fit the training images, our proposed NeurEPDiff learns a nonlinear mapping function between the time-dependent velocity fields. A composition of integral operators and smooth activation functions is formulated in each layer of NeurEPDiff to effectively approximate such mappings. The fact that NeurEPDiff is able to rapidly provide the numerical solution of EPDiff (given any initial condition) results in a significantly reduced computational cost of geodesic shooting of diffeomorphisms in a high-dimensional image space. Additionally, the properties of discretiztion/resolution-invariant of NeurEPDiff make its performance generalizable to multiple image resolutions after being trained offline. We demonstrate the effectiveness of NeurEPDiff in registering two image datasets: 2D synthetic data and 3D brain resonance imaging (MRI). The registration accuracy and computational efficiency are compared with the state-of-the-art diffeomophic registration algorithms with geodesic shooting.","created":"2023-03-13","meta":{"link":"http://arxiv.org/abs/2303.07115v1","tag":"medical-cv"}}
{"title":"Weakly Unsupervised Domain Adaptation for Vestibular Schwannoma Segmentation","abstract":"Vestibular schwannoma (VS) is a non-cancerous tumor located next to the ear that can cause hearing loss. Most brain MRI images acquired from patients are contrast-enhanced T1 (ceT1), with a growing interest in high-resolution T2 images (hrT2) to replace ceT1, which involves the use of a contrast agent. As hrT2 images are currently scarce, it is less likely to train robust machine learning models to segment VS or other brain structures. In this work, we propose a weakly supervised machine learning approach that learns from only ceT1 scans and adapts to segment two structures from hrT2 scans: the VS and the cochlea from the crossMoDA dataset. Our model 1) generates fake hrT2 scans from ceT1 images and segmentation masks, 2) is trained using the fake hrT2 scans, 3) predicts the augmented real hrT2 scans, and 4) is retrained again using both the fake and real hrT2. The final result of this model has been computed on an unseen testing dataset provided by the 2022 crossMoDA challenge organizers. The mean dice score and average symmetric surface distance (ASSD) are 0.78 and 0.46, respectively. The predicted segmentation masks achieved a dice score of 0.83 and an ASSD of 0.56 on the VS, and a dice score of 0.74 and an ASSD of 0.35 on the cochleas.","created":"2023-03-13","meta":{"link":"http://arxiv.org/abs/2303.07093v1","tag":"medical-cv"}}
{"title":"MLP-SRGAN: A Single-Dimension Super Resolution GAN using MLP-Mixer","abstract":"We propose a novel architecture called MLP-SRGAN, which is a single-dimension Super Resolution Generative Adversarial Network (SRGAN) that utilizes Multi-Layer Perceptron Mixers (MLP-Mixers) along with convolutional layers to upsample in the slice direction. MLP-SRGAN is trained and validated using high resolution (HR) FLAIR MRI from the MSSEG2 challenge dataset. The method was applied to three multicentre FLAIR datasets (CAIN, ADNI, CCNA) of images with low spatial resolution in the slice dimension to examine performance on held-out (unseen) clinical data. Upsampled results are compared to several state-of-the-art SR networks. For images with high resolution (HR) ground truths, peak-signal-to-noise-ratio (PSNR) and structural similarity index (SSIM) are used to measure upsampling performance. Several new structural, no-reference image quality metrics were proposed to quantify sharpness (edge strength), noise (entropy), and blurriness (low frequency information) in the absence of ground truths. Results show MLP-SRGAN results in sharper edges, less blurring, preserves more texture and fine-anatomical detail, with fewer parameters, faster training/evaluation time, and smaller model size than existing methods. Code for MLP-SRGAN training and inference, data generators, models and no-reference image quality metrics will be available at https://github.com/IAMLAB-Ryerson/MLP-SRGAN.","created":"2023-03-11","meta":{"link":"http://arxiv.org/abs/2303.06298v1","tag":"medical-cv"}}
{"title":"3D Masked Autoencoders with Application to Anomaly Detection in Non-Contrast Enhanced Breast MRI","abstract":"Self-supervised models allow (pre-)training on unlabeled data and therefore have the potential to overcome the need for large annotated cohorts. One leading self-supervised model is the masked autoencoder (MAE) which was developed on natural imaging data. The MAE is masking out a high fraction of visual transformer (ViT) input patches, to then recover the uncorrupted images as a pretraining task. In this work, we extend MAE to perform anomaly detection on breast magnetic resonance imaging (MRI). This new model, coined masked autoencoder for medical imaging (MAEMI) is trained on two non-contrast enhanced MRI sequences, aiming at lesion detection without the need for intravenous injection of contrast media and temporal image acquisition. During training, only non-cancerous images are presented to the model, with the purpose of localizing anomalous tumor regions during test time. We use a public dataset for model development. Performance of the architecture is evaluated in reference to subtraction images created from dynamic contrast enhanced (DCE)-MRI.","created":"2023-03-10","meta":{"link":"http://arxiv.org/abs/2303.05861v1","tag":"medical-cv"}}
{"title":"Self-Supervised CSF Inpainting with Synthetic Atrophy for Improved Accuracy Validation of Cortical Surface Analyses","abstract":"Accuracy validation of cortical thickness measurement is a difficult problem due to the lack of ground truth data. To address this need, many methods have been developed to synthetically induce gray matter (GM) atrophy in an MRI via deformable registration, creating a set of images with known changes in cortical thickness. However, these methods often cause blurring in atrophied regions, and cannot simulate realistic atrophy within deep sulci where cerebrospinal fluid (CSF) is obscured or absent. In this paper, we present a solution using a self-supervised inpainting model to generate CSF in these regions and create images with more plausible GM/CSF boundaries. Specifically, we introduce a novel, 3D GAN model that incorporates patch-based dropout training, edge map priors, and sinusoidal positional encoding, all of which are established methods previously limited to 2D domains. We show that our framework significantly improves the quality of the resulting synthetic images and is adaptable to unseen data with fine-tuning. We also demonstrate that our resulting dataset can be employed for accuracy validation of cortical segmentation and thickness measurement.","created":"2023-03-10","meta":{"link":"http://arxiv.org/abs/2303.05777v1","tag":"medical-cv"}}
{"title":"Fast Diffusion Sampler for Inverse Problems by Geometric Decomposition","abstract":"Diffusion models have shown exceptional performance in solving inverse problems. However, one major limitation is the slow inference time. While faster diffusion samplers have been developed for unconditional sampling, there has been limited research on conditional sampling in the context of inverse problems. In this study, we propose a novel and efficient diffusion sampling strategy that employs the geometric decomposition of diffusion sampling. Specifically, we discover that the samples generated from diffusion models can be decomposed into two orthogonal components: a ``denoised\" component obtained by projecting the sample onto the clean data manifold, and a ``noise\" component that induces a transition to the next lower-level noisy manifold with the addition of stochastic noise. Furthermore, we prove that, under some conditions on the clean data manifold, the conjugate gradient update for imposing conditioning from the denoised signal belongs to the clean manifold, resulting in a much faster and more accurate diffusion sampling. Our method is applicable regardless of the parameterization and setting (i.e., VE, VP). Notably, we achieve state-of-the-art reconstruction quality on challenging real-world medical inverse imaging problems, including multi-coil MRI reconstruction and 3D CT reconstruction. Moreover, our proposed method achieves more than 80 times faster inference time than the previous state-of-the-art method.","created":"2023-03-10","meta":{"link":"http://arxiv.org/abs/2303.05754v1","tag":"medical-cv"}}
{"title":"Generalized Diffusion MRI Denoising and Super-Resolution using Swin Transformers","abstract":"Diffusion MRI is a non-invasive, in-vivo medical imaging method able to map tissue microstructure and structural connectivity of the human brain, as well as detect changes, such as brain development and injury, not visible by other clinical neuroimaging techniques. However, acquiring high signal-to-noise ratio (SNR) datasets with high angular and spatial sampling requires prohibitively long scan times, limiting usage in many important clinical settings, especially children, the elderly, and emergency patients with acute neurological disorders who might not be able to cooperate with the MRI scan without conscious sedation or general anesthesia. Here, we propose to use a Swin UNEt TRansformers (Swin UNETR) model, trained on augmented Human Connectome Project (HCP) data and conditioned on registered T1 scans, to perform generalized denoising and super-resolution of diffusion MRI invariant to acquisition parameters, patient populations, scanners, and sites. We qualitatively demonstrate super-resolution with artificially downsampled HCP data in normal adult volunteers. Our experiments on two other unrelated datasets, one of children with neurodevelopmental disorders and one of traumatic brain injury patients, show that our method demonstrates superior denoising despite wide data distribution shifts. Further improvement can be achieved via finetuning with just one additional subject. We apply our model to diffusion tensor (2nd order spherical harmonic) and higher-order spherical harmonic coefficient estimation and show results superior to current state-of-the-art methods. Our method can be used out-of-the-box or minimally finetuned to denoise and super-resolve a wide variety of diffusion MRI datasets. The code and model are publicly available at https://github.com/ucsfncl/dmri-swin.","created":"2023-03-10","meta":{"link":"http://arxiv.org/abs/2303.05686v1","tag":"medical-cv"}}
{"title":"Resolving quantitative MRI model degeneracy with machine learning via training data distribution design","abstract":"Quantitative MRI (qMRI) aims to map tissue properties non-invasively via models that relate these unknown quantities to measured MRI signals. Estimating these unknowns, which has traditionally required model fitting - an often iterative procedure, can now be done with one-shot machine learning (ML) approaches. Such parameter estimation may be complicated by intrinsic qMRI signal model degeneracy: different combinations of tissue properties produce the same signal. Despite their many advantages, it remains unclear whether ML approaches can resolve this issue. Growing empirical evidence appears to suggest ML approaches remain susceptible to model degeneracy. Here we demonstrate under the right circumstances ML can address this issue. Inspired by recent works on the impact of training data distributions on ML-based parameter estimation, we propose to resolve model degeneracy by designing training data distributions. We put forward a classification of model degeneracies and identify one particular kind of degeneracies amenable to the proposed attack. The strategy is demonstrated successfully using the Revised NODDI model with standard multi-shell diffusion MRI data as an exemplar. Our results illustrate the importance of training set design which has the potential to allow accurate estimation of tissue properties with ML.","created":"2023-03-09","meta":{"link":"http://arxiv.org/abs/2303.05464v1","tag":"medical-cv"}}
{"title":"M3AE: Multimodal Representation Learning for Brain Tumor Segmentation with Missing Modalities","abstract":"Multimodal magnetic resonance imaging (MRI) provides complementary information for sub-region analysis of brain tumors. Plenty of methods have been proposed for automatic brain tumor segmentation using four common MRI modalities and achieved remarkable performance. In practice, however, it is common to have one or more modalities missing due to image corruption, artifacts, acquisition protocols, allergy to contrast agents, or simply cost. In this work, we propose a novel two-stage framework for brain tumor segmentation with missing modalities. In the first stage, a multimodal masked autoencoder (M3AE) is proposed, where both random modalities (i.e., modality dropout) and random patches of the remaining modalities are masked for a reconstruction task, for self-supervised learning of robust multimodal representations against missing modalities. To this end, we name our framework M3AE. Meanwhile, we employ model inversion to optimize a representative full-modal image at marginal extra cost, which will be used to substitute for the missing modalities and boost performance during inference. Then in the second stage, a memory-efficient self distillation is proposed to distill knowledge between heterogenous missing-modal situations while fine-tuning the model for supervised segmentation. Our M3AE belongs to the 'catch-all' genre where a single model can be applied to all possible subsets of modalities, thus is economic for both training and deployment. Extensive experiments on BraTS 2018 and 2020 datasets demonstrate its superior performance to existing state-of-the-art methods with missing modalities, as well as the efficacy of its components. Our code is available at: https://github.com/ccarliu/m3ae.","created":"2023-03-09","meta":{"link":"http://arxiv.org/abs/2303.05302v1","tag":"medical-cv"}}
{"title":"Classification in Histopathology: A unique deep embeddings extractor for multiple classification tasks","abstract":"In biomedical imaging, deep learning-based methods are state-of-the-art for every modality (virtual slides, MRI, etc.) In histopathology, these methods can be used to detect certain biomarkers or classify lesions. However, such techniques require large amounts of data to train high-performing models which can be intrinsically difficult to acquire, especially when it comes to scarce biomarkers. To address this challenge, we use a single, pre-trained, deep embeddings extractor to convert images into deep features and train small, dedicated classification head on these embeddings for each classification task. This approach offers several benefits such as the ability to reuse a single pre-trained deep network for various tasks; reducing the amount of labeled data needed as classification heads have fewer parameters; and accelerating training time by up to 1000 times, which allows for much more tuning of the classification head. In this work, we perform an extensive comparison of various open-source backbones and assess their fit to the target histological image domain. This is achieved using a novel method based on a proxy classification task. We demonstrate that thanks to this selection method, an optimal feature extractor can be selected for different tasks on the target domain. We also introduce a feature space augmentation strategy which proves to substantially improve the final metrics computed for the different tasks considered. To demonstrate the benefit of such backbone selection and feature-space augmentation, our experiments are carried out on three separate classification tasks and show a clear improvement on each of them: microcalcifications (29.1% F1-score increase), lymph nodes metastasis (12.5% F1-score increase), mitosis (15.0% F1-score increase).","created":"2023-03-09","meta":{"link":"http://arxiv.org/abs/2303.05180v1","tag":"medical-cv"}}
{"title":"Hybrid Dual Mean-Teacher Network With Double-Uncertainty Guidance for Semi-Supervised Segmentation of MRI Scans","abstract":"Semi-supervised learning has made significant progress in medical image segmentation. However, existing methods primarily utilize information acquired from a single dimensionality (2D/3D), resulting in sub-optimal performance on challenging data, such as magnetic resonance imaging (MRI) scans with multiple objects and highly anisotropic resolution. To address this issue, we present a Hybrid Dual Mean-Teacher (HD-Teacher) model with hybrid, semi-supervised, and multi-task learning to achieve highly effective semi-supervised segmentation. HD-Teacher employs a 2D and a 3D mean-teacher network to produce segmentation labels and signed distance fields from the hybrid information captured in both dimensionalities. This hybrid learning mechanism allows HD-Teacher to combine the `best of both worlds', utilizing features extracted from either 2D, 3D, or both dimensions to produce outputs as it sees fit. Outputs from 2D and 3D teacher models are also dynamically combined, based on their individual uncertainty scores, into a single hybrid prediction, where the hybrid uncertainty is estimated. We then propose a hybrid regularization module to encourage both student models to produce results close to the uncertainty-weighted hybrid prediction. The hybrid uncertainty suppresses unreliable knowledge in the hybrid prediction, leaving only useful information to improve network performance further. Extensive experiments of binary and multi-class segmentation conducted on three MRI datasets demonstrate the effectiveness of the proposed framework. Code is available at https://github.com/ThisGame42/Hybrid-Teacher.","created":"2023-03-09","meta":{"link":"http://arxiv.org/abs/2303.05126v1","tag":"medical-cv"}}
{"title":"Segmentation method for cerebral blood vessels from MRA using hysteresis","abstract":"Segmentation of cerebral blood vessels from Magnetic Resonance Imaging (MRI) is an open problem that could be solved with deep learning (DL). However, annotated data for training is often scarce. Due to the absence of open-source tools, we aim to develop a classical segmentation method that generates vessel ground truth from Magnetic Resonance Angiography for DL training of segmentation across a variety of modalities. The method combines size-specific Hessian filters, hysteresis thresholding and connected component correction. The optimal choice of processing steps was evaluated with a blinded scoring by a clinician using 24 3D images. The results show that all method steps are necessary to produce the highest (14.2/15) vessel segmentation quality score. Omitting the connected component correction caused the largest quality loss. The method, which is available on GitHub, can be used to train DL models for vessel segmentation.","created":"2023-03-09","meta":{"link":"http://arxiv.org/abs/2303.05113v1","tag":"medical-cv"}}
{"title":"SSL^2: Self-Supervised Learning meets Semi-Supervised Learning: Multiple Sclerosis Segmentation in 7T-MRI from large-scale 3T-MRI","abstract":"Automated segmentation of multiple sclerosis (MS) lesions from MRI scans is important to quantify disease progression. In recent years, convolutional neural networks (CNNs) have shown top performance for this task when a large amount of labeled data is available. However, the accuracy of CNNs suffers when dealing with few and/or sparsely labeled datasets. A potential solution is to leverage the information available in large public datasets in conjunction with a target dataset which only has limited labeled data. In this paper, we propose a training framework, SSL2 (self-supervised-semi-supervised), for multi-modality MS lesion segmentation with limited supervision. We adopt self-supervised learning to leverage the knowledge from large public 3T datasets to tackle the limitations of a small 7T target dataset. To leverage the information from unlabeled 7T data, we also evaluate state-of-the-art semi-supervised methods for other limited annotation settings, such as small labeled training size and sparse annotations. We use the shifted-window (Swin) transformer1 as our backbone network. The effectiveness of self-supervised and semi-supervised training strategies is evaluated in our in-house 7T MRI dataset. The results indicate that each strategy improves lesion segmentation for both limited training data size and for sparse labeling scenarios. The combined overall framework further improves the performance substantially compared to either of its components alone. Our proposed framework thus provides a promising solution for future data/label-hungry 7T MS studies.","created":"2023-03-09","meta":{"link":"http://arxiv.org/abs/2303.05026v1","tag":"medical-cv"}}
{"title":"MDAESF: Cine MRI Reconstruction Based on Motion-Guided Deformable Alignment and Efficient Spatiotemporal Self-Attention Fusion","abstract":"Cine MRI can jointly obtain the continuous influence of the anatomical structure and physiological and pathological mechanisms of organs in the two dimensions of time domain and space domain. Compared with ordinary two-dimensional static MRI images, the information in the time dimension of cine MRI contains many important information. But the information in the temporal dimension is not well utilized in past methods. To make full use of spatiotemporal information and reduce the influence of artifacts, this paper proposes a cine MRI reconstruction model based on second-order bidirectional propagation, motion-guided deformable alignment, and efficient spatiotemporal self-attention fusion. Compared to other advanced methods, our proposed method achieved better image reconstruction quality in terms of peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM) metrics as well as visual effects. The source code will be made available on https://github.com/GtLinyer/MDAESF.","created":"2023-03-09","meta":{"link":"http://arxiv.org/abs/2303.04968v1","tag":"medical-cv"}}
{"title":"Reverse Engineering Breast MRIs: Predicting Acquisition Parameters Directly from Images","abstract":"The image acquisition parameters (IAPs) used to create MRI scans are central to defining the appearance of the images. Deep learning models trained on data acquired using certain parameters might not generalize well to images acquired with different parameters. Being able to recover such parameters directly from an image could help determine whether a deep learning model is applicable, and could assist with data harmonization and/or domain adaptation. Here, we introduce a neural network model that can predict many complex IAPs used to generate an MR image with high accuracy solely using the image, with a single forward pass. These predicted parameters include field strength, echo and repetition times, acquisition matrix, scanner model, scan options, and others. Even challenging parameters such as contrast agent type can be predicted with good accuracy. We perform a variety of experiments and analyses of our model's ability to predict IAPs on many MRI scans of new patients, and demonstrate its usage in a realistic application. Predicting IAPs from the images is an important step toward better understanding the relationship between image appearance and IAPs. This in turn will advance the understanding of many concepts related to the generalizability of neural network models on medical images, including domain shift, domain adaptation, and data harmonization.","created":"2023-03-08","meta":{"link":"http://arxiv.org/abs/2303.04911v1","tag":"medical-cv"}}
{"title":"MetaMorph: Learning Metamorphic Image Transformation With Appearance Changes","abstract":"This paper presents a novel predictive model, MetaMorph, for metamorphic registration of images with appearance changes (i.e., caused by brain tumors). In contrast to previous learning-based registration methods that have little or no control over appearance-changes, our model introduces a new regularization that can effectively suppress the negative effects of appearance changing areas. In particular, we develop a piecewise regularization on the tangent space of diffeomorphic transformations (also known as initial velocity fields) via learned segmentation maps of abnormal regions. The geometric transformation and appearance changes are treated as joint tasks that are mutually beneficial. Our model MetaMorph is more robust and accurate when searching for an optimal registration solution under the guidance of segmentation, which in turn improves the segmentation performance by providing appropriately augmented training labels. We validate MetaMorph on real 3D human brain tumor magnetic resonance imaging (MRI) scans. Experimental results show that our model outperforms the state-of-the-art learning-based registration models. The proposed MetaMorph has great potential in various image-guided clinical interventions, e.g., real-time image-guided navigation systems for tumor removal surgery.","created":"2023-03-08","meta":{"link":"http://arxiv.org/abs/2303.04849v1","tag":"medical-cv"}}
{"title":"Patched Diffusion Models for Unsupervised Anomaly Detection in Brain MRI","abstract":"The use of supervised deep learning techniques to detect pathologies in brain MRI scans can be challenging due to the diversity of brain anatomy and the need for annotated data sets. An alternative approach is to use unsupervised anomaly detection, which only requires sample-level labels of healthy brains to create a reference representation. This reference representation can then be compared to unhealthy brain anatomy in a pixel-wise manner to identify abnormalities. To accomplish this, generative models are needed to create anatomically consistent MRI scans of healthy brains. While recent diffusion models have shown promise in this task, accurately generating the complex structure of the human brain remains a challenge. In this paper, we propose a method that reformulates the generation task of diffusion models as a patch-based estimation of healthy brain anatomy, using spatial context to guide and improve reconstruction. We evaluate our approach on data of tumors and multiple sclerosis lesions and demonstrate a relative improvement of 25.1% compared to existing baselines.","created":"2023-03-07","meta":{"link":"http://arxiv.org/abs/2303.03758v1","tag":"medical-cv"}}
{"title":"Deep Learning Based Dominant Index Lesion Segmentation for MR-guided Radiation Therapy of Prostate Cancer","abstract":"Dose escalation radiotherapy allows increased control of prostate cancer (PCa) but requires segmentation of dominant index lesions (DIL), motivating the development of automated methods for fast, accurate, and consistent segmentation of PCa DIL. We evaluated five deep-learning networks on apparent diffusion coefficient (ADC) MRI from 500 lesions in 365 patients arising from internal training Dataset 1 (1.5Tesla GE MR with endorectal coil), external ProstateX Dataset 2 (3Tesla Siemens MR), and internal inter-rater Dataset 3 (3Tesla Philips MR). The networks include: multiple resolution residually connected network (MRRN) and MRRN regularized in training with deep supervision (MRRN-DS), Unet, Unet++, ResUnet, and fast panoptic segmentation (FPSnet) as well as fast panoptic segmentation with smoothed labels (FPSnet-SL). Models were evaluated by volumetric DIL segmentation accuracy using Dice similarity coefficient (DSC) and detection accuracy, as a function of lesion aggressiveness, size, and location (Dataset 1 and 2), and accuracy with respect to two-raters (on Dataset 3). In general MRRN-DS more accurately segmented tumors than other methods on the testing datasets. MRRN-DS significantly outperformed ResUnet in Dataset2 (DSC of 0.54 vs. 0.44, p<0.001) and the Unet++ in Dataset3 (DSC of 0.45 vs. p=0.04). FPSnet-SL was similarly accurate as MRRN-DS in Dataset2 (p = 0.30), but MRRN-DS significantly outperformed FPSnet and FPSnet-SL in both Dataset1 (0.60 vs 0.51 [p=0.01] and 0.54 [p=0.049] respectively) and Dataset3 (0.45 vs 0.06 [p=0.002] and 0.24 [p=0.004] respectively). Finally, MRRN-DS produced slightly higher agreement with experienced radiologist than two radiologists in Dataset 3 (DSC of 0.45 vs. 0.41).","created":"2023-03-06","meta":{"link":"http://arxiv.org/abs/2303.03494v1","tag":"medical-cv"}}
{"title":"Breast simulation pipeline: from medical imaging to patient-specific simulations","abstract":"Breast-conserving surgery is the most acceptable operation for breast cancer removal from an invasive and psychological point of view. Before the surgical procedure, a preoperative MRI is performed in the prone configuration, while the surgery is achieved in the supine position. This leads to a considerable movement of the breast, including the tumor, between the two poses, complicating the surgeon's task. In this work, a simulation pipeline allowing the computation of patient-specific geometry and the prediction of personalized breast material properties was put forward. Through image segmentation, a finite element model including the subject-specific geometry is established. By first computing an undeformed state of the breast, the geometrico-material model is calibrated by surface acquisition in the intra-operative stance. Using an elastic corotational formulation, the patient-specific mechanical properties of the breast and skin were identified to obtain the best estimates of the supine configuration. The final results are a Mean Absolute Error of 4.00mm for the mechanical parameters E_breast = 0.32 kPa and E_skin = 22.72 kPa, congruent with the current state-of-the-art. The Covariance Matrix Adaptation Evolution Strategy optimizer converges on average between 5 to 30 min depending on the initial parameters, reaching a simulation speed of 20s. To our knowledge, our model offers one of the best compromises between accuracy and speed. Satisfactory results were obtained for the estimation of breast deformation from preoperative to intra-operative configuration. Furthermore, we have demonstrated the clinical feasibility of such applications using a simulation framework that aims at the smallest disturbance of the actual surgical pipeline.","created":"2023-03-06","meta":{"link":"http://arxiv.org/abs/2303.03987v1","tag":"medical-cv"}}
{"title":"SurfNN: Joint Reconstruction of Multiple Cortical Surfaces from Magnetic Resonance Images","abstract":"To achieve fast, robust, and accurate reconstruction of the human cortical surfaces from 3D magnetic resonance images (MRIs), we develop a novel deep learning-based framework, referred to as SurfNN, to reconstruct simultaneously both inner (between white matter and gray matter) and outer (pial) surfaces from MRIs. Different from existing deep learning-based cortical surface reconstruction methods that either reconstruct the cortical surfaces separately or neglect the interdependence between the inner and outer surfaces, SurfNN reconstructs both the inner and outer cortical surfaces jointly by training a single network to predict a midthickness surface that lies at the center of the inner and outer cortical surfaces. The input of SurfNN consists of a 3D MRI and an initialization of the midthickness surface that is represented both implicitly as a 3D distance map and explicitly as a triangular mesh with spherical topology, and its output includes both the inner and outer cortical surfaces, as well as the midthickness surface. The method has been evaluated on a large-scale MRI dataset and demonstrated competitive cortical surface reconstruction performance.","created":"2023-03-06","meta":{"link":"http://arxiv.org/abs/2303.02922v1","tag":"medical-cv"}}
{"title":"A Complex Quasi-Newton Proximal Method for Image Reconstruction in Compressed Sensing MRI","abstract":"Model-based methods are widely used for reconstruction in compressed sensing (CS) magnetic resonance imaging (MRI), using priors to describe the images of interest. The reconstruction process is equivalent to solving a composite optimization problem. Accelerated proximal methods (APMs) are very popular approaches for such problems. This paper proposes a complex quasi-Newton proximal method (CQNPM) for the wavelet and total variation based CS MRI reconstruction. Compared with APMs, CQNPM requires fewer iterations to converge but needs to compute a more challenging proximal mapping called weighted proximal mapping (WPM). To make CQNPM more practical, we propose efficient methods to solve the related WPM. Numerical experiments demonstrate the effectiveness and efficiency of CQNPM.","created":"2023-03-05","meta":{"link":"http://arxiv.org/abs/2303.02586v1","tag":"medical-cv"}}
{"title":"Detection of the Arterial Input Function Using DSC-MRI Data","abstract":"Accurate detection of arterial input function is a crucial step in obtaining perfusion hemodynamic parameters using dynamic susceptibility contrast-enhanced magnetic resonance imaging. It is required as input for perfusion quantification and has a great impact on the result of the deconvolution operation. To improve the reproducibility and reliability of arterial input function detection, several semi- or fully automatic methods have been proposed. This study provides an overview of the current state of the field of arterial input function detection. Methods most commonly used for semi- and fully automatic arterial input function detection are reviewed, and their advantages and disadvantages are listed.","created":"2023-03-04","meta":{"link":"http://arxiv.org/abs/2303.02516v1","tag":"medical-cv"}}
{"title":"Zero-Shot Self-Supervised Joint Temporal Image and Sensitivity Map Reconstruction via Linear Latent Space","abstract":"Fast spin-echo (FSE) pulse sequences for Magnetic Resonance Imaging (MRI) offer important imaging contrast in clinically feasible scan times. T2-shuffling is widely used to resolve temporal signal dynamics in FSE acquisitions by exploiting temporal correlations via linear latent space and a predefined regularizer. However, predefined regularizers fail to exploit the incoherence especially for 2D acquisitions.Recent self-supervised learning methods achieve high-fidelity reconstructions by learning a regularizer from undersampled data without a standard supervised training data set. In this work, we propose a novel approach that utilizes a self supervised learning framework to learn a regularizer constrained on a linear latent space which improves time-resolved FSE images reconstruction quality. Additionally, in regimes without groundtruth sensitivity maps, we propose joint estimation of coil-sensitivity maps using an iterative reconstruction technique. Our technique functions is in a zero-shot fashion, as it only utilizes data from a single scan of highly undersampled time series images. We perform experiments on simulated and retrospective in-vivo data to evaluate the performance of the proposed zero-shot learning method for temporal FSE reconstruction. The results demonstrate the success of our proposed method where NMSE and SSIM are significantly increased and the artifacts are reduced.","created":"2023-03-03","meta":{"link":"http://arxiv.org/abs/2303.02254v1","tag":"medical-cv"}}
{"title":"Automated Ventricle Parcellation and Evan's Ratio Computation in Pre- and Post-Surgical Ventriculomegaly","abstract":"Normal pressure hydrocephalus~(NPH) is a brain disorder associated with enlarged ventricles and multiple cognitive and motor symptoms. The degree of ventricular enlargement can be measured using magnetic resonance images~(MRIs) and characterized quantitatively using the Evan's ratio (ER). Automatic computation of ER is desired to avoid the extra time and variations associated with manual measurements on MRI. Because shunt surgery is often used to treat NPH, it is necessary that this process be robust to image artifacts caused by the shunt and related implants. In this paper, we propose a 3D regions-of-interest aware (ROI-aware) network for segmenting the ventricles. The method achieves state-of-the-art performance on both pre-surgery MRIs and post-surgery MRIs with artifacts. Based on our segmentation results, we also describe an automated approach to compute ER from these results. Experimental results on multiple datasets demonstrate the potential of the proposed method to assist clinicians in the diagnosis and management of NPH.","created":"2023-03-03","meta":{"link":"http://arxiv.org/abs/2303.01922v2","tag":"medical-cv"}}
{"title":"Optimization-Based Deep learning methods for Magnetic Resonance Imaging Reconstruction and Synthesis","abstract":"This dissertation is devoted to provide advanced nonconvex nonsmooth variational models of (Magnetic Resonance Image) MRI reconstruction, efficient learnable image reconstruction algorithms and parameter training algorithms that improve the accuracy and robustness of the optimization-based deep learning methods for compressed sensing MRI reconstruction and synthesis. The first part introduces a novel optimization based deep neural network whose architecture is inspired by proximal gradient descent for solving a variational model. The second part is a substantial extension of the preliminary work in the first part by solving the calibration-free fast pMRI reconstruction problem in a discrete-time optimal control framework. The third part aims at developing a generalizable Magnetic Resonance Imaging (MRI) reconstruction method in the meta-learning framework. The last part aims to synthesize target modality of MRI by using partially scanned k-space data from source modalities instead of fully scanned data that is used in the state-of-the-art multimodal synthesis.","created":"2023-03-02","meta":{"link":"http://arxiv.org/abs/2303.01515v1","tag":"medical-cv"}}
{"title":"Transferring Models Trained on Natural Images to 3D MRI via Position Encoded Slice Models","abstract":"Transfer learning has remarkably improved computer vision. These advances also promise improvements in neuroimaging, where training set sizes are often small. However, various difficulties arise in directly applying models pretrained on natural images to radiologic images, such as MRIs. In particular, a mismatch in the input space (2D images vs. 3D MRIs) restricts the direct transfer of models, often forcing us to consider only a few MRI slices as input. To this end, we leverage the 2D-Slice-CNN architecture of Gupta et al. (2021), which embeds all the MRI slices with 2D encoders (neural networks that take 2D image input) and combines them via permutation-invariant layers. With the insight that the pretrained model can serve as the 2D encoder, we initialize the 2D encoder with ImageNet pretrained weights that outperform those initialized and trained from scratch on two neuroimaging tasks -- brain age prediction on the UK Biobank dataset and Alzheimer's disease detection on the ADNI dataset. Further, we improve the modeling capabilities of 2D-Slice models by incorporating spatial information through position embeddings, which can improve the performance in some cases.","created":"2023-03-02","meta":{"link":"http://arxiv.org/abs/2303.01491v1","tag":"medical-cv"}}
{"title":"Evidence-empowered Transfer Learning for Alzheimer's Disease","abstract":"Transfer learning has been widely utilized to mitigate the data scarcity problem in the field of Alzheimer's disease (AD). Conventional transfer learning relies on re-using models trained on AD-irrelevant tasks such as natural image classification. However, it often leads to negative transfer due to the discrepancy between the non-medical source and target medical domains. To address this, we present evidence-empowered transfer learning for AD diagnosis. Unlike conventional approaches, we leverage an AD-relevant auxiliary task, namely morphological change prediction, without requiring additional MRI data. In this auxiliary task, the diagnosis model learns the evidential and transferable knowledge from morphological features in MRI scans. Experimental results demonstrate that our framework is not only effective in improving detection performance regardless of model capacity, but also more data-efficient and faithful.","created":"2023-03-02","meta":{"link":"http://arxiv.org/abs/2303.01105v4","tag":"medical-cv"}}
{"title":"Improved Segmentation of Deep Sulci in Cortical Gray Matter Using a Deep Learning Framework Incorporating Laplace's Equation","abstract":"When developing tools for automated cortical segmentation, the ability to produce topologically correct segmentations is important in order to compute geometrically valid morphometry measures. In practice, accurate cortical segmentation is challenged by image artifacts and the highly convoluted anatomy of the cortex itself. To address this, we propose a novel deep learning-based cortical segmentation method in which prior knowledge about the geometry of the cortex is incorporated into the network during the training process. We design a loss function which uses the theory of Laplace's equation applied to the cortex to locally penalize unresolved boundaries between tightly folded sulci. Using an ex vivo MRI dataset of human medial temporal lobe specimens, we demonstrate that our approach outperforms baseline segmentation networks, both quantitatively and qualitatively.","created":"2023-03-01","meta":{"link":"http://arxiv.org/abs/2303.00795v2","tag":"medical-cv"}}
{"title":"Unsupervised Pathology Detection: A Deep Dive Into the State of the Art","abstract":"Deep unsupervised approaches are gathering increased attention for applications such as pathology detection and segmentation in medical images since they promise to alleviate the need for large labeled datasets and are more generalizable than their supervised counterparts in detecting any kind of rare pathology. As the Unsupervised Anomaly Detection (UAD) literature continuously grows and new paradigms emerge, it is vital to continuously evaluate and benchmark new methods in a common framework, in order to reassess the state-of-the-art (SOTA) and identify promising research directions. To this end, we evaluate a diverse selection of cutting-edge UAD methods on multiple medical datasets, comparing them against the established SOTA in UAD for brain MRI. Our experiments demonstrate that newly developed feature-modeling methods from the industrial and medical literature achieve increased performance compared to previous work and set the new SOTA in a variety of modalities and datasets. Additionally, we show that such methods are capable of benefiting from recently developed self-supervised pre-training algorithms, further increasing their performance. Finally, we perform a series of experiments in order to gain further insights into some unique characteristics of selected models and datasets. Our code can be found under https://github.com/iolag/UPD_study/.","created":"2023-03-01","meta":{"link":"http://arxiv.org/abs/2303.00609v1","tag":"medical-cv"}}
{"title":"Indescribable Multi-modal Spatial Evaluator","abstract":"Multi-modal image registration spatially aligns two images with different distributions. One of its major challenges is that images acquired from different imaging machines have different imaging distributions, making it difficult to focus only on the spatial aspect of the images and ignore differences in distributions. In this study, we developed a self-supervised approach, Indescribable Multi-model Spatial Evaluator (IMSE), to address multi-modal image registration. IMSE creates an accurate multi-modal spatial evaluator to measure spatial differences between two images, and then optimizes registration by minimizing the error predicted of the evaluator. To optimize IMSE performance, we also proposed a new style enhancement method called Shuffle Remap which randomizes the image distribution into multiple segments, and then randomly disorders and remaps these segments, so that the distribution of the original image is changed. Shuffle Remap can help IMSE to predict the difference in spatial location from unseen target distributions. Our results show that IMSE outperformed the existing methods for registration using T1-T2 and CT-MRI datasets. IMSE also can be easily integrated into the traditional registration process, and can provide a convenient way to evaluate and visualize registration results. IMSE also has the potential to be used as a new paradigm for image-to-image translation. Our code is available at https://github.com/Kid-Liet/IMSE.","created":"2023-03-01","meta":{"link":"http://arxiv.org/abs/2303.00369v2","tag":"medical-cv"}}
{"title":"An end-to-end SE(3)-equivariant segmentation network","abstract":"Convolutional neural networks (CNNs) allow for parameter sharing and translational equivariance by using convolutional kernels in their linear layers. By restricting these kernels to be SO(3)-steerable, CNNs can further improve parameter sharing and equivariance. These equivariant convolutional layers have several advantages over standard convolutional layers, including increased robustness to unseen poses, smaller network size, and improved sample efficiency. Despite this, most segmentation networks used in medical image analysis continue to rely on standard convolutional kernels. In this paper, we present a new family of segmentation networks that use equivariant voxel convolutions based on spherical harmonics, as well as equivariant pooling and normalization operations. These SE(3)-equivariant volumetric segmentation networks, which are robust to data poses not seen during training, do not require rotation-based data augmentation during training. In addition, we demonstrate improved segmentation performance in MRI brain tumor and healthy brain structure segmentation tasks, with enhanced robustness to reduced amounts of training data and improved parameter efficiency. Code to reproduce our results, and to implement the equivariant segmentation networks for other tasks is available at http://github.com/SCAN-NRAD/e3nn_Unet","created":"2023-03-01","meta":{"link":"http://arxiv.org/abs/2303.00351v2","tag":"medical-cv"}}
{"title":"Initial experiences with Direct Imaging of Neuronal Activity (DIANA) in humans","abstract":"Functional MRI (fMRI) has been widely used to study activity patterns in the human brain. It infers neuronal activity from the associated hemodynamic response, which fundamentally limits its spatial and temporal specificity. In mice, the Direct Imaging of Neuronal Activity (DIANA) method revealed MRI signals that correlated with intracellular voltage changes, showing high spatial and temporal specificity. In this work we attempted DIANA in humans. Four visual paradigms were tested, exploring different stimulus types (flickering noise patterns, and naturalistic images) and stimulus durations (50-200ms). Regions of interest (ROI) were derived from traditional fMRI acquisitions and anatomical scans. When using small manually drawn ROI, signals were detected that resembled possible functional activity. However, increasing the stimulus duration did not lead to corroborating signal changes. Moreover, these signals disappeared when averaged over larger functionally or anatomically derived ROI. Further analysis of the data highlighted, DIANA's sensitivity to inflow effects and subject motion. Therefore, care should be taken not to mistake artifacts for neuronal activity. Although we did not yet observe clear DIANA signals in humans, it is possible that a higher spatial resolution is needed to separate signals with opposite signs in different laminar compartments. However, obtaining such data may be particularly challenging because repetitive experiments with short interstimulus intervals can be strenuous for the subjects. To obtain better data, improvements in sequence and stimulus designs are needed to maximize the DIANA signal and minimize confounds. However, without a clear understanding of DIANA's biophysical underpinnings it is difficult to do so. Therefore, it may be more effective to first study DIANA's biophysical underpinnings in a controlled, yet biologically revenant, setting.","created":"2023-03-01","meta":{"link":"http://arxiv.org/abs/2303.00161v1","tag":"medical-cv"}}
{"title":"PixCUE: Joint Uncertainty Estimation and Image Reconstruction in MRI using Deep Pixel Classification","abstract":"Deep learning (DL) models are capable of successfully exploiting latent representations in MR data and have become state-of-the-art for accelerated MRI reconstruction. However, undersampling the measurements in k-space as well as the over- or under-parameterized and non-transparent nature of DL make these models exposed to uncertainty. Consequently, uncertainty estimation has become a major issue in DL MRI reconstruction. To estimate uncertainty, Monte Carlo (MC) inference techniques have become a common practice where multiple reconstructions are utilized to compute the variance in reconstruction as a measurement of uncertainty. However, these methods demand high computational costs as they require multiple inferences through the DL model. To this end, we introduce a method to estimate uncertainty during MRI reconstruction using a pixel classification framework. The proposed method, PixCUE (stands for Pixel Classification Uncertainty Estimation) produces the reconstructed image along with an uncertainty map during a single forward pass through the DL model. We demonstrate that this approach generates uncertainty maps that highly correlate with the reconstruction errors with respect to various MR imaging sequences and under numerous adversarial conditions. We also show that the estimated uncertainties are correlated to that of the conventional MC method. We further provide an empirical relationship between the uncertainty estimations using PixCUE and well-established reconstruction metrics such as NMSE, PSNR, and SSIM. We conclude that PixCUE is capable of reliably estimating the uncertainty in MRI reconstruction with a minimum additional computational cost.","created":"2023-02-28","meta":{"link":"http://arxiv.org/abs/2303.00111v2","tag":"medical-cv"}}
{"title":"Estimating Head Motion from MR-Images","abstract":"Head motion is an omnipresent confounder of magnetic resonance image (MRI) analyses as it systematically affects morphometric measurements, even when visual quality control is performed. In order to estimate subtle head motion, that remains undetected by experts, we introduce a deep learning method to predict in-scanner head motion directly from T1-weighted (T1w), T2-weighted (T2w) and fluid-attenuated inversion recovery (FLAIR) images using motion estimates from an in-scanner depth camera as ground truth. Since we work with data from compliant healthy participants of the Rhineland Study, head motion and resulting imaging artifacts are less prevalent than in most clinical cohorts and more difficult to detect. Our method demonstrates improved performance compared to state-of-the-art motion estimation methods and can quantify drift and respiration movement independently. Finally, on unseen data, our predictions preserve the known, significant correlation with age.","created":"2023-02-28","meta":{"link":"http://arxiv.org/abs/2302.14490v1","tag":"medical-cv"}}
{"title":"SSL-QALAS: Self-Supervised Learning for Rapid Multiparameter Estimation in Quantitative MRI Using 3D-QALAS","abstract":"Purpose: To develop and evaluate a method for rapid estimation of multiparametric T1, T2, proton density (PD), and inversion efficiency (IE) maps from 3D-quantification using an interleaved Look-Locker acquisition sequence with T2 preparation pulse (3D-QALAS) measurements using self-supervised learning (SSL) without the need for an external dictionary. Methods: A SSL-based QALAS mapping method (SSL-QALAS) was developed for rapid and dictionary-free estimation of multiparametric maps from 3D-QALAS measurements. The accuracy of the reconstructed quantitative maps using dictionary matching and SSL-QALAS was evaluated by comparing the estimated T1 and T2 values with those obtained from the reference methods on an ISMRM/NIST phantom. The SSL-QALAS and the dictionary matching methods were also compared in vivo, and generalizability was evaluated by comparing the scan-specific, pre-trained, and transfer learning models. Results: Phantom experiments showed that both the dictionary matching and SSL-QALAS methods produced T1 and T2 estimates that had a strong linear agreement with the reference values in the ISMRM/NIST phantom. Further, SSL-QALAS showed similar performance with dictionary matching in reconstructing the T1, T2, PD, and IE maps on in vivo data. Rapid reconstruction of multiparametric maps was enabled by inferring the data using a pre-trained SSL-QALAS model within 10 s. Fast scan-specific tuning was also demonstrated by fine-tuning the pre-trained model with the target subject's data within 15 min. Conclusion: The proposed SSL-QALAS method enabled rapid reconstruction of multiparametric maps from 3D-QALAS measurements without an external dictionary or labeled ground-truth training data.","created":"2023-02-28","meta":{"link":"http://arxiv.org/abs/2302.14240v1","tag":"medical-cv"}}
{"title":"Curriculum Based Multi-Task Learning for Parkinson's Disease Detection","abstract":"There is great interest in developing radiological classifiers for diagnosis, staging, and predictive modeling in progressive diseases such as Parkinson's disease (PD), a neurodegenerative disease that is difficult to detect in its early stages. Here we leverage severity-based meta-data on the stages of disease to define a curriculum for training a deep convolutional neural network (CNN). Typically, deep learning networks are trained by randomly selecting samples in each mini-batch. By contrast, curriculum learning is a training strategy that aims to boost classifier performance by starting with examples that are easier to classify. Here we define a curriculum to progressively increase the difficulty of the training data corresponding to the Hoehn and Yahr (H&Y) staging system for PD (total N=1,012; 653 PD patients, 359 controls; age range: 20.0-84.9 years). Even with our multi-task setting using pre-trained CNNs and transfer learning, PD classification based on T1-weighted (T1-w) MRI was challenging (ROC AUC: 0.59-0.65), but curriculum training boosted performance (by 3.9%) compared to our baseline model. Future work with multimodal imaging may further boost performance.","created":"2023-02-27","meta":{"link":"http://arxiv.org/abs/2302.13631v1","tag":"medical-cv"}}
{"title":"Adaptive Sampling for Linear Sensing Systems via Langevin Dynamics","abstract":"Adaptive or dynamic signal sampling in sensing systems can adapt subsequent sampling strategies based on acquired signals, thereby potentially improving image quality and speed. This paper proposes a Bayesian method for adaptive sampling based on greedy variance reduction and stochastic gradient Langevin dynamics (SGLD). The image priors involved can be either analytical or neural network-based. Notably, the learned image priors generalize well to out-of-distribution test cases that have different statistics than the training dataset. As a real-world validation, the method is applied to accelerate the acquisition of magnetic resonance imaging (MRI). Compared to non-adaptive sampling, the proposed method effectively improved the image quality by 2-3 dB in PSNR, and improved the restoration of subtle details.","created":"2023-02-27","meta":{"link":"http://arxiv.org/abs/2302.13468v1","tag":"medical-cv"}}
{"title":"Extended Version of \"New Theory and Faster Computations for Subspace-Based Sensitivity Map Estimation in Multichannel MRI''","abstract":"This is an unabridged version of a journal manuscript that has been submitted for publication [1]. (Due to length restrictions, we were forced to remove substantial amounts of content from the version that was submitted to the journal, including more detailed theoretical explanations, additional figures, and a more comprehensive bibliography. This content remains intact in this version of the document).   Sensitivity map estimation is important in many multichannel MRI applications. Subspace-based sensitivity map estimation methods like ESPIRiT are popular and perform well, though can be computationally expensive and their theoretical principles can be nontrivial to understand. In the first part of this work, we present a novel theoretical derivation of subspace-based sensitivity map estimation based on a linear-predictability/structured low-rank modeling perspective. This results in an estimation approach that is equivalent to ESPIRiT, but with distinct theory that may be more intuitive for some readers. In the second part of this work, we propose and evaluate a set of computational acceleration approaches (collectively known as PISCO) that can enable substantial improvements in computation time (up to ~100x in the examples we show) and memory for subspace-based sensitivity map estimation.","created":"2023-02-26","meta":{"link":"http://arxiv.org/abs/2302.13431v1","tag":"medical-cv"}}
{"title":"DeepBrainPrint: A Novel Contrastive Framework for Brain MRI Re-Identification","abstract":"Recent advances in MRI have led to the creation of large datasets. With the increase in data volume, it has become difficult to locate previous scans of the same patient within these datasets (a process known as re-identification). To address this issue, we propose an AI-powered medical imaging retrieval framework called DeepBrainPrint, which is designed to retrieve brain MRI scans of the same patient. Our framework is a semi-self-supervised contrastive deep learning approach with three main innovations. First, we use a combination of self-supervised and supervised paradigms to create an effective brain fingerprint from MRI scans that can be used for real-time image retrieval. Second, we use a special weighting function to guide the training and improve model convergence. Third, we introduce new imaging transformations to improve retrieval robustness in the presence of intensity variations (i.e. different scan contrasts), and to account for age and disease progression in patients. We tested DeepBrainPrint on a large dataset of T1-weighted brain MRIs from the Alzheimer's Disease Neuroimaging Initiative (ADNI) and on a synthetic dataset designed to evaluate retrieval performance with different image modalities. Our results show that DeepBrainPrint outperforms previous methods, including simple similarity metrics and more advanced contrastive deep learning frameworks.","created":"2023-02-25","meta":{"link":"http://arxiv.org/abs/2302.13057v1","tag":"medical-cv"}}
{"title":"Video4MRI: An Empirical Study on Brain Magnetic Resonance Image Analytics with CNN-based Video Classification Frameworks","abstract":"To address the problem of medical image recognition, computer vision techniques like convolutional neural networks (CNN) are frequently used. Recently, 3D CNN-based models dominate the field of magnetic resonance image (MRI) analytics. Due to the high similarity between MRI data and videos, we conduct extensive empirical studies on video recognition techniques for MRI classification to answer the questions: (1) can we directly use video recognition models for MRI classification, (2) which model is more appropriate for MRI, (3) are the common tricks like data augmentation in video recognition still useful for MRI classification? Our work suggests that advanced video techniques benefit MRI classification. In this paper, four datasets of Alzheimer's and Parkinson's disease recognition are utilized in experiments, together with three alternative video recognition models and data augmentation techniques that are frequently applied to video tasks. In terms of efficiency, the results reveal that the video framework performs better than 3D-CNN models by 5% - 11% with 50% - 66% less trainable parameters. This report pushes forward the potential fusion of 3D medical imaging and video understanding research.","created":"2023-02-24","meta":{"link":"http://arxiv.org/abs/2302.12688v1","tag":"medical-cv"}}
{"title":"Getting the Phase Right: The Importance of Accurate Phase Definition in balanced Steady-State Free Precession MRI","abstract":"Balanced steady-state free precession (bSSFP) MRI sequences provide images with a high signal-to-noise ratio and T2/T1 contrast1. Phase-cycled (PC) bSSFP, which refers to multiple acquisitions with different linear phase increments of the radiofrequency (RF) pulse, can be used for artifact removal and quantitative parametric mapping. For this application, the signal phase is an indispensable source of information. In contrast to early publications, contradictory mathematical descriptions of the PC-bSSFP signal model have been reported. While the magnitude is typically well described, the signal phase is often not directly derived from the Bloch equations, leading to inaccurate signal descriptions. This is particularly relevant for multi-compartment systems where bSSFP profile asymmetries can be observed. This letter emphasizes the importance of accurate phase definitions to describe the bSSFP profile, by providing an intuitive derivation and an experimental validation using single and two-compartment phantoms.","created":"2023-02-24","meta":{"link":"http://arxiv.org/abs/2302.12548v1","tag":"medical-cv"}}
{"title":"Implicit neural representations for unsupervised super-resolution and denoising of 4D flow MRI","abstract":"4D flow MRI is a non-invasive imaging method that can measure blood flow velocities over time. However, the velocity fields detected by this technique have limitations due to low resolution and measurement noise. Coordinate-based neural networks have been researched to improve accuracy, with SIRENs being suitable for super-resolution tasks. Our study investigates SIRENs for time-varying 3-directional velocity fields measured in the aorta by 4D flow MRI, achieving denoising and super-resolution. We trained our method on voxel coordinates and benchmarked our approach using synthetic measurements and a real 4D flow MRI scan. Our optimized SIREN architecture outperformed state-of-the-art techniques, producing denoised and super-resolved velocity fields from clinical data. Our approach is quick to execute and straightforward to implement for novel cases, achieving 4D super-resolution.","created":"2023-02-24","meta":{"link":"http://arxiv.org/abs/2302.12835v1","tag":"medical-cv"}}
{"title":"Selective experience replay compression using coresets for lifelong deep reinforcement learning in medical imaging","abstract":"Selective experience replay is a popular strategy for integrating lifelong learning with deep reinforcement learning. Selective experience replay aims to recount selected experiences from previous tasks to avoid catastrophic forgetting. Furthermore, selective experience replay based techniques are model agnostic and allow experiences to be shared across different models. However, storing experiences from all previous tasks make lifelong learning using selective experience replay computationally very expensive and impractical as the number of tasks increase. To that end, we propose a reward distribution-preserving coreset compression technique for compressing experience replay buffers stored for selective experience replay.   We evaluated the coreset compression technique on the brain tumor segmentation (BRATS) dataset for the task of ventricle localization and on the whole-body MRI for localization of left knee cap, left kidney, right trochanter, left lung, and spleen. The coreset lifelong learning models trained on a sequence of 10 different brain MR imaging environments demonstrated excellent performance localizing the ventricle with a mean pixel error distance of 12.93 for the compression ratio of 10x. In comparison, the conventional lifelong learning model localized the ventricle with a mean pixel distance of 10.87. Similarly, the coreset lifelong learning models trained on whole-body MRI demonstrated no significant difference (p=0.28) between the 10x compressed coreset lifelong learning models and conventional lifelong learning models for all the landmarks. The mean pixel distance for the 10x compressed models across all the landmarks was 25.30, compared to 19.24 for the conventional lifelong learning models. Our results demonstrate that the potential of the coreset-based ERB compression method for compressing experiences without a significant drop in performance.","created":"2023-02-22","meta":{"link":"http://arxiv.org/abs/2302.11510v4","tag":"medical-cv"}}
{"title":"Semi-Supervised Segmentation of Multi-vendor and Multi-center Cardiac MRI using Histogram Matching","abstract":"Automatic segmentation of the heart cavity is an essential task for the diagnosis of cardiac diseases. In this paper, we propose a semi-supervised segmentation setup for leveraging unlabeled data to segment Left-ventricle, Right-ventricle, and Myocardium. We utilize an enhanced version of residual U-Net architecture on a large-scale cardiac MRI dataset. Handling the class imbalanced data issue using dice loss, the enhanced supervised model is able to achieve better dice scores in comparison with a vanilla U-Net model. We applied several augmentation techniques including histogram matching to increase the performance of our model in other domains. Also, we introduce a simple but efficient semi-supervised segmentation method to improve segmentation results without the need for large labeled data. Finally, we applied our method on two benchmark datasets, STACOM2018, and M\\&Ms 2020 challenges, to show the potency of the proposed model. The effectiveness of our proposed model is demonstrated by the quantitative results. The model achieves average dice scores of 0.921, 0.926, and 0.891 for Left-ventricle, Right-ventricle, and Myocardium respectively.","created":"2023-02-22","meta":{"link":"http://arxiv.org/abs/2302.11200v1","tag":"medical-cv"}}
{"title":"MM-SFENet: Multi-scale Multi-task Localization and Classification of Bladder Cancer in MRI with Spatial Feature Encoder Network","abstract":"Background and Objective: Bladder cancer is a common malignant urinary carcinoma, with muscle-invasive and non-muscle-invasive as its two major subtypes. This paper aims to achieve automated bladder cancer invasiveness localization and classification based on MRI. Method: Different from previous efforts that segment bladder wall and tumor, we propose a novel end-to-end multi-scale multi-task spatial feature encoder network (MM-SFENet) for locating and classifying bladder cancer, according to the classification criteria of the spatial relationship between the tumor and bladder wall. First, we built a backbone with residual blocks to distinguish bladder wall and tumor; then, a spatial feature encoder is designed to encode the multi-level features of the backbone to learn the criteria. Results: We substitute Smooth-L1 Loss with IoU Loss for multi-task learning, to improve the accuracy of the classification task. By testing a total of 1287 MRIs collected from 98 patients at the hospital, the mAP and IoU are used as the evaluation metrics. The experimental result could reach 93.34\\% and 83.16\\% on test set. Conclusions: The experimental result demonstrates the effectiveness of the proposed MM-SFENet on the localization and classification of bladder cancer. It may provide an effective supplementary diagnosis method for bladder cancer staging.","created":"2023-02-22","meta":{"link":"http://arxiv.org/abs/2302.11095v1","tag":"medical-cv"}}
{"title":"Posterior Annealing: Fast Calibrated Uncertainty for Regression","abstract":"Bayesian deep learning approaches that allow uncertainty estimation for regression problems often converge slowly and yield poorly calibrated uncertainty estimates that can not be effectively used for quantification. Recently proposed post hoc calibration techniques are seldom applicable to regression problems and often add overhead to an already slow model training phase. This work presents a fast calibrated uncertainty estimation method for regression tasks, called posterior annealing, that consistently improves the convergence of deep regression models and yields calibrated uncertainty without any post hoc calibration phase. Unlike previous methods for calibrated uncertainty in regression that focus only on low-dimensional regression problems, our method works well on a wide spectrum of regression problems. Our empirical analysis shows that our approach is generalizable to various network architectures including, multilayer perceptrons, 1D/2D convolutional networks, and graph neural networks, on five vastly diverse tasks, i.e., chaotic particle trajectory denoising, physical property prediction of molecules using 3D atomistic representation, natural image super-resolution, and medical image translation using MRI images.","created":"2023-02-21","meta":{"link":"http://arxiv.org/abs/2302.11012v1","tag":"medical-cv"}}
{"title":"Establishing group-level brain structural connectivity incorporating anatomical knowledge under latent space modeling","abstract":"Brain structural connectivity, capturing the white matter fiber tracts among brain regions inferred by diffusion MRI (dMRI), provides a unique characterization of brain anatomical organization. One fundamental question to address with structural connectivity is how to properly summarize and perform statistical inference for a group-level connectivity architecture, for instance, under different sex groups, or disease cohorts. Existing analyses commonly summarize group-level brain connectivity by a simple entry-wise sample mean or median across individual brain connectivity matrices. However, such a heuristic approach fully ignores the associations among structural connections and the topological properties of brain networks. In this project, we propose a latent space-based generative network model to estimate group-level brain connectivity. We name our method the attributes-informed brain connectivity (ABC) model, which compared with existing group-level connectivity estimations, (1) offers an interpretable latent space representation of the group-level connectivity, (2) incorporates the anatomical knowledge of nodes and tests its co-varying relationship with connectivity and (3) quantifies the uncertainty and evaluates the likelihood of the estimated group-level effects against chance. We devise a novel Bayesian MCMC algorithm to estimate the model. By applying the ABC model to study brain structural connectivity stratified by sex among Alzheimer's Disease (AD) subjects and healthy controls incorporating the anatomical attributes (volume, thickness and area) on nodes, our method shows superior predictive power on out-of-sample structural connectivity and identifies meaningful sex-specific network neuromarkers for AD.","created":"2023-02-21","meta":{"link":"http://arxiv.org/abs/2304.01345v1","tag":"medical-cv"}}
{"title":"3D Radiation Hydrodynamic Simulations of Gravitational Instability in AGN Accretion Disks: Effects of Radiation Pressure","abstract":"We perform 3D radiation hydrodynamic local shearing box simulations to study the outcome of gravitational instability (GI) in optically thick Active Galactic Nuclei (AGN) accretion disks. GI develops when the Toomre parameter QT \\leq 1, and may lead to turbulent heating that balances radiative cooling. However, when radiative cooling is too efficient, the disk may undergo runaway gravitational fragmentation. In the fully gas-pressure-dominated case, we confirm the classical result that such a thermal balance holds when the Shakura-Sunyaev viscosity parameter (alpha) due to the gravitationally-driven turbulence is \\sim 0.2, corresponding to dimensionless cooling times Omega tcool \\sim 5. As the fraction of support by radiation pressure increases, the disk becomes more prone to fragmentation, with a reduced (increased) critical value of alpha (omega tcool). The effect is already significant when the radiation pressure exceeds 10% of the gas pressure, while fully radiation-pressure-dominated disks fragment at Omega tcool <50 . The latter translates to a maximum turbulence level alpha<0.02, comparable to that generated by Magnetorotational Instability (MRI). Our results suggest that gravitationally unstable (QT \\sim 1) outer regions of AGN disks with significant radiation pressure (likely for high/near- Eddington accretion rates) should always fragment into stars, and perhaps black holes.","created":"2023-02-21","meta":{"link":"http://arxiv.org/abs/2302.10868v2","tag":"medical-cv"}}
{"title":"SF2Former: Amyotrophic Lateral Sclerosis Identification From Multi-center MRI Data Using Spatial and Frequency Fusion Transformer","abstract":"Amyotrophic Lateral Sclerosis (ALS) is a complex neurodegenerative disorder involving motor neuron degeneration. Significant research has begun to establish brain magnetic resonance imaging (MRI) as a potential biomarker to diagnose and monitor the state of the disease. Deep learning has turned into a prominent class of machine learning programs in computer vision and has been successfully employed to solve diverse medical image analysis tasks. However, deep learning-based methods applied to neuroimaging have not achieved superior performance in ALS patients classification from healthy controls due to having insignificant structural changes correlated with pathological features. Therefore, the critical challenge in deep models is to determine useful discriminative features with limited training data. By exploiting the long-range relationship of image features, this study introduces a framework named SF2Former that leverages vision transformer architecture's power to distinguish the ALS subjects from the control group. To further improve the network's performance, spatial and frequency domain information are combined because MRI scans are captured in the frequency domain before being converted to the spatial domain. The proposed framework is trained with a set of consecutive coronal 2D slices, which uses the pre-trained weights on ImageNet by leveraging transfer learning. Finally, a majority voting scheme has been employed to those coronal slices of a particular subject to produce the final classification decision. Our proposed architecture has been thoroughly assessed with multi-modal neuroimaging data using two well-organized versions of the Canadian ALS Neuroimaging Consortium (CALSNIC) multi-center datasets. The experimental results demonstrate the superiority of our proposed strategy in terms of classification accuracy compared with several popular deep learning-based techniques.","created":"2023-02-21","meta":{"link":"http://arxiv.org/abs/2302.10859v2","tag":"medical-cv"}}
{"title":"Supervisory Control of Modular Discrete-Event Systems under Partial Observation: Normality","abstract":"Complex systems are often composed of many small communicating components called modules. We investigate the synthesis of supervisory controllers for modular systems under partial observation that, as the closed-loop system, realize the supremal normal sublanguage of the specification. We call such controllers maximally permissive normal supervisors. The challenge in modular systems is to find conditions under which the global nonblocking and maximally permissive normal supervisor can be achieved locally as the parallel composition of local normal supervisors. We show that a structural concept of hierarchical supervisory control called modified observation consistency (MOC) is such a condition. However, the algorithmic verification of MOC is an open problem, and therefore it is necessary to find easily-verifiable conditions that ensure MOC. We show that the condition that all shared events are observable is such a condition. Considering specifications, we examine both local specifications, where each module has its own specification, and global specifications. We combine our results for normality with the existing results for controllability to locally synthesize the nonblocking and maximally permissive controllable and normal supervisor. Finally, we illustrate the results on an industrial case study of the patient table of an MRI scanner.","created":"2023-02-21","meta":{"link":"http://arxiv.org/abs/2302.10666v1","tag":"medical-cv"}}
{"title":"A Bibliography of Multiple Sclerosis Lesions Detection Methods using Brain MRIs","abstract":"Introduction: Multiple Sclerosis (MS) is a chronic disease that affects millions of people across the globe. MS can critically affect different organs of the central nervous system such as the eyes, the spinal cord, and the brain.   Background: To help physicians in diagnosing MS lesions, computer-aided methods are widely used. In this regard, a considerable research has been carried out in the area of automatic detection and segmentation of MS lesions in magnetic resonance images (MRIs).   Methodology: In this study, we review the different approaches that have been used in computer-aided detection and segmentation of MS lesions. Our review resulted in categorizing MS lesion segmentation approaches into six broad categories: data-driven, statistical, supervised machine learning, unsupervised machine learning, fuzzy, and deep learning-based techniques. We critically analyze the different techniques under these approaches and highlight their strengths and weaknesses.   Results: From the study, we observe that a considerable amount of work, around 25% of related literature, is focused on statistical-based MS lesion segmentation techniques, followed by 21.15% for data-driven based methods, 19.23% for deep learning and 15.38% for supervised methods.   Implication: The study points out the challenges/gaps to be addressed in future research. The study shows the work which has been done in last one decade in detection and segmentation of MS lesions. The results show that, in recent years, deep learning methods are outperforming all the others methods.","created":"2023-02-19","meta":{"link":"http://arxiv.org/abs/2302.09516v1","tag":"medical-cv"}}
{"title":"FastCod: Fast Brain Connectivity in Diffusion Imaging","abstract":"Connectivity information derived from diffusion-weighted magnetic resonance images~(DW-MRIs) plays an important role in studying human subcortical gray matter structures. However, due to the $O(N^2)$ complexity of computing the connectivity of each voxel to every other voxel (or multiple ROIs), the current practice of extracting connectivity information is highly inefficient. This makes the processing of high-resolution images and population-level analyses very computationally demanding. To address this issue, we propose a more efficient way to extract connectivity information; briefly, we consider two regions/voxels to be connected if a white matter fiber streamline passes through them -- no matter where the streamline originates. We consider the thalamus parcellation task for demonstration purposes; our experiments show that our approach brings a 30 to 120 times speedup over traditional approaches with comparable qualitative parcellation results. We also demonstrate high-resolution connectivity features can be super-resolved from low-resolution DW-MRI in our framework. Together, these two innovations enable higher resolution connectivity analysis from DW-MRI. Our source code is availible at jasonbian97.github.io/fastcod.","created":"2023-02-18","meta":{"link":"http://arxiv.org/abs/2302.09247v1","tag":"medical-cv"}}
{"title":"Dual-Domain Self-Supervised Learning for Accelerated Non-Cartesian MRI Reconstruction","abstract":"While enabling accelerated acquisition and improved reconstruction accuracy, current deep MRI reconstruction networks are typically supervised, require fully sampled data, and are limited to Cartesian sampling patterns. These factors limit their practical adoption as fully-sampled MRI is prohibitively time-consuming to acquire clinically. Further, non-Cartesian sampling patterns are particularly desirable as they are more amenable to acceleration and show improved motion robustness. To this end, we present a fully self-supervised approach for accelerated non-Cartesian MRI reconstruction which leverages self-supervision in both k-space and image domains. In training, the undersampled data are split into disjoint k-space domain partitions. For the k-space self-supervision, we train a network to reconstruct the input undersampled data from both the disjoint partitions and from itself. For the image-level self-supervision, we enforce appearance consistency obtained from the original undersampled data and the two partitions. Experimental results on our simulated multi-coil non-Cartesian MRI dataset demonstrate that DDSS can generate high-quality reconstruction that approaches the accuracy of the fully supervised reconstruction, outperforming previous baseline methods. Finally, DDSS is shown to scale to highly challenging real-world clinical MRI reconstruction acquired on a portable low-field (0.064 T) MRI scanner with no data available for supervised training while demonstrating improved image quality as compared to traditional reconstruction, as determined by a radiologist study.","created":"2023-02-18","meta":{"link":"http://arxiv.org/abs/2302.09244v1","tag":"medical-cv"}}
{"title":"Brainomaly: Unsupervised Neurologic Disease Detection Utilizing Unannotated T1-weighted Brain MR Images","abstract":"Deep neural networks have revolutionized the field of supervised learning by enabling accurate predictions through learning from large annotated datasets. However, acquiring large annotated medical imaging datasets is a challenging task, especially for rare diseases, due to the high cost, time, and effort required for annotation. In these scenarios, unsupervised disease detection methods, such as anomaly detection, can save significant human effort. A typically used approach for anomaly detection is to learn the images from healthy subjects only, assuming the model will detect the images from diseased subjects as outliers. However, in many real-world scenarios, unannotated datasets with a mix of healthy and diseased individuals are available. Recent studies have shown improvement in unsupervised disease/anomaly detection using such datasets of unannotated images from healthy and diseased individuals compared to datasets that only include images from healthy individuals. A major issue remains unaddressed in these studies, which is selecting the best model for inference from a set of trained models without annotated samples. To address this issue, we propose Brainomaly, a GAN-based image-to-image translation method for neurologic disease detection using unannotated T1-weighted brain MRIs of individuals with neurologic diseases and healthy subjects. Brainomaly is trained to remove the diseased regions from the input brain MRIs and generate MRIs of corresponding healthy brains. Instead of generating the healthy images directly, Brainomaly generates an additive map where each voxel indicates the amount of changes required to make the input image look healthy. In addition, Brainomaly uses a pseudo-AUC metric for inference model selection, which further improves the detection performance. Our Brainomaly outperforms existing state-of-the-art methods by large margins.","created":"2023-02-18","meta":{"link":"http://arxiv.org/abs/2302.09200v2","tag":"medical-cv"}}
{"title":"sMRI-PatchNet: A novel explainable patch-based deep learning network for Alzheimer's disease diagnosis and discriminative atrophy localisation with Structural MRI","abstract":"Structural magnetic resonance imaging (sMRI) can identify subtle brain changes due to its high contrast for soft tissues and high spatial resolution. It has been widely used in diagnosing neurological brain diseases, such as Alzheimer disease (AD). However, the size of 3D high-resolution data poses a significant challenge for data analysis and processing. Since only a few areas of the brain show structural changes highly associated with AD, the patch-based methods dividing the whole image data into several small regular patches have shown promising for more efficient sMRI-based image analysis. The major challenges of the patch-based methods on sMRI include identifying the discriminative patches, combining features from the discrete discriminative patches, and designing appropriate classifiers. This work proposes a novel patch-based deep learning network (sMRI-PatchNet) with explainable patch localisation and selection for AD diagnosis using sMRI. Specifically, it consists of two primary components: 1) A fast and efficient explainable patch selection mechanism for determining the most discriminative patches based on computing the SHapley Additive exPlanations (SHAP) contribution to a transfer learning model for AD diagnosis on massive medical data; and 2) A novel patch-based network for extracting deep features and AD classfication from the selected patches with position embeddings to retain position information, capable of capturing the global and local information of inter- and intra-patches. This method has been applied for the AD classification and the prediction of the transitional state moderate cognitive impairment (MCI) conversion with real datasets.","created":"2023-02-17","meta":{"link":"http://arxiv.org/abs/2302.08967v2","tag":"medical-cv"}}
{"title":"PhaseNet: Phase-Encode Denoising Network for Compressed Sensing MRI","abstract":"Sparse reconstruction is an important aspect of modern medical imaging, reducing the acquisition time of relatively slow modalities such as magnetic resonance imaging (MRI). Popular methods are based mostly on compressed sensing (CS), which relies on the random sampling of Fourier coefficients ($k$-space) to produce incoherent (noise-like) artefacts that can be removed via convex optimisation. Hardware constraints currently limit Cartesian CS to one dimensional (1D) phase-encode undersampling schemes, leading to coherent and structured artefacts. Reconstruction algorithms typically deploy an idealised and limited 2D regularisation for artefact removal, which increases the difficulty of image recovery. Recognising that phase-encode artefacts can be separated into contiguous 1D signals, we develop two decoupling techniques that enable explicit 1D regularisation. We thereby leverage the excellent incoherence characteristics in the phase-encode direction. We also derive a combined 1D + 2D reconstruction technique that further takes advantage of spatial relationships within the image, leading to an improvement of existing 2D deep-learned (DL) recovery techniques. Performance is evaluated on a brain and knee dataset. We find the proposed 1D CNN modules significantly improve PSNR and SSIM scores compared to the base 2D models, demonstrating a superior scaling of performance compared to increasing the size of 2D network layers.","created":"2023-02-17","meta":{"link":"http://arxiv.org/abs/2302.08861v1","tag":"medical-cv"}}
{"title":"Unsupervised Domain Adaptation for MRI Volume Segmentation and Classification Using Image-to-Image Translation","abstract":"Unsupervised domain adaptation is a type of domain adaptation and exploits labeled data from the source domain and unlabeled data from the target one. In the Cross-Modality Domain Adaptation for Medical Image Segmenta-tion challenge (crossMoDA2022), contrast enhanced T1 MRI volumes for brain are provided as the source domain data, and high-resolution T2 MRI volumes are provided as the target domain data. The crossMoDA2022 challenge contains two tasks, segmentation of vestibular schwannoma (VS) and cochlea, and clas-sification of VS with Koos grade. In this report, we presented our solution for the crossMoDA2022 challenge. We employ an image-to-image translation method for unsupervised domain adaptation and residual U-Net the segmenta-tion task. We use SVM for the classification task. The experimental results show that the mean DSC and ASSD are 0.614 and 2.936 for the segmentation task and MA-MAE is 0.84 for the classification task.","created":"2023-02-16","meta":{"link":"http://arxiv.org/abs/2302.08016v1","tag":"medical-cv"}}
{"title":"Functional Connectivity Dynamics show Resting-State Instability and Rightward Parietal Dysfunction in ADHD","abstract":"Attention Deficit/Hyperactivity Disorder (ADHD) is one of the most common neurodevelopmental disorders in children and is characterised by inattention, impulsiveness and hyperactivity. While several studies have analysed the static functional connectivity in the resting-state functional MRI (rs-fMRI) of ADHD patients, detailed investigations are required to characterize the connectivity dynamics in the brain. In an attempt to establish a link between attention instability and the dynamic properties of Functional Connectivity (FC), we investigated the differences in temporal variability of FC between 40 children with ADHD and 40 Typically Developing (TD) children. Using a sliding-window method to segment the rs-fMRI scans in time, we employed seed-to-voxel correlation analysis for each window to obtain time-evolving seed connectivity maps for seeds placed in the posterior cingulate cortex (PCC) and the medial prefrontal cortex (mPFC). For each subject, the standard deviation of the voxel connectivity time series was used as a measure of the temporal variability of FC. Results showed that ADHD patients exhibited significantly higher variability in dFC than TD children in the cingulo-temporal, cingulo-parietal, fronto-temporal, and fronto-parietal networks ($p_{FWE} < 0.05$). Atypical temporal variability was observed in the left and right temporal gyri, the anterior cingulate cortex, and lateral regions of the right parietal cortex. The observations are consistent with visual attention issues, executive control deficit, and rightward parietal dysfunction reported in ADHD, respectively. These results help in understanding the disorder with a fresh perspective linking behavioural inattention with instability in FC in the brain.","created":"2023-02-15","meta":{"link":"http://arxiv.org/abs/2302.07961v1","tag":"medical-cv"}}
{"title":"Edge-weighted pFISTA-Net for MRI Reconstruction","abstract":"Deep learning based on unrolled algorithm has served as an effective method for accelerated magnetic resonance imaging (MRI). However, many methods ignore the direct use of edge information to assist MRI reconstruction. In this work, we present the edge-weighted pFISTA-Net that directly applies the detected edge map to the soft-thresholding part of pFISTA-Net. The soft-thresholding value of different regions will be adjusted according to the edge map. Experimental results of a public brain dataset show that the proposed yields reconstructions with lower error and better artifact suppression compared with the state-of-the-art deep learning-based methods. The edge-weighted pFISTA-Net also shows robustness for different undersampling masks and edge detection operators. In addition, we extend the edge weighted structure to joint reconstruction and segmentation network and obtain improved reconstruction performance and more accurate segmentation results.","created":"2023-02-15","meta":{"link":"http://arxiv.org/abs/2302.07468v1","tag":"medical-cv"}}
{"title":"Synthesizing audio from tongue motion during speech using tagged MRI via transformer","abstract":"Investigating the relationship between internal tissue point motion of the tongue and oropharyngeal muscle deformation measured from tagged MRI and intelligible speech can aid in advancing speech motor control theories and developing novel treatment methods for speech related-disorders. However, elucidating the relationship between these two sources of information is challenging, due in part to the disparity in data structure between spatiotemporal motion fields (i.e., 4D motion fields) and one-dimensional audio waveforms. In this work, we present an efficient encoder-decoder translation network for exploring the predictive information inherent in 4D motion fields via 2D spectrograms as a surrogate of the audio data. Specifically, our encoder is based on 3D convolutional spatial modeling and transformer-based temporal modeling. The extracted features are processed by an asymmetric 2D convolution decoder to generate spectrograms that correspond to 4D motion fields. Furthermore, we incorporate a generative adversarial training approach into our framework to further improve synthesis quality on our generated spectrograms. We experiment on 63 paired motion field sequences and speech waveforms, demonstrating that our framework enables the generation of clear audio waveforms from a sequence of motion fields. Thus, our framework has the potential to improve our understanding of the relationship between these two modalities and inform the development of treatments for speech disorders.","created":"2023-02-14","meta":{"link":"http://arxiv.org/abs/2302.07203v1","tag":"medical-cv"}}
{"title":"Exact sinogram: an analytical approach to the Radon transform of phantoms","abstract":"Phantoms can serve as a gold standard for the validation of MRI numerical methods. In some special cases, it is possible to compute analytically the Radon transform, or sinogram, of a phantom. In this work, we present analytical formulae to compute the exact sinograms of three classes of phantoms. We compare the use of the discrete Radon transform, that yields an approximate sinogram, and the correspondent analytical sinogram for image reconstruction.","created":"2023-02-13","meta":{"link":"http://arxiv.org/abs/2302.06283v1","tag":"medical-cv"}}
{"title":"Multi-class Brain Tumor Segmentation using Graph Attention Network","abstract":"Brain tumor segmentation from magnetic resonance imaging (MRI) plays an important role in diagnostic radiology. To overcome the practical issues in manual approaches, there is a huge demand for building automatic tumor segmentation algorithms. This work introduces an efficient brain tumor summation model by exploiting the advancement in MRI and graph neural networks (GNNs). The model represents the volumetric MRI as a region adjacency graph (RAG) and learns to identify the type of tumors through a graph attention network (GAT) -- a variant of GNNs. The ablation analysis conducted on two benchmark datasets proves that the proposed model can produce competitive results compared to the leading-edge solutions. It achieves mean dice scores of 0.91, 0.86, 0.79, and mean Hausdorff distances in the 95th percentile (HD95) of 5.91, 6.08, and 9.52 mm, respectively, for whole tumor, core tumor, and enhancing tumor segmentation on BraTS2021 validation dataset. On average, these performances are >6\\% and >50%, compared to a GNN-based baseline model, respectively, on dice score and HD95 evaluation metrics.","created":"2023-02-11","meta":{"link":"http://arxiv.org/abs/2302.05598v1","tag":"medical-cv"}}
{"title":"Pressure-Poisson Equation in Numerical Simulation of Cerebral Arterial Circulation and Its Effect on the Electrical Conductivity of the Brain","abstract":"Background and Objective: This study considers dynamic modelling of the cerebral arterial circulation and reconstructing an atlas for the electrical conductivity of the brain. The conductivity is a governing parameter in several electrophysiological modalities such as electroencephalography (EEG) and transcranial electrical stimulation (tES). While high-resolution 7 Tesla Magnetic Resonance Imaging (MRI) data allows for reconstructing the cerebral arteries with a cross-sectional diameter larger than the voxel size, the conductivity cannot be directly inferred from MRI data. The state-of-the-art head models applied in EEG and tES typically associate each head tissue compartment with a constant conductivity, omitting any dynamical effects of cerebral circulation. Incorporating those effects poses the challenge of solving a system of incompressible Navier-Stokes equations (NSEs) in a realistic multi-compartment head model.   Methods: We propose that circulation in the distinguishable arteries can be estimated via the pressure Poisson equation (PPE). To establish a fluid exchange model between arteries and microarteries, a boundary condition derived from the Hagen-Poisseuille model is applied. The relationship between the estimated blood concentration and the tissue conductivity is approximated through Archie's law for fluid flow in porous media.   Results: Through the formulation of the PPE and a set of boundary conditions based on the Hagen-Poisseuille model, we obtained an equivalent formulation of the incompressible NSEs. Thus, allowing effective blood pressure estimation in cerebral arteries segmented from open 7 Tesla MRI data.   Conclusions: We developed and built a useful modeling framework that accounts for the effects of dynamic blood flow on a novel MRI-based conductivity atlas.","created":"2023-02-09","meta":{"link":"http://arxiv.org/abs/2302.04814v2","tag":"medical-cv"}}
{"title":"Complex Network for Complex Problems: A comparative study of CNN and Complex-valued CNN","abstract":"Neural networks, especially convolutional neural networks (CNN), are one of the most common tools these days used in computer vision. Most of these networks work with real-valued data using real-valued features. Complex-valued convolutional neural networks (CV-CNN) can preserve the algebraic structure of complex-valued input data and have the potential to learn more complex relationships between the input and the ground-truth. Although some comparisons of CNNs and CV-CNNs for different tasks have been performed in the past, a large-scale investigation comparing different models operating on different tasks has not been conducted. Furthermore, because complex features contain both real and imaginary components, CV-CNNs have double the number of trainable parameters as real-valued CNNs in terms of the actual number of trainable parameters. Whether or not the improvements in performance with CV-CNN observed in the past have been because of the complex features or just because of having double the number of trainable parameters has not yet been explored. This paper presents a comparative study of CNN, CNNx2 (CNN with double the number of trainable parameters as the CNN), and CV-CNN. The experiments were performed using seven models for two different tasks - brain tumour classification and segmentation in brain MRIs. The results have revealed that the CV-CNN models outperformed the CNN and CNNx2 models.","created":"2023-02-09","meta":{"link":"http://arxiv.org/abs/2302.04584v1","tag":"medical-cv"}}
{"title":"New starting point registration method for tagged MRI tongue motion estimation","abstract":"Accurate tongue motion estimation is essential for tongue function evaluation. The harmonic phase processing (HARP) method and the phase vector incompressible registration algorithm (PVIRA) based on HARP can generate motion estimates from tagged MRI images, but they suffer from tag jumping due to large motions. This paper proposes a new registration method by combining the stationary velocity fields produced by PVIRA between successive time frames as a new initialization of the final registration stage to avoid tag jumping. The experiment results demonstrate the proposed method can avoid tag jumping and outperform the existing methods on tongue motion estimates.","created":"2023-02-08","meta":{"link":"http://arxiv.org/abs/2302.04330v1","tag":"medical-cv"}}
{"title":"Enhancing Modality-Agnostic Representations via Meta-Learning for Brain Tumor Segmentation","abstract":"In the medical vision domain, different imaging modalities provide complementary information. However, in practice, not all modalities may be available during inference. Previous approaches, e.g., knowledge distillation or image synthesis, often assume the availability of full modalities for all patients during training; this is unrealistic and impractical owing to the variability in data collection across sites. We propose a novel approach to learn enhanced modality-agnostic representations by employing a novel meta-learning strategy in training, even when only a fraction of full modality patients are available. Meta-learning enhances partial modality representations to full modality representations by meta-training on partial modality data and meta-testing on limited full modality samples. Additionally, we co-supervise this feature enrichment by introducing an auxiliary adversarial learning branch. More specifically, a missing modality detector is used as a discriminator to mimic the full modality setting. Our segmentation framework significantly outperforms state-of-the-art brain tumor segmentation techniques in missing modality scenarios, as demonstrated on two brain tumor MRI datasets.","created":"2023-02-08","meta":{"link":"http://arxiv.org/abs/2302.04308v1","tag":"medical-cv"}}
{"title":"Adapting Pre-trained Vision Transformers from 2D to 3D through Weight Inflation Improves Medical Image Segmentation","abstract":"Given the prevalence of 3D medical imaging technologies such as MRI and CT that are widely used in diagnosing and treating diverse diseases, 3D segmentation is one of the fundamental tasks of medical image analysis. Recently, Transformer-based models have started to achieve state-of-the-art performances across many vision tasks, through pre-training on large-scale natural image benchmark datasets. While works on medical image analysis have also begun to explore Transformer-based models, there is currently no optimal strategy to effectively leverage pre-trained Transformers, primarily due to the difference in dimensionality between 2D natural images and 3D medical images. Existing solutions either split 3D images into 2D slices and predict each slice independently, thereby losing crucial depth-wise information, or modify the Transformer architecture to support 3D inputs without leveraging pre-trained weights. In this work, we use a simple yet effective weight inflation strategy to adapt pre-trained Transformers from 2D to 3D, retaining the benefit of both transfer learning and depth information. We further investigate the effectiveness of transfer from different pre-training sources and objectives. Our approach achieves state-of-the-art performances across a broad range of 3D medical image datasets, and can become a standard strategy easily utilized by all work on Transformer-based models for 3D medical images, to maximize performance.","created":"2023-02-08","meta":{"link":"http://arxiv.org/abs/2302.04303v1","tag":"medical-cv"}}
{"title":"A Survey of Feature detection methods for localisation of plain sections of Axial Brain Magnetic Resonance Imaging","abstract":"Matching MRI brain images between patients or mapping patients' MRI slices to the simulated atlas of a brain is key to the automatic registration of MRI of a brain. The ability to match MRI images would also enable such applications as indexing and searching MRI images among multiple patients or selecting images from the region of interest. In this work, we have introduced robustness, accuracy and cumulative distance metrics and methodology that allows us to compare different techniques and approaches in matching brain MRI of different patients or matching MRI brain slice to a position in the brain atlas. To that end, we have used feature detection methods AGAST, AKAZE, BRISK, GFTT, HardNet, and ORB, which are established methods in image processing, and compared them on their resistance to image degradation and their ability to match the same brain MRI slice of different patients. We have demonstrated that some of these techniques can correctly match most of the brain MRI slices of different patients. When matching is performed with the atlas of the human brain, their performance is significantly lower. The best performing feature detection method was a combination of SIFT detector and HardNet descriptor that achieved 93% accuracy in matching images with other patients and only 52% accurately matched images when compared to atlas.","created":"2023-02-08","meta":{"link":"http://arxiv.org/abs/2302.04173v1","tag":"medical-cv"}}
{"title":"Learning from pseudo-labels: deep networks improve consistency in longitudinal brain volume estimation","abstract":"Brain atrophy is an important biomarker for monitoring neurodegeneration and disease progression in conditions such as multiple sclerosis (MS). An accurate and robust quantitative measurement of brain volume change is paramount for translational research and clinical applications. This paper presents a deep learning based method, DeepBVC, for longitudinal brain volume change measurement using 3D T1-weighted MRI scans. Trained with the intermediate outputs from SIENA, DeepBVC is designed to take into account the variance caused by different scanners and acquisition protocols. Compared with SIENA, DeepBVC demonstrates higher consistency in terms of volume change estimation across multiple time points in MS subjects; and greater stability and superior performance in scan-rescan experiments. Moreover, the results also show that DeepBVC is insensitive to acquisition variance in terms of imaging contrast, voxel resolution, random bias field and signal-to-noise ratio. Measurement robustness, automation and processing speed suggest a broad potential of DeepBVC in both research and clinical quantitative neuroimaging applications.","created":"2023-02-08","meta":{"link":"http://arxiv.org/abs/2302.03975v1","tag":"medical-cv"}}
{"title":"Med-NCA: Robust and Lightweight Segmentation with Neural Cellular Automata","abstract":"Access to the proper infrastructure is critical when performing medical image segmentation with Deep Learning. This requirement makes it difficult to run state-of-the-art segmentation models in resource-constrained scenarios like primary care facilities in rural areas and during crises. The recently emerging field of Neural Cellular Automata (NCA) has shown that locally interacting one-cell models can achieve competitive results in tasks such as image generation or segmentations in low-resolution inputs. However, they are constrained by high VRAM requirements and the difficulty of reaching convergence for high-resolution images. To counteract these limitations we propose Med-NCA, an end-to-end NCA training pipeline for high-resolution image segmentation. Our method follows a two-step process. Global knowledge is first communicated between cells across the downscaled image. Following that, patch-based segmentation is performed. Our proposed Med-NCA outperforms the classic UNet by 2% and 3% Dice for hippocampus and prostate segmentation, respectively, while also being 500 times smaller. We also show that Med-NCA is by design invariant with respect to image scale, shape and translation, experiencing only slight performance degradation even with strong shifts; and is robust against MRI acquisition artefacts. Med-NCA enables high-resolution medical image segmentation even on a Raspberry Pi B+, arguably the smallest device able to run PyTorch and that can be powered by a standard power bank.","created":"2023-02-07","meta":{"link":"http://arxiv.org/abs/2302.03473v1","tag":"medical-cv"}}
{"title":"Improving CT Image Segmentation Accuracy Using StyleGAN Driven Data Augmentation","abstract":"Medical Image Segmentation is a useful application for medical image analysis including detecting diseases and abnormalities in imaging modalities such as MRI, CT etc. Deep learning has proven to be promising for this task but usually has a low accuracy because of the lack of appropriate publicly available annotated or segmented medical datasets. In addition, the datasets that are available may have a different texture because of different dosage values or scanner properties than the images that need to be segmented. This paper presents a StyleGAN-driven approach for segmenting publicly available large medical datasets by using readily available extremely small annotated datasets in similar modalities. The approach involves augmenting the small segmented dataset and eliminating texture differences between the two datasets. The dataset is augmented by being passed through six different StyleGANs that are trained on six different style images taken from the large non-annotated dataset we want to segment. Specifically, style transfer is used to augment the training dataset. The annotations of the training dataset are hence combined with the textures of the non-annotated dataset to generate new anatomically sound images. The augmented dataset is then used to train a U-Net segmentation network which displays a significant improvement in the segmentation accuracy in segmenting the large non-annotated dataset.","created":"2023-02-07","meta":{"link":"http://arxiv.org/abs/2302.03285v1","tag":"medical-cv"}}
{"title":"DDM$^2$: Self-Supervised Diffusion MRI Denoising with Generative Diffusion Models","abstract":"Magnetic resonance imaging (MRI) is a common and life-saving medical imaging technique. However, acquiring high signal-to-noise ratio MRI scans requires long scan times, resulting in increased costs and patient discomfort, and decreased throughput. Thus, there is great interest in denoising MRI scans, especially for the subtype of diffusion MRI scans that are severely SNR-limited. While most prior MRI denoising methods are supervised in nature, acquiring supervised training datasets for the multitude of anatomies, MRI scanners, and scan parameters proves impractical. Here, we propose Denoising Diffusion Models for Denoising Diffusion MRI (DDM$^2$), a self-supervised denoising method for MRI denoising using diffusion denoising generative models. Our three-stage framework integrates statistic-based denoising theory into diffusion models and performs denoising through conditional generation. During inference, we represent input noisy measurements as a sample from an intermediate posterior distribution within the diffusion Markov chain. We conduct experiments on 4 real-world in-vivo diffusion MRI datasets and show that our DDM$^2$ demonstrates superior denoising performances ascertained with clinically-relevant visual qualitative and quantitative metrics.","created":"2023-02-06","meta":{"link":"http://arxiv.org/abs/2302.03018v1","tag":"medical-cv"}}
{"title":"An Unsupervised Framework for Joint MRI Super Resolution and Gibbs Artifact Removal","abstract":"The k-space data generated from magnetic resonance imaging (MRI) is only a finite sampling of underlying signals. Therefore, MRI images often suffer from low spatial resolution and Gibbs ringing artifacts. Previous studies tackled these two problems separately, where super resolution methods tend to enhance Gibbs artifacts, whereas Gibbs ringing removal methods tend to blur the images. It is also a challenge that high resolution ground truth is hard to obtain in clinical MRI. In this paper, we propose an unsupervised learning framework for both MRI super resolution and Gibbs artifacts removal without using high resolution ground truth. Furthermore, we propose regularization methods to improve the model's generalizability across out-of-distribution MRI images. We evaluated our proposed methods with other state-of-the-art methods on eight MRI datasets with various contrasts and anatomical structures. Our method not only achieves the best SR performance but also significantly reduces the Gibbs artifacts. Our method also demonstrates good generalizability across different datasets, which is beneficial to clinical applications where training data are usually scarce and biased.","created":"2023-02-06","meta":{"link":"http://arxiv.org/abs/2302.02849v1","tag":"medical-cv"}}
{"title":"Accelerated Dynamic Magnetic Resonance Imaging from Spatial-Subspace Reconstructions (SPARS)","abstract":"Dynamic contrast-enhanced (DCE) magnetic resonance imaging (MRI) ideally requires a high spatial and high temporal resolution, but hardware limitations prevent acquisitions from simultaneously achieving both. Existing image reconstruction techniques can artificially create spatial resolution at a given temporal resolution by estimating data that is not acquired, but, ultimately, spatial details are sacrificed at very high acceleration rates. The purpose of this paper is to introduce the concept of spatial subspace reconstructions (SPARS) and demonstrate its ability to reconstruct high spatial resolution dynamic images from as few as one acquired radial spoke per dynamic frame. Briefly, a low-temporal-high-spatial resolution organization of the acquired raw data is used to estimate a spatial subspace in which the high-temporal-high-spatial ground truth data resides. This subspace is then used to estimate entire images from single k-space spokes. In both simulated and human in-vivo data, the proposed SPARS reconstruction method outperformed standard GRASP and GRASP-Pro reconstruction, providing a shorter reconstruction time and yielding higher accuracy from both a spatial and temporal perspective.","created":"2023-02-06","meta":{"link":"http://arxiv.org/abs/2302.02564v1","tag":"medical-cv"}}
{"title":"Active Learning in Brain Tumor Segmentation with Uncertainty Sampling, Annotation Redundancy Restriction, and Data Initialization","abstract":"Deep learning models have demonstrated great potential in medical 3D imaging, but their development is limited by the expensive, large volume of annotated data required. Active learning (AL) addresses this by training a model on a subset of the most informative data samples without compromising performance. We compared different AL strategies and propose a framework that minimizes the amount of data needed for state-of-the-art performance. 638 multi-institutional brain tumor MRI images were used to train a 3D U-net model and compare AL strategies. We investigated uncertainty sampling, annotation redundancy restriction, and initial dataset selection techniques. Uncertainty estimation techniques including Bayesian estimation with dropout, bootstrapping, and margins sampling were compared to random query. Strategies to avoid annotation redundancy by removing similar images within the to-be-annotated subset were considered as well. We determined the minimum amount of data necessary to achieve similar performance to the model trained on the full dataset ({\\alpha} = 0.1). A variance-based selection strategy using radiomics to identify the initial training dataset is also proposed. Bayesian approximation with dropout at training and testing showed similar results to that of the full data model with less than 20% of the training data (p=0.293) compared to random query achieving similar performance at 56.5% of the training data (p=0.814). Annotation redundancy restriction techniques achieved state-of-the-art performance at approximately 40%-50% of the training data. Radiomics dataset initialization had higher Dice with initial dataset sizes of 20 and 80 images, but improvements were not significant. In conclusion, we investigated various AL strategies with dropout uncertainty estimation achieving state-of-the-art performance with the least annotated data.","created":"2023-02-05","meta":{"link":"http://arxiv.org/abs/2302.10185v1","tag":"medical-cv"}}
{"title":"Selecting the Best Optimizers for Deep Learning based Medical Image Segmentation","abstract":"The goal of this work is to identify the best optimizers for deep learning in the context of cardiac image segmentation and to provide guidance on how to design segmentation networks with effective optimization strategies. Adaptive learning helps with fast convergence by starting with a larger learning rate (LR) and gradually decreasing it. Momentum optimizers are particularly effective at quickly optimizing neural networks within the accelerated schemes category. By revealing the potential interplay between these two types of algorithms (LR and momentum optimizers or momentum rate (MR) in short), in this article, we explore the two variants of SGD algorithms in a single setting. We suggest using cyclic learning as the base optimizer and integrating optimal values of learning rate and momentum rate. We investigated the relationship of LR and MR under an important problem of medical image segmentation of cardiac structures from MRI and CT scans. We conducted experiments using the cardiac imaging dataset from the ACDC challenge of MICCAI 2017, and four different architectures shown to be successful for cardiac image segmentation problems. Our comprehensive evaluations demonstrated that the proposed optimizer achieved better results (over a 2\\% improvement in the dice metric) than other optimizers in deep learning literature with similar or lower computational cost in both single and multi-object segmentation settings. We hypothesized that combination of accelerated and adaptive optimization methods can have a drastic effect in medical image segmentation performances. To this end, we proposed a new cyclic optimization method (\\textit{CLMR}) to address the efficiency and accuracy problems in deep learning based medical image segmentation. The proposed strategy yielded better generalization in comparison to adaptive optimizers.","created":"2023-02-05","meta":{"link":"http://arxiv.org/abs/2302.02289v1","tag":"medical-cv"}}
{"title":"Recurrence With Correlation Network for Medical Image Registration","abstract":"We present Recurrence with Correlation Network (RWCNet), a medical image registration network with multi-scale features and a cost volume layer. We demonstrate that these architectural features improve medical image registration accuracy in two image registration datasets prepared for the MICCAI 2022 Learn2Reg Workshop Challenge. On the large-displacement National Lung Screening Test (NLST) dataset, RWCNet is able to achieve a total registration error (TRE) of 2.11mm between corresponding keypoints without instance fine-tuning. On the OASIS brain MRI dataset, RWCNet is able to achieve an average dice overlap of 81.7% for 35 different anatomical labels. It outperforms another multi-scale network, the Laplacian Image Registration Network (LapIRN), on both datasets. Ablation experiments are performed to highlight the contribution of the various architectural features. While multi-scale features improved validation accuracy for both datasets, the cost volume layer and number of recurrent steps only improved performance on the large-displacement NLST dataset. This result suggests that cost volume layer and iterative refinement using RNN provide good support for optimization and generalization in large-displacement medical image registration. The code for RWCNet is available at https://github.com/vigsivan/optimization-based-registration.","created":"2023-02-05","meta":{"link":"http://arxiv.org/abs/2302.02283v1","tag":"medical-cv"}}
{"title":"IMPORTANT-Net: Integrated MRI Multi-Parameter Reinforcement Fusion Generator with Attention Network for Synthesizing Absent Data","abstract":"Magnetic resonance imaging (MRI) is highly sensitive for lesion detection in the breasts. Sequences obtained with different settings can capture the specific characteristics of lesions. Such multi-parameter MRI information has been shown to improve radiologist performance in lesion classification, as well as improving the performance of artificial intelligence models in various tasks. However, obtaining multi-parameter MRI makes the examination costly in both financial and time perspectives, and there may be safety concerns for special populations, thus making acquisition of the full spectrum of MRI sequences less durable. In this study, different than naive input fusion or feature concatenation from existing MRI parameters, a novel $\\textbf{I}$ntegrated MRI $\\textbf{M}$ulti-$\\textbf{P}$arameter reinf$\\textbf{O}$rcement fusion generato$\\textbf{R}$ wi$\\textbf{T}$h $\\textbf{A}$tte$\\textbf{NT}$ion Network (IMPORTANT-Net) is developed to generate missing parameters. First, the parameter reconstruction module is used to encode and restore the existing MRI parameters to obtain the corresponding latent representation information at any scale level. Then the multi-parameter fusion with attention module enables the interaction of the encoded information from different parameters through a set of algorithmic strategies, and applies different weights to the information through the attention mechanism after information fusion to obtain refined representation information. Finally, a reinforcement fusion scheme embedded in a $V^{-}$-shape generation module is used to combine the hierarchical representations to generate the missing MRI parameter. Results showed that our IMPORTANT-Net is capable of generating missing MRI parameters and outperforms comparable state-of-the-art networks. Our code is available at https://github.com/Netherlands-Cancer-Institute/MRI_IMPORTANT_NET.","created":"2023-02-03","meta":{"link":"http://arxiv.org/abs/2302.01788v1","tag":"medical-cv"}}
{"title":"Three-dimensional Global Simulations of Type-II Planet-disk Interaction with a Magnetized Disk Wind: I. Magnetic Flux Concentration and Gap Properties","abstract":"Giant planets embedded in protoplanetary disks (PPDs) can create annulus density gaps around their orbits in the type-II regime, potentially responsible for the ubiquity of annular substructures observed in PPDs. Despite of substantial amount of works studying type-II planet migration and gap properties, they are almost exclusively conducted under the viscous accretion disk framework. However, recent studies have established magnetized disk winds as the primary driving disk accretion and evolution, which can co-exist with turbulence from the magneto-rotational instability (MRI) in the outer PPDs. We conduct a series of 3D global non-ideal magneto-hydrodynamic (MHD) simulations of type-II planet-disk interaction applicable to the outer PPDs. Our simulations properly resolve the MRI turbulence and accommodate the MHD disk wind. We found that the planet triggers the poloidal magnetic flux concentration around its orbit. The concentrated magnetic flux strongly enhances angular momentum removal in the gap, which is along the inclined poloidal field through a strong outflow emanating from the disk surface outward of the planet gap. The resulting planet-induced gap shape is more similar to an inviscid disk, while being much deeper, which can be understood from a simple inhomogeneous wind torque prescription. The corotation region is characterized by a fast trans-sonic accretion flow that is asymmetric in azimuth about the planet and lacking the horseshoe turns, and the meridional flow is weakened. The torque acting on the planet generally drives inward migration, though the migration rate can be affected by the presence of neighboring gaps through stochastic, planet-free magnetic flux concentration.","created":"2023-02-03","meta":{"link":"http://arxiv.org/abs/2302.01514v1","tag":"medical-cv"}}
{"title":"Deep Learning (DL)-based Automatic Segmentation of the Internal Pudendal Artery (IPA) for Reduction of Erectile Dysfunction in Definitive Radiotherapy of Localized Prostate Cancer","abstract":"Background and purpose: Radiation-induced erectile dysfunction (RiED) is commonly seen in prostate cancer patients. Clinical trials have been developed in multiple institutions to investigate whether dose-sparing to the internal-pudendal-arteries (IPA) will improve retention of sexual potency. The IPA is usually not considered a conventional organ-at-risk (OAR) due to segmentation difficulty. In this work, we propose a deep learning (DL)-based auto-segmentation model for the IPA that utilizes CT and MRI or CT alone as the input image modality to accommodate variation in clinical practice. Materials and methods: 86 patients with CT and MRI images and noisy IPA labels were recruited in this study. We split the data into 42/14/30 for model training, testing, and a clinical observer study, respectively. There were three major innovations in this model: 1) we designed an architecture with squeeze-and-excite blocks and modality attention for effective feature extraction and production of accurate segmentation, 2) a novel loss function was used for training the model effectively with noisy labels, and 3) modality dropout strategy was used for making the model capable of segmentation in the absence of MRI. Results: The DSC, ASD, and HD95 values for the test dataset were 62.2%, 2.54mm, and 7mm, respectively. AI segmented contours were dosimetrically equivalent to the expert physician's contours. The observer study showed that expert physicians' scored AI contours (mean=3.7) higher than inexperienced physicians' contours (mean=3.1). When inexperienced physicians started with AI contours, the score improved to 3.7. Conclusion: The proposed model achieved good quality IPA contours to improve uniformity of segmentation and to facilitate introduction of standardized IPA segmentation into clinical trials and practice.","created":"2023-02-03","meta":{"link":"http://arxiv.org/abs/2302.01493v1","tag":"medical-cv"}}
{"title":"A Convolutional-based Model for Early Prediction of Alzheimer's based on the Dementia Stage in the MRI Brain Images","abstract":"Alzheimer's disease is a degenerative brain disease. Being the primary cause of Dementia in adults and progressively destroys brain memory. Though Alzheimer's disease does not have a cure currently, diagnosing it at an earlier stage will help reduce the severity of the disease. Thus, early diagnosis of Alzheimer's could help to reduce or stop the disease from progressing. In this paper, we proposed a deep convolutional neural network-based model for learning model using to determine the stage of Dementia in adults based on the Magnetic Resonance Imaging (MRI) images to detect the early onset of Alzheimer's.","created":"2023-02-02","meta":{"link":"http://arxiv.org/abs/2302.01417v2","tag":"medical-cv"}}
{"title":"Local implicit neural representations for multi-sequence MRI translation","abstract":"In radiological practice, multi-sequence MRI is routinely acquired to characterize anatomy and tissue. However, due to the heterogeneity of imaging protocols and contra-indications to contrast agents, some MRI sequences, e.g. contrast-enhanced T1-weighted image (T1ce), may not be acquired. This creates difficulties for large-scale clinical studies for which heterogeneous datasets are aggregated. Modern deep learning techniques have demonstrated the capability of synthesizing missing sequences from existing sequences, through learning from an extensive multi-sequence MRI dataset. In this paper, we propose a novel MR image translation solution based on local implicit neural representations. We split the available MRI sequences into local patches and assign to each patch a local multi-layer perceptron (MLP) that represents a patch in the T1ce. The parameters of these local MLPs are generated by a hypernetwork based on image features. Experimental results and ablation studies on the BraTS challenge dataset showed that the local MLPs are critical for recovering fine image and tumor details, as they allow for local specialization that is highly important for accurate image translation. Compared to a classical pix2pix model, the proposed method demonstrated visual improvement and significantly improved quantitative scores (MSE 0.86 x 10^-3 vs. 1.02 x 10^-3 and SSIM 94.9 vs 94.3)","created":"2023-02-02","meta":{"link":"http://arxiv.org/abs/2302.01031v1","tag":"medical-cv"}}
{"title":"Longformer: Longitudinal Transformer for Alzheimer's Disease Classification with Structural MRIs","abstract":"Structural magnetic resonance imaging (sMRI) is widely used for brain neurological disease diagnosis; while longitudinal MRIs are often collected to monitor and capture disease progression, as clinically used in diagnosing Alzheimer's disease (AD). However, most current methods neglect AD's progressive nature and only take a single sMRI for recognizing AD. In this paper, we consider the problem of leveraging the longitudinal MRIs of a subject for AD identification. To capture longitudinal changes in sMRIs, we propose a novel model Longformer, a spatiotemporal transformer network that performs attention mechanisms spatially on sMRIs at each time point and integrates brain region features over time to obtain longitudinal embeddings for classification. Our Longformer achieves state-of-the-art performance on two binary classification tasks of separating different stages of AD using the ADNI dataset. Our source code is available at https://github.com/Qybc/LongFormer.","created":"2023-02-02","meta":{"link":"http://arxiv.org/abs/2302.00901v2","tag":"medical-cv"}}
{"title":"Synthesis-based Imaging-Differentiation Representation Learning for Multi-Sequence 3D/4D MRI","abstract":"Multi-sequence MRIs can be necessary for reliable diagnosis in clinical practice due to the complimentary information within sequences. However, redundant information exists across sequences, which interferes with mining efficient representations by modern machine learning or deep learning models. To handle various clinical scenarios, we propose a sequence-to-sequence generation framework (Seq2Seq) for imaging-differentiation representation learning. In this study, not only do we propose arbitrary 3D/4D sequence generation within one model to generate any specified target sequence, but also we are able to rank the importance of each sequence based on a new metric estimating the difficulty of a sequence being generated. Furthermore, we also exploit the generation inability of the model to extract regions that contain unique information for each sequence. We conduct extensive experiments using three datasets including a toy dataset of 20,000 simulated subjects, a brain MRI dataset of 1,251 subjects, and a breast MRI dataset of 2,101 subjects, to demonstrate that (1) our proposed Seq2Seq is efficient and lightweight for complex clinical datasets and can achieve excellent image quality; (2) top-ranking sequences can be used to replace complete sequences with non-inferior performance; (3) combining MRI with our imaging-differentiation map leads to better performance in clinical tasks such as glioblastoma MGMT promoter methylation status prediction and breast cancer pathological complete response status prediction. Our code is available at https://github.com/fiy2W/mri_seq2seq.","created":"2023-02-01","meta":{"link":"http://arxiv.org/abs/2302.00517v1","tag":"medical-cv"}}
{"title":"Fast and direct inversion methods for the multivariate nonequispaced fast Fourier transform","abstract":"The well-known discrete Fourier transform (DFT) can easily be generalized to arbitrary nodes in the spatial domain. The fast procedure for this generalization is referred to as nonequispaced fast Fourier transform (NFFT). Various applications such as MRI, solution of PDEs, etc., are interested in the inverse problem, i.,e., computing Fourier coefficients from given nonequispaced data. In this paper we survey different kinds of approaches to tackle this problem. In contrast to iterative procedures, where multiple iteration steps are needed for computing a solution, we focus especially on so-called direct inversion methods. We review density compensation techniques and introduce a new scheme that leads to an exact reconstruction for trigonometric polynomials. In addition, we consider a matrix optimization approach using Frobenius norm minimization to obtain an inverse NFFT.","created":"2023-02-01","meta":{"link":"http://arxiv.org/abs/2302.00414v1","tag":"medical-cv"}}
{"title":"iPAL: A Machine Learning Based Smart Healthcare Framework For Automatic Diagnosis Of Attention Deficit/Hyperactivity Disorder (ADHD)","abstract":"ADHD is a prevalent disorder among the younger population. Standard evaluation techniques currently use evaluation forms, interviews with the patient, and more. However, its symptoms are similar to those of many other disorders like depression, conduct disorder, and oppositional defiant disorder, and these current diagnosis techniques are not very effective. Thus, a sophisticated computing model holds the potential to provide a promising diagnosis solution to this problem. This work attempts to explore methods to diagnose ADHD using combinations of multiple established machine learning techniques like neural networks and SVM models on the ADHD200 dataset and explore the field of neuroscience. In this work, multiclass classification is performed on phenotypic data using an SVM model. The better results have been analyzed on the phenotypic data compared to other supervised learning techniques like Logistic regression, KNN, AdaBoost, etc. In addition, neural networks have been implemented on functional connectivity from the MRI data of a sample of 40 subjects provided to achieve high accuracy without prior knowledge of neuroscience. It is combined with the phenotypic classifier using the ensemble technique to get a binary classifier. It is further trained and tested on 400 out of 824 subjects from the ADHD200 data set and achieved an accuracy of 92.5% for binary classification The training and testing accuracy has been achieved upto 99% using ensemble classifier.","created":"2023-02-01","meta":{"link":"http://arxiv.org/abs/2302.00332v1","tag":"medical-cv"}}
{"title":"Review of methods for automatic cerebral microbleeds detection","abstract":"Cerebral microbleeds detection is an important and challenging task. With the gaining popularity of the MRI, the ability to detect cerebral microbleeds also raises. Unfortunately, for radiologists, it is a time-consuming and laborious procedure. For this reason, various solutions to automate this process have been proposed for several years, but none of them is currently used in medical practice. In this context, the need to systematize the existing knowledge and best practices has been recognized as a factor facilitating the imminent synthesis of a real CMBs detection system practically applicable in medicine. To the best of our knowledge, all available publications regarding automatic cerebral microbleeds detection have been gathered, described, and assessed in this paper in order to distinguish the current research state and provide a starting point for future studies.","created":"2023-01-31","meta":{"link":"http://arxiv.org/abs/2301.13549v1","tag":"medical-cv"}}
{"title":"BabelBrain: An Open-Source Application for Prospective Modeling of Transcranial Focused Ultrasound for Neuromodulation Applications","abstract":"BabelBrain is an open-source standalone graphic-user-interface application designed for studies of neuromodulation using transcranial focused ultrasound. It calculates the transmitted acoustic field in the brain tissue, taking into account the distortion effects caused by the skull barrier. The simulation is prepared using scans from magnetic resonance imaging (MRI) and, if available, computed tomography and zero-echo time MRI scans. It also calculates the thermal effects based on a given ultrasound regime, such as the total duration of exposure, the duty cycle, and acoustic intensity. The tool is designed to work in tandem with neuronavigation and visualization software, such as 3DSlicer. It uses image processing to prepare domains for ultrasound simulation and uses the BabelViscoFDTD library for transcranial modeling calculations. BabelBrain supports multiple GPU backends, including Metal, OpenCL, and CUDA, and works on all major operating systems including Linux, MacOS, and Windows. This tool is particularly optimized for Apple ARM64 systems, which are common in brain imaging research. The paper presents the modeling pipeline used in BabelBrain and a numerical study where different methods of acoustic properties mapping were tested to select the best method that can reproduce the transcranial pressure transmission efficiency reported in the literature.","created":"2023-01-30","meta":{"link":"http://arxiv.org/abs/2301.12727v2","tag":"medical-cv"}}
{"title":"Global Three-Dimensional Radiation Magnetohydrodynamic Simulations of Accretion onto a Stellar Mass Black Hole at Sub- and Near-critical Accretion Rates","abstract":"We present global 3D radiation magnetohydrodynamical simulations of accretion onto a 6.62 solar mass black hole with quasi-steady state accretion rates reaching 0.016 to 0.9 times the critical accretion rate, which is defined as the accretion rate to power the Eddington luminosity assuming a 10% radiative efficiency, in different runs. The simulations show no sign of thermal instability over hundreds of thermal timescales at 10 $r_{\\rm g}$. The energy dissipation happens close to the mid-plane in the near-critical runs and near the disk surface in the low accretion rate run. The total radiative luminosity inside $\\sim$20 $r_{\\rm g}$ is about 1% to 30% the Eddington limit, with a radiative efficiency of about 6% and 3%, respectively, in the sub- and near-critical accretion regimes. In both cases, self-consistent turbulence generated by the magnetorotational instability (MRI) leads to angular momentum transfer, and the disk is supported by magnetic pressure. Outflows from the central low-density funnel with a terminal velocity of $\\sim$0.1$c$ are seen only in the near-critical runs. We conclude that these magnetic pressure dominated disks are thermally stable and thicker than the $\\alpha$ disk, and the effective temperature profiles are much flatter than that in the $\\alpha$ disks. The magnetic pressure of these disks are comparable within an order of magnitude with the previous analytical magnetic pressure dominated disk model.","created":"2023-01-30","meta":{"link":"http://arxiv.org/abs/2301.12679v1","tag":"medical-cv"}}
{"title":"Implementing a Hybrid Quantum-Classical Neural Network by Utilizing a Variational Quantum Circuit for Detection of Dementia","abstract":"Magnetic resonance imaging (MRI) is a common technique to scan brains for strokes, tumors, and other abnormalities that cause forms of dementia. However, correctly diagnosing forms of dementia from MRIs is difficult, as nearly 1 in 3 patients with Alzheimer's were misdiagnosed in 2019, an issue neural networks can rectify. Quantum computing applications This proposed novel neural network architecture uses a fully-connected (FC) layer, which reduces the number of features to obtain an expectation value by implementing a variational quantum circuit (VQC). The VQC created in this study utilizes a layer of Hadamard gates, Rotation-Y gates that are parameterized by tanh(intensity) * (pi/2) of a pixel, controlled-not (CNOT) gates, and measurement operators to obtain the expected values. This study found that the proposed hybrid quantum-classical convolutional neural network (QCCNN) provided 97.5% and 95.1% testing and validation accuracies, respectively, which was considerably higher than the classical neural network (CNN) testing and validation accuracies of 91.5% and 89.2%. Additionally, using a testing set of 100 normal and 100 dementia MRI images, the QCCNN detected normal and demented images correctly 95% and 98% of the time, compared to the CNN accuracies of 89% and 91%. With hospitals like Massachusetts General Hospital beginning to adopt machine learning applications for biomedical image detection, this proposed architecture would approve accuracies and potentially save more lives. Furthermore, the proposed architecture is generally flexible, and can be used for transfer-learning tasks, saving time and resources.","created":"2023-01-29","meta":{"link":"http://arxiv.org/abs/2301.12505v1","tag":"medical-cv"}}
{"title":"Machine-learning-informed parameter estimation improves the reliability of spinal cord diffusion MRI","abstract":"Purpose: We address the challenge of inaccurate parameter estimation in diffusion MRI when the signal-to-noise ratio (SNR) is very low, as in the spinal cord. The accuracy of conventional maximum-likelihood estimation (MLE) depends highly on initialisation. Unfavourable choices could result in suboptimal parameter estimates. Current methods to address this issue, such as grid search (GS) can increase computation time substantially. Methods: We propose a machine learning (ML) informed MLE approach that combines conventional MLE with ML approaches synergistically. ML-based methods have been developed recently to improve the speed and precision of parameter estimation. However, they can generate high systematic bias in estimated parameters when SNR is low. In the proposed ML-MLE approach, an artificial neural network model is trained to provide sensible initialisation for MLE efficiently, with the final solution determined by MLE, avoiding biases typically affecting pure ML estimations. Results: Using parameter estimation of neurite orientation dispersion and density imaging as an example, simulation and in vivo experiments suggest that the ML-MLE method can reduce outlier estimates from conventional MLE in white matter voxels affected by CSF contamination. It also accelerates computation compared to GS-MLE. Conclusion: The ML-MLE method can improve the reliability of parameter estimation with reduced computation time compared to GS-MLE, making it a practical tool for diffusion dataset with low SNR.","created":"2023-01-28","meta":{"link":"http://arxiv.org/abs/2301.12294v1","tag":"medical-cv"}}
{"title":"Neural Gas Network Image Features and Segmentation for Brain Tumor Detection Using Magnetic Resonance Imaging Data","abstract":"Accurate detection of brain tumors could save lots of lives and increasing the accuracy of this binary classification even as much as a few percent has high importance. Neural Gas Networks (NGN) is a fast, unsupervised algorithm that could be used in data clustering, image pattern recognition, and image segmentation. In this research, we used the metaheuristic Firefly Algorithm (FA) for image contrast enhancement as pre-processing and NGN weights for feature extraction and segmentation of Magnetic Resonance Imaging (MRI) data on two brain tumor datasets from the Kaggle platform. Also, tumor classification is conducted by Support Vector Machine (SVM) classification algorithms and compared with a deep learning technique plus other features in train and test phases. Additionally, NGN tumor segmentation is evaluated by famous performance metrics such as Accuracy, F-measure, Jaccard, and more versus ground truth data and compared with traditional segmentation techniques. The proposed method is fast and precise in both tasks of tumor classification and segmentation compared with other methods. A classification accuracy of 95.14 % and segmentation accuracy of 0.977 is achieved by the proposed method.","created":"2023-01-28","meta":{"link":"http://arxiv.org/abs/2301.12176v1","tag":"medical-cv"}}
{"title":"Hierarchical Perception Adversarial Learning Framework for Compressed Sensing MRI","abstract":"The long acquisition time has limited the accessibility of magnetic resonance imaging (MRI) because it leads to patient discomfort and motion artifacts. Although several MRI techniques have been proposed to reduce the acquisition time, compressed sensing in magnetic resonance imaging (CS-MRI) enables fast acquisition without compromising SNR and resolution. However, existing CS-MRI methods suffer from the challenge of aliasing artifacts. This challenge results in the noise-like textures and missing the fine details, thus leading to unsatisfactory reconstruction performance. To tackle this challenge, we propose a hierarchical perception adversarial learning framework (HP-ALF). HP-ALF can perceive the image information in the hierarchical mechanism: image-level perception and patch-level perception. The former can reduce the visual perception difference in the entire image, and thus achieve aliasing artifact removal. The latter can reduce this difference in the regions of the image, and thus recover fine details. Specifically, HP-ALF achieves the hierarchical mechanism by utilizing multilevel perspective discrimination. This discrimination can provide the information from two perspectives (overall and regional) for adversarial learning. It also utilizes a global and local coherent discriminator to provide structure information to the generator during training. In addition, HP-ALF contains a context-aware learning block to effectively exploit the slice information between individual images for better reconstruction performance. The experiments validated on three datasets demonstrate the effectiveness of HP-ALF and its superiority to the comparative methods.","created":"2023-01-27","meta":{"link":"http://arxiv.org/abs/2302.10309v1","tag":"medical-cv"}}
{"title":"Harmonizing Flows: Unsupervised MR harmonization based on normalizing flows","abstract":"In this paper, we propose an unsupervised framework based on normalizing flows that harmonizes MR images to mimic the distribution of the source domain. The proposed framework consists of three steps. First, a shallow harmonizer network is trained to recover images of the source domain from their augmented versions. A normalizing flow network is then trained to learn the distribution of the source domain. Finally, at test time, a harmonizer network is modified so that the output images match the source domain's distribution learned by the normalizing flow model. Our unsupervised, source-free and task-independent approach is evaluated on cross-domain brain MRI segmentation using data from four different sites. Results demonstrate its superior performance compared to existing methods.","created":"2023-01-27","meta":{"link":"http://arxiv.org/abs/2301.11551v1","tag":"medical-cv"}}
{"title":"Anatomy-aware and acquisition-agnostic joint registration with SynthMorph","abstract":"Affine image registration is a cornerstone of medical-image processing and analysis. While classical algorithms can achieve excellent accuracy, they solve a time-consuming optimization for every new image pair. Deep-learning (DL) methods learn a function that maps an image pair to an output transform. Evaluating the functions is fast, but capturing large transforms can be challenging, and networks tend to struggle if a test-image characteristic shifts from the training domain, such as the contrast or resolution. A majority of affine methods are also agnostic to the anatomy the user wishes to align; the registration will be inaccurate if algorithms consider all structures in the image. We address these shortcomings with a fast, robust, and easy-to-use DL tool for affine and deformable registration of any brain image without preprocessing, right off the MRI scanner. First, we rigorously analyze how competing architectures learn affine transforms across a diverse set of neuroimaging data, aiming to truly capture the behavior of methods in the real world. Second, we leverage a recent strategy to train networks with wildly varying images synthesized from label maps, yielding robust performance across acquisition specifics. Third, we optimize the spatial overlap of select anatomical labels, which enables networks to distinguish between anatomy of interest and irrelevant structures, removing the need for preprocessing that excludes content that would otherwise reduce the accuracy of anatomy-specific registration. We combine the affine model with prior work on deformable registration and test brain-specific registration across a landscape of MRI protocols unseen at training, demonstrating consistent and improved accuracy compared to existing tools. We distribute our code and tool at https://w3id.org/synthmorph, providing a single complete end-to-end solution for registration of brain MRI.","created":"2023-01-26","meta":{"link":"http://arxiv.org/abs/2301.11329v1","tag":"medical-cv"}}
{"title":"Gene-SGAN: a method for discovering disease subtypes with imaging and genetic signatures via multi-view weakly-supervised deep clustering","abstract":"Disease heterogeneity has been a critical challenge for precision diagnosis and treatment, especially in neurologic and neuropsychiatric diseases. Many diseases can display multiple distinct brain phenotypes across individuals, potentially reflecting disease subtypes that can be captured using MRI and machine learning methods. However, biological interpretability and treatment relevance are limited if the derived subtypes are not associated with genetic drivers or susceptibility factors. Herein, we describe Gene-SGAN - a multi-view, weakly-supervised deep clustering method - which dissects disease heterogeneity by jointly considering phenotypic and genetic data, thereby conferring genetic correlations to the disease subtypes and associated endophenotypic signatures. We first validate the generalizability, interpretability, and robustness of Gene-SGAN in semi-synthetic experiments. We then demonstrate its application to real multi-site datasets from 28,858 individuals, deriving subtypes of Alzheimer's disease and brain endophenotypes associated with hypertension, from MRI and SNP data. Derived brain phenotypes displayed significant differences in neuroanatomical patterns, genetic determinants, biological and clinical biomarkers, indicating potentially distinct underlying neuropathologic processes, genetic drivers, and susceptibility factors. Overall, Gene-SGAN is broadly applicable to disease subtyping and endophenotype discovery, and is herein tested on disease-related, genetically-driven neuroimaging phenotypes.","created":"2023-01-25","meta":{"link":"http://arxiv.org/abs/2301.10772v1","tag":"medical-cv"}}
{"title":"JointNET: A Deep Model for Predicting Active Sacroiliitis from Sacroiliac Joint Radiography","abstract":"Purpose: To develop a deep learning model that predicts active inflammation from sacroiliac joint radiographs and to compare the success with radiologists. Materials and Methods: A total of 1,537 (augmented 1752) grade 0 SIJs of 768 patients were retrospectively analyzed. Gold-standard MRI exams showed active inflammation in 330 joints according to ASAS criteria. A convolutional neural network model (JointNET) was developed to detect MRI-based active inflammation labels solely based on radiographs. Two radiologists blindly evaluated the radiographs for comparison. Python, PyTorch, and SPSS were used for analyses. P<0.05 was considered statistically significant. Results: JointNET differentiated active inflammation from radiographs with a mean AUROC of 89.2 (95% CI:86.8%, 91.7%). The sensitivity was 69.0% (95% CI:65.3%, 72.7%) and specificity 90.4% (95% CI:87.8 % 92.9%). The mean accuracy was 90.2% (95% CI: 87.6%, 92.8%). The positive predictive value was 74.6% (95% CI: 72.5%, 76.7%) and negative predictive value was 87.9% (95% CI: 85.4%, 90.5%) when prevalence was considered 1%. Statistical analyses showed a significant difference between active inflammation and healthy groups (p<0.05). Radiologists accuracies were less than 65% to discriminate active inflammation from sacroiliac joint radiographs. Conclusion: JointNET successfully predicts active inflammation from sacroiliac joint radiographs, with superior performance to human observers.","created":"2023-01-25","meta":{"link":"http://arxiv.org/abs/2301.10769v2","tag":"medical-cv"}}
{"title":"Data Consistent Deep Rigid MRI Motion Correction","abstract":"Motion artifacts are a pervasive problem in MRI, leading to misdiagnosis or mischaracterization in population-level imaging studies. Current retrospective rigid intra-slice motion correction techniques jointly optimize estimates of the image and the motion parameters. In this paper, we use a deep network to reduce the joint image-motion parameter search to a search over rigid motion parameters alone. Our network produces a reconstruction as a function of two inputs: corrupted k-space data and motion parameters. We train the network using simulated, motion-corrupted k-space data generated from known motion parameters. At test-time, we estimate unknown motion parameters by minimizing a data consistency loss between the motion parameters, the network-based image reconstruction given those parameters, and the acquired measurements. Intra-slice motion correction experiments on simulated and realistic 2D fast spin echo brain MRI achieve high reconstruction fidelity while retaining the benefits of explicit data consistency-based optimization. Our code is publicly available at https://www.github.com/nalinimsingh/neuroMoCo.","created":"2023-01-25","meta":{"link":"http://arxiv.org/abs/2301.10365v1","tag":"medical-cv"}}
{"title":"Correction of high-order phase variation effects in dynamic field monitoring","abstract":"Purpose: Field monitoring measures field perturbations, which can be accounted for during image reconstructions. In certain field monitoring environments, significant phase deviations can arise far from isocenter due to the finite extent of the gradient and/or main magnet. This can degrade the accuracy of field dynamics when field probes are placed near or outside the diameter spherical volume of the gradient coils and/or main magnet, leading to corrupted image quality. The objective of this work was to develop a correction algorithm that reduces errors from highly nonlinear phase variations at distant field probes in field dynamic fits. Methods: The algorithm is split into three components. Component one fits phase coefficients one spatial order at a time, while the second implements a weighted least squares solution based on probe distance. After initial fitting, component three calculates phase residuals and removes the phase for distant probes before re-fitting. Two healthy volunteers were scanned on a head-only 7T MRI using diffusion-weighted single-shot spiral and EPI sequences and field monitoring was performed. Images were reconstructed with and without phase coefficient correction and compared qualitatively. Results: The algorithm was able to correct corrupted field dynamics, resulting in image quality improvements. Significant artefact reduction was observed when correcting higher order fits, especially for diffusion weighted images. Stepwise fitting provided the most correction benefit, which was marginally improved when adding weighted least squares and phase residual corrections. Conclusion: The proposed algorithm can mitigate effects of phase errors in field monitoring, providing improved reliability of field dynamic characterization.","created":"2023-01-23","meta":{"link":"http://arxiv.org/abs/2301.09726v1","tag":"medical-cv"}}
{"title":"DELTA-MRI: Direct deformation Estimation from LongiTudinally Acquired k-space data","abstract":"Longitudinal MRI is an important diagnostic imaging tool for evaluating the effects of treatment and monitoring disease progression. However, MRI, and particularly longitudinal MRI, is known to be time consuming. To accelerate imaging, compressed sensing (CS) theory has been applied to exploit sparsity, both on single image as on image sequence level. State-of-the-art CS methods however, are generally focused on image reconstruction, and consider analysis (e.g., alignment, change detection) as a post-processing step.   In this study, we propose DELTA-MRI, a novel framework to estimate longitudinal image changes {\\it directly} from a reference image and subsequently acquired, strongly sub-sampled MRI k-space data. In contrast to state-of-the-art longitudinal CS based imaging, our method avoids the conventional multi-step process of image reconstruction of subsequent images, image alignment, and deformation vector field computation. Instead, the set of follow-up images, along with motion and deformation vector fields that describe their relation to the reference image, are estimated in one go. Experiments show that DELTA-MRI performs significantly better than the state-of-the-art in terms of the normalized reconstruction error.","created":"2023-01-23","meta":{"link":"http://arxiv.org/abs/2301.09455v1","tag":"medical-cv"}}
{"title":"ViGU: Vision GNN U-Net for Fast MRI","abstract":"Deep learning models have been widely applied for fast MRI. The majority of existing deep learning models, e.g., convolutional neural networks, work on data with Euclidean or regular grids structures. However, high-dimensional features extracted from MR data could be encapsulated in non-Euclidean manifolds. This disparity between the go-to assumption of existing models and data requirements limits the flexibility to capture irregular anatomical features in MR data. In this work, we introduce a novel Vision GNN type network for fast MRI called Vision GNN U-Net (ViGU). More precisely, the pixel array is first embedded into patches and then converted into a graph. Secondly, a U-shape network is developed using several graph blocks in symmetrical encoder and decoder paths. Moreover, we show that the proposed ViGU can also benefit from Generative Adversarial Networks yielding to its variant ViGU-GAN. We demonstrate, through numerical and visual experiments, that the proposed ViGU and GAN variant outperform existing CNN and GAN-based methods. Moreover, we show that the proposed network readily competes with approaches based on Transformers while requiring a fraction of the computational cost. More importantly, the graph structure of the network reveals how the network extracts features from MR images, providing intuitive explainability.","created":"2023-01-23","meta":{"link":"http://arxiv.org/abs/2302.10273v1","tag":"medical-cv"}}
{"title":"On the determination of optimal tuning parameters for a space-variant LASSO problem using geometric and convex analysis techniques","abstract":"Compressed Sensing (CS) comprises a wide range of theoretical and applied techniques to recover signals given a partial knowledge of their coefficients. It finds its applications in several fields, such as mathematics, physics, engineering, and many medical sciences, to name a few. Driven by our interest in the mathematics behind Magnetic Resonance Imaging (MRI) and Compressed Sensing (CS), we use convex analysis techniques to determine analytically the optimal tuning parameters of the space-variant LASSO with voxel-wise weighting, under assumptions on the fidelity term, either on the sign of its gradient or orthogonality-like conditions on its matrix. Finally, we conclude conjecturing what the explicit form of optimal parameters should be in the most general setting (hypotheses-free) of the space-variant LASSO.","created":"2023-01-22","meta":{"link":"http://arxiv.org/abs/2301.09083v1","tag":"medical-cv"}}
{"title":"Successive Subspace Learning for Cardiac Disease Classification with Two-phase Deformation Fields from Cine MRI","abstract":"Cardiac cine magnetic resonance imaging (MRI) has been used to characterize cardiovascular diseases (CVD), often providing a noninvasive phenotyping tool.~While recently flourished deep learning based approaches using cine MRI yield accurate characterization results, the performance is often degraded by small training samples. In addition, many deep learning models are deemed a ``black box,\" for which models remain largely elusive in how models yield a prediction and how reliable they are. To alleviate this, this work proposes a lightweight successive subspace learning (SSL) framework for CVD classification, based on an interpretable feedforward design, in conjunction with a cardiac atlas. Specifically, our hierarchical SSL model is based on (i) neighborhood voxel expansion, (ii) unsupervised subspace approximation, (iii) supervised regression, and (iv) multi-level feature integration. In addition, using two-phase 3D deformation fields, including end-diastolic and end-systolic phases, derived between the atlas and individual subjects as input offers objective means of assessing CVD, even with small training samples. We evaluate our framework on the ACDC2017 database, comprising one healthy group and four disease groups. Compared with 3D CNN-based approaches, our framework achieves superior classification performance with 140$\\times$ fewer parameters, which supports its potential value in clinical use.","created":"2023-01-21","meta":{"link":"http://arxiv.org/abs/2301.08959v1","tag":"medical-cv"}}
{"title":"Dynamic MLP for MRI Reconstruction","abstract":"As convolutional neural networks (CNN) become the most successful reconstruction technique for accelerated Magnetic Resonance Imaging (MRI), CNN reaches its limit on image quality especially in sharpness. Further improvement on image quality often comes at massive computational costs, hindering their practicability in the clinic setting. MRI reconstruction is essentially a deconvolution problem, which demands long-distance information that is difficult to be captured by CNNs with small convolution kernels. The multi-layer perceptron (MLP) is able to model such long-distance information, but it restricts a fixed input size while the reconstruction of images in flexible resolutions is required in the clinic setting. In this paper, we proposed a hybrid CNN and MLP reconstruction strategy, featured by dynamic MLP (dMLP) that accepts arbitrary image sizes. Experiments were conducted using 3D multi-coil MRI. Our results suggested the proposed dMLP can improve image sharpness compared to its pure CNN counterpart, while costing minor additional GPU memory and computation time. We further compared the proposed dMLP with CNNs using large kernels and studied pure MLP-based reconstruction using a stack of 1D dMLPs, as well as its CNN counterpart using only 1D convolutions. We observed the enlarged receptive field has noticeably improved image quality, while simply using CNN with a large kernel leads to difficulties in training. Noticeably, the pure MLP-based method has been outperformed by CNN-involved methods, which matches the observations in other computer vision tasks for natural images.","created":"2023-01-21","meta":{"link":"http://arxiv.org/abs/2301.08868v1","tag":"medical-cv"}}
{"title":"Synthesis and characterization of PEG-coated Zn$_{0.3}$Mn$_x$Fe$_{2.7-x}$O$_4$ nanoparticles as the dual T1/T2-weighted MRI contrast agent","abstract":"Super-paramagnetic nanoparticles (NPs) have been widely explored as magnetic resonance imaging (MRI) contrast agents because of a combination of favorable magnetic properties, biocompability and ease of fabrication. MRI using traditional T1- or T2-weighted single mode contrast-enhanced techniques may yield inaccurate imaging results. In the present work, a T1/T2 dual mode contrast agent based on the super-paramagnetic zinc-manganese ferrite (Zn$_{0.3}$Mn$_x$Fe$_{2.7-x}$O$_4$, x= 0, 0.25, 0.75 and 1) NPs with small core size and a hydrophilic PEG surface coating is reported. The TEM, TGA and FTIR results confirmed the formation of a uniform coating on the NPs surface. The MRI analysis revealed that the Zn$_{0.3}$Mn$_{0.5}$Fe$_{2.2}$O$_4$ NPs had the maximum image contrast compared to other zinc-manganese ferrite samples. Cell viability evaluations revealed that the coated and uncoated particles did not inhibit cell growth pattern. The present PEG-coated Zn$_{0.3}$Mn$_{0.5}$Fe$_{2.2}$O$_4$ NPs can be utilized as a suitable T1/T2-weighted MRI contrast agent for better diagnostic of abnormalities in the organs or tissues.","created":"2023-01-21","meta":{"link":"http://arxiv.org/abs/2301.13788v1","tag":"medical-cv"}}
{"title":"On Retrospective k-space Subsampling schemes For Deep MRI Reconstruction","abstract":"Purpose: Acquiring fully-sampled MRI $k$-space data is time-consuming, and collecting accelerated data can reduce the acquisition time. Employing 2D Cartesian-rectilinear subsampling schemes is a conventional approach for accelerated acquisitions; however, this often results in imprecise reconstructions, even with the use of Deep Learning (DL), especially at high acceleration factors. Non-rectilinear or non-Cartesian trajectories can be implemented in MRI scanners as alternative subsampling options. This work investigates the impact of the $k$-space subsampling scheme on the quality of reconstructed accelerated MRI measurements produced by trained DL models.   Methods: The Recurrent Variational Network (RecurrentVarNet) was used as the DL-based MRI-reconstruction architecture. Cartesian, fully-sampled multi-coil $k$-space measurements from three datasets were retrospectively subsampled with different accelerations using eight distinct subsampling schemes: four Cartesian-rectilinear, two Cartesian non-rectilinear, and two non-Cartesian. Experiments were conducted in two frameworks: scheme-specific, where a distinct model was trained and evaluated for each dataset-subsampling scheme pair, and multi-scheme, where for each dataset a single model was trained on data randomly subsampled by any of the eight schemes and evaluated on data subsampled by all schemes.   Results: In both frameworks, RecurrentVarNets trained and evaluated on non-rectilinearly subsampled data demonstrated superior performance, particularly for high accelerations. In the multi-scheme setting, reconstruction performance on rectilinearly subsampled data improved when compared to the scheme-specific experiments.   Conclusion: Our findings demonstrate the potential for using DL-based methods, trained on non-rectilinearly subsampled measurements, to optimize scan time and image quality.","created":"2023-01-20","meta":{"link":"http://arxiv.org/abs/2301.08365v3","tag":"medical-cv"}}
{"title":"The role of noise in denoising models for anomaly detection in medical images","abstract":"Pathological brain lesions exhibit diverse appearance in brain images, in terms of intensity, texture, shape, size, and location. Comprehensive sets of data and annotations are difficult to acquire. Therefore, unsupervised anomaly detection approaches have been proposed using only normal data for training, with the aim of detecting outlier anomalous voxels at test time. Denoising methods, for instance classical denoising autoencoders (DAEs) and more recently emerging diffusion models, are a promising approach, however naive application of pixelwise noise leads to poor anomaly detection performance. We show that optimization of the spatial resolution and magnitude of the noise improves the performance of different model training regimes, with similar noise parameter adjustments giving good performance for both DAEs and diffusion models. Visual inspection of the reconstructions suggests that the training noise influences the trade-off between the extent of the detail that is reconstructed and the extent of erasure of anomalies, both of which contribute to better anomaly detection performance. We validate our findings on two real-world datasets (tumor detection in brain MRI and hemorrhage/ischemia/tumor detection in brain CT), showing good detection on diverse anomaly appearances. Overall, we find that a DAE trained with coarse noise is a fast and simple method that gives state-of-the-art accuracy. Diffusion models applied to anomaly detection are as yet in their infancy and provide a promising avenue for further research.","created":"2023-01-19","meta":{"link":"http://arxiv.org/abs/2301.08330v1","tag":"medical-cv"}}
{"title":"Position Regression for Unsupervised Anomaly Detection","abstract":"In recent years, anomaly detection has become an essential field in medical image analysis. Most current anomaly detection methods for medical images are based on image reconstruction. In this work, we propose a novel anomaly detection approach based on coordinate regression. Our method estimates the position of patches within a volume, and is trained only on data of healthy subjects. During inference, we can detect and localize anomalies by considering the error of the position estimate of a given patch. We apply our method to 3D CT volumes and evaluate it on patients with intracranial haemorrhages and cranial fractures. The results show that our method performs well in detecting these anomalies. Furthermore, we show that our method requires less memory than comparable approaches that involve image reconstruction. This is highly relevant for processing large 3D volumes, for instance, CT or MRI scans.","created":"2023-01-19","meta":{"link":"http://arxiv.org/abs/2301.08064v1","tag":"medical-cv"}}
{"title":"Active learning for medical image segmentation with stochastic batches","abstract":"The performance of learning-based algorithms improves with the amount of labelled data used for training. Yet, manually annotating data can be tedious and expensive, especially in medical image segmentation. To reduce manual labelling, active learning (AL) targets the most informative samples from the unlabelled set to annotate and add to the labelled training set. On one hand, most active learning works have focused on the classification or limited segmentation of natural images, despite active learning being highly desirable in the difficult task of medical image segmentation. On the other hand, uncertainty-based AL approaches notoriously offer sub-optimal batch-query strategies, while diversity-based methods tend to be computationally expensive. Over and above methodological hurdles, random sampling has proven an extremely difficult baseline to outperform when varying learning and sampling conditions. This work aims to take advantage of the diversity and speed offered by random sampling to improve the selection of uncertainty-based AL methods for segmenting medical images. More specifically, we propose to compute uncertainty at the level of batches instead of samples through an original use of stochastic batches during sampling in AL. Exhaustive experiments on medical image segmentation, with an illustration on MRI prostate imaging, show that the benefits of stochastic batches during sample selection are robust to a variety of changes in the training and sampling procedures.","created":"2023-01-18","meta":{"link":"http://arxiv.org/abs/2301.07670v1","tag":"medical-cv"}}
{"title":"Model-based inexact graph matching on top of CNNs for semantic scene understanding","abstract":"Deep learning based pipelines for semantic segmentation often ignore structural information available on annotated images used for training. We propose a novel post-processing module enforcing structural knowledge about the objects of interest to improve segmentation results provided by deep learning. This module corresponds to a \"many-to-one-or-none\" inexact graph matching approach, and is formulated as a quadratic assignment problem. Our approach is compared to a CNN-based segmentation (for various CNN backbones) on two public datasets, one for face segmentation from 2D RGB images (FASSEG), and the other for brain segmentation from 3D MRIs (IBSR). Evaluations are performed using two types of structural information (distances and directional relations, , this choice being a hyper-parameter of our generic framework). On FASSEG data, results show that our module improves accuracy of the CNN by about 6.3% (the Hausdorff distance decreases from 22.11 to 20.71). On IBSR data, the improvement is of 51% (the Hausdorff distance decreases from 11.01 to 5.4). In addition, our approach is shown to be resilient to small training datasets that often limit the performance of deep learning methods: the improvement increases as the size of the training dataset decreases.","created":"2023-01-18","meta":{"link":"http://arxiv.org/abs/2301.07468v1","tag":"medical-cv"}}
{"title":"Three-dimensional reconstruction and characterization of bladder deformations","abstract":"Background and Objective: Pelvic floor disorders are prevalent diseases and patient care remains difficult as the dynamics of the pelvic floor remains poorly known. So far, only 2D dynamic observations of straining exercises at excretion are available in the clinics and the understanding of three-dimensional pelvic organs mechanical defects is not yet achievable. In this context, we proposed a complete methodology for the 3D representation of the non-reversible bladder deformations during exercises, directly combined with synthesized 3D representation of the location of the highest strain areas on the organ surface. Methods: Novel image segmentation and registration approaches have been combined with three geometrical configurations of up-to-date rapid dynamic multi-slices MRI acquisition for the reconstruction of real-time dynamic bladder volumes. Results: For the first time, we proposed real-time 3D deformation fields of the bladder under strain from in-bore forced breathing exercises. The potential of our method was assessed on eight control subjects undergoing forced breathing exercises. We obtained average volume deviation of the reconstructed dynamic volume of bladders around 2.5\\% and high registration accuracy with mean distance values of 0.4 $\\pm$ 0.3 mm and Hausdorff distance values of 2.2 $\\pm$ 1.1 mm. Conclusions: Immediately transferable to the clinics with rapid acquisitions, the proposed framework represents a real advance in the field of pelvic floor disorders as it provides, for the first time, a proper 3D+t spatial tracking of bladder non-reversible deformations. This work is intended to be extended to patients with cavities filling and excretion to better characterize the degree of severity of pelvic floor pathologies for diagnostic assistance or in preoperative surgical planning.","created":"2023-01-18","meta":{"link":"http://arxiv.org/abs/2301.07385v1","tag":"medical-cv"}}
{"title":"Deep Learning Enables Reduced Gadolinium Dose for Contrast-Enhanced Blood-Brain Barrier Opening","abstract":"Focused ultrasound (FUS) can be used to open the blood-brain barrier (BBB), and MRI with contrast agents can detect that opening. However, repeated use of gadolinium-based contrast agents (GBCAs) presents safety concerns to patients. This study is the first to propose the idea of modeling a volume transfer constant (Ktrans) through deep learning to reduce the dosage of contrast agents. The goal of the study is not only to reconstruct artificial intelligence (AI) derived Ktrans images but to also enhance the intensity with low dosage contrast agent T1 weighted MRI scans. We successfully validated this idea through a previous state-of-the-art temporal network algorithm, which focused on extracting time domain features at the voxel level. Then we used a Spatiotemporal Network (ST-Net), composed of a spatiotemporal convolutional neural network (CNN)-based deep learning architecture with the addition of a three-dimensional CNN encoder, to improve the model performance. We tested the ST-Net model on ten datasets of FUS-induced BBB-openings aquired from different sides of the mouse brain. ST-Net successfully detected and enhanced BBB-opening signals without sacrificing spatial domain information. ST-Net was shown to be a promising method of reducing the need of contrast agents for modeling BBB-opening K-trans maps from time-series Dynamic Contrast-Enhanced Magnetic Resonance Imaging (DCE-MRI) scans.","created":"2023-01-18","meta":{"link":"http://arxiv.org/abs/2301.07248v1","tag":"medical-cv"}}
{"title":"DRIMET: Deep Registration for 3D Incompressible Motion Estimation in Tagged-MRI with Application to the Tongue","abstract":"Tagged magnetic resonance imaging (MRI) has been used for decades to observe and quantify the detailed motion of deforming tissue. However, this technique faces several challenges such as tag fading, large motion, long computation times, and difficulties in obtaining diffeomorphic incompressible flow fields. To address these issues, this paper presents a novel unsupervised phase-based 3D motion estimation technique for tagged MRI. We introduce two key innovations. First, we apply a sinusoidal transformation to the harmonic phase input, which enables end-to-end training and avoids the need for phase interpolation. Second, we propose a Jacobian determinant-based learning objective to encourage incompressible flow fields for deforming biological tissues. Our method efficiently estimates 3D motion fields that are accurate, dense, and approximately diffeomorphic and incompressible. The efficacy of the method is assessed using human tongue motion during speech, and includes both healthy controls and patients that have undergone glossectomy. We show that the method outperforms existing approaches, and also exhibits improvements in speed, robustness to tag fading, and large tongue motion.","created":"2023-01-18","meta":{"link":"http://arxiv.org/abs/2301.07234v2","tag":"medical-cv"}}
{"title":"MRI-powered Magnetic Miniature Capsule Robot with HIFU-controlled On-demand Drug Delivery","abstract":"Magnetic resonance imaging (MRI)-guided robotic systems offer great potential for new minimally invasive medical tools, including MRI-powered miniature robots. By re-purposing the imaging hardware of an MRI scanner, the magnetic miniature robot could be navigated into the remote part of the patient's body without needing tethered endoscopic tools. However, the state-of-art MRI-powered magnetic miniature robots have limited functionality besides navigation. Here, we propose an MRI-powered magnetic miniature capsule robot benefiting from acoustic streaming forces generated by MRI-guided high-intensity focus ultrasound (HIFU) for controlled drug release. Our design comprises a polymer capsule shell with a submillimeter-diameter drug-release hole that captures an air bubble functioning as a stopper. We use the HIFU pulse to initiate drug release by removing the air bubble once the capsule robot reaches the target location. By controlling acoustic pressure, we also regulate the drug release rate for multiple location targeting during navigation. We demonstrated that the proposed magnetic capsule robot could travel at high speed up to 1.13 cm/s in ex vivo porcine small intestine and release drug to multiple target sites in a single operation, using a combination of MRI-powered actuation and HIFU-controlled release. The proposed MRI-guided microrobotic drug release system will greatly impact minimally invasive medical procedures by allowing on-demand targeted drug delivery.","created":"2023-01-17","meta":{"link":"http://arxiv.org/abs/2301.07197v1","tag":"medical-cv"}}
{"title":"Model Reproducibility Study on Left Atrial Fibres","abstract":"We present an open-source software pipeline to create patient-specific left atrial (LA) models with fibre orientations and a fibrosis map, suitable for electrophysiology simulations. The semi-automatic pipeline takes as input a contrast enhanced magnetic resonance angiogram, and a late gadolinium enhanced (LGE) contrast magnetic resonance (CMR). Five operators were allocated 20 cases each from a set of 50 CMR datasets to create a total of 100 models to evaluate inter/intra-operator variability. Each output model consisted of (1) a labelled surface mesh open at the pulmonary veins (PV) and mitral valve (MV), (2) fibre orientations mapped from a diffusion tensor MRI human atlas, (3) fibrosis map from the LGE-CMR scan, and (4) simulation of local activation time (LAT) and phase singularity (PS) mapping. We evaluated reproducibility in our pipeline by comparing agreement in shape of the output meshes, fibrosis distribution in the LA body, and fibre orientations; simulations outputs were evaluated comparing total activation times of LAT maps, mean conduction velocity (CV), and structural similarity index measure (SSIM) of PS maps. Our workflow allows a single model to be created in 16.72 +/- 12.25 minutes. Results in this abstract are reported as inter/intra. Shape only differed noticeably with users' selection of the MV and the length of the PV from the ostia to the distal end; fibrosis agreement (0.91/0.99 ICC) and fibre orientation agreement (60.63/71.77 %) were high. LAT maps showed good agreement, the median of the absolute difference of the total activation times was 2.02ms/1.37ms. The average of the mean CV difference was -4.04mm/s / 2.1mm/s. PS maps showed a moderately good agreement with SSIM of 0.648/0.608. Although we found notable differences in the models due to user input, our tests show that operator variability was comparable to that of image resolution or fibre estimation.","created":"2023-01-17","meta":{"link":"http://arxiv.org/abs/2301.06998v1","tag":"medical-cv"}}
{"title":"Machine learning techniques for the Schizophrenia diagnosis: A comprehensive review and future research directions","abstract":"Schizophrenia (SCZ) is a brain disorder where different people experience different symptoms, such as hallucination, delusion, flat-talk, disorganized thinking, etc. In the long term, this can cause severe effects and diminish life expectancy by more than ten years. Therefore, early and accurate diagnosis of SCZ is prevalent, and modalities like structural magnetic resonance imaging (sMRI), functional MRI (fMRI), diffusion tensor imaging (DTI), and electroencephalogram (EEG) assist in witnessing the brain abnormalities of the patients. Moreover, for accurate diagnosis of SCZ, researchers have used machine learning (ML) algorithms for the past decade to distinguish the brain patterns of healthy and SCZ brains using MRI and fMRI images. This paper seeks to acquaint SCZ researchers with ML and to discuss its recent applications to the field of SCZ study. This paper comprehensively reviews state-of-the-art techniques such as ML classifiers, artificial neural network (ANN), deep learning (DL) models, methodological fundamentals, and applications with previous studies. The motivation of this paper is to benefit from finding the research gaps that may lead to the development of a new model for accurate SCZ diagnosis. The paper concludes with the research finding, followed by the future scope that directly contributes to new research directions.","created":"2023-01-16","meta":{"link":"http://arxiv.org/abs/2301.07496v1","tag":"medical-cv"}}
{"title":"Evaluating clinical diversity and plausibility of synthetic capsule endoscopic images","abstract":"Wireless Capsule Endoscopy (WCE) is being increasingly used as an alternative imaging modality for complete and non-invasive screening of the gastrointestinal tract. Although this is advantageous in reducing unnecessary hospital admissions, it also demands that a WCE diagnostic protocol be in place so larger populations can be effectively screened. This calls for training and education protocols attuned specifically to this modality. Like training in other modalities such as traditional endoscopy, CT, MRI, etc., a WCE training protocol would require an atlas comprising of a large corpora of images that show vivid descriptions of pathologies and abnormalities, ideally observed over a period of time. Since such comprehensive atlases are presently lacking in WCE, in this work, we propose a deep learning method for utilizing already available studies across different institutions for the creation of a realistic WCE atlas using StyleGAN. We identify clinically relevant attributes in WCE such that synthetic images can be generated with selected attributes on cue. Beyond this, we also simulate several disease progression scenarios. The generated images are evaluated for realism and plausibility through three subjective online experiments with the participation of eight gastroenterology experts from three geographical locations and a variety of years of experience. The results from the experiments indicate that the images are highly realistic and the disease scenarios plausible. The images comprising the atlas are available publicly for use in training applications as well as supplementing real datasets for deep learning.","created":"2023-01-16","meta":{"link":"http://arxiv.org/abs/2301.06366v1","tag":"medical-cv"}}
{"title":"Segmenting thalamic nuclei from manifold projections of multi-contrast MRI","abstract":"The thalamus is a subcortical gray matter structure that plays a key role in relaying sensory and motor signals within the brain. Its nuclei can atrophy or otherwise be affected by neurological disease and injuries including mild traumatic brain injury. Segmenting both the thalamus and its nuclei is challenging because of the relatively low contrast within and around the thalamus in conventional magnetic resonance (MR) images. This paper explores imaging features to determine key tissue signatures that naturally cluster, from which we can parcellate thalamic nuclei. Tissue contrasts include T1-weighted and T2-weighted images, MR diffusion measurements including FA, mean diffusivity, Knutsson coefficients that represent fiber orientation, and synthetic multi-TI images derived from FGATIR and T1-weighted images. After registration of these contrasts and isolation of the thalamus, we use the uniform manifold approximation and projection (UMAP) method for dimensionality reduction to produce a low-dimensional representation of the data within the thalamus. Manual labeling of the thalamus provides labels for our UMAP embedding from which k nearest neighbors can be used to label new unseen voxels in that same UMAP embedding. N -fold cross-validation of the method reveals comparable performance to state-of-the-art methods for thalamic parcellation.","created":"2023-01-15","meta":{"link":"http://arxiv.org/abs/2301.06114v3","tag":"medical-cv"}}
{"title":"Unsupervised Cardiac Segmentation Utilizing Synthesized Images from Anatomical Labels","abstract":"Cardiac segmentation is in great demand for clinical practice. Due to the enormous labor of manual delineation, unsupervised segmentation is desired. The ill-posed optimization problem of this task is inherently challenging, requiring well-designed constraints. In this work, we propose an unsupervised framework for multi-class segmentation with both intensity and shape constraints. Firstly, we extend a conventional non-convex energy function as an intensity constraint and implement it with U-Net. For shape constraint, synthetic images are generated from anatomical labels via image-to-image translation, as shape supervision for the segmentation network. Moreover, augmentation invariance is applied to facilitate the segmentation network to learn the latent features in terms of shape. We evaluated the proposed framework using the public datasets from MICCAI2019 MSCMR Challenge and achieved promising results on cardiac MRIs with Dice scores of 0.5737, 0.7796, and 0.6287 in Myo, LV, and RV, respectively.","created":"2023-01-15","meta":{"link":"http://arxiv.org/abs/2301.06043v1","tag":"medical-cv"}}
{"title":"Learning Regularization Parameter-Maps for Variational Image Reconstruction using Deep Neural Networks and Algorithm Unrolling","abstract":"We introduce a method for fast estimation of data-adapted, spatio-temporally dependent regularization parameter-maps for variational image reconstruction, focusing on total variation (TV)-minimization. Our approach is inspired by recent developments in algorithm unrolling using deep neural networks (NNs), and relies on two distinct sub-networks. The first sub-network estimates the regularization parameter-map from the input data. The second sub-network unrolls $T$ iterations of an iterative algorithm which approximately solves the corresponding TV-minimization problem incorporating the previously estimated regularization parameter-map. The overall network is trained end-to-end in a supervised learning fashion using pairs of clean-corrupted data but crucially without the need of having access to labels for the optimal regularization parameter-maps. We prove consistency of the unrolled scheme by showing that the unrolled energy functional used for the supervised learning $\\Gamma$-converges as $T$ tends to infinity, to the corresponding functional that incorporates the exact solution map of the TV-minimization problem. We apply and evaluate our method on a variety of large scale and dynamic imaging problems in which the automatic computation of such parameters has been so far challenging: 2D dynamic cardiac MRI reconstruction, quantitative brain MRI reconstruction, low-dose CT and dynamic image denoising. The proposed method consistently improves the TV-reconstructions using scalar parameters and the obtained parameter-maps adapt well to each imaging problem and data by leading to the preservation of detailed features. Although the choice of the regularization parameter-maps is data-driven and based on NNs, the proposed algorithm is entirely interpretable since it inherits the properties of the respective iterative reconstruction method from which the network is implicitly defined.","created":"2023-01-14","meta":{"link":"http://arxiv.org/abs/2301.05888v1","tag":"medical-cv"}}
{"title":"Multi-Target Landmark Detection with Incomplete Images via Reinforcement Learning and Shape Prior","abstract":"Medical images are generally acquired with limited field-of-view (FOV), which could lead to incomplete regions of interest (ROI), and thus impose a great challenge on medical image analysis. This is particularly evident for the learning-based multi-target landmark detection, where algorithms could be misleading to learn primarily the variation of background due to the varying FOV, failing the detection of targets. Based on learning a navigation policy, instead of predicting targets directly, reinforcement learning (RL)-based methods have the potential totackle this challenge in an efficient manner. Inspired by this, in this work we propose a multi-agent RL framework for simultaneous multi-target landmark detection. This framework is aimed to learn from incomplete or (and) complete images to form an implicit knowledge of global structure, which is consolidated during the training stage for the detection of targets from either complete or incomplete test images. To further explicitly exploit the global structural information from incomplete images, we propose to embed a shape model into the RL process. With this prior knowledge, the proposed RL model can not only localize dozens of targetssimultaneously, but also work effectively and robustly in the presence of incomplete images. We validated the applicability and efficacy of the proposed method on various multi-target detection tasks with incomplete images from practical clinics, using body dual-energy X-ray absorptiometry (DXA), cardiac MRI and head CT datasets. Results showed that our method could predict whole set of landmarks with incomplete training images up to 80% missing proportion (average distance error 2.29 cm on body DXA), and could detect unseen landmarks in regions with missing image information outside FOV of target images (average distance error 6.84 mm on 3D half-head CT).","created":"2023-01-13","meta":{"link":"http://arxiv.org/abs/2301.05392v1","tag":"medical-cv"}}
{"title":"Prostate Lesion Estimation using Prostate Masks from Biparametric MRI","abstract":"Biparametric MRI has emerged as an alternative to multiparametric prostate MRI, which eliminates the need for the potential harms to the patient due to the contrast medium. One major issue with biparametric MRI is difficulty to detect clinically significant prostate cancer (csPCA). Deep learning algorithms have emerged as an alternative solution to detect csPCA in cohort studies. We present a workflow which predicts csPCA on biparametric prostate MRI PI-CAI 2022 Challenge with over 10,000 carefully-curated prostate MRI exams. We propose to to segment the prostate gland first to the central gland (transition + central zone) and the peripheral gland. Then we utilize these predcitions in combination with T2, ADC and DWI images to train an ensemble nnU-Net model. Finally, we utilize clinical indices PSA and ADC intensity distributions of lesion regions to reduce the false positives. Our method achieves top results on open-validation stage with a AUROC of 0.888 and AP of 0.732.","created":"2023-01-11","meta":{"link":"http://arxiv.org/abs/2301.09673v1","tag":"medical-cv"}}
{"title":"Multiscale Metamorphic VAE for 3D Brain MRI Synthesis","abstract":"Generative modeling of 3D brain MRIs presents difficulties in achieving high visual fidelity while ensuring sufficient coverage of the data distribution. In this work, we propose to address this challenge with composable, multiscale morphological transformations in a variational autoencoder (VAE) framework. These transformations are applied to a chosen reference brain image to generate MRI volumes, equipping the model with strong anatomical inductive biases. We structure the VAE latent space in a way such that the model covers the data distribution sufficiently well. We show substantial performance improvements in FID while retaining comparable, or superior, reconstruction quality compared to prior work based on VAEs and generative adversarial networks (GANs).","created":"2023-01-09","meta":{"link":"http://arxiv.org/abs/2301.03588v2","tag":"medical-cv"}}
{"title":"3D Diffusion MRI Using Simultaneous Multi-slab with Blipped-CAIPI (Blipped-SMSlab) in a 4D K-space Framework","abstract":"Purpose: To develop an efficient simultaneous multi-slab imaging method with blipped-controlled aliasing in parallel imaging (blipped-SMSlab) in a 4D k-space framework, and demonstrate its efficacy in high-resolution diffusion MRI (dMRI).   Theory and Methods: First, the SMSlab 4D k-space signal expression is formulated, and the phase interferences from intra-slab and inter-slab encodings on the same physical z axis are analyzed. Then, the blipped-SMSlab dMRI sequence is designed, with blipped-CAIPI gradients for inter-slab encoding, and a 2D multi-band accelerated navigator for inter-kz-shot phase correction. Third, strategies are developed to remove the phase interferences, by RF phase modulation and/or phase correction during reconstruction, thus decoupling intra-slab and inter-slab encodings that are otherwise entangled. In vivo experiments are performed to validate the blipped-SMSlab method, and preliminarily evaluate its performance in high-resolution dMRI compared with traditional 2D imaging.   Results: In the 4D k-space framework, inter-slab and intra-slab phase interferences of blipped-SMSlab are successfully removed using the proposed strategies. Compared with non-CAIPI sampling, the blipped-SMSlab acquisition reduces the g-factor and g-factor-related SNR penalty by about 12%. In addition, in vivo experiments show the SNR advantage of blipped-SMSlab dMRI over traditional 2D dMRI for 1.3 and 1.0 mm isotropic resolution imaging with matched acquisition time.   Conclusion: Removing inter-slab and intra-slab phase interferences enables SMSlab dMRI with blipped-CAIPI in a 4D k-space framework. The proposed blipped-SMSlab dMRI is demonstrated to be more SNR-efficient than 2D dMRI and thus capable of high-quality, high-resolution fiber orientation detection.","created":"2023-01-09","meta":{"link":"http://arxiv.org/abs/2301.03153v1","tag":"medical-cv"}}
{"title":"Annealed Score-Based Diffusion Model for MR Motion Artifact Reduction","abstract":"Motion artifact reduction is one of the important research topics in MR imaging, as the motion artifact degrades image quality and makes diagnosis difficult. Recently, many deep learning approaches have been studied for motion artifact reduction. Unfortunately, most existing models are trained in a supervised manner, requiring paired motion-corrupted and motion-free images, or are based on a strict motion-corruption model, which limits their use for real-world situations. To address this issue, here we present an annealed score-based diffusion model for MRI motion artifact reduction. Specifically, we train a score-based model using only motion-free images, and then motion artifacts are removed by applying forward and reverse diffusion processes repeatedly to gradually impose a low-frequency data consistency. Experimental results verify that the proposed method successfully reduces both simulated and in vivo motion artifacts, outperforming the state-of-the-art deep learning methods.","created":"2023-01-08","meta":{"link":"http://arxiv.org/abs/2301.03027v1","tag":"medical-cv"}}
{"title":"KomaMRI.jl: An Open-Source Framework for General MRI Simulations with GPU Acceleration","abstract":"Purpose: To develop an open-source, high-performance, easy-to-use, extensible, cross-platform, and general MRI simulation framework (Koma).   Methods: Koma was developed using the Julia programming language. Like other MRI simulators, it solves the Bloch equations with CPU and GPU parallelization. The inputs are the scanner parameters, the phantom, and the pulse sequence that is Pulseq-compatible. The raw data is stored in the ISMRMRD format. For the reconstruction, MRIReco.jl is used. A graphical user interface utilizing web technologies was also designed. Two types of experiments were performed: one to compare the quality of the results and the execution speed, and the second to compare its usability. Finally, the use of Koma in quantitative imaging was demonstrated by simulating Magnetic Resonance Fingerprinting (MRF) acquisitions.   Results: Koma was compared to two well-known open-source MRI simulators, JEMRIS and MRiLab. Highly accurate results (with MAEs below 0.1% compared to JEMRIS) and better GPU performance than MRiLab were demonstrated. In an experiment with students, Koma was proved to be easy to use, eight times faster on personal computers than JEMRIS, and 65% of them recommended it. The potential for designing acquisition and reconstruction techniques was also shown through the simulation of MRF acquisitions, with conclusions that agree with the literature.   Conclusions: Koma's speed and flexibility have the potential to make simulations more accessible for education and research. Koma is expected to be used for designing and testing novel pulse sequences before implementing them in the scanner with Pulseq files, and for creating synthetic data to train machine learning models.","created":"2023-01-06","meta":{"link":"http://arxiv.org/abs/2301.02702v1","tag":"medical-cv"}}
{"title":"3D dose prediction for Gamma Knife radiosurgery using deep learning and data modification","abstract":"Purpose: To develop a machine learning-based, 3D dose prediction methodology for Gamma Knife (GK) radiosurgery. The methodology accounts for cases involving targets of any number, size, and shape. Methods: Data from 322 GK treatment plans was modified by isolating and cropping the contoured MRI and clinical dose distributions based on tumor location, then scaling the resulting tumor spaces to a standard size. An accompanying 3D tensor was created for each instance to account for tumor size. The modified dataset for 272 patients was used to train both a generative adversarial network (GAN-GK) and a 3D U-Net model (U-Net-GK). Unmodified data was used to train equivalent baseline models. All models were used to predict the dose distribution of 50 out-of-sample patients. Prediction accuracy was evaluated using gamma, with criteria of 4%/2mm, 3%/3mm, 3%/1mm and 1%/1mm. Prediction quality was assessed using coverage, selectivity, and conformity indices. Results: The predictions resulting from GAN-GK and U-Net-GK were similar to their clinical counterparts, with average gamma (4%/2mm) passing rates of 84.9 and 83.1, respectively. In contrast, the gamma passing rate of baseline models were significantly worse than their respective GK-specific models (p < 0.001) at all criterion levels. The quality of GK-specific predictions was also similar to that of clinical plans. Conclusion: Deep learning models can use GK-specific data modification to predict 3D dose distributions for GKRS plans with a large range in size, shape, or number of targets. Standard deep learning models applied to unmodified GK data generated poorer predictions.","created":"2023-01-06","meta":{"link":"http://arxiv.org/abs/2301.02640v1","tag":"medical-cv"}}
{"title":"Learning Deep MRI Reconstruction Models from Scratch in Low-Data Regimes","abstract":"Magnetic resonance imaging (MRI) is an essential diagnostic tool that suffers from prolonged scan times. Reconstruction methods can alleviate this limitation by recovering clinically usable images from accelerated acquisitions. In particular, learning-based methods promise performance leaps by employing deep neural networks as data-driven priors. A powerful approach uses scan-specific (SS) priors that leverage information regarding the underlying physical signal model for reconstruction. SS priors are learned on each individual test scan without the need for a training dataset, albeit they suffer from computationally burdening inference with nonlinear networks. An alternative approach uses scan-general (SG) priors that instead leverage information regarding the latent features of MRI images for reconstruction. SG priors are frozen at test time for efficiency, albeit they require learning from a large training dataset. Here, we introduce a novel parallel-stream fusion model (PSFNet) that synergistically fuses SS and SG priors for performant MRI reconstruction in low-data regimes, while maintaining competitive inference times to SG methods. PSFNet implements its SG prior based on a nonlinear network, yet it forms its SS prior based on a linear network to maintain efficiency. A pervasive framework for combining multiple priors in MRI reconstruction is algorithmic unrolling that uses serially alternated projections, causing error propagation under low-data regimes. To alleviate error propagation, PSFNet combines its SS and SG priors via a novel parallel-stream architecture with learnable fusion parameters. Demonstrations are performed on multi-coil brain MRI for varying amounts of training data. PSFNet outperforms SG methods in low-data regimes, and surpasses SS methods with few tens of training samples.","created":"2023-01-06","meta":{"link":"http://arxiv.org/abs/2301.02613v1","tag":"medical-cv"}}
{"title":"Automatic segmentation of clear cell renal cell tumors, kidney, and cysts in patients with von Hippel-Lindau syndrome using U-net architecture on magnetic resonance images","abstract":"We demonstrate automated segmentation of clear cell renal cell carcinomas (ccRCC), cysts, and surrounding normal kidney parenchyma in patients with von Hippel-Lindau (VHL) syndrome using convolutional neural networks (CNN) on Magnetic Resonance Imaging (MRI). We queried 115 VHL patients and 117 scans (3 patients have two separate scans) with 504 ccRCCs and 1171 cysts from 2015 to 2021. Lesions were manually segmented on T1 excretory phase, co-registered on all contrast-enhanced T1 sequences and used to train 2D and 3D U-Net. The U-Net performance was evaluated on 10 randomized splits of the cohort. The models were evaluated using the dice similarity coefficient (DSC). Our 2D U-Net achieved an average ccRCC lesion detection Area under the curve (AUC) of 0.88 and DSC scores of 0.78, 0.40, and 0.46 for segmentation of the kidney, cysts, and tumors, respectively. Our 3D U-Net achieved an average ccRCC lesion detection AUC of 0.79 and DSC scores of 0.67, 0.32, and 0.34 for kidney, cysts, and tumors, respectively. We demonstrated good detection and moderate segmentation results using U-Net for ccRCC on MRI. Automatic detection and segmentation of normal renal parenchyma, cysts, and masses may assist radiologists in quantifying the burden of disease in patients with VHL.","created":"2023-01-06","meta":{"link":"http://arxiv.org/abs/2301.02538v1","tag":"medical-cv"}}
{"title":"Convolutional XGBoost (C-XGBOOST) Model for Brain Tumor Detection","abstract":"Brain tumors are masses or abnormal growths of cells within the brain or the central spinal canal with symptoms such as headaches, seizures, weakness or numbness in the arms or legs, changes in personality or behaviour, nausea, vomiting, vision or hearing problems and dizziness. Conventional diagnosis of brain tumour involves some tests and procedure which may include the consideration of medical history, physical examination, imaging tests (such as CT or MRI scans), and biopsy (removal and examination of a small piece of the tumor tissue). These procedures, while effective, are mentally strenuous and time demanding due to the manual examination of the brain scans and the thorough evaluation of test results. It has been established in lots of medical research that brain tumours diagnosed and treated early generally tends to have a better prognosis. Deep learning techniques have evolved over the years and have demonstrated impressive and faster outcomes in the classification of brain tumours in medical imaging, with very little to no human interference. This study proposes a model for the early detection of brain tumours using a combination of convolutional neural networks (CNNs) and extreme gradient boosting (XGBoost). The proposed model, named C-XGBoost has a lower model complexity compared to purely CNNs, making it easier to train and less prone to overfitting. It is also better able to handle imbalanced and unstructured data, which are common issues in real-world medical image classification tasks. To evaluate the effectiveness of the proposed model, we employed a dataset of brain MRI images with and without tumours.","created":"2023-01-05","meta":{"link":"http://arxiv.org/abs/2301.02317v1","tag":"medical-cv"}}
{"title":"A deep learning approach to using wearable seismocardiography (SCG) for diagnosing aortic valve stenosis and predicting aortic hemodynamics obtained by 4D flow MRI","abstract":"In this paper, we explored the use of deep learning for the prediction of aortic flow metrics obtained using 4D flow MRI using wearable seismocardiography (SCG) devices. 4D flow MRI provides a comprehensive assessment of cardiovascular hemodynamics, but it is costly and time-consuming. We hypothesized that deep learning could be used to identify pathological changes in blood flow, such as elevated peak systolic velocity Vmax in patients with heart valve diseases, from SCG signals. We also investigated the ability of this deep learning technique to differentiate between patients diagnosed with aortic valve stenosis (AS), non-AS patients with a bicuspid aortic valve (BAV), non-AS patients with a mechanical aortic valve (MAV), and healthy subjects with a normal tricuspid aortic valve (TAV). In a study of 77 subjects who underwent same-day 4D flow MRI and SCG, we found that the Vmax values obtained using deep learning and SCGs were in good agreement with those obtained by 4D flow MRI. Additionally, subjects with TAV, BAV, MAV, and AS could be classified with ROC-AUC values of 92%, 95%, 81%, and 83%, respectively. This suggests that SCG obtained using low-cost wearable electronics may be used as a supplement to 4D flow MRI exams or as a screening tool for aortic valve disease.","created":"2023-01-05","meta":{"link":"http://arxiv.org/abs/2301.02130v1","tag":"medical-cv"}}
{"title":"Deep Learning for Breast MRI Style Transfer with Limited Training Data","abstract":"In this work we introduce a novel medical image style transfer method, StyleMapper, that can transfer medical scans to an unseen style with access to limited training data. This is made possible by training our model on unlimited possibilities of simulated random medical imaging styles on the training set, making our work more computationally efficient when compared with other style transfer methods. Moreover, our method enables arbitrary style transfer: transferring images to styles unseen in training. This is useful for medical imaging, where images are acquired using different protocols and different scanner models, resulting in a variety of styles that data may need to be transferred between. Methods: Our model disentangles image content from style and can modify an image's style by simply replacing the style encoding with one extracted from a single image of the target style, with no additional optimization required. This also allows the model to distinguish between different styles of images, including among those that were unseen in training. We propose a formal description of the proposed model. Results: Experimental results on breast magnetic resonance images indicate the effectiveness of our method for style transfer. Conclusion: Our style transfer method allows for the alignment of medical images taken with different scanners into a single unified style dataset, allowing for the training of other downstream tasks on such a dataset for tasks such as classification, object detection and others.","created":"2023-01-05","meta":{"link":"http://arxiv.org/abs/2301.02069v1","tag":"medical-cv"}}
{"title":"Physics-informed self-supervised deep learning reconstruction for accelerated first-pass perfusion cardiac MRI","abstract":"First-pass perfusion cardiac magnetic resonance (FPP-CMR) is becoming an essential non-invasive imaging method for detecting deficits of myocardial blood flow, allowing the assessment of coronary heart disease. Nevertheless, acquisitions suffer from relatively low spatial resolution and limited heart coverage. Compressed sensing (CS) methods have been proposed to accelerate FPP-CMR and achieve higher spatial resolution. However, the long reconstruction times have limited the widespread clinical use of CS in FPP-CMR. Deep learning techniques based on supervised learning have emerged as alternatives for speeding up reconstructions. However, these approaches require fully sampled data for training, which is not possible to obtain, particularly high-resolution FPP-CMR images. Here, we propose a physics-informed self-supervised deep learning FPP-CMR reconstruction approach for accelerating FPP-CMR scans and hence facilitate high spatial resolution imaging. The proposed method provides high-quality FPP-CMR images from 10x undersampled data without using fully sampled reference data.","created":"2023-01-05","meta":{"link":"http://arxiv.org/abs/2301.02033v1","tag":"medical-cv"}}
{"title":"TractGraphCNN: anatomically informed graph CNN for classification using diffusion MRI tractography","abstract":"The structure and variability of the brain's connections can be investigated via prediction of non-imaging phenotypes using neural networks. However, known neuroanatomical relationships between input features are generally ignored in network design. We propose TractGraphCNN, a novel, anatomically informed graph CNN framework for machine learning tasks using diffusion MRI tractography. An EdgeConv module aggregates features from anatomically similar white matter connections indicated by graph edges, and an attention module enables interpretation of predictive white matter tracts. Results in a sex prediction testbed task demonstrate strong performance of TractGraphCNN in two large datasets (HCP and ABCD). Graphs informed by white matter geometry demonstrate higher performance than graphs informed by gray matter connectivity. Overall, the bilateral cingulum and left middle longitudinal fasciculus are consistently highly predictive of sex. This work shows the potential of incorporating anatomical information, especially known anatomical similarities between input features, to guide convolutions in neural networks.","created":"2023-01-05","meta":{"link":"http://arxiv.org/abs/2301.01911v1","tag":"medical-cv"}}
{"title":"MSCDA: Multi-level Semantic-guided Contrast Improves Unsupervised Domain Adaptation for Breast MRI Segmentation in Small Datasets","abstract":"Deep learning (DL) applied to breast tissue segmentation in magnetic resonance imaging (MRI) has received increased attention in the last decade, however, the domain shift which arises from different vendors, acquisition protocols, and biological heterogeneity, remains an important but challenging obstacle on the path towards clinical implementation. Recently, unsupervised domain adaptation (UDA) methods have attempted to mitigate this problem by incorporating self-training with contrastive learning. To better exploit the underlying semantic information of the image at different levels, we propose a Multi-level Semantic-guided Contrastive Domain Adaptation (MSCDA) framework to align the feature representation between domains. In particular, we extend the contrastive loss by incorporating pixel-to-pixel, pixel-to-centroid, and centroid-to-centroid contrasts to integrate semantic information of images. We utilize a category-wise cross-domain sampling strategy to sample anchors from target images and build a hybrid memory bank to store samples from source images. Two breast MRI datasets were retrospectively collected: The source dataset contains non-contrast MRI examinations from 11 healthy volunteers and the target dataset contains contrast-enhanced MRI examinations of 134 invasive breast cancer patients. We set up experiments from source T2W image to target dynamic contrast-enhanced (DCE)-T1W image (T2W-to-T1W) and from source T1W image to target T2W image (T1W-to-T2W). The proposed method achieved Dice similarity coefficient (DSC) of 89.2\\% and 84.0\\% in T2W-to-T1W and T1W-to-T2W, respectively, outperforming state-of-the-art methods. Notably, good performance is still achieved with a smaller source dataset, proving that our framework is label-efficient.","created":"2023-01-04","meta":{"link":"http://arxiv.org/abs/2301.02554v1","tag":"medical-cv"}}
{"title":"UNAEN: Unsupervised Abnormality Extraction Network for MRI Motion Artifact Reduction","abstract":"Motion artifact reduction is one of the most concerned problems in magnetic resonance imaging. In recent years, deep learning-based methods have been widely investigated for artifact reduction tasks in MRI. As a retrospective processing method, neural network does not cost additional acquisition time or require new acquisition equipment, and seems to work better than traditional artifact reduction methods. In the previous study, training such models require the paired motion-corrupted and motion-free MR images. However, it is extremely tough or even impossible to obtain these images in reality because patients have difficulty in maintaining the same state during two image acquisition, which makes the training in a supervised manner impractical. In this paper, we proposed a new unsupervised abnormality extraction network (UNAEN) to alleviate this problem. Our network realizes the transition from artifact domain to motion-free domain by processing the abnormal information introduced by artifact in unpaired MR images. Different from directly generating artifact reduction results from motion-corrupted MR images, we adopted the strategy of abnormality extraction to indirectly correct the impact of artifact in MR images by learning the deep features. Experimental results show that our method is superior to state-of-the-art networks and can potentially be applied in real clinical settings.","created":"2023-01-04","meta":{"link":"http://arxiv.org/abs/2301.01732v3","tag":"medical-cv"}}
{"title":"Holistic Multi-Slice Framework for Dynamic Simultaneous Multi-Slice MRI Reconstruction","abstract":"Dynamic Magnetic Resonance Imaging (dMRI) is widely used to assess various cardiac conditions such as cardiac motion and blood flow. To accelerate MR acquisition, techniques such as undersampling and Simultaneous Multi-Slice (SMS) are often used. Special reconstruction algorithms are needed to reconstruct multiple SMS image slices from the entangled information. Deep learning (DL)-based methods have shown promising results for single-slice MR reconstruction, but the addition of SMS acceleration raises unique challenges due to the composite k-space signals and the resulting images with strong inter-slice artifacts. Furthermore, many dMRI applications lack sufficient data for training reconstruction neural networks. In this study, we propose a novel DL-based framework for dynamic SMS reconstruction. Our main contributions are 1) a combination of data transformation steps and network design that effectively leverages the unique characteristics of undersampled dynamic SMS data, and 2) an MR physics-guided transfer learning strategy that addresses the data scarcity issue. Thorough comparisons with multiple baseline methods illustrate the strengths of our proposed methods.","created":"2023-01-03","meta":{"link":"http://arxiv.org/abs/2301.01355v1","tag":"medical-cv"}}
{"title":"Developing and deploying deep learning models in brain MRI: a review","abstract":"Magnetic Resonance Imaging (MRI) of the brain has benefited from deep learning (DL) to alleviate the burden on radiologists and MR technologists, and improve throughput. The easy accessibility of DL tools have resulted in the rapid increase of DL models and subsequent peer-reviewed publications. However, the rate of deployment in clinical settings is low. Therefore, this review attempts to bring together the ideas from data collection to deployment into the clinic building on the guidelines and principles that accreditation agencies have espoused. We introduce the need for and the role of DL to deliver accessible MRI. This is followed by a brief review of DL examples in the context of neuropathologies. Based on these studies and others, we collate the prerequisites to develop and deploy DL models for brain MRI. We then delve into the guiding principles to practice good machine learning practices in the context of neuroimaging with a focus on explainability. A checklist based on the FDA's good machine learning practices is provided as a summary of these guidelines. Finally, we review the current challenges and future opportunities in DL for brain MRI.","created":"2023-01-03","meta":{"link":"http://arxiv.org/abs/2301.01241v1","tag":"medical-cv"}}
{"title":"Towards retrospective motion correction and reconstruction for clinical 3D brain MRI protocols with a reference contrast","abstract":"Motion artifacts often spoil the radiological interpretation of MR images, and in the most severe cases the scan needs be repeated, with additional costs for the provider. We discuss the application of a novel 3D retrospective rigid motion correction and reconstruction scheme for MRI, which leverages multiple scans contained in a MR session. Typically, in a multi-contrast MR session, motion does not equally affect all the scans, and some motion-free scans are generally available, so that we can exploit their anatomic similarity. The uncorrupted scan is used as a reference in a generalized rigid-motion registration problem to remove the motion artifacts affecting the corrupted scans. We discuss the potential of the proposed algorithm with a prospective in-vivo study and clinical 3D brain protocols. This framework can be easily incorporated into the existing clinical practice with no disruption to the conventional workflow.","created":"2023-01-03","meta":{"link":"http://arxiv.org/abs/2301.01106v1","tag":"medical-cv"}}
{"title":"Implicit-Explicit Multirate Infinitesimal Stage-Restart Methods","abstract":"Implicit-Explicit (IMEX) methods are flexible numerical time integration methods which solve an initial-value problem (IVP) that is partitioned into stiff and nonstiff processes with the goal of lower computational costs than a purely implicit or explicit approach. A complementary form of flexible IVP solvers are multirate infinitesimal methods for problems partitioned into fast- and slow-changing dynamics, that solve a multirate IVP by evolving a sequence of ``fast'' IVPs using any suitably accurate algorithm. This article introduces a new class of high-order implicit-explicit multirate methods that are designed for multirate IVPs in which the slow-changing dynamics are further partitioned in an IMEX fashion. This new class, which we call implicit-explicit multirate stage-restart (IMEX-MRI-SR), both improves upon the previous implicit-explicit multirate generalized-structure additive Runge Kutta (IMEX-MRI-GARK) methods, and extends multirate exponential Runge Kutta (MERK) methods into the IMEX context. We leverage GARK theory to derive conditions guaranteeing orders of accuracy up to four. We provide second-, third-, and fourth-order accurate example methods and perform numerical simulations demonstrating convergence rates and computational performance in both fixed-step and adaptive-step settings.","created":"2023-01-02","meta":{"link":"http://arxiv.org/abs/2301.00865v1","tag":"medical-cv"}}
{"title":"Experimental demonstration of diffusion limitations on resolution and SNR in MR microscopy","abstract":"Magnetic resonance microscopy images at cellular resolution (< 10 microns) are limited by diffusion. SNR and spatial resolution suffer from the dephasing of transverse magnetization caused by diffusion of spins in strong gradients. Such effects may be reduced by using phase encoding instead of frequency encoding readout gradients. Demonstration of the benefits of phase encoding are lacking, and the conditions in which it is preferred are not clearly established. We quantify when phase encoding outperforms a readout gradient with emphasis on the detrimental effects of diffusion on SNR and resolution. A 15.2T MRI scanner, with 1 T/m gradients, and micro solenoid RF coils < 1 mm in diameter, were used to quantify diffusion effects on resolution and SNR of frequency and phase encoded acquisitions. Frequency and phase encoding resolution and SNR per square root time were calculated and measured for images at the diffusion limited resolution. The point-spread-function was measured for phase and frequency encoding using additional constant time gradients with voxels 3-15 microns. The effect of diffusion during the readout gradient on SNR was experimentally demonstrated. The achieved resolutions of frequency and phase encoded acquisitions were measured via the point-spread-function. SNR per square root time and actual resolution were calculated for a wide range of gradient amplitudes, diffusion coefficients, and relaxation properties. The results provide a practical guide on how to choose between phase and frequency encoding. Images of excised rat spinal cord at 10 x 10 microns in-plane demonstrate benefits of phase encoding in the form of higher measured resolution and SNR vs the same image acquired with a conventional readout. We demonstrate the extent to which phase encoding outperforms readout gradients in SNR and resolution over a wide range of voxel sizes, sample, and hardware properties.","created":"2023-01-02","meta":{"link":"http://arxiv.org/abs/2301.00727v2","tag":"medical-cv"}}
{"title":"A plug-in graph neural network to boost temporal sensitivity in fMRI analysis","abstract":"Learning-based methods have recently enabled performance leaps in analysis of high-dimensional functional MRI (fMRI) time series. Deep learning models that receive as input functional connectivity (FC) features among brain regions have been commonly adopted in the literature. However, many models focus on temporally static FC features across a scan, reducing sensitivity to dynamic features of brain activity. Here, we describe a plug-in graph neural network that can be flexibly integrated into a main learning-based fMRI model to boost its temporal sensitivity. Receiving brain regions as nodes and blood-oxygen-level-dependent (BOLD) signals as node inputs, the proposed GraphCorr method leverages a node embedder module based on a transformer encoder to capture temporally-windowed latent representations of BOLD signals. GraphCorr also leverages a lag filter module to account for delayed interactions across nodes by computing cross-correlation of windowed BOLD signals across a range of time lags. Information captured by the two modules is fused via a message passing algorithm executed on the graph, and enhanced node features are then computed at the output. These enhanced features are used to drive a subsequent learning-based model to analyze fMRI time series with elevated sensitivity. Comprehensive demonstrations on two public datasets indicate improved classification performance and interpretability for several state-of-the-art graphical and convolutional methods that employ GraphCorr-derived feature representations of fMRI time series as their input.","created":"2023-01-01","meta":{"link":"http://arxiv.org/abs/2301.00439v1","tag":"medical-cv"}}
{"title":"Spatiotemporal implicit neural representation for unsupervised dynamic MRI reconstruction","abstract":"Supervised Deep-Learning (DL)-based reconstruction algorithms have shown state-of-the-art results for highly-undersampled dynamic Magnetic Resonance Imaging (MRI) reconstruction. However, the requirement of excessive high-quality ground-truth data hinders their applications due to the generalization problem. Recently, Implicit Neural Representation (INR) has appeared as a powerful DL-based tool for solving the inverse problem by characterizing the attributes of a signal as a continuous function of corresponding coordinates in an unsupervised manner. In this work, we proposed an INR-based method to improve dynamic MRI reconstruction from highly undersampled k-space data, which only takes spatiotemporal coordinates as inputs. Specifically, the proposed INR represents the dynamic MRI images as an implicit function and encodes them into neural networks. The weights of the network are learned from sparsely-acquired (k, t)-space data itself only, without external training datasets or prior images. Benefiting from the strong implicit continuity regularization of INR together with explicit regularization for low-rankness and sparsity, our proposed method outperforms the compared scan-specific methods at various acceleration factors. E.g., experiments on retrospective cardiac cine datasets show an improvement of 5.5 ~ 7.1 dB in PSNR for extremely high accelerations (up to 41.6-fold). The high-quality and inner continuity of the images provided by INR has great potential to further improve the spatiotemporal resolution of dynamic MRI, without the need of any training data.","created":"2022-12-31","meta":{"link":"http://arxiv.org/abs/2301.00127v2","tag":"medical-cv"}}
{"title":"Uncertainty quantification for sparse Fourier recovery","abstract":"One of the most prominent methods for uncertainty quantification in high-dimen-sional statistics is the desparsified LASSO that relies on unconstrained $\\ell_1$-minimization. The majority of initial works focused on real (sub-)Gaussian designs. However, in many applications, such as magnetic resonance imaging (MRI), the measurement process possesses a certain structure due to the nature of the problem. The measurement operator in MRI can be described by a subsampled Fourier matrix. The purpose of this work is to extend the uncertainty quantification process using the desparsified LASSO to design matrices originating from a bounded orthonormal system, which naturally generalizes the subsampled Fourier case and also allows for the treatment of the case where the sparsity basis is not the standard basis. In particular we construct honest confidence intervals for every pixel of an MR image that is sparse in the standard basis provided the number of measurements satisfies $n \\gtrsim\\max\\{ s\\log^2 s\\log p, s \\log^2 p \\}$ or that is sparse with respect to the Haar Wavelet basis provided a slightly larger number of measurements.","created":"2022-12-30","meta":{"link":"http://arxiv.org/abs/2212.14864v1","tag":"medical-cv"}}
{"title":"Head-and-neck multi-channel B1+ mapping and carotid arteries RF shimming using a parallel transmit head coil","abstract":"Purpose: Neurovascular MRI suffers from a rapid drop in B1+ into the neck when using transmit head coils at 7T. One solution to improving B1+ magnitude in the major feeding arteries in the neck is to use custom RF shims on parallel transmit (pTx) head coils. However, calculating such shims requires robust multi-channel B1+ maps in both the head and the neck, which is challenging due to low RF penetration into the neck, limited dynamic range of multi-channel B1+ mapping techniques, and B0 sensitivity. We therefore sought a robust large-dynamic-range pTx field mapping protocol, and tested whether RF shimming can improve carotid artery B1+ in practice.   Methods: A pipeline is presented that combines B1+ mapping data acquired using circularly polarized (CP-) and CP2-mode RF shims at multiple voltages. The pipeline was evaluated by comparing the predicted and measured B1+ for multiple random transmit shims, and by assessing the ability of RF shimming to increase the B1+ in the carotid arteries.   Results: The proposed method achieved good agreement between predicted and measured B1+ in both the head and the neck. The B1+ magnitude in the carotid arteries can be increased by 42% using tailored RF shims or by 37% using universal RF shims, while also improving the RF homogeneity compared to CP mode.   Conclusion: B1+ in the neck can be increased using RF shims calculated from multi-channel B1+ maps in both the head and the neck. This can be achieved using universal phase-only RF shims, facilitating easy implementation in existing sequences.","created":"2022-12-30","meta":{"link":"http://arxiv.org/abs/2212.14596v1","tag":"medical-cv"}}
{"title":"3D Masked Modelling Advances Lesion Classification in Axial T2w Prostate MRI","abstract":"Masked Image Modelling (MIM) has been shown to be an efficient self-supervised learning (SSL) pre-training paradigm when paired with transformer architectures and in the presence of a large amount of unlabelled natural images. The combination of the difficulties in accessing and obtaining large amounts of labeled data and the availability of unlabelled data in the medical imaging domain makes MIM an interesting approach to advance deep learning (DL) applications based on 3D medical imaging data. Nevertheless, SSL and, in particular, MIM applications with medical imaging data are rather scarce and there is still uncertainty. around the potential of such a learning paradigm in the medical domain. We study MIM in the context of Prostate Cancer (PCa) lesion classification with T2 weighted (T2w) axial magnetic resonance imaging (MRI) data. In particular, we explore the effect of using MIM when coupled with convolutional neural networks (CNNs) under different conditions such as different masking strategies, obtaining better results in terms of AUC than other pre-training strategies like ImageNet weight initialization.","created":"2022-12-29","meta":{"link":"http://arxiv.org/abs/2212.14267v1","tag":"medical-cv"}}
{"title":"MyI-Net: Fully Automatic Detection and Quantification of Myocardial Infarction from Cardiovascular MRI Images","abstract":"A \"heart attack\" or myocardial infarction (MI), occurs when an artery supplying blood to the heart is abruptly occluded. The \"gold standard\" method for imaging MI is Cardiovascular Magnetic Resonance Imaging (MRI), with intravenously administered gadolinium-based contrast (late gadolinium enhancement). However, no \"gold standard\" fully automated method for the quantification of MI exists. In this work, we propose an end-to-end fully automatic system (MyI-Net) for the detection and quantification of MI in MRI images. This has the potential to reduce the uncertainty due to the technical variability across labs and inherent problems of the data and labels. Our system consists of four processing stages designed to maintain the flow of information across scales. First, features from raw MRI images are generated using feature extractors built on ResNet and MoblieNet architectures. This is followed by the Atrous Spatial Pyramid Pooling (ASPP) to produce spatial information at different scales to preserve more image context. High-level features from ASPP and initial low-level features are concatenated at the third stage and then passed to the fourth stage where spatial information is recovered via up-sampling to produce final image segmentation output into: i) background, ii) heart muscle, iii) blood and iv) scar areas. New models were compared with state-of-art models and manual quantification. Our models showed favorable performance in global segmentation and scar tissue detection relative to state-of-the-art work, including a four-fold better performance in matching scar pixels to contours produced by clinicians.","created":"2022-12-28","meta":{"link":"http://arxiv.org/abs/2212.13715v1","tag":"medical-cv"}}
{"title":"Brain Cancer Segmentation Using YOLOv5 Deep Neural Network","abstract":"An expansion of aberrant brain cells is referred to as a brain tumor. The brain's architecture is extremely intricate, with several regions controlling various nervous system processes. Any portion of the brain or skull can develop a brain tumor, including the brain's protective coating, the base of the skull, the brainstem, the sinuses, the nasal cavity, and many other places. Over the past ten years, numerous developments in the field of computer-aided brain tumor diagnosis have been made. Recently, instance segmentation has attracted a lot of interest in numerous computer vision applications. It seeks to assign various IDs to various scene objects, even if they are members of the same class. Typically, a two-stage pipeline is used to perform instance segmentation. This study shows brain cancer segmentation using YOLOv5. Yolo takes dataset as picture format and corresponding text file. You Only Look Once (YOLO) is a viral and widely used algorithm. YOLO is famous for its object recognition properties. You Only Look Once (YOLO) is a popular algorithm that has gone viral. YOLO is well known for its ability to identify objects. YOLO V2, V3, V4, and V5 are some of the YOLO latest versions that experts have published in recent years. Early brain tumor detection is one of the most important jobs that neurologists and radiologists have. However, it can be difficult and error-prone to manually identify and segment brain tumors from Magnetic Resonance Imaging (MRI) data. For making an early diagnosis of the condition, an automated brain tumor detection system is necessary. The model of the research paper has three classes. They are respectively Meningioma, Pituitary, Glioma. The results show that, our model achieves competitive accuracy, in terms of runtime usage of M2 10 core GPU.","created":"2022-12-27","meta":{"link":"http://arxiv.org/abs/2212.13599v1","tag":"medical-cv"}}
{"title":"Transformer and GAN Based Super-Resolution Reconstruction Network for Medical Images","abstract":"Because of the necessity to obtain high-quality images with minimal radiation doses, such as in low-field magnetic resonance imaging, super-resolution reconstruction in medical imaging has become more popular (MRI). However, due to the complexity and high aesthetic requirements of medical imaging, image super-resolution reconstruction remains a difficult challenge. In this paper, we offer a deep learning-based strategy for reconstructing medical images from low resolutions utilizing Transformer and Generative Adversarial Networks (T-GAN). The integrated system can extract more precise texture information and focus more on important locations through global image matching after successfully inserting Transformer into the generative adversarial network for picture reconstruction. Furthermore, we weighted the combination of content loss, adversarial loss, and adversarial feature loss as the final multi-task loss function during the training of our proposed model T-GAN. In comparison to established measures like PSNR and SSIM, our suggested T-GAN achieves optimal performance and recovers more texture features in super-resolution reconstruction of MRI scanned images of the knees and belly.","created":"2022-12-26","meta":{"link":"http://arxiv.org/abs/2212.13068v1","tag":"medical-cv"}}
{"title":"Application of Unsupervised Domain Adaptation for Structural MRI Analysis","abstract":"The primary goal of this work is to study the effectiveness of an unsupervised domain adaptation approach for various applications such as binary classification and anomaly detection in the context of Alzheimer's disease (AD) detection for the OASIS datasets. We also explore image reconstruction and image synthesis for analyzing and generating 3D structural MRI data to establish performance benchmarks for anomaly detection. We successfully demonstrate that domain adaptation improves the performance of AD detection when implemented in both supervised and unsupervised settings. Additionally, the proposed methodology achieves state-of-the-art performance for binary classification on the OASIS-1 dataset.","created":"2022-12-26","meta":{"link":"http://arxiv.org/abs/2212.12986v1","tag":"medical-cv"}}
{"title":"Hybrid Representation Learning for Cognitive Diagnosis in Late-Life Depression Over 5 Years with Structural MRI","abstract":"Late-life depression (LLD) is a highly prevalent mood disorder occurring in older adults and is frequently accompanied by cognitive impairment (CI). Studies have shown that LLD may increase the risk of Alzheimer's disease (AD). However, the heterogeneity of presentation of geriatric depression suggests that multiple biological mechanisms may underlie it. Current biological research on LLD progression incorporates machine learning that combines neuroimaging data with clinical observations. There are few studies on incident cognitive diagnostic outcomes in LLD based on structural MRI (sMRI). In this paper, we describe the development of a hybrid representation learning (HRL) framework for predicting cognitive diagnosis over 5 years based on T1-weighted sMRI data. Specifically, we first extract prediction-oriented MRI features via a deep neural network, and then integrate them with handcrafted MRI features via a Transformer encoder for cognitive diagnosis prediction. Two tasks are investigated in this work, including (1) identifying cognitively normal subjects with LLD and never-depressed older healthy subjects, and (2) identifying LLD subjects who developed CI (or even AD) and those who stayed cognitively normal over five years. To the best of our knowledge, this is among the first attempts to study the complex heterogeneous progression of LLD based on task-oriented and handcrafted MRI features. We validate the proposed HRL on 294 subjects with T1-weighted MRIs from two clinically harmonized studies. Experimental results suggest that the HRL outperforms several classical machine learning and state-of-the-art deep learning methods in LLD identification and prediction tasks.","created":"2022-12-24","meta":{"link":"http://arxiv.org/abs/2212.12810v1","tag":"medical-cv"}}
{"title":"TMS-Net: A Segmentation Network Coupled With A Run-time Quality Control Method For Robust Cardiac Image Segmentation","abstract":"Recently, deep networks have shown impressive performance for the segmentation of cardiac Magnetic Resonance Imaging (MRI) images. However, their achievement is proving slow to transition to widespread use in medical clinics because of robustness issues leading to low trust of clinicians to their results. Predicting run-time quality of segmentation masks can be useful to warn clinicians against poor results. Despite its importance, there are few studies on this problem. To address this gap, we propose a quality control method based on the agreement across decoders of a multi-view network, TMS-Net, measured by the cosine similarity. The network takes three view inputs resliced from the same 3D image along different axes. Different from previous multi-view networks, TMS-Net has a single encoder and three decoders, leading to better noise robustness, segmentation performance and run-time quality estimation in our experiments on the segmentation of the left atrium on STACOM 2013 and STACOM 2018 challenge datasets. We also present a way to generate poor segmentation masks by using noisy images generated with engineered noise and Rician noise to simulate undertraining, high anisotropy and poor imaging settings problems. Our run-time quality estimation method show a good classification of poor and good quality segmentation masks with an AUC reaching to 0.97 on STACOM 2018. We believe that TMS-Net and our run-time quality estimation method has a high potential to increase the thrust of clinicians to automatic image analysis tools.","created":"2022-12-21","meta":{"link":"http://arxiv.org/abs/2212.10877v1","tag":"medical-cv"}}
{"title":"High-fidelity Direct Contrast Synthesis from Magnetic Resonance Fingerprinting","abstract":"Magnetic Resonance Fingerprinting (MRF) is an efficient quantitative MRI technique that can extract important tissue and system parameters such as T1, T2, B0, and B1 from a single scan. This property also makes it attractive for retrospectively synthesizing contrast-weighted images. In general, contrast-weighted images like T1-weighted, T2-weighted, etc., can be synthesized directly from parameter maps through spin-dynamics simulation (i.e., Bloch or Extended Phase Graph models). However, these approaches often exhibit artifacts due to imperfections in the mapping, the sequence modeling, and the data acquisition. Here we propose a supervised learning-based method that directly synthesizes contrast-weighted images from the MRF data without going through the quantitative mapping and spin-dynamics simulation. To implement our direct contrast synthesis (DCS) method, we deploy a conditional Generative Adversarial Network (GAN) framework and propose a multi-branch U-Net as the generator. The input MRF data are used to directly synthesize T1-weighted, T2-weighted, and fluid-attenuated inversion recovery (FLAIR) images through supervised training on paired MRF and target spin echo-based contrast-weighted scans. In-vivo experiments demonstrate excellent image quality compared to simulation-based contrast synthesis and previous DCS methods, both visually as well as by quantitative metrics. We also demonstrate cases where our trained model is able to mitigate in-flow and spiral off-resonance artifacts that are typically seen in MRF reconstructions and thus more faithfully represent conventional spin echo-based contrast-weighted images.","created":"2022-12-21","meta":{"link":"http://arxiv.org/abs/2212.10817v1","tag":"medical-cv"}}
{"title":"Multi-coil MRI by analytic continuation","abstract":"We present novel reconstruction and stability analysis methodologies for two-dimensional, multi-coil MRI, based on analytic continuation ideas. We show that the 2-D, limited-data MRI inverse problem, whereby the missing parts of $\\textbf{k}$-space (Fourier space) are lines parallel to either $k_1$ or $k_2$ (i.e., the $\\textbf{k}$-space axis), can be reduced to a set of 1-D Fredholm type inverse problems. The Fredholm equations are then solved to recover the 2-D image on 1-D line profiles (``slice-by-slice\" imaging). The technique is tested on a range of medical in vivo images (e.g., brain, spine, cardiac), and phantom data. Our method is shown to offer optimal performance, in terms of structural similarity, when compared against similar methods from the literature, and when the $\\textbf{k}$-space data is sub-sampled at random so as to simulate motion corruption. In addition, we present a Singular Value Decomposition (SVD) and stability analysis of the Fredholm operators, and compare the stability properties of different $\\textbf{k}$-space sub-sampling schemes (e.g., random vs uniform accelerated sampling).","created":"2022-12-20","meta":{"link":"http://arxiv.org/abs/2212.10036v1","tag":"medical-cv"}}
{"title":"Fast Low Rank column-wise Compressive Sensing for Accelerated Dynamic MRI","abstract":"This work develops a novel set of algorithms, alternating Gradient Descent (GD) and minimization for MRI (altGDmin-MRI1 and altGDmin-MRI2), for accelerated dynamic MRI by assuming an approximate low-rank (LR) model on the matrix formed by the vectorized images of the sequence. The LR model itself is well-known in the MRI literature; our contribution is the novel GD-based algorithms which are much faster, memory efficient, and general compared with existing work; and careful use of a 3-level hierarchical LR model. By general, we mean that, with a single choice of parameters, our method provides accurate reconstructions for multiple accelerated dynamic MRI applications, multiple sampling rates and sampling schemes.   We show that our methods outperform many of the popular existing approaches while also being faster than all of them, on average. This claim is based on comparisons on 8 different retrospectively under sampled multi-coil dynamic MRI applications, sampled using either 1D Cartesian or 2D pseudo radial under sampling, at multiple sampling rates. Evaluations on some prospectively under sampled datasets are also provided. Our second contribution is a mini-batch subspace tracking extension that can process new measurements and return reconstructions within a short delay after they arrive. The recovery algorithm itself is also faster than its batch counterpart.","created":"2022-12-19","meta":{"link":"http://arxiv.org/abs/2212.09664v1","tag":"medical-cv"}}
{"title":"Resection cavity auto-contouring for patients with pediatric medulloblastoma using only CT information","abstract":"Purpose: Target delineation for radiation therapy is a time-consuming and complex task. Autocontouring gross tumor volumes (GTVs) has been shown to increase efficiency. However, there is limited literature on post-operative target delineation, particularly for CT-based studies. To this end, we trained a CT-based autocontouring model to contour the post-operative GTV of pediatric patients with medulloblastoma.   Methods: 104 retrospective pediatric CT scans were used to train a GTV auto-contouring model. 80 patients were then preselected for contour visibility, continuity, and location to train an additional model. Each GTV was manually annotated with a visibility score based on the number of slices with a visible GTV (1 = <25%, 2 = 25%-50%, 3 = >50%-75%, and 4 = >75%-100%). Contrast and the contrast-to-noise ratio (CNR) were calculated for the GTV contour with respect to a cropped background image. Both models were tested on the original and pre-selected testing sets. The resulting surface and overlap metrics were calculated comparing the clinical and autocontoured GTVs and the corresponding clinical target volumes (CTVs).   Results: 80 patients were pre-selected to have a continuous GTV within the posterior fossa. Of these, 7, 41, 21, and 11 were visibly scored as 4, 3, 2, and 1, respectively. The contrast and CNR removed an additional 11 and 20 patients from the dataset, respectively. The Dice similarity coefficients (DSC) were 0.61 +/- 0.29 and 0.67 +/- 0.22 on the models without pre-selected training data and 0.55 +/- 13.01 and 0.83 +/- 0.17 on the models with pre-selected data, respectively. The DSC on the CTV expansions were 0.90 +/- 0.13. Conclusion: We automatically contoured continuous GTVs within the posterior fossa on scans that had contrast >=10 HU. CT-Based auto-contouring algorithms have potential to positively impact centers with limited MRI access.","created":"2022-12-19","meta":{"link":"http://arxiv.org/abs/2212.09564v1","tag":"medical-cv"}}
{"title":"Multimodal CNN Networks for Brain Tumor Segmentation in MRI: A BraTS 2022 Challenge Solution","abstract":"Automatic segmentation is essential for the brain tumor diagnosis, disease prognosis, and follow-up therapy of patients with gliomas. Still, accurate detection of gliomas and their sub-regions in multimodal MRI is very challenging due to the variety of scanners and imaging protocols. Over the last years, the BraTS Challenge has provided a large number of multi-institutional MRI scans as a benchmark for glioma segmentation algorithms. This paper describes our contribution to the BraTS 2022 Continuous Evaluation challenge. We propose a new ensemble of multiple deep learning frameworks namely, DeepSeg, nnU-Net, and DeepSCAN for automatic glioma boundaries detection in pre-operative MRI. It is worth noting that our ensemble models took first place in the final evaluation on the BraTS testing dataset with Dice scores of 0.9294, 0.8788, and 0.8803, and Hausdorf distance of 5.23, 13.54, and 12.05, for the whole tumor, tumor core, and enhancing tumor, respectively. Furthermore, the proposed ensemble method ranked first in the final ranking on another unseen test dataset, namely Sub-Saharan Africa dataset, achieving mean Dice scores of 0.9737, 0.9593, and 0.9022, and HD95 of 2.66, 1.72, 3.32 for the whole tumor, tumor core, and enhancing tumor, respectively. The docker image for the winning submission is publicly available at (https://hub.docker.com/r/razeineldin/camed22).","created":"2022-12-19","meta":{"link":"http://arxiv.org/abs/2212.09310v1","tag":"medical-cv"}}
{"title":"Segmentation Ability Map: Interpret deep features for medical image segmentation","abstract":"Deep convolutional neural networks (CNNs) have been widely used for medical image segmentation. In most studies, only the output layer is exploited to compute the final segmentation results and the hidden representations of the deep learned features have not been well understood. In this paper, we propose a prototype segmentation (ProtoSeg) method to compute a binary segmentation map based on deep features. We measure the segmentation abilities of the features by computing the Dice between the feature segmentation map and ground-truth, named as the segmentation ability score (SA score for short). The corresponding SA score can quantify the segmentation abilities of deep features in different layers and units to understand the deep neural networks for segmentation. In addition, our method can provide a mean SA score which can give a performance estimation of the output on the test images without ground-truth. Finally, we use the proposed ProtoSeg method to compute the segmentation map directly on input images to further understand the segmentation ability of each input image. Results are presented on segmenting tumors in brain MRI, lesions in skin images, COVID-related abnormality in CT images, prostate segmentation in abdominal MRI, and pancreatic mass segmentation in CT images. Our method can provide new insights for interpreting and explainable AI systems for medical image segmentation.   Our code is available on: \\url{https://github.com/shengfly/ProtoSeg}.","created":"2022-12-19","meta":{"link":"http://arxiv.org/abs/2212.09206v1","tag":"medical-cv"}}
{"title":"Development of A Real-time POCUS Image Quality Assessment and Acquisition Guidance System","abstract":"Point-of-care ultrasound (POCUS) is one of the most commonly applied tools for cardiac function imaging in the clinical routine of the emergency department and pediatric intensive care unit. The prior studies demonstrate that AI-assisted software can guide nurses or novices without prior sonography experience to acquire POCUS by recognizing the interest region, assessing image quality, and providing instructions. However, these AI algorithms cannot simply replace the role of skilled sonographers in acquiring diagnostic-quality POCUS. Unlike chest X-ray, CT, and MRI, which have standardized imaging protocols, POCUS can be acquired with high inter-observer variability. Though being with variability, they are usually all clinically acceptable and interpretable. In challenging clinical environments, sonographers employ novel heuristics to acquire POCUS in complex scenarios. To help novice learners to expedite the training process while reducing the dependency on experienced sonographers in the curriculum implementation, We will develop a framework to perform real-time AI-assisted quality assessment and probe position guidance to provide training process for novice learners with less manual intervention.","created":"2022-12-16","meta":{"link":"http://arxiv.org/abs/2212.08624v2","tag":"medical-cv"}}
{"title":"BigBrain-MR: a new digital phantom with anatomically-realistic magnetic resonance properties at 100-\u03bcm resolution for magnetic resonance methods development","abstract":"The benefits, opportunities and growing availability of ultra-high field magnetic resonance imaging (MRI) for humans have prompted an expansion in research and development efforts towards increasingly more advanced high-resolution imaging techniques. To maximize their effectiveness, these efforts need to be supported by powerful computational simulation platforms that can adequately reproduce the biophysical characteristics of MRI, with high spatial resolution. In this work, we have sought to address this need by developing a novel digital phantom with realistic anatomical detail up to 100-um resolution, including multiple MRI properties that affect image generation. This phantom, termed BigBrain-MR, was generated from the publicly available BigBrain histological dataset and lower-resolution in-vivo 7T-MRI data, using a newly-developed image processing framework that allows mapping the general properties of the latter into the fine anatomical scale of the former. Overall, the mapping framework was found to be effective and robust, yielding a diverse range of realistic \"in-vivo-like\" MRI contrasts and maps at 100-um resolution. BigBrain-MR was then tested in three different imaging applications (motion effects and interpolation, super-resolution imaging, and parallel imaging reconstruction) to investigate its properties, value and validity as a simulation platform. The results consistently showed that BigBrain-MR can closely approximate the behavior of real in-vivo data, more realistically and with more extensive features than a more classic option such as the Shepp-Logan phantom. This novel phantom is therefore deemed a favorable choice to support methodological development in brain MRI, and has been made freely available to the community.","created":"2022-12-15","meta":{"link":"http://arxiv.org/abs/2212.08165v1","tag":"medical-cv"}}
{"title":"Prediction of Model Generalizability for Unseen Data: Methodology and Case Study in Brain Metastases Detection in T1-Weighted Contrast-Enhanced 3D MRI","abstract":"A medical AI system's generalizability describes the continuity of its performance acquired from varying geographic, historical, and methodologic settings. Previous literature on this topic has mostly focused on \"how\" to achieve high generalizability with limited success. Instead, we aim to understand \"when\" the generalizability is achieved: Our study presents a medical AI system that could estimate its generalizability status for unseen data on-the-fly. We introduce a latent space mapping (LSM) approach utilizing Frechet distance loss to force the underlying training data distribution into a multivariate normal distribution. During the deployment, a given test data's LSM distribution is processed to detect its deviation from the forced distribution; hence, the AI system could predict its generalizability status for any previously unseen data set. If low model generalizability is detected, then the user is informed by a warning message. While the approach is applicable for most classification deep neural networks, we demonstrate its application to a brain metastases (BM) detector for T1-weighted contrast-enhanced (T1c) 3D MRI. The BM detection model was trained using 175 T1c studies acquired internally, and tested using (1) 42 internally and (2) 72 externally acquired exams from the publicly distributed Brain Mets dataset provided by the Stanford University School of Medicine. Generalizability scores, false positive (FP) rates, and sensitivities of the BM detector were computed for the test datasets. The model predicted its generalizability to be low for 31% of the testing data, where it produced (1) ~13.5 FPs at 76.1% BM detection sensitivity for the low and (2) ~10.5 FPs at 89.2% BM detection sensitivity for the high generalizability groups respectively. The results suggest that the proposed formulation enables a model to predict its generalizability for unseen data.","created":"2022-12-15","meta":{"link":"http://arxiv.org/abs/2212.08127v1","tag":"medical-cv"}}
{"title":"Generating Realistic 3D Brain MRIs Using a Conditional Diffusion Probabilistic Model","abstract":"Training deep learning models on brain MRI is often plagued by small sample size, which can lead to biased training or overfitting. One potential solution is to synthetically generate realistic MRIs via generative models such as Generative Adversarial Network (GAN). However, existing GANs for synthesizing realistic brain MRIs largely rely on image-to-image conditioned transformations requiring extensive, well-curated pairs of MRI samples for training. On the other hand, unconditioned GAN models (i.e., those generating MRI from random noise) are unstable during training and tend to produce blurred images during inference. Here, we propose an efficient strategy that generates high fidelity 3D brain MRI via Diffusion Probabilistic Model (DPM). To this end, we train a conditional DPM with attention to generate an MRI sub-volume (a set of slices at arbitrary locations) conditioned on another subset of slices from the same MRI. By computing attention weights from slice indices and using a mask to encode the target and conditional slices, the model is able to learn the long-range dependency across distant slices with limited computational resources. After training, the model can progressively synthesize a new 3D brain MRI by generating the first subset of slices from random noise and conditionally generating subsequent slices. Based on 1262 t1-weighted MRIs from three neuroimaging studies, our experiments demonstrate that the proposed method can generate high quality 3D MRIs that share the same distribution as real MRIs and are more realistic than the ones produced by GAN-based models.","created":"2022-12-15","meta":{"link":"http://arxiv.org/abs/2212.08034v1","tag":"medical-cv"}}
{"title":"Towards fully automated deep-learning-based brain tumor segmentation: is brain extraction still necessary?","abstract":"State-of-the-art brain tumor segmentation is based on deep learning models applied to multi-modal MRIs. Currently, these models are trained on images after a preprocessing stage that involves registration, interpolation, brain extraction (BE, also known as skull-stripping) and manual correction by an expert. However, for clinical practice, this last step is tedious and time-consuming and, therefore, not always feasible, resulting in skull-stripping faults that can negatively impact the tumor segmentation quality. Still, the extent of this impact has never been measured for any of the many different BE methods available. In this work, we propose an automatic brain tumor segmentation pipeline and evaluate its performance with multiple BE methods. Our experiments show that the choice of a BE method can compromise up to 15.7% of the tumor segmentation performance. Moreover, we propose training and testing tumor segmentation models on non-skull-stripped images, effectively discarding the BE step from the pipeline. Our results show that this approach leads to a competitive performance at a fraction of the time. We conclude that, in contrast to the current paradigm, training tumor segmentation models on non-skull-stripped images can be the best option when high performance in clinical practice is desired.","created":"2022-12-14","meta":{"link":"http://arxiv.org/abs/2212.07497v1","tag":"medical-cv"}}
{"title":"A Critical Appraisal of Data Augmentation Methods for Imaging-Based Medical Diagnosis Applications","abstract":"Current data augmentation techniques and transformations are well suited for improving the size and quality of natural image datasets but are not yet optimized for medical imaging. We hypothesize that sub-optimal data augmentations can easily distort or occlude medical images, leading to false positives or negatives during patient diagnosis, prediction, or therapy/surgery evaluation. In our experimental results, we found that utilizing commonly used intensity-based data augmentation distorts the MRI scans and leads to texture information loss, thus negatively affecting the overall performance of classification. Additionally, we observed that commonly used data augmentation methods cannot be used with a plug-and-play approach in medical imaging, and requires manual tuning and adjustment.","created":"2022-12-14","meta":{"link":"http://arxiv.org/abs/2301.02181v1","tag":"medical-cv"}}
{"title":"Unsupervised Domain Adaptation for Automated Knee Osteoarthritis Phenotype Classification","abstract":"Purpose: The aim of this study was to demonstrate the utility of unsupervised domain adaptation (UDA) in automated knee osteoarthritis (OA) phenotype classification using a small dataset (n=50). Materials and Methods: For this retrospective study, we collected 3,166 three-dimensional (3D) double-echo steady-state magnetic resonance (MR) images from the Osteoarthritis Initiative dataset and 50 3D turbo/fast spin-echo MR images from our institute (in 2020 and 2021) as the source and target datasets, respectively. For each patient, the degree of knee OA was initially graded according to the MRI Osteoarthritis Knee Score (MOAKS) before being converted to binary OA phenotype labels. The proposed UDA pipeline included (a) pre-processing, which involved automatic segmentation and region-of-interest cropping; (b) source classifier training, which involved pre-training phenotype classifiers on the source dataset; (c) target encoder adaptation, which involved unsupervised adaption of the source encoder to the target encoder and (d) target classifier validation, which involved statistical analysis of the target classification performance evaluated by the area under the receiver operating characteristic curve (AUROC), sensitivity, specificity and accuracy. Additionally, a classifier was trained without UDA for comparison. Results: The target classifier trained with UDA achieved improved AUROC, sensitivity, specificity and accuracy for both knee OA phenotypes compared with the classifier trained without UDA. Conclusion: The proposed UDA approach improves the performance of automated knee OA phenotype classification for small target datasets by utilising a large, high-quality source dataset for training. The results successfully demonstrated the advantages of the UDA approach in classification on small datasets.","created":"2022-12-14","meta":{"link":"http://arxiv.org/abs/2212.07023v1","tag":"medical-cv"}}
{"title":"SPIRiT-Diffusion: SPIRiT-driven Score-Based Generative Modeling for Vessel Wall imaging","abstract":"Diffusion model is the most advanced method in image generation and has been successfully applied to MRI reconstruction. However, the existing methods do not consider the characteristics of multi-coil acquisition of MRI data. Therefore, we give a new diffusion model, called SPIRiT-Diffusion, based on the SPIRiT iterative reconstruction algorithm. Specifically, SPIRiT-Diffusion characterizes the prior distribution of coil-by-coil images by score matching and characterizes the k-space redundant prior between coils based on self-consistency. With sufficient prior constraint utilized, we achieve superior reconstruction results on the joint Intracranial and Carotid Vessel Wall imaging dataset.","created":"2022-12-14","meta":{"link":"http://arxiv.org/abs/2212.11274v1","tag":"medical-cv"}}
{"title":"Effects of anterior temporal lobe resection on cortical morphology","abstract":"Anterior temporal lobe resection (ATLR) is a surgical procedure to treat drug-resistant temporal lobe epilepsy (TLE). Resection may involve large amounts of cortical tissue. Here, we examine the effects of this surgery on cortical morphology measured in independent variables both near the resection and remotely.   We studied 101 individuals with TLE (55 left, 46 right onset) who underwent ATLR. For each individual we considered one pre-surgical MRI and one follow-up MRI 2 to 13 months after surgery. We used our newly developed surface-based method to locally compute traditional morphological variables (average cortical thickness, exposed surface area, and total surface area), and the independent measures $K$, $I$, and $S$, where $K$ measures white matter tension, $I$ captures isometric scaling, and $S$ contains the remaining information about cortical shape. Data from 924 healthy controls was included to account for healthy ageing effects occurring during scans. A SurfStat random field theory clustering approach assessed changes across the cortex caused by ATLR.   Compared to preoperative data, surgery had marked effects on all morphological measures. Ipsilateral effects were located in the orbitofrontal and inferior frontal gyri, the pre- and postcentral gyri and supramarginal gyrus, and the lateral occipital gyrus and lingual cortex. Contralateral effects were in the lateral occipital gyrus, and inferior frontal gyrus and frontal pole.   The restructuring following ATLR is reflected in widespread morphological changes, mainly in regions near the resection, but also remotely in regions that are structurally connected to the anterior temporal lobe. The causes could include mechanical effects, Wallerian degeneration, or compensatory plasticity. The study of independent measures revealed additional effects compared to traditional measures.","created":"2022-12-13","meta":{"link":"http://arxiv.org/abs/2212.06529v1","tag":"medical-cv"}}
{"title":"Solving Sample-Level Out-of-Distribution Detection on 3D Medical Images","abstract":"Deep Learning (DL) models tend to perform poorly when the data comes from a distribution different from the training one. In critical applications such as medical imaging, out-of-distribution (OOD) detection helps to identify such data samples, increasing the model's reliability. Recent works have developed DL-based OOD detection that achieves promising results on 2D medical images. However, scaling most of these approaches on 3D images is computationally intractable. Furthermore, the current 3D solutions struggle to achieve acceptable results in detecting even synthetic OOD samples. Such limited performance might indicate that DL often inefficiently embeds large volumetric images. We argue that using the intensity histogram of the original CT or MRI scan as embedding is descriptive enough to run OOD detection. Therefore, we propose a histogram-based method that requires no DL and achieves almost perfect results in this domain. Our proposal is supported two-fold. We evaluate the performance on the publicly available datasets, where our method scores 1.0 AUROC in most setups. And we score second in the Medical Out-of-Distribution challenge without fine-tuning and exploiting task-specific knowledge. Carefully discussing the limitations, we conclude that our method solves the sample-level OOD detection on 3D medical images in the current setting.","created":"2022-12-13","meta":{"link":"http://arxiv.org/abs/2212.06506v1","tag":"medical-cv"}}
{"title":"Mixed Supervision of Histopathology Improves Prostate Cancer Classification from MRI","abstract":"Non-invasive prostate cancer detection from MRI has the potential to revolutionize patient care by providing early detection of clinically-significant disease (ISUP grade group >= 2), but has thus far shown limited positive predictive value. To address this, we present an MRI-based deep learning method for predicting clinically significant prostate cancer applicable to a patient population with subsequent ground truth biopsy results ranging from benign pathology to ISUP grade group~5. Specifically, we demonstrate that mixed supervision via diverse histopathological ground truth improves classification performance despite the cost of reduced concordance with image-based segmentation. That is, where prior approaches have utilized pathology results as ground truth derived from targeted biopsies and whole-mount prostatectomy to strongly supervise the localization of clinically significant cancer, our approach also utilizes weak supervision signals extracted from nontargeted systematic biopsies with regional localization to improve overall performance. Our key innovation is performing regression by distribution rather than simply by value, enabling use of additional pathology findings traditionally ignored by deep learning strategies. We evaluated our model on a dataset of 973 (testing n=160) multi-parametric prostate MRI exams collected at UCSF from 2015-2018 followed by MRI/ultrasound fusion (targeted) biopsy and systematic (nontargeted) biopsy of the prostate gland, demonstrating that deep networks trained with mixed supervision of histopathology can significantly exceed the performance of the Prostate Imaging-Reporting and Data System (PI-RADS) clinical standard for prostate MRI interpretation.","created":"2022-12-13","meta":{"link":"http://arxiv.org/abs/2212.06336v1","tag":"medical-cv"}}
{"title":"Efficient Bayesian Uncertainty Estimation for nnU-Net","abstract":"The self-configuring nnU-Net has achieved leading performance in a large range of medical image segmentation challenges. It is widely considered as the model of choice and a strong baseline for medical image segmentation. However, despite its extraordinary performance, nnU-Net does not supply a measure of uncertainty to indicate its possible failure. This can be problematic for large-scale image segmentation applications, where data are heterogeneous and nnU-Net may fail without notice. In this work, we introduce a novel method to estimate nnU-Net uncertainty for medical image segmentation. We propose a highly effective scheme for posterior sampling of weight space for Bayesian uncertainty estimation. Different from previous baseline methods such as Monte Carlo Dropout and mean-field Bayesian Neural Networks, our proposed method does not require a variational architecture and keeps the original nnU-Net architecture intact, thereby preserving its excellent performance and ease of use. Additionally, we boost the segmentation performance over the original nnU-Net via marginalizing multi-modal posterior models. We applied our method on the public ACDC and M&M datasets of cardiac MRI and demonstrated improved uncertainty estimation over a range of baseline methods. The proposed method further strengthens nnU-Net for medical image segmentation in terms of both segmentation accuracy and quality control.","created":"2022-12-12","meta":{"link":"http://arxiv.org/abs/2212.06278v1","tag":"medical-cv"}}
{"title":"Z-SSMNet: A Zonal-aware Self-Supervised Mesh Network for Prostate Cancer Detection and Diagnosis in bpMRI","abstract":"Prostate cancer (PCa) is one of the most prevalent cancers in men and many people around the world die from clinically significant PCa (csPCa). Early diagnosis of csPCa in bi-parametric MRI (bpMRI), which is non-invasive, cost-effective, and more efficient compared to multiparametric MRI (mpMRI), can contribute to precision care for PCa. The rapid rise in artificial intelligence (AI) algorithms are enabling unprecedented improvements in providing decision support systems that can aid in csPCa diagnosis and understanding. However, existing state of the art AI algorithms which are based on deep learning technology are often limited to 2D images that fails to capture inter-slice correlations in 3D volumetric images. The use of 3D convolutional neural networks (CNNs) partly overcomes this limitation, but it does not adapt to the anisotropy of images, resulting in sub-optimal semantic representation and poor generalization. Furthermore, due to the limitation of the amount of labelled data of bpMRI and the difficulty of labelling, existing CNNs are built on relatively small datasets, leading to a poor performance. To address the limitations identified above, we propose a new Zonal-aware Self-supervised Mesh Network (Z-SSMNet) that adaptatively fuses multiple 2D, 2.5D and 3D CNNs to effectively balance representation for sparse inter-slice information and dense intra-slice information in bpMRI. A self-supervised learning (SSL) technique is further introduced to pre-train our network using unlabelled data to learn the generalizable image features. Furthermore, we constrained our network to understand the zonal specific domain knowledge to improve the diagnosis precision of csPCa. Experiments on the PI-CAI Challenge dataset demonstrate our proposed method achieves better performance for csPCa detection and diagnosis in bpMRI.","created":"2022-12-12","meta":{"link":"http://arxiv.org/abs/2212.05808v1","tag":"medical-cv"}}
{"title":"Noise2Contrast: Multi-Contrast Fusion Enables Self-Supervised Tomographic Image Denoising","abstract":"Self-supervised image denoising techniques emerged as convenient methods that allow training denoising models without requiring ground-truth noise-free data. Existing methods usually optimize loss metrics that are calculated from multiple noisy realizations of similar images, e.g., from neighboring tomographic slices. However, those approaches fail to utilize the multiple contrasts that are routinely acquired in medical imaging modalities like MRI or dual-energy CT. In this work, we propose the new self-supervised training scheme Noise2Contrast that combines information from multiple measured image contrasts to train a denoising model. We stack denoising with domain-transfer operators to utilize the independent noise realizations of different image contrasts to derive a self-supervised loss. The trained denoising operator achieves convincing quantitative and qualitative results, outperforming state-of-the-art self-supervised methods by 4.7-11.0%/4.8-7.3% (PSNR/SSIM) on brain MRI data and by 43.6-50.5%/57.1-77.1% (PSNR/SSIM) on dual-energy CT X-ray microscopy data with respect to the noisy baseline. Our experiments on different real measured data sets indicate that Noise2Contrast training generalizes to other multi-contrast imaging modalities.","created":"2022-12-09","meta":{"link":"http://arxiv.org/abs/2212.04832v1","tag":"medical-cv"}}
{"title":"3D Inception-Based TransMorph: Pre- and Post-operative Multi-contrast MRI Registration in Brain Tumors","abstract":"Deformable image registration is a key task in medical image analysis. The Brain Tumor Sequence Registration challenge (BraTS-Reg) aims at establishing correspondences between pre-operative and follow-up scans of the same patient diagnosed with an adult brain diffuse high-grade glioma and intends to address the challenging task of registering longitudinal data with major tissue appearance changes. In this work, we proposed a two-stage cascaded network based on the Inception and TransMorph models. The dataset for each patient was comprised of a native pre-contrast (T1), a contrast-enhanced T1-weighted (T1-CE), a T2-weighted (T2), and a Fluid Attenuated Inversion Recovery (FLAIR). The Inception model was used to fuse the 4 image modalities together and extract the most relevant information. Then, a variant of the TransMorph architecture was adapted to generate the displacement fields. The Loss function was composed of a standard image similarity measure, a diffusion regularizer, and an edge-map similarity measure added to overcome intensity dependence and reinforce correct boundary deformation. We observed that the addition of the Inception module substantially increased the performance of the network. Additionally, performing an initial affine registration before training the model showed improved accuracy in the landmark error measurements between pre and post-operative MRIs. We observed that our best model composed of the Inception and TransMorph architectures while using an initially affine registered dataset had the best performance with a median absolute error of 2.91 (initial error = 7.8). We achieved 6th place at the time of model submission in the final testing phase of the BraTS-Reg challenge.","created":"2022-12-08","meta":{"link":"http://arxiv.org/abs/2212.04579v1","tag":"medical-cv"}}
{"title":"Motion-Invariant Variational Auto-Encoding of Brain Structural Connectomes","abstract":"Mapping of human brain structural connectomes via diffusion MRI offers a unique opportunity to understand brain structural connectivity and relate it to various human traits, such as cognition. However, motion artifacts from head movement during image acquisition can impact the connectome reconstructions, rendering the subsequent inference results unreliable. We aim to develop a generative model to learn low-dimensional representations of structural connectomes that are invariant to motion artifacts, so that we can link brain networks and human traits more accurately, and generate motion-adjusted connectomes. We applied the proposed model to data from the Adolescent Brain Cognitive Development (ABCD) study and the Human Connectome Project (HCP) to investigate how our motion-invariant connectomes facilitate understanding of the brain network and its relationship with cognition. Empirical results demonstrate that the proposed motion-invariant variational auto-encoder (inv-VAE) outperforms its competitors on various aspects. In particular, motion-adjusted structural connectomes are more strongly associated with a wide array of cognition-related traits than other approaches without motion adjustment.","created":"2022-12-08","meta":{"link":"http://arxiv.org/abs/2212.04535v1","tag":"medical-cv"}}
{"title":"Transformer-based normative modelling for anomaly detection of early schizophrenia","abstract":"Despite the impact of psychiatric disorders on clinical health, early-stage diagnosis remains a challenge. Machine learning studies have shown that classifiers tend to be overly narrow in the diagnosis prediction task. The overlap between conditions leads to high heterogeneity among participants that is not adequately captured by classification models. To address this issue, normative approaches have surged as an alternative method. By using a generative model to learn the distribution of healthy brain data patterns, we can identify the presence of pathologies as deviations or outliers from the distribution learned by the model. In particular, deep generative models showed great results as normative models to identify neurological lesions in the brain. However, unlike most neurological lesions, psychiatric disorders present subtle changes widespread in several brain regions, making these alterations challenging to identify. In this work, we evaluate the performance of transformer-based normative models to detect subtle brain changes expressed in adolescents and young adults. We trained our model on 3D MRI scans of neurotypical individuals (N=1,765). Then, we obtained the likelihood of neurotypical controls and psychiatric patients with early-stage schizophrenia from an independent dataset (N=93) from the Human Connectome Project. Using the predicted likelihood of the scans as a proxy for a normative score, we obtained an AUROC of 0.82 when assessing the difference between controls and individuals with early-stage schizophrenia. Our approach surpassed recent normative methods based on brain age and Gaussian Process, showing the promising use of deep generative models to help in individualised analyses.","created":"2022-12-08","meta":{"link":"http://arxiv.org/abs/2212.04984v1","tag":"medical-cv"}}
{"title":"Identifying mechanisms driving the early response of triple negative breast cancer patients to neoadjuvant chemotherapy using a mechanistic model integrating in vitro and in vivo imaging data","abstract":"Neoadjuvant chemotherapy (NAC) is a standard-of-care treatment for locally advanced triple negative breast cancer (TNBC) before surgery. The early assessment of TNBC response to NAC would enable an oncologist to adapt the therapeutic plan of a non-responding patient, thereby improving treatment outcomes while preventing unnecessary toxicities. To this end, a promising approach consists of obtaining \\textsl{in silico} personalized forecasts of tumor response to NAC \\textsl{via} computer simulation of mechanistic models constrained with patient-specific magnetic resonance imaging (MRI) data acquired early during NAC. Here, we present a model featuring the essential mechanisms of TNBC growth and response to NAC, including an explicit description of drug pharmacodynamics and pharmacokinetics. As longitudinal \\textsl{in vivo} MRI data for model calibration is limited, we perform a sensitivity analysis to identify the model mechanisms driving the response to two NAC drug combinations: doxorubicin with cyclophosphamide, and paclitaxel with carboplatin. The model parameter space is constructed by combining patient-specific MRI-based \\textsl{in silico} parameter estimates and \\textit{in vitro} measurements of pharmacodynamic parameters obtained using time-resolved microscopy assays of several TNBC lines. The sensitivity analysis is run in two MRI-based scenarios corresponding to a well-perfused and a poorly-perfused tumor. Out of the 15 parameters considered herein, only the baseline tumor cell net proliferation rate along with the maximum concentrations and effects of doxorubicin, carboplatin, and paclitaxel exhibit a relevant impact on model forecasts (total effect index, $S_T>$0.1). These results dramatically limit the number of parameters that require \\textsl{in vivo} MRI-constrained calibration, thereby facilitating the clinical application of our model.","created":"2022-12-08","meta":{"link":"http://arxiv.org/abs/2212.04270v1","tag":"medical-cv"}}
{"title":"P2T2: a Physically-primed deep-neural-network approach for robust $T_{2}$ distribution estimation from quantitative $T_{2}$-weighted MRI","abstract":"Estimation of the T2 distribution from multi-echo T2-Weighted MRI (T2W) data can provide insight into the microscopic content of tissue using macroscopic imaging. This information can be used as a biomarker for several pathologies, such as tumor characterization, osteoarthritis, and neurodegenerative diseases. Recently, deep neural network (DNN) based methods were proposed for T2 distribution estimation from MRI data. However, these methods are highly sensitive to distribution shifts such as variations in the echo-times (TE) used during acquisition. Therefore, DNN-based methods cannot be utilized in large-scale multi-institutional trials with heterogeneous acquisition protocols. We present P2T2, a new physically-primed DNN approach for T2 distribution estimation that is robust to different acquisition parameters while maintaining state-of-the-art estimation accuracy. Our P2T2 model encodes the forward model of the signal decay by taking as input the TE acquisition array, in addition to the MRI signal, and provides an estimate of the corresponding T2 distribution as its output. Our P2T2 model has improved the robustness against distribution shifts in the acquisition process by more than 50% compared to the previously proposed DNN model. When tested without any distribution shifts, our model achieved about the same accuracy. Finally, when applied to real human MRI data, our P2T2 model produced the most detailed Myelin-Water fraction maps compared to both the MIML model and classical approaches. Our proposed physically-primed approach improved the generalization capacity of DNN models for T2 distribution estimation and their robustness against distribution shifts compared to previous approaches without compromising the accuracy.","created":"2022-12-08","meta":{"link":"http://arxiv.org/abs/2212.04928v1","tag":"medical-cv"}}
{"title":"Few-shot Medical Image Segmentation with Cycle-resemblance Attention","abstract":"Recently, due to the increasing requirements of medical imaging applications and the professional requirements of annotating medical images, few-shot learning has gained increasing attention in the medical image semantic segmentation field. To perform segmentation with limited number of labeled medical images, most existing studies use Proto-typical Networks (PN) and have obtained compelling success. However, these approaches overlook the query image features extracted from the proposed representation network, failing to preserving the spatial connection between query and support images. In this paper, we propose a novel self-supervised few-shot medical image segmentation network and introduce a novel Cycle-Resemblance Attention (CRA) module to fully leverage the pixel-wise relation between query and support medical images. Notably, we first line up multiple attention blocks to refine more abundant relation information. Then, we present CRAPNet by integrating the CRA module with a classic prototype network, where pixel-wise relations between query and support features are well recaptured for segmentation. Extensive experiments on two different medical image datasets, e.g., abdomen MRI and abdomen CT, demonstrate the superiority of our model over existing state-of-the-art methods.","created":"2022-12-07","meta":{"link":"http://arxiv.org/abs/2212.03967v1","tag":"medical-cv"}}
{"title":"ERNet: Unsupervised Collective Extraction and Registration in Neuroimaging Data","abstract":"Brain extraction and registration are important preprocessing steps in neuroimaging data analysis, where the goal is to extract the brain regions from MRI scans (i.e., extraction step) and align them with a target brain image (i.e., registration step). Conventional research mainly focuses on developing methods for the extraction and registration tasks separately under supervised settings. The performance of these methods highly depends on the amount of training samples and visual inspections performed by experts for error correction. However, in many medical studies, collecting voxel-level labels and conducting manual quality control in high-dimensional neuroimages (e.g., 3D MRI) are very expensive and time-consuming. Moreover, brain extraction and registration are highly related tasks in neuroimaging data and should be solved collectively. In this paper, we study the problem of unsupervised collective extraction and registration in neuroimaging data. We propose a unified end-to-end framework, called ERNet (Extraction-Registration Network), to jointly optimize the extraction and registration tasks, allowing feedback between them. Specifically, we use a pair of multi-stage extraction and registration modules to learn the extraction mask and transformation, where the extraction network improves the extraction accuracy incrementally and the registration network successively warps the extracted image until it is well-aligned with the target image. Experiment results on real-world datasets show that our proposed method can effectively improve the performance on extraction and registration tasks in neuroimaging data. Our code and data can be found at https://github.com/ERNetERNet/ERNet","created":"2022-12-06","meta":{"link":"http://arxiv.org/abs/2212.03306v1","tag":"medical-cv"}}
{"title":"Hybrid Model using Feature Extraction and Non-linear SVM for Brain Tumor Classification","abstract":"It is essential to classify brain tumors from magnetic resonance imaging (MRI) accurately for better and timely treatment of the patients. In this paper, we propose a hybrid model, using VGG along with Nonlinear-SVM (Soft and Hard) to classify the brain tumors: glioma and pituitary and tumorous and non-tumorous. The VGG-SVM model is trained for two different datasets of two classes; thus, we perform binary classification. The VGG models are trained via the PyTorch python library to obtain the highest testing accuracy of tumor classification. The method is threefold, in the first step, we normalize and resize the images, and the second step consists of feature extraction through variants of the VGG model. The third step classified brain tumors using non-linear SVM (soft and hard). We have obtained 98.18% accuracy for the first dataset and 99.78% for the second dataset using VGG19. The classification accuracies for non-linear SVM are 95.50% and 97.98% with linear and rbf kernel and 97.95% for soft SVM with RBF kernel with D1, and 96.75% and 98.60% with linear and RBF kernel and 98.38% for soft SVM with RBF kernel with D2. Results indicate that the hybrid VGG-SVM model, especially VGG 19 with SVM, is able to outperform existing techniques and achieve high accuracy.","created":"2022-12-06","meta":{"link":"http://arxiv.org/abs/2212.02794v1","tag":"medical-cv"}}
{"title":"Simultaneous mapping of temperature and hydration in proton exchange membrane of fuel cells using magnetic resonance imaging","abstract":"The efficiency of a proton exchange membrane (PEM) fuel cell depends on the mobility of protons in the PEM, which is determined by the hydration and temperature of the membrane. While optical techniques or neutron or x-ray scattering techniques may be used to study the inhomogeneities in hydration and temperature in PEMs, these techniques cannot provide 3 dimensional spatial resolution in measuring layered PEMs. Due to their ability to provide non-invasive 3D images, spin-lattice relaxation time (T1) and spin-spin relaxation time (T2) contrast magnetic resonance imaging (MRI) of protons in PEMs have been suggested as methods to map hydration in the fuel cells. We show that while T1 and T2 imaging may be used to map hydration in PEMs under isothermal conditions, proton T1 and T2 are also a function of temperature. For PEM fuel cells, where current densities are large and thermal gradients are expected, T1 and T2 relaxation times cannot be used for mapping hydration. The chemical shift of the mobile proton is, however, a strong function of hydration but not temperature. Therefore, chemical shift imaging (CSI) can be used to map hydration. The diffusion constant of the mobile proton, which can be determined by pulsed field gradient NMR, increases with both temperature and hydration. Therefore, CSI followed by imaging of diffusion via pulsed field gradients can be used for separate mappings of hydration and temperature in PEMs. Here, we demonstrate a 16 x 16 pixel MRI mapping of hydration and temperature in Nafion PEMs with a spatial resolution of 1 mm x 1 mm, a total scan time of 3 minutes, a temperature resolution of 6 K, and an uncertainty in hydration within 15%. The demonstrated mapping can be generalized for imaging exchange membranes of any fuel cells or flow batteries.","created":"2022-12-05","meta":{"link":"http://arxiv.org/abs/2212.02589v3","tag":"medical-cv"}}
{"title":"Particle migration of suspensions in a pressure-driven flow over and through a porous structure","abstract":"Laboratory experiments were conducted to study particle migration and flow properties of non- Brownian, non-colloidal suspensions ranging from 10% to 40% particle volume fraction in a pressure-driven flow over and through a porous structure at low Reynolds number. Particle concentration maps, velocity maps and corresponding profiles were acquired using a magnetic resonance imaging (MRI) technique. The model porous medium consists of square arrays of circular rods oriented across the flow in a rectangular microchannel. It was observed that the square arrays of the circular rods modify the velocity profiles and result in heterogeneous concentration fields for various suspensions. As the bulk particle volume fraction of the suspension increases, particles tend to concentrate in the free channel relative to the porous medium while the centerline velocity profile along the lateral direction becomes increasingly blunted. Within the porous structure, concentrated suspensions exhibit smaller periodic axial velocity variations due to the geometry compared to semi-dilute suspensions (bulk volume fraction ranges from 10% to 20%) and show periodic concentration variations, where average particle concentration is slightly greater between the rods than on top of the rods. For concentrated systems, high particle concentration pathways aligned with the flow direction are observed in regions that correspond to gaps between rods within the porous medium.","created":"2022-12-05","meta":{"link":"http://arxiv.org/abs/2212.02550v1","tag":"medical-cv"}}
{"title":"Decoding natural image stimuli from fMRI data with a surface-based convolutional network","abstract":"Due to the low signal-to-noise ratio and limited resolution of functional MRI data, and the high complexity of natural images, reconstructing a visual stimulus from human brain fMRI measurements is a challenging task. In this work, we propose a novel approach for this task, which we call Cortex2Image, to decode visual stimuli with high semantic fidelity and rich fine-grained detail. In particular, we train a surface-based convolutional network model that maps from brain response to semantic image features first (Cortex2Semantic). We then combine this model with a high-quality image generator (Instance-Conditioned GAN) to train another mapping from brain response to fine-grained image features using a variational approach (Cortex2Detail). Image reconstructions obtained by our proposed method achieve state-of-the-art semantic fidelity, while yielding good fine-grained similarity with the ground-truth stimulus. Our code is available at: https://github.com/zijin-gu/meshconv-decoding.git.","created":"2022-12-05","meta":{"link":"http://arxiv.org/abs/2212.02409v2","tag":"medical-cv"}}
{"title":"L2SR: Learning to Sample and Reconstruct for Accelerated MRI","abstract":"Accelerated MRI aims to find a pair of samplers and reconstructors to reduce acquisition time while maintaining the reconstruction quality. Most of the existing works focus on finding either sparse samplers with a fixed reconstructor or finding reconstructors with a fixed sampler. Recently, people have begun to consider learning samplers and reconstructors jointly. In this paper, we propose an alternating training framework for finding a good pair of samplers and reconstructors via deep reinforcement learning (RL). In particular, we propose a novel sparse-reward Partially Observed Markov Decision Process (POMDP) to formulate the MRI sampling trajectory. Compared to the existing works that utilize dense-reward POMDPs, the proposed sparse-reward POMDP is more computationally efficient and has a provable advantage over dense-reward POMDPs. We evaluate our method on fastMRI, a public benchmark MRI dataset, and it achieves state-of-the-art reconstruction performances.","created":"2022-12-05","meta":{"link":"http://arxiv.org/abs/2212.02190v2","tag":"medical-cv"}}
{"title":"LE-UDA: Label-efficient unsupervised domain adaptation for medical image segmentation","abstract":"While deep learning methods hitherto have achieved considerable success in medical image segmentation, they are still hampered by two limitations: (i) reliance on large-scale well-labeled datasets, which are difficult to curate due to the expert-driven and time-consuming nature of pixel-level annotations in clinical practices, and (ii) failure to generalize from one domain to another, especially when the target domain is a different modality with severe domain shifts. Recent unsupervised domain adaptation~(UDA) techniques leverage abundant labeled source data together with unlabeled target data to reduce the domain gap, but these methods degrade significantly with limited source annotations. In this study, we address this underexplored UDA problem, investigating a challenging but valuable realistic scenario, where the source domain not only exhibits domain shift~w.r.t. the target domain but also suffers from label scarcity. In this regard, we propose a novel and generic framework called ``Label-Efficient Unsupervised Domain Adaptation\"~(LE-UDA). In LE-UDA, we construct self-ensembling consistency for knowledge transfer between both domains, as well as a self-ensembling adversarial learning module to achieve better feature alignment for UDA. To assess the effectiveness of our method, we conduct extensive experiments on two different tasks for cross-modality segmentation between MRI and CT images. Experimental results demonstrate that the proposed LE-UDA can efficiently leverage limited source labels to improve cross-domain segmentation performance, outperforming state-of-the-art UDA approaches in the literature. Code is available at: https://github.com/jacobzhaoziyuan/LE-UDA.","created":"2022-12-05","meta":{"link":"http://arxiv.org/abs/2212.02078v1","tag":"medical-cv"}}
{"title":"CloudBrain-ReconAI: An Online Platform for MRI Reconstruction and Image Quality Evaluation","abstract":"Efficient collaboration between engineers and radiologists is important for image reconstruction algorithm development and image quality evaluation in magnetic resonance imaging (MRI). Here, we develop CloudBrain-ReconAI, an online cloud computing platform, for algorithm deployment, fast and blind reader study. This platform supports online image reconstruction using state-of-the-art artificial intelligence and compressed sensing algorithms with applications to fast imaging and high-resolution diffusion imaging. Through visiting the website, radiologists can easily score and mark the images. Then, automatic statistical analysis will be provided. CloudBrain-ReconAI is now open accessed at https://csrc.xmu.edu.cn/CloudBrain.html and will be continually improved to serve the MRI research community.","created":"2022-12-04","meta":{"link":"http://arxiv.org/abs/2212.01878v1","tag":"medical-cv"}}
{"title":"MouseGAN++: Unsupervised Disentanglement and Contrastive Representation for Multiple MRI Modalities Synthesis and Structural Segmentation of Mouse Brain","abstract":"Segmenting the fine structure of the mouse brain on magnetic resonance (MR) images is critical for delineating morphological regions, analyzing brain function, and understanding their relationships. Compared to a single MRI modality, multimodal MRI data provide complementary tissue features that can be exploited by deep learning models, resulting in better segmentation results. However, multimodal mouse brain MRI data is often lacking, making automatic segmentation of mouse brain fine structure a very challenging task. To address this issue, it is necessary to fuse multimodal MRI data to produce distinguished contrasts in different brain structures. Hence, we propose a novel disentangled and contrastive GAN-based framework, named MouseGAN++, to synthesize multiple MR modalities from single ones in a structure-preserving manner, thus improving the segmentation performance by imputing missing modalities and multi-modality fusion. Our results demonstrate that the translation performance of our method outperforms the state-of-the-art methods. Using the subsequently learned modality-invariant information as well as the modality-translated images, MouseGAN++ can segment fine brain structures with averaged dice coefficients of 90.0% (T2w) and 87.9% (T1w), respectively, achieving around +10% performance improvement compared to the state-of-the-art algorithms. Our results demonstrate that MouseGAN++, as a simultaneous image synthesis and segmentation method, can be used to fuse cross-modality information in an unpaired manner and yield more robust performance in the absence of multimodal data. We release our method as a mouse brain structural segmentation tool for free academic usage at https://github.com/yu02019.","created":"2022-12-04","meta":{"link":"http://arxiv.org/abs/2212.01825v1","tag":"medical-cv"}}
{"title":"Brain Tumor Synthetic Data Generation with Adaptive StyleGANs","abstract":"Generative models have been very successful over the years and have received significant attention for synthetic data generation. As deep learning models are getting more and more complex, they require large amounts of data to perform accurately. In medical image analysis, such generative models play a crucial role as the available data is limited due to challenges related to data privacy, lack of data diversity, or uneven data distributions. In this paper, we present a method to generate brain tumor MRI images using generative adversarial networks. We have utilized StyleGAN2 with ADA methodology to generate high-quality brain MRI with tumors while using a significantly smaller amount of training data when compared to the existing approaches. We use three pre-trained models for transfer learning. Results demonstrate that the proposed method can learn the distributions of brain tumors. Furthermore, the model can generate high-quality synthetic brain MRI with a tumor that can limit the small sample size issues. The approach can addresses the limited data availability by generating realistic-looking brain MRI with tumors. The code is available at: ~\\url{https://github.com/rizwanqureshi123/Brain-Tumor-Synthetic-Data}.","created":"2022-12-04","meta":{"link":"http://arxiv.org/abs/2212.01772v1","tag":"medical-cv"}}
{"title":"Semi-supervised Learning with Robust Loss in Brain Segmentation","abstract":"In this work, we used a semi-supervised learning method to train deep learning model that can segment the brain MRI images. The semi-supervised model uses less labeled data, and the performance is competitive with the supervised model with full labeled data. This framework could reduce the cost of labeling MRI images. We also introduced robust loss to reduce the noise effects of inaccurate labels generated in semi-supervised learning.","created":"2022-12-03","meta":{"link":"http://arxiv.org/abs/2212.03082v1","tag":"medical-cv"}}
{"title":"Regularized Optimal Mass Transport with Nonlinear Diffusion","abstract":"In this paper, we combine nonlinear diffusion with the regularized optimal mass transport (rOMT) model. As we will demonstrate, this new approach provides further insights into certain applications of fluid flow analysis in the brain. From the point of view of image processing, the anisotropic diffusion method, based on Perona-Malik, explicitly considers edge information. Applied to rOMT analysis of glymphatic transport based on DCE-MRI data, this new framework appears to capture a larger advection-dominant volume.","created":"2022-12-03","meta":{"link":"http://arxiv.org/abs/2301.03428v1","tag":"medical-cv"}}
{"title":"Investigating certain choices of CNN configurations for brain lesion segmentation","abstract":"Brain tumor imaging has been part of the clinical routine for many years to perform non-invasive detection and grading of tumors. Tumor segmentation is a crucial step for managing primary brain tumors because it allows a volumetric analysis to have a longitudinal follow-up of tumor growth or shrinkage to monitor disease progression and therapy response. In addition, it facilitates further quantitative analysis such as radiomics. Deep learning models, in particular CNNs, have been a methodology of choice in many applications of medical image analysis including brain tumor segmentation. In this study, we investigated the main design aspects of CNN models for the specific task of MRI-based brain tumor segmentation. Two commonly used CNN architectures (i.e. DeepMedic and U-Net) were used to evaluate the impact of the essential parameters such as learning rate, batch size, loss function, and optimizer. The performance of CNN models using different configurations was assessed with the BraTS 2018 dataset to determine the most performant model. Then, the generalization ability of the model was assessed using our in-house dataset. For all experiments, U-Net achieved a higher DSC compared to the DeepMedic. However, the difference was only statistically significant for whole tumor segmentation using FLAIR sequence data and tumor core segmentation using T1w sequence data. Adam and SGD both with the initial learning rate set to 0.001 provided the highest segmentation DSC when training the CNN model using U-Net and DeepMedic architectures, respectively. No significant difference was observed when using different normalization approaches. In terms of loss functions, a weighted combination of soft Dice and cross-entropy loss with the weighting term set to 0.5 resulted in an improved segmentation performance and training stability for both DeepMedic and U-Net models.","created":"2022-12-02","meta":{"link":"http://arxiv.org/abs/2212.01235v1","tag":"medical-cv"}}
{"title":"Robust Circuitry-Based Scores of Structural Importance of Human Brain Areas","abstract":"We consider the 1015-vertex human consensus connectome computed from the diffusion MRI data of 1064 subjects. We define seven different orders on these 1015 graph vertices, where the orders depend on parameters derived from the brain circuitry, that is, from the properties of the edges (or connections) incident to the vertices ordered. We order the vertices according to their degree, the sum, the maximum, and the average of the fiber counts on the incident edges, and the sum, the maximum and the average length of the fibers in the incident edges. We analyze the similarities of these seven orders by the Spearman correlation coefficient and by their inversion numbers and have found that all of these seven orders have great similarities. In other words, if we interpret the orders as scoring of the importance of the vertices in the consensus connectome, then the scores of the vertices will be similar in all seven orderings. That is, important vertices of the human connectome typically have many neighbors, connected with long and thick axonal fibers (where thickness is measured by fiber numbers), and their incident edges have high maximum and average values of length and fiber-number parameters, too. Therefore, these parameters may yield robust ways of deciding which vertices are more important in the anatomy of our brain circuitry than the others.","created":"2022-11-30","meta":{"link":"http://arxiv.org/abs/2212.00168v1","tag":"medical-cv"}}
{"title":"Generalized Deep Learning-based Proximal Gradient Descent for MR Reconstruction","abstract":"The data consistency for the physical forward model is crucial in inverse problems, especially in MR imaging reconstruction. The standard way is to unroll an iterative algorithm into a neural network with a forward model embedded. The forward model always changes in clinical practice, so the learning component's entanglement with the forward model makes the reconstruction hard to generalize. The deep learning-based proximal gradient descent was proposed and use a network as regularization term that is independent of the forward model, which makes it more generalizable for different MR acquisition settings. This one-time pre-trained regularization is applied to different MR acquisition settings and was compared to conventional L1 regularization showing ~3 dB improvement in the peak signal-to-noise ratio. We also demonstrated the flexibility of the proposed method in choosing different undersampling patterns.","created":"2022-11-30","meta":{"link":"http://arxiv.org/abs/2211.16881v2","tag":"medical-cv"}}
