{"created":"2023-10-09 17:59:53","title":"FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing","abstract":"Text-to-video editing aims to edit the visual appearance of a source video conditional on textual prompts. A major challenge in this task is to ensure that all frames in the edited video are visually consistent. Most recent works apply advanced text-to-image diffusion models to this task by inflating 2D spatial attention in the U-Net into spatio-temporal attention. Although temporal context can be added through spatio-temporal attention, it may introduce some irrelevant information for each patch and therefore cause inconsistency in the edited video. In this paper, for the first time, we introduce optical flow into the attention module in the diffusion model's U-Net to address the inconsistency issue for text-to-video editing. Our method, FLATTEN, enforces the patches on the same flow path across different frames to attend to each other in the attention module, thus improving the visual consistency in the edited videos. Additionally, our method is training-free and can be seamlessly integrated into any diffusion-based text-to-video editing methods and improve their visual consistency. Experiment results on existing text-to-video editing benchmarks show that our proposed method achieves the new state-of-the-art performance. In particular, our method excels in maintaining the visual consistency in the edited videos.","sentences":["Text-to-video editing aims to edit the visual appearance of a source video conditional on textual prompts.","A major challenge in this task is to ensure that all frames in the edited video are visually consistent.","Most recent works apply advanced text-to-image diffusion models to this task by inflating 2D spatial attention in the U-Net into spatio-temporal attention.","Although temporal context can be added through spatio-temporal attention, it may introduce some irrelevant information for each patch and therefore cause inconsistency in the edited video.","In this paper, for the first time, we introduce optical flow into the attention module in the diffusion model's U-Net to address the inconsistency issue for text-to-video editing.","Our method, FLATTEN, enforces the patches on the same flow path across different frames to attend to each other in the attention module, thus improving the visual consistency in the edited videos.","Additionally, our method is training-free and can be seamlessly integrated into any diffusion-based text-to-video editing methods and improve their visual consistency.","Experiment results on existing text-to-video editing benchmarks show that our proposed method achieves the new state-of-the-art performance.","In particular, our method excels in maintaining the visual consistency in the edited videos."],"url":"http://arxiv.org/abs/2310.05922v1"}
{"created":"2023-10-09 17:59:26","title":"SimPLR: A Simple and Plain Transformer for Object Detection and Segmentation","abstract":"The ability to detect objects in images at varying scales has played a pivotal role in the design of modern object detectors. Despite considerable progress in removing handcrafted components using transformers, multi-scale feature maps remain a key factor for their empirical success, even with a plain backbone like the Vision Transformer (ViT). In this paper, we show that this reliance on feature pyramids is unnecessary and a transformer-based detector with scale-aware attention enables the plain detector `SimPLR' whose backbone and detection head both operate on single-scale features. The plain architecture allows SimPLR to effectively take advantages of self-supervised learning and scaling approaches with ViTs, yielding strong performance compared to multi-scale counterparts. We demonstrate through our experiments that when scaling to larger backbones, SimPLR indicates better performance than end-to-end detectors (Mask2Former) and plain-backbone detectors (ViTDet), while consistently being faster. The code will be released.","sentences":["The ability to detect objects in images at varying scales has played a pivotal role in the design of modern object detectors.","Despite considerable progress in removing handcrafted components using transformers, multi-scale feature maps remain a key factor for their empirical success, even with a plain backbone like the Vision Transformer (ViT).","In this paper, we show that this reliance on feature pyramids is unnecessary and a transformer-based detector with scale-aware attention enables the plain detector `SimPLR' whose backbone and detection head both operate on single-scale features.","The plain architecture allows SimPLR to effectively take advantages of self-supervised learning and scaling approaches with ViTs, yielding strong performance compared to multi-scale counterparts.","We demonstrate through our experiments that when scaling to larger backbones, SimPLR indicates better performance than end-to-end detectors (Mask2Former) and plain-backbone detectors (ViTDet), while consistently being faster.","The code will be released."],"url":"http://arxiv.org/abs/2310.05920v1"}
{"created":"2023-10-09 17:59:21","title":"Few-Shot Spoken Language Understanding via Joint Speech-Text Models","abstract":"Recent work on speech representation models jointly pre-trained with text has demonstrated the potential of improving speech representations by encoding speech and text in a shared space. In this paper, we leverage such shared representations to address the persistent challenge of limited data availability in spoken language understanding tasks. By employing a pre-trained speech-text model, we find that models fine-tuned on text can be effectively transferred to speech testing data. With as little as 1 hour of labeled speech data, our proposed approach achieves comparable performance on spoken language understanding tasks (specifically, sentiment analysis and named entity recognition) when compared to previous methods using speech-only pre-trained models fine-tuned on 10 times more data. Beyond the proof-of-concept study, we also analyze the latent representations. We find that the bottom layers of speech-text models are largely task-agnostic and align speech and text representations into a shared space, while the top layers are more task-specific.","sentences":["Recent work on speech representation models jointly pre-trained with text has demonstrated the potential of improving speech representations by encoding speech and text in a shared space.","In this paper, we leverage such shared representations to address the persistent challenge of limited data availability in spoken language understanding tasks.","By employing a pre-trained speech-text model, we find that models fine-tuned on text can be effectively transferred to speech testing data.","With as little as 1 hour of labeled speech data, our proposed approach achieves comparable performance on spoken language understanding tasks (specifically, sentiment analysis and named entity recognition) when compared to previous methods using speech-only pre-trained models fine-tuned on 10 times more data.","Beyond the proof-of-concept study, we also analyze the latent representations.","We find that the bottom layers of speech-text models are largely task-agnostic and align speech and text representations into a shared space, while the top layers are more task-specific."],"url":"http://arxiv.org/abs/2310.05919v1"}
{"created":"2023-10-09 17:59:12","title":"Drivable Avatar Clothing: Faithful Full-Body Telepresence with Dynamic Clothing Driven by Sparse RGB-D Input","abstract":"Clothing is an important part of human appearance but challenging to model in photorealistic avatars. In this work we present avatars with dynamically moving loose clothing that can be faithfully driven by sparse RGB-D inputs as well as body and face motion. We propose a Neural Iterative Closest Point (N-ICP) algorithm that can efficiently track the coarse garment shape given sparse depth input. Given the coarse tracking results, the input RGB-D images are then remapped to texel-aligned features, which are fed into the drivable avatar models to faithfully reconstruct appearance details. We evaluate our method against recent image-driven synthesis baselines, and conduct a comprehensive analysis of the N-ICP algorithm. We demonstrate that our method can generalize to a novel testing environment, while preserving the ability to produce high-fidelity and faithful clothing dynamics and appearance.","sentences":["Clothing is an important part of human appearance but challenging to model in photorealistic avatars.","In this work we present avatars with dynamically moving loose clothing that can be faithfully driven by sparse RGB-D inputs as well as body and face motion.","We propose a Neural Iterative Closest Point (N-ICP) algorithm that can efficiently track the coarse garment shape given sparse depth input.","Given the coarse tracking results, the input RGB-D images are then remapped to texel-aligned features, which are fed into the drivable avatar models to faithfully reconstruct appearance details.","We evaluate our method against recent image-driven synthesis baselines, and conduct a comprehensive analysis of the N-ICP algorithm.","We demonstrate that our method can generalize to a novel testing environment, while preserving the ability to produce high-fidelity and faithful clothing dynamics and appearance."],"url":"http://arxiv.org/abs/2310.05917v1"}
{"created":"2023-10-09 17:59:04","title":"Interpreting CLIP's Image Representation via Text-Based Decomposition","abstract":"We investigate the CLIP image encoder by analyzing how individual model components affect the final representation. We decompose the image representation as a sum across individual image patches, model layers, and attention heads, and use CLIP's text representation to interpret the summands. Interpreting the attention heads, we characterize each head's role by automatically finding text representations that span its output space, which reveals property-specific roles for many heads (e.g. location or shape). Next, interpreting the image patches, we uncover an emergent spatial localization within CLIP. Finally, we use this understanding to remove spurious features from CLIP and to create a strong zero-shot image segmenter. Our results indicate that a scalable understanding of transformer models is attainable and can be used to repair and improve models.","sentences":["We investigate the CLIP image encoder by analyzing how individual model components affect the final representation.","We decompose the image representation as a sum across individual image patches, model layers, and attention heads, and use CLIP's text representation to interpret the summands.","Interpreting the attention heads, we characterize each head's role by automatically finding text representations that span its output space, which reveals property-specific roles for many heads (e.g. location or shape).","Next, interpreting the image patches, we uncover an emergent spatial localization within CLIP.","Finally, we use this understanding to remove spurious features from CLIP and to create a strong zero-shot image segmenter.","Our results indicate that a scalable understanding of transformer models is attainable and can be used to repair and improve models."],"url":"http://arxiv.org/abs/2310.05916v1"}
{"created":"2023-10-09 17:58:38","title":"FireAct: Toward Language Agent Fine-tuning","abstract":"Recent efforts have augmented language models (LMs) with external tools or environments, leading to the development of language agents that can reason and act. However, most of these agents rely on few-shot prompting techniques with off-the-shelf LMs. In this paper, we investigate and argue for the overlooked direction of fine-tuning LMs to obtain language agents. Using a setup of question answering (QA) with a Google search API, we explore a variety of base LMs, prompting methods, fine-tuning data, and QA tasks, and find language agents are consistently improved after fine-tuning their backbone LMs. For example, fine-tuning Llama2-7B with 500 agent trajectories generated by GPT-4 leads to a 77% HotpotQA performance increase. Furthermore, we propose FireAct, a novel approach to fine-tuning LMs with trajectories from multiple tasks and prompting methods, and show having more diverse fine-tuning data can further improve agents. Along with other findings regarding scaling effects, robustness, generalization, efficiency and cost, our work establishes comprehensive benefits of fine-tuning LMs for agents, and provides an initial set of experimental designs, insights, as well as open questions toward language agent fine-tuning.","sentences":["Recent efforts have augmented language models (LMs) with external tools or environments, leading to the development of language agents that can reason and act.","However, most of these agents rely on few-shot prompting techniques with off-the-shelf LMs.","In this paper, we investigate and argue for the overlooked direction of fine-tuning LMs to obtain language agents.","Using a setup of question answering (QA) with a Google search API, we explore a variety of base LMs, prompting methods, fine-tuning data, and QA tasks, and find language agents are consistently improved after fine-tuning their backbone LMs.","For example, fine-tuning Llama2-7B with 500 agent trajectories generated by GPT-4 leads to a 77% HotpotQA performance increase.","Furthermore, we propose FireAct, a novel approach to fine-tuning LMs with trajectories from multiple tasks and prompting methods, and show having more diverse fine-tuning data can further improve agents.","Along with other findings regarding scaling effects, robustness, generalization, efficiency and cost, our work establishes comprehensive benefits of fine-tuning LMs for agents, and provides an initial set of experimental designs, insights, as well as open questions toward language agent fine-tuning."],"url":"http://arxiv.org/abs/2310.05915v1"}
{"created":"2023-10-09 17:58:34","title":"NEFTune: Noisy Embeddings Improve Instruction Finetuning","abstract":"We show that language model finetuning can be improved, sometimes dramatically, with a simple augmentation. NEFTune adds noise to the embedding vectors during training. Standard finetuning of LLaMA-2-7B using Alpaca achieves 29.79% on AlpacaEval, which rises to 64.69% using noisy embeddings. NEFTune also improves over strong baselines on modern instruction datasets. Models trained with Evol-Instruct see a 10% improvement, with ShareGPT an 8% improvement, and with OpenPlatypus an 8% improvement. Even powerful models further refined with RLHF such as LLaMA-2-Chat benefit from additional training with NEFTune.","sentences":["We show that language model finetuning can be improved, sometimes dramatically, with a simple augmentation.","NEFTune adds noise to the embedding vectors during training.","Standard finetuning of LLaMA-2-7B using Alpaca achieves 29.79% on AlpacaEval, which rises to 64.69% using noisy embeddings.","NEFTune also improves over strong baselines on modern instruction datasets.","Models trained with Evol-Instruct see a 10% improvement, with ShareGPT an 8% improvement, and with OpenPlatypus an 8% improvement.","Even powerful models further refined with RLHF such as LLaMA-2-Chat benefit from additional training with NEFTune."],"url":"http://arxiv.org/abs/2310.05914v1"}
{"created":"2023-10-09 17:56:53","title":"SALMON: Self-Alignment with Principle-Following Reward Models","abstract":"Supervised Fine-Tuning (SFT) on response demonstrations combined with Reinforcement Learning from Human Feedback (RLHF) constitutes a powerful paradigm for aligning LLM-based AI agents. However, a significant limitation of such an approach is its dependency on high-quality human annotations, making its application to intricate tasks challenging due to difficulties in obtaining consistent response demonstrations and in-distribution response preferences. This paper presents a novel approach, namely SALMON (Self-ALignMent with principle-fOllowiNg reward models), to align base language models with minimal human supervision, using only a small set of human-defined principles, yet achieving superior performance. Central to our approach is a principle-following reward model. Trained on synthetic preference data, this model can generate reward scores based on arbitrary human-defined principles. By merely adjusting these principles during the RL training phase, we gain full control over the preferences with the reward model, subsequently influencing the behavior of the RL-trained policies, and eliminating the reliance on the collection of online human preferences. Applying our method to the LLaMA-2-70b base language model, we developed an AI assistant named Dromedary-2. With only 6 exemplars for in-context learning and 31 human-defined principles, Dromedary-2 significantly surpasses the performance of several state-of-the-art AI systems, including LLaMA-2-Chat-70b, on various benchmark datasets. We have open-sourced the code and model weights to encourage further research into aligning LLM-based AI agents with enhanced supervision efficiency, improved controllability, and scalable oversight.","sentences":["Supervised Fine-Tuning (SFT) on response demonstrations combined with Reinforcement Learning from Human Feedback (RLHF) constitutes a powerful paradigm for aligning LLM-based AI agents.","However, a significant limitation of such an approach is its dependency on high-quality human annotations, making its application to intricate tasks challenging due to difficulties in obtaining consistent response demonstrations and in-distribution response preferences.","This paper presents a novel approach, namely SALMON (Self-ALignMent with principle-fOllowiNg reward models), to align base language models with minimal human supervision, using only a small set of human-defined principles, yet achieving superior performance.","Central to our approach is a principle-following reward model.","Trained on synthetic preference data, this model can generate reward scores based on arbitrary human-defined principles.","By merely adjusting these principles during the RL training phase, we gain full control over the preferences with the reward model, subsequently influencing the behavior of the RL-trained policies, and eliminating the reliance on the collection of online human preferences.","Applying our method to the LLaMA-2-70b base language model, we developed an AI assistant named Dromedary-2.","With only 6 exemplars for in-context learning and 31 human-defined principles, Dromedary-2 significantly surpasses the performance of several state-of-the-art AI systems, including LLaMA-2-Chat-70b, on various benchmark datasets.","We have open-sourced the code and model weights to encourage further research into aligning LLM-based AI agents with enhanced supervision efficiency, improved controllability, and scalable oversight."],"url":"http://arxiv.org/abs/2310.05910v1"}
{"created":"2023-10-09 17:49:50","title":"TAIL: Task-specific Adapters for Imitation Learning with Large Pretrained Models","abstract":"The full potential of large pretrained models remains largely untapped in control domains like robotics. This is mainly because of the scarcity of data and the computational challenges associated with training or fine-tuning these large models for such applications. Prior work mainly emphasizes effective pretraining of large models for decision-making, with little exploration into how to perform data-efficient continual adaptation of these models for new tasks. Recognizing these constraints, we introduce TAIL (Task-specific Adapters for Imitation Learning), a framework for efficient adaptation to new control tasks. Inspired by recent advancements in parameter-efficient fine-tuning in language domains, we explore efficient fine-tuning techniques -- e.g., Bottleneck Adapters, P-Tuning, and Low-Rank Adaptation (LoRA) -- in TAIL to adapt large pretrained models for new tasks with limited demonstration data. Our extensive experiments in large-scale language-conditioned manipulation tasks comparing prevalent parameter-efficient fine-tuning techniques and adaptation baselines suggest that TAIL with LoRA can achieve the best post-adaptation performance with only 1\\% of the trainable parameters of full fine-tuning, while avoiding catastrophic forgetting and preserving adaptation plasticity in continual learning settings.","sentences":["The full potential of large pretrained models remains largely untapped in control domains like robotics.","This is mainly because of the scarcity of data and the computational challenges associated with training or fine-tuning these large models for such applications.","Prior work mainly emphasizes effective pretraining of large models for decision-making, with little exploration into how to perform data-efficient continual adaptation of these models for new tasks.","Recognizing these constraints, we introduce TAIL (Task-specific Adapters for Imitation Learning), a framework for efficient adaptation to new control tasks.","Inspired by recent advancements in parameter-efficient fine-tuning in language domains, we explore efficient fine-tuning techniques -- e.g., Bottleneck Adapters, P-Tuning, and Low-Rank Adaptation (LoRA) -- in TAIL to adapt large pretrained models for new tasks with limited demonstration data.","Our extensive experiments in large-scale language-conditioned manipulation tasks comparing prevalent parameter-efficient fine-tuning techniques and adaptation baselines suggest that TAIL with LoRA can achieve the best post-adaptation performance with only 1\\% of the trainable parameters of full fine-tuning, while avoiding catastrophic forgetting and preserving adaptation plasticity in continual learning settings."],"url":"http://arxiv.org/abs/2310.05905v1"}
{"created":"2023-10-09 17:47:09","title":"On Multi-Fidelity Impedance Tuning for Human-Robot Cooperative Manipulation","abstract":"We examine how a human-robot interaction (HRI) system may be designed when input-output data from previous experiments are available. In particular, we consider how to select an optimal impedance in the assistance design for a cooperative manipulation task with a new operator. Due to the variability between individuals, the design parameters that best suit one operator of the robot may not be the best parameters for another one. However, by incorporating historical data using a linear auto-regressive (AR-1) Gaussian process, the search for a new operator's optimal parameters can be accelerated. We lay out a framework for optimizing the human-robot cooperative manipulation that only requires input-output data. We establish how the AR-1 model improves the bound on the regret and numerically simulate a human-robot cooperative manipulation task to show the regret improvement. Further, we show how our approach's input-output nature provides robustness against modeling error through an additional numerical study.","sentences":["We examine how a human-robot interaction (HRI) system may be designed when input-output data from previous experiments are available.","In particular, we consider how to select an optimal impedance in the assistance design for a cooperative manipulation task with a new operator.","Due to the variability between individuals, the design parameters that best suit one operator of the robot may not be the best parameters for another one.","However, by incorporating historical data using a linear auto-regressive (AR-1) Gaussian process, the search for a new operator's optimal parameters can be accelerated.","We lay out a framework for optimizing the human-robot cooperative manipulation that only requires input-output data.","We establish how the AR-1 model improves the bound on the regret and numerically simulate a human-robot cooperative manipulation task to show the regret improvement.","Further, we show how our approach's input-output nature provides robustness against modeling error through an additional numerical study."],"url":"http://arxiv.org/abs/2310.05904v1"}
{"created":"2023-10-09 17:41:29","title":"Lion Secretly Solves Constrained Optimization: As Lyapunov Predicts","abstract":"Lion (Evolved Sign Momentum), a new optimizer discovered through program search, has shown promising results in training large AI models. It performs comparably or favorably to AdamW but with greater memory efficiency. As we can expect from the results of a random search program, Lion incorporates elements from several existing algorithms, including signed momentum, decoupled weight decay, Polak, and Nesterov momentum, but does not fit into any existing category of theoretically grounded optimizers. Thus, even though Lion appears to perform well as a general-purpose optimizer for a wide range of tasks, its theoretical basis remains uncertain. This lack of theoretical clarity limits opportunities to further enhance and expand Lion's efficacy.   This work aims to demystify Lion. Based on both continuous-time and discrete-time analysis, we demonstrate that Lion is a theoretically novel and principled approach for minimizing a general loss function $f(x)$ while enforcing a bound constraint $\\|x\\|_\\infty \\leq 1/\\lambda$. Lion achieves this through the incorporation of decoupled weight decay, where $\\lambda$ represents the weight decay coefficient. Our analysis is made possible by the development of a new Lyapunov function for the Lion updates. It applies to a broader family of Lion-$\\kappa$ algorithms, where the $\\text{sign}(\\cdot)$ operator in Lion is replaced by the subgradient of a convex function $\\kappa$, leading to the solution of a general composite optimization problem of $\\min_x f(x) + \\kappa^*(x)$. Our findings provide valuable insights into the dynamics of Lion and pave the way for further improvements and extensions of Lion-related algorithms.","sentences":["Lion (Evolved Sign Momentum), a new optimizer discovered through program search, has shown promising results in training large AI models.","It performs comparably or favorably to AdamW but with greater memory efficiency.","As we can expect from the results of a random search program, Lion incorporates elements from several existing algorithms, including signed momentum, decoupled weight decay, Polak, and Nesterov momentum, but does not fit into any existing category of theoretically grounded optimizers.","Thus, even though Lion appears to perform well as a general-purpose optimizer for a wide range of tasks, its theoretical basis remains uncertain.","This lack of theoretical clarity limits opportunities to further enhance and expand Lion's efficacy.   ","This work aims to demystify Lion.","Based on both continuous-time and discrete-time analysis, we demonstrate that Lion is a theoretically novel and principled approach for minimizing a general loss function $f(x)$ while enforcing a bound constraint $\\|x\\|_\\infty \\leq 1/\\lambda$. Lion achieves this through the incorporation of decoupled weight decay, where $\\lambda$ represents the weight decay coefficient.","Our analysis is made possible by the development of a new Lyapunov function for the Lion updates.","It applies to a broader family of Lion-$\\kappa$ algorithms, where the $\\text{sign}(\\cdot)$ operator in Lion is replaced by the subgradient of a convex function $\\kappa$, leading to the solution of a general composite optimization problem of $\\min_x f(x)","+","\\kappa^*(x)$. Our findings provide valuable insights into the dynamics of Lion and pave the way for further improvements and extensions of Lion-related algorithms."],"url":"http://arxiv.org/abs/2310.05898v1"}
{"created":"2023-10-09 17:28:35","title":"Streaming Anchor Loss: Augmenting Supervision with Temporal Significance","abstract":"Streaming neural network models for fast frame-wise responses to various speech and sensory signals are widely adopted on resource-constrained platforms. Hence, increasing the learning capacity of such streaming models (i.e., by adding more parameters) to improve the predictive power may not be viable for real-world tasks. In this work, we propose a new loss, Streaming Anchor Loss (SAL), to better utilize the given learning capacity by encouraging the model to learn more from essential frames. More specifically, our SAL and its focal variations dynamically modulate the frame-wise cross entropy loss based on the importance of the corresponding frames so that a higher loss penalty is assigned for frames within the temporal proximity of semantically critical events. Therefore, our loss ensures that the model training focuses on predicting the relatively rare but task-relevant frames. Experimental results with standard lightweight convolutional and recurrent streaming networks on three different speech based detection tasks demonstrate that SAL enables the model to learn the overall task more effectively with improved accuracy and latency, without any additional data, model parameters, or architectural changes.","sentences":["Streaming neural network models for fast frame-wise responses to various speech and sensory signals are widely adopted on resource-constrained platforms.","Hence, increasing the learning capacity of such streaming models (i.e., by adding more parameters) to improve the predictive power may not be viable for real-world tasks.","In this work, we propose a new loss, Streaming Anchor Loss (SAL), to better utilize the given learning capacity by encouraging the model to learn more from essential frames.","More specifically, our SAL and its focal variations dynamically modulate the frame-wise cross entropy loss based on the importance of the corresponding frames so that a higher loss penalty is assigned for frames within the temporal proximity of semantically critical events.","Therefore, our loss ensures that the model training focuses on predicting the relatively rare but task-relevant frames.","Experimental results with standard lightweight convolutional and recurrent streaming networks on three different speech based detection tasks demonstrate that SAL enables the model to learn the overall task more effectively with improved accuracy and latency, without any additional data, model parameters, or architectural changes."],"url":"http://arxiv.org/abs/2310.05886v1"}
{"created":"2023-10-09 17:28:05","title":"DTPP: Differentiable Joint Conditional Prediction and Cost Evaluation for Tree Policy Planning in Autonomous Driving","abstract":"Motion prediction and cost evaluation are vital components in the decision-making system of autonomous vehicles. However, existing methods often ignore the importance of cost learning and treat them as separate modules. In this study, we employ a tree-structured policy planner and propose a differentiable joint training framework for both ego-conditioned prediction and cost models, resulting in a direct improvement of the final planning performance. For conditional prediction, we introduce a query-centric Transformer model that performs efficient ego-conditioned motion prediction. For planning cost, we propose a learnable context-aware cost function with latent interaction features, facilitating differentiable joint learning. We validate our proposed approach using the real-world nuPlan dataset and its associated planning test platform. Our framework not only matches state-of-the-art planning methods but outperforms other learning-based methods in planning quality, while operating more efficiently in terms of runtime. We show that joint training delivers significantly better performance than separate training of the two modules. Additionally, we find that tree-structured policy planning outperforms the conventional single-stage planning approach.","sentences":["Motion prediction and cost evaluation are vital components in the decision-making system of autonomous vehicles.","However, existing methods often ignore the importance of cost learning and treat them as separate modules.","In this study, we employ a tree-structured policy planner and propose a differentiable joint training framework for both ego-conditioned prediction and cost models, resulting in a direct improvement of the final planning performance.","For conditional prediction, we introduce a query-centric Transformer model that performs efficient ego-conditioned motion prediction.","For planning cost, we propose a learnable context-aware cost function with latent interaction features, facilitating differentiable joint learning.","We validate our proposed approach using the real-world nuPlan dataset and its associated planning test platform.","Our framework not only matches state-of-the-art planning methods but outperforms other learning-based methods in planning quality, while operating more efficiently in terms of runtime.","We show that joint training delivers significantly better performance than separate training of the two modules.","Additionally, we find that tree-structured policy planning outperforms the conventional single-stage planning approach."],"url":"http://arxiv.org/abs/2310.05885v1"}
{"created":"2023-10-09 17:27:36","title":"A Meta-Learning Perspective on Transformers for Causal Language Modeling","abstract":"The Transformer architecture has become prominent in developing large causal language models. However, mechanisms to explain its capabilities are not well understood. Focused on the training process, here we establish a meta-learning view of the Transformer architecture when trained for the causal language modeling task, by explicating an inner optimization process that may happen within the Transformer. Further, from within the inner optimization, we discover and theoretically analyze a special characteristic of the norms of learned token representations within Transformer-based causal language models. Our analysis is supported by experiments conducted on pre-trained large language models and real-world data.","sentences":["The Transformer architecture has become prominent in developing large causal language models.","However, mechanisms to explain its capabilities are not well understood.","Focused on the training process, here we establish a meta-learning view of the Transformer architecture when trained for the causal language modeling task, by explicating an inner optimization process that may happen within the Transformer.","Further, from within the inner optimization, we discover and theoretically analyze a special characteristic of the norms of learned token representations within Transformer-based causal language models.","Our analysis is supported by experiments conducted on pre-trained large language models and real-world data."],"url":"http://arxiv.org/abs/2310.05884v1"}
{"created":"2023-10-09 17:23:20","title":"Evaluating a VR System for Collecting Safety-Critical Vehicle-Pedestrian Interactions","abstract":"Autonomous vehicles (AVs) require comprehensive and reliable pedestrian trajectory data to ensure safe operation. However, obtaining data of safety-critical scenarios such as jaywalking and near-collisions, or uncommon agents such as children, disabled pedestrians, and vulnerable road users poses logistical and ethical challenges. This paper evaluates a Virtual Reality (VR) system designed to collect pedestrian trajectory and body pose data in a controlled, low-risk environment. We substantiate the usefulness of such a system through semi-structured interviews with professionals in the AV field, and validate the effectiveness of the system through two empirical studies: a first-person user evaluation involving 62 participants, and a third-person evaluative survey involving 290 respondents. Our findings demonstrate that the VR-based data collection system elicits realistic responses for capturing pedestrian data in safety-critical or uncommon vehicle-pedestrian interaction scenarios.","sentences":["Autonomous vehicles (AVs) require comprehensive and reliable pedestrian trajectory data to ensure safe operation.","However, obtaining data of safety-critical scenarios such as jaywalking and near-collisions, or uncommon agents such as children, disabled pedestrians, and vulnerable road users poses logistical and ethical challenges.","This paper evaluates a Virtual Reality (VR) system designed to collect pedestrian trajectory and body pose data in a controlled, low-risk environment.","We substantiate the usefulness of such a system through semi-structured interviews with professionals in the AV field, and validate the effectiveness of the system through two empirical studies: a first-person user evaluation involving 62 participants, and a third-person evaluative survey involving 290 respondents.","Our findings demonstrate that the VR-based data collection system elicits realistic responses for capturing pedestrian data in safety-critical or uncommon vehicle-pedestrian interaction scenarios."],"url":"http://arxiv.org/abs/2310.05882v1"}
{"created":"2023-10-09 17:22:58","title":"Controllable Chest X-Ray Report Generation from Longitudinal Representations","abstract":"Radiology reports are detailed text descriptions of the content of medical scans. Each report describes the presence/absence and location of relevant clinical findings, commonly including comparison with prior exams of the same patient to describe how they evolved. Radiology reporting is a time-consuming process, and scan results are often subject to delays. One strategy to speed up reporting is to integrate automated reporting systems, however clinical deployment requires high accuracy and interpretability. Previous approaches to automated radiology reporting generally do not provide the prior study as input, precluding comparison which is required for clinical accuracy in some types of scans, and offer only unreliable methods of interpretability. Therefore, leveraging an existing visual input format of anatomical tokens, we introduce two novel aspects: (1) longitudinal representation learning -- we input the prior scan as an additional input, proposing a method to align, concatenate and fuse the current and prior visual information into a joint longitudinal representation which can be provided to the multimodal report generation model; (2) sentence-anatomy dropout -- a training strategy for controllability in which the report generator model is trained to predict only sentences from the original report which correspond to the subset of anatomical regions given as input. We show through in-depth experiments on the MIMIC-CXR dataset how the proposed approach achieves state-of-the-art results while enabling anatomy-wise controllable report generation.","sentences":["Radiology reports are detailed text descriptions of the content of medical scans.","Each report describes the presence/absence and location of relevant clinical findings, commonly including comparison with prior exams of the same patient to describe how they evolved.","Radiology reporting is a time-consuming process, and scan results are often subject to delays.","One strategy to speed up reporting is to integrate automated reporting systems, however clinical deployment requires high accuracy and interpretability.","Previous approaches to automated radiology reporting generally do not provide the prior study as input, precluding comparison which is required for clinical accuracy in some types of scans, and offer only unreliable methods of interpretability.","Therefore, leveraging an existing visual input format of anatomical tokens, we introduce two novel aspects: (1) longitudinal representation learning -- we input the prior scan as an additional input, proposing a method to align, concatenate and fuse the current and prior visual information into a joint longitudinal representation which can be provided to the multimodal report generation model; (2) sentence-anatomy dropout -- a training strategy for controllability in which the report generator model is trained to predict only sentences from the original report which correspond to the subset of anatomical regions given as input.","We show through in-depth experiments on the MIMIC-CXR dataset how the proposed approach achieves state-of-the-art results while enabling anatomy-wise controllable report generation."],"url":"http://arxiv.org/abs/2310.05881v1"}
{"created":"2023-10-09 17:19:49","title":"A Machine Learning Approach to Predicting Single Event Upsets","abstract":"A single event upset (SEU) is a critical soft error that occurs in semiconductor devices on exposure to ionising particles from space environments. SEUs cause bit flips in the memory component of semiconductors. This creates a multitude of safety hazards as stored information becomes less reliable. Currently, SEUs are only detected several hours after their occurrence. CREMER, the model presented in this paper, predicts SEUs in advance using machine learning. CREMER uses only positional data to predict SEU occurrence, making it robust, inexpensive and scalable. Upon implementation, the improved reliability of memory devices will create a digitally safer environment onboard space vehicles.","sentences":["A single event upset (SEU) is a critical soft error that occurs in semiconductor devices on exposure to ionising particles from space environments.","SEUs cause bit flips in the memory component of semiconductors.","This creates a multitude of safety hazards as stored information becomes less reliable.","Currently, SEUs are only detected several hours after their occurrence.","CREMER, the model presented in this paper, predicts SEUs in advance using machine learning.","CREMER uses only positional data to predict SEU occurrence, making it robust, inexpensive and scalable.","Upon implementation, the improved reliability of memory devices will create a digitally safer environment onboard space vehicles."],"url":"http://arxiv.org/abs/2310.05878v1"}
{"created":"2023-10-09 17:15:22","title":"AI Systems of Concern","abstract":"Concerns around future dangers from advanced AI often centre on systems hypothesised to have intrinsic characteristics such as agent-like behaviour, strategic awareness, and long-range planning. We label this cluster of characteristics as \"Property X\". Most present AI systems are low in \"Property X\"; however, in the absence of deliberate steering, current research directions may rapidly lead to the emergence of highly capable AI systems that are also high in \"Property X\". We argue that \"Property X\" characteristics are intrinsically dangerous, and when combined with greater capabilities will result in AI systems for which safety and control is difficult to guarantee. Drawing on several scholars' alternative frameworks for possible AI research trajectories, we argue that most of the proposed benefits of advanced AI can be obtained by systems designed to minimise this property. We then propose indicators and governance interventions to identify and limit the development of systems with risky \"Property X\" characteristics.","sentences":["Concerns around future dangers from advanced AI often centre on systems hypothesised to have intrinsic characteristics such as agent-like behaviour, strategic awareness, and long-range planning.","We label this cluster of characteristics as \"Property X\".","Most present AI systems are low in \"Property X\"; however, in the absence of deliberate steering, current research directions may rapidly lead to the emergence of highly capable AI systems that are also high in \"Property X\".","We argue that \"Property X\" characteristics are intrinsically dangerous, and when combined with greater capabilities will result in AI systems for which safety and control is difficult to guarantee.","Drawing on several scholars' alternative frameworks for possible AI research trajectories, we argue that most of the proposed benefits of advanced AI can be obtained by systems designed to minimise this property.","We then propose indicators and governance interventions to identify and limit the development of systems with risky \"Property X\" characteristics."],"url":"http://arxiv.org/abs/2310.05876v1"}
{"created":"2023-10-09 17:13:10","title":"Geom-Erasing: Geometry-Driven Removal of Implicit Concept in Diffusion Models","abstract":"Fine-tuning diffusion models through personalized datasets is an acknowledged method for improving generation quality across downstream tasks, which, however, often inadvertently generates unintended concepts such as watermarks and QR codes, attributed to the limitations in image sources and collecting methods within specific downstream tasks. Existing solutions suffer from eliminating these unintentionally learned implicit concepts, primarily due to the dependency on the model's ability to recognize concepts that it actually cannot discern. In this work, we introduce \\methodname, a novel approach that successfully removes the implicit concepts with either an additional accessible classifier or detector model to encode geometric information of these concepts into text domain. Moreover, we propose \\textit{Implicit Concept}, a novel image-text dataset imbued with three implicit concepts (\\ie, watermarks, QR codes, and text) for training and evaluation. Experimental results demonstrate that \\methodname not only identifies but also proficiently eradicates implicit concepts, revealing a significant improvement over the existing methods. The integration of geometric information marks a substantial progression in the precise removal of implicit concepts in diffusion models.","sentences":["Fine-tuning diffusion models through personalized datasets is an acknowledged method for improving generation quality across downstream tasks, which, however, often inadvertently generates unintended concepts such as watermarks and QR codes, attributed to the limitations in image sources and collecting methods within specific downstream tasks.","Existing solutions suffer from eliminating these unintentionally learned implicit concepts, primarily due to the dependency on the model's ability to recognize concepts that it actually cannot discern.","In this work, we introduce \\methodname, a novel approach that successfully removes the implicit concepts with either an additional accessible classifier or detector model to encode geometric information of these concepts into text domain.","Moreover, we propose \\textit{Implicit Concept}, a novel image-text dataset imbued with three implicit concepts (\\ie, watermarks, QR codes, and text) for training and evaluation.","Experimental results demonstrate that \\methodname not only identifies but also proficiently eradicates implicit concepts, revealing a significant improvement over the existing methods.","The integration of geometric information marks a substantial progression in the precise removal of implicit concepts in diffusion models."],"url":"http://arxiv.org/abs/2310.05873v1"}
{"created":"2023-10-09 17:10:35","title":"ViCor: Bridging Visual Understanding and Commonsense Reasoning with Large Language Models","abstract":"In our work, we explore the synergistic capabilities of pre-trained vision-and-language models (VLMs) and large language models (LLMs) for visual commonsense reasoning (VCR). We categorize the problem of VCR into visual commonsense understanding (VCU) and visual commonsense inference (VCI). For VCU, which involves perceiving the literal visual content, pre-trained VLMs exhibit strong cross-dataset generalization. On the other hand, in VCI, where the goal is to infer conclusions beyond image content, VLMs face difficulties. We find that a baseline where VLMs provide perception results (image captions) to LLMs leads to improved performance on VCI. However, we identify a challenge with VLMs' passive perception, which often misses crucial context information, leading to incorrect or uncertain reasoning by LLMs. To mitigate this issue, we suggest a collaborative approach where LLMs, when uncertain about their reasoning, actively direct VLMs to concentrate on and gather relevant visual elements to support potential commonsense inferences. In our method, named ViCor, pre-trained LLMs serve as problem classifiers to analyze the problem category, VLM commanders to leverage VLMs differently based on the problem classification, and visual commonsense reasoners to answer the question. VLMs will perform visual recognition and understanding. We evaluate our framework on two VCR benchmark datasets and outperform all other methods that do not require in-domain supervised fine-tuning.","sentences":["In our work, we explore the synergistic capabilities of pre-trained vision-and-language models (VLMs) and large language models (LLMs) for visual commonsense reasoning (VCR).","We categorize the problem of VCR into visual commonsense understanding (VCU) and visual commonsense inference (VCI).","For VCU, which involves perceiving the literal visual content, pre-trained VLMs exhibit strong cross-dataset generalization.","On the other hand, in VCI, where the goal is to infer conclusions beyond image content, VLMs face difficulties.","We find that a baseline where VLMs provide perception results (image captions) to LLMs leads to improved performance on VCI.","However, we identify a challenge with VLMs' passive perception, which often misses crucial context information, leading to incorrect or uncertain reasoning by LLMs.","To mitigate this issue, we suggest a collaborative approach where LLMs, when uncertain about their reasoning, actively direct VLMs to concentrate on and gather relevant visual elements to support potential commonsense inferences.","In our method, named ViCor, pre-trained LLMs serve as problem classifiers to analyze the problem category, VLM commanders to leverage VLMs differently based on the problem classification, and visual commonsense reasoners to answer the question.","VLMs will perform visual recognition and understanding.","We evaluate our framework on two VCR benchmark datasets and outperform all other methods that do not require in-domain supervised fine-tuning."],"url":"http://arxiv.org/abs/2310.05872v1"}
{"created":"2023-10-09 17:07:26","title":"Dynamic value alignment through preference aggregation of multiple objectives","abstract":"The development of ethical AI systems is currently geared toward setting objective functions that align with human objectives. However, finding such functions remains a research challenge, while in RL, setting rewards by hand is a fairly standard approach. We present a methodology for dynamic value alignment, where the values that are to be aligned with are dynamically changing, using a multiple-objective approach. We apply this approach to extend Deep $Q$-Learning to accommodate multiple objectives and evaluate this method on a simplified two-leg intersection controlled by a switching agent.Our approach dynamically accommodates the preferences of drivers on the system and achieves better overall performance across three metrics (speeds, stops, and waits) while integrating objectives that have competing or conflicting actions.","sentences":["The development of ethical AI systems is currently geared toward setting objective functions that align with human objectives.","However, finding such functions remains a research challenge, while in RL, setting rewards by hand is a fairly standard approach.","We present a methodology for dynamic value alignment, where the values that are to be aligned with are dynamically changing, using a multiple-objective approach.","We apply this approach to extend Deep $Q$-Learning to accommodate multiple objectives and evaluate this method on a simplified two-leg intersection controlled by a switching agent.","Our approach dynamically accommodates the preferences of drivers on the system and achieves better overall performance across three metrics (speeds, stops, and waits) while integrating objectives that have competing or conflicting actions."],"url":"http://arxiv.org/abs/2310.05871v1"}
{"created":"2023-10-09 17:05:25","title":"HyperAttention: Long-context Attention in Near-Linear Time","abstract":"We present an approximate attention mechanism named HyperAttention to address the computational challenges posed by the growing complexity of long contexts used in Large Language Models (LLMs). Recent work suggests that in the worst-case scenario, quadratic time is necessary unless the entries of the attention matrix are bounded or the matrix has low stable rank. We introduce two parameters which measure: (1) the max column norm in the normalized attention matrix, and (2) the ratio of row norms in the unnormalized attention matrix after detecting and removing large entries. We use these fine-grained parameters to capture the hardness of the problem. Despite previous lower bounds, we are able to achieve a linear time sampling algorithm even when the matrix has unbounded entries or a large stable rank, provided the above parameters are small. HyperAttention features a modular design that easily accommodates integration of other fast low-level implementations, particularly FlashAttention. Empirically, employing Locality Sensitive Hashing (LSH) to identify large entries, HyperAttention outperforms existing methods, giving significant speed improvements compared to state-of-the-art solutions like FlashAttention. We validate the empirical performance of HyperAttention on a variety of different long-context length datasets. For example, HyperAttention makes the inference time of ChatGLM2 50\\% faster on 32k context length while perplexity increases from 5.6 to 6.3. On larger context length, e.g., 131k, with causal masking, HyperAttention offers 5-fold speedup on a single attention layer.","sentences":["We present an approximate attention mechanism named HyperAttention to address the computational challenges posed by the growing complexity of long contexts used in Large Language Models (LLMs).","Recent work suggests that in the worst-case scenario, quadratic time is necessary unless the entries of the attention matrix are bounded or the matrix has low stable rank.","We introduce two parameters which measure: (1) the max column norm in the normalized attention matrix, and (2) the ratio of row norms in the unnormalized attention matrix after detecting and removing large entries.","We use these fine-grained parameters to capture the hardness of the problem.","Despite previous lower bounds, we are able to achieve a linear time sampling algorithm even when the matrix has unbounded entries or a large stable rank, provided the above parameters are small.","HyperAttention features a modular design that easily accommodates integration of other fast low-level implementations, particularly FlashAttention.","Empirically, employing Locality Sensitive Hashing (LSH) to identify large entries, HyperAttention outperforms existing methods, giving significant speed improvements compared to state-of-the-art solutions like FlashAttention.","We validate the empirical performance of HyperAttention on a variety of different long-context length datasets.","For example, HyperAttention makes the inference time of ChatGLM2 50\\% faster on 32k context length while perplexity increases from 5.6 to 6.3.","On larger context length, e.g., 131k, with causal masking, HyperAttention offers 5-fold speedup on a single attention layer."],"url":"http://arxiv.org/abs/2310.05869v1"}
{"created":"2023-10-09 17:05:23","title":"Bio-inspired computational memory model of the Hippocampus: an approach to a neuromorphic spike-based Content-Addressable Memory","abstract":"The brain has computational capabilities that surpass those of modern systems, being able to solve complex problems efficiently in a simple way. Neuromorphic engineering aims to mimic biology in order to develop new systems capable of incorporating such capabilities. Bio-inspired learning systems continue to be a challenge that must be solved, and much work needs to be done in this regard. Among all brain regions, the hippocampus stands out as an autoassociative short-term memory with the capacity to learn and recall memories from any fragment of them. These characteristics make the hippocampus an ideal candidate for developing bio-inspired learning systems that, in addition, resemble content-addressable memories. Therefore, in this work we propose a bio-inspired spiking content-addressable memory model based on the CA3 region of the hippocampus with the ability to learn, forget and recall memories, both orthogonal and non-orthogonal, from any fragment of them. The model was implemented on the SpiNNaker hardware platform using Spiking Neural Networks. A set of experiments based on functional, stress and applicability tests were performed to demonstrate its correct functioning. This work presents the first hardware implementation of a fully-functional bio-inspired spiking hippocampal content-addressable memory model, paving the way for the development of future more complex neuromorphic systems.","sentences":["The brain has computational capabilities that surpass those of modern systems, being able to solve complex problems efficiently in a simple way.","Neuromorphic engineering aims to mimic biology in order to develop new systems capable of incorporating such capabilities.","Bio-inspired learning systems continue to be a challenge that must be solved, and much work needs to be done in this regard.","Among all brain regions, the hippocampus stands out as an autoassociative short-term memory with the capacity to learn and recall memories from any fragment of them.","These characteristics make the hippocampus an ideal candidate for developing bio-inspired learning systems that, in addition, resemble content-addressable memories.","Therefore, in this work we propose a bio-inspired spiking content-addressable memory model based on the CA3 region of the hippocampus with the ability to learn, forget and recall memories, both orthogonal and non-orthogonal, from any fragment of them.","The model was implemented on the SpiNNaker hardware platform using Spiking Neural Networks.","A set of experiments based on functional, stress and applicability tests were performed to demonstrate its correct functioning.","This work presents the first hardware implementation of a fully-functional bio-inspired spiking hippocampal content-addressable memory model, paving the way for the development of future more complex neuromorphic systems."],"url":"http://arxiv.org/abs/2310.05868v1"}
{"created":"2023-10-09 17:03:39","title":"Domain-wise Invariant Learning for Panoptic Scene Graph Generation","abstract":"Panoptic Scene Graph Generation (PSG) involves the detection of objects and the prediction of their corresponding relationships (predicates). However, the presence of biased predicate annotations poses a significant challenge for PSG models, as it hinders their ability to establish a clear decision boundary among different predicates. This issue substantially impedes the practical utility and real-world applicability of PSG models. To address the intrinsic bias above, we propose a novel framework to infer potentially biased annotations by measuring the predicate prediction risks within each subject-object pair (domain), and adaptively transfer the biased annotations to consistent ones by learning invariant predicate representation embeddings. Experiments show that our method significantly improves the performance of benchmark models, achieving a new state-of-the-art performance, and shows great generalization and effectiveness on PSG dataset.","sentences":["Panoptic Scene Graph Generation (PSG) involves the detection of objects and the prediction of their corresponding relationships (predicates).","However, the presence of biased predicate annotations poses a significant challenge for PSG models, as it hinders their ability to establish a clear decision boundary among different predicates.","This issue substantially impedes the practical utility and real-world applicability of PSG models.","To address the intrinsic bias above, we propose a novel framework to infer potentially biased annotations by measuring the predicate prediction risks within each subject-object pair (domain), and adaptively transfer the biased annotations to consistent ones by learning invariant predicate representation embeddings.","Experiments show that our method significantly improves the performance of benchmark models, achieving a new state-of-the-art performance, and shows great generalization and effectiveness on PSG dataset."],"url":"http://arxiv.org/abs/2310.05867v1"}
{"created":"2023-10-09 17:02:50","title":"A Learning-Based Framework for Safe Human-Robot Collaboration with Multiple Backup Control Barrier Functions","abstract":"Ensuring robot safety in complex environments is a difficult task due to actuation limits, such as torque bounds. This paper presents a safety-critical control framework that leverages learning-based switching between multiple backup controllers to formally guarantee safety under bounded control inputs while satisfying driver intention. By leveraging backup controllers designed to uphold safety and input constraints, backup control barrier functions (BCBFs) construct implicitly defined control invariance sets via a feasible quadratic program (QP). However, BCBF performance largely depends on the design and conservativeness of the chosen backup controller, especially in our setting of human-driven vehicles in complex, e.g, off-road, conditions. While conservativeness can be reduced by using multiple backup controllers, determining when to switch is an open problem. Consequently, we develop a broadcast scheme that estimates driver intention and integrates BCBFs with multiple backup strategies for human-robot interaction. An LSTM classifier uses data inputs from the robot, human, and safety algorithms to continually choose a backup controller in real-time. We demonstrate our method's efficacy on a dual-track robot in obstacle avoidance scenarios. Our framework guarantees robot safety while adhering to driver intention.","sentences":["Ensuring robot safety in complex environments is a difficult task due to actuation limits, such as torque bounds.","This paper presents a safety-critical control framework that leverages learning-based switching between multiple backup controllers to formally guarantee safety under bounded control inputs while satisfying driver intention.","By leveraging backup controllers designed to uphold safety and input constraints, backup control barrier functions (BCBFs) construct implicitly defined control invariance sets via a feasible quadratic program (QP).","However, BCBF performance largely depends on the design and conservativeness of the chosen backup controller, especially in our setting of human-driven vehicles in complex, e.g, off-road, conditions.","While conservativeness can be reduced by using multiple backup controllers, determining when to switch is an open problem.","Consequently, we develop a broadcast scheme that estimates driver intention and integrates BCBFs with multiple backup strategies for human-robot interaction.","An LSTM classifier uses data inputs from the robot, human, and safety algorithms to continually choose a backup controller in real-time.","We demonstrate our method's efficacy on a dual-track robot in obstacle avoidance scenarios.","Our framework guarantees robot safety while adhering to driver intention."],"url":"http://arxiv.org/abs/2310.05865v1"}
{"created":"2023-10-09 16:57:57","title":"Rephrase, Augment, Reason: Visual Grounding of Questions for Vision-Language Models","abstract":"An increasing number of vision-language tasks can be handled with little to no training, i.e., in a zero and few-shot manner, by marrying large language models (LLMs) to vision encoders, resulting in large vision-language models (LVLMs). While this has huge upsides, such as not requiring training data or custom architectures, how an input is presented to a LVLM can have a major impact on zero-shot model performance. In particular, inputs phrased in an underspecified way can result in incorrect answers due to factors like missing visual information, complex implicit reasoning, or linguistic ambiguity. Therefore, adding visually grounded information to the input as a preemptive clarification should improve model performance by reducing underspecification, e.g., by localizing objects and disambiguating references. Similarly, in the VQA setting, changing the way questions are framed can make them easier for models to answer. To this end, we present Rephrase, Augment and Reason (RepARe), a gradient-free framework that extracts salient details about the image using the underlying LVLM as a captioner and reasoner, in order to propose modifications to the original question. We then use the LVLM's confidence over a generated answer as an unsupervised scoring function to select the rephrased question most likely to improve zero-shot performance. Focusing on two visual question answering tasks, we show that RepARe can result in a 3.85% (absolute) increase in zero-shot performance on VQAv2 and a 6.41% point increase on A-OKVQA. Additionally, we find that using gold answers for oracle question candidate selection achieves a substantial gain in VQA accuracy by up to 14.41%. Through extensive analysis, we demonstrate that outputs from RepARe increase syntactic complexity, and effectively utilize vision-language interaction and the frozen language model in LVLMs.","sentences":["An increasing number of vision-language tasks can be handled with little to no training, i.e., in a zero and few-shot manner, by marrying large language models (LLMs) to vision encoders, resulting in large vision-language models (LVLMs).","While this has huge upsides, such as not requiring training data or custom architectures, how an input is presented to a LVLM can have a major impact on zero-shot model performance.","In particular, inputs phrased in an underspecified way can result in incorrect answers due to factors like missing visual information, complex implicit reasoning, or linguistic ambiguity.","Therefore, adding visually grounded information to the input as a preemptive clarification should improve model performance by reducing underspecification, e.g., by localizing objects and disambiguating references.","Similarly, in the VQA setting, changing the way questions are framed can make them easier for models to answer.","To this end, we present Rephrase, Augment and Reason (RepARe), a gradient-free framework that extracts salient details about the image using the underlying LVLM as a captioner and reasoner, in order to propose modifications to the original question.","We then use the LVLM's confidence over a generated answer as an unsupervised scoring function to select the rephrased question most likely to improve zero-shot performance.","Focusing on two visual question answering tasks, we show that RepARe can result in a 3.85% (absolute) increase in zero-shot performance on VQAv2 and a 6.41% point increase on A-OKVQA.","Additionally, we find that using gold answers for oracle question candidate selection achieves a substantial gain in VQA accuracy by up to 14.41%.","Through extensive analysis, we demonstrate that outputs from RepARe increase syntactic complexity, and effectively utilize vision-language interaction and the frozen language model in LVLMs."],"url":"http://arxiv.org/abs/2310.05861v1"}
{"created":"2023-10-09 16:52:48","title":"DSAC-T: Distributional Soft Actor-Critic with Three Refinements","abstract":"Reinforcement learning (RL) has proven to be highly effective in tackling complex decision-making and control tasks. However, prevalent model-free RL methods often face severe performance degradation due to the well-known overestimation issue. In response to this problem, we recently introduced an off-policy RL algorithm, called distributional soft actor-critic (DSAC or DSAC-v1), which can effectively improve the value estimation accuracy by learning a continuous Gaussian value distribution. Nonetheless, standard DSAC has its own shortcomings, including occasionally unstable learning processes and needs for task-specific reward scaling, which may hinder its overall performance and adaptability in some special tasks. This paper further introduces three important refinements to standard DSAC in order to address these shortcomings. These refinements consist of critic gradient adjusting, twin value distribution learning, and variance-based target return clipping. The modified RL algorithm is named as DSAC with three refinements (DSAC-T or DSAC-v2), and its performances are systematically evaluated on a diverse set of benchmark tasks. Without any task-specific hyperparameter tuning, DSAC-T surpasses a lot of mainstream model-free RL algorithms, including SAC, TD3, DDPG, TRPO, and PPO, in all tested environments. Additionally, DSAC-T, unlike its standard version, ensures a highly stable learning process and delivers similar performance across varying reward scales.","sentences":["Reinforcement learning (RL) has proven to be highly effective in tackling complex decision-making and control tasks.","However, prevalent model-free RL methods often face severe performance degradation due to the well-known overestimation issue.","In response to this problem, we recently introduced an off-policy RL algorithm, called distributional soft actor-critic (DSAC or DSAC-v1), which can effectively improve the value estimation accuracy by learning a continuous Gaussian value distribution.","Nonetheless, standard DSAC has its own shortcomings, including occasionally unstable learning processes and needs for task-specific reward scaling, which may hinder its overall performance and adaptability in some special tasks.","This paper further introduces three important refinements to standard DSAC in order to address these shortcomings.","These refinements consist of critic gradient adjusting, twin value distribution learning, and variance-based target return clipping.","The modified RL algorithm is named as DSAC with three refinements (DSAC-T or DSAC-v2), and its performances are systematically evaluated on a diverse set of benchmark tasks.","Without any task-specific hyperparameter tuning, DSAC-T surpasses a lot of mainstream model-free RL algorithms, including SAC, TD3, DDPG, TRPO, and PPO, in all tested environments.","Additionally, DSAC-T, unlike its standard version, ensures a highly stable learning process and delivers similar performance across varying reward scales."],"url":"http://arxiv.org/abs/2310.05858v1"}
{"created":"2023-10-09 16:52:07","title":"Improving Summarization with Human Edits","abstract":"Recent work has shown the promise of learning with human feedback paradigms to produce human-determined high-quality text. Existing works use human feedback to train large language models (LLMs) in general domain abstractive summarization and have obtained summary quality exceeding traditional likelihood training. In this paper, we focus on a less explored form of human feedback -- Human Edits. We propose Sequence Alignment (un)Likelihood Training (SALT), a novel technique to use both the human-edited and model-generated data together in the training loop. In addition, we demonstrate simulating Human Edits with ground truth summaries coming from existing training data -- Imitation edits, along with the model-generated summaries obtained after the training, to reduce the need for expensive human-edit data. In our experiments, we extend human feedback exploration from general domain summarization to medical domain summarization. Our results demonstrate the effectiveness of SALT to improve the summary quality with Human and Imitation Edits.","sentences":["Recent work has shown the promise of learning with human feedback paradigms to produce human-determined high-quality text.","Existing works use human feedback to train large language models (LLMs) in general domain abstractive summarization and have obtained summary quality exceeding traditional likelihood training.","In this paper, we focus on a less explored form of human feedback -- Human Edits.","We propose Sequence Alignment (un)Likelihood Training (SALT), a novel technique to use both the human-edited and model-generated data together in the training loop.","In addition, we demonstrate simulating Human Edits with ground truth summaries coming from existing training data -- Imitation edits, along with the model-generated summaries obtained after the training, to reduce the need for expensive human-edit data.","In our experiments, we extend human feedback exploration from general domain summarization to medical domain summarization.","Our results demonstrate the effectiveness of SALT to improve the summary quality with Human and Imitation Edits."],"url":"http://arxiv.org/abs/2310.05857v1"}
{"created":"2023-10-09 16:49:59","title":"\"Mango Mango, How to Let The Lettuce Dry Without A Spinner?'': Exploring User Perceptions of Using An LLM-Based Conversational Assistant Toward Cooking Partner","abstract":"The rapid advancement of the Large Language Model (LLM) has created numerous potentials for integration with conversational assistants (CAs) assisting people in their daily tasks, particularly due to their extensive flexibility. However, users' real-world experiences interacting with these assistants remain unexplored. In this research, we chose cooking, a complex daily task, as a scenario to investigate people's successful and unsatisfactory experiences while receiving assistance from an LLM-based CA, Mango Mango. We discovered that participants value the system's ability to provide extensive information beyond the recipe, offer customized instructions based on context, and assist them in dynamically planning the task. However, they expect the system to be more adaptive to oral conversation and provide more suggestive responses to keep users actively involved. Recognizing that users began treating our LLM-CA as a personal assistant or even a partner rather than just a recipe-reading tool, we propose several design considerations for future development.","sentences":["The rapid advancement of the Large Language Model (LLM) has created numerous potentials for integration with conversational assistants (CAs) assisting people in their daily tasks, particularly due to their extensive flexibility.","However, users' real-world experiences interacting with these assistants remain unexplored.","In this research, we chose cooking, a complex daily task, as a scenario to investigate people's successful and unsatisfactory experiences while receiving assistance from an LLM-based CA, Mango Mango.","We discovered that participants value the system's ability to provide extensive information beyond the recipe, offer customized instructions based on context, and assist them in dynamically planning the task.","However, they expect the system to be more adaptive to oral conversation and provide more suggestive responses to keep users actively involved.","Recognizing that users began treating our LLM-CA as a personal assistant or even a partner rather than just a recipe-reading tool, we propose several design considerations for future development."],"url":"http://arxiv.org/abs/2310.05853v1"}
{"created":"2023-10-09 16:42:00","title":"GraphLLM: Boosting Graph Reasoning Ability of Large Language Model","abstract":"The advancement of Large Language Models (LLMs) has remarkably pushed the boundaries towards artificial general intelligence (AGI), with their exceptional ability on understanding diverse types of information, including but not limited to images and audio. Despite this progress, a critical gap remains in empowering LLMs to proficiently understand and reason on graph data. Recent studies underscore LLMs' underwhelming performance on fundamental graph reasoning tasks. In this paper, we endeavor to unearth the obstacles that impede LLMs in graph reasoning, pinpointing the common practice of converting graphs into natural language descriptions (Graph2Text) as a fundamental bottleneck. To overcome this impediment, we introduce GraphLLM, a pioneering end-to-end approach that synergistically integrates graph learning models with LLMs. This synergy equips LLMs with the ability to proficiently interpret and reason on graph data, harnessing the superior expressive power of graph learning models. Our empirical evaluations across four fundamental graph reasoning tasks validate the effectiveness of GraphLLM. The results exhibit a substantial average accuracy enhancement of 54.44%, alongside a noteworthy context reduction of 96.45% across various graph reasoning tasks.","sentences":["The advancement of Large Language Models (LLMs) has remarkably pushed the boundaries towards artificial general intelligence (AGI), with their exceptional ability on understanding diverse types of information, including but not limited to images and audio.","Despite this progress, a critical gap remains in empowering LLMs to proficiently understand and reason on graph data.","Recent studies underscore LLMs' underwhelming performance on fundamental graph reasoning tasks.","In this paper, we endeavor to unearth the obstacles that impede LLMs in graph reasoning, pinpointing the common practice of converting graphs into natural language descriptions (Graph2Text) as a fundamental bottleneck.","To overcome this impediment, we introduce GraphLLM, a pioneering end-to-end approach that synergistically integrates graph learning models with LLMs.","This synergy equips LLMs with the ability to proficiently interpret and reason on graph data, harnessing the superior expressive power of graph learning models.","Our empirical evaluations across four fundamental graph reasoning tasks validate the effectiveness of GraphLLM.","The results exhibit a substantial average accuracy enhancement of 54.44%, alongside a noteworthy context reduction of 96.45% across various graph reasoning tasks."],"url":"http://arxiv.org/abs/2310.05845v1"}
{"created":"2023-10-09 16:37:19","title":"Robust Angular Synchronization via Directed Graph Neural Networks","abstract":"The angular synchronization problem aims to accurately estimate (up to a constant additive phase) a set of unknown angles $\\theta_1, \\dots, \\theta_n\\in[0, 2\\pi)$ from $m$ noisy measurements of their offsets $\\theta_i-\\theta_j \\;\\mbox{mod} \\; 2\\pi.$ Applications include, for example, sensor network localization, phase retrieval, and distributed clock synchronization. An extension of the problem to the heterogeneous setting (dubbed $k$-synchronization) is to estimate $k$ groups of angles simultaneously, given noisy observations (with unknown group assignment) from each group. Existing methods for angular synchronization usually perform poorly in high-noise regimes, which are common in applications. In this paper, we leverage neural networks for the angular synchronization problem, and its heterogeneous extension, by proposing GNNSync, a theoretically-grounded end-to-end trainable framework using directed graph neural networks. In addition, new loss functions are devised to encode synchronization objectives. Experimental results on extensive data sets demonstrate that GNNSync attains competitive, and often superior, performance against a comprehensive set of baselines for the angular synchronization problem and its extension, validating the robustness of GNNSync even at high noise levels.","sentences":["The angular synchronization problem aims to accurately estimate (up to a constant additive phase) a set of unknown angles $\\theta_1, \\dots, \\theta_n\\in[0, 2\\pi)$ from $m$ noisy measurements of their offsets $\\theta_i-\\theta_j \\;\\mbox{mod} \\; 2\\pi.$ Applications include, for example, sensor network localization, phase retrieval, and distributed clock synchronization.","An extension of the problem to the heterogeneous setting (dubbed $k$-synchronization) is to estimate $k$ groups of angles simultaneously, given noisy observations (with unknown group assignment) from each group.","Existing methods for angular synchronization usually perform poorly in high-noise regimes, which are common in applications.","In this paper, we leverage neural networks for the angular synchronization problem, and its heterogeneous extension, by proposing GNNSync, a theoretically-grounded end-to-end trainable framework using directed graph neural networks.","In addition, new loss functions are devised to encode synchronization objectives.","Experimental results on extensive data sets demonstrate that GNNSync attains competitive, and often superior, performance against a comprehensive set of baselines for the angular synchronization problem and its extension, validating the robustness of GNNSync even at high noise levels."],"url":"http://arxiv.org/abs/2310.05842v1"}
{"created":"2023-10-09 16:33:44","title":"Predicting Accident Severity: An Analysis Of Factors Affecting Accident Severity Using Random Forest Model","abstract":"Road accidents have significant economic and societal costs, with a small number of severe accidents accounting for a large portion of these costs. Predicting accident severity can help in the proactive approach to road safety by identifying potential unsafe road conditions and taking well-informed actions to reduce the number of severe accidents. This study investigates the effectiveness of the Random Forest machine learning algorithm for predicting the severity of an accident. The model is trained on a dataset of accident records from a large metropolitan area and evaluated using various metrics. Hyperparameters and feature selection are optimized to improve the model's performance. The results show that the Random Forest model is an effective tool for predicting accident severity with an accuracy of over 80%. The study also identifies the top six most important variables in the model, which include wind speed, pressure, humidity, visibility, clear conditions, and cloud cover. The fitted model has an Area Under the Curve of 80%, a recall of 79.2%, a precision of 97.1%, and an F1 score of 87.3%. These results suggest that the proposed model has higher performance in explaining the target variable, which is the accident severity class. Overall, the study provides evidence that the Random Forest model is a viable and reliable tool for predicting accident severity and can be used to help reduce the number of fatalities and injuries due to road accidents in the United States","sentences":["Road accidents have significant economic and societal costs, with a small number of severe accidents accounting for a large portion of these costs.","Predicting accident severity can help in the proactive approach to road safety by identifying potential unsafe road conditions and taking well-informed actions to reduce the number of severe accidents.","This study investigates the effectiveness of the Random Forest machine learning algorithm for predicting the severity of an accident.","The model is trained on a dataset of accident records from a large metropolitan area and evaluated using various metrics.","Hyperparameters and feature selection are optimized to improve the model's performance.","The results show that the Random Forest model is an effective tool for predicting accident severity with an accuracy of over 80%.","The study also identifies the top six most important variables in the model, which include wind speed, pressure, humidity, visibility, clear conditions, and cloud cover.","The fitted model has an Area Under the Curve of 80%, a recall of 79.2%, a precision of 97.1%, and an F1 score of 87.3%.","These results suggest that the proposed model has higher performance in explaining the target variable, which is the accident severity class.","Overall, the study provides evidence that the Random Forest model is a viable and reliable tool for predicting accident severity and can be used to help reduce the number of fatalities and injuries due to road accidents in the United States"],"url":"http://arxiv.org/abs/2310.05840v1"}
{"created":"2023-10-09 16:30:23","title":"Directed Symmetric Multicut is W[1]-hard","abstract":"Given a directed graph $G$ and a set of vertex pairs $\\{(s_1,t_1), \\dots, (s_m, t_m)\\}$, the Directed Symmetric Multicut problem asks to delete the minimum number of edges from $G$ to separate every pair $(s_i, t_i)$ into distinct strong components. Eiben, Rambaud and Wahlstr\\\"om [IPEC 2022] initiated the study of this problem parameterized by the solution size. They gave a fixed-parameter tractable 2-approximation algorithm, and left the exact parameterized complexity status as an open question. We answer their question in negative, showing that Directed Symmetric Multicut is W[1]-hard.","sentences":["Given a directed graph $G$ and a set of vertex pairs $\\{(s_1,t_1), \\dots, (s_m, t_m)\\}$, the Directed Symmetric Multicut problem asks to delete the minimum number of edges from $G$ to separate every pair $(s_i, t_i)$ into distinct strong components.","Eiben, Rambaud and Wahlstr\\\"om [IPEC 2022] initiated the study of this problem parameterized by the solution size.","They gave a fixed-parameter tractable 2-approximation algorithm, and left the exact parameterized complexity status as an open question.","We answer their question in negative, showing that Directed Symmetric Multicut is W[1]-hard."],"url":"http://arxiv.org/abs/2310.05839v1"}
{"created":"2023-10-09 16:26:34","title":"A Real-time Method for Inserting Virtual Objects into Neural Radiance Fields","abstract":"We present the first real-time method for inserting a rigid virtual object into a neural radiance field, which produces realistic lighting and shadowing effects, as well as allows interactive manipulation of the object. By exploiting the rich information about lighting and geometry in a NeRF, our method overcomes several challenges of object insertion in augmented reality. For lighting estimation, we produce accurate, robust and 3D spatially-varying incident lighting that combines the near-field lighting from NeRF and an environment lighting to account for sources not covered by the NeRF. For occlusion, we blend the rendered virtual object with the background scene using an opacity map integrated from the NeRF. For shadows, with a precomputed field of spherical signed distance field, we query the visibility term for any point around the virtual object, and cast soft, detailed shadows onto 3D surfaces. Compared with state-of-the-art techniques, our approach can insert virtual object into scenes with superior fidelity, and has a great potential to be further applied to augmented reality systems.","sentences":["We present the first real-time method for inserting a rigid virtual object into a neural radiance field, which produces realistic lighting and shadowing effects, as well as allows interactive manipulation of the object.","By exploiting the rich information about lighting and geometry in a NeRF, our method overcomes several challenges of object insertion in augmented reality.","For lighting estimation, we produce accurate, robust and 3D spatially-varying incident lighting that combines the near-field lighting from NeRF and an environment lighting to account for sources not covered by the NeRF.","For occlusion, we blend the rendered virtual object with the background scene using an opacity map integrated from the NeRF.","For shadows, with a precomputed field of spherical signed distance field, we query the visibility term for any point around the virtual object, and cast soft, detailed shadows onto 3D surfaces.","Compared with state-of-the-art techniques, our approach can insert virtual object into scenes with superior fidelity, and has a great potential to be further applied to augmented reality systems."],"url":"http://arxiv.org/abs/2310.05837v1"}
{"created":"2023-10-09 16:25:36","title":"Latent Wander: an Alternative Interface for Interactive and Serendipitous Discovery of Large AV Archives","abstract":"Audiovisual (AV) archives are invaluable for holistically preserving the past. Unlike other forms, AV archives can be difficult to explore. This is not only because of its complex modality and sheer volume but also the lack of appropriate interfaces beyond keyword search. The recent rise in text-to-video retrieval tasks in computer science opens the gate to accessing AV content more naturally and semantically, able to map natural language descriptive sentences to matching videos. However, applications of this model are rarely seen. The contribution of this work is threefold. First, working with RTS (T\\'el\\'evision Suisse Romande), we identified the key blockers in a real archive for implementing such models. We built a functioning pipeline for encoding raw archive videos to the text-to-video feature vectors. Second, we designed and verified a method to encode and retrieve videos using emotionally abundant descriptions not supported in the original model. Third, we proposed an initial prototype for immersive and interactive exploration of AV archives in a latent space based on the previously mentioned encoding of videos.","sentences":["Audiovisual (AV) archives are invaluable for holistically preserving the past.","Unlike other forms, AV archives can be difficult to explore.","This is not only because of its complex modality and sheer volume but also the lack of appropriate interfaces beyond keyword search.","The recent rise in text-to-video retrieval tasks in computer science opens the gate to accessing AV content more naturally and semantically, able to map natural language descriptive sentences to matching videos.","However, applications of this model are rarely seen.","The contribution of this work is threefold.","First, working with RTS (T\\'el\\'evision Suisse Romande), we identified the key blockers in a real archive for implementing such models.","We built a functioning pipeline for encoding raw archive videos to the text-to-video feature vectors.","Second, we designed and verified a method to encode and retrieve videos using emotionally abundant descriptions not supported in the original model.","Third, we proposed an initial prototype for immersive and interactive exploration of AV archives in a latent space based on the previously mentioned encoding of videos."],"url":"http://arxiv.org/abs/2310.05835v1"}
{"created":"2023-10-09 16:22:11","title":"A Bias-Variance-Covariance Decomposition of Kernel Scores for Generative Models","abstract":"Generative models, like large language models, are becoming increasingly relevant in our daily lives, yet a theoretical framework to assess their generalization behavior and uncertainty does not exist. Particularly, the problem of uncertainty estimation is commonly solved in an ad-hoc manner and task dependent. For example, natural language approaches cannot be transferred to image generation. In this paper we introduce the first bias-variance-covariance decomposition for kernel scores and their associated entropy. We propose unbiased and consistent estimators for each quantity which only require generated samples but not the underlying model itself. As an application, we offer a generalization evaluation of diffusion models and discover how mode collapse of minority groups is a contrary phenomenon to overfitting. Further, we demonstrate that variance and predictive kernel entropy are viable measures of uncertainty for image, audio, and language generation. Specifically, our approach for uncertainty estimation is more predictive of performance on CoQA and TriviaQA question answering datasets than existing baselines and can also be applied to closed-source models.","sentences":["Generative models, like large language models, are becoming increasingly relevant in our daily lives, yet a theoretical framework to assess their generalization behavior and uncertainty does not exist.","Particularly, the problem of uncertainty estimation is commonly solved in an ad-hoc manner and task dependent.","For example, natural language approaches cannot be transferred to image generation.","In this paper we introduce the first bias-variance-covariance decomposition for kernel scores and their associated entropy.","We propose unbiased and consistent estimators for each quantity which only require generated samples but not the underlying model itself.","As an application, we offer a generalization evaluation of diffusion models and discover how mode collapse of minority groups is a contrary phenomenon to overfitting.","Further, we demonstrate that variance and predictive kernel entropy are viable measures of uncertainty for image, audio, and language generation.","Specifically, our approach for uncertainty estimation is more predictive of performance on CoQA and TriviaQA question answering datasets than existing baselines and can also be applied to closed-source models."],"url":"http://arxiv.org/abs/2310.05833v1"}
{"created":"2023-10-09 16:17:42","title":"Revisiting the Temporal Modeling in Spatio-Temporal Predictive Learning under A Unified View","abstract":"Spatio-temporal predictive learning plays a crucial role in self-supervised learning, with wide-ranging applications across a diverse range of fields. Previous approaches for temporal modeling fall into two categories: recurrent-based and recurrent-free methods. The former, while meticulously processing frames one by one, neglect short-term spatio-temporal information redundancies, leading to inefficiencies. The latter naively stack frames sequentially, overlooking the inherent temporal dependencies. In this paper, we re-examine the two dominant temporal modeling approaches within the realm of spatio-temporal predictive learning, offering a unified perspective. Building upon this analysis, we introduce USTEP (Unified Spatio-TEmporal Predictive learning), an innovative framework that reconciles the recurrent-based and recurrent-free methods by integrating both micro-temporal and macro-temporal scales. Extensive experiments on a wide range of spatio-temporal predictive learning demonstrate that USTEP achieves significant improvements over existing temporal modeling approaches, thereby establishing it as a robust solution for a wide range of spatio-temporal applications.","sentences":["Spatio-temporal predictive learning plays a crucial role in self-supervised learning, with wide-ranging applications across a diverse range of fields.","Previous approaches for temporal modeling fall into two categories: recurrent-based and recurrent-free methods.","The former, while meticulously processing frames one by one, neglect short-term spatio-temporal information redundancies, leading to inefficiencies.","The latter naively stack frames sequentially, overlooking the inherent temporal dependencies.","In this paper, we re-examine the two dominant temporal modeling approaches within the realm of spatio-temporal predictive learning, offering a unified perspective.","Building upon this analysis, we introduce USTEP (Unified Spatio-TEmporal Predictive learning), an innovative framework that reconciles the recurrent-based and recurrent-free methods by integrating both micro-temporal and macro-temporal scales.","Extensive experiments on a wide range of spatio-temporal predictive learning demonstrate that USTEP achieves significant improvements over existing temporal modeling approaches, thereby establishing it as a robust solution for a wide range of spatio-temporal applications."],"url":"http://arxiv.org/abs/2310.05829v1"}
{"created":"2023-10-09 16:10:51","title":"Write What You Want: Applying Text-to-video Retrieval to Audiovisual Archives","abstract":"Audiovisual (AV) archives, as an essential reservoir of our cultural assets, are suffering from the issue of accessibility. The complex nature of the medium itself made processing and interaction an open challenge still in the field of computer vision, multimodal learning, and human-computer interaction, as well as in culture and heritage. In recent years, with the raising of video retrieval tasks, methods in retrieving video content with natural language (text-to-video retrieval) gained quite some attention and have reached a performance level where real-world application is on the horizon. Appealing as it may sound, such methods focus on retrieving videos using plain visual-focused descriptions of what has happened in the video and finding videos such as instructions. It is too early to say such methods would be the new paradigms for accessing and encoding complex video content into high-dimensional data, but they are indeed innovative attempts and foundations to build future exploratory interfaces for AV archives (e.g. allow users to write stories and retrieve related snippets in the archive, or encoding video content at high-level for visualisation). This work filled the application gap by examining such text-to-video retrieval methods from an implementation point of view and proposed and verified a classifier-enhanced workflow to allow better results when dealing with in-situ queries that might have been different from the training dataset. Such a workflow is then applied to the real-world archive from T\\'el\\'evision Suisse Romande (RTS) to create a demo. At last, a human-centred evaluation is conducted to understand whether the text-to-video retrieval methods improve the overall experience of accessing AV archives.","sentences":["Audiovisual (AV) archives, as an essential reservoir of our cultural assets, are suffering from the issue of accessibility.","The complex nature of the medium itself made processing and interaction an open challenge still in the field of computer vision, multimodal learning, and human-computer interaction, as well as in culture and heritage.","In recent years, with the raising of video retrieval tasks, methods in retrieving video content with natural language (text-to-video retrieval) gained quite some attention and have reached a performance level where real-world application is on the horizon.","Appealing as it may sound, such methods focus on retrieving videos using plain visual-focused descriptions of what has happened in the video and finding videos such as instructions.","It is too early to say such methods would be the new paradigms for accessing and encoding complex video content into high-dimensional data, but they are indeed innovative attempts and foundations to build future exploratory interfaces for AV archives (e.g. allow users to write stories and retrieve related snippets in the archive, or encoding video content at high-level for visualisation).","This work filled the application gap by examining such text-to-video retrieval methods from an implementation point of view and proposed and verified a classifier-enhanced workflow to allow better results when dealing with in-situ queries that might have been different from the training dataset.","Such a workflow is then applied to the real-world archive from T\\'el\\'evision Suisse Romande (RTS) to create a demo.","At last, a human-centred evaluation is conducted to understand whether the text-to-video retrieval methods improve the overall experience of accessing AV archives."],"url":"http://arxiv.org/abs/2310.05825v1"}
{"created":"2023-10-09 16:08:23","title":"Terminology-Aware Translation with Constrained Decoding and Large Language Model Prompting","abstract":"Terminology correctness is important in the downstream application of machine translation, and a prevalent way to ensure this is to inject terminology constraints into a translation system. In our submission to the WMT 2023 terminology translation task, we adopt a translate-then-refine approach which can be domain-independent and requires minimal manual efforts. We annotate random source words with pseudo-terminology translations obtained from word alignment to first train a terminology-aware model. Further, we explore two post-processing methods. First, we use an alignment process to discover whether a terminology constraint has been violated, and if so, we re-decode with the violating word negatively constrained. Alternatively, we leverage a large language model to refine a hypothesis by providing it with terminology constraints. Results show that our terminology-aware model learns to incorporate terminologies effectively, and the large language model refinement process can further improve terminology recall.","sentences":["Terminology correctness is important in the downstream application of machine translation, and a prevalent way to ensure this is to inject terminology constraints into a translation system.","In our submission to the WMT 2023 terminology translation task, we adopt a translate-then-refine approach which can be domain-independent and requires minimal manual efforts.","We annotate random source words with pseudo-terminology translations obtained from word alignment to first train a terminology-aware model.","Further, we explore two post-processing methods.","First, we use an alignment process to discover whether a terminology constraint has been violated, and if so, we re-decode with the violating word negatively constrained.","Alternatively, we leverage a large language model to refine a hypothesis by providing it with terminology constraints.","Results show that our terminology-aware model learns to incorporate terminologies effectively, and the large language model refinement process can further improve terminology recall."],"url":"http://arxiv.org/abs/2310.05824v1"}
{"created":"2023-10-09 16:05:43","title":"Pre-trained Spatial Priors on Multichannel NMF for Music Source Separation","abstract":"This paper presents a novel approach to sound source separation that leverages spatial information obtained during the recording setup. Our method trains a spatial mixing filter using solo passages to capture information about the room impulse response and transducer response at each sensor location. This pre-trained filter is then integrated into a multichannel non-negative matrix factorization (MNMF) scheme to better capture the variances of different sound sources. The recording setup used in our experiments is the typical setup for orchestra recordings, with a main microphone and a close \"cardioid\" or \"supercardioid\" microphone for each section of the orchestra. This makes the proposed method applicable to many existing recordings. Experiments on polyphonic ensembles demonstrate the effectiveness of the proposed framework in separating individual sound sources, improving performance compared to conventional MNMF methods.","sentences":["This paper presents a novel approach to sound source separation that leverages spatial information obtained during the recording setup.","Our method trains a spatial mixing filter using solo passages to capture information about the room impulse response and transducer response at each sensor location.","This pre-trained filter is then integrated into a multichannel non-negative matrix factorization (MNMF) scheme to better capture the variances of different sound sources.","The recording setup used in our experiments is the typical setup for orchestra recordings, with a main microphone and a close \"cardioid\" or \"supercardioid\" microphone for each section of the orchestra.","This makes the proposed method applicable to many existing recordings.","Experiments on polyphonic ensembles demonstrate the effectiveness of the proposed framework in separating individual sound sources, improving performance compared to conventional MNMF methods."],"url":"http://arxiv.org/abs/2310.05821v1"}
{"created":"2023-10-09 16:03:22","title":"SC-Safety: A Multi-round Open-ended Question Adversarial Safety Benchmark for Large Language Models in Chinese","abstract":"Large language models (LLMs), like ChatGPT and GPT-4, have demonstrated remarkable abilities in natural language understanding and generation. However, alongside their positive impact on our daily tasks, they can also produce harmful content that negatively affects societal perceptions. To systematically assess the safety of Chinese LLMs, we introduce SuperCLUE-Safety (SC-Safety) - a multi-round adversarial benchmark with 4912 open-ended questions covering more than 20 safety sub-dimensions. Adversarial human-model interactions and conversations significantly increase the challenges compared to existing methods. Experiments on 13 major LLMs supporting Chinese yield the following insights: 1) Closed-source models outperform open-sourced ones in terms of safety; 2) Models released from China demonstrate comparable safety levels to LLMs like GPT-3.5-turbo; 3) Some smaller models with 6B-13B parameters can compete effectively in terms of safety. By introducing SC-Safety, we aim to promote collaborative efforts to create safer and more trustworthy LLMs. The benchmark and findings provide guidance on model selection. Our benchmark can be found at https://www.CLUEbenchmarks.com","sentences":["Large language models (LLMs), like ChatGPT and GPT-4, have demonstrated remarkable abilities in natural language understanding and generation.","However, alongside their positive impact on our daily tasks, they can also produce harmful content that negatively affects societal perceptions.","To systematically assess the safety of Chinese LLMs, we introduce SuperCLUE-Safety (SC-Safety) - a multi-round adversarial benchmark with 4912 open-ended questions covering more than 20 safety sub-dimensions.","Adversarial human-model interactions and conversations significantly increase the challenges compared to existing methods.","Experiments on 13 major LLMs supporting Chinese yield the following insights: 1) Closed-source models outperform open-sourced ones in terms of safety; 2) Models released from China demonstrate comparable safety levels to LLMs like GPT-3.5-turbo; 3) Some smaller models with 6B-13B parameters can compete effectively in terms of safety.","By introducing SC-Safety, we aim to promote collaborative efforts to create safer and more trustworthy LLMs.","The benchmark and findings provide guidance on model selection.","Our benchmark can be found at https://www.CLUEbenchmarks.com"],"url":"http://arxiv.org/abs/2310.05818v1"}
{"created":"2023-10-09 15:53:42","title":"Audio compression-assisted feature extraction for voice replay attack detection","abstract":"Replay attack is one of the most effective and simplest voice spoofing attacks. Detecting replay attacks is challenging, according to the Automatic Speaker Verification Spoofing and Countermeasures Challenge 2021 (ASVspoof 2021), because they involve a loudspeaker, a microphone, and acoustic conditions (e.g., background noise). One obstacle to detecting replay attacks is finding robust feature representations that reflect the channel noise information added to the replayed speech. This study proposes a feature extraction approach that uses audio compression for assistance. Audio compression compresses audio to preserve content and speaker information for transmission. The missed information after decompression is expected to contain content- and speaker-independent information (e.g., channel noise added during the replay process). We conducted a comprehensive experiment with a few data augmentation techniques and 3 classifiers on the ASVspoof 2021 physical access (PA) set and confirmed the effectiveness of the proposed feature extraction approach. To the best of our knowledge, the proposed approach achieves the lowest EER at 22.71% on the ASVspoof 2021 PA evaluation set.","sentences":["Replay attack is one of the most effective and simplest voice spoofing attacks.","Detecting replay attacks is challenging, according to the Automatic Speaker Verification Spoofing and Countermeasures Challenge 2021 (ASVspoof 2021), because they involve a loudspeaker, a microphone, and acoustic conditions (e.g., background noise).","One obstacle to detecting replay attacks is finding robust feature representations that reflect the channel noise information added to the replayed speech.","This study proposes a feature extraction approach that uses audio compression for assistance.","Audio compression compresses audio to preserve content and speaker information for transmission.","The missed information after decompression is expected to contain content- and speaker-independent information (e.g., channel noise added during the replay process).","We conducted a comprehensive experiment with a few data augmentation techniques and 3 classifiers on the ASVspoof 2021 physical access (PA) set and confirmed the effectiveness of the proposed feature extraction approach.","To the best of our knowledge, the proposed approach achieves the lowest EER at 22.71% on the ASVspoof 2021 PA evaluation set."],"url":"http://arxiv.org/abs/2310.05813v1"}
{"created":"2023-10-09 15:52:59","title":"Provably Convergent Data-Driven Convex-Nonconvex Regularization","abstract":"An emerging new paradigm for solving inverse problems is via the use of deep learning to learn a regularizer from data. This leads to high-quality results, but often at the cost of provable guarantees. In this work, we show how well-posedness and convergent regularization arises within the convex-nonconvex (CNC) framework for inverse problems. We introduce a novel input weakly convex neural network (IWCNN) construction to adapt the method of learned adversarial regularization to the CNC framework. Empirically we show that our method overcomes numerical issues of previous adversarial methods.","sentences":["An emerging new paradigm for solving inverse problems is via the use of deep learning to learn a regularizer from data.","This leads to high-quality results, but often at the cost of provable guarantees.","In this work, we show how well-posedness and convergent regularization arises within the convex-nonconvex (CNC) framework for inverse problems.","We introduce a novel input weakly convex neural network (IWCNN) construction to adapt the method of learned adversarial regularization to the CNC framework.","Empirically we show that our method overcomes numerical issues of previous adversarial methods."],"url":"http://arxiv.org/abs/2310.05812v1"}
{"created":"2023-10-09 15:45:08","title":"A Simple Open-Loop Baseline for Reinforcement Learning Locomotion Tasks","abstract":"In search of the simplest baseline capable of competing with Deep Reinforcement Learning on locomotion tasks, we propose a biologically inspired model-free open-loop strategy. Drawing upon prior knowledge and harnessing the elegance of simple oscillators to generate periodic joint motions, it achieves respectable performance in five different locomotion environments, with a number of tunable parameters that is a tiny fraction of the thousands typically required by RL algorithms. Unlike RL methods, which are prone to performance degradation when exposed to sensor noise or failure, our open-loop oscillators exhibit remarkable robustness due to their lack of reliance on sensors. Furthermore, we showcase a successful transfer from simulation to reality using an elastic quadruped, all without the need for randomization or reward engineering.","sentences":["In search of the simplest baseline capable of competing with Deep Reinforcement Learning on locomotion tasks, we propose a biologically inspired model-free open-loop strategy.","Drawing upon prior knowledge and harnessing the elegance of simple oscillators to generate periodic joint motions, it achieves respectable performance in five different locomotion environments, with a number of tunable parameters that is a tiny fraction of the thousands typically required by RL algorithms.","Unlike RL methods, which are prone to performance degradation when exposed to sensor noise or failure, our open-loop oscillators exhibit remarkable robustness due to their lack of reliance on sensors.","Furthermore, we showcase a successful transfer from simulation to reality using an elastic quadruped, all without the need for randomization or reward engineering."],"url":"http://arxiv.org/abs/2310.05808v1"}
{"created":"2023-10-09 15:44:35","title":"Sharing Information Between Machine Tools to Improve Surface Finish Forecasting","abstract":"At present, most surface-quality prediction methods can only perform single-task prediction which results in under-utilised datasets, repetitive work and increased experimental costs. To counter this, the authors propose a Bayesian hierarchical model to predict surface-roughness measurements for a turning machining process. The hierarchical model is compared to multiple independent Bayesian linear regression models to showcase the benefits of partial pooling in a machining setting with respect to prediction accuracy and uncertainty quantification.","sentences":["At present, most surface-quality prediction methods can only perform single-task prediction which results in under-utilised datasets, repetitive work and increased experimental costs.","To counter this, the authors propose a Bayesian hierarchical model to predict surface-roughness measurements for a turning machining process.","The hierarchical model is compared to multiple independent Bayesian linear regression models to showcase the benefits of partial pooling in a machining setting with respect to prediction accuracy and uncertainty quantification."],"url":"http://arxiv.org/abs/2310.05807v1"}
{"created":"2023-10-09 15:43:07","title":"Learning Language-guided Adaptive Hyper-modality Representation for Multimodal Sentiment Analysis","abstract":"Though Multimodal Sentiment Analysis (MSA) proves effective by utilizing rich information from multiple sources (e.g., language, video, and audio), the potential sentiment-irrelevant and conflicting information across modalities may hinder the performance from being further improved. To alleviate this, we present Adaptive Language-guided Multimodal Transformer (ALMT), which incorporates an Adaptive Hyper-modality Learning (AHL) module to learn an irrelevance/conflict-suppressing representation from visual and audio features under the guidance of language features at different scales. With the obtained hyper-modality representation, the model can obtain a complementary and joint representation through multimodal fusion for effective MSA. In practice, ALMT achieves state-of-the-art performance on several popular datasets (e.g., MOSI, MOSEI and CH-SIMS) and an abundance of ablation demonstrates the validity and necessity of our irrelevance/conflict suppression mechanism.","sentences":["Though Multimodal Sentiment Analysis (MSA) proves effective by utilizing rich information from multiple sources (e.g., language, video, and audio), the potential sentiment-irrelevant and conflicting information across modalities may hinder the performance from being further improved.","To alleviate this, we present Adaptive Language-guided Multimodal Transformer (ALMT), which incorporates an Adaptive Hyper-modality Learning (AHL) module to learn an irrelevance/conflict-suppressing representation from visual and audio features under the guidance of language features at different scales.","With the obtained hyper-modality representation, the model can obtain a complementary and joint representation through multimodal fusion for effective MSA.","In practice, ALMT achieves state-of-the-art performance on several popular datasets (e.g., MOSI, MOSEI and CH-SIMS) and an abundance of ablation demonstrates the validity and necessity of our irrelevance/conflict suppression mechanism."],"url":"http://arxiv.org/abs/2310.05804v1"}
{"created":"2023-10-09 15:37:06","title":"An operator preconditioning perspective on training in physics-informed machine learning","abstract":"In this paper, we investigate the behavior of gradient descent algorithms in physics-informed machine learning methods like PINNs, which minimize residuals connected to partial differential equations (PDEs). Our key result is that the difficulty in training these models is closely related to the conditioning of a specific differential operator. This operator, in turn, is associated to the Hermitian square of the differential operator of the underlying PDE. If this operator is ill-conditioned, it results in slow or infeasible training. Therefore, preconditioning this operator is crucial. We employ both rigorous mathematical analysis and empirical evaluations to investigate various strategies, explaining how they better condition this critical operator, and consequently improve training.","sentences":["In this paper, we investigate the behavior of gradient descent algorithms in physics-informed machine learning methods like PINNs, which minimize residuals connected to partial differential equations (PDEs).","Our key result is that the difficulty in training these models is closely related to the conditioning of a specific differential operator.","This operator, in turn, is associated to the Hermitian square of the differential operator of the underlying PDE.","If this operator is ill-conditioned, it results in slow or infeasible training.","Therefore, preconditioning this operator is crucial.","We employ both rigorous mathematical analysis and empirical evaluations to investigate various strategies, explaining how they better condition this critical operator, and consequently improve training."],"url":"http://arxiv.org/abs/2310.05801v1"}
{"created":"2023-10-09 15:31:03","title":"Are Large Language Models Post Hoc Explainers?","abstract":"Large Language Models (LLMs) are increasingly used as powerful tools for a plethora of natural language processing (NLP) applications. A recent innovation, in-context learning (ICL), enables LLMs to learn new tasks by supplying a few examples in the prompt during inference time, thereby eliminating the need for model fine-tuning. While LLMs have been utilized in several applications, their applicability in explaining the behavior of other models remains relatively unexplored. Despite the growing number of new explanation techniques, many require white-box access to the model and/or are computationally expensive, highlighting a need for next-generation post hoc explainers. In this work, we present the first framework to study the effectiveness of LLMs in explaining other predictive models. More specifically, we propose a novel framework encompassing multiple prompting strategies: i) Perturbation-based ICL, ii) Prediction-based ICL, iii) Instruction-based ICL, and iv) Explanation-based ICL, with varying levels of information about the underlying ML model and the local neighborhood of the test sample. We conduct extensive experiments with real-world benchmark datasets to demonstrate that LLM-generated explanations perform on par with state-of-the-art post hoc explainers using their ability to leverage ICL examples and their internal knowledge in generating model explanations. On average, across four datasets and two ML models, we observe that LLMs identify the most important feature with 72.19% accuracy, opening up new frontiers in explainable artificial intelligence (XAI) to explore LLM-based explanation frameworks.","sentences":["Large Language Models (LLMs) are increasingly used as powerful tools for a plethora of natural language processing (NLP) applications.","A recent innovation, in-context learning (ICL), enables LLMs to learn new tasks by supplying a few examples in the prompt during inference time, thereby eliminating the need for model fine-tuning.","While LLMs have been utilized in several applications, their applicability in explaining the behavior of other models remains relatively unexplored.","Despite the growing number of new explanation techniques, many require white-box access to the model and/or are computationally expensive, highlighting a need for next-generation post hoc explainers.","In this work, we present the first framework to study the effectiveness of LLMs in explaining other predictive models.","More specifically, we propose a novel framework encompassing multiple prompting strategies: i) Perturbation-based ICL, ii) Prediction-based ICL, iii) Instruction-based ICL, and iv) Explanation-based ICL, with varying levels of information about the underlying ML model and the local neighborhood of the test sample.","We conduct extensive experiments with real-world benchmark datasets to demonstrate that LLM-generated explanations perform on par with state-of-the-art post hoc explainers using their ability to leverage ICL examples and their internal knowledge in generating model explanations.","On average, across four datasets and two ML models, we observe that LLMs identify the most important feature with 72.19% accuracy, opening up new frontiers in explainable artificial intelligence (XAI) to explore LLM-based explanation frameworks."],"url":"http://arxiv.org/abs/2310.05797v1"}
{"created":"2023-10-09 15:29:32","title":"Computation-Limited Signals: A Channel Capacity Regime Constrained by Computational Complexity","abstract":"In this letter, we introduce the computational-limited (comp-limited) signals, a communication capacity regime in which the signal time computational complexity overhead is the key constraint -- rather than power or bandwidth -- to the overall communication capacity. To relate capacity and time complexity, we propose a novel mathematical framework that builds on concepts of information theory and computational complexity. In particular, the algorithmic capacity stands for the ratio between the upper-bound number of bits modulated in a symbol and the lower-bound time complexity required to turn these bits into a communication symbol. By setting this ratio as function of the channel resources, we classify a given signal design as comp-limited if its algorithmic capacity nullifies as the channel resources grow. As a use-case, we show that an uncoded OFDM transmitter is comp-limited unless the lower-bound computational complexity of the N-point DFT problem verifies as $\\Omega(N)$, which remains an open challenge in theoretical computer science.","sentences":["In this letter, we introduce the computational-limited (comp-limited) signals, a communication capacity regime in which the signal time computational complexity overhead is the key constraint -- rather than power or bandwidth -- to the overall communication capacity.","To relate capacity and time complexity, we propose a novel mathematical framework that builds on concepts of information theory and computational complexity.","In particular, the algorithmic capacity stands for the ratio between the upper-bound number of bits modulated in a symbol and the lower-bound time complexity required to turn these bits into a communication symbol.","By setting this ratio as function of the channel resources, we classify a given signal design as comp-limited if its algorithmic capacity nullifies as the channel resources grow.","As a use-case, we show that an uncoded OFDM transmitter is comp-limited unless the lower-bound computational complexity of the N-point DFT problem verifies as $\\Omega(N)$, which remains an open challenge in theoretical computer science."],"url":"http://arxiv.org/abs/2310.05794v1"}
{"created":"2023-10-09 15:29:10","title":"DiffuSeq-v2: Bridging Discrete and Continuous Text Spaces for Accelerated Seq2Seq Diffusion Models","abstract":"Diffusion models have gained prominence in generating high-quality sequences of text. Nevertheless, current approaches predominantly represent discrete text within a continuous diffusion space, which incurs substantial computational overhead during training and results in slower sampling speeds. In this paper, we introduce a soft absorbing state that facilitates the diffusion model in learning to reconstruct discrete mutations based on the underlying Gaussian space, thereby enhancing its capacity to recover conditional signals. During the sampling phase, we employ state-of-the-art ODE solvers within the continuous space to expedite the sampling process. Comprehensive experimental evaluations reveal that our proposed method effectively accelerates the training convergence by 4x and generates samples of similar quality 800x faster, rendering it significantly closer to practical application. \\footnote{The code is released at \\url{https://github.com/Shark-NLP/DiffuSeq}","sentences":["Diffusion models have gained prominence in generating high-quality sequences of text.","Nevertheless, current approaches predominantly represent discrete text within a continuous diffusion space, which incurs substantial computational overhead during training and results in slower sampling speeds.","In this paper, we introduce a soft absorbing state that facilitates the diffusion model in learning to reconstruct discrete mutations based on the underlying Gaussian space, thereby enhancing its capacity to recover conditional signals.","During the sampling phase, we employ state-of-the-art ODE solvers within the continuous space to expedite the sampling process.","Comprehensive experimental evaluations reveal that our proposed method effectively accelerates the training convergence by 4x and generates samples of similar quality 800x faster, rendering it significantly closer to practical application.","\\footnote{The code is released at \\url{https://github.com/Shark-NLP/DiffuSeq}"],"url":"http://arxiv.org/abs/2310.05793v1"}
{"created":"2023-10-09 15:26:07","title":"Problem-Solving Guide: Predicting the Algorithm Tags and Difficulty for Competitive Programming Problems","abstract":"The recent program development industries have required problem-solving abilities for engineers, especially application developers. However, AI-based education systems to help solve computer algorithm problems have not yet attracted attention, while most big tech companies require the ability to solve algorithm problems including Google, Meta, and Amazon. The most useful guide to solving algorithm problems might be guessing the category (tag) of the facing problems. Therefore, our study addresses the task of predicting the algorithm tag as a useful tool for engineers and developers. Moreover, we also consider predicting the difficulty levels of algorithm problems, which can be used as useful guidance to calculate the required time to solve that problem. In this paper, we present a real-world algorithm problem multi-task dataset, AMT, by mainly collecting problem samples from the most famous and large competitive programming website Codeforces. To the best of our knowledge, our proposed dataset is the most large-scale dataset for predicting algorithm tags compared to previous studies. Moreover, our work is the first to address predicting the difficulty levels of algorithm problems. We present a deep learning-based novel method for simultaneously predicting algorithm tags and the difficulty levels of an algorithm problem given. All datasets and source codes are available at https://github.com/sronger/PSG_Predicting_Algorithm_Tags_and_Difficulty.","sentences":["The recent program development industries have required problem-solving abilities for engineers, especially application developers.","However, AI-based education systems to help solve computer algorithm problems have not yet attracted attention, while most big tech companies require the ability to solve algorithm problems including Google, Meta, and Amazon.","The most useful guide to solving algorithm problems might be guessing the category (tag) of the facing problems.","Therefore, our study addresses the task of predicting the algorithm tag as a useful tool for engineers and developers.","Moreover, we also consider predicting the difficulty levels of algorithm problems, which can be used as useful guidance to calculate the required time to solve that problem.","In this paper, we present a real-world algorithm problem multi-task dataset, AMT, by mainly collecting problem samples from the most famous and large competitive programming website Codeforces.","To the best of our knowledge, our proposed dataset is the most large-scale dataset for predicting algorithm tags compared to previous studies.","Moreover, our work is the first to address predicting the difficulty levels of algorithm problems.","We present a deep learning-based novel method for simultaneously predicting algorithm tags and the difficulty levels of an algorithm problem given.","All datasets and source codes are available at https://github.com/sronger/PSG_Predicting_Algorithm_Tags_and_Difficulty."],"url":"http://arxiv.org/abs/2310.05791v1"}
{"created":"2023-10-09 15:22:13","title":"Efficient Hybrid Oversampling and Intelligent Undersampling for Imbalanced Big Data Classification","abstract":"Imbalanced classification is a well-known challenge faced by many real-world applications. This issue occurs when the distribution of the target variable is skewed, leading to a prediction bias toward the majority class. With the arrival of the Big Data era, there is a pressing need for efficient solutions to solve this problem. In this work, we present a novel resampling method called SMOTENN that combines intelligent undersampling and oversampling using a MapReduce framework. Both procedures are performed on the same pass over the data, conferring efficiency to the technique. The SMOTENN method is complemented with an efficient implementation of the neighborhoods related to the minority samples. Our experimental results show the virtues of this approach, outperforming alternative resampling techniques for small- and medium-sized datasets while achieving positive results on large datasets with reduced running times.","sentences":["Imbalanced classification is a well-known challenge faced by many real-world applications.","This issue occurs when the distribution of the target variable is skewed, leading to a prediction bias toward the majority class.","With the arrival of the Big Data era, there is a pressing need for efficient solutions to solve this problem.","In this work, we present a novel resampling method called SMOTENN that combines intelligent undersampling and oversampling using a MapReduce framework.","Both procedures are performed on the same pass over the data, conferring efficiency to the technique.","The SMOTENN method is complemented with an efficient implementation of the neighborhoods related to the minority samples.","Our experimental results show the virtues of this approach, outperforming alternative resampling techniques for small- and medium-sized datasets while achieving positive results on large datasets with reduced running times."],"url":"http://arxiv.org/abs/2310.05789v1"}
{"created":"2023-10-09 15:20:10","title":"Canonization of a random circulant graph by counting walks","abstract":"It is well known that almost all graphs are canonizable by a simple combinatorial routine known as color refinement. With high probability, this method assigns a unique label to each vertex of a random input graph and, hence, it is applicable only to asymmetric graphs. The strength of combinatorial refinement techniques becomes a subtle issue if the input graphs are highly symmetric. We prove that the combination of color refinement with vertex individualization produces a canonical labeling for almost all circulant digraphs (Cayley digraphs of a cyclic group). To our best knowledge, this is the first application of combinatorial refinement in the realm of vertex-transitive graphs. Remarkably, we do not even need the full power of the color refinement algorithm. We show that the canonical label of a vertex $v$ can be obtained just by counting walks of each length from $v$ to an individualized vertex.","sentences":["It is well known that almost all graphs are canonizable by a simple combinatorial routine known as color refinement.","With high probability, this method assigns a unique label to each vertex of a random input graph and, hence, it is applicable only to asymmetric graphs.","The strength of combinatorial refinement techniques becomes a subtle issue if the input graphs are highly symmetric.","We prove that the combination of color refinement with vertex individualization produces a canonical labeling for almost all circulant digraphs (Cayley digraphs of a cyclic group).","To our best knowledge, this is the first application of combinatorial refinement in the realm of vertex-transitive graphs.","Remarkably, we do not even need the full power of the color refinement algorithm.","We show that the canonical label of a vertex $v$ can be obtained just by counting walks of each length from $v$ to an individualized vertex."],"url":"http://arxiv.org/abs/2310.05788v1"}
{"created":"2023-10-09 15:16:35","title":"Joint object detection and re-identification for 3D obstacle multi-camera systems","abstract":"In recent years, the field of autonomous driving has witnessed remarkable advancements, driven by the integration of a multitude of sensors, including cameras and LiDAR systems, in different prototypes. However, with the proliferation of sensor data comes the pressing need for more sophisticated information processing techniques. This research paper introduces a novel modification to an object detection network that uses camera and lidar information, incorporating an additional branch designed for the task of re-identifying objects across adjacent cameras within the same vehicle while elevating the quality of the baseline 3D object detection outcomes. The proposed methodology employs a two-step detection pipeline: initially, an object detection network is employed, followed by a 3D box estimator that operates on the filtered point cloud generated from the network's detections. Extensive experimental evaluations encompassing both 2D and 3D domains validate the effectiveness of the proposed approach and the results underscore the superiority of this method over traditional Non-Maximum Suppression (NMS) techniques, with an improvement of more than 5\\% in the car category in the overlapping areas.","sentences":["In recent years, the field of autonomous driving has witnessed remarkable advancements, driven by the integration of a multitude of sensors, including cameras and LiDAR systems, in different prototypes.","However, with the proliferation of sensor data comes the pressing need for more sophisticated information processing techniques.","This research paper introduces a novel modification to an object detection network that uses camera and lidar information, incorporating an additional branch designed for the task of re-identifying objects across adjacent cameras within the same vehicle while elevating the quality of the baseline 3D object detection outcomes.","The proposed methodology employs a two-step detection pipeline: initially, an object detection network is employed, followed by a 3D box estimator that operates on the filtered point cloud generated from the network's detections.","Extensive experimental evaluations encompassing both 2D and 3D domains validate the effectiveness of the proposed approach and the results underscore the superiority of this method over traditional Non-Maximum Suppression (NMS) techniques, with an improvement of more than 5\\% in the car category in the overlapping areas."],"url":"http://arxiv.org/abs/2310.05785v1"}
{"created":"2023-10-09 15:16:02","title":"The Parameterised Complexity of Integer Multicommodity Flow","abstract":"The Integer Multicommodity Flow problem has been studied extensively in the literature. However, from a parameterised perspective, mostly special cases, such as the Disjoint Paths problem, have been considered. Therefore, we investigate the parameterised complexity of the general Integer Multicommodity Flow problem. We show that the decision version of this problem on directed graphs for a constant number of commodities, when the capacities are given in unary, is XNLP-complete with pathwidth as parameter and XALP-complete with treewidth as parameter. When the capacities are given in binary, the problem is NP-complete even for graphs of pathwidth at most 13. We give related results for undirected graphs. These results imply that the problem is unlikely to be fixed-parameter tractable by these parameters.   In contrast, we show that the problem does become fixed-parameter tractable when weighted tree partition width (a variant of tree partition width for edge weighted graphs) is used as parameter.","sentences":["The Integer Multicommodity Flow problem has been studied extensively in the literature.","However, from a parameterised perspective, mostly special cases, such as the Disjoint Paths problem, have been considered.","Therefore, we investigate the parameterised complexity of the general Integer Multicommodity Flow problem.","We show that the decision version of this problem on directed graphs for a constant number of commodities, when the capacities are given in unary, is XNLP-complete with pathwidth as parameter and XALP-complete with treewidth as parameter.","When the capacities are given in binary, the problem is NP-complete even for graphs of pathwidth at most 13.","We give related results for undirected graphs.","These results imply that the problem is unlikely to be fixed-parameter tractable by these parameters.   ","In contrast, we show that the problem does become fixed-parameter tractable when weighted tree partition width (a variant of tree partition width for edge weighted graphs) is used as parameter."],"url":"http://arxiv.org/abs/2310.05784v1"}
{"created":"2023-10-09 15:15:05","title":"Aligning Language Models with Human Preferences via a Bayesian Approach","abstract":"In the quest to advance human-centric natural language generation (NLG) systems, ensuring alignment between NLG models and human preferences is crucial. For this alignment, current popular methods leverage a reinforcement learning (RL) approach with a reward model trained on feedback from humans. However, inherent disagreements due to the subjective nature of human preferences pose a significant challenge for training the reward model, resulting in a deterioration of the NLG performance. To tackle this issue, previous approaches typically rely on majority voting or averaging to consolidate multiple inconsistent preferences into a merged one. Although straightforward to understand and execute, such methods suffer from an inability to capture the nuanced degrees of disaggregation among humans and may only represent a specialized subset of individuals, thereby lacking the ability to quantitatively disclose the universality of human preferences. To address this challenge, this paper proposes a novel approach, which employs a Bayesian framework to account for the distribution of disagreements among human preferences as training a preference model, and names it as d-PM. Besides, considering the RL strategy's inefficient and complex training process over the training efficiency, we further propose utilizing the contrastive learning strategy to train the NLG model with the preference scores derived from the d-PM model. Extensive experiments on two human-centric NLG tasks, i.e., emotional support conversation and integrity \"Rule-of-Thumb\" generation, show that our method consistently exceeds previous SOTA models in both automatic and human evaluations.","sentences":["In the quest to advance human-centric natural language generation (NLG) systems, ensuring alignment between NLG models and human preferences is crucial.","For this alignment, current popular methods leverage a reinforcement learning (RL) approach with a reward model trained on feedback from humans.","However, inherent disagreements due to the subjective nature of human preferences pose a significant challenge for training the reward model, resulting in a deterioration of the NLG performance.","To tackle this issue, previous approaches typically rely on majority voting or averaging to consolidate multiple inconsistent preferences into a merged one.","Although straightforward to understand and execute, such methods suffer from an inability to capture the nuanced degrees of disaggregation among humans and may only represent a specialized subset of individuals, thereby lacking the ability to quantitatively disclose the universality of human preferences.","To address this challenge, this paper proposes a novel approach, which employs a Bayesian framework to account for the distribution of disagreements among human preferences as training a preference model, and names it as d-PM.","Besides, considering the RL strategy's inefficient and complex training process over the training efficiency, we further propose utilizing the contrastive learning strategy to train the NLG model with the preference scores derived from the d-PM model.","Extensive experiments on two human-centric NLG tasks, i.e., emotional support conversation and integrity \"Rule-of-Thumb\" generation, show that our method consistently exceeds previous SOTA models in both automatic and human evaluations."],"url":"http://arxiv.org/abs/2310.05782v1"}
{"created":"2023-10-09 15:11:02","title":"Why Should This Article Be Deleted? Transparent Stance Detection in Multilingual Wikipedia Editor Discussions","abstract":"The moderation of content on online platforms is usually non-transparent. On Wikipedia, however, this discussion is carried out publicly and the editors are encouraged to use the content moderation policies as explanations for making moderation decisions. Currently, only a few comments explicitly mention those policies -- 20% of the English ones, but as few as 2% of the German and Turkish comments. To aid in this process of understanding how content is moderated, we construct a novel multilingual dataset of Wikipedia editor discussions along with their reasoning in three languages. The dataset contains the stances of the editors (keep, delete, merge, comment), along with the stated reason, and a content moderation policy, for each edit decision. We demonstrate that stance and corresponding reason (policy) can be predicted jointly with a high degree of accuracy, adding transparency to the decision-making process. We release both our joint prediction models and the multilingual content moderation dataset for further research on automated transparent content moderation.","sentences":["The moderation of content on online platforms is usually non-transparent.","On Wikipedia, however, this discussion is carried out publicly and the editors are encouraged to use the content moderation policies as explanations for making moderation decisions.","Currently, only a few comments explicitly mention those policies -- 20% of the English ones, but as few as 2% of the German and Turkish comments.","To aid in this process of understanding how content is moderated, we construct a novel multilingual dataset of Wikipedia editor discussions along with their reasoning in three languages.","The dataset contains the stances of the editors (keep, delete, merge, comment), along with the stated reason, and a content moderation policy, for each edit decision.","We demonstrate that stance and corresponding reason (policy) can be predicted jointly with a high degree of accuracy, adding transparency to the decision-making process.","We release both our joint prediction models and the multilingual content moderation dataset for further research on automated transparent content moderation."],"url":"http://arxiv.org/abs/2310.05779v1"}
{"created":"2023-10-09 15:07:03","title":"Unknown Truths and Unknowable Truths","abstract":"Notions of unknown truths and unknowable truths are important in formal epistemology, which are related to each other in e.g. Fitch's paradox of knowability. Although there have been some logical research on the notion of unknown truths and some philosophical discussion on the two notions, there seems to be no logical research on unknowable truths. In this paper, we propose a logic of unknowable truths, investigate the logical properties of unknown truths and unknowable truths, which includes the similarities of the two notions and the relationship between the two notions, and axiomatize this logic.","sentences":["Notions of unknown truths and unknowable truths are important in formal epistemology, which are related to each other in e.g. Fitch's paradox of knowability.","Although there have been some logical research on the notion of unknown truths and some philosophical discussion on the two notions, there seems to be no logical research on unknowable truths.","In this paper, we propose a logic of unknowable truths, investigate the logical properties of unknown truths and unknowable truths, which includes the similarities of the two notions and the relationship between the two notions, and axiomatize this logic."],"url":"http://arxiv.org/abs/2310.05777v1"}
{"created":"2023-10-09 14:57:41","title":"Towards Lossless Dataset Distillation via Difficulty-Aligned Trajectory Matching","abstract":"The ultimate goal of Dataset Distillation is to synthesize a small synthetic dataset such that a model trained on this synthetic set will perform equally well as a model trained on the full, real dataset. Until now, no method of Dataset Distillation has reached this completely lossless goal, in part due to the fact that previous methods only remain effective when the total number of synthetic samples is extremely small. Since only so much information can be contained in such a small number of samples, it seems that to achieve truly loss dataset distillation, we must develop a distillation method that remains effective as the size of the synthetic dataset grows. In this work, we present such an algorithm and elucidate why existing methods fail to generate larger, high-quality synthetic sets. Current state-of-the-art methods rely on trajectory-matching, or optimizing the synthetic data to induce similar long-term training dynamics as the real data. We empirically find that the training stage of the trajectories we choose to match (i.e., early or late) greatly affects the effectiveness of the distilled dataset. Specifically, early trajectories (where the teacher network learns easy patterns) work well for a low-cardinality synthetic set since there are fewer examples wherein to distribute the necessary information. Conversely, late trajectories (where the teacher network learns hard patterns) provide better signals for larger synthetic sets since there are now enough samples to represent the necessary complex patterns. Based on our findings, we propose to align the difficulty of the generated patterns with the size of the synthetic dataset. In doing so, we successfully scale trajectory matching-based methods to larger synthetic datasets, achieving lossless dataset distillation for the very first time. Code and distilled datasets are available at https://gzyaftermath.github.io/DATM.","sentences":["The ultimate goal of Dataset Distillation is to synthesize a small synthetic dataset such that a model trained on this synthetic set will perform equally well as a model trained on the full, real dataset.","Until now, no method of Dataset Distillation has reached this completely lossless goal, in part due to the fact that previous methods only remain effective when the total number of synthetic samples is extremely small.","Since only so much information can be contained in such a small number of samples, it seems that to achieve truly loss dataset distillation, we must develop a distillation method that remains effective as the size of the synthetic dataset grows.","In this work, we present such an algorithm and elucidate why existing methods fail to generate larger, high-quality synthetic sets.","Current state-of-the-art methods rely on trajectory-matching, or optimizing the synthetic data to induce similar long-term training dynamics as the real data.","We empirically find that the training stage of the trajectories we choose to match (i.e., early or late) greatly affects the effectiveness of the distilled dataset.","Specifically, early trajectories (where the teacher network learns easy patterns) work well for a low-cardinality synthetic set since there are fewer examples wherein to distribute the necessary information.","Conversely, late trajectories (where the teacher network learns hard patterns) provide better signals for larger synthetic sets since there are now enough samples to represent the necessary complex patterns.","Based on our findings, we propose to align the difficulty of the generated patterns with the size of the synthetic dataset.","In doing so, we successfully scale trajectory matching-based methods to larger synthetic datasets, achieving lossless dataset distillation for the very first time.","Code and distilled datasets are available at https://gzyaftermath.github.io/DATM."],"url":"http://arxiv.org/abs/2310.05773v1"}
{"created":"2023-10-09 14:57:37","title":"RateRL: A Framework for Developing RL-Based Rate Adaptation Algorithms in ns-3","abstract":"The increasing complexity of recent Wi-Fi amendments is making the use of traditional algorithms and heuristics unfeasible to address the Rate Adaptation (RA) problem. This is due to the large combination of configuration parameters along with the high variability of the wireless channel. Recently, several works have proposed the usage of Reinforcement Learning (RL) techniques to address the problem. However, the proposed solutions lack sufficient technical explanation. Also, the lack of standard frameworks enabling the reproducibility of results and the limited availability of source code, makes the fair comparison with state of the art approaches a challenge. This paper proposes a framework, named RateRL, that integrates state of the art libraries with the well-known Network Simulator 3 (ns-3) to enable the implementation and evaluation of RL-based RA algorithms. To the best of our knowledge, RateRL is the first tool available to assist researchers during the implementation, validation and evaluation phases of RL-based RA algorithms and enable the fair comparison between competing algorithms.","sentences":["The increasing complexity of recent Wi-Fi amendments is making the use of traditional algorithms and heuristics unfeasible to address the Rate Adaptation (RA) problem.","This is due to the large combination of configuration parameters along with the high variability of the wireless channel.","Recently, several works have proposed the usage of Reinforcement Learning (RL) techniques to address the problem.","However, the proposed solutions lack sufficient technical explanation.","Also, the lack of standard frameworks enabling the reproducibility of results and the limited availability of source code, makes the fair comparison with state of the art approaches a challenge.","This paper proposes a framework, named RateRL, that integrates state of the art libraries with the well-known Network Simulator 3 (ns-3) to enable the implementation and evaluation of RL-based RA algorithms.","To the best of our knowledge, RateRL is the first tool available to assist researchers during the implementation, validation and evaluation phases of RL-based RA algorithms and enable the fair comparison between competing algorithms."],"url":"http://arxiv.org/abs/2310.05772v1"}
{"created":"2023-10-09 14:57:05","title":"Foundation Models Meet Visualizations: Challenges and Opportunities","abstract":"Recent studies have indicated that foundation models, such as BERT and GPT, excel in adapting to a variety of downstream tasks. This adaptability has established them as the dominant force in building artificial intelligence (AI) systems. As visualization techniques intersect with these models, a new research paradigm emerges. This paper divides these intersections into two main areas: visualizations for foundation models (VIS4FM) and foundation models for visualizations (FM4VIS). In VIS4FM, we explore the primary role of visualizations in understanding, refining, and evaluating these intricate models. This addresses the pressing need for transparency, explainability, fairness, and robustness. Conversely, within FM4VIS, we highlight how foundation models can be utilized to advance the visualization field itself. The confluence of foundation models and visualizations holds great promise, but it also comes with its own set of challenges. By highlighting these challenges and the growing opportunities, this paper seeks to provide a starting point for continued exploration in this promising avenue.","sentences":["Recent studies have indicated that foundation models, such as BERT and GPT, excel in adapting to a variety of downstream tasks.","This adaptability has established them as the dominant force in building artificial intelligence (AI) systems.","As visualization techniques intersect with these models, a new research paradigm emerges.","This paper divides these intersections into two main areas: visualizations for foundation models (VIS4FM) and foundation models for visualizations (FM4VIS).","In VIS4FM, we explore the primary role of visualizations in understanding, refining, and evaluating these intricate models.","This addresses the pressing need for transparency, explainability, fairness, and robustness.","Conversely, within FM4VIS, we highlight how foundation models can be utilized to advance the visualization field itself.","The confluence of foundation models and visualizations holds great promise, but it also comes with its own set of challenges.","By highlighting these challenges and the growing opportunities, this paper seeks to provide a starting point for continued exploration in this promising avenue."],"url":"http://arxiv.org/abs/2310.05771v1"}
{"created":"2023-10-09 14:54:37","title":"DANet: Enhancing Small Object Detection through an Efficient Deformable Attention Network","abstract":"Efficient and accurate detection of small objects in manufacturing settings, such as defects and cracks, is crucial for ensuring product quality and safety. To address this issue, we proposed a comprehensive strategy by synergizing Faster R-CNN with cutting-edge methods. By combining Faster R-CNN with Feature Pyramid Network, we enable the model to efficiently handle multi-scale features intrinsic to manufacturing environments. Additionally, Deformable Net is used that contorts and conforms to the geometric variations of defects, bringing precision in detecting even the minuscule and complex features. Then, we incorporated an attention mechanism called Convolutional Block Attention Module in each block of our base ResNet50 network to selectively emphasize informative features and suppress less useful ones. After that we incorporated RoI Align, replacing RoI Pooling for finer region-of-interest alignment and finally the integration of Focal Loss effectively handles class imbalance, crucial for rare defect occurrences. The rigorous evaluation of our model on both the NEU-DET and Pascal VOC datasets underscores its robust performance and generalization capabilities. On the NEU-DET dataset, our model exhibited a profound understanding of steel defects, achieving state-of-the-art accuracy in identifying various defects. Simultaneously, when evaluated on the Pascal VOC dataset, our model showcases its ability to detect objects across a wide spectrum of categories within complex and small scenes.","sentences":["Efficient and accurate detection of small objects in manufacturing settings, such as defects and cracks, is crucial for ensuring product quality and safety.","To address this issue, we proposed a comprehensive strategy by synergizing Faster R-CNN with cutting-edge methods.","By combining Faster R-CNN with Feature Pyramid Network, we enable the model to efficiently handle multi-scale features intrinsic to manufacturing environments.","Additionally, Deformable Net is used that contorts and conforms to the geometric variations of defects, bringing precision in detecting even the minuscule and complex features.","Then, we incorporated an attention mechanism called Convolutional Block Attention Module in each block of our base ResNet50 network to selectively emphasize informative features and suppress less useful ones.","After that we incorporated RoI Align, replacing RoI Pooling for finer region-of-interest alignment and finally the integration of Focal Loss effectively handles class imbalance, crucial for rare defect occurrences.","The rigorous evaluation of our model on both the NEU-DET and Pascal VOC datasets underscores its robust performance and generalization capabilities.","On the NEU-DET dataset, our model exhibited a profound understanding of steel defects, achieving state-of-the-art accuracy in identifying various defects.","Simultaneously, when evaluated on the Pascal VOC dataset, our model showcases its ability to detect objects across a wide spectrum of categories within complex and small scenes."],"url":"http://arxiv.org/abs/2310.05768v1"}
{"created":"2023-10-09 14:49:37","title":"Topological Community Detection: A Sheaf-Theoretic Approach","abstract":"We propose a model for network community detection using topological data analysis, a branch of modern data science that leverages theory from algebraic topology to statistical analysis and machine learning. Specifically, we use cellular sheaves, which relate local to global properties of various algebraic topological constructions, to propose three new algorithms for vertex clustering over networks to detect communities. We apply our algorithms to real social network data in numerical experiments and obtain near optimal results in terms of modularity. Our work is the first implementation of sheaves on real social network data and provides a solid proof-of-concept for future work using sheaves as tools to study complex systems captured by networks and simplicial complexes.","sentences":["We propose a model for network community detection using topological data analysis, a branch of modern data science that leverages theory from algebraic topology to statistical analysis and machine learning.","Specifically, we use cellular sheaves, which relate local to global properties of various algebraic topological constructions, to propose three new algorithms for vertex clustering over networks to detect communities.","We apply our algorithms to real social network data in numerical experiments and obtain near optimal results in terms of modularity.","Our work is the first implementation of sheaves on real social network data and provides a solid proof-of-concept for future work using sheaves as tools to study complex systems captured by networks and simplicial complexes."],"url":"http://arxiv.org/abs/2310.05767v1"}
{"created":"2023-10-09 14:49:16","title":"FeatSense -- A Feature-based Registration Algorithm with GPU-accelerated TSDF-Mapping Backend for NVIDIA Jetson Boards","abstract":"This paper presents FeatSense, a feature-based GPU-accelerated SLAM system for high resolution LiDARs, combined with a map generation algorithm for real-time generation of large Truncated Signed Distance Fields (TSDFs) on embedded hardware. FeatSense uses LiDAR point cloud features for odometry estimation and point cloud registration. The registered point clouds are integrated into a global Truncated Signed Distance Field (TSDF) representation. FeatSense is intended to run on embedded systems with integrated GPU-accelerator like NVIDIA Jetson boards. In this paper, we present a real-time capable TSDF-SLAM system specially tailored for close coupled CPU/GPU systems. The implementation is evaluated in various structured and unstructured environments and benchmarked against existing reference datasets. The main contribution of this paper is the ability to register up to 128 scan lines of an Ouster OS1-128 LiDAR at 10Hz on a NVIDIA AGX Xavier while achieving a TSDF map generation speedup by a factor of 100 compared to previous work on the same power budget.","sentences":["This paper presents FeatSense, a feature-based GPU-accelerated SLAM system for high resolution LiDARs, combined with a map generation algorithm for real-time generation of large Truncated Signed Distance Fields (TSDFs) on embedded hardware.","FeatSense uses LiDAR point cloud features for odometry estimation and point cloud registration.","The registered point clouds are integrated into a global Truncated Signed Distance Field (TSDF) representation.","FeatSense is intended to run on embedded systems with integrated GPU-accelerator like NVIDIA Jetson boards.","In this paper, we present a real-time capable TSDF-SLAM system specially tailored for close coupled CPU/GPU systems.","The implementation is evaluated in various structured and unstructured environments and benchmarked against existing reference datasets.","The main contribution of this paper is the ability to register up to 128 scan lines of an Ouster OS1-128 LiDAR at 10Hz on a NVIDIA AGX Xavier while achieving a TSDF map generation speedup by a factor of 100 compared to previous work on the same power budget."],"url":"http://arxiv.org/abs/2310.05766v1"}
{"created":"2023-10-09 14:46:21","title":"Examining the simulation-to-reality gap of a wheel loader digging in deformable terrain","abstract":"We investigate how well a wheel loader simulator can replicate a real one when performing bucket filling in a pile of gravel. The comparisons are made using field test time series of the vehicle motion and actuation forces, loaded mass, and total work. The vehicle was modeled as a rigid multibody system with frictional contacts, driveline, and linear actuators. For the soil, we tested discrete element models of different resolutions, with and without multiscale acceleration. The spatio-temporal resolution ranged between 50-400 mm and 2-500 ms, and the computational speed was between 1/10,000 to 5 times faster than real-time. The simulation-to-reality gap was found to be around 10% and exhibited a weak dependence on the level of fidelity, i.e. accessible with real-time simulation and faster. Furthermore, the sensitivity of an optimized force feedback controller under transfer between different simulation domains was investigated. The domain bias was observed to cause a performance reduction of 5% despite the domain gap being about 15%.","sentences":["We investigate how well a wheel loader simulator can replicate a real one when performing bucket filling in a pile of gravel.","The comparisons are made using field test time series of the vehicle motion and actuation forces, loaded mass, and total work.","The vehicle was modeled as a rigid multibody system with frictional contacts, driveline, and linear actuators.","For the soil, we tested discrete element models of different resolutions, with and without multiscale acceleration.","The spatio-temporal resolution ranged between 50-400 mm and 2-500 ms, and the computational speed was between 1/10,000 to 5 times faster than real-time.","The simulation-to-reality gap was found to be around 10% and exhibited a weak dependence on the level of fidelity, i.e. accessible with real-time simulation and faster.","Furthermore, the sensitivity of an optimized force feedback controller under transfer between different simulation domains was investigated.","The domain bias was observed to cause a performance reduction of 5% despite the domain gap being about 15%."],"url":"http://arxiv.org/abs/2310.05765v1"}
{"created":"2023-10-09 14:45:33","title":"Harmonic Self-Conditioned Flow Matching for Multi-Ligand Docking and Binding Site Design","abstract":"A significant amount of protein function requires binding small molecules, including enzymatic catalysis. As such, designing binding pockets for small molecules has several impactful applications ranging from drug synthesis to energy storage. Towards this goal, we first develop HarmonicFlow, an improved generative process over 3D protein-ligand binding structures based on our self-conditioned flow matching objective. FlowSite extends this flow model to jointly generate a protein pocket's discrete residue types and the molecule's binding 3D structure. We show that HarmonicFlow improves upon the state-of-the-art generative processes for docking in simplicity, generality, and performance. Enabled by this structure modeling, FlowSite designs binding sites substantially better than baseline approaches and provides the first general solution for binding site design.","sentences":["A significant amount of protein function requires binding small molecules, including enzymatic catalysis.","As such, designing binding pockets for small molecules has several impactful applications ranging from drug synthesis to energy storage.","Towards this goal, we first develop HarmonicFlow, an improved generative process over 3D protein-ligand binding structures based on our self-conditioned flow matching objective.","FlowSite extends this flow model to jointly generate a protein pocket's discrete residue types and the molecule's binding 3D structure.","We show that HarmonicFlow improves upon the state-of-the-art generative processes for docking in simplicity, generality, and performance.","Enabled by this structure modeling, FlowSite designs binding sites substantially better than baseline approaches and provides the first general solution for binding site design."],"url":"http://arxiv.org/abs/2310.05764v1"}
{"created":"2023-10-09 14:44:01","title":"3D tomatoes' localisation with monocular cameras using histogram filters","abstract":"Performing tasks in agriculture, such as fruit monitoring or harvesting, requires perceiving the objects' spatial position. RGB-D cameras are limited under open-field environments due to lightning interferences. Therefore, in this study, we approach the use of Histogram Filters (Bayesian Discrete Filters) to estimate the position of tomatoes in the tomato plant. Two kernel filters were studied: the square kernel and the Gaussian kernel. The implemented algorithm was essayed in simulation, with and without Gaussian noise and random noise, and in a testbed at laboratory conditions. The algorithm reported a mean absolute error lower than 10 mm in simulation and 20 mm in the testbed at laboratory conditions with an assessing distance of about 0.5 m. So, the results are viable for real environments and should be improved at closer distances.","sentences":["Performing tasks in agriculture, such as fruit monitoring or harvesting, requires perceiving the objects' spatial position.","RGB-D cameras are limited under open-field environments due to lightning interferences.","Therefore, in this study, we approach the use of Histogram Filters (Bayesian Discrete Filters) to estimate the position of tomatoes in the tomato plant.","Two kernel filters were studied: the square kernel and the Gaussian kernel.","The implemented algorithm was essayed in simulation, with and without Gaussian noise and random noise, and in a testbed at laboratory conditions.","The algorithm reported a mean absolute error lower than 10 mm in simulation and 20 mm in the testbed at laboratory conditions with an assessing distance of about 0.5 m. So, the results are viable for real environments and should be improved at closer distances."],"url":"http://arxiv.org/abs/2310.05762v1"}
{"created":"2023-10-09 14:33:32","title":"Nonlinear Correct and Smooth for Semi-Supervised Learning","abstract":"Graph-based semi-supervised learning (GSSL) has been used successfully in various applications. Existing methods leverage the graph structure and labeled samples for classification. Label Propagation (LP) and Graph Neural Networks (GNNs) both iteratively pass messages on graphs, where LP propagates node labels through edges and GNN aggregates node features from the neighborhood. Recently, combining LP and GNN has led to improved performance. However, utilizing labels and features jointly in higher-order graphs has not been explored. Therefore, we propose Nonlinear Correct and Smooth (NLCS), which improves the existing post-processing approach by incorporating non-linearity and higher-order representation into the residual propagation to handle intricate node relationships effectively. Systematic evaluations show that our method achieves remarkable average improvements of 13.71% over base prediction and 2.16% over the state-of-the-art post-processing method on six commonly used datasets. Comparisons and analyses show our method effectively utilizes labels and features jointly in higher-order graphs to resolve challenging graph relationships.","sentences":["Graph-based semi-supervised learning (GSSL) has been used successfully in various applications.","Existing methods leverage the graph structure and labeled samples for classification.","Label Propagation (LP) and Graph Neural Networks (GNNs) both iteratively pass messages on graphs, where LP propagates node labels through edges and GNN aggregates node features from the neighborhood.","Recently, combining LP and GNN has led to improved performance.","However, utilizing labels and features jointly in higher-order graphs has not been explored.","Therefore, we propose Nonlinear Correct and Smooth (NLCS), which improves the existing post-processing approach by incorporating non-linearity and higher-order representation into the residual propagation to handle intricate node relationships effectively.","Systematic evaluations show that our method achieves remarkable average improvements of 13.71% over base prediction and 2.16% over the state-of-the-art post-processing method on six commonly used datasets.","Comparisons and analyses show our method effectively utilizes labels and features jointly in higher-order graphs to resolve challenging graph relationships."],"url":"http://arxiv.org/abs/2310.05757v1"}
{"created":"2023-10-09 14:31:03","title":"Deep Concept Removal","abstract":"We address the problem of concept removal in deep neural networks, aiming to learn representations that do not encode certain specified concepts (e.g., gender etc.) We propose a novel method based on adversarial linear classifiers trained on a concept dataset, which helps to remove the targeted attribute while maintaining model performance. Our approach Deep Concept Removal incorporates adversarial probing classifiers at various layers of the network, effectively addressing concept entanglement and improving out-of-distribution generalization. We also introduce an implicit gradient-based technique to tackle the challenges associated with adversarial training using linear classifiers. We evaluate the ability to remove a concept on a set of popular distributionally robust optimization (DRO) benchmarks with spurious correlations, as well as out-of-distribution (OOD) generalization tasks.","sentences":["We address the problem of concept removal in deep neural networks, aiming to learn representations that do not encode certain specified concepts (e.g., gender etc.)","We propose a novel method based on adversarial linear classifiers trained on a concept dataset, which helps to remove the targeted attribute while maintaining model performance.","Our approach Deep Concept Removal incorporates adversarial probing classifiers at various layers of the network, effectively addressing concept entanglement and improving out-of-distribution generalization.","We also introduce an implicit gradient-based technique to tackle the challenges associated with adversarial training using linear classifiers.","We evaluate the ability to remove a concept on a set of popular distributionally robust optimization (DRO) benchmarks with spurious correlations, as well as out-of-distribution (OOD) generalization tasks."],"url":"http://arxiv.org/abs/2310.05755v1"}
{"created":"2023-10-09 14:30:10","title":"Unleashing the power of Neural Collapse for Transferability Estimation","abstract":"Transferability estimation aims to provide heuristics for quantifying how suitable a pre-trained model is for a specific downstream task, without fine-tuning them all. Prior studies have revealed that well-trained models exhibit the phenomenon of Neural Collapse. Based on a widely used neural collapse metric in existing literature, we observe a strong correlation between the neural collapse of pre-trained models and their corresponding fine-tuned models. Inspired by this observation, we propose a novel method termed Fair Collapse (FaCe) for transferability estimation by comprehensively measuring the degree of neural collapse in the pre-trained model. Typically, FaCe comprises two different terms: the variance collapse term, which assesses the class separation and within-class compactness, and the class fairness term, which quantifies the fairness of the pre-trained model towards each class. We investigate FaCe on a variety of pre-trained classification models across different network architectures, source datasets, and training loss functions. Results show that FaCe yields state-of-the-art performance on different tasks including image classification, semantic segmentation, and text classification, which demonstrate the effectiveness and generalization of our method.","sentences":["Transferability estimation aims to provide heuristics for quantifying how suitable a pre-trained model is for a specific downstream task, without fine-tuning them all.","Prior studies have revealed that well-trained models exhibit the phenomenon of Neural Collapse.","Based on a widely used neural collapse metric in existing literature, we observe a strong correlation between the neural collapse of pre-trained models and their corresponding fine-tuned models.","Inspired by this observation, we propose a novel method termed Fair Collapse (FaCe) for transferability estimation by comprehensively measuring the degree of neural collapse in the pre-trained model.","Typically, FaCe comprises two different terms: the variance collapse term, which assesses the class separation and within-class compactness, and the class fairness term, which quantifies the fairness of the pre-trained model towards each class.","We investigate FaCe on a variety of pre-trained classification models across different network architectures, source datasets, and training loss functions.","Results show that FaCe yields state-of-the-art performance on different tasks including image classification, semantic segmentation, and text classification, which demonstrate the effectiveness and generalization of our method."],"url":"http://arxiv.org/abs/2310.05754v1"}
{"created":"2023-10-09 14:30:06","title":"Large-Scale OD Matrix Estimation with A Deep Learning Method","abstract":"The estimation of origin-destination (OD) matrices is a crucial aspect of Intelligent Transport Systems (ITS). It involves adjusting an initial OD matrix by regressing the current observations like traffic counts of road sections (e.g., using least squares). However, the OD estimation problem lacks sufficient constraints and is mathematically underdetermined. To alleviate this problem, some researchers incorporate a prior OD matrix as a target in the regression to provide more structural constraints. However, this approach is highly dependent on the existing prior matrix, which may be outdated. Others add structural constraints through sensor data, such as vehicle trajectory and speed, which can reflect more current structural constraints in real-time. Our proposed method integrates deep learning and numerical optimization algorithms to infer matrix structure and guide numerical optimization. This approach combines the advantages of both deep learning and numerical optimization algorithms. The neural network(NN) learns to infer structural constraints from probe traffic flows, eliminating dependence on prior information and providing real-time performance. Additionally, due to the generalization capability of NN, this method is economical in engineering. We conducted tests to demonstrate the good generalization performance of our method on a large-scale synthetic dataset. Subsequently, we verified the stability of our method on real traffic data. Our experiments provided confirmation of the benefits of combining NN and numerical optimization.","sentences":["The estimation of origin-destination (OD) matrices is a crucial aspect of Intelligent Transport Systems (ITS).","It involves adjusting an initial OD matrix by regressing the current observations like traffic counts of road sections (e.g., using least squares).","However, the OD estimation problem lacks sufficient constraints and is mathematically underdetermined.","To alleviate this problem, some researchers incorporate a prior OD matrix as a target in the regression to provide more structural constraints.","However, this approach is highly dependent on the existing prior matrix, which may be outdated.","Others add structural constraints through sensor data, such as vehicle trajectory and speed, which can reflect more current structural constraints in real-time.","Our proposed method integrates deep learning and numerical optimization algorithms to infer matrix structure and guide numerical optimization.","This approach combines the advantages of both deep learning and numerical optimization algorithms.","The neural network(NN) learns to infer structural constraints from probe traffic flows, eliminating dependence on prior information and providing real-time performance.","Additionally, due to the generalization capability of NN, this method is economical in engineering.","We conducted tests to demonstrate the good generalization performance of our method on a large-scale synthetic dataset.","Subsequently, we verified the stability of our method on real traffic data.","Our experiments provided confirmation of the benefits of combining NN and numerical optimization."],"url":"http://arxiv.org/abs/2310.05753v1"}
{"created":"2023-10-09 14:29:20","title":"The Gulf of Interpretation: From Chart to Message and Back Again","abstract":"Charts are used to communicate data visually, but designing an effective chart that a broad set of people can understand is challenging. Usually, we do not know whether a chart's intended message aligns with the message readers perceive. In this mixed-methods study, we investigate how data journalists encode data and how a broad audience engages with, experiences, and understands these data visualizations. We conducted a series of workshops and interviews with school students, university students, job seekers, designers, and senior citizens to collect perceived messages and subjective feedback on a sample of eight real-world charts. We analyzed these messages and compared them to the intended message of the chart producer. Four of the collected messages from consumers were then provided to data journalists (including the ones that created the original charts) as a starting point to re-design the charts accordingly. The results from our work underline the difficulty of complex charts such as stacked bar charts and Sankey diagrams. Consumers are often overwhelmed with the amount of data provided and are easily confused with terms (as text) not well known. Chart producers tend to be faithful with data but are willing to abstract further when asked to transport particular messages visually. There are strong conventions on how to visually encode particular information that might not be to the benefit of many consumers.","sentences":["Charts are used to communicate data visually, but designing an effective chart that a broad set of people can understand is challenging.","Usually, we do not know whether a chart's intended message aligns with the message readers perceive.","In this mixed-methods study, we investigate how data journalists encode data and how a broad audience engages with, experiences, and understands these data visualizations.","We conducted a series of workshops and interviews with school students, university students, job seekers, designers, and senior citizens to collect perceived messages and subjective feedback on a sample of eight real-world charts.","We analyzed these messages and compared them to the intended message of the chart producer.","Four of the collected messages from consumers were then provided to data journalists (including the ones that created the original charts) as a starting point to re-design the charts accordingly.","The results from our work underline the difficulty of complex charts such as stacked bar charts and Sankey diagrams.","Consumers are often overwhelmed with the amount of data provided and are easily confused with terms (as text) not well known.","Chart producers tend to be faithful with data but are willing to abstract further when asked to transport particular messages visually.","There are strong conventions on how to visually encode particular information that might not be to the benefit of many consumers."],"url":"http://arxiv.org/abs/2310.05752v1"}
{"created":"2023-10-09 14:29:00","title":"A Review of the Ethics of Artificial Intelligence and its Applications in the United States","abstract":"This study is focused on the ethics of Artificial Intelligence and its application in the United States, the paper highlights the impact AI has in every sector of the US economy and multiple facets of the technological space and the resultant effect on entities spanning businesses, government, academia, and civil society. There is a need for ethical considerations as these entities are beginning to depend on AI for delivering various crucial tasks, which immensely influence their operations, decision-making, and interactions with each other. The adoption of ethical principles, guidelines, and standards of work is therefore required throughout the entire process of AI development, deployment, and usage to ensure responsible and ethical AI practices. Our discussion explores eleven fundamental 'ethical principles' structured as overarching themes. These encompass Transparency, Justice, Fairness, Equity, Non- Maleficence, Responsibility, Accountability, Privacy, Beneficence, Freedom, Autonomy, Trust, Dignity, Sustainability, and Solidarity. These principles collectively serve as a guiding framework, directing the ethical path for the responsible development, deployment, and utilization of artificial intelligence (AI) technologies across diverse sectors and entities within the United States. The paper also discusses the revolutionary impact of AI applications, such as Machine Learning, and explores various approaches used to implement AI ethics. This examination is crucial to address the growing concerns surrounding the inherent risks associated with the widespread use of artificial intelligence.","sentences":["This study is focused on the ethics of Artificial Intelligence and its application in the United States, the paper highlights the impact AI has in every sector of the US economy and multiple facets of the technological space and the resultant effect on entities spanning businesses, government, academia, and civil society.","There is a need for ethical considerations as these entities are beginning to depend on AI for delivering various crucial tasks, which immensely influence their operations, decision-making, and interactions with each other.","The adoption of ethical principles, guidelines, and standards of work is therefore required throughout the entire process of AI development, deployment, and usage to ensure responsible and ethical AI practices.","Our discussion explores eleven fundamental 'ethical principles' structured as overarching themes.","These encompass Transparency, Justice, Fairness, Equity, Non- Maleficence, Responsibility, Accountability, Privacy, Beneficence, Freedom, Autonomy, Trust, Dignity, Sustainability, and Solidarity.","These principles collectively serve as a guiding framework, directing the ethical path for the responsible development, deployment, and utilization of artificial intelligence (AI) technologies across diverse sectors and entities within the United States.","The paper also discusses the revolutionary impact of AI applications, such as Machine Learning, and explores various approaches used to implement AI ethics.","This examination is crucial to address the growing concerns surrounding the inherent risks associated with the widespread use of artificial intelligence."],"url":"http://arxiv.org/abs/2310.05751v1"}
{"created":"2023-10-09 14:22:09","title":"Put Your Money Where Your Mouth Is: Evaluating Strategic Planning and Execution of LLM Agents in an Auction Arena","abstract":"Can Large Language Models (LLMs) simulate human behavior in complex environments? LLMs have recently been shown to exhibit advanced reasoning skills but much of NLP evaluation still relies on static benchmarks. Answering this requires evaluation environments that probe strategic reasoning in competitive, dynamic scenarios that involve long-term planning. We introduce AucArena, a novel simulation environment for evaluating LLMs within auctions, a setting chosen for being highly unpredictable and involving many skills related to resource and risk management, while also being easy to evaluate. We conduct several controlled simulations using state-of-the-art LLMs as bidding agents. We find that through simple prompting, LLMs do indeed demonstrate many of the skills needed for effectively engaging in auctions (e.g., managing budget, adhering to long-term goals and priorities), skills that we find can be sharpened by explicitly encouraging models to be adaptive and observe strategies in past auctions. These results are significant as they show the potential of using LLM agents to model intricate social dynamics, especially in competitive settings. However, we also observe considerable variability in the capabilities of individual LLMs. Notably, even our most advanced models (GPT-4) are occasionally surpassed by heuristic baselines and human agents, highlighting the potential for further improvements in the design of LLM agents and the important role that our simulation environment can play in further testing and refining agent architectures.","sentences":["Can Large Language Models (LLMs) simulate human behavior in complex environments?","LLMs have recently been shown to exhibit advanced reasoning skills but much of NLP evaluation still relies on static benchmarks.","Answering this requires evaluation environments that probe strategic reasoning in competitive, dynamic scenarios that involve long-term planning.","We introduce AucArena, a novel simulation environment for evaluating LLMs within auctions, a setting chosen for being highly unpredictable and involving many skills related to resource and risk management, while also being easy to evaluate.","We conduct several controlled simulations using state-of-the-art LLMs as bidding agents.","We find that through simple prompting, LLMs do indeed demonstrate many of the skills needed for effectively engaging in auctions (e.g., managing budget, adhering to long-term goals and priorities), skills that we find can be sharpened by explicitly encouraging models to be adaptive and observe strategies in past auctions.","These results are significant as they show the potential of using LLM agents to model intricate social dynamics, especially in competitive settings.","However, we also observe considerable variability in the capabilities of individual LLMs.","Notably, even our most advanced models (GPT-4) are occasionally surpassed by heuristic baselines and human agents, highlighting the potential for further improvements in the design of LLM agents and the important role that our simulation environment can play in further testing and refining agent architectures."],"url":"http://arxiv.org/abs/2310.05746v1"}
{"created":"2023-10-09 14:10:29","title":"Language Model Beats Diffusion -- Tokenizer is Key to Visual Generation","abstract":"While Large Language Models (LLMs) are the dominant models for generative tasks in language, they do not perform as well as diffusion models on image and video generation. To effectively use LLMs for visual generation, one crucial component is the visual tokenizer that maps pixel-space inputs to discrete tokens appropriate for LLM learning. In this paper, we introduce MAGVIT-v2, a video tokenizer designed to generate concise and expressive tokens for both videos and images using a common token vocabulary. Equipped with this new tokenizer, we show that LLMs outperform diffusion models on standard image and video generation benchmarks including ImageNet and Kinetics. In addition, we demonstrate that our tokenizer surpasses the previously top-performing video tokenizer on two more tasks: (1) video compression comparable to the next-generation video codec (VCC) according to human evaluations, and (2) learning effective representations for action recognition tasks.","sentences":["While Large Language Models (LLMs) are the dominant models for generative tasks in language, they do not perform as well as diffusion models on image and video generation.","To effectively use LLMs for visual generation, one crucial component is the visual tokenizer that maps pixel-space inputs to discrete tokens appropriate for LLM learning.","In this paper, we introduce MAGVIT-v2, a video tokenizer designed to generate concise and expressive tokens for both videos and images using a common token vocabulary.","Equipped with this new tokenizer, we show that LLMs outperform diffusion models on standard image and video generation benchmarks including ImageNet and Kinetics.","In addition, we demonstrate that our tokenizer surpasses the previously top-performing video tokenizer on two more tasks: (1) video compression comparable to the next-generation video codec (VCC) according to human evaluations, and (2) learning effective representations for action recognition tasks."],"url":"http://arxiv.org/abs/2310.05737v1"}
{"created":"2023-10-09 14:10:21","title":"LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models","abstract":"Large language models (LLMs) have been applied in various applications due to their astonishing capabilities. With advancements in technologies such as chain-of-thought (CoT) prompting and in-context learning (ICL), the prompts fed to LLMs are becoming increasingly lengthy, even exceeding tens of thousands of tokens. To accelerate model inference and reduce cost, this paper presents LLMLingua, a coarse-to-fine prompt compression method that involves a budget controller to maintain semantic integrity under high compression ratios, a token-level iterative compression algorithm to better model the interdependence between compressed contents, and an instruction tuning based method for distribution alignment between language models. We conduct experiments and analysis over four datasets from different scenarios, i.e., GSM8K, BBH, ShareGPT, and Arxiv-March23; showing that the proposed approach yields state-of-the-art performance and allows for up to 20x compression with little performance loss. Our code is available at https://aka.ms/LLMLingua.","sentences":["Large language models (LLMs) have been applied in various applications due to their astonishing capabilities.","With advancements in technologies such as chain-of-thought (CoT) prompting and in-context learning (ICL), the prompts fed to LLMs are becoming increasingly lengthy, even exceeding tens of thousands of tokens.","To accelerate model inference and reduce cost, this paper presents LLMLingua, a coarse-to-fine prompt compression method that involves a budget controller to maintain semantic integrity under high compression ratios, a token-level iterative compression algorithm to better model the interdependence between compressed contents, and an instruction tuning based method for distribution alignment between language models.","We conduct experiments and analysis over four datasets from different scenarios, i.e., GSM8K, BBH, ShareGPT, and Arxiv-March23; showing that the proposed approach yields state-of-the-art performance and allows for up to 20x compression with little performance loss.","Our code is available at https://aka.ms/LLMLingua."],"url":"http://arxiv.org/abs/2310.05736v1"}
{"created":"2023-10-09 14:05:46","title":"Polyhedral approach to weighted connected matchings in general graphs","abstract":"A connected matching in a graph G consists of a set of pairwise disjoint edges whose covered vertices induce a connected subgraph of G. While finding a connected matching of maximum cardinality is a well-solved problem, it is NP-hard to determine an optimal connected matching in an edge-weighted graph, even in the planar bipartite case. We present two mixed integer programming formulations and a sophisticated branch-and-cut scheme to find weighted connected matchings in general graphs. The formulations explore different polyhedra associated to this problem, including strong valid inequalities both from the matching polytope and from the connected subgraph polytope. We conjecture that one attains a tight approximation of the convex hull of connected matchings using our strongest formulation, and report encouraging computational results over DIMACS Implementation Challenge benchmark instances. The source code of the complete implementation is also made available.","sentences":["A connected matching in a graph G consists of a set of pairwise disjoint edges whose covered vertices induce a connected subgraph of G.","While finding a connected matching of maximum cardinality is a well-solved problem, it is NP-hard to determine an optimal connected matching in an edge-weighted graph, even in the planar bipartite case.","We present two mixed integer programming formulations and a sophisticated branch-and-cut scheme to find weighted connected matchings in general graphs.","The formulations explore different polyhedra associated to this problem, including strong valid inequalities both from the matching polytope and from the connected subgraph polytope.","We conjecture that one attains a tight approximation of the convex hull of connected matchings using our strongest formulation, and report encouraging computational results over DIMACS Implementation Challenge benchmark instances.","The source code of the complete implementation is also made available."],"url":"http://arxiv.org/abs/2310.05733v1"}
{"created":"2023-10-09 14:04:48","title":"Improved Scheduling with a Shared Resource","abstract":"We consider the following shared-resource scheduling problem: Given a set of jobs $J$, for each $j\\in J$ we must schedule a job-specific processing volume of $v_j>0$. A total resource of $1$ is available at any time. Jobs have a resource requirement $r_j\\in[0,1]$, and the resources assigned to them may vary over time. However, assigning them less will cause a proportional slowdown.   We consider two settings. In the first, we seek to minimize the makespan in an online setting: The resource assignment of a job must be fixed before the next job arrives. Here we give an optimal $e/(e-1)$-competitive algorithm with runtime $\\mathcal{O}(n \\log n)$. In the second, we aim to minimize the total completion time. We use a continuous linear programming (CLP) formulation for the fractional total completion time and combine it with a previously known dominance property from malleable job scheduling to obtain a lower bound on the total completion time. We extract structural properties by considering a geometrical representation of a CLP's primal-dual pair. We combine the CLP schedule with a greedy schedule to obtain a $(3/2+\\varepsilon)$-approximation for this setting. This improves upon the so far best-known approximation factor of $2$.","sentences":["We consider the following shared-resource scheduling problem: Given a set of jobs $J$, for each $j\\in J$ we must schedule a job-specific processing volume of $v_j>0$. A total resource of $1$ is available at any time.","Jobs have a resource requirement $r_j\\in[0,1]$, and the resources assigned to them may vary over time.","However, assigning them less will cause a proportional slowdown.   ","We consider two settings.","In the first, we seek to minimize the makespan in an online setting: The resource assignment of a job must be fixed before the next job arrives.","Here we give an optimal $e/(e-1)$-competitive algorithm with runtime $\\mathcal{O}(n \\log n)$. In the second, we aim to minimize the total completion time.","We use a continuous linear programming (CLP) formulation for the fractional total completion time and combine it with a previously known dominance property from malleable job scheduling to obtain a lower bound on the total completion time.","We extract structural properties by considering a geometrical representation of a CLP's primal-dual pair.","We combine the CLP schedule with a greedy schedule to obtain a $(3/2+\\varepsilon)$-approximation for this setting.","This improves upon the so far best-known approximation factor of $2$."],"url":"http://arxiv.org/abs/2310.05732v1"}
{"created":"2023-10-09 14:04:28","title":"A Blockchain-driven Architecture for Usage Control in Solid","abstract":"Decentralization initiatives like Solid enable data owners to control who has access to their data and to stimulate innovation by creating both application and data markets. Once data owners share their data with others, though, it is no longer possible for them to control how their data are used. To address this issue, we propose a usage control architecture to monitor compliance with usage control policies. To this end, our solution relies on blockchain and trusted execution environments. We demonstrate the potential of the architecture by describing the various workflows needed to realize a motivating use case scenario for data markets. Additionally, we discuss the merits of the approach from privacy, security, integrateability, and affordability perspectives.","sentences":["Decentralization initiatives like Solid enable data owners to control who has access to their data and to stimulate innovation by creating both application and data markets.","Once data owners share their data with others, though, it is no longer possible for them to control how their data are used.","To address this issue, we propose a usage control architecture to monitor compliance with usage control policies.","To this end, our solution relies on blockchain and trusted execution environments.","We demonstrate the potential of the architecture by describing the various workflows needed to realize a motivating use case scenario for data markets.","Additionally, we discuss the merits of the approach from privacy, security, integrateability, and affordability perspectives."],"url":"http://arxiv.org/abs/2310.05731v1"}
{"created":"2023-10-09 13:59:13","title":"Hidden Permutations to the Rescue: Multi-Pass Streaming Lower Bounds for Approximate Matchings","abstract":"We prove that any semi-streaming algorithm for $(1-\\epsilon)$-approximation of maximum bipartite matching requires \\[ \\Omega(\\frac{\\log{(1/\\epsilon)}}{{\\log{(1/\\beta)}}}) \\] passes, where $\\beta \\in (0,1)$ is the largest parameter so that an $n$-vertex graph with $n^{\\beta}$ edge-disjoint induced matchings of size $\\Theta(n)$ exist (such graphs are referred to as RS graphs). Currently, it is known that \\[ \\Omega(\\frac{1}{\\log\\log{n}}) \\leq \\beta \\leq 1-\\Theta(\\frac{\\log^*{n}}{{\\log{n}}}) \\] and closing this huge gap between upper and lower bounds has remained a notoriously difficult problem in combinatorics.   Under the plausible hypothesis that $\\beta = \\Omega(1)$, our lower bound result provides the first pass-approximation lower bound for (small) constant approximation of matchings in the semi-streaming model, a longstanding open question in the graph streaming literature.   Our techniques are based on analyzing communication protocols for compressing (hidden) permutations. Prior work in this context relied on reducing such problems to Boolean domain and analyzing them via tools like XOR Lemmas and Fourier analysis on Boolean hypercube. In contrast, our main technical contribution is a hardness amplification result for permutations through concatenation in place of prior XOR Lemmas. This result is proven by analyzing permutations directly via simple tools from group representation theory combined with detailed information-theoretic arguments, and can be of independent interest.","sentences":["We prove that any semi-streaming algorithm for $(1-\\epsilon)$-approximation of maximum bipartite matching requires \\[ \\Omega(\\frac{\\log{(1/\\epsilon)}}{{\\log{(1/\\beta)}}}) \\] passes, where $\\beta \\in (0,1)$ is the largest parameter so that an $n$-vertex graph with $n^{\\beta}$ edge-disjoint induced matchings of size $\\Theta(n)$ exist (such graphs are referred to as RS graphs).","Currently, it is known that \\[ \\Omega(\\frac{1}{\\log\\log{n}})","\\leq \\beta \\leq 1-\\Theta(\\frac{\\log^*{n}}{{\\log{n}}})","\\] and closing this huge gap between upper and lower bounds has remained a notoriously difficult problem in combinatorics.   ","Under the plausible hypothesis that $\\beta = \\Omega(1)$, our lower bound result provides the first pass-approximation lower bound for (small) constant approximation of matchings in the semi-streaming model, a longstanding open question in the graph streaming literature.   ","Our techniques are based on analyzing communication protocols for compressing (hidden) permutations.","Prior work in this context relied on reducing such problems to Boolean domain and analyzing them via tools like XOR Lemmas and Fourier analysis on Boolean hypercube.","In contrast, our main technical contribution is a hardness amplification result for permutations through concatenation in place of prior XOR Lemmas.","This result is proven by analyzing permutations directly via simple tools from group representation theory combined with detailed information-theoretic arguments, and can be of independent interest."],"url":"http://arxiv.org/abs/2310.05728v1"}
{"created":"2023-10-09 13:55:45","title":"The Program Testing Ability of Large Language Models for Code","abstract":"Recent development of large language models (LLMs) for code like CodeX and CodeT5+ demonstrates tremendous promise in achieving code intelligence. Their ability of synthesizing code that completes a program for performing a pre-defined task has been intensively tested and verified on benchmark datasets including HumanEval and MBPP. Yet, evaluation of these LLMs from more perspectives (than just program synthesis) is also anticipated, considering their broad scope of applications in software engineering. In this paper, we explore the ability of LLMs for testing programs/code. By performing thorough analyses of recent LLMs for code in program testing, we show a series of intriguing properties of these models and demonstrate how program testing ability of LLMs can be improved. Following recent work which utilizes generated test cases to enhance program synthesis, we further leverage our findings in improving the quality of the synthesized programs and show +11.77% and +4.22% higher code pass rates on HumanEval+ comparing with the GPT-3.5-turbo baseline and the recent state-of-the-art, respectively.","sentences":["Recent development of large language models (LLMs) for code like CodeX and CodeT5+ demonstrates tremendous promise in achieving code intelligence.","Their ability of synthesizing code that completes a program for performing a pre-defined task has been intensively tested and verified on benchmark datasets including HumanEval and MBPP.","Yet, evaluation of these LLMs from more perspectives (than just program synthesis) is also anticipated, considering their broad scope of applications in software engineering.","In this paper, we explore the ability of LLMs for testing programs/code.","By performing thorough analyses of recent LLMs for code in program testing, we show a series of intriguing properties of these models and demonstrate how program testing ability of LLMs can be improved.","Following recent work which utilizes generated test cases to enhance program synthesis, we further leverage our findings in improving the quality of the synthesized programs and show +11.77% and +4.22% higher code pass rates on HumanEval+ comparing with the GPT-3.5-turbo baseline and the recent state-of-the-art, respectively."],"url":"http://arxiv.org/abs/2310.05727v1"}
{"created":"2023-10-09 13:47:05","title":"Planning to Go Out-of-Distribution in Offline-to-Online Reinforcement Learning","abstract":"Offline pretraining with a static dataset followed by online fine-tuning (offline-to-online, or OtO) is a paradigm that is well matched to a real-world RL deployment process: in few real settings would one deploy an offline policy with no test runs and tuning. In this scenario, we aim to find the best-performing policy within a limited budget of online interactions. Previous work in the OtO setting has focused on correcting for bias introduced by the policy-constraint mechanisms of offline RL algorithms. Such constraints keep the learned policy close to the behavior policy that collected the dataset, but this unnecessarily limits policy performance if the behavior policy is far from optimal. Instead, we forgo policy constraints and frame OtO RL as an exploration problem: we must maximize the benefit of the online data-collection. We study major online RL exploration paradigms, adapting them to work well with the OtO setting. These adapted methods contribute several strong baselines. Also, we introduce an algorithm for planning to go out of distribution (PTGOOD), which targets online exploration in relatively high-reward regions of the state-action space unlikely to be visited by the behavior policy. By leveraging concepts from the Conditional Entropy Bottleneck, PTGOOD encourages data collected online to provide new information relevant to improving the final deployment policy. In that way the limited interaction budget is used effectively. We show that PTGOOD significantly improves agent returns during online fine-tuning and finds the optimal policy in as few as 10k online steps in Walker and in as few as 50k in complex control tasks like Humanoid. Also, we find that PTGOOD avoids the suboptimal policy convergence that many of our baselines exhibit in several environments.","sentences":["Offline pretraining with a static dataset followed by online fine-tuning (offline-to-online, or OtO) is a paradigm that is well matched to a real-world RL deployment process: in few real settings would one deploy an offline policy with no test runs and tuning.","In this scenario, we aim to find the best-performing policy within a limited budget of online interactions.","Previous work in the OtO setting has focused on correcting for bias introduced by the policy-constraint mechanisms of offline RL algorithms.","Such constraints keep the learned policy close to the behavior policy that collected the dataset, but this unnecessarily limits policy performance if the behavior policy is far from optimal.","Instead, we forgo policy constraints and frame OtO RL as an exploration problem: we must maximize the benefit of the online data-collection.","We study major online RL exploration paradigms, adapting them to work well with the OtO setting.","These adapted methods contribute several strong baselines.","Also, we introduce an algorithm for planning to go out of distribution (PTGOOD), which targets online exploration in relatively high-reward regions of the state-action space unlikely to be visited by the behavior policy.","By leveraging concepts from the Conditional Entropy Bottleneck, PTGOOD encourages data collected online to provide new information relevant to improving the final deployment policy.","In that way the limited interaction budget is used effectively.","We show that PTGOOD significantly improves agent returns during online fine-tuning and finds the optimal policy in as few as 10k online steps in Walker and in as few as 50k in complex control tasks like Humanoid.","Also, we find that PTGOOD avoids the suboptimal policy convergence that many of our baselines exhibit in several environments."],"url":"http://arxiv.org/abs/2310.05723v1"}
{"created":"2023-10-09 13:45:21","title":"HyperLips: Hyper Control Lips with High Resolution Decoder for Talking Face Generation","abstract":"Talking face generation has a wide range of potential applications in the field of virtual digital humans. However, rendering high-fidelity facial video while ensuring lip synchronization is still a challenge for existing audio-driven talking face generation approaches. To address this issue, we propose HyperLips, a two-stage framework consisting of a hypernetwork for controlling lips and a high-resolution decoder for rendering high-fidelity faces.In the first stage, we construct a base face generation network that uses the hypernetwork to control the encoding latent code of the visual face information over audio. First, FaceEncoder is used to obtain latent code by extracting features from the visual face information taken from the video source containing the face frame.Then, HyperConv, which weighting parameters are updated by HyperNet with the audio features as input, will modify the latent code to synchronize the lip movement with the audio. Finally, FaceDecoder will decode the modified and synchronized latent code into visual face content. In the second stage, we obtain higher quality face videos through a high-resolution decoder. To further improve the quality of face generation, we trained a high-resolution decoder, HRDecoder, using face images and detected sketches generated from the first stage as input.Extensive quantitative and qualitative experiments show that our method outperforms state-of-the-art work with more realistic, high-fidelity, and lip synchronization. Project page: https://semchan.github.io/HyperLips/","sentences":["Talking face generation has a wide range of potential applications in the field of virtual digital humans.","However, rendering high-fidelity facial video while ensuring lip synchronization is still a challenge for existing audio-driven talking face generation approaches.","To address this issue, we propose HyperLips, a two-stage framework consisting of a hypernetwork for controlling lips and a high-resolution decoder for rendering high-fidelity faces.","In the first stage, we construct a base face generation network that uses the hypernetwork to control the encoding latent code of the visual face information over audio.","First, FaceEncoder is used to obtain latent code by extracting features from the visual face information taken from the video source containing the face frame.","Then, HyperConv, which weighting parameters are updated by HyperNet with the audio features as input, will modify the latent code to synchronize the lip movement with the audio.","Finally, FaceDecoder will decode the modified and synchronized latent code into visual face content.","In the second stage, we obtain higher quality face videos through a high-resolution decoder.","To further improve the quality of face generation, we trained a high-resolution decoder, HRDecoder, using face images and detected sketches generated from the first stage as input.","Extensive quantitative and qualitative experiments show that our method outperforms state-of-the-art work with more realistic, high-fidelity, and lip synchronization.","Project page: https://semchan.github.io/HyperLips/"],"url":"http://arxiv.org/abs/2310.05720v1"}
{"created":"2023-10-09 13:40:31","title":"Transformer Fusion with Optimal Transport","abstract":"Fusion is a technique for merging multiple independently-trained neural networks in order to combine their capabilities. Past attempts have been restricted to the case of fully-connected, convolutional, and residual networks. In this paper, we present a systematic approach for fusing two or more transformer-based networks exploiting Optimal Transport to (soft-)align the various architectural components. We flesh out an abstraction for layer alignment, that can generalize to arbitrary architectures -- in principle -- and we apply this to the key ingredients of Transformers such as multi-head self-attention, layer-normalization, and residual connections, and we discuss how to handle them via various ablation studies. Furthermore, our method allows the fusion of models of different sizes (heterogeneous fusion), providing a new and efficient way for compression of Transformers. The proposed approach is evaluated on both image classification tasks via Vision Transformer and natural language modeling tasks using BERT. Our approach consistently outperforms vanilla fusion, and, after a surprisingly short finetuning, also outperforms the individual converged parent models. In our analysis, we uncover intriguing insights about the significant role of soft alignment in the case of Transformers. Our results showcase the potential of fusing multiple Transformers, thus compounding their expertise, in the budding paradigm of model fusion and recombination.","sentences":["Fusion is a technique for merging multiple independently-trained neural networks in order to combine their capabilities.","Past attempts have been restricted to the case of fully-connected, convolutional, and residual networks.","In this paper, we present a systematic approach for fusing two or more transformer-based networks exploiting Optimal Transport to (soft-)align the various architectural components.","We flesh out an abstraction for layer alignment, that can generalize to arbitrary architectures -- in principle -- and we apply this to the key ingredients of Transformers such as multi-head self-attention, layer-normalization, and residual connections, and we discuss how to handle them via various ablation studies.","Furthermore, our method allows the fusion of models of different sizes (heterogeneous fusion), providing a new and efficient way for compression of Transformers.","The proposed approach is evaluated on both image classification tasks via Vision Transformer and natural language modeling tasks using BERT.","Our approach consistently outperforms vanilla fusion, and, after a surprisingly short finetuning, also outperforms the individual converged parent models.","In our analysis, we uncover intriguing insights about the significant role of soft alignment in the case of Transformers.","Our results showcase the potential of fusing multiple Transformers, thus compounding their expertise, in the budding paradigm of model fusion and recombination."],"url":"http://arxiv.org/abs/2310.05719v1"}
{"created":"2023-10-09 13:39:26","title":"EdVAE: Mitigating Codebook Collapse with Evidential Discrete Variational Autoencoders","abstract":"Codebook collapse is a common problem in training deep generative models with discrete representation spaces like Vector Quantized Variational Autoencoders (VQ-VAEs). We observe that the same problem arises for the alternatively designed discrete variational autoencoders (dVAEs) whose encoder directly learns a distribution over the codebook embeddings to represent the data. We hypothesize that using the softmax function to obtain a probability distribution causes the codebook collapse by assigning overconfident probabilities to the best matching codebook elements. In this paper, we propose a novel way to incorporate evidential deep learning (EDL) instead of softmax to combat the codebook collapse problem of dVAE. We evidentially monitor the significance of attaining the probability distribution over the codebook embeddings, in contrast to softmax usage. Our experiments using various datasets show that our model, called EdVAE, mitigates codebook collapse while improving the reconstruction performance, and enhances the codebook usage compared to dVAE and VQ-VAE based models.","sentences":["Codebook collapse is a common problem in training deep generative models with discrete representation spaces like Vector Quantized Variational Autoencoders (VQ-VAEs).","We observe that the same problem arises for the alternatively designed discrete variational autoencoders (dVAEs) whose encoder directly learns a distribution over the codebook embeddings to represent the data.","We hypothesize that using the softmax function to obtain a probability distribution causes the codebook collapse by assigning overconfident probabilities to the best matching codebook elements.","In this paper, we propose a novel way to incorporate evidential deep learning (EDL) instead of softmax to combat the codebook collapse problem of dVAE.","We evidentially monitor the significance of attaining the probability distribution over the codebook embeddings, in contrast to softmax usage.","Our experiments using various datasets show that our model, called EdVAE, mitigates codebook collapse while improving the reconstruction performance, and enhances the codebook usage compared to dVAE and VQ-VAE based models."],"url":"http://arxiv.org/abs/2310.05718v1"}
{"created":"2023-10-09 13:39:06","title":"STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines","abstract":"In this work, we present STOPNet, a framework for 6-DoF object suction detection on production lines, with a focus on but not limited to transparent objects, which is an important and challenging problem in robotic systems and modern industry. Current methods requiring depth input fail on transparent objects due to depth cameras' deficiency in sensing their geometry, while we proposed a novel framework to reconstruct the scene on the production line depending only on RGB input, based on multiview stereo. Compared to existing works, our method not only reconstructs the whole 3D scene in order to obtain high-quality 6-DoF suction poses in real time but also generalizes to novel environments, novel arrangements and novel objects, including challenging transparent objects, both in simulation and the real world. Extensive experiments in simulation and the real world show that our method significantly surpasses the baselines and has better generalizability, which caters to practical industrial needs.","sentences":["In this work, we present STOPNet, a framework for 6-DoF object suction detection on production lines, with a focus on but not limited to transparent objects, which is an important and challenging problem in robotic systems and modern industry.","Current methods requiring depth input fail on transparent objects due to depth cameras' deficiency in sensing their geometry, while we proposed a novel framework to reconstruct the scene on the production line depending only on RGB input, based on multiview stereo.","Compared to existing works, our method not only reconstructs the whole 3D scene in order to obtain high-quality 6-DoF suction poses in real time but also generalizes to novel environments, novel arrangements and novel objects, including challenging transparent objects, both in simulation and the real world.","Extensive experiments in simulation and the real world show that our method significantly surpasses the baselines and has better generalizability, which caters to practical industrial needs."],"url":"http://arxiv.org/abs/2310.05717v1"}
{"created":"2023-10-09 13:38:03","title":"DecAP: Decaying Action Priors for Accelerated Learning of Torque-Based Legged Locomotion Policies","abstract":"Optimal Control for legged robots has gone through a paradigm shift from position-based to torque-based control, owing to the latter's compliant and robust nature. In parallel to this shift, the community has also turned to Deep Reinforcement Learning (DRL) as a promising approach to directly learn locomotion policies for complex real-life tasks. However, most end-to-end DRL approaches still operate in position space, mainly because learning in torque space is often sample-inefficient and does not consistently converge to natural gaits. To address these challenges, we introduce Decaying Action Priors (DecAP), a novel three-stage framework to learn and deploy torque policies for legged locomotion. In the first stage, we generate our own imitation data by training a position policy, eliminating the need for expert knowledge in designing optimal controllers. The second stage incorporates decaying action priors to enhance the exploration of torque-based policies aided by imitation rewards. We show that our approach consistently outperforms imitation learning alone and is significantly robust to the scaling of these rewards. Finally, our third stage facilitates safe sim-to-real transfer by directly deploying our learned torques, alongside low-gain PID control from our trained position policy. We demonstrate the generality of our approach by training torque-based locomotion policies for a biped, a quadruped, and a hexapod robot in simulation, and experimentally demonstrate our learned policies on a quadruped (Unitree Go1).","sentences":["Optimal Control for legged robots has gone through a paradigm shift from position-based to torque-based control, owing to the latter's compliant and robust nature.","In parallel to this shift, the community has also turned to Deep Reinforcement Learning (DRL) as a promising approach to directly learn locomotion policies for complex real-life tasks.","However, most end-to-end DRL approaches still operate in position space, mainly because learning in torque space is often sample-inefficient and does not consistently converge to natural gaits.","To address these challenges, we introduce Decaying Action Priors (DecAP), a novel three-stage framework to learn and deploy torque policies for legged locomotion.","In the first stage, we generate our own imitation data by training a position policy, eliminating the need for expert knowledge in designing optimal controllers.","The second stage incorporates decaying action priors to enhance the exploration of torque-based policies aided by imitation rewards.","We show that our approach consistently outperforms imitation learning alone and is significantly robust to the scaling of these rewards.","Finally, our third stage facilitates safe sim-to-real transfer by directly deploying our learned torques, alongside low-gain PID control from our trained position policy.","We demonstrate the generality of our approach by training torque-based locomotion policies for a biped, a quadruped, and a hexapod robot in simulation, and experimentally demonstrate our learned policies on a quadruped (Unitree Go1)."],"url":"http://arxiv.org/abs/2310.05714v1"}
{"created":"2023-10-09 13:35:28","title":"Imitator Learning: Achieve Out-of-the-Box Imitation Ability in Variable Environments","abstract":"Imitation learning (IL) enables agents to mimic expert behaviors. Most previous IL techniques focus on precisely imitating one policy through mass demonstrations. However, in many applications, what humans require is the ability to perform various tasks directly through a few demonstrations of corresponding tasks, where the agent would meet many unexpected changes when deployed. In this scenario, the agent is expected to not only imitate the demonstration but also adapt to unforeseen environmental changes.   This motivates us to propose a new topic called imitator learning (ItorL), which aims to derive an imitator module that can on-the-fly reconstruct the imitation policies based on very limited expert demonstrations for different unseen tasks, without any extra adjustment. In this work, we focus on imitator learning based on only one expert demonstration. To solve ItorL, we propose Demo-Attention Actor-Critic (DAAC), which integrates IL into a reinforcement-learning paradigm that can regularize policies' behaviors in unexpected situations. Besides, for autonomous imitation policy building, we design a demonstration-based attention architecture for imitator policy that can effectively output imitated actions by adaptively tracing the suitable states in demonstrations. We develop a new navigation benchmark and a robot environment for \\topic~and show that DAAC~outperforms previous imitation methods \\textit{with large margins} both on seen and unseen tasks.","sentences":["Imitation learning (IL) enables agents to mimic expert behaviors.","Most previous IL techniques focus on precisely imitating one policy through mass demonstrations.","However, in many applications, what humans require is the ability to perform various tasks directly through a few demonstrations of corresponding tasks, where the agent would meet many unexpected changes when deployed.","In this scenario, the agent is expected to not only imitate the demonstration but also adapt to unforeseen environmental changes.   ","This motivates us to propose a new topic called imitator learning (ItorL), which aims to derive an imitator module that can on-the-fly reconstruct the imitation policies based on very limited expert demonstrations for different unseen tasks, without any extra adjustment.","In this work, we focus on imitator learning based on only one expert demonstration.","To solve ItorL, we propose Demo-Attention Actor-Critic (DAAC), which integrates IL into a reinforcement-learning paradigm that can regularize policies' behaviors in unexpected situations.","Besides, for autonomous imitation policy building, we design a demonstration-based attention architecture for imitator policy that can effectively output imitated actions by adaptively tracing the suitable states in demonstrations.","We develop a new navigation benchmark and a robot environment for \\topic~and show that DAAC~outperforms previous imitation methods \\textit{with large margins} both on seen and unseen tasks."],"url":"http://arxiv.org/abs/2310.05712v1"}
