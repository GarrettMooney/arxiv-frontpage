{"created":"2023-09-19 17:59:54","title":"SlimPajama-DC: Understanding Data Combinations for LLM Training","abstract":"This paper aims to understand the impacts of various data combinations (e.g., web text, wikipedia, github, books) on the training of large language models using SlimPajama. SlimPajama is a rigorously deduplicated, multi-source dataset, which has been refined and further deduplicated to 627B tokens from the extensive 1.2T tokens RedPajama dataset contributed by Together. We've termed our research as SlimPajama-DC, an empirical analysis designed to uncover fundamental characteristics and best practices associated with employing SlimPajama in the training of large language models. During our research with SlimPajama, two pivotal observations emerged: (1) Global deduplication vs. local deduplication. We analyze and discuss how global (across different sources of datasets) and local (within the single source of dataset) deduplications affect the performance of trained models. (2) Proportions of high-quality/highly-deduplicated multi-source datasets in the combination. To study this, we construct six configurations of SlimPajama dataset and train individual ones using 1.3B Cerebras-GPT model with Alibi and SwiGLU. Our best configuration outperforms the 1.3B model trained on RedPajama using the same number of training tokens by a significant margin. All our 1.3B models are trained on Cerebras 16$\\times$ CS-2 cluster with a total of 80 PFLOP/s in bf16 mixed precision. We further extend our discoveries (such as increasing data diversity is crucial after global deduplication) on a 7B model with large batch-size training. Our models and the separate SlimPajama-DC datasets are available at: https://huggingface.co/MBZUAI-LLM and https://huggingface.co/datasets/cerebras/SlimPajama-627B.","sentences":["This paper aims to understand the impacts of various data combinations (e.g., web text, wikipedia, github, books) on the training of large language models using SlimPajama.","SlimPajama is a rigorously deduplicated, multi-source dataset, which has been refined and further deduplicated to 627B tokens from the extensive 1.2T tokens RedPajama dataset contributed by Together.","We've termed our research as SlimPajama-DC, an empirical analysis designed to uncover fundamental characteristics and best practices associated with employing SlimPajama in the training of large language models.","During our research with SlimPajama, two pivotal observations emerged: (1) Global deduplication vs. local deduplication.","We analyze and discuss how global (across different sources of datasets) and local (within the single source of dataset) deduplications affect the performance of trained models.","(2) Proportions of high-quality/highly-deduplicated multi-source datasets in the combination.","To study this, we construct six configurations of SlimPajama dataset and train individual ones using 1.3B Cerebras-GPT model with Alibi and SwiGLU.","Our best configuration outperforms the 1.3B model trained on RedPajama using the same number of training tokens by a significant margin.","All our 1.3B models are trained on Cerebras 16$\\times$ CS-2 cluster with a total of 80 PFLOP/s in bf16 mixed precision.","We further extend our discoveries (such as increasing data diversity is crucial after global deduplication) on a 7B model with large batch-size training.","Our models and the separate SlimPajama-DC datasets are available at: https://huggingface.co/MBZUAI-LLM and https://huggingface.co/datasets/cerebras/SlimPajama-627B."],"url":"http://arxiv.org/abs/2309.10818v1"}
{"created":"2023-09-19 17:55:07","title":"Multisource Holography","abstract":"Holographic displays promise several benefits including high quality 3D imagery, accurate accommodation cues, and compact form-factors. However, holography relies on coherent illumination which can create undesirable speckle noise in the final image. Although smooth phase holograms can be speckle-free, their non-uniform eyebox makes them impractical, and speckle mitigation with partially coherent sources also reduces resolution. Averaging sequential frames for speckle reduction requires high speed modulators and consumes temporal bandwidth that may be needed elsewhere in the system.   In this work, we propose multisource holography, a novel architecture that uses an array of sources to suppress speckle in a single frame without sacrificing resolution. By using two spatial light modulators, arranged sequentially, each source in the array can be controlled almost independently to create a version of the target content with different speckle. Speckle is then suppressed when the contributions from the multiple sources are averaged at the image plane. We introduce an algorithm to calculate multisource holograms, analyze the design space, and demonstrate up to a 10 dB increase in peak signal-to-noise ratio compared to an equivalent single source system. Finally, we validate the concept with a benchtop experimental prototype by producing both 2D images and focal stacks with natural defocus cues.","sentences":["Holographic displays promise several benefits including high quality 3D imagery, accurate accommodation cues, and compact form-factors.","However, holography relies on coherent illumination which can create undesirable speckle noise in the final image.","Although smooth phase holograms can be speckle-free, their non-uniform eyebox makes them impractical, and speckle mitigation with partially coherent sources also reduces resolution.","Averaging sequential frames for speckle reduction requires high speed modulators and consumes temporal bandwidth that may be needed elsewhere in the system.   ","In this work, we propose multisource holography, a novel architecture that uses an array of sources to suppress speckle in a single frame without sacrificing resolution.","By using two spatial light modulators, arranged sequentially, each source in the array can be controlled almost independently to create a version of the target content with different speckle.","Speckle is then suppressed when the contributions from the multiple sources are averaged at the image plane.","We introduce an algorithm to calculate multisource holograms, analyze the design space, and demonstrate up to a 10 dB increase in peak signal-to-noise ratio compared to an equivalent single source system.","Finally, we validate the concept with a benchtop experimental prototype by producing both 2D images and focal stacks with natural defocus cues."],"url":"http://arxiv.org/abs/2309.10816v1"}
{"created":"2023-09-19 17:54:22","title":"PanopticNeRF-360: Panoramic 3D-to-2D Label Transfer in Urban Scenes","abstract":"Training perception systems for self-driving cars requires substantial annotations. However, manual labeling in 2D images is highly labor-intensive. While existing datasets provide rich annotations for pre-recorded sequences, they fall short in labeling rarely encountered viewpoints, potentially hampering the generalization ability for perception models. In this paper, we present PanopticNeRF-360, a novel approach that combines coarse 3D annotations with noisy 2D semantic cues to generate consistent panoptic labels and high-quality images from any viewpoint. Our key insight lies in exploiting the complementarity of 3D and 2D priors to mutually enhance geometry and semantics. Specifically, we propose to leverage noisy semantic and instance labels in both 3D and 2D spaces to guide geometry optimization. Simultaneously, the improved geometry assists in filtering noise present in the 3D and 2D annotations by merging them in 3D space via a learned semantic field. To further enhance appearance, we combine MLP and hash grids to yield hybrid scene features, striking a balance between high-frequency appearance and predominantly contiguous semantics. Our experiments demonstrate PanopticNeRF-360's state-of-the-art performance over existing label transfer methods on the challenging urban scenes of the KITTI-360 dataset. Moreover, PanopticNeRF-360 enables omnidirectional rendering of high-fidelity, multi-view and spatiotemporally consistent appearance, semantic and instance labels. We make our code and data available at https://github.com/fuxiao0719/PanopticNeRF","sentences":["Training perception systems for self-driving cars requires substantial annotations.","However, manual labeling in 2D images is highly labor-intensive.","While existing datasets provide rich annotations for pre-recorded sequences, they fall short in labeling rarely encountered viewpoints, potentially hampering the generalization ability for perception models.","In this paper, we present PanopticNeRF-360, a novel approach that combines coarse 3D annotations with noisy 2D semantic cues to generate consistent panoptic labels and high-quality images from any viewpoint.","Our key insight lies in exploiting the complementarity of 3D and 2D priors to mutually enhance geometry and semantics.","Specifically, we propose to leverage noisy semantic and instance labels in both 3D and 2D spaces to guide geometry optimization.","Simultaneously, the improved geometry assists in filtering noise present in the 3D and 2D annotations by merging them in 3D space via a learned semantic field.","To further enhance appearance, we combine MLP and hash grids to yield hybrid scene features, striking a balance between high-frequency appearance and predominantly contiguous semantics.","Our experiments demonstrate PanopticNeRF-360's state-of-the-art performance over existing label transfer methods on the challenging urban scenes of the KITTI-360 dataset.","Moreover, PanopticNeRF-360 enables omnidirectional rendering of high-fidelity, multi-view and spatiotemporally consistent appearance, semantic and instance labels.","We make our code and data available at https://github.com/fuxiao0719/PanopticNeRF"],"url":"http://arxiv.org/abs/2309.10815v1"}
{"created":"2023-09-19 17:54:21","title":"Natural Language Embedded Programs for Hybrid Language Symbolic Reasoning","abstract":"How can we perform computations over natural language representations to solve tasks that require symbolic and numeric reasoning? We propose natural language embedded programs (NLEP) as a unifying framework for addressing math/symbolic reasoning, natural language understanding, and instruction following tasks. Our approach prompts a language model to generate full Python programs that define functions over data structures which contain natural language representations of structured knowledge. A Python interpreter then executes the generated code and prints the output. Despite using a task-general prompt, we find that this approach can improve upon strong baselines across a range of different tasks including math and symbolic reasoning, text classification, question answering, and instruction following. We further find the generated programs are often interpretable and enable post-hoc verification of the intermediate reasoning steps.","sentences":["How can we perform computations over natural language representations to solve tasks that require symbolic and numeric reasoning?","We propose natural language embedded programs (NLEP) as a unifying framework for addressing math/symbolic reasoning, natural language understanding, and instruction following tasks.","Our approach prompts a language model to generate full Python programs that define functions over data structures which contain natural language representations of structured knowledge.","A Python interpreter then executes the generated code and prints the output.","Despite using a task-general prompt, we find that this approach can improve upon strong baselines across a range of different tasks including math and symbolic reasoning, text classification, question answering, and instruction following.","We further find the generated programs are often interpretable and enable post-hoc verification of the intermediate reasoning steps."],"url":"http://arxiv.org/abs/2309.10814v1"}
{"created":"2023-09-19 17:52:50","title":"Modeling interdisciplinary interactions among Physics, Mathematics & Computer Science","abstract":"Interdisciplinarity has over the recent years have gained tremendous importance and has become one of the key ways of doing cutting edge research. In this paper we attempt to model the citation flow across three different fields -- Physics (PHY), Mathematics (MA) and Computer Science (CS). For instance, is there a specific pattern in which these fields cite one another? We carry out experiments on a dataset comprising more than 1.2 million articles taken from these three fields. We quantify the citation interactions among these three fields through temporal bucket signatures. We present numerical models based on variants of the recently proposed relay-linking framework to explain the citation dynamics across the three disciplines. These models make a modest attempt to unfold the underlying principles of how citation links could have been formed across the three fields over time.","sentences":["Interdisciplinarity has over the recent years have gained tremendous importance and has become one of the key ways of doing cutting edge research.","In this paper we attempt to model the citation flow across three different fields -- Physics (PHY), Mathematics (MA) and Computer Science (CS).","For instance, is there a specific pattern in which these fields cite one another?","We carry out experiments on a dataset comprising more than 1.2 million articles taken from these three fields.","We quantify the citation interactions among these three fields through temporal bucket signatures.","We present numerical models based on variants of the recently proposed relay-linking framework to explain the citation dynamics across the three disciplines.","These models make a modest attempt to unfold the underlying principles of how citation links could have been formed across the three fields over time."],"url":"http://arxiv.org/abs/2309.10811v1"}
{"created":"2023-09-19 17:51:33","title":"PGDiff: Guiding Diffusion Models for Versatile Face Restoration via Partial Guidance","abstract":"Exploiting pre-trained diffusion models for restoration has recently become a favored alternative to the traditional task-specific training approach. Previous works have achieved noteworthy success by limiting the solution space using explicit degradation models. However, these methods often fall short when faced with complex degradations as they generally cannot be precisely modeled. In this paper, we propose PGDiff by introducing partial guidance, a fresh perspective that is more adaptable to real-world degradations compared to existing works. Rather than specifically defining the degradation process, our approach models the desired properties, such as image structure and color statistics of high-quality images, and applies this guidance during the reverse diffusion process. These properties are readily available and make no assumptions about the degradation process. When combined with a diffusion prior, this partial guidance can deliver appealing results across a range of restoration tasks. Additionally, PGDiff can be extended to handle composite tasks by consolidating multiple high-quality image properties, achieved by integrating the guidance from respective tasks. Experimental results demonstrate that our method not only outperforms existing diffusion-prior-based approaches but also competes favorably with task-specific models.","sentences":["Exploiting pre-trained diffusion models for restoration has recently become a favored alternative to the traditional task-specific training approach.","Previous works have achieved noteworthy success by limiting the solution space using explicit degradation models.","However, these methods often fall short when faced with complex degradations as they generally cannot be precisely modeled.","In this paper, we propose PGDiff by introducing partial guidance, a fresh perspective that is more adaptable to real-world degradations compared to existing works.","Rather than specifically defining the degradation process, our approach models the desired properties, such as image structure and color statistics of high-quality images, and applies this guidance during the reverse diffusion process.","These properties are readily available and make no assumptions about the degradation process.","When combined with a diffusion prior, this partial guidance can deliver appealing results across a range of restoration tasks.","Additionally, PGDiff can be extended to handle composite tasks by consolidating multiple high-quality image properties, achieved by integrating the guidance from respective tasks.","Experimental results demonstrate that our method not only outperforms existing diffusion-prior-based approaches but also competes favorably with task-specific models."],"url":"http://arxiv.org/abs/2309.10810v1"}
{"created":"2023-09-19 17:50:57","title":"Semantic Text Compression for Classification","abstract":"We study semantic compression for text where meanings contained in the text are conveyed to a source decoder, e.g., for classification. The main motivator to move to such an approach of recovering the meaning without requiring exact reconstruction is the potential resource savings, both in storage and in conveying the information to another node. Towards this end, we propose semantic quantization and compression approaches for text where we utilize sentence embeddings and the semantic distortion metric to preserve the meaning. Our results demonstrate that the proposed semantic approaches result in substantial (orders of magnitude) savings in the required number of bits for message representation at the expense of very modest accuracy loss compared to the semantic agnostic baseline. We compare the results of proposed approaches and observe that resource savings enabled by semantic quantization can be further amplified by semantic clustering. Importantly, we observe the generalizability of the proposed methodology which produces excellent results on many benchmark text classification datasets with a diverse array of contexts.","sentences":["We study semantic compression for text where meanings contained in the text are conveyed to a source decoder, e.g., for classification.","The main motivator to move to such an approach of recovering the meaning without requiring exact reconstruction is the potential resource savings, both in storage and in conveying the information to another node.","Towards this end, we propose semantic quantization and compression approaches for text where we utilize sentence embeddings and the semantic distortion metric to preserve the meaning.","Our results demonstrate that the proposed semantic approaches result in substantial (orders of magnitude) savings in the required number of bits for message representation at the expense of very modest accuracy loss compared to the semantic agnostic baseline.","We compare the results of proposed approaches and observe that resource savings enabled by semantic quantization can be further amplified by semantic clustering.","Importantly, we observe the generalizability of the proposed methodology which produces excellent results on many benchmark text classification datasets with a diverse array of contexts."],"url":"http://arxiv.org/abs/2309.10809v1"}
{"created":"2023-09-19 17:50:27","title":"AI Foundation Models for Weather and Climate: Applications, Design, and Implementation","abstract":"Machine learning and deep learning methods have been widely explored in understanding the chaotic behavior of the atmosphere and furthering weather forecasting. There has been increasing interest from technology companies, government institutions, and meteorological agencies in building digital twins of the Earth. Recent approaches using transformers, physics-informed machine learning, and graph neural networks have demonstrated state-of-the-art performance on relatively narrow spatiotemporal scales and specific tasks. With the recent success of generative artificial intelligence (AI) using pre-trained transformers for language modeling and vision with prompt engineering and fine-tuning, we are now moving towards generalizable AI. In particular, we are witnessing the rise of AI foundation models that can perform competitively on multiple domain-specific downstream tasks. Despite this progress, we are still in the nascent stages of a generalizable AI model for global Earth system models, regional climate models, and mesoscale weather models. Here, we review current state-of-the-art AI approaches, primarily from transformer and operator learning literature in the context of meteorology. We provide our perspective on criteria for success towards a family of foundation models for nowcasting and forecasting weather and climate predictions. We also discuss how such models can perform competitively on downstream tasks such as downscaling (super-resolution), identifying conditions conducive to the occurrence of wildfires, and predicting consequential meteorological phenomena across various spatiotemporal scales such as hurricanes and atmospheric rivers. In particular, we examine current AI methodologies and contend they have matured enough to design and implement a weather foundation model.","sentences":["Machine learning and deep learning methods have been widely explored in understanding the chaotic behavior of the atmosphere and furthering weather forecasting.","There has been increasing interest from technology companies, government institutions, and meteorological agencies in building digital twins of the Earth.","Recent approaches using transformers, physics-informed machine learning, and graph neural networks have demonstrated state-of-the-art performance on relatively narrow spatiotemporal scales and specific tasks.","With the recent success of generative artificial intelligence (AI) using pre-trained transformers for language modeling and vision with prompt engineering and fine-tuning, we are now moving towards generalizable AI.","In particular, we are witnessing the rise of AI foundation models that can perform competitively on multiple domain-specific downstream tasks.","Despite this progress, we are still in the nascent stages of a generalizable AI model for global Earth system models, regional climate models, and mesoscale weather models.","Here, we review current state-of-the-art AI approaches, primarily from transformer and operator learning literature in the context of meteorology.","We provide our perspective on criteria for success towards a family of foundation models for nowcasting and forecasting weather and climate predictions.","We also discuss how such models can perform competitively on downstream tasks such as downscaling (super-resolution), identifying conditions conducive to the occurrence of wildfires, and predicting consequential meteorological phenomena across various spatiotemporal scales such as hurricanes and atmospheric rivers.","In particular, we examine current AI methodologies and contend they have matured enough to design and implement a weather foundation model."],"url":"http://arxiv.org/abs/2309.10808v1"}
{"created":"2023-09-19 17:47:03","title":"Machine Learning-Driven Burrowing with a Snake-Like Robot","abstract":"Subterranean burrowing is inherently difficult for robots because of the high forces experienced as well as the high amount of uncertainty in this domain. Because of the difficulty in modeling forces in granular media, we propose the use of a novel machine-learning control strategy to obtain optimal techniques for vertical self-burrowing. In this paper, we realize a snake-like bio-inspired robot that is equipped with an IMU and two triple-axis magnetometers. Utilizing magnetic field strength as an analog for depth, a novel deep learning architecture was proposed based on sinusoidal and random data in order to obtain a more efficient strategy for vertical self-burrowing. This strategy was able to outperform many other standard burrowing techniques and was able to automatically reach targeted burrowing depths. We hope these results will serve as a proof of concept for how optimization can be used to unlock the secrets of navigating in the subterranean world more efficiently.","sentences":["Subterranean burrowing is inherently difficult for robots because of the high forces experienced as well as the high amount of uncertainty in this domain.","Because of the difficulty in modeling forces in granular media, we propose the use of a novel machine-learning control strategy to obtain optimal techniques for vertical self-burrowing.","In this paper, we realize a snake-like bio-inspired robot that is equipped with an IMU and two triple-axis magnetometers.","Utilizing magnetic field strength as an analog for depth, a novel deep learning architecture was proposed based on sinusoidal and random data in order to obtain a more efficient strategy for vertical self-burrowing.","This strategy was able to outperform many other standard burrowing techniques and was able to automatically reach targeted burrowing depths.","We hope these results will serve as a proof of concept for how optimization can be used to unlock the secrets of navigating in the subterranean world more efficiently."],"url":"http://arxiv.org/abs/2309.10802v1"}
{"created":"2023-09-19 17:46:36","title":"Hierarchical Annotated Skeleton-Guided Tree-based Motion Planning","abstract":"We present a hierarchical tree-based motion planning strategy, HAS-RRT, guided by the workspace skeleton to solve motion planning problems in robotics and computational biology. Relying on the information about the connectivity of the workspace and the ranking of available paths in the workspace, the strategy prioritizes paths indicated by the workspace guidance to find a valid motion plan for the moving object efficiently. In instances of suboptimal guidance, the strategy adapts its reliance on the guidance by hierarchically reverting to local exploration of the planning space. We offer an extensive comparative analysis against other tree-based planning strategies and demonstrate that HAS-RRT reliably and efficiently finds low-cost paths. In contrast to methods prone to inconsistent performance across different environments or reliance on specific parameters, HAS-RRT is robust to workspace variability.","sentences":["We present a hierarchical tree-based motion planning strategy, HAS-RRT, guided by the workspace skeleton to solve motion planning problems in robotics and computational biology.","Relying on the information about the connectivity of the workspace and the ranking of available paths in the workspace, the strategy prioritizes paths indicated by the workspace guidance to find a valid motion plan for the moving object efficiently.","In instances of suboptimal guidance, the strategy adapts its reliance on the guidance by hierarchically reverting to local exploration of the planning space.","We offer an extensive comparative analysis against other tree-based planning strategies and demonstrate that HAS-RRT reliably and efficiently finds low-cost paths.","In contrast to methods prone to inconsistent performance across different environments or reliance on specific parameters, HAS-RRT is robust to workspace variability."],"url":"http://arxiv.org/abs/2309.10801v1"}
{"created":"2023-09-19 17:43:11","title":"Heuristic Search for Path Finding with Refuelling","abstract":"This paper considers a generalization of the Path Finding (PF) with refueling constraints referred to as the Refuelling Path Finding (RF-PF) problem. Just like PF, the RF-PF problem is defined over a graph, where vertices are gas stations with known fuel prices, and edge costs depend on the gas consumption between the corresponding vertices. RF-PF seeks a minimum-cost path from the start to the goal vertex for a robot with a limited gas tank and a limited number of refuelling stops. While RF-PF is polynomial-time solvable, it remains a challenge to quickly compute an optimal solution in practice since the robot needs to simultaneously determine the path, where to make the stops, and the amount to refuel at each stop. This paper develops a heuristic search algorithm called Refuel A* (RF-A* ) that iteratively constructs partial solution paths from the start to the goal guided by a heuristic function while leveraging dominance rules for state pruning during planning. RF-A* is guaranteed to find an optimal solution and runs more than an order of magnitude faster than the existing state of the art (a polynomial time algorithm) when tested in large city maps with hundreds of gas stations.","sentences":["This paper considers a generalization of the Path Finding (PF) with refueling constraints referred to as the Refuelling Path Finding (RF-PF) problem.","Just like PF, the RF-PF problem is defined over a graph, where vertices are gas stations with known fuel prices, and edge costs depend on the gas consumption between the corresponding vertices.","RF-PF seeks a minimum-cost path from the start to the goal vertex for a robot with a limited gas tank and a limited number of refuelling stops.","While RF-PF is polynomial-time solvable, it remains a challenge to quickly compute an optimal solution in practice since the robot needs to simultaneously determine the path, where to make the stops, and the amount to refuel at each stop.","This paper develops a heuristic search algorithm called Refuel A* (RF-A* ) that iteratively constructs partial solution paths from the start to the goal guided by a heuristic function while leveraging dominance rules for state pruning during planning.","RF-A* is guaranteed to find an optimal solution and runs more than an order of magnitude faster than the existing state of the art (a polynomial time algorithm) when tested in large city maps with hundreds of gas stations."],"url":"http://arxiv.org/abs/2309.10796v1"}
{"created":"2023-09-19 17:41:28","title":"Mobile Manipulation Platform for Autonomous Indoor Inspections in Low-Clearance Areas","abstract":"Mobile manipulators have been used for inspection, maintenance and repair tasks over the years, but there are some key limitations. Stability concerns typically require mobile platforms to be large in order to handle far-reaching manipulators, or for the manipulators to have drastically reduced workspaces to fit onto smaller mobile platforms. Therefore we propose a combination of two widely-used robots, the Clearpath Jackal unmanned ground vehicle and the Kinova Gen3 six degree-of-freedom manipulator. The Jackal has a small footprint and works well in low-clearance indoor environments. Extensive testing of localization, navigation and mapping using LiDAR sensors makes the Jackal a well developed mobile platform suitable for mobile manipulation. The Gen3 has a long reach with reasonable power consumption for manipulation tasks. A wrist camera for RGB-D sensing and a customizable end effector interface makes the Gen3 suitable for a myriad of manipulation tasks. Typically these features would result in an unstable platform, however with a few minor hardware and software modifications, we have produced a stable, high-performance mobile manipulation platform with significant mobility, reach, sensing, and maneuverability for indoor inspection tasks, without degradation of the component robots' individual capabilities. These assertions were investigated with hardware via semi-autonomous navigation to waypoints in a busy indoor environment, and high-precision self-alignment alongside planar structures for intervention tasks.","sentences":["Mobile manipulators have been used for inspection, maintenance and repair tasks over the years, but there are some key limitations.","Stability concerns typically require mobile platforms to be large in order to handle far-reaching manipulators, or for the manipulators to have drastically reduced workspaces to fit onto smaller mobile platforms.","Therefore we propose a combination of two widely-used robots, the Clearpath Jackal unmanned ground vehicle and the Kinova Gen3 six degree-of-freedom manipulator.","The Jackal has a small footprint and works well in low-clearance indoor environments.","Extensive testing of localization, navigation and mapping using LiDAR sensors makes the Jackal a well developed mobile platform suitable for mobile manipulation.","The Gen3 has a long reach with reasonable power consumption for manipulation tasks.","A wrist camera for RGB-D sensing and a customizable end effector interface makes the Gen3 suitable for a myriad of manipulation tasks.","Typically these features would result in an unstable platform, however with a few minor hardware and software modifications, we have produced a stable, high-performance mobile manipulation platform with significant mobility, reach, sensing, and maneuverability for indoor inspection tasks, without degradation of the component robots' individual capabilities.","These assertions were investigated with hardware via semi-autonomous navigation to waypoints in a busy indoor environment, and high-precision self-alignment alongside planar structures for intervention tasks."],"url":"http://arxiv.org/abs/2309.10794v1"}
{"created":"2023-09-19 17:39:20","title":"Guide Your Agent with Adaptive Multimodal Rewards","abstract":"Developing an agent capable of adapting to unseen environments remains a difficult challenge in imitation learning. In this work, we present Adaptive Return-conditioned Policy (ARP), an efficient framework designed to enhance the agent's generalization ability using natural language task descriptions and pre-trained multimodal encoders. Our key idea is to calculate a similarity between visual observations and natural language instructions in the pre-trained multimodal embedding space (such as CLIP) and use it as a reward signal. We then train a return-conditioned policy using expert demonstrations labeled with multimodal rewards. Because the multimodal rewards provide adaptive signals at each timestep, our ARP effectively mitigates the goal misgeneralization. This results in superior generalization performances even when faced with unseen text instructions, compared to existing text-conditioned policies. To improve the quality of rewards, we also introduce a fine-tuning method for pre-trained multimodal encoders, further enhancing the performance. Video demonstrations and source code are available on the project website: https://sites.google.com/view/2023arp.","sentences":["Developing an agent capable of adapting to unseen environments remains a difficult challenge in imitation learning.","In this work, we present Adaptive Return-conditioned Policy (ARP), an efficient framework designed to enhance the agent's generalization ability using natural language task descriptions and pre-trained multimodal encoders.","Our key idea is to calculate a similarity between visual observations and natural language instructions in the pre-trained multimodal embedding space (such as CLIP) and use it as a reward signal.","We then train a return-conditioned policy using expert demonstrations labeled with multimodal rewards.","Because the multimodal rewards provide adaptive signals at each timestep, our ARP effectively mitigates the goal misgeneralization.","This results in superior generalization performances even when faced with unseen text instructions, compared to existing text-conditioned policies.","To improve the quality of rewards, we also introduce a fine-tuning method for pre-trained multimodal encoders, further enhancing the performance.","Video demonstrations and source code are available on the project website: https://sites.google.com/view/2023arp."],"url":"http://arxiv.org/abs/2309.10790v1"}
{"created":"2023-09-19 17:32:21","title":"Language as the Medium: Multimodal Video Classification through text only","abstract":"Despite an exciting new wave of multimodal machine learning models, current approaches still struggle to interpret the complex contextual relationships between the different modalities present in videos. Going beyond existing methods that emphasize simple activities or objects, we propose a new model-agnostic approach for generating detailed textual descriptions that captures multimodal video information. Our method leverages the extensive knowledge learnt by large language models, such as GPT-3.5 or Llama2, to reason about textual descriptions of the visual and aural modalities, obtained from BLIP-2, Whisper and ImageBind. Without needing additional finetuning of video-text models or datasets, we demonstrate that available LLMs have the ability to use these multimodal textual descriptions as proxies for ``sight'' or ``hearing'' and perform zero-shot multimodal classification of videos in-context. Our evaluations on popular action recognition benchmarks, such as UCF-101 or Kinetics, show these context-rich descriptions can be successfully used in video understanding tasks. This method points towards a promising new research direction in multimodal classification, demonstrating how an interplay between textual, visual and auditory machine learning models can enable more holistic video understanding.","sentences":["Despite an exciting new wave of multimodal machine learning models, current approaches still struggle to interpret the complex contextual relationships between the different modalities present in videos.","Going beyond existing methods that emphasize simple activities or objects, we propose a new model-agnostic approach for generating detailed textual descriptions that captures multimodal video information.","Our method leverages the extensive knowledge learnt by large language models, such as GPT-3.5 or Llama2, to reason about textual descriptions of the visual and aural modalities, obtained from BLIP-2, Whisper and ImageBind.","Without needing additional finetuning of video-text models or datasets, we demonstrate that available LLMs have the ability to use these multimodal textual descriptions as proxies for ``sight'' or ``hearing'' and perform zero-shot multimodal classification of videos in-context.","Our evaluations on popular action recognition benchmarks, such as UCF-101 or Kinetics, show these context-rich descriptions can be successfully used in video understanding tasks.","This method points towards a promising new research direction in multimodal classification, demonstrating how an interplay between textual, visual and auditory machine learning models can enable more holistic video understanding."],"url":"http://arxiv.org/abs/2309.10783v1"}
{"created":"2023-09-19 17:32:03","title":"DeFi composability as MEV non-interference","abstract":"Complex DeFi services are usually constructed by composing a variety of simpler smart contracts. The permissionless nature of the blockchains where these smart contracts are executed makes DeFi services exposed to security risks, since adversaries can target any of the underlying contracts to economically damage the compound service. We introduce a new notion of secure composability of smart contracts, which ensures that adversaries cannot economically harm the compound contract by interfering with its dependencies.","sentences":["Complex DeFi services are usually constructed by composing a variety of simpler smart contracts.","The permissionless nature of the blockchains where these smart contracts are executed makes DeFi services exposed to security risks, since adversaries can target any of the underlying contracts to economically damage the compound service.","We introduce a new notion of secure composability of smart contracts, which ensures that adversaries cannot economically harm the compound contract by interfering with its dependencies."],"url":"http://arxiv.org/abs/2309.10781v1"}
{"created":"2023-09-19 17:31:29","title":"Towards affective computing that works for everyone","abstract":"Missing diversity, equity, and inclusion elements in affective computing datasets directly affect the accuracy and fairness of emotion recognition algorithms across different groups. A literature review reveals how affective computing systems may work differently for different groups due to, for instance, mental health conditions impacting facial expressions and speech or age-related changes in facial appearance and health. Our work analyzes existing affective computing datasets and highlights a disconcerting lack of diversity in current affective computing datasets regarding race, sex/gender, age, and (mental) health representation. By emphasizing the need for more inclusive sampling strategies and standardized documentation of demographic factors in datasets, this paper provides recommendations and calls for greater attention to inclusivity and consideration of societal consequences in affective computing research to promote ethical and accurate outcomes in this emerging field.","sentences":["Missing diversity, equity, and inclusion elements in affective computing datasets directly affect the accuracy and fairness of emotion recognition algorithms across different groups.","A literature review reveals how affective computing systems may work differently for different groups due to, for instance, mental health conditions impacting facial expressions and speech or age-related changes in facial appearance and health.","Our work analyzes existing affective computing datasets and highlights a disconcerting lack of diversity in current affective computing datasets regarding race, sex/gender, age, and (mental) health representation.","By emphasizing the need for more inclusive sampling strategies and standardized documentation of demographic factors in datasets, this paper provides recommendations and calls for greater attention to inclusivity and consideration of societal consequences in affective computing research to promote ethical and accurate outcomes in this emerging field."],"url":"http://arxiv.org/abs/2309.10780v1"}
{"created":"2023-09-19 17:25:02","title":"EU law and emotion data","abstract":"This article sheds light on legal implications and challenges surrounding emotion data processing within the EU's legal framework. Despite the sensitive nature of emotion data, the GDPR does not categorize it as special data, resulting in a lack of comprehensive protection. The article also discusses the nuances of different approaches to affective computing and their relevance to the processing of special data under the GDPR. Moreover, it points to potential tensions with data protection principles, such as fairness and accuracy. Our article also highlights some of the consequences, including harm, that processing of emotion data may have for individuals concerned. Additionally, we discuss how the AI Act proposal intends to regulate affective computing. Finally, the article outlines the new obligations and transparency requirements introduced by the DSA for online platforms utilizing emotion data. Our article aims at raising awareness among the affective computing community about the applicable legal requirements when developing AC systems intended for the EU market, or when working with study participants located in the EU. We also stress the importance of protecting the fundamental rights of individuals even when the law struggles to keep up with technological developments that capture sensitive emotion data.","sentences":["This article sheds light on legal implications and challenges surrounding emotion data processing within the EU's legal framework.","Despite the sensitive nature of emotion data, the GDPR does not categorize it as special data, resulting in a lack of comprehensive protection.","The article also discusses the nuances of different approaches to affective computing and their relevance to the processing of special data under the GDPR.","Moreover, it points to potential tensions with data protection principles, such as fairness and accuracy.","Our article also highlights some of the consequences, including harm, that processing of emotion data may have for individuals concerned.","Additionally, we discuss how the AI Act proposal intends to regulate affective computing.","Finally, the article outlines the new obligations and transparency requirements introduced by the DSA for online platforms utilizing emotion data.","Our article aims at raising awareness among the affective computing community about the applicable legal requirements when developing AC systems intended for the EU market, or when working with study participants located in the EU.","We also stress the importance of protecting the fundamental rights of individuals even when the law struggles to keep up with technological developments that capture sensitive emotion data."],"url":"http://arxiv.org/abs/2309.10776v1"}
{"created":"2023-09-19 17:21:12","title":"$O(k)$-Equivariant Dimensionality Reduction on Stiefel Manifolds","abstract":"Many real-world datasets live on high-dimensional Stiefel and Grassmannian manifolds, $V_k(\\mathbb{R}^N)$ and $Gr(k, \\mathbb{R}^N)$ respectively, and benefit from projection onto lower-dimensional Stiefel (respectively, Grassmannian) manifolds. In this work, we propose an algorithm called Principal Stiefel Coordinates (PSC) to reduce data dimensionality from $ V_k(\\mathbb{R}^N)$ to $V_k(\\mathbb{R}^n)$ in an $O(k)$-equivariant manner ($k \\leq n \\ll N$). We begin by observing that each element $\\alpha \\in V_n(\\mathbb{R}^N)$ defines an isometric embedding of $V_k(\\mathbb{R}^n)$ into $V_k(\\mathbb{R}^N)$. Next, we optimize for such an embedding map that minimizes data fit error by warm-starting with the output of principal component analysis (PCA) and applying gradient descent. Then, we define a continuous and $O(k)$-equivariant map $\\pi_\\alpha$ that acts as a ``closest point operator'' to project the data onto the image of $V_k(\\mathbb{R}^n)$ in $V_k(\\mathbb{R}^N)$ under the embedding determined by $\\alpha$, while minimizing distortion. Because this dimensionality reduction is $O(k)$-equivariant, these results extend to Grassmannian manifolds as well. Lastly, we show that the PCA output globally minimizes projection error in a noiseless setting, but that our algorithm achieves a meaningfully different and improved outcome when the data does not lie exactly on the image of a linearly embedded lower-dimensional Stiefel manifold as above. Multiple numerical experiments using synthetic and real-world data are performed.","sentences":["Many real-world datasets live on high-dimensional Stiefel and Grassmannian manifolds, $V_k(\\mathbb{R}^N)$ and $Gr(k, \\mathbb{R}^N)$ respectively, and benefit from projection onto lower-dimensional Stiefel (respectively, Grassmannian) manifolds.","In this work, we propose an algorithm called Principal Stiefel Coordinates (PSC) to reduce data dimensionality from $ V_k(\\mathbb{R}^N)$ to $V_k(\\mathbb{R}^n)$ in an $O(k)$-equivariant manner ($k \\leq n \\ll N$).","We begin by observing that each element $\\alpha \\in V_n(\\mathbb{R}^N)$ defines an isometric embedding of $V_k(\\mathbb{R}^n)$ into $V_k(\\mathbb{R}^N)$. Next, we optimize for such an embedding map that minimizes data fit error by warm-starting with the output of principal component analysis (PCA) and applying gradient descent.","Then, we define a continuous and $O(k)$-equivariant map $\\pi_\\alpha$ that acts as a ``closest point operator'' to project the data onto the image of $V_k(\\mathbb{R}^n)$ in $V_k(\\mathbb{R}^N)$ under the embedding determined by $\\alpha$, while minimizing distortion.","Because this dimensionality reduction is $O(k)$-equivariant, these results extend to Grassmannian manifolds as well.","Lastly, we show that the PCA output globally minimizes projection error in a noiseless setting, but that our algorithm achieves a meaningfully different and improved outcome when the data does not lie exactly on the image of a linearly embedded lower-dimensional Stiefel manifold as above.","Multiple numerical experiments using synthetic and real-world data are performed."],"url":"http://arxiv.org/abs/2309.10775v1"}
{"created":"2023-09-19 17:20:58","title":"Semi-supervised Domain Adaptation in Graph Transfer Learning","abstract":"As a specific case of graph transfer learning, unsupervised domain adaptation on graphs aims for knowledge transfer from label-rich source graphs to unlabeled target graphs. However, graphs with topology and attributes usually have considerable cross-domain disparity and there are numerous real-world scenarios where merely a subset of nodes are labeled in the source graph. This imposes critical challenges on graph transfer learning due to serious domain shifts and label scarcity. To address these challenges, we propose a method named Semi-supervised Graph Domain Adaptation (SGDA). To deal with the domain shift, we add adaptive shift parameters to each of the source nodes, which are trained in an adversarial manner to align the cross-domain distributions of node embedding, thus the node classifier trained on labeled source nodes can be transferred to the target nodes. Moreover, to address the label scarcity, we propose pseudo-labeling on unlabeled nodes, which improves classification on the target graph via measuring the posterior influence of nodes based on their relative position to the class centroids. Finally, extensive experiments on a range of publicly accessible datasets validate the effectiveness of our proposed SGDA in different experimental settings.","sentences":["As a specific case of graph transfer learning, unsupervised domain adaptation on graphs aims for knowledge transfer from label-rich source graphs to unlabeled target graphs.","However, graphs with topology and attributes usually have considerable cross-domain disparity and there are numerous real-world scenarios where merely a subset of nodes are labeled in the source graph.","This imposes critical challenges on graph transfer learning due to serious domain shifts and label scarcity.","To address these challenges, we propose a method named Semi-supervised Graph Domain Adaptation (SGDA).","To deal with the domain shift, we add adaptive shift parameters to each of the source nodes, which are trained in an adversarial manner to align the cross-domain distributions of node embedding, thus the node classifier trained on labeled source nodes can be transferred to the target nodes.","Moreover, to address the label scarcity, we propose pseudo-labeling on unlabeled nodes, which improves classification on the target graph via measuring the posterior influence of nodes based on their relative position to the class centroids.","Finally, extensive experiments on a range of publicly accessible datasets validate the effectiveness of our proposed SGDA in different experimental settings."],"url":"http://arxiv.org/abs/2309.10773v1"}
{"created":"2023-09-19 17:18:36","title":"Interactive Distillation of Large Single-Topic Corpora of Scientific Papers","abstract":"Highly specific datasets of scientific literature are important for both research and education. However, it is difficult to build such datasets at scale. A common approach is to build these datasets reductively by applying topic modeling on an established corpus and selecting specific topics. A more robust but time-consuming approach is to build the dataset constructively in which a subject matter expert (SME) handpicks documents. This method does not scale and is prone to error as the dataset grows. Here we showcase a new tool, based on machine learning, for constructively generating targeted datasets of scientific literature. Given a small initial \"core\" corpus of papers, we build a citation network of documents. At each step of the citation network, we generate text embeddings and visualize the embeddings through dimensionality reduction. Papers are kept in the dataset if they are \"similar\" to the core or are otherwise pruned through human-in-the-loop selection. Additional insight into the papers is gained through sub-topic modeling using SeNMFk. We demonstrate our new tool for literature review by applying it to two different fields in machine learning.","sentences":["Highly specific datasets of scientific literature are important for both research and education.","However, it is difficult to build such datasets at scale.","A common approach is to build these datasets reductively by applying topic modeling on an established corpus and selecting specific topics.","A more robust but time-consuming approach is to build the dataset constructively in which a subject matter expert (SME) handpicks documents.","This method does not scale and is prone to error as the dataset grows.","Here we showcase a new tool, based on machine learning, for constructively generating targeted datasets of scientific literature.","Given a small initial \"core\" corpus of papers, we build a citation network of documents.","At each step of the citation network, we generate text embeddings and visualize the embeddings through dimensionality reduction.","Papers are kept in the dataset if they are \"similar\" to the core or are otherwise pruned through human-in-the-loop selection.","Additional insight into the papers is gained through sub-topic modeling using SeNMFk.","We demonstrate our new tool for literature review by applying it to two different fields in machine learning."],"url":"http://arxiv.org/abs/2309.10772v1"}
{"created":"2023-09-19 17:18:09","title":"Redefining Qualitative Analysis in the AI Era: Utilizing ChatGPT for Efficient Thematic Analysis","abstract":"Thematic analysis is a cornerstone of qualitative research, yet it is often marked by labor-intensive procedures. Recent advances in artificial intelligence (AI), especially with large-scale language models (LLMs) such as ChatGPT, present potential avenues to enhance qualitative data analysis. This research delves into the effectiveness of ChatGPT in refining the thematic analysis process. We conducted semi-structured interviews with 17 participants, inclusive of a 4-participant pilot study, to identify the challenges and reservations concerning the incorporation of ChatGPT in qualitative analysis. In partnership with 13 qualitative analysts, we crafted cueing frameworks to bolster ChatGPT's contribution to thematic analysis. The results indicate that these frameworks not only amplify the quality of thematic analysis but also bridge a significant connection between AI and qualitative research. These insights carry pivotal implications for academics and professionals keen on harnessing AI for qualitative data exploration.","sentences":["Thematic analysis is a cornerstone of qualitative research, yet it is often marked by labor-intensive procedures.","Recent advances in artificial intelligence (AI), especially with large-scale language models (LLMs) such as ChatGPT, present potential avenues to enhance qualitative data analysis.","This research delves into the effectiveness of ChatGPT in refining the thematic analysis process.","We conducted semi-structured interviews with 17 participants, inclusive of a 4-participant pilot study, to identify the challenges and reservations concerning the incorporation of ChatGPT in qualitative analysis.","In partnership with 13 qualitative analysts, we crafted cueing frameworks to bolster ChatGPT's contribution to thematic analysis.","The results indicate that these frameworks not only amplify the quality of thematic analysis but also bridge a significant connection between AI and qualitative research.","These insights carry pivotal implications for academics and professionals keen on harnessing AI for qualitative data exploration."],"url":"http://arxiv.org/abs/2309.10771v1"}
{"created":"2023-09-19 17:17:28","title":"FRASIMED: a Clinical French Annotated Resource Produced through Crosslingual BERT-Based Annotation Projection","abstract":"Natural language processing (NLP) applications such as named entity recognition (NER) for low-resource corpora do not benefit from recent advances in the development of large language models (LLMs) where there is still a need for larger annotated datasets. This research article introduces a methodology for generating translated versions of annotated datasets through crosslingual annotation projection. Leveraging a language agnostic BERT-based approach, it is an efficient solution to increase low-resource corpora with few human efforts and by only using already available open data resources. Quantitative and qualitative evaluations are often lacking when it comes to evaluating the quality and effectiveness of semi-automatic data generation strategies. The evaluation of our crosslingual annotation projection approach showed both effectiveness and high accuracy in the resulting dataset. As a practical application of this methodology, we present the creation of French Annotated Resource with Semantic Information for Medical Entities Detection (FRASIMED), an annotated corpus comprising 2'051 synthetic clinical cases in French. The corpus is now available for researchers and practitioners to develop and refine French natural language processing (NLP) applications in the clinical field (https://zenodo.org/record/8355629), making it the largest open annotated corpus with linked medical concepts in French.","sentences":["Natural language processing (NLP) applications such as named entity recognition (NER) for low-resource corpora do not benefit from recent advances in the development of large language models (LLMs) where there is still a need for larger annotated datasets.","This research article introduces a methodology for generating translated versions of annotated datasets through crosslingual annotation projection.","Leveraging a language agnostic BERT-based approach, it is an efficient solution to increase low-resource corpora with few human efforts and by only using already available open data resources.","Quantitative and qualitative evaluations are often lacking when it comes to evaluating the quality and effectiveness of semi-automatic data generation strategies.","The evaluation of our crosslingual annotation projection approach showed both effectiveness and high accuracy in the resulting dataset.","As a practical application of this methodology, we present the creation of French Annotated Resource with Semantic Information for Medical Entities Detection (FRASIMED), an annotated corpus comprising 2'051 synthetic clinical cases in French.","The corpus is now available for researchers and practitioners to develop and refine French natural language processing (NLP) applications in the clinical field (https://zenodo.org/record/8355629), making it the largest open annotated corpus with linked medical concepts in French."],"url":"http://arxiv.org/abs/2309.10770v1"}
{"created":"2023-09-19 17:05:37","title":"Combinatorial Contracts Beyond Gross Substitutes","abstract":"We study the combinatorial contracting problem of D\\\"utting et al. [FOCS '21], in which a principal seeks to incentivize an agent to take a set of costly actions. In their model, there is a binary outcome (the agent can succeed or fail), and the success probability and the costs depend on the set of actions taken. The optimal contract is linear, paying the agent an $\\alpha$ fraction of the reward. For gross substitutes (GS) rewards and additive costs, they give a poly-time algorithm for finding the optimal contract. They use the properties of GS functions to argue that there are poly-many \"critical values\" of $\\alpha$, and that one can iterate through all of them efficiently in order to find the optimal contract.   In this work we study to which extent GS rewards and additive costs constitute a tractability frontier for combinatorial contracts. We present an algorithm that for any rewards and costs, enumerates all critical values, with poly-many demand queries (in the number of critical values). This implies the tractability of the optimal contract for any setting with poly-many critical values and efficient demand oracle. A direct corollary is a poly-time algorithm for the optimal contract in settings with supermodular rewards and submodular costs. We also study a natural class of matching-based instances with XOS rewards and additive costs. While the demand problem for this setting is tractable, we show that it admits an exponential number of critical values. On the positive side, we present (pseudo-) polynomial-time algorithms for two natural special cases of this setting. Our work unveils a profound connection to sensitivity analysis, and designates matching-based instances as a crucial focal point for gaining a deeper understanding of combinatorial contract settings.","sentences":["We study the combinatorial contracting problem of D\\\"utting et al.","[FOCS '21], in which a principal seeks to incentivize an agent to take a set of costly actions.","In their model, there is a binary outcome (the agent can succeed or fail), and the success probability and the costs depend on the set of actions taken.","The optimal contract is linear, paying the agent an $\\alpha$ fraction of the reward.","For gross substitutes (GS) rewards and additive costs, they give a poly-time algorithm for finding the optimal contract.","They use the properties of GS functions to argue that there are poly-many \"critical values\" of $\\alpha$, and that one can iterate through all of them efficiently in order to find the optimal contract.   ","In this work we study to which extent GS rewards and additive costs constitute a tractability frontier for combinatorial contracts.","We present an algorithm that for any rewards and costs, enumerates all critical values, with poly-many demand queries (in the number of critical values).","This implies the tractability of the optimal contract for any setting with poly-many critical values and efficient demand oracle.","A direct corollary is a poly-time algorithm for the optimal contract in settings with supermodular rewards and submodular costs.","We also study a natural class of matching-based instances with XOS rewards and additive costs.","While the demand problem for this setting is tractable, we show that it admits an exponential number of critical values.","On the positive side, we present (pseudo-) polynomial-time algorithms for two natural special cases of this setting.","Our work unveils a profound connection to sensitivity analysis, and designates matching-based instances as a crucial focal point for gaining a deeper understanding of combinatorial contract settings."],"url":"http://arxiv.org/abs/2309.10766v1"}
{"created":"2023-09-19 17:04:36","title":"MAGIC-TBR: Multiview Attention Fusion for Transformer-based Bodily Behavior Recognition in Group Settings","abstract":"Bodily behavioral language is an important social cue, and its automated analysis helps in enhancing the understanding of artificial intelligence systems. Furthermore, behavioral language cues are essential for active engagement in social agent-based user interactions. Despite the progress made in computer vision for tasks like head and body pose estimation, there is still a need to explore the detection of finer behaviors such as gesturing, grooming, or fumbling. This paper proposes a multiview attention fusion method named MAGIC-TBR that combines features extracted from videos and their corresponding Discrete Cosine Transform coefficients via a transformer-based approach. The experiments are conducted on the BBSI dataset and the results demonstrate the effectiveness of the proposed feature fusion with multiview attention. The code is available at: https://github.com/surbhimadan92/MAGIC-TBR","sentences":["Bodily behavioral language is an important social cue, and its automated analysis helps in enhancing the understanding of artificial intelligence systems.","Furthermore, behavioral language cues are essential for active engagement in social agent-based user interactions.","Despite the progress made in computer vision for tasks like head and body pose estimation, there is still a need to explore the detection of finer behaviors such as gesturing, grooming, or fumbling.","This paper proposes a multiview attention fusion method named MAGIC-TBR that combines features extracted from videos and their corresponding Discrete Cosine Transform coefficients via a transformer-based approach.","The experiments are conducted on the BBSI dataset and the results demonstrate the effectiveness of the proposed feature fusion with multiview attention.","The code is available at: https://github.com/surbhimadan92/MAGIC-TBR"],"url":"http://arxiv.org/abs/2309.10765v1"}
{"created":"2023-09-19 17:00:34","title":"A Blueprint for Precise and Fault-Tolerant Analog Neural Networks","abstract":"Analog computing has reemerged as a promising avenue for accelerating deep neural networks (DNNs) due to its potential to overcome the energy efficiency and scalability challenges posed by traditional digital architectures. However, achieving high precision and DNN accuracy using such technologies is challenging, as high-precision data converters are costly and impractical. In this paper, we address this challenge by using the residue number system (RNS). RNS allows composing high-precision operations from multiple low-precision operations, thereby eliminating the information loss caused by the limited precision of the data converters. Our study demonstrates that analog accelerators utilizing the RNS-based approach can achieve ${\\geq}99\\%$ of FP32 accuracy for state-of-the-art DNN inference using data converters with only $6$-bit precision whereas a conventional analog core requires more than $8$-bit precision to achieve the same accuracy in the same DNNs. The reduced precision requirements imply that using RNS can reduce the energy consumption of analog accelerators by several orders of magnitude while maintaining the same throughput and precision. Our study extends this approach to DNN training, where we can efficiently train DNNs using $7$-bit integer arithmetic while achieving accuracy comparable to FP32 precision. Lastly, we present a fault-tolerant dataflow using redundant RNS error-correcting codes to protect the computation against noise and errors inherent within an analog accelerator.","sentences":["Analog computing has reemerged as a promising avenue for accelerating deep neural networks (DNNs) due to its potential to overcome the energy efficiency and scalability challenges posed by traditional digital architectures.","However, achieving high precision and DNN accuracy using such technologies is challenging, as high-precision data converters are costly and impractical.","In this paper, we address this challenge by using the residue number system (RNS).","RNS allows composing high-precision operations from multiple low-precision operations, thereby eliminating the information loss caused by the limited precision of the data converters.","Our study demonstrates that analog accelerators utilizing the RNS-based approach can achieve ${\\geq}99\\%$ of FP32 accuracy for state-of-the-art DNN inference using data converters with only $6$-bit precision whereas a conventional analog core requires more than $8$-bit precision to achieve the same accuracy in the same DNNs.","The reduced precision requirements imply that using RNS can reduce the energy consumption of analog accelerators by several orders of magnitude while maintaining the same throughput and precision.","Our study extends this approach to DNN training, where we can efficiently train DNNs using $7$-bit integer arithmetic while achieving accuracy comparable to FP32 precision.","Lastly, we present a fault-tolerant dataflow using redundant RNS error-correcting codes to protect the computation against noise and errors inherent within an analog accelerator."],"url":"http://arxiv.org/abs/2309.10759v1"}
{"created":"2023-09-19 17:00:04","title":"RIS-Assisted Over-the-Air Adaptive Federated Learning with Noisy Downlink","abstract":"Over-the-air federated learning (OTA-FL) exploits the inherent superposition property of wireless channels to integrate the communication and model aggregation. Though a naturally promising framework for wireless federated learning, it requires care to mitigate physical layer impairments. In this work, we consider a heterogeneous edge-intelligent network with different edge device resources and non-i.i.d. user dataset distributions, under a general non-convex learning objective. We leverage the Reconfigurable Intelligent Surface (RIS) technology to augment OTA-FL system over simultaneous time varying uplink and downlink noisy communication channels under imperfect CSI scenario. We propose a cross-layer algorithm that jointly optimizes RIS configuration, communication and computation resources in this general realistic setting. Specifically, we design dynamic local update steps in conjunction with RIS phase shifts and transmission power to boost learning performance. We present a convergence analysis of the proposed algorithm, and show that it outperforms the existing unified approach under heterogeneous system and imperfect CSI in numerical results.","sentences":["Over-the-air federated learning (OTA-FL) exploits the inherent superposition property of wireless channels to integrate the communication and model aggregation.","Though a naturally promising framework for wireless federated learning, it requires care to mitigate physical layer impairments.","In this work, we consider a heterogeneous edge-intelligent network with different edge device resources and non-i.i.d. user dataset distributions, under a general non-convex learning objective.","We leverage the Reconfigurable Intelligent Surface (RIS) technology to augment OTA-FL system over simultaneous time varying uplink and downlink noisy communication channels under imperfect CSI scenario.","We propose a cross-layer algorithm that jointly optimizes RIS configuration, communication and computation resources in this general realistic setting.","Specifically, we design dynamic local update steps in conjunction with RIS phase shifts and transmission power to boost learning performance.","We present a convergence analysis of the proposed algorithm, and show that it outperforms the existing unified approach under heterogeneous system and imperfect CSI in numerical results."],"url":"http://arxiv.org/abs/2309.10758v1"}
{"created":"2023-09-19 16:48:29","title":"SHOWMe: Benchmarking Object-agnostic Hand-Object 3D Reconstruction","abstract":"Recent hand-object interaction datasets show limited real object variability and rely on fitting the MANO parametric model to obtain groundtruth hand shapes. To go beyond these limitations and spur further research, we introduce the SHOWMe dataset which consists of 96 videos, annotated with real and detailed hand-object 3D textured meshes. Following recent work, we consider a rigid hand-object scenario, in which the pose of the hand with respect to the object remains constant during the whole video sequence. This assumption allows us to register sub-millimetre-precise groundtruth 3D scans to the image sequences in SHOWMe. Although simpler, this hypothesis makes sense in terms of applications where the required accuracy and level of detail is important eg., object hand-over in human-robot collaboration, object scanning, or manipulation and contact point analysis. Importantly, the rigidity of the hand-object systems allows to tackle video-based 3D reconstruction of unknown hand-held objects using a 2-stage pipeline consisting of a rigid registration step followed by a multi-view reconstruction (MVR) part. We carefully evaluate a set of non-trivial baselines for these two stages and show that it is possible to achieve promising object-agnostic 3D hand-object reconstructions employing an SfM toolbox or a hand pose estimator to recover the rigid transforms and off-the-shelf MVR algorithms. However, these methods remain sensitive to the initial camera pose estimates which might be imprecise due to lack of textures on the objects or heavy occlusions of the hands, leaving room for improvements in the reconstruction. Code and dataset are available at https://europe.naverlabs.com/research/showme","sentences":["Recent hand-object interaction datasets show limited real object variability and rely on fitting the MANO parametric model to obtain groundtruth hand shapes.","To go beyond these limitations and spur further research, we introduce the SHOWMe dataset which consists of 96 videos, annotated with real and detailed hand-object 3D textured meshes.","Following recent work, we consider a rigid hand-object scenario, in which the pose of the hand with respect to the object remains constant during the whole video sequence.","This assumption allows us to register sub-millimetre-precise groundtruth 3D scans to the image sequences in SHOWMe.","Although simpler, this hypothesis makes sense in terms of applications where the required accuracy and level of detail is important eg., object hand-over in human-robot collaboration, object scanning, or manipulation and contact point analysis.","Importantly, the rigidity of the hand-object systems allows to tackle video-based 3D reconstruction of unknown hand-held objects using a 2-stage pipeline consisting of a rigid registration step followed by a multi-view reconstruction (MVR) part.","We carefully evaluate a set of non-trivial baselines for these two stages and show that it is possible to achieve promising object-agnostic 3D hand-object reconstructions employing an SfM toolbox or a hand pose estimator to recover the rigid transforms and off-the-shelf MVR algorithms.","However, these methods remain sensitive to the initial camera pose estimates which might be imprecise due to lack of textures on the objects or heavy occlusions of the hands, leaving room for improvements in the reconstruction.","Code and dataset are available at https://europe.naverlabs.com/research/showme"],"url":"http://arxiv.org/abs/2309.10748v1"}
{"created":"2023-09-19 16:41:19","title":"Evaluating large language models' ability to understand metaphor and sarcasm using a screening test for Asperger syndrome","abstract":"Metaphors and sarcasm are precious fruits of our highly-evolved social communication skills. However, children with Asperger syndrome are known to have difficulties in comprehending sarcasm, even if they possess a certain level of verbal IQ sufficient for understanding metaphors. Given that, a screening test that scores the ability to understand metaphor and sarcasm has been used to differentiate Asperger syndrome from other symptoms exhibiting akin external behaviors (e.g., attention-deficit/hyperactivity disorder). This study uses the standardized test to examine the capability of recent large language models (LLMs) in understanding human nuanced communication. The results divulged that, whereas their ability to comprehend metaphors has been improved with the increase of the number of model parameters, the improvement in sarcasm understanding was not observed. This implies that an alternative approach is imperative to imbue LLMs with the capacity to grasp sarcasm, which has been associated with the amygdala, a pivotal cerebral region for emotional learning, in the case of humans.","sentences":["Metaphors and sarcasm are precious fruits of our highly-evolved social communication skills.","However, children with Asperger syndrome are known to have difficulties in comprehending sarcasm, even if they possess a certain level of verbal IQ sufficient for understanding metaphors.","Given that, a screening test that scores the ability to understand metaphor and sarcasm has been used to differentiate Asperger syndrome from other symptoms exhibiting akin external behaviors (e.g., attention-deficit/hyperactivity disorder).","This study uses the standardized test to examine the capability of recent large language models (LLMs) in understanding human nuanced communication.","The results divulged that, whereas their ability to comprehend metaphors has been improved with the increase of the number of model parameters, the improvement in sarcasm understanding was not observed.","This implies that an alternative approach is imperative to imbue LLMs with the capacity to grasp sarcasm, which has been associated with the amygdala, a pivotal cerebral region for emotional learning, in the case of humans."],"url":"http://arxiv.org/abs/2309.10744v1"}
{"created":"2023-09-19 16:36:33","title":"Accelerating Diffusion-Based Text-to-Audio Generation with Consistency Distillation","abstract":"Diffusion models power a vast majority of text-to-audio (TTA) generation methods. Unfortunately, these models suffer from slow inference speed due to iterative queries to the underlying denoising network, thus unsuitable for scenarios with inference time or computational constraints. This work modifies the recently proposed consistency distillation framework to train TTA models that require only a single neural network query. In addition to incorporating classifier-free guidance into the distillation process, we leverage the availability of generated audio during distillation training to fine-tune the consistency TTA model with novel loss functions in the audio space, such as the CLAP score. Our objective and subjective evaluation results on the AudioCaps dataset show that consistency models retain diffusion models' high generation quality and diversity while reducing the number of queries by a factor of 400.","sentences":["Diffusion models power a vast majority of text-to-audio (TTA) generation methods.","Unfortunately, these models suffer from slow inference speed due to iterative queries to the underlying denoising network, thus unsuitable for scenarios with inference time or computational constraints.","This work modifies the recently proposed consistency distillation framework to train TTA models that require only a single neural network query.","In addition to incorporating classifier-free guidance into the distillation process, we leverage the availability of generated audio during distillation training to fine-tune the consistency TTA model with novel loss functions in the audio space, such as the CLAP score.","Our objective and subjective evaluation results on the AudioCaps dataset show that consistency models retain diffusion models' high generation quality and diversity while reducing the number of queries by a factor of 400."],"url":"http://arxiv.org/abs/2309.10740v1"}
{"created":"2023-09-19 16:34:24","title":"MelodyGLM: Multi-task Pre-training for Symbolic Melody Generation","abstract":"Pre-trained language models have achieved impressive results in various music understanding and generation tasks. However, existing pre-training methods for symbolic melody generation struggle to capture multi-scale, multi-dimensional structural information in note sequences, due to the domain knowledge discrepancy between text and music. Moreover, the lack of available large-scale symbolic melody datasets limits the pre-training improvement. In this paper, we propose MelodyGLM, a multi-task pre-training framework for generating melodies with long-term structure. We design the melodic n-gram and long span sampling strategies to create local and global blank infilling tasks for modeling the local and global structures in melodies. Specifically, we incorporate pitch n-grams, rhythm n-grams, and their combined n-grams into the melodic n-gram blank infilling tasks for modeling the multi-dimensional structures in melodies. To this end, we have constructed a large-scale symbolic melody dataset, MelodyNet, containing more than 0.4 million melody pieces. MelodyNet is utilized for large-scale pre-training and domain-specific n-gram lexicon construction. Both subjective and objective evaluations demonstrate that MelodyGLM surpasses the standard and previous pre-training methods. In particular, subjective evaluations show that, on the melody continuation task, MelodyGLM achieves average improvements of 0.82, 0.87, 0.78, and 0.94 in consistency, rhythmicity, structure, and overall quality, respectively. Notably, MelodyGLM nearly matches the quality of human-composed melodies on the melody inpainting task.","sentences":["Pre-trained language models have achieved impressive results in various music understanding and generation tasks.","However, existing pre-training methods for symbolic melody generation struggle to capture multi-scale, multi-dimensional structural information in note sequences, due to the domain knowledge discrepancy between text and music.","Moreover, the lack of available large-scale symbolic melody datasets limits the pre-training improvement.","In this paper, we propose MelodyGLM, a multi-task pre-training framework for generating melodies with long-term structure.","We design the melodic n-gram and long span sampling strategies to create local and global blank infilling tasks for modeling the local and global structures in melodies.","Specifically, we incorporate pitch n-grams, rhythm n-grams, and their combined n-grams into the melodic n-gram blank infilling tasks for modeling the multi-dimensional structures in melodies.","To this end, we have constructed a large-scale symbolic melody dataset, MelodyNet, containing more than 0.4 million melody pieces.","MelodyNet is utilized for large-scale pre-training and domain-specific n-gram lexicon construction.","Both subjective and objective evaluations demonstrate that MelodyGLM surpasses the standard and previous pre-training methods.","In particular, subjective evaluations show that, on the melody continuation task, MelodyGLM achieves average improvements of 0.82, 0.87, 0.78, and 0.94 in consistency, rhythmicity, structure, and overall quality, respectively.","Notably, MelodyGLM nearly matches the quality of human-composed melodies on the melody inpainting task."],"url":"http://arxiv.org/abs/2309.10738v1"}
{"created":"2023-09-19 16:32:04","title":"Monte-Carlo tree search with uncertainty propagation via optimal transport","abstract":"This paper introduces a novel backup strategy for Monte-Carlo Tree Search (MCTS) designed for highly stochastic and partially observable Markov decision processes. We adopt a probabilistic approach, modeling both value and action-value nodes as Gaussian distributions. We introduce a novel backup operator that computes value nodes as the Wasserstein barycenter of their action-value children nodes; thus, propagating the uncertainty of the estimate across the tree to the root node. We study our novel backup operator when using a novel combination of $L^1$-Wasserstein barycenter with $\\alpha$-divergence, by drawing a notable connection to the generalized mean backup operator. We complement our probabilistic backup operator with two sampling strategies, based on optimistic selection and Thompson sampling, obtaining our Wasserstein MCTS algorithm. We provide theoretical guarantees of asymptotic convergence to the optimal policy, and an empirical evaluation on several stochastic and partially observable environments, where our approach outperforms well-known related baselines.","sentences":["This paper introduces a novel backup strategy for Monte-Carlo Tree Search (MCTS) designed for highly stochastic and partially observable Markov decision processes.","We adopt a probabilistic approach, modeling both value and action-value nodes as Gaussian distributions.","We introduce a novel backup operator that computes value nodes as the Wasserstein barycenter of their action-value children nodes; thus, propagating the uncertainty of the estimate across the tree to the root node.","We study our novel backup operator when using a novel combination of $L^1$-Wasserstein barycenter with $\\alpha$-divergence, by drawing a notable connection to the generalized mean backup operator.","We complement our probabilistic backup operator with two sampling strategies, based on optimistic selection and Thompson sampling, obtaining our Wasserstein MCTS algorithm.","We provide theoretical guarantees of asymptotic convergence to the optimal policy, and an empirical evaluation on several stochastic and partially observable environments, where our approach outperforms well-known related baselines."],"url":"http://arxiv.org/abs/2309.10737v1"}
{"created":"2023-09-19 16:29:34","title":"Mixture Weight Estimation and Model Prediction in Multi-source Multi-target Domain Adaptation","abstract":"We consider the problem of learning a model from multiple heterogeneous sources with the goal of performing well on a new target distribution. The goal of learner is to mix these data sources in a target-distribution aware way and simultaneously minimize the empirical risk on the mixed source. The literature has made some tangible advancements in establishing theory of learning on mixture domain. However, there are still two unsolved problems. Firstly, how to estimate the optimal mixture of sources, given a target domain; Secondly, when there are numerous target domains, how to solve empirical risk minimization (ERM) for each target using possibly unique mixture of data sources in a computationally efficient manner. In this paper we address both problems efficiently and with guarantees. We cast the first problem, mixture weight estimation, as a convex-nonconcave compositional minimax problem, and propose an efficient stochastic algorithm with provable stationarity guarantees. Next, for the second problem, we identify that for certain regimes, solving ERM for each target domain individually can be avoided, and instead parameters for a target optimal model can be viewed as a non-linear function on a space of the mixture coefficients. Building upon this, we show that in the offline setting, a GD-trained overparameterized neural network can provably learn such function to predict the model of target domain instead of solving a designated ERM problem. Finally, we also consider an online setting and propose a label efficient online algorithm, which predicts parameters for new targets given an arbitrary sequence of mixing coefficients, while enjoying regret guarantees.","sentences":["We consider the problem of learning a model from multiple heterogeneous sources with the goal of performing well on a new target distribution.","The goal of learner is to mix these data sources in a target-distribution aware way and simultaneously minimize the empirical risk on the mixed source.","The literature has made some tangible advancements in establishing theory of learning on mixture domain.","However, there are still two unsolved problems.","Firstly, how to estimate the optimal mixture of sources, given a target domain; Secondly, when there are numerous target domains, how to solve empirical risk minimization (ERM) for each target using possibly unique mixture of data sources in a computationally efficient manner.","In this paper we address both problems efficiently and with guarantees.","We cast the first problem, mixture weight estimation, as a convex-nonconcave compositional minimax problem, and propose an efficient stochastic algorithm with provable stationarity guarantees.","Next, for the second problem, we identify that for certain regimes, solving ERM for each target domain individually can be avoided, and instead parameters for a target optimal model can be viewed as a non-linear function on a space of the mixture coefficients.","Building upon this, we show that in the offline setting, a GD-trained overparameterized neural network can provably learn such function to predict the model of target domain instead of solving a designated ERM problem.","Finally, we also consider an online setting and propose a label efficient online algorithm, which predicts parameters for new targets given an arbitrary sequence of mixing coefficients, while enjoying regret guarantees."],"url":"http://arxiv.org/abs/2309.10736v1"}
{"created":"2023-09-19 16:14:57","title":"GPT4AIGChip: Towards Next-Generation AI Accelerator Design Automation via Large Language Models","abstract":"The remarkable capabilities and intricate nature of Artificial Intelligence (AI) have dramatically escalated the imperative for specialized AI accelerators. Nonetheless, designing these accelerators for various AI workloads remains both labor- and time-intensive. While existing design exploration and automation tools can partially alleviate the need for extensive human involvement, they still demand substantial hardware expertise, posing a barrier to non-experts and stifling AI accelerator development. Motivated by the astonishing potential of large language models (LLMs) for generating high-quality content in response to human language instructions, we embark on this work to examine the possibility of harnessing LLMs to automate AI accelerator design. Through this endeavor, we develop GPT4AIGChip, a framework intended to democratize AI accelerator design by leveraging human natural languages instead of domain-specific languages. Specifically, we first perform an in-depth investigation into LLMs' limitations and capabilities for AI accelerator design, thus aiding our understanding of our current position and garnering insights into LLM-powered automated AI accelerator design. Furthermore, drawing inspiration from the above insights, we develop a framework called GPT4AIGChip, which features an automated demo-augmented prompt-generation pipeline utilizing in-context learning to guide LLMs towards creating high-quality AI accelerator design. To our knowledge, this work is the first to demonstrate an effective pipeline for LLM-powered automated AI accelerator generation. Accordingly, we anticipate that our insights and framework can serve as a catalyst for innovations in next-generation LLM-powered design automation tools.","sentences":["The remarkable capabilities and intricate nature of Artificial Intelligence (AI) have dramatically escalated the imperative for specialized AI accelerators.","Nonetheless, designing these accelerators for various AI workloads remains both labor- and time-intensive.","While existing design exploration and automation tools can partially alleviate the need for extensive human involvement, they still demand substantial hardware expertise, posing a barrier to non-experts and stifling AI accelerator development.","Motivated by the astonishing potential of large language models (LLMs) for generating high-quality content in response to human language instructions, we embark on this work to examine the possibility of harnessing LLMs to automate AI accelerator design.","Through this endeavor, we develop GPT4AIGChip, a framework intended to democratize AI accelerator design by leveraging human natural languages instead of domain-specific languages.","Specifically, we first perform an in-depth investigation into LLMs' limitations and capabilities for AI accelerator design, thus aiding our understanding of our current position and garnering insights into LLM-powered automated AI accelerator design.","Furthermore, drawing inspiration from the above insights, we develop a framework called GPT4AIGChip, which features an automated demo-augmented prompt-generation pipeline utilizing in-context learning to guide LLMs towards creating high-quality AI accelerator design.","To our knowledge, this work is the first to demonstrate an effective pipeline for LLM-powered automated AI accelerator generation.","Accordingly, we anticipate that our insights and framework can serve as a catalyst for innovations in next-generation LLM-powered design automation tools."],"url":"http://arxiv.org/abs/2309.10730v1"}
{"created":"2023-09-19 16:12:37","title":"QuBEC: Boosting Equivalence Checking for Quantum Circuits with QEC Embedding","abstract":"Quantum computing has proven to be capable of accelerating many algorithms by performing tasks that classical computers cannot. Currently, Noisy Intermediate Scale Quantum (NISQ) machines struggle from scalability and noise issues to render a commercial quantum computer. However, the physical and software improvements of a quantum computer can efficiently control quantum gate noise. As the complexity of quantum algorithms and implementation increases, software control of quantum circuits may lead to a more intricate design. Consequently, the verification of quantum circuits becomes crucial in ensuring the correctness of the compilation, along with other processes, including quantum error correction and assertions, that can increase the fidelity of quantum circuits. In this paper, we propose a Decision Diagram-based quantum equivalence checking approach, QuBEC, that requires less latency compared to existing techniques, while accounting for circuits with quantum error correction redundancy. Our proposed methodology reduces verification time on certain benchmark circuits by up to $271.49 \\times$, while the number of Decision Diagram nodes required is reduced by up to $798.31 \\times$, compared to state-of-the-art strategies. The proposed QuBEC framework can contribute to the advancement of quantum computing by enabling faster and more efficient verification of quantum circuits, paving the way for the development of larger and more complex quantum algorithms.","sentences":["Quantum computing has proven to be capable of accelerating many algorithms by performing tasks that classical computers cannot.","Currently, Noisy Intermediate Scale Quantum (NISQ) machines struggle from scalability and noise issues to render a commercial quantum computer.","However, the physical and software improvements of a quantum computer can efficiently control quantum gate noise.","As the complexity of quantum algorithms and implementation increases, software control of quantum circuits may lead to a more intricate design.","Consequently, the verification of quantum circuits becomes crucial in ensuring the correctness of the compilation, along with other processes, including quantum error correction and assertions, that can increase the fidelity of quantum circuits.","In this paper, we propose a Decision Diagram-based quantum equivalence checking approach, QuBEC, that requires less latency compared to existing techniques, while accounting for circuits with quantum error correction redundancy.","Our proposed methodology reduces verification time on certain benchmark circuits by up to $271.49 \\times$, while the number of Decision Diagram nodes required is reduced by up to $798.31 \\times$, compared to state-of-the-art strategies.","The proposed QuBEC framework can contribute to the advancement of quantum computing by enabling faster and more efficient verification of quantum circuits, paving the way for the development of larger and more complex quantum algorithms."],"url":"http://arxiv.org/abs/2309.10728v1"}
{"created":"2023-09-19 16:09:01","title":"Few-Shot Panoptic Segmentation With Foundation Models","abstract":"Current state-of-the-art methods for panoptic segmentation require an immense amount of annotated training data that is both arduous and expensive to obtain posing a significant challenge for their widespread adoption. Concurrently, recent breakthroughs in visual representation learning have sparked a paradigm shift leading to the advent of large foundation models that can be trained with completely unlabeled images. In this work, we propose to leverage such task-agnostic image features to enable few-shot panoptic segmentation by presenting Segmenting Panoptic Information with Nearly 0 labels (SPINO). In detail, our method combines a DINOv2 backbone with lightweight network heads for semantic segmentation and boundary estimation. We show that our approach, albeit being trained with only ten annotated images, predicts high-quality pseudo-labels that can be used with any existing panoptic segmentation method. Notably, we demonstrate that SPINO achieves competitive results compared to fully supervised baselines while using less than 0.3% of the ground truth labels, paving the way for learning complex visual recognition tasks leveraging foundation models. To illustrate its general applicability, we further deploy SPINO on real-world robotic vision systems for both outdoor and indoor environments. To foster future research, we make the code and trained models publicly available at http://spino.cs.uni-freiburg.de.","sentences":["Current state-of-the-art methods for panoptic segmentation require an immense amount of annotated training data that is both arduous and expensive to obtain posing a significant challenge for their widespread adoption.","Concurrently, recent breakthroughs in visual representation learning have sparked a paradigm shift leading to the advent of large foundation models that can be trained with completely unlabeled images.","In this work, we propose to leverage such task-agnostic image features to enable few-shot panoptic segmentation by presenting Segmenting Panoptic Information with Nearly 0 labels (SPINO).","In detail, our method combines a DINOv2 backbone with lightweight network heads for semantic segmentation and boundary estimation.","We show that our approach, albeit being trained with only ten annotated images, predicts high-quality pseudo-labels that can be used with any existing panoptic segmentation method.","Notably, we demonstrate that SPINO achieves competitive results compared to fully supervised baselines while using less than 0.3% of the ground truth labels, paving the way for learning complex visual recognition tasks leveraging foundation models.","To illustrate its general applicability, we further deploy SPINO on real-world robotic vision systems for both outdoor and indoor environments.","To foster future research, we make the code and trained models publicly available at http://spino.cs.uni-freiburg.de."],"url":"http://arxiv.org/abs/2309.10726v1"}
{"created":"2023-09-19 16:08:33","title":"Causality-Driven One-Shot Learning for Prostate Cancer Grading from MRI","abstract":"In this paper, we present a novel method to automatically classify medical images that learns and leverages weak causal signals in the image. Our framework consists of a convolutional neural network backbone and a causality-extractor module that extracts cause-effect relationships between feature maps that can inform the model on the appearance of a feature in one place of the image, given the presence of another feature within some other place of the image. To evaluate the effectiveness of our approach in low-data scenarios, we train our causality-driven architecture in a One-shot learning scheme, where we propose a new meta-learning procedure entailing meta-training and meta-testing tasks that are designed using related classes but at different levels of granularity. We conduct binary and multi-class classification experiments on a publicly available dataset of prostate MRI images. To validate the effectiveness of the proposed causality-driven module, we perform an ablation study and conduct qualitative assessments using class activation maps to highlight regions strongly influencing the network's decision-making process. Our findings show that causal relationships among features play a crucial role in enhancing the model's ability to discern relevant information and yielding more reliable and interpretable predictions. This would make it a promising approach for medical image classification tasks.","sentences":["In this paper, we present a novel method to automatically classify medical images that learns and leverages weak causal signals in the image.","Our framework consists of a convolutional neural network backbone and a causality-extractor module that extracts cause-effect relationships between feature maps that can inform the model on the appearance of a feature in one place of the image, given the presence of another feature within some other place of the image.","To evaluate the effectiveness of our approach in low-data scenarios, we train our causality-driven architecture in a One-shot learning scheme, where we propose a new meta-learning procedure entailing meta-training and meta-testing tasks that are designed using related classes but at different levels of granularity.","We conduct binary and multi-class classification experiments on a publicly available dataset of prostate MRI images.","To validate the effectiveness of the proposed causality-driven module, we perform an ablation study and conduct qualitative assessments using class activation maps to highlight regions strongly influencing the network's decision-making process.","Our findings show that causal relationships among features play a crucial role in enhancing the model's ability to discern relevant information and yielding more reliable and interpretable predictions.","This would make it a promising approach for medical image classification tasks."],"url":"http://arxiv.org/abs/2309.10725v1"}
{"created":"2023-09-19 16:04:50","title":"Sound Source Localization is All about Cross-Modal Alignment","abstract":"Humans can easily perceive the direction of sound sources in a visual scene, termed sound source localization. Recent studies on learning-based sound source localization have mainly explored the problem from a localization perspective. However, prior arts and existing benchmarks do not account for a more important aspect of the problem, cross-modal semantic understanding, which is essential for genuine sound source localization. Cross-modal semantic understanding is important in understanding semantically mismatched audio-visual events, e.g., silent objects, or off-screen sounds. To account for this, we propose a cross-modal alignment task as a joint task with sound source localization to better learn the interaction between audio and visual modalities. Thereby, we achieve high localization performance with strong cross-modal semantic understanding. Our method outperforms the state-of-the-art approaches in both sound source localization and cross-modal retrieval. Our work suggests that jointly tackling both tasks is necessary to conquer genuine sound source localization.","sentences":["Humans can easily perceive the direction of sound sources in a visual scene, termed sound source localization.","Recent studies on learning-based sound source localization have mainly explored the problem from a localization perspective.","However, prior arts and existing benchmarks do not account for a more important aspect of the problem, cross-modal semantic understanding, which is essential for genuine sound source localization.","Cross-modal semantic understanding is important in understanding semantically mismatched audio-visual events, e.g., silent objects, or off-screen sounds.","To account for this, we propose a cross-modal alignment task as a joint task with sound source localization to better learn the interaction between audio and visual modalities.","Thereby, we achieve high localization performance with strong cross-modal semantic understanding.","Our method outperforms the state-of-the-art approaches in both sound source localization and cross-modal retrieval.","Our work suggests that jointly tackling both tasks is necessary to conquer genuine sound source localization."],"url":"http://arxiv.org/abs/2309.10724v1"}
{"created":"2023-09-19 16:04:09","title":"LEA*: An A* Variant Algorithm with Improved Edge Efficiency for Robot Motion Planning","abstract":"In this work, we introduce a new graph search algorithm, lazy edged based A* (LEA*), for robot motion planning. By using an edge queue and exploiting the idea of lazy search, LEA* is optimally vertex efficient similar to A*, and has improved edge efficiency compared to A*. LEA* is simple and easy to implement with minimum modification to A*, resulting in a very small overhead compared to previous lazy search algorithms. We also explore the effect of inflated heuristics, which results in the weighted LEA* (wLEA*). We show that the edge efficiency of wLEA* becomes close to LazySP and, thus is near-optimal. We test LEA* and wLEA* on 2D planning problems and planning of a 7-DOF manipulator. We perform a thorough comparison with previous algorithms by considering sparse, medium, and cluttered random worlds and small, medium, and large graph sizes. Our results show that LEA* and wLEA* are the fastest algorithms to find the plan compared to previous algorithms.","sentences":["In this work, we introduce a new graph search algorithm, lazy edged based A* (LEA*), for robot motion planning.","By using an edge queue and exploiting the idea of lazy search, LEA* is optimally vertex efficient similar to A*, and has improved edge efficiency compared to A*.","LEA* is simple and easy to implement with minimum modification to A*, resulting in a very small overhead compared to previous lazy search algorithms.","We also explore the effect of inflated heuristics, which results in the weighted LEA* (wLEA*).","We show that the edge efficiency of wLEA* becomes close to LazySP and, thus is near-optimal.","We test LEA* and wLEA* on 2D planning problems and planning of a 7-DOF manipulator.","We perform a thorough comparison with previous algorithms by considering sparse, medium, and cluttered random worlds and small, medium, and large graph sizes.","Our results show that LEA* and wLEA* are the fastest algorithms to find the plan compared to previous algorithms."],"url":"http://arxiv.org/abs/2309.10722v1"}
{"created":"2023-09-19 16:02:23","title":"DRIVE: Data-driven Robot Input Vector Exploration","abstract":"An accurate motion model is a fundamental component of most autonomous navigation systems. While much work has been done on improving model formulation, no standard protocol exists for gathering empirical data required to train models. In this work, we address this issue by proposing Data-driven Robot Input Vector Exploration (DRIVE), a protocol that enables characterizing uncrewed ground vehicles (UGVs) input limits and gathering empirical model training data. We also propose a novel learned slip approach outperforming similar acceleration learning approaches. Our contributions are validated through an extensive experimental evaluation, cumulating over 7 km and 1.8 h of driving data over three distinct UGVs and four terrain types. We show that our protocol offers increased predictive performance over common human-driven data-gathering protocols. Furthermore, our protocol converges with 46 s of training data, almost four times less than the shortest human dataset gathering protocol. We show that the operational limit for our model is reached in extreme slip conditions encountered on surfaced ice. DRIVE is an efficient way of characterizing UGV motion in its operational conditions. Our code and dataset are both available online at this link: https://github.com/norlab-ulaval/DRIVE.","sentences":["An accurate motion model is a fundamental component of most autonomous navigation systems.","While much work has been done on improving model formulation, no standard protocol exists for gathering empirical data required to train models.","In this work, we address this issue by proposing Data-driven Robot Input Vector Exploration (DRIVE), a protocol that enables characterizing uncrewed ground vehicles (UGVs) input limits and gathering empirical model training data.","We also propose a novel learned slip approach outperforming similar acceleration learning approaches.","Our contributions are validated through an extensive experimental evaluation, cumulating over 7 km and 1.8 h of driving data over three distinct UGVs and four terrain types.","We show that our protocol offers increased predictive performance over common human-driven data-gathering protocols.","Furthermore, our protocol converges with 46 s of training data, almost four times less than the shortest human dataset gathering protocol.","We show that the operational limit for our model is reached in extreme slip conditions encountered on surfaced ice.","DRIVE is an efficient way of characterizing UGV motion in its operational conditions.","Our code and dataset are both available online at this link: https://github.com/norlab-ulaval/DRIVE."],"url":"http://arxiv.org/abs/2309.10718v1"}
{"created":"2023-09-19 16:02:12","title":"Learning Model Predictive Control with Error Dynamics Regression for Autonomous Racing","abstract":"This work presents a novel Learning Model Predictive Control (LMPC) strategy for autonomous racing at the handling limit that can iteratively explore and learn unknown dynamics in high-speed operational domains. We start from existing LMPC formulations and modify the system dynamics learning method. In particular, our approach uses a nominal, global, nonlinear, physics-based model with a local, linear, data-driven learning of the error dynamics. We conduct experiments in simulation, 1/10th scale hardware, and deployed the proposed LMPC on a full-scale autonomous race car used in the Indy Autonomous Challenge (IAC) with closed loop experiments at the Putnam Park Road Course in Indiana, USA. The results show that the proposed control policy exhibits improved robustness to parameter tuning and data scarcity. Incremental and safety-aware exploration toward the limit of handling and iterative learning of the vehicle dynamics in high-speed domains is observed both in simulations and experiments.","sentences":["This work presents a novel Learning Model Predictive Control (LMPC) strategy for autonomous racing at the handling limit that can iteratively explore and learn unknown dynamics in high-speed operational domains.","We start from existing LMPC formulations and modify the system dynamics learning method.","In particular, our approach uses a nominal, global, nonlinear, physics-based model with a local, linear, data-driven learning of the error dynamics.","We conduct experiments in simulation, 1/10th scale hardware, and deployed the proposed LMPC on a full-scale autonomous race car used in the Indy Autonomous Challenge (IAC) with closed loop experiments at the Putnam Park Road Course in Indiana, USA.","The results show that the proposed control policy exhibits improved robustness to parameter tuning and data scarcity.","Incremental and safety-aware exploration toward the limit of handling and iterative learning of the vehicle dynamics in high-speed domains is observed both in simulations and experiments."],"url":"http://arxiv.org/abs/2309.10716v1"}
{"created":"2023-09-19 16:01:20","title":"Reconstruct-and-Generate Diffusion Model for Detail-Preserving Image Denoising","abstract":"Image denoising is a fundamental and challenging task in the field of computer vision. Most supervised denoising methods learn to reconstruct clean images from noisy inputs, which have intrinsic spectral bias and tend to produce over-smoothed and blurry images. Recently, researchers have explored diffusion models to generate high-frequency details in image restoration tasks, but these models do not guarantee that the generated texture aligns with real images, leading to undesirable artifacts. To address the trade-off between visual appeal and fidelity of high-frequency details in denoising tasks, we propose a novel approach called the Reconstruct-and-Generate Diffusion Model (RnG). Our method leverages a reconstructive denoising network to recover the majority of the underlying clean signal, which serves as the initial estimation for subsequent steps to maintain fidelity. Additionally, it employs a diffusion algorithm to generate residual high-frequency details, thereby enhancing visual quality. We further introduce a two-stage training scheme to ensure effective collaboration between the reconstructive and generative modules of RnG. To reduce undesirable texture introduced by the diffusion model, we also propose an adaptive step controller that regulates the number of inverse steps applied by the diffusion model, allowing control over the level of high-frequency details added to each patch as well as saving the inference computational cost. Through our proposed RnG, we achieve a better balance between perception and distortion. We conducted extensive experiments on both synthetic and real denoising datasets, validating the superiority of the proposed approach.","sentences":["Image denoising is a fundamental and challenging task in the field of computer vision.","Most supervised denoising methods learn to reconstruct clean images from noisy inputs, which have intrinsic spectral bias and tend to produce over-smoothed and blurry images.","Recently, researchers have explored diffusion models to generate high-frequency details in image restoration tasks, but these models do not guarantee that the generated texture aligns with real images, leading to undesirable artifacts.","To address the trade-off between visual appeal and fidelity of high-frequency details in denoising tasks, we propose a novel approach called the Reconstruct-and-Generate Diffusion Model (RnG).","Our method leverages a reconstructive denoising network to recover the majority of the underlying clean signal, which serves as the initial estimation for subsequent steps to maintain fidelity.","Additionally, it employs a diffusion algorithm to generate residual high-frequency details, thereby enhancing visual quality.","We further introduce a two-stage training scheme to ensure effective collaboration between the reconstructive and generative modules of RnG. To reduce undesirable texture introduced by the diffusion model, we also propose an adaptive step controller that regulates the number of inverse steps applied by the diffusion model, allowing control over the level of high-frequency details added to each patch as well as saving the inference computational cost.","Through our proposed RnG, we achieve a better balance between perception and distortion.","We conducted extensive experiments on both synthetic and real denoising datasets, validating the superiority of the proposed approach."],"url":"http://arxiv.org/abs/2309.10714v1"}
{"created":"2023-09-19 16:00:49","title":"Interpret Vision Transformers as ConvNets with Dynamic Convolutions","abstract":"There has been a debate about the superiority between vision Transformers and ConvNets, serving as the backbone of computer vision models. Although they are usually considered as two completely different architectures, in this paper, we interpret vision Transformers as ConvNets with dynamic convolutions, which enables us to characterize existing Transformers and dynamic ConvNets in a unified framework and compare their design choices side by side. In addition, our interpretation can also guide the network design as researchers now can consider vision Transformers from the design space of ConvNets and vice versa. We demonstrate such potential through two specific studies. First, we inspect the role of softmax in vision Transformers as the activation function and find it can be replaced by commonly used ConvNets modules, such as ReLU and Layer Normalization, which results in a faster convergence rate and better performance. Second, following the design of depth-wise convolution, we create a corresponding depth-wise vision Transformer that is more efficient with comparable performance. The potential of the proposed unified interpretation is not limited to the given examples and we hope it can inspire the community and give rise to more advanced network architectures.","sentences":["There has been a debate about the superiority between vision Transformers and ConvNets, serving as the backbone of computer vision models.","Although they are usually considered as two completely different architectures, in this paper, we interpret vision Transformers as ConvNets with dynamic convolutions, which enables us to characterize existing Transformers and dynamic ConvNets in a unified framework and compare their design choices side by side.","In addition, our interpretation can also guide the network design as researchers now can consider vision Transformers from the design space of ConvNets and vice versa.","We demonstrate such potential through two specific studies.","First, we inspect the role of softmax in vision Transformers as the activation function and find it can be replaced by commonly used ConvNets modules, such as ReLU and Layer Normalization, which results in a faster convergence rate and better performance.","Second, following the design of depth-wise convolution, we create a corresponding depth-wise vision Transformer that is more efficient with comparable performance.","The potential of the proposed unified interpretation is not limited to the given examples and we hope it can inspire the community and give rise to more advanced network architectures."],"url":"http://arxiv.org/abs/2309.10713v1"}
{"created":"2023-09-19 16:00:09","title":"Latent Space Energy-based Model for Fine-grained Open Set Recognition","abstract":"Fine-grained open-set recognition (FineOSR) aims to recognize images belonging to classes with subtle appearance differences while rejecting images of unknown classes. A recent trend in OSR shows the benefit of generative models to discriminative unknown detection. As a type of generative model, energy-based models (EBM) are the potential for hybrid modeling of generative and discriminative tasks. However, most existing EBMs suffer from density estimation in high-dimensional space, which is critical to recognizing images from fine-grained classes. In this paper, we explore the low-dimensional latent space with energy-based prior distribution for OSR in a fine-grained visual world. Specifically, based on the latent space EBM, we propose an attribute-aware information bottleneck (AIB), a residual attribute feature aggregation (RAFA) module, and an uncertainty-based virtual outlier synthesis (UVOS) module to improve the expressivity, granularity, and density of the samples in fine-grained classes, respectively. Our method is flexible to take advantage of recent vision transformers for powerful visual classification and generation. The method is validated on both fine-grained and general visual classification datasets while preserving the capability of generating photo-realistic fake images with high resolution.","sentences":["Fine-grained open-set recognition (FineOSR) aims to recognize images belonging to classes with subtle appearance differences while rejecting images of unknown classes.","A recent trend in OSR shows the benefit of generative models to discriminative unknown detection.","As a type of generative model, energy-based models (EBM) are the potential for hybrid modeling of generative and discriminative tasks.","However, most existing EBMs suffer from density estimation in high-dimensional space, which is critical to recognizing images from fine-grained classes.","In this paper, we explore the low-dimensional latent space with energy-based prior distribution for OSR in a fine-grained visual world.","Specifically, based on the latent space EBM, we propose an attribute-aware information bottleneck (AIB), a residual attribute feature aggregation (RAFA) module, and an uncertainty-based virtual outlier synthesis (UVOS) module to improve the expressivity, granularity, and density of the samples in fine-grained classes, respectively.","Our method is flexible to take advantage of recent vision transformers for powerful visual classification and generation.","The method is validated on both fine-grained and general visual classification datasets while preserving the capability of generating photo-realistic fake images with high resolution."],"url":"http://arxiv.org/abs/2309.10711v1"}
{"created":"2023-09-19 15:46:40","title":"OpenBA: An Open-sourced 15B Bilingual Asymmetric seq2seq Model Pre-trained from Scratch","abstract":"Large language models (LLMs) with billions of parameters have demonstrated outstanding performance on various natural language processing tasks. This report presents OpenBA, an open-sourced 15B bilingual asymmetric seq2seq model, to contribute an LLM variant to the Chinese-oriented open-source model community. We enhance OpenBA with effective and efficient techniques as well as adopt a three-stage training strategy to train the model from scratch. Our solution can also achieve very competitive performance with only 380B tokens, which is better than LLaMA-70B on the BELEBELE benchmark, BLOOM-176B on the MMLU benchmark, GLM-130B on the C-Eval (hard) benchmark. This report provides the main details to pre-train an analogous model, including pre-training data processing, Bilingual Flan data collection, the empirical observations that inspire our model architecture design, training objectives of different stages, and other enhancement techniques. We have refactored our code to follow the design principles of the Huggingface Transformers Library, making it more convenient for developers to use, and released checkpoints of different training stages at https://huggingface.co/openBA. More details of our project are available at https://github.com/OpenNLG/openBA.git.","sentences":["Large language models (LLMs) with billions of parameters have demonstrated outstanding performance on various natural language processing tasks.","This report presents OpenBA, an open-sourced 15B bilingual asymmetric seq2seq model, to contribute an LLM variant to the Chinese-oriented open-source model community.","We enhance OpenBA with effective and efficient techniques as well as adopt a three-stage training strategy to train the model from scratch.","Our solution can also achieve very competitive performance with only 380B tokens, which is better than LLaMA-70B on the BELEBELE benchmark, BLOOM-176B on the MMLU benchmark, GLM-130B on the C-Eval (hard) benchmark.","This report provides the main details to pre-train an analogous model, including pre-training data processing, Bilingual Flan data collection, the empirical observations that inspire our model architecture design, training objectives of different stages, and other enhancement techniques.","We have refactored our code to follow the design principles of the Huggingface Transformers Library, making it more convenient for developers to use, and released checkpoints of different training stages at https://huggingface.co/openBA.","More details of our project are available at https://github.com/OpenNLG/openBA.git."],"url":"http://arxiv.org/abs/2309.10706v1"}
{"created":"2023-09-19 15:40:42","title":"Measurement Simplification in \u03c1-POMDP with Performance Guarantees","abstract":"Decision making under uncertainty is at the heart of any autonomous system acting with imperfect information. The cost of solving the decision making problem is exponential in the action and observation spaces, thus rendering it unfeasible for many online systems. This paper introduces a novel approach to efficient decision-making, by partitioning the high-dimensional observation space. Using the partitioned observation space, we formulate analytical bounds on the expected information-theoretic reward, for general belief distributions. These bounds are then used to plan efficiently while keeping performance guarantees. We show that the bounds are adaptive, computationally efficient, and that they converge to the original solution. We extend the partitioning paradigm and present a hierarchy of partitioned spaces that allows greater efficiency in planning. We then propose a specific variant of these bounds for Gaussian beliefs and show a theoretical performance improvement of at least a factor of 4. Finally, we compare our novel method to other state of the art algorithms in active SLAM scenarios, in simulation and in real experiments. In both cases we show a significant speed-up in planning with performance guarantees.","sentences":["Decision making under uncertainty is at the heart of any autonomous system acting with imperfect information.","The cost of solving the decision making problem is exponential in the action and observation spaces, thus rendering it unfeasible for many online systems.","This paper introduces a novel approach to efficient decision-making, by partitioning the high-dimensional observation space.","Using the partitioned observation space, we formulate analytical bounds on the expected information-theoretic reward, for general belief distributions.","These bounds are then used to plan efficiently while keeping performance guarantees.","We show that the bounds are adaptive, computationally efficient, and that they converge to the original solution.","We extend the partitioning paradigm and present a hierarchy of partitioned spaces that allows greater efficiency in planning.","We then propose a specific variant of these bounds for Gaussian beliefs and show a theoretical performance improvement of at least a factor of 4.","Finally, we compare our novel method to other state of the art algorithms in active SLAM scenarios, in simulation and in real experiments.","In both cases we show a significant speed-up in planning with performance guarantees."],"url":"http://arxiv.org/abs/2309.10701v1"}
{"created":"2023-09-19 15:37:24","title":"OASIS: Optimal Arrangements for Sensing in SLAM","abstract":"The number and arrangement of sensors on an autonomous mobile robot dramatically influence its perception capabilities. Ensuring that sensors are mounted in a manner that enables accurate detection, localization, and mapping is essential for the success of downstream control tasks. However, when designing a new robotic platform, researchers and practitioners alike usually mimic standard configurations or maximize simple heuristics like field-of-view (FOV) coverage to decide where to place exteroceptive sensors. In this work, we conduct an information-theoretic investigation of this overlooked element of mobile robotic perception in the context of simultaneous localization and mapping (SLAM). We show how to formalize the sensor arrangement problem as a form of subset selection under the E-optimality performance criterion. While this formulation is NP-hard in general, we further show that a combination of greedy sensor selection and fast convex relaxation-based post-hoc verification enables the efficient recovery of certifiably optimal sensor designs in practice. Results from synthetic experiments reveal that sensors placed with OASIS outperform benchmarks in terms of mean squared error of visual SLAM estimates.","sentences":["The number and arrangement of sensors on an autonomous mobile robot dramatically influence its perception capabilities.","Ensuring that sensors are mounted in a manner that enables accurate detection, localization, and mapping is essential for the success of downstream control tasks.","However, when designing a new robotic platform, researchers and practitioners alike usually mimic standard configurations or maximize simple heuristics like field-of-view (FOV) coverage to decide where to place exteroceptive sensors.","In this work, we conduct an information-theoretic investigation of this overlooked element of mobile robotic perception in the context of simultaneous localization and mapping (SLAM).","We show how to formalize the sensor arrangement problem as a form of subset selection under the E-optimality performance criterion.","While this formulation is NP-hard in general, we further show that a combination of greedy sensor selection and fast convex relaxation-based post-hoc verification enables the efficient recovery of certifiably optimal sensor designs in practice.","Results from synthetic experiments reveal that sensors placed with OASIS outperform benchmarks in terms of mean squared error of visual SLAM estimates."],"url":"http://arxiv.org/abs/2309.10698v1"}
{"created":"2023-09-19 15:29:12","title":"From \"Let's Google\" to \"Let's ChatGPT\": Student and Instructor Perspectives on the influence of LLMs on Undergraduate Engineering Education","abstract":"The rise in popularity of Large Language Models (LLMs) has prompted discussions in academic circles, with students exploring LLM-based tools for coursework inquiries and instructors exploring them for teaching and research. Even though a lot of work is underway to create LLM-based tools tailored for students and instructors, there is a lack of comprehensive user studies that capture the perspectives of students and instructors regarding LLMs. This paper addresses this gap by conducting surveys and interviews within undergraduate engineering universities in India. Using 1306 survey responses among students, 112 student interviews, and 27 instructor interviews around the academic usage of ChatGPT (a popular LLM), this paper offers insights into the current usage patterns, perceived benefits, threats, and challenges, as well as recommendations for enhancing the adoption of LLMs among students and instructors. These insights are further utilized to discuss the practical implications of LLMs in undergraduate engineering education and beyond.","sentences":["The rise in popularity of Large Language Models (LLMs) has prompted discussions in academic circles, with students exploring LLM-based tools for coursework inquiries and instructors exploring them for teaching and research.","Even though a lot of work is underway to create LLM-based tools tailored for students and instructors, there is a lack of comprehensive user studies that capture the perspectives of students and instructors regarding LLMs.","This paper addresses this gap by conducting surveys and interviews within undergraduate engineering universities in India.","Using 1306 survey responses among students, 112 student interviews, and 27 instructor interviews around the academic usage of ChatGPT (a popular LLM), this paper offers insights into the current usage patterns, perceived benefits, threats, and challenges, as well as recommendations for enhancing the adoption of LLMs among students and instructors.","These insights are further utilized to discuss the practical implications of LLMs in undergraduate engineering education and beyond."],"url":"http://arxiv.org/abs/2309.10694v1"}
{"created":"2023-09-19 15:25:42","title":"MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback","abstract":"To solve complex tasks, large language models (LLMs) often require multiple rounds of interactions with the user, sometimes assisted by external tools. However, current evaluation paradigms often focus solely on benchmark performance with single-turn exchanges, neglecting the intricate interactions among the user, LLMs, and external tools, creating a discrepancy between benchmark evaluation and real-world use cases. We introduce MINT benchmark to evaluate LLMs' ability to solve tasks with multi-turn interactions by (1) using tools and (2) leveraging natural language feedback. To ensure reproducibility, we provide an evaluation framework where LLMs can access tools by executing Python code and receive natural language feedback from the user simulated with GPT-4. We repurpose a diverse set of established datasets and tasks focusing on reasoning, coding, and decision-making and carefully curate them into a compact subset of instances for efficient evaluation. Our analysis of 20 open- and closed-source LLMs offers intriguing findings. (1) LLMs generally benefit from tool interactions and language feedback, with performance gains (absolute, same below) of 1--8% per additional turn with tool use and 2--17% with natural language feedback. (2) Better single-turn performance does not guarantee better multi-turn performance. (3) Surprisingly, on LLMs we evaluated, we found supervised instruction-finetuning (SIFT) and reinforcement learning from human feedback (RLHF) generally hurt multi-turn capabilities. We hope MINT can help measure progress and incentivize research in improving LLMs' capabilities in multi-turn interactions, especially for open-source communities where multi-turn human evaluation has been less accessible compared to commercial LLMs with a larger user base.","sentences":["To solve complex tasks, large language models (LLMs) often require multiple rounds of interactions with the user, sometimes assisted by external tools.","However, current evaluation paradigms often focus solely on benchmark performance with single-turn exchanges, neglecting the intricate interactions among the user, LLMs, and external tools, creating a discrepancy between benchmark evaluation and real-world use cases.","We introduce MINT benchmark to evaluate LLMs' ability to solve tasks with multi-turn interactions by (1) using tools and (2) leveraging natural language feedback.","To ensure reproducibility, we provide an evaluation framework where LLMs can access tools by executing Python code and receive natural language feedback from the user simulated with GPT-4.","We repurpose a diverse set of established datasets and tasks focusing on reasoning, coding, and decision-making and carefully curate them into a compact subset of instances for efficient evaluation.","Our analysis of 20 open- and closed-source LLMs offers intriguing findings.","(1) LLMs generally benefit from tool interactions and language feedback, with performance gains (absolute, same below) of 1--8% per additional turn with tool use and 2--17% with natural language feedback.","(2) Better single-turn performance does not guarantee better multi-turn performance.","(3) Surprisingly, on LLMs we evaluated, we found supervised instruction-finetuning (SIFT) and reinforcement learning from human feedback (RLHF) generally hurt multi-turn capabilities.","We hope MINT can help measure progress and incentivize research in improving LLMs' capabilities in multi-turn interactions, especially for open-source communities where multi-turn human evaluation has been less accessible compared to commercial LLMs with a larger user base."],"url":"http://arxiv.org/abs/2309.10691v1"}
{"created":"2023-09-19 15:23:52","title":"ReShader: View-Dependent Highlights for Single Image View-Synthesis","abstract":"In recent years, novel view synthesis from a single image has seen significant progress thanks to the rapid advancements in 3D scene representation and image inpainting techniques. While the current approaches are able to synthesize geometrically consistent novel views, they often do not handle the view-dependent effects properly. Specifically, the highlights in their synthesized images usually appear to be glued to the surfaces, making the novel views unrealistic. To address this major problem, we make a key observation that the process of synthesizing novel views requires changing the shading of the pixels based on the novel camera, and moving them to appropriate locations. Therefore, we propose to split the view synthesis process into two independent tasks of pixel reshading and relocation. During the reshading process, we take the single image as the input and adjust its shading based on the novel camera. This reshaded image is then used as the input to an existing view synthesis method to relocate the pixels and produce the final novel view image. We propose to use a neural network to perform reshading and generate a large set of synthetic input-reshaded pairs to train our network. We demonstrate that our approach produces plausible novel view images with realistic moving highlights on a variety of real world scenes.","sentences":["In recent years, novel view synthesis from a single image has seen significant progress thanks to the rapid advancements in 3D scene representation and image inpainting techniques.","While the current approaches are able to synthesize geometrically consistent novel views, they often do not handle the view-dependent effects properly.","Specifically, the highlights in their synthesized images usually appear to be glued to the surfaces, making the novel views unrealistic.","To address this major problem, we make a key observation that the process of synthesizing novel views requires changing the shading of the pixels based on the novel camera, and moving them to appropriate locations.","Therefore, we propose to split the view synthesis process into two independent tasks of pixel reshading and relocation.","During the reshading process, we take the single image as the input and adjust its shading based on the novel camera.","This reshaded image is then used as the input to an existing view synthesis method to relocate the pixels and produce the final novel view image.","We propose to use a neural network to perform reshading and generate a large set of synthetic input-reshaded pairs to train our network.","We demonstrate that our approach produces plausible novel view images with realistic moving highlights on a variety of real world scenes."],"url":"http://arxiv.org/abs/2309.10689v1"}
{"created":"2023-09-19 15:23:07","title":"On the different regimes of Stochastic Gradient Descent","abstract":"Modern deep networks are trained with stochastic gradient descent (SGD) whose key parameters are the number of data considered at each step or batch size $B$, and the step size or learning rate $\\eta$. For small $B$ and large $\\eta$, SGD corresponds to a stochastic evolution of the parameters, whose noise amplitude is governed by the `temperature' $T\\equiv \\eta/B$. Yet this description is observed to break down for sufficiently large batches $B\\geq B^*$, or simplifies to gradient descent (GD) when the temperature is sufficiently small. Understanding where these cross-overs take place remains a central challenge. Here we resolve these questions for a teacher-student perceptron classification model, and show empirically that our key predictions still apply to deep networks. Specifically, we obtain a phase diagram in the $B$-$\\eta$ plane that separates three dynamical phases: $\\textit{(i)}$ a noise-dominated SGD governed by temperature, $\\textit{(ii)}$ a large-first-step-dominated SGD and $\\textit{(iii)}$ GD. These different phases also corresponds to different regimes of generalization error. Remarkably, our analysis reveals that the batch size $B^*$ separating regimes $\\textit{(i)}$ and $\\textit{(ii)}$ scale with the size $P$ of the training set, with an exponent that characterizes the hardness of the classification problem.","sentences":["Modern deep networks are trained with stochastic gradient descent (SGD) whose key parameters are the number of data considered at each step or batch size $B$, and the step size or learning rate $\\eta$.","For small $B$ and large $\\eta$, SGD corresponds to a stochastic evolution of the parameters, whose noise amplitude is governed by the `temperature' $T\\equiv \\eta/B$.","Yet this description is observed to break down for sufficiently large batches $B\\geq B^*$, or simplifies to gradient descent (GD) when the temperature is sufficiently small.","Understanding where these cross-overs take place remains a central challenge.","Here we resolve these questions for a teacher-student perceptron classification model, and show empirically that our key predictions still apply to deep networks.","Specifically, we obtain a phase diagram in the $B$-$\\eta$ plane that separates three dynamical phases: $\\textit{(i)}$ a noise-dominated SGD governed by temperature, $\\textit{(ii)}$ a large-first-step-dominated SGD and $\\textit{(iii)}$ GD.","These different phases also corresponds to different regimes of generalization error.","Remarkably, our analysis reveals that the batch size $B^*$ separating regimes $\\textit{(i)}$ and $\\textit{(ii)}$ scale with the size $P$ of the training set, with an exponent that characterizes the hardness of the classification problem."],"url":"http://arxiv.org/abs/2309.10688v1"}
{"created":"2023-09-19 15:08:10","title":"Locally Stylized Neural Radiance Fields","abstract":"In recent years, there has been increasing interest in applying stylization on 3D scenes from a reference style image, in particular onto neural radiance fields (NeRF). While performing stylization directly on NeRF guarantees appearance consistency over arbitrary novel views, it is a challenging problem to guide the transfer of patterns from the style image onto different parts of the NeRF scene. In this work, we propose a stylization framework for NeRF based on local style transfer. In particular, we use a hash-grid encoding to learn the embedding of the appearance and geometry components, and show that the mapping defined by the hash table allows us to control the stylization to a certain extent. Stylization is then achieved by optimizing the appearance branch while keeping the geometry branch fixed. To support local style transfer, we propose a new loss function that utilizes a segmentation network and bipartite matching to establish region correspondences between the style image and the content images obtained from volume rendering. Our experiments show that our method yields plausible stylization results with novel view synthesis while having flexible controllability via manipulating and customizing the region correspondences.","sentences":["In recent years, there has been increasing interest in applying stylization on 3D scenes from a reference style image, in particular onto neural radiance fields (NeRF).","While performing stylization directly on NeRF guarantees appearance consistency over arbitrary novel views, it is a challenging problem to guide the transfer of patterns from the style image onto different parts of the NeRF scene.","In this work, we propose a stylization framework for NeRF based on local style transfer.","In particular, we use a hash-grid encoding to learn the embedding of the appearance and geometry components, and show that the mapping defined by the hash table allows us to control the stylization to a certain extent.","Stylization is then achieved by optimizing the appearance branch while keeping the geometry branch fixed.","To support local style transfer, we propose a new loss function that utilizes a segmentation network and bipartite matching to establish region correspondences between the style image and the content images obtained from volume rendering.","Our experiments show that our method yields plausible stylization results with novel view synthesis while having flexible controllability via manipulating and customizing the region correspondences."],"url":"http://arxiv.org/abs/2309.10684v1"}
{"created":"2023-09-19 15:07:26","title":"Learning-Initialized Trajectory Planning in Unknown Environments","abstract":"Autonomous flight in unknown environments requires precise planning for both the spatial and temporal profiles of trajectories, which generally involves nonconvex optimization, leading to high time costs and susceptibility to local optima. To address these limitations, we introduce the Learning-Initialized Trajectory Planner (LIT-Planner), a novel approach that guides optimization using a Neural Network (NN) Planner to provide initial values. We first leverage the spatial-temporal optimization with batch sampling to generate training cases, aiming to capture multimodality in trajectories. Based on these data, the NN-Planner maps visual and inertial observations to trajectory parameters for handling unknown environments. The network outputs are then optimized to enhance both reliability and explainability, ensuring robust performance. Furthermore, we propose a framework that supports robust online replanning with tolerance to planning latency. Comprehensive simulations validate the LIT-Planner's time efficiency without compromising trajectory quality compared to optimization-based methods. Real-world experiments further demonstrate its practical suitability for autonomous drone navigation.","sentences":["Autonomous flight in unknown environments requires precise planning for both the spatial and temporal profiles of trajectories, which generally involves nonconvex optimization, leading to high time costs and susceptibility to local optima.","To address these limitations, we introduce the Learning-Initialized Trajectory Planner (LIT-Planner), a novel approach that guides optimization using a Neural Network (NN) Planner to provide initial values.","We first leverage the spatial-temporal optimization with batch sampling to generate training cases, aiming to capture multimodality in trajectories.","Based on these data, the NN-Planner maps visual and inertial observations to trajectory parameters for handling unknown environments.","The network outputs are then optimized to enhance both reliability and explainability, ensuring robust performance.","Furthermore, we propose a framework that supports robust online replanning with tolerance to planning latency.","Comprehensive simulations validate the LIT-Planner's time efficiency without compromising trajectory quality compared to optimization-based methods.","Real-world experiments further demonstrate its practical suitability for autonomous drone navigation."],"url":"http://arxiv.org/abs/2309.10683v1"}
{"created":"2023-09-19 15:04:55","title":"Social Interactions Mediated by the Internet and the Big- Five: a Cross-Country Analysis","abstract":"This study analyzes the possible relationship between personality traits, in terms of Big Five (extraversion, agreeableness, responsibility, emotional stability and openness to experience), and social interactions mediated by digital platforms in different socioeconomic and cultural contexts. We considered data from a questionnaire and the experience of using a chatbot, as a mean of requesting and offering help, with students from 4 universities: University of Trento (Italy), the National University of Mongolia, the School of Economics of London (United Kingdom) and the Universidad Cat\\'olica Nuestra Se\\~nora de la Asunci\\'on (Paraguay). The main findings confirm that personality traits may influence social interactions and active participation in groups. Therefore, they should be taken into account to enrich the recommendation of matching algorithms between people who ask for help and people who could respond not only on the basis of their knowledge and skills.","sentences":["This study analyzes the possible relationship between personality traits, in terms of Big Five (extraversion, agreeableness, responsibility, emotional stability and openness to experience), and social interactions mediated by digital platforms in different socioeconomic and cultural contexts.","We considered data from a questionnaire and the experience of using a chatbot, as a mean of requesting and offering help, with students from 4 universities: University of Trento (Italy), the National University of Mongolia, the School of Economics of London (United Kingdom) and the Universidad Cat\\'olica Nuestra Se\\~nora de la Asunci\\'on (Paraguay).","The main findings confirm that personality traits may influence social interactions and active participation in groups.","Therefore, they should be taken into account to enrich the recommendation of matching algorithms between people who ask for help and people who could respond not only on the basis of their knowledge and skills."],"url":"http://arxiv.org/abs/2309.10681v1"}
{"created":"2023-09-19 15:03:12","title":"Dialogues with algorithms","abstract":"In this short paper we focus on human in the loop for rule-based software used for law enforcement. For example, one can think of software that computes fines like tachograph software, software that prepares evidence like DNA sequencing software or social profiling software to patrol in high-risk zones, among others. An important difference between a legal human agent and a software application lies in possible dialogues. A human agent can be interrogated to motivate her decisions. Often such dialogues with software are at the best extremely hard but mostly impossible. We observe that the absence of a dialogue can sincerely violate civil rights and legal principles like, for example, Transparency or Contestability. Thus, possible dialogues with legal algorithms are at the least highly desirable. Futuristic as this may sound, we observe that in various realms of formal methods, such dialogues are easily obtainable. However, this triggers the usual tension between the expressibility of the dialogue language and the feasibility of the corresponding computations.","sentences":["In this short paper we focus on human in the loop for rule-based software used for law enforcement.","For example, one can think of software that computes fines like tachograph software, software that prepares evidence like DNA sequencing software or social profiling software to patrol in high-risk zones, among others.","An important difference between a legal human agent and a software application lies in possible dialogues.","A human agent can be interrogated to motivate her decisions.","Often such dialogues with software are at the best extremely hard but mostly impossible.","We observe that the absence of a dialogue can sincerely violate civil rights and legal principles like, for example, Transparency or Contestability.","Thus, possible dialogues with legal algorithms are at the least highly desirable.","Futuristic as this may sound, we observe that in various realms of formal methods, such dialogues are easily obtainable.","However, this triggers the usual tension between the expressibility of the dialogue language and the feasibility of the corresponding computations."],"url":"http://arxiv.org/abs/2309.10678v1"}
{"created":"2023-09-19 15:02:58","title":"Estimating Contamination via Perplexity: Quantifying Memorisation in Language Model Evaluation","abstract":"Data contamination in model evaluation is getting increasingly prevalent as the massive training corpora of large language models often unintentionally include benchmark samples. Therefore, contamination analysis has became an inevitable part of reliable model evaluation. However, existing method of contamination analysis requires the access of the entire training data which is often confidential for recent models. This prevent the community to rigorously audit these models and conduct accurate assessment of their capability. In this paper, we propose a novel method to quantify contamination without the access of the full training set, that measure the extent of contamination with perplexity. Our analysis provides evidence of significant memorisation of recent foundation models in popular reading comprehension, summarisation benchmarks, while multiple choice appears less contaminated.","sentences":["Data contamination in model evaluation is getting increasingly prevalent as the massive training corpora of large language models often unintentionally include benchmark samples.","Therefore, contamination analysis has became an inevitable part of reliable model evaluation.","However, existing method of contamination analysis requires the access of the entire training data which is often confidential for recent models.","This prevent the community to rigorously audit these models and conduct accurate assessment of their capability.","In this paper, we propose a novel method to quantify contamination without the access of the full training set, that measure the extent of contamination with perplexity.","Our analysis provides evidence of significant memorisation of recent foundation models in popular reading comprehension, summarisation benchmarks, while multiple choice appears less contaminated."],"url":"http://arxiv.org/abs/2309.10677v1"}
{"created":"2023-09-19 14:56:31","title":"USED: Universal Speaker Extraction and Diarization","abstract":"Speaker extraction and diarization are two crucial enabling techniques for speech applications. Speaker extraction aims to extract a target speaker's voice from a multi-talk mixture, while speaker diarization demarcates speech segments by speaker, identifying `who spoke when'. The previous studies have typically treated the two tasks independently. However, the two tasks share a similar objective, that is to disentangle the speakers in the spectral domain for the former but in the temporal domain for the latter. It is logical to believe that the speaker turns obtained from speaker diarization can benefit speaker extraction, while the extracted speech offers more accurate speaker turns than the mixture speech. In this paper, we propose a unified framework called Universal Speaker Extraction and Diarization (USED). We extend the existing speaker extraction model to simultaneously extract the waveforms of all speakers. We also employ a scenario-aware differentiated loss function to address the problem of sparsely overlapped speech in real-world conversations. We show that the USED model significantly outperforms the baselines for both speaker extraction and diarization tasks, in both highly overlapped and sparsely overlapped scenarios. Audio samples are available at https://ajyy.github.io/demo/USED/.","sentences":["Speaker extraction and diarization are two crucial enabling techniques for speech applications.","Speaker extraction aims to extract a target speaker's voice from a multi-talk mixture, while speaker diarization demarcates speech segments by speaker, identifying `who spoke when'.","The previous studies have typically treated the two tasks independently.","However, the two tasks share a similar objective, that is to disentangle the speakers in the spectral domain for the former but in the temporal domain for the latter.","It is logical to believe that the speaker turns obtained from speaker diarization can benefit speaker extraction, while the extracted speech offers more accurate speaker turns than the mixture speech.","In this paper, we propose a unified framework called Universal Speaker Extraction and Diarization (USED).","We extend the existing speaker extraction model to simultaneously extract the waveforms of all speakers.","We also employ a scenario-aware differentiated loss function to address the problem of sparsely overlapped speech in real-world conversations.","We show that the USED model significantly outperforms the baselines for both speaker extraction and diarization tasks, in both highly overlapped and sparsely overlapped scenarios.","Audio samples are available at https://ajyy.github.io/demo/USED/."],"url":"http://arxiv.org/abs/2309.10674v1"}
{"created":"2023-09-19 14:54:29","title":"Asymptotically Optimal Belief Space Planning in Discrete Partially-Observable Domains","abstract":"Robots often have to operate in discrete partially observable worlds, where the states of world are only observable at runtime. To react to different world states, robots need contingencies. However, computing contingencies is costly and often non-optimal. To address this problem, we develop the improved path tree optimization (PTO) method. PTO computes motion contingencies by constructing a tree of motion paths in belief space. This is achieved by constructing a graph of configurations, then adding observation edges to extend the graph to belief space. Afterwards, we use a dynamic programming step to extract the path tree. PTO extends prior work by adding a camera-based state sampler to improve the search for observation points. We also add support to non-euclidean state spaces, provide an implementation in the open motion planning library (OMPL), and evaluate PTO on four realistic scenarios with a virtual camera in up to 10-dimensional state spaces. We compare PTO with a default and with the new camera-based state sampler. The results indicate that the camera-based state sampler improves success rates in 3 out of 4 scenarios while having a significant lower memory footprint. This makes PTO an important contribution to advance the state-of-the-art for discrete belief space planning.","sentences":["Robots often have to operate in discrete partially observable worlds, where the states of world are only observable at runtime.","To react to different world states, robots need contingencies.","However, computing contingencies is costly and often non-optimal.","To address this problem, we develop the improved path tree optimization (PTO) method.","PTO computes motion contingencies by constructing a tree of motion paths in belief space.","This is achieved by constructing a graph of configurations, then adding observation edges to extend the graph to belief space.","Afterwards, we use a dynamic programming step to extract the path tree.","PTO extends prior work by adding a camera-based state sampler to improve the search for observation points.","We also add support to non-euclidean state spaces, provide an implementation in the open motion planning library (OMPL), and evaluate PTO on four realistic scenarios with a virtual camera in up to 10-dimensional state spaces.","We compare PTO with a default and with the new camera-based state sampler.","The results indicate that the camera-based state sampler improves success rates in 3 out of 4 scenarios while having a significant lower memory footprint.","This makes PTO an important contribution to advance the state-of-the-art for discrete belief space planning."],"url":"http://arxiv.org/abs/2309.10672v1"}
{"created":"2023-09-19 14:54:07","title":"CloudSimSC: A Toolkit for Modeling and Simulation of Serverless Computing Environments","abstract":"Serverless computing is gaining traction as an attractive model for the deployment of a multitude of workloads in the cloud. Designing and building effective resource management solutions for any computing environment requires extensive long term testing, experimentation and analysis of the achieved performance metrics. Utilizing real test beds and serverless platforms for such experimentation work is often times not possible due to resource, time and cost constraints. Thus, employing simulators to model these environments is key to overcoming the challenge of examining the viability of such novel ideas for resource management. Existing simulation software developed for serverless environments lack generalizibility in terms of their architecture as well as the various aspects of resource management, where most are purely focused on modeling function performance under a specific platform architecture. In contrast, we have developed a serverless simulation model with induced flexibility in its architecture as well as the key resource management aspects of function scheduling and scaling. Further, we incorporate techniques for easily deriving monitoring metrics required for evaluating any implemented solutions by users. Our work is presented as CloudSimSC, a modular extension to CloudSim which is a simulator tool extensively used for modeling cloud environments by the research community. We discuss the implemented features in our simulation tool using multiple use cases.","sentences":["Serverless computing is gaining traction as an attractive model for the deployment of a multitude of workloads in the cloud.","Designing and building effective resource management solutions for any computing environment requires extensive long term testing, experimentation and analysis of the achieved performance metrics.","Utilizing real test beds and serverless platforms for such experimentation work is often times not possible due to resource, time and cost constraints.","Thus, employing simulators to model these environments is key to overcoming the challenge of examining the viability of such novel ideas for resource management.","Existing simulation software developed for serverless environments lack generalizibility in terms of their architecture as well as the various aspects of resource management, where most are purely focused on modeling function performance under a specific platform architecture.","In contrast, we have developed a serverless simulation model with induced flexibility in its architecture as well as the key resource management aspects of function scheduling and scaling.","Further, we incorporate techniques for easily deriving monitoring metrics required for evaluating any implemented solutions by users.","Our work is presented as CloudSimSC, a modular extension to CloudSim which is a simulator tool extensively used for modeling cloud environments by the research community.","We discuss the implemented features in our simulation tool using multiple use cases."],"url":"http://arxiv.org/abs/2309.10671v1"}
{"created":"2023-09-19 14:50:38","title":"Language Modeling Is Compression","abstract":"It has long been established that predictive models can be transformed into lossless compressors and vice versa. Incidentally, in recent years, the machine learning community has focused on training increasingly large and powerful self-supervised (language) models. Since these large language models exhibit impressive predictive capabilities, they are well-positioned to be strong compressors. In this work, we advocate for viewing the prediction problem through the lens of compression and evaluate the compression capabilities of large (foundation) models. We show that large language models are powerful general-purpose predictors and that the compression viewpoint provides novel insights into scaling laws, tokenization, and in-context learning. For example, Chinchilla 70B, while trained primarily on text, compresses ImageNet patches to 43.4% and LibriSpeech samples to 16.4% of their raw size, beating domain-specific compressors like PNG (58.5%) or FLAC (30.3%), respectively. Finally, we show that the prediction-compression equivalence allows us to use any compressor (like gzip) to build a conditional generative model.","sentences":["It has long been established that predictive models can be transformed into lossless compressors and vice versa.","Incidentally, in recent years, the machine learning community has focused on training increasingly large and powerful self-supervised (language) models.","Since these large language models exhibit impressive predictive capabilities, they are well-positioned to be strong compressors.","In this work, we advocate for viewing the prediction problem through the lens of compression and evaluate the compression capabilities of large (foundation) models.","We show that large language models are powerful general-purpose predictors and that the compression viewpoint provides novel insights into scaling laws, tokenization, and in-context learning.","For example, Chinchilla 70B, while trained primarily on text, compresses ImageNet patches to 43.4% and LibriSpeech samples to 16.4% of their raw size, beating domain-specific compressors like PNG (58.5%) or FLAC (30.3%), respectively.","Finally, we show that the prediction-compression equivalence allows us to use any compressor (like gzip) to build a conditional generative model."],"url":"http://arxiv.org/abs/2309.10668v1"}
{"created":"2023-09-19 14:49:50","title":"Learning Tri-modal Embeddings for Zero-Shot Soundscape Mapping","abstract":"We focus on the task of soundscape mapping, which involves predicting the most probable sounds that could be perceived at a particular geographic location. We utilise recent state-of-the-art models to encode geotagged audio, a textual description of the audio, and an overhead image of its capture location using contrastive pre-training. The end result is a shared embedding space for the three modalities, which enables the construction of soundscape maps for any geographic region from textual or audio queries. Using the SoundingEarth dataset, we find that our approach significantly outperforms the existing SOTA, with an improvement of image-to-audio Recall@100 from 0.256 to 0.450. Our code is available at https://github.com/mvrl/geoclap.","sentences":["We focus on the task of soundscape mapping, which involves predicting the most probable sounds that could be perceived at a particular geographic location.","We utilise recent state-of-the-art models to encode geotagged audio, a textual description of the audio, and an overhead image of its capture location using contrastive pre-training.","The end result is a shared embedding space for the three modalities, which enables the construction of soundscape maps for any geographic region from textual or audio queries.","Using the SoundingEarth dataset, we find that our approach significantly outperforms the existing SOTA, with an improvement of image-to-audio Recall@100 from 0.256 to 0.450.","Our code is available at https://github.com/mvrl/geoclap."],"url":"http://arxiv.org/abs/2309.10667v1"}
{"created":"2023-09-19 14:48:21","title":"Fast-dRRT*: Efficient Multi-Robot Motion Planning for Automated Industrial Manufacturing","abstract":"We present Fast-dRRT*, a sampling-based multi-robot planner, for real-time industrial automation scenarios. Fast-dRRT* builds upon the discrete rapidly-exploring random tree (dRRT*) planner, and extends dRRT* by using pre-computed swept volumes for efficient collision detection, deadlock avoidance for partial multi-robot problems, and a simplified rewiring strategy. We evaluate Fast-dRRT* on five challenging multi-robot scenarios using two to four industrial robot arms from various manufacturers. The scenarios comprise situations involving deadlocks, narrow passages, and close proximity tasks. The results are compared against dRRT*, and show Fast-dRRT* to outperform dRRT* by up to 94% in terms of finding solutions within given time limits, while only sacrificing up to 35% on initial solution cost. Furthermore, Fast-dRRT* demonstrates resilience against noise in target configurations, and is able to solve challenging welding, and pick and place tasks with reduced computational time. This makes Fast-dRRT* a promising option for real-time motion planning in industrial automation.","sentences":["We present Fast-dRRT*, a sampling-based multi-robot planner, for real-time industrial automation scenarios.","Fast-dRRT* builds upon the discrete rapidly-exploring random tree (dRRT*) planner, and extends dRRT*","by using pre-computed swept volumes for efficient collision detection, deadlock avoidance for partial multi-robot problems, and a simplified rewiring strategy.","We evaluate Fast-dRRT* on five challenging multi-robot scenarios using two to four industrial robot arms from various manufacturers.","The scenarios comprise situations involving deadlocks, narrow passages, and close proximity tasks.","The results are compared against dRRT*, and show Fast-dRRT* to outperform dRRT*","by up to 94% in terms of finding solutions within given time limits, while only sacrificing up to 35% on initial solution cost.","Furthermore, Fast-dRRT* demonstrates resilience against noise in target configurations, and is able to solve challenging welding, and pick and place tasks with reduced computational time.","This makes Fast-dRRT* a promising option for real-time motion planning in industrial automation."],"url":"http://arxiv.org/abs/2309.10665v1"}
{"created":"2023-09-19 14:48:20","title":"Preliminaries paper: Byzantine Tolerant Strong Auditable Atomic Register","abstract":"An auditable register extends the classical register with an audit operation that returns information on the read operations performed on the register. In this paper, we study Byzantine resilient auditable register implementations in an asynchronous message-passing system. Existing solutions implement the auditable register on top of at least 4f+1 servers, where at most $f$ can be Byzantine. We show that 4f+1 servers are necessary to implement auditability without communication between servers, or implement does not implement strong auditability when relaxing the constraint on the servers' communication, letting them interact with each other. In this setting, it exists a solution using 3f+1 servers to implement a simple auditable atomic register. In this work, we implement strong auditable register using 3f+1 servers with server to server communication, this result reinforced that with communication between servers, auditability (event strong auditability) does not come with an additional cost in terms of the number of servers.","sentences":["An auditable register extends the classical register with an audit operation that returns information on the read operations performed on the register.","In this paper, we study Byzantine resilient auditable register implementations in an asynchronous message-passing system.","Existing solutions implement the auditable register on top of at least 4f+1 servers, where at most $f$ can be Byzantine.","We show that 4f+1 servers are necessary to implement auditability without communication between servers, or implement does not implement strong auditability when relaxing the constraint on the servers' communication, letting them interact with each other.","In this setting, it exists a solution using 3f+1 servers to implement a simple auditable atomic register.","In this work, we implement strong auditable register using 3f+1 servers with server to server communication, this result reinforced that with communication between servers, auditability (event strong auditability) does not come with an additional cost in terms of the number of servers."],"url":"http://arxiv.org/abs/2309.10664v1"}
{"created":"2023-09-19 14:46:11","title":"Improved guarantees for the a priori TSP","abstract":"We revisit the a priori TSP (with independent activation) and prove stronger approximation guarantees than were previously known. In the a priori TSP, we are given a metric space $(V,c)$ and an activation probability $p(v)$ for each customer $v\\in V$. We ask for a TSP tour $T$ for $V$ that minimizes the expected length after cutting $T$ short by skipping the inactive customers. All known approximation algorithms select a nonempty subset $S$ of the customers and construct a master route solution, consisting of a TSP tour for $S$ and two edges connecting every customer $v\\in V\\setminus S$ to a nearest customer in $S$. We address the following questions. If we randomly sample the subset $S$, what should be the sampling probabilities? How much worse than the optimum can the best master route solution be? The answers to these questions (we provide almost matching lower and upper bounds) lead to improved approximation guarantees: less than 3.1 with randomized sampling, and less than 5.9 with a deterministic polynomial-time algorithm.","sentences":["We revisit the a priori TSP (with independent activation) and prove stronger approximation guarantees than were previously known.","In the a priori TSP, we are given a metric space $(V,c)$ and an activation probability $p(v)$ for each customer $v\\in V$.","We ask for a TSP tour $T$ for $V$ that minimizes the expected length after cutting $T$ short by skipping the inactive customers.","All known approximation algorithms select a nonempty subset $S$ of the customers and construct a master route solution, consisting of a TSP tour for $S$ and two edges connecting every customer $v\\in V\\setminus S$ to a nearest customer in $S$. We address the following questions.","If we randomly sample the subset $S$, what should be the sampling probabilities?","How much worse than the optimum can the best master route solution be?","The answers to these questions (we provide almost matching lower and upper bounds) lead to improved approximation guarantees: less than 3.1 with randomized sampling, and less than 5.9 with a deterministic polynomial-time algorithm."],"url":"http://arxiv.org/abs/2309.10663v1"}
{"created":"2023-09-19 14:42:33","title":"NusaWrites: Constructing High-Quality Corpora for Underrepresented and Extremely Low-Resource Languages","abstract":"Democratizing access to natural language processing (NLP) technology is crucial, especially for underrepresented and extremely low-resource languages. Previous research has focused on developing labeled and unlabeled corpora for these languages through online scraping and document translation. While these methods have proven effective and cost-efficient, we have identified limitations in the resulting corpora, including a lack of lexical diversity and cultural relevance to local communities. To address this gap, we conduct a case study on Indonesian local languages. We compare the effectiveness of online scraping, human translation, and paragraph writing by native speakers in constructing datasets. Our findings demonstrate that datasets generated through paragraph writing by native speakers exhibit superior quality in terms of lexical diversity and cultural content. In addition, we present the \\datasetname{} benchmark, encompassing 12 underrepresented and extremely low-resource languages spoken by millions of individuals in Indonesia. Our empirical experiment results using existing multilingual large language models conclude the need to extend these models to more underrepresented languages. We release the NusaWrites dataset at https://github.com/IndoNLP/nusa-writes.","sentences":["Democratizing access to natural language processing (NLP) technology is crucial, especially for underrepresented and extremely low-resource languages.","Previous research has focused on developing labeled and unlabeled corpora for these languages through online scraping and document translation.","While these methods have proven effective and cost-efficient, we have identified limitations in the resulting corpora, including a lack of lexical diversity and cultural relevance to local communities.","To address this gap, we conduct a case study on Indonesian local languages.","We compare the effectiveness of online scraping, human translation, and paragraph writing by native speakers in constructing datasets.","Our findings demonstrate that datasets generated through paragraph writing by native speakers exhibit superior quality in terms of lexical diversity and cultural content.","In addition, we present the \\datasetname{} benchmark, encompassing 12 underrepresented and extremely low-resource languages spoken by millions of individuals in Indonesia.","Our empirical experiment results using existing multilingual large language models conclude the need to extend these models to more underrepresented languages.","We release the NusaWrites dataset at https://github.com/IndoNLP/nusa-writes."],"url":"http://arxiv.org/abs/2309.10661v1"}
{"created":"2023-09-19 14:40:13","title":"Implementing a new fully stepwise decomposition-based sampling technique for the hybrid water level forecasting model in real-world application","abstract":"Various time variant non-stationary signals need to be pre-processed properly in hydrological time series forecasting in real world, for example, predictions of water level. Decomposition method is a good candidate and widely used in such a pre-processing problem. However, decomposition methods with an inappropriate sampling technique may introduce future data which is not available in practical applications, and result in incorrect decomposition-based forecasting models. In this work, a novel Fully Stepwise Decomposition-Based (FSDB) sampling technique is well designed for the decomposition-based forecasting model, strictly avoiding introducing future information. This sampling technique with decomposition methods, such as Variational Mode Decomposition (VMD) and Singular spectrum analysis (SSA), is applied to predict water level time series in three different stations of Guoyang and Chaohu basins in China. Results of VMD-based hybrid model using FSDB sampling technique show that Nash-Sutcliffe Efficiency (NSE) coefficient is increased by 6.4%, 28.8% and 7.0% in three stations respectively, compared with those obtained from the currently most advanced sampling technique. In the meantime, for series of SSA-based experiments, NSE is increased by 3.2%, 3.1% and 1.1% respectively. We conclude that the newly developed FSDB sampling technique can be used to enhance the performance of decomposition-based hybrid model in water level time series forecasting in real world.","sentences":["Various time variant non-stationary signals need to be pre-processed properly in hydrological time series forecasting in real world, for example, predictions of water level.","Decomposition method is a good candidate and widely used in such a pre-processing problem.","However, decomposition methods with an inappropriate sampling technique may introduce future data which is not available in practical applications, and result in incorrect decomposition-based forecasting models.","In this work, a novel Fully Stepwise Decomposition-Based (FSDB) sampling technique is well designed for the decomposition-based forecasting model, strictly avoiding introducing future information.","This sampling technique with decomposition methods, such as Variational Mode Decomposition (VMD) and Singular spectrum analysis (SSA), is applied to predict water level time series in three different stations of Guoyang and Chaohu basins in China.","Results of VMD-based hybrid model using FSDB sampling technique show that Nash-Sutcliffe Efficiency (NSE) coefficient is increased by 6.4%, 28.8% and 7.0% in three stations respectively, compared with those obtained from the currently most advanced sampling technique.","In the meantime, for series of SSA-based experiments, NSE is increased by 3.2%, 3.1% and 1.1% respectively.","We conclude that the newly developed FSDB sampling technique can be used to enhance the performance of decomposition-based hybrid model in water level time series forecasting in real world."],"url":"http://arxiv.org/abs/2309.10658v1"}
{"created":"2023-09-19 14:39:39","title":"Learning Adaptive Safety for Multi-Agent Systems","abstract":"Ensuring safety in dynamic multi-agent systems is challenging due to limited information about the other agents. Control Barrier Functions (CBFs) are showing promise for safety assurance but current methods make strong assumptions about other agents and often rely on manual tuning to balance safety, feasibility, and performance. In this work, we delve into the problem of adaptive safe learning for multi-agent systems with CBF. We show how emergent behavior can be profoundly influenced by the CBF configuration, highlighting the necessity for a responsive and dynamic approach to CBF design. We present ASRL, a novel adaptive safe RL framework, to fully automate the optimization of policy and CBF coefficients, to enhance safety and long-term performance through reinforcement learning. By directly interacting with the other agents, ASRL learns to cope with diverse agent behaviours and maintains the cost violations below a desired limit. We evaluate ASRL in a multi-robot system and a competitive multi-agent racing scenario, against learning-based and control-theoretic approaches. We empirically demonstrate the efficacy and flexibility of ASRL, and assess generalization and scalability to out-of-distribution scenarios. Code and supplementary material are public online.","sentences":["Ensuring safety in dynamic multi-agent systems is challenging due to limited information about the other agents.","Control Barrier Functions (CBFs) are showing promise for safety assurance but current methods make strong assumptions about other agents and often rely on manual tuning to balance safety, feasibility, and performance.","In this work, we delve into the problem of adaptive safe learning for multi-agent systems with CBF.","We show how emergent behavior can be profoundly influenced by the CBF configuration, highlighting the necessity for a responsive and dynamic approach to CBF design.","We present ASRL, a novel adaptive safe RL framework, to fully automate the optimization of policy and CBF coefficients, to enhance safety and long-term performance through reinforcement learning.","By directly interacting with the other agents, ASRL learns to cope with diverse agent behaviours and maintains the cost violations below a desired limit.","We evaluate ASRL in a multi-robot system and a competitive multi-agent racing scenario, against learning-based and control-theoretic approaches.","We empirically demonstrate the efficacy and flexibility of ASRL, and assess generalization and scalability to out-of-distribution scenarios.","Code and supplementary material are public online."],"url":"http://arxiv.org/abs/2309.10657v1"}
{"created":"2023-09-19 14:39:03","title":"A spectrum of physics-informed Gaussian processes for regression in engineering","abstract":"Despite the growing availability of sensing and data in general, we remain unable to fully characterise many in-service engineering systems and structures from a purely data-driven approach. The vast data and resources available to capture human activity are unmatched in our engineered world, and, even in cases where data could be referred to as ``big,'' they will rarely hold information across operational windows or life spans. This paper pursues the combination of machine learning technology and physics-based reasoning to enhance our ability to make predictive models with limited data. By explicitly linking the physics-based view of stochastic processes with a data-based regression approach, a spectrum of possible Gaussian process models are introduced that enable the incorporation of different levels of expert knowledge of a system. Examples illustrate how these approaches can significantly reduce reliance on data collection whilst also increasing the interpretability of the model, another important consideration in this context.","sentences":["Despite the growing availability of sensing and data in general, we remain unable to fully characterise many in-service engineering systems and structures from a purely data-driven approach.","The vast data and resources available to capture human activity are unmatched in our engineered world, and, even in cases where data could be referred to as ``big,'' they will rarely hold information across operational windows or life spans.","This paper pursues the combination of machine learning technology and physics-based reasoning to enhance our ability to make predictive models with limited data.","By explicitly linking the physics-based view of stochastic processes with a data-based regression approach, a spectrum of possible Gaussian process models are introduced that enable the incorporation of different levels of expert knowledge of a system.","Examples illustrate how these approaches can significantly reduce reliance on data collection whilst also increasing the interpretability of the model, another important consideration in this context."],"url":"http://arxiv.org/abs/2309.10656v1"}
{"created":"2023-09-19 14:38:16","title":"Spiral Complete Coverage Path Planning Based on Conformal Slit Mapping in Multi-connected Domains","abstract":"Generating a smooth and shorter spiral complete coverage path in a multi-connected domain is an important research area in robotic cavity machining. Traditional spiral path planning methods in multi-connected domains involve a subregion division procedure; a deformed spiral path is incorporated within each subregion, and these paths within the subregions are interconnected with bridges. In intricate domains with abundant voids and irregular boundaries, the added subregion boundaries increase the path avoidance requirements. This results in excessive bridging and necessitates longer uneven-density spirals to achieve complete subregion coverage. Considering that conformal slit mapping can transform multi-connected regions into regular disks or annuluses without subregion division, this paper presents a novel spiral complete coverage path planning method by conformal slit mapping. Firstly, a slit mapping calculation technique is proposed for segmented cubic spline boundaries with corners. Then, a spiral path spacing control method is developed based on the maximum inscribed circle radius between adjacent conformal slit mapping iso-parameters. Lastly, the spiral path is derived by offsetting iso-parameters. The complexity and applicability of the proposed method are comprehensively analyzed across various boundary scenarios. Meanwhile, two cavities milling experiments are conducted to compare the new method with conventional spiral complete coverage path methods. The comparation indicate that the new path meets the requirement for complete coverage in cavity machining while reducing path length and machining time by 12.70% and 12.34%, respectively.","sentences":["Generating a smooth and shorter spiral complete coverage path in a multi-connected domain is an important research area in robotic cavity machining.","Traditional spiral path planning methods in multi-connected domains involve a subregion division procedure; a deformed spiral path is incorporated within each subregion, and these paths within the subregions are interconnected with bridges.","In intricate domains with abundant voids and irregular boundaries, the added subregion boundaries increase the path avoidance requirements.","This results in excessive bridging and necessitates longer uneven-density spirals to achieve complete subregion coverage.","Considering that conformal slit mapping can transform multi-connected regions into regular disks or annuluses without subregion division, this paper presents a novel spiral complete coverage path planning method by conformal slit mapping.","Firstly, a slit mapping calculation technique is proposed for segmented cubic spline boundaries with corners.","Then, a spiral path spacing control method is developed based on the maximum inscribed circle radius between adjacent conformal slit mapping iso-parameters.","Lastly, the spiral path is derived by offsetting iso-parameters.","The complexity and applicability of the proposed method are comprehensively analyzed across various boundary scenarios.","Meanwhile, two cavities milling experiments are conducted to compare the new method with conventional spiral complete coverage path methods.","The comparation indicate that the new path meets the requirement for complete coverage in cavity machining while reducing path length and machining time by 12.70% and 12.34%, respectively."],"url":"http://arxiv.org/abs/2309.10655v1"}
{"created":"2023-09-19 14:34:01","title":"CFGPT: Chinese Financial Assistant with Large Language Model","abstract":"Large language models (LLMs) have demonstrated great potential in natural language processing tasks within the financial domain. In this work, we present a Chinese Financial Generative Pre-trained Transformer framework, named CFGPT, which includes a dataset~(CFData) for pre-training and supervised fine-tuning, a financial LLM~(CFLLM) to adeptly manage financial texts, and a deployment framework~(CFAPP) designed to navigate real-world financial applications. The CFData comprising both a pre-training dataset and a supervised fine-tuning dataset, where the pre-training dataset collates Chinese financial data and analytics, alongside a smaller subset of general-purpose text with 584M documents and 141B tokens in total, and the supervised fine-tuning dataset is tailored for six distinct financial tasks, embodying various facets of financial analysis and decision-making with 1.5M instruction pairs and 1.5B tokens in total. The CFLLM, which is based on InternLM-7B to balance the model capability and size, is trained on CFData in two stage, continued pre-training and supervised fine-tuning. The CFAPP is centered on large language models (LLMs) and augmented with additional modules to ensure multifaceted functionality in real-world application. Our codes are released at https://github.com/TongjiFinLab/CFGPT.","sentences":["Large language models (LLMs) have demonstrated great potential in natural language processing tasks within the financial domain.","In this work, we present a Chinese Financial Generative Pre-trained Transformer framework, named CFGPT, which includes a dataset~(CFData) for pre-training and supervised fine-tuning, a financial LLM~(CFLLM) to adeptly manage financial texts, and a deployment framework~(CFAPP) designed to navigate real-world financial applications.","The CFData comprising both a pre-training dataset and a supervised fine-tuning dataset, where the pre-training dataset collates Chinese financial data and analytics, alongside a smaller subset of general-purpose text with 584M documents and 141B tokens in total, and the supervised fine-tuning dataset is tailored for six distinct financial tasks, embodying various facets of financial analysis and decision-making with 1.5M instruction pairs and 1.5B tokens in total.","The CFLLM, which is based on InternLM-7B to balance the model capability and size, is trained on CFData in two stage, continued pre-training and supervised fine-tuning.","The CFAPP is centered on large language models (LLMs) and augmented with additional modules to ensure multifaceted functionality in real-world application.","Our codes are released at https://github.com/TongjiFinLab/CFGPT."],"url":"http://arxiv.org/abs/2309.10654v1"}
{"created":"2023-09-19 14:33:14","title":"Nonlinear dynamic analysis of shear- and torsion-free rods using isogeometric discretization, outlier removal and robust time integration","abstract":"In this paper, we present a discrete formulation of nonlinear shear- and torsion-free rods based on \\cite{gebhardt_2021_beam} that uses isogeometric discretization and robust time integration. Omitting the director as an independent variable field, we reduce the number of degrees of freedom and obtain discrete solutions in multiple copies of the Euclidean space $\\left(\\mathbb{R}^3\\right)$, which is larger than the corresponding multiple copies of the manifold $\\left(\\mathbb{R}^3 \\cross S^2\\right)$ obtained with standard Hermite finite elements. For implicit time integration, we choose a hybrid form of the mid-point rule and the trapezoidal rule that preserves the linear angular momentum exactly and approximates the energy accurately. In addition, we apply a recently introduced approach for outlier removal \\cite{hiemstra_outlier_2021} that reduces high-frequency content in the response without affecting the accuracy, ensuring robustness of our nonlinear discrete formulation. We illustrate the efficiency of our nonlinear discrete formulation for static and transient rods under different loading conditions, demonstrating good accuracy in space, time and the frequency domain. Our numerical example coincides with a relevant application case, the simulation of mooring lines.","sentences":["In this paper, we present a discrete formulation of nonlinear shear- and torsion-free rods based on \\cite{gebhardt_2021_beam} that uses isogeometric discretization and robust time integration.","Omitting the director as an independent variable field, we reduce the number of degrees of freedom and obtain discrete solutions in multiple copies of the Euclidean space $\\left(\\mathbb{R}^3\\right)$, which is larger than the corresponding multiple copies of the manifold $\\left(\\mathbb{R}^3 \\cross S^2\\right)$ obtained with standard Hermite finite elements.","For implicit time integration, we choose a hybrid form of the mid-point rule and the trapezoidal rule that preserves the linear angular momentum exactly and approximates the energy accurately.","In addition, we apply a recently introduced approach for outlier removal \\cite{hiemstra_outlier_2021} that reduces high-frequency content in the response without affecting the accuracy, ensuring robustness of our nonlinear discrete formulation.","We illustrate the efficiency of our nonlinear discrete formulation for static and transient rods under different loading conditions, demonstrating good accuracy in space, time and the frequency domain.","Our numerical example coincides with a relevant application case, the simulation of mooring lines."],"url":"http://arxiv.org/abs/2309.10652v1"}
{"created":"2023-09-19 14:30:14","title":"Multi-Stain Self-Attention Graph Multiple Instance Learning Pipeline for Histopathology Whole Slide Images","abstract":"Whole Slide Images (WSIs) present a challenging computer vision task due to their gigapixel size and presence of numerous artefacts. Yet they are a valuable resource for patient diagnosis and stratification, often representing the gold standard for diagnostic tasks. Real-world clinical datasets tend to come as sets of heterogeneous WSIs with labels present at the patient-level, with poor to no annotations. Weakly supervised attention-based multiple instance learning approaches have been developed in recent years to address these challenges, but can fail to resolve both long and short-range dependencies. Here we propose an end-to-end multi-stain self-attention graph (MUSTANG) multiple instance learning pipeline, which is designed to solve a weakly-supervised gigapixel multi-image classification task, where the label is assigned at the patient-level, but no slide-level labels or region annotations are available. The pipeline uses a self-attention based approach by restricting the operations to a highly sparse k-Nearest Neighbour Graph of embedded WSI patches based on the Euclidean distance. We show this approach achieves a state-of-the-art F1-score/AUC of 0.89/0.92, outperforming the widely used CLAM model. Our approach is highly modular and can easily be modified to suit different clinical datasets, as it only requires a patient-level label without annotations and accepts WSI sets of different sizes, as the graphs can be of varying sizes and structures. The source code can be found at https://github.com/AmayaGS/MUSTANG.","sentences":["Whole Slide Images (WSIs) present a challenging computer vision task due to their gigapixel size and presence of numerous artefacts.","Yet they are a valuable resource for patient diagnosis and stratification, often representing the gold standard for diagnostic tasks.","Real-world clinical datasets tend to come as sets of heterogeneous WSIs with labels present at the patient-level, with poor to no annotations.","Weakly supervised attention-based multiple instance learning approaches have been developed in recent years to address these challenges, but can fail to resolve both long and short-range dependencies.","Here we propose an end-to-end multi-stain self-attention graph (MUSTANG) multiple instance learning pipeline, which is designed to solve a weakly-supervised gigapixel multi-image classification task, where the label is assigned at the patient-level, but no slide-level labels or region annotations are available.","The pipeline uses a self-attention based approach by restricting the operations to a highly sparse k-Nearest Neighbour Graph of embedded WSI patches based on the Euclidean distance.","We show this approach achieves a state-of-the-art F1-score/AUC of 0.89/0.92, outperforming the widely used CLAM model.","Our approach is highly modular and can easily be modified to suit different clinical datasets, as it only requires a patient-level label without annotations and accepts WSI sets of different sizes, as the graphs can be of varying sizes and structures.","The source code can be found at https://github.com/AmayaGS/MUSTANG."],"url":"http://arxiv.org/abs/2309.10650v1"}
{"created":"2023-09-19 14:29:57","title":"Cross-modal and Cross-domain Knowledge Transfer for Label-free 3D Segmentation","abstract":"Current state-of-the-art point cloud-based perception methods usually rely on large-scale labeled data, which requires expensive manual annotations. A natural option is to explore the unsupervised methodology for 3D perception tasks. However, such methods often face substantial performance-drop difficulties. Fortunately, we found that there exist amounts of image-based datasets and an alternative can be proposed, i.e., transferring the knowledge in the 2D images to 3D point clouds. Specifically, we propose a novel approach for the challenging cross-modal and cross-domain adaptation task by fully exploring the relationship between images and point clouds and designing effective feature alignment strategies. Without any 3D labels, our method achieves state-of-the-art performance for 3D point cloud semantic segmentation on SemanticKITTI by using the knowledge of KITTI360 and GTA5, compared to existing unsupervised and weakly-supervised baselines.","sentences":["Current state-of-the-art point cloud-based perception methods usually rely on large-scale labeled data, which requires expensive manual annotations.","A natural option is to explore the unsupervised methodology for 3D perception tasks.","However, such methods often face substantial performance-drop difficulties.","Fortunately, we found that there exist amounts of image-based datasets and an alternative can be proposed, i.e., transferring the knowledge in the 2D images to 3D point clouds.","Specifically, we propose a novel approach for the challenging cross-modal and cross-domain adaptation task by fully exploring the relationship between images and point clouds and designing effective feature alignment strategies.","Without any 3D labels, our method achieves state-of-the-art performance for 3D point cloud semantic segmentation on SemanticKITTI by using the knowledge of KITTI360 and GTA5, compared to existing unsupervised and weakly-supervised baselines."],"url":"http://arxiv.org/abs/2309.10649v1"}
{"created":"2023-09-19 14:28:09","title":"Towards Energy-Aware Federated Traffic Prediction for Cellular Networks","abstract":"Cellular traffic prediction is a crucial activity for optimizing networks in fifth-generation (5G) networks and beyond, as accurate forecasting is essential for intelligent network design, resource allocation and anomaly mitigation. Although machine learning (ML) is a promising approach to effectively predict network traffic, the centralization of massive data in a single data center raises issues regarding confidentiality, privacy and data transfer demands. To address these challenges, federated learning (FL) emerges as an appealing ML training framework which offers high accurate predictions through parallel distributed computations. However, the environmental impact of these methods is often overlooked, which calls into question their sustainability. In this paper, we address the trade-off between accuracy and energy consumption in FL by proposing a novel sustainability indicator that allows assessing the feasibility of ML models. Then, we comprehensively evaluate state-of-the-art deep learning (DL) architectures in a federated scenario using real-world measurements from base station (BS) sites in the area of Barcelona, Spain. Our findings indicate that larger ML models achieve marginally improved performance but have a significant environmental impact in terms of carbon footprint, which make them impractical for real-world applications.","sentences":["Cellular traffic prediction is a crucial activity for optimizing networks in fifth-generation (5G) networks and beyond, as accurate forecasting is essential for intelligent network design, resource allocation and anomaly mitigation.","Although machine learning (ML) is a promising approach to effectively predict network traffic, the centralization of massive data in a single data center raises issues regarding confidentiality, privacy and data transfer demands.","To address these challenges, federated learning (FL) emerges as an appealing ML training framework which offers high accurate predictions through parallel distributed computations.","However, the environmental impact of these methods is often overlooked, which calls into question their sustainability.","In this paper, we address the trade-off between accuracy and energy consumption in FL by proposing a novel sustainability indicator that allows assessing the feasibility of ML models.","Then, we comprehensively evaluate state-of-the-art deep learning (DL) architectures in a federated scenario using real-world measurements from base station (BS) sites in the area of Barcelona, Spain.","Our findings indicate that larger ML models achieve marginally improved performance but have a significant environmental impact in terms of carbon footprint, which make them impractical for real-world applications."],"url":"http://arxiv.org/abs/2309.10645v1"}
{"created":"2023-09-19 14:27:59","title":"Robin: A Novel Method to Produce Robust Interpreters for Deep Learning-Based Code Classifiers","abstract":"Deep learning has been widely used in source code classification tasks, such as code classification according to their functionalities, code authorship attribution, and vulnerability detection. Unfortunately, the black-box nature of deep learning makes it hard to interpret and understand why a classifier (i.e., classification model) makes a particular prediction on a given example. This lack of interpretability (or explainability) might have hindered their adoption by practitioners because it is not clear when they should or should not trust a classifier's prediction. The lack of interpretability has motivated a number of studies in recent years. However, existing methods are neither robust nor able to cope with out-of-distribution examples. In this paper, we propose a novel method to produce \\underline{Rob}ust \\underline{in}terpreters for a given deep learning-based code classifier; the method is dubbed Robin. The key idea behind Robin is a novel hybrid structure combining an interpreter and two approximators, while leveraging the ideas of adversarial training and data augmentation. Experimental results show that on average the interpreter produced by Robin achieves a 6.11\\% higher fidelity (evaluated on the classifier), 67.22\\% higher fidelity (evaluated on the approximator), and 15.87x higher robustness than that of the three existing interpreters we evaluated. Moreover, the interpreter is 47.31\\% less affected by out-of-distribution examples than that of LEMNA.","sentences":["Deep learning has been widely used in source code classification tasks, such as code classification according to their functionalities, code authorship attribution, and vulnerability detection.","Unfortunately, the black-box nature of deep learning makes it hard to interpret and understand why a classifier (i.e., classification model) makes a particular prediction on a given example.","This lack of interpretability (or explainability) might have hindered their adoption by practitioners because it is not clear when they should or should not trust a classifier's prediction.","The lack of interpretability has motivated a number of studies in recent years.","However, existing methods are neither robust nor able to cope with out-of-distribution examples.","In this paper, we propose a novel method to produce \\underline{Rob}ust \\underline{in}terpreters for a given deep learning-based code classifier; the method is dubbed Robin.","The key idea behind Robin is a novel hybrid structure combining an interpreter and two approximators, while leveraging the ideas of adversarial training and data augmentation.","Experimental results show that on average the interpreter produced by Robin achieves a 6.11\\% higher fidelity (evaluated on the classifier), 67.22\\% higher fidelity (evaluated on the approximator), and 15.87x higher robustness than that of the three existing interpreters we evaluated.","Moreover, the interpreter is 47.31\\% less affected by out-of-distribution examples than that of LEMNA."],"url":"http://arxiv.org/abs/2309.10644v1"}
{"created":"2023-09-19 14:21:33","title":"KFC: Kinship Verification with Fair Contrastive Loss and Multi-Task Learning","abstract":"Kinship verification is an emerging task in computer vision with multiple potential applications. However, there's no large enough kinship dataset to train a representative and robust model, which is a limitation for achieving better performance. Moreover, face verification is known to exhibit bias, which has not been dealt with by previous kinship verification works and sometimes even results in serious issues. So we first combine existing kinship datasets and label each identity with the correct race in order to take race information into consideration and provide a larger and complete dataset, called KinRace dataset. Secondly, we propose a multi-task learning model structure with attention module to enhance accuracy, which surpasses state-of-the-art performance. Lastly, our fairness-aware contrastive loss function with adversarial learning greatly mitigates racial bias. We introduce a debias term into traditional contrastive loss and implement gradient reverse in race classification task, which is an innovative idea to mix two fairness methods to alleviate bias. Exhaustive experimental evaluation demonstrates the effectiveness and superior performance of the proposed KFC in both standard deviation and accuracy at the same time.","sentences":["Kinship verification is an emerging task in computer vision with multiple potential applications.","However, there's no large enough kinship dataset to train a representative and robust model, which is a limitation for achieving better performance.","Moreover, face verification is known to exhibit bias, which has not been dealt with by previous kinship verification works and sometimes even results in serious issues.","So we first combine existing kinship datasets and label each identity with the correct race in order to take race information into consideration and provide a larger and complete dataset, called KinRace dataset.","Secondly, we propose a multi-task learning model structure with attention module to enhance accuracy, which surpasses state-of-the-art performance.","Lastly, our fairness-aware contrastive loss function with adversarial learning greatly mitigates racial bias.","We introduce a debias term into traditional contrastive loss and implement gradient reverse in race classification task, which is an innovative idea to mix two fairness methods to alleviate bias.","Exhaustive experimental evaluation demonstrates the effectiveness and superior performance of the proposed KFC in both standard deviation and accuracy at the same time."],"url":"http://arxiv.org/abs/2309.10641v1"}
{"created":"2023-09-19 14:20:55","title":"Geometric structure of Deep Learning networks and construction of global ${\\mathcal L}^2$ minimizers","abstract":"In this paper, we provide a geometric interpretation of the structure of Deep Learning (DL) networks, characterized by $L$ hidden layers, a ramp activation function, an ${\\mathcal L}^2$ Schatten class (or Hilbert-Schmidt) cost function, and input and output spaces ${\\mathbb R}^Q$ with equal dimension $Q\\geq1$. The hidden layers are defined on spaces ${\\mathbb R}^{Q}$, as well. We apply our recent results on shallow neural networks to construct an explicit family of minimizers for the global minimum of the cost function in the case $L\\geq Q$, which we show to be degenerate. In the context presented here, the hidden layers of the DL network \"curate\" the training inputs by recursive application of a truncation map that minimizes the noise to signal ratio of the training inputs. Moreover, we determine a set of $2^Q-1$ distinct degenerate local minima of the cost function.","sentences":["In this paper, we provide a geometric interpretation of the structure of Deep Learning (DL) networks, characterized by $L$ hidden layers, a ramp activation function, an ${\\mathcal L}^2$ Schatten class (or Hilbert-Schmidt) cost function, and input and output spaces ${\\mathbb R}^Q$ with equal dimension $Q\\geq1$.","The hidden layers are defined on spaces ${\\mathbb R}^{Q}$, as well.","We apply our recent results on shallow neural networks to construct an explicit family of minimizers for the global minimum of the cost function in the case $L\\geq Q$, which we show to be degenerate.","In the context presented here, the hidden layers of the DL network \"curate\" the training inputs by recursive application of a truncation map that minimizes the noise to signal ratio of the training inputs.","Moreover, we determine a set of $2^Q-1$ distinct degenerate local minima of the cost function."],"url":"http://arxiv.org/abs/2309.10639v1"}
{"created":"2023-09-19 14:04:04","title":"Exploring the Influence of Information Entropy Change in Learning Systems","abstract":"In this work, we explore the influence of entropy change in deep learning systems by adding noise to the inputs/latent features. The applications in this paper focus on deep learning tasks within computer vision, but the proposed theory can be further applied to other fields. Noise is conventionally viewed as a harmful perturbation in various deep learning architectures, such as convolutional neural networks (CNNs) and vision transformers (ViTs), as well as different learning tasks like image classification and transfer learning. However, this paper aims to rethink whether the conventional proposition always holds. We demonstrate that specific noise can boost the performance of various deep architectures under certain conditions. We theoretically prove the enhancement gained from positive noise by reducing the task complexity defined by information entropy and experimentally show the significant performance gain in large image datasets, such as the ImageNet. Herein, we use the information entropy to define the complexity of the task. We categorize the noise into two types, positive noise (PN) and harmful noise (HN), based on whether the noise can help reduce the complexity of the task. Extensive experiments of CNNs and ViTs have shown performance improvements by proactively injecting positive noise, where we achieved an unprecedented top 1 accuracy of over 95% on ImageNet. Both theoretical analysis and empirical evidence have confirmed that the presence of positive noise can benefit the learning process, while the traditionally perceived harmful noise indeed impairs deep learning models. The different roles of noise offer new explanations for deep models on specific tasks and provide a new paradigm for improving model performance. Moreover, it reminds us that we can influence the performance of learning systems via information entropy change.","sentences":["In this work, we explore the influence of entropy change in deep learning systems by adding noise to the inputs/latent features.","The applications in this paper focus on deep learning tasks within computer vision, but the proposed theory can be further applied to other fields.","Noise is conventionally viewed as a harmful perturbation in various deep learning architectures, such as convolutional neural networks (CNNs) and vision transformers (ViTs), as well as different learning tasks like image classification and transfer learning.","However, this paper aims to rethink whether the conventional proposition always holds.","We demonstrate that specific noise can boost the performance of various deep architectures under certain conditions.","We theoretically prove the enhancement gained from positive noise by reducing the task complexity defined by information entropy and experimentally show the significant performance gain in large image datasets, such as the ImageNet.","Herein, we use the information entropy to define the complexity of the task.","We categorize the noise into two types, positive noise (PN) and harmful noise (HN), based on whether the noise can help reduce the complexity of the task.","Extensive experiments of CNNs and ViTs have shown performance improvements by proactively injecting positive noise, where we achieved an unprecedented top 1 accuracy of over 95% on ImageNet.","Both theoretical analysis and empirical evidence have confirmed that the presence of positive noise can benefit the learning process, while the traditionally perceived harmful noise indeed impairs deep learning models.","The different roles of noise offer new explanations for deep models on specific tasks and provide a new paradigm for improving model performance.","Moreover, it reminds us that we can influence the performance of learning systems via information entropy change."],"url":"http://arxiv.org/abs/2309.10625v1"}
{"created":"2023-09-19 14:02:25","title":"6G Underlayer Network Concepts for Ultra Reliable and Low Latency Communication in Manufacturing","abstract":"Underlayer networks in the context of 6G for manufacturing are crucial. They address the evolving needs of highly interconnected and autonomous systems in industry. The digitalization of manufacturing processes, driven by the Internet of Things and increased data availability, enables more efficient and demand-driven production. However, wireless connectivity, which offers flexibility and easy integration of components, comes with challenges such as signal interference or high latency. A new management system is needed to coordinate and route traffic of multiple networks in a specific coverage area. This paper proposes underlayer networks designed for manufacturing, providing low latency, reliability, and security. These networks enable wireless connectivity and integration of wireless technologies into the manufacturing environment, enhancing flexibility and efficiency. The paper also discusses network slicing, spectrum sharing, and the limitations of current wireless networks in manufacturing. It introduces a network concept for underlayer networks and evaluates its application in closed-loop communication for machine tools. The study concludes with future research prospects in this area.","sentences":["Underlayer networks in the context of 6G for manufacturing are crucial.","They address the evolving needs of highly interconnected and autonomous systems in industry.","The digitalization of manufacturing processes, driven by the Internet of Things and increased data availability, enables more efficient and demand-driven production.","However, wireless connectivity, which offers flexibility and easy integration of components, comes with challenges such as signal interference or high latency.","A new management system is needed to coordinate and route traffic of multiple networks in a specific coverage area.","This paper proposes underlayer networks designed for manufacturing, providing low latency, reliability, and security.","These networks enable wireless connectivity and integration of wireless technologies into the manufacturing environment, enhancing flexibility and efficiency.","The paper also discusses network slicing, spectrum sharing, and the limitations of current wireless networks in manufacturing.","It introduces a network concept for underlayer networks and evaluates its application in closed-loop communication for machine tools.","The study concludes with future research prospects in this area."],"url":"http://arxiv.org/abs/2309.10624v1"}
{"created":"2023-09-19 14:01:09","title":"Flip: Data-Centric Edge CGRA Accelerator","abstract":"Coarse-Grained Reconfigurable Arrays (CGRA) are promising edge accelerators due to the outstanding balance in flexibility, performance, and energy efficiency. Classic CGRAs statically map compute operations onto the processing elements (PE) and route the data dependencies among the operations through the Network-on-Chip. However, CGRAs are designed for fine-grained static instruction-level parallelism and struggle to accelerate applications with dynamic and irregular data-level parallelism, such as graph processing. To address this limitation, we present Flip, a novel accelerator that enhances traditional CGRA architectures to boost the performance of graph applications. Flip retains the classic CGRA execution model while introducing a special data-centric mode for efficient graph processing. Specifically, it exploits the natural data parallelism of graph algorithms by mapping graph vertices onto processing elements (PEs) rather than the operations, and supporting dynamic routing of temporary data according to the runtime evolution of the graph frontier. Experimental results demonstrate that Flip achieves up to 36$\\times$ speedup with merely 19% more area compared to classic CGRAs. Compared to state-of-the-art large-scale graph processors, Flip has similar energy efficiency and 2.2$\\times$ better area efficiency at a much-reduced power/area budget.","sentences":["Coarse-Grained Reconfigurable Arrays (CGRA) are promising edge accelerators due to the outstanding balance in flexibility, performance, and energy efficiency.","Classic CGRAs statically map compute operations onto the processing elements (PE) and route the data dependencies among the operations through the Network-on-Chip.","However, CGRAs are designed for fine-grained static instruction-level parallelism and struggle to accelerate applications with dynamic and irregular data-level parallelism, such as graph processing.","To address this limitation, we present Flip, a novel accelerator that enhances traditional CGRA architectures to boost the performance of graph applications.","Flip retains the classic CGRA execution model while introducing a special data-centric mode for efficient graph processing.","Specifically, it exploits the natural data parallelism of graph algorithms by mapping graph vertices onto processing elements (PEs) rather than the operations, and supporting dynamic routing of temporary data according to the runtime evolution of the graph frontier.","Experimental results demonstrate that Flip achieves up to 36$\\times$ speedup with merely 19% more area compared to classic CGRAs.","Compared to state-of-the-art large-scale graph processors, Flip has similar energy efficiency and 2.2$\\times$ better area efficiency at a much-reduced power/area budget."],"url":"http://arxiv.org/abs/2309.10623v1"}
{"created":"2023-09-19 13:55:39","title":"Large language models can accurately predict searcher preferences","abstract":"Relevance labels, which indicate whether a search result is valuable to a searcher, are key to evaluating and optimising search systems. The best way to capture the true preferences of users is to ask them for their careful feedback on which results would be useful, but this approach does not scale to produce a large number of labels. Getting relevance labels at scale is usually done with third-party labellers, who judge on behalf of the user, but there is a risk of low-quality data if the labeller doesn't understand user needs. To improve quality, one standard approach is to study real users through interviews, user studies and direct feedback, find areas where labels are systematically disagreeing with users, then educate labellers about user needs through judging guidelines, training and monitoring. This paper introduces an alternate approach for improving label quality. It takes careful feedback from real users, which by definition is the highest-quality first-party gold data that can be derived, and develops an large language model prompt that agrees with that data.   We present ideas and observations from deploying language models for large-scale relevance labelling at Bing, and illustrate with data from TREC. We have found large language models can be effective, with accuracy as good as human labellers and similar capability to pick the hardest queries, best runs, and best groups. Systematic changes to the prompts make a difference in accuracy, but so too do simple paraphrases. To measure agreement with real searchers needs high-quality ``gold'' labels, but with these we find that models produce better labels than third-party workers, for a fraction of the cost, and these labels let us train notably better rankers.","sentences":["Relevance labels, which indicate whether a search result is valuable to a searcher, are key to evaluating and optimising search systems.","The best way to capture the true preferences of users is to ask them for their careful feedback on which results would be useful, but this approach does not scale to produce a large number of labels.","Getting relevance labels at scale is usually done with third-party labellers, who judge on behalf of the user, but there is a risk of low-quality data if the labeller doesn't understand user needs.","To improve quality, one standard approach is to study real users through interviews, user studies and direct feedback, find areas where labels are systematically disagreeing with users, then educate labellers about user needs through judging guidelines, training and monitoring.","This paper introduces an alternate approach for improving label quality.","It takes careful feedback from real users, which by definition is the highest-quality first-party gold data that can be derived, and develops an large language model prompt that agrees with that data.   ","We present ideas and observations from deploying language models for large-scale relevance labelling at Bing, and illustrate with data from TREC.","We have found large language models can be effective, with accuracy as good as human labellers and similar capability to pick the hardest queries, best runs, and best groups.","Systematic changes to the prompts make a difference in accuracy, but so too do simple paraphrases.","To measure agreement with real searchers needs high-quality ``gold'' labels, but with these we find that models produce better labels than third-party workers, for a fraction of the cost, and these labels let us train notably better rankers."],"url":"http://arxiv.org/abs/2309.10621v1"}
{"created":"2023-09-19 13:53:07","title":"Perceptual Factors for Environmental Modeling in Robotic Active Perception","abstract":"Accurately assessing the potential value of new sensor observations is a critical aspect of planning for active perception. This task is particularly challenging when reasoning about high-level scene understanding using measurements from vision-based neural networks. Due to appearance-based reasoning, the measurements are susceptible to several environmental effects such as the presence of occluders, variations in lighting conditions, and redundancy of information due to similarity in appearance between nearby viewpoints. To address this, we propose a new active perception framework incorporating an arbitrary number of perceptual effects in planning and fusion. Our method models the correlation with the environment by a set of general functions termed perceptual factors to construct a perceptual map, which quantifies the aggregated influence of the environment on candidate viewpoints. This information is seamlessly incorporated into the planning and fusion processes by adjusting the uncertainty associated with measurements to weigh their contributions. We evaluate our perceptual maps in a simulated environment that reproduces environmental conditions common in robotics applications. Our results show that, by accounting for environmental effects within our perceptual maps, we improve in the state estimation by correctly selecting the viewpoints and considering the measurement noise correctly when affected by environmental factors. We furthermore deploy our approach on a ground robot to showcase its applicability for real-world active perception missions.","sentences":["Accurately assessing the potential value of new sensor observations is a critical aspect of planning for active perception.","This task is particularly challenging when reasoning about high-level scene understanding using measurements from vision-based neural networks.","Due to appearance-based reasoning, the measurements are susceptible to several environmental effects such as the presence of occluders, variations in lighting conditions, and redundancy of information due to similarity in appearance between nearby viewpoints.","To address this, we propose a new active perception framework incorporating an arbitrary number of perceptual effects in planning and fusion.","Our method models the correlation with the environment by a set of general functions termed perceptual factors to construct a perceptual map, which quantifies the aggregated influence of the environment on candidate viewpoints.","This information is seamlessly incorporated into the planning and fusion processes by adjusting the uncertainty associated with measurements to weigh their contributions.","We evaluate our perceptual maps in a simulated environment that reproduces environmental conditions common in robotics applications.","Our results show that, by accounting for environmental effects within our perceptual maps, we improve in the state estimation by correctly selecting the viewpoints and considering the measurement noise correctly when affected by environmental factors.","We furthermore deploy our approach on a ground robot to showcase its applicability for real-world active perception missions."],"url":"http://arxiv.org/abs/2309.10620v1"}
{"created":"2023-09-19 13:52:06","title":"Source-free Active Domain Adaptation for Diabetic Retinopathy Grading Based on Ultra-wide-field Fundus Image","abstract":"Domain adaptation (DA) has been widely applied in the diabetic retinopathy (DR) grading of unannotated ultra-wide-field (UWF) fundus images, which can transfer annotated knowledge from labeled color fundus images. However, suffering from huge domain gaps and complex real-world scenarios, the DR grading performance of most mainstream DA is far from that of clinical diagnosis. To tackle this, we propose a novel source-free active domain adaptation (SFADA) in this paper. Specifically, we focus on DR grading problem itself and propose to generate features of color fundus images with continuously evolving relationships of DRs, actively select a few valuable UWF fundus images for labeling with local representation matching, and adapt model on UWF fundus images with DR lesion prototypes. Notably, the SFADA also takes data privacy and computational efficiency into consideration. Extensive experimental results demonstrate that our proposed SFADA achieves state-of-the-art DR grading performance, increasing accuracy by 20.9% and quadratic weighted kappa by 18.63% compared with baseline and reaching 85.36% and 92.38% respectively. These investigations show that the potential of our approach for real clinical practice is promising.","sentences":["Domain adaptation (DA) has been widely applied in the diabetic retinopathy (DR) grading of unannotated ultra-wide-field (UWF) fundus images, which can transfer annotated knowledge from labeled color fundus images.","However, suffering from huge domain gaps and complex real-world scenarios, the DR grading performance of most mainstream DA is far from that of clinical diagnosis.","To tackle this, we propose a novel source-free active domain adaptation (SFADA) in this paper.","Specifically, we focus on DR grading problem itself and propose to generate features of color fundus images with continuously evolving relationships of DRs, actively select a few valuable UWF fundus images for labeling with local representation matching, and adapt model on UWF fundus images with DR lesion prototypes.","Notably, the SFADA also takes data privacy and computational efficiency into consideration.","Extensive experimental results demonstrate that our proposed SFADA achieves state-of-the-art DR grading performance, increasing accuracy by 20.9% and quadratic weighted kappa by 18.63% compared with baseline and reaching 85.36% and 92.38% respectively.","These investigations show that the potential of our approach for real clinical practice is promising."],"url":"http://arxiv.org/abs/2309.10619v1"}
{"created":"2023-09-19 13:48:26","title":"A Dynamic Linear Bias Incorporation Scheme for Nonnegative Latent Factor Analysis","abstract":"High-Dimensional and Incomplete (HDI) data is commonly encountered in big data-related applications like social network services systems, which are concerning the limited interactions among numerous nodes. Knowledge acquisition from HDI data is a vital issue in the domain of data science due to their embedded rich patterns like node behaviors, where the fundamental task is to perform HDI data representation learning. Nonnegative Latent Factor Analysis (NLFA) models have proven to possess the superiority to address this issue, where a linear bias incorporation (LBI) scheme is important in present the training overshooting and fluctuation, as well as preventing the model from premature convergence. However, existing LBI schemes are all statistic ones where the linear biases are fixed, which significantly restricts the scalability of the resultant NLFA model and results in loss of representation learning ability to HDI data. Motivated by the above discoveries, this paper innovatively presents the dynamic linear bias incorporation (DLBI) scheme. It firstly extends the linear bias vectors into matrices, and then builds a binary weight matrix to switch the active/inactive states of the linear biases. The weight matrix's each entry switches between the binary states dynamically corresponding to the linear bias value variation, thereby establishing the dynamic linear biases for an NLFA model. Empirical studies on three HDI datasets from real applications demonstrate that the proposed DLBI-based NLFA model obtains higher representation accuracy several than state-of-the-art models do, as well as highly-competitive computational efficiency.","sentences":["High-Dimensional and Incomplete (HDI) data is commonly encountered in big data-related applications like social network services systems, which are concerning the limited interactions among numerous nodes.","Knowledge acquisition from HDI data is a vital issue in the domain of data science due to their embedded rich patterns like node behaviors, where the fundamental task is to perform HDI data representation learning.","Nonnegative Latent Factor Analysis (NLFA) models have proven to possess the superiority to address this issue, where a linear bias incorporation (LBI) scheme is important in present the training overshooting and fluctuation, as well as preventing the model from premature convergence.","However, existing LBI schemes are all statistic ones where the linear biases are fixed, which significantly restricts the scalability of the resultant NLFA model and results in loss of representation learning ability to HDI data.","Motivated by the above discoveries, this paper innovatively presents the dynamic linear bias incorporation (DLBI) scheme.","It firstly extends the linear bias vectors into matrices, and then builds a binary weight matrix to switch the active/inactive states of the linear biases.","The weight matrix's each entry switches between the binary states dynamically corresponding to the linear bias value variation, thereby establishing the dynamic linear biases for an NLFA model.","Empirical studies on three HDI datasets from real applications demonstrate that the proposed DLBI-based NLFA model obtains higher representation accuracy several than state-of-the-art models do, as well as highly-competitive computational efficiency."],"url":"http://arxiv.org/abs/2309.10618v1"}
{"created":"2023-09-19 13:47:31","title":"Intelligent Debris Mass Estimation Model for Autonomous Underwater Vehicle","abstract":"Marine debris poses a significant threat to the survival of marine wildlife, often leading to entanglement and starvation, ultimately resulting in death. Therefore, removing debris from the ocean is crucial to restore the natural balance and allow marine life to thrive. Instance segmentation is an advanced form of object detection that identifies objects and precisely locates and separates them, making it an essential tool for autonomous underwater vehicles (AUVs) to navigate and interact with their underwater environment effectively. AUVs use image segmentation to analyze images captured by their cameras to navigate underwater environments. In this paper, we use instance segmentation to calculate the area of individual objects within an image, we use YOLOV7 in Roboflow to generate a set of bounding boxes for each object in the image with a class label and a confidence score for every detection. A segmentation mask is then created for each object by applying a binary mask to the object's bounding box. The masks are generated by applying a binary threshold to the output of a convolutional neural network trained to segment objects from the background. Finally, refining the segmentation mask for each object is done by applying post-processing techniques such as morphological operations and contour detection, to improve the accuracy and quality of the mask. The process of estimating the area of instance segmentation involves calculating the area of each segmented instance separately and then summing up the areas of all instances to obtain the total area. The calculation is carried out using standard formulas based on the shape of the object, such as rectangles and circles. In cases where the object is complex, the Monte Carlo method is used to estimate the area. This method provides a higher degree of accuracy than traditional methods, especially when using a large number of samples.","sentences":["Marine debris poses a significant threat to the survival of marine wildlife, often leading to entanglement and starvation, ultimately resulting in death.","Therefore, removing debris from the ocean is crucial to restore the natural balance and allow marine life to thrive.","Instance segmentation is an advanced form of object detection that identifies objects and precisely locates and separates them, making it an essential tool for autonomous underwater vehicles (AUVs) to navigate and interact with their underwater environment effectively.","AUVs use image segmentation to analyze images captured by their cameras to navigate underwater environments.","In this paper, we use instance segmentation to calculate the area of individual objects within an image, we use YOLOV7 in Roboflow to generate a set of bounding boxes for each object in the image with a class label and a confidence score for every detection.","A segmentation mask is then created for each object by applying a binary mask to the object's bounding box.","The masks are generated by applying a binary threshold to the output of a convolutional neural network trained to segment objects from the background.","Finally, refining the segmentation mask for each object is done by applying post-processing techniques such as morphological operations and contour detection, to improve the accuracy and quality of the mask.","The process of estimating the area of instance segmentation involves calculating the area of each segmented instance separately and then summing up the areas of all instances to obtain the total area.","The calculation is carried out using standard formulas based on the shape of the object, such as rectangles and circles.","In cases where the object is complex, the Monte Carlo method is used to estimate the area.","This method provides a higher degree of accuracy than traditional methods, especially when using a large number of samples."],"url":"http://arxiv.org/abs/2309.10617v1"}
{"created":"2023-09-19 13:37:47","title":"An Extendable Python Implementation of Robust Optimisation Monte Carlo","abstract":"Performing inference in statistical models with an intractable likelihood is challenging, therefore, most likelihood-free inference (LFI) methods encounter accuracy and efficiency limitations. In this paper, we present the implementation of the LFI method Robust Optimisation Monte Carlo (ROMC) in the Python package ELFI. ROMC is a novel and efficient (highly-parallelizable) LFI framework that provides accurate weighted samples from the posterior. Our implementation can be used in two ways. First, a scientist may use it as an out-of-the-box LFI algorithm; we provide an easy-to-use API harmonized with the principles of ELFI, enabling effortless comparisons with the rest of the methods included in the package. Additionally, we have carefully split ROMC into isolated components for supporting extensibility. A researcher may experiment with novel method(s) for solving part(s) of ROMC without reimplementing everything from scratch. In both scenarios, the ROMC parts can run in a fully-parallelized manner, exploiting all CPU cores. We also provide helpful functionalities for (i) inspecting the inference process and (ii) evaluating the obtained samples. Finally, we test the robustness of our implementation on some typical LFI examples.","sentences":["Performing inference in statistical models with an intractable likelihood is challenging, therefore, most likelihood-free inference (LFI) methods encounter accuracy and efficiency limitations.","In this paper, we present the implementation of the LFI method Robust Optimisation Monte Carlo (ROMC) in the Python package ELFI.","ROMC is a novel and efficient (highly-parallelizable) LFI framework that provides accurate weighted samples from the posterior.","Our implementation can be used in two ways.","First, a scientist may use it as an out-of-the-box LFI algorithm; we provide an easy-to-use API harmonized with the principles of ELFI, enabling effortless comparisons with the rest of the methods included in the package.","Additionally, we have carefully split ROMC into isolated components for supporting extensibility.","A researcher may experiment with novel method(s) for solving part(s) of ROMC without reimplementing everything from scratch.","In both scenarios, the ROMC parts can run in a fully-parallelized manner, exploiting all CPU cores.","We also provide helpful functionalities for (i) inspecting the inference process and (ii) evaluating the obtained samples.","Finally, we test the robustness of our implementation on some typical LFI examples."],"url":"http://arxiv.org/abs/2309.10612v1"}
