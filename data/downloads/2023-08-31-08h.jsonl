{"created":"2023-08-30 17:59:11","title":"Boosting Detection in Crowd Analysis via Underutilized Output Features","abstract":"Detection-based methods have been viewed unfavorably in crowd analysis due to their poor performance in dense crowds. However, we argue that the potential of these methods has been underestimated, as they offer crucial information for crowd analysis that is often ignored. Specifically, the area size and confidence score of output proposals and bounding boxes provide insight into the scale and density of the crowd. To leverage these underutilized features, we propose Crowd Hat, a plug-and-play module that can be easily integrated with existing detection models. This module uses a mixed 2D-1D compression technique to refine the output features and obtain the spatial and numerical distribution of crowd-specific information. Based on these features, we further propose region-adaptive NMS thresholds and a decouple-then-align paradigm that address the major limitations of detection-based methods. Our extensive evaluations on various crowd analysis tasks, including crowd counting, localization, and detection, demonstrate the effectiveness of utilizing output features and the potential of detection-based methods in crowd analysis.","sentences":["Detection-based methods have been viewed unfavorably in crowd analysis due to their poor performance in dense crowds.","However, we argue that the potential of these methods has been underestimated, as they offer crucial information for crowd analysis that is often ignored.","Specifically, the area size and confidence score of output proposals and bounding boxes provide insight into the scale and density of the crowd.","To leverage these underutilized features, we propose Crowd Hat, a plug-and-play module that can be easily integrated with existing detection models.","This module uses a mixed 2D-1D compression technique to refine the output features and obtain the spatial and numerical distribution of crowd-specific information.","Based on these features, we further propose region-adaptive NMS thresholds and a decouple-then-align paradigm that address the major limitations of detection-based methods.","Our extensive evaluations on various crowd analysis tasks, including crowd counting, localization, and detection, demonstrate the effectiveness of utilizing output features and the potential of detection-based methods in crowd analysis."],"url":"http://arxiv.org/abs/2308.16187v1"}
{"created":"2023-08-30 17:59:05","title":"Learning Vision-based Pursuit-Evasion Robot Policies","abstract":"Learning strategic robot behavior -- like that required in pursuit-evasion interactions -- under real-world constraints is extremely challenging. It requires exploiting the dynamics of the interaction, and planning through both physical state and latent intent uncertainty. In this paper, we transform this intractable problem into a supervised learning problem, where a fully-observable robot policy generates supervision for a partially-observable one. We find that the quality of the supervision signal for the partially-observable pursuer policy depends on two key factors: the balance of diversity and optimality of the evader's behavior and the strength of the modeling assumptions in the fully-observable policy. We deploy our policy on a physical quadruped robot with an RGB-D camera on pursuit-evasion interactions in the wild. Despite all the challenges, the sensing constraints bring about creativity: the robot is pushed to gather information when uncertain, predict intent from noisy measurements, and anticipate in order to intercept. Project webpage: https://abajcsy.github.io/vision-based-pursuit/","sentences":["Learning strategic robot behavior -- like that required in pursuit-evasion interactions -- under real-world constraints is extremely challenging.","It requires exploiting the dynamics of the interaction, and planning through both physical state and latent intent uncertainty.","In this paper, we transform this intractable problem into a supervised learning problem, where a fully-observable robot policy generates supervision for a partially-observable one.","We find that the quality of the supervision signal for the partially-observable pursuer policy depends on two key factors: the balance of diversity and optimality of the evader's behavior and the strength of the modeling assumptions in the fully-observable policy.","We deploy our policy on a physical quadruped robot with an RGB-D camera on pursuit-evasion interactions in the wild.","Despite all the challenges, the sensing constraints bring about creativity: the robot is pushed to gather information when uncertain, predict intent from noisy measurements, and anticipate in order to intercept.","Project webpage: https://abajcsy.github.io/vision-based-pursuit/"],"url":"http://arxiv.org/abs/2308.16185v1"}
{"created":"2023-08-30 17:59:02","title":"SAM-Med2D","abstract":"The Segment Anything Model (SAM) represents a state-of-the-art research advancement in natural image segmentation, achieving impressive results with input prompts such as points and bounding boxes. However, our evaluation and recent research indicate that directly applying the pretrained SAM to medical image segmentation does not yield satisfactory performance. This limitation primarily arises from significant domain gap between natural images and medical images. To bridge this gap, we introduce SAM-Med2D, the most comprehensive studies on applying SAM to medical 2D images. Specifically, we first collect and curate approximately 4.6M images and 19.7M masks from public and private datasets, constructing a large-scale medical image segmentation dataset encompassing various modalities and objects. Then, we comprehensively fine-tune SAM on this dataset and turn it into SAM-Med2D. Unlike previous methods that only adopt bounding box or point prompts as interactive segmentation approach, we adapt SAM to medical image segmentation through more comprehensive prompts involving bounding boxes, points, and masks. We additionally fine-tune the encoder and decoder of the original SAM to obtain a well-performed SAM-Med2D, leading to the most comprehensive fine-tuning strategies to date. Finally, we conducted a comprehensive evaluation and analysis to investigate the performance of SAM-Med2D in medical image segmentation across various modalities, anatomical structures, and organs. Concurrently, we validated the generalization capability of SAM-Med2D on 9 datasets from MICCAI 2023 challenge. Overall, our approach demonstrated significantly superior performance and generalization capability compared to SAM.","sentences":["The Segment Anything Model (SAM) represents a state-of-the-art research advancement in natural image segmentation, achieving impressive results with input prompts such as points and bounding boxes.","However, our evaluation and recent research indicate that directly applying the pretrained SAM to medical image segmentation does not yield satisfactory performance.","This limitation primarily arises from significant domain gap between natural images and medical images.","To bridge this gap, we introduce SAM-Med2D, the most comprehensive studies on applying SAM to medical 2D images.","Specifically, we first collect and curate approximately 4.6M images and 19.7M masks from public and private datasets, constructing a large-scale medical image segmentation dataset encompassing various modalities and objects.","Then, we comprehensively fine-tune SAM on this dataset and turn it into SAM-Med2D. Unlike previous methods that only adopt bounding box or point prompts as interactive segmentation approach, we adapt SAM to medical image segmentation through more comprehensive prompts involving bounding boxes, points, and masks.","We additionally fine-tune the encoder and decoder of the original SAM to obtain a well-performed SAM-Med2D, leading to the most comprehensive fine-tuning strategies to date.","Finally, we conducted a comprehensive evaluation and analysis to investigate the performance of SAM-Med2D in medical image segmentation across various modalities, anatomical structures, and organs.","Concurrently, we validated the generalization capability of SAM-Med2D on 9 datasets from MICCAI 2023 challenge.","Overall, our approach demonstrated significantly superior performance and generalization capability compared to SAM."],"url":"http://arxiv.org/abs/2308.16184v1"}
{"created":"2023-08-30 17:58:50","title":"GREC: Generalized Referring Expression Comprehension","abstract":"The objective of Classic Referring Expression Comprehension (REC) is to produce a bounding box corresponding to the object mentioned in a given textual description. Commonly, existing datasets and techniques in classic REC are tailored for expressions that pertain to a single target, meaning a sole expression is linked to one specific object. Expressions that refer to multiple targets or involve no specific target have not been taken into account. This constraint hinders the practical applicability of REC. This study introduces a new benchmark termed as Generalized Referring Expression Comprehension (GREC). This benchmark extends the classic REC by permitting expressions to describe any number of target objects. To achieve this goal, we have built the first large-scale GREC dataset named gRefCOCO. This dataset encompasses a range of expressions: those referring to multiple targets, expressions with no specific target, and the single-target expressions. The design of GREC and gRefCOCO ensures smooth compatibility with classic REC. The proposed gRefCOCO dataset, a GREC method implementation code, and GREC evaluation code are available at https://github.com/henghuiding/gRefCOCO.","sentences":["The objective of Classic Referring Expression Comprehension (REC) is to produce a bounding box corresponding to the object mentioned in a given textual description.","Commonly, existing datasets and techniques in classic REC are tailored for expressions that pertain to a single target, meaning a sole expression is linked to one specific object.","Expressions that refer to multiple targets or involve no specific target have not been taken into account.","This constraint hinders the practical applicability of REC.","This study introduces a new benchmark termed as Generalized Referring Expression Comprehension (GREC).","This benchmark extends the classic REC by permitting expressions to describe any number of target objects.","To achieve this goal, we have built the first large-scale GREC dataset named gRefCOCO.","This dataset encompasses a range of expressions: those referring to multiple targets, expressions with no specific target, and the single-target expressions.","The design of GREC and gRefCOCO ensures smooth compatibility with classic REC.","The proposed gRefCOCO dataset, a GREC method implementation code, and GREC evaluation code are available at https://github.com/henghuiding/gRefCOCO."],"url":"http://arxiv.org/abs/2308.16182v1"}
{"created":"2023-08-30 17:57:37","title":"Framework and Methodology for Verification of a Complex Scientific Simulation Software, Flash-X","abstract":"Computational science relies on scientific software as its primary instrument for scientific discovery. Therefore, similar to the use of other types of scientific instruments, correct software and the correct operation of the software is necessary for executing rigorous scientific investigations. Scientific software verification can be especially difficult, as users typically need to modify the software as part of a scientific study. Systematic methodologies for building test suites for scientific software are rare in the literature. Here, we describe a methodology that we have developed for Flash-X, a community simulation software for multiple scientific domains, that has composable components that can be permuted and combined in a multitude of ways to generate a wide range of applications. Ensuring sufficient code coverage by a test suite is particularly challenging due to this composability. Our methodology includes a consideration of trade-offs between meeting software quality goals, developer productivity, and meeting the scientific goals of the Flash-X user community.","sentences":["Computational science relies on scientific software as its primary instrument for scientific discovery.","Therefore, similar to the use of other types of scientific instruments, correct software and the correct operation of the software is necessary for executing rigorous scientific investigations.","Scientific software verification can be especially difficult, as users typically need to modify the software as part of a scientific study.","Systematic methodologies for building test suites for scientific software are rare in the literature.","Here, we describe a methodology that we have developed for Flash-X, a community simulation software for multiple scientific domains, that has composable components that can be permuted and combined in a multitude of ways to generate a wide range of applications.","Ensuring sufficient code coverage by a test suite is particularly challenging due to this composability.","Our methodology includes a consideration of trade-offs between meeting software quality goals, developer productivity, and meeting the scientific goals of the Flash-X user community."],"url":"http://arxiv.org/abs/2308.16180v1"}
{"created":"2023-08-30 17:55:28","title":"General Purpose Audio Effect Removal","abstract":"Although the design and application of audio effects is well understood, the inverse problem of removing these effects is significantly more challenging and far less studied. Recently, deep learning has been applied to audio effect removal; however, existing approaches have focused on narrow formulations considering only one effect or source type at a time. In realistic scenarios, multiple effects are applied with varying source content. This motivates a more general task, which we refer to as general purpose audio effect removal. We developed a dataset for this task using five audio effects across four different sources and used it to train and evaluate a set of existing architectures. We found that no single model performed optimally on all effect types and sources. To address this, we introduced RemFX, an approach designed to mirror the compositionality of applied effects. We first trained a set of the best-performing effect-specific removal models and then leveraged an audio effect classification model to dynamically construct a graph of our models at inference. We found our approach to outperform single model baselines, although examples with many effects present remain challenging.","sentences":["Although the design and application of audio effects is well understood, the inverse problem of removing these effects is significantly more challenging and far less studied.","Recently, deep learning has been applied to audio effect removal; however, existing approaches have focused on narrow formulations considering only one effect or source type at a time.","In realistic scenarios, multiple effects are applied with varying source content.","This motivates a more general task, which we refer to as general purpose audio effect removal.","We developed a dataset for this task using five audio effects across four different sources and used it to train and evaluate a set of existing architectures.","We found that no single model performed optimally on all effect types and sources.","To address this, we introduced RemFX, an approach designed to mirror the compositionality of applied effects.","We first trained a set of the best-performing effect-specific removal models and then leveraged an audio effect classification model to dynamically construct a graph of our models at inference.","We found our approach to outperform single model baselines, although examples with many effects present remain challenging."],"url":"http://arxiv.org/abs/2308.16177v1"}
{"created":"2023-08-30 17:53:25","title":"Quantifying Uncertainty in Answers from any Language Model via Intrinsic and Extrinsic Confidence Assessment","abstract":"We introduce BSDetector, a method for detecting bad and speculative answers from a pretrained Large Language Model by estimating a numeric confidence score for any output it generated. Our uncertainty quantification technique works for any LLM accessible only via a black-box API, and combines intrinsic and extrinsic assessments of confidence into a single trustworthiness estimate for any LLM response to a given prompt. Our method is extremely general and can applied to all of the best LLMs available today (whose training data remains unknown). By expending a bit of extra computation, users of any LLM API can now get the same response as they would ordinarily, as well as a confidence estimate that caution when not to trust this response. Experiments on both closed and open-form Question-Answer benchmarks reveal that BSDetector more accurately identifies incorrect LLM responses than alternative uncertainty estimation procedures (for both GPT-3 and ChatGPT). By sampling multiple responses from the LLM and considering the one with the highest confidence score, we can additionally obtain more accurate responses from the same LLM, without any extra training steps.","sentences":["We introduce BSDetector, a method for detecting bad and speculative answers from a pretrained Large Language Model by estimating a numeric confidence score for any output it generated.","Our uncertainty quantification technique works for any LLM accessible only via a black-box API, and combines intrinsic and extrinsic assessments of confidence into a single trustworthiness estimate for any LLM response to a given prompt.","Our method is extremely general and can applied to all of the best LLMs available today (whose training data remains unknown).","By expending a bit of extra computation, users of any LLM API can now get the same response as they would ordinarily, as well as a confidence estimate that caution when not to trust this response.","Experiments on both closed and open-form Question-Answer benchmarks reveal that BSDetector more accurately identifies incorrect LLM responses than alternative uncertainty estimation procedures (for both GPT-3 and ChatGPT).","By sampling multiple responses from the LLM and considering the one with the highest confidence score, we can additionally obtain more accurate responses from the same LLM, without any extra training steps."],"url":"http://arxiv.org/abs/2308.16175v1"}
{"created":"2023-08-30 17:22:11","title":"Algebraic, Topological, and Mereological Foundations of Existential Granules","abstract":"In this research, new concepts of existential granules that determine themselves are invented, and are characterized from algebraic, topological, and mereological perspectives. Existential granules are those that determine themselves initially, and interact with their environment subsequently. Examples of the concept, such as those of granular balls, though inadequately defined, algorithmically established, and insufficiently theorized in earlier works by others, are already used in applications of rough sets and soft computing. It is shown that they fit into multiple theoretical frameworks (axiomatic, adaptive, and others) of granular computing. The characterization is intended for algorithm development, application to classification problems and possible mathematical foundations of generalizations of the approach. Additionally, many open problems are posed and directions provided.","sentences":["In this research, new concepts of existential granules that determine themselves are invented, and are characterized from algebraic, topological, and mereological perspectives.","Existential granules are those that determine themselves initially, and interact with their environment subsequently.","Examples of the concept, such as those of granular balls, though inadequately defined, algorithmically established, and insufficiently theorized in earlier works by others, are already used in applications of rough sets and soft computing.","It is shown that they fit into multiple theoretical frameworks (axiomatic, adaptive, and others) of granular computing.","The characterization is intended for algorithm development, application to classification problems and possible mathematical foundations of generalizations of the approach.","Additionally, many open problems are posed and directions provided."],"url":"http://arxiv.org/abs/2308.16157v1"}
{"created":"2023-08-30 17:20:46","title":"MMVP: Motion-Matrix-based Video Prediction","abstract":"A central challenge of video prediction lies where the system has to reason the objects' future motions from image frames while simultaneously maintaining the consistency of their appearances across frames. This work introduces an end-to-end trainable two-stream video prediction framework, Motion-Matrix-based Video Prediction (MMVP), to tackle this challenge. Unlike previous methods that usually handle motion prediction and appearance maintenance within the same set of modules, MMVP decouples motion and appearance information by constructing appearance-agnostic motion matrices. The motion matrices represent the temporal similarity of each and every pair of feature patches in the input frames, and are the sole input of the motion prediction module in MMVP. This design improves video prediction in both accuracy and efficiency, and reduces the model size. Results of extensive experiments demonstrate that MMVP outperforms state-of-the-art systems on public data sets by non-negligible large margins (about 1 db in PSNR, UCF Sports) in significantly smaller model sizes (84% the size or smaller). Please refer to https://github.com/Kay1794/MMVP-motion-matrix-based-video-prediction for the official code and the datasets used in this paper.","sentences":["A central challenge of video prediction lies where the system has to reason the objects' future motions from image frames while simultaneously maintaining the consistency of their appearances across frames.","This work introduces an end-to-end trainable two-stream video prediction framework, Motion-Matrix-based Video Prediction (MMVP), to tackle this challenge.","Unlike previous methods that usually handle motion prediction and appearance maintenance within the same set of modules, MMVP decouples motion and appearance information by constructing appearance-agnostic motion matrices.","The motion matrices represent the temporal similarity of each and every pair of feature patches in the input frames, and are the sole input of the motion prediction module in MMVP.","This design improves video prediction in both accuracy and efficiency, and reduces the model size.","Results of extensive experiments demonstrate that MMVP outperforms state-of-the-art systems on public data sets by non-negligible large margins (about 1 db in PSNR, UCF Sports) in significantly smaller model sizes (84% the size or smaller).","Please refer to https://github.com/Kay1794/MMVP-motion-matrix-based-video-prediction for the official code and the datasets used in this paper."],"url":"http://arxiv.org/abs/2308.16154v1"}
{"created":"2023-08-30 17:16:45","title":"Automatic assessment of text-based responses in post-secondary education: A systematic review","abstract":"Text-based open-ended questions in academic formative and summative assessments help students become deep learners and prepare them to understand concepts for a subsequent test conceptually. However, grading text-based questions, especially in large (>50 enrolled students) courses, is a tedious and time-costing process for instructors. Text processing models continue progressing with the rapid development of Artificial Intelligence (AI) tools and Natural Language Processing (NLP) algorithms. Especially after breakthroughs in Large Language Models (LLM), there is immense potential to automate rapid assessment and feedback of text-based responses in education. This systematic review adopts a scientific and reproducible literature search strategy based on the PRISMA process using explicit inclusion and exclusion criteria to study text-based automatic assessment systems in post-secondary education, screening 838 papers and synthesizing 93 studies. To understand how text-based automatic assessment systems have been developed and applied in education in recent years, all included studies are summarized and categorized according to a proposed comprehensive theoretical framework, including the input and output of the automatic assessment system, research motivation, and research outcome, aiming to answer three research questions accordingly. Additionally, the typical studies of automated assessment systems and application domains in these studies are investigated and summarized. This systematic review will provide an overview of recent educational applications of text-based assessment systems for understanding the latest AI/NLP developments assisting in text-based assessments in higher education. We expect it will particularly benefit researchers and educators incorporating LLMs such as ChatGPT into their educational activities.","sentences":["Text-based open-ended questions in academic formative and summative assessments help students become deep learners and prepare them to understand concepts for a subsequent test conceptually.","However, grading text-based questions, especially in large (>50 enrolled students) courses, is a tedious and time-costing process for instructors.","Text processing models continue progressing with the rapid development of Artificial Intelligence (AI) tools and Natural Language Processing (NLP) algorithms.","Especially after breakthroughs in Large Language Models (LLM), there is immense potential to automate rapid assessment and feedback of text-based responses in education.","This systematic review adopts a scientific and reproducible literature search strategy based on the PRISMA process using explicit inclusion and exclusion criteria to study text-based automatic assessment systems in post-secondary education, screening 838 papers and synthesizing 93 studies.","To understand how text-based automatic assessment systems have been developed and applied in education in recent years, all included studies are summarized and categorized according to a proposed comprehensive theoretical framework, including the input and output of the automatic assessment system, research motivation, and research outcome, aiming to answer three research questions accordingly.","Additionally, the typical studies of automated assessment systems and application domains in these studies are investigated and summarized.","This systematic review will provide an overview of recent educational applications of text-based assessment systems for understanding the latest AI/NLP developments assisting in text-based assessments in higher education.","We expect it will particularly benefit researchers and educators incorporating LLMs such as ChatGPT into their educational activities."],"url":"http://arxiv.org/abs/2308.16151v1"}
{"created":"2023-08-30 17:07:17","title":"Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models","abstract":"We introduce Jais and Jais-chat, new state-of-the-art Arabic-centric foundation and instruction-tuned open generative large language models (LLMs). The models are based on the GPT-3 decoder-only architecture and are pretrained on a mixture of Arabic and English texts, including source code in various programming languages. With 13 billion parameters, they demonstrate better knowledge and reasoning capabilities in Arabic than any existing open Arabic and multilingual models by a sizable margin, based on extensive evaluation. Moreover, the models are competitive in English compared to English-centric open models of similar size, despite being trained on much less English data. We provide a detailed description of the training, the tuning, the safety alignment, and the evaluation of the models. We release two open versions of the model -- the foundation Jais model, and an instruction-tuned Jais-chat variant -- with the aim of promoting research on Arabic LLMs. Available at https://huggingface.co/inception-mbzuai/jais-13b-chat","sentences":["We introduce Jais and Jais-chat, new state-of-the-art Arabic-centric foundation and instruction-tuned open generative large language models (LLMs).","The models are based on the GPT-3 decoder-only architecture and are pretrained on a mixture of Arabic and English texts, including source code in various programming languages.","With 13 billion parameters, they demonstrate better knowledge and reasoning capabilities in Arabic than any existing open Arabic and multilingual models by a sizable margin, based on extensive evaluation.","Moreover, the models are competitive in English compared to English-centric open models of similar size, despite being trained on much less English data.","We provide a detailed description of the training, the tuning, the safety alignment, and the evaluation of the models.","We release two open versions of the model -- the foundation Jais model, and an instruction-tuned Jais-chat variant -- with the aim of promoting research on Arabic LLMs.","Available at https://huggingface.co/inception-mbzuai/jais-13b-chat"],"url":"http://arxiv.org/abs/2308.16149v1"}
{"created":"2023-08-30 17:01:01","title":"CircleFormer: Circular Nuclei Detection in Whole Slide Images with Circle Queries and Attention","abstract":"Both CNN-based and Transformer-based object detection with bounding box representation have been extensively studied in computer vision and medical image analysis, but circular object detection in medical images is still underexplored. Inspired by the recent anchor free CNN-based circular object detection method (CircleNet) for ball-shape glomeruli detection in renal pathology, in this paper, we present CircleFormer, a Transformer-based circular medical object detection with dynamic anchor circles. Specifically, queries with circle representation in Transformer decoder iteratively refine the circular object detection results, and a circle cross attention module is introduced to compute the similarity between circular queries and image features. A generalized circle IoU (gCIoU) is proposed to serve as a new regression loss of circular object detection as well. Moreover, our approach is easy to generalize to the segmentation task by adding a simple segmentation branch to CircleFormer. We evaluate our method in circular nuclei detection and segmentation on the public MoNuSeg dataset, and the experimental results show that our method achieves promising performance compared with the state-of-the-art approaches. The effectiveness of each component is validated via ablation studies as well. Our code is released at: \\url{https://github.com/zhanghx-iim-ahu/CircleFormer}.","sentences":["Both CNN-based and Transformer-based object detection with bounding box representation have been extensively studied in computer vision and medical image analysis, but circular object detection in medical images is still underexplored.","Inspired by the recent anchor free CNN-based circular object detection method (CircleNet) for ball-shape glomeruli detection in renal pathology, in this paper, we present CircleFormer, a Transformer-based circular medical object detection with dynamic anchor circles.","Specifically, queries with circle representation in Transformer decoder iteratively refine the circular object detection results, and a circle cross attention module is introduced to compute the similarity between circular queries and image features.","A generalized circle IoU (gCIoU) is proposed to serve as a new regression loss of circular object detection as well.","Moreover, our approach is easy to generalize to the segmentation task by adding a simple segmentation branch to CircleFormer.","We evaluate our method in circular nuclei detection and segmentation on the public MoNuSeg dataset, and the experimental results show that our method achieves promising performance compared with the state-of-the-art approaches.","The effectiveness of each component is validated via ablation studies as well.","Our code is released at: \\url{https://github.com/zhanghx-iim-ahu/CircleFormer}."],"url":"http://arxiv.org/abs/2308.16145v1"}
{"created":"2023-08-30 16:52:31","title":"Intergroup Bias in Attitudes Toward Restrictions on Uncivil Political Expression and Its Underlying Mechanisms","abstract":"There appears to be a dilemma between the freedom of expression and protection from the adverse effects of uncivil political expression online. While previous studies have revealed various factors that affect attitudes toward freedom of expression and speech restrictions, it is less clear whether people have intergroup biases when forming these attitudes. To address this gap, the present study conducted a pre-registered online survey experiment and investigated people's attitudes toward uncivil political expression by randomizing its in-group and out-group affiliations. The results revealed that people tend to perceive uncivil political expression directed from an out-group toward an in-group as more uncivil, compared to the expression originating from an in-group toward an out-group. This difference subsequently influences their inclination to endorse speech restrictions when faced with uncivil political comments: stronger support for restrictions on expressions from the out-group toward the in-group as opposed to those from the in-group toward the out-group. These findings should serve as a wake-up call to public opinion that advocates for restrictions on uncivil political expression.","sentences":["There appears to be a dilemma between the freedom of expression and protection from the adverse effects of uncivil political expression online.","While previous studies have revealed various factors that affect attitudes toward freedom of expression and speech restrictions, it is less clear whether people have intergroup biases when forming these attitudes.","To address this gap, the present study conducted a pre-registered online survey experiment and investigated people's attitudes toward uncivil political expression by randomizing its in-group and out-group affiliations.","The results revealed that people tend to perceive uncivil political expression directed from an out-group toward an in-group as more uncivil, compared to the expression originating from an in-group toward an out-group.","This difference subsequently influences their inclination to endorse speech restrictions when faced with uncivil political comments: stronger support for restrictions on expressions from the out-group toward the in-group as opposed to those from the in-group toward the out-group.","These findings should serve as a wake-up call to public opinion that advocates for restrictions on uncivil political expression."],"url":"http://arxiv.org/abs/2308.16140v1"}
{"created":"2023-08-30 16:52:20","title":"MedShapeNet -- A Large-Scale Dataset of 3D Medical Shapes for Computer Vision","abstract":"We present MedShapeNet, a large collection of anatomical shapes (e.g., bones, organs, vessels) and 3D surgical instrument models. Prior to the deep learning era, the broad application of statistical shape models (SSMs) in medical image analysis is evidence that shapes have been commonly used to describe medical data. Nowadays, however, state-of-the-art (SOTA) deep learning algorithms in medical imaging are predominantly voxel-based. In computer vision, on the contrary, shapes (including, voxel occupancy grids, meshes, point clouds and implicit surface models) are preferred data representations in 3D, as seen from the numerous shape-related publications in premier vision conferences, such as the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), as well as the increasing popularity of ShapeNet (about 51,300 models) and Princeton ModelNet (127,915 models) in computer vision research. MedShapeNet is created as an alternative to these commonly used shape benchmarks to facilitate the translation of data-driven vision algorithms to medical applications, and it extends the opportunities to adapt SOTA vision algorithms to solve critical medical problems. Besides, the majority of the medical shapes in MedShapeNet are modeled directly on the imaging data of real patients, and therefore it complements well existing shape benchmarks comprising of computer-aided design (CAD) models. MedShapeNet currently includes more than 100,000 medical shapes, and provides annotations in the form of paired data. It is therefore also a freely available repository of 3D models for extended reality (virtual reality - VR, augmented reality - AR, mixed reality - MR) and medical 3D printing. This white paper describes in detail the motivations behind MedShapeNet, the shape acquisition procedures, the use cases, as well as the usage of the online shape search portal: https://medshapenet.ikim.nrw/","sentences":["We present MedShapeNet, a large collection of anatomical shapes (e.g., bones, organs, vessels) and 3D surgical instrument models.","Prior to the deep learning era, the broad application of statistical shape models (SSMs) in medical image analysis is evidence that shapes have been commonly used to describe medical data.","Nowadays, however, state-of-the-art (SOTA) deep learning algorithms in medical imaging are predominantly voxel-based.","In computer vision, on the contrary, shapes (including, voxel occupancy grids, meshes, point clouds and implicit surface models) are preferred data representations in 3D, as seen from the numerous shape-related publications in premier vision conferences, such as the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), as well as the increasing popularity of ShapeNet (about 51,300 models) and Princeton ModelNet (127,915 models) in computer vision research.","MedShapeNet is created as an alternative to these commonly used shape benchmarks to facilitate the translation of data-driven vision algorithms to medical applications, and it extends the opportunities to adapt SOTA vision algorithms to solve critical medical problems.","Besides, the majority of the medical shapes in MedShapeNet are modeled directly on the imaging data of real patients, and therefore it complements well existing shape benchmarks comprising of computer-aided design (CAD) models.","MedShapeNet currently includes more than 100,000 medical shapes, and provides annotations in the form of paired data.","It is therefore also a freely available repository of 3D models for extended reality (virtual reality - VR, augmented reality - AR, mixed reality - MR) and medical 3D printing.","This white paper describes in detail the motivations behind MedShapeNet, the shape acquisition procedures, the use cases, as well as the usage of the online shape search portal: https://medshapenet.ikim.nrw/"],"url":"http://arxiv.org/abs/2308.16139v1"}
{"created":"2023-08-30 16:47:51","title":"LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models","abstract":"In recent years, there have been remarkable advancements in the performance of Transformer-based Large Language Models (LLMs) across various domains. As these LLMs are deployed for increasingly complex tasks, they often face the needs to conduct longer reasoning processes or understanding larger contexts. In these situations, the length generalization failure of LLMs on long sequences become more prominent. Most pre-training schemes truncate training sequences to a fixed length (such as 2048 for LLaMa). LLMs often struggle to generate fluent texts, let alone carry out downstream tasks, after longer contexts, even with relative positional encoding which is designed to cope with this problem. Common solutions such as finetuning on longer corpora often involves daunting hardware and time costs and requires careful training process design. To more efficiently leverage the generation capacity of existing LLMs, we theoretically and empirically investigate the main out-of-distribution (OOD) factors contributing to this problem. Inspired by this diagnosis, we propose a simple yet effective solution for on-the-fly length generalization, LM-Infinite, which involves only a $\\Lambda$-shaped attention mask and a distance limit while requiring no parameter updates or learning. We find it applicable to a variety of LLMs using relative-position encoding methods. LM-Infinite is computational efficient with $O(n)$ time and space, and demonstrates consistent fluency and generation quality to as long as 32k tokens on ArXiv and OpenWebText2 datasets, with 2.72x decoding speedup. On downstream task such as passkey retrieval, it continues to work on inputs much longer than training lengths where vanilla models fail immediately.","sentences":["In recent years, there have been remarkable advancements in the performance of Transformer-based Large Language Models (LLMs) across various domains.","As these LLMs are deployed for increasingly complex tasks, they often face the needs to conduct longer reasoning processes or understanding larger contexts.","In these situations, the length generalization failure of LLMs on long sequences become more prominent.","Most pre-training schemes truncate training sequences to a fixed length (such as 2048 for LLaMa).","LLMs often struggle to generate fluent texts, let alone carry out downstream tasks, after longer contexts, even with relative positional encoding which is designed to cope with this problem.","Common solutions such as finetuning on longer corpora often involves daunting hardware and time costs and requires careful training process design.","To more efficiently leverage the generation capacity of existing LLMs, we theoretically and empirically investigate the main out-of-distribution (OOD) factors contributing to this problem.","Inspired by this diagnosis, we propose a simple yet effective solution for on-the-fly length generalization, LM-Infinite, which involves only a $\\Lambda$-shaped attention mask and a distance limit while requiring no parameter updates or learning.","We find it applicable to a variety of LLMs using relative-position encoding methods.","LM-Infinite is computational efficient with $O(n)$ time and space, and demonstrates consistent fluency and generation quality to as long as 32k tokens on ArXiv and OpenWebText2 datasets, with 2.72x decoding speedup.","On downstream task such as passkey retrieval, it continues to work on inputs much longer than training lengths where vanilla models fail immediately."],"url":"http://arxiv.org/abs/2308.16137v1"}
{"created":"2023-08-30 16:26:26","title":"Near-Field 3D Localization via MIMO Radar: Cram\u00e9r-Rao Bound Analysis and Estimator Design","abstract":"This paper studies a near-field multiple-input multiple-output (MIMO) radar sensing system, in which the transceivers with massive antennas aim to localize multiple near-field targets in the three-dimensional (3D) space over unknown cluttered environments. We consider a spherical wavefront propagation with both channel phase and amplitude variations over different antennas. Under this setup, the unknown parameters include the 3D coordinates and complex reflection coefficients of the targets, as well as the noise and interference covariance matrix. First, by considering general transmit signal waveforms, we derive the Fisher information matrix (FIM) corresponding to the 3D coordinates and the complex reflection coefficients of the targets and accordingly obtain the Cram\\'er-Rao bound (CRB) for the 3D coordinates. This provides a performance bound for 3D near-field target localization. For the special single-target case, we obtain the CRB in an analytical form, and analyze its asymptotic scaling behaviors with respect to the target distance and antenna size of the transceiver. Next, to facilitate practical localization, we propose two estimators to localize targets based on the maximum likelihood (ML) criterion, namely the 3D approximate cyclic optimization (3D-ACO) and the 3D cyclic optimization with white Gaussian noise (3D-CO-WGN), respectively. Numerical results validate the asymptotic CRB analysis and show that the consideration of varying channel amplitudes is vital to achieve accurate CRB and localization when the targets are close to the transceivers. It is also shown that the proposed estimators achieve localization performance close to the derived CRB under various cluttered environments, thus validating their effectiveness in practical implementation. Furthermore, it is shown that transmit waveforms have a significant impact on CRB and the localization performance.","sentences":["This paper studies a near-field multiple-input multiple-output (MIMO) radar sensing system, in which the transceivers with massive antennas aim to localize multiple near-field targets in the three-dimensional (3D) space over unknown cluttered environments.","We consider a spherical wavefront propagation with both channel phase and amplitude variations over different antennas.","Under this setup, the unknown parameters include the 3D coordinates and complex reflection coefficients of the targets, as well as the noise and interference covariance matrix.","First, by considering general transmit signal waveforms, we derive the Fisher information matrix (FIM) corresponding to the 3D coordinates and the complex reflection coefficients of the targets and accordingly obtain the Cram\\'er-Rao bound (CRB) for the 3D coordinates.","This provides a performance bound for 3D near-field target localization.","For the special single-target case, we obtain the CRB in an analytical form, and analyze its asymptotic scaling behaviors with respect to the target distance and antenna size of the transceiver.","Next, to facilitate practical localization, we propose two estimators to localize targets based on the maximum likelihood (ML) criterion, namely the 3D approximate cyclic optimization (3D-ACO) and the 3D cyclic optimization with white Gaussian noise (3D-CO-WGN), respectively.","Numerical results validate the asymptotic CRB analysis and show that the consideration of varying channel amplitudes is vital to achieve accurate CRB and localization when the targets are close to the transceivers.","It is also shown that the proposed estimators achieve localization performance close to the derived CRB under various cluttered environments, thus validating their effectiveness in practical implementation.","Furthermore, it is shown that transmit waveforms have a significant impact on CRB and the localization performance."],"url":"http://arxiv.org/abs/2308.16130v1"}
{"created":"2023-08-30 16:23:07","title":"CorrEmbed: Evaluating Pre-trained Model Image Similarity Efficacy with a Novel Metric","abstract":"Detecting visually similar images is a particularly useful attribute to look to when calculating product recommendations. Embedding similarity, which utilizes pre-trained computer vision models to extract high-level image features, has demonstrated remarkable efficacy in identifying images with similar compositions. However, there is a lack of methods for evaluating the embeddings generated by these models, as conventional loss and performance metrics do not adequately capture their performance in image similarity search tasks.   In this paper, we evaluate the viability of the image embeddings from numerous pre-trained computer vision models using a novel approach named CorrEmbed. Our approach computes the correlation between distances in image embeddings and distances in human-generated tag vectors. We extensively evaluate numerous pre-trained Torchvision models using this metric, revealing an intuitive relationship of linear scaling between ImageNet1k accuracy scores and tag-correlation scores. Importantly, our method also identifies deviations from this pattern, providing insights into how different models capture high-level image features.   By offering a robust performance evaluation of these pre-trained models, CorrEmbed serves as a valuable tool for researchers and practitioners seeking to develop effective, data-driven approaches to similar item recommendations in fashion retail.","sentences":["Detecting visually similar images is a particularly useful attribute to look to when calculating product recommendations.","Embedding similarity, which utilizes pre-trained computer vision models to extract high-level image features, has demonstrated remarkable efficacy in identifying images with similar compositions.","However, there is a lack of methods for evaluating the embeddings generated by these models, as conventional loss and performance metrics do not adequately capture their performance in image similarity search tasks.   ","In this paper, we evaluate the viability of the image embeddings from numerous pre-trained computer vision models using a novel approach named CorrEmbed.","Our approach computes the correlation between distances in image embeddings and distances in human-generated tag vectors.","We extensively evaluate numerous pre-trained Torchvision models using this metric, revealing an intuitive relationship of linear scaling between ImageNet1k accuracy scores and tag-correlation scores.","Importantly, our method also identifies deviations from this pattern, providing insights into how different models capture high-level image features.   ","By offering a robust performance evaluation of these pre-trained models, CorrEmbed serves as a valuable tool for researchers and practitioners seeking to develop effective, data-driven approaches to similar item recommendations in fashion retail."],"url":"http://arxiv.org/abs/2308.16126v1"}
{"created":"2023-08-30 16:21:02","title":"Spatial Graph Coarsening: Weather and Weekday Prediction with London's Bike-Sharing Service using GNN","abstract":"This study introduced the use of Graph Neural Network (GNN) for predicting the weather and weekday of a day in London, from the dataset of Santander Cycles bike-sharing system as a graph classification task. The proposed GNN models newly introduced (i) a concatenation operator of graph features with trained node embeddings and (ii) a graph coarsening operator based on geographical contiguity, namely \"Spatial Graph Coarsening\". With the node features of land-use characteristics and number of households around the bike stations and graph features of temperatures in the city, our proposed models outperformed the baseline model in cross-entropy loss and accuracy of the validation dataset.","sentences":["This study introduced the use of Graph Neural Network (GNN) for predicting the weather and weekday of a day in London, from the dataset of Santander Cycles bike-sharing system as a graph classification task.","The proposed GNN models newly introduced (i) a concatenation operator of graph features with trained node embeddings and (ii) a graph coarsening operator based on geographical contiguity, namely \"Spatial Graph Coarsening\".","With the node features of land-use characteristics and number of households around the bike stations and graph features of temperatures in the city, our proposed models outperformed the baseline model in cross-entropy loss and accuracy of the validation dataset."],"url":"http://arxiv.org/abs/2308.16122v1"}
{"created":"2023-08-30 16:17:26","title":"Response: Emergent analogical reasoning in large language models","abstract":"In their recent Nature Human Behaviour paper, \"Emergent analogical reasoning in large language models,\" (Webb, Holyoak, and Lu, 2023) the authors argue that \"large language models such as GPT-3 have acquired an emergent ability to find zero-shot solutions to a broad range of analogy problems.\" In this response, we provide counterexamples of the letter string analogies. In our tests, GPT-3 fails to solve even the easiest variants of the problems presented in the original paper. Zero-shot reasoning is an extraordinary claim that requires extraordinary evidence. We do not see that evidence in our experiments. To strengthen claims of humanlike reasoning such as zero-shot reasoning, it is important that the field develop approaches that rule out data memorization.","sentences":["In their recent Nature Human Behaviour paper, \"Emergent analogical reasoning in large language models,\" (Webb, Holyoak, and Lu, 2023) the authors argue that \"large language models such as GPT-3 have acquired an emergent ability to find zero-shot solutions to a broad range of analogy problems.\"","In this response, we provide counterexamples of the letter string analogies.","In our tests, GPT-3 fails to solve even the easiest variants of the problems presented in the original paper.","Zero-shot reasoning is an extraordinary claim that requires extraordinary evidence.","We do not see that evidence in our experiments.","To strengthen claims of humanlike reasoning such as zero-shot reasoning, it is important that the field develop approaches that rule out data memorization."],"url":"http://arxiv.org/abs/2308.16118v1"}
{"created":"2023-08-30 16:14:20","title":"survex: an R package for explaining machine learning survival models","abstract":"Due to their flexibility and superior performance, machine learning models frequently complement and outperform traditional statistical survival models. However, their widespread adoption is hindered by a lack of user-friendly tools to explain their internal operations and prediction rationales. To tackle this issue, we introduce the survex R package, which provides a cohesive framework for explaining any survival model by applying explainable artificial intelligence techniques. The capabilities of the proposed software encompass understanding and diagnosing survival models, which can lead to their improvement. By revealing insights into the decision-making process, such as variable effects and importances, survex enables the assessment of model reliability and the detection of biases. Thus, transparency and responsibility may be promoted in sensitive areas, such as biomedical research and healthcare applications.","sentences":["Due to their flexibility and superior performance, machine learning models frequently complement and outperform traditional statistical survival models.","However, their widespread adoption is hindered by a lack of user-friendly tools to explain their internal operations and prediction rationales.","To tackle this issue, we introduce the survex R package, which provides a cohesive framework for explaining any survival model by applying explainable artificial intelligence techniques.","The capabilities of the proposed software encompass understanding and diagnosing survival models, which can lead to their improvement.","By revealing insights into the decision-making process, such as variable effects and importances, survex enables the assessment of model reliability and the detection of biases.","Thus, transparency and responsibility may be promoted in sensitive areas, such as biomedical research and healthcare applications."],"url":"http://arxiv.org/abs/2308.16113v1"}
{"created":"2023-08-30 16:10:21","title":"Improving Few-shot Image Generation by Structural Discrimination and Textural Modulation","abstract":"Few-shot image generation, which aims to produce plausible and diverse images for one category given a few images from this category, has drawn extensive attention. Existing approaches either globally interpolate different images or fuse local representations with pre-defined coefficients. However, such an intuitive combination of images/features only exploits the most relevant information for generation, leading to poor diversity and coarse-grained semantic fusion. To remedy this, this paper proposes a novel textural modulation (TexMod) mechanism to inject external semantic signals into internal local representations. Parameterized by the feedback from the discriminator, our TexMod enables more fined-grained semantic injection while maintaining the synthesis fidelity. Moreover, a global structural discriminator (StructD) is developed to explicitly guide the model to generate images with reasonable layout and outline. Furthermore, the frequency awareness of the model is reinforced by encouraging the model to distinguish frequency signals. Together with these techniques, we build a novel and effective model for few-shot image generation. The effectiveness of our model is identified by extensive experiments on three popular datasets and various settings. Besides achieving state-of-the-art synthesis performance on these datasets, our proposed techniques could be seamlessly integrated into existing models for a further performance boost.","sentences":["Few-shot image generation, which aims to produce plausible and diverse images for one category given a few images from this category, has drawn extensive attention.","Existing approaches either globally interpolate different images or fuse local representations with pre-defined coefficients.","However, such an intuitive combination of images/features only exploits the most relevant information for generation, leading to poor diversity and coarse-grained semantic fusion.","To remedy this, this paper proposes a novel textural modulation (TexMod) mechanism to inject external semantic signals into internal local representations.","Parameterized by the feedback from the discriminator, our TexMod enables more fined-grained semantic injection while maintaining the synthesis fidelity.","Moreover, a global structural discriminator (StructD) is developed to explicitly guide the model to generate images with reasonable layout and outline.","Furthermore, the frequency awareness of the model is reinforced by encouraging the model to distinguish frequency signals.","Together with these techniques, we build a novel and effective model for few-shot image generation.","The effectiveness of our model is identified by extensive experiments on three popular datasets and various settings.","Besides achieving state-of-the-art synthesis performance on these datasets, our proposed techniques could be seamlessly integrated into existing models for a further performance boost."],"url":"http://arxiv.org/abs/2308.16110v1"}
{"created":"2023-08-30 16:04:54","title":"Grandma Karl is 27 years old -- research agenda for pseudonymization of research data","abstract":"Accessibility of research data is critical for advances in many research fields, but textual data often cannot be shared due to the personal and sensitive information which it contains, e.g names or political opinions. General Data Protection Regulation (GDPR) suggests pseudonymization as a solution to secure open access to research data, but we need to learn more about pseudonymization as an approach before adopting it for manipulation of research data. This paper outlines a research agenda within pseudonymization, namely need of studies into the effects of pseudonymization on unstructured data in relation to e.g. readability and language assessment, as well as the effectiveness of pseudonymization as a way of protecting writer identity, while also exploring different ways of developing context-sensitive algorithms for detection, labelling and replacement of personal information in unstructured data. The recently granted project on pseudonymization Grandma Karl is 27 years old addresses exactly those challenges.","sentences":["Accessibility of research data is critical for advances in many research fields, but textual data often cannot be shared due to the personal and sensitive information which it contains, e.g names or political opinions.","General Data Protection Regulation (GDPR) suggests pseudonymization as a solution to secure open access to research data, but we need to learn more about pseudonymization as an approach before adopting it for manipulation of research data.","This paper outlines a research agenda within pseudonymization, namely need of studies into the effects of pseudonymization on unstructured data in relation to e.g. readability and language assessment, as well as the effectiveness of pseudonymization as a way of protecting writer identity, while also exploring different ways of developing context-sensitive algorithms for detection, labelling and replacement of personal information in unstructured data.","The recently granted project on pseudonymization Grandma Karl is 27 years old addresses exactly those challenges."],"url":"http://arxiv.org/abs/2308.16109v1"}
{"created":"2023-08-30 15:54:06","title":"Advanced Deep Regression Models for Forecasting Time Series Oil Production","abstract":"Global oil demand is rapidly increasing and is expected to reach 106.3 million barrels per day by 2040. Thus, it is vital for hydrocarbon extraction industries to forecast their production to optimize their operations and avoid losses. Big companies have realized that exploiting the power of deep learning (DL) and the massive amount of data from various oil wells for this purpose can save a lot of operational costs and reduce unwanted environmental impacts. In this direction, researchers have proposed models using conventional machine learning (ML) techniques for oil production forecasting. However, these techniques are inappropriate for this problem as they can not capture historical patterns found in time series data, resulting in inaccurate predictions. This research aims to overcome these issues by developing advanced data-driven regression models using sequential convolutions and long short-term memory (LSTM) units. Exhaustive analyses are conducted to select the optimal sequence length, model hyperparameters, and cross-well dataset formation to build highly generalized robust models. A comprehensive experimental study on Volve oilfield data validates the proposed models. It reveals that the LSTM-based sequence learning model can predict oil production better than the 1-D convolutional neural network (CNN) with mean absolute error (MAE) and R2 score of 111.16 and 0.98, respectively. It is also found that the LSTM-based model performs better than all the existing state-of-the-art solutions and achieves a 37% improvement compared to a standard linear regression, which is considered the baseline model in this work.","sentences":["Global oil demand is rapidly increasing and is expected to reach 106.3 million barrels per day by 2040.","Thus, it is vital for hydrocarbon extraction industries to forecast their production to optimize their operations and avoid losses.","Big companies have realized that exploiting the power of deep learning (DL) and the massive amount of data from various oil wells for this purpose can save a lot of operational costs and reduce unwanted environmental impacts.","In this direction, researchers have proposed models using conventional machine learning (ML) techniques for oil production forecasting.","However, these techniques are inappropriate for this problem as they can not capture historical patterns found in time series data, resulting in inaccurate predictions.","This research aims to overcome these issues by developing advanced data-driven regression models using sequential convolutions and long short-term memory (LSTM) units.","Exhaustive analyses are conducted to select the optimal sequence length, model hyperparameters, and cross-well dataset formation to build highly generalized robust models.","A comprehensive experimental study on Volve oilfield data validates the proposed models.","It reveals that the LSTM-based sequence learning model can predict oil production better than the 1-D convolutional neural network (CNN) with mean absolute error (MAE) and R2 score of 111.16 and 0.98, respectively.","It is also found that the LSTM-based model performs better than all the existing state-of-the-art solutions and achieves a 37% improvement compared to a standard linear regression, which is considered the baseline model in this work."],"url":"http://arxiv.org/abs/2308.16105v1"}
{"created":"2023-08-30 15:51:03","title":"A Surgery-Detection Two-Dimensional Panorama of Signal Acquisition Technologies in Brain-Computer Interface","abstract":"Brain-computer interface (BCI) technology is an interdisciplinary field that allows individuals to connect with the external world. The performance of BCI systems relies predominantly on the advancements of signal acquisition technology. This paper aims to present a comprehensive overview of signal acquisition technologies in BCI by examining research articles published in the past decade. Our review incorporates both clinician and engineer perspectives and presents a surgery-detection two-dimensional panorama of signal acquisition technologies in BCI. We classify the technologies into nine distinct categories, providing representative examples and emphasizing the significant challenges associated with each modality. Our review provides researchers and practitioners with a macroscopic understanding of BCI signal acquisition technologies and discuss the field's major issues today. Future development in BCI signal acquisition technology should prioritize the integration of diverse disciplines and perspectives. Striking a balance among signal quality, trauma, biocompatibility, and other relevant factors is crucial. This will promote the advancement of BCI technology, enhancing its efficiency, safety, and reliability, and ultimately contributing to a promising future for humanity.","sentences":["Brain-computer interface (BCI) technology is an interdisciplinary field that allows individuals to connect with the external world.","The performance of BCI systems relies predominantly on the advancements of signal acquisition technology.","This paper aims to present a comprehensive overview of signal acquisition technologies in BCI by examining research articles published in the past decade.","Our review incorporates both clinician and engineer perspectives and presents a surgery-detection two-dimensional panorama of signal acquisition technologies in BCI.","We classify the technologies into nine distinct categories, providing representative examples and emphasizing the significant challenges associated with each modality.","Our review provides researchers and practitioners with a macroscopic understanding of BCI signal acquisition technologies and discuss the field's major issues today.","Future development in BCI signal acquisition technology should prioritize the integration of diverse disciplines and perspectives.","Striking a balance among signal quality, trauma, biocompatibility, and other relevant factors is crucial.","This will promote the advancement of BCI technology, enhancing its efficiency, safety, and reliability, and ultimately contributing to a promising future for humanity."],"url":"http://arxiv.org/abs/2308.16102v1"}
{"created":"2023-08-30 15:48:24","title":"Rate-Splitting for CF Massive MIMO Systems With Channel Aging","abstract":"The cell-free (CF) massive multiple-input multiple-output (MIMO) system is considered a cutting-edge technology in next-generation mobile communication due to its ability to provide high-performance coverage seamlessly and uniformly. This paper aims to mitigate the negative impact of channel aging due to the movement of user equipment in CF massive MIMO systems by utilizing rate-splitting (RS) technology. Taking into account the outdated channel state information, we obtain the achievable sum spectral efficiency (SE) of the RS-assisted CF massive MIMO system, where the private messages can directly adopt conventional maximum ratio, local minimum mean square error (MMSE), and centralized MMSE precoding schemes. Moreover, we propose a bisection-based precoding scheme that maximizes the minimum SE of common messages, which outperforms the superposition-based and random precoding schemes and exhibits strong robustness in complex mobile scenarios. Furthermore, we derive a novel closed-form sum SE expression for the considered system. The results demonstrate that RS technology can mitigate interference in mobile CF massive MIMO systems, improving overall system performance.","sentences":["The cell-free (CF) massive multiple-input multiple-output (MIMO) system is considered a cutting-edge technology in next-generation mobile communication due to its ability to provide high-performance coverage seamlessly and uniformly.","This paper aims to mitigate the negative impact of channel aging due to the movement of user equipment in CF massive MIMO systems by utilizing rate-splitting (RS) technology.","Taking into account the outdated channel state information, we obtain the achievable sum spectral efficiency (SE) of the RS-assisted CF massive MIMO system, where the private messages can directly adopt conventional maximum ratio, local minimum mean square error (MMSE), and centralized MMSE precoding schemes.","Moreover, we propose a bisection-based precoding scheme that maximizes the minimum SE of common messages, which outperforms the superposition-based and random precoding schemes and exhibits strong robustness in complex mobile scenarios.","Furthermore, we derive a novel closed-form sum SE expression for the considered system.","The results demonstrate that RS technology can mitigate interference in mobile CF massive MIMO systems, improving overall system performance."],"url":"http://arxiv.org/abs/2308.16099v1"}
{"created":"2023-08-30 15:44:01","title":"Food Choice Mimicry on a Large University Campus","abstract":"Social influence is a strong determinant of food consumption, which in turn influences health. Although consistent observations have been made on the role of social factors in driving similarities in food consumption, much less is known about the precise governing mechanisms. We study social influence on food choice through carefully designed causal analyses, leveraging the sequential nature of shop queues on a major university campus. In particular, we consider a large number of adjacent purchases where a focal user immediately follows another user (\"partner\") in the checkout queue and both make a purchase. Identifying the partner's impact on the focal user, we find strong evidence of a specific behavioral mechanism for how dietary similarities between individuals arise: purchasing mimicry, a phenomenon where the focal user copies the partner's purchases. For instance, across food additions purchased during lunchtime together with a meal, we find that the focal user is significantly more likely to purchase the food item when the partner buys the item, v.s. when the partner does not, increasing the purchasing probability by 14% in absolute terms, or by 83% in relative terms. The effect is observed across all food types, but largest for condiments, and smallest for soft drinks. We find that no such effect is observed when a focal user is compared to a random (rather than directly preceding) partner. Furthermore, purchasing mimicry is present across age, gender, and status subpopulations, but strongest for students and the youngest persons. Finally, we find a dose-response relationship whereby mimicry decreases as proximity in the purchasing queue decreases. The results of this study elucidate the behavioral mechanism of purchasing mimicry and have further implications for understanding and improving dietary behaviors on campus.","sentences":["Social influence is a strong determinant of food consumption, which in turn influences health.","Although consistent observations have been made on the role of social factors in driving similarities in food consumption, much less is known about the precise governing mechanisms.","We study social influence on food choice through carefully designed causal analyses, leveraging the sequential nature of shop queues on a major university campus.","In particular, we consider a large number of adjacent purchases where a focal user immediately follows another user (\"partner\") in the checkout queue and both make a purchase.","Identifying the partner's impact on the focal user, we find strong evidence of a specific behavioral mechanism for how dietary similarities between individuals arise: purchasing mimicry, a phenomenon where the focal user copies the partner's purchases.","For instance, across food additions purchased during lunchtime together with a meal, we find that the focal user is significantly more likely to purchase the food item when the partner buys the item, v.s. when the partner does not, increasing the purchasing probability by 14% in absolute terms, or by 83% in relative terms.","The effect is observed across all food types, but largest for condiments, and smallest for soft drinks.","We find that no such effect is observed when a focal user is compared to a random (rather than directly preceding) partner.","Furthermore, purchasing mimicry is present across age, gender, and status subpopulations, but strongest for students and the youngest persons.","Finally, we find a dose-response relationship whereby mimicry decreases as proximity in the purchasing queue decreases.","The results of this study elucidate the behavioral mechanism of purchasing mimicry and have further implications for understanding and improving dietary behaviors on campus."],"url":"http://arxiv.org/abs/2308.16095v1"}
{"created":"2023-08-30 15:26:35","title":"Application of Zone Method based Machine Learning and Physics-Informed Neural Networks in Reheating Furnaces","abstract":"Despite the high economic relevance of Foundation Industries, certain components like Reheating furnaces within their manufacturing chain are energy-intensive. Notable energy consumption reduction could be obtained by reducing the overall heating time in furnaces. Computer-integrated Machine Learning (ML) and Artificial Intelligence (AI) powered control systems in furnaces could be enablers in achieving the Net-Zero goals in Foundation Industries for sustainable manufacturing.   In this work, due to the infeasibility of achieving good quality data in scenarios like reheating furnaces, classical Hottel's zone method based computational model has been used to generate data for ML and Deep Learning (DL) based model training via regression. It should be noted that the zone method provides an elegant way to model the physical phenomenon of Radiative Heat Transfer (RHT), the dominating heat transfer mechanism in high-temperature processes inside heating furnaces. Using this data, an extensive comparison among a wide range of state-of-the-art, representative ML and DL methods has been made against their temperature prediction performances in varying furnace environments. Owing to their holistic balance among inference times and model performance, DL stands out among its counterparts. To further enhance the Out-Of-Distribution (OOD) generalization capability of the trained DL models, we propose a Physics-Informed Neural Network (PINN) by incorporating prior physical knowledge using a set of novel Energy-Balance regularizers. Our setup is a generic framework, is geometry-agnostic of the 3D structure of the underlying furnace, and as such could accommodate any standard ML regression model, to serve as a Digital Twin of the underlying physical processes, for transitioning Foundation Industries towards Industry 4.0.","sentences":["Despite the high economic relevance of Foundation Industries, certain components like Reheating furnaces within their manufacturing chain are energy-intensive.","Notable energy consumption reduction could be obtained by reducing the overall heating time in furnaces.","Computer-integrated Machine Learning (ML) and Artificial Intelligence (AI) powered control systems in furnaces could be enablers in achieving the Net-Zero goals in Foundation Industries for sustainable manufacturing.   ","In this work, due to the infeasibility of achieving good quality data in scenarios like reheating furnaces, classical Hottel's zone method based computational model has been used to generate data for ML and Deep Learning (DL) based model training via regression.","It should be noted that the zone method provides an elegant way to model the physical phenomenon of Radiative Heat Transfer (RHT), the dominating heat transfer mechanism in high-temperature processes inside heating furnaces.","Using this data, an extensive comparison among a wide range of state-of-the-art, representative ML and DL methods has been made against their temperature prediction performances in varying furnace environments.","Owing to their holistic balance among inference times and model performance, DL stands out among its counterparts.","To further enhance the Out-Of-Distribution (OOD) generalization capability of the trained DL models, we propose a Physics-Informed Neural Network (PINN) by incorporating prior physical knowledge using a set of novel Energy-Balance regularizers.","Our setup is a generic framework, is geometry-agnostic of the 3D structure of the underlying furnace, and as such could accommodate any standard ML regression model, to serve as a Digital Twin of the underlying physical processes, for transitioning Foundation Industries towards Industry 4.0."],"url":"http://arxiv.org/abs/2308.16089v1"}
{"created":"2023-08-30 15:17:25","title":"State Estimation over Broadcast and Multi-Access Channels in an Unreliable Regime","abstract":"This article examines the problem of state estimation over multi-terminal channels in an unreliable regime. More specifically, we consider two canonical settings. In the first setting, measurements of a common stochastic source need to be transmitted to two distinct remote monitors over a packet-erasure broadcast channel. In the second setting, measurements of two distinct stochastic sources need to be transmitted to a common remote monitor over a packet-erasure multi-access channel. For these networked systems, we uncover the fundamental performance limits in the sense of a causal tradeoff between the estimation error and the communication cost by identifying optimal encoding and decoding strategies. In the course of our analysis, we introduce two novel semantic metrics that play essential roles in state estimation over broadcast and multi-access channels. The first metric arising in the context of broadcast channels is the dissemination value of information, which quantifies the valuation of provisioning a piece of information to multiple receivers simultaneously. The second metric arising in the context of multi-access channels is the prioritization value of information, which quantifies the valuation of provisioning a piece of information chosen from one out of multiple transmitters. Our findings certify that the optimal encoding and decoding strategies hinge on these semantic metrics.","sentences":["This article examines the problem of state estimation over multi-terminal channels in an unreliable regime.","More specifically, we consider two canonical settings.","In the first setting, measurements of a common stochastic source need to be transmitted to two distinct remote monitors over a packet-erasure broadcast channel.","In the second setting, measurements of two distinct stochastic sources need to be transmitted to a common remote monitor over a packet-erasure multi-access channel.","For these networked systems, we uncover the fundamental performance limits in the sense of a causal tradeoff between the estimation error and the communication cost by identifying optimal encoding and decoding strategies.","In the course of our analysis, we introduce two novel semantic metrics that play essential roles in state estimation over broadcast and multi-access channels.","The first metric arising in the context of broadcast channels is the dissemination value of information, which quantifies the valuation of provisioning a piece of information to multiple receivers simultaneously.","The second metric arising in the context of multi-access channels is the prioritization value of information, which quantifies the valuation of provisioning a piece of information chosen from one out of multiple transmitters.","Our findings certify that the optimal encoding and decoding strategies hinge on these semantic metrics."],"url":"http://arxiv.org/abs/2308.16085v1"}
{"created":"2023-08-30 15:16:56","title":"P2M: A Fast Solver for Querying Distance from Point to Mesh Surface","abstract":"Most of the existing point-to-mesh distance query solvers, such as Proximity Query Package (PQP), Embree and Fast Closest Point Query (FCPW), are based on bounding volume hierarchy (BVH). The hierarchical organizational structure enables one to eliminate the vast majority of triangles that do not help find the closest point. In this paper, we develop a totally different algorithmic paradigm, named P2M, to speed up point-to-mesh distance queries. Our original intention is to precompute a KD tree (KDT) of mesh vertices to approximately encode the geometry of a mesh surface containing vertices, edges and faces. However, it is very likely that the closest primitive to the query point is an edge e (resp., a face f), but the KDT reports a mesh vertex \\u{psion} instead. We call \\u{psion} an interceptor of e (resp., f). The main contribution of this paper is to invent a simple yet effective interception inspection rule and an efficient flooding interception inspection algorithm for quickly finding out all the interception pairs. Once the KDT and the interception table are precomputed, the query stage proceeds by first searching the KDT and then looking up the interception table to retrieve the closest geometric primitive. Statistics show that our query algorithm runs many times faster than the state-of-the-art solvers.","sentences":["Most of the existing point-to-mesh distance query solvers, such as Proximity Query Package (PQP), Embree and Fast Closest Point Query (FCPW), are based on bounding volume hierarchy (BVH).","The hierarchical organizational structure enables one to eliminate the vast majority of triangles that do not help find the closest point.","In this paper, we develop a totally different algorithmic paradigm, named P2M, to speed up point-to-mesh distance queries.","Our original intention is to precompute a KD tree (KDT) of mesh vertices to approximately encode the geometry of a mesh surface containing vertices, edges and faces.","However, it is very likely that the closest primitive to the query point is an edge e (resp., a face f), but the KDT reports a mesh vertex \\u{psion} instead.","We call \\u{psion} an interceptor of e (resp., f).","The main contribution of this paper is to invent a simple yet effective interception inspection rule and an efficient flooding interception inspection algorithm for quickly finding out all the interception pairs.","Once the KDT and the interception table are precomputed, the query stage proceeds by first searching the KDT and then looking up the interception table to retrieve the closest geometric primitive.","Statistics show that our query algorithm runs many times faster than the state-of-the-art solvers."],"url":"http://arxiv.org/abs/2308.16084v1"}
{"created":"2023-08-30 15:15:31","title":"Learned Image Reasoning Prior Penetrates Deep Unfolding Network for Panchromatic and Multi-Spectral Image Fusion","abstract":"The success of deep neural networks for pan-sharpening is commonly in a form of black box, lacking transparency and interpretability. To alleviate this issue, we propose a novel model-driven deep unfolding framework with image reasoning prior tailored for the pan-sharpening task. Different from existing unfolding solutions that deliver the proximal operator networks as the uncertain and vague priors, our framework is motivated by the content reasoning ability of masked autoencoders (MAE) with insightful designs. Specifically, the pre-trained MAE with spatial masking strategy, acting as intrinsic reasoning prior, is embedded into unfolding architecture. Meanwhile, the pre-trained MAE with spatial-spectral masking strategy is treated as the regularization term within loss function to constrain the spatial-spectral consistency. Such designs penetrate the image reasoning prior into deep unfolding networks while improving its interpretability and representation capability. The uniqueness of our framework is that the holistic learning process is explicitly integrated with the inherent physical mechanism underlying the pan-sharpening task. Extensive experiments on multiple satellite datasets demonstrate the superiority of our method over the existing state-of-the-art approaches. Code will be released at \\url{https://manman1995.github.io/}.","sentences":["The success of deep neural networks for pan-sharpening is commonly in a form of black box, lacking transparency and interpretability.","To alleviate this issue, we propose a novel model-driven deep unfolding framework with image reasoning prior tailored for the pan-sharpening task.","Different from existing unfolding solutions that deliver the proximal operator networks as the uncertain and vague priors, our framework is motivated by the content reasoning ability of masked autoencoders (MAE) with insightful designs.","Specifically, the pre-trained MAE with spatial masking strategy, acting as intrinsic reasoning prior, is embedded into unfolding architecture.","Meanwhile, the pre-trained MAE with spatial-spectral masking strategy is treated as the regularization term within loss function to constrain the spatial-spectral consistency.","Such designs penetrate the image reasoning prior into deep unfolding networks while improving its interpretability and representation capability.","The uniqueness of our framework is that the holistic learning process is explicitly integrated with the inherent physical mechanism underlying the pan-sharpening task.","Extensive experiments on multiple satellite datasets demonstrate the superiority of our method over the existing state-of-the-art approaches.","Code will be released at \\url{https://manman1995.github.io/}."],"url":"http://arxiv.org/abs/2308.16083v1"}
{"created":"2023-08-30 15:14:56","title":"SignDiff: Learning Diffusion Models for American Sign Language Production","abstract":"The field of Sign Language Production (SLP) lacked a large-scale, pre-trained model based on deep learning for continuous American Sign Language (ASL) production in the past decade. This limitation hampers communication for all individuals with disabilities relying on ASL. To address this issue, we undertook the secondary development and utilization of How2Sign, one of the largest publicly available ASL datasets. Despite its significance, prior researchers in the field of sign language have not effectively employed this corpus due to the intricacies involved in American Sign Language Production (ASLP).   To conduct large-scale ASLP, we propose SignDiff based on the latest work in related fields, which is a dual-condition diffusion pre-training model that can generate human sign language speakers from a skeleton pose. SignDiff has a novel Frame Reinforcement Network called FR-Net, similar to dense human pose estimation work, which enhances the correspondence between text lexical symbols and sign language dense pose frames reduce the occurrence of multiple fingers in the diffusion model. In addition, our ASLP method proposes two new improved modules and a new loss function to improve the accuracy and quality of sign language skeletal posture and enhance the ability of the model to train on large-scale data.   We propose the first baseline for ASL production and report the scores of 17.19 and 12.85 on BLEU-4 on the How2Sign dev/test sets. We also evaluated our model on the previous mainstream dataset called PHOENIX14T, and the main experiments achieved the results of SOTA. In addition, our image quality far exceeds all previous results by 10 percentage points on the SSIM indicator. Finally, we conducted ablation studies and qualitative evaluations for discussion.","sentences":["The field of Sign Language Production (SLP) lacked a large-scale, pre-trained model based on deep learning for continuous American Sign Language (ASL) production in the past decade.","This limitation hampers communication for all individuals with disabilities relying on ASL.","To address this issue, we undertook the secondary development and utilization of How2Sign, one of the largest publicly available ASL datasets.","Despite its significance, prior researchers in the field of sign language have not effectively employed this corpus due to the intricacies involved in American Sign Language Production (ASLP).   ","To conduct large-scale ASLP, we propose SignDiff based on the latest work in related fields, which is a dual-condition diffusion pre-training model that can generate human sign language speakers from a skeleton pose.","SignDiff has a novel Frame Reinforcement Network called FR-Net, similar to dense human pose estimation work, which enhances the correspondence between text lexical symbols and sign language dense pose frames reduce the occurrence of multiple fingers in the diffusion model.","In addition, our ASLP method proposes two new improved modules and a new loss function to improve the accuracy and quality of sign language skeletal posture and enhance the ability of the model to train on large-scale data.   ","We propose the first baseline for ASL production and report the scores of 17.19 and 12.85 on BLEU-4 on the How2Sign dev/test sets.","We also evaluated our model on the previous mainstream dataset called PHOENIX14T, and the main experiments achieved the results of SOTA.","In addition, our image quality far exceeds all previous results by 10 percentage points on the SSIM indicator.","Finally, we conducted ablation studies and qualitative evaluations for discussion."],"url":"http://arxiv.org/abs/2308.16082v1"}
{"created":"2023-08-30 14:52:14","title":"Impact of Visual Context on Noisy Multimodal NMT: An Empirical Study for English to Indian Languages","abstract":"The study investigates the effectiveness of utilizing multimodal information in Neural Machine Translation (NMT). While prior research focused on using multimodal data in low-resource scenarios, this study examines how image features impact translation when added to a large-scale, pre-trained unimodal NMT system. Surprisingly, the study finds that images might be redundant in this context. Additionally, the research introduces synthetic noise to assess whether images help the model deal with textual noise. Multimodal models slightly outperform text-only models in noisy settings, even with random images. The study's experiments translate from English to Hindi, Bengali, and Malayalam, outperforming state-of-the-art benchmarks significantly. Interestingly, the effect of visual context varies with source text noise: no visual context works best for non-noisy translations, cropped image features are optimal for low noise, and full image features work better in high-noise scenarios. This sheds light on the role of visual context, especially in noisy settings, opening up a new research direction for Noisy Neural Machine Translation in multimodal setups. The research emphasizes the importance of combining visual and textual information for improved translation in various environments.","sentences":["The study investigates the effectiveness of utilizing multimodal information in Neural Machine Translation (NMT).","While prior research focused on using multimodal data in low-resource scenarios, this study examines how image features impact translation when added to a large-scale, pre-trained unimodal NMT system.","Surprisingly, the study finds that images might be redundant in this context.","Additionally, the research introduces synthetic noise to assess whether images help the model deal with textual noise.","Multimodal models slightly outperform text-only models in noisy settings, even with random images.","The study's experiments translate from English to Hindi, Bengali, and Malayalam, outperforming state-of-the-art benchmarks significantly.","Interestingly, the effect of visual context varies with source text noise: no visual context works best for non-noisy translations, cropped image features are optimal for low noise, and full image features work better in high-noise scenarios.","This sheds light on the role of visual context, especially in noisy settings, opening up a new research direction for Noisy Neural Machine Translation in multimodal setups.","The research emphasizes the importance of combining visual and textual information for improved translation in various environments."],"url":"http://arxiv.org/abs/2308.16075v1"}
{"created":"2023-08-30 14:49:34","title":"Semantic Image Synthesis via Class-Adaptive Cross-Attention","abstract":"In semantic image synthesis, the state of the art is dominated by methods that use spatially-adaptive normalization layers, which allow for excellent visual generation quality and editing versatility. Granted their efficacy, recent research efforts have focused toward finer-grained local style control and multi-modal generation. By construction though, such layers tend to overlook global image statistics leading to unconvincing local style editing and causing global inconsistencies such as color or illumination distribution shifts. Also, the semantic layout is required for mapping styles in the generator, putting a strict alignment constraint over the features. In response, we designed a novel architecture where cross-attention layers are used in place of de-normalization ones for conditioning the image generation. Our model inherits the advantages of both solutions, retaining state-of-the-art reconstruction quality, as well as improved global and local style transfer. Code and models available at https://github.com/TFonta/CA2SIS.","sentences":["In semantic image synthesis, the state of the art is dominated by methods that use spatially-adaptive normalization layers, which allow for excellent visual generation quality and editing versatility.","Granted their efficacy, recent research efforts have focused toward finer-grained local style control and multi-modal generation.","By construction though, such layers tend to overlook global image statistics leading to unconvincing local style editing and causing global inconsistencies such as color or illumination distribution shifts.","Also, the semantic layout is required for mapping styles in the generator, putting a strict alignment constraint over the features.","In response, we designed a novel architecture where cross-attention layers are used in place of de-normalization ones for conditioning the image generation.","Our model inherits the advantages of both solutions, retaining state-of-the-art reconstruction quality, as well as improved global and local style transfer.","Code and models available at https://github.com/TFonta/CA2SIS."],"url":"http://arxiv.org/abs/2308.16071v1"}
{"created":"2023-08-30 14:44:04","title":"Consensus of state of the art mortality prediction models: From all-cause mortality to sudden death prediction","abstract":"Worldwide, many millions of people die suddenly and unexpectedly each year, either with or without a prior history of cardiovascular disease. Such events are sparse (once in a lifetime), many victims will not have had prior investigations for cardiac disease and many different definitions of sudden death exist. Accordingly, sudden death is hard to predict.   This analysis used NHS Electronic Health Records (EHRs) for people aged $\\geq$50 years living in the Greater Glasgow and Clyde (GG\\&C) region in 2010 (n = 380,000) to try to overcome these challenges. We investigated whether medical history, blood tests, prescription of medicines, and hospitalisations might, in combination, predict a heightened risk of sudden death.   We compared the performance of models trained to predict either sudden death or all-cause mortality. We built six models for each outcome of interest: three taken from state-of-the-art research (BEHRT, Deepr and Deep Patient), and three of our own creation. We trained these using two different data representations: a language-based representation, and a sparse temporal matrix.   We used global interpretability to understand the most important features of each model, and compare how much agreement there was amongst models using Rank Biased Overlap. It is challenging to account for correlated variables without increasing the complexity of the interpretability technique. We overcame this by clustering features into groups and comparing the most important groups for each model. We found the agreement between models to be much higher when accounting for correlated variables.   Our analysis emphasises the challenge of predicting sudden death and emphasises the need for better understanding and interpretation of machine learning models applied to healthcare applications.","sentences":["Worldwide, many millions of people die suddenly and unexpectedly each year, either with or without a prior history of cardiovascular disease.","Such events are sparse (once in a lifetime), many victims will not have had prior investigations for cardiac disease and many different definitions of sudden death exist.","Accordingly, sudden death is hard to predict.   ","This analysis used NHS Electronic Health Records (EHRs) for people aged $\\geq$50 years living in the Greater Glasgow and Clyde (GG\\&C) region in 2010 (n = 380,000) to try to overcome these challenges.","We investigated whether medical history, blood tests, prescription of medicines, and hospitalisations might, in combination, predict a heightened risk of sudden death.   ","We compared the performance of models trained to predict either sudden death or all-cause mortality.","We built six models for each outcome of interest: three taken from state-of-the-art research (BEHRT, Deepr and Deep Patient), and three of our own creation.","We trained these using two different data representations: a language-based representation, and a sparse temporal matrix.   ","We used global interpretability to understand the most important features of each model, and compare how much agreement there was amongst models using Rank Biased Overlap.","It is challenging to account for correlated variables without increasing the complexity of the interpretability technique.","We overcame this by clustering features into groups and comparing the most important groups for each model.","We found the agreement between models to be much higher when accounting for correlated variables.   ","Our analysis emphasises the challenge of predicting sudden death and emphasises the need for better understanding and interpretation of machine learning models applied to healthcare applications."],"url":"http://arxiv.org/abs/2308.16067v1"}
{"created":"2023-08-30 14:36:25","title":"Conti Inc.: Understanding the Internal Discussions of a large Ransomware-as-a-Service Operator with Machine Learning","abstract":"Ransomware-as-a-service (RaaS) is increasing the scale and complexity of ransomware attacks. Understanding the internal operations behind RaaS has been a challenge due to the illegality of such activities. The recent chat leak of the Conti RaaS operator, one of the most infamous ransomware operators on the international scene, offers a key opportunity to better understand the inner workings of such organizations. This paper analyzes the main topic discussions in the Conti chat leak using machine learning techniques such as Natural Language Processing (NLP) and Latent Dirichlet Allocation (LDA), as well as visualization strategies. Five discussion topics are found: 1) Business, 2) Technical, 3) Internal tasking/Management, 4) Malware, and 5) Customer Service/Problem Solving. Moreover, the distribution of topics among Conti members shows that only 4% of individuals have specialized discussions while almost all individuals (96%) are all-rounders, meaning that their discussions revolve around the five topics. The results also indicate that a significant proportion of Conti discussions are non-tech related. This study thus highlights that running such large RaaS operations requires a workforce skilled beyond technical abilities, with individuals involved in various tasks, from management to customer service or problem solving. The discussion topics also show that the organization behind the Conti RaaS oper5086933ator shares similarities with a large firm. We conclude that, although RaaS represents an example of specialization in the cybercrime industry, only a few members are specialized in one topic, while the rest runs and coordinates the RaaS operation.","sentences":["Ransomware-as-a-service (RaaS) is increasing the scale and complexity of ransomware attacks.","Understanding the internal operations behind RaaS has been a challenge due to the illegality of such activities.","The recent chat leak of the Conti RaaS operator, one of the most infamous ransomware operators on the international scene, offers a key opportunity to better understand the inner workings of such organizations.","This paper analyzes the main topic discussions in the Conti chat leak using machine learning techniques such as Natural Language Processing (NLP) and Latent Dirichlet Allocation (LDA), as well as visualization strategies.","Five discussion topics are found: 1) Business, 2) Technical, 3) Internal tasking/Management, 4) Malware, and 5) Customer Service/Problem Solving.","Moreover, the distribution of topics among Conti members shows that only 4% of individuals have specialized discussions while almost all individuals (96%) are all-rounders, meaning that their discussions revolve around the five topics.","The results also indicate that a significant proportion of Conti discussions are non-tech related.","This study thus highlights that running such large RaaS operations requires a workforce skilled beyond technical abilities, with individuals involved in various tasks, from management to customer service or problem solving.","The discussion topics also show that the organization behind the Conti RaaS oper5086933ator shares similarities with a large firm.","We conclude that, although RaaS represents an example of specialization in the cybercrime industry, only a few members are specialized in one topic, while the rest runs and coordinates the RaaS operation."],"url":"http://arxiv.org/abs/2308.16061v1"}
{"created":"2023-08-30 14:33:25","title":"Text-to-OverpassQL: A Natural Language Interface for Complex Geodata Querying of OpenStreetMap","abstract":"We present Text-to-OverpassQL, a task designed to facilitate a natural language interface for querying geodata from OpenStreetMap (OSM). The Overpass Query Language (OverpassQL) allows users to formulate complex database queries and is widely adopted in the OSM ecosystem. Generating Overpass queries from natural language input serves multiple use-cases. It enables novice users to utilize OverpassQL without prior knowledge, assists experienced users with crafting advanced queries, and enables tool-augmented large language models to access information stored in the OSM database. In order to assess the performance of current sequence generation models on this task, we propose OverpassNL, a dataset of 8,352 queries with corresponding natural language inputs. We further introduce task specific evaluation metrics and ground the evaluation of the Text-to-OverpassQL task by executing the queries against the OSM database. We establish strong baselines by finetuning sequence-to-sequence models and adapting large language models with in-context examples. The detailed evaluation reveals strengths and weaknesses of the considered learning strategies, laying the foundations for further research into the Text-to-OverpassQL task.","sentences":["We present Text-to-OverpassQL, a task designed to facilitate a natural language interface for querying geodata from OpenStreetMap (OSM).","The Overpass Query Language (OverpassQL) allows users to formulate complex database queries and is widely adopted in the OSM ecosystem.","Generating Overpass queries from natural language input serves multiple use-cases.","It enables novice users to utilize OverpassQL without prior knowledge, assists experienced users with crafting advanced queries, and enables tool-augmented large language models to access information stored in the OSM database.","In order to assess the performance of current sequence generation models on this task, we propose OverpassNL, a dataset of 8,352 queries with corresponding natural language inputs.","We further introduce task specific evaluation metrics and ground the evaluation of the Text-to-OverpassQL task by executing the queries against the OSM database.","We establish strong baselines by finetuning sequence-to-sequence models and adapting large language models with in-context examples.","The detailed evaluation reveals strengths and weaknesses of the considered learning strategies, laying the foundations for further research into the Text-to-OverpassQL task."],"url":"http://arxiv.org/abs/2308.16060v1"}
{"created":"2023-08-30 14:28:26","title":"Low-Rank Multitask Learning based on Tensorized SVMs and LSSVMs","abstract":"Multitask learning (MTL) leverages task-relatedness to enhance performance. With the emergence of multimodal data, tasks can now be referenced by multiple indices. In this paper, we employ high-order tensors, with each mode corresponding to a task index, to naturally represent tasks referenced by multiple indices and preserve their structural relations. Based on this representation, we propose a general framework of low-rank MTL methods with tensorized support vector machines (SVMs) and least square support vector machines (LSSVMs), where the CP factorization is deployed over the coefficient tensor. Our approach allows to model the task relation through a linear combination of shared factors weighted by task-specific factors and is generalized to both classification and regression problems. Through the alternating optimization scheme and the Lagrangian function, each subproblem is transformed into a convex problem, formulated as a quadratic programming or linear system in the dual form. In contrast to previous MTL frameworks, our decision function in the dual induces a weighted kernel function with a task-coupling term characterized by the similarities of the task-specific factors, better revealing the explicit relations across tasks in MTL. Experimental results validate the effectiveness and superiority of our proposed methods compared to existing state-of-the-art approaches in MTL. The code of implementation will be available at https://github.com/liujiani0216/TSVM-MTL.","sentences":["Multitask learning (MTL) leverages task-relatedness to enhance performance.","With the emergence of multimodal data, tasks can now be referenced by multiple indices.","In this paper, we employ high-order tensors, with each mode corresponding to a task index, to naturally represent tasks referenced by multiple indices and preserve their structural relations.","Based on this representation, we propose a general framework of low-rank MTL methods with tensorized support vector machines (SVMs) and least square support vector machines (LSSVMs), where the CP factorization is deployed over the coefficient tensor.","Our approach allows to model the task relation through a linear combination of shared factors weighted by task-specific factors and is generalized to both classification and regression problems.","Through the alternating optimization scheme and the Lagrangian function, each subproblem is transformed into a convex problem, formulated as a quadratic programming or linear system in the dual form.","In contrast to previous MTL frameworks, our decision function in the dual induces a weighted kernel function with a task-coupling term characterized by the similarities of the task-specific factors, better revealing the explicit relations across tasks in MTL.","Experimental results validate the effectiveness and superiority of our proposed methods compared to existing state-of-the-art approaches in MTL.","The code of implementation will be available at https://github.com/liujiani0216/TSVM-MTL."],"url":"http://arxiv.org/abs/2308.16056v1"}
{"created":"2023-08-30 14:24:16","title":"AsyncET: Asynchronous Learning for Knowledge Graph Entity Typing with Auxiliary Relations","abstract":"Knowledge graph entity typing (KGET) is a task to predict the missing entity types in knowledge graphs (KG). Previously, KG embedding (KGE) methods tried to solve the KGET task by introducing an auxiliary relation, 'hasType', to model the relationship between entities and their types. However, a single auxiliary relation has limited expressiveness for diverse entity-type patterns. We improve the expressiveness of KGE methods by introducing multiple auxiliary relations in this work. Similar entity types are grouped to reduce the number of auxiliary relations and improve their capability to model entity-type patterns with different granularities. With the presence of multiple auxiliary relations, we propose a method adopting an Asynchronous learning scheme for Entity Typing, named AsyncET, which updates the entity and type embeddings alternatively to keep the learned entity embedding up-to-date and informative for entity type prediction. Experiments are conducted on two commonly used KGET datasets to show that the performance of KGE methods on the KGET task can be substantially improved by the proposed multiple auxiliary relations and asynchronous embedding learning. Furthermore, our method has a significant advantage over state-of-the-art methods in model sizes and time complexity.","sentences":["Knowledge graph entity typing (KGET) is a task to predict the missing entity types in knowledge graphs (KG).","Previously, KG embedding (KGE) methods tried to solve the KGET task by introducing an auxiliary relation, 'hasType', to model the relationship between entities and their types.","However, a single auxiliary relation has limited expressiveness for diverse entity-type patterns.","We improve the expressiveness of KGE methods by introducing multiple auxiliary relations in this work.","Similar entity types are grouped to reduce the number of auxiliary relations and improve their capability to model entity-type patterns with different granularities.","With the presence of multiple auxiliary relations, we propose a method adopting an Asynchronous learning scheme for Entity Typing, named AsyncET, which updates the entity and type embeddings alternatively to keep the learned entity embedding up-to-date and informative for entity type prediction.","Experiments are conducted on two commonly used KGET datasets to show that the performance of KGE methods on the KGET task can be substantially improved by the proposed multiple auxiliary relations and asynchronous embedding learning.","Furthermore, our method has a significant advantage over state-of-the-art methods in model sizes and time complexity."],"url":"http://arxiv.org/abs/2308.16055v1"}
{"created":"2023-08-30 14:19:31","title":"OldVisOnline: Curating a Dataset of Historical Visualizations","abstract":"With the increasing adoption of digitization, more and more historical visualizations created hundreds of years ago are accessible in digital libraries online. It provides a unique opportunity for visualization and history research. Meanwhile, there is no large-scale digital collection dedicated to historical visualizations. The visualizations are scattered in various collections, which hinders retrieval. In this study, we curate the first large-scale dataset dedicated to historical visualizations. Our dataset comprises 13K historical visualization images with corresponding processed metadata from seven digital libraries. In curating the dataset, we propose a workflow to scrape and process heterogeneous metadata. We develop a semi-automatic labeling approach to distinguish visualizations from other artifacts. Our dataset can be accessed with OldVisOnline, a system we have built to browse and label historical visualizations. We discuss our vision of usage scenarios and research opportunities with our dataset, such as textual criticism for historical visualizations. Drawing upon our experience, we summarize recommendations for future efforts to improve our dataset.","sentences":["With the increasing adoption of digitization, more and more historical visualizations created hundreds of years ago are accessible in digital libraries online.","It provides a unique opportunity for visualization and history research.","Meanwhile, there is no large-scale digital collection dedicated to historical visualizations.","The visualizations are scattered in various collections, which hinders retrieval.","In this study, we curate the first large-scale dataset dedicated to historical visualizations.","Our dataset comprises 13K historical visualization images with corresponding processed metadata from seven digital libraries.","In curating the dataset, we propose a workflow to scrape and process heterogeneous metadata.","We develop a semi-automatic labeling approach to distinguish visualizations from other artifacts.","Our dataset can be accessed with OldVisOnline, a system we have built to browse and label historical visualizations.","We discuss our vision of usage scenarios and research opportunities with our dataset, such as textual criticism for historical visualizations.","Drawing upon our experience, we summarize recommendations for future efforts to improve our dataset."],"url":"http://arxiv.org/abs/2308.16053v1"}
{"created":"2023-08-30 14:19:09","title":"Telepresence Lantern -- Designing an Immersive Video-Mediated Communication Device for Older Adults","abstract":"We present the Telepresence Lantern concept, developed to provide opportunities for older adults to stay in contact with remote family and friends. It provides a new approach to video-mediated communication, designed to facilitate natural and ambient interactions with simplified call setup. Video communication is an established way to enhance social connectedness, but traditional approaches create a high friction to frequent connection due to, for example, technological barriers. Through interactive sessions with older adult users, we created design and function prototypes to suit their needs and preferences. The main features of our design are a curved, wide field-of-view screen and corresponding camera and sound setup, and the affordance to easily move the device from room-to-room. An interactive user session with a fully functional prototype validated the potential of this concept for improving communication among older adults and their families.","sentences":["We present the Telepresence Lantern concept, developed to provide opportunities for older adults to stay in contact with remote family and friends.","It provides a new approach to video-mediated communication, designed to facilitate natural and ambient interactions with simplified call setup.","Video communication is an established way to enhance social connectedness, but traditional approaches create a high friction to frequent connection due to, for example, technological barriers.","Through interactive sessions with older adult users, we created design and function prototypes to suit their needs and preferences.","The main features of our design are a curved, wide field-of-view screen and corresponding camera and sound setup, and the affordance to easily move the device from room-to-room.","An interactive user session with a fully functional prototype validated the potential of this concept for improving communication among older adults and their families."],"url":"http://arxiv.org/abs/2308.16052v1"}
{"created":"2023-08-30 14:02:42","title":"Optimal Non-Adaptive Cell Probe Dictionaries and Hashing","abstract":"We present a simple and provably optimal non-adaptive cell probe data structure for the static dictionary problem. Our data structure supports storing a set of $n$ key-value pairs from $[u]\\times [u]$ using $s$ words of space and answering key lookup queries in $t = O(\\lg(u/n)/\\lg(s/n))$ non-adaptive probes. This generalizes a solution to the membership problem (i.e., where no values are associated with keys) due to Buhrman et al. and matches a recent lower bound by Persiano and Yeo.   Using the ideas underlying our data structure, we also obtain the first implementation of a $n$-wise independent family of hash functions with optimal evaluation time in the cell probe model.","sentences":["We present a simple and provably optimal non-adaptive cell probe data structure for the static dictionary problem.","Our data structure supports storing a set of $n$ key-value pairs from $[u]\\times","[u]$ using $s$ words of space and answering key lookup queries in $t = O(\\lg(u/n)/\\lg(s/n))$ non-adaptive probes.","This generalizes a solution to the membership problem (i.e., where no values are associated with keys) due to Buhrman et al. and matches a recent lower bound by Persiano and Yeo.   Using the ideas underlying our data structure, we also obtain the first implementation of a $n$-wise independent family of hash functions with optimal evaluation time in the cell probe model."],"url":"http://arxiv.org/abs/2308.16042v1"}
{"created":"2023-08-30 14:00:48","title":"From Pixels to Portraits: A Comprehensive Survey of Talking Head Generation Techniques and Applications","abstract":"Recent advancements in deep learning and computer vision have led to a surge of interest in generating realistic talking heads. This paper presents a comprehensive survey of state-of-the-art methods for talking head generation. We systematically categorises them into four main approaches: image-driven, audio-driven, video-driven and others (including neural radiance fields (NeRF), and 3D-based methods). We provide an in-depth analysis of each method, highlighting their unique contributions, strengths, and limitations. Furthermore, we thoroughly compare publicly available models, evaluating them on key aspects such as inference time and human-rated quality of the generated outputs. Our aim is to provide a clear and concise overview of the current landscape in talking head generation, elucidating the relationships between different approaches and identifying promising directions for future research. This survey will serve as a valuable reference for researchers and practitioners interested in this rapidly evolving field.","sentences":["Recent advancements in deep learning and computer vision have led to a surge of interest in generating realistic talking heads.","This paper presents a comprehensive survey of state-of-the-art methods for talking head generation.","We systematically categorises them into four main approaches: image-driven, audio-driven, video-driven and others (including neural radiance fields (NeRF), and 3D-based methods).","We provide an in-depth analysis of each method, highlighting their unique contributions, strengths, and limitations.","Furthermore, we thoroughly compare publicly available models, evaluating them on key aspects such as inference time and human-rated quality of the generated outputs.","Our aim is to provide a clear and concise overview of the current landscape in talking head generation, elucidating the relationships between different approaches and identifying promising directions for future research.","This survey will serve as a valuable reference for researchers and practitioners interested in this rapidly evolving field."],"url":"http://arxiv.org/abs/2308.16041v1"}
{"created":"2023-08-30 13:52:34","title":"On the difficulty to beat the first linear programming bound for binary codes","abstract":"The first linear programming bound of McEliece, Rodemich, Rumsey, and Welch is the best known asymptotic upper bound for binary codes, for a certain subrange of distances. Starting from the work of Friedman and Tillich, there are, by now, some arguably easier and more direct arguments for this bound. We show that this more recent line of argument runs into certain difficulties if one tries to go beyond this bound (say, towards the second linear programming bound of McEliece, Rodemich, Rumsey, and Welch).","sentences":["The first linear programming bound of McEliece, Rodemich, Rumsey, and Welch is the best known asymptotic upper bound for binary codes, for a certain subrange of distances.","Starting from the work of Friedman and Tillich, there are, by now, some arguably easier and more direct arguments for this bound.","We show that this more recent line of argument runs into certain difficulties if one tries to go beyond this bound (say, towards the second linear programming bound of McEliece, Rodemich, Rumsey, and Welch)."],"url":"http://arxiv.org/abs/2308.16038v1"}
{"created":"2023-08-30 13:47:25","title":"Independent set in $k$-Claw-Free Graphs: Conditional $\u03c7$-boundedness and the Power of LP/SDP Relaxations","abstract":"This paper studies $k$-claw-free graphs, exploring the connection between an extremal combinatorics question and the power of a convex program in approximating the maximum-weight independent set in this graph class. For the extremal question, we consider the notion, that we call \\textit{conditional $\\chi$-boundedness} of a graph: Given a graph $G$ that is assumed to contain an independent set of a certain (constant) size, we are interested in upper bounding the chromatic number in terms of the clique number of $G$. This question, besides being interesting on its own, has algorithmic implications (which have been relatively neglected in the literature) on the performance of SDP relaxations in estimating the value of maximum-weight independent set.   For $k=3$, Chudnovsky and Seymour (JCTB 2010) prove that any $3$-claw-free graph $G$ with an independent set of size three must satisfy $\\chi(G) \\leq 2 \\omega(G)$. Their result implies a factor $2$-estimation algorithm for the maximum weight independent set via an SDP relaxation (providing the first non-trivial result for maximum-weight independent set in such graphs via a convex relaxation). An obvious open question is whether a similar conditional $\\chi$-boundedness phenomenon holds for any $k$-claw-free graph. Our main result answers this question negatively. We further present some evidence that our construction could be useful in studying more broadly the power of convex relaxations in the context of approximating maximum weight independent set in $k$-claw free graphs. In particular, we prove a lower bound on families of convex programs that are stronger than known convex relaxations used algorithmically in this context.","sentences":["This paper studies $k$-claw-free graphs, exploring the connection between an extremal combinatorics question and the power of a convex program in approximating the maximum-weight independent set in this graph class.","For the extremal question, we consider the notion, that we call \\textit{conditional $\\chi$-boundedness} of a graph: Given a graph $G$ that is assumed to contain an independent set of a certain (constant) size, we are interested in upper bounding the chromatic number in terms of the clique number of $G$. This question, besides being interesting on its own, has algorithmic implications (which have been relatively neglected in the literature) on the performance of SDP relaxations in estimating the value of maximum-weight independent set.   ","For $k=3$, Chudnovsky and Seymour (JCTB 2010) prove that any $3$-claw-free graph $G$ with an independent set of size three must satisfy $\\chi(G) \\leq 2 \\omega(G)$. Their result implies a factor $2$-estimation algorithm for the maximum weight independent set via an SDP relaxation (providing the first non-trivial result for maximum-weight independent set in such graphs via a convex relaxation).","An obvious open question is whether a similar conditional $\\chi$-boundedness phenomenon holds for any $k$-claw-free graph.","Our main result answers this question negatively.","We further present some evidence that our construction could be useful in studying more broadly the power of convex relaxations in the context of approximating maximum weight independent set in $k$-claw free graphs.","In particular, we prove a lower bound on families of convex programs that are stronger than known convex relaxations used algorithmically in this context."],"url":"http://arxiv.org/abs/2308.16033v1"}
{"created":"2023-08-30 13:42:04","title":"Breaking the Interference and Fading Gridlock in Backscatter Communications: State-of-the-Art, Design Challenges, and Future Directions","abstract":"With the rapid advancement of the Internet of Things (IoT) and mobile communication technologies, a multitude of devices are becoming interconnected, marking the onset of an era where all things are connected. While this growth opens opportunities for novel products and applications, it also leads to increased energy demand and battery reliance in IoT devices, creating a significant bottleneck that hinders sustainable progress. Traditional energy harvesting (EH) techniques, although promising, face limitations such as insufficient efficiency, high costs, and practical constraints that impede widespread adoption. Backscatter communication (BackCom), a low-power and passive method, emerges as a promising solution to these challenges, directly addressing stranded energy impasse by reducing manufacturing costs and energy consumption in IoT devices. We perform an in-depth analysis of three primary BackCom architectures: Monostatic, Bistatic, and Ambient BackComs. In our exploration, we identify fundamental challenges, such as complex interference environments (including the direct-link interference and the mutual interference among tags) and double-path fading, which contribute to suboptimal performance in BackCom systems. This review aims to furnish a comprehensive examination of existing solutions designed to combat complex interference environments and double-path fading, offering insightful analysis and comparison to select effective strategies to address these challenges. We also delve into emerging trends and challenges in BackCom, forecasting potential paths for technological advancement and providing insights into navigating the intricate landscape of future communication needs. Our work provides researchers and engineers with a clear and comprehensive perspective, enabling them to better understand and creatively tackle the ongoing challenges in BackCom systems.","sentences":["With the rapid advancement of the Internet of Things (IoT) and mobile communication technologies, a multitude of devices are becoming interconnected, marking the onset of an era where all things are connected.","While this growth opens opportunities for novel products and applications, it also leads to increased energy demand and battery reliance in IoT devices, creating a significant bottleneck that hinders sustainable progress.","Traditional energy harvesting (EH) techniques, although promising, face limitations such as insufficient efficiency, high costs, and practical constraints that impede widespread adoption.","Backscatter communication (BackCom), a low-power and passive method, emerges as a promising solution to these challenges, directly addressing stranded energy impasse by reducing manufacturing costs and energy consumption in IoT devices.","We perform an in-depth analysis of three primary BackCom architectures: Monostatic, Bistatic, and Ambient BackComs.","In our exploration, we identify fundamental challenges, such as complex interference environments (including the direct-link interference and the mutual interference among tags) and double-path fading, which contribute to suboptimal performance in BackCom systems.","This review aims to furnish a comprehensive examination of existing solutions designed to combat complex interference environments and double-path fading, offering insightful analysis and comparison to select effective strategies to address these challenges.","We also delve into emerging trends and challenges in BackCom, forecasting potential paths for technological advancement and providing insights into navigating the intricate landscape of future communication needs.","Our work provides researchers and engineers with a clear and comprehensive perspective, enabling them to better understand and creatively tackle the ongoing challenges in BackCom systems."],"url":"http://arxiv.org/abs/2308.16031v1"}
{"created":"2023-08-30 13:37:30","title":"Knowing Your Annotator: Rapidly Testing the Reliability of Affect Annotation","abstract":"The laborious and costly nature of affect annotation is a key detrimental factor for obtaining large scale corpora with valid and reliable affect labels. Motivated by the lack of tools that can effectively determine an annotator's reliability, this paper proposes general quality assurance (QA) tests for real-time continuous annotation tasks. Assuming that the annotation tasks rely on stimuli with audiovisual components, such as videos, we propose and evaluate two QA tests: a visual and an auditory QA test. We validate the QA tool across 20 annotators that are asked to go through the test followed by a lengthy task of annotating the engagement of gameplay videos. Our findings suggest that the proposed QA tool reveals, unsurprisingly, that trained annotators are more reliable than the best of untrained crowdworkers we could employ. Importantly, the QA tool introduced can predict effectively the reliability of an affect annotator with 80% accuracy, thereby, saving on resources, effort and cost, and maximizing the reliability of labels solicited in affective corpora. The introduced QA tool is available and accessible through the PAGAN annotation platform.","sentences":["The laborious and costly nature of affect annotation is a key detrimental factor for obtaining large scale corpora with valid and reliable affect labels.","Motivated by the lack of tools that can effectively determine an annotator's reliability, this paper proposes general quality assurance (QA) tests for real-time continuous annotation tasks.","Assuming that the annotation tasks rely on stimuli with audiovisual components, such as videos, we propose and evaluate two QA tests: a visual and an auditory QA test.","We validate the QA tool across 20 annotators that are asked to go through the test followed by a lengthy task of annotating the engagement of gameplay videos.","Our findings suggest that the proposed QA tool reveals, unsurprisingly, that trained annotators are more reliable than the best of untrained crowdworkers we could employ.","Importantly, the QA tool introduced can predict effectively the reliability of an affect annotator with 80% accuracy, thereby, saving on resources, effort and cost, and maximizing the reliability of labels solicited in affective corpora.","The introduced QA tool is available and accessible through the PAGAN annotation platform."],"url":"http://arxiv.org/abs/2308.16029v1"}
{"created":"2023-08-30 13:30:57","title":"A Critical Analysis of the What3Words Geocoding Algorithm","abstract":"What3Words is a geocoding application that uses triples of words instead of alphanumeric coordinates to identify locations. What3Words has grown rapidly in popularity over the past few years and is used in logistical applications worldwide, including by emergency services. What3Words has also attracted criticism for being less reliable than claimed, in particular that the chance of confusing one address with another is high. This paper investigates these claims and shows that the What3Words algorithm for assigning addresses to grid boxes creates many pairs of confusable addresses, some of which are quite close together. The implications of this for the use of What3Words in critical or emergency situations is discussed.","sentences":["What3Words is a geocoding application that uses triples of words instead of alphanumeric coordinates to identify locations.","What3Words has grown rapidly in popularity over the past few years and is used in logistical applications worldwide, including by emergency services.","What3Words has also attracted criticism for being less reliable than claimed, in particular that the chance of confusing one address with another is high.","This paper investigates these claims and shows that the What3Words algorithm for assigning addresses to grid boxes creates many pairs of confusable addresses, some of which are quite close together.","The implications of this for the use of What3Words in critical or emergency situations is discussed."],"url":"http://arxiv.org/abs/2308.16025v1"}
{"created":"2023-08-30 13:27:25","title":"Functional Shell and Reusable Components for Easy GUIs","abstract":"Some object-oriented GUI toolkits tangle state management with rendering. Functional shells and observable toolkits like GUI Easy simplify and promote the creation of reusable views by analogy to functional programming. We have successfully used GUI Easy on small and large GUI projects. We report on our experience constructing and using GUI Easy and derive from that experience several architectural patterns and principles for building functional programs out of imperative systems.","sentences":["Some object-oriented GUI toolkits tangle state management with rendering.","Functional shells and observable toolkits like GUI Easy simplify and promote the creation of reusable views by analogy to functional programming.","We have successfully used GUI Easy on small and large GUI projects.","We report on our experience constructing and using GUI Easy and derive from that experience several architectural patterns and principles for building functional programs out of imperative systems."],"url":"http://arxiv.org/abs/2308.16024v1"}
{"created":"2023-08-30 13:21:51","title":"CALM: Contrastive Cross-modal Speaking Style Modeling for Expressive Text-to-Speech Synthesis","abstract":"To further improve the speaking styles of synthesized speeches, current text-to-speech (TTS) synthesis systems commonly employ reference speeches to stylize their outputs instead of just the input texts. These reference speeches are obtained by manual selection which is resource-consuming, or selected by semantic features. However, semantic features contain not only style-related information, but also style irrelevant information. The information irrelevant to speaking style in the text could interfere the reference audio selection and result in improper speaking styles. To improve the reference selection, we propose Contrastive Acoustic-Linguistic Module (CALM) to extract the Style-related Text Feature (STF) from the text. CALM optimizes the correlation between the speaking style embedding and the extracted STF with contrastive learning. Thus, a certain number of the most appropriate reference speeches for the input text are selected by retrieving the speeches with the top STF similarities. Then the style embeddings are weighted summarized according to their STF similarities and used to stylize the synthesized speech of TTS. Experiment results demonstrate the effectiveness of our proposed approach, with both objective evaluations and subjective evaluations on the speaking styles of the synthesized speeches outperform a baseline approach with semantic-feature-based reference selection.","sentences":["To further improve the speaking styles of synthesized speeches, current text-to-speech (TTS) synthesis systems commonly employ reference speeches to stylize their outputs instead of just the input texts.","These reference speeches are obtained by manual selection which is resource-consuming, or selected by semantic features.","However, semantic features contain not only style-related information, but also style irrelevant information.","The information irrelevant to speaking style in the text could interfere the reference audio selection and result in improper speaking styles.","To improve the reference selection, we propose Contrastive Acoustic-Linguistic Module (CALM) to extract the Style-related Text Feature (STF) from the text.","CALM optimizes the correlation between the speaking style embedding and the extracted STF with contrastive learning.","Thus, a certain number of the most appropriate reference speeches for the input text are selected by retrieving the speeches with the top STF similarities.","Then the style embeddings are weighted summarized according to their STF similarities and used to stylize the synthesized speech of TTS.","Experiment results demonstrate the effectiveness of our proposed approach, with both objective evaluations and subjective evaluations on the speaking styles of the synthesized speeches outperform a baseline approach with semantic-feature-based reference selection."],"url":"http://arxiv.org/abs/2308.16021v1"}
{"created":"2023-08-30 13:21:36","title":"Decomposing Triangulations into 4-Connected Components","abstract":"A connected graph is 4-connected if it contains at least five vertices and removing any three of them does not disconnect it. A frequent preprocessing step in graph drawing is to decompose a plane graph into its 4-connected components and to determine their nesting structure. A linear-time algorithm for this problem was already proposed by Kant. However, using common graph data structures, we found the subroutine dealing with triangulated graphs difficult to implement in such a way that it actually runs in linear time. As a drop-in replacement, we provide a different, easy-to-implement linear-time algorithm that decomposes a triangulated graph into its 4-connected components and computes the respective nesting structure. The algorithm is based on depth-first search.","sentences":["A connected graph is 4-connected if it contains at least five vertices and removing any three of them does not disconnect it.","A frequent preprocessing step in graph drawing is to decompose a plane graph into its 4-connected components and to determine their nesting structure.","A linear-time algorithm for this problem was already proposed by Kant.","However, using common graph data structures, we found the subroutine dealing with triangulated graphs difficult to implement in such a way that it actually runs in linear time.","As a drop-in replacement, we provide a different, easy-to-implement linear-time algorithm that decomposes a triangulated graph into its 4-connected components and computes the respective nesting structure.","The algorithm is based on depth-first search."],"url":"http://arxiv.org/abs/2308.16020v1"}
{"created":"2023-08-30 13:20:54","title":"Topology-aware MLP for Skeleton-based Action Recognition","abstract":"Graph convolution networks (GCNs) have achieved remarkable performance in skeleton-based action recognition. However, existing previous GCN-based methods have relied excessively on elaborate human body priors and constructed complex feature aggregation mechanisms, which limits the generalizability of networks. To solve these problems, we propose a novel Spatial Topology Gating Unit (STGU), which is an MLP-based variant without extra priors, to capture the co-occurrence topology features that encode the spatial dependency across all joints. In STGU, to model the sample-specific and completely independent point-wise topology attention, a new gate-based feature interaction mechanism is introduced to activate the features point-to-point by the attention map generated from the input. Based on the STGU, in this work, we propose the first topology-aware MLP-based model, Ta-MLP, for skeleton-based action recognition. In comparison with existing previous methods on three large-scale datasets, Ta-MLP achieves competitive performance. In addition, Ta-MLP reduces the parameters by up to 62.5% with favorable results. Compared with previous state-of-the-art (SOAT) approaches, Ta-MLP pushes the frontier of real-time action recognition. The code will be available at https://github.com/BUPTSJZhang/Ta-MLP.","sentences":["Graph convolution networks (GCNs) have achieved remarkable performance in skeleton-based action recognition.","However, existing previous GCN-based methods have relied excessively on elaborate human body priors and constructed complex feature aggregation mechanisms, which limits the generalizability of networks.","To solve these problems, we propose a novel Spatial Topology Gating Unit (STGU), which is an MLP-based variant without extra priors, to capture the co-occurrence topology features that encode the spatial dependency across all joints.","In STGU, to model the sample-specific and completely independent point-wise topology attention, a new gate-based feature interaction mechanism is introduced to activate the features point-to-point by the attention map generated from the input.","Based on the STGU, in this work, we propose the first topology-aware MLP-based model, Ta-MLP, for skeleton-based action recognition.","In comparison with existing previous methods on three large-scale datasets, Ta-MLP achieves competitive performance.","In addition, Ta-MLP reduces the parameters by up to 62.5% with favorable results.","Compared with previous state-of-the-art (SOAT) approaches, Ta-MLP pushes the frontier of real-time action recognition.","The code will be available at https://github.com/BUPTSJZhang/Ta-MLP."],"url":"http://arxiv.org/abs/2308.16018v1"}
{"created":"2023-08-30 13:20:46","title":"Hidden-Role Games: Equilibrium Concepts and Computation","abstract":"In this paper, we study the class of games known as hidden-role games in which players get privately assigned a team and are faced with the challenge of recognizing and cooperating with teammates. This model includes both popular recreational games such as the Mafia/Werewolf family and The Resistance (Avalon) and real-world security settings, where a distributed system wants to operate while some of its nodes are controlled by adversaries. There has been little to no formal mathematical grounding of such settings in the literature, and it is not even immediately clear what the right solution concept is. In particular, the suitable notion of equilibrium depends on communication available to the players (whether players can communicate, whether they can communicate in private, and whether they can observe who is communicating), and defining it turns out to be a nontrivial task with several surprising consequences. We show that in certain cases, including the above recreational games, near-optimal equilibria can be computed efficiently. In most other cases, we show that computing an optimal equilibrium is either NP-hard or coNP-hard. Lastly, we experimentally validate our approach by computing nearly-exact equilibria for complete Avalon instances up to 6 players whose size in terms of number of information sets is larger than $10^{56}$.","sentences":["In this paper, we study the class of games known as hidden-role games in which players get privately assigned a team and are faced with the challenge of recognizing and cooperating with teammates.","This model includes both popular recreational games such as the Mafia/Werewolf family and The Resistance (Avalon) and real-world security settings, where a distributed system wants to operate while some of its nodes are controlled by adversaries.","There has been little to no formal mathematical grounding of such settings in the literature, and it is not even immediately clear what the right solution concept is.","In particular, the suitable notion of equilibrium depends on communication available to the players (whether players can communicate, whether they can communicate in private, and whether they can observe who is communicating), and defining it turns out to be a nontrivial task with several surprising consequences.","We show that in certain cases, including the above recreational games, near-optimal equilibria can be computed efficiently.","In most other cases, we show that computing an optimal equilibrium is either NP-hard or coNP-hard.","Lastly, we experimentally validate our approach by computing nearly-exact equilibria for complete Avalon instances up to 6 players whose size in terms of number of information sets is larger than $10^{56}$."],"url":"http://arxiv.org/abs/2308.16017v1"}
{"created":"2023-08-30 13:20:18","title":"Carnot: A highly Scalable and Responsive BFT Consensus protocol","abstract":"We present Carnot, a leader-based Byzantine Fault Tolerant (BFT) consensus protocol that is responsive and operates under the partially synchronous model. Responsive BFT consensus protocols exhibit wire-speed operation and deliver instantaneous finality, thereby addressing a fundamental need in distributed systems. A key challenge in scaling these protocols has been the computational complexity associated with authenticator verification. We demonstrate that Carnot effectively addresses this bottleneck by adeptly streamlining the verification and aggregation of O(log(N)) authenticators per node. This notable advancement marks a substantial improvement over the prevailing O(N) state-of-the-art approaches. Leveraging this inherent property, Carnot demonstrates its capacity to seamlessly scale to networks comprising tens to hundreds of thousands of nodes. We envision Carnot as a critical stride towards bridging the gap between classical BFT consensus mechanisms and blockchain technology.","sentences":["We present Carnot, a leader-based Byzantine Fault Tolerant (BFT) consensus protocol that is responsive and operates under the partially synchronous model.","Responsive BFT consensus protocols exhibit wire-speed operation and deliver instantaneous finality, thereby addressing a fundamental need in distributed systems.","A key challenge in scaling these protocols has been the computational complexity associated with authenticator verification.","We demonstrate that Carnot effectively addresses this bottleneck by adeptly streamlining the verification and aggregation of O(log(N))","authenticators per node.","This notable advancement marks a substantial improvement over the prevailing O(N) state-of-the-art approaches.","Leveraging this inherent property, Carnot demonstrates its capacity to seamlessly scale to networks comprising tens to hundreds of thousands of nodes.","We envision Carnot as a critical stride towards bridging the gap between classical BFT consensus mechanisms and blockchain technology."],"url":"http://arxiv.org/abs/2308.16016v1"}
{"created":"2023-08-30 12:55:02","title":"EnsembleFollower: A Hybrid Car-Following Framework Based On Reinforcement Learning and Hierarchical Planning","abstract":"Car-following models have made significant contributions to our understanding of longitudinal driving behavior. However, they often exhibit limited accuracy and flexibility, as they cannot fully capture the complexity inherent in car-following processes, or may falter in unseen scenarios due to their reliance on confined driving skills present in training data. It is worth noting that each car-following model possesses its own strengths and weaknesses depending on specific driving scenarios. Therefore, we propose EnsembleFollower, a hierarchical planning framework for achieving advanced human-like car-following. The EnsembleFollower framework involves a high-level Reinforcement Learning-based agent responsible for judiciously managing multiple low-level car-following models according to the current state, either by selecting an appropriate low-level model to perform an action or by allocating different weights across all low-level components. Moreover, we propose a jerk-constrained kinematic model for more convincing car-following simulations. We evaluate the proposed method based on real-world driving data from the HighD dataset. The experimental results illustrate that EnsembleFollower yields improved accuracy of human-like behavior and achieves effectiveness in combining hybrid models, demonstrating that our proposed framework can handle diverse car-following conditions by leveraging the strengths of various low-level models.","sentences":["Car-following models have made significant contributions to our understanding of longitudinal driving behavior.","However, they often exhibit limited accuracy and flexibility, as they cannot fully capture the complexity inherent in car-following processes, or may falter in unseen scenarios due to their reliance on confined driving skills present in training data.","It is worth noting that each car-following model possesses its own strengths and weaknesses depending on specific driving scenarios.","Therefore, we propose EnsembleFollower, a hierarchical planning framework for achieving advanced human-like car-following.","The EnsembleFollower framework involves a high-level Reinforcement Learning-based agent responsible for judiciously managing multiple low-level car-following models according to the current state, either by selecting an appropriate low-level model to perform an action or by allocating different weights across all low-level components.","Moreover, we propose a jerk-constrained kinematic model for more convincing car-following simulations.","We evaluate the proposed method based on real-world driving data from the HighD dataset.","The experimental results illustrate that EnsembleFollower yields improved accuracy of human-like behavior and achieves effectiveness in combining hybrid models, demonstrating that our proposed framework can handle diverse car-following conditions by leveraging the strengths of various low-level models."],"url":"http://arxiv.org/abs/2308.16008v1"}
{"created":"2023-08-30 12:37:42","title":"On the entropy and information of Gaussian mixtures","abstract":"We establish several convexity properties for the entropy and Fisher information of mixtures of centered Gaussian distributions. First, we prove that if $X_1, X_2$ are independent scalar Gaussian mixtures, then the entropy of $\\sqrt{t}X_1 + \\sqrt{1-t}X_2$ is concave in $t \\in [0,1]$, thus confirming a conjecture of Ball, Nayar and Tkocz (2016) for this class of random variables. In fact, we prove a generalisation of this assertion which also strengthens a result of Eskenazis, Nayar and Tkocz (2018). For the Fisher information, we extend a convexity result of Bobkov (2022) by showing that the Fisher information matrix is operator convex as a matrix-valued function acting on densities of mixtures in $\\mathbb{R}^d$. As an application, we establish rates for the convergence of the Fisher information matrix of the sum of weighted i.i.d. Gaussian mixtures in the operator norm along the central limit theorem under mild moment assumptions.","sentences":["We establish several convexity properties for the entropy and Fisher information of mixtures of centered Gaussian distributions.","First, we prove that if $X_1, X_2$ are independent scalar Gaussian mixtures, then the entropy of $\\sqrt{t}X_1 + \\sqrt{1-t}X_2$ is concave in $t \\in","[0,1]$, thus confirming a conjecture of Ball, Nayar and Tkocz (2016) for this class of random variables.","In fact, we prove a generalisation of this assertion which also strengthens a result of Eskenazis, Nayar and Tkocz (2018).","For the Fisher information, we extend a convexity result of Bobkov (2022) by showing that the Fisher information matrix is operator convex as a matrix-valued function acting on densities of mixtures in $\\mathbb{R}^d$. As an application, we establish rates for the convergence of the Fisher information matrix of the sum of weighted i.i.d.","Gaussian mixtures in the operator norm along the central limit theorem under mild moment assumptions."],"url":"http://arxiv.org/abs/2308.15997v1"}
{"created":"2023-08-30 12:37:03","title":"DTrOCR: Decoder-only Transformer for Optical Character Recognition","abstract":"Typical text recognition methods rely on an encoder-decoder structure, in which the encoder extracts features from an image, and the decoder produces recognized text from these features. In this study, we propose a simpler and more effective method for text recognition, known as the Decoder-only Transformer for Optical Character Recognition (DTrOCR). This method uses a decoder-only Transformer to take advantage of a generative language model that is pre-trained on a large corpus. We examined whether a generative language model that has been successful in natural language processing can also be effective for text recognition in computer vision. Our experiments demonstrated that DTrOCR outperforms current state-of-the-art methods by a large margin in the recognition of printed, handwritten, and scene text in both English and Chinese.","sentences":["Typical text recognition methods rely on an encoder-decoder structure, in which the encoder extracts features from an image, and the decoder produces recognized text from these features.","In this study, we propose a simpler and more effective method for text recognition, known as the Decoder-only Transformer for Optical Character Recognition (DTrOCR).","This method uses a decoder-only Transformer to take advantage of a generative language model that is pre-trained on a large corpus.","We examined whether a generative language model that has been successful in natural language processing can also be effective for text recognition in computer vision.","Our experiments demonstrated that DTrOCR outperforms current state-of-the-art methods by a large margin in the recognition of printed, handwritten, and scene text in both English and Chinese."],"url":"http://arxiv.org/abs/2308.15996v1"}
{"created":"2023-08-30 12:24:55","title":"AI-powered Fraud Detection in Decentralized Finance: A Project Life Cycle Perspective","abstract":"In recent years, blockchain technology has introduced decentralized finance (DeFi) as an alternative to traditional financial systems. DeFi aims to create a transparent and efficient financial ecosystem using smart contracts and emerging decentralized applications. However, the growing popularity of DeFi has made it a target for fraudulent activities, resulting in losses of billions of dollars due to various types of frauds. To address these issues, researchers have explored the potential of artificial intelligence (AI) approaches to detect such fraudulent activities. Yet, there is a lack of a systematic survey to organize and summarize those existing works and to identify the future research opportunities. In this survey, we provide a systematic taxonomy of various frauds in the DeFi ecosystem, categorized by the different stages of a DeFi project's life cycle: project development, introduction, growth, maturity, and decline. This taxonomy is based on our finding: many frauds have strong correlations in the stage of the DeFi project. According to the taxonomy, we review existing AI-powered detection methods, including statistical modeling, natural language processing and other machine learning techniques, etc. We find that fraud detection in different stages employs distinct types of methods and observe the commendable performance of tree-based and graph-related models in tackling fraud detection tasks. By analyzing the challenges and trends, we present the findings to provide proactive suggestion and guide future research in DeFi fraud detection. We believe that this survey is able to support researchers, practitioners, and regulators in establishing a secure and trustworthy DeFi ecosystem.","sentences":["In recent years, blockchain technology has introduced decentralized finance (DeFi) as an alternative to traditional financial systems.","DeFi aims to create a transparent and efficient financial ecosystem using smart contracts and emerging decentralized applications.","However, the growing popularity of DeFi has made it a target for fraudulent activities, resulting in losses of billions of dollars due to various types of frauds.","To address these issues, researchers have explored the potential of artificial intelligence (AI) approaches to detect such fraudulent activities.","Yet, there is a lack of a systematic survey to organize and summarize those existing works and to identify the future research opportunities.","In this survey, we provide a systematic taxonomy of various frauds in the DeFi ecosystem, categorized by the different stages of a DeFi project's life cycle: project development, introduction, growth, maturity, and decline.","This taxonomy is based on our finding: many frauds have strong correlations in the stage of the DeFi project.","According to the taxonomy, we review existing AI-powered detection methods, including statistical modeling, natural language processing and other machine learning techniques, etc.","We find that fraud detection in different stages employs distinct types of methods and observe the commendable performance of tree-based and graph-related models in tackling fraud detection tasks.","By analyzing the challenges and trends, we present the findings to provide proactive suggestion and guide future research in DeFi fraud detection.","We believe that this survey is able to support researchers, practitioners, and regulators in establishing a secure and trustworthy DeFi ecosystem."],"url":"http://arxiv.org/abs/2308.15992v1"}
{"created":"2023-08-30 12:24:30","title":"DRL-Based Trajectory Tracking for Motion-Related Modules in Autonomous Driving","abstract":"Autonomous driving systems are always built on motion-related modules such as the planner and the controller. An accurate and robust trajectory tracking method is indispensable for these motion-related modules as a primitive routine. Current methods often make strong assumptions about the model such as the context and the dynamics, which are not robust enough to deal with the changing scenarios in a real-world system. In this paper, we propose a Deep Reinforcement Learning (DRL)-based trajectory tracking method for the motion-related modules in autonomous driving systems. The representation learning ability of DL and the exploration nature of RL bring strong robustness and improve accuracy. Meanwhile, it enhances versatility by running the trajectory tracking in a model-free and data-driven manner. Through extensive experiments, we demonstrate both the efficiency and effectiveness of our method compared to current methods.","sentences":["Autonomous driving systems are always built on motion-related modules such as the planner and the controller.","An accurate and robust trajectory tracking method is indispensable for these motion-related modules as a primitive routine.","Current methods often make strong assumptions about the model such as the context and the dynamics, which are not robust enough to deal with the changing scenarios in a real-world system.","In this paper, we propose a Deep Reinforcement Learning (DRL)-based trajectory tracking method for the motion-related modules in autonomous driving systems.","The representation learning ability of DL and the exploration nature of RL bring strong robustness and improve accuracy.","Meanwhile, it enhances versatility by running the trajectory tracking in a model-free and data-driven manner.","Through extensive experiments, we demonstrate both the efficiency and effectiveness of our method compared to current methods."],"url":"http://arxiv.org/abs/2308.15991v1"}
{"created":"2023-08-30 12:22:58","title":"Dual-path Transformer Based Neural Beamformer for Target Speech Extraction","abstract":"Neural beamformers, integrating both pre-separation and beamforming modules, have shown impressive efficacy in the target speech extraction task. Nevertheless, the performance of these beamformers is inherently constrained by the predictive accuracy of the pre-separation module. In this paper, we introduce a neural beamformer underpinned by a dual-path transformer. Initially, we harness the cross-attention mechanism in the time domain, extracting pivotal spatial information related to beamforming from the noisy covariance matrix. Subsequently, in the frequency domain, the self-attention mechanism is employed to bolster the model's capacity to process frequency-specific details. By design, our model circumvents the influence of pre-separation modules, delivering the performance in a more holistic end-to-end fashion. Experimental results reveal that our model not only surpasses contemporary leading neural beamforming algorithms in separation performance, but also achieves this with a notable reduction in parameter count.","sentences":["Neural beamformers, integrating both pre-separation and beamforming modules, have shown impressive efficacy in the target speech extraction task.","Nevertheless, the performance of these beamformers is inherently constrained by the predictive accuracy of the pre-separation module.","In this paper, we introduce a neural beamformer underpinned by a dual-path transformer.","Initially, we harness the cross-attention mechanism in the time domain, extracting pivotal spatial information related to beamforming from the noisy covariance matrix.","Subsequently, in the frequency domain, the self-attention mechanism is employed to bolster the model's capacity to process frequency-specific details.","By design, our model circumvents the influence of pre-separation modules, delivering the performance in a more holistic end-to-end fashion.","Experimental results reveal that our model not only surpasses contemporary leading neural beamforming algorithms in separation performance, but also achieves this with a notable reduction in parameter count."],"url":"http://arxiv.org/abs/2308.15990v1"}
{"created":"2023-08-30 12:19:35","title":"DiffuVolume: Diffusion Model for Volume based Stereo Matching","abstract":"Stereo matching is a significant part in many computer vision tasks and driving-based applications. Recently cost volume-based methods have achieved great success benefiting from the rich geometry information in paired images. However, the redundancy of cost volume also interferes with the model training and limits the performance. To construct a more precise cost volume, we pioneeringly apply the diffusion model to stereo matching. Our method, termed DiffuVolume, considers the diffusion model as a cost volume filter, which will recurrently remove the redundant information from the cost volume. Two main designs make our method not trivial. Firstly, to make the diffusion model more adaptive to stereo matching, we eschew the traditional manner of directly adding noise into the image but embed the diffusion model into a task-specific module. In this way, we outperform the traditional diffusion stereo matching method by 22% EPE improvement and 240 times inference acceleration. Secondly, DiffuVolume can be easily embedded into any volume-based stereo matching network with boost performance but slight parameters rise (only 2%). By adding the DiffuVolume into well-performed methods, we outperform all the published methods on Scene Flow, KITTI2012, KITTI2015 benchmarks and zero-shot generalization setting. It is worth mentioning that the proposed model ranks 1st on KITTI 2012 leader board, 2nd on KITTI 2015 leader board since 15, July 2023.","sentences":["Stereo matching is a significant part in many computer vision tasks and driving-based applications.","Recently cost volume-based methods have achieved great success benefiting from the rich geometry information in paired images.","However, the redundancy of cost volume also interferes with the model training and limits the performance.","To construct a more precise cost volume, we pioneeringly apply the diffusion model to stereo matching.","Our method, termed DiffuVolume, considers the diffusion model as a cost volume filter, which will recurrently remove the redundant information from the cost volume.","Two main designs make our method not trivial.","Firstly, to make the diffusion model more adaptive to stereo matching, we eschew the traditional manner of directly adding noise into the image but embed the diffusion model into a task-specific module.","In this way, we outperform the traditional diffusion stereo matching method by 22% EPE improvement and 240 times inference acceleration.","Secondly, DiffuVolume can be easily embedded into any volume-based stereo matching network with boost performance but slight parameters rise (only 2%).","By adding the DiffuVolume into well-performed methods, we outperform all the published methods on Scene Flow, KITTI2012, KITTI2015 benchmarks and zero-shot generalization setting.","It is worth mentioning that the proposed model ranks 1st on KITTI 2012 leader board, 2nd on KITTI 2015 leader board since 15, July 2023."],"url":"http://arxiv.org/abs/2308.15989v1"}
{"created":"2023-08-30 12:19:19","title":"Support Testing in the Huge Object Model","abstract":"The Huge Object model is a distribution testing model in which we are given access to independent samples from an unknown distribution over the set of strings $\\{0,1\\}^n$, but are only allowed to query a few bits from the samples.   We investigate the problem of testing whether a distribution is supported on $m$ elements in this model. It turns out that the behavior of this property is surprisingly intricate, especially when also considering the question of adaptivity.   We prove lower and upper bounds for both adaptive and non-adaptive algorithms in the one-sided and two-sided error regime. Our bounds are tight when $m$ is fixed to a constant (and the distance parameter $\\varepsilon$ is the only variable). For the general case, our bounds are at most $O(\\log m)$ apart.   In particular, our results show a surprising $O(\\log \\varepsilon^{-1})$ gap between the number of queries required for non-adaptive testing as compared to adaptive testing. For one sided error testing, we also show that an $O(\\log m)$ gap between the number of samples and the number of queries is necessary.   Our results utilize a wide variety of combinatorial and probabilistic methods.","sentences":["The Huge Object model is a distribution testing model in which we are given access to independent samples from an unknown distribution over the set of strings $\\{0,1\\}^n$, but are only allowed to query a few bits from the samples.   ","We investigate the problem of testing whether a distribution is supported on $m$ elements in this model.","It turns out that the behavior of this property is surprisingly intricate, especially when also considering the question of adaptivity.   ","We prove lower and upper bounds for both adaptive and non-adaptive algorithms in the one-sided and two-sided error regime.","Our bounds are tight when $m$ is fixed to a constant (and the distance parameter $\\varepsilon$ is the only variable).","For the general case, our bounds are at most $O(\\log m)$ apart.   ","In particular, our results show a surprising $O(\\log \\varepsilon^{-1})$ gap between the number of queries required for non-adaptive testing as compared to adaptive testing.","For one sided error testing, we also show that an $O(\\log m)$ gap between the number of samples and the number of queries is necessary.   ","Our results utilize a wide variety of combinatorial and probabilistic methods."],"url":"http://arxiv.org/abs/2308.15988v1"}
{"created":"2023-08-30 12:18:18","title":"FPTQ: Fine-grained Post-Training Quantization for Large Language Models","abstract":"In the era of large-scale language models, the substantial parameter size poses significant challenges for deployment. Being a prevalent compression technique, quantization has emerged as the mainstream practice to tackle this issue, which is mainly centered on two recipes W8A8 and W4A16 (i.e. weights and activations in such bit widths). In this study, we propose a novel W4A8 post-training quantization method for the available open-sourced LLMs, which combines the advantages of both two recipes. Therefore, we can leverage the benefit in the I/O utilization of 4-bit weight quantization and the acceleration due to 8-bit matrix computation. Nevertheless, the W4A8 faces notorious performance degradation. As a remedy, we involve layerwise activation quantization strategies which feature a novel logarithmic equalization for most intractable layers, and we combine them with fine-grained weight quantization. Without whistles and bells, we eliminate the necessity for further fine-tuning and obtain the state-of-the-art W4A8 quantized performance on BLOOM, LLaMA, and LLaMA-2 on standard benchmarks. We confirm that the W4A8 quantization is achievable for the deployment of large language models, fostering their wide-spreading real-world applications.","sentences":["In the era of large-scale language models, the substantial parameter size poses significant challenges for deployment.","Being a prevalent compression technique, quantization has emerged as the mainstream practice to tackle this issue, which is mainly centered on two recipes W8A8 and W4A16 (i.e. weights and activations in such bit widths).","In this study, we propose a novel W4A8 post-training quantization method for the available open-sourced LLMs, which combines the advantages of both two recipes.","Therefore, we can leverage the benefit in the I/O utilization of 4-bit weight quantization and the acceleration due to 8-bit matrix computation.","Nevertheless, the W4A8 faces notorious performance degradation.","As a remedy, we involve layerwise activation quantization strategies which feature a novel logarithmic equalization for most intractable layers, and we combine them with fine-grained weight quantization.","Without whistles and bells, we eliminate the necessity for further fine-tuning and obtain the state-of-the-art W4A8 quantized performance on BLOOM, LLaMA, and LLaMA-2 on standard benchmarks.","We confirm that the W4A8 quantization is achievable for the deployment of large language models, fostering their wide-spreading real-world applications."],"url":"http://arxiv.org/abs/2308.15987v1"}
{"created":"2023-08-30 12:13:41","title":"Vision-Based Traffic Accident Detection and Anticipation: A Survey","abstract":"Traffic accident detection and anticipation is an obstinate road safety problem and painstaking efforts have been devoted. With the rapid growth of video data, Vision-based Traffic Accident Detection and Anticipation (named Vision-TAD and Vision-TAA) become the last one-mile problem for safe driving and surveillance safety. However, the long-tailed, unbalanced, highly dynamic, complex, and uncertain properties of traffic accidents form the Out-of-Distribution (OOD) feature for Vision-TAD and Vision-TAA. Current AI development may focus on these OOD but important problems. What has been done for Vision-TAD and Vision-TAA? What direction we should focus on in the future for this problem? A comprehensive survey is important. We present the first survey on Vision-TAD in the deep learning era and the first-ever survey for Vision-TAA. The pros and cons of each research prototype are discussed in detail during the investigation. In addition, we also provide a critical review of 31 publicly available benchmarks and related evaluation metrics. Through this survey, we want to spawn new insights and open possible trends for Vision-TAD and Vision-TAA tasks.","sentences":["Traffic accident detection and anticipation is an obstinate road safety problem and painstaking efforts have been devoted.","With the rapid growth of video data, Vision-based Traffic Accident Detection and Anticipation (named Vision-TAD and Vision-TAA) become the last one-mile problem for safe driving and surveillance safety.","However, the long-tailed, unbalanced, highly dynamic, complex, and uncertain properties of traffic accidents form the Out-of-Distribution (OOD) feature for Vision-TAD and Vision-TAA.","Current AI development may focus on these OOD but important problems.","What has been done for Vision-TAD and Vision-TAA?","What direction we should focus on in the future for this problem?","A comprehensive survey is important.","We present the first survey on Vision-TAD in the deep learning era and the first-ever survey for Vision-TAA.","The pros and cons of each research prototype are discussed in detail during the investigation.","In addition, we also provide a critical review of 31 publicly available benchmarks and related evaluation metrics.","Through this survey, we want to spawn new insights and open possible trends for Vision-TAD and Vision-TAA tasks."],"url":"http://arxiv.org/abs/2308.15985v1"}
{"created":"2023-08-30 12:13:13","title":"Learning Structure-from-Motion with Graph Attention Networks","abstract":"In this paper we tackle the problem of learning Structure-from-Motion (SfM) through the use of graph attention networks. SfM is a classic computer vision problem that is solved though iterative minimization of reprojection errors, referred to as Bundle Adjustment (BA), starting from a good initialization. In order to obtain a good enough initialization to BA, conventional methods rely on a sequence of sub-problems (such as pairwise pose estimation, pose averaging or triangulation) which provides an initial solution that can then be refined using BA. In this work we replace these sub-problems by learning a model that takes as input the 2D keypoints detected across multiple views, and outputs the corresponding camera poses and 3D keypoint coordinates. Our model takes advantage of graph neural networks to learn SfM-specific primitives, and we show that it can be used for fast inference of the reconstruction for new and unseen sequences. The experimental results show that the proposed model outperforms competing learning-based methods, and challenges COLMAP while having lower runtime.","sentences":["In this paper we tackle the problem of learning Structure-from-Motion (SfM) through the use of graph attention networks.","SfM is a classic computer vision problem that is solved though iterative minimization of reprojection errors, referred to as Bundle Adjustment (BA), starting from a good initialization.","In order to obtain a good enough initialization to BA, conventional methods rely on a sequence of sub-problems (such as pairwise pose estimation, pose averaging or triangulation) which provides an initial solution that can then be refined using BA.","In this work we replace these sub-problems by learning a model that takes as input the 2D keypoints detected across multiple views, and outputs the corresponding camera poses and 3D keypoint coordinates.","Our model takes advantage of graph neural networks to learn SfM-specific primitives, and we show that it can be used for fast inference of the reconstruction for new and unseen sequences.","The experimental results show that the proposed model outperforms competing learning-based methods, and challenges COLMAP while having lower runtime."],"url":"http://arxiv.org/abs/2308.15984v1"}
