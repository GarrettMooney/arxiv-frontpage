{"created":"2023-08-10 17:59:46","title":"Iterative Reweighted Least Squares Networks With Convergence Guarantees for Solving Inverse Imaging Problems","abstract":"In this work we present a novel optimization strategy for image reconstruction tasks under analysis-based image regularization, which promotes sparse and/or low-rank solutions in some learned transform domain. We parameterize such regularizers using potential functions that correspond to weighted extensions of the $\\ell_p^p$-vector and $\\mathcal{S}_p^p$ Schatten-matrix quasi-norms with $0 < p \\le 1$. Our proposed minimization strategy extends the Iteratively Reweighted Least Squares (IRLS) method, typically used for synthesis-based $\\ell_p$ and $\\mathcal{S}_p$ norm and analysis-based $\\ell_1$ and nuclear norm regularization. We prove that under mild conditions our minimization algorithm converges linearly to a stationary point, and we provide an upper bound for its convergence rate. Further, to select the parameters of the regularizers that deliver the best results for the problem at hand, we propose to learn them from training data by formulating the supervised learning process as a stochastic bilevel optimization problem. We show that thanks to the convergence guarantees of our proposed minimization strategy, such optimization can be successfully performed with a memory-efficient implicit back-propagation scheme. We implement our learned IRLS variants as recurrent networks and assess their performance on the challenging image reconstruction tasks of non-blind deblurring, super-resolution and demosaicking. The comparisons against other existing learned reconstruction approaches demonstrate that our overall method is very competitive and in many cases outperforms existing unrolled networks, whose number of parameters is orders of magnitude higher than in our case.","sentences":["In this work we present a novel optimization strategy for image reconstruction tasks under analysis-based image regularization, which promotes sparse and/or low-rank solutions in some learned transform domain.","We parameterize such regularizers using potential functions that correspond to weighted extensions of the $\\ell_p^p$-vector and $\\mathcal{S}_p^p$ Schatten-matrix quasi-norms with $0 <","p \\le 1$.","Our proposed minimization strategy extends the Iteratively Reweighted Least Squares (IRLS) method, typically used for synthesis-based $\\ell_p$ and $\\mathcal{S}_p$ norm and analysis-based $\\ell_1$ and nuclear norm regularization.","We prove that under mild conditions our minimization algorithm converges linearly to a stationary point, and we provide an upper bound for its convergence rate.","Further, to select the parameters of the regularizers that deliver the best results for the problem at hand, we propose to learn them from training data by formulating the supervised learning process as a stochastic bilevel optimization problem.","We show that thanks to the convergence guarantees of our proposed minimization strategy, such optimization can be successfully performed with a memory-efficient implicit back-propagation scheme.","We implement our learned IRLS variants as recurrent networks and assess their performance on the challenging image reconstruction tasks of non-blind deblurring, super-resolution and demosaicking.","The comparisons against other existing learned reconstruction approaches demonstrate that our overall method is very competitive and in many cases outperforms existing unrolled networks, whose number of parameters is orders of magnitude higher than in our case."],"url":"http://arxiv.org/abs/2308.05745v1"}
{"created":"2023-08-10 17:59:34","title":"PlankAssembly: Robust 3D Reconstruction from Three Orthographic Views with Learnt Shape Programs","abstract":"In this paper, we develop a new method to automatically convert 2D line drawings from three orthographic views into 3D CAD models. Existing methods for this problem reconstruct 3D models by back-projecting the 2D observations into 3D space while maintaining explicit correspondence between the input and output. Such methods are sensitive to errors and noises in the input, thus often fail in practice where the input drawings created by human designers are imperfect. To overcome this difficulty, we leverage the attention mechanism in a Transformer-based sequence generation model to learn flexible mappings between the input and output. Further, we design shape programs which are suitable for generating the objects of interest to boost the reconstruction accuracy and facilitate CAD modeling applications. Experiments on a new benchmark dataset show that our method significantly outperforms existing ones when the inputs are noisy or incomplete.","sentences":["In this paper, we develop a new method to automatically convert 2D line drawings from three orthographic views into 3D CAD models.","Existing methods for this problem reconstruct 3D models by back-projecting the 2D observations into 3D space while maintaining explicit correspondence between the input and output.","Such methods are sensitive to errors and noises in the input, thus often fail in practice where the input drawings created by human designers are imperfect.","To overcome this difficulty, we leverage the attention mechanism in a Transformer-based sequence generation model to learn flexible mappings between the input and output.","Further, we design shape programs which are suitable for generating the objects of interest to boost the reconstruction accuracy and facilitate CAD modeling applications.","Experiments on a new benchmark dataset show that our method significantly outperforms existing ones when the inputs are noisy or incomplete."],"url":"http://arxiv.org/abs/2308.05744v1"}
{"created":"2023-08-10 17:58:02","title":"Neural Progressive Meshes","abstract":"The recent proliferation of 3D content that can be consumed on hand-held devices necessitates efficient tools for transmitting large geometric data, e.g., 3D meshes, over the Internet. Detailed high-resolution assets can pose a challenge to storage as well as transmission bandwidth, and level-of-detail techniques are often used to transmit an asset using an appropriate bandwidth budget. It is especially desirable for these methods to transmit data progressively, improving the quality of the geometry with more data. Our key insight is that the geometric details of 3D meshes often exhibit similar local patterns even across different shapes, and thus can be effectively represented with a shared learned generative space. We learn this space using a subdivision-based encoder-decoder architecture trained in advance on a large collection of surfaces. We further observe that additional residual features can be transmitted progressively between intermediate levels of subdivision that enable the client to control the tradeoff between bandwidth cost and quality of reconstruction, providing a neural progressive mesh representation. We evaluate our method on a diverse set of complex 3D shapes and demonstrate that it outperforms baselines in terms of compression ratio and reconstruction quality.","sentences":["The recent proliferation of 3D content that can be consumed on hand-held devices necessitates efficient tools for transmitting large geometric data, e.g., 3D meshes, over the Internet.","Detailed high-resolution assets can pose a challenge to storage as well as transmission bandwidth, and level-of-detail techniques are often used to transmit an asset using an appropriate bandwidth budget.","It is especially desirable for these methods to transmit data progressively, improving the quality of the geometry with more data.","Our key insight is that the geometric details of 3D meshes often exhibit similar local patterns even across different shapes, and thus can be effectively represented with a shared learned generative space.","We learn this space using a subdivision-based encoder-decoder architecture trained in advance on a large collection of surfaces.","We further observe that additional residual features can be transmitted progressively between intermediate levels of subdivision that enable the client to control the tradeoff between bandwidth cost and quality of reconstruction, providing a neural progressive mesh representation.","We evaluate our method on a diverse set of complex 3D shapes and demonstrate that it outperforms baselines in terms of compression ratio and reconstruction quality."],"url":"http://arxiv.org/abs/2308.05741v1"}
{"created":"2023-08-10 17:57:22","title":"Zero Grads Ever Given: Learning Local Surrogate Losses for Non-Differentiable Graphics","abstract":"Gradient-based optimization is now ubiquitous across graphics, but unfortunately can not be applied to problems with undefined or zero gradients. To circumvent this issue, the loss function can be manually replaced by a \"surrogate\" that has similar minima but is differentiable. Our proposed framework, ZeroGrads, automates this process by learning a neural approximation of the objective function, the surrogate, which in turn can be used to differentiate through arbitrary black-box graphics pipelines. We train the surrogate on an actively smoothed version of the objective and encourage locality, focusing the surrogate's capacity on what matters at the current training episode. The fitting is performed online, alongside the parameter optimization, and self-supervised, without pre-computed data or pre-trained models. As sampling the objective is expensive (it requires a full rendering or simulator run), we devise an efficient sampling scheme that allows for tractable run-times and competitive performance at little overhead. We demonstrate optimizing diverse non-convex, non-differentiable black-box problems in graphics, such as visibility in rendering, discrete parameter spaces in procedural modelling or optimal control in physics-driven animation. In contrast to more traditional algorithms, our approach scales well to higher dimensions, which we demonstrate on problems with up to 35k interlinked variables.","sentences":["Gradient-based optimization is now ubiquitous across graphics, but unfortunately can not be applied to problems with undefined or zero gradients.","To circumvent this issue, the loss function can be manually replaced by a \"surrogate\" that has similar minima but is differentiable.","Our proposed framework, ZeroGrads, automates this process by learning a neural approximation of the objective function, the surrogate, which in turn can be used to differentiate through arbitrary black-box graphics pipelines.","We train the surrogate on an actively smoothed version of the objective and encourage locality, focusing the surrogate's capacity on what matters at the current training episode.","The fitting is performed online, alongside the parameter optimization, and self-supervised, without pre-computed data or pre-trained models.","As sampling the objective is expensive (it requires a full rendering or simulator run), we devise an efficient sampling scheme that allows for tractable run-times and competitive performance at little overhead.","We demonstrate optimizing diverse non-convex, non-differentiable black-box problems in graphics, such as visibility in rendering, discrete parameter spaces in procedural modelling or optimal control in physics-driven animation.","In contrast to more traditional algorithms, our approach scales well to higher dimensions, which we demonstrate on problems with up to 35k interlinked variables."],"url":"http://arxiv.org/abs/2308.05739v1"}
{"created":"2023-08-10 17:57:06","title":"Follow Anything: Open-set detection, tracking, and following in real-time","abstract":"Tracking and following objects of interest is critical to several robotics use cases, ranging from industrial automation to logistics and warehousing, to healthcare and security. In this paper, we present a robotic system to detect, track, and follow any object in real-time. Our approach, dubbed ``follow anything'' (FAn), is an open-vocabulary and multimodal model -- it is not restricted to concepts seen at training time and can be applied to novel classes at inference time using text, images, or click queries. Leveraging rich visual descriptors from large-scale pre-trained models (foundation models), FAn can detect and segment objects by matching multimodal queries (text, images, clicks) against an input image sequence. These detected and segmented objects are tracked across image frames, all while accounting for occlusion and object re-emergence. We demonstrate FAn on a real-world robotic system (a micro aerial vehicle) and report its ability to seamlessly follow the objects of interest in a real-time control loop. FAn can be deployed on a laptop with a lightweight (6-8 GB) graphics card, achieving a throughput of 6-20 frames per second. To enable rapid adoption, deployment, and extensibility, we open-source all our code on our project webpage at https://github.com/alaamaalouf/FollowAnything . We also encourage the reader the watch our 5-minutes explainer video in this https://www.youtube.com/watch?v=6Mgt3EPytrw .","sentences":["Tracking and following objects of interest is critical to several robotics use cases, ranging from industrial automation to logistics and warehousing, to healthcare and security.","In this paper, we present a robotic system to detect, track, and follow any object in real-time.","Our approach, dubbed ``follow anything'' (FAn), is an open-vocabulary and multimodal model -- it is not restricted to concepts seen at training time and can be applied to novel classes at inference time using text, images, or click queries.","Leveraging rich visual descriptors from large-scale pre-trained models (foundation models), FAn can detect and segment objects by matching multimodal queries (text, images, clicks) against an input image sequence.","These detected and segmented objects are tracked across image frames, all while accounting for occlusion and object re-emergence.","We demonstrate FAn on a real-world robotic system (a micro aerial vehicle) and report its ability to seamlessly follow the objects of interest in a real-time control loop.","FAn can be deployed on a laptop with a lightweight (6-8 GB) graphics card, achieving a throughput of 6-20 frames per second.","To enable rapid adoption, deployment, and extensibility, we open-source all our code on our project webpage at https://github.com/alaamaalouf/FollowAnything .","We also encourage the reader the watch our 5-minutes explainer video in this https://www.youtube.com/watch?v=6Mgt3EPytrw ."],"url":"http://arxiv.org/abs/2308.05737v1"}
{"created":"2023-08-10 17:56:53","title":"MapTRv2: An End-to-End Framework for Online Vectorized HD Map Construction","abstract":"High-definition (HD) map provides abundant and precise static environmental information of the driving scene, serving as a fundamental and indispensable component for planning in autonomous driving system. In this paper, we present \\textbf{Map} \\textbf{TR}ansformer, an end-to-end framework for online vectorized HD map construction. We propose a unified permutation-equivalent modeling approach, \\ie, modeling map element as a point set with a group of equivalent permutations, which accurately describes the shape of map element and stabilizes the learning process. We design a hierarchical query embedding scheme to flexibly encode structured map information and perform hierarchical bipartite matching for map element learning. To speed up convergence, we further introduce auxiliary one-to-many matching and dense supervision. The proposed method well copes with various map elements with arbitrary shapes. It runs at real-time inference speed and achieves state-of-the-art performance on both nuScenes and Argoverse2 datasets. Abundant qualitative results show stable and robust map construction quality in complex and various driving scenes. Code and more demos are available at \\url{https://github.com/hustvl/MapTR} for facilitating further studies and applications.","sentences":["High-definition (HD) map provides abundant and precise static environmental information of the driving scene, serving as a fundamental and indispensable component for planning in autonomous driving system.","In this paper, we present \\textbf{Map} \\textbf{TR}ansformer, an end-to-end framework for online vectorized HD map construction.","We propose a unified permutation-equivalent modeling approach, \\ie, modeling map element as a point set with a group of equivalent permutations, which accurately describes the shape of map element and stabilizes the learning process.","We design a hierarchical query embedding scheme to flexibly encode structured map information and perform hierarchical bipartite matching for map element learning.","To speed up convergence, we further introduce auxiliary one-to-many matching and dense supervision.","The proposed method well copes with various map elements with arbitrary shapes.","It runs at real-time inference speed and achieves state-of-the-art performance on both nuScenes and Argoverse2 datasets.","Abundant qualitative results show stable and robust map construction quality in complex and various driving scenes.","Code and more demos are available at \\url{https://github.com/hustvl/MapTR} for facilitating further studies and applications."],"url":"http://arxiv.org/abs/2308.05736v1"}
{"created":"2023-08-10 17:55:13","title":"AudioLDM 2: Learning Holistic Audio Generation with Self-supervised Pretraining","abstract":"Although audio generation shares commonalities across different types of audio, such as speech, music, and sound effects, designing models for each type requires careful consideration of specific objectives and biases that can significantly differ from those of other types. To bring us closer to a unified perspective of audio generation, this paper proposes a framework that utilizes the same learning method for speech, music, and sound effect generation. Our framework introduces a general representation of audio, called language of audio (LOA). Any audio can be translated into LOA based on AudioMAE, a self-supervised pre-trained representation learning model. In the generation process, we translate any modalities into LOA by using a GPT-2 model, and we perform self-supervised audio generation learning with a latent diffusion model conditioned on LOA. The proposed framework naturally brings advantages such as in-context learning abilities and reusable self-supervised pretrained AudioMAE and latent diffusion models. Experiments on the major benchmarks of text-to-audio, text-to-music, and text-to-speech demonstrate new state-of-the-art or competitive performance to previous approaches. Our demo and code are available at https://audioldm.github.io/audioldm2.","sentences":["Although audio generation shares commonalities across different types of audio, such as speech, music, and sound effects, designing models for each type requires careful consideration of specific objectives and biases that can significantly differ from those of other types.","To bring us closer to a unified perspective of audio generation, this paper proposes a framework that utilizes the same learning method for speech, music, and sound effect generation.","Our framework introduces a general representation of audio, called language of audio (LOA).","Any audio can be translated into LOA based on AudioMAE, a self-supervised pre-trained representation learning model.","In the generation process, we translate any modalities into LOA by using a GPT-2 model, and we perform self-supervised audio generation learning with a latent diffusion model conditioned on LOA.","The proposed framework naturally brings advantages such as in-context learning abilities and reusable self-supervised pretrained AudioMAE and latent diffusion models.","Experiments on the major benchmarks of text-to-audio, text-to-music, and text-to-speech demonstrate new state-of-the-art or competitive performance to previous approaches.","Our demo and code are available at https://audioldm.github.io/audioldm2."],"url":"http://arxiv.org/abs/2308.05734v1"}
{"created":"2023-08-10 17:55:02","title":"FrozenRecon: Pose-free 3D Scene Reconstruction with Frozen Depth Models","abstract":"3D scene reconstruction is a long-standing vision task. Existing approaches can be categorized into geometry-based and learning-based methods. The former leverages multi-view geometry but can face catastrophic failures due to the reliance on accurate pixel correspondence across views. The latter was proffered to mitigate these issues by learning 2D or 3D representation directly. However, without a large-scale video or 3D training data, it can hardly generalize to diverse real-world scenarios due to the presence of tens of millions or even billions of optimization parameters in the deep network. Recently, robust monocular depth estimation models trained with large-scale datasets have been proven to possess weak 3D geometry prior, but they are insufficient for reconstruction due to the unknown camera parameters, the affine-invariant property, and inter-frame inconsistency. Here, we propose a novel test-time optimization approach that can transfer the robustness of affine-invariant depth models such as LeReS to challenging diverse scenes while ensuring inter-frame consistency, with only dozens of parameters to optimize per video frame. Specifically, our approach involves freezing the pre-trained affine-invariant depth model's depth predictions, rectifying them by optimizing the unknown scale-shift values with a geometric consistency alignment module, and employing the resulting scale-consistent depth maps to robustly obtain camera poses and achieve dense scene reconstruction, even in low-texture regions. Experiments show that our method achieves state-of-the-art cross-dataset reconstruction on five zero-shot testing datasets.","sentences":["3D scene reconstruction is a long-standing vision task.","Existing approaches can be categorized into geometry-based and learning-based methods.","The former leverages multi-view geometry but can face catastrophic failures due to the reliance on accurate pixel correspondence across views.","The latter was proffered to mitigate these issues by learning 2D or 3D representation directly.","However, without a large-scale video or 3D training data, it can hardly generalize to diverse real-world scenarios due to the presence of tens of millions or even billions of optimization parameters in the deep network.","Recently, robust monocular depth estimation models trained with large-scale datasets have been proven to possess weak 3D geometry prior, but they are insufficient for reconstruction due to the unknown camera parameters, the affine-invariant property, and inter-frame inconsistency.","Here, we propose a novel test-time optimization approach that can transfer the robustness of affine-invariant depth models such as LeReS to challenging diverse scenes while ensuring inter-frame consistency, with only dozens of parameters to optimize per video frame.","Specifically, our approach involves freezing the pre-trained affine-invariant depth model's depth predictions, rectifying them by optimizing the unknown scale-shift values with a geometric consistency alignment module, and employing the resulting scale-consistent depth maps to robustly obtain camera poses and achieve dense scene reconstruction, even in low-texture regions.","Experiments show that our method achieves state-of-the-art cross-dataset reconstruction on five zero-shot testing datasets."],"url":"http://arxiv.org/abs/2308.05733v1"}
{"created":"2023-08-10 17:53:05","title":"PDE-Refiner: Achieving Accurate Long Rollouts with Neural PDE Solvers","abstract":"Time-dependent partial differential equations (PDEs) are ubiquitous in science and engineering. Recently, mostly due to the high computational cost of traditional solution techniques, deep neural network based surrogates have gained increased interest. The practical utility of such neural PDE solvers relies on their ability to provide accurate, stable predictions over long time horizons, which is a notoriously hard problem. In this work, we present a large-scale analysis of common temporal rollout strategies, identifying the neglect of non-dominant spatial frequency information, often associated with high frequencies in PDE solutions, as the primary pitfall limiting stable, accurate rollout performance. Based on these insights, we draw inspiration from recent advances in diffusion models to introduce PDE-Refiner; a novel model class that enables more accurate modeling of all frequency components via a multistep refinement process. We validate PDE-Refiner on challenging benchmarks of complex fluid dynamics, demonstrating stable and accurate rollouts that consistently outperform state-of-the-art models, including neural, numerical, and hybrid neural-numerical architectures. We further demonstrate that PDE-Refiner greatly enhances data efficiency, since the denoising objective implicitly induces a novel form of spectral data augmentation. Finally, PDE-Refiner's connection to diffusion models enables an accurate and efficient assessment of the model's predictive uncertainty, allowing us to estimate when the surrogate becomes inaccurate.","sentences":["Time-dependent partial differential equations (PDEs) are ubiquitous in science and engineering.","Recently, mostly due to the high computational cost of traditional solution techniques, deep neural network based surrogates have gained increased interest.","The practical utility of such neural PDE solvers relies on their ability to provide accurate, stable predictions over long time horizons, which is a notoriously hard problem.","In this work, we present a large-scale analysis of common temporal rollout strategies, identifying the neglect of non-dominant spatial frequency information, often associated with high frequencies in PDE solutions, as the primary pitfall limiting stable, accurate rollout performance.","Based on these insights, we draw inspiration from recent advances in diffusion models to introduce PDE-Refiner; a novel model class that enables more accurate modeling of all frequency components via a multistep refinement process.","We validate PDE-Refiner on challenging benchmarks of complex fluid dynamics, demonstrating stable and accurate rollouts that consistently outperform state-of-the-art models, including neural, numerical, and hybrid neural-numerical architectures.","We further demonstrate that PDE-Refiner greatly enhances data efficiency, since the denoising objective implicitly induces a novel form of spectral data augmentation.","Finally, PDE-Refiner's connection to diffusion models enables an accurate and efficient assessment of the model's predictive uncertainty, allowing us to estimate when the surrogate becomes inaccurate."],"url":"http://arxiv.org/abs/2308.05732v1"}
{"created":"2023-08-10 17:53:03","title":"Rethinking Integration of Prediction and Planning in Deep Learning-Based Automated Driving Systems: A Review","abstract":"Automated driving has the potential to revolutionize personal, public, and freight mobility. Besides the enormous challenge of perception, i.e. accurately perceiving the environment using available sensor data, automated driving comprises planning a safe, comfortable, and efficient motion trajectory. To promote safety and progress, many works rely on modules that predict the future motion of surrounding traffic. Modular automated driving systems commonly handle prediction and planning as sequential separate tasks. While this accounts for the influence of surrounding traffic on the ego-vehicle, it fails to anticipate the reactions of traffic participants to the ego-vehicle's behavior. Recent works suggest that integrating prediction and planning in an interdependent joint step is necessary to achieve safe, efficient, and comfortable driving. While various models implement such integrated systems, a comprehensive overview and theoretical understanding of different principles are lacking. We systematically review state-of-the-art deep learning-based prediction, planning, and integrated prediction and planning models. Different facets of the integration ranging from model architecture and model design to behavioral aspects are considered and related to each other. Moreover, we discuss the implications, strengths, and limitations of different integration methods. By pointing out research gaps, describing relevant future challenges, and highlighting trends in the research field, we identify promising directions for future research.","sentences":["Automated driving has the potential to revolutionize personal, public, and freight mobility.","Besides the enormous challenge of perception, i.e. accurately perceiving the environment using available sensor data, automated driving comprises planning a safe, comfortable, and efficient motion trajectory.","To promote safety and progress, many works rely on modules that predict the future motion of surrounding traffic.","Modular automated driving systems commonly handle prediction and planning as sequential separate tasks.","While this accounts for the influence of surrounding traffic on the ego-vehicle, it fails to anticipate the reactions of traffic participants to the ego-vehicle's behavior.","Recent works suggest that integrating prediction and planning in an interdependent joint step is necessary to achieve safe, efficient, and comfortable driving.","While various models implement such integrated systems, a comprehensive overview and theoretical understanding of different principles are lacking.","We systematically review state-of-the-art deep learning-based prediction, planning, and integrated prediction and planning models.","Different facets of the integration ranging from model architecture and model design to behavioral aspects are considered and related to each other.","Moreover, we discuss the implications, strengths, and limitations of different integration methods.","By pointing out research gaps, describing relevant future challenges, and highlighting trends in the research field, we identify promising directions for future research."],"url":"http://arxiv.org/abs/2308.05731v1"}
{"created":"2023-08-10 17:41:19","title":"EXPRESSO: A Benchmark and Analysis of Discrete Expressive Speech Resynthesis","abstract":"Recent work has shown that it is possible to resynthesize high-quality speech based, not on text, but on low bitrate discrete units that have been learned in a self-supervised fashion and can therefore capture expressive aspects of speech that are hard to transcribe (prosody, voice styles, non-verbal vocalization). The adoption of these methods is still limited by the fact that most speech synthesis datasets are read, severely limiting spontaneity and expressivity. Here, we introduce Expresso, a high-quality expressive speech dataset for textless speech synthesis that includes both read speech and improvised dialogues rendered in 26 spontaneous expressive styles. We illustrate the challenges and potentials of this dataset with an expressive resynthesis benchmark where the task is to encode the input in low-bitrate units and resynthesize it in a target voice while preserving content and style. We evaluate resynthesis quality with automatic metrics for different self-supervised discrete encoders, and explore tradeoffs between quality, bitrate and invariance to speaker and style. All the dataset, evaluation metrics and baseline models are open source","sentences":["Recent work has shown that it is possible to resynthesize high-quality speech based, not on text, but on low bitrate discrete units that have been learned in a self-supervised fashion and can therefore capture expressive aspects of speech that are hard to transcribe (prosody, voice styles, non-verbal vocalization).","The adoption of these methods is still limited by the fact that most speech synthesis datasets are read, severely limiting spontaneity and expressivity.","Here, we introduce Expresso, a high-quality expressive speech dataset for textless speech synthesis that includes both read speech and improvised dialogues rendered in 26 spontaneous expressive styles.","We illustrate the challenges and potentials of this dataset with an expressive resynthesis benchmark where the task is to encode the input in low-bitrate units and resynthesize it in a target voice while preserving content and style.","We evaluate resynthesis quality with automatic metrics for different self-supervised discrete encoders, and explore tradeoffs between quality, bitrate and invariance to speaker and style.","All the dataset, evaluation metrics and baseline models are open source"],"url":"http://arxiv.org/abs/2308.05725v1"}
{"created":"2023-08-10 17:39:51","title":"Optimizing Performance of Feedforward and Convolutional Neural Networks through Dynamic Activation Functions","abstract":"Deep learning training training algorithms are a huge success in recent years in many fields including speech, text,image video etc. Deeper and deeper layers are proposed with huge success with resnet structures having around 152 layers. Shallow convolution neural networks(CNN's) are still an active research, where some phenomena are still unexplained. Activation functions used in the network are of utmost importance, as they provide non linearity to the networks. Relu's are the most commonly used activation function.We show a complex piece-wise linear(PWL) activation in the hidden layer. We show that these PWL activations work much better than relu activations in our networks for convolution neural networks and multilayer perceptrons. Result comparison in PyTorch for shallow and deep CNNs are given to further strengthen our case.","sentences":["Deep learning training training algorithms are a huge success in recent years in many fields including speech, text,image video etc.","Deeper and deeper layers are proposed with huge success with resnet structures having around 152 layers.","Shallow convolution neural networks(CNN's) are still an active research, where some phenomena are still unexplained.","Activation functions used in the network are of utmost importance, as they provide non linearity to the networks.","Relu's are the most commonly used activation function.","We show a complex piece-wise linear(PWL) activation in the hidden layer.","We show that these PWL activations work much better than relu activations in our networks for convolution neural networks and multilayer perceptrons.","Result comparison in PyTorch for shallow and deep CNNs are given to further strengthen our case."],"url":"http://arxiv.org/abs/2308.05724v1"}
{"created":"2023-08-10 17:37:49","title":"Deformable Mixer Transformer with Gating for Multi-Task Learning of Dense Prediction","abstract":"CNNs and Transformers have their own advantages and both have been widely used for dense prediction in multi-task learning (MTL). Most of the current studies on MTL solely rely on CNN or Transformer. In this work, we present a novel MTL model by combining both merits of deformable CNN and query-based Transformer with shared gating for multi-task learning of dense prediction. This combination may offer a simple and efficient solution owing to its powerful and flexible task-specific learning and advantages of lower cost, less complexity and smaller parameters than the traditional MTL methods. We introduce deformable mixer Transformer with gating (DeMTG), a simple and effective encoder-decoder architecture up-to-date that incorporates the convolution and attention mechanism in a unified network for MTL. It is exquisitely designed to use advantages of each block, and provide deformable and comprehensive features for all tasks from local and global perspective. First, the deformable mixer encoder contains two types of operators: the channel-aware mixing operator leveraged to allow communication among different channels, and the spatial-aware deformable operator with deformable convolution applied to efficiently sample more informative spatial locations. Second, the task-aware gating transformer decoder is used to perform the task-specific predictions, in which task interaction block integrated with self-attention is applied to capture task interaction features, and the task query block integrated with gating attention is leveraged to select corresponding task-specific features. Further, the experiment results demonstrate that the proposed DeMTG uses fewer GFLOPs and significantly outperforms current Transformer-based and CNN-based competitive models on a variety of metrics on three dense prediction datasets. Our code and models are available at https://github.com/yangyangxu0/DeMTG.","sentences":["CNNs and Transformers have their own advantages and both have been widely used for dense prediction in multi-task learning (MTL).","Most of the current studies on MTL solely rely on CNN or Transformer.","In this work, we present a novel MTL model by combining both merits of deformable CNN and query-based Transformer with shared gating for multi-task learning of dense prediction.","This combination may offer a simple and efficient solution owing to its powerful and flexible task-specific learning and advantages of lower cost, less complexity and smaller parameters than the traditional MTL methods.","We introduce deformable mixer Transformer with gating (DeMTG), a simple and effective encoder-decoder architecture up-to-date that incorporates the convolution and attention mechanism in a unified network for MTL.","It is exquisitely designed to use advantages of each block, and provide deformable and comprehensive features for all tasks from local and global perspective.","First, the deformable mixer encoder contains two types of operators: the channel-aware mixing operator leveraged to allow communication among different channels, and the spatial-aware deformable operator with deformable convolution applied to efficiently sample more informative spatial locations.","Second, the task-aware gating transformer decoder is used to perform the task-specific predictions, in which task interaction block integrated with self-attention is applied to capture task interaction features, and the task query block integrated with gating attention is leveraged to select corresponding task-specific features.","Further, the experiment results demonstrate that the proposed DeMTG uses fewer GFLOPs and significantly outperforms current Transformer-based and CNN-based competitive models on a variety of metrics on three dense prediction datasets.","Our code and models are available at https://github.com/yangyangxu0/DeMTG."],"url":"http://arxiv.org/abs/2308.05721v1"}
{"created":"2023-08-10 17:22:28","title":"Testing GPT-4 with Wolfram Alpha and Code Interpreter plug-ins on math and science problems","abstract":"This report describes a test of the large language model GPT-4 with the Wolfram Alpha and the Code Interpreter plug-ins on 105 original problems in science and math, at the high school and college levels, carried out in June-August 2023. Our tests suggest that the plug-ins significantly enhance GPT's ability to solve these problems. Having said that, there are still often \"interface\" failures; that is, GPT often has trouble formulating problems in a way that elicits useful answers from the plug-ins. Fixing these interface failures seems like a central challenge in making GPT a reliable tool for college-level calculation problems.","sentences":["This report describes a test of the large language model GPT-4 with the Wolfram Alpha and the Code Interpreter plug-ins on 105 original problems in science and math, at the high school and college levels, carried out in June-August 2023.","Our tests suggest that the plug-ins significantly enhance GPT's ability to solve these problems.","Having said that, there are still often \"interface\" failures; that is, GPT often has trouble formulating problems in a way that elicits useful answers from the plug-ins.","Fixing these interface failures seems like a central challenge in making GPT a reliable tool for college-level calculation problems."],"url":"http://arxiv.org/abs/2308.05713v1"}
{"created":"2023-08-10 17:20:02","title":"A Comparison of Classical and Deep Reinforcement Learning Methods for HVAC Control","abstract":"Reinforcement learning (RL) is a promising approach for optimizing HVAC control. RL offers a framework for improving system performance, reducing energy consumption, and enhancing cost efficiency. We benchmark two popular classical and deep RL methods (Q-Learning and Deep-Q-Networks) across multiple HVAC environments and explore the practical consideration of model hyper-parameter selection and reward tuning. The findings provide insight for configuring RL agents in HVAC systems, promoting energy-efficient and cost-effective operation.","sentences":["Reinforcement learning (RL) is a promising approach for optimizing HVAC control.","RL offers a framework for improving system performance, reducing energy consumption, and enhancing cost efficiency.","We benchmark two popular classical and deep RL methods (Q-Learning and Deep-Q-Networks) across multiple HVAC environments and explore the practical consideration of model hyper-parameter selection and reward tuning.","The findings provide insight for configuring RL agents in HVAC systems, promoting energy-efficient and cost-effective operation."],"url":"http://arxiv.org/abs/2308.05711v1"}
{"created":"2023-08-10 17:18:25","title":"A Mathematical Foundation for the Spatial Uncertainty of Critical Points in Probabilistic Scalar Fields","abstract":"Critical points mark locations in the domain where the level-set topology of a scalar function undergoes fundamental changes and thus indicate potentially interesting features in the data. Established methods exist to locate and relate such points in a deterministic setting, but it is less well understood how the concept of critical points can be extended to the analysis of uncertain data. Most methods for this task aim at finding likely locations of critical points or estimate the probability of their occurrence locally but do not indicate if critical points at potentially different locations in different realizations of a stochastic process are manifestations of the same feature, which is required to characterize the spatial uncertainty of critical points. Previous work on relating critical points across different realizations reported challenges for interpreting the resulting spatial distribution of critical points but did not investigate the causes. In this work, we provide a mathematical formulation of the problem of finding critical points with spatial uncertainty and computing their spatial distribution, which leads us to the notion of uncertain critical points. We analyze the theoretical properties of these structures and highlight connections to existing works for special classes of uncertain fields. We derive conditions under which well-interpretable results can be obtained and discuss the implications of those restrictions for the field of visualization. We demonstrate that the discussed limitations are not purely academic but also arise in real-world data.","sentences":["Critical points mark locations in the domain where the level-set topology of a scalar function undergoes fundamental changes and thus indicate potentially interesting features in the data.","Established methods exist to locate and relate such points in a deterministic setting, but it is less well understood how the concept of critical points can be extended to the analysis of uncertain data.","Most methods for this task aim at finding likely locations of critical points or estimate the probability of their occurrence locally but do not indicate if critical points at potentially different locations in different realizations of a stochastic process are manifestations of the same feature, which is required to characterize the spatial uncertainty of critical points.","Previous work on relating critical points across different realizations reported challenges for interpreting the resulting spatial distribution of critical points but did not investigate the causes.","In this work, we provide a mathematical formulation of the problem of finding critical points with spatial uncertainty and computing their spatial distribution, which leads us to the notion of uncertain critical points.","We analyze the theoretical properties of these structures and highlight connections to existing works for special classes of uncertain fields.","We derive conditions under which well-interpretable results can be obtained and discuss the implications of those restrictions for the field of visualization.","We demonstrate that the discussed limitations are not purely academic but also arise in real-world data."],"url":"http://arxiv.org/abs/2308.05710v1"}
{"created":"2023-08-10 17:14:07","title":"Shadow Datasets, New challenging datasets for Causal Representation Learning","abstract":"Discovering causal relations among semantic factors is an emergent topic in representation learning. Most causal representation learning (CRL) methods are fully supervised, which is impractical due to costly labeling. To resolve this restriction, weakly supervised CRL methods were introduced. To evaluate CRL performance, four existing datasets, Pendulum, Flow, CelebA(BEARD) and CelebA(SMILE), are utilized. However, existing CRL datasets are limited to simple graphs with few generative factors. Thus we propose two new datasets with a larger number of diverse generative factors and more sophisticated causal graphs. In addition, current real datasets, CelebA(BEARD) and CelebA(SMILE), the originally proposed causal graphs are not aligned with the dataset distributions. Thus, we propose modifications to them.","sentences":["Discovering causal relations among semantic factors is an emergent topic in representation learning.","Most causal representation learning (CRL) methods are fully supervised, which is impractical due to costly labeling.","To resolve this restriction, weakly supervised CRL methods were introduced.","To evaluate CRL performance, four existing datasets, Pendulum, Flow, CelebA(BEARD) and CelebA(SMILE), are utilized.","However, existing CRL datasets are limited to simple graphs with few generative factors.","Thus we propose two new datasets with a larger number of diverse generative factors and more sophisticated causal graphs.","In addition, current real datasets, CelebA(BEARD) and CelebA(SMILE), the originally proposed causal graphs are not aligned with the dataset distributions.","Thus, we propose modifications to them."],"url":"http://arxiv.org/abs/2308.05707v1"}
{"created":"2023-08-10 17:04:51","title":"Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving","abstract":"In recent years there have been remarkable advancements in autonomous driving. While autonomous vehicles demonstrate high performance in closed-set conditions, they encounter difficulties when confronted with unexpected situations. At the same time, world models emerged in the field of model-based reinforcement learning as a way to enable agents to predict the future depending on potential actions. This led to outstanding results in sparse reward and complex control tasks. This work provides an overview of how world models can be leveraged to perform anomaly detection in the domain of autonomous driving. We provide a characterization of world models and relate individual components to previous works in anomaly detection to facilitate further research in the field.","sentences":["In recent years there have been remarkable advancements in autonomous driving.","While autonomous vehicles demonstrate high performance in closed-set conditions, they encounter difficulties when confronted with unexpected situations.","At the same time, world models emerged in the field of model-based reinforcement learning as a way to enable agents to predict the future depending on potential actions.","This led to outstanding results in sparse reward and complex control tasks.","This work provides an overview of how world models can be leveraged to perform anomaly detection in the domain of autonomous driving.","We provide a characterization of world models and relate individual components to previous works in anomaly detection to facilitate further research in the field."],"url":"http://arxiv.org/abs/2308.05701v1"}
{"created":"2023-08-10 17:04:12","title":"The Privacy-Value-App Relationship and the Value-Centered Privacy Assistant","abstract":"Many of us make quick decisions that affect our data privacy on our smartphones without due consideration of our values. One such decision point is establishing whether to download a smartphone app or not. In this work, we aim to better understand the relationship between our values, our privacy preferences, and our app choices, as well as explore the effectiveness of a smartphone value-centered privacy assistant (VcPA) at promoting value-centered app selection. To do this, we conducted a mixed-methods study that involved two phases. The first was an online survey of 273 smartphone user's values and privacy preferences when considering whether to download one of two apps (Lose It! and OpenLitterMap). Our results suggest that values and privacy preferences are related in an app or context-dependent manner. The second phase was testing the VcPA with 77 users in a synthetic Mock App Store setting. We established usability of a VcPA, with the VcPA helping some users more than others with selecting apps consistent with their selected value profile. Future qualitative and context-specific explorations of user perspectives could contribute to adequately capturing the specific role of values for privacy decision-making and improving the VcPA.","sentences":["Many of us make quick decisions that affect our data privacy on our smartphones without due consideration of our values.","One such decision point is establishing whether to download a smartphone app or not.","In this work, we aim to better understand the relationship between our values, our privacy preferences, and our app choices, as well as explore the effectiveness of a smartphone value-centered privacy assistant (VcPA) at promoting value-centered app selection.","To do this, we conducted a mixed-methods study that involved two phases.","The first was an online survey of 273 smartphone user's values and privacy preferences when considering whether to download one of two apps (Lose It! and OpenLitterMap).","Our results suggest that values and privacy preferences are related in an app or context-dependent manner.","The second phase was testing the VcPA with 77 users in a synthetic Mock App Store setting.","We established usability of a VcPA, with the VcPA helping some users more than others with selecting apps consistent with their selected value profile.","Future qualitative and context-specific explorations of user perspectives could contribute to adequately capturing the specific role of values for privacy decision-making and improving the VcPA."],"url":"http://arxiv.org/abs/2308.05700v1"}
{"created":"2023-08-10 17:00:46","title":"MobiScout: A Scalable Cloud-Based Driving and Activity Monitoring Platform Featuring an IOS App and a WatchOS Extension","abstract":"MobiScout is an iOS software that monitors users' driving habits and physiological conditions while on the road. The Mobiscout app was created to provide a low-cost next-generation data collection and analysis solution for naturalistic driving studies. MobiScout collects real-time data, including physiological information from drivers in their normal driving conditions using sensors and cameras on mobile phones, smartwatches, and Bluetooth-enabled OBD equipment. The MobiScout software captures vehicle and driving data, including speed, braking, pulse rate, and acceleration, while the phone's camera captures everything inside and outside the car. Data captured can be streamed to cloud storage in real-time or persisted in local storage in WIFI dead zones. The information gathered will be studied further to better understand typical traffic behavior, performance, surroundings, and driving context among drivers.","sentences":["MobiScout is an iOS software that monitors users' driving habits and physiological conditions while on the road.","The Mobiscout app was created to provide a low-cost next-generation data collection and analysis solution for naturalistic driving studies.","MobiScout collects real-time data, including physiological information from drivers in their normal driving conditions using sensors and cameras on mobile phones, smartwatches, and Bluetooth-enabled OBD equipment.","The MobiScout software captures vehicle and driving data, including speed, braking, pulse rate, and acceleration, while the phone's camera captures everything inside and outside the car.","Data captured can be streamed to cloud storage in real-time or persisted in local storage in WIFI dead zones.","The information gathered will be studied further to better understand typical traffic behavior, performance, surroundings, and driving context among drivers."],"url":"http://arxiv.org/abs/2308.05698v1"}
{"created":"2023-08-10 16:59:36","title":"SSLRec: A Self-Supervised Learning Library for Recommendation","abstract":"Self-supervised learning (SSL) has gained significant interest in recent years as a solution to address the challenges posed by sparse and noisy data in recommender systems. Despite the growing number of SSL algorithms designed to provide state-of-the-art performance in various recommendation scenarios (e.g., graph collaborative filtering, sequential recommendation, social recommendation, KG-enhanced recommendation), there is still a lack of unified frameworks that integrate recommendation algorithms across different domains. Such a framework could serve as the cornerstone for self-supervised recommendation algorithms, unifying the validation of existing methods and driving the design of new ones. To address this gap, we introduce SSLRec, a novel benchmark platform that provides a standardized, flexible, and comprehensive framework for evaluating various SSL-enhanced recommenders. The SSLRec library features a modular architecture that allows users to easily evaluate state-of-the-art models and a complete set of data augmentation and self-supervised toolkits to help create SSL recommendation models with specific needs. Furthermore, SSLRec simplifies the process of training and evaluating different recommendation models with consistent and fair settings. Our SSLRec platform covers a comprehensive set of state-of-the-art SSL-enhanced recommendation models across different scenarios, enabling researchers to evaluate these cutting-edge models and drive further innovation in the field. Our implemented SSLRec framework is available at the source code repository https://github.com/HKUDS/SSLRec.","sentences":["Self-supervised learning (SSL) has gained significant interest in recent years as a solution to address the challenges posed by sparse and noisy data in recommender systems.","Despite the growing number of SSL algorithms designed to provide state-of-the-art performance in various recommendation scenarios (e.g., graph collaborative filtering, sequential recommendation, social recommendation, KG-enhanced recommendation), there is still a lack of unified frameworks that integrate recommendation algorithms across different domains.","Such a framework could serve as the cornerstone for self-supervised recommendation algorithms, unifying the validation of existing methods and driving the design of new ones.","To address this gap, we introduce SSLRec, a novel benchmark platform that provides a standardized, flexible, and comprehensive framework for evaluating various SSL-enhanced recommenders.","The SSLRec library features a modular architecture that allows users to easily evaluate state-of-the-art models and a complete set of data augmentation and self-supervised toolkits to help create SSL recommendation models with specific needs.","Furthermore, SSLRec simplifies the process of training and evaluating different recommendation models with consistent and fair settings.","Our SSLRec platform covers a comprehensive set of state-of-the-art SSL-enhanced recommendation models across different scenarios, enabling researchers to evaluate these cutting-edge models and drive further innovation in the field.","Our implemented SSLRec framework is available at the source code repository https://github.com/HKUDS/SSLRec."],"url":"http://arxiv.org/abs/2308.05697v1"}
{"created":"2023-08-10 16:58:51","title":"A Preliminary Study of the Intrinsic Relationship between Complexity and Alignment","abstract":"Training large language models (LLMs) with open-domain instruction data has yielded remarkable success in aligning to end tasks and user preferences. Extensive research has highlighted that enhancing the quality and diversity of instruction data consistently improves performance. However, the impact of data complexity, as a crucial metric, remains relatively unexplored in three aspects: (1) scaling law, where the sustainability of performance improvements with increasing complexity is uncertain, (2) additional tokens, whether the improvement brought by complexity comes from introducing more training tokens, and (3) curriculum tuning, where the potential advantages of incorporating instructions ranging from easy to difficult are not yet fully understood. In this paper, we propose \\textit{tree-instruct} to systematically enhance the complexity of instruction data in a controllable manner. This approach adds a specified number of nodes into the instruction semantic tree, yielding new instruction data based on the modified tree. By adjusting the number of added nodes, we can control the difficulty level in the modified instruction data. Our preliminary experiments reveal the following insights: (1) Increasing complexity consistently leads to sustained performance improvements. For instance, using 1,000 instruction data and 10 nodes resulted in a substantial 24\\% increase in win rate. (2) Under the same token budget, a few complex instructions outperform diverse yet simple instructions. (3) Curriculum instruction tuning might not yield the anticipated results; focusing on increasing complexity appears to be the key.","sentences":["Training large language models (LLMs) with open-domain instruction data has yielded remarkable success in aligning to end tasks and user preferences.","Extensive research has highlighted that enhancing the quality and diversity of instruction data consistently improves performance.","However, the impact of data complexity, as a crucial metric, remains relatively unexplored in three aspects: (1) scaling law, where the sustainability of performance improvements with increasing complexity is uncertain, (2) additional tokens, whether the improvement brought by complexity comes from introducing more training tokens, and (3) curriculum tuning, where the potential advantages of incorporating instructions ranging from easy to difficult are not yet fully understood.","In this paper, we propose \\textit{tree-instruct} to systematically enhance the complexity of instruction data in a controllable manner.","This approach adds a specified number of nodes into the instruction semantic tree, yielding new instruction data based on the modified tree.","By adjusting the number of added nodes, we can control the difficulty level in the modified instruction data.","Our preliminary experiments reveal the following insights: (1) Increasing complexity consistently leads to sustained performance improvements.","For instance, using 1,000 instruction data and 10 nodes resulted in a substantial 24\\% increase in win rate.","(2) Under the same token budget, a few complex instructions outperform diverse yet simple instructions.","(3) Curriculum instruction tuning might not yield the anticipated results; focusing on increasing complexity appears to be the key."],"url":"http://arxiv.org/abs/2308.05696v1"}
{"created":"2023-08-10 16:57:14","title":"Masked Diffusion as Self-supervised Representation Learner","abstract":"Denoising diffusion probabilistic models have recently demonstrated state-of-the-art generative performance and been used as strong pixel-level representation learners. This paper decomposes the interrelation between the generative capability and representation learning ability inherent in diffusion models. We present masked diffusion model (MDM), a scalable self-supervised representation learner that substitutes the conventional additive Gaussian noise of traditional diffusion with a masking mechanism. Our proposed approach convincingly surpasses prior benchmarks, demonstrating remarkable advancements in both medical and natural image semantic segmentation tasks, particularly within the context of few-shot scenario.","sentences":["Denoising diffusion probabilistic models have recently demonstrated state-of-the-art generative performance and been used as strong pixel-level representation learners.","This paper decomposes the interrelation between the generative capability and representation learning ability inherent in diffusion models.","We present masked diffusion model (MDM), a scalable self-supervised representation learner that substitutes the conventional additive Gaussian noise of traditional diffusion with a masking mechanism.","Our proposed approach convincingly surpasses prior benchmarks, demonstrating remarkable advancements in both medical and natural image semantic segmentation tasks, particularly within the context of few-shot scenario."],"url":"http://arxiv.org/abs/2308.05695v1"}
{"created":"2023-08-10 16:54:12","title":"Limitations of Game Comonads via Homomorphism Indistinguishability","abstract":"Abramsky, Dawar, and Wang (2017) introduced the pebbling comonad for k-variable counting logic and thereby initiated a line of work that imports category theoretic machinery to finite model theory. Such game comonads have been developed for various logics, yielding characterisations of logical equivalences in terms of isomorphisms in the associated co-Kleisli category. We show a first limitation of this approach by studying linear-algebraic logic, which is strictly more expressive than first-order counting logic and whose k-variable logical equivalence relations are known as invertible-map equivalences (IM). We show that there exists no finite-rank comonad on the category of graphs whose co-Kleisli isomorphisms characterise IM-equivalence, answering a question of \\'O Conghaile and Dawar (CSL 2021). We obtain this result by ruling out a characterisation of IM-equivalence in terms of homomorphism indistinguishability and employing the Lov\\'asz-type theorems for game comonads established by Dawar, Jakl, and Reggio (2021). Two graphs are homomorphism indistinguishable over a graph class if they admit the same number of homomorphisms from every graph in the class. The IM-equivalences cannot be characterised in this way, neither when counting homomorphisms in the natural numbers, nor in any finite prime field.","sentences":["Abramsky, Dawar, and Wang (2017) introduced the pebbling comonad for k-variable counting logic and thereby initiated a line of work that imports category theoretic machinery to finite model theory.","Such game comonads have been developed for various logics, yielding characterisations of logical equivalences in terms of isomorphisms in the associated co-Kleisli category.","We show a first limitation of this approach by studying linear-algebraic logic, which is strictly more expressive than first-order counting logic and whose k-variable logical equivalence relations are known as invertible-map equivalences (IM).","We show that there exists no finite-rank comonad on the category of graphs whose co-Kleisli isomorphisms characterise IM-equivalence, answering a question of \\'O Conghaile and Dawar (CSL 2021).","We obtain this result by ruling out a characterisation of IM-equivalence in terms of homomorphism indistinguishability and employing the Lov\\'asz-type theorems for game comonads established by Dawar, Jakl, and Reggio (2021).","Two graphs are homomorphism indistinguishable over a graph class if they admit the same number of homomorphisms from every graph in the class.","The IM-equivalences cannot be characterised in this way, neither when counting homomorphisms in the natural numbers, nor in any finite prime field."],"url":"http://arxiv.org/abs/2308.05693v1"}
{"created":"2023-08-10 16:48:57","title":"Isolated Scheduling for Distributed Training Tasks in GPU Clusters","abstract":"Distributed machine learning (DML) technology makes it possible to train large neural networks in a reasonable amount of time. Meanwhile, as the computing power grows much faster than network capacity, network communication has gradually become the bottleneck of DML. Current multi-tenant GPU clusters face network contention caused by hash-collision problem which not only further increases the overhead of communication, but also creates unfairness and affects the user experience. In this paper, we firstly analyse how network contention affects the training time in a cluster with 32 NVIDIA V100 GPUs. Then we propose vClos to eliminate network contention by jointly optimizing network topology and communication pattern in distributed training. An OCS-vClos which introduces a layer of optical circuit switches (OCSs) in the leaf-spine network is also proposed to reduce potential network resource fragmentation caused by resource allocation strategy in vClos. Testbed experiments and real-trace-based large-scale simulations are conducted to demonstrate the superiority of vClos over existing network resource scheduling strategies.","sentences":["Distributed machine learning (DML) technology makes it possible to train large neural networks in a reasonable amount of time.","Meanwhile, as the computing power grows much faster than network capacity, network communication has gradually become the bottleneck of DML.","Current multi-tenant GPU clusters face network contention caused by hash-collision problem which not only further increases the overhead of communication, but also creates unfairness and affects the user experience.","In this paper, we firstly analyse how network contention affects the training time in a cluster with 32 NVIDIA V100 GPUs.","Then we propose vClos to eliminate network contention by jointly optimizing network topology and communication pattern in distributed training.","An OCS-vClos which introduces a layer of optical circuit switches (OCSs) in the leaf-spine network is also proposed to reduce potential network resource fragmentation caused by resource allocation strategy in vClos.","Testbed experiments and real-trace-based large-scale simulations are conducted to demonstrate the superiority of vClos over existing network resource scheduling strategies."],"url":"http://arxiv.org/abs/2308.05692v1"}
{"created":"2023-08-10 16:34:20","title":"Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition with Skeleton-Motion-Informed Gradient","abstract":"Recently, methods for skeleton-based human activity recognition have been shown to be vulnerable to adversarial attacks. However, these attack methods require either the full knowledge of the victim (i.e. white-box attacks), access to training data (i.e. transfer-based attacks) or frequent model queries (i.e. black-box attacks). All their requirements are highly restrictive, raising the question of how detrimental the vulnerability is. In this paper, we show that the vulnerability indeed exists. To this end, we consider a new attack task: the attacker has no access to the victim model or the training data or labels, where we coin the term hard no-box attack. Specifically, we first learn a motion manifold where we define an adversarial loss to compute a new gradient for the attack, named skeleton-motion-informed (SMI) gradient. Our gradient contains information of the motion dynamics, which is different from existing gradient-based attack methods that compute the loss gradient assuming each dimension in the data is independent. The SMI gradient can augment many gradient-based attack methods, leading to a new family of no-box attack methods. Extensive evaluation and comparison show that our method imposes a real threat to existing classifiers. They also show that the SMI gradient improves the transferability and imperceptibility of adversarial samples in both no-box and transfer-based black-box settings.","sentences":["Recently, methods for skeleton-based human activity recognition have been shown to be vulnerable to adversarial attacks.","However, these attack methods require either the full knowledge of the victim (i.e. white-box attacks), access to training data (i.e. transfer-based attacks) or frequent model queries (i.e. black-box attacks).","All their requirements are highly restrictive, raising the question of how detrimental the vulnerability is.","In this paper, we show that the vulnerability indeed exists.","To this end, we consider a new attack task: the attacker has no access to the victim model or the training data or labels, where we coin the term hard no-box attack.","Specifically, we first learn a motion manifold where we define an adversarial loss to compute a new gradient for the attack, named skeleton-motion-informed (SMI) gradient.","Our gradient contains information of the motion dynamics, which is different from existing gradient-based attack methods that compute the loss gradient assuming each dimension in the data is independent.","The SMI gradient can augment many gradient-based attack methods, leading to a new family of no-box attack methods.","Extensive evaluation and comparison show that our method imposes a real threat to existing classifiers.","They also show that the SMI gradient improves the transferability and imperceptibility of adversarial samples in both no-box and transfer-based black-box settings."],"url":"http://arxiv.org/abs/2308.05681v1"}
{"created":"2023-08-10 16:33:17","title":"Finding Already Debunked Narratives via Multistage Retrieval: Enabling Cross-Lingual, Cross-Dataset and Zero-Shot Learning","abstract":"The task of retrieving already debunked narratives aims to detect stories that have already been fact-checked. The successful detection of claims that have already been debunked not only reduces the manual efforts of professional fact-checkers but can also contribute to slowing the spread of misinformation. Mainly due to the lack of readily available data, this is an understudied problem, particularly when considering the cross-lingual task, i.e. the retrieval of fact-checking articles in a language different from the language of the online post being checked. This paper fills this gap by (i) creating a novel dataset to enable research on cross-lingual retrieval of already debunked narratives, using tweets as queries to a database of fact-checking articles; (ii) presenting an extensive experiment to benchmark fine-tuned and off-the-shelf multilingual pre-trained Transformer models for this task; and (iii) proposing a novel multistage framework that divides this cross-lingual debunk retrieval task into refinement and re-ranking stages. Results show that the task of cross-lingual retrieval of already debunked narratives is challenging and off-the-shelf Transformer models fail to outperform a strong lexical-based baseline (BM25). Nevertheless, our multistage retrieval framework is robust, outperforming BM25 in most scenarios and enabling cross-domain and zero-shot learning, without significantly harming the model's performance.","sentences":["The task of retrieving already debunked narratives aims to detect stories that have already been fact-checked.","The successful detection of claims that have already been debunked not only reduces the manual efforts of professional fact-checkers but can also contribute to slowing the spread of misinformation.","Mainly due to the lack of readily available data, this is an understudied problem, particularly when considering the cross-lingual task, i.e. the retrieval of fact-checking articles in a language different from the language of the online post being checked.","This paper fills this gap by (i) creating a novel dataset to enable research on cross-lingual retrieval of already debunked narratives, using tweets as queries to a database of fact-checking articles; (ii) presenting an extensive experiment to benchmark fine-tuned and off-the-shelf multilingual pre-trained Transformer models for this task; and (iii) proposing a novel multistage framework that divides this cross-lingual debunk retrieval task into refinement and re-ranking stages.","Results show that the task of cross-lingual retrieval of already debunked narratives is challenging and off-the-shelf Transformer models fail to outperform a strong lexical-based baseline (BM25).","Nevertheless, our multistage retrieval framework is robust, outperforming BM25 in most scenarios and enabling cross-domain and zero-shot learning, without significantly harming the model's performance."],"url":"http://arxiv.org/abs/2308.05680v1"}
{"created":"2023-08-10 16:22:58","title":"Algorithms for 3D Hilbert Encoding and Decoding","abstract":"This paper presents algorithms and pseudocode for encoding and decoding 3D Hilbert orderings.","sentences":["This paper presents algorithms and pseudocode for encoding and decoding 3D Hilbert orderings."],"url":"http://arxiv.org/abs/2308.05673v1"}
{"created":"2023-08-10 16:10:54","title":"2D3D-MATR: 2D-3D Matching Transformer for Detection-free Registration between Images and Point Clouds","abstract":"The commonly adopted detect-then-match approach to registration finds difficulties in the cross-modality cases due to the incompatible keypoint detection and inconsistent feature description. We propose, 2D3D-MATR, a detection-free method for accurate and robust registration between images and point clouds. Our method adopts a coarse-to-fine pipeline where it first computes coarse correspondences between downsampled patches of the input image and the point cloud and then extends them to form dense correspondences between pixels and points within the patch region. The coarse-level patch matching is based on transformer which jointly learns global contextual constraints with self-attention and cross-modality correlations with cross-attention. To resolve the scale ambiguity in patch matching, we construct a multi-scale pyramid for each image patch and learn to find for each point patch the best matching image patch at a proper resolution level. Extensive experiments on two public benchmarks demonstrate that 2D3D-MATR outperforms the previous state-of-the-art P2-Net by around $20$ percentage points on inlier ratio and over $10$ points on registration recall. Our code and models are available at \\url{https://github.com/minhaolee/2D3DMATR}.","sentences":["The commonly adopted detect-then-match approach to registration finds difficulties in the cross-modality cases due to the incompatible keypoint detection and inconsistent feature description.","We propose, 2D3D-MATR, a detection-free method for accurate and robust registration between images and point clouds.","Our method adopts a coarse-to-fine pipeline where it first computes coarse correspondences between downsampled patches of the input image and the point cloud and then extends them to form dense correspondences between pixels and points within the patch region.","The coarse-level patch matching is based on transformer which jointly learns global contextual constraints with self-attention and cross-modality correlations with cross-attention.","To resolve the scale ambiguity in patch matching, we construct a multi-scale pyramid for each image patch and learn to find for each point patch the best matching image patch at a proper resolution level.","Extensive experiments on two public benchmarks demonstrate that 2D3D-MATR outperforms the previous state-of-the-art P2-Net by around $20$ percentage points on inlier ratio and over $10$ points on registration recall.","Our code and models are available at \\url{https://github.com/minhaolee/2D3DMATR}."],"url":"http://arxiv.org/abs/2308.05667v1"}
{"created":"2023-08-10 16:06:10","title":"Exploring Deep Learning Approaches to Predict Person and Vehicle Trips: An Analysis of NHTS Data","abstract":"Modern transportation planning relies heavily on accurate predictions of person and vehicle trips. However, traditional planning models often fail to account for the intricacies and dynamics of travel behavior, leading to less-than-optimal accuracy in these predictions. This study explores the potential of deep learning techniques to transform the way we approach trip predictions, and ultimately, transportation planning. Utilizing a comprehensive dataset from the National Household Travel Survey (NHTS), we developed and trained a deep learning model for predicting person and vehicle trips. The proposed model leverages the vast amount of information in the NHTS data, capturing complex, non-linear relationships that were previously overlooked by traditional models. As a result, our deep learning model achieved an impressive accuracy of 98% for person trip prediction and 96% for vehicle trip estimation. This represents a significant improvement over the performances of traditional transportation planning models, thereby demonstrating the power of deep learning in this domain. The implications of this study extend beyond just more accurate predictions. By enhancing the accuracy and reliability of trip prediction models, planners can formulate more effective, data-driven transportation policies, infrastructure, and services. As such, our research underscores the need for the transportation planning field to embrace advanced techniques like deep learning. The detailed methodology, along with a thorough discussion of the results and their implications, are presented in the subsequent sections of this paper.","sentences":["Modern transportation planning relies heavily on accurate predictions of person and vehicle trips.","However, traditional planning models often fail to account for the intricacies and dynamics of travel behavior, leading to less-than-optimal accuracy in these predictions.","This study explores the potential of deep learning techniques to transform the way we approach trip predictions, and ultimately, transportation planning.","Utilizing a comprehensive dataset from the National Household Travel Survey (NHTS), we developed and trained a deep learning model for predicting person and vehicle trips.","The proposed model leverages the vast amount of information in the NHTS data, capturing complex, non-linear relationships that were previously overlooked by traditional models.","As a result, our deep learning model achieved an impressive accuracy of 98% for person trip prediction and 96% for vehicle trip estimation.","This represents a significant improvement over the performances of traditional transportation planning models, thereby demonstrating the power of deep learning in this domain.","The implications of this study extend beyond just more accurate predictions.","By enhancing the accuracy and reliability of trip prediction models, planners can formulate more effective, data-driven transportation policies, infrastructure, and services.","As such, our research underscores the need for the transportation planning field to embrace advanced techniques like deep learning.","The detailed methodology, along with a thorough discussion of the results and their implications, are presented in the subsequent sections of this paper."],"url":"http://arxiv.org/abs/2308.05665v1"}
{"created":"2023-08-10 15:58:28","title":"AD-CLIP: Adapting Domains in Prompt Space Using CLIP","abstract":"Although deep learning models have shown impressive performance on supervised learning tasks, they often struggle to generalize well when the training (source) and test (target) domains differ. Unsupervised domain adaptation (DA) has emerged as a popular solution to this problem. However, current DA techniques rely on visual backbones, which may lack semantic richness. Despite the potential of large-scale vision-language foundation models like CLIP, their effectiveness for DA has yet to be fully explored. To address this gap, we introduce AD-CLIP, a domain-agnostic prompt learning strategy for CLIP that aims to solve the DA problem in the prompt space. We leverage the frozen vision backbone of CLIP to extract both image style (domain) and content information, which we apply to learn prompt tokens. Our prompts are designed to be domain-invariant and class-generalizable, by conditioning prompt learning on image style and content features simultaneously. We use standard supervised contrastive learning in the source domain, while proposing an entropy minimization strategy to align domains in the embedding space given the target domain data. We also consider a scenario where only target domain samples are available during testing, without any source domain data, and propose a cross-domain style mapping network to hallucinate domain-agnostic tokens. Our extensive experiments on three benchmark DA datasets demonstrate the effectiveness of AD-CLIP compared to existing literature.","sentences":["Although deep learning models have shown impressive performance on supervised learning tasks, they often struggle to generalize well when the training (source) and test (target) domains differ.","Unsupervised domain adaptation (DA) has emerged as a popular solution to this problem.","However, current DA techniques rely on visual backbones, which may lack semantic richness.","Despite the potential of large-scale vision-language foundation models like CLIP, their effectiveness for DA has yet to be fully explored.","To address this gap, we introduce AD-CLIP, a domain-agnostic prompt learning strategy for CLIP that aims to solve the DA problem in the prompt space.","We leverage the frozen vision backbone of CLIP to extract both image style (domain) and content information, which we apply to learn prompt tokens.","Our prompts are designed to be domain-invariant and class-generalizable, by conditioning prompt learning on image style and content features simultaneously.","We use standard supervised contrastive learning in the source domain, while proposing an entropy minimization strategy to align domains in the embedding space given the target domain data.","We also consider a scenario where only target domain samples are available during testing, without any source domain data, and propose a cross-domain style mapping network to hallucinate domain-agnostic tokens.","Our extensive experiments on three benchmark DA datasets demonstrate the effectiveness of AD-CLIP compared to existing literature."],"url":"http://arxiv.org/abs/2308.05659v1"}
{"created":"2023-08-10 15:57:47","title":"Automatic Extraction of Relevant Road Infrastructure using Connected vehicle data and Deep Learning Model","abstract":"In today's rapidly evolving urban landscapes, efficient and accurate mapping of road infrastructure is critical for optimizing transportation systems, enhancing road safety, and improving the overall mobility experience for drivers and commuters. Yet, a formidable bottleneck obstructs progress - the laborious and time-intensive manual identification of intersections. Simply considering the shear number of intersections that need to be identified, and the labor hours required per intersection, the need for an automated solution becomes undeniable. To address this challenge, we propose a novel approach that leverages connected vehicle data and cutting-edge deep learning techniques. By employing geohashing to segment vehicle trajectories and then generating image representations of road segments, we utilize the YOLOv5 (You Only Look Once version 5) algorithm for accurate classification of both straight road segments and intersections. Experimental results demonstrate an impressive overall classification accuracy of 95%, with straight roads achieving a remarkable 97% F1 score and intersections reaching a 90% F1 score. This approach not only saves time and resources but also enables more frequent updates and a comprehensive understanding of the road network. Our research showcases the potential impact on traffic management, urban planning, and autonomous vehicle navigation systems. The fusion of connected vehicle data and deep learning models holds promise for a transformative shift in road infrastructure mapping, propelling us towards a smarter, safer, and more connected transportation ecosystem.","sentences":["In today's rapidly evolving urban landscapes, efficient and accurate mapping of road infrastructure is critical for optimizing transportation systems, enhancing road safety, and improving the overall mobility experience for drivers and commuters.","Yet, a formidable bottleneck obstructs progress - the laborious and time-intensive manual identification of intersections.","Simply considering the shear number of intersections that need to be identified, and the labor hours required per intersection, the need for an automated solution becomes undeniable.","To address this challenge, we propose a novel approach that leverages connected vehicle data and cutting-edge deep learning techniques.","By employing geohashing to segment vehicle trajectories and then generating image representations of road segments, we utilize the YOLOv5 (You Only Look Once version 5) algorithm for accurate classification of both straight road segments and intersections.","Experimental results demonstrate an impressive overall classification accuracy of 95%, with straight roads achieving a remarkable 97% F1 score and intersections reaching a 90% F1 score.","This approach not only saves time and resources but also enables more frequent updates and a comprehensive understanding of the road network.","Our research showcases the potential impact on traffic management, urban planning, and autonomous vehicle navigation systems.","The fusion of connected vehicle data and deep learning models holds promise for a transformative shift in road infrastructure mapping, propelling us towards a smarter, safer, and more connected transportation ecosystem."],"url":"http://arxiv.org/abs/2308.05658v1"}
{"created":"2023-08-10 15:51:02","title":"Effect of eHMI on pedestrian road crossing behavior in shared space with Automated Vehicles","abstract":"A shared space area is a low-speed urban area in which pedestrians, cyclists, and vehicles share the road, often relying on informal interaction rules and greatly expanding freedom of movement for pedestrians and cyclists. While shared space has the potential to improve pedestrian priority in urban areas, it presents unique challenges for pedestrian-AV interaction due to the absence of a clear right of way. The current study applied Virtual Reality (VR) experiments to investigate pedestrian-AV interaction in a shared space, with a particular focus on the impact of external human-machine interfaces (eHMIs) on pedestrian crossing behavior. Fifty-three participants took part in the VR experiment and three eHMI conditions were investigated: no eHMI, eHMI with a pedestrian sign on the windshield, and eHMI with a projected zebra crossing on the road. Data collected via VR and questionnaires were used for objective and subjective measures to understand pedestrian-AV interaction. The study revealed that the presence of eHMI had an impact on participants' gazing behavior but not on their crossing decisions. Additionally, participants had a positive user experience with the current VR setting and expressed a high level of trust and perceived safety during their interaction with the AV. These findings highlight the potential of utilizing VR to explore and understand pedestrian-AV interactions.","sentences":["A shared space area is a low-speed urban area in which pedestrians, cyclists, and vehicles share the road, often relying on informal interaction rules and greatly expanding freedom of movement for pedestrians and cyclists.","While shared space has the potential to improve pedestrian priority in urban areas, it presents unique challenges for pedestrian-AV interaction due to the absence of a clear right of way.","The current study applied Virtual Reality (VR) experiments to investigate pedestrian-AV interaction in a shared space, with a particular focus on the impact of external human-machine interfaces (eHMIs) on pedestrian crossing behavior.","Fifty-three participants took part in the VR experiment and three eHMI conditions were investigated: no eHMI, eHMI with a pedestrian sign on the windshield, and eHMI with a projected zebra crossing on the road.","Data collected via VR and questionnaires were used for objective and subjective measures to understand pedestrian-AV interaction.","The study revealed that the presence of eHMI had an impact on participants' gazing behavior but not on their crossing decisions.","Additionally, participants had a positive user experience with the current VR setting and expressed a high level of trust and perceived safety during their interaction with the AV.","These findings highlight the potential of utilizing VR to explore and understand pedestrian-AV interactions."],"url":"http://arxiv.org/abs/2308.05654v1"}
{"created":"2023-08-10 15:46:33","title":"ESBMC v7.3: Model Checking C++ Programs using Clang AST","abstract":"This paper introduces ESBMC v7.3, the latest Efficient SMT-Based Context-Bounded Model Checker version, which now incorporates a new clang-based C++ front-end. While the previous CPROVER-based front-end served well for handling C++03 programs, it encountered challenges keeping up with the evolving C++ language. As new language and library features were added in each C++ version, the limitations of the old front-end became apparent, leading to difficult-to-maintain code. Consequently, modern C++ programs were challenging to verify. To overcome this obstacle, we redeveloped the front-end, opting for a more robust approach using clang. The new front-end efficiently traverses the Abstract Syntax Tree (AST) in-memory using clang APIs and transforms each AST node into ESBMC's Intermediate Representation. Through extensive experimentation, our results demonstrate that ESBMC v7.3 with the new front-end significantly reduces parse and conversion errors, enabling successful verification of a wide range of C++ programs, thereby outperforming previous ESBMC versions.","sentences":["This paper introduces ESBMC v7.3, the latest Efficient SMT-Based Context-Bounded Model Checker version, which now incorporates a new clang-based C++ front-end.","While the previous CPROVER-based front-end served well for handling C++03 programs, it encountered challenges keeping up with the evolving C++ language.","As new language and library features were added in each C++ version, the limitations of the old front-end became apparent, leading to difficult-to-maintain code.","Consequently, modern C++ programs were challenging to verify.","To overcome this obstacle, we redeveloped the front-end, opting for a more robust approach using clang.","The new front-end efficiently traverses the Abstract Syntax Tree (AST) in-memory using clang APIs and transforms each AST node into ESBMC's Intermediate Representation.","Through extensive experimentation, our results demonstrate that ESBMC v7.3 with the new front-end significantly reduces parse and conversion errors, enabling successful verification of a wide range of C++ programs, thereby outperforming previous ESBMC versions."],"url":"http://arxiv.org/abs/2308.05649v1"}
{"created":"2023-08-10 15:45:45","title":"Counterfactual Cross-modality Reasoning for Weakly Supervised Video Moment Localization","abstract":"Video moment localization aims to retrieve the target segment of an untrimmed video according to the natural language query. Weakly supervised methods gains attention recently, as the precise temporal location of the target segment is not always available. However, one of the greatest challenges encountered by the weakly supervised method is implied in the mismatch between the video and language induced by the coarse temporal annotations. To refine the vision-language alignment, recent works contrast the cross-modality similarities driven by reconstructing masked queries between positive and negative video proposals. However, the reconstruction may be influenced by the latent spurious correlation between the unmasked and the masked parts, which distorts the restoring process and further degrades the efficacy of contrastive learning since the masked words are not completely reconstructed from the cross-modality knowledge. In this paper, we discover and mitigate this spurious correlation through a novel proposed counterfactual cross-modality reasoning method. Specifically, we first formulate query reconstruction as an aggregated causal effect of cross-modality and query knowledge. Then by introducing counterfactual cross-modality knowledge into this aggregation, the spurious impact of the unmasked part contributing to the reconstruction is explicitly modeled. Finally, by suppressing the unimodal effect of masked query, we can rectify the reconstructions of video proposals to perform reasonable contrastive learning. Extensive experimental evaluations demonstrate the effectiveness of our proposed method. The code is available at \\href{https://github.com/sLdZ0306/CCR}{https://github.com/sLdZ0306/CCR}.","sentences":["Video moment localization aims to retrieve the target segment of an untrimmed video according to the natural language query.","Weakly supervised methods gains attention recently, as the precise temporal location of the target segment is not always available.","However, one of the greatest challenges encountered by the weakly supervised method is implied in the mismatch between the video and language induced by the coarse temporal annotations.","To refine the vision-language alignment, recent works contrast the cross-modality similarities driven by reconstructing masked queries between positive and negative video proposals.","However, the reconstruction may be influenced by the latent spurious correlation between the unmasked and the masked parts, which distorts the restoring process and further degrades the efficacy of contrastive learning since the masked words are not completely reconstructed from the cross-modality knowledge.","In this paper, we discover and mitigate this spurious correlation through a novel proposed counterfactual cross-modality reasoning method.","Specifically, we first formulate query reconstruction as an aggregated causal effect of cross-modality and query knowledge.","Then by introducing counterfactual cross-modality knowledge into this aggregation, the spurious impact of the unmasked part contributing to the reconstruction is explicitly modeled.","Finally, by suppressing the unimodal effect of masked query, we can rectify the reconstructions of video proposals to perform reasonable contrastive learning.","Extensive experimental evaluations demonstrate the effectiveness of our proposed method.","The code is available at \\href{https://github.com/sLdZ0306/CCR}{https://github.com/sLdZ0306/CCR}."],"url":"http://arxiv.org/abs/2308.05648v1"}
{"created":"2023-08-10 15:43:46","title":"AST-MHSA : Code Summarization using Multi-Head Self-Attention","abstract":"Code summarization aims to generate concise natural language descriptions for source code. The prevailing approaches adopt transformer-based encoder-decoder architectures, where the Abstract Syntax Tree (AST) of the source code is utilized for encoding structural information. However, ASTs are much longer than the corresponding source code, and existing methods ignore this size constraint by directly feeding the entire linearized AST into the encoders. This simplistic approach makes it challenging to extract truly valuable dependency relations from the overlong input sequence and leads to significant computational overhead due to self-attention applied to all nodes in the AST.   To address this issue effectively and efficiently, we present a model, AST-MHSA that uses multi-head attention to extract the important semantic information from the AST. The model consists of two main components: an encoder and a decoder. The encoder takes as input the abstract syntax tree (AST) of the code and generates a sequence of hidden states. The decoder then takes these hidden states as input and generates a natural language summary of the code.   The multi-head attention mechanism allows the model to learn different representations of the input code, which can be combined to generate a more comprehensive summary. The model is trained on a dataset of code and summaries, and the parameters of the model are optimized to minimize the loss between the generated summaries and the ground-truth summaries.","sentences":["Code summarization aims to generate concise natural language descriptions for source code.","The prevailing approaches adopt transformer-based encoder-decoder architectures, where the Abstract Syntax Tree (AST) of the source code is utilized for encoding structural information.","However, ASTs are much longer than the corresponding source code, and existing methods ignore this size constraint by directly feeding the entire linearized AST into the encoders.","This simplistic approach makes it challenging to extract truly valuable dependency relations from the overlong input sequence and leads to significant computational overhead due to self-attention applied to all nodes in the AST.   ","To address this issue effectively and efficiently, we present a model, AST-MHSA that uses multi-head attention to extract the important semantic information from the AST.","The model consists of two main components: an encoder and a decoder.","The encoder takes as input the abstract syntax tree (AST) of the code and generates a sequence of hidden states.","The decoder then takes these hidden states as input and generates a natural language summary of the code.   ","The multi-head attention mechanism allows the model to learn different representations of the input code, which can be combined to generate a more comprehensive summary.","The model is trained on a dataset of code and summaries, and the parameters of the model are optimized to minimize the loss between the generated summaries and the ground-truth summaries."],"url":"http://arxiv.org/abs/2308.05646v1"}
{"created":"2023-08-10 15:37:33","title":"QTWTL: Quality Aware Time Window Temporal Logic for Performance Monitoring","abstract":"In various service-oriented applications such as distributed autonomous delivery, healthcare, tourism, transportation, and many others, where service agents need to perform serial and time-bounded tasks to achieve their goals, quality of service must constantly be assured. In addition to safety requirements, such agents also need to fulfill performance requirements in order to satisfy their quality of service. This paper proposes the novel quality-aware time window temporal logic (QTWTL) by extending the traditional time window temporal logic (TWTL) with two operators for counting and aggregation operations. We also propose offline runtime monitoring algorithms for the performance monitoring of QTWTL specifications. To analyze the feasibility and efficiency of our proposed approach, we generate a large number of traces using the New York City Taxi and Limousine Commission Trip Record data, formalize their performance requirements using QTWTL, and monitor them using the proposed algorithms. The obtained results show that the monitoring algorithm has a linear space and time complexity with respect to the number of traces monitored.","sentences":["In various service-oriented applications such as distributed autonomous delivery, healthcare, tourism, transportation, and many others, where service agents need to perform serial and time-bounded tasks to achieve their goals, quality of service must constantly be assured.","In addition to safety requirements, such agents also need to fulfill performance requirements in order to satisfy their quality of service.","This paper proposes the novel quality-aware time window temporal logic (QTWTL) by extending the traditional time window temporal logic (TWTL) with two operators for counting and aggregation operations.","We also propose offline runtime monitoring algorithms for the performance monitoring of QTWTL specifications.","To analyze the feasibility and efficiency of our proposed approach, we generate a large number of traces using the New York City Taxi and Limousine Commission Trip Record data, formalize their performance requirements using QTWTL, and monitor them using the proposed algorithms.","The obtained results show that the monitoring algorithm has a linear space and time complexity with respect to the number of traces monitored."],"url":"http://arxiv.org/abs/2308.05644v1"}
{"created":"2023-08-10 15:32:46","title":"A Comparative Visual Analytics Framework for Evaluating Evolutionary Processes in Multi-objective Optimization","abstract":"Evolutionary multi-objective optimization (EMO) algorithms have been demonstrated to be effective in solving multi-criteria decision-making problems. In real-world applications, analysts often employ several algorithms concurrently and compare their solution sets to gain insight into the characteristics of different algorithms and explore a broader range of feasible solutions. However, EMO algorithms are typically treated as black boxes, leading to difficulties in performing detailed analysis and comparisons between the internal evolutionary processes. Inspired by the successful application of visual analytics tools in explainable AI, we argue that interactive visualization can significantly enhance the comparative analysis between multiple EMO algorithms. In this paper, we present a visual analytics framework that enables the exploration and comparison of evolutionary processes in EMO algorithms. Guided by a literature review and expert interviews, the proposed framework addresses various analytical tasks and establishes a multi-faceted visualization design to support the comparative analysis of intermediate generations in the evolution as well as solution sets. We demonstrate the effectiveness of our framework through case studies on benchmarking and real-world multi-objective optimization problems to elucidate how analysts can leverage our framework to inspect and compare diverse algorithms.","sentences":["Evolutionary multi-objective optimization (EMO) algorithms have been demonstrated to be effective in solving multi-criteria decision-making problems.","In real-world applications, analysts often employ several algorithms concurrently and compare their solution sets to gain insight into the characteristics of different algorithms and explore a broader range of feasible solutions.","However, EMO algorithms are typically treated as black boxes, leading to difficulties in performing detailed analysis and comparisons between the internal evolutionary processes.","Inspired by the successful application of visual analytics tools in explainable AI, we argue that interactive visualization can significantly enhance the comparative analysis between multiple EMO algorithms.","In this paper, we present a visual analytics framework that enables the exploration and comparison of evolutionary processes in EMO algorithms.","Guided by a literature review and expert interviews, the proposed framework addresses various analytical tasks and establishes a multi-faceted visualization design to support the comparative analysis of intermediate generations in the evolution as well as solution sets.","We demonstrate the effectiveness of our framework through case studies on benchmarking and real-world multi-objective optimization problems to elucidate how analysts can leverage our framework to inspect and compare diverse algorithms."],"url":"http://arxiv.org/abs/2308.05640v1"}
{"created":"2023-08-10 15:27:59","title":"The Fast and the Private: Task-based Dataset Search","abstract":"Recent dataset search platforms use ML task-based utility measures rather than metadata-based keywords, to search large dataset corpora. Requesters provide an initial dataset, and the platform seeks additional datasets that augment -- join or union -- requester's dataset to most improve the model (e.g., linear regression) performance. Although effective, current task-based data searches are stymied by (1) high latency which deters users, (2) privacy concerns for regulatory standards, and (3) low data quality which provides low utility. We introduce Mileena, a fast, private, and high-quality task-based dataset search platform. At its heart, Mileena is built on pre-computed semi-ring sketches for efficient ML training and evaluation. Based on semi-ring, we develop a novel Factorized Privacy Mechanism that makes the search differentially private and scales to arbitrary corpus sizes and numbers of requests without major quality degradation. We also demonstrate the early promise in using LLM-based agents for automatic data transformation and applying semi-rings to support causal discovery and treatment effect estimation.","sentences":["Recent dataset search platforms use ML task-based utility measures rather than metadata-based keywords, to search large dataset corpora.","Requesters provide an initial dataset, and the platform seeks additional datasets that augment -- join or union -- requester's dataset to most improve the model (e.g., linear regression) performance.","Although effective, current task-based data searches are stymied by (1) high latency which deters users, (2) privacy concerns for regulatory standards, and (3) low data quality which provides low utility.","We introduce Mileena, a fast, private, and high-quality task-based dataset search platform.","At its heart, Mileena is built on pre-computed semi-ring sketches for efficient ML training and evaluation.","Based on semi-ring, we develop a novel Factorized Privacy Mechanism that makes the search differentially private and scales to arbitrary corpus sizes and numbers of requests without major quality degradation.","We also demonstrate the early promise in using LLM-based agents for automatic data transformation and applying semi-rings to support causal discovery and treatment effect estimation."],"url":"http://arxiv.org/abs/2308.05637v1"}
{"created":"2023-08-10 15:26:35","title":"A Homomorphic Encryption Framework for Privacy-Preserving Spiking Neural Networks","abstract":"Machine learning (ML) is widely used today, especially through deep neural networks (DNNs), however, increasing computational load and resource requirements have led to cloud-based solutions. To address this problem, a new generation of networks called Spiking Neural Networks (SNN) has emerged, which mimic the behavior of the human brain to improve efficiency and reduce energy consumption. These networks often process large amounts of sensitive information, such as confidential data, and thus privacy issues arise. Homomorphic encryption (HE) offers a solution, allowing calculations to be performed on encrypted data without decrypting it. This research compares traditional DNNs and SNNs using the Brakerski/Fan-Vercauteren (BFV) encryption scheme. The LeNet-5 model, a widely-used convolutional architecture, is used for both DNN and SNN models based on the LeNet-5 architecture, and the networks are trained and compared using the FashionMNIST dataset. The results show that SNNs using HE achieve up to 40% higher accuracy than DNNs for low values of the plaintext modulus t, although their execution time is longer due to their time-coding nature with multiple time-steps.","sentences":["Machine learning (ML) is widely used today, especially through deep neural networks (DNNs), however, increasing computational load and resource requirements have led to cloud-based solutions.","To address this problem, a new generation of networks called Spiking Neural Networks (SNN) has emerged, which mimic the behavior of the human brain to improve efficiency and reduce energy consumption.","These networks often process large amounts of sensitive information, such as confidential data, and thus privacy issues arise.","Homomorphic encryption (HE) offers a solution, allowing calculations to be performed on encrypted data without decrypting it.","This research compares traditional DNNs and SNNs using the Brakerski/Fan-Vercauteren (BFV) encryption scheme.","The LeNet-5 model, a widely-used convolutional architecture, is used for both DNN and SNN models based on the LeNet-5 architecture, and the networks are trained and compared using the FashionMNIST dataset.","The results show that SNNs using HE achieve up to 40% higher accuracy than DNNs for low values of the plaintext modulus t, although their execution time is longer due to their time-coding nature with multiple time-steps."],"url":"http://arxiv.org/abs/2308.05636v1"}
{"created":"2023-08-10 15:24:37","title":"Tracing the Influence of Predecessors on Trajectory Prediction","abstract":"In real-world traffic scenarios, agents such as pedestrians and car drivers often observe neighboring agents who exhibit similar behavior as examples and then mimic their actions to some extent in their own behavior. This information can serve as prior knowledge for trajectory prediction, which is unfortunately largely overlooked in current trajectory prediction models. This paper introduces a novel Predecessor-and-Successor (PnS) method that incorporates a predecessor tracing module to model the influence of predecessors (identified from concurrent neighboring agents) on the successor (target agent) within the same scene. The method utilizes the moving patterns of these predecessors to guide the predictor in trajectory prediction. PnS effectively aligns the motion encodings of the successor with multiple potential predecessors in a probabilistic manner, facilitating the decoding process. We demonstrate the effectiveness of PnS by integrating it into a graph-based predictor for pedestrian trajectory prediction on the ETH/UCY datasets, resulting in a new state-of-the-art performance. Furthermore, we replace the HD map-based scene-context module with our PnS method in a transformer-based predictor for vehicle trajectory prediction on the nuScenes dataset, showing that the predictor maintains good prediction performance even without relying on any map information.","sentences":["In real-world traffic scenarios, agents such as pedestrians and car drivers often observe neighboring agents who exhibit similar behavior as examples and then mimic their actions to some extent in their own behavior.","This information can serve as prior knowledge for trajectory prediction, which is unfortunately largely overlooked in current trajectory prediction models.","This paper introduces a novel Predecessor-and-Successor (PnS) method that incorporates a predecessor tracing module to model the influence of predecessors (identified from concurrent neighboring agents) on the successor (target agent) within the same scene.","The method utilizes the moving patterns of these predecessors to guide the predictor in trajectory prediction.","PnS effectively aligns the motion encodings of the successor with multiple potential predecessors in a probabilistic manner, facilitating the decoding process.","We demonstrate the effectiveness of PnS by integrating it into a graph-based predictor for pedestrian trajectory prediction on the ETH/UCY datasets, resulting in a new state-of-the-art performance.","Furthermore, we replace the HD map-based scene-context module with our PnS method in a transformer-based predictor for vehicle trajectory prediction on the nuScenes dataset, showing that the predictor maintains good prediction performance even without relying on any map information."],"url":"http://arxiv.org/abs/2308.05634v1"}
{"created":"2023-08-10 15:22:11","title":"IIHT: Medical Report Generation with Image-to-Indicator Hierarchical Transformer","abstract":"Automated medical report generation has become increasingly important in medical analysis. It can produce computer-aided diagnosis descriptions and thus significantly alleviate the doctors' work. Inspired by the huge success of neural machine translation and image captioning, various deep learning methods have been proposed for medical report generation. However, due to the inherent properties of medical data, including data imbalance and the length and correlation between report sequences, the generated reports by existing methods may exhibit linguistic fluency but lack adequate clinical accuracy. In this work, we propose an image-to-indicator hierarchical transformer (IIHT) framework for medical report generation. It consists of three modules, i.e., a classifier module, an indicator expansion module and a generator module. The classifier module first extracts image features from the input medical images and produces disease-related indicators with their corresponding states. The disease-related indicators are subsequently utilised as input for the indicator expansion module, incorporating the \"data-text-data\" strategy. The transformer-based generator then leverages these extracted features along with image features as auxiliary information to generate final reports. Furthermore, the proposed IIHT method is feasible for radiologists to modify disease indicators in real-world scenarios and integrate the operations into the indicator expansion module for fluent and accurate medical report generation. Extensive experiments and comparisons with state-of-the-art methods under various evaluation metrics demonstrate the great performance of the proposed method.","sentences":["Automated medical report generation has become increasingly important in medical analysis.","It can produce computer-aided diagnosis descriptions and thus significantly alleviate the doctors' work.","Inspired by the huge success of neural machine translation and image captioning, various deep learning methods have been proposed for medical report generation.","However, due to the inherent properties of medical data, including data imbalance and the length and correlation between report sequences, the generated reports by existing methods may exhibit linguistic fluency but lack adequate clinical accuracy.","In this work, we propose an image-to-indicator hierarchical transformer (IIHT) framework for medical report generation.","It consists of three modules, i.e., a classifier module, an indicator expansion module and a generator module.","The classifier module first extracts image features from the input medical images and produces disease-related indicators with their corresponding states.","The disease-related indicators are subsequently utilised as input for the indicator expansion module, incorporating the \"data-text-data\" strategy.","The transformer-based generator then leverages these extracted features along with image features as auxiliary information to generate final reports.","Furthermore, the proposed IIHT method is feasible for radiologists to modify disease indicators in real-world scenarios and integrate the operations into the indicator expansion module for fluent and accurate medical report generation.","Extensive experiments and comparisons with state-of-the-art methods under various evaluation metrics demonstrate the great performance of the proposed method."],"url":"http://arxiv.org/abs/2308.05633v1"}
{"created":"2023-08-10 15:18:16","title":"ReLU and Addition-based Gated RNN","abstract":"We replace the multiplication and sigmoid function of the conventional recurrent gate with addition and ReLU activation. This mechanism is designed to maintain long-term memory for sequence processing but at a reduced computational cost, thereby opening up for more efficient execution or larger models on restricted hardware. Recurrent Neural Networks (RNNs) with gating mechanisms such as LSTM and GRU have been widely successful in learning from sequential data due to their ability to capture long-term dependencies. Conventionally, the update based on current inputs and the previous state history is each multiplied with dynamic weights and combined to compute the next state. However, multiplication can be computationally expensive, especially for certain hardware architectures or alternative arithmetic systems such as homomorphic encryption. It is demonstrated that the novel gating mechanism can capture long-term dependencies for a standard synthetic sequence learning task while significantly reducing computational costs such that execution time is reduced by half on CPU and by one-third under encryption. Experimental results on handwritten text recognition tasks furthermore show that the proposed architecture can be trained to achieve comparable accuracy to conventional GRU and LSTM baselines. The gating mechanism introduced in this paper may enable privacy-preserving AI applications operating under homomorphic encryption by avoiding the multiplication of encrypted variables. It can also support quantization in (unencrypted) plaintext applications, with the potential for substantial performance gains since the addition-based formulation can avoid the expansion to double precision often required for multiplication.","sentences":["We replace the multiplication and sigmoid function of the conventional recurrent gate with addition and ReLU activation.","This mechanism is designed to maintain long-term memory for sequence processing but at a reduced computational cost, thereby opening up for more efficient execution or larger models on restricted hardware.","Recurrent Neural Networks (RNNs) with gating mechanisms such as LSTM and GRU have been widely successful in learning from sequential data due to their ability to capture long-term dependencies.","Conventionally, the update based on current inputs and the previous state history is each multiplied with dynamic weights and combined to compute the next state.","However, multiplication can be computationally expensive, especially for certain hardware architectures or alternative arithmetic systems such as homomorphic encryption.","It is demonstrated that the novel gating mechanism can capture long-term dependencies for a standard synthetic sequence learning task while significantly reducing computational costs such that execution time is reduced by half on CPU and by one-third under encryption.","Experimental results on handwritten text recognition tasks furthermore show that the proposed architecture can be trained to achieve comparable accuracy to conventional GRU and LSTM baselines.","The gating mechanism introduced in this paper may enable privacy-preserving AI applications operating under homomorphic encryption by avoiding the multiplication of encrypted variables.","It can also support quantization in (unencrypted) plaintext applications, with the potential for substantial performance gains since the addition-based formulation can avoid the expansion to double precision often required for multiplication."],"url":"http://arxiv.org/abs/2308.05629v1"}
{"created":"2023-08-10 15:15:26","title":"CoBaIR: A Python Library for Context-Based Intention Recognition in Human-Robot-Interaction","abstract":"Human-Robot Interaction (HRI) becomes more and more important in a world where robots integrate fast in all aspects of our lives but HRI applications depend massively on the utilized robotic system as well as the deployment environment and cultural differences. Because of these variable dependencies it is often not feasible to use a data-driven approach to train a model for human intent recognition. Expert systems have been proven to close this gap very efficiently. Furthermore, it is important to support understandability in HRI systems to establish trust in the system. To address the above-mentioned challenges in HRI we present an adaptable python library in which current state-of-the-art Models for context recognition can be integrated. For Context-Based Intention Recognition a two-layer Bayesian Network (BN) is used. The bayesian approach offers explainability and clarity in the creation of scenarios and is easily extendable with more modalities. Additionally, it can be used as an expert system if no data is available but can as well be fine-tuned when data becomes available.","sentences":["Human-Robot Interaction (HRI) becomes more and more important in a world where robots integrate fast in all aspects of our lives but HRI applications depend massively on the utilized robotic system as well as the deployment environment and cultural differences.","Because of these variable dependencies it is often not feasible to use a data-driven approach to train a model for human intent recognition.","Expert systems have been proven to close this gap very efficiently.","Furthermore, it is important to support understandability in HRI systems to establish trust in the system.","To address the above-mentioned challenges in HRI we present an adaptable python library in which current state-of-the-art Models for context recognition can be integrated.","For Context-Based Intention Recognition a two-layer Bayesian Network (BN) is used.","The bayesian approach offers explainability and clarity in the creation of scenarios and is easily extendable with more modalities.","Additionally, it can be used as an expert system if no data is available but can as well be fine-tuned when data becomes available."],"url":"http://arxiv.org/abs/2308.05627v1"}
{"created":"2023-08-10 15:10:08","title":"Normalized Gradients for All","abstract":"In this short note, I show how to adapt to H\\\"{o}lder smoothness using normalized gradients in a black-box way. Moreover, the bound will depend on a novel notion of local H\\\"{o}lder smoothness. The main idea directly comes from Levy [2017].","sentences":["In this short note, I show how to adapt to H\\\"{o}lder smoothness using normalized gradients in a black-box way.","Moreover, the bound will depend on a novel notion of local H\\\"{o}lder smoothness.","The main idea directly comes from Levy [2017]."],"url":"http://arxiv.org/abs/2308.05621v1"}
{"created":"2023-08-10 15:09:14","title":"A Robust and Rapidly Deployable Waypoint Navigation Architecture for Long-Duration Operations in GPS-Denied Environments","abstract":"For long-duration operations in GPS-denied environments, accurate and repeatable waypoint navigation is an essential capability. While simultaneous localization and mapping (SLAM) works well for single-session operations, repeated, multi-session operations require robots to navigate to the same spot(s) accurately and precisely each and every time. Localization and navigation errors can build up from one session to the next if they are not accounted for. Localization using a global reference map works well, but there are no publicly available packages for quickly building maps and navigating with them. We propose a new architecture using a combination of two publicly available packages with a newly released package to create a fully functional multi-session navigation system for ground vehicles. The system takes just a few hours from the beginning of the first manual scan to perform autonomous waypoint navigation.","sentences":["For long-duration operations in GPS-denied environments, accurate and repeatable waypoint navigation is an essential capability.","While simultaneous localization and mapping (SLAM) works well for single-session operations, repeated, multi-session operations require robots to navigate to the same spot(s) accurately and precisely each and every time.","Localization and navigation errors can build up from one session to the next if they are not accounted for.","Localization using a global reference map works well, but there are no publicly available packages for quickly building maps and navigating with them.","We propose a new architecture using a combination of two publicly available packages with a newly released package to create a fully functional multi-session navigation system for ground vehicles.","The system takes just a few hours from the beginning of the first manual scan to perform autonomous waypoint navigation."],"url":"http://arxiv.org/abs/2308.05620v1"}
{"created":"2023-08-10 15:01:52","title":"A Neural Network Based Choice Model for Assortment Optimization","abstract":"Discrete-choice models are used in economics, marketing and revenue management to predict customer purchase probabilities, say as a function of prices and other features of the offered assortment. While they have been shown to be expressive, capturing customer heterogeneity and behaviour, they are also hard to estimate, often based on many unobservables like utilities; and moreover, they still fail to capture many salient features of customer behaviour. A natural question then, given their success in other contexts, is if neural networks can eliminate the necessity of carefully building a context-dependent customer behaviour model and hand-coding and tuning the estimation. It is unclear however how one would incorporate assortment effects into such a neural network, and also how one would optimize the assortment with such a black-box generative model of choice probabilities. In this paper we investigate first whether a single neural network architecture can predict purchase probabilities for datasets from various contexts and generated under various models and assumptions. Next, we develop an assortment optimization formulation that is solvable by off-the-shelf integer programming solvers. We compare against a variety of benchmark discrete-choice models on simulated as well as real-world datasets, developing training tricks along the way to make the neural network prediction and subsequent optimization robust and comparable in performance to the alternates.","sentences":["Discrete-choice models are used in economics, marketing and revenue management to predict customer purchase probabilities, say as a function of prices and other features of the offered assortment.","While they have been shown to be expressive, capturing customer heterogeneity and behaviour, they are also hard to estimate, often based on many unobservables like utilities; and moreover, they still fail to capture many salient features of customer behaviour.","A natural question then, given their success in other contexts, is if neural networks can eliminate the necessity of carefully building a context-dependent customer behaviour model and hand-coding and tuning the estimation.","It is unclear however how one would incorporate assortment effects into such a neural network, and also how one would optimize the assortment with such a black-box generative model of choice probabilities.","In this paper we investigate first whether a single neural network architecture can predict purchase probabilities for datasets from various contexts and generated under various models and assumptions.","Next, we develop an assortment optimization formulation that is solvable by off-the-shelf integer programming solvers.","We compare against a variety of benchmark discrete-choice models on simulated as well as real-world datasets, developing training tricks along the way to make the neural network prediction and subsequent optimization robust and comparable in performance to the alternates."],"url":"http://arxiv.org/abs/2308.05617v1"}
{"created":"2023-08-10 14:54:21","title":"A Smart Robotic System for Industrial Plant Supervision","abstract":"In today's chemical production plants, human field operators perform frequent checks on the plant's integrity to guarantee high safety standards, and thus are possibly the first to encounter dangerous operating conditions. To alleviate their tasks of failure detection and monitoring by audio, visual, and olfactory perceptions, we present a robotic system that consists of an autonomously navigating robot integrated with various sensors and data processing. We aim to resemble the human sensing and interpretation capabilities of sight, smell, and hearing, for providing automated inspection. We evaluate our system extensively at a wastewater facility in full working conditions. Our results demonstrate that the system is able to robustly navigate a plant and to provide useful information about critical operating conditions.","sentences":["In today's chemical production plants, human field operators perform frequent checks on the plant's integrity to guarantee high safety standards, and thus are possibly the first to encounter dangerous operating conditions.","To alleviate their tasks of failure detection and monitoring by audio, visual, and olfactory perceptions, we present a robotic system that consists of an autonomously navigating robot integrated with various sensors and data processing.","We aim to resemble the human sensing and interpretation capabilities of sight, smell, and hearing, for providing automated inspection.","We evaluate our system extensively at a wastewater facility in full working conditions.","Our results demonstrate that the system is able to robustly navigate a plant and to provide useful information about critical operating conditions."],"url":"http://arxiv.org/abs/2308.05612v1"}
{"created":"2023-08-10 14:41:17","title":"LASIGE and UNICAGE solution to the NASA LitCoin NLP Competition","abstract":"Biomedical Natural Language Processing (NLP) tends to become cumbersome for most researchers, frequently due to the amount and heterogeneity of text to be processed. To address this challenge, the industry is continuously developing highly efficient tools and creating more flexible engineering solutions. This work presents the integration between industry data engineering solutions for efficient data processing and academic systems developed for Named Entity Recognition (LasigeUnicage\\_NER) and Relation Extraction (BiOnt). Our design reflects an integration of those components with external knowledge in the form of additional training data from other datasets and biomedical ontologies. We used this pipeline in the 2022 LitCoin NLP Challenge, where our team LasigeUnicage was awarded the 7th Prize out of approximately 200 participating teams, reflecting a successful collaboration between the academia (LASIGE) and the industry (Unicage). The software supporting this work is available at \\url{https://github.com/lasigeBioTM/Litcoin-Lasige_Unicage}.","sentences":["Biomedical Natural Language Processing (NLP) tends to become cumbersome for most researchers, frequently due to the amount and heterogeneity of text to be processed.","To address this challenge, the industry is continuously developing highly efficient tools and creating more flexible engineering solutions.","This work presents the integration between industry data engineering solutions for efficient data processing and academic systems developed for Named Entity Recognition (LasigeUnicage\\_NER) and Relation Extraction (BiOnt).","Our design reflects an integration of those components with external knowledge in the form of additional training data from other datasets and biomedical ontologies.","We used this pipeline in the 2022 LitCoin NLP Challenge, where our team LasigeUnicage was awarded the 7th Prize out of approximately 200 participating teams, reflecting a successful collaboration between the academia (LASIGE) and the industry (Unicage).","The software supporting this work is available at \\url{https://github.com/lasigeBioTM/Litcoin-Lasige_Unicage}."],"url":"http://arxiv.org/abs/2308.05609v1"}
{"created":"2023-08-10 14:32:18","title":"Self-Supervised Monocular Depth Estimation by Direction-aware Cumulative Convolution Network","abstract":"Monocular depth estimation is known as an ill-posed task in which objects in a 2D image usually do not contain sufficient information to predict their depth. Thus, it acts differently from other tasks (e.g., classification and segmentation) in many ways. In this paper, we find that self-supervised monocular depth estimation shows a direction sensitivity and environmental dependency in the feature representation. But the current backbones borrowed from other tasks pay less attention to handling different types of environmental information, limiting the overall depth accuracy. To bridge this gap, we propose a new Direction-aware Cumulative Convolution Network (DaCCN), which improves the depth feature representation in two aspects. First, we propose a direction-aware module, which can learn to adjust the feature extraction in each direction, facilitating the encoding of different types of information. Secondly, we design a new cumulative convolution to improve the efficiency for aggregating important environmental information. Experiments show that our method achieves significant improvements on three widely used benchmarks, KITTI, Cityscapes, and Make3D, setting a new state-of-the-art performance on the popular benchmarks with all three types of self-supervision.","sentences":["Monocular depth estimation is known as an ill-posed task in which objects in a 2D image usually do not contain sufficient information to predict their depth.","Thus, it acts differently from other tasks (e.g., classification and segmentation) in many ways.","In this paper, we find that self-supervised monocular depth estimation shows a direction sensitivity and environmental dependency in the feature representation.","But the current backbones borrowed from other tasks pay less attention to handling different types of environmental information, limiting the overall depth accuracy.","To bridge this gap, we propose a new Direction-aware Cumulative Convolution Network (DaCCN), which improves the depth feature representation in two aspects.","First, we propose a direction-aware module, which can learn to adjust the feature extraction in each direction, facilitating the encoding of different types of information.","Secondly, we design a new cumulative convolution to improve the efficiency for aggregating important environmental information.","Experiments show that our method achieves significant improvements on three widely used benchmarks, KITTI, Cityscapes, and Make3D, setting a new state-of-the-art performance on the popular benchmarks with all three types of self-supervision."],"url":"http://arxiv.org/abs/2308.05605v1"}
{"created":"2023-08-10 14:21:33","title":"Object Goal Navigation with Recursive Implicit Maps","abstract":"Object goal navigation aims to navigate an agent to locations of a given object category in unseen environments. Classical methods explicitly build maps of environments and require extensive engineering while lacking semantic information for object-oriented exploration. On the other hand, end-to-end learning methods alleviate manual map design and predict actions using implicit representations. Such methods, however, lack an explicit notion of geometry and may have limited ability to encode navigation history. In this work, we propose an implicit spatial map for object goal navigation. Our implicit map is recursively updated with new observations at each step using a transformer. To encourage spatial reasoning, we introduce auxiliary tasks and train our model to reconstruct explicit maps as well as to predict visual features, semantic labels and actions. Our method significantly outperforms the state of the art on the challenging MP3D dataset and generalizes well to the HM3D dataset. We successfully deploy our model on a real robot and achieve encouraging object goal navigation results in real scenes using only a few real-world demonstrations. Code, trained models and videos are available at \\url{https://www.di.ens.fr/willow/research/onav_rim/}.","sentences":["Object goal navigation aims to navigate an agent to locations of a given object category in unseen environments.","Classical methods explicitly build maps of environments and require extensive engineering while lacking semantic information for object-oriented exploration.","On the other hand, end-to-end learning methods alleviate manual map design and predict actions using implicit representations.","Such methods, however, lack an explicit notion of geometry and may have limited ability to encode navigation history.","In this work, we propose an implicit spatial map for object goal navigation.","Our implicit map is recursively updated with new observations at each step using a transformer.","To encourage spatial reasoning, we introduce auxiliary tasks and train our model to reconstruct explicit maps as well as to predict visual features, semantic labels and actions.","Our method significantly outperforms the state of the art on the challenging MP3D dataset and generalizes well to the HM3D dataset.","We successfully deploy our model on a real robot and achieve encouraging object goal navigation results in real scenes using only a few real-world demonstrations.","Code, trained models and videos are available at \\url{https://www.di.ens.fr/willow/research/onav_rim/}."],"url":"http://arxiv.org/abs/2308.05602v1"}
{"created":"2023-08-10 14:20:43","title":"Multi-graph Spatio-temporal Graph Convolutional Network for Traffic Flow Prediction","abstract":"Inter-city highway transportation is significant for urban life. As one of the key functions in intelligent transportation system (ITS), traffic evaluation always plays significant role nowadays, and daily traffic flow prediction still faces challenges at network-wide toll stations. On the one hand, the data imbalance in practice among various locations deteriorates the performance of prediction. On the other hand, complex correlative spatio-temporal factors cannot be comprehensively employed in long-term duration. In this paper, a prediction method is proposed for daily traffic flow in highway domain through spatio-temporal deep learning. In our method, data normalization strategy is used to deal with data imbalance, due to long-tail distribution of traffic flow at network-wide toll stations. And then, based on graph convolutional network, we construct networks in distinct semantics to capture spatio-temporal features. Beside that, meteorology and calendar features are used by our model in the full connection stage to extra external characteristics of traffic flow. By extensive experiments and case studies in one Chinese provincial highway, our method shows clear improvement in predictive accuracy than baselines and practical benefits in business.","sentences":["Inter-city highway transportation is significant for urban life.","As one of the key functions in intelligent transportation system (ITS), traffic evaluation always plays significant role nowadays, and daily traffic flow prediction still faces challenges at network-wide toll stations.","On the one hand, the data imbalance in practice among various locations deteriorates the performance of prediction.","On the other hand, complex correlative spatio-temporal factors cannot be comprehensively employed in long-term duration.","In this paper, a prediction method is proposed for daily traffic flow in highway domain through spatio-temporal deep learning.","In our method, data normalization strategy is used to deal with data imbalance, due to long-tail distribution of traffic flow at network-wide toll stations.","And then, based on graph convolutional network, we construct networks in distinct semantics to capture spatio-temporal features.","Beside that, meteorology and calendar features are used by our model in the full connection stage to extra external characteristics of traffic flow.","By extensive experiments and case studies in one Chinese provincial highway, our method shows clear improvement in predictive accuracy than baselines and practical benefits in business."],"url":"http://arxiv.org/abs/2308.05601v1"}
{"created":"2023-08-10 14:19:58","title":"NUPES : Non-Uniform Post-Training Quantization via Power Exponent Search","abstract":"Deep neural network (DNN) deployment has been confined to larger hardware devices due to their expensive computational requirements. This challenge has recently reached another scale with the emergence of large language models (LLMs). In order to reduce both their memory footprint and latency, a promising technique is quantization. It consists in converting floating point representations to low bit-width fixed point representations, usually by assuming a uniform mapping onto a regular grid. This process, referred to in the literature as uniform quantization, may however be ill-suited as most DNN weights and activations follow a bell-shaped distribution. This is even worse on LLMs whose weight distributions are known to exhibit large, high impact, outlier values. In this work, we propose an improvement over the most commonly adopted way to tackle this limitation in deep learning models quantization, namely, non-uniform quantization. NUPES leverages automorphisms to preserve the scalar multiplications. Such transformations are derived from power functions. However, the optimization of the exponent parameter and weight values remains a challenging and novel problem which could not be solved with previous post training optimization techniques which only learn to round up or down weight values in order to preserve the predictive function. We circumvent this limitation with a new paradigm: learning new quantized weights over the entire quantized space. Similarly, we enable the optimization of the power exponent, i.e. the optimization of the quantization operator itself during training by alleviating all the numerical instabilities. The resulting predictive function is compatible with integer-only low-bit inference. We show the ability of the method to achieve state-of-the-art compression rates in both, data-free and data-driven configurations.","sentences":["Deep neural network (DNN) deployment has been confined to larger hardware devices due to their expensive computational requirements.","This challenge has recently reached another scale with the emergence of large language models (LLMs).","In order to reduce both their memory footprint and latency, a promising technique is quantization.","It consists in converting floating point representations to low bit-width fixed point representations, usually by assuming a uniform mapping onto a regular grid.","This process, referred to in the literature as uniform quantization, may however be ill-suited as most DNN weights and activations follow a bell-shaped distribution.","This is even worse on LLMs whose weight distributions are known to exhibit large, high impact, outlier values.","In this work, we propose an improvement over the most commonly adopted way to tackle this limitation in deep learning models quantization, namely, non-uniform quantization.","NUPES leverages automorphisms to preserve the scalar multiplications.","Such transformations are derived from power functions.","However, the optimization of the exponent parameter and weight values remains a challenging and novel problem which could not be solved with previous post training optimization techniques which only learn to round up or down weight values in order to preserve the predictive function.","We circumvent this limitation with a new paradigm: learning new quantized weights over the entire quantized space.","Similarly, we enable the optimization of the power exponent, i.e. the optimization of the quantization operator itself during training by alleviating all the numerical instabilities.","The resulting predictive function is compatible with integer-only low-bit inference.","We show the ability of the method to achieve state-of-the-art compression rates in both, data-free and data-driven configurations."],"url":"http://arxiv.org/abs/2308.05600v1"}
{"created":"2023-08-10 14:14:13","title":"You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content","abstract":"The spread of toxic content online is an important problem that has adverse effects on user experience online and in our society at large. Motivated by the importance and impact of the problem, research focuses on developing solutions to detect toxic content, usually leveraging machine learning (ML) models trained on human-annotated datasets. While these efforts are important, these models usually do not generalize well and they can not cope with new trends (e.g., the emergence of new toxic terms). Currently, we are witnessing a shift in the approach to tackling societal issues online, particularly leveraging large language models (LLMs) like GPT-3 or T5 that are trained on vast corpora and have strong generalizability. In this work, we investigate how we can use LLMs and prompt learning to tackle the problem of toxic content, particularly focusing on three tasks; 1) Toxicity Classification, 2) Toxic Span Detection, and 3) Detoxification. We perform an extensive evaluation over five model architectures and eight datasets demonstrating that LLMs with prompt learning can achieve similar or even better performance compared to models trained on these specific tasks. We find that prompt learning achieves around 10\\% improvement in the toxicity classification task compared to the baselines, while for the toxic span detection task we find better performance to the best baseline (0.643 vs. 0.640 in terms of $F_1$-score). Finally, for the detoxification task, we find that prompt learning can successfully reduce the average toxicity score (from 0.775 to 0.213) while preserving semantic meaning.","sentences":["The spread of toxic content online is an important problem that has adverse effects on user experience online and in our society at large.","Motivated by the importance and impact of the problem, research focuses on developing solutions to detect toxic content, usually leveraging machine learning (ML) models trained on human-annotated datasets.","While these efforts are important, these models usually do not generalize well and they can not cope with new trends (e.g., the emergence of new toxic terms).","Currently, we are witnessing a shift in the approach to tackling societal issues online, particularly leveraging large language models (LLMs) like GPT-3 or T5 that are trained on vast corpora and have strong generalizability.","In this work, we investigate how we can use LLMs and prompt learning to tackle the problem of toxic content, particularly focusing on three tasks; 1) Toxicity Classification, 2) Toxic Span Detection, and 3) Detoxification.","We perform an extensive evaluation over five model architectures and eight datasets demonstrating that LLMs with prompt learning can achieve similar or even better performance compared to models trained on these specific tasks.","We find that prompt learning achieves around 10\\% improvement in the toxicity classification task compared to the baselines, while for the toxic span detection task we find better performance to the best baseline (0.643 vs. 0.640 in terms of $F_1$-score).","Finally, for the detoxification task, we find that prompt learning can successfully reduce the average toxicity score (from 0.775 to 0.213) while preserving semantic meaning."],"url":"http://arxiv.org/abs/2308.05596v1"}
{"created":"2023-08-10 14:08:50","title":"Test-Time Selection for Robust Skin Lesion Analysis","abstract":"Skin lesion analysis models are biased by artifacts placed during image acquisition, which influence model predictions despite carrying no clinical information. Solutions that address this problem by regularizing models to prevent learning those spurious features achieve only partial success, and existing test-time debiasing techniques are inappropriate for skin lesion analysis due to either making unrealistic assumptions on the distribution of test data or requiring laborious annotation from medical practitioners. We propose TTS (Test-Time Selection), a human-in-the-loop method that leverages positive (e.g., lesion area) and negative (e.g., artifacts) keypoints in test samples. TTS effectively steers models away from exploiting spurious artifact-related correlations without retraining, and with less annotation requirements. Our solution is robust to a varying availability of annotations, and different levels of bias. We showcase on the ISIC2019 dataset (for which we release a subset of annotated images) how our model could be deployed in the real-world for mitigating bias.","sentences":["Skin lesion analysis models are biased by artifacts placed during image acquisition, which influence model predictions despite carrying no clinical information.","Solutions that address this problem by regularizing models to prevent learning those spurious features achieve only partial success, and existing test-time debiasing techniques are inappropriate for skin lesion analysis due to either making unrealistic assumptions on the distribution of test data or requiring laborious annotation from medical practitioners.","We propose TTS (Test-Time Selection), a human-in-the-loop method that leverages positive (e.g., lesion area) and negative (e.g., artifacts) keypoints in test samples.","TTS effectively steers models away from exploiting spurious artifact-related correlations without retraining, and with less annotation requirements.","Our solution is robust to a varying availability of annotations, and different levels of bias.","We showcase on the ISIC2019 dataset (for which we release a subset of annotated images) how our model could be deployed in the real-world for mitigating bias."],"url":"http://arxiv.org/abs/2308.05595v1"}
{"created":"2023-08-10 14:03:48","title":"Robust Lifelong Indoor LiDAR Localization using the Area Graph","abstract":"Lifelong indoor localization in a given map is the basis for navigation of autonomous mobile robots. In this letter, we address the problem of robust localization in cluttered indoor environments like office spaces and corridors using 3D LiDAR point clouds in a given Area Graph, which is a hierarchical, topometric semantic map representation that uses polygons to demark areas such as rooms, corridors or buildings. This representation is very compact, can represent different floors of buildings through its hierarchy and provides semantic information that helps with localization, like poses of doors and glass. In contrast to this, commonly used map representations, such as occupancy grid maps or point clouds, lack these features and require frequent updates in response to environmental changes (e.g. moved furniture), unlike our approach, which matches against lifelong architectural features such as walls and doors. For that we apply filtering to remove clutter from the 3D input point cloud and then employ further scoring and weight functions for localization. Given a broad initial guess from WiFi localization, our experiments show that our global localization and the weighted point to line ICP pose tracking perform very well, even when compared to localization and SLAM algorithms that use the current, feature-rich cluttered map for localization.","sentences":["Lifelong indoor localization in a given map is the basis for navigation of autonomous mobile robots.","In this letter, we address the problem of robust localization in cluttered indoor environments like office spaces and corridors using 3D LiDAR point clouds in a given Area Graph, which is a hierarchical, topometric semantic map representation that uses polygons to demark areas such as rooms, corridors or buildings.","This representation is very compact, can represent different floors of buildings through its hierarchy and provides semantic information that helps with localization, like poses of doors and glass.","In contrast to this, commonly used map representations, such as occupancy grid maps or point clouds, lack these features and require frequent updates in response to environmental changes (e.g. moved furniture), unlike our approach, which matches against lifelong architectural features such as walls and doors.","For that we apply filtering to remove clutter from the 3D input point cloud and then employ further scoring and weight functions for localization.","Given a broad initial guess from WiFi localization, our experiments show that our global localization and the weighted point to line ICP pose tracking perform very well, even when compared to localization and SLAM algorithms that use the current, feature-rich cluttered map for localization."],"url":"http://arxiv.org/abs/2308.05593v1"}
{"created":"2023-08-10 13:52:44","title":"Banzhaf Values for Facts in Query Answering","abstract":"Quantifying the contribution of database facts to query answers has been studied as means of explanation. The Banzhaf value, originally developed in Game Theory, is a natural measure of fact contribution, yet its efficient computation for select-project-join-union queries is challenging. In this paper, we introduce three algorithms to compute the Banzhaf value of database facts: an exact algorithm, an anytime deterministic approximation algorithm with relative error guarantees, and an algorithm for ranking and top-$k$. They have three key building blocks: compilation of query lineage into an equivalent function that allows efficient Banzhaf value computation; dynamic programming computation of the Banzhaf values of variables in a Boolean function using the Banzhaf values for constituent functions; and a mechanism to compute efficiently lower and upper bounds on Banzhaf values for any positive DNF function.   We complement the algorithms with a dichotomy for the Banzhaf-based ranking problem: given two facts, deciding whether the Banzhaf value of one is greater than of the other is tractable for hierarchical queries and intractable for non-hierarchical queries.   We show experimentally that our algorithms significantly outperform exact and approximate algorithms from prior work, most times up to two orders of magnitude. Our algorithms can also cover challenging problem instances that are beyond reach for prior work.","sentences":["Quantifying the contribution of database facts to query answers has been studied as means of explanation.","The Banzhaf value, originally developed in Game Theory, is a natural measure of fact contribution, yet its efficient computation for select-project-join-union queries is challenging.","In this paper, we introduce three algorithms to compute the Banzhaf value of database facts: an exact algorithm, an anytime deterministic approximation algorithm with relative error guarantees, and an algorithm for ranking and top-$k$.","They have three key building blocks: compilation of query lineage into an equivalent function that allows efficient Banzhaf value computation; dynamic programming computation of the Banzhaf values of variables in a Boolean function using the Banzhaf values for constituent functions; and a mechanism to compute efficiently lower and upper bounds on Banzhaf values for any positive DNF function.   ","We complement the algorithms with a dichotomy for the Banzhaf-based ranking problem: given two facts, deciding whether the Banzhaf value of one is greater than of the other is tractable for hierarchical queries and intractable for non-hierarchical queries.   ","We show experimentally that our algorithms significantly outperform exact and approximate algorithms from prior work, most times up to two orders of magnitude.","Our algorithms can also cover challenging problem instances that are beyond reach for prior work."],"url":"http://arxiv.org/abs/2308.05588v1"}
{"created":"2023-08-10 13:50:17","title":"Proximal Policy Optimization Actual Combat: Manipulating Output Tokenizer Length","abstract":"The Reinforcement Learning from Human Feedback (RLHF) plays a pivotal role in shaping the impact of large language models (LLMs), contributing significantly to controlling output toxicity and selecting output styles, particularly as LLMs often harbor misleading content, highlighting the urgency to align them with human values for secure AI systems. The RLHF, characterized by complexity, instability, and sensitivity to hyperparameters, makes the evaluation of the reward model for complex tasks challenging, thereby further complicating the use of Proximal Policy Optimization (PPO). In this paper, we introduce a simple task designed to employ Gloden as a reward model that validates the effectiveness of PPO and inspires it, primarily explaining the task of utilizing PPO to manipulate the tokenizer length of the output generated by the model. Experiments confirm that PPO is not only effective in manipulating the output tokenizer length to a certain extent in this type of task but also exhibits facilitated training once the influence of the reward model effect is excluded, making it an exciting development.","sentences":["The Reinforcement Learning from Human Feedback (RLHF) plays a pivotal role in shaping the impact of large language models (LLMs), contributing significantly to controlling output toxicity and selecting output styles, particularly as LLMs often harbor misleading content, highlighting the urgency to align them with human values for secure AI systems.","The RLHF, characterized by complexity, instability, and sensitivity to hyperparameters, makes the evaluation of the reward model for complex tasks challenging, thereby further complicating the use of Proximal Policy Optimization (PPO).","In this paper, we introduce a simple task designed to employ Gloden as a reward model that validates the effectiveness of PPO and inspires it, primarily explaining the task of utilizing PPO to manipulate the tokenizer length of the output generated by the model.","Experiments confirm that PPO is not only effective in manipulating the output tokenizer length to a certain extent in this type of task but also exhibits facilitated training once the influence of the reward model effect is excluded, making it an exciting development."],"url":"http://arxiv.org/abs/2308.05585v1"}
{"created":"2023-08-10 13:49:26","title":"Generative Diffusion Models for Radio Wireless Channel Modelling and Sampling","abstract":"Channel modelling is essential to designing modern wireless communication systems. The increasing complexity of channel modelling and the cost of collecting high-quality wireless channel data have become major challenges. In this paper, we propose a diffusion model based channel sampling approach for rapidly synthesizing channel realizations from limited data. We use a diffusion model with a U Net based architecture operating in the frequency space domain. To evaluate how well the proposed model reproduces the true distribution of channels in the training dataset, two evaluation metrics are used: $i)$ the approximate $2$-Wasserstein distance between real and generated distributions of the normalized power spectrum in the antenna and frequency domains and $ii)$ precision and recall metric for distributions. We show that, compared to existing GAN based approaches which suffer from mode collapse and unstable training, our diffusion based approach trains stably and generates diverse and high-fidelity samples from the true channel distribution. We also show that we can pretrain the model on a simulated urban macro-cellular channel dataset and fine-tune it on a smaller, out-of-distribution urban micro-cellular dataset, therefore showing that it is feasible to model real world channels using limited data with this approach.","sentences":["Channel modelling is essential to designing modern wireless communication systems.","The increasing complexity of channel modelling and the cost of collecting high-quality wireless channel data have become major challenges.","In this paper, we propose a diffusion model based channel sampling approach for rapidly synthesizing channel realizations from limited data.","We use a diffusion model with a U Net based architecture operating in the frequency space domain.","To evaluate how well the proposed model reproduces the true distribution of channels in the training dataset, two evaluation metrics are used: $i)$ the approximate $2$-Wasserstein distance between real and generated distributions of the normalized power spectrum in the antenna and frequency domains and $ii)$ precision and recall metric for distributions.","We show that, compared to existing GAN based approaches which suffer from mode collapse and unstable training, our diffusion based approach trains stably and generates diverse and high-fidelity samples from the true channel distribution.","We also show that we can pretrain the model on a simulated urban macro-cellular channel dataset and fine-tune it on a smaller, out-of-distribution urban micro-cellular dataset, therefore showing that it is feasible to model real world channels using limited data with this approach."],"url":"http://arxiv.org/abs/2308.05583v1"}
{"created":"2023-08-10 13:46:36","title":"Usability Assessment of the OnlyKey Hardware Two-Factor Authentication Key Among Low Vision or Blind Users","abstract":"Hardware security keys undoubtedly have advantage for users as \"usability\" pain is trivial compared to the maximum \"security\" gain in authentication. Naturally, the hardware factor in the authentication received a widespread adoption amongst average users, as it is ergonomically less demanding than phone texts or authentication prompts. This ergonomic advantage in particular is essential for users who are blind or low vision, as their interaction with a phone is impractical. However, the \"usability\" for low vision or blind users pain might be much higher than an average well-bodied user for the same \"security\" gain. In an effort to learn more we conducted a usability assessment with ten low vision or blind users setting up the OnlyKey two-factor authentication key. First, the setup process was insurmountable for more than half of the participants, resulting in a situation where the hardware key was abandoned. Secondly, the lack of tactile orientation led participants to consider it as both impractical, and prone to difficulties locating or loosing it. We discuss the implications of our findings for future improvements in usable authentication for visually impaired users.","sentences":["Hardware security keys undoubtedly have advantage for users as \"usability\" pain is trivial compared to the maximum \"security\" gain in authentication.","Naturally, the hardware factor in the authentication received a widespread adoption amongst average users, as it is ergonomically less demanding than phone texts or authentication prompts.","This ergonomic advantage in particular is essential for users who are blind or low vision, as their interaction with a phone is impractical.","However, the \"usability\" for low vision or blind users pain might be much higher than an average well-bodied user for the same \"security\" gain.","In an effort to learn more we conducted a usability assessment with ten low vision or blind users setting up the OnlyKey two-factor authentication key.","First, the setup process was insurmountable for more than half of the participants, resulting in a situation where the hardware key was abandoned.","Secondly, the lack of tactile orientation led participants to consider it as both impractical, and prone to difficulties locating or loosing it.","We discuss the implications of our findings for future improvements in usable authentication for visually impaired users."],"url":"http://arxiv.org/abs/2308.05582v1"}
{"created":"2023-08-10 13:44:54","title":"Category Feature Transformer for Semantic Segmentation","abstract":"Aggregation of multi-stage features has been revealed to play a significant role in semantic segmentation. Unlike previous methods employing point-wise summation or concatenation for feature aggregation, this study proposes the Category Feature Transformer (CFT) that explores the flow of category embedding and transformation among multi-stage features through the prevalent multi-head attention mechanism. CFT learns unified feature embeddings for individual semantic categories from high-level features during each aggregation process and dynamically broadcasts them to high-resolution features. Integrating the proposed CFT into a typical feature pyramid structure exhibits superior performance over a broad range of backbone networks. We conduct extensive experiments on popular semantic segmentation benchmarks. Specifically, the proposed CFT obtains a compelling 55.1% mIoU with greatly reduced model parameters and computations on the challenging ADE20K dataset.","sentences":["Aggregation of multi-stage features has been revealed to play a significant role in semantic segmentation.","Unlike previous methods employing point-wise summation or concatenation for feature aggregation, this study proposes the Category Feature Transformer (CFT) that explores the flow of category embedding and transformation among multi-stage features through the prevalent multi-head attention mechanism.","CFT learns unified feature embeddings for individual semantic categories from high-level features during each aggregation process and dynamically broadcasts them to high-resolution features.","Integrating the proposed CFT into a typical feature pyramid structure exhibits superior performance over a broad range of backbone networks.","We conduct extensive experiments on popular semantic segmentation benchmarks.","Specifically, the proposed CFT obtains a compelling 55.1% mIoU with greatly reduced model parameters and computations on the challenging ADE20K dataset."],"url":"http://arxiv.org/abs/2308.05581v1"}
{"created":"2023-08-10 13:42:03","title":"Bijective Density-Equalizing Quasiconformal Map for Multiply-Connected Open Surfaces","abstract":"This paper proposes a novel method for computing bijective density-equalizing quasiconformal (DEQ) flattening maps for multiply-connected open surfaces. In conventional density-equalizing maps, shape deformations are solely driven by prescribed constraints on the density distribution, defined as the population per unit area, while the bijectivity and local geometric distortions of the mappings are uncontrolled. Also, prior methods have primarily focused on simply-connected open surfaces but not surfaces with more complicated topologies. Our proposed method overcomes these issues by formulating the density diffusion process as a quasiconformal flow, which allows us to effectively control the local geometric distortion and guarantee the bijectivity of the mapping by solving an energy minimization problem involving the Beltrami coefficient of the mapping. To achieve an optimal parameterization of multiply-connected surfaces, we develop an iterative scheme that optimizes both the shape of the target planar circular domain and the density-equalizing quasiconformal map onto it. In addition, landmark constraints can be incorporated into our proposed method for consistent feature alignment. The method can also be naturally applied to simply-connected open surfaces. By changing the prescribed population, a large variety of surface flattening maps with different desired properties can be achieved. The method is tested on both synthetic and real examples, demonstrating its efficacy in various applications in computer graphics and medical imaging.","sentences":["This paper proposes a novel method for computing bijective density-equalizing quasiconformal (DEQ) flattening maps for multiply-connected open surfaces.","In conventional density-equalizing maps, shape deformations are solely driven by prescribed constraints on the density distribution, defined as the population per unit area, while the bijectivity and local geometric distortions of the mappings are uncontrolled.","Also, prior methods have primarily focused on simply-connected open surfaces but not surfaces with more complicated topologies.","Our proposed method overcomes these issues by formulating the density diffusion process as a quasiconformal flow, which allows us to effectively control the local geometric distortion and guarantee the bijectivity of the mapping by solving an energy minimization problem involving the Beltrami coefficient of the mapping.","To achieve an optimal parameterization of multiply-connected surfaces, we develop an iterative scheme that optimizes both the shape of the target planar circular domain and the density-equalizing quasiconformal map onto it.","In addition, landmark constraints can be incorporated into our proposed method for consistent feature alignment.","The method can also be naturally applied to simply-connected open surfaces.","By changing the prescribed population, a large variety of surface flattening maps with different desired properties can be achieved.","The method is tested on both synthetic and real examples, demonstrating its efficacy in various applications in computer graphics and medical imaging."],"url":"http://arxiv.org/abs/2308.05579v1"}
{"created":"2023-08-10 13:39:40","title":"Do Language Models Refer?","abstract":"What do language models (LMs) do with language? Everyone agrees that they produce sequences of (mostly) coherent sentences. But are they saying anything with those strings or simply babbling in a convincing simulacrum of language use? This is a vague question, and there are many ways of making it precise. Here we will address one aspect of the question, namely, whether LMs' words refer: that is, whether the outputs of LMs achieve \"word-to-world\" connections. There is prima facie reason to think they do not since LMs do not interact with the world in the way that ordinary language users do. Drawing on insights from the externalist tradition in philosophy of language, we argue that appearances are misleading and that there is good reason to think that LMs can refer.","sentences":["What do language models (LMs) do with language?","Everyone agrees that they produce sequences of (mostly) coherent sentences.","But are they saying anything with those strings or simply babbling in a convincing simulacrum of language use?","This is a vague question, and there are many ways of making it precise.","Here we will address one aspect of the question, namely, whether LMs' words refer: that is, whether the outputs of LMs achieve \"word-to-world\" connections.","There is prima facie reason to think they do not since LMs do not interact with the world in the way that ordinary language users do.","Drawing on insights from the externalist tradition in philosophy of language, we argue that appearances are misleading and that there is good reason to think that LMs can refer."],"url":"http://arxiv.org/abs/2308.05576v1"}
{"created":"2023-08-10 13:39:19","title":"Symmetry Defense Against XGBoost Adversarial Perturbation Attacks","abstract":"We examine whether symmetry can be used to defend tree-based ensemble classifiers such as gradient-boosting decision trees (GBDTs) against adversarial perturbation attacks. The idea is based on a recent symmetry defense for convolutional neural network classifiers (CNNs) that utilizes CNNs' lack of invariance with respect to symmetries. CNNs lack invariance because they can classify a symmetric sample, such as a horizontally flipped image, differently from the original sample. CNNs' lack of invariance also means that CNNs can classify symmetric adversarial samples differently from the incorrect classification of adversarial samples. Using CNNs' lack of invariance, the recent CNN symmetry defense has shown that the classification of symmetric adversarial samples reverts to the correct sample classification. In order to apply the same symmetry defense to GBDTs, we examine GBDT invariance and are the first to show that GBDTs also lack invariance with respect to symmetries. We apply and evaluate the GBDT symmetry defense for nine datasets against six perturbation attacks with a threat model that ranges from zero-knowledge to perfect-knowledge adversaries. Using the feature inversion symmetry against zero-knowledge adversaries, we achieve up to 100% accuracy on adversarial samples even when default and robust classifiers have 0% accuracy. Using the feature inversion and horizontal flip symmetries against perfect-knowledge adversaries, we achieve up to over 95% accuracy on adversarial samples for the GBDT classifier of the F-MNIST dataset even when default and robust classifiers have 0% accuracy.","sentences":["We examine whether symmetry can be used to defend tree-based ensemble classifiers such as gradient-boosting decision trees (GBDTs) against adversarial perturbation attacks.","The idea is based on a recent symmetry defense for convolutional neural network classifiers (CNNs) that utilizes CNNs' lack of invariance with respect to symmetries.","CNNs lack invariance because they can classify a symmetric sample, such as a horizontally flipped image, differently from the original sample.","CNNs' lack of invariance also means that CNNs can classify symmetric adversarial samples differently from the incorrect classification of adversarial samples.","Using CNNs' lack of invariance, the recent CNN symmetry defense has shown that the classification of symmetric adversarial samples reverts to the correct sample classification.","In order to apply the same symmetry defense to GBDTs, we examine GBDT invariance and are the first to show that GBDTs also lack invariance with respect to symmetries.","We apply and evaluate the GBDT symmetry defense for nine datasets against six perturbation attacks with a threat model that ranges from zero-knowledge to perfect-knowledge adversaries.","Using the feature inversion symmetry against zero-knowledge adversaries, we achieve up to 100% accuracy on adversarial samples even when default and robust classifiers have 0% accuracy.","Using the feature inversion and horizontal flip symmetries against perfect-knowledge adversaries, we achieve up to over 95% accuracy on adversarial samples for the GBDT classifier of the F-MNIST dataset even when default and robust classifiers have 0% accuracy."],"url":"http://arxiv.org/abs/2308.05575v1"}
{"created":"2023-08-10 13:38:09","title":"Exploring Linguistic Similarity and Zero-Shot Learning for Multilingual Translation of Dravidian Languages","abstract":"Current research in zero-shot translation is plagued by several issues such as high compute requirements, increased training time and off target translations. Proposed remedies often come at the cost of additional data or compute requirements. Pivot based neural machine translation is preferred over a single-encoder model for most settings despite the increased training and evaluation time. In this work, we overcome the shortcomings of zero-shot translation by taking advantage of transliteration and linguistic similarity. We build a single encoder-decoder neural machine translation system for Dravidian-Dravidian multilingual translation and perform zero-shot translation. We compare the data vs zero-shot accuracy tradeoff and evaluate the performance of our vanilla method against the current state of the art pivot based method. We also test the theory that morphologically rich languages require large vocabularies by restricting the vocabulary using an optimal transport based technique. Our model manages to achieves scores within 3 BLEU of large-scale pivot-based models when it is trained on 50\\% of the language directions.","sentences":["Current research in zero-shot translation is plagued by several issues such as high compute requirements, increased training time and off target translations.","Proposed remedies often come at the cost of additional data or compute requirements.","Pivot based neural machine translation is preferred over a single-encoder model for most settings despite the increased training and evaluation time.","In this work, we overcome the shortcomings of zero-shot translation by taking advantage of transliteration and linguistic similarity.","We build a single encoder-decoder neural machine translation system for Dravidian-Dravidian multilingual translation and perform zero-shot translation.","We compare the data vs zero-shot accuracy tradeoff and evaluate the performance of our vanilla method against the current state of the art pivot based method.","We also test the theory that morphologically rich languages require large vocabularies by restricting the vocabulary using an optimal transport based technique.","Our model manages to achieves scores within 3 BLEU of large-scale pivot-based models when it is trained on 50\\% of the language directions."],"url":"http://arxiv.org/abs/2308.05574v1"}
{"created":"2023-08-10 13:29:12","title":"C5: Towards Better Conversation Comprehension and Contextual Continuity for ChatGPT","abstract":"Large language models (LLMs), such as ChatGPT, have demonstrated outstanding performance in various fields, particularly in natural language understanding and generation tasks. In complex application scenarios, users tend to engage in multi-turn conversations with ChatGPT to keep contextual information and obtain comprehensive responses. However, human forgetting and model contextual forgetting remain prominent issues in multi-turn conversation scenarios, which challenge the users' conversation comprehension and contextual continuity for ChatGPT. To address these challenges, we propose an interactive conversation visualization system called C5, which includes Global View, Topic View, and Context-associated Q\\&A View. The Global View uses the GitLog diagram metaphor to represent the conversation structure, presenting the trend of conversation evolution and supporting the exploration of locally salient features. The Topic View is designed to display all the question and answer nodes and their relationships within a topic using the structure of a knowledge graph, thereby display the relevance and evolution of conversations. The Context-associated Q\\&A View consists of three linked views, which allow users to explore individual conversations deeply while providing specific contextual information when posing questions. The usefulness and effectiveness of C5 were evaluated through a case study and a user study.","sentences":["Large language models (LLMs), such as ChatGPT, have demonstrated outstanding performance in various fields, particularly in natural language understanding and generation tasks.","In complex application scenarios, users tend to engage in multi-turn conversations with ChatGPT to keep contextual information and obtain comprehensive responses.","However, human forgetting and model contextual forgetting remain prominent issues in multi-turn conversation scenarios, which challenge the users' conversation comprehension and contextual continuity for ChatGPT.","To address these challenges, we propose an interactive conversation visualization system called C5, which includes Global View, Topic View, and Context-associated Q\\&A View.","The Global View uses the GitLog diagram metaphor to represent the conversation structure, presenting the trend of conversation evolution and supporting the exploration of locally salient features.","The Topic View is designed to display all the question and answer nodes and their relationships within a topic using the structure of a knowledge graph, thereby display the relevance and evolution of conversations.","The Context-associated Q\\&A View consists of three linked views, which allow users to explore individual conversations deeply while providing specific contextual information when posing questions.","The usefulness and effectiveness of C5 were evaluated through a case study and a user study."],"url":"http://arxiv.org/abs/2308.05567v1"}
{"created":"2023-08-10 13:28:59","title":"AutoGluon-TimeSeries: AutoML for Probabilistic Time Series Forecasting","abstract":"We introduce AutoGluon-TimeSeries - an open-source AutoML library for probabilistic time series forecasting. Focused on ease of use and robustness, AutoGluon-TimeSeries enables users to generate accurate point and quantile forecasts with just 3 lines of Python code. Built on the design philosophy of AutoGluon, AutoGluon-TimeSeries leverages ensembles of diverse forecasting models to deliver high accuracy within a short training time. AutoGluon-TimeSeries combines both conventional statistical models, machine-learning based forecasting approaches, and ensembling techniques. In our evaluation on 29 benchmark datasets, AutoGluon-TimeSeries demonstrates strong empirical performance, outperforming a range of forecasting methods in terms of both point and quantile forecast accuracy, and often even improving upon the best-in-hindsight combination of prior methods.","sentences":["We introduce AutoGluon-TimeSeries - an open-source AutoML library for probabilistic time series forecasting.","Focused on ease of use and robustness, AutoGluon-TimeSeries enables users to generate accurate point and quantile forecasts with just 3 lines of Python code.","Built on the design philosophy of AutoGluon, AutoGluon-TimeSeries leverages ensembles of diverse forecasting models to deliver high accuracy within a short training time.","AutoGluon-TimeSeries combines both conventional statistical models, machine-learning based forecasting approaches, and ensembling techniques.","In our evaluation on 29 benchmark datasets, AutoGluon-TimeSeries demonstrates strong empirical performance, outperforming a range of forecasting methods in terms of both point and quantile forecast accuracy, and often even improving upon the best-in-hindsight combination of prior methods."],"url":"http://arxiv.org/abs/2308.05566v1"}
{"created":"2023-08-10 13:28:38","title":"Analysis of the LockBit 3.0 and its infiltration into Advanced's infrastructure crippling NHS services","abstract":"The LockBit 3.0 ransomware variant is arguably the most threatening of malware in recent times. With no regard for a victim's industry, the ransomware has undergone several evolutions to arrive at an adaptable and evasive variant which has been a menace to governments and organisations, recently infiltrating Advanced Computer Software group. Previous LockBit studies mostly concentrated on measuring the impact of the ransomware attack, prevention, encryption detection, decryption, or data recovery, thereby providing little or no benefit to the less tech savvy populace as a detailed breakdown of the mode of attack is rarely examined. This article analyses the LockBit 3.0 attack techniques with a contextual illustration of the attack on Advanced Computer Software group. With the NHS being a major client of the organisation, and its services alongside 15 other clients being crippled for hours during the attack, attention is drawn to how dreadful such disruption may be in critical organisations. We observed that the upgrade of Lockbit based on releasing newer versions is in a bid to continuously ensure the malware's efficiency - a virtue that keeps it at the zenith - by staying ahead of improved defenses. Our study highlights social engineering as a vibrant portal to Lockbit's maliciousness and indicates an investment in detection systems may profit more than in prevention systems. Therefore, further research should consider improving detection systems against Lockbit 3.0.","sentences":["The LockBit 3.0 ransomware variant is arguably the most threatening of malware in recent times.","With no regard for a victim's industry, the ransomware has undergone several evolutions to arrive at an adaptable and evasive variant which has been a menace to governments and organisations, recently infiltrating Advanced Computer Software group.","Previous LockBit studies mostly concentrated on measuring the impact of the ransomware attack, prevention, encryption detection, decryption, or data recovery, thereby providing little or no benefit to the less tech savvy populace as a detailed breakdown of the mode of attack is rarely examined.","This article analyses the LockBit 3.0 attack techniques with a contextual illustration of the attack on Advanced Computer Software group.","With the NHS being a major client of the organisation, and its services alongside 15 other clients being crippled for hours during the attack, attention is drawn to how dreadful such disruption may be in critical organisations.","We observed that the upgrade of Lockbit based on releasing newer versions is in a bid to continuously ensure the malware's efficiency - a virtue that keeps it at the zenith - by staying ahead of improved defenses.","Our study highlights social engineering as a vibrant portal to Lockbit's maliciousness and indicates an investment in detection systems may profit more than in prevention systems.","Therefore, further research should consider improving detection systems against Lockbit 3.0."],"url":"http://arxiv.org/abs/2308.05565v1"}
{"created":"2023-08-10 13:24:27","title":"Recent Advancements In The Field Of Deepfake Detection","abstract":"A deepfake is a photo or video of a person whose image has been digitally altered or partially replaced with an image of someone else. Deepfakes have the potential to cause a variety of problems and are often used maliciously. A common usage is altering videos of prominent political figures and celebrities. These deepfakes can portray them making offensive, problematic, and/or untrue statements. Current deepfakes can be very realistic, and when used in this way, can spread panic and even influence elections and political opinions. There are many deepfake detection strategies currently in use but finding the most comprehensive and universal method is critical. So, in this survey we will address the problems of malicious deepfake creation and the lack of universal deepfake detection methods. Our objective is to survey and analyze a variety of current methods and advances in the field of deepfake detection.","sentences":["A deepfake is a photo or video of a person whose image has been digitally altered or partially replaced with an image of someone else.","Deepfakes have the potential to cause a variety of problems and are often used maliciously.","A common usage is altering videos of prominent political figures and celebrities.","These deepfakes can portray them making offensive, problematic, and/or untrue statements.","Current deepfakes can be very realistic, and when used in this way, can spread panic and even influence elections and political opinions.","There are many deepfake detection strategies currently in use but finding the most comprehensive and universal method is critical.","So, in this survey we will address the problems of malicious deepfake creation and the lack of universal deepfake detection methods.","Our objective is to survey and analyze a variety of current methods and advances in the field of deepfake detection."],"url":"http://arxiv.org/abs/2308.05563v1"}
{"created":"2023-08-10 13:19:10","title":"Using Machine Learning To Identify Software Weaknesses From Software Requirement Specifications","abstract":"Secure software engineering is crucial but can be time-consuming; therefore, methods that could expedite the identification of software weaknesses without reducing the process efficacy would benefit the software engineering industry and thus benefit modern life. This research focuses on finding an efficient machine learning algorithm to identify software weaknesses from requirement specifications. The research uses the CWE repository and PROMISE exp dataset for training. Keywords extracted using latent semantic analysis help map the CWE categories to PROMISE_exp. Naive Bayes, support vector machine (SVM), decision trees, neural network, and convolutional neural network (CNN) algorithms were tested, with SVM and neural network producing reliable results. The research is unique contribution lies in the mapping technique and algorithm selection. It serves as a valuable reference for the secure software engineering community seeking to expedite the development lifecycle without compromising efficacy. Future work involves testing more algorithms, optimizing existing ones, and improving the training sets accuracy.","sentences":["Secure software engineering is crucial but can be time-consuming; therefore, methods that could expedite the identification of software weaknesses without reducing the process efficacy would benefit the software engineering industry and thus benefit modern life.","This research focuses on finding an efficient machine learning algorithm to identify software weaknesses from requirement specifications.","The research uses the CWE repository and PROMISE exp dataset for training.","Keywords extracted using latent semantic analysis help map the CWE categories to PROMISE_exp.","Naive Bayes, support vector machine (SVM), decision trees, neural network, and convolutional neural network (CNN) algorithms were tested, with SVM and neural network producing reliable results.","The research is unique contribution lies in the mapping technique and algorithm selection.","It serves as a valuable reference for the secure software engineering community seeking to expedite the development lifecycle without compromising efficacy.","Future work involves testing more algorithms, optimizing existing ones, and improving the training sets accuracy."],"url":"http://arxiv.org/abs/2308.05558v1"}
{"created":"2023-08-10 13:18:46","title":"Accountability of Things: Large-Scale Tamper-Evident Logging for Smart Devices","abstract":"Our modern world relies on a growing number of interconnected and interacting devices, leading to a plethora of logs establishing audit trails for all kinds of events. Simultaneously, logs become increasingly important for forensic investigations, and thus, an adversary will aim to alter logs to avoid culpability, e.g., by compromising devices that generate and store logs. Thus, it is essential to ensure that no one can tamper with any logs without going undetected. However, existing approaches to establish tamper evidence of logs do not scale and cannot protect the increasingly large number of devices found today, as they impose large storage or network overheads. Additionally, most schemes do not provide an efficient mechanism to prove that individual events have been logged to establish accountability when different devices interact.   This paper introduces a novel scheme for practical large-scale tamper-evident logging with the help of a trusted third party. To achieve this, we present a new binary hash tree construction designed around timestamps to achieve constant storage overhead with a configured temporal resolution. Additionally, our design enables the efficient construction of shareable proofs, proving that an event was indeed logged. Our evaluation shows that - using practical parameters - our scheme can localize any tampering of logs with a sub-second resolution, with a constant overhead of ~8KB per hour per device.","sentences":["Our modern world relies on a growing number of interconnected and interacting devices, leading to a plethora of logs establishing audit trails for all kinds of events.","Simultaneously, logs become increasingly important for forensic investigations, and thus, an adversary will aim to alter logs to avoid culpability, e.g., by compromising devices that generate and store logs.","Thus, it is essential to ensure that no one can tamper with any logs without going undetected.","However, existing approaches to establish tamper evidence of logs do not scale and cannot protect the increasingly large number of devices found today, as they impose large storage or network overheads.","Additionally, most schemes do not provide an efficient mechanism to prove that individual events have been logged to establish accountability when different devices interact.   ","This paper introduces a novel scheme for practical large-scale tamper-evident logging with the help of a trusted third party.","To achieve this, we present a new binary hash tree construction designed around timestamps to achieve constant storage overhead with a configured temporal resolution.","Additionally, our design enables the efficient construction of shareable proofs, proving that an event was indeed logged.","Our evaluation shows that - using practical parameters - our scheme can localize any tampering of logs with a sub-second resolution, with a constant overhead of ~8KB per hour per device."],"url":"http://arxiv.org/abs/2308.05557v1"}
{"created":"2023-08-10 13:07:58","title":"3D Modeling of a Guitar Using a Computer Tomography Scan","abstract":"This paper describes the development of a detailed 3D geometric model of an acoustical guitar. Modeling an instrument is a sophisticated task considering the individual parts and their complex shapes. The geometry of the parts visible from the outside can be measured using appropriate tools, but it is very difficult to measure the details of the internal parts like bracing, heels, and other features by hand through the sound hole. Otherwise, it would be necessary to disassemble the guitar to measure the precise position and dimensions of the parts inside it. Reassembling the guitar could result in improper functioning. To avoid damaging the instrument by disassembling or taking inaccurate measurements through the sound hole, a computer tomography (CT) scan of the guitar body was performed. Using this method, cross-sectional images of the guitar body in all the three dimensions were extracted with 1 mm spacing between adjacent images. In total, approximately 2000 images were generated and used in developing the geometric model of the guitar. The 3D model will be further used to develop a vibro-acoustic simulation model of the guitar","sentences":["This paper describes the development of a detailed 3D geometric model of an acoustical guitar.","Modeling an instrument is a sophisticated task considering the individual parts and their complex shapes.","The geometry of the parts visible from the outside can be measured using appropriate tools, but it is very difficult to measure the details of the internal parts like bracing, heels, and other features by hand through the sound hole.","Otherwise, it would be necessary to disassemble the guitar to measure the precise position and dimensions of the parts inside it.","Reassembling the guitar could result in improper functioning.","To avoid damaging the instrument by disassembling or taking inaccurate measurements through the sound hole, a computer tomography (CT) scan of the guitar body was performed.","Using this method, cross-sectional images of the guitar body in all the three dimensions were extracted with 1 mm spacing between adjacent images.","In total, approximately 2000 images were generated and used in developing the geometric model of the guitar.","The 3D model will be further used to develop a vibro-acoustic simulation model of the guitar"],"url":"http://arxiv.org/abs/2308.05552v1"}
{"created":"2023-08-10 13:06:05","title":"Cross-Domain Product Representation Learning for Rich-Content E-Commerce","abstract":"The proliferation of short video and live-streaming platforms has revolutionized how consumers engage in online shopping. Instead of browsing product pages, consumers are now turning to rich-content e-commerce, where they can purchase products through dynamic and interactive media like short videos and live streams. This emerging form of online shopping has introduced technical challenges, as products may be presented differently across various media domains. Therefore, a unified product representation is essential for achieving cross-domain product recognition to ensure an optimal user search experience and effective product recommendations. Despite the urgent industrial need for a unified cross-domain product representation, previous studies have predominantly focused only on product pages without taking into account short videos and live streams. To fill the gap in the rich-content e-commerce area, in this paper, we introduce a large-scale cRoss-dOmain Product Ecognition dataset, called ROPE. ROPE covers a wide range of product categories and contains over 180,000 products, corresponding to millions of short videos and live streams. It is the first dataset to cover product pages, short videos, and live streams simultaneously, providing the basis for establishing a unified product representation across different media domains. Furthermore, we propose a Cross-dOmain Product rEpresentation framework, namely COPE, which unifies product representations in different domains through multimodal learning including text and vision. Extensive experiments on downstream tasks demonstrate the effectiveness of COPE in learning a joint feature space for all product domains.","sentences":["The proliferation of short video and live-streaming platforms has revolutionized how consumers engage in online shopping.","Instead of browsing product pages, consumers are now turning to rich-content e-commerce, where they can purchase products through dynamic and interactive media like short videos and live streams.","This emerging form of online shopping has introduced technical challenges, as products may be presented differently across various media domains.","Therefore, a unified product representation is essential for achieving cross-domain product recognition to ensure an optimal user search experience and effective product recommendations.","Despite the urgent industrial need for a unified cross-domain product representation, previous studies have predominantly focused only on product pages without taking into account short videos and live streams.","To fill the gap in the rich-content e-commerce area, in this paper, we introduce a large-scale cRoss-dOmain Product Ecognition dataset, called ROPE.","ROPE covers a wide range of product categories and contains over 180,000 products, corresponding to millions of short videos and live streams.","It is the first dataset to cover product pages, short videos, and live streams simultaneously, providing the basis for establishing a unified product representation across different media domains.","Furthermore, we propose a Cross-dOmain Product rEpresentation framework, namely COPE, which unifies product representations in different domains through multimodal learning including text and vision.","Extensive experiments on downstream tasks demonstrate the effectiveness of COPE in learning a joint feature space for all product domains."],"url":"http://arxiv.org/abs/2308.05550v1"}
{"created":"2023-08-10 12:59:24","title":"Testing Updated Apps by Adapting Learned Models","abstract":"Although App updates are frequent and software engineers would like to verify updated features only, automated testing techniques verify entire Apps and are thus wasting resources. We present Continuous Adaptation of Learned Models (CALM), an automated App testing approach that efficiently tests App updates by adapting App models learned when automatically testing previous App versions. CALM focuses on functional testing. Since functional correctness can be mainly verified through the visual inspection of App screens, CALM minimizes the number of App screens to be visualized by software testers while maximizing the percentage of updated methods and instructions exercised. Our empirical evaluation shows that CALM exercises a significantly higher proportion of updated methods and instructions than six state-of-the-art approaches, for the same maximum number of App screens to be visually inspected. Further, in common update scenarios, where only a small fraction of methods are updated, CALM is even quicker to outperform all competing approaches in a more significant way.","sentences":["Although App updates are frequent and software engineers would like to verify updated features only, automated testing techniques verify entire Apps and are thus wasting resources.","We present Continuous Adaptation of Learned Models (CALM), an automated App testing approach that efficiently tests App updates by adapting App models learned when automatically testing previous App versions.","CALM focuses on functional testing.","Since functional correctness can be mainly verified through the visual inspection of App screens, CALM minimizes the number of App screens to be visualized by software testers while maximizing the percentage of updated methods and instructions exercised.","Our empirical evaluation shows that CALM exercises a significantly higher proportion of updated methods and instructions than six state-of-the-art approaches, for the same maximum number of App screens to be visually inspected.","Further, in common update scenarios, where only a small fraction of methods are updated, CALM is even quicker to outperform all competing approaches in a more significant way."],"url":"http://arxiv.org/abs/2308.05549v1"}
{"created":"2023-08-10 12:55:57","title":"Enhancing AUV Autonomy With Model Predictive Path Integral Control","abstract":"Autonomous underwater vehicles (AUVs) play a crucial role in surveying marine environments, carrying out underwater inspection tasks, and ocean exploration. However, in order to ensure that the AUV is able to carry out its mission successfully, a control system capable of adapting to changing environmental conditions is required. Furthermore, to ensure the robotic platform's safe operation, the onboard controller should be able to operate under certain constraints. In this work, we investigate the feasibility of Model Predictive Path Integral Control (MPPI) for the control of an AUV. We utilise a non-linear model of the AUV to propagate the samples of the MPPI, which allow us to compute the control action in real time. We provide a detailed evaluation of the effect of the main hyperparameters on the performance of the MPPI controller. Furthermore, we compared the performance of the proposed method with a classical PID and Cascade PID approach, demonstrating the superiority of our proposed controller. Finally, we present results where environmental constraints are added and show how MPPI can handle them by simply incorporating those constraints in the cost function.","sentences":["Autonomous underwater vehicles (AUVs) play a crucial role in surveying marine environments, carrying out underwater inspection tasks, and ocean exploration.","However, in order to ensure that the AUV is able to carry out its mission successfully, a control system capable of adapting to changing environmental conditions is required.","Furthermore, to ensure the robotic platform's safe operation, the onboard controller should be able to operate under certain constraints.","In this work, we investigate the feasibility of Model Predictive Path Integral Control (MPPI) for the control of an AUV.","We utilise a non-linear model of the AUV to propagate the samples of the MPPI, which allow us to compute the control action in real time.","We provide a detailed evaluation of the effect of the main hyperparameters on the performance of the MPPI controller.","Furthermore, we compared the performance of the proposed method with a classical PID and Cascade PID approach, demonstrating the superiority of our proposed controller.","Finally, we present results where environmental constraints are added and show how MPPI can handle them by simply incorporating those constraints in the cost function."],"url":"http://arxiv.org/abs/2308.05547v1"}
{"created":"2023-08-10 12:55:39","title":"Multiuser Communications with Movable-Antenna Base Station Via Antenna Position Optimization","abstract":"This paper studies the deployment of multiple movable antennas (MAs) at the base station (BS) for enhancing the multiuser communication performance. First, we model the multiuser channel in the uplink to characterize the wireless channel variation caused by MAs' movement at the BS. Then, an optimization problem is formulated to maximize the minimum achievable rate among multiple users for MA-aided uplink multiuser communications by jointly optimizing the MAs' positions, their receive combining at the BS, and the transmit power of users, under the constraints of finite moving region of MAs, minimum inter-MA distance, and maximum transmit power of each user. To solve this challenging non-convex optimization problem, a two-loop iterative algorithm is proposed by leveraging the particle swarm optimization (PSO) method. Specifically, the outer-loop updates the positions of a set of particles, where each particle's position represents one realization of the antenna positioning vector (APV) of all MAs. The inner-loop implements the fitness evaluation for each particle in terms of the max-min achievable rate of multiple users with its corresponding APV, where the receive combining matrix of the BS and the transmit power of each user are optimized by applying the block coordinate descent (BCD) technique. Simulation results show that the antenna position optimization for MAs-aided BS can significantly improve the rate performance as compared to conventional BS with fixed-position antennas (FPAs).","sentences":["This paper studies the deployment of multiple movable antennas (MAs) at the base station (BS) for enhancing the multiuser communication performance.","First, we model the multiuser channel in the uplink to characterize the wireless channel variation caused by MAs' movement at the BS.","Then, an optimization problem is formulated to maximize the minimum achievable rate among multiple users for MA-aided uplink multiuser communications by jointly optimizing the MAs' positions, their receive combining at the BS, and the transmit power of users, under the constraints of finite moving region of MAs, minimum inter-MA distance, and maximum transmit power of each user.","To solve this challenging non-convex optimization problem, a two-loop iterative algorithm is proposed by leveraging the particle swarm optimization (PSO) method.","Specifically, the outer-loop updates the positions of a set of particles, where each particle's position represents one realization of the antenna positioning vector (APV) of all MAs.","The inner-loop implements the fitness evaluation for each particle in terms of the max-min achievable rate of multiple users with its corresponding APV, where the receive combining matrix of the BS and the transmit power of each user are optimized by applying the block coordinate descent (BCD) technique.","Simulation results show that the antenna position optimization for MAs-aided BS can significantly improve the rate performance as compared to conventional BS with fixed-position antennas (FPAs)."],"url":"http://arxiv.org/abs/2308.05546v1"}
