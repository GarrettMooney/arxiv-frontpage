{"created":"2023-06-29 17:59:57","title":"An Efficient General-Purpose Modular Vision Model via Multi-Task Heterogeneous Training","abstract":"We present a model that can perform multiple vision tasks and can be adapted to other downstream tasks efficiently. Despite considerable progress in multi-task learning, most efforts focus on learning from multi-label data: a single image set with multiple task labels. Such multi-label data sets are rare, small, and expensive. We say heterogeneous to refer to image sets with different task labels, or to combinations of single-task datasets. Few have explored training on such heterogeneous datasets. General-purpose vision models are still dominated by single-task pretraining, and it remains unclear how to scale up multi-task models by leveraging mainstream vision datasets designed for different purposes. The challenges lie in managing large intrinsic differences among vision tasks, including data distribution, architectures, task-specific modules, dataset scales, and sampling strategies. To address these challenges, we propose to modify and scale up mixture-of-experts (MoE) vision transformers, so that they can simultaneously learn classification, detection, and segmentation on diverse mainstream vision datasets including ImageNet, COCO, and ADE20K. Our approach achieves comparable results to single-task state-of-the-art models and demonstrates strong generalization on downstream tasks. Due to its emergent modularity, this general-purpose model decomposes into high-performing components, efficiently adapting to downstream tasks. We can fine-tune it with fewer training parameters, fewer model parameters, and less computation. Additionally, its modularity allows for easy expansion in continual-learning-without-forgetting scenarios. Finally, these functions can be controlled and combined to meet various demands of downstream tasks.","sentences":["We present a model that can perform multiple vision tasks and can be adapted to other downstream tasks efficiently.","Despite considerable progress in multi-task learning, most efforts focus on learning from multi-label data: a single image set with multiple task labels.","Such multi-label data sets are rare, small, and expensive.","We say heterogeneous to refer to image sets with different task labels, or to combinations of single-task datasets.","Few have explored training on such heterogeneous datasets.","General-purpose vision models are still dominated by single-task pretraining, and it remains unclear how to scale up multi-task models by leveraging mainstream vision datasets designed for different purposes.","The challenges lie in managing large intrinsic differences among vision tasks, including data distribution, architectures, task-specific modules, dataset scales, and sampling strategies.","To address these challenges, we propose to modify and scale up mixture-of-experts (MoE) vision transformers, so that they can simultaneously learn classification, detection, and segmentation on diverse mainstream vision datasets including ImageNet, COCO, and","ADE20K.","Our approach achieves comparable results to single-task state-of-the-art models and demonstrates strong generalization on downstream tasks.","Due to its emergent modularity, this general-purpose model decomposes into high-performing components, efficiently adapting to downstream tasks.","We can fine-tune it with fewer training parameters, fewer model parameters, and less computation.","Additionally, its modularity allows for easy expansion in continual-learning-without-forgetting scenarios.","Finally, these functions can be controlled and combined to meet various demands of downstream tasks."],"url":"http://arxiv.org/abs/2306.17165v1"}
{"created":"2023-06-29 17:59:05","title":"Can Machines Garden? Systematically Comparing the AlphaGarden vs. Professional Horticulturalists","abstract":"The AlphaGarden is an automated testbed for indoor polyculture farming which combines a first-order plant simulator, a gantry robot, a seed planting algorithm, plant phenotyping and tracking algorithms, irrigation sensors and algorithms, and custom pruning tools and algorithms. In this paper, we systematically compare the performance of the AlphaGarden to professional horticulturalists on the staff of the UC Berkeley Oxford Tract Greenhouse. The humans and the machine tend side-by-side polyculture gardens with the same seed arrangement. We compare performance in terms of canopy coverage, plant diversity, and water consumption. Results from two 60-day cycles suggest that the automated AlphaGarden performs comparably to professional horticulturalists in terms of coverage and diversity, and reduces water consumption by as much as 44%. Code, videos, and datasets are available at https://sites.google.com/berkeley.edu/systematiccomparison.","sentences":["The AlphaGarden is an automated testbed for indoor polyculture farming which combines a first-order plant simulator, a gantry robot, a seed planting algorithm, plant phenotyping and tracking algorithms, irrigation sensors and algorithms, and custom pruning tools and algorithms.","In this paper, we systematically compare the performance of the AlphaGarden to professional horticulturalists on the staff of the UC Berkeley Oxford Tract Greenhouse.","The humans and the machine tend side-by-side polyculture gardens with the same seed arrangement.","We compare performance in terms of canopy coverage, plant diversity, and water consumption.","Results from two 60-day cycles suggest that the automated AlphaGarden performs comparably to professional horticulturalists in terms of coverage and diversity, and reduces water consumption by as much as 44%.","Code, videos, and datasets are available at https://sites.google.com/berkeley.edu/systematiccomparison."],"url":"http://arxiv.org/abs/2306.17162v1"}
{"created":"2023-06-29 17:57:55","title":"FogROS2-SGC: A ROS2 Cloud Robotics Platform for Secure Global Connectivity","abstract":"The Robot Operating System (ROS2) is the most widely used software platform for building robotics applications. FogROS2 extends ROS2 to allow robots to access cloud computing on demand. However, ROS2 and FogROS2 assume that all robots are locally connected and that each robot has full access and control of the other robots. With applications like distributed multi-robot systems, remote robot control, and mobile robots, robotics increasingly involves the global Internet and complex trust management. Existing approaches for connecting disjoint ROS2 networks lack key features such as security, compatibility, efficiency, and ease of use. We introduce FogROS2-SGC, an extension of FogROS2 that can effectively connect robot systems across different physical locations, networks, and Data Distribution Services (DDS). With globally unique and location-independent identifiers, FogROS2-SGC securely and efficiently routes data between robotics components around the globe. FogROS2-SGC is agnostic to the ROS2 distribution and configuration, is compatible with non-ROS2 software, and seamlessly extends existing ROS2 applications without any code modification. Experiments suggest FogROS2-SGC is 19x faster than rosbridge (a ROS2 package with comparable features, but lacking security). We also apply FogROS2-SGC to 4 robots and compute nodes that are 3600km apart. Videos and code are available on the project website https://sites.google.com/view/fogros2-sgc.","sentences":["The Robot Operating System (ROS2) is the most widely used software platform for building robotics applications.","FogROS2 extends ROS2 to allow robots to access cloud computing on demand.","However, ROS2 and FogROS2 assume that all robots are locally connected and that each robot has full access and control of the other robots.","With applications like distributed multi-robot systems, remote robot control, and mobile robots, robotics increasingly involves the global Internet and complex trust management.","Existing approaches for connecting disjoint ROS2 networks lack key features such as security, compatibility, efficiency, and ease of use.","We introduce FogROS2-SGC, an extension of FogROS2 that can effectively connect robot systems across different physical locations, networks, and Data Distribution Services (DDS).","With globally unique and location-independent identifiers, FogROS2-SGC securely and efficiently routes data between robotics components around the globe.","FogROS2-SGC is agnostic to the ROS2 distribution and configuration, is compatible with non-ROS2 software, and seamlessly extends existing ROS2 applications without any code modification.","Experiments suggest FogROS2-SGC is 19x faster than rosbridge (a ROS2 package with comparable features, but lacking security).","We also apply FogROS2-SGC to 4 robots and compute nodes that are 3600km apart.","Videos and code are available on the project website https://sites.google.com/view/fogros2-sgc."],"url":"http://arxiv.org/abs/2306.17157v1"}
{"created":"2023-06-29 17:57:40","title":"Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors","abstract":"Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies for introductory programming. Recent works have studied these models for different scenarios relevant to programming education; however, these works are limited for several reasons, as they typically consider already outdated models or only specific scenario(s). Consequently, there is a lack of a systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios. In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios. We evaluate using five introductory Python programming problems and real-world buggy programs from an online platform, and assess performance using expert-based annotations. Our results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to human tutors' performance for several scenarios. These results also highlight settings where GPT-4 still struggles, providing exciting future directions on developing techniques to improve the performance of these models.","sentences":["Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies for introductory programming.","Recent works have studied these models for different scenarios relevant to programming education; however, these works are limited for several reasons, as they typically consider already outdated models or only specific scenario(s).","Consequently, there is a lack of a systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios.","In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios.","We evaluate using five introductory Python programming problems and real-world buggy programs from an online platform, and assess performance using expert-based annotations.","Our results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to human tutors' performance for several scenarios.","These results also highlight settings where GPT-4 still struggles, providing exciting future directions on developing techniques to improve the performance of these models."],"url":"http://arxiv.org/abs/2306.17156v1"}
{"created":"2023-06-29 17:55:14","title":"Generate Anything Anywhere in Any Scene","abstract":"Text-to-image diffusion models have attracted considerable interest due to their wide applicability across diverse fields. However, challenges persist in creating controllable models for personalized object generation. In this paper, we first identify the entanglement issues in existing personalized generative models, and then propose a straightforward and efficient data augmentation training strategy that guides the diffusion model to focus solely on object identity. By inserting the plug-and-play adapter layers from a pre-trained controllable diffusion model, our model obtains the ability to control the location and size of each generated personalized object. During inference, we propose a regionally-guided sampling technique to maintain the quality and fidelity of the generated images. Our method achieves comparable or superior fidelity for personalized objects, yielding a robust, versatile, and controllable text-to-image diffusion model that is capable of generating realistic and personalized images. Our approach demonstrates significant potential for various applications, such as those in art, entertainment, and advertising design.","sentences":["Text-to-image diffusion models have attracted considerable interest due to their wide applicability across diverse fields.","However, challenges persist in creating controllable models for personalized object generation.","In this paper, we first identify the entanglement issues in existing personalized generative models, and then propose a straightforward and efficient data augmentation training strategy that guides the diffusion model to focus solely on object identity.","By inserting the plug-and-play adapter layers from a pre-trained controllable diffusion model, our model obtains the ability to control the location and size of each generated personalized object.","During inference, we propose a regionally-guided sampling technique to maintain the quality and fidelity of the generated images.","Our method achieves comparable or superior fidelity for personalized objects, yielding a robust, versatile, and controllable text-to-image diffusion model that is capable of generating realistic and personalized images.","Our approach demonstrates significant potential for various applications, such as those in art, entertainment, and advertising design."],"url":"http://arxiv.org/abs/2306.17154v1"}
{"created":"2023-06-29 17:44:18","title":"Filtered-Guided Diffusion: Fast Filter Guidance for Black-Box Diffusion Models","abstract":"Recent advances in diffusion-based generative models have shown incredible promise for Image-to-Image translation and editing. Most recent work in this space relies on additional training or architecture-specific adjustments to the diffusion process. In this work, we show that much of this low-level control can be achieved without additional training or any access to features of the diffusion model. Our method simply applies a filter to the input of each diffusion step based on the output of the previous step in an adaptive manner. Notably, this approach does not depend on any specific architecture or sampler and can be done without access to internal features of the network, making it easy to combine with other techniques, samplers, and diffusion architectures. Furthermore, it has negligible cost to performance, and allows for more continuous adjustment of guidance strength than other approaches. We show FGD offers a fast and strong baseline that is competitive with recent architecture-dependent approaches. Furthermore, FGD can also be used as a simple add-on to enhance the structural guidance of other state-of-the-art I2I methods. Finally, our derivation of this method helps to understand the impact of self attention, a key component of other recent architecture-specific I2I approaches, in a more architecture-independent way. Project page: https://github.com/jaclyngu/FilteredGuidedDiffusion","sentences":["Recent advances in diffusion-based generative models have shown incredible promise for Image-to-Image translation and editing.","Most recent work in this space relies on additional training or architecture-specific adjustments to the diffusion process.","In this work, we show that much of this low-level control can be achieved without additional training or any access to features of the diffusion model.","Our method simply applies a filter to the input of each diffusion step based on the output of the previous step in an adaptive manner.","Notably, this approach does not depend on any specific architecture or sampler and can be done without access to internal features of the network, making it easy to combine with other techniques, samplers, and diffusion architectures.","Furthermore, it has negligible cost to performance, and allows for more continuous adjustment of guidance strength than other approaches.","We show FGD offers a fast and strong baseline that is competitive with recent architecture-dependent approaches.","Furthermore, FGD can also be used as a simple add-on to enhance the structural guidance of other state-of-the-art I2I methods.","Finally, our derivation of this method helps to understand the impact of self attention, a key component of other recent architecture-specific I2I approaches, in a more architecture-independent way.","Project page: https://github.com/jaclyngu/FilteredGuidedDiffusion"],"url":"http://arxiv.org/abs/2306.17141v1"}
{"created":"2023-06-29 17:41:41","title":"ID-Pose: Sparse-view Camera Pose Estimation by Inverting Diffusion Models","abstract":"Given sparse views of an object, estimating their camera poses is a long-standing and intractable problem. We harness the pre-trained diffusion model of novel views conditioned on viewpoints (Zero-1-to-3). We present ID-Pose which inverses the denoising diffusion process to estimate the relative pose given two input images. ID-Pose adds a noise on one image, and predicts the noise conditioned on the other image and a decision variable for the pose. The prediction error is used as the objective to find the optimal pose with the gradient descent method. ID-Pose can handle more than two images and estimate each of the poses with multiple image pairs from triangular relationships. ID-Pose requires no training and generalizes to real-world images. We conduct experiments using high-quality real-scanned 3D objects, where ID-Pose significantly outperforms state-of-the-art methods.","sentences":["Given sparse views of an object, estimating their camera poses is a long-standing and intractable problem.","We harness the pre-trained diffusion model of novel views conditioned on viewpoints (Zero-1-to-3).","We present ID-Pose which inverses the denoising diffusion process to estimate the relative pose given two input images.","ID-Pose adds a noise on one image, and predicts the noise conditioned on the other image and a decision variable for the pose.","The prediction error is used as the objective to find the optimal pose with the gradient descent method.","ID-Pose can handle more than two images and estimate each of the poses with multiple image pairs from triangular relationships.","ID-Pose requires no training and generalizes to real-world images.","We conduct experiments using high-quality real-scanned 3D objects, where ID-Pose significantly outperforms state-of-the-art methods."],"url":"http://arxiv.org/abs/2306.17140v1"}
{"created":"2023-06-29 17:36:08","title":"ItyFuzz: Snapshot-Based Fuzzer for Smart Contract","abstract":"Smart contracts are critical financial instruments, and their security is of utmost importance. However, smart contract programs are difficult to fuzz due to the persistent blockchain state behind all transactions. Mutating sequences of transactions are complex and often lead to a suboptimal exploration for both input and program spaces. In this paper, we introduce a novel snapshot-based fuzzer ItyFuzz for testing smart contracts. In ItyFuzz, instead of storing sequences of transactions and mutating from them, we snapshot states and singleton transactions. To explore interesting states, ItyFuzz introduces a dataflow waypoint mechanism to identify states with more potential momentum. ItyFuzz also incorporates comparison waypoints to prune the space of states. By maintaining snapshots of the states, ItyFuzz can synthesize concrete exploits like reentrancy attacks quickly. Because ItyFuzz has second-level response time to test a smart contract, it can be used for on-chain testing, which has many benefits compared to local development testing. Finally, we evaluate ItyFuzz on real-world smart contracts and some hacked on-chain DeFi projects. ItyFuzz outperforms existing fuzzers in terms of instructional coverage and can find and generate realistic exploits for on-chain projects quickly.","sentences":["Smart contracts are critical financial instruments, and their security is of utmost importance.","However, smart contract programs are difficult to fuzz due to the persistent blockchain state behind all transactions.","Mutating sequences of transactions are complex and often lead to a suboptimal exploration for both input and program spaces.","In this paper, we introduce a novel snapshot-based fuzzer ItyFuzz for testing smart contracts.","In ItyFuzz, instead of storing sequences of transactions and mutating from them, we snapshot states and singleton transactions.","To explore interesting states, ItyFuzz introduces a dataflow waypoint mechanism to identify states with more potential momentum.","ItyFuzz also incorporates comparison waypoints to prune the space of states.","By maintaining snapshots of the states, ItyFuzz can synthesize concrete exploits like reentrancy attacks quickly.","Because ItyFuzz has second-level response time to test a smart contract, it can be used for on-chain testing, which has many benefits compared to local development testing.","Finally, we evaluate ItyFuzz on real-world smart contracts and some hacked on-chain DeFi projects.","ItyFuzz outperforms existing fuzzers in terms of instructional coverage and can find and generate realistic exploits for on-chain projects quickly."],"url":"http://arxiv.org/abs/2306.17135v1"}
{"created":"2023-06-29 17:34:42","title":"Evaluation of AI-Supported Input Methods in Augmented Reality Environment","abstract":"Augmented Reality (AR) solutions are providing tools that could improve applications in the medical and industrial fields. Augmentation can provide additional information in training, visualization, and work scenarios, to increase efficiency, reliability, and safety, while improving communication with other devices and systems on the network. Unfortunately, tasks in these fields often require both hands to execute, reducing the variety of input methods suitable to control AR applications. People with certain physical disabilities, where they are not able to use their hands, are also negatively impacted when using these devices. The goal of this work is to provide novel hand-free interfacing methods, using AR technology, in association with AI support approaches to produce an improved Human-Computer interaction solution.","sentences":["Augmented Reality (AR) solutions are providing tools that could improve applications in the medical and industrial fields.","Augmentation can provide additional information in training, visualization, and work scenarios, to increase efficiency, reliability, and safety, while improving communication with other devices and systems on the network.","Unfortunately, tasks in these fields often require both hands to execute, reducing the variety of input methods suitable to control AR applications.","People with certain physical disabilities, where they are not able to use their hands, are also negatively impacted when using these devices.","The goal of this work is to provide novel hand-free interfacing methods, using AR technology, in association with AI support approaches to produce an improved Human-Computer interaction solution."],"url":"http://arxiv.org/abs/2306.17132v1"}
{"created":"2023-06-29 17:31:33","title":"Ducho: A Unified Framework for the Extraction of Multimodal Features in Recommendation","abstract":"In multimodal-aware recommendation, the extraction of meaningful multimodal features is at the basis of high-quality recommendations. Generally, each recommendation framework implements its multimodal extraction procedures with specific strategies and tools. This is limiting for two reasons: (i) different extraction strategies do not ease the interdependence among multimodal recommendation frameworks; thus, they cannot be efficiently and fairly compared; (ii) given the large plethora of pre-trained deep learning models made available by different open source tools, model designers do not have access to shared interfaces to extract features. Motivated by the outlined aspects, we propose Ducho, a unified framework for the extraction of multimodal features in recommendation. By integrating three widely-adopted deep learning libraries as backends, namely, TensorFlow, PyTorch, and Transformers, we provide a shared interface to extract and process features where each backend's specific methods are abstracted to the end user. Noteworthy, the extraction pipeline is easily configurable with a YAML-based file where the user can specify, for each modality, the list of models (and their specific backends/parameters) to perform the extraction. Finally, to make Ducho accessible to the community, we build a public Docker image equipped with a ready-to-use CUDA environment and propose three demos to test its functionalities for different scenarios and tasks. The GitHub repository and the documentation is accessible at this link: https://github.com/sisinflab/Ducho.","sentences":["In multimodal-aware recommendation, the extraction of meaningful multimodal features is at the basis of high-quality recommendations.","Generally, each recommendation framework implements its multimodal extraction procedures with specific strategies and tools.","This is limiting for two reasons: (i) different extraction strategies do not ease the interdependence among multimodal recommendation frameworks; thus, they cannot be efficiently and fairly compared; (ii) given the large plethora of pre-trained deep learning models made available by different open source tools, model designers do not have access to shared interfaces to extract features.","Motivated by the outlined aspects, we propose Ducho, a unified framework for the extraction of multimodal features in recommendation.","By integrating three widely-adopted deep learning libraries as backends, namely, TensorFlow, PyTorch, and Transformers, we provide a shared interface to extract and process features where each backend's specific methods are abstracted to the end user.","Noteworthy, the extraction pipeline is easily configurable with a YAML-based file where the user can specify, for each modality, the list of models (and their specific backends/parameters) to perform the extraction.","Finally, to make Ducho accessible to the community, we build a public Docker image equipped with a ready-to-use CUDA environment and propose three demos to test its functionalities for different scenarios and tasks.","The GitHub repository and the documentation is accessible at this link: https://github.com/sisinflab/Ducho."],"url":"http://arxiv.org/abs/2306.17125v1"}
{"created":"2023-06-29 17:26:51","title":"PVP: Personalized Video Prior for Editable Dynamic Portraits using StyleGAN","abstract":"Portrait synthesis creates realistic digital avatars which enable users to interact with others in a compelling way. Recent advances in StyleGAN and its extensions have shown promising results in synthesizing photorealistic and accurate reconstruction of human faces. However, previous methods often focus on frontal face synthesis and most methods are not able to handle large head rotations due to the training data distribution of StyleGAN. In this work, our goal is to take as input a monocular video of a face, and create an editable dynamic portrait able to handle extreme head poses. The user can create novel viewpoints, edit the appearance, and animate the face. Our method utilizes pivotal tuning inversion (PTI) to learn a personalized video prior from a monocular video sequence. Then we can input pose and expression coefficients to MLPs and manipulate the latent vectors to synthesize different viewpoints and expressions of the subject. We also propose novel loss functions to further disentangle pose and expression in the latent space. Our algorithm shows much better performance over previous approaches on monocular video datasets, and it is also capable of running in real-time at 54 FPS on an RTX 3080.","sentences":["Portrait synthesis creates realistic digital avatars which enable users to interact with others in a compelling way.","Recent advances in StyleGAN and its extensions have shown promising results in synthesizing photorealistic and accurate reconstruction of human faces.","However, previous methods often focus on frontal face synthesis and most methods are not able to handle large head rotations due to the training data distribution of StyleGAN.","In this work, our goal is to take as input a monocular video of a face, and create an editable dynamic portrait able to handle extreme head poses.","The user can create novel viewpoints, edit the appearance, and animate the face.","Our method utilizes pivotal tuning inversion (PTI) to learn a personalized video prior from a monocular video sequence.","Then we can input pose and expression coefficients to MLPs and manipulate the latent vectors to synthesize different viewpoints and expressions of the subject.","We also propose novel loss functions to further disentangle pose and expression in the latent space.","Our algorithm shows much better performance over previous approaches on monocular video datasets, and it is also capable of running in real-time at 54 FPS on an RTX 3080."],"url":"http://arxiv.org/abs/2306.17123v1"}
{"created":"2023-06-29 17:20:05","title":"Learning Nuclei Representations with Masked Image Modelling","abstract":"Masked image modelling (MIM) is a powerful self-supervised representation learning paradigm, whose potential has not been widely demonstrated in medical image analysis. In this work, we show the capacity of MIM to capture rich semantic representations of Haemotoxylin & Eosin (H&E)-stained images at the nuclear level. Inspired by Bidirectional Encoder representation from Image Transformers (BEiT), we split the images into smaller patches and generate corresponding discrete visual tokens. In addition to the regular grid-based patches, typically used in visual Transformers, we introduce patches of individual cell nuclei. We propose positional encoding of the irregular distribution of these structures within an image. We pre-train the model in a self-supervised manner on H&E-stained whole-slide images of diffuse large B-cell lymphoma, where cell nuclei have been segmented. The pre-training objective is to recover the original discrete visual tokens of the masked image on the one hand, and to reconstruct the visual tokens of the masked object instances on the other. Coupling these two pre-training tasks allows us to build powerful, context-aware representations of nuclei. Our model generalizes well and can be fine-tuned on downstream classification tasks, achieving improved cell classification accuracy on PanNuke dataset by more than 5% compared to current instance segmentation methods.","sentences":["Masked image modelling (MIM) is a powerful self-supervised representation learning paradigm, whose potential has not been widely demonstrated in medical image analysis.","In this work, we show the capacity of MIM to capture rich semantic representations of Haemotoxylin & Eosin (H&E)-stained images at the nuclear level.","Inspired by Bidirectional Encoder representation from Image Transformers (BEiT), we split the images into smaller patches and generate corresponding discrete visual tokens.","In addition to the regular grid-based patches, typically used in visual Transformers, we introduce patches of individual cell nuclei.","We propose positional encoding of the irregular distribution of these structures within an image.","We pre-train the model in a self-supervised manner on H&E-stained whole-slide images of diffuse large B-cell lymphoma, where cell nuclei have been segmented.","The pre-training objective is to recover the original discrete visual tokens of the masked image on the one hand, and to reconstruct the visual tokens of the masked object instances on the other.","Coupling these two pre-training tasks allows us to build powerful, context-aware representations of nuclei.","Our model generalizes well and can be fine-tuned on downstream classification tasks, achieving improved cell classification accuracy on PanNuke dataset by more than 5% compared to current instance segmentation methods."],"url":"http://arxiv.org/abs/2306.17116v1"}
{"created":"2023-06-29 17:17:57","title":"Michelangelo: Conditional 3D Shape Generation based on Shape-Image-Text Aligned Latent Representation","abstract":"We present a novel alignment-before-generation approach to tackle the challenging task of generating general 3D shapes based on 2D images or texts. Directly learning a conditional generative model from images or texts to 3D shapes is prone to producing inconsistent results with the conditions because 3D shapes have an additional dimension whose distribution significantly differs from that of 2D images and texts. To bridge the domain gap among the three modalities and facilitate multi-modal-conditioned 3D shape generation, we explore representing 3D shapes in a shape-image-text-aligned space. Our framework comprises two models: a Shape-Image-Text-Aligned Variational Auto-Encoder (SITA-VAE) and a conditional Aligned Shape Latent Diffusion Model (ASLDM). The former model encodes the 3D shapes into the shape latent space aligned to the image and text and reconstructs the fine-grained 3D neural fields corresponding to given shape embeddings via the transformer-based decoder. The latter model learns a probabilistic mapping function from the image or text space to the latent shape space. Our extensive experiments demonstrate that our proposed approach can generate higher-quality and more diverse 3D shapes that better semantically conform to the visual or textural conditional inputs, validating the effectiveness of the shape-image-text-aligned space for cross-modality 3D shape generation.","sentences":["We present a novel alignment-before-generation approach to tackle the challenging task of generating general 3D shapes based on 2D images or texts.","Directly learning a conditional generative model from images or texts to 3D shapes is prone to producing inconsistent results with the conditions because 3D shapes have an additional dimension whose distribution significantly differs from that of 2D images and texts.","To bridge the domain gap among the three modalities and facilitate multi-modal-conditioned 3D shape generation, we explore representing 3D shapes in a shape-image-text-aligned space.","Our framework comprises two models: a Shape-Image-Text-Aligned Variational Auto-Encoder (SITA-VAE) and a conditional Aligned Shape Latent Diffusion Model (ASLDM).","The former model encodes the 3D shapes into the shape latent space aligned to the image and text and reconstructs the fine-grained 3D neural fields corresponding to given shape embeddings via the transformer-based decoder.","The latter model learns a probabilistic mapping function from the image or text space to the latent shape space.","Our extensive experiments demonstrate that our proposed approach can generate higher-quality and more diverse 3D shapes that better semantically conform to the visual or textural conditional inputs, validating the effectiveness of the shape-image-text-aligned space for cross-modality 3D shape generation."],"url":"http://arxiv.org/abs/2306.17115v1"}
{"created":"2023-06-29 17:08:57","title":"Synthetic Demographic Data Generation for Card Fraud Detection Using GANs","abstract":"Using machine learning models to generate synthetic data has become common in many fields. Technology to generate synthetic transactions that can be used to detect fraud is also growing fast. Generally, this synthetic data contains only information about the transaction, such as the time, place, and amount of money. It does not usually contain the individual user's characteristics (age and gender are occasionally included). Using relatively complex synthetic demographic data may improve the complexity of transaction data features, thus improving the fraud detection performance. Benefiting from developments of machine learning, some deep learning models have potential to perform better than other well-established synthetic data generation methods, such as microsimulation. In this study, we built a deep-learning Generative Adversarial Network (GAN), called DGGAN, which will be used for demographic data generation. Our model generates samples during model training, which we found important to overcame class imbalance issues. This study can help improve the cognition of synthetic data and further explore the application of synthetic data generation in card fraud detection.","sentences":["Using machine learning models to generate synthetic data has become common in many fields.","Technology to generate synthetic transactions that can be used to detect fraud is also growing fast.","Generally, this synthetic data contains only information about the transaction, such as the time, place, and amount of money.","It does not usually contain the individual user's characteristics (age and gender are occasionally included).","Using relatively complex synthetic demographic data may improve the complexity of transaction data features, thus improving the fraud detection performance.","Benefiting from developments of machine learning, some deep learning models have potential to perform better than other well-established synthetic data generation methods, such as microsimulation.","In this study, we built a deep-learning Generative Adversarial Network (GAN), called DGGAN, which will be used for demographic data generation.","Our model generates samples during model training, which we found important to overcame class imbalance issues.","This study can help improve the cognition of synthetic data and further explore the application of synthetic data generation in card fraud detection."],"url":"http://arxiv.org/abs/2306.17109v1"}
{"created":"2023-06-29 17:08:53","title":"ManimML: Communicating Machine Learning Architectures with Animation","abstract":"There has been an explosion in interest in machine learning (ML) in recent years due to its applications to science and engineering. However, as ML techniques have advanced, tools for explaining and visualizing novel ML algorithms have lagged behind. Animation has been shown to be a powerful tool for making engaging visualizations of systems that dynamically change over time, which makes it well suited to the task of communicating ML algorithms. However, the current approach to animating ML algorithms is to handcraft applications that highlight specific algorithms or use complex generalized animation software. We developed ManimML, an open-source Python library for easily generating animations of ML algorithms directly from code. We sought to leverage ML practitioners' preexisting knowledge of programming rather than requiring them to learn complex animation software. ManimML has a familiar syntax for specifying neural networks that mimics popular deep learning frameworks like Pytorch. A user can take a preexisting neural network architecture and easily write a specification for an animation in ManimML, which will then automatically compose animations for different components of the system into a final animation of the entire neural network. ManimML is open source and available at https://github.com/helblazer811/ManimML.","sentences":["There has been an explosion in interest in machine learning (ML) in recent years due to its applications to science and engineering.","However, as ML techniques have advanced, tools for explaining and visualizing novel ML algorithms have lagged behind.","Animation has been shown to be a powerful tool for making engaging visualizations of systems that dynamically change over time, which makes it well suited to the task of communicating ML algorithms.","However, the current approach to animating ML algorithms is to handcraft applications that highlight specific algorithms or use complex generalized animation software.","We developed ManimML, an open-source Python library for easily generating animations of ML algorithms directly from code.","We sought to leverage ML practitioners' preexisting knowledge of programming rather than requiring them to learn complex animation software.","ManimML has a familiar syntax for specifying neural networks that mimics popular deep learning frameworks like Pytorch.","A user can take a preexisting neural network architecture and easily write a specification for an animation in ManimML, which will then automatically compose animations for different components of the system into a final animation of the entire neural network.","ManimML is open source and available at https://github.com/helblazer811/ManimML."],"url":"http://arxiv.org/abs/2306.17108v1"}
{"created":"2023-06-29 17:08:16","title":"LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image Understanding","abstract":"Instruction tuning unlocks the superior capability of Large Language Models (LLM) to interact with humans. Furthermore, recent instruction-following datasets include images as visual inputs, collecting responses for image-based instructions. However, visual instruction-tuned models cannot comprehend textual details within images well. This work enhances the current visual instruction tuning pipeline with text-rich images (e.g., movie posters, book covers, etc.). Specifically, we first use publicly available OCR tools to collect results on 422K text-rich images from the LAION dataset. Moreover, we prompt text-only GPT-4 with recognized texts and image captions to generate 16K conversations, each containing question-answer pairs for text-rich images. By combining our collected data with previous multi-modal instruction-following data, our model, LLaVAR, substantially improves the LLaVA model's capability on text-based VQA datasets (up to 20% accuracy improvement) while achieving an accuracy of 91.42% on ScienceQA. The GPT-4-based instruction-following evaluation also demonstrates the improvement of our model on both natural images and text-rich images. Through qualitative analysis, LLaVAR shows promising interaction (e.g., reasoning, writing, and elaboration) skills with humans based on the latest real-world online content that combines text and images. We make our code/data/models publicly available at https://llavar.github.io/.","sentences":["Instruction tuning unlocks the superior capability of Large Language Models (LLM) to interact with humans.","Furthermore, recent instruction-following datasets include images as visual inputs, collecting responses for image-based instructions.","However, visual instruction-tuned models cannot comprehend textual details within images well.","This work enhances the current visual instruction tuning pipeline with text-rich images (e.g., movie posters, book covers, etc.).","Specifically, we first use publicly available OCR tools to collect results on 422K text-rich images from the LAION dataset.","Moreover, we prompt text-only GPT-4 with recognized texts and image captions to generate 16K conversations, each containing question-answer pairs for text-rich images.","By combining our collected data with previous multi-modal instruction-following data, our model, LLaVAR, substantially improves the LLaVA model's capability on text-based VQA datasets (up to 20% accuracy improvement) while achieving an accuracy of 91.42% on ScienceQA.","The GPT-4-based instruction-following evaluation also demonstrates the improvement of our model on both natural images and text-rich images.","Through qualitative analysis, LLaVAR shows promising interaction (e.g., reasoning, writing, and elaboration) skills with humans based on the latest real-world online content that combines text and images.","We make our code/data/models publicly available at https://llavar.github.io/."],"url":"http://arxiv.org/abs/2306.17107v1"}
{"created":"2023-06-29 17:07:34","title":"Are Neurons Actually Collapsed? On the Fine-Grained Structure in Neural Representations","abstract":"Recent work has observed an intriguing ''Neural Collapse'' phenomenon in well-trained neural networks, where the last-layer representations of training samples with the same label collapse into each other. This appears to suggest that the last-layer representations are completely determined by the labels, and do not depend on the intrinsic structure of input distribution. We provide evidence that this is not a complete description, and that the apparent collapse hides important fine-grained structure in the representations. Specifically, even when representations apparently collapse, the small amount of remaining variation can still faithfully and accurately captures the intrinsic structure of input distribution. As an example, if we train on CIFAR-10 using only 5 coarse-grained labels (by combining two classes into one super-class) until convergence, we can reconstruct the original 10-class labels from the learned representations via unsupervised clustering. The reconstructed labels achieve $93\\%$ accuracy on the CIFAR-10 test set, nearly matching the normal CIFAR-10 accuracy for the same architecture. We also provide an initial theoretical result showing the fine-grained representation structure in a simplified synthetic setting. Our results show concretely how the structure of input data can play a significant role in determining the fine-grained structure of neural representations, going beyond what Neural Collapse predicts.","sentences":["Recent work has observed an intriguing ''Neural Collapse'' phenomenon in well-trained neural networks, where the last-layer representations of training samples with the same label collapse into each other.","This appears to suggest that the last-layer representations are completely determined by the labels, and do not depend on the intrinsic structure of input distribution.","We provide evidence that this is not a complete description, and that the apparent collapse hides important fine-grained structure in the representations.","Specifically, even when representations apparently collapse, the small amount of remaining variation can still faithfully and accurately captures the intrinsic structure of input distribution.","As an example, if we train on CIFAR-10 using only 5 coarse-grained labels (by combining two classes into one super-class) until convergence, we can reconstruct the original 10-class labels from the learned representations via unsupervised clustering.","The reconstructed labels achieve $93\\%$ accuracy on the CIFAR-10 test set, nearly matching the normal CIFAR-10 accuracy for the same architecture.","We also provide an initial theoretical result showing the fine-grained representation structure in a simplified synthetic setting.","Our results show concretely how the structure of input data can play a significant role in determining the fine-grained structure of neural representations, going beyond what Neural Collapse predicts."],"url":"http://arxiv.org/abs/2306.17105v1"}
{"created":"2023-06-29 17:06:42","title":"Deep Ensemble for Rotorcraft Attitude Prediction","abstract":"Historically, the rotorcraft community has experienced a higher fatal accident rate than other aviation segments, including commercial and general aviation. Recent advancements in artificial intelligence (AI) and the application of these technologies in different areas of our lives are both intriguing and encouraging. When developed appropriately for the aviation domain, AI techniques provide an opportunity to help design systems that can address rotorcraft safety challenges. Our recent work demonstrated that AI algorithms could use video data from onboard cameras and correctly identify different flight parameters from cockpit gauges, e.g., indicated airspeed. These AI-based techniques provide a potentially cost-effective solution, especially for small helicopter operators, to record the flight state information and perform post-flight analyses. We also showed that carefully designed and trained AI systems could accurately predict rotorcraft attitude (i.e., pitch and yaw) from outside scenes (images or video data). Ordinary off-the-shelf video cameras were installed inside the rotorcraft cockpit to record the outside scene, including the horizon. The AI algorithm could correctly identify rotorcraft attitude at an accuracy in the range of 80\\%. In this work, we combined five different onboard camera viewpoints to improve attitude prediction accuracy to 94\\%. In this paper, five onboard camera views included the pilot windshield, co-pilot windshield, pilot Electronic Flight Instrument System (EFIS) display, co-pilot EFIS display, and the attitude indicator gauge. Using video data from each camera view, we trained various convolutional neural networks (CNNs), which achieved prediction accuracy in the range of 79\\% % to 90\\% %. We subsequently ensembled the learned knowledge from all CNNs and achieved an ensembled accuracy of 93.3\\%.","sentences":["Historically, the rotorcraft community has experienced a higher fatal accident rate than other aviation segments, including commercial and general aviation.","Recent advancements in artificial intelligence (AI) and the application of these technologies in different areas of our lives are both intriguing and encouraging.","When developed appropriately for the aviation domain, AI techniques provide an opportunity to help design systems that can address rotorcraft safety challenges.","Our recent work demonstrated that AI algorithms could use video data from onboard cameras and correctly identify different flight parameters from cockpit gauges, e.g., indicated airspeed.","These AI-based techniques provide a potentially cost-effective solution, especially for small helicopter operators, to record the flight state information and perform post-flight analyses.","We also showed that carefully designed and trained AI systems could accurately predict rotorcraft attitude (i.e., pitch and yaw) from outside scenes (images or video data).","Ordinary off-the-shelf video cameras were installed inside the rotorcraft cockpit to record the outside scene, including the horizon.","The AI algorithm could correctly identify rotorcraft attitude at an accuracy in the range of 80\\%.","In this work, we combined five different onboard camera viewpoints to improve attitude prediction accuracy to 94\\%.","In this paper, five onboard camera views included the pilot windshield, co-pilot windshield, pilot Electronic Flight Instrument System (EFIS) display, co-pilot EFIS display, and the attitude indicator gauge.","Using video data from each camera view, we trained various convolutional neural networks (CNNs), which achieved prediction accuracy in the range of 79\\% % to 90\\% %.","We subsequently ensembled the learned knowledge from all CNNs and achieved an ensembled accuracy of 93.3\\%."],"url":"http://arxiv.org/abs/2306.17104v1"}
{"created":"2023-06-29 17:01:51","title":"LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT","abstract":"We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic lyrics transcription method achieving state-of-the-art performance on various lyrics transcription datasets, even in challenging genres such as rock and metal. Our novel, training-free approach utilizes Whisper, a weakly supervised robust speech recognition model, and GPT-4, today's most performant chat-based large language model. In the proposed method, Whisper functions as the \"ear\" by transcribing the audio, while GPT-4 serves as the \"brain,\" acting as an annotator with a strong performance for contextualized output selection and correction. Our experiments show that LyricWhiz significantly reduces Word Error Rate compared to existing methods in English and can effectively transcribe lyrics across multiple languages. Furthermore, we use LyricWhiz to create the first publicly available, large-scale, multilingual lyrics transcription dataset with a CC-BY-NC-SA copyright license, based on MTG-Jamendo, and offer a human-annotated subset for noise level estimation and evaluation. We anticipate that our proposed method and dataset will advance the development of multilingual lyrics transcription, a challenging and emerging task.","sentences":["We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic lyrics transcription method achieving state-of-the-art performance on various lyrics transcription datasets, even in challenging genres such as rock and metal.","Our novel, training-free approach utilizes Whisper, a weakly supervised robust speech recognition model, and GPT-4, today's most performant chat-based large language model.","In the proposed method, Whisper functions as the \"ear\" by transcribing the audio, while GPT-4 serves as the \"brain,\" acting as an annotator with a strong performance for contextualized output selection and correction.","Our experiments show that LyricWhiz significantly reduces Word Error Rate compared to existing methods in English and can effectively transcribe lyrics across multiple languages.","Furthermore, we use LyricWhiz to create the first publicly available, large-scale, multilingual lyrics transcription dataset with a CC-BY-NC-SA copyright license, based on MTG-Jamendo, and offer a human-annotated subset for noise level estimation and evaluation.","We anticipate that our proposed method and dataset will advance the development of multilingual lyrics transcription, a challenging and emerging task."],"url":"http://arxiv.org/abs/2306.17103v1"}
{"created":"2023-06-29 16:58:08","title":"Identifying Important Sensory Feedback for Learning Locomotion Skills","abstract":"Robot motor skills can be learned through deep reinforcement learning (DRL) by neural networks as state-action mappings. While the selection of state observations is crucial, there has been a lack of quantitative analysis to date. Here, we present a systematic saliency analysis that quantitatively evaluates the relative importance of different feedback states for motor skills learned through DRL. Our approach can identify the most essential feedback states for locomotion skills, including balance recovery, trotting, bounding, pacing and galloping. By using only key states including joint positions, gravity vector, base linear and angular velocities, we demonstrate that a simulated quadruped robot can achieve robust performance in various test scenarios across these distinct skills. The benchmarks using task performance metrics show that locomotion skills learned with key states can achieve comparable performance to those with all states, and the task performance or learning success rate will drop significantly if key states are missing. This work provides quantitative insights into the relationship between state observations and specific types of motor skills, serving as a guideline for robot motor learning. The proposed method is applicable to differentiable state-action mapping, such as neural network based control policies, enabling the learning of a wide range of motor skills with minimal sensing dependencies.","sentences":["Robot motor skills can be learned through deep reinforcement learning (DRL) by neural networks as state-action mappings.","While the selection of state observations is crucial, there has been a lack of quantitative analysis to date.","Here, we present a systematic saliency analysis that quantitatively evaluates the relative importance of different feedback states for motor skills learned through DRL.","Our approach can identify the most essential feedback states for locomotion skills, including balance recovery, trotting, bounding, pacing and galloping.","By using only key states including joint positions, gravity vector, base linear and angular velocities, we demonstrate that a simulated quadruped robot can achieve robust performance in various test scenarios across these distinct skills.","The benchmarks using task performance metrics show that locomotion skills learned with key states can achieve comparable performance to those with all states, and the task performance or learning success rate will drop significantly if key states are missing.","This work provides quantitative insights into the relationship between state observations and specific types of motor skills, serving as a guideline for robot motor learning.","The proposed method is applicable to differentiable state-action mapping, such as neural network based control policies, enabling the learning of a wide range of motor skills with minimal sensing dependencies."],"url":"http://arxiv.org/abs/2306.17101v1"}
{"created":"2023-06-29 16:57:22","title":"RL4CO: an Extensive Reinforcement Learning for Combinatorial Optimization Benchmark","abstract":"We introduce RL4CO, an extensive reinforcement learning (RL) for combinatorial optimization (CO) benchmark. RL4CO employs state-of-the-art software libraries as well as best practices in implementation, such as modularity and configuration management, to be efficient and easily modifiable by researchers for adaptations of neural network architecture, environments, and algorithms. Contrary to the existing focus on specific tasks like the traveling salesman problem (TSP) for performance assessment, we underline the importance of scalability and generalization capabilities for diverse optimization tasks. We also systematically benchmark sample efficiency, zero-shot generalization, and adaptability to changes in data distributions of various models. Our experiments show that some recent state-of-the-art methods fall behind their predecessors when evaluated using these new metrics, suggesting the necessity for a more balanced view of the performance of neural CO solvers. We hope RL4CO will encourage the exploration of novel solutions to complex real-world tasks, allowing to compare with existing methods through a standardized interface that decouples the science from the software engineering. We make our library publicly available at https://github.com/kaist-silab/rl4co.","sentences":["We introduce RL4CO, an extensive reinforcement learning (RL) for combinatorial optimization (CO) benchmark.","RL4CO employs state-of-the-art software libraries as well as best practices in implementation, such as modularity and configuration management, to be efficient and easily modifiable by researchers for adaptations of neural network architecture, environments, and algorithms.","Contrary to the existing focus on specific tasks like the traveling salesman problem (TSP) for performance assessment, we underline the importance of scalability and generalization capabilities for diverse optimization tasks.","We also systematically benchmark sample efficiency, zero-shot generalization, and adaptability to changes in data distributions of various models.","Our experiments show that some recent state-of-the-art methods fall behind their predecessors when evaluated using these new metrics, suggesting the necessity for a more balanced view of the performance of neural CO solvers.","We hope RL4CO will encourage the exploration of novel solutions to complex real-world tasks, allowing to compare with existing methods through a standardized interface that decouples the science from the software engineering.","We make our library publicly available at https://github.com/kaist-silab/rl4co."],"url":"http://arxiv.org/abs/2306.17100v1"}
{"created":"2023-06-29 16:57:19","title":"When Bidders Are DAOs","abstract":"In a typical decentralized autonomous organization (DAO), people organize themselves into a group that is programmatically managed. DAOs can act as bidders in auctions, with a DAO's bid treated by the auctioneer as if it had been submitted by an individual, without regard to the internal structure of the DAO. We study auctions in which the bidders are DAOs. More precisely, we consider the design of two-level auctions in which the \"participants\" are groups of bidders rather than individuals. Bidders form DAOs to pool resources, but must then also negotiate the terms by which the DAO's winnings are shared. We model the outcome of a DAO's negotiations by an aggregation function (which aggregates DAO members' bids into a single group bid), and a budget-balanced cost-sharing mechanism (that determines DAO members' access to the DAO's allocation and distributes the total payment demanded from the DAO to its members). We pursue two-level mechanisms that are incentive-compatible (with truthful bidding a dominant strategy for members of each DAO) and approximately welfare-optimal. We prove that, even in the case of a single-item auction, incentive-compatible welfare maximization is not possible: No matter what the outer mechanism and the cost-sharing mechanisms used by DAOs, the welfare of the resulting two-level mechanism can be a $\\approx \\ln n$ factor less than optimal. We complement this lower bound with a natural two-level mechanism that achieves a matching approximate welfare guarantee. Our upper bound also extends to multi-item auctions where individuals have additive valuations. Finally, we show that our positive results cannot be extended much further: Even in multi-item settings with unit-demand bidders, truthful two-level mechanisms form a highly restricted class and as a consequence cannot guarantee any non-trivial approximation of the maximum social welfare.","sentences":["In a typical decentralized autonomous organization (DAO), people organize themselves into a group that is programmatically managed.","DAOs can act as bidders in auctions, with a DAO's bid treated by the auctioneer as if it had been submitted by an individual, without regard to the internal structure of the DAO.","We study auctions in which the bidders are DAOs.","More precisely, we consider the design of two-level auctions in which the \"participants\" are groups of bidders rather than individuals.","Bidders form DAOs to pool resources, but must then also negotiate the terms by which the DAO's winnings are shared.","We model the outcome of a DAO's negotiations by an aggregation function (which aggregates DAO members' bids into a single group bid), and a budget-balanced cost-sharing mechanism (that determines DAO members' access to the DAO's allocation and distributes the total payment demanded from the DAO to its members).","We pursue two-level mechanisms that are incentive-compatible (with truthful bidding a dominant strategy for members of each DAO) and approximately welfare-optimal.","We prove that, even in the case of a single-item auction, incentive-compatible welfare maximization is not possible: No matter what the outer mechanism and the cost-sharing mechanisms used by DAOs, the welfare of the resulting two-level mechanism can be a $\\approx \\ln n$ factor less than optimal.","We complement this lower bound with a natural two-level mechanism that achieves a matching approximate welfare guarantee.","Our upper bound also extends to multi-item auctions where individuals have additive valuations.","Finally, we show that our positive results cannot be extended much further: Even in multi-item settings with unit-demand bidders, truthful two-level mechanisms form a highly restricted class and as a consequence cannot guarantee any non-trivial approximation of the maximum social welfare."],"url":"http://arxiv.org/abs/2306.17099v1"}
{"created":"2023-06-29 16:55:36","title":"Oriented Spanners","abstract":"Given a point set $P$ in the Euclidean plane and a parameter $t$, we define an \\emph{oriented $t$-spanner} as an oriented subgraph of the complete bi-directed graph such that for every pair of points, the shortest cycle in $G$ through those points is at most a factor $t$ longer than the shortest oriented cycle in the complete bi-directed graph. We investigate the problem of computing sparse graphs with small oriented dilation.   As we can show that minimising oriented dilation for a given number of edges is NP-hard in the plane, we first consider one-dimensional point sets. While obtaining a $1$-spanner in this setting is straightforward, already for five points such a spanner has no plane embedding with the leftmost and rightmost point on the outer face.   This leads to restricting to oriented graphs with a one-page book embedding on the one-dimensional point set. For this case we present a dynamic program to compute the graph of minimum oriented dilation that runs in $O(n^8)$ time for $n$ points, and a greedy algorithm that computes a $5$-spanner in $O(n\\log n)$ time.   Expanding these results finally gives us a result for two-dimensional point sets: we prove that for convex point sets the greedy triangulation results in an oriented $O(1)$-spanner.","sentences":["Given a point set $P$ in the Euclidean plane and a parameter $t$, we define an \\emph{oriented $t$-spanner} as an oriented subgraph of the complete bi-directed graph such that for every pair of points, the shortest cycle in $G$ through those points is at most a factor $t$ longer than the shortest oriented cycle in the complete bi-directed graph.","We investigate the problem of computing sparse graphs with small oriented dilation.   ","As we can show that minimising oriented dilation for a given number of edges is NP-hard in the plane, we first consider one-dimensional point sets.","While obtaining a $1$-spanner in this setting is straightforward, already for five points such a spanner has no plane embedding with the leftmost and rightmost point on the outer face.   ","This leads to restricting to oriented graphs with a one-page book embedding on the one-dimensional point set.","For this case we present a dynamic program to compute the graph of minimum oriented dilation that runs in $O(n^8)$ time for $n$ points, and a greedy algorithm that computes a $5$-spanner in $O(n\\log n)$ time.   ","Expanding these results finally gives us a result for two-dimensional point sets: we prove that for convex point sets the greedy triangulation results in an oriented $O(1)$-spanner."],"url":"http://arxiv.org/abs/2306.17097v1"}
{"created":"2023-06-29 16:48:15","title":"The Importance of Robust Features in Mitigating Catastrophic Forgetting","abstract":"Continual learning (CL) is an approach to address catastrophic forgetting, which refers to forgetting previously learned knowledge by neural networks when trained on new tasks or data distributions. The adversarial robustness has decomposed features into robust and non-robust types and demonstrated that models trained on robust features significantly enhance adversarial robustness. However, no study has been conducted on the efficacy of robust features from the lens of the CL model in mitigating catastrophic forgetting in CL. In this paper, we introduce the CL robust dataset and train four baseline models on both the standard and CL robust datasets. Our results demonstrate that the CL models trained on the CL robust dataset experienced less catastrophic forgetting of the previously learned tasks than when trained on the standard dataset. Our observations highlight the significance of the features provided to the underlying CL models, showing that CL robust features can alleviate catastrophic forgetting.","sentences":["Continual learning (CL) is an approach to address catastrophic forgetting, which refers to forgetting previously learned knowledge by neural networks when trained on new tasks or data distributions.","The adversarial robustness has decomposed features into robust and non-robust types and demonstrated that models trained on robust features significantly enhance adversarial robustness.","However, no study has been conducted on the efficacy of robust features from the lens of the CL model in mitigating catastrophic forgetting in CL.","In this paper, we introduce the CL robust dataset and train four baseline models on both the standard and CL robust datasets.","Our results demonstrate that the CL models trained on the CL robust dataset experienced less catastrophic forgetting of the previously learned tasks than when trained on the standard dataset.","Our observations highlight the significance of the features provided to the underlying CL models, showing that CL robust features can alleviate catastrophic forgetting."],"url":"http://arxiv.org/abs/2306.17091v1"}
{"created":"2023-06-29 16:48:00","title":"Sparsity exploitation via discovering graphical models in multi-variate time-series forecasting","abstract":"Graph neural networks (GNNs) have been widely applied in multi-variate time-series forecasting (MTSF) tasks because of their capability in capturing the correlations among different time-series. These graph-based learning approaches improve the forecasting performance by discovering and understanding the underlying graph structures, which represent the data correlation. When the explicit prior graph structures are not available, most existing works cannot guarantee the sparsity of the generated graphs that make the overall model computational expensive and less interpretable. In this work, we propose a decoupled training method, which includes a graph generating module and a GNNs forecasting module. First, we use Graphical Lasso (or GraphLASSO) to directly exploit the sparsity pattern from data to build graph structures in both static and time-varying cases. Second, we fit these graph structures and the input data into a Graph Convolutional Recurrent Network (GCRN) to train a forecasting model. The experimental results on three real-world datasets show that our novel approach has competitive performance against existing state-of-the-art forecasting algorithms while providing sparse, meaningful and explainable graph structures and reducing training time by approximately 40%. Our PyTorch implementation is publicly available at https://github.com/HySonLab/GraphLASSO","sentences":["Graph neural networks (GNNs) have been widely applied in multi-variate time-series forecasting (MTSF) tasks because of their capability in capturing the correlations among different time-series.","These graph-based learning approaches improve the forecasting performance by discovering and understanding the underlying graph structures, which represent the data correlation.","When the explicit prior graph structures are not available, most existing works cannot guarantee the sparsity of the generated graphs that make the overall model computational expensive and less interpretable.","In this work, we propose a decoupled training method, which includes a graph generating module and a GNNs forecasting module.","First, we use Graphical Lasso (or GraphLASSO) to directly exploit the sparsity pattern from data to build graph structures in both static and time-varying cases.","Second, we fit these graph structures and the input data into a Graph Convolutional Recurrent Network (GCRN) to train a forecasting model.","The experimental results on three real-world datasets show that our novel approach has competitive performance against existing state-of-the-art forecasting algorithms while providing sparse, meaningful and explainable graph structures and reducing training time by approximately 40%.","Our PyTorch implementation is publicly available at https://github.com/HySonLab/GraphLASSO"],"url":"http://arxiv.org/abs/2306.17090v1"}
{"created":"2023-06-29 16:47:11","title":"Concept-Oriented Deep Learning with Large Language Models","abstract":"Large Language Models (LLMs) have been successfully used in many natural-language tasks and applications including text generation and AI chatbots. They also are a promising new technology for concept-oriented deep learning (CODL). However, the prerequisite is that LLMs understand concepts and ensure conceptual consistency. We discuss these in this paper, as well as major uses of LLMs for CODL including concept extraction from text, concept graph extraction from text, and concept learning. Human knowledge consists of both symbolic (conceptual) knowledge and embodied (sensory) knowledge. Text-only LLMs, however, can represent only symbolic (conceptual) knowledge. Multimodal LLMs, on the other hand, are capable of representing the full range (conceptual and sensory) of human knowledge. We discuss conceptual understanding in visual-language LLMs, the most important multimodal LLMs, and major uses of them for CODL including concept extraction from image, concept graph extraction from image, and concept learning. While uses of LLMs for CODL are valuable standalone, they are particularly valuable as part of LLM applications such as AI chatbots.","sentences":["Large Language Models (LLMs) have been successfully used in many natural-language tasks and applications including text generation and AI chatbots.","They also are a promising new technology for concept-oriented deep learning (CODL).","However, the prerequisite is that LLMs understand concepts and ensure conceptual consistency.","We discuss these in this paper, as well as major uses of LLMs for CODL including concept extraction from text, concept graph extraction from text, and concept learning.","Human knowledge consists of both symbolic (conceptual) knowledge and embodied (sensory) knowledge.","Text-only LLMs, however, can represent only symbolic (conceptual) knowledge.","Multimodal LLMs, on the other hand, are capable of representing the full range (conceptual and sensory) of human knowledge.","We discuss conceptual understanding in visual-language LLMs, the most important multimodal LLMs, and major uses of them for CODL including concept extraction from image, concept graph extraction from image, and concept learning.","While uses of LLMs for CODL are valuable standalone, they are particularly valuable as part of LLM applications such as AI chatbots."],"url":"http://arxiv.org/abs/2306.17089v1"}
{"created":"2023-06-29 16:36:05","title":"Re-Rank - Expand - Repeat: Adaptive Query Expansion for Document Retrieval Using Words and Entities","abstract":"Sparse and dense pseudo-relevance feedback (PRF) approaches perform poorly on challenging queries due to low precision in first-pass retrieval. However, recent advances in neural language models (NLMs) can re-rank relevant documents to top ranks, even when few are in the re-ranking pool. This paper first addresses the problem of poor pseudo-relevance feedback by simply applying re-ranking prior to query expansion and re-executing this query. We find that this change alone can improve the retrieval effectiveness of sparse and dense PRF approaches by 5-8%. Going further, we propose a new expansion model, Latent Entity Expansion (LEE), a fine-grained word and entity-based relevance modelling incorporating localized features. Finally, we include an \"adaptive\" component to the retrieval process, which iteratively refines the re-ranking pool during scoring using the expansion model, i.e. we \"re-rank - expand - repeat\". Using LEE, we achieve (to our knowledge) the best NDCG, MAP and R@1000 results on the TREC Robust 2004 and CODEC adhoc document datasets, demonstrating a significant advancement in expansion effectiveness.","sentences":["Sparse and dense pseudo-relevance feedback (PRF) approaches perform poorly on challenging queries due to low precision in first-pass retrieval.","However, recent advances in neural language models (NLMs) can re-rank relevant documents to top ranks, even when few are in the re-ranking pool.","This paper first addresses the problem of poor pseudo-relevance feedback by simply applying re-ranking prior to query expansion and re-executing this query.","We find that this change alone can improve the retrieval effectiveness of sparse and dense PRF approaches by 5-8%.","Going further, we propose a new expansion model, Latent Entity Expansion (LEE), a fine-grained word and entity-based relevance modelling incorporating localized features.","Finally, we include an \"adaptive\" component to the retrieval process, which iteratively refines the re-ranking pool during scoring using the expansion model, i.e. we \"re-rank - expand - repeat\".","Using LEE, we achieve (to our knowledge) the best NDCG, MAP and R@1000 results on the TREC Robust 2004 and CODEC adhoc document datasets, demonstrating a significant advancement in expansion effectiveness."],"url":"http://arxiv.org/abs/2306.17082v1"}
{"created":"2023-06-29 16:28:34","title":"RAPGen: An Approach for Fixing Code Inefficiencies in Zero-Shot","abstract":"Performance bugs are non-functional bugs that can even manifest in well-tested commercial products. Fixing these performance bugs is an important yet challenging problem. In this work, we address this challenge and present a new approach called Retrieval-Augmented Prompt Generation (RAPGen). Given a code snippet with a performance issue, RAPGen first retrieves a prompt instruction from a pre-constructed knowledge-base of previous performance bug fixes and then generates a prompt using the retrieved instruction. It then uses this prompt on a Large Language Model (such as Codex) in zero-shot to generate a fix. We compare our approach with the various prompt variations and state of the art methods in the task of performance bug fixing. Our evaluation shows that RAPGen can generate performance improvement suggestions equivalent or better than a developer in ~60% of the cases, getting ~39% of them verbatim, in an expert-verified dataset of past performance changes made by C# developers.","sentences":["Performance bugs are non-functional bugs that can even manifest in well-tested commercial products.","Fixing these performance bugs is an important yet challenging problem.","In this work, we address this challenge and present a new approach called Retrieval-Augmented Prompt Generation (RAPGen).","Given a code snippet with a performance issue, RAPGen first retrieves a prompt instruction from a pre-constructed knowledge-base of previous performance bug fixes and then generates a prompt using the retrieved instruction.","It then uses this prompt on a Large Language Model (such as Codex) in zero-shot to generate a fix.","We compare our approach with the various prompt variations and state of the art methods in the task of performance bug fixing.","Our evaluation shows that RAPGen can generate performance improvement suggestions equivalent or better than a developer in ~60% of the cases, getting ~39% of them verbatim, in an expert-verified dataset of past performance changes made by C# developers."],"url":"http://arxiv.org/abs/2306.17077v1"}
{"created":"2023-06-29 16:25:04","title":"Detect Any Deepfakes: Segment Anything Meets Face Forgery Detection and Localization","abstract":"The rapid advancements in computer vision have stimulated remarkable progress in face forgery techniques, capturing the dedicated attention of researchers committed to detecting forgeries and precisely localizing manipulated areas. Nonetheless, with limited fine-grained pixel-wise supervision labels, deepfake detection models perform unsatisfactorily on precise forgery detection and localization. To address this challenge, we introduce the well-trained vision segmentation foundation model, i.e., Segment Anything Model (SAM) in face forgery detection and localization. Based on SAM, we propose the Detect Any Deepfakes (DADF) framework with the Multiscale Adapter, which can capture short- and long-range forgery contexts for efficient fine-tuning. Moreover, to better identify forged traces and augment the model's sensitivity towards forgery regions, Reconstruction Guided Attention (RGA) module is proposed. The proposed framework seamlessly integrates end-to-end forgery localization and detection optimization. Extensive experiments on three benchmark datasets demonstrate the superiority of our approach for both forgery detection and localization. The codes will be released soon at https://github.com/laiyingxin2/DADF.","sentences":["The rapid advancements in computer vision have stimulated remarkable progress in face forgery techniques, capturing the dedicated attention of researchers committed to detecting forgeries and precisely localizing manipulated areas.","Nonetheless, with limited fine-grained pixel-wise supervision labels, deepfake detection models perform unsatisfactorily on precise forgery detection and localization.","To address this challenge, we introduce the well-trained vision segmentation foundation model, i.e., Segment Anything Model (SAM) in face forgery detection and localization.","Based on SAM, we propose the Detect Any Deepfakes (DADF) framework with the Multiscale Adapter, which can capture short- and long-range forgery contexts for efficient fine-tuning.","Moreover, to better identify forged traces and augment the model's sensitivity towards forgery regions, Reconstruction Guided Attention (RGA) module is proposed.","The proposed framework seamlessly integrates end-to-end forgery localization and detection optimization.","Extensive experiments on three benchmark datasets demonstrate the superiority of our approach for both forgery detection and localization.","The codes will be released soon at https://github.com/laiyingxin2/DADF."],"url":"http://arxiv.org/abs/2306.17075v1"}
{"created":"2023-06-29 16:24:32","title":"Learning Structure-Guided Diffusion Model for 2D Human Pose Estimation","abstract":"One of the mainstream schemes for 2D human pose estimation (HPE) is learning keypoints heatmaps by a neural network. Existing methods typically improve the quality of heatmaps by customized architectures, such as high-resolution representation and vision Transformers. In this paper, we propose \\textbf{DiffusionPose}, a new scheme that formulates 2D HPE as a keypoints heatmaps generation problem from noised heatmaps. During training, the keypoints are diffused to random distribution by adding noises and the diffusion model learns to recover ground-truth heatmaps from noised heatmaps with respect to conditions constructed by image feature. During inference, the diffusion model generates heatmaps from initialized heatmaps in a progressive denoising way. Moreover, we further explore improving the performance of DiffusionPose with conditions from human structural information. Extensive experiments show the prowess of our DiffusionPose, with improvements of 1.6, 1.2, and 1.2 mAP on widely-used COCO, CrowdPose, and AI Challenge datasets, respectively.","sentences":["One of the mainstream schemes for 2D human pose estimation (HPE) is learning keypoints heatmaps by a neural network.","Existing methods typically improve the quality of heatmaps by customized architectures, such as high-resolution representation and vision Transformers.","In this paper, we propose \\textbf{DiffusionPose}, a new scheme that formulates 2D HPE as a keypoints heatmaps generation problem from noised heatmaps.","During training, the keypoints are diffused to random distribution by adding noises and the diffusion model learns to recover ground-truth heatmaps from noised heatmaps with respect to conditions constructed by image feature.","During inference, the diffusion model generates heatmaps from initialized heatmaps in a progressive denoising way.","Moreover, we further explore improving the performance of DiffusionPose with conditions from human structural information.","Extensive experiments show the prowess of our DiffusionPose, with improvements of 1.6, 1.2, and 1.2 mAP on widely-used COCO, CrowdPose, and AI Challenge datasets, respectively."],"url":"http://arxiv.org/abs/2306.17074v1"}
{"created":"2023-06-29 16:24:30","title":"Axis-Parallel Right Angle Crossing Graphs","abstract":"A RAC graph is one admitting a RAC drawing, that is, a polyline drawing in which each crossing occurs at a right angle. Originally motivated by psychological studies on readability of graph layouts, RAC graphs form one of the most prominent graph classes in beyond planarity.   In this work, we study a subclass of RAC graphs, called axis-parallel RAC (or apRAC, for short), that restricts the crossings to pairs of axis-parallel edge-segments. apRAC drawings combine the readability of planar drawings with the clarity of (non-planar) orthogonal drawings. We consider these graphs both with and without bends. Our contribution is as follows: (i) We study inclusion relationships between apRAC and traditional RAC graphs. (ii) We establish bounds on the edge density of apRAC graphs. (iii) We show that every graph with maximum degree 8 is 2-bend apRAC and give a linear time drawing algorithm. Some of our results on apRAC graphs also improve the state of the art for general RAC graphs. We conclude our work with a list of open questions and a discussion of a natural generalization of the apRAC model.","sentences":["A RAC graph is one admitting a RAC drawing, that is, a polyline drawing in which each crossing occurs at a right angle.","Originally motivated by psychological studies on readability of graph layouts, RAC graphs form one of the most prominent graph classes in beyond planarity.   ","In this work, we study a subclass of RAC graphs, called axis-parallel RAC (or apRAC, for short), that restricts the crossings to pairs of axis-parallel edge-segments.","apRAC drawings combine the readability of planar drawings with the clarity of (non-planar) orthogonal drawings.","We consider these graphs both with and without bends.","Our contribution is as follows: (i) We study inclusion relationships between apRAC and traditional RAC graphs.","(ii) We establish bounds on the edge density of apRAC graphs.","(iii) We show that every graph with maximum degree 8 is 2-bend apRAC and give a linear time drawing algorithm.","Some of our results on apRAC graphs also improve the state of the art for general RAC graphs.","We conclude our work with a list of open questions and a discussion of a natural generalization of the apRAC model."],"url":"http://arxiv.org/abs/2306.17073v1"}
{"created":"2023-06-29 16:17:04","title":"Interdisciplinary Methods in Computational Creativity: How Human Variables Shape Human-Inspired AI Research","abstract":"The word creativity originally described a concept from human psychology, but in the realm of computational creativity (CC), it has become much more. The question of what creativity means when it is part of a computational system might be considered core to CC. Pinning down the meaning of creativity, and concepts like it, becomes salient when researchers port concepts from human psychology to computation, a widespread practice extending beyond CC into artificial intelligence (AI). Yet, the human processes shaping human-inspired computational systems have been little investigated. In this paper, we question which human literatures (social sciences, psychology, neuroscience) enter AI scholarship and how they are translated at the port of entry. This study is based on 22 in-depth, semi-structured interviews, primarily with human-inspired AI researchers, half of whom focus on creativity as a major research area. This paper focuses on findings most relevant to CC. We suggest that which human literature enters AI bears greater scrutiny because ideas may become disconnected from context in their home discipline. Accordingly, we recommend that CC researchers document the decisions and context of their practices, particularly those practices formalizing human concepts for machines. Publishing reflexive commentary on human elements in CC and AI would provide a useful record and permit greater dialogue with other disciplines.","sentences":["The word creativity originally described a concept from human psychology, but in the realm of computational creativity (CC), it has become much more.","The question of what creativity means when it is part of a computational system might be considered core to CC.","Pinning down the meaning of creativity, and concepts like it, becomes salient when researchers port concepts from human psychology to computation, a widespread practice extending beyond CC into artificial intelligence (AI).","Yet, the human processes shaping human-inspired computational systems have been little investigated.","In this paper, we question which human literatures (social sciences, psychology, neuroscience) enter AI scholarship and how they are translated at the port of entry.","This study is based on 22 in-depth, semi-structured interviews, primarily with human-inspired AI researchers, half of whom focus on creativity as a major research area.","This paper focuses on findings most relevant to CC.","We suggest that which human literature enters AI bears greater scrutiny because ideas may become disconnected from context in their home discipline.","Accordingly, we recommend that CC researchers document the decisions and context of their practices, particularly those practices formalizing human concepts for machines.","Publishing reflexive commentary on human elements in CC and AI would provide a useful record and permit greater dialogue with other disciplines."],"url":"http://arxiv.org/abs/2306.17070v1"}
{"created":"2023-06-29 16:14:43","title":"On the Predictive Accuracy of Neural Temporal Point Process Models for Continuous-time Event Data","abstract":"Temporal Point Processes (TPPs) serve as the standard mathematical framework for modeling asynchronous event sequences in continuous time. However, classical TPP models are often constrained by strong assumptions, limiting their ability to capture complex real-world event dynamics. To overcome this limitation, researchers have proposed Neural TPPs, which leverage neural network parametrizations to offer more flexible and efficient modeling. While recent studies demonstrate the effectiveness of Neural TPPs, they often lack a unified setup, relying on different baselines, datasets, and experimental configurations. This makes it challenging to identify the key factors driving improvements in predictive accuracy, hindering research progress. To bridge this gap, we present a comprehensive large-scale experimental study that systematically evaluates the predictive accuracy of state-of-the-art neural TPP models. Our study encompasses multiple real-world and synthetic event sequence datasets, following a carefully designed unified setup. We thoroughly investigate the influence of major architectural components such as event encoding, history encoder, and decoder parametrization on both time and mark prediction tasks. Additionally, we delve into the less explored area of probabilistic calibration for neural TPP models. By analyzing our results, we draw insightful conclusions regarding the significance of history size and the impact of architectural components on predictive accuracy. Furthermore, we shed light on the miscalibration of mark distributions in neural TPP models. Our study aims to provide valuable insights into the performance and characteristics of neural TPP models, contributing to a better understanding of their strengths and limitations.","sentences":["Temporal Point Processes (TPPs) serve as the standard mathematical framework for modeling asynchronous event sequences in continuous time.","However, classical TPP models are often constrained by strong assumptions, limiting their ability to capture complex real-world event dynamics.","To overcome this limitation, researchers have proposed Neural TPPs, which leverage neural network parametrizations to offer more flexible and efficient modeling.","While recent studies demonstrate the effectiveness of Neural TPPs, they often lack a unified setup, relying on different baselines, datasets, and experimental configurations.","This makes it challenging to identify the key factors driving improvements in predictive accuracy, hindering research progress.","To bridge this gap, we present a comprehensive large-scale experimental study that systematically evaluates the predictive accuracy of state-of-the-art neural TPP models.","Our study encompasses multiple real-world and synthetic event sequence datasets, following a carefully designed unified setup.","We thoroughly investigate the influence of major architectural components such as event encoding, history encoder, and decoder parametrization on both time and mark prediction tasks.","Additionally, we delve into the less explored area of probabilistic calibration for neural TPP models.","By analyzing our results, we draw insightful conclusions regarding the significance of history size and the impact of architectural components on predictive accuracy.","Furthermore, we shed light on the miscalibration of mark distributions in neural TPP models.","Our study aims to provide valuable insights into the performance and characteristics of neural TPP models, contributing to a better understanding of their strengths and limitations."],"url":"http://arxiv.org/abs/2306.17066v1"}
{"created":"2023-06-29 16:12:53","title":"5-Approximation for $\\mathcal{H}$-Treewidth Essentially as Fast as $\\mathcal{H}$-Deletion Parameterized by Solution Size","abstract":"The notion of $\\mathcal{H}$-treewidth, where $\\mathcal{H}$ is a hereditary graph class, was recently introduced as a generalization of the treewidth of an undirected graph. Roughly speaking, a graph of $\\mathcal{H}$-treewidth at most $k$ can be decomposed into (arbitrarily large) $\\mathcal{H}$-subgraphs which interact only through vertex sets of size $O(k)$ which can be organized in a tree-like fashion. $\\mathcal{H}$-treewidth can be used as a hybrid parameterization to develop fixed-parameter tractable algorithms for $\\mathcal{H}$-deletion problems, which ask to find a minimum vertex set whose removal from a given graph $G$ turns it into a member of $\\mathcal{H}$. The bottleneck in the current parameterized algorithms lies in the computation of suitable tree $\\mathcal{H}$-decompositions.   We present FPT approximation algorithms to compute tree $\\mathcal{H}$-decompositions for hereditary and union-closed graph classes $\\mathcal{H}$. Given a graph of $\\mathcal{H}$-treewidth $k$, we can compute a 5-approximate tree $\\mathcal{H}$-decomposition in time $f(O(k)) \\cdot n^{O(1)}$ whenever $\\mathcal{H}$-deletion parameterized by solution size can be solved in time $f(k) \\cdot n^{O(1)}$ for some function $f(k) \\geq 2^k$. The current-best algorithms either achieve an approximation factor of $k^{O(1)}$ or construct optimal decompositions while suffering from non-uniformity with unknown parameter dependence. Using these decompositions, we obtain algorithms solving Odd Cycle Transversal in time $2^{O(k)} \\cdot n^{O(1)}$ parameterized by $\\mathsf{bipartite}$-treewidth and Vertex Planarization in time $2^{O(k \\log k)} \\cdot n^{O(1)}$ parameterized by $\\mathsf{planar}$-treewidth, showing that these can be as fast as the solution-size parameterizations and giving the first ETH-tight algorithms for parameterizations by hybrid width measures.","sentences":["The notion of $\\mathcal{H}$-treewidth, where $\\mathcal{H}$ is a hereditary graph class, was recently introduced as a generalization of the treewidth of an undirected graph.","Roughly speaking, a graph of $\\mathcal{H}$-treewidth at most $k$ can be decomposed into (arbitrarily large) $\\mathcal{H}$-subgraphs which interact only through vertex sets of size $O(k)$ which can be organized in a tree-like fashion.","$\\mathcal{H}$-treewidth can be used as a hybrid parameterization to develop fixed-parameter tractable algorithms for $\\mathcal{H}$-deletion problems, which ask to find a minimum vertex set whose removal from a given graph $G$ turns it into a member of $\\mathcal{H}$. The bottleneck in the current parameterized algorithms lies in the computation of suitable tree $\\mathcal{H}$-decompositions.   ","We present FPT approximation algorithms to compute tree $\\mathcal{H}$-decompositions for hereditary and union-closed graph classes $\\mathcal{H}$. Given a graph of $\\mathcal{H}$-treewidth $k$, we can compute a 5-approximate tree $\\mathcal{H}$-decomposition in time $f(O(k))","\\cdot n^{O(1)}$ whenever $\\mathcal{H}$-deletion parameterized by solution size can be solved in time $f(k) \\cdot n^{O(1)}$ for some function $f(k)","\\geq","2^k$.","The current-best algorithms either achieve an approximation factor of $k^{O(1)}$ or construct optimal decompositions while suffering from non-uniformity with unknown parameter dependence.","Using these decompositions, we obtain algorithms solving Odd Cycle Transversal in time $2^{O(k)} \\cdot n^{O(1)}$ parameterized by $\\mathsf{bipartite}$-treewidth and Vertex Planarization in time $2^{O(k \\log k)} \\cdot n^{O(1)}$ parameterized by $\\mathsf{planar}$-treewidth, showing that these can be as fast as the solution-size parameterizations and giving the first ETH-tight algorithms for parameterizations by hybrid width measures."],"url":"http://arxiv.org/abs/2306.17065v1"}
{"created":"2023-06-29 16:10:18","title":"Honesty is the Best Policy: On the Accuracy of Apple Privacy Labels Compared to Apps' Privacy Policies","abstract":"Apple introduced \\textit{privacy labels} in Dec. 2020 as a way for developers to report the privacy behaviors of their apps. While Apple does not validate labels, they do also require developers to provide a privacy policy, which offers an important comparison point. In this paper, we applied the NLP framework of Polisis to extract features of the privacy policy for 515,920 apps on the iOS App Store comparing the output to the privacy labels. We identify discrepancies between the policies and the labels, particularly as it relates to data collected that is linked to users. We find that 287$\\pm196$K apps' privacy policies may indicate data collection that is linked to users than what is reported in the privacy labels. More alarming, a large number of (97$\\pm30$\\%) of the apps that have {\\em Data Not Collected} privacy label have a privacy policy that indicates otherwise. We provide insights into potential sources for discrepancies, including the use of templates and confusion around Apple's definitions and requirements. These results suggest that there is still significant work to be done to help developers more accurately labeling their apps. Incorporating a Polisis-like system as a first-order check can help improve the current state and better inform developers when there are possible misapplication of privacy labels.","sentences":["Apple introduced \\textit{privacy labels} in Dec. 2020 as a way for developers to report the privacy behaviors of their apps.","While Apple does not validate labels, they do also require developers to provide a privacy policy, which offers an important comparison point.","In this paper, we applied the NLP framework of Polisis to extract features of the privacy policy for 515,920 apps on the iOS App Store comparing the output to the privacy labels.","We identify discrepancies between the policies and the labels, particularly as it relates to data collected that is linked to users.","We find that 287$\\pm196$K apps' privacy policies may indicate data collection that is linked to users than what is reported in the privacy labels.","More alarming, a large number of (97$\\pm30$\\%) of the apps that have {\\em Data Not Collected} privacy label have a privacy policy that indicates otherwise.","We provide insights into potential sources for discrepancies, including the use of templates and confusion around Apple's definitions and requirements.","These results suggest that there is still significant work to be done to help developers more accurately labeling their apps.","Incorporating a Polisis-like system as a first-order check can help improve the current state and better inform developers when there are possible misapplication of privacy labels."],"url":"http://arxiv.org/abs/2306.17063v1"}
{"created":"2023-06-29 16:10:07","title":"Gesture Recognition with mmWave Wi-Fi Access Points: Lessons Learned","abstract":"In recent years, channel state information (CSI) at sub-6 GHz has been widely exploited for Wi-Fi sensing, particularly for activity and gesture recognition. In this work, we instead explore mmWave (60 GHz) Wi-Fi signals for gesture recognition/pose estimation. Our focus is on the mmWave Wi-Fi signals so that they can be used not only for high data rate communication but also for improved sensing e.g., for extended reality (XR) applications. For this reason, we extract spatial beam signal-to-noise ratios (SNRs) from the periodic beam training employed by IEEE 802.11ad devices. We consider a set of 10 gestures/poses motivated by XR applications. We conduct experiments in two environments and with three people.As a comparison, we also collect CSI from IEEE 802.11ac devices. To extract features from the CSI and the beam SNR, we leverage a deep neural network (DNN). The DNN classifier achieves promising results on the beam SNR task with state-of-the-art 96.7% accuracy in a single environment, even with a limited dataset. We also investigate the robustness of the beam SNR against CSI across different environments. Our experiments reveal that features from the CSI generalize without additional re-training, while those from beam SNRs do not. Therefore, re-training is required in the latter case.","sentences":["In recent years, channel state information (CSI) at sub-6 GHz has been widely exploited for Wi-Fi sensing, particularly for activity and gesture recognition.","In this work, we instead explore mmWave (60 GHz)","Wi-Fi signals for gesture recognition/pose estimation.","Our focus is on the mmWave Wi-Fi signals so that they can be used not only for high data rate communication but also for improved sensing e.g., for extended reality (XR) applications.","For this reason, we extract spatial beam signal-to-noise ratios (SNRs) from the periodic beam training employed by IEEE 802.11ad devices.","We consider a set of 10 gestures/poses motivated by XR applications.","We conduct experiments in two environments and with three people.","As a comparison, we also collect CSI from IEEE 802.11ac devices.","To extract features from the CSI and the beam SNR, we leverage a deep neural network (DNN).","The DNN classifier achieves promising results on the beam SNR task with state-of-the-art 96.7% accuracy in a single environment, even with a limited dataset.","We also investigate the robustness of the beam SNR against CSI across different environments.","Our experiments reveal that features from the CSI generalize without additional re-training, while those from beam SNRs do not.","Therefore, re-training is required in the latter case."],"url":"http://arxiv.org/abs/2306.17062v1"}
{"created":"2023-06-29 16:09:56","title":"RowPress: Amplifying Read Disturbance in Modern DRAM Chips","abstract":"Memory isolation is critical for system reliability, security, and safety. Unfortunately, read disturbance can break memory isolation in modern DRAM chips. For example, RowHammer is a well-studied read-disturb phenomenon where repeatedly opening and closing (i.e., hammering) a DRAM row many times causes bitflips in physically nearby rows.   This paper experimentally demonstrates and analyzes another widespread read-disturb phenomenon, RowPress, in real DDR4 DRAM chips. RowPress breaks memory isolation by keeping a DRAM row open for a long period of time, which disturbs physically nearby rows enough to cause bitflips. We show that RowPress amplifies DRAM's vulnerability to read-disturb attacks by significantly reducing the number of row activations needed to induce a bitflip by one to two orders of magnitude under realistic conditions. In extreme cases, RowPress induces bitflips in a DRAM row when an adjacent row is activated only once. Our detailed characterization of 164 real DDR4 DRAM chips shows that RowPress 1) affects chips from all three major DRAM manufacturers, 2) gets worse as DRAM technology scales down to smaller node sizes, and 3) affects a different set of DRAM cells from RowHammer and behaves differently from RowHammer as temperature and access pattern changes.   We demonstrate in a real DDR4-based system with RowHammer protection that 1) a user-level program induces bitflips by leveraging RowPress while conventional RowHammer cannot do so, and 2) a memory controller that adaptively keeps the DRAM row open for a longer period of time based on access pattern can facilitate RowPress-based attacks. To prevent bitflips due to RowPress, we describe and evaluate a new methodology that adapts existing RowHammer mitigation techniques to also mitigate RowPress with low additional performance overhead. We open source all our code and data to facilitate future research on RowPress.","sentences":["Memory isolation is critical for system reliability, security, and safety.","Unfortunately, read disturbance can break memory isolation in modern DRAM chips.","For example, RowHammer is a well-studied read-disturb phenomenon where repeatedly opening and closing (i.e., hammering) a DRAM row many times causes bitflips in physically nearby rows.   ","This paper experimentally demonstrates and analyzes another widespread read-disturb phenomenon, RowPress, in real DDR4 DRAM chips.","RowPress breaks memory isolation by keeping a DRAM row open for a long period of time, which disturbs physically nearby rows enough to cause bitflips.","We show that RowPress amplifies DRAM's vulnerability to read-disturb attacks by significantly reducing the number of row activations needed to induce a bitflip by one to two orders of magnitude under realistic conditions.","In extreme cases, RowPress induces bitflips in a DRAM row when an adjacent row is activated only once.","Our detailed characterization of 164 real DDR4 DRAM chips shows that RowPress 1) affects chips from all three major DRAM manufacturers, 2) gets worse as DRAM technology scales down to smaller node sizes, and 3) affects a different set of DRAM cells from RowHammer and behaves differently from RowHammer as temperature and access pattern changes.   ","We demonstrate in a real DDR4-based system with RowHammer protection that 1) a user-level program induces bitflips by leveraging RowPress while conventional RowHammer cannot do so, and 2) a memory controller that adaptively keeps the DRAM row open for a longer period of time based on access pattern can facilitate RowPress-based attacks.","To prevent bitflips due to RowPress, we describe and evaluate a new methodology that adapts existing RowHammer mitigation techniques to also mitigate RowPress with low additional performance overhead.","We open source all our code and data to facilitate future research on RowPress."],"url":"http://arxiv.org/abs/2306.17061v1"}
{"created":"2023-06-29 16:05:40","title":"The mapKurator System: A Complete Pipeline for Extracting and Linking Text from Historical Maps","abstract":"Documents hold spatial focus and valuable locality characteristics. For example, descriptions of listings in real estate or travel blogs contain information about specific local neighborhoods. This information is valuable to characterize how humans perceive their environment. However, the first step to making use of this information is to identify the spatial focus (e.g., a city) of a document. Traditional approaches for identifying the spatial focus of a document rely on detecting and disambiguating toponyms from the document. This approach requires a vocabulary set of location phrases and ad-hoc rules, which ignore important words related to location. Recent topic modeling approaches using large language models often consider a few topics, each with broad coverage. In contrast, the spatial focus of a document can be a country, a city, or even a neighborhood, which together, is much larger than the number of topics considered in these approaches. Additionally, topic modeling methods are often applied to broad topics of news articles where context is easily distinguishable. To identify the geographic focus of a document effectively, we present a simple but effective Joint Embedding of multi-LocaLitY (JELLY), which jointly learns representations with separate encoders of document and location. JELLY significantly outperforms state-of-the-art methods for identifying spatial focus from documents from a number of sources. We also demonstrate case studies on the arithmetic of the learned representations, including identifying cities with similar locality characteristics and zero-shot learning to identify document spatial focus.","sentences":["Documents hold spatial focus and valuable locality characteristics.","For example, descriptions of listings in real estate or travel blogs contain information about specific local neighborhoods.","This information is valuable to characterize how humans perceive their environment.","However, the first step to making use of this information is to identify the spatial focus (e.g., a city) of a document.","Traditional approaches for identifying the spatial focus of a document rely on detecting and disambiguating toponyms from the document.","This approach requires a vocabulary set of location phrases and ad-hoc rules, which ignore important words related to location.","Recent topic modeling approaches using large language models often consider a few topics, each with broad coverage.","In contrast, the spatial focus of a document can be a country, a city, or even a neighborhood, which together, is much larger than the number of topics considered in these approaches.","Additionally, topic modeling methods are often applied to broad topics of news articles where context is easily distinguishable.","To identify the geographic focus of a document effectively, we present a simple but effective Joint Embedding of multi-LocaLitY (JELLY), which jointly learns representations with separate encoders of document and location.","JELLY significantly outperforms state-of-the-art methods for identifying spatial focus from documents from a number of sources.","We also demonstrate case studies on the arithmetic of the learned representations, including identifying cities with similar locality characteristics and zero-shot learning to identify document spatial focus."],"url":"http://arxiv.org/abs/2306.17059v1"}
{"created":"2023-06-29 16:00:06","title":"Two-tiered Online Optimization of Region-wide Datacenter Resource Allocation via Deep Reinforcement Learning","abstract":"This paper addresses the important need for advanced techniques in continuously allocating workloads on shared infrastructures in data centers, a problem arising due to the growing popularity and scale of cloud computing. It particularly emphasizes the scarcity of research ensuring guaranteed capacity in capacity reservations during large-scale failures. To tackle these issues, the paper presents scalable solutions for resource management. It builds on the prior establishment of capacity reservation in cluster management systems and the two-level resource allocation problem addressed by the Resource Allowance System (RAS). Recognizing the limitations of Mixed Integer Linear Programming (MILP) for server assignment in a dynamic environment, this paper proposes the use of Deep Reinforcement Learning (DRL), which has been successful in achieving long-term optimal results for time-varying systems. A novel two-level design that utilizes a DRL-based algorithm is introduced to solve optimal server-to-reservation assignment, taking into account of fault tolerance, server movement minimization, and network affinity requirements due to the impracticality of directly applying DRL algorithms to large-scale instances with millions of decision variables. The paper explores the interconnection of these levels and the benefits of such an approach for achieving long-term optimal results in the context of large-scale cloud systems. We further show in the experiment section that our two-level DRL approach outperforms the MIP solver and heuristic approaches and exhibits significantly reduced computation time compared to the MIP solver. Specifically, our two-level DRL approach performs 15% better than the MIP solver on minimizing the overall cost. Also, it uses only 26 seconds to execute 30 rounds of decision making, while the MIP solver needs nearly an hour.","sentences":["This paper addresses the important need for advanced techniques in continuously allocating workloads on shared infrastructures in data centers, a problem arising due to the growing popularity and scale of cloud computing.","It particularly emphasizes the scarcity of research ensuring guaranteed capacity in capacity reservations during large-scale failures.","To tackle these issues, the paper presents scalable solutions for resource management.","It builds on the prior establishment of capacity reservation in cluster management systems and the two-level resource allocation problem addressed by the Resource Allowance System (RAS).","Recognizing the limitations of Mixed Integer Linear Programming (MILP) for server assignment in a dynamic environment, this paper proposes the use of Deep Reinforcement Learning (DRL), which has been successful in achieving long-term optimal results for time-varying systems.","A novel two-level design that utilizes a DRL-based algorithm is introduced to solve optimal server-to-reservation assignment, taking into account of fault tolerance, server movement minimization, and network affinity requirements due to the impracticality of directly applying DRL algorithms to large-scale instances with millions of decision variables.","The paper explores the interconnection of these levels and the benefits of such an approach for achieving long-term optimal results in the context of large-scale cloud systems.","We further show in the experiment section that our two-level DRL approach outperforms the MIP solver and heuristic approaches and exhibits significantly reduced computation time compared to the MIP solver.","Specifically, our two-level DRL approach performs 15% better than the MIP solver on minimizing the overall cost.","Also, it uses only 26 seconds to execute 30 rounds of decision making, while the MIP solver needs nearly an hour."],"url":"http://arxiv.org/abs/2306.17054v1"}
{"created":"2023-06-29 15:59:04","title":"Spatial Reasoning via Deep Vision Models for Robotic Sequential Manipulation","abstract":"In this paper, we propose using deep neural architectures (i.e., vision transformers and ResNet) as heuristics for sequential decision-making in robotic manipulation problems. This formulation enables predicting the subset of objects that are relevant for completing a task. Such problems are often addressed by task and motion planning (TAMP) formulations combining symbolic reasoning and continuous motion planning. In essence, the action-object relationships are resolved for discrete, symbolic decisions that are used to solve manipulation motions (e.g., via nonlinear trajectory optimization). However, solving long-horizon tasks requires consideration of all possible action-object combinations which limits the scalability of TAMP approaches. To overcome this combinatorial complexity, we introduce a visual perception module integrated with a TAMP-solver. Given a task and an initial image of the scene, the learned model outputs the relevancy of objects to accomplish the task. By incorporating the predictions of the model into a TAMP formulation as a heuristic, the size of the search space is significantly reduced. Results show that our framework finds feasible solutions more efficiently when compared to a state-of-the-art TAMP solver.","sentences":["In this paper, we propose using deep neural architectures (i.e., vision transformers and ResNet) as heuristics for sequential decision-making in robotic manipulation problems.","This formulation enables predicting the subset of objects that are relevant for completing a task.","Such problems are often addressed by task and motion planning (TAMP) formulations combining symbolic reasoning and continuous motion planning.","In essence, the action-object relationships are resolved for discrete, symbolic decisions that are used to solve manipulation motions (e.g., via nonlinear trajectory optimization).","However, solving long-horizon tasks requires consideration of all possible action-object combinations which limits the scalability of TAMP approaches.","To overcome this combinatorial complexity, we introduce a visual perception module integrated with a TAMP-solver.","Given a task and an initial image of the scene, the learned model outputs the relevancy of objects to accomplish the task.","By incorporating the predictions of the model into a TAMP formulation as a heuristic, the size of the search space is significantly reduced.","Results show that our framework finds feasible solutions more efficiently when compared to a state-of-the-art TAMP solver."],"url":"http://arxiv.org/abs/2306.17053v1"}
{"created":"2023-06-29 15:57:07","title":"Safe Model-Based Multi-Agent Mean-Field Reinforcement Learning","abstract":"Many applications, e.g., in shared mobility, require coordinating a large number of agents. Mean-field reinforcement learning addresses the resulting scalability challenge by optimizing the policy of a representative agent. In this paper, we address an important generalization where there exist global constraints on the distribution of agents (e.g., requiring capacity constraints or minimum coverage requirements to be met). We propose Safe-$\\text{M}^3$-UCRL, the first model-based algorithm that attains safe policies even in the case of unknown transition dynamics. As a key ingredient, it uses epistemic uncertainty in the transition model within a log-barrier approach to ensure pessimistic constraints satisfaction with high probability. We showcase Safe-$\\text{M}^3$-UCRL on the vehicle repositioning problem faced by many shared mobility operators and evaluate its performance through simulations built on Shenzhen taxi trajectory data. Our algorithm effectively meets the demand in critical areas while ensuring service accessibility in regions with low demand.","sentences":["Many applications, e.g., in shared mobility, require coordinating a large number of agents.","Mean-field reinforcement learning addresses the resulting scalability challenge by optimizing the policy of a representative agent.","In this paper, we address an important generalization where there exist global constraints on the distribution of agents (e.g., requiring capacity constraints or minimum coverage requirements to be met).","We propose Safe-$\\text{M}^3$-UCRL, the first model-based algorithm that attains safe policies even in the case of unknown transition dynamics.","As a key ingredient, it uses epistemic uncertainty in the transition model within a log-barrier approach to ensure pessimistic constraints satisfaction with high probability.","We showcase Safe-$\\text{M}^3$-UCRL on the vehicle repositioning problem faced by many shared mobility operators and evaluate its performance through simulations built on Shenzhen taxi trajectory data.","Our algorithm effectively meets the demand in critical areas while ensuring service accessibility in regions with low demand."],"url":"http://arxiv.org/abs/2306.17052v1"}
{"created":"2023-06-29 15:43:06","title":"Spiking Denoising Diffusion Probabilistic Models","abstract":"Spiking neural networks (SNNs) have ultra-low energy consumption and high biological plausibility due to their binary and bio-driven nature compared with artificial neural networks (ANNs). While previous research has primarily focused on enhancing the performance of SNNs in classification tasks, the generative potential of SNNs remains relatively unexplored. In our paper, we put forward Spiking Denoising Diffusion Probabilistic Models (SDDPM), a new class of SNN-based generative models that achieve high sample quality. To fully exploit the energy efficiency of SNNs, we propose a purely Spiking U-Net architecture, which achieves comparable performance to its ANN counterpart using only 4 time steps, resulting in significantly reduced energy consumption. Extensive experimental results reveal that our approach achieves state-of-the-art on the generative tasks and substantially outperforms other SNN-based generative models, achieving up to $12\\times$ and $6\\times$ improvement on the CIFAR-10 and the CelebA datasets, respectively. Moreover, we propose a threshold-guided strategy that can further improve the performances by 16.7% in a training-free manner. The SDDPM symbolizes a significant advancement in the field of SNN generation, injecting new perspectives and potential avenues of exploration.","sentences":["Spiking neural networks (SNNs) have ultra-low energy consumption and high biological plausibility due to their binary and bio-driven nature compared with artificial neural networks (ANNs).","While previous research has primarily focused on enhancing the performance of SNNs in classification tasks, the generative potential of SNNs remains relatively unexplored.","In our paper, we put forward Spiking Denoising Diffusion Probabilistic Models (SDDPM), a new class of SNN-based generative models that achieve high sample quality.","To fully exploit the energy efficiency of SNNs, we propose a purely Spiking U-Net architecture, which achieves comparable performance to its ANN counterpart using only 4 time steps, resulting in significantly reduced energy consumption.","Extensive experimental results reveal that our approach achieves state-of-the-art on the generative tasks and substantially outperforms other SNN-based generative models, achieving up to $12\\times$ and $6\\times$ improvement on the CIFAR-10 and the CelebA datasets, respectively.","Moreover, we propose a threshold-guided strategy that can further improve the performances by 16.7% in a training-free manner.","The SDDPM symbolizes a significant advancement in the field of SNN generation, injecting new perspectives and potential avenues of exploration."],"url":"http://arxiv.org/abs/2306.17046v1"}
{"created":"2023-06-29 15:39:20","title":"Towards Grammatical Tagging for the Legal Language of Cybersecurity","abstract":"Legal language can be understood as the language typically used by those engaged in the legal profession and, as such, it may come both in spoken or written form. Recent legislation on cybersecurity obviously uses legal language in writing, thus inheriting all its interpretative complications due to the typical abundance of cases and sub-cases as well as to the general richness in detail. This paper faces the challenge of the essential interpretation of the legal language of cybersecurity, namely of the extraction of the essential Parts of Speech (POS) from the legal documents concerning cybersecurity. The challenge is overcome by our methodology for POS tagging of legal language. It leverages state-of-the-art open-source tools for Natural Language Processing (NLP) as well as manual analysis to validate the outcomes of the tools. As a result, the methodology is automated and, arguably, general for any legal language following minor tailoring of the preprocessing step. It is demonstrated over the most relevant EU legislation on cybersecurity, namely on the NIS 2 directive, producing the first, albeit essential, structured interpretation of such a relevant document. Moreover, our findings indicate that tools such as SpaCy and ClausIE reach their limits over the legal language of the NIS 2.","sentences":["Legal language can be understood as the language typically used by those engaged in the legal profession and, as such, it may come both in spoken or written form.","Recent legislation on cybersecurity obviously uses legal language in writing, thus inheriting all its interpretative complications due to the typical abundance of cases and sub-cases as well as to the general richness in detail.","This paper faces the challenge of the essential interpretation of the legal language of cybersecurity, namely of the extraction of the essential Parts of Speech (POS) from the legal documents concerning cybersecurity.","The challenge is overcome by our methodology for POS tagging of legal language.","It leverages state-of-the-art open-source tools for Natural Language Processing (NLP) as well as manual analysis to validate the outcomes of the tools.","As a result, the methodology is automated and, arguably, general for any legal language following minor tailoring of the preprocessing step.","It is demonstrated over the most relevant EU legislation on cybersecurity, namely on the NIS 2 directive, producing the first, albeit essential, structured interpretation of such a relevant document.","Moreover, our findings indicate that tools such as SpaCy and ClausIE reach their limits over the legal language of the NIS 2."],"url":"http://arxiv.org/abs/2306.17042v1"}
{"created":"2023-06-29 15:38:54","title":"Matroidal Entropy Functions: Constructions, Characterizations and Representations","abstract":"In this paper, we characterize matroidal entropy functions, i.e., entropy functions in the form $\\mathbf{h} = \\log v \\cdot \\mathbf{r}_M$ , where $v \\ge 2$ is an integer and $\\mathbf{r}_M$ is the rank function of a matroid $M$. By constructing the variable strength arrays of some matroid operations, we characterized matroidal entropy functions induced by regular matroids and some matroids with the same p-characteristic set as uniform matroid $U_{2,4}$.","sentences":["In this paper, we characterize matroidal entropy functions, i.e., entropy functions in the form $\\mathbf{h} = \\log v \\cdot \\mathbf{r}_M$ , where $v \\ge 2$ is an integer and $\\mathbf{r}_M$ is the rank function of a matroid $M$. By constructing the variable strength arrays of some matroid operations, we characterized matroidal entropy functions induced by regular matroids and some matroids with the same p-characteristic set as uniform matroid $U_{2,4}$."],"url":"http://arxiv.org/abs/2306.17041v1"}
{"created":"2023-06-29 15:37:19","title":"Comparison of Single- and Multi- Objective Optimization Quality for Evolutionary Equation Discovery","abstract":"Evolutionary differential equation discovery proved to be a tool to obtain equations with less a priori assumptions than conventional approaches, such as sparse symbolic regression over the complete possible terms library. The equation discovery field contains two independent directions. The first one is purely mathematical and concerns differentiation, the object of optimization and its relation to the functional spaces and others. The second one is dedicated purely to the optimizational problem statement. Both topics are worth investigating to improve the algorithm's ability to handle experimental data a more artificial intelligence way, without significant pre-processing and a priori knowledge of their nature. In the paper, we consider the prevalence of either single-objective optimization, which considers only the discrepancy between selected terms in the equation, or multi-objective optimization, which additionally takes into account the complexity of the obtained equation. The proposed comparison approach is shown on classical model examples -- Burgers equation, wave equation, and Korteweg - de Vries equation.","sentences":["Evolutionary differential equation discovery proved to be a tool to obtain equations with less a priori assumptions than conventional approaches, such as sparse symbolic regression over the complete possible terms library.","The equation discovery field contains two independent directions.","The first one is purely mathematical and concerns differentiation, the object of optimization and its relation to the functional spaces and others.","The second one is dedicated purely to the optimizational problem statement.","Both topics are worth investigating to improve the algorithm's ability to handle experimental data a more artificial intelligence way, without significant pre-processing and a priori knowledge of their nature.","In the paper, we consider the prevalence of either single-objective optimization, which considers only the discrepancy between selected terms in the equation, or multi-objective optimization, which additionally takes into account the complexity of the obtained equation.","The proposed comparison approach is shown on classical model examples -- Burgers equation, wave equation, and Korteweg - de Vries equation."],"url":"http://arxiv.org/abs/2306.17038v1"}
{"created":"2023-06-29 15:35:39","title":"Relaxed Local Correctability from Local Testing","abstract":"We cement the intuitive connection between relaxed local correctability and local testing by presenting a concrete framework for building a relaxed locally correctable code from any family of linear locally testable codes with sufficiently high rate. When instantiated using the locally testable codes of Dinur et al. (STOC 2022), this framework yields the first asymptotically good relaxed locally correctable and decodable codes with polylogarithmic query complexity, which finally closes the superpolynomial gap between query lower and upper bounds. Our construction combines high-rate locally testable codes of various sizes to produce a code that is locally testable at every scale: we can gradually \"zoom in\" to any desired codeword index, and a local tester at each step certifies that the next, smaller restriction of the input has low error.   Our codes asymptotically inherit the rate and distance of any locally testable code used in the final step of the construction. Therefore, our technique also yields nonexplicit relaxed locally correctable codes with polylogarithmic query complexity that have rate and distance approaching the Gilbert-Varshamov bound.","sentences":["We cement the intuitive connection between relaxed local correctability and local testing by presenting a concrete framework for building a relaxed locally correctable code from any family of linear locally testable codes with sufficiently high rate.","When instantiated using the locally testable codes of Dinur et al.","(STOC 2022), this framework yields the first asymptotically good relaxed locally correctable and decodable codes with polylogarithmic query complexity, which finally closes the superpolynomial gap between query lower and upper bounds.","Our construction combines high-rate locally testable codes of various sizes to produce a code that is locally testable at every scale: we can gradually \"zoom in\" to any desired codeword index, and a local tester at each step certifies that the next, smaller restriction of the input has low error.   ","Our codes asymptotically inherit the rate and distance of any locally testable code used in the final step of the construction.","Therefore, our technique also yields nonexplicit relaxed locally correctable codes with polylogarithmic query complexity that have rate and distance approaching the Gilbert-Varshamov bound."],"url":"http://arxiv.org/abs/2306.17035v1"}
{"created":"2023-06-29 15:35:34","title":"Exploring & Exploiting High-Order Graph Structure for Sparse Knowledge Graph Completion","abstract":"Sparse knowledge graph (KG) scenarios pose a challenge for previous Knowledge Graph Completion (KGC) methods, that is, the completion performance decreases rapidly with the increase of graph sparsity. This problem is also exacerbated because of the widespread existence of sparse KGs in practical applications. To alleviate this challenge, we present a novel framework, LR-GCN, that is able to automatically capture valuable long-range dependency among entities to supplement insufficient structure features and distill logical reasoning knowledge for sparse KGC. The proposed approach comprises two main components: a GNN-based predictor and a reasoning path distiller. The reasoning path distiller explores high-order graph structures such as reasoning paths and encodes them as rich-semantic edges, explicitly compositing long-range dependencies into the predictor. This step also plays an essential role in densifying KGs, effectively alleviating the sparse issue. Furthermore, the path distiller further distills logical reasoning knowledge from these mined reasoning paths into the predictor. These two components are jointly optimized using a well-designed variational EM algorithm. Extensive experiments and analyses on four sparse benchmarks demonstrate the effectiveness of our proposed method.","sentences":["Sparse knowledge graph (KG) scenarios pose a challenge for previous Knowledge Graph Completion (KGC) methods, that is, the completion performance decreases rapidly with the increase of graph sparsity.","This problem is also exacerbated because of the widespread existence of sparse KGs in practical applications.","To alleviate this challenge, we present a novel framework, LR-GCN, that is able to automatically capture valuable long-range dependency among entities to supplement insufficient structure features and distill logical reasoning knowledge for sparse KGC.","The proposed approach comprises two main components: a GNN-based predictor and a reasoning path distiller.","The reasoning path distiller explores high-order graph structures such as reasoning paths and encodes them as rich-semantic edges, explicitly compositing long-range dependencies into the predictor.","This step also plays an essential role in densifying KGs, effectively alleviating the sparse issue.","Furthermore, the path distiller further distills logical reasoning knowledge from these mined reasoning paths into the predictor.","These two components are jointly optimized using a well-designed variational EM algorithm.","Extensive experiments and analyses on four sparse benchmarks demonstrate the effectiveness of our proposed method."],"url":"http://arxiv.org/abs/2306.17034v1"}
{"created":"2023-06-29 15:34:26","title":"Safety-Aware Task Composition for Discrete and Continuous Reinforcement Learning","abstract":"Compositionality is a critical aspect of scalable system design. Reinforcement learning (RL) has recently shown substantial success in task learning, but has only recently begun to truly leverage composition. In this paper, we focus on Boolean composition of learned tasks as opposed to functional or sequential composition. Existing Boolean composition for RL focuses on reaching a satisfying absorbing state in environments with discrete action spaces, but does not support composable safety (i.e., avoidance) constraints. We advance the state of the art in Boolean composition of learned tasks with three contributions: i) introduce two distinct notions of safety in this framework; ii) show how to enforce either safety semantics, prove correctness (under some assumptions), and analyze the trade-offs between the two safety notions; and iii) extend Boolean composition from discrete action spaces to continuous action spaces. We demonstrate these techniques using modified versions of value iteration in a grid world, Deep Q-Network (DQN) in a grid world with image observations, and Twin Delayed DDPG (TD3) in a continuous-observation and continuous-action Bullet physics environment. We believe that these contributions advance the theory of safe reinforcement learning by allowing zero-shot composition of policies satisfying safety properties.","sentences":["Compositionality is a critical aspect of scalable system design.","Reinforcement learning (RL) has recently shown substantial success in task learning, but has only recently begun to truly leverage composition.","In this paper, we focus on Boolean composition of learned tasks as opposed to functional or sequential composition.","Existing Boolean composition for RL focuses on reaching a satisfying absorbing state in environments with discrete action spaces, but does not support composable safety (i.e., avoidance) constraints.","We advance the state of the art in Boolean composition of learned tasks with three contributions: i) introduce two distinct notions of safety in this framework; ii) show how to enforce either safety semantics, prove correctness (under some assumptions), and analyze the trade-offs between the two safety notions; and iii) extend Boolean composition from discrete action spaces to continuous action spaces.","We demonstrate these techniques using modified versions of value iteration in a grid world, Deep Q-Network (DQN) in a grid world with image observations, and Twin Delayed DDPG (TD3) in a continuous-observation and continuous-action Bullet physics environment.","We believe that these contributions advance the theory of safe reinforcement learning by allowing zero-shot composition of policies satisfying safety properties."],"url":"http://arxiv.org/abs/2306.17033v1"}
{"created":"2023-06-29 15:25:51","title":"SkiROS2: A skill-based Robot Control Platform for ROS","abstract":"The need for autonomous robot systems in both the service and the industrial domain is larger than ever. In the latter, the transition to small batches or even \"batch size 1\" in production created a need for robot control system architectures that can provide the required flexibility. Such architectures must not only have a sufficient knowledge integration framework. It must also support autonomous mission execution and allow for interchangeability and interoperability between different tasks and robot systems. We introduce SkiROS2, a skill-based robot control platform on top of ROS. SkiROS2 proposes a layered, hybrid control structure for automated task planning, and reactive execution, supported by a knowledge base for reasoning about the world state and entities. The scheduling formulation builds on the extended behavior tree model that merges task-level planning and execution. This allows for a high degree of modularity and a fast reaction to changes in the environment. The skill formulation based on pre-, hold- and post-conditions allows to organize robot programs and to compose diverse skills reaching from perception to low-level control and the incorporation of external tools. We relate SkiROS2 to the field and outline three example use cases that cover task planning, reasoning, multisensory input, integration in a manufacturing execution system and reinforcement learning.","sentences":["The need for autonomous robot systems in both the service and the industrial domain is larger than ever.","In the latter, the transition to small batches or even \"batch size 1\" in production created a need for robot control system architectures that can provide the required flexibility.","Such architectures must not only have a sufficient knowledge integration framework.","It must also support autonomous mission execution and allow for interchangeability and interoperability between different tasks and robot systems.","We introduce SkiROS2, a skill-based robot control platform on top of ROS.","SkiROS2 proposes a layered, hybrid control structure for automated task planning, and reactive execution, supported by a knowledge base for reasoning about the world state and entities.","The scheduling formulation builds on the extended behavior tree model that merges task-level planning and execution.","This allows for a high degree of modularity and a fast reaction to changes in the environment.","The skill formulation based on pre-, hold- and post-conditions allows to organize robot programs and to compose diverse skills reaching from perception to low-level control and the incorporation of external tools.","We relate SkiROS2 to the field and outline three example use cases that cover task planning, reasoning, multisensory input, integration in a manufacturing execution system and reinforcement learning."],"url":"http://arxiv.org/abs/2306.17030v1"}
{"created":"2023-06-29 15:17:37","title":"Towards Optimal Prior-Free Permissionless Rebate Mechanisms, with applications to Automated Market Makers & Combinatorial Orderflow Auctions","abstract":"Maximal Extractable Value (MEV) has become a critical issue for blockchain ecosystems, as it enables validators or block proposers to extract value by ordering, including or censoring users' transactions. This paper aims to present a formal approach for determining the appropriate compensation for users whose transactions are executed in bundles, as opposed to individually. We explore the impact of MEV on users, discuss the Shapley value as a solution for fair compensation, and delve into the mechanisms of MEV rebates and auctions as a means to undermine the power of the block producer.","sentences":["Maximal Extractable Value (MEV) has become a critical issue for blockchain ecosystems, as it enables validators or block proposers to extract value by ordering, including or censoring users' transactions.","This paper aims to present a formal approach for determining the appropriate compensation for users whose transactions are executed in bundles, as opposed to individually.","We explore the impact of MEV on users, discuss the Shapley value as a solution for fair compensation, and delve into the mechanisms of MEV rebates and auctions as a means to undermine the power of the block producer."],"url":"http://arxiv.org/abs/2306.17024v1"}
{"created":"2023-06-29 15:12:24","title":"Classifying Crime Types using Judgment Documents from Social Media","abstract":"The task of determining crime types based on criminal behavior facts has become a very important and meaningful task in social science. But the problem facing the field now is that the data samples themselves are unevenly distributed, due to the nature of the crime itself. At the same time, data sets in the judicial field are less publicly available, and it is not practical to produce large data sets for direct training. This article proposes a new training model to solve this problem through NLP processing methods. We first propose a Crime Fact Data Preprocessing Module (CFDPM), which can balance the defects of uneven data set distribution by generating new samples. Then we use a large open source dataset (CAIL-big) as our pretraining dataset and a small dataset collected by ourselves for Fine-tuning, giving it good generalization ability to unfamiliar small datasets. At the same time, we use the improved Bert model with dynamic masking to improve the model. Experiments show that the proposed method achieves state-of-the-art results on the present dataset. At the same time, the effectiveness of module CFDPM is proved by experiments. This article provides a valuable methodology contribution for classifying social science texts such as criminal behaviors. Extensive experiments on public benchmarks show that the proposed method achieves new state-of-the-art results.","sentences":["The task of determining crime types based on criminal behavior facts has become a very important and meaningful task in social science.","But the problem facing the field now is that the data samples themselves are unevenly distributed, due to the nature of the crime itself.","At the same time, data sets in the judicial field are less publicly available, and it is not practical to produce large data sets for direct training.","This article proposes a new training model to solve this problem through NLP processing methods.","We first propose a Crime Fact Data Preprocessing Module (CFDPM), which can balance the defects of uneven data set distribution by generating new samples.","Then we use a large open source dataset (CAIL-big) as our pretraining dataset and a small dataset collected by ourselves for Fine-tuning, giving it good generalization ability to unfamiliar small datasets.","At the same time, we use the improved Bert model with dynamic masking to improve the model.","Experiments show that the proposed method achieves state-of-the-art results on the present dataset.","At the same time, the effectiveness of module CFDPM is proved by experiments.","This article provides a valuable methodology contribution for classifying social science texts such as criminal behaviors.","Extensive experiments on public benchmarks show that the proposed method achieves new state-of-the-art results."],"url":"http://arxiv.org/abs/2306.17020v1"}
{"created":"2023-06-29 15:06:21","title":"milliFlow: Scene Flow Estimation on mmWave Radar Point Cloud for Human Motion Sensing","abstract":"Approaching the era of ubiquitous computing, human motion sensing plays a crucial role in smart systems for decision making, user interaction, and personalized services. Extensive research has been conducted on human tracking, pose estimation, gesture recognition, and activity recognition, which are predominantly based on cameras in traditional methods. However, the intrusive nature of cameras limits their use in smart home applications. To address this, mmWave radars have gained popularity due to their privacy-friendly features. In this work, we propose \\textit{milliFlow}, a novel deep learning method for scene flow estimation as a complementary motion information for mmWave point cloud, serving as an intermediate level of features and directly benefiting downstream human motion sensing tasks. Experimental results demonstrate the superior performance of our method with an average 3D endpoint error of 4.6cm, significantly surpassing the competing approaches. Furthermore, by incorporating scene flow information, we achieve remarkable improvements in human activity recognition, human parsing, and human body part tracking. To foster further research in this area, we provide our codebase and dataset for open access.","sentences":["Approaching the era of ubiquitous computing, human motion sensing plays a crucial role in smart systems for decision making, user interaction, and personalized services.","Extensive research has been conducted on human tracking, pose estimation, gesture recognition, and activity recognition, which are predominantly based on cameras in traditional methods.","However, the intrusive nature of cameras limits their use in smart home applications.","To address this, mmWave radars have gained popularity due to their privacy-friendly features.","In this work, we propose \\textit{milliFlow}, a novel deep learning method for scene flow estimation as a complementary motion information for mmWave point cloud, serving as an intermediate level of features and directly benefiting downstream human motion sensing tasks.","Experimental results demonstrate the superior performance of our method with an average 3D endpoint error of 4.6cm, significantly surpassing the competing approaches.","Furthermore, by incorporating scene flow information, we achieve remarkable improvements in human activity recognition, human parsing, and human body part tracking.","To foster further research in this area, we provide our codebase and dataset for open access."],"url":"http://arxiv.org/abs/2306.17010v1"}
{"created":"2023-06-29 15:00:32","title":"VibHead: An Authentication Scheme for Smart Headsets through Vibration","abstract":"Recent years have witnessed the fast penetration of Virtual Reality (VR) and Augmented Reality (AR) systems into our daily life, the security and privacy issues of the VR/AR applications have been attracting considerable attention. Most VR/AR systems adopt head-mounted devices (i.e., smart headsets) to interact with users and the devices usually store the users' private data. Hence, authentication schemes are desired for the head-mounted devices. Traditional knowledge-based authentication schemes for general personal devices have been proved vulnerable to shoulder-surfing attacks, especially considering the headsets may block the sight of the users. Although the robustness of the knowledge-based authentication can be improved by designing complicated secret codes in virtual space, this approach induces a compromise of usability. Another choice is to leverage the users' biometrics; however, it either relies on highly advanced equipments which may not always be available in commercial headsets or introduce heavy cognitive load to users.   In this paper, we propose a vibration-based authentication scheme, VibHead, for smart headsets. Since the propagation of vibration signals through human heads presents unique patterns for different individuals, VibHead employs a CNN-based model to classify registered legitimate users based the features extracted from the vibration signals. We also design a two-step authentication scheme where the above user classifiers are utilized to distinguish the legitimate user from illegitimate ones. We implement VibHead on a Microsoft HoloLens equipped with a linear motor and an IMU sensor which are commonly used in off-the-shelf personal smart devices. According to the results of our extensive experiments, with short vibration signals ($\\leq 1s$), VibHead has an outstanding authentication accuracy; both FAR and FRR are around 5%.","sentences":["Recent years have witnessed the fast penetration of Virtual Reality (VR) and Augmented Reality (AR) systems into our daily life, the security and privacy issues of the VR/AR applications have been attracting considerable attention.","Most VR/AR systems adopt head-mounted devices (i.e., smart headsets) to interact with users and the devices usually store the users' private data.","Hence, authentication schemes are desired for the head-mounted devices.","Traditional knowledge-based authentication schemes for general personal devices have been proved vulnerable to shoulder-surfing attacks, especially considering the headsets may block the sight of the users.","Although the robustness of the knowledge-based authentication can be improved by designing complicated secret codes in virtual space, this approach induces a compromise of usability.","Another choice is to leverage the users' biometrics; however, it either relies on highly advanced equipments which may not always be available in commercial headsets or introduce heavy cognitive load to users.   ","In this paper, we propose a vibration-based authentication scheme, VibHead, for smart headsets.","Since the propagation of vibration signals through human heads presents unique patterns for different individuals, VibHead employs a CNN-based model to classify registered legitimate users based the features extracted from the vibration signals.","We also design a two-step authentication scheme where the above user classifiers are utilized to distinguish the legitimate user from illegitimate ones.","We implement VibHead on a Microsoft HoloLens equipped with a linear motor and an IMU sensor which are commonly used in off-the-shelf personal smart devices.","According to the results of our extensive experiments, with short vibration signals ($\\leq 1s$), VibHead has an outstanding authentication accuracy; both FAR and FRR are around 5%."],"url":"http://arxiv.org/abs/2306.17002v1"}
{"created":"2023-06-29 15:00:12","title":"MotionTrack: End-to-End Transformer-based Multi-Object Tracing with LiDAR-Camera Fusion","abstract":"Multiple Object Tracking (MOT) is crucial to autonomous vehicle perception. End-to-end transformer-based algorithms, which detect and track objects simultaneously, show great potential for the MOT task. However, most existing methods focus on image-based tracking with a single object category. In this paper, we propose an end-to-end transformer-based MOT algorithm (MotionTrack) with multi-modality sensor inputs to track objects with multiple classes. Our objective is to establish a transformer baseline for the MOT in an autonomous driving environment. The proposed algorithm consists of a transformer-based data association (DA) module and a transformer-based query enhancement module to achieve MOT and Multiple Object Detection (MOD) simultaneously. The MotionTrack and its variations achieve better results (AMOTA score at 0.55) on the nuScenes dataset compared with other classical baseline models, such as the AB3DMOT, the CenterTrack, and the probabilistic 3D Kalman filter. In addition, we prove that a modified attention mechanism can be utilized for DA to accomplish the MOT, and aggregate history features to enhance the MOD performance.","sentences":["Multiple Object Tracking (MOT) is crucial to autonomous vehicle perception.","End-to-end transformer-based algorithms, which detect and track objects simultaneously, show great potential for the MOT task.","However, most existing methods focus on image-based tracking with a single object category.","In this paper, we propose an end-to-end transformer-based MOT algorithm (MotionTrack) with multi-modality sensor inputs to track objects with multiple classes.","Our objective is to establish a transformer baseline for the MOT in an autonomous driving environment.","The proposed algorithm consists of a transformer-based data association (DA) module and a transformer-based query enhancement module to achieve MOT and Multiple Object Detection (MOD) simultaneously.","The MotionTrack and its variations achieve better results (AMOTA score at 0.55) on the nuScenes dataset compared with other classical baseline models, such as the AB3DMOT, the CenterTrack, and the probabilistic 3D Kalman filter.","In addition, we prove that a modified attention mechanism can be utilized for DA to accomplish the MOT, and aggregate history features to enhance the MOD performance."],"url":"http://arxiv.org/abs/2306.17000v1"}
{"created":"2023-06-29 14:59:43","title":"Spectral Batch Normalization: Normalization in the Frequency Domain","abstract":"Regularization is a set of techniques that are used to improve the generalization ability of deep neural networks. In this paper, we introduce spectral batch normalization (SBN), a novel effective method to improve generalization by normalizing feature maps in the frequency (spectral) domain. The activations of residual networks without batch normalization (BN) tend to explode exponentially in the depth of the network at initialization. This leads to extremely large feature map norms even though the parameters are relatively small. These explosive dynamics can be very detrimental to learning. BN makes weight decay regularization on the scaling factors $\\gamma, \\beta$ approximately equivalent to an additive penalty on the norm of the feature maps, which prevents extremely large feature map norms to a certain degree. However, we show experimentally that, despite the approximate additive penalty of BN, feature maps in deep neural networks (DNNs) tend to explode at the beginning of the network and that feature maps of DNNs contain large values during the whole training. This phenomenon also occurs in a weakened form in non-residual networks. SBN addresses large feature maps by normalizing them in the frequency domain. In our experiments, we empirically show that SBN prevents exploding feature maps at initialization and large feature map values during the training. Moreover, the normalization of feature maps in the frequency domain leads to more uniform distributed frequency components. This discourages the DNNs to rely on single frequency components of feature maps. These, together with other effects of SBN, have a regularizing effect on the training of residual and non-residual networks. We show experimentally that using SBN in addition to standard regularization methods improves the performance of DNNs by a relevant margin, e.g. ResNet50 on ImageNet by 0.71%.","sentences":["Regularization is a set of techniques that are used to improve the generalization ability of deep neural networks.","In this paper, we introduce spectral batch normalization (SBN), a novel effective method to improve generalization by normalizing feature maps in the frequency (spectral) domain.","The activations of residual networks without batch normalization (BN) tend to explode exponentially in the depth of the network at initialization.","This leads to extremely large feature map norms even though the parameters are relatively small.","These explosive dynamics can be very detrimental to learning.","BN makes weight decay regularization on the scaling factors $\\gamma, \\beta$ approximately equivalent to an additive penalty on the norm of the feature maps, which prevents extremely large feature map norms to a certain degree.","However, we show experimentally that, despite the approximate additive penalty of BN, feature maps in deep neural networks (DNNs) tend to explode at the beginning of the network and that feature maps of DNNs contain large values during the whole training.","This phenomenon also occurs in a weakened form in non-residual networks.","SBN addresses large feature maps by normalizing them in the frequency domain.","In our experiments, we empirically show that SBN prevents exploding feature maps at initialization and large feature map values during the training.","Moreover, the normalization of feature maps in the frequency domain leads to more uniform distributed frequency components.","This discourages the DNNs to rely on single frequency components of feature maps.","These, together with other effects of SBN, have a regularizing effect on the training of residual and non-residual networks.","We show experimentally that using SBN in addition to standard regularization methods improves the performance of DNNs by a relevant margin, e.g. ResNet50 on ImageNet by 0.71%."],"url":"http://arxiv.org/abs/2306.16999v1"}
{"created":"2023-06-29 14:57:56","title":"Computing Star Discrepancies with Numerical Black-Box Optimization Algorithms","abstract":"The $L_{\\infty}$ star discrepancy is a measure for the regularity of a finite set of points taken from $[0,1)^d$. Low discrepancy point sets are highly relevant for Quasi-Monte Carlo methods in numerical integration and several other applications. Unfortunately, computing the $L_{\\infty}$ star discrepancy of a given point set is known to be a hard problem, with the best exact algorithms falling short for even moderate dimensions around 8. However, despite the difficulty of finding the global maximum that defines the $L_{\\infty}$ star discrepancy of the set, local evaluations at selected points are inexpensive. This makes the problem tractable by black-box optimization approaches.   In this work we compare 8 popular numerical black-box optimization algorithms on the $L_{\\infty}$ star discrepancy computation problem, using a wide set of instances in dimensions 2 to 15. We show that all used optimizers perform very badly on a large majority of the instances and that in many cases random search outperforms even the more sophisticated solvers. We suspect that state-of-the-art numerical black-box optimization techniques fail to capture the global structure of the problem, an important shortcoming that may guide their future development.   We also provide a parallel implementation of the best-known algorithm to compute the discrepancy.","sentences":["The $L_{\\infty}$ star discrepancy is a measure for the regularity of a finite set of points taken from $[0,1)^d$. Low discrepancy point sets are highly relevant for Quasi-Monte Carlo methods in numerical integration and several other applications.","Unfortunately, computing the $L_{\\infty}$ star discrepancy of a given point set is known to be a hard problem, with the best exact algorithms falling short for even moderate dimensions around 8.","However, despite the difficulty of finding the global maximum that defines the $L_{\\infty}$ star discrepancy of the set, local evaluations at selected points are inexpensive.","This makes the problem tractable by black-box optimization approaches.   ","In this work we compare 8 popular numerical black-box optimization algorithms on the $L_{\\infty}$ star discrepancy computation problem, using a wide set of instances in dimensions 2 to 15.","We show that all used optimizers perform very badly on a large majority of the instances and that in many cases random search outperforms even the more sophisticated solvers.","We suspect that state-of-the-art numerical black-box optimization techniques fail to capture the global structure of the problem, an important shortcoming that may guide their future development.   ","We also provide a parallel implementation of the best-known algorithm to compute the discrepancy."],"url":"http://arxiv.org/abs/2306.16998v1"}
{"created":"2023-06-29 14:54:10","title":"Unsupervised 3D registration through optimization-guided cyclical self-training","abstract":"State-of-the-art deep learning-based registration methods employ three different learning strategies: supervised learning, which requires costly manual annotations, unsupervised learning, which heavily relies on hand-crafted similarity metrics designed by domain experts, or learning from synthetic data, which introduces a domain shift. To overcome the limitations of these strategies, we propose a novel self-supervised learning paradigm for unsupervised registration, relying on self-training. Our idea is based on two key insights. Feature-based differentiable optimizers 1) perform reasonable registration even from random features and 2) stabilize the training of the preceding feature extraction network on noisy labels. Consequently, we propose cyclical self-training, where pseudo labels are initialized as the displacement fields inferred from random features and cyclically updated based on more and more expressive features from the learning feature extractor, yielding a self-reinforcement effect. We evaluate the method for abdomen and lung registration, consistently surpassing metric-based supervision and outperforming diverse state-of-the-art competitors. Source code is available at https://github.com/multimodallearning/reg-cyclical-self-train.","sentences":["State-of-the-art deep learning-based registration methods employ three different learning strategies: supervised learning, which requires costly manual annotations, unsupervised learning, which heavily relies on hand-crafted similarity metrics designed by domain experts, or learning from synthetic data, which introduces a domain shift.","To overcome the limitations of these strategies, we propose a novel self-supervised learning paradigm for unsupervised registration, relying on self-training.","Our idea is based on two key insights.","Feature-based differentiable optimizers 1) perform reasonable registration even from random features and 2) stabilize the training of the preceding feature extraction network on noisy labels.","Consequently, we propose cyclical self-training, where pseudo labels are initialized as the displacement fields inferred from random features and cyclically updated based on more and more expressive features from the learning feature extractor, yielding a self-reinforcement effect.","We evaluate the method for abdomen and lung registration, consistently surpassing metric-based supervision and outperforming diverse state-of-the-art competitors.","Source code is available at https://github.com/multimodallearning/reg-cyclical-self-train."],"url":"http://arxiv.org/abs/2306.16997v1"}
{"created":"2023-06-29 14:52:04","title":"Weight Compander: A Simple Weight Reparameterization for Regularization","abstract":"Regularization is a set of techniques that are used to improve the generalization ability of deep neural networks. In this paper, we introduce weight compander (WC), a novel effective method to improve generalization by reparameterizing each weight in deep neural networks using a nonlinear function. It is a general, intuitive, cheap and easy to implement method, which can be combined with various other regularization techniques. Large weights in deep neural networks are a sign of a more complex network that is overfitted to the training data. Moreover, regularized networks tend to have a greater range of weights around zero with fewer weights centered at zero. We introduce a weight reparameterization function which is applied to each weight and implicitly reduces overfitting by restricting the magnitude of the weights while forcing them away from zero at the same time. This leads to a more democratic decision-making in the network. Firstly, individual weights cannot have too much influence in the prediction process due to the restriction of their magnitude. Secondly, more weights are used in the prediction process, since they are forced away from zero during the training. This promotes the extraction of more features from the input data and increases the level of weight redundancy, which makes the network less sensitive to statistical differences between training and test data. We extend our method to learn the hyperparameters of the introduced weight reparameterization function. This avoids hyperparameter search and gives the network the opportunity to align the weight reparameterization with the training progress. We show experimentally that using weight compander in addition to standard regularization methods improves the performance of neural networks.","sentences":["Regularization is a set of techniques that are used to improve the generalization ability of deep neural networks.","In this paper, we introduce weight compander (WC), a novel effective method to improve generalization by reparameterizing each weight in deep neural networks using a nonlinear function.","It is a general, intuitive, cheap and easy to implement method, which can be combined with various other regularization techniques.","Large weights in deep neural networks are a sign of a more complex network that is overfitted to the training data.","Moreover, regularized networks tend to have a greater range of weights around zero with fewer weights centered at zero.","We introduce a weight reparameterization function which is applied to each weight and implicitly reduces overfitting by restricting the magnitude of the weights while forcing them away from zero at the same time.","This leads to a more democratic decision-making in the network.","Firstly, individual weights cannot have too much influence in the prediction process due to the restriction of their magnitude.","Secondly, more weights are used in the prediction process, since they are forced away from zero during the training.","This promotes the extraction of more features from the input data and increases the level of weight redundancy, which makes the network less sensitive to statistical differences between training and test data.","We extend our method to learn the hyperparameters of the introduced weight reparameterization function.","This avoids hyperparameter search and gives the network the opportunity to align the weight reparameterization with the training progress.","We show experimentally that using weight compander in addition to standard regularization methods improves the performance of neural networks."],"url":"http://arxiv.org/abs/2306.16993v1"}
{"created":"2023-06-29 14:51:19","title":"Noise-Aware Quantum Software Testing","abstract":"Quantum Computing (QC) promises computational speedup over classic computing for solving some complex problems. However, noise exists in current and near-term quantum computers. Quantum software testing (for gaining confidence in quantum software's correctness) is inevitably impacted by noise, to the extent that it is impossible to know if a test case failed due to noise or real faults. Existing testing techniques test quantum programs without considering noise, i.e., by executing tests on ideal quantum computer simulators. Consequently, they are not directly applicable to testing quantum software on real QC hardware or noisy simulators. To this end, we propose a noise-aware approach (named QOIN) to alleviate the noise effect on test results of quantum programs. QOIN employs machine learning techniques (e.g., transfer learning) to learn the noise effect of a quantum computer and filter it from a quantum program's outputs. Such filtered outputs are then used as the input to perform test case assessments (determining the passing or failing of a test case execution against a test oracle). We evaluated QOIN on IBM's 23 noise models with nine real-world quantum programs and 1000 artificial quantum programs. We also generated faulty versions of these programs to check if a failing test case execution can be determined under noise. Results show that QOIN can reduce the noise effect by more than $80\\%$. To check QOIN's effectiveness for quantum software testing, we used an existing test oracle for quantum software testing. The results showed that the F1-score of the test oracle was improved on average by $82\\%$ for six real-world programs and by $75\\%$ for 800 artificial programs, demonstrating that QOIN can effectively learn noise patterns and enable noise-aware quantum software testing.","sentences":["Quantum Computing (QC) promises computational speedup over classic computing for solving some complex problems.","However, noise exists in current and near-term quantum computers.","Quantum software testing (for gaining confidence in quantum software's correctness) is inevitably impacted by noise, to the extent that it is impossible to know if a test case failed due to noise or real faults.","Existing testing techniques test quantum programs without considering noise, i.e., by executing tests on ideal quantum computer simulators.","Consequently, they are not directly applicable to testing quantum software on real QC hardware or noisy simulators.","To this end, we propose a noise-aware approach (named QOIN) to alleviate the noise effect on test results of quantum programs.","QOIN employs machine learning techniques (e.g., transfer learning) to learn the noise effect of a quantum computer and filter it from a quantum program's outputs.","Such filtered outputs are then used as the input to perform test case assessments (determining the passing or failing of a test case execution against a test oracle).","We evaluated QOIN on IBM's 23 noise models with nine real-world quantum programs and 1000 artificial quantum programs.","We also generated faulty versions of these programs to check if a failing test case execution can be determined under noise.","Results show that QOIN can reduce the noise effect by more than $80\\%$. To check QOIN's effectiveness for quantum software testing, we used an existing test oracle for quantum software testing.","The results showed that the F1-score of the test oracle was improved on average by $82\\%$ for six real-world programs and by $75\\%$ for 800 artificial programs, demonstrating that QOIN can effectively learn noise patterns and enable noise-aware quantum software testing."],"url":"http://arxiv.org/abs/2306.16992v1"}
{"created":"2023-06-29 14:50:23","title":"Integrating Large Pre-trained Models into Multimodal Named Entity Recognition with Evidential Fusion","abstract":"Multimodal Named Entity Recognition (MNER) is a crucial task for information extraction from social media platforms such as Twitter. Most current methods rely on attention weights to extract information from both text and images but are often unreliable and lack interpretability. To address this problem, we propose incorporating uncertainty estimation into the MNER task, producing trustworthy predictions. Our proposed algorithm models the distribution of each modality as a Normal-inverse Gamma distribution, and fuses them into a unified distribution with an evidential fusion mechanism, enabling hierarchical characterization of uncertainties and promotion of prediction accuracy and trustworthiness. Additionally, we explore the potential of pre-trained large foundation models in MNER and propose an efficient fusion approach that leverages their robust feature representations. Experiments on two datasets demonstrate that our proposed method outperforms the baselines and achieves new state-of-the-art performance.","sentences":["Multimodal Named Entity Recognition (MNER) is a crucial task for information extraction from social media platforms such as Twitter.","Most current methods rely on attention weights to extract information from both text and images but are often unreliable and lack interpretability.","To address this problem, we propose incorporating uncertainty estimation into the MNER task, producing trustworthy predictions.","Our proposed algorithm models the distribution of each modality as a Normal-inverse Gamma distribution, and fuses them into a unified distribution with an evidential fusion mechanism, enabling hierarchical characterization of uncertainties and promotion of prediction accuracy and trustworthiness.","Additionally, we explore the potential of pre-trained large foundation models in MNER and propose an efficient fusion approach that leverages their robust feature representations.","Experiments on two datasets demonstrate that our proposed method outperforms the baselines and achieves new state-of-the-art performance."],"url":"http://arxiv.org/abs/2306.16991v1"}
{"created":"2023-06-29 14:33:20","title":"Defending Black-box Classifiers by Bayesian Boundary Correction","abstract":"Classifiers based on deep neural networks have been recently challenged by Adversarial Attack, where the widely existing vulnerability has invoked the research in defending them from potential threats. Given a vulnerable classifier, existing defense methods are mostly white-box and often require re-training the victim under modified loss functions/training regimes. While the model/data/training specifics of the victim are usually unavailable to the user, re-training is unappealing, if not impossible for reasons such as limited computational resources. To this end, we propose a new black-box defense framework. It can turn any pre-trained classifier into a resilient one with little knowledge of the model specifics. This is achieved by new joint Bayesian treatments on the clean data, the adversarial examples and the classifier, for maximizing their joint probability. It is further equipped with a new post-train strategy which keeps the victim intact. We name our framework Bayesian Boundary Correction (BBC). BBC is a general and flexible framework that can easily adapt to different data types. We instantiate BBC for image classification and skeleton-based human activity recognition, for both static and dynamic data. Exhaustive evaluation shows that BBC has superior robustness and can enhance robustness without severely hurting the clean accuracy, compared with existing defense methods.","sentences":["Classifiers based on deep neural networks have been recently challenged by Adversarial Attack, where the widely existing vulnerability has invoked the research in defending them from potential threats.","Given a vulnerable classifier, existing defense methods are mostly white-box and often require re-training the victim under modified loss functions/training regimes.","While the model/data/training specifics of the victim are usually unavailable to the user, re-training is unappealing, if not impossible for reasons such as limited computational resources.","To this end, we propose a new black-box defense framework.","It can turn any pre-trained classifier into a resilient one with little knowledge of the model specifics.","This is achieved by new joint Bayesian treatments on the clean data, the adversarial examples and the classifier, for maximizing their joint probability.","It is further equipped with a new post-train strategy which keeps the victim intact.","We name our framework Bayesian Boundary Correction (BBC).","BBC is a general and flexible framework that can easily adapt to different data types.","We instantiate BBC for image classification and skeleton-based human activity recognition, for both static and dynamic data.","Exhaustive evaluation shows that BBC has superior robustness and can enhance robustness without severely hurting the clean accuracy, compared with existing defense methods."],"url":"http://arxiv.org/abs/2306.16979v1"}
{"created":"2023-06-29 14:32:06","title":"End-to-end Reinforcement Learning for Online Coverage Path Planning in Unknown Environments","abstract":"Coverage path planning is the problem of finding the shortest path that covers the entire free space of a given confined area, with applications ranging from robotic lawn mowing and vacuum cleaning, to demining and search-and-rescue tasks. While offline methods can find provably complete, and in some cases optimal, paths for known environments, their value is limited in online scenarios where the environment is not known beforehand, especially in the presence of non-static obstacles. We propose an end-to-end reinforcement learning-based approach in continuous state and action space, for the online coverage path planning problem that can handle unknown environments. We construct the observation space from both global maps and local sensory inputs, allowing the agent to plan a long-term path, and simultaneously act on short-term obstacle detections. To account for large-scale environments, we propose to use a multi-scale map input representation. Furthermore, we propose a novel total variation reward term for eliminating thin strips of uncovered space in the learned path. To validate the effectiveness of our approach, we perform extensive experiments in simulation with a distance sensor, surpassing the performance of a recent reinforcement learning-based approach.","sentences":["Coverage path planning is the problem of finding the shortest path that covers the entire free space of a given confined area, with applications ranging from robotic lawn mowing and vacuum cleaning, to demining and search-and-rescue tasks.","While offline methods can find provably complete, and in some cases optimal, paths for known environments, their value is limited in online scenarios where the environment is not known beforehand, especially in the presence of non-static obstacles.","We propose an end-to-end reinforcement learning-based approach in continuous state and action space, for the online coverage path planning problem that can handle unknown environments.","We construct the observation space from both global maps and local sensory inputs, allowing the agent to plan a long-term path, and simultaneously act on short-term obstacle detections.","To account for large-scale environments, we propose to use a multi-scale map input representation.","Furthermore, we propose a novel total variation reward term for eliminating thin strips of uncovered space in the learned path.","To validate the effectiveness of our approach, we perform extensive experiments in simulation with a distance sensor, surpassing the performance of a recent reinforcement learning-based approach."],"url":"http://arxiv.org/abs/2306.16978v1"}
{"created":"2023-06-29 14:31:07","title":"Diffusion-Jump GNNs: Homophiliation via Learnable Metric Filters","abstract":"High-order Graph Neural Networks (HO-GNNs) have been developed to infer consistent latent spaces in the heterophilic regime, where the label distribution is not correlated with the graph structure. However, most of the existing HO-GNNs are hop-based, i.e., they rely on the powers of the transition matrix. As a result, these architectures are not fully reactive to the classification loss and the achieved structural filters have static supports. In other words, neither the filters' supports nor their coefficients can be learned with these networks. They are confined, instead, to learn combinations of filters. To address the above concerns, we propose Diffusion-jump GNNs a method relying on asymptotic diffusion distances that operates on jumps. A diffusion-pump generates pairwise distances whose projections determine both the support and coefficients of each structural filter. These filters are called jumps because they explore a wide range of scales in order to find bonds between scattered nodes with the same label. Actually, the full process is controlled by the classification loss. Both the jumps and the diffusion distances react to classification errors (i.e. they are learnable). Homophiliation, i.e., the process of learning piecewise smooth latent spaces in the heterophilic regime, is formulated as a Dirichlet problem: the known labels determine the border nodes and the diffusion-pump ensures a minimal deviation of the semi-supervised grouping from a canonical unsupervised grouping. This triggers the update of both the diffusion distances and, consequently, the jumps in order to minimize the classification error. The Dirichlet formulation has several advantages. It leads to the definition of structural heterophily, a novel measure beyond edge heterophily. It also allows us to investigate links with (learnable) diffusion distances, absorbing random walks and stochastic diffusion.","sentences":["High-order Graph Neural Networks (HO-GNNs) have been developed to infer consistent latent spaces in the heterophilic regime, where the label distribution is not correlated with the graph structure.","However, most of the existing HO-GNNs are hop-based, i.e., they rely on the powers of the transition matrix.","As a result, these architectures are not fully reactive to the classification loss and the achieved structural filters have static supports.","In other words, neither the filters' supports nor their coefficients can be learned with these networks.","They are confined, instead, to learn combinations of filters.","To address the above concerns, we propose Diffusion-jump GNNs a method relying on asymptotic diffusion distances that operates on jumps.","A diffusion-pump generates pairwise distances whose projections determine both the support and coefficients of each structural filter.","These filters are called jumps because they explore a wide range of scales in order to find bonds between scattered nodes with the same label.","Actually, the full process is controlled by the classification loss.","Both the jumps and the diffusion distances react to classification errors (i.e. they are learnable).","Homophiliation, i.e., the process of learning piecewise smooth latent spaces in the heterophilic regime, is formulated as a Dirichlet problem: the known labels determine the border nodes and the diffusion-pump ensures a minimal deviation of the semi-supervised grouping from a canonical unsupervised grouping.","This triggers the update of both the diffusion distances and, consequently, the jumps in order to minimize the classification error.","The Dirichlet formulation has several advantages.","It leads to the definition of structural heterophily, a novel measure beyond edge heterophily.","It also allows us to investigate links with (learnable) diffusion distances, absorbing random walks and stochastic diffusion."],"url":"http://arxiv.org/abs/2306.16976v1"}
{"created":"2023-06-29 14:28:22","title":"Experience Transfer for Robust Direct Data-Driven Control","abstract":"Learning-based control uses data to design efficient controllers for specific systems. When multiple systems are involved, experience transfer usually focuses on data availability and controller performance yet neglects robustness to variations between systems. In contrast, this letter explores experience transfer from a robustness perspective. We leverage the transfer to design controllers that are robust not only to the uncertainty regarding an individual agent's model but also to the choice of agent in a fleet. Experience transfer enables the design of safe and robust controllers that work out of the box for all systems in a heterogeneous fleet. Our approach combines scenario optimization and recent formulations for direct data-driven control without the need to estimate a model of the system or determine uncertainty bounds for its parameters. We demonstrate the benefits of our data-driven robustification method through a numerical case study and obtain learned controllers that generalize well from a small number of open-loop trajectories in a quadcopter simulation.","sentences":["Learning-based control uses data to design efficient controllers for specific systems.","When multiple systems are involved, experience transfer usually focuses on data availability and controller performance yet neglects robustness to variations between systems.","In contrast, this letter explores experience transfer from a robustness perspective.","We leverage the transfer to design controllers that are robust not only to the uncertainty regarding an individual agent's model but also to the choice of agent in a fleet.","Experience transfer enables the design of safe and robust controllers that work out of the box for all systems in a heterogeneous fleet.","Our approach combines scenario optimization and recent formulations for direct data-driven control without the need to estimate a model of the system or determine uncertainty bounds for its parameters.","We demonstrate the benefits of our data-driven robustification method through a numerical case study and obtain learned controllers that generalize well from a small number of open-loop trajectories in a quadcopter simulation."],"url":"http://arxiv.org/abs/2306.16973v1"}
{"created":"2023-06-29 14:17:24","title":"End-to-end Autonomous Driving: Challenges and Frontiers","abstract":"The autonomous driving community has witnessed a rapid growth in approaches that embrace an end-to-end algorithm framework, utilizing raw sensor input to generate vehicle motion plans, instead of concentrating on individual tasks such as detection and motion prediction. End-to-end systems, in comparison to modular pipelines, benefit from joint feature optimization for perception and planning. This field has flourished due to the availability of large-scale datasets, closed-loop evaluation, and the increasing need for autonomous driving algorithms to perform effectively in challenging scenarios. In this survey, we provide a comprehensive analysis of more than 250 papers, covering the motivation, roadmap, methodology, challenges, and future trends in end-to-end autonomous driving. We delve into several critical challenges, including multi-modality, interpretability, causal confusion, robustness, and world models, amongst others. Additionally, we discuss current advancements in foundation models and visual pre-training, as well as how to incorporate these techniques within the end-to-end driving framework. To facilitate future research, we maintain an active repository that contains up-to-date links to relevant literature and open-source projects at https://github.com/OpenDriveLab/End-to-end-Autonomous-Driving.","sentences":["The autonomous driving community has witnessed a rapid growth in approaches that embrace an end-to-end algorithm framework, utilizing raw sensor input to generate vehicle motion plans, instead of concentrating on individual tasks such as detection and motion prediction.","End-to-end systems, in comparison to modular pipelines, benefit from joint feature optimization for perception and planning.","This field has flourished due to the availability of large-scale datasets, closed-loop evaluation, and the increasing need for autonomous driving algorithms to perform effectively in challenging scenarios.","In this survey, we provide a comprehensive analysis of more than 250 papers, covering the motivation, roadmap, methodology, challenges, and future trends in end-to-end autonomous driving.","We delve into several critical challenges, including multi-modality, interpretability, causal confusion, robustness, and world models, amongst others.","Additionally, we discuss current advancements in foundation models and visual pre-training, as well as how to incorporate these techniques within the end-to-end driving framework.","To facilitate future research, we maintain an active repository that contains up-to-date links to relevant literature and open-source projects at https://github.com/OpenDriveLab/End-to-end-Autonomous-Driving."],"url":"http://arxiv.org/abs/2306.16927v1"}
{"created":"2023-06-29 14:16:54","title":"On the relevance of acoustic measurements for creating realistic virtual acoustic environments","abstract":"Geometrical approaches for room acoustics simulation have the advantage of requiring limited computational resources while still achieving a high perceptual plausibility. A common approach is using the image source model for direct and early reflections in connection with further simplified models such as a feedback delay network for the diffuse reverberant tail. When recreating real spaces as virtual acoustic environments using room acoustics simulation, the perceptual relevance of individual parameters in the simulation is unclear. Here we investigate the importance of underlying acoustical measurements and technical evaluation methods to obtain high-quality room acoustics simulations in agreement with dummy-head recordings of a real space. We focus on the role of source directivity. The effect of including measured, modelled, and omnidirectional source directivity in room acoustics simulations was assessed in comparison to the measured reference. Technical evaluation strategies to verify and improve the accuracy of various elements in the simulation processing chain from source, the room properties, to the receiver are presented. Perceptual results from an ABX listening experiment with random speech tokens are shown and compared with technical measures for a ranking of simulation approaches.","sentences":["Geometrical approaches for room acoustics simulation have the advantage of requiring limited computational resources while still achieving a high perceptual plausibility.","A common approach is using the image source model for direct and early reflections in connection with further simplified models such as a feedback delay network for the diffuse reverberant tail.","When recreating real spaces as virtual acoustic environments using room acoustics simulation, the perceptual relevance of individual parameters in the simulation is unclear.","Here we investigate the importance of underlying acoustical measurements and technical evaluation methods to obtain high-quality room acoustics simulations in agreement with dummy-head recordings of a real space.","We focus on the role of source directivity.","The effect of including measured, modelled, and omnidirectional source directivity in room acoustics simulations was assessed in comparison to the measured reference.","Technical evaluation strategies to verify and improve the accuracy of various elements in the simulation processing chain from source, the room properties, to the receiver are presented.","Perceptual results from an ABX listening experiment with random speech tokens are shown and compared with technical measures for a ranking of simulation approaches."],"url":"http://arxiv.org/abs/2306.16967v1"}
{"created":"2023-06-29 14:14:52","title":"Online Coalition Formation under Random Arrival or Coalition Dissolution","abstract":"Coalition formation considers the question of how to partition a set of $n$ agents into disjoint coalitions according to their preferences. We consider a cardinal utility model with additively separable aggregation of preferences and study the online variant of coalition formation, where the agents arrive in sequence and whenever an agent arrives, they have to be assigned to a coalition immediately. The goal is to maximize social welfare. In a purely deterministic model, the greedy algorithm, where an agent is assigned to the coalition with the largest gain, is known to achieve an optimal competitive ratio, which heavily relies on the range of utilities.   We complement this result by considering two related models. First, we study a model where agents arrive in a random order. We find that the competitive ratio of the greedy algorithm is $\\Theta\\left(\\frac{1}{n^2}\\right)$, whereas an alternative algorithm, which is based on alternating between waiting and greedy phases, can achieve a competitive ratio of $\\Theta\\left(\\frac{1}{n}\\right)$. Second, we relax the irrevocability of decisions by allowing to dissolve coalitions into singleton coalitions, presenting a matching-based algorithm that once again achieves a competitive ratio of $\\Theta\\left(\\frac{1}{n}\\right)$. Hence, compared to the base model, we present two ways to achieve a competitive ratio that precisely gets rid of utility dependencies. Our results also give novel insights in weighted online matching.","sentences":["Coalition formation considers the question of how to partition a set of $n$ agents into disjoint coalitions according to their preferences.","We consider a cardinal utility model with additively separable aggregation of preferences and study the online variant of coalition formation, where the agents arrive in sequence and whenever an agent arrives, they have to be assigned to a coalition immediately.","The goal is to maximize social welfare.","In a purely deterministic model, the greedy algorithm, where an agent is assigned to the coalition with the largest gain, is known to achieve an optimal competitive ratio, which heavily relies on the range of utilities.   ","We complement this result by considering two related models.","First, we study a model where agents arrive in a random order.","We find that the competitive ratio of the greedy algorithm is $\\Theta\\left(\\frac{1}{n^2}\\right)$, whereas an alternative algorithm, which is based on alternating between waiting and greedy phases, can achieve a competitive ratio of $\\Theta\\left(\\frac{1}{n}\\right)$. Second, we relax the irrevocability of decisions by allowing to dissolve coalitions into singleton coalitions, presenting a matching-based algorithm that once again achieves a competitive ratio of $\\Theta\\left(\\frac{1}{n}\\right)$. Hence, compared to the base model, we present two ways to achieve a competitive ratio that precisely gets rid of utility dependencies.","Our results also give novel insights in weighted online matching."],"url":"http://arxiv.org/abs/2306.16965v1"}
{"created":"2023-06-29 14:13:15","title":"Speech-based Age and Gender Prediction with Transformers","abstract":"We report on the curation of several publicly available datasets for age and gender prediction. Furthermore, we present experiments to predict age and gender with models based on a pre-trained wav2vec 2.0. Depending on the dataset, we achieve an MAE between 7.1 years and 10.8 years for age, and at least 91.1% ACC for gender (female, male, child). Compared to a modelling approach built on handcrafted features, our proposed system shows an improvement of 9% UAR for age and 4% UAR for gender. To make our findings reproducible, we release the best performing model to the community as well as the sample lists of the data splits.","sentences":["We report on the curation of several publicly available datasets for age and gender prediction.","Furthermore, we present experiments to predict age and gender with models based on a pre-trained wav2vec 2.0.","Depending on the dataset, we achieve an MAE between 7.1 years and 10.8 years for age, and at least 91.1% ACC for gender (female, male, child).","Compared to a modelling approach built on handcrafted features, our proposed system shows an improvement of 9% UAR for age and 4% UAR for gender.","To make our findings reproducible, we release the best performing model to the community as well as the sample lists of the data splits."],"url":"http://arxiv.org/abs/2306.16962v1"}
{"created":"2023-06-29 14:12:58","title":"AI-Powered Interfaces for Extended Reality to support Remote Maintenance","abstract":"High-end components that conduct complicated tasks automatically are a part of modern industrial systems. However, in order for these parts to function at the desired level, they need to be maintained by qualified experts. Solutions based on Augmented Reality (AR) have been established with the goal of raising production rates and quality while lowering maintenance costs. With the introduction of two unique interaction interfaces based on wearable targets and human face orientation, we are proposing hands-free advanced interactive solutions in this study with the goal of reducing the bias towards certain users. Using traditional devices in real time, a comparison investigation using alternative interaction interfaces is conducted. The suggested solutions are supported by various AI powered methods such as novel gravity-map based motion adjustment that is made possible by predictive deep models that reduce the bias of traditional hand- or finger-based interaction interfaces","sentences":["High-end components that conduct complicated tasks automatically are a part of modern industrial systems.","However, in order for these parts to function at the desired level, they need to be maintained by qualified experts.","Solutions based on Augmented Reality (AR) have been established with the goal of raising production rates and quality while lowering maintenance costs.","With the introduction of two unique interaction interfaces based on wearable targets and human face orientation, we are proposing hands-free advanced interactive solutions in this study with the goal of reducing the bias towards certain users.","Using traditional devices in real time, a comparison investigation using alternative interaction interfaces is conducted.","The suggested solutions are supported by various AI powered methods such as novel gravity-map based motion adjustment that is made possible by predictive deep models that reduce the bias of traditional hand- or finger-based interaction interfaces"],"url":"http://arxiv.org/abs/2306.16961v1"}
{"created":"2023-06-29 14:05:35","title":"Identifiability of direct effects from summary causal graphs","abstract":"Dynamic structural causal models (SCMs) are a powerful framework for reasoning in dynamic systems about direct effects which measure how a change in one variable affects another variable while holding all other variables constant. The causal relations in a dynamic structural causal model can be qualitatively represented with a full-time causal graph. Assuming linearity and causal sufficiency and given the full-time causal graph, the direct causal effect is always identifiable and can be estimated from data by adjusting on any set of variables given by the so-called single-door criterion. However, in many application such a graph is not available for various reasons but nevertheless experts have access to an abstraction of the full-time causal graph which represents causal relations between time series while omitting temporal information. This paper presents a complete identifiability result which characterizes all cases for which the direct effect is graphically identifiable from summary causal graphs and gives two sound finite adjustment sets that can be used to estimate the direct effect whenever it is identifiable.","sentences":["Dynamic structural causal models (SCMs) are a powerful framework for reasoning in dynamic systems about direct effects which measure how a change in one variable affects another variable while holding all other variables constant.","The causal relations in a dynamic structural causal model can be qualitatively represented with a full-time causal graph.","Assuming linearity and causal sufficiency and given the full-time causal graph, the direct causal effect is always identifiable and can be estimated from data by adjusting on any set of variables given by the so-called single-door criterion.","However, in many application such a graph is not available for various reasons but nevertheless experts have access to an abstraction of the full-time causal graph which represents causal relations between time series while omitting temporal information.","This paper presents a complete identifiability result which characterizes all cases for which the direct effect is graphically identifiable from summary causal graphs and gives two sound finite adjustment sets that can be used to estimate the direct effect whenever it is identifiable."],"url":"http://arxiv.org/abs/2306.16958v1"}
{"created":"2023-06-29 14:04:24","title":"Cross-Inferential Networks for Source-free Unsupervised Domain Adaptation","abstract":"One central challenge in source-free unsupervised domain adaptation (UDA) is the lack of an effective approach to evaluate the prediction results of the adapted network model in the target domain. To address this challenge, we propose to explore a new method called cross-inferential networks (CIN). Our main idea is that, when we adapt the network model to predict the sample labels from encoded features, we use these prediction results to construct new training samples with derived labels to learn a new examiner network that performs a different but compatible task in the target domain. Specifically, in this work, the base network model is performing image classification while the examiner network is tasked to perform relative ordering of triplets of samples whose training labels are carefully constructed from the prediction results of the base network model. Two similarity measures, cross-network correlation matrix similarity and attention consistency, are then developed to provide important guidance for the UDA process. Our experimental results on benchmark datasets demonstrate that our proposed CIN approach can significantly improve the performance of source-free UDA.","sentences":["One central challenge in source-free unsupervised domain adaptation (UDA) is the lack of an effective approach to evaluate the prediction results of the adapted network model in the target domain.","To address this challenge, we propose to explore a new method called cross-inferential networks (CIN).","Our main idea is that, when we adapt the network model to predict the sample labels from encoded features, we use these prediction results to construct new training samples with derived labels to learn a new examiner network that performs a different but compatible task in the target domain.","Specifically, in this work, the base network model is performing image classification while the examiner network is tasked to perform relative ordering of triplets of samples whose training labels are carefully constructed from the prediction results of the base network model.","Two similarity measures, cross-network correlation matrix similarity and attention consistency, are then developed to provide important guidance for the UDA process.","Our experimental results on benchmark datasets demonstrate that our proposed CIN approach can significantly improve the performance of source-free UDA."],"url":"http://arxiv.org/abs/2306.16957v1"}
{"created":"2023-06-29 14:03:49","title":"MEMD-ABSA: A Multi-Element Multi-Domain Dataset for Aspect-Based Sentiment Analysis","abstract":"Aspect-based sentiment analysis is a long-standing research interest in the field of opinion mining, and in recent years, researchers have gradually shifted their focus from simple ABSA subtasks to end-to-end multi-element ABSA tasks. However, the datasets currently used in the research are limited to individual elements of specific tasks, usually focusing on in-domain settings, ignoring implicit aspects and opinions, and with a small data scale. To address these issues, we propose a large-scale Multi-Element Multi-Domain dataset (MEMD) that covers the four elements across five domains, including nearly 20,000 review sentences and 30,000 quadruples annotated with explicit and implicit aspects and opinions for ABSA research. Meanwhile, we evaluate generative and non-generative baselines on multiple ABSA subtasks under the open domain setting, and the results show that open domain ABSA as well as mining implicit aspects and opinions remain ongoing challenges to be addressed. The datasets are publicly released at \\url{https://github.com/NUSTM/MEMD-ABSA}.","sentences":["Aspect-based sentiment analysis is a long-standing research interest in the field of opinion mining, and in recent years, researchers have gradually shifted their focus from simple ABSA subtasks to end-to-end multi-element ABSA tasks.","However, the datasets currently used in the research are limited to individual elements of specific tasks, usually focusing on in-domain settings, ignoring implicit aspects and opinions, and with a small data scale.","To address these issues, we propose a large-scale Multi-Element Multi-Domain dataset (MEMD) that covers the four elements across five domains, including nearly 20,000 review sentences and 30,000 quadruples annotated with explicit and implicit aspects and opinions for ABSA research.","Meanwhile, we evaluate generative and non-generative baselines on multiple ABSA subtasks under the open domain setting, and the results show that open domain ABSA as well as mining implicit aspects and opinions remain ongoing challenges to be addressed.","The datasets are publicly released at \\url{https://github.com/NUSTM/MEMD-ABSA}."],"url":"http://arxiv.org/abs/2306.16956v1"}
{"created":"2023-06-29 13:59:18","title":"Predicting Music Hierarchies with a Graph-Based Neural Decoder","abstract":"This paper describes a data-driven framework to parse musical sequences into dependency trees, which are hierarchical structures used in music cognition research and music analysis. The parsing involves two steps. First, the input sequence is passed through a transformer encoder to enrich it with contextual information. Then, a classifier filters the graph of all possible dependency arcs to produce the dependency tree. One major benefit of this system is that it can be easily integrated into modern deep-learning pipelines. Moreover, since it does not rely on any particular symbolic grammar, it can consider multiple musical features simultaneously, make use of sequential context information, and produce partial results for noisy inputs. We test our approach on two datasets of musical trees -- time-span trees of monophonic note sequences and harmonic trees of jazz chord sequences -- and show that our approach outperforms previous methods.","sentences":["This paper describes a data-driven framework to parse musical sequences into dependency trees, which are hierarchical structures used in music cognition research and music analysis.","The parsing involves two steps.","First, the input sequence is passed through a transformer encoder to enrich it with contextual information.","Then, a classifier filters the graph of all possible dependency arcs to produce the dependency tree.","One major benefit of this system is that it can be easily integrated into modern deep-learning pipelines.","Moreover, since it does not rely on any particular symbolic grammar, it can consider multiple musical features simultaneously, make use of sequential context information, and produce partial results for noisy inputs.","We test our approach on two datasets of musical trees -- time-span trees of monophonic note sequences and harmonic trees of jazz chord sequences -- and show that our approach outperforms previous methods."],"url":"http://arxiv.org/abs/2306.16955v1"}
{"created":"2023-06-29 13:49:06","title":"Alternative Telescopic Displacement: An Efficient Multimodal Alignment Method","abstract":"Feature alignment is the primary means of fusing multimodal data. We propose a feature alignment method that fully fuses multimodal information, which alternately shifts and expands feature information from different modalities to have a consistent representation in a feature space. The proposed method can robustly capture high-level interactions between features of different modalities, thus significantly improving the performance of multimodal learning. We also show that the proposed method outperforms other popular multimodal schemes on multiple tasks. Experimental evaluation of ETT and MIT-BIH-Arrhythmia, datasets shows that the proposed method achieves state of the art performance.","sentences":["Feature alignment is the primary means of fusing multimodal data.","We propose a feature alignment method that fully fuses multimodal information, which alternately shifts and expands feature information from different modalities to have a consistent representation in a feature space.","The proposed method can robustly capture high-level interactions between features of different modalities, thus significantly improving the performance of multimodal learning.","We also show that the proposed method outperforms other popular multimodal schemes on multiple tasks.","Experimental evaluation of ETT and MIT-BIH-Arrhythmia, datasets shows that the proposed method achieves state of the art performance."],"url":"http://arxiv.org/abs/2306.16950v1"}
{"created":"2023-06-29 13:47:18","title":"The War of the Efficiencies: Understanding the Tension between Carbon and Energy Optimization","abstract":"Major innovations in computing have been driven by scaling up computing infrastructure, while aggressively optimizing operating costs. The result is a network of worldwide datacenters that consume a large amount of energy, mostly in an energy-efficient manner. Since the electric grid powering these datacenters provided a simple and opaque abstraction of an unlimited and reliable power supply, the computing industry remained largely oblivious to the carbon intensity of the electricity it uses. Much like the rest of the society, it generally treated the carbon intensity of the electricity as constant, which was mostly true for a fossil fuel-driven grid. As a result, the cost-driven objective of increasing energy-efficiency -- by doing more work per unit of energy -- has generally been viewed as the most carbon-efficient approach. However, as the electric grid is increasingly powered by clean energy and is exposing its time-varying carbon intensity, the most energy-efficient operation is no longer necessarily the most carbon-efficient operation. There has been a recent focus on exploiting the flexibility of computing's workloads -- along temporal, spatial, and resource dimensions -- to reduce carbon emissions, which comes at the cost of either performance or energy efficiency. In this paper, we discuss the trade-offs between energy efficiency and carbon efficiency in exploiting computing's flexibility and show that blindly optimizing for energy efficiency is not always the right approach.","sentences":["Major innovations in computing have been driven by scaling up computing infrastructure, while aggressively optimizing operating costs.","The result is a network of worldwide datacenters that consume a large amount of energy, mostly in an energy-efficient manner.","Since the electric grid powering these datacenters provided a simple and opaque abstraction of an unlimited and reliable power supply, the computing industry remained largely oblivious to the carbon intensity of the electricity it uses.","Much like the rest of the society, it generally treated the carbon intensity of the electricity as constant, which was mostly true for a fossil fuel-driven grid.","As a result, the cost-driven objective of increasing energy-efficiency -- by doing more work per unit of energy -- has generally been viewed as the most carbon-efficient approach.","However, as the electric grid is increasingly powered by clean energy and is exposing its time-varying carbon intensity, the most energy-efficient operation is no longer necessarily the most carbon-efficient operation.","There has been a recent focus on exploiting the flexibility of computing's workloads -- along temporal, spatial, and resource dimensions -- to reduce carbon emissions, which comes at the cost of either performance or energy efficiency.","In this paper, we discuss the trade-offs between energy efficiency and carbon efficiency in exploiting computing's flexibility and show that blindly optimizing for energy efficiency is not always the right approach."],"url":"http://arxiv.org/abs/2306.16948v1"}
{"created":"2023-06-29 13:35:16","title":"BEDLAM: A Synthetic Dataset of Bodies Exhibiting Detailed Lifelike Animated Motion","abstract":"We show, for the first time, that neural networks trained only on synthetic data achieve state-of-the-art accuracy on the problem of 3D human pose and shape (HPS) estimation from real images. Previous synthetic datasets have been small, unrealistic, or lacked realistic clothing. Achieving sufficient realism is non-trivial and we show how to do this for full bodies in motion. Specifically, our BEDLAM dataset contains monocular RGB videos with ground-truth 3D bodies in SMPL-X format. It includes a diversity of body shapes, motions, skin tones, hair, and clothing. The clothing is realistically simulated on the moving bodies using commercial clothing physics simulation. We render varying numbers of people in realistic scenes with varied lighting and camera motions. We then train various HPS regressors using BEDLAM and achieve state-of-the-art accuracy on real-image benchmarks despite training with synthetic data. We use BEDLAM to gain insights into what model design choices are important for accuracy. With good synthetic training data, we find that a basic method like HMR approaches the accuracy of the current SOTA method (CLIFF). BEDLAM is useful for a variety of tasks and all images, ground truth bodies, 3D clothing, support code, and more are available for research purposes. Additionally, we provide detailed information about our synthetic data generation pipeline, enabling others to generate their own datasets. See the project page: https://bedlam.is.tue.mpg.de/.","sentences":["We show, for the first time, that neural networks trained only on synthetic data achieve state-of-the-art accuracy on the problem of 3D human pose and shape (HPS) estimation from real images.","Previous synthetic datasets have been small, unrealistic, or lacked realistic clothing.","Achieving sufficient realism is non-trivial and we show how to do this for full bodies in motion.","Specifically, our BEDLAM dataset contains monocular RGB videos with ground-truth 3D bodies in SMPL-X format.","It includes a diversity of body shapes, motions, skin tones, hair, and clothing.","The clothing is realistically simulated on the moving bodies using commercial clothing physics simulation.","We render varying numbers of people in realistic scenes with varied lighting and camera motions.","We then train various HPS regressors using BEDLAM and achieve state-of-the-art accuracy on real-image benchmarks despite training with synthetic data.","We use BEDLAM to gain insights into what model design choices are important for accuracy.","With good synthetic training data, we find that a basic method like HMR approaches the accuracy of the current SOTA method (CLIFF).","BEDLAM is useful for a variety of tasks and all images, ground truth bodies, 3D clothing, support code, and more are available for research purposes.","Additionally, we provide detailed information about our synthetic data generation pipeline, enabling others to generate their own datasets.","See the project page: https://bedlam.is.tue.mpg.de/."],"url":"http://arxiv.org/abs/2306.16940v1"}
{"created":"2023-06-29 13:34:35","title":"Restore Translation Using Equivariant Neural Networks","abstract":"Invariance to spatial transformations such as translations and rotations is a desirable property and a basic design principle for classification neural networks. However, the commonly used convolutional neural networks (CNNs) are actually very sensitive to even small translations. There exist vast works to achieve exact or approximate transformation invariance by designing transformation-invariant models or assessing the transformations. These works usually make changes to the standard CNNs and harm the performance on standard datasets. In this paper, rather than modifying the classifier, we propose a pre-classifier restorer to recover translated (or even rotated) inputs to the original ones which will be fed into any classifier for the same dataset. The restorer is based on a theoretical result which gives a sufficient and necessary condition for an affine operator to be translational equivariant on a tensor space.","sentences":["Invariance to spatial transformations such as translations and rotations is a desirable property and a basic design principle for classification neural networks.","However, the commonly used convolutional neural networks (CNNs) are actually very sensitive to even small translations.","There exist vast works to achieve exact or approximate transformation invariance by designing transformation-invariant models or assessing the transformations.","These works usually make changes to the standard CNNs and harm the performance on standard datasets.","In this paper, rather than modifying the classifier, we propose a pre-classifier restorer to recover translated (or even rotated) inputs to the original ones which will be fed into any classifier for the same dataset.","The restorer is based on a theoretical result which gives a sufficient and necessary condition for an affine operator to be translational equivariant on a tensor space."],"url":"http://arxiv.org/abs/2306.16938v1"}
{"created":"2023-06-29 13:33:02","title":"DreamDiffusion: Generating High-Quality Images from Brain EEG Signals","abstract":"This paper introduces DreamDiffusion, a novel method for generating high-quality images directly from brain electroencephalogram (EEG) signals, without the need to translate thoughts into text. DreamDiffusion leverages pre-trained text-to-image models and employs temporal masked signal modeling to pre-train the EEG encoder for effective and robust EEG representations. Additionally, the method further leverages the CLIP image encoder to provide extra supervision to better align EEG, text, and image embeddings with limited EEG-image pairs. Overall, the proposed method overcomes the challenges of using EEG signals for image generation, such as noise, limited information, and individual differences, and achieves promising results. Quantitative and qualitative results demonstrate the effectiveness of the proposed method as a significant step towards portable and low-cost ``thoughts-to-image'', with potential applications in neuroscience and computer vision.","sentences":["This paper introduces DreamDiffusion, a novel method for generating high-quality images directly from brain electroencephalogram (EEG) signals, without the need to translate thoughts into text.","DreamDiffusion leverages pre-trained text-to-image models and employs temporal masked signal modeling to pre-train the EEG encoder for effective and robust EEG representations.","Additionally, the method further leverages the CLIP image encoder to provide extra supervision to better align EEG, text, and image embeddings with limited EEG-image pairs.","Overall, the proposed method overcomes the challenges of using EEG signals for image generation, such as noise, limited information, and individual differences, and achieves promising results.","Quantitative and qualitative results demonstrate the effectiveness of the proposed method as a significant step towards portable and low-cost ``thoughts-to-image'', with potential applications in neuroscience and computer vision."],"url":"http://arxiv.org/abs/2306.16934v1"}
{"created":"2023-06-29 13:30:41","title":"UMASS_BioNLP at MEDIQA-Chat 2023: Can LLMs generate high-quality synthetic note-oriented doctor-patient conversations?","abstract":"This paper presents UMASS_BioNLP team participation in the MEDIQA-Chat 2023 shared task for Task-A and Task-C. We focus especially on Task-C and propose a novel LLMs cooperation system named a doctor-patient loop to generate high-quality conversation data sets. The experiment results demonstrate that our approaches yield reasonable performance as evaluated by automatic metrics such as ROUGE, medical concept recall, BLEU, and Self-BLEU. Furthermore, we conducted a comparative analysis between our proposed method and ChatGPT and GPT-4. This analysis also investigates the potential of utilizing cooperation LLMs to generate high-quality datasets.","sentences":["This paper presents UMASS_BioNLP team participation in the MEDIQA-Chat 2023 shared task for Task-A and Task-C. We focus especially on Task-C and propose a novel LLMs cooperation system named a doctor-patient loop to generate high-quality conversation data sets.","The experiment results demonstrate that our approaches yield reasonable performance as evaluated by automatic metrics such as ROUGE, medical concept recall, BLEU, and Self-BLEU.","Furthermore, we conducted a comparative analysis between our proposed method and ChatGPT and GPT-4.","This analysis also investigates the potential of utilizing cooperation LLMs to generate high-quality datasets."],"url":"http://arxiv.org/abs/2306.16931v1"}
{"created":"2023-06-29 13:28:16","title":"One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization","abstract":"Single image 3D reconstruction is an important but challenging task that requires extensive knowledge of our natural world. Many existing methods solve this problem by optimizing a neural radiance field under the guidance of 2D diffusion models but suffer from lengthy optimization time, 3D inconsistency results, and poor geometry. In this work, we propose a novel method that takes a single image of any object as input and generates a full 360-degree 3D textured mesh in a single feed-forward pass. Given a single image, we first use a view-conditioned 2D diffusion model, Zero123, to generate multi-view images for the input view, and then aim to lift them up to 3D space. Since traditional reconstruction methods struggle with inconsistent multi-view predictions, we build our 3D reconstruction module upon an SDF-based generalizable neural surface reconstruction method and propose several critical training strategies to enable the reconstruction of 360-degree meshes. Without costly optimizations, our method reconstructs 3D shapes in significantly less time than existing methods. Moreover, our method favors better geometry, generates more 3D consistent results, and adheres more closely to the input image. We evaluate our approach on both synthetic data and in-the-wild images and demonstrate its superiority in terms of both mesh quality and runtime. In addition, our approach can seamlessly support the text-to-3D task by integrating with off-the-shelf text-to-image diffusion models.","sentences":["Single image 3D reconstruction is an important but challenging task that requires extensive knowledge of our natural world.","Many existing methods solve this problem by optimizing a neural radiance field under the guidance of 2D diffusion models but suffer from lengthy optimization time, 3D inconsistency results, and poor geometry.","In this work, we propose a novel method that takes a single image of any object as input and generates a full 360-degree 3D textured mesh in a single feed-forward pass.","Given a single image, we first use a view-conditioned 2D diffusion model, Zero123, to generate multi-view images for the input view, and then aim to lift them up to 3D space.","Since traditional reconstruction methods struggle with inconsistent multi-view predictions, we build our 3D reconstruction module upon an SDF-based generalizable neural surface reconstruction method and propose several critical training strategies to enable the reconstruction of 360-degree meshes.","Without costly optimizations, our method reconstructs 3D shapes in significantly less time than existing methods.","Moreover, our method favors better geometry, generates more 3D consistent results, and adheres more closely to the input image.","We evaluate our approach on both synthetic data and in-the-wild images and demonstrate its superiority in terms of both mesh quality and runtime.","In addition, our approach can seamlessly support the text-to-3D task by integrating with off-the-shelf text-to-image diffusion models."],"url":"http://arxiv.org/abs/2306.16928v1"}
{"created":"2023-06-29 13:24:12","title":"OSP: Boosting Distributed Model Training with 2-stage Synchronization","abstract":"Distributed deep learning (DDL) is a promising research area, which aims to increase the efficiency of training deep learning tasks with large size of datasets and models. As the computation capability of DDL nodes continues to increase, the network connection between nodes is becoming a major bottleneck. Various methods of gradient compression and improved model synchronization have been proposed to address this bottleneck in Parameter-Server-based DDL. However, these two types of methods can result in accuracy loss due to discarded gradients and have limited enhancement on the throughput of model synchronization, respectively. To address these challenges, we propose a new model synchronization method named Overlapped Synchronization Parallel (OSP), which achieves efficient communication with a 2-stage synchronization approach and uses Local-Gradient-based Parameter correction (LGP) to avoid accuracy loss caused by stale parameters. The prototype of OSP has been implemented using PyTorch and evaluated on commonly used deep learning models and datasets with a 9-node testbed. Evaluation results show that OSP can achieve up to 50\\% improvement in throughput without accuracy loss compared to popular synchronization models.","sentences":["Distributed deep learning (DDL) is a promising research area, which aims to increase the efficiency of training deep learning tasks with large size of datasets and models.","As the computation capability of DDL nodes continues to increase, the network connection between nodes is becoming a major bottleneck.","Various methods of gradient compression and improved model synchronization have been proposed to address this bottleneck in Parameter-Server-based DDL.","However, these two types of methods can result in accuracy loss due to discarded gradients and have limited enhancement on the throughput of model synchronization, respectively.","To address these challenges, we propose a new model synchronization method named Overlapped Synchronization Parallel (OSP), which achieves efficient communication with a 2-stage synchronization approach and uses Local-Gradient-based Parameter correction (LGP) to avoid accuracy loss caused by stale parameters.","The prototype of OSP has been implemented using PyTorch and evaluated on commonly used deep learning models and datasets with a 9-node testbed.","Evaluation results show that OSP can achieve up to 50\\% improvement in throughput without accuracy loss compared to popular synchronization models."],"url":"http://arxiv.org/abs/2306.16926v1"}
{"created":"2023-06-29 13:22:13","title":"MIS-FM: 3D Medical Image Segmentation using Foundation Models Pretrained on a Large-Scale Unannotated Dataset","abstract":"Pretraining with large-scale 3D volumes has a potential for improving the segmentation performance on a target medical image dataset where the training images and annotations are limited. Due to the high cost of acquiring pixel-level segmentation annotations on the large-scale pretraining dataset, pretraining with unannotated images is highly desirable. In this work, we propose a novel self-supervised learning strategy named Volume Fusion (VF) for pretraining 3D segmentation models. It fuses several random patches from a foreground sub-volume to a background sub-volume based on a predefined set of discrete fusion coefficients, and forces the model to predict the fusion coefficient of each voxel, which is formulated as a self-supervised segmentation task without manual annotations. Additionally, we propose a novel network architecture based on parallel convolution and transformer blocks that is suitable to be transferred to different downstream segmentation tasks with various scales of organs and lesions. The proposed model was pretrained with 110k unannotated 3D CT volumes, and experiments with different downstream segmentation targets including head and neck organs, thoracic/abdominal organs showed that our pretrained model largely outperformed training from scratch and several state-of-the-art self-supervised training methods and segmentation models. The code and pretrained model are available at https://github.com/openmedlab/MIS-FM.","sentences":["Pretraining with large-scale 3D volumes has a potential for improving the segmentation performance on a target medical image dataset where the training images and annotations are limited.","Due to the high cost of acquiring pixel-level segmentation annotations on the large-scale pretraining dataset, pretraining with unannotated images is highly desirable.","In this work, we propose a novel self-supervised learning strategy named Volume Fusion (VF) for pretraining 3D segmentation models.","It fuses several random patches from a foreground sub-volume to a background sub-volume based on a predefined set of discrete fusion coefficients, and forces the model to predict the fusion coefficient of each voxel, which is formulated as a self-supervised segmentation task without manual annotations.","Additionally, we propose a novel network architecture based on parallel convolution and transformer blocks that is suitable to be transferred to different downstream segmentation tasks with various scales of organs and lesions.","The proposed model was pretrained with 110k unannotated 3D CT volumes, and experiments with different downstream segmentation targets including head and neck organs, thoracic/abdominal organs showed that our pretrained model largely outperformed training from scratch and several state-of-the-art self-supervised training methods and segmentation models.","The code and pretrained model are available at https://github.com/openmedlab/MIS-FM."],"url":"http://arxiv.org/abs/2306.16925v1"}
{"created":"2023-06-29 13:14:42","title":"Provable Advantage of Curriculum Learning on Parity Targets with Mixed Inputs","abstract":"Experimental results have shown that curriculum learning, i.e., presenting simpler examples before more complex ones, can improve the efficiency of learning. Some recent theoretical results also showed that changing the sampling distribution can help neural networks learn parities, with formal results only for large learning rates and one-step arguments. Here we show a separation result in the number of training steps with standard (bounded) learning rates on a common sample distribution: if the data distribution is a mixture of sparse and dense inputs, there exists a regime in which a 2-layer ReLU neural network trained by a curriculum noisy-GD (or SGD) algorithm that uses sparse examples first, can learn parities of sufficiently large degree, while any fully connected neural network of possibly larger width or depth trained by noisy-GD on the unordered samples cannot learn without additional steps. We also provide experimental results supporting the qualitative separation beyond the specific regime of the theoretical results.","sentences":["Experimental results have shown that curriculum learning, i.e., presenting simpler examples before more complex ones, can improve the efficiency of learning.","Some recent theoretical results also showed that changing the sampling distribution can help neural networks learn parities, with formal results only for large learning rates and one-step arguments.","Here we show a separation result in the number of training steps with standard (bounded) learning rates on a common sample distribution: if the data distribution is a mixture of sparse and dense inputs, there exists a regime in which a 2-layer ReLU neural network trained by a curriculum","noisy-GD (or SGD) algorithm that uses sparse examples first, can learn parities of sufficiently large degree, while any fully connected neural network of possibly larger width or depth trained by noisy-GD on the unordered samples cannot learn without additional steps.","We also provide experimental results supporting the qualitative separation beyond the specific regime of the theoretical results."],"url":"http://arxiv.org/abs/2306.16921v1"}
{"created":"2023-06-29 13:09:31","title":"The Drunkard's Odometry: Estimating Camera Motion in Deforming Scenes","abstract":"Estimating camera motion in deformable scenes poses a complex and open research challenge. Most existing non-rigid structure from motion techniques assume to observe also static scene parts besides deforming scene parts in order to establish an anchoring reference. However, this assumption does not hold true in certain relevant application cases such as endoscopies. Deformable odometry and SLAM pipelines, which tackle the most challenging scenario of exploratory trajectories, suffer from a lack of robustness and proper quantitative evaluation methodologies. To tackle this issue with a common benchmark, we introduce the Drunkard's Dataset, a challenging collection of synthetic data targeting visual navigation and reconstruction in deformable environments. This dataset is the first large set of exploratory camera trajectories with ground truth inside 3D scenes where every surface exhibits non-rigid deformations over time. Simulations in realistic 3D buildings lets us obtain a vast amount of data and ground truth labels, including camera poses, RGB images and depth, optical flow and normal maps at high resolution and quality. We further present a novel deformable odometry method, dubbed the Drunkard's Odometry, which decomposes optical flow estimates into rigid-body camera motion and non-rigid scene deformations. In order to validate our data, our work contains an evaluation of several baselines as well as a novel tracking error metric which does not require ground truth data. Dataset and code: https://davidrecasens.github.io/TheDrunkard'sOdometry/","sentences":["Estimating camera motion in deformable scenes poses a complex and open research challenge.","Most existing non-rigid structure from motion techniques assume to observe also static scene parts besides deforming scene parts in order to establish an anchoring reference.","However, this assumption does not hold true in certain relevant application cases such as endoscopies.","Deformable odometry and SLAM pipelines, which tackle the most challenging scenario of exploratory trajectories, suffer from a lack of robustness and proper quantitative evaluation methodologies.","To tackle this issue with a common benchmark, we introduce the Drunkard's Dataset, a challenging collection of synthetic data targeting visual navigation and reconstruction in deformable environments.","This dataset is the first large set of exploratory camera trajectories with ground truth inside 3D scenes where every surface exhibits non-rigid deformations over time.","Simulations in realistic 3D buildings lets us obtain a vast amount of data and ground truth labels, including camera poses, RGB images and depth, optical flow and normal maps at high resolution and quality.","We further present a novel deformable odometry method, dubbed the Drunkard's Odometry, which decomposes optical flow estimates into rigid-body camera motion and non-rigid scene deformations.","In order to validate our data, our work contains an evaluation of several baselines as well as a novel tracking error metric which does not require ground truth data.","Dataset and code: https://davidrecasens.github.io/TheDrunkard'sOdometry/"],"url":"http://arxiv.org/abs/2306.16917v1"}
{"created":"2023-06-29 13:08:36","title":"Obeying the Order: Introducing Ordered Transfer Hyperparameter Optimisation","abstract":"We introduce ordered transfer hyperparameter optimisation (OTHPO), a version of transfer learning for hyperparameter optimisation (HPO) where the tasks follow a sequential order. Unlike for state-of-the-art transfer HPO, the assumption is that each task is most correlated to those immediately before it. This matches many deployed settings, where hyperparameters are retuned as more data is collected; for instance tuning a sequence of movie recommendation systems as more movies and ratings are added. We propose a formal definition, outline the differences to related problems and propose a basic OTHPO method that outperforms state-of-the-art transfer HPO. We empirically show the importance of taking order into account using ten benchmarks. The benchmarks are in the setting of gradually accumulating data, and span XGBoost, random forest, approximate k-nearest neighbor, elastic net, support vector machines and a separate real-world motivated optimisation problem. We open source the benchmarks to foster future research on ordered transfer HPO.","sentences":["We introduce ordered transfer hyperparameter optimisation (OTHPO), a version of transfer learning for hyperparameter optimisation (HPO) where the tasks follow a sequential order.","Unlike for state-of-the-art transfer HPO, the assumption is that each task is most correlated to those immediately before it.","This matches many deployed settings, where hyperparameters are retuned as more data is collected; for instance tuning a sequence of movie recommendation systems as more movies and ratings are added.","We propose a formal definition, outline the differences to related problems and propose a basic OTHPO method that outperforms state-of-the-art transfer HPO.","We empirically show the importance of taking order into account using ten benchmarks.","The benchmarks are in the setting of gradually accumulating data, and span XGBoost, random forest, approximate k-nearest neighbor, elastic net, support vector machines and a separate real-world motivated optimisation problem.","We open source the benchmarks to foster future research on ordered transfer HPO."],"url":"http://arxiv.org/abs/2306.16916v1"}
{"created":"2023-06-29 13:08:12","title":"Computationally Assisted Quality Control for Public Health Data Streams","abstract":"Irregularities in public health data streams (like COVID-19 Cases) hamper data-driven decision-making for public health stakeholders. A real-time, computer-generated list of the most important, outlying data points from thousands of daily-updated public health data streams could assist an expert reviewer in identifying these irregularities. However, existing outlier detection frameworks perform poorly on this task because they do not account for the data volume or for the statistical properties of public health streams. Accordingly, we developed FlaSH (Flagging Streams in public Health), a practical outlier detection framework for public health data users that uses simple, scalable models to capture these statistical properties explicitly. In an experiment where human experts evaluate FlaSH and existing methods (including deep learning approaches), FlaSH scales to the data volume of this task, matches or exceeds these other methods in mean accuracy, and identifies the outlier points that users empirically rate as more helpful. Based on these results, FlaSH has been deployed on data streams used by public health stakeholders.","sentences":["Irregularities in public health data streams (like COVID-19 Cases) hamper data-driven decision-making for public health stakeholders.","A real-time, computer-generated list of the most important, outlying data points from thousands of daily-updated public health data streams could assist an expert reviewer in identifying these irregularities.","However, existing outlier detection frameworks perform poorly on this task because they do not account for the data volume or for the statistical properties of public health streams.","Accordingly, we developed FlaSH (Flagging Streams in public Health), a practical outlier detection framework for public health data users that uses simple, scalable models to capture these statistical properties explicitly.","In an experiment where human experts evaluate FlaSH and existing methods (including deep learning approaches), FlaSH scales to the data volume of this task, matches or exceeds these other methods in mean accuracy, and identifies the outlier points that users empirically rate as more helpful.","Based on these results, FlaSH has been deployed on data streams used by public health stakeholders."],"url":"http://arxiv.org/abs/2306.16914v1"}
{"created":"2023-06-29 13:05:12","title":"AutoML in Heavily Constrained Applications","abstract":"Optimizing a machine learning pipeline for a task at hand requires careful configuration of various hyperparameters, typically supported by an AutoML system that optimizes the hyperparameters for the given training dataset. Yet, depending on the AutoML system's own second-order meta-configuration, the performance of the AutoML process can vary significantly. Current AutoML systems cannot automatically adapt their own configuration to a specific use case. Further, they cannot compile user-defined application constraints on the effectiveness and efficiency of the pipeline and its generation. In this paper, we propose Caml, which uses meta-learning to automatically adapt its own AutoML parameters, such as the search strategy, the validation strategy, and the search space, for a task at hand. The dynamic AutoML strategy of Caml takes user-defined constraints into account and obtains constraint-satisfying pipelines with high predictive performance.","sentences":["Optimizing a machine learning pipeline for a task at hand requires careful configuration of various hyperparameters, typically supported by an AutoML system that optimizes the hyperparameters for the given training dataset.","Yet, depending on the AutoML system's own second-order meta-configuration, the performance of the AutoML process can vary significantly.","Current AutoML systems cannot automatically adapt their own configuration to a specific use case.","Further, they cannot compile user-defined application constraints on the effectiveness and efficiency of the pipeline and its generation.","In this paper, we propose Caml, which uses meta-learning to automatically adapt its own AutoML parameters, such as the search strategy, the validation strategy, and the search space, for a task at hand.","The dynamic AutoML strategy of Caml takes user-defined constraints into account and obtains constraint-satisfying pipelines with high predictive performance."],"url":"http://arxiv.org/abs/2306.16913v1"}
{"created":"2023-06-29 12:48:25","title":"Leveraging Cross-Utterance Context For ASR Decoding","abstract":"While external language models (LMs) are often incorporated into the decoding stage of automated speech recognition systems, these models usually operate with limited context. Cross utterance information has been shown to be beneficial during second pass re-scoring, however this limits the hypothesis space based on the local information available to the first pass LM. In this work, we investigate the incorporation of long-context transformer LMs for cross-utterance decoding of acoustic models via beam search, and compare against results from n-best rescoring. Results demonstrate that beam search allows for an improved use of cross-utterance context. When evaluating on the long-format dataset AMI, results show a 0.7\\% and 0.3\\% absolute reduction on dev and test sets compared to the single-utterance setting, with improvements when including up to 500 tokens of prior context. Evaluations are also provided for Tedlium-1 with less significant improvements of around 0.1\\% absolute.","sentences":["While external language models (LMs) are often incorporated into the decoding stage of automated speech recognition systems, these models usually operate with limited context.","Cross utterance information has been shown to be beneficial during second pass re-scoring, however this limits the hypothesis space based on the local information available to the first pass LM.","In this work, we investigate the incorporation of long-context transformer LMs for cross-utterance decoding of acoustic models via beam search, and compare against results from n-best rescoring.","Results demonstrate that beam search allows for an improved use of cross-utterance context.","When evaluating on the long-format dataset AMI, results show a 0.7\\% and 0.3\\% absolute reduction on dev and test sets compared to the single-utterance setting, with improvements when including up to 500 tokens of prior context.","Evaluations are also provided for Tedlium-1 with less significant improvements of around 0.1\\% absolute."],"url":"http://arxiv.org/abs/2306.16903v1"}
{"created":"2023-06-29 12:48:00","title":"From Query Tools to Causal Architects: Harnessing Large Language Models for Advanced Causal Discovery from Data","abstract":"Large Language Models (LLMs) exhibit exceptional abilities for causal analysis between concepts in numerous societally impactful domains, including medicine, science, and law. Recent research on LLM performance in various causal discovery and inference tasks has given rise to a new ladder in the classical three-stage framework of causality. In this paper, we advance the current research of LLM-driven causal discovery by proposing a novel framework that combines knowledge-based LLM causal analysis with data-driven causal structure learning. To make LLM more than a query tool and to leverage its power in discovering natural and new laws of causality, we integrate the valuable LLM expertise on existing causal mechanisms into statistical analysis of objective data to build a novel and practical baseline for causal structure learning.   We introduce a universal set of prompts designed to extract causal graphs from given variables and assess the influence of LLM prior causality on recovering causal structures from data. We demonstrate the significant enhancement of LLM expertise on the quality of recovered causal structures from data, while also identifying critical challenges and issues, along with potential approaches to address them. As a pioneering study, this paper aims to emphasize the new frontier that LLMs are opening for classical causal discovery and inference, and to encourage the widespread adoption of LLM capabilities in data-driven causal analysis.","sentences":["Large Language Models (LLMs) exhibit exceptional abilities for causal analysis between concepts in numerous societally impactful domains, including medicine, science, and law.","Recent research on LLM performance in various causal discovery and inference tasks has given rise to a new ladder in the classical three-stage framework of causality.","In this paper, we advance the current research of LLM-driven causal discovery by proposing a novel framework that combines knowledge-based LLM causal analysis with data-driven causal structure learning.","To make LLM more than a query tool and to leverage its power in discovering natural and new laws of causality, we integrate the valuable LLM expertise on existing causal mechanisms into statistical analysis of objective data to build a novel and practical baseline for causal structure learning.   ","We introduce a universal set of prompts designed to extract causal graphs from given variables and assess the influence of LLM prior causality on recovering causal structures from data.","We demonstrate the significant enhancement of LLM expertise on the quality of recovered causal structures from data, while also identifying critical challenges and issues, along with potential approaches to address them.","As a pioneering study, this paper aims to emphasize the new frontier that LLMs are opening for classical causal discovery and inference, and to encourage the widespread adoption of LLM capabilities in data-driven causal analysis."],"url":"http://arxiv.org/abs/2306.16902v1"}
{"created":"2023-06-29 12:44:53","title":"Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research","abstract":"Many recent improvements in NLP stem from the development and use of large pre-trained language models (PLMs) with billions of parameters. Large model sizes makes computational cost one of the main limiting factors for training and evaluating such models; and has raised severe concerns about the sustainability, reproducibility, and inclusiveness for researching PLMs. These concerns are often based on personal experiences and observations. However, there had not been any large-scale surveys that investigate them. In this work, we provide a first attempt to quantify these concerns regarding three topics, namely, environmental impact, equity, and impact on peer reviewing. By conducting a survey with 312 participants from the NLP community, we capture existing (dis)parities between different and within groups with respect to seniority, academia, and industry; and their impact on the peer reviewing process. For each topic, we provide an analysis and devise recommendations to mitigate found disparities, some of which already successfully implemented. Finally, we discuss additional concerns raised by many participants in free-text responses.","sentences":["Many recent improvements in NLP stem from the development and use of large pre-trained language models (PLMs) with billions of parameters.","Large model sizes makes computational cost one of the main limiting factors for training and evaluating such models; and has raised severe concerns about the sustainability, reproducibility, and inclusiveness for researching PLMs.","These concerns are often based on personal experiences and observations.","However, there had not been any large-scale surveys that investigate them.","In this work, we provide a first attempt to quantify these concerns regarding three topics, namely, environmental impact, equity, and impact on peer reviewing.","By conducting a survey with 312 participants from the NLP community, we capture existing (dis)parities between different and within groups with respect to seniority, academia, and industry; and their impact on the peer reviewing process.","For each topic, we provide an analysis and devise recommendations to mitigate found disparities, some of which already successfully implemented.","Finally, we discuss additional concerns raised by many participants in free-text responses."],"url":"http://arxiv.org/abs/2306.16900v1"}
{"created":"2023-06-29 12:43:32","title":"An improved kernelization algorithm for Trivially Perfect Editing","abstract":"In the Trivially Perfect Editing problem one is given an undirected graph $G = (V,E)$ and an integer $k$ and seeks to add or delete at most $k$ edges in $G$ to obtain a trivially perfect graph. In a recent work, Dumas, Perez and Todinca [Algorithmica 2023] proved that this problem admits a kernel with $O(k^3)$ vertices. This result heavily relies on the fact that the size of trivially perfect modules can be bounded by $O(k^2)$ as shown by Drange and Pilipczuk [Algorithmica 2018]. To obtain their cubic vertex-kernel, Dumas, Perez and Todinca [Algorithmica 2023] then showed that a more intricate structure, so-called \\emph{comb}, can be reduced to $O(k^2)$ vertices. In this work we show that the bound can be improved to $O(k)$ for both aforementioned structures and thus obtain a kernel with $O(k^2)$ vertices. Our approach relies on the straightforward yet powerful observation that any large enough structure contains unaffected vertices whose neighborhood remains unchanged by an editing of size $k$, implying strong structural properties.","sentences":["In the Trivially Perfect Editing problem one is given an undirected graph $G = (V,E)$ and an integer $k$ and seeks to add or delete at most $k$ edges in $G$ to obtain a trivially perfect graph.","In a recent work, Dumas, Perez and Todinca [Algorithmica 2023] proved that this problem admits a kernel with $O(k^3)$ vertices.","This result heavily relies on the fact that the size of trivially perfect modules can be bounded by $O(k^2)$ as shown by Drange and Pilipczuk [Algorithmica 2018].","To obtain their cubic vertex-kernel, Dumas, Perez and Todinca [Algorithmica 2023] then showed that a more intricate structure, so-called \\emph{comb}, can be reduced to $O(k^2)$ vertices.","In this work we show that the bound can be improved to $O(k)$ for both aforementioned structures and thus obtain a kernel with $O(k^2)$ vertices.","Our approach relies on the straightforward yet powerful observation that any large enough structure contains unaffected vertices whose neighborhood remains unchanged by an editing of size $k$, implying strong structural properties."],"url":"http://arxiv.org/abs/2306.16899v1"}
{"created":"2023-06-29 12:39:25","title":"Whole-Body Exploration with a Manipulator Using Heat Equation","abstract":"This paper presents a whole-body robot control method for exploring and probing a given region of interest. The ergodic control formalism behind such an exploration behavior consists of matching the time-averaged statistics of a robot trajectory with the spatial statistics of the target distribution. Most existing ergodic control approaches assume the robots/sensors as individual point agents moving in space. We introduce an approach exploiting multiple kinematically constrained agents on the whole-body of a robotic manipulator, where a consensus among the agents is found for generating control actions. To do so, we exploit an existing ergodic control formulation called heat equation-driven area coverage (HEDAC), combining local and global exploration on a potential field resulting from heat diffusion. Our approach extends HEDAC to applications where robots have multiple sensors on the whole-body (such as tactile skin) and use all sensors to optimally explore the given region. We show that our approach increases the exploration performance in terms of ergodicity and scales well to real-world problems using agents distributed on multiple robot links. We compare our method with HEDAC in kinematic simulation and demonstrate the applicability of an online exploration task with a 7-axis Franka Emika robot.","sentences":["This paper presents a whole-body robot control method for exploring and probing a given region of interest.","The ergodic control formalism behind such an exploration behavior consists of matching the time-averaged statistics of a robot trajectory with the spatial statistics of the target distribution.","Most existing ergodic control approaches assume the robots/sensors as individual point agents moving in space.","We introduce an approach exploiting multiple kinematically constrained agents on the whole-body of a robotic manipulator, where a consensus among the agents is found for generating control actions.","To do so, we exploit an existing ergodic control formulation called heat equation-driven area coverage (HEDAC), combining local and global exploration on a potential field resulting from heat diffusion.","Our approach extends HEDAC to applications where robots have multiple sensors on the whole-body (such as tactile skin) and use all sensors to optimally explore the given region.","We show that our approach increases the exploration performance in terms of ergodicity and scales well to real-world problems using agents distributed on multiple robot links.","We compare our method with HEDAC in kinematic simulation and demonstrate the applicability of an online exploration task with a 7-axis Franka Emika robot."],"url":"http://arxiv.org/abs/2306.16898v1"}
{"created":"2023-06-29 12:29:21","title":"Traceable Group-Wise Self-Optimizing Feature Transformation Learning: A Dual Optimization Perspective","abstract":"Feature transformation aims to reconstruct an effective representation space by mathematically refining the existing features. It serves as a pivotal approach to combat the curse of dimensionality, enhance model generalization, mitigate data sparsity, and extend the applicability of classical models. Existing research predominantly focuses on domain knowledge-based feature engineering or learning latent representations. However, these methods, while insightful, lack full automation and fail to yield a traceable and optimal representation space. An indispensable question arises: Can we concurrently address these limitations when reconstructing a feature space for a machine-learning task? Our initial work took a pioneering step towards this challenge by introducing a novel self-optimizing framework. This framework leverages the power of three cascading reinforced agents to automatically select candidate features and operations for generating improved feature transformation combinations. Despite the impressive strides made, there was room for enhancing its effectiveness and generalization capability. In this extended journal version, we advance our initial work from two distinct yet interconnected perspectives: 1) We propose a refinement of the original framework, which integrates a graph-based state representation method to capture the feature interactions more effectively and develop different Q-learning strategies to alleviate Q-value overestimation further. 2) We utilize a new optimization technique (actor-critic) to train the entire self-optimizing framework in order to accelerate the model convergence and improve the feature transformation performance. Finally, to validate the improved effectiveness and generalization capability of our framework, we perform extensive experiments and conduct comprehensive analyses.","sentences":["Feature transformation aims to reconstruct an effective representation space by mathematically refining the existing features.","It serves as a pivotal approach to combat the curse of dimensionality, enhance model generalization, mitigate data sparsity, and extend the applicability of classical models.","Existing research predominantly focuses on domain knowledge-based feature engineering or learning latent representations.","However, these methods, while insightful, lack full automation and fail to yield a traceable and optimal representation space.","An indispensable question arises: Can we concurrently address these limitations when reconstructing a feature space for a machine-learning task?","Our initial work took a pioneering step towards this challenge by introducing a novel self-optimizing framework.","This framework leverages the power of three cascading reinforced agents to automatically select candidate features and operations for generating improved feature transformation combinations.","Despite the impressive strides made, there was room for enhancing its effectiveness and generalization capability.","In this extended journal version, we advance our initial work from two distinct yet interconnected perspectives: 1) We propose a refinement of the original framework, which integrates a graph-based state representation method to capture the feature interactions more effectively and develop different Q-learning strategies to alleviate Q-value overestimation further.","2) We utilize a new optimization technique (actor-critic) to train the entire self-optimizing framework in order to accelerate the model convergence and improve the feature transformation performance.","Finally, to validate the improved effectiveness and generalization capability of our framework, we perform extensive experiments and conduct comprehensive analyses."],"url":"http://arxiv.org/abs/2306.16893v1"}
{"created":"2023-06-29 12:25:19","title":"Harnessing the Power of Hugging Face Transformers for Predicting Mental Health Disorders in Social Networks","abstract":"Early diagnosis of mental disorders and intervention can facilitate the prevention of severe injuries and the improvement of treatment results. Using social media and pre-trained language models, this study explores how user-generated data can be used to predict mental disorder symptoms. Our study compares four different BERT models of Hugging Face with standard machine learning techniques used in automatic depression diagnosis in recent literature. The results show that new models outperform the previous approach with an accuracy rate of up to 97%. Analyzing the results while complementing past findings, we find that even tiny amounts of data (like users' bio descriptions) have the potential to predict mental disorders. We conclude that social media data is an excellent source of mental health screening, and pre-trained models can effectively automate this critical task.","sentences":["Early diagnosis of mental disorders and intervention can facilitate the prevention of severe injuries and the improvement of treatment results.","Using social media and pre-trained language models, this study explores how user-generated data can be used to predict mental disorder symptoms.","Our study compares four different BERT models of Hugging Face with standard machine learning techniques used in automatic depression diagnosis in recent literature.","The results show that new models outperform the previous approach with an accuracy rate of up to 97%.","Analyzing the results while complementing past findings, we find that even tiny amounts of data (like users' bio descriptions) have the potential to predict mental disorders.","We conclude that social media data is an excellent source of mental health screening, and pre-trained models can effectively automate this critical task."],"url":"http://arxiv.org/abs/2306.16891v1"}
{"created":"2023-06-29 12:22:47","title":"Trajectory Poisson multi-Bernoulli mixture filter for traffic monitoring using a drone","abstract":"This paper proposes a multi-object tracking (MOT) algorithm for traffic monitoring using a drone equipped with optical and thermal cameras. Object detections on the images are obtained using a neural network for each type of camera. The cameras are modelled as direction-of-arrival (DOA) sensors. Each DOA detection follows a von-Mises Fisher distribution, whose mean direction is obtain by projecting a vehicle position on the ground to the camera. We then use the trajectory Poisson multi-Bernoulli mixture filter (TPMBM), which is a Bayesian MOT algorithm, to optimally estimate the set of vehicle trajectories. We have also developed a parameter estimation algorithm for the measurement model. We have tested the accuracy of the resulting TPMBM filter in synthetic and experimental data sets.","sentences":["This paper proposes a multi-object tracking (MOT) algorithm for traffic monitoring using a drone equipped with optical and thermal cameras.","Object detections on the images are obtained using a neural network for each type of camera.","The cameras are modelled as direction-of-arrival (DOA) sensors.","Each DOA detection follows a von-Mises Fisher distribution, whose mean direction is obtain by projecting a vehicle position on the ground to the camera.","We then use the trajectory Poisson multi-Bernoulli mixture filter (TPMBM), which is a Bayesian MOT algorithm, to optimally estimate the set of vehicle trajectories.","We have also developed a parameter estimation algorithm for the measurement model.","We have tested the accuracy of the resulting TPMBM filter in synthetic and experimental data sets."],"url":"http://arxiv.org/abs/2306.16890v1"}
