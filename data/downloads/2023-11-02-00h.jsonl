{"created":"2023-10-31 17:59:58","title":"FPO++: Efficient Encoding and Rendering of Dynamic Neural Radiance Fields by Analyzing and Enhancing Fourier PlenOctrees","abstract":"Fourier PlenOctrees have shown to be an efficient representation for real-time rendering of dynamic Neural Radiance Fields (NeRF). Despite its many advantages, this method suffers from artifacts introduced by the involved compression when combining it with recent state-of-the-art techniques for training the static per-frame NeRF models. In this paper, we perform an in-depth analysis of these artifacts and leverage the resulting insights to propose an improved representation. In particular, we present a novel density encoding that adapts the Fourier-based compression to the characteristics of the transfer function used by the underlying volume rendering procedure and leads to a substantial reduction of artifacts in the dynamic model. Furthermore, we show an augmentation of the training data that relaxes the periodicity assumption of the compression. We demonstrate the effectiveness of our enhanced Fourier PlenOctrees in the scope of quantitative and qualitative evaluations on synthetic and real-world scenes.","sentences":["Fourier PlenOctrees have shown to be an efficient representation for real-time rendering of dynamic Neural Radiance Fields (NeRF).","Despite its many advantages, this method suffers from artifacts introduced by the involved compression when combining it with recent state-of-the-art techniques for training the static per-frame NeRF models.","In this paper, we perform an in-depth analysis of these artifacts and leverage the resulting insights to propose an improved representation.","In particular, we present a novel density encoding that adapts the Fourier-based compression to the characteristics of the transfer function used by the underlying volume rendering procedure and leads to a substantial reduction of artifacts in the dynamic model.","Furthermore, we show an augmentation of the training data that relaxes the periodicity assumption of the compression.","We demonstrate the effectiveness of our enhanced Fourier PlenOctrees in the scope of quantitative and qualitative evaluations on synthetic and real-world scenes."],"url":"http://arxiv.org/abs/2310.20710v1"}
{"created":"2023-10-31 17:59:56","title":"Unexpected Improvements to Expected Improvement for Bayesian Optimization","abstract":"Expected Improvement (EI) is arguably the most popular acquisition function in Bayesian optimization and has found countless successful applications, but its performance is often exceeded by that of more recent methods. Notably, EI and its variants, including for the parallel and multi-objective settings, are challenging to optimize because their acquisition values vanish numerically in many regions. This difficulty generally increases as the number of observations, dimensionality of the search space, or the number of constraints grow, resulting in performance that is inconsistent across the literature and most often sub-optimal. Herein, we propose LogEI, a new family of acquisition functions whose members either have identical or approximately equal optima as their canonical counterparts, but are substantially easier to optimize numerically. We demonstrate that numerical pathologies manifest themselves in \"classic\" analytic EI, Expected Hypervolume Improvement (EHVI), as well as their constrained, noisy, and parallel variants, and propose corresponding reformulations that remedy these pathologies. Our empirical results show that members of the LogEI family of acquisition functions substantially improve on the optimization performance of their canonical counterparts and surprisingly, are on par with or exceed the performance of recent state-of-the-art acquisition functions, highlighting the understated role of numerical optimization in the literature.","sentences":["Expected Improvement (EI) is arguably the most popular acquisition function in Bayesian optimization and has found countless successful applications, but its performance is often exceeded by that of more recent methods.","Notably, EI and its variants, including for the parallel and multi-objective settings, are challenging to optimize because their acquisition values vanish numerically in many regions.","This difficulty generally increases as the number of observations, dimensionality of the search space, or the number of constraints grow, resulting in performance that is inconsistent across the literature and most often sub-optimal.","Herein, we propose LogEI, a new family of acquisition functions whose members either have identical or approximately equal optima as their canonical counterparts, but are substantially easier to optimize numerically.","We demonstrate that numerical pathologies manifest themselves in \"classic\" analytic EI, Expected Hypervolume Improvement (EHVI), as well as their constrained, noisy, and parallel variants, and propose corresponding reformulations that remedy these pathologies.","Our empirical results show that members of the LogEI family of acquisition functions substantially improve on the optimization performance of their canonical counterparts and surprisingly, are on par with or exceed the performance of recent state-of-the-art acquisition functions, highlighting the understated role of numerical optimization in the literature."],"url":"http://arxiv.org/abs/2310.20708v1"}
{"created":"2023-10-31 17:59:38","title":"What's In My Big Data?","abstract":"Large text corpora are the backbone of language models. However, we have a limited understanding of the content of these corpora, including general statistics, quality, social factors, and inclusion of evaluation data (contamination). In this work, we propose What's In My Big Data? (WIMBD), a platform and a set of sixteen analyses that allow us to reveal and compare the contents of large text corpora. WIMBD builds on two basic capabilities -- count and search -- at scale, which allows us to analyze more than 35 terabytes on a standard compute node. We apply WIMBD to ten different corpora used to train popular language models, including C4, The Pile, and RedPajama. Our analysis uncovers several surprising and previously undocumented findings about these corpora, including the high prevalence of duplicate, synthetic, and low-quality content, personally identifiable information, toxic language, and benchmark contamination. For instance, we find that about 50% of the documents in RedPajama and LAION-2B-en are duplicates. In addition, several datasets used for benchmarking models trained on such corpora are contaminated with respect to important benchmarks, including the Winograd Schema Challenge and parts of GLUE and SuperGLUE. We open-source WIMBD's code and artifacts to provide a standard set of evaluations for new text-based corpora and to encourage more analyses and transparency around them: github.com/allenai/wimbd.","sentences":["Large text corpora are the backbone of language models.","However, we have a limited understanding of the content of these corpora, including general statistics, quality, social factors, and inclusion of evaluation data (contamination).","In this work, we propose What's In My Big Data?","(WIMBD), a platform and a set of sixteen analyses that allow us to reveal and compare the contents of large text corpora.","WIMBD builds on two basic capabilities -- count and search -- at scale, which allows us to analyze more than 35 terabytes on a standard compute node.","We apply WIMBD to ten different corpora used to train popular language models, including C4, The Pile, and RedPajama.","Our analysis uncovers several surprising and previously undocumented findings about these corpora, including the high prevalence of duplicate, synthetic, and low-quality content, personally identifiable information, toxic language, and benchmark contamination.","For instance, we find that about 50% of the documents in RedPajama and LAION-2B-en are duplicates.","In addition, several datasets used for benchmarking models trained on such corpora are contaminated with respect to important benchmarks, including the Winograd Schema Challenge and parts of GLUE and SuperGLUE.","We open-source WIMBD's code and artifacts to provide a standard set of evaluations for new text-based corpora and to encourage more analyses and transparency around them: github.com/allenai/wimbd."],"url":"http://arxiv.org/abs/2310.20707v1"}
{"created":"2023-10-31 17:59:14","title":"Farthest Greedy Path Sampling for Two-shot Recommender Search","abstract":"Weight-sharing Neural Architecture Search (WS-NAS) provides an efficient mechanism for developing end-to-end deep recommender models. However, in complex search spaces, distinguishing between superior and inferior architectures (or paths) is challenging. This challenge is compounded by the limited coverage of the supernet and the co-adaptation of subnet weights, which restricts the exploration and exploitation capabilities inherent to weight-sharing mechanisms. To address these challenges, we introduce Farthest Greedy Path Sampling (FGPS), a new path sampling strategy that balances path quality and diversity. FGPS enhances path diversity to facilitate more comprehensive supernet exploration, while emphasizing path quality to ensure the effective identification and utilization of promising architectures. By incorporating FGPS into a Two-shot NAS (TS-NAS) framework, we derive high-performance architectures. Evaluations on three Click-Through Rate (CTR) prediction benchmarks demonstrate that our approach consistently achieves superior results, outperforming both manually designed and most NAS-based models.","sentences":["Weight-sharing Neural Architecture Search (WS-NAS) provides an efficient mechanism for developing end-to-end deep recommender models.","However, in complex search spaces, distinguishing between superior and inferior architectures (or paths) is challenging.","This challenge is compounded by the limited coverage of the supernet and the co-adaptation of subnet weights, which restricts the exploration and exploitation capabilities inherent to weight-sharing mechanisms.","To address these challenges, we introduce Farthest Greedy Path Sampling (FGPS), a new path sampling strategy that balances path quality and diversity.","FGPS enhances path diversity to facilitate more comprehensive supernet exploration, while emphasizing path quality to ensure the effective identification and utilization of promising architectures.","By incorporating FGPS into a Two-shot NAS (TS-NAS) framework, we derive high-performance architectures.","Evaluations on three Click-Through Rate (CTR) prediction benchmarks demonstrate that our approach consistently achieves superior results, outperforming both manually designed and most NAS-based models."],"url":"http://arxiv.org/abs/2310.20705v1"}
{"created":"2023-10-31 17:59:14","title":"DDAM-PS: Diligent Domain Adaptive Mixer for Person Search","abstract":"Person search (PS) is a challenging computer vision problem where the objective is to achieve joint optimization for pedestrian detection and re-identification (ReID). Although previous advancements have shown promising performance in the field under fully and weakly supervised learning fashion, there exists a major gap in investigating the domain adaptation ability of PS models. In this paper, we propose a diligent domain adaptive mixer (DDAM) for person search (DDAP-PS) framework that aims to bridge a gap to improve knowledge transfer from the labeled source domain to the unlabeled target domain. Specifically, we introduce a novel DDAM module that generates moderate mixed-domain representations by combining source and target domain representations. The proposed DDAM module encourages domain mixing to minimize the distance between the two extreme domains, thereby enhancing the ReID task. To achieve this, we introduce two bridge losses and a disparity loss. The objective of the two bridge losses is to guide the moderate mixed-domain representations to maintain an appropriate distance from both the source and target domain representations. The disparity loss aims to prevent the moderate mixed-domain representations from being biased towards either the source or target domains, thereby avoiding overfitting. Furthermore, we address the conflict between the two subtasks, localization and ReID, during domain adaptation. To handle this cross-task conflict, we forcefully decouple the norm-aware embedding, which aids in better learning of the moderate mixed-domain representation. We conduct experiments to validate the effectiveness of our proposed method. Our approach demonstrates favorable performance on the challenging PRW and CUHK-SYSU datasets. Our source code is publicly available at \\url{https://github.com/mustansarfiaz/DDAM-PS}.","sentences":["Person search (PS) is a challenging computer vision problem where the objective is to achieve joint optimization for pedestrian detection and re-identification (ReID).","Although previous advancements have shown promising performance in the field under fully and weakly supervised learning fashion, there exists a major gap in investigating the domain adaptation ability of PS models.","In this paper, we propose a diligent domain adaptive mixer (DDAM) for person search (DDAP-PS) framework that aims to bridge a gap to improve knowledge transfer from the labeled source domain to the unlabeled target domain.","Specifically, we introduce a novel DDAM module that generates moderate mixed-domain representations by combining source and target domain representations.","The proposed DDAM module encourages domain mixing to minimize the distance between the two extreme domains, thereby enhancing the ReID task.","To achieve this, we introduce two bridge losses and a disparity loss.","The objective of the two bridge losses is to guide the moderate mixed-domain representations to maintain an appropriate distance from both the source and target domain representations.","The disparity loss aims to prevent the moderate mixed-domain representations from being biased towards either the source or target domains, thereby avoiding overfitting.","Furthermore, we address the conflict between the two subtasks, localization and ReID, during domain adaptation.","To handle this cross-task conflict, we forcefully decouple the norm-aware embedding, which aids in better learning of the moderate mixed-domain representation.","We conduct experiments to validate the effectiveness of our proposed method.","Our approach demonstrates favorable performance on the challenging PRW and CUHK-SYSU datasets.","Our source code is publicly available at \\url{https://github.com/mustansarfiaz/DDAM-PS}."],"url":"http://arxiv.org/abs/2310.20706v1"}
{"created":"2023-10-31 17:59:07","title":"Limited Data, Unlimited Potential: A Study on ViTs Augmented by Masked Autoencoders","abstract":"Vision Transformers (ViTs) have become ubiquitous in computer vision. Despite their success, ViTs lack inductive biases, which can make it difficult to train them with limited data. To address this challenge, prior studies suggest training ViTs with self-supervised learning (SSL) and fine-tuning sequentially. However, we observe that jointly optimizing ViTs for the primary task and a Self-Supervised Auxiliary Task (SSAT) is surprisingly beneficial when the amount of training data is limited. We explore the appropriate SSL tasks that can be optimized alongside the primary task, the training schemes for these tasks, and the data scale at which they can be most effective. Our findings reveal that SSAT is a powerful technique that enables ViTs to leverage the unique characteristics of both the self-supervised and primary tasks, achieving better performance than typical ViTs pre-training with SSL and fine-tuning sequentially. Our experiments, conducted on 10 datasets, demonstrate that SSAT significantly improves ViT performance while reducing carbon footprint. We also confirm the effectiveness of SSAT in the video domain for deepfake detection, showcasing its generalizability. Our code is available at https://github.com/dominickrei/Limited-data-vits.","sentences":["Vision Transformers (ViTs) have become ubiquitous in computer vision.","Despite their success, ViTs lack inductive biases, which can make it difficult to train them with limited data.","To address this challenge, prior studies suggest training ViTs with self-supervised learning (SSL) and fine-tuning sequentially.","However, we observe that jointly optimizing ViTs for the primary task and a Self-Supervised Auxiliary Task (SSAT) is surprisingly beneficial when the amount of training data is limited.","We explore the appropriate SSL tasks that can be optimized alongside the primary task, the training schemes for these tasks, and the data scale at which they can be most effective.","Our findings reveal that SSAT is a powerful technique that enables ViTs to leverage the unique characteristics of both the self-supervised and primary tasks, achieving better performance than typical ViTs pre-training with SSL and fine-tuning sequentially.","Our experiments, conducted on 10 datasets, demonstrate that SSAT significantly improves ViT performance while reducing carbon footprint.","We also confirm the effectiveness of SSAT in the video domain for deepfake detection, showcasing its generalizability.","Our code is available at https://github.com/dominickrei/Limited-data-vits."],"url":"http://arxiv.org/abs/2310.20704v1"}
{"created":"2023-10-31 17:59:05","title":"Vanishing Gradients in Reinforcement Finetuning of Language Models","abstract":"Pretrained language models are commonly aligned with human preferences and downstream tasks via reinforcement finetuning (RFT), which entails maximizing a (possibly learned) reward function using policy gradient algorithms. This work highlights a fundamental optimization obstacle in RFT: we prove that the expected gradient for an input vanishes when its reward standard deviation under the model is small, even if the expected reward is far from optimal. Through experiments on an RFT benchmark and controlled environments, as well as a theoretical analysis, we then demonstrate that vanishing gradients due to small reward standard deviation are prevalent and detrimental, leading to extremely slow reward maximization. Lastly, we explore ways to overcome vanishing gradients in RFT. We find the common practice of an initial supervised finetuning (SFT) phase to be the most promising candidate, which sheds light on its importance in an RFT pipeline. Moreover, we show that a relatively small number of SFT optimization steps on as few as 1% of the input samples can suffice, indicating that the initial SFT phase need not be expensive in terms of compute and data labeling efforts. Overall, our results emphasize that being mindful for inputs whose expected gradient vanishes, as measured by the reward standard deviation, is crucial for successful execution of RFT.","sentences":["Pretrained language models are commonly aligned with human preferences and downstream tasks via reinforcement finetuning (RFT), which entails maximizing a (possibly learned) reward function using policy gradient algorithms.","This work highlights a fundamental optimization obstacle in RFT: we prove that the expected gradient for an input vanishes when its reward standard deviation under the model is small, even if the expected reward is far from optimal.","Through experiments on an RFT benchmark and controlled environments, as well as a theoretical analysis, we then demonstrate that vanishing gradients due to small reward standard deviation are prevalent and detrimental, leading to extremely slow reward maximization.","Lastly, we explore ways to overcome vanishing gradients in RFT.","We find the common practice of an initial supervised finetuning (SFT) phase to be the most promising candidate, which sheds light on its importance in an RFT pipeline.","Moreover, we show that a relatively small number of SFT optimization steps on as few as 1% of the input samples can suffice, indicating that the initial SFT phase need not be expensive in terms of compute and data labeling efforts.","Overall, our results emphasize that being mindful for inputs whose expected gradient vanishes, as measured by the reward standard deviation, is crucial for successful execution of RFT."],"url":"http://arxiv.org/abs/2310.20703v1"}
{"created":"2023-10-31 17:58:17","title":"SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction","abstract":"Recently video generation has achieved substantial progress with realistic results. Nevertheless, existing AI-generated videos are usually very short clips (\"shot-level\") depicting a single scene. To deliver a coherent long video (\"story-level\"), it is desirable to have creative transition and prediction effects across different clips. This paper presents a short-to-long video diffusion model, SEINE, that focuses on generative transition and prediction. The goal is to generate high-quality long videos with smooth and creative transitions between scenes and varying lengths of shot-level videos. Specifically, we propose a random-mask video diffusion model to automatically generate transitions based on textual descriptions. By providing the images of different scenes as inputs, combined with text-based control, our model generates transition videos that ensure coherence and visual quality. Furthermore, the model can be readily extended to various tasks such as image-to-video animation and autoregressive video prediction. To conduct a comprehensive evaluation of this new generative task, we propose three assessing criteria for smooth and creative transition: temporal consistency, semantic similarity, and video-text semantic alignment. Extensive experiments validate the effectiveness of our approach over existing methods for generative transition and prediction, enabling the creation of story-level long videos. Project page: https://vchitect.github.io/SEINE-project/ .","sentences":["Recently video generation has achieved substantial progress with realistic results.","Nevertheless, existing AI-generated videos are usually very short clips (\"shot-level\") depicting a single scene.","To deliver a coherent long video (\"story-level\"), it is desirable to have creative transition and prediction effects across different clips.","This paper presents a short-to-long video diffusion model, SEINE, that focuses on generative transition and prediction.","The goal is to generate high-quality long videos with smooth and creative transitions between scenes and varying lengths of shot-level videos.","Specifically, we propose a random-mask video diffusion model to automatically generate transitions based on textual descriptions.","By providing the images of different scenes as inputs, combined with text-based control, our model generates transition videos that ensure coherence and visual quality.","Furthermore, the model can be readily extended to various tasks such as image-to-video animation and autoregressive video prediction.","To conduct a comprehensive evaluation of this new generative task, we propose three assessing criteria for smooth and creative transition: temporal consistency, semantic similarity, and video-text semantic alignment.","Extensive experiments validate the effectiveness of our approach over existing methods for generative transition and prediction, enabling the creation of story-level long videos.","Project page: https://vchitect.github.io/SEINE-project/ ."],"url":"http://arxiv.org/abs/2310.20700v1"}
{"created":"2023-10-31 17:56:51","title":"Text-Transport: Toward Learning Causal Effects of Natural Language","abstract":"As language technologies gain prominence in real-world settings, it is important to understand how changes to language affect reader perceptions. This can be formalized as the causal effect of varying a linguistic attribute (e.g., sentiment) on a reader's response to the text. In this paper, we introduce Text-Transport, a method for estimation of causal effects from natural language under any text distribution. Current approaches for valid causal effect estimation require strong assumptions about the data, meaning the data from which one can estimate valid causal effects often is not representative of the actual target domain of interest. To address this issue, we leverage the notion of distribution shift to describe an estimator that transports causal effects between domains, bypassing the need for strong assumptions in the target domain. We derive statistical guarantees on the uncertainty of this estimator, and we report empirical results and analyses that support the validity of Text-Transport across data settings. Finally, we use Text-Transport to study a realistic setting--hate speech on social media--in which causal effects do shift significantly between text domains, demonstrating the necessity of transport when conducting causal inference on natural language.","sentences":["As language technologies gain prominence in real-world settings, it is important to understand how changes to language affect reader perceptions.","This can be formalized as the causal effect of varying a linguistic attribute (e.g., sentiment) on a reader's response to the text.","In this paper, we introduce Text-Transport, a method for estimation of causal effects from natural language under any text distribution.","Current approaches for valid causal effect estimation require strong assumptions about the data, meaning the data from which one can estimate valid causal effects often is not representative of the actual target domain of interest.","To address this issue, we leverage the notion of distribution shift to describe an estimator that transports causal effects between domains, bypassing the need for strong assumptions in the target domain.","We derive statistical guarantees on the uncertainty of this estimator, and we report empirical results and analyses that support the validity of Text-Transport across data settings.","Finally, we use Text-Transport to study a realistic setting--hate speech on social media--in which causal effects do shift significantly between text domains, demonstrating the necessity of transport when conducting causal inference on natural language."],"url":"http://arxiv.org/abs/2310.20697v1"}
{"created":"2023-10-31 17:56:11","title":"HAP: Structure-Aware Masked Image Modeling for Human-Centric Perception","abstract":"Model pre-training is essential in human-centric perception. In this paper, we first introduce masked image modeling (MIM) as a pre-training approach for this task. Upon revisiting the MIM training strategy, we reveal that human structure priors offer significant potential. Motivated by this insight, we further incorporate an intuitive human structure prior - human parts - into pre-training. Specifically, we employ this prior to guide the mask sampling process. Image patches, corresponding to human part regions, have high priority to be masked out. This encourages the model to concentrate more on body structure information during pre-training, yielding substantial benefits across a range of human-centric perception tasks. To further capture human characteristics, we propose a structure-invariant alignment loss that enforces different masked views, guided by the human part prior, to be closely aligned for the same image. We term the entire method as HAP. HAP simply uses a plain ViT as the encoder yet establishes new state-of-the-art performance on 11 human-centric benchmarks, and on-par result on one dataset. For example, HAP achieves 78.1% mAP on MSMT17 for person re-identification, 86.54% mA on PA-100K for pedestrian attribute recognition, 78.2% AP on MS COCO for 2D pose estimation, and 56.0 PA-MPJPE on 3DPW for 3D pose and shape estimation.","sentences":["Model pre-training is essential in human-centric perception.","In this paper, we first introduce masked image modeling (MIM) as a pre-training approach for this task.","Upon revisiting the MIM training strategy, we reveal that human structure priors offer significant potential.","Motivated by this insight, we further incorporate an intuitive human structure prior - human parts - into pre-training.","Specifically, we employ this prior to guide the mask sampling process.","Image patches, corresponding to human part regions, have high priority to be masked out.","This encourages the model to concentrate more on body structure information during pre-training, yielding substantial benefits across a range of human-centric perception tasks.","To further capture human characteristics, we propose a structure-invariant alignment loss that enforces different masked views, guided by the human part prior, to be closely aligned for the same image.","We term the entire method as HAP.","HAP simply uses a plain ViT as the encoder yet establishes new state-of-the-art performance on 11 human-centric benchmarks, and on-par result on one dataset.","For example, HAP achieves 78.1% mAP on MSMT17 for person re-identification, 86.54% mA on PA-100K for pedestrian attribute recognition, 78.2% AP on MS COCO for 2D pose estimation, and 56.0 PA-MPJPE on 3DPW for 3D pose and shape estimation."],"url":"http://arxiv.org/abs/2310.20695v1"}
{"created":"2023-10-31 17:52:22","title":"Learning From Mistakes Makes LLM Better Reasoner","abstract":"Large language models (LLMs) recently exhibited remarkable reasoning capabilities on solving math problems. To further improve this capability, this work proposes Learning from Mistakes (LeMa), akin to human learning processes. Consider a human student who failed to solve a math problem, he will learn from what mistake he has made and how to correct it. Mimicking this error-driven learning process, LeMa fine-tunes LLMs on mistake-correction data pairs generated by GPT-4. Specifically, we first collect inaccurate reasoning paths from various LLMs and then employ GPT-4 as a \"corrector\" to (1) identify the mistake step, (2) explain the reason for the mistake, and (3) correct the mistake and generate the final answer. Experimental results demonstrate the effectiveness of LeMa: across five backbone LLMs and two mathematical reasoning tasks, LeMa consistently improves the performance compared with fine-tuning on CoT data alone. Impressively, LeMa can also benefit specialized LLMs such as WizardMath and MetaMath, achieving 85.4% pass@1 accuracy on GSM8K and 27.1% on MATH. This surpasses the SOTA performance achieved by non-execution open-source models on these challenging tasks. Our code, data and models will be publicly available at https://github.com/microsoft/CodeT.","sentences":["Large language models (LLMs) recently exhibited remarkable reasoning capabilities on solving math problems.","To further improve this capability, this work proposes Learning from Mistakes (LeMa), akin to human learning processes.","Consider a human student who failed to solve a math problem, he will learn from what mistake he has made and how to correct it.","Mimicking this error-driven learning process, LeMa fine-tunes LLMs on mistake-correction data pairs generated by GPT-4.","Specifically, we first collect inaccurate reasoning paths from various LLMs and then employ GPT-4 as a \"corrector\" to (1) identify the mistake step, (2) explain the reason for the mistake, and (3) correct the mistake and generate the final answer.","Experimental results demonstrate the effectiveness of LeMa: across five backbone LLMs and two mathematical reasoning tasks, LeMa consistently improves the performance compared with fine-tuning on CoT data alone.","Impressively, LeMa can also benefit specialized LLMs such as WizardMath and MetaMath, achieving 85.4% pass@1 accuracy on GSM8K and 27.1% on MATH.","This surpasses the SOTA performance achieved by non-execution open-source models on these challenging tasks.","Our code, data and models will be publicly available at https://github.com/microsoft/CodeT."],"url":"http://arxiv.org/abs/2310.20689v1"}
{"created":"2023-10-31 17:49:48","title":"NeRF Revisited: Fixing Quadrature Instability in Volume Rendering","abstract":"Neural radiance fields (NeRF) rely on volume rendering to synthesize novel views. Volume rendering requires evaluating an integral along each ray, which is numerically approximated with a finite sum that corresponds to the exact integral along the ray under piecewise constant volume density. As a consequence, the rendered result is unstable w.r.t. the choice of samples along the ray, a phenomenon that we dub quadrature instability. We propose a mathematically principled solution by reformulating the sample-based rendering equation so that it corresponds to the exact integral under piecewise linear volume density. This simultaneously resolves multiple issues: conflicts between samples along different rays, imprecise hierarchical sampling, and non-differentiability of quantiles of ray termination distances w.r.t. model parameters. We demonstrate several benefits over the classical sample-based rendering equation, such as sharper textures, better geometric reconstruction, and stronger depth supervision. Our proposed formulation can be also be used as a drop-in replacement to the volume rendering equation of existing NeRF-based methods. Our project page can be found at pl-nerf.github.io.","sentences":["Neural radiance fields (NeRF) rely on volume rendering to synthesize novel views.","Volume rendering requires evaluating an integral along each ray, which is numerically approximated with a finite sum that corresponds to the exact integral along the ray under piecewise constant volume density.","As a consequence, the rendered result is unstable w.r.t.","the choice of samples along the ray, a phenomenon that we dub quadrature instability.","We propose a mathematically principled solution by reformulating the sample-based rendering equation so that it corresponds to the exact integral under piecewise linear volume density.","This simultaneously resolves multiple issues: conflicts between samples along different rays, imprecise hierarchical sampling, and non-differentiability of quantiles of ray termination distances w.r.t. model parameters.","We demonstrate several benefits over the classical sample-based rendering equation, such as sharper textures, better geometric reconstruction, and stronger depth supervision.","Our proposed formulation can be also be used as a drop-in replacement to the volume rendering equation of existing NeRF-based methods.","Our project page can be found at pl-nerf.github.io."],"url":"http://arxiv.org/abs/2310.20685v1"}
{"created":"2023-10-31 17:48:22","title":"Compression with Exact Error Distribution for Federated Learning","abstract":"Compression schemes have been extensively used in Federated Learning (FL) to reduce the communication cost of distributed learning. While most approaches rely on a bounded variance assumption of the noise produced by the compressor, this paper investigates the use of compression and aggregation schemes that produce a specific error distribution, e.g., Gaussian or Laplace, on the aggregated data. We present and analyze different aggregation schemes based on layered quantizers achieving exact error distribution. We provide different methods to leverage the proposed compression schemes to obtain compression-for-free in differential privacy applications. Our general compression methods can recover and improve standard FL schemes with Gaussian perturbations such as Langevin dynamics and randomized smoothing.","sentences":["Compression schemes have been extensively used in Federated Learning (FL) to reduce the communication cost of distributed learning.","While most approaches rely on a bounded variance assumption of the noise produced by the compressor, this paper investigates the use of compression and aggregation schemes that produce a specific error distribution, e.g., Gaussian or Laplace, on the aggregated data.","We present and analyze different aggregation schemes based on layered quantizers achieving exact error distribution.","We provide different methods to leverage the proposed compression schemes to obtain compression-for-free in differential privacy applications.","Our general compression methods can recover and improve standard FL schemes with Gaussian perturbations such as Langevin dynamics and randomized smoothing."],"url":"http://arxiv.org/abs/2310.20682v1"}
{"created":"2023-10-31 17:45:39","title":"Latent Field Discovery In Interacting Dynamical Systems With Neural Fields","abstract":"Systems of interacting objects often evolve under the influence of field effects that govern their dynamics, yet previous works have abstracted away from such effects, and assume that systems evolve in a vacuum. In this work, we focus on discovering these fields, and infer them from the observed dynamics alone, without directly observing them. We theorize the presence of latent force fields, and propose neural fields to learn them. Since the observed dynamics constitute the net effect of local object interactions and global field effects, recently popularized equivariant networks are inapplicable, as they fail to capture global information. To address this, we propose to disentangle local object interactions -- which are $\\mathrm{SE}(n)$ equivariant and depend on relative states -- from external global field effects -- which depend on absolute states. We model interactions with equivariant graph networks, and combine them with neural fields in a novel graph network that integrates field forces. Our experiments show that we can accurately discover the underlying fields in charged particles settings, traffic scenes, and gravitational n-body problems, and effectively use them to learn the system and forecast future trajectories.","sentences":["Systems of interacting objects often evolve under the influence of field effects that govern their dynamics, yet previous works have abstracted away from such effects, and assume that systems evolve in a vacuum.","In this work, we focus on discovering these fields, and infer them from the observed dynamics alone, without directly observing them.","We theorize the presence of latent force fields, and propose neural fields to learn them.","Since the observed dynamics constitute the net effect of local object interactions and global field effects, recently popularized equivariant networks are inapplicable, as they fail to capture global information.","To address this, we propose to disentangle local object interactions -- which are $\\mathrm{SE}(n)$ equivariant and depend on relative states -- from external global field effects -- which depend on absolute states.","We model interactions with equivariant graph networks, and combine them with neural fields in a novel graph network that integrates field forces.","Our experiments show that we can accurately discover the underlying fields in charged particles settings, traffic scenes, and gravitational n-body problems, and effectively use them to learn the system and forecast future trajectories."],"url":"http://arxiv.org/abs/2310.20679v1"}
{"created":"2023-10-31 17:37:35","title":"Balancing Act: Constraining Disparate Impact in Sparse Models","abstract":"Model pruning is a popular approach to enable the deployment of large deep learning models on edge devices with restricted computational or storage capacities. Although sparse models achieve performance comparable to that of their dense counterparts at the level of the entire dataset, they exhibit high accuracy drops for some data sub-groups. Existing methods to mitigate this disparate impact induced by pruning (i) rely on surrogate metrics that address the problem indirectly and have limited interpretability; or (ii) scale poorly with the number of protected sub-groups in terms of computational cost. We propose a constrained optimization approach that $\\textit{directly addresses the disparate impact of pruning}$: our formulation bounds the accuracy change between the dense and sparse models, for each sub-group. This choice of constraints provides an interpretable success criterion to determine if a pruned model achieves acceptable disparity levels. Experimental results demonstrate that our technique scales reliably to problems involving large models and hundreds of protected sub-groups.","sentences":["Model pruning is a popular approach to enable the deployment of large deep learning models on edge devices with restricted computational or storage capacities.","Although sparse models achieve performance comparable to that of their dense counterparts at the level of the entire dataset, they exhibit high accuracy drops for some data sub-groups.","Existing methods to mitigate this disparate impact induced by pruning (i) rely on surrogate metrics that address the problem indirectly and have limited interpretability; or (ii) scale poorly with the number of protected sub-groups in terms of computational cost.","We propose a constrained optimization approach that $\\textit{directly addresses the disparate impact of pruning}$: our formulation bounds the accuracy change between the dense and sparse models, for each sub-group.","This choice of constraints provides an interpretable success criterion to determine if a pruned model achieves acceptable disparity levels.","Experimental results demonstrate that our technique scales reliably to problems involving large models and hundreds of protected sub-groups."],"url":"http://arxiv.org/abs/2310.20673v1"}
{"created":"2023-10-31 17:32:07","title":"Modeling multi-legged robot locomotion with slipping and its experimental validation","abstract":"Multi-legged robots with six or more legs are not in common use, despite designs with superior stability, maneuverability, and a low number of actuators being available for over 20 years. This may be in part due to the difficulty in modeling multi-legged motion with slipping and producing reliable predictions of body velocity. Here we present a detailed measurement of the foot contact forces in a hexapedal robot with multiple sliding contacts, and provide an algorithm for predicting these contact forces and the body velocity. The algorithm relies on the recently published observation that even while slipping, multi-legged robots are principally kinematic, and employ a friction law ansatz that allows us to compute the shape-change to body-velocity connection and the foot contact forces. This results in the ability to simulate motion plans for a large number of potentially slipping legs. In homogeneous environments, this can run in (parallel) logarithmic time of the planning horizon","sentences":["Multi-legged robots with six or more legs are not in common use, despite designs with superior stability, maneuverability, and a low number of actuators being available for over 20 years.","This may be in part due to the difficulty in modeling multi-legged motion with slipping and producing reliable predictions of body velocity.","Here we present a detailed measurement of the foot contact forces in a hexapedal robot with multiple sliding contacts, and provide an algorithm for predicting these contact forces and the body velocity.","The algorithm relies on the recently published observation that even while slipping, multi-legged robots are principally kinematic, and employ a friction law ansatz that allows us to compute the shape-change to body-velocity connection and the foot contact forces.","This results in the ability to simulate motion plans for a large number of potentially slipping legs.","In homogeneous environments, this can run in (parallel) logarithmic time of the planning horizon"],"url":"http://arxiv.org/abs/2310.20669v1"}
{"created":"2023-10-31 17:30:57","title":"StairNet: Visual Recognition of Stairs for Human-Robot Locomotion","abstract":"Human-robot walking with prosthetic legs and exoskeletons, especially over complex terrains such as stairs, remains a significant challenge. Egocentric vision has the unique potential to detect the walking environment prior to physical interactions, which can improve transitions to and from stairs. This motivated us to create the StairNet initiative to support the development of new deep learning models for visual sensing and recognition of stairs, with an emphasis on lightweight and efficient neural networks for onboard real-time inference. In this study, we present an overview of the development of our large-scale dataset with over 515,000 manually labeled images, as well as our development of different deep learning models (e.g., 2D and 3D CNN, hybrid CNN and LSTM, and ViT networks) and training methods (e.g., supervised learning with temporal data and semi-supervised learning with unlabeled images) using our new dataset. We consistently achieved high classification accuracy (i.e., up to 98.8%) with different designs, offering trade-offs between model accuracy and size. When deployed on mobile devices with GPU and NPU accelerators, our deep learning models achieved inference speeds up to 2.8 ms. We also deployed our models on custom-designed CPU-powered smart glasses. However, limitations in the embedded hardware yielded slower inference speeds of 1.5 seconds, presenting a trade-off between human-centered design and performance. Overall, we showed that StairNet can be an effective platform to develop and study new visual perception systems for human-robot locomotion with applications in exoskeleton and prosthetic leg control.","sentences":["Human-robot walking with prosthetic legs and exoskeletons, especially over complex terrains such as stairs, remains a significant challenge.","Egocentric vision has the unique potential to detect the walking environment prior to physical interactions, which can improve transitions to and from stairs.","This motivated us to create the StairNet initiative to support the development of new deep learning models for visual sensing and recognition of stairs, with an emphasis on lightweight and efficient neural networks for onboard real-time inference.","In this study, we present an overview of the development of our large-scale dataset with over 515,000 manually labeled images, as well as our development of different deep learning models (e.g., 2D and 3D CNN, hybrid CNN and LSTM, and ViT networks) and training methods (e.g., supervised learning with temporal data and semi-supervised learning with unlabeled images) using our new dataset.","We consistently achieved high classification accuracy (i.e., up to 98.8%) with different designs, offering trade-offs between model accuracy and size.","When deployed on mobile devices with GPU and NPU accelerators, our deep learning models achieved inference speeds up to 2.8 ms.","We also deployed our models on custom-designed CPU-powered smart glasses.","However, limitations in the embedded hardware yielded slower inference speeds of 1.5 seconds, presenting a trade-off between human-centered design and performance.","Overall, we showed that StairNet can be an effective platform to develop and study new visual perception systems for human-robot locomotion with applications in exoskeleton and prosthetic leg control."],"url":"http://arxiv.org/abs/2310.20666v1"}
{"created":"2023-10-31 17:29:46","title":"Offline RL with Observation Histories: Analyzing and Improving Sample Complexity","abstract":"Offline reinforcement learning (RL) can in principle synthesize more optimal behavior from a dataset consisting only of suboptimal trials. One way that this can happen is by \"stitching\" together the best parts of otherwise suboptimal trajectories that overlap on similar states, to create new behaviors where each individual state is in-distribution, but the overall returns are higher. However, in many interesting and complex applications, such as autonomous navigation and dialogue systems, the state is partially observed. Even worse, the state representation is unknown or not easy to define. In such cases, policies and value functions are often conditioned on observation histories instead of states. In these cases, it is not clear if the same kind of \"stitching\" is feasible at the level of observation histories, since two different trajectories would always have different histories, and thus \"similar states\" that might lead to effective stitching cannot be leveraged. Theoretically, we show that standard offline RL algorithms conditioned on observation histories suffer from poor sample complexity, in accordance with the above intuition. We then identify sufficient conditions under which offline RL can still be efficient -- intuitively, it needs to learn a compact representation of history comprising only features relevant for action selection. We introduce a bisimulation loss that captures the extent to which this happens, and propose that offline RL can explicitly optimize this loss to aid worst-case sample complexity. Empirically, we show that across a variety of tasks either our proposed loss improves performance, or the value of this loss is already minimized as a consequence of standard offline RL, indicating that it correlates well with good performance.","sentences":["Offline reinforcement learning (RL) can in principle synthesize more optimal behavior from a dataset consisting only of suboptimal trials.","One way that this can happen is by \"stitching\" together the best parts of otherwise suboptimal trajectories that overlap on similar states, to create new behaviors where each individual state is in-distribution, but the overall returns are higher.","However, in many interesting and complex applications, such as autonomous navigation and dialogue systems, the state is partially observed.","Even worse, the state representation is unknown or not easy to define.","In such cases, policies and value functions are often conditioned on observation histories instead of states.","In these cases, it is not clear if the same kind of \"stitching\" is feasible at the level of observation histories, since two different trajectories would always have different histories, and thus \"similar states\" that might lead to effective stitching cannot be leveraged.","Theoretically, we show that standard offline RL algorithms conditioned on observation histories suffer from poor sample complexity, in accordance with the above intuition.","We then identify sufficient conditions under which offline RL can still be efficient -- intuitively, it needs to learn a compact representation of history comprising only features relevant for action selection.","We introduce a bisimulation loss that captures the extent to which this happens, and propose that offline RL can explicitly optimize this loss to aid worst-case sample complexity.","Empirically, we show that across a variety of tasks either our proposed loss improves performance, or the value of this loss is already minimized as a consequence of standard offline RL, indicating that it correlates well with good performance."],"url":"http://arxiv.org/abs/2310.20663v1"}
{"created":"2023-10-31 17:25:07","title":"Non-Compositionality in Sentiment: New Data and Analyses","abstract":"When natural language phrases are combined, their meaning is often more than the sum of their parts. In the context of NLP tasks such as sentiment analysis, where the meaning of a phrase is its sentiment, that still applies. Many NLP studies on sentiment analysis, however, focus on the fact that sentiment computations are largely compositional. We, instead, set out to obtain non-compositionality ratings for phrases with respect to their sentiment. Our contributions are as follows: a) a methodology for obtaining those non-compositionality ratings, b) a resource of ratings for 259 phrases -- NonCompSST -- along with an analysis of that resource, and c) an evaluation of computational models for sentiment analysis using this new resource.","sentences":["When natural language phrases are combined, their meaning is often more than the sum of their parts.","In the context of NLP tasks such as sentiment analysis, where the meaning of a phrase is its sentiment, that still applies.","Many NLP studies on sentiment analysis, however, focus on the fact that sentiment computations are largely compositional.","We, instead, set out to obtain non-compositionality ratings for phrases with respect to their sentiment.","Our contributions are as follows: a) a methodology for obtaining those non-compositionality ratings, b) a resource of ratings for 259 phrases -- NonCompSST -- along with an analysis of that resource, and c) an evaluation of computational models for sentiment analysis using this new resource."],"url":"http://arxiv.org/abs/2310.20656v1"}
{"created":"2023-10-31 17:24:40","title":"\"Pick-and-Pass\" as a Hat-Trick Class for First-Principle Memory, Generalizability, and Interpretability Benchmarks","abstract":"Closed drafting or \"pick and pass\" is a popular game mechanic where each round players select a card or other playable element from their hand and pass the rest to the next player. Games employing closed drafting make for great studies on memory and turn order due to their explicitly calculable memory of other players' hands. In this paper, we establish first-principle benchmarks for studying model-free reinforcement learning algorithms and their comparative ability to learn memory in a popular family of closed drafting games called \"Sushi Go Party!\", producing state-of-the-art results on this environment along the way. Furthermore, as Sushi Go Party! can be expressed as a set of closely-related games based on the set of cards in play, we quantify the generalizability of reinforcement learning algorithms trained on various sets of cards, establishing key trends between generalized performance and the set distance between the train and evaluation game configurations. Finally, we fit decision rules to interpret the strategy of the learned models and compare them to the ranking preferences of human players, finding intuitive common rules and intriguing new moves.","sentences":["Closed drafting or \"pick and pass\" is a popular game mechanic where each round players select a card or other playable element from their hand and pass the rest to the next player.","Games employing closed drafting make for great studies on memory and turn order due to their explicitly calculable memory of other players' hands.","In this paper, we establish first-principle benchmarks for studying model-free reinforcement learning algorithms and their comparative ability to learn memory in a popular family of closed drafting games called \"Sushi Go Party!\", producing state-of-the-art results on this environment along the way.","Furthermore, as Sushi Go Party! can be expressed as a set of closely-related games based on the set of cards in play, we quantify the generalizability of reinforcement learning algorithms trained on various sets of cards, establishing key trends between generalized performance and the set distance between the train and evaluation game configurations.","Finally, we fit decision rules to interpret the strategy of the learned models and compare them to the ranking preferences of human players, finding intuitive common rules and intriguing new moves."],"url":"http://arxiv.org/abs/2310.20654v1"}
{"created":"2023-10-31 17:21:26","title":"Addressing Limitations of State-Aware Imitation Learning for Autonomous Driving","abstract":"Conditional Imitation learning is a common and effective approach to train autonomous driving agents. However, two issues limit the full potential of this approach: (i) the inertia problem, a special case of causal confusion where the agent mistakenly correlates low speed with no acceleration, and (ii) low correlation between offline and online performance due to the accumulation of small errors that brings the agent in a previously unseen state. Both issues are critical for state-aware models, yet informing the driving agent of its internal state as well as the state of the environment is of crucial importance. In this paper we propose a multi-task learning agent based on a multi-stage vision transformer with state token propagation. We feed the state of the vehicle along with the representation of the environment as a special token of the transformer and propagate it throughout the network. This allows us to tackle the aforementioned issues from different angles: guiding the driving policy with learned stop/go information, performing data augmentation directly on the state of the vehicle and visually explaining the model's decisions. We report a drastic decrease in inertia and a high correlation between offline and online metrics.","sentences":["Conditional Imitation learning is a common and effective approach to train autonomous driving agents.","However, two issues limit the full potential of this approach: (i) the inertia problem, a special case of causal confusion where the agent mistakenly correlates low speed with no acceleration, and (ii) low correlation between offline and online performance due to the accumulation of small errors that brings the agent in a previously unseen state.","Both issues are critical for state-aware models, yet informing the driving agent of its internal state as well as the state of the environment is of crucial importance.","In this paper we propose a multi-task learning agent based on a multi-stage vision transformer with state token propagation.","We feed the state of the vehicle along with the representation of the environment as a special token of the transformer and propagate it throughout the network.","This allows us to tackle the aforementioned issues from different angles: guiding the driving policy with learned stop/go information, performing data augmentation directly on the state of the vehicle and visually explaining the model's decisions.","We report a drastic decrease in inertia and a high correlation between offline and online metrics."],"url":"http://arxiv.org/abs/2310.20650v1"}
{"created":"2023-10-31 17:20:30","title":"Dynamic Batch Norm Statistics Update for Natural Robustness","abstract":"DNNs trained on natural clean samples have been shown to perform poorly on corrupted samples, such as noisy or blurry images. Various data augmentation methods have been recently proposed to improve DNN's robustness against common corruptions. Despite their success, they require computationally expensive training and cannot be applied to off-the-shelf trained models. Recently, it has been shown that updating BatchNorm (BN) statistics of an off-the-shelf model on a single corruption improves its accuracy on that corruption significantly. However, adopting the idea at inference time when the type of corruption is unknown and changing decreases the effectiveness of this method. In this paper, we harness the Fourier domain to detect the corruption type, a challenging task in the image domain. We propose a unified framework consisting of a corruption-detection model and BN statistics update that improves the corruption accuracy of any off-the-shelf trained model. We benchmark our framework on different models and datasets. Our results demonstrate about 8% and 4% accuracy improvement on CIFAR10-C and ImageNet-C, respectively. Furthermore, our framework can further improve the accuracy of state-of-the-art robust models, such as AugMix and DeepAug.","sentences":["DNNs trained on natural clean samples have been shown to perform poorly on corrupted samples, such as noisy or blurry images.","Various data augmentation methods have been recently proposed to improve DNN's robustness against common corruptions.","Despite their success, they require computationally expensive training and cannot be applied to off-the-shelf trained models.","Recently, it has been shown that updating BatchNorm (BN) statistics of an off-the-shelf model on a single corruption improves its accuracy on that corruption significantly.","However, adopting the idea at inference time when the type of corruption is unknown and changing decreases the effectiveness of this method.","In this paper, we harness the Fourier domain to detect the corruption type, a challenging task in the image domain.","We propose a unified framework consisting of a corruption-detection model and BN statistics update that improves the corruption accuracy of any off-the-shelf trained model.","We benchmark our framework on different models and datasets.","Our results demonstrate about 8% and 4% accuracy improvement on CIFAR10-C and ImageNet-C, respectively.","Furthermore, our framework can further improve the accuracy of state-of-the-art robust models, such as AugMix and DeepAug."],"url":"http://arxiv.org/abs/2310.20649v1"}
{"created":"2023-10-31 17:11:29","title":"Performance Improvement in Multi-class Classification via Automated Hierarchy Generation and Exploitation through Extended LCPN Schemes","abstract":"Hierarchical classification (HC) plays a pivotal role in multi-class classification tasks, where objects are organized into a hierarchical structure. This study explores the performance of HC through a comprehensive analysis that encompasses both hierarchy generation and hierarchy exploitation. This analysis is particularly relevant in scenarios where a predefined hierarchy structure is not readily accessible. Notably, two novel hierarchy exploitation schemes, LCPN+ and LCPN+F, which extend the capabilities of LCPN and combine the strengths of global and local classification, have been introduced and evaluated alongside existing methods. The findings reveal the consistent superiority of LCPN+F, which outperforms other schemes across various datasets and scenarios. Moreover, this research emphasizes not only effectiveness but also efficiency, as LCPN+ and LCPN+F maintain runtime performance comparable to Flat Classification (FC). Additionally, this study underscores the importance of selecting the right hierarchy exploitation scheme to maximize classification performance. This work extends our understanding of HC and establishes a benchmark for future research, fostering advancements in multi-class classification methodologies.","sentences":["Hierarchical classification (HC) plays a pivotal role in multi-class classification tasks, where objects are organized into a hierarchical structure.","This study explores the performance of HC through a comprehensive analysis that encompasses both hierarchy generation and hierarchy exploitation.","This analysis is particularly relevant in scenarios where a predefined hierarchy structure is not readily accessible.","Notably, two novel hierarchy exploitation schemes, LCPN+ and LCPN+F, which extend the capabilities of LCPN and combine the strengths of global and local classification, have been introduced and evaluated alongside existing methods.","The findings reveal the consistent superiority of LCPN+F, which outperforms other schemes across various datasets and scenarios.","Moreover, this research emphasizes not only effectiveness but also efficiency, as LCPN+ and LCPN+F maintain runtime performance comparable to Flat Classification (FC).","Additionally, this study underscores the importance of selecting the right hierarchy exploitation scheme to maximize classification performance.","This work extends our understanding of HC and establishes a benchmark for future research, fostering advancements in multi-class classification methodologies."],"url":"http://arxiv.org/abs/2310.20641v1"}
{"created":"2023-10-31 17:06:36","title":"Histopathological Image Analysis with Style-Augmented Feature Domain Mixing for Improved Generalization","abstract":"Histopathological images are essential for medical diagnosis and treatment planning, but interpreting them accurately using machine learning can be challenging due to variations in tissue preparation, staining and imaging protocols. Domain generalization aims to address such limitations by enabling the learning models to generalize to new datasets or populations. Style transfer-based data augmentation is an emerging technique that can be used to improve the generalizability of machine learning models for histopathological images. However, existing style transfer-based methods can be computationally expensive, and they rely on artistic styles, which can negatively impact model accuracy. In this study, we propose a feature domain style mixing technique that uses adaptive instance normalization to generate style-augmented versions of images. We compare our proposed method with existing style transfer-based data augmentation methods and found that it performs similarly or better, despite requiring less computation and time. Our results demonstrate the potential of feature domain statistics mixing in the generalization of learning models for histopathological image analysis.","sentences":["Histopathological images are essential for medical diagnosis and treatment planning, but interpreting them accurately using machine learning can be challenging due to variations in tissue preparation, staining and imaging protocols.","Domain generalization aims to address such limitations by enabling the learning models to generalize to new datasets or populations.","Style transfer-based data augmentation is an emerging technique that can be used to improve the generalizability of machine learning models for histopathological images.","However, existing style transfer-based methods can be computationally expensive, and they rely on artistic styles, which can negatively impact model accuracy.","In this study, we propose a feature domain style mixing technique that uses adaptive instance normalization to generate style-augmented versions of images.","We compare our proposed method with existing style transfer-based data augmentation methods and found that it performs similarly or better, despite requiring less computation and time.","Our results demonstrate the potential of feature domain statistics mixing in the generalization of learning models for histopathological image analysis."],"url":"http://arxiv.org/abs/2310.20638v1"}
{"created":"2023-10-31 17:05:02","title":"Using Higher-Order Moments to Assess the Quality of GAN-generated Image Features","abstract":"The rapid advancement of Generative Adversarial Networks (GANs) necessitates the need to robustly evaluate these models. Among the established evaluation criteria, the Fr\\'{e}chet Inception Distance (FID) has been widely adopted due to its conceptual simplicity, fast computation time, and strong correlation with human perception. However, FID has inherent limitations, mainly stemming from its assumption that feature embeddings follow a Gaussian distribution, and therefore can be defined by their first two moments. As this does not hold in practice, in this paper we explore the importance of third-moments in image feature data and use this information to define a new measure, which we call the Skew Inception Distance (SID). We prove that SID is a pseudometric on probability distributions, show how it extends FID, and present a practical method for its computation. Our numerical experiments support that SID either tracks with FID or, in some cases, aligns more closely with human perception when evaluating image features of ImageNet data.","sentences":["The rapid advancement of Generative Adversarial Networks (GANs) necessitates the need to robustly evaluate these models.","Among the established evaluation criteria, the Fr\\'{e}chet Inception Distance (FID) has been widely adopted due to its conceptual simplicity, fast computation time, and strong correlation with human perception.","However, FID has inherent limitations, mainly stemming from its assumption that feature embeddings follow a Gaussian distribution, and therefore can be defined by their first two moments.","As this does not hold in practice, in this paper we explore the importance of third-moments in image feature data and use this information to define a new measure, which we call the Skew Inception Distance (SID).","We prove that SID is a pseudometric on probability distributions, show how it extends FID, and present a practical method for its computation.","Our numerical experiments support that SID either tracks with FID or, in some cases, aligns more closely with human perception when evaluating image features of ImageNet data."],"url":"http://arxiv.org/abs/2310.20636v1"}
{"created":"2023-10-31 17:02:33","title":"Defining a New NLP Playground","abstract":"The recent explosion of performance of large language models (LLMs) has changed the field of Natural Language Processing (NLP) more abruptly and seismically than any other shift in the field's 80-year history. This has resulted in concerns that the field will become homogenized and resource-intensive. The new status quo has put many academic researchers, especially PhD students, at a disadvantage. This paper aims to define a new NLP playground by proposing 20+ PhD-dissertation-worthy research directions, covering theoretical analysis, new and challenging problems, learning paradigms, and interdisciplinary applications.","sentences":["The recent explosion of performance of large language models (LLMs) has changed the field of Natural Language Processing (NLP) more abruptly and seismically than any other shift in the field's 80-year history.","This has resulted in concerns that the field will become homogenized and resource-intensive.","The new status quo has put many academic researchers, especially PhD students, at a disadvantage.","This paper aims to define a new NLP playground by proposing 20+ PhD-dissertation-worthy research directions, covering theoretical analysis, new and challenging problems, learning paradigms, and interdisciplinary applications."],"url":"http://arxiv.org/abs/2310.20633v1"}
{"created":"2023-10-31 17:01:32","title":"Constrained Planarity in Practice -- Engineering the Synchronized Planarity Algorithm","abstract":"In the constrained planarity setting, we ask whether a graph admits a planar drawing that additionally satisfies a given set of constraints. These constraints are often derived from very natural problems; prominent examples are Level Planarity, where vertices have to lie on given horizontal lines indicating a hierarchy, and Clustered Planarity, where we additionally draw the boundaries of clusters which recursively group the vertices in a crossing-free manner. Despite receiving significant amount of attention and substantial theoretical progress on these problems, only very few of the found solutions have been put into practice and evaluated experimentally.   In this paper, we describe our implementation of the recent quadratic-time algorithm by Bl\\\"asius et al. [TALG Vol 19, No 4] for solving the problem Synchronized Planarity, which can be seen as a common generalization of several constrained planarity problems, including the aforementioned ones. Our experimental evaluation on an existing benchmark set shows that even our baseline implementation outperforms all competitors by at least an order of magnitude. We systematically investigate the degrees of freedom in the implementation of the Synchronized Planarity algorithm for larger instances and propose several modifications that further improve the performance. Altogether, this allows us to solve instances with up to 100 vertices in milliseconds and instances with up to 100 000 vertices within a few minutes.","sentences":["In the constrained planarity setting, we ask whether a graph admits a planar drawing that additionally satisfies a given set of constraints.","These constraints are often derived from very natural problems; prominent examples are Level Planarity, where vertices have to lie on given horizontal lines indicating a hierarchy, and Clustered Planarity, where we additionally draw the boundaries of clusters which recursively group the vertices in a crossing-free manner.","Despite receiving significant amount of attention and substantial theoretical progress on these problems, only very few of the found solutions have been put into practice and evaluated experimentally.   ","In this paper, we describe our implementation of the recent quadratic-time algorithm by Bl\\\"asius et al.","[TALG Vol 19, No 4] for solving the problem Synchronized Planarity, which can be seen as a common generalization of several constrained planarity problems, including the aforementioned ones.","Our experimental evaluation on an existing benchmark set shows that even our baseline implementation outperforms all competitors by at least an order of magnitude.","We systematically investigate the degrees of freedom in the implementation of the Synchronized Planarity algorithm for larger instances and propose several modifications that further improve the performance.","Altogether, this allows us to solve instances with up to 100 vertices in milliseconds and instances with up to 100 000 vertices within a few minutes."],"url":"http://arxiv.org/abs/2310.20632v1"}
{"created":"2023-10-31 16:55:06","title":"LoRA Fine-tuning Efficiently Undoes Safety Training in Llama 2-Chat 70B","abstract":"AI developers often apply safety alignment procedures to prevent the misuse of their AI systems. For example, before Meta released Llama 2-Chat, a collection of instruction fine-tuned large language models, they invested heavily in safety training, incorporating extensive red-teaming and reinforcement learning from human feedback. However, it remains unclear how well safety training guards against model misuse when attackers have access to model weights. We explore the robustness of safety training in language models by subversively fine-tuning the public weights of Llama 2-Chat. We employ low-rank adaptation (LoRA) as an efficient fine-tuning method. With a budget of less than $200 per model and using only one GPU, we successfully undo the safety training of Llama 2-Chat models of sizes 7B, 13B, and 70B. Specifically, our fine-tuning technique significantly reduces the rate at which the model refuses to follow harmful instructions. We achieve a refusal rate below 1% for our 70B Llama 2-Chat model on two refusal benchmarks. Our fine-tuning method retains general performance, which we validate by comparing our fine-tuned models against Llama 2-Chat across two benchmarks. Additionally, we present a selection of harmful outputs produced by our models. While there is considerable uncertainty about the scope of risks from current models, it is likely that future models will have significantly more dangerous capabilities, including the ability to hack into critical infrastructure, create dangerous bio-weapons, or autonomously replicate and adapt to new environments. We show that subversive fine-tuning is practical and effective, and hence argue that evaluating risks from fine-tuning should be a core part of risk assessments for releasing model weights.","sentences":["AI developers often apply safety alignment procedures to prevent the misuse of their AI systems.","For example, before Meta released Llama 2-Chat, a collection of instruction fine-tuned large language models, they invested heavily in safety training, incorporating extensive red-teaming and reinforcement learning from human feedback.","However, it remains unclear how well safety training guards against model misuse when attackers have access to model weights.","We explore the robustness of safety training in language models by subversively fine-tuning the public weights of Llama 2-Chat.","We employ low-rank adaptation (LoRA) as an efficient fine-tuning method.","With a budget of less than $200 per model and using only one GPU, we successfully undo the safety training of Llama 2-Chat models of sizes 7B, 13B, and 70B. Specifically, our fine-tuning technique significantly reduces the rate at which the model refuses to follow harmful instructions.","We achieve a refusal rate below 1% for our 70B Llama 2-Chat model on two refusal benchmarks.","Our fine-tuning method retains general performance, which we validate by comparing our fine-tuned models against Llama 2-Chat across two benchmarks.","Additionally, we present a selection of harmful outputs produced by our models.","While there is considerable uncertainty about the scope of risks from current models, it is likely that future models will have significantly more dangerous capabilities, including the ability to hack into critical infrastructure, create dangerous bio-weapons, or autonomously replicate and adapt to new environments.","We show that subversive fine-tuning is practical and effective, and hence argue that evaluating risks from fine-tuning should be a core part of risk assessments for releasing model weights."],"url":"http://arxiv.org/abs/2310.20624v1"}
{"created":"2023-10-31 16:54:54","title":"Fully dynamic approximation schemes on planar and apex-minor-free graphs","abstract":"The classic technique of Baker [J. ACM '94] is the most fundamental approach for designing approximation schemes on planar, or more generally topologically-constrained graphs, and it has been applied in a myriad of different variants and settings throughout the last 30 years. In this work we propose a dynamic variant of Baker's technique, where instead of finding an approximate solution in a given static graph, the task is to design a data structure for maintaining an approximate solution in a fully dynamic graph, that is, a graph that is changing over time by edge deletions and edge insertions. Specifically, we address the two most basic problems -- Maximum Weight Independent Set and Minimum Weight Dominating Set -- and we prove the following: for a fully dynamic $n$-vertex planar graph $G$, one can:   * maintain a $(1-\\varepsilon)$-approximation of the maximum weight of an independent set in $G$ with amortized update time $f(\\varepsilon)\\cdot n^{o(1)}$; and,   * under the additional assumption that the maximum degree of the graph is bounded at all times by a constant, also maintain a $(1+\\varepsilon)$-approximation of the minimum weight of a dominating set in $G$ with amortized update time $f(\\varepsilon)\\cdot n^{o(1)}$.   In both cases, $f(\\varepsilon)$ is doubly-exponential in $\\mathrm{poly}(1/\\varepsilon)$ and the data structure can be initialized in time $f(\\varepsilon)\\cdot n^{1+o(1)}$. All our results in fact hold in the larger generality of any graph class that excludes a fixed apex-graph as a minor.","sentences":["The classic technique of Baker [J. ACM '94] is the most fundamental approach for designing approximation schemes on planar, or more generally topologically-constrained graphs, and it has been applied in a myriad of different variants and settings throughout the last 30 years.","In this work we propose a dynamic variant of Baker's technique, where instead of finding an approximate solution in a given static graph, the task is to design a data structure for maintaining an approximate solution in a fully dynamic graph, that is, a graph that is changing over time by edge deletions and edge insertions.","Specifically, we address the two most basic problems -- Maximum Weight Independent Set and Minimum Weight Dominating Set -- and we prove the following: for a fully dynamic $n$-vertex planar graph $G$, one can:   * maintain a $(1-\\varepsilon)$-approximation of the maximum weight of an independent set in $G$ with amortized update time $f(\\varepsilon)\\cdot n^{o(1)}$; and,   ","*","under the additional assumption that the maximum degree of the graph is bounded at all times by a constant, also maintain a $(1+\\varepsilon)$-approximation of the minimum weight of a dominating set in $G$ with amortized update time $f(\\varepsilon)\\cdot n^{o(1)}$.   In both cases, $f(\\varepsilon)$ is doubly-exponential in $\\mathrm{poly}(1/\\varepsilon)$ and the data structure can be initialized in time $f(\\varepsilon)\\cdot n^{1+o(1)}$.","All our results in fact hold in the larger generality of any graph class that excludes a fixed apex-graph as a minor."],"url":"http://arxiv.org/abs/2310.20623v1"}
{"created":"2023-10-31 16:54:14","title":"Deepfake detection by exploiting surface anomalies: the SurFake approach","abstract":"The ever-increasing use of synthetically generated content in different sectors of our everyday life, one for all media information, poses a strong need for deepfake detection tools in order to avoid the proliferation of altered messages. The process to identify manipulated content, in particular images and videos, is basically performed by looking for the presence of some inconsistencies and/or anomalies specifically due to the fake generation process. Different techniques exist in the scientific literature that exploit diverse ad-hoc features in order to highlight possible modifications. In this paper, we propose to investigate how deepfake creation can impact on the characteristics that the whole scene had at the time of the acquisition. In particular, when an image (video) is captured the overall geometry of the scene (e.g. surfaces) and the acquisition process (e.g. illumination) determine a univocal environment that is directly represented by the image pixel values; all these intrinsic relations are possibly changed by the deepfake generation process. By resorting to the analysis of the characteristics of the surfaces depicted in the image it is possible to obtain a descriptor usable to train a CNN for deepfake detection: we refer to such an approach as SurFake. Experimental results carried out on the FF++ dataset for different kinds of deepfake forgeries and diverse deep learning models confirm that such a feature can be adopted to discriminate between pristine and altered images; furthermore, experiments witness that it can also be combined with visual data to provide a certain improvement in terms of detection accuracy.","sentences":["The ever-increasing use of synthetically generated content in different sectors of our everyday life, one for all media information, poses a strong need for deepfake detection tools in order to avoid the proliferation of altered messages.","The process to identify manipulated content, in particular images and videos, is basically performed by looking for the presence of some inconsistencies and/or anomalies specifically due to the fake generation process.","Different techniques exist in the scientific literature that exploit diverse ad-hoc features in order to highlight possible modifications.","In this paper, we propose to investigate how deepfake creation can impact on the characteristics that the whole scene had at the time of the acquisition.","In particular, when an image (video) is captured the overall geometry of the scene (e.g. surfaces) and the acquisition process (e.g. illumination) determine a univocal environment that is directly represented by the image pixel values; all these intrinsic relations are possibly changed by the deepfake generation process.","By resorting to the analysis of the characteristics of the surfaces depicted in the image it is possible to obtain a descriptor usable to train a CNN for deepfake detection: we refer to such an approach as SurFake.","Experimental results carried out on the FF++ dataset for different kinds of deepfake forgeries and diverse deep learning models confirm that such a feature can be adopted to discriminate between pristine and altered images; furthermore, experiments witness that it can also be combined with visual data to provide a certain improvement in terms of detection accuracy."],"url":"http://arxiv.org/abs/2310.20621v1"}
{"created":"2023-10-31 16:53:10","title":"The Unreasonable Effectiveness of Random Target Embeddings for Continuous-Output Neural Machine Translation","abstract":"Continuous-output neural machine translation (CoNMT) replaces the discrete next-word prediction problem with an embedding prediction. The semantic structure of the target embedding space (i.e., closeness of related words) is intuitively believed to be crucial. We challenge this assumption and show that completely random output embeddings can outperform laboriously pretrained ones, especially on larger datasets. Further investigation shows this surprising effect is strongest for rare words, due to the geometry of their embeddings. We shed further light on this finding by designing a mixed strategy that combines random and pre-trained embeddings for different tokens.","sentences":["Continuous-output neural machine translation (CoNMT) replaces the discrete next-word prediction problem with an embedding prediction.","The semantic structure of the target embedding space (i.e., closeness of related words) is intuitively believed to be crucial.","We challenge this assumption and show that completely random output embeddings can outperform laboriously pretrained ones, especially on larger datasets.","Further investigation shows this surprising effect is strongest for rare words, due to the geometry of their embeddings.","We shed further light on this finding by designing a mixed strategy that combines random and pre-trained embeddings for different tokens."],"url":"http://arxiv.org/abs/2310.20620v1"}
{"created":"2023-10-31 16:51:40","title":"Diffusion Reconstruction of Ultrasound Images with Informative Uncertainty","abstract":"Despite its wide use in medicine, ultrasound imaging faces several challenges related to its poor signal-to-noise ratio and several sources of noise and artefacts. Enhancing ultrasound image quality involves balancing concurrent factors like contrast, resolution, and speckle preservation. In recent years, there has been progress both in model-based and learning-based approaches to improve ultrasound image reconstruction. Bringing the best from both worlds, we propose a hybrid approach leveraging advances in diffusion models. To this end, we adapt Denoising Diffusion Restoration Models (DDRM) to incorporate ultrasound physics through a linear direct model and an unsupervised fine-tuning of the prior diffusion model. We conduct comprehensive experiments on simulated, in-vitro, and in-vivo data, demonstrating the efficacy of our approach in achieving high-quality image reconstructions from a single plane wave input and in comparison to state-of-the-art methods. Finally, given the stochastic nature of the method, we analyse in depth the statistical properties of single and multiple-sample reconstructions, experimentally show the informativeness of their variance, and provide an empirical model relating this behaviour to speckle noise. The code and data are available at: (upon acceptance).","sentences":["Despite its wide use in medicine, ultrasound imaging faces several challenges related to its poor signal-to-noise ratio and several sources of noise and artefacts.","Enhancing ultrasound image quality involves balancing concurrent factors like contrast, resolution, and speckle preservation.","In recent years, there has been progress both in model-based and learning-based approaches to improve ultrasound image reconstruction.","Bringing the best from both worlds, we propose a hybrid approach leveraging advances in diffusion models.","To this end, we adapt Denoising Diffusion Restoration Models (DDRM) to incorporate ultrasound physics through a linear direct model and an unsupervised fine-tuning of the prior diffusion model.","We conduct comprehensive experiments on simulated, in-vitro, and in-vivo data, demonstrating the efficacy of our approach in achieving high-quality image reconstructions from a single plane wave input and in comparison to state-of-the-art methods.","Finally, given the stochastic nature of the method, we analyse in depth the statistical properties of single and multiple-sample reconstructions, experimentally show the informativeness of their variance, and provide an empirical model relating this behaviour to speckle noise.","The code and data are available at: (upon acceptance)."],"url":"http://arxiv.org/abs/2310.20618v1"}
{"created":"2023-10-31 16:50:05","title":"Near-Optimal Min-Sum Motion Planning for Two Square Robots in a Polygonal Environment","abstract":"Let $\\mathcal{W} \\subset \\mathbb{R}^2$ be a planar polygonal environment (i.e., a polygon potentially with holes) with a total of $n$ vertices, and let $A,B$ be two robots, each modeled as an axis-aligned unit square, that can translate inside $\\mathcal{W}$. Given source and target placements $s_A,t_A,s_B,t_B \\in \\mathcal{W}$ of $A$ and $B$, respectively, the goal is to compute a \\emph{collision-free motion plan} $\\mathbf{\\pi}^*$, i.e., a motion plan that continuously moves $A$ from $s_A$ to $t_A$ and $B$ from $s_B$ to $t_B$ so that $A$ and $B$ remain inside $\\mathcal{W}$ and do not collide with each other during the motion. Furthermore, if such a plan exists, then we wish to return a plan that minimizes the sum of the lengths of the paths traversed by the robots, $\\left|\\mathbf{\\pi}^*\\right|$. Given $\\mathcal{W}, s_A,t_A,s_B,t_B$ and a parameter $\\varepsilon > 0$, we present an $n^2\\varepsilon^{-O(1)} \\log n$-time $(1+\\varepsilon)$-approximation algorithm for this problem. We are not aware of any polynomial time algorithm for this problem, nor do we know whether the problem is NP-Hard. Our result is the first polynomial-time $(1+\\varepsilon)$-approximation algorithm for an optimal motion planning problem involving two robots moving in a polygonal environment.","sentences":["Let $\\mathcal{W} \\subset \\mathbb{R}^2$ be a planar polygonal environment (i.e., a polygon potentially with holes) with a total of $n$ vertices, and let $A,B$ be two robots, each modeled as an axis-aligned unit square, that can translate inside $\\mathcal{W}$. Given source and target placements $s_A,t_A,s_B,","t_B \\in \\mathcal{W}$ of $A$ and $B$, respectively, the goal is to compute a \\emph{collision-free motion plan} $\\mathbf{\\pi}^*$, i.e., a motion plan that continuously moves $A$ from $s_A$ to $t_A$ and $B$ from $s_B$ to $t_B$ so that $A$ and $B$ remain inside $\\mathcal{W}$ and do not collide with each other during the motion.","Furthermore, if such a plan exists, then we wish to return a plan that minimizes the sum of the lengths of the paths traversed by the robots, $\\left|\\mathbf{\\pi}^*\\right|$. Given $\\mathcal{W}, s_A,t_A,s_B,t_B$ and a parameter $\\varepsilon > 0$, we present an $n^2\\varepsilon^{-O(1)} \\log n$-time $(1+\\varepsilon)$-approximation algorithm for this problem.","We are not aware of any polynomial time algorithm for this problem, nor do we know whether the problem is NP-Hard.","Our result is the first polynomial-time $(1+\\varepsilon)$-approximation algorithm for an optimal motion planning problem involving two robots moving in a polygonal environment."],"url":"http://arxiv.org/abs/2310.20615v1"}
{"created":"2023-10-31 16:43:56","title":"Autonomous Robotic Reinforcement Learning with Asynchronous Human Feedback","abstract":"Ideally, we would place a robot in a real-world environment and leave it there improving on its own by gathering more experience autonomously. However, algorithms for autonomous robotic learning have been challenging to realize in the real world. While this has often been attributed to the challenge of sample complexity, even sample-efficient techniques are hampered by two major challenges - the difficulty of providing well \"shaped\" rewards, and the difficulty of continual reset-free training. In this work, we describe a system for real-world reinforcement learning that enables agents to show continual improvement by training directly in the real world without requiring painstaking effort to hand-design reward functions or reset mechanisms. Our system leverages occasional non-expert human-in-the-loop feedback from remote users to learn informative distance functions to guide exploration while leveraging a simple self-supervised learning algorithm for goal-directed policy learning. We show that in the absence of resets, it is particularly important to account for the current \"reachability\" of the exploration policy when deciding which regions of the space to explore. Based on this insight, we instantiate a practical learning system - GEAR, which enables robots to simply be placed in real-world environments and left to train autonomously without interruption. The system streams robot experience to a web interface only requiring occasional asynchronous feedback from remote, crowdsourced, non-expert humans in the form of binary comparative feedback. We evaluate this system on a suite of robotic tasks in simulation and demonstrate its effectiveness at learning behaviors both in simulation and the real world. Project website https://guided-exploration-autonomous-rl.github.io/GEAR/.","sentences":["Ideally, we would place a robot in a real-world environment and leave it there improving on its own by gathering more experience autonomously.","However, algorithms for autonomous robotic learning have been challenging to realize in the real world.","While this has often been attributed to the challenge of sample complexity, even sample-efficient techniques are hampered by two major challenges - the difficulty of providing well \"shaped\" rewards, and the difficulty of continual reset-free training.","In this work, we describe a system for real-world reinforcement learning that enables agents to show continual improvement by training directly in the real world without requiring painstaking effort to hand-design reward functions or reset mechanisms.","Our system leverages occasional non-expert human-in-the-loop feedback from remote users to learn informative distance functions to guide exploration while leveraging a simple self-supervised learning algorithm for goal-directed policy learning.","We show that in the absence of resets, it is particularly important to account for the current \"reachability\" of the exploration policy when deciding which regions of the space to explore.","Based on this insight, we instantiate a practical learning system - GEAR, which enables robots to simply be placed in real-world environments and left to train autonomously without interruption.","The system streams robot experience to a web interface only requiring occasional asynchronous feedback from remote, crowdsourced, non-expert humans in the form of binary comparative feedback.","We evaluate this system on a suite of robotic tasks in simulation and demonstrate its effectiveness at learning behaviors both in simulation and the real world.","Project website https://guided-exploration-autonomous-rl.github.io/GEAR/."],"url":"http://arxiv.org/abs/2310.20608v1"}
{"created":"2023-10-31 16:43:03","title":"What a Whole Slide Image Can Tell? Subtype-guided Masked Transformer for Pathological Image Captioning","abstract":"Pathological captioning of Whole Slide Images (WSIs), though is essential in computer-aided pathological diagnosis, has rarely been studied due to the limitations in datasets and model training efficacy. In this paper, we propose a new paradigm Subtype-guided Masked Transformer (SGMT) for pathological captioning based on Transformers, which treats a WSI as a sequence of sparse patches and generates an overall caption sentence from the sequence. An accompanying subtype prediction is introduced into SGMT to guide the training process and enhance the captioning accuracy. We also present an Asymmetric Masked Mechansim approach to tackle the large size constraint of pathological image captioning, where the numbers of sequencing patches in SGMT are sampled differently in the training and inferring phases, respectively. Experiments on the PatchGastricADC22 dataset demonstrate that our approach effectively adapts to the task with a transformer-based model and achieves superior performance than traditional RNN-based methods. Our codes are to be made available for further research and development.","sentences":["Pathological captioning of Whole Slide Images (WSIs), though is essential in computer-aided pathological diagnosis, has rarely been studied due to the limitations in datasets and model training efficacy.","In this paper, we propose a new paradigm Subtype-guided Masked Transformer (SGMT) for pathological captioning based on Transformers, which treats a WSI as a sequence of sparse patches and generates an overall caption sentence from the sequence.","An accompanying subtype prediction is introduced into SGMT to guide the training process and enhance the captioning accuracy.","We also present an Asymmetric Masked Mechansim approach to tackle the large size constraint of pathological image captioning, where the numbers of sequencing patches in SGMT are sampled differently in the training and inferring phases, respectively.","Experiments on the PatchGastricADC22 dataset demonstrate that our approach effectively adapts to the task with a transformer-based model and achieves superior performance than traditional RNN-based methods.","Our codes are to be made available for further research and development."],"url":"http://arxiv.org/abs/2310.20607v1"}
{"created":"2023-10-31 16:42:10","title":"One-Way Communication Complexity of Partial XOR Functions","abstract":"Boolean function $F(x,y)$ for $x,y \\in \\{0,1\\}^n$ is an XOR function if $F(x,y)=f(x\\oplus y)$ for some function $f$ on $n$ input bits, where $\\oplus$ is a bit-wise XOR. XOR functions are relevant in communication complexity, partially for allowing Fourier analytic technique. For total XOR functions it is known that deterministic communication complexity of $F$ is closely related to parity decision tree complexity of $f$. Montanaro and Osbourne (2009) observed that one-sided communication complexity $D_{cc}^{\\rightarrow}(F)$ of $F$ is exactly equal to nonadaptive parity decision tree complexity $NADT^{\\oplus}(f)$ of $f$. Hatami et al. (2018) showed that unrestricted communication complexity of $F$ is polynomially related to parity decision tree complexity of $f$.   We initiate the studies of a similar connection for partial functions. We show that in case of one-sided communication complexity whether these measures are equal, depends on the number of undefined inputs of $f$. On the one hand, if $D_{cc}^{\\rightarrow}(F)=t$ and $f$ is undefined on at most $O(\\frac{2^{n-t}}{\\sqrt{n-t}})$, then $NADT^{\\oplus}(f)=t$.   On the other hand, for a wide range of values of $D_{cc}^{\\rightarrow}(F)$ and $NADT^{\\oplus}(f)$ (from constant to $n-2$) we provide partial functions for which $D_{cc}^{\\rightarrow}(F) < NADT^{\\oplus}(f)$. In particular, we provide a function with an exponential gap between the two measures. Our separation results translate to the case of two-sided communication complexity as well, in particular showing that the result of Hatami et al. (2018) cannot be generalized to partial functions.   Previous results for total functions heavily rely on Boolean Fourier analysis and the technique does not translate to partial functions. For the proofs of our results we build a linear algebraic framework instead. Separation results are proved through the reduction to covering codes.","sentences":["Boolean function $F(x,y)$ for $x,y \\in \\{0,1\\}^n$ is an XOR function if $F(x,y)=f(x\\oplus y)$ for some function $f$ on $n$ input bits, where $\\oplus$ is a bit-wise XOR.","XOR functions are relevant in communication complexity, partially for allowing Fourier analytic technique.","For total XOR functions it is known that deterministic communication complexity of $F$ is closely related to parity decision tree complexity of $f$. Montanaro and Osbourne (2009) observed that one-sided communication complexity $D_{cc}^{\\rightarrow}(F)$ of $F$ is exactly equal to nonadaptive parity decision tree complexity $NADT^{\\oplus}(f)$ of $f$. Hatami et al.","(2018) showed that unrestricted communication complexity of $F$ is polynomially related to parity decision tree complexity of $f$.   We initiate the studies of a similar connection for partial functions.","We show that in case of one-sided communication complexity whether these measures are equal, depends on the number of undefined inputs of $f$. On the one hand, if $D_{cc}^{\\rightarrow}(F)=t$ and $f$ is undefined on at most $O(\\frac{2^{n-t}}{\\sqrt{n-t}})$, then $NADT^{\\oplus}(f)=t$.   On the other hand, for a wide range of values of $D_{cc}^{\\rightarrow}(F)$ and $NADT^{\\oplus}(f)$ (from constant to $n-2$) we provide partial functions for which $D_{cc}^{\\rightarrow}(F) <","NADT^{\\oplus}(f)$. In particular, we provide a function with an exponential gap between the two measures.","Our separation results translate to the case of two-sided communication complexity as well, in particular showing that the result of Hatami et al.","(2018) cannot be generalized to partial functions.   ","Previous results for total functions heavily rely on Boolean Fourier analysis and the technique does not translate to partial functions.","For the proofs of our results we build a linear algebraic framework instead.","Separation results are proved through the reduction to covering codes."],"url":"http://arxiv.org/abs/2310.20606v1"}
{"created":"2023-10-31 16:39:58","title":"Learning Lyapunov-Stable Polynomial Dynamical Systems Through Imitation","abstract":"Imitation learning is a paradigm to address complex motion planning problems by learning a policy to imitate an expert's behavior. However, relying solely on the expert's data might lead to unsafe actions when the robot deviates from the demonstrated trajectories. Stability guarantees have previously been provided utilizing nonlinear dynamical systems, acting as high-level motion planners, in conjunction with the Lyapunov stability theorem. Yet, these methods are prone to inaccurate policies, high computational cost, sample inefficiency, or quasi stability when replicating complex and highly nonlinear trajectories. To mitigate this problem, we present an approach for learning a globally stable nonlinear dynamical system as a motion planning policy. We model the nonlinear dynamical system as a parametric polynomial and learn the polynomial's coefficients jointly with a Lyapunov candidate. To showcase its success, we compare our method against the state of the art in simulation and conduct real-world experiments with the Kinova Gen3 Lite manipulator arm. Our experiments demonstrate the sample efficiency and reproduction accuracy of our method for various expert trajectories, while remaining stable in the face of perturbations.","sentences":["Imitation learning is a paradigm to address complex motion planning problems by learning a policy to imitate an expert's behavior.","However, relying solely on the expert's data might lead to unsafe actions when the robot deviates from the demonstrated trajectories.","Stability guarantees have previously been provided utilizing nonlinear dynamical systems, acting as high-level motion planners, in conjunction with the Lyapunov stability theorem.","Yet, these methods are prone to inaccurate policies, high computational cost, sample inefficiency, or quasi stability when replicating complex and highly nonlinear trajectories.","To mitigate this problem, we present an approach for learning a globally stable nonlinear dynamical system as a motion planning policy.","We model the nonlinear dynamical system as a parametric polynomial and learn the polynomial's coefficients jointly with a Lyapunov candidate.","To showcase its success, we compare our method against the state of the art in simulation and conduct real-world experiments with the Kinova Gen3 Lite manipulator arm.","Our experiments demonstrate the sample efficiency and reproduction accuracy of our method for various expert trajectories, while remaining stable in the face of perturbations."],"url":"http://arxiv.org/abs/2310.20605v1"}
{"created":"2023-10-31 16:37:30","title":"Compliant actuators that mimic biological muscle performance with applications in a highly biomimetic robotic arm","abstract":"This paper endeavours to bridge the existing gap in muscular actuator design for ligament-skeletal-inspired robots, thereby fostering the evolution of these robotic systems. We introduce two novel compliant actuators, namely the Internal Torsion Spring Compliant Actuator (ICA) and the External Spring Compliant Actuator (ECA), and present a comparative analysis against the previously conceived Magnet Integrated Soft Actuator (MISA) through computational and experimental results. These actuators, employing a motor-tendon system, emulate biological muscle-like forms, enhancing artificial muscle technology. A robotic arm application inspired by the skeletal ligament system is presented. Experiments demonstrate satisfactory power in tasks like lifting dumbbells (peak power: 36W), playing table tennis (end-effector speed: 3.2 m/s), and door opening, without compromising biomimetic aesthetics. Compared to other linear stiffness serial elastic actuators (SEAs), ECA and ICA exhibit high power-to-volume (361 x 10^3 W/m) and power-to-mass (111.6 W/kg) ratios respectively, endorsing the biomimetic design's promise in robotic development.","sentences":["This paper endeavours to bridge the existing gap in muscular actuator design for ligament-skeletal-inspired robots, thereby fostering the evolution of these robotic systems.","We introduce two novel compliant actuators, namely the Internal Torsion Spring Compliant Actuator (ICA) and the External Spring Compliant Actuator (ECA), and present a comparative analysis against the previously conceived Magnet Integrated Soft Actuator (MISA) through computational and experimental results.","These actuators, employing a motor-tendon system, emulate biological muscle-like forms, enhancing artificial muscle technology.","A robotic arm application inspired by the skeletal ligament system is presented.","Experiments demonstrate satisfactory power in tasks like lifting dumbbells (peak power: 36W), playing table tennis (end-effector speed: 3.2 m/s), and door opening, without compromising biomimetic aesthetics.","Compared to other linear stiffness serial elastic actuators (SEAs), ECA and ICA exhibit high power-to-volume (361 x 10^3 W/m) and power-to-mass (111.6 W/kg) ratios respectively, endorsing the biomimetic design's promise in robotic development."],"url":"http://arxiv.org/abs/2310.20602v1"}
{"created":"2023-10-31 16:34:49","title":"Online Conversion with Switching Costs: Robust and Learning-Augmented Algorithms","abstract":"We introduce and study online conversion with switching costs, a family of online problems that capture emerging problems at the intersection of energy and sustainability. In this problem, an online player attempts to purchase (alternatively, sell) fractional shares of an asset during a fixed time horizon with length $T$. At each time step, a cost function (alternatively, price function) is revealed, and the player must irrevocably decide an amount of asset to convert. The player also incurs a switching cost whenever their decision changes in consecutive time steps, i.e., when they increase or decrease their purchasing amount. We introduce competitive (robust) threshold-based algorithms for both the minimization and maximization variants of this problem, and show they are optimal among deterministic online algorithms. We then propose learning-augmented algorithms that take advantage of untrusted black-box advice (such as predictions from a machine learning model) to achieve significantly better average-case performance without sacrificing worst-case competitive guarantees. Finally, we empirically evaluate our proposed algorithms using a carbon-aware EV charging case study, showing that our algorithms substantially improve on baseline methods for this problem.","sentences":["We introduce and study online conversion with switching costs, a family of online problems that capture emerging problems at the intersection of energy and sustainability.","In this problem, an online player attempts to purchase (alternatively, sell) fractional shares of an asset during a fixed time horizon with length","$T$. At each time step, a cost function (alternatively, price function) is revealed, and the player must irrevocably decide an amount of asset to convert.","The player also incurs a switching cost whenever their decision changes in consecutive time steps, i.e., when they increase or decrease their purchasing amount.","We introduce competitive (robust) threshold-based algorithms for both the minimization and maximization variants of this problem, and show they are optimal among deterministic online algorithms.","We then propose learning-augmented algorithms that take advantage of untrusted black-box advice (such as predictions from a machine learning model) to achieve significantly better average-case performance without sacrificing worst-case competitive guarantees.","Finally, we empirically evaluate our proposed algorithms using a carbon-aware EV charging case study, showing that our algorithms substantially improve on baseline methods for this problem."],"url":"http://arxiv.org/abs/2310.20598v1"}
{"created":"2023-10-31 16:30:16","title":"FLODCAST: Flow and Depth Forecasting via Multimodal Recurrent Architectures","abstract":"Forecasting motion and spatial positions of objects is of fundamental importance, especially in safety-critical settings such as autonomous driving. In this work, we address the issue by forecasting two different modalities that carry complementary information, namely optical flow and depth. To this end we propose FLODCAST a flow and depth forecasting model that leverages a multitask recurrent architecture, trained to jointly forecast both modalities at once. We stress the importance of training using flows and depth maps together, demonstrating that both tasks improve when the model is informed of the other modality. We train the proposed model to also perform predictions for several timesteps in the future. This provides better supervision and leads to more precise predictions, retaining the capability of the model to yield outputs autoregressively for any future time horizon. We test our model on the challenging Cityscapes dataset, obtaining state of the art results for both flow and depth forecasting. Thanks to the high quality of the generated flows, we also report benefits on the downstream task of segmentation forecasting, injecting our predictions in a flow-based mask-warping framework.","sentences":["Forecasting motion and spatial positions of objects is of fundamental importance, especially in safety-critical settings such as autonomous driving.","In this work, we address the issue by forecasting two different modalities that carry complementary information, namely optical flow and depth.","To this end we propose FLODCAST a flow and depth forecasting model that leverages a multitask recurrent architecture, trained to jointly forecast both modalities at once.","We stress the importance of training using flows and depth maps together, demonstrating that both tasks improve when the model is informed of the other modality.","We train the proposed model to also perform predictions for several timesteps in the future.","This provides better supervision and leads to more precise predictions, retaining the capability of the model to yield outputs autoregressively for any future time horizon.","We test our model on the challenging Cityscapes dataset, obtaining state of the art results for both flow and depth forecasting.","Thanks to the high quality of the generated flows, we also report benefits on the downstream task of segmentation forecasting, injecting our predictions in a flow-based mask-warping framework."],"url":"http://arxiv.org/abs/2310.20593v1"}
{"created":"2023-10-31 16:26:42","title":"An Enhanced RRT based Algorithm for Dynamic Path Planning and Energy Management of a Mobile Robot","abstract":"Mobile robots often have limited battery life and need to recharge periodically. This paper presents an RRT- based path-planning algorithm that addresses battery power management. A path is generated continuously from the robot's current position to its recharging station. The robot decides if a recharge is needed based on the energy required to travel on that path and the robot's current power. RRT* is used to generate the first path, and then subsequent paths are made using information from previous trees. Finally, the presented algorithm was compared with Extended Rate Random Tree (ERRT) algorithm","sentences":["Mobile robots often have limited battery life and need to recharge periodically.","This paper presents an RRT- based path-planning algorithm that addresses battery power management.","A path is generated continuously from the robot's current position to its recharging station.","The robot decides if a recharge is needed based on the energy required to travel on that path and the robot's current power.","RRT* is used to generate the first path, and then subsequent paths are made using information from previous trees.","Finally, the presented algorithm was compared with Extended Rate Random Tree (ERRT) algorithm"],"url":"http://arxiv.org/abs/2310.20590v1"}
{"created":"2023-10-31 16:26:36","title":"Increasing The Performance of Cognitively Inspired Data-Efficient Language Models via Implicit Structure Building","abstract":"In this paper, we describe our submission to the BabyLM Challenge 2023 shared task on data-efficient language model (LM) pretraining (Warstadt et al., 2023). We train transformer-based masked language models that incorporate unsupervised predictions about hierarchical sentence structure into the model architecture. Concretely, we use the Structformer architecture (Shen et al., 2021) and variants thereof. StructFormer models have been shown to perform well on unsupervised syntactic induction based on limited pretraining data, and to yield performance improvements over a vanilla transformer architecture (Shen et al., 2021). Evaluation of our models on 39 tasks provided by the BabyLM challenge shows promising improvements of models that integrate a hierarchical bias into the architecture at some particular tasks, even though they fail to consistently outperform the RoBERTa baseline model provided by the shared task organizers on all tasks.","sentences":["In this paper, we describe our submission to the BabyLM Challenge 2023 shared task on data-efficient language model (LM) pretraining (Warstadt et al., 2023).","We train transformer-based masked language models that incorporate unsupervised predictions about hierarchical sentence structure into the model architecture.","Concretely, we use the Structformer architecture (Shen et al., 2021) and variants thereof.","StructFormer models have been shown to perform well on unsupervised syntactic induction based on limited pretraining data, and to yield performance improvements over a vanilla transformer architecture (Shen et al., 2021).","Evaluation of our models on 39 tasks provided by the BabyLM challenge shows promising improvements of models that integrate a hierarchical bias into the architecture at some particular tasks, even though they fail to consistently outperform the RoBERTa baseline model provided by the shared task organizers on all tasks."],"url":"http://arxiv.org/abs/2310.20589v1"}
{"created":"2023-10-31 16:26:33","title":"Zero-Shot Medical Information Retrieval via Knowledge Graph Embedding","abstract":"In the era of the Internet of Things (IoT), the retrieval of relevant medical information has become essential for efficient clinical decision-making. This paper introduces MedFusionRank, a novel approach to zero-shot medical information retrieval (MIR) that combines the strengths of pre-trained language models and statistical methods while addressing their limitations. The proposed approach leverages a pre-trained BERT-style model to extract compact yet informative keywords. These keywords are then enriched with domain knowledge by linking them to conceptual entities within a medical knowledge graph. Experimental evaluations on medical datasets demonstrate MedFusion Rank's superior performance over existing methods, with promising results with a variety of evaluation metrics. MedFusionRank demonstrates efficacy in retrieving relevant information, even from short or single-term queries.","sentences":["In the era of the Internet of Things (IoT), the retrieval of relevant medical information has become essential for efficient clinical decision-making.","This paper introduces MedFusionRank, a novel approach to zero-shot medical information retrieval (MIR) that combines the strengths of pre-trained language models and statistical methods while addressing their limitations.","The proposed approach leverages a pre-trained BERT-style model to extract compact yet informative keywords.","These keywords are then enriched with domain knowledge by linking them to conceptual entities within a medical knowledge graph.","Experimental evaluations on medical datasets demonstrate MedFusion Rank's superior performance over existing methods, with promising results with a variety of evaluation metrics.","MedFusionRank demonstrates efficacy in retrieving relevant information, even from short or single-term queries."],"url":"http://arxiv.org/abs/2310.20588v1"}
{"created":"2023-10-31 16:24:17","title":"Unleashing the Power of Pre-trained Language Models for Offline Reinforcement Learning","abstract":"Offline reinforcement learning (RL) aims to find a near-optimal policy using pre-collected datasets. In real-world scenarios, data collection could be costly and risky; therefore, offline RL becomes particularly challenging when the in-domain data is limited. Given recent advances in Large Language Models (LLMs) and their few-shot learning prowess, this paper introduces $\\textbf{La}$nguage Models for $\\textbf{Mo}$tion Control ($\\textbf{LaMo}$), a general framework based on Decision Transformers to effectively use pre-trained Language Models (LMs) for offline RL. Our framework highlights four crucial components: (1) Initializing Decision Transformers with sequentially pre-trained LMs, (2) employing the LoRA fine-tuning method, in contrast to full-weight fine-tuning, to combine the pre-trained knowledge from LMs and in-domain knowledge effectively, (3) using the non-linear MLP transformation instead of linear projections, to generate embeddings, and (4) integrating an auxiliary language prediction loss during fine-tuning to stabilize the LMs and retain their original abilities on languages. Empirical results indicate $\\textbf{LaMo}$ achieves state-of-the-art performance in sparse-reward tasks and closes the gap between value-based offline RL methods and decision transformers in dense-reward tasks. In particular, our method demonstrates superior performance in scenarios with limited data samples. Our project website is https://lamo2023.github.io","sentences":["Offline reinforcement learning (RL) aims to find a near-optimal policy using pre-collected datasets.","In real-world scenarios, data collection could be costly and risky; therefore, offline RL becomes particularly challenging when the in-domain data is limited.","Given recent advances in Large Language Models (LLMs) and their few-shot learning prowess, this paper introduces $\\textbf{La}$nguage Models for $\\textbf{Mo}$tion Control ($\\textbf{LaMo}$), a general framework based on Decision Transformers to effectively use pre-trained Language Models (LMs) for offline RL.","Our framework highlights four crucial components: (1) Initializing Decision Transformers with sequentially pre-trained LMs, (2) employing the LoRA fine-tuning method, in contrast to full-weight fine-tuning, to combine the pre-trained knowledge from LMs and in-domain knowledge effectively, (3) using the non-linear MLP transformation instead of linear projections, to generate embeddings, and (4) integrating an auxiliary language prediction loss during fine-tuning to stabilize the LMs and retain their original abilities on languages.","Empirical results indicate $\\textbf{LaMo}$ achieves state-of-the-art performance in sparse-reward tasks and closes the gap between value-based offline RL methods and decision transformers in dense-reward tasks.","In particular, our method demonstrates superior performance in scenarios with limited data samples.","Our project website is https://lamo2023.github.io"],"url":"http://arxiv.org/abs/2310.20587v1"}
{"created":"2023-10-31 16:15:13","title":"Stochastic Gradient Descent for Gaussian Processes Done Right","abstract":"We study the optimisation problem associated with Gaussian process regression using squared loss. The most common approach to this problem is to apply an exact solver, such as conjugate gradient descent, either directly, or to a reduced-order version of the problem. Recently, driven by successes in deep learning, stochastic gradient descent has gained traction as an alternative. In this paper, we show that when done right$\\unicode{x2014}$by which we mean using specific insights from the optimisation and kernel communities$\\unicode{x2014}$this approach is highly effective. We thus introduce a particular stochastic dual gradient descent algorithm, that may be implemented with a few lines of code using any deep learning framework. We explain our design decisions by illustrating their advantage against alternatives with ablation studies and show that the new method is highly competitive. Our evaluations on standard regression benchmarks and a Bayesian optimisation task set our approach apart from preconditioned conjugate gradients, variational Gaussian process approximations, and a previous version of stochastic gradient descent for Gaussian processes. On a molecular binding affinity prediction task, our method places Gaussian process regression on par in terms of performance with state-of-the-art graph neural networks.","sentences":["We study the optimisation problem associated with Gaussian process regression using squared loss.","The most common approach to this problem is to apply an exact solver, such as conjugate gradient descent, either directly, or to a reduced-order version of the problem.","Recently, driven by successes in deep learning, stochastic gradient descent has gained traction as an alternative.","In this paper, we show that when done right$\\unicode{x2014}$by which we mean using specific insights from the optimisation and kernel communities$\\unicode{x2014}$this approach is highly effective.","We thus introduce a particular stochastic dual gradient descent algorithm, that may be implemented with a few lines of code using any deep learning framework.","We explain our design decisions by illustrating their advantage against alternatives with ablation studies and show that the new method is highly competitive.","Our evaluations on standard regression benchmarks and a Bayesian optimisation task set our approach apart from preconditioned conjugate gradients, variational Gaussian process approximations, and a previous version of stochastic gradient descent for Gaussian processes.","On a molecular binding affinity prediction task, our method places Gaussian process regression on par in terms of performance with state-of-the-art graph neural networks."],"url":"http://arxiv.org/abs/2310.20581v1"}
{"created":"2023-10-31 16:12:21","title":"Offloading Real-Time Tasks in IIoT Environments under Consideration of Networking Uncertainties","abstract":"Offloading is a popular way to overcome the resource and power constraints of networked embedded devices, which are increasingly found in industrial environments. It involves moving resource-intensive computational tasks to a more powerful device on the network, often in close proximity to enable wireless communication. However, many Industrial Internet of Things (IIoT) applications have real-time constraints. Offloading such tasks over a wireless network with latency uncertainties poses new challenges.   In this paper, we aim to better understand these challenges by proposing a system architecture and scheduler for real-time task offloading in wireless IIoT environments. Based on a prototype, we then evaluate different system configurations and discuss their trade-offs and implications. Our design showed to prevent deadline misses under high load and network uncertainties and was able to outperform a reference scheduler in terms of successful task throughput. Under heavy task load, where the reference scheduler had a success rate of 5%, our design achieved a success rate of 60%.","sentences":["Offloading is a popular way to overcome the resource and power constraints of networked embedded devices, which are increasingly found in industrial environments.","It involves moving resource-intensive computational tasks to a more powerful device on the network, often in close proximity to enable wireless communication.","However, many Industrial Internet of Things (IIoT) applications have real-time constraints.","Offloading such tasks over a wireless network with latency uncertainties poses new challenges.   ","In this paper, we aim to better understand these challenges by proposing a system architecture and scheduler for real-time task offloading in wireless IIoT environments.","Based on a prototype, we then evaluate different system configurations and discuss their trade-offs and implications.","Our design showed to prevent deadline misses under high load and network uncertainties and was able to outperform a reference scheduler in terms of successful task throughput.","Under heavy task load, where the reference scheduler had a success rate of 5%, our design achieved a success rate of 60%."],"url":"http://arxiv.org/abs/2310.20577v1"}
{"created":"2023-10-31 16:08:38","title":"Information-Theoretic Trust Regions for Stochastic Gradient-Based Optimization","abstract":"Stochastic gradient-based optimization is crucial to optimize neural networks. While popular approaches heuristically adapt the step size and direction by rescaling gradients, a more principled approach to improve optimizers requires second-order information. Such methods precondition the gradient using the objective's Hessian. Yet, computing the Hessian is usually expensive and effectively using second-order information in the stochastic gradient setting is non-trivial. We propose using Information-Theoretic Trust Region Optimization (arTuRO) for improved updates with uncertain second-order information. By modeling the network parameters as a Gaussian distribution and using a Kullback-Leibler divergence-based trust region, our approach takes bounded steps accounting for the objective's curvature and uncertainty in the parameters. Before each update, it solves the trust region problem for an optimal step size, resulting in a more stable and faster optimization process. We approximate the diagonal elements of the Hessian from stochastic gradients using a simple recursive least squares approach, constructing a model of the expected Hessian over time using only first-order information. We show that arTuRO combines the fast convergence of adaptive moment-based optimization with the generalization capabilities of SGD.","sentences":["Stochastic gradient-based optimization is crucial to optimize neural networks.","While popular approaches heuristically adapt the step size and direction by rescaling gradients, a more principled approach to improve optimizers requires second-order information.","Such methods precondition the gradient using the objective's Hessian.","Yet, computing the Hessian is usually expensive and effectively using second-order information in the stochastic gradient setting is non-trivial.","We propose using Information-Theoretic Trust Region Optimization (arTuRO) for improved updates with uncertain second-order information.","By modeling the network parameters as a Gaussian distribution and using a Kullback-Leibler divergence-based trust region, our approach takes bounded steps accounting for the objective's curvature and uncertainty in the parameters.","Before each update, it solves the trust region problem for an optimal step size, resulting in a more stable and faster optimization process.","We approximate the diagonal elements of the Hessian from stochastic gradients using a simple recursive least squares approach, constructing a model of the expected Hessian over time using only first-order information.","We show that arTuRO combines the fast convergence of adaptive moment-based optimization with the generalization capabilities of SGD."],"url":"http://arxiv.org/abs/2310.20574v1"}
{"created":"2023-10-31 15:52:06","title":"Predictive Control for Autonomous Driving with Uncertain, Multi-modal Predictions","abstract":"We propose a Stochastic MPC (SMPC) formulation for path planning with autonomous vehicles in scenarios involving multiple agents with multi-modal predictions. The multi-modal predictions capture the uncertainty of urban driving in distinct modes/maneuvers (e.g., yield, keep speed) and driving trajectories (e.g., speed, turning radius), which are incorporated for multi-modal collision avoidance chance constraints for path planning. In the presence of multi-modal uncertainties, it is challenging to reliably compute feasible path planning solutions at real-time frequencies ($\\geq$ 10 Hz). Our main technological contribution is a convex SMPC formulation that simultaneously (1) optimizes over parameterized feedback policies and (2) allocates risk levels for each mode of the prediction. The use of feedback policies and risk allocation enhances the feasibility and performance of the SMPC formulation against multi-modal predictions with large uncertainty. We evaluate our approach via simulations and road experiments with a full-scale vehicle interacting in closed-loop with virtual vehicles. We consider distinct, multi-modal driving scenarios: 1) Negotiating a traffic light and a fast, tailgating agent, 2) Executing an unprotected left turn at a traffic intersection, and 3) Changing lanes in the presence of multiple agents. For all of these scenarios, our approach reliably computes multi-modal solutions to the path-planning problem at real-time frequencies.","sentences":["We propose a Stochastic MPC (SMPC) formulation for path planning with autonomous vehicles in scenarios involving multiple agents with multi-modal predictions.","The multi-modal predictions capture the uncertainty of urban driving in distinct modes/maneuvers (e.g., yield, keep speed) and driving trajectories (e.g., speed, turning radius), which are incorporated for multi-modal collision avoidance chance constraints for path planning.","In the presence of multi-modal uncertainties, it is challenging to reliably compute feasible path planning solutions at real-time frequencies ($\\geq$ 10 Hz).","Our main technological contribution is a convex SMPC formulation that simultaneously (1) optimizes over parameterized feedback policies and (2) allocates risk levels for each mode of the prediction.","The use of feedback policies and risk allocation enhances the feasibility and performance of the SMPC formulation against multi-modal predictions with large uncertainty.","We evaluate our approach via simulations and road experiments with a full-scale vehicle interacting in closed-loop with virtual vehicles.","We consider distinct, multi-modal driving scenarios: 1) Negotiating a traffic light and a fast, tailgating agent, 2) Executing an unprotected left turn at a traffic intersection, and 3)","Changing lanes in the presence of multiple agents.","For all of these scenarios, our approach reliably computes multi-modal solutions to the path-planning problem at real-time frequencies."],"url":"http://arxiv.org/abs/2310.20561v1"}
{"created":"2023-10-31 15:41:08","title":"Breaking the Token Barrier: Chunking and Convolution for Efficient Long Text Classification with BERT","abstract":"Transformer-based models, specifically BERT, have propelled research in various NLP tasks. However, these models are limited to a maximum token limit of 512 tokens. Consequently, this makes it non-trivial to apply it in a practical setting with long input. Various complex methods have claimed to overcome this limit, but recent research questions the efficacy of these models across different classification tasks. These complex architectures evaluated on carefully curated long datasets perform at par or worse than simple baselines. In this work, we propose a relatively simple extension to vanilla BERT architecture called ChunkBERT that allows finetuning of any pretrained models to perform inference on arbitrarily long text. The proposed method is based on chunking token representations and CNN layers, making it compatible with any pre-trained BERT. We evaluate chunkBERT exclusively on a benchmark for comparing long-text classification models across a variety of tasks (including binary classification, multi-class classification, and multi-label classification). A BERT model finetuned using the ChunkBERT method performs consistently across long samples in the benchmark while utilizing only a fraction (6.25\\%) of the original memory footprint. These findings suggest that efficient finetuning and inference can be achieved through simple modifications to pre-trained BERT models.","sentences":["Transformer-based models, specifically BERT, have propelled research in various NLP tasks.","However, these models are limited to a maximum token limit of 512 tokens.","Consequently, this makes it non-trivial to apply it in a practical setting with long input.","Various complex methods have claimed to overcome this limit, but recent research questions the efficacy of these models across different classification tasks.","These complex architectures evaluated on carefully curated long datasets perform at par or worse than simple baselines.","In this work, we propose a relatively simple extension to vanilla BERT architecture called ChunkBERT that allows finetuning of any pretrained models to perform inference on arbitrarily long text.","The proposed method is based on chunking token representations and CNN layers, making it compatible with any pre-trained BERT.","We evaluate chunkBERT exclusively on a benchmark for comparing long-text classification models across a variety of tasks (including binary classification, multi-class classification, and multi-label classification).","A BERT model finetuned using the ChunkBERT method performs consistently across long samples in the benchmark while utilizing only a fraction (6.25\\%) of the original memory footprint.","These findings suggest that efficient finetuning and inference can be achieved through simple modifications to pre-trained BERT models."],"url":"http://arxiv.org/abs/2310.20558v1"}
{"created":"2023-10-31 15:35:51","title":"Fast and Delay-Robust Multimodal Journey Planning","abstract":"We study journey planning in multimodal networks consisting of public transit plus an unrestricted transfer mode (e.g., walking or cycling). In order to provide good results in practice, algorithms must account for vehicle delays. Delay-responsive algorithms receive a continuous stream of delay updates and must return optimal journeys in the currently known delay scenario. Updates are incorporated in an update phase, which must be fast (e.g., a few seconds). The fastest known approach for multimodal journey planning is ULTRA, which precomputes shortcuts representing transfers between vehicles. This allows query algorithms to find Pareto-optimal journeys regarding arrival time and the number of public transit trips without any performance loss compared to pure public transit networks. However, the precomputation phase does not account for delays and is too slow to rerun during the update phase. We present Delay-ULTRA, a delay-responsive variant of ULTRA. Since accounting for all theoretically possible delays would yield an impractically large set of shortcuts, our approach precomputes shortcuts that are provably sufficient as long as delays do not exceed a configurable limit (e.g., 5 minutes). To handle delays above the limit (which are less frequent in practice), we propose a heuristic search for missing shortcuts that is fast enough to be run during the update phase. Our experimental evaluation on real-world data shows that Delay-ULTRA fails to find less than 0.02% of optimal journeys on metropolitan and mid-sized country networks, and 0.16% on the much larger Germany network. Considering that the available delay information in realistic applications is never perfectly accurate, these error rates are negligible. Query speed is at most twice as slow as ULTRA without delay information, and up to 8 times faster than the fastest exact algorithm, which does not require a preprocessing phase.","sentences":["We study journey planning in multimodal networks consisting of public transit plus an unrestricted transfer mode (e.g., walking or cycling).","In order to provide good results in practice, algorithms must account for vehicle delays.","Delay-responsive algorithms receive a continuous stream of delay updates and must return optimal journeys in the currently known delay scenario.","Updates are incorporated in an update phase, which must be fast (e.g., a few seconds).","The fastest known approach for multimodal journey planning is ULTRA, which precomputes shortcuts representing transfers between vehicles.","This allows query algorithms to find Pareto-optimal journeys regarding arrival time and the number of public transit trips without any performance loss compared to pure public transit networks.","However, the precomputation phase does not account for delays and is too slow to rerun during the update phase.","We present Delay-ULTRA, a delay-responsive variant of ULTRA.","Since accounting for all theoretically possible delays would yield an impractically large set of shortcuts, our approach precomputes shortcuts that are provably sufficient as long as delays do not exceed a configurable limit (e.g., 5 minutes).","To handle delays above the limit (which are less frequent in practice), we propose a heuristic search for missing shortcuts that is fast enough to be run during the update phase.","Our experimental evaluation on real-world data shows that Delay-ULTRA fails to find less than 0.02% of optimal journeys on metropolitan and mid-sized country networks, and 0.16% on the much larger Germany network.","Considering that the available delay information in realistic applications is never perfectly accurate, these error rates are negligible.","Query speed is at most twice as slow as ULTRA without delay information, and up to 8 times faster than the fastest exact algorithm, which does not require a preprocessing phase."],"url":"http://arxiv.org/abs/2310.20554v1"}
{"created":"2023-10-31 15:34:59","title":"Privacy-preserving design of graph neural networks with applications to vertical federated learning","abstract":"The paradigm of vertical federated learning (VFL), where institutions collaboratively train machine learning models via combining each other's local feature or label information, has achieved great success in applications to financial risk management (FRM). The surging developments of graph representation learning (GRL) have opened up new opportunities for FRM applications under FL via efficiently utilizing the graph-structured data generated from underlying transaction networks. Meanwhile, transaction information is often considered highly sensitive. To prevent data leakage during training, it is critical to develop FL protocols with formal privacy guarantees. In this paper, we present an end-to-end GRL framework in the VFL setting called VESPER, which is built upon a general privatization scheme termed perturbed message passing (PMP) that allows the privatization of many popular graph neural architectures.Based on PMP, we discuss the strengths and weaknesses of specific design choices of concrete graph neural architectures and provide solutions and improvements for both dense and sparse graphs. Extensive empirical evaluations over both public datasets and an industry dataset demonstrate that VESPER is capable of training high-performance GNN models over both sparse and dense graphs under reasonable privacy budgets.","sentences":["The paradigm of vertical federated learning (VFL), where institutions collaboratively train machine learning models via combining each other's local feature or label information, has achieved great success in applications to financial risk management (FRM).","The surging developments of graph representation learning (GRL) have opened up new opportunities for FRM applications under FL via efficiently utilizing the graph-structured data generated from underlying transaction networks.","Meanwhile, transaction information is often considered highly sensitive.","To prevent data leakage during training, it is critical to develop FL protocols with formal privacy guarantees.","In this paper, we present an end-to-end GRL framework in the VFL setting called VESPER, which is built upon a general privatization scheme termed perturbed message passing (PMP) that allows the privatization of many popular graph neural architectures.","Based on PMP, we discuss the strengths and weaknesses of specific design choices of concrete graph neural architectures and provide solutions and improvements for both dense and sparse graphs.","Extensive empirical evaluations over both public datasets and an industry dataset demonstrate that VESPER is capable of training high-performance GNN models over both sparse and dense graphs under reasonable privacy budgets."],"url":"http://arxiv.org/abs/2310.20552v1"}
{"created":"2023-10-31 15:31:39","title":"CapsFusion: Rethinking Image-Text Data at Scale","abstract":"Large multimodal models demonstrate remarkable generalist ability to perform diverse multimodal tasks in a zero-shot manner. Large-scale web-based image-text pairs contribute fundamentally to this success, but suffer from excessive noise. Recent studies use alternative captions synthesized by captioning models and have achieved notable benchmark performance. However, our experiments reveal significant Scalability Deficiency and World Knowledge Loss issues in models trained with synthetic captions, which have been largely obscured by their initial benchmark success. Upon closer examination, we identify the root cause as the overly-simplified language structure and lack of knowledge details in existing synthetic captions. To provide higher-quality and more scalable multimodal pretraining data, we propose CapsFusion, an advanced framework that leverages large language models to consolidate and refine information from both web-based image-text pairs and synthetic captions. Extensive experiments show that CapsFusion captions exhibit remarkable all-round superiority over existing captions in terms of model performance (e.g., 18.8 and 18.3 improvements in CIDEr score on COCO and NoCaps), sample efficiency (requiring 11-16 times less computation than baselines), world knowledge depth, and scalability. These effectiveness, efficiency and scalability advantages position CapsFusion as a promising candidate for future scaling of LMM training.","sentences":["Large multimodal models demonstrate remarkable generalist ability to perform diverse multimodal tasks in a zero-shot manner.","Large-scale web-based image-text pairs contribute fundamentally to this success, but suffer from excessive noise.","Recent studies use alternative captions synthesized by captioning models and have achieved notable benchmark performance.","However, our experiments reveal significant Scalability Deficiency and World Knowledge Loss issues in models trained with synthetic captions, which have been largely obscured by their initial benchmark success.","Upon closer examination, we identify the root cause as the overly-simplified language structure and lack of knowledge details in existing synthetic captions.","To provide higher-quality and more scalable multimodal pretraining data, we propose CapsFusion, an advanced framework that leverages large language models to consolidate and refine information from both web-based image-text pairs and synthetic captions.","Extensive experiments show that CapsFusion captions exhibit remarkable all-round superiority over existing captions in terms of model performance (e.g., 18.8 and 18.3 improvements in CIDEr score on COCO and NoCaps), sample efficiency (requiring 11-16 times less computation than baselines), world knowledge depth, and scalability.","These effectiveness, efficiency and scalability advantages position CapsFusion as a promising candidate for future scaling of LMM training."],"url":"http://arxiv.org/abs/2310.20550v1"}
{"created":"2023-10-31 15:26:33","title":"Multi-task learning of convex combinations of forecasting models","abstract":"Forecast combination involves using multiple forecasts to create a single, more accurate prediction. Recently, feature-based forecasting has been employed to either select the most appropriate forecasting models or to learn the weights of their convex combination. In this paper, we present a multi-task learning methodology that simultaneously addresses both problems. This approach is implemented through a deep neural network with two branches: the regression branch, which learns the weights of various forecasting methods by minimizing the error of combined forecasts, and the classification branch, which selects forecasting methods with an emphasis on their diversity. To generate training labels for the classification task, we introduce an optimization-driven approach that identifies the most appropriate methods for a given time series. The proposed approach elicits the essential role of diversity in feature-based forecasting and highlights the interplay between model combination and model selection when learning forecasting ensembles. Experimental results on a large set of series from the M4 competition dataset show that our proposal enhances point forecast accuracy compared to state-of-the-art methods.","sentences":["Forecast combination involves using multiple forecasts to create a single, more accurate prediction.","Recently, feature-based forecasting has been employed to either select the most appropriate forecasting models or to learn the weights of their convex combination.","In this paper, we present a multi-task learning methodology that simultaneously addresses both problems.","This approach is implemented through a deep neural network with two branches: the regression branch, which learns the weights of various forecasting methods by minimizing the error of combined forecasts, and the classification branch, which selects forecasting methods with an emphasis on their diversity.","To generate training labels for the classification task, we introduce an optimization-driven approach that identifies the most appropriate methods for a given time series.","The proposed approach elicits the essential role of diversity in feature-based forecasting and highlights the interplay between model combination and model selection when learning forecasting ensembles.","Experimental results on a large set of series from the M4 competition dataset show that our proposal enhances point forecast accuracy compared to state-of-the-art methods."],"url":"http://arxiv.org/abs/2310.20545v1"}
{"created":"2023-10-31 15:21:22","title":"The Computational Lens: from Quantum Physics to Neuroscience","abstract":"Two transformative waves of computing have redefined the way we approach science. The first wave came with the birth of the digital computer, which enabled scientists to numerically simulate their models and analyze massive datasets. This technological breakthrough led to the emergence of many sub-disciplines bearing the prefix \"computational\" in their names. Currently, we are in the midst of the second wave, marked by the remarkable advancements in artificial intelligence. From predicting protein structures to classifying galaxies, the scope of its applications is vast, and there can only be more awaiting us on the horizon.   While these two waves influence scientific methodology at the instrumental level, in this dissertation, I will present the computational lens in science, aiming at the conceptual level. Specifically, the central thesis posits that computation serves as a convenient and mechanistic language for understanding and analyzing information processing systems, offering the advantages of composability and modularity.   This dissertation begins with an illustration of the blueprint of the computational lens, supported by a review of relevant previous work. Subsequently, I will present my own works in quantum physics and neuroscience as concrete examples. In the concluding chapter, I will contemplate the potential of applying the computational lens across various scientific fields, in a way that can provide significant domain insights, and discuss potential future directions.","sentences":["Two transformative waves of computing have redefined the way we approach science.","The first wave came with the birth of the digital computer, which enabled scientists to numerically simulate their models and analyze massive datasets.","This technological breakthrough led to the emergence of many sub-disciplines bearing the prefix \"computational\" in their names.","Currently, we are in the midst of the second wave, marked by the remarkable advancements in artificial intelligence.","From predicting protein structures to classifying galaxies, the scope of its applications is vast, and there can only be more awaiting us on the horizon.   ","While these two waves influence scientific methodology at the instrumental level, in this dissertation, I will present the computational lens in science, aiming at the conceptual level.","Specifically, the central thesis posits that computation serves as a convenient and mechanistic language for understanding and analyzing information processing systems, offering the advantages of composability and modularity.   ","This dissertation begins with an illustration of the blueprint of the computational lens, supported by a review of relevant previous work.","Subsequently, I will present my own works in quantum physics and neuroscience as concrete examples.","In the concluding chapter, I will contemplate the potential of applying the computational lens across various scientific fields, in a way that can provide significant domain insights, and discuss potential future directions."],"url":"http://arxiv.org/abs/2310.20539v1"}
{"created":"2023-10-31 15:19:20","title":"Dynamic Dictionary with Subconstant Wasted Bits per Key","abstract":"Dictionaries have been one of the central questions in data structures. A dictionary data structure maintains a set of key-value pairs under insertions and deletions such that given a query key, the data structure efficiently returns its value. The state-of-the-art dictionaries [Bender, Farach-Colton, Kuszmaul, Kuszmaul, Liu 2022] store $n$ key-value pairs with only $O(n \\log^{(k)} n)$ bits of redundancy, and support all operations in $O(k)$ time, for $k \\leq \\log^* n$. It was recently shown to be optimal [Li, Liang, Yu, Zhou 2023b].   In this paper, we study the regime where the redundant bits is $R=o(n)$, and show that when $R$ is at least $n/\\text{poly}\\log n$, all operations can be supported in $O(\\log^* n + \\log (n/R))$ time, matching the lower bound in this regime [Li, Liang, Yu, Zhou 2023b]. We present two data structures based on which range $R$ is in. The data structure for $R<n/\\log^{0.1} n$ utilizes a generalization of adapters studied in [Berger, Kuszmaul, Polak, Tidor, Wein 2022] and [Li, Liang, Yu, Zhou 2023a]. The data structure for $R \\geq n/\\log^{0.1} n$ is based on recursively hashing into buckets with logarithmic sizes.","sentences":["Dictionaries have been one of the central questions in data structures.","A dictionary data structure maintains a set of key-value pairs under insertions and deletions such that given a query key, the data structure efficiently returns its value.","The state-of-the-art dictionaries [Bender, Farach-Colton, Kuszmaul, Kuszmaul, Liu 2022] store $n$ key-value pairs with only $O(n \\log^{(k)}","n)$ bits of redundancy, and support all operations in $O(k)$ time, for $k \\leq \\log^* n$. It was recently shown to be optimal [Li, Liang, Yu, Zhou 2023b].   ","In this paper, we study the regime where the redundant bits is $R=o(n)$, and show that when $R$ is at least $n/\\text{poly}\\log n$, all operations can be supported in $O(\\log^* n + \\log (n/R))$ time, matching the lower bound in this regime","[Li, Liang, Yu, Zhou 2023b].","We present two data structures based on which range $R$ is in.","The data structure for $R<n/\\log^{0.1} n$ utilizes a generalization of adapters studied in [Berger, Kuszmaul, Polak, Tidor, Wein 2022] and","[Li, Liang, Yu, Zhou 2023a].","The data structure for $R \\geq n/\\log^{0.1} n$ is based on recursively hashing into buckets with logarithmic sizes."],"url":"http://arxiv.org/abs/2310.20536v1"}
{"created":"2023-10-31 15:16:57","title":"Algebraic hierarchical locally recoverable codes with nested affine subspace recovery","abstract":"Codes with locality, also known as locally recoverable codes, allow for recovery of erasures using proper subsets of other coordinates. Theses subsets are typically of small cardinality to promote recovery using limited network traffic and other resources. Hierarchical locally recoverable codes allow for recovery of erasures using sets of other symbols whose sizes increase as needed to allow for recovery of more symbols. In this paper, we construct codes with hierarchical locality from a geometric perspective, using fiber products of curves. We demonstrate how the constructed hierarchical codes can be viewed as punctured subcodes of Reed-Muller codes. This point of view provides natural structures for local recovery at each level in the hierarchy.","sentences":["Codes with locality, also known as locally recoverable codes, allow for recovery of erasures using proper subsets of other coordinates.","Theses subsets are typically of small cardinality to promote recovery using limited network traffic and other resources.","Hierarchical locally recoverable codes allow for recovery of erasures using sets of other symbols whose sizes increase as needed to allow for recovery of more symbols.","In this paper, we construct codes with hierarchical locality from a geometric perspective, using fiber products of curves.","We demonstrate how the constructed hierarchical codes can be viewed as punctured subcodes of Reed-Muller codes.","This point of view provides natural structures for local recovery at each level in the hierarchy."],"url":"http://arxiv.org/abs/2310.20533v1"}
{"created":"2023-10-31 15:04:53","title":"Group-Feature (Sensor) Selection With Controlled Redundancy Using Neural Networks","abstract":"In this paper, we present a novel embedded feature selection method based on a Multi-layer Perceptron (MLP) network and generalize it for group-feature or sensor selection problems, which can control the level of redundancy among the selected features or groups. Additionally, we have generalized the group lasso penalty for feature selection to encompass a mechanism for selecting valuable group features while simultaneously maintaining a control over redundancy. We establish the monotonicity and convergence of the proposed algorithm, with a smoothed version of the penalty terms, under suitable assumptions. Experimental results on several benchmark datasets demonstrate the promising performance of the proposed methodology for both feature selection and group feature selection over some state-of-the-art methods.","sentences":["In this paper, we present a novel embedded feature selection method based on a Multi-layer Perceptron (MLP) network and generalize it for group-feature or sensor selection problems, which can control the level of redundancy among the selected features or groups.","Additionally, we have generalized the group lasso penalty for feature selection to encompass a mechanism for selecting valuable group features while simultaneously maintaining a control over redundancy.","We establish the monotonicity and convergence of the proposed algorithm, with a smoothed version of the penalty terms, under suitable assumptions.","Experimental results on several benchmark datasets demonstrate the promising performance of the proposed methodology for both feature selection and group feature selection over some state-of-the-art methods."],"url":"http://arxiv.org/abs/2310.20524v1"}
{"created":"2023-10-31 14:56:51","title":"Improving RRT for Automated Parking in Real-world Scenarios","abstract":"Automated parking is a self-driving feature that has been in cars for several years. Parking assistants in currently sold cars fail to park in more complex real-world scenarios and require the driver to move the car to an expected starting position before the assistant is activated. We overcome these limitations by proposing a planning algorithm consisting of two stages: (1) a geometric planner for maneuvering inside the parking slot and (2) a Rapidly-exploring Random Trees (RRT)-based planner that finds a collision-free path from the initial position to the slot entry. Evaluation of computational experiments demonstrates that improvements over commonly used RRT extensions reduce the parking path cost by 21 % and reduce the computation time by 79.5 %. The suitability of the algorithm for real-world parking scenarios was verified in physical experiments with Porsche Cayenne.","sentences":["Automated parking is a self-driving feature that has been in cars for several years.","Parking assistants in currently sold cars fail to park in more complex real-world scenarios and require the driver to move the car to an expected starting position before the assistant is activated.","We overcome these limitations by proposing a planning algorithm consisting of two stages: (1) a geometric planner for maneuvering inside the parking slot and (2) a Rapidly-exploring Random Trees (RRT)-based planner that finds a collision-free path from the initial position to the slot entry.","Evaluation of computational experiments demonstrates that improvements over commonly used RRT extensions reduce the parking path cost by 21 % and reduce the computation time by 79.5 %.","The suitability of the algorithm for real-world parking scenarios was verified in physical experiments with Porsche Cayenne."],"url":"http://arxiv.org/abs/2310.20518v1"}
{"created":"2023-10-31 14:55:55","title":"LoRa Multi-Hop Networks for Monitoring Underground Mining Environments","abstract":"Internet of Things applications have gained widespread recognition for their efficacy in typical scenarios, such as smart cities and smart healthcare. Nonetheless, there exist numerous unconventional situations where IoT technologies have not yet been massively applied, though they can be extremely useful. One of such domains is the underground mining sector, where enhancing automation monitoring through wireless communications is of essential significance. In this paper, we focus on the development, implementation, and evaluation of a LoRa-based multi-hop network tailored specifically for monitoring underground mining environments, where data traffic is sporadic, but energy efficiency is of paramount importance. We hence define a synchronization framework that makes it possible for the nodes to sleep for most of the time, waking up only when they need to exchange traffic. Notably, our network achieves a sub 40us proven synchronization accuracy between parent-child pairs with minimum overhead for diverse topologies, rendering it highly viable for subterranean operations. Furthermore, for proper network dimensioning, we model the interplay between network's throughput, frame size, and sampling periods of potential applications. Moreover, we propose a model to estimate devices' duty cycle based on their position within the multi-hop network, along with empirical observations for its validation. The proposed models make it possible to optimize the network's performance to meet the specific demands that can arise from the different subterranean use cases, in which robustness, low power operation, and compliance with radio-frequency regulations are key requirements that must be met.","sentences":["Internet of Things applications have gained widespread recognition for their efficacy in typical scenarios, such as smart cities and smart healthcare.","Nonetheless, there exist numerous unconventional situations where IoT technologies have not yet been massively applied, though they can be extremely useful.","One of such domains is the underground mining sector, where enhancing automation monitoring through wireless communications is of essential significance.","In this paper, we focus on the development, implementation, and evaluation of a LoRa-based multi-hop network tailored specifically for monitoring underground mining environments, where data traffic is sporadic, but energy efficiency is of paramount importance.","We hence define a synchronization framework that makes it possible for the nodes to sleep for most of the time, waking up only when they need to exchange traffic.","Notably, our network achieves a sub 40us proven synchronization accuracy between parent-child pairs with minimum overhead for diverse topologies, rendering it highly viable for subterranean operations.","Furthermore, for proper network dimensioning, we model the interplay between network's throughput, frame size, and sampling periods of potential applications.","Moreover, we propose a model to estimate devices' duty cycle based on their position within the multi-hop network, along with empirical observations for its validation.","The proposed models make it possible to optimize the network's performance to meet the specific demands that can arise from the different subterranean use cases, in which robustness, low power operation, and compliance with radio-frequency regulations are key requirements that must be met."],"url":"http://arxiv.org/abs/2310.20515v1"}
