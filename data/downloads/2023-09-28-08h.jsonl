{"created":"2023-09-27 17:59:48","title":"SHACIRA: Scalable HAsh-grid Compression for Implicit Neural Representations","abstract":"Implicit Neural Representations (INR) or neural fields have emerged as a popular framework to encode multimedia signals such as images and radiance fields while retaining high-quality. Recently, learnable feature grids proposed by Instant-NGP have allowed significant speed-up in the training as well as the sampling of INRs by replacing a large neural network with a multi-resolution look-up table of feature vectors and a much smaller neural network. However, these feature grids come at the expense of large memory consumption which can be a bottleneck for storage and streaming applications. In this work, we propose SHACIRA, a simple yet effective task-agnostic framework for compressing such feature grids with no additional post-hoc pruning/quantization stages. We reparameterize feature grids with quantized latent weights and apply entropy regularization in the latent space to achieve high levels of compression across various domains. Quantitative and qualitative results on diverse datasets consisting of images, videos, and radiance fields, show that our approach outperforms existing INR approaches without the need for any large datasets or domain-specific heuristics. Our project page is available at http://shacira.github.io .","sentences":["Implicit Neural Representations (INR) or neural fields have emerged as a popular framework to encode multimedia signals such as images and radiance fields while retaining high-quality.","Recently, learnable feature grids proposed by Instant-NGP have allowed significant speed-up in the training as well as the sampling of INRs by replacing a large neural network with a multi-resolution look-up table of feature vectors and a much smaller neural network.","However, these feature grids come at the expense of large memory consumption which can be a bottleneck for storage and streaming applications.","In this work, we propose SHACIRA, a simple yet effective task-agnostic framework for compressing such feature grids with no additional post-hoc pruning/quantization stages.","We reparameterize feature grids with quantized latent weights and apply entropy regularization in the latent space to achieve high levels of compression across various domains.","Quantitative and qualitative results on diverse datasets consisting of images, videos, and radiance fields, show that our approach outperforms existing INR approaches without the need for any large datasets or domain-specific heuristics.","Our project page is available at http://shacira.github.io ."],"url":"http://arxiv.org/abs/2309.15848v1"}
{"created":"2023-09-27 17:59:11","title":"Exploiting the Signal-Leak Bias in Diffusion Models","abstract":"There is a bias in the inference pipeline of most diffusion models. This bias arises from a signal leak whose distribution deviates from the noise distribution, creating a discrepancy between training and inference processes. We demonstrate that this signal-leak bias is particularly significant when models are tuned to a specific style, causing sub-optimal style matching. Recent research tries to avoid the signal leakage during training. We instead show how we can exploit this signal-leak bias in existing diffusion models to allow more control over the generated images. This enables us to generate images with more varied brightness, and images that better match a desired style or color. By modeling the distribution of the signal leak in the spatial frequency and pixel domains, and including a signal leak in the initial latent, we generate images that better match expected results without any additional training.","sentences":["There is a bias in the inference pipeline of most diffusion models.","This bias arises from a signal leak whose distribution deviates from the noise distribution, creating a discrepancy between training and inference processes.","We demonstrate that this signal-leak bias is particularly significant when models are tuned to a specific style, causing sub-optimal style matching.","Recent research tries to avoid the signal leakage during training.","We instead show how we can exploit this signal-leak bias in existing diffusion models to allow more control over the generated images.","This enables us to generate images with more varied brightness, and images that better match a desired style or color.","By modeling the distribution of the signal leak in the spatial frequency and pixel domains, and including a signal leak in the initial latent, we generate images that better match expected results without any additional training."],"url":"http://arxiv.org/abs/2309.15842v1"}
{"created":"2023-09-27 17:58:30","title":"Examining the Values Reflected by Children during AI Problem Formulation","abstract":"Understanding how children design and what they value in AI interfaces that allow them to explicitly train their models such as teachable machines, could help increase such activities' impact and guide the design of future technologies. In a co-design session using a modified storyboard, a team of 5 children (aged 7-13 years) and adult co-designers, engaged in AI problem formulation activities where they imagine their own teachable machines. Our findings, leveraging an established psychological value framework (the Rokeach Value Survey), illuminate how children conceptualize and embed their values in AI systems that they themselves devise to support their everyday activities. Specifically, we find that children's proposed ideas require advanced system intelligence, e.g. emotion detection and understanding the social relationships of a user. The underlying models could be trained under multiple modalities and any errors would be fixed by adding more data or by anticipating negative examples. Children's ideas showed they cared about family and expected machines to understand their social context before making decisions.","sentences":["Understanding how children design and what they value in AI interfaces that allow them to explicitly train their models such as teachable machines, could help increase such activities' impact and guide the design of future technologies.","In a co-design session using a modified storyboard, a team of 5 children (aged 7-13 years) and adult co-designers, engaged in AI problem formulation activities where they imagine their own teachable machines.","Our findings, leveraging an established psychological value framework (the Rokeach Value Survey), illuminate how children conceptualize and embed their values in AI systems that they themselves devise to support their everyday activities.","Specifically, we find that children's proposed ideas require advanced system intelligence, e.g. emotion detection and understanding the social relationships of a user.","The underlying models could be trained under multiple modalities and any errors would be fixed by adding more data or by anticipating negative examples.","Children's ideas showed they cared about family and expected machines to understand their social context before making decisions."],"url":"http://arxiv.org/abs/2309.15839v1"}
{"created":"2023-09-27 17:52:39","title":"OrthoPlanes: A Novel Representation for Better 3D-Awareness of GANs","abstract":"We present a new method for generating realistic and view-consistent images with fine geometry from 2D image collections. Our method proposes a hybrid explicit-implicit representation called \\textbf{OrthoPlanes}, which encodes fine-grained 3D information in feature maps that can be efficiently generated by modifying 2D StyleGANs. Compared to previous representations, our method has better scalability and expressiveness with clear and explicit information. As a result, our method can handle more challenging view-angles and synthesize articulated objects with high spatial degree of freedom. Experiments demonstrate that our method achieves state-of-the-art results on FFHQ and SHHQ datasets, both quantitatively and qualitatively. Project page: \\url{https://orthoplanes.github.io/}.","sentences":["We present a new method for generating realistic and view-consistent images with fine geometry from 2D image collections.","Our method proposes a hybrid explicit-implicit representation called \\textbf{OrthoPlanes}, which encodes fine-grained 3D information in feature maps that can be efficiently generated by modifying 2D StyleGANs.","Compared to previous representations, our method has better scalability and expressiveness with clear and explicit information.","As a result, our method can handle more challenging view-angles and synthesize articulated objects with high spatial degree of freedom.","Experiments demonstrate that our method achieves state-of-the-art results on FFHQ and SHHQ datasets, both quantitatively and qualitatively.","Project page: \\url{https://orthoplanes.github.io/}."],"url":"http://arxiv.org/abs/2309.15830v1"}
{"created":"2023-09-27 17:48:14","title":"Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing","abstract":"Recent works in end-to-end speech-to-text translation (ST) have proposed multi-tasking methods with soft parameter sharing which leverage machine translation (MT) data via secondary encoders that map text inputs to an eventual cross-modal representation. In this work, we instead propose a ST/MT multi-tasking framework with hard parameter sharing in which all model parameters are shared cross-modally. Our method reduces the speech-text modality gap via a pre-processing stage which converts speech and text inputs into two discrete token sequences of similar length -- this allows models to indiscriminately process both modalities simply using a joint vocabulary. With experiments on MuST-C, we demonstrate that our multi-tasking framework improves attentional encoder-decoder, Connectionist Temporal Classification (CTC), transducer, and joint CTC/attention models by an average of +0.5 BLEU without any external MT data. Further, we show that this framework incorporates external MT data, yielding +0.8 BLEU, and also improves transfer learning from pre-trained textual models, yielding +1.8 BLEU.","sentences":["Recent works in end-to-end speech-to-text translation (ST) have proposed multi-tasking methods with soft parameter sharing which leverage machine translation (MT) data via secondary encoders that map text inputs to an eventual cross-modal representation.","In this work, we instead propose a ST/MT multi-tasking framework with hard parameter sharing in which all model parameters are shared cross-modally.","Our method reduces the speech-text modality gap via a pre-processing stage which converts speech and text inputs into two discrete token sequences of similar length -- this allows models to indiscriminately process both modalities simply using a joint vocabulary.","With experiments on MuST-C, we demonstrate that our multi-tasking framework improves attentional encoder-decoder, Connectionist Temporal Classification (CTC), transducer, and joint CTC/attention models by an average of +0.5 BLEU without any external MT data.","Further, we show that this framework incorporates external MT data, yielding +0.8 BLEU, and also improves transfer learning from pre-trained textual models, yielding +1.8 BLEU."],"url":"http://arxiv.org/abs/2309.15826v1"}
{"created":"2023-09-27 17:45:49","title":"LGMCTS: Language-Guided Monte-Carlo Tree Search for Executable Semantic Object Rearrangement","abstract":"We introduce a novel approach to the executable semantic object rearrangement problem. In this challenge, a robot seeks to create an actionable plan that rearranges objects within a scene according to a pattern dictated by a natural language description. Unlike existing methods such as StructFormer and StructDiffusion, which tackle the issue in two steps by first generating poses and then leveraging a task planner for action plan formulation, our method concurrently addresses pose generation and action planning. We achieve this integration using a Language-Guided Monte-Carlo Tree Search (LGMCTS). Quantitative evaluations are provided on two simulation datasets, and complemented by qualitative tests with a real robot.","sentences":["We introduce a novel approach to the executable semantic object rearrangement problem.","In this challenge, a robot seeks to create an actionable plan that rearranges objects within a scene according to a pattern dictated by a natural language description.","Unlike existing methods such as StructFormer and StructDiffusion, which tackle the issue in two steps by first generating poses and then leveraging a task planner for action plan formulation, our method concurrently addresses pose generation and action planning.","We achieve this integration using a Language-Guided Monte-Carlo Tree Search (LGMCTS).","Quantitative evaluations are provided on two simulation datasets, and complemented by qualitative tests with a real robot."],"url":"http://arxiv.org/abs/2309.15821v1"}
{"created":"2023-09-27 17:44:18","title":"Show-1: Marrying Pixel and Latent Diffusion Models for Text-to-Video Generation","abstract":"Significant advancements have been achieved in the realm of large-scale pre-trained text-to-video Diffusion Models (VDMs). However, previous methods either rely solely on pixel-based VDMs, which come with high computational costs, or on latent-based VDMs, which often struggle with precise text-video alignment. In this paper, we are the first to propose a hybrid model, dubbed as Show-1, which marries pixel-based and latent-based VDMs for text-to-video generation. Our model first uses pixel-based VDMs to produce a low-resolution video of strong text-video correlation. After that, we propose a novel expert translation method that employs the latent-based VDMs to further upsample the low-resolution video to high resolution. Compared to latent VDMs, Show-1 can produce high-quality videos of precise text-video alignment; Compared to pixel VDMs, Show-1 is much more efficient (GPU memory usage during inference is 15G vs 72G). We also validate our model on standard video generation benchmarks. Our code and model weights are publicly available at \\url{https://github.com/showlab/Show-1}.","sentences":["Significant advancements have been achieved in the realm of large-scale pre-trained text-to-video Diffusion Models (VDMs).","However, previous methods either rely solely on pixel-based VDMs, which come with high computational costs, or on latent-based VDMs, which often struggle with precise text-video alignment.","In this paper, we are the first to propose a hybrid model, dubbed as Show-1, which marries pixel-based and latent-based VDMs for text-to-video generation.","Our model first uses pixel-based VDMs to produce a low-resolution video of strong text-video correlation.","After that, we propose a novel expert translation method that employs the latent-based VDMs to further upsample the low-resolution video to high resolution.","Compared to latent VDMs, Show-1 can produce high-quality videos of precise text-video alignment; Compared to pixel VDMs, Show-1 is much more efficient (GPU memory usage during inference is 15G vs 72G).","We also validate our model on standard video generation benchmarks.","Our code and model weights are publicly available at \\url{https://github.com/showlab/Show-1}."],"url":"http://arxiv.org/abs/2309.15818v1"}
{"created":"2023-09-27 17:36:19","title":"Convolutional Networks with Oriented 1D Kernels","abstract":"In computer vision, 2D convolution is arguably the most important operation performed by a ConvNet. Unsurprisingly, it has been the focus of intense software and hardware optimization and enjoys highly efficient implementations. In this work, we ask an intriguing question: can we make a ConvNet work without 2D convolutions? Surprisingly, we find that the answer is yes -- we show that a ConvNet consisting entirely of 1D convolutions can do just as well as 2D on ImageNet classification. Specifically, we find that one key ingredient to a high-performing 1D ConvNet is oriented 1D kernels: 1D kernels that are oriented not just horizontally or vertically, but also at other angles. Our experiments show that oriented 1D convolutions can not only replace 2D convolutions but also augment existing architectures with large kernels, leading to improved accuracy with minimal FLOPs increase. A key contribution of this work is a highly-optimized custom CUDA implementation of oriented 1D kernels, specialized to the depthwise convolution setting. Our benchmarks demonstrate that our custom CUDA implementation almost perfectly realizes the theoretical advantage of 1D convolution: it is faster than a native horizontal convolution for any arbitrary angle. Code is available at https://github.com/princeton-vl/Oriented1D.","sentences":["In computer vision, 2D convolution is arguably the most important operation performed by a ConvNet.","Unsurprisingly, it has been the focus of intense software and hardware optimization and enjoys highly efficient implementations.","In this work, we ask an intriguing question: can we make a ConvNet work without 2D convolutions?","Surprisingly, we find that the answer is yes -- we show that a ConvNet consisting entirely of 1D convolutions can do just as well as 2D on ImageNet classification.","Specifically, we find that one key ingredient to a high-performing 1D ConvNet is oriented 1D kernels: 1D kernels that are oriented not just horizontally or vertically, but also at other angles.","Our experiments show that oriented 1D convolutions can not only replace 2D convolutions but also augment existing architectures with large kernels, leading to improved accuracy with minimal FLOPs increase.","A key contribution of this work is a highly-optimized custom CUDA implementation of oriented 1D kernels, specialized to the depthwise convolution setting.","Our benchmarks demonstrate that our custom CUDA implementation almost perfectly realizes the theoretical advantage of 1D convolution: it is faster than a native horizontal convolution for any arbitrary angle.","Code is available at https://github.com/princeton-vl/Oriented1D."],"url":"http://arxiv.org/abs/2309.15812v1"}
{"created":"2023-09-27 17:34:13","title":"Fair Canonical Correlation Analysis","abstract":"This paper investigates fairness and bias in Canonical Correlation Analysis (CCA), a widely used statistical technique for examining the relationship between two sets of variables. We present a framework that alleviates unfairness by minimizing the correlation disparity error associated with protected attributes. Our approach enables CCA to learn global projection matrices from all data points while ensuring that these matrices yield comparable correlation levels to group-specific projection matrices. Experimental evaluation on both synthetic and real-world datasets demonstrates the efficacy of our method in reducing correlation disparity error without compromising CCA accuracy.","sentences":["This paper investigates fairness and bias in Canonical Correlation Analysis (CCA), a widely used statistical technique for examining the relationship between two sets of variables.","We present a framework that alleviates unfairness by minimizing the correlation disparity error associated with protected attributes.","Our approach enables CCA to learn global projection matrices from all data points while ensuring that these matrices yield comparable correlation levels to group-specific projection matrices.","Experimental evaluation on both synthetic and real-world datasets demonstrates the efficacy of our method in reducing correlation disparity error without compromising CCA accuracy."],"url":"http://arxiv.org/abs/2309.15809v1"}
{"created":"2023-09-27 17:30:19","title":"Emu: Enhancing Image Generation Models Using Photogenic Needles in a Haystack","abstract":"Training text-to-image models with web scale image-text pairs enables the generation of a wide range of visual concepts from text. However, these pre-trained models often face challenges when it comes to generating highly aesthetic images. This creates the need for aesthetic alignment post pre-training. In this paper, we propose quality-tuning to effectively guide a pre-trained model to exclusively generate highly visually appealing images, while maintaining generality across visual concepts. Our key insight is that supervised fine-tuning with a set of surprisingly small but extremely visually appealing images can significantly improve the generation quality. We pre-train a latent diffusion model on $1.1$ billion image-text pairs and fine-tune it with only a few thousand carefully selected high-quality images. The resulting model, Emu, achieves a win rate of $82.9\\%$ compared with its pre-trained only counterpart. Compared to the state-of-the-art SDXLv1.0, Emu is preferred $68.4\\%$ and $71.3\\%$ of the time on visual appeal on the standard PartiPrompts and our Open User Input benchmark based on the real-world usage of text-to-image models. In addition, we show that quality-tuning is a generic approach that is also effective for other architectures, including pixel diffusion and masked generative transformer models.","sentences":["Training text-to-image models with web scale image-text pairs enables the generation of a wide range of visual concepts from text.","However, these pre-trained models often face challenges when it comes to generating highly aesthetic images.","This creates the need for aesthetic alignment post pre-training.","In this paper, we propose quality-tuning to effectively guide a pre-trained model to exclusively generate highly visually appealing images, while maintaining generality across visual concepts.","Our key insight is that supervised fine-tuning with a set of surprisingly small but extremely visually appealing images can significantly improve the generation quality.","We pre-train a latent diffusion model on $1.1$ billion image-text pairs and fine-tune it with only a few thousand carefully selected high-quality images.","The resulting model, Emu, achieves a win rate of $82.9\\%$ compared with its pre-trained only counterpart.","Compared to the state-of-the-art SDXLv1.0, Emu is preferred $68.4\\%$ and $71.3\\%$ of the time on visual appeal on the standard PartiPrompts and our Open User Input benchmark based on the real-world usage of text-to-image models.","In addition, we show that quality-tuning is a generic approach that is also effective for other architectures, including pixel diffusion and masked generative transformer models."],"url":"http://arxiv.org/abs/2309.15807v1"}
{"created":"2023-09-27 17:29:41","title":"Lyra: Orchestrating Dual Correction in Automated Theorem Proving","abstract":"Large Language Models (LLMs) present an intriguing avenue for exploration in the field of formal theorem proving. Nevertheless, their full potential, particularly concerning the mitigation of hallucinations and refinement through prover error messages, remains an area that has yet to be thoroughly investigated. To enhance the effectiveness of LLMs in the field, we introduce the Lyra, a new framework that employs two distinct correction mechanisms: Tool Correction (TC) and Conjecture Correction (CC). To implement Tool Correction in the post-processing of formal proofs, we leverage prior knowledge to utilize predefined prover tools (e.g., Sledgehammer) for guiding the replacement of incorrect tools. Tool Correction significantly contributes to mitigating hallucinations, thereby improving the overall accuracy of the proof. In addition, we introduce Conjecture Correction, an error feedback mechanism designed to interact with prover to refine formal proof conjectures with prover error messages. Compared to the previous refinement framework, the proposed Conjecture Correction refines generation with instruction but does not collect paired (generation, error & refinement) prompts. Our method has achieved state-of-the-art (SOTA) performance on both miniF2F validation (48.0% -> 55.3%) and test (45.5% -> 51.2%). We also present 3 IMO problems solved by Lyra. We believe Tool Correction (post-process for hallucination mitigation) and Conjecture Correction (subgoal adjustment from interaction with environment) could provide a promising avenue for future research in this field.","sentences":["Large Language Models (LLMs) present an intriguing avenue for exploration in the field of formal theorem proving.","Nevertheless, their full potential, particularly concerning the mitigation of hallucinations and refinement through prover error messages, remains an area that has yet to be thoroughly investigated.","To enhance the effectiveness of LLMs in the field, we introduce the Lyra, a new framework that employs two distinct correction mechanisms: Tool Correction (TC) and Conjecture Correction (CC).","To implement Tool Correction in the post-processing of formal proofs, we leverage prior knowledge to utilize predefined prover tools (e.g., Sledgehammer) for guiding the replacement of incorrect tools.","Tool Correction significantly contributes to mitigating hallucinations, thereby improving the overall accuracy of the proof.","In addition, we introduce Conjecture Correction, an error feedback mechanism designed to interact with prover to refine formal proof conjectures with prover error messages.","Compared to the previous refinement framework, the proposed Conjecture Correction refines generation with instruction but does not collect paired (generation, error & refinement) prompts.","Our method has achieved state-of-the-art (SOTA) performance on both miniF2F validation (48.0% -> 55.3%) and test (45.5% -> 51.2%).","We also present 3 IMO problems solved by Lyra.","We believe Tool Correction (post-process for hallucination mitigation) and Conjecture Correction (subgoal adjustment from interaction with environment) could provide a promising avenue for future research in this field."],"url":"http://arxiv.org/abs/2309.15806v1"}
{"created":"2023-09-27 17:21:13","title":"Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study","abstract":"Speech signals, typically sampled at rates in the tens of thousands per second, contain redundancies, evoking inefficiencies in sequence modeling. High-dimensional speech features such as spectrograms are often used as the input for the subsequent model. However, they can still be redundant. Recent investigations proposed the use of discrete speech units derived from self-supervised learning representations, which significantly compresses the size of speech data. Applying various methods, such as de-duplication and subword modeling, can further compress the speech sequence length. Hence, training time is significantly reduced while retaining notable performance. In this study, we undertake a comprehensive and systematic exploration into the application of discrete units within end-to-end speech processing models. Experiments on 12 automatic speech recognition, 3 speech translation, and 1 spoken language understanding corpora demonstrate that discrete units achieve reasonably good results in almost all the settings. We intend to release our configurations and trained models to foster future research efforts.","sentences":["Speech signals, typically sampled at rates in the tens of thousands per second, contain redundancies, evoking inefficiencies in sequence modeling.","High-dimensional speech features such as spectrograms are often used as the input for the subsequent model.","However, they can still be redundant.","Recent investigations proposed the use of discrete speech units derived from self-supervised learning representations, which significantly compresses the size of speech data.","Applying various methods, such as de-duplication and subword modeling, can further compress the speech sequence length.","Hence, training time is significantly reduced while retaining notable performance.","In this study, we undertake a comprehensive and systematic exploration into the application of discrete units within end-to-end speech processing models.","Experiments on 12 automatic speech recognition, 3 speech translation, and 1 spoken language understanding corpora demonstrate that discrete units achieve reasonably good results in almost all the settings.","We intend to release our configurations and trained models to foster future research efforts."],"url":"http://arxiv.org/abs/2309.15800v1"}
{"created":"2023-09-27 17:16:32","title":"Node-Aligned Graph-to-Graph Generation for Retrosynthesis Prediction","abstract":"Single-step retrosynthesis is a crucial task in organic chemistry and drug design, requiring the identification of required reactants to synthesize a specific compound. with the advent of computer-aided synthesis planning, there is growing interest in using machine-learning techniques to facilitate the process. Existing template-free machine learning-based models typically utilize transformer structures and represent molecules as ID sequences. However, these methods often face challenges in fully leveraging the extensive topological information of the molecule and aligning atoms between the production and reactants, leading to results that are not as competitive as those of semi-template models. Our proposed method, Node-Aligned Graph-to-Graph (NAG2G), also serves as a transformer-based template-free model but utilizes 2D molecular graphs and 3D conformation information. Furthermore, our approach simplifies the incorporation of production-reactant atom mapping alignment by leveraging node alignment to determine a specific order for node generation and generating molecular graphs in an auto-regressive manner node-by-node. This method ensures that the node generation order coincides with the node order in the input graph, overcoming the difficulty of determining a specific node generation order in an auto-regressive manner. Our extensive benchmarking results demonstrate that the proposed NAG2G can outperform the previous state-of-the-art baselines in various metrics.","sentences":["Single-step retrosynthesis is a crucial task in organic chemistry and drug design, requiring the identification of required reactants to synthesize a specific compound.","with the advent of computer-aided synthesis planning, there is growing interest in using machine-learning techniques to facilitate the process.","Existing template-free machine learning-based models typically utilize transformer structures and represent molecules as ID sequences.","However, these methods often face challenges in fully leveraging the extensive topological information of the molecule and aligning atoms between the production and reactants, leading to results that are not as competitive as those of semi-template models.","Our proposed method, Node-Aligned Graph-to-Graph (NAG2G), also serves as a transformer-based template-free model but utilizes 2D molecular graphs and 3D conformation information.","Furthermore, our approach simplifies the incorporation of production-reactant atom mapping alignment by leveraging node alignment to determine a specific order for node generation and generating molecular graphs in an auto-regressive manner node-by-node.","This method ensures that the node generation order coincides with the node order in the input graph, overcoming the difficulty of determining a specific node generation order in an auto-regressive manner.","Our extensive benchmarking results demonstrate that the proposed NAG2G can outperform the previous state-of-the-art baselines in various metrics."],"url":"http://arxiv.org/abs/2309.15798v1"}
{"created":"2023-09-27 17:09:36","title":"Some Efficient and Optimal K-Norm Mechanisms","abstract":"A differentially private computation often begins with a bound on a $d$-dimensional statistic's $\\ell_p$ sensitivity. The $K$-norm mechanism can yield more accurate additive noise by using a statistic-specific (and possibly non-$\\ell_p$) norm. However, sampling such mechanisms requires sampling from the corresponding norm balls. These are $d$-dimensional convex polytopes, and the fastest known general algorithm for approximately sampling such polytopes takes time $\\tilde O(d^{3+\\omega})$, where $\\omega \\geq 2$ is the matrix multiplication exponent. For the simple problems of sum and ranked vote, this paper constructs samplers that run in time $\\tilde O(d^2)$. More broadly, we suggest that problem-specific $K$-norm mechanisms may be an overlooked practical tool for private additive noise.","sentences":["A differentially private computation often begins with a bound on a $d$-dimensional statistic's $\\ell_p$ sensitivity.","The $K$-norm mechanism can yield more accurate additive noise by using a statistic-specific (and possibly non-$\\ell_p$) norm.","However, sampling such mechanisms requires sampling from the corresponding norm balls.","These are $d$-dimensional convex polytopes, and the fastest known general algorithm for approximately sampling such polytopes takes time $\\tilde O(d^{3+\\omega})$, where $\\omega \\geq 2$ is the matrix multiplication exponent.","For the simple problems of sum and ranked vote, this paper constructs samplers that run in time $\\tilde O(d^2)$. More broadly, we suggest that problem-specific $K$-norm mechanisms may be an overlooked practical tool for private additive noise."],"url":"http://arxiv.org/abs/2309.15790v1"}
{"created":"2023-09-27 17:08:40","title":"Large Language Model Routing with Benchmark Datasets","abstract":"There is a rapidly growing number of open-source Large Language Models (LLMs) and benchmark datasets to compare them. While some models dominate these benchmarks, no single model typically achieves the best accuracy in all tasks and use cases. In this work, we address the challenge of selecting the best LLM out of a collection of models for new tasks. We propose a new formulation for the problem, in which benchmark datasets are repurposed to learn a \"router\" model for this LLM selection, and we show that this problem can be reduced to a collection of binary classification tasks. We demonstrate the utility and limitations of learning model routers from various benchmark datasets, where we consistently improve performance upon using any single model for all tasks.","sentences":["There is a rapidly growing number of open-source Large Language Models (LLMs) and benchmark datasets to compare them.","While some models dominate these benchmarks, no single model typically achieves the best accuracy in all tasks and use cases.","In this work, we address the challenge of selecting the best LLM out of a collection of models for new tasks.","We propose a new formulation for the problem, in which benchmark datasets are repurposed to learn a \"router\" model for this LLM selection, and we show that this problem can be reduced to a collection of binary classification tasks.","We demonstrate the utility and limitations of learning model routers from various benchmark datasets, where we consistently improve performance upon using any single model for all tasks."],"url":"http://arxiv.org/abs/2309.15789v1"}
{"created":"2023-09-27 17:04:22","title":"Partial Transport for Point-Cloud Registration","abstract":"Point cloud registration plays a crucial role in various fields, including robotics, computer graphics, and medical imaging. This process involves determining spatial relationships between different sets of points, typically within a 3D space. In real-world scenarios, complexities arise from non-rigid movements and partial visibility, such as occlusions or sensor noise, making non-rigid registration a challenging problem. Classic non-rigid registration methods are often computationally demanding, suffer from unstable performance, and, importantly, have limited theoretical guarantees. The optimal transport problem and its unbalanced variations (e.g., the optimal partial transport problem) have emerged as powerful tools for point-cloud registration, establishing a strong benchmark in this field. These methods view point clouds as empirical measures and provide a mathematically rigorous way to quantify the `correspondence' between (the transformed) source and target points. In this paper, we approach the point-cloud registration problem through the lens of optimal transport theory and first propose a comprehensive set of non-rigid registration methods based on the optimal partial transportation problem. Subsequently, leveraging the emerging work on efficient solutions to the one-dimensional optimal partial transport problem, we extend our proposed algorithms via slicing to gain significant computational efficiency, resulting in fast and robust non-rigid registration algorithms. We demonstrate the effectiveness of our proposed methods and compare them against baselines on various 3D and 2D non-rigid registration problems where the source and target point clouds are corrupted by random noise.","sentences":["Point cloud registration plays a crucial role in various fields, including robotics, computer graphics, and medical imaging.","This process involves determining spatial relationships between different sets of points, typically within a 3D space.","In real-world scenarios, complexities arise from non-rigid movements and partial visibility, such as occlusions or sensor noise, making non-rigid registration a challenging problem.","Classic non-rigid registration methods are often computationally demanding, suffer from unstable performance, and, importantly, have limited theoretical guarantees.","The optimal transport problem and its unbalanced variations (e.g., the optimal partial transport problem) have emerged as powerful tools for point-cloud registration, establishing a strong benchmark in this field.","These methods view point clouds as empirical measures and provide a mathematically rigorous way to quantify the `correspondence' between (the transformed) source and target points.","In this paper, we approach the point-cloud registration problem through the lens of optimal transport theory and first propose a comprehensive set of non-rigid registration methods based on the optimal partial transportation problem.","Subsequently, leveraging the emerging work on efficient solutions to the one-dimensional optimal partial transport problem, we extend our proposed algorithms via slicing to gain significant computational efficiency, resulting in fast and robust non-rigid registration algorithms.","We demonstrate the effectiveness of our proposed methods and compare them against baselines on various 3D and 2D non-rigid registration problems where the source and target point clouds are corrupted by random noise."],"url":"http://arxiv.org/abs/2309.15787v1"}
{"created":"2023-09-27 16:59:15","title":"Model-based design of temporal analysis for products (TAP) reactors: A simulated case study in oxidative propane dehydrogenation","abstract":"Temporal analysis of products (TAP) reactors enable experiments that probe numerous kinetic processes within a single set of experimental data through variations in pulse intensity, delay, or temperature. Selecting additional TAP experiments often involves arbitrary selection of reaction conditions or the use of chemical intuition. To make experiment selection in TAP more robust, we explore the efficacy of model-based design of experiments (MBDoE) for precision in TAP reactor kinetic modeling. We successfully applied this approach to a case study of synthetic oxidative propane dehydrogenation (OPDH) that involves pulses of propane and oxygen. We found that experiments identified as optimal through the MBDoE for precision generally reduce parameter uncertainties to a higher degree than alternative experiments. The performance of MBDoE for model divergence was also explored for OPDH, with the relevant active sites (catalyst structure) being unknown. An experiment that maximized the divergence between the three proposed mechanisms was identified and led to clear mechanism discrimination. However, re-optimization of kinetic parameters eliminated the ability to discriminate. The findings yield insight into the prospects and limitations of MBDoE for TAP and transient kinetic experiments.","sentences":["Temporal analysis of products (TAP) reactors enable experiments that probe numerous kinetic processes within a single set of experimental data through variations in pulse intensity, delay, or temperature.","Selecting additional TAP experiments often involves arbitrary selection of reaction conditions or the use of chemical intuition.","To make experiment selection in TAP more robust, we explore the efficacy of model-based design of experiments (MBDoE) for precision in TAP reactor kinetic modeling.","We successfully applied this approach to a case study of synthetic oxidative propane dehydrogenation (OPDH) that involves pulses of propane and oxygen.","We found that experiments identified as optimal through the MBDoE for precision generally reduce parameter uncertainties to a higher degree than alternative experiments.","The performance of MBDoE for model divergence was also explored for OPDH, with the relevant active sites (catalyst structure) being unknown.","An experiment that maximized the divergence between the three proposed mechanisms was identified and led to clear mechanism discrimination.","However, re-optimization of kinetic parameters eliminated the ability to discriminate.","The findings yield insight into the prospects and limitations of MBDoE for TAP and transient kinetic experiments."],"url":"http://arxiv.org/abs/2309.15786v1"}
{"created":"2023-09-27 16:58:35","title":"One For All: Video Conversation is Feasible Without Video Instruction Tuning","abstract":"The recent progress in Large Language Models (LLM) has spurred various advancements in image-language conversation agents, while how to build a proficient video-based dialogue system is still under exploration. Considering the extensive scale of LLM and visual backbone, minimal GPU memory is left for facilitating effective temporal modeling, which is crucial for comprehending and providing feedback on videos. To this end, we propose Branching Temporal Adapter (BT-Adapter), a novel method for extending image-language pretrained models into the video domain. Specifically, BT-Adapter serves as a plug-and-use temporal modeling branch alongside the pretrained visual encoder, which is tuned while keeping the backbone frozen. Just pretrained once, BT-Adapter can be seamlessly integrated into all image conversation models using this version of CLIP, enabling video conversations without the need for video instructions. Besides, we develop a unique asymmetric token masking strategy inside the branch with tailor-made training tasks for BT-Adapter, facilitating faster convergence and better results. Thanks to BT-Adapter, we are able to empower existing multimodal dialogue models with strong video understanding capabilities without incurring excessive GPU costs. Without bells and whistles, BT-Adapter achieves (1) state-of-the-art zero-shot results on various video tasks using thousands of fewer GPU hours. (2) better performance than current video chatbots without any video instruction tuning. (3) state-of-the-art results of video chatting using video instruction tuning, outperforming previous SOTAs by a large margin.","sentences":["The recent progress in Large Language Models (LLM) has spurred various advancements in image-language conversation agents, while how to build a proficient video-based dialogue system is still under exploration.","Considering the extensive scale of LLM and visual backbone, minimal GPU memory is left for facilitating effective temporal modeling, which is crucial for comprehending and providing feedback on videos.","To this end, we propose Branching Temporal Adapter (BT-Adapter), a novel method for extending image-language pretrained models into the video domain.","Specifically, BT-Adapter serves as a plug-and-use temporal modeling branch alongside the pretrained visual encoder, which is tuned while keeping the backbone frozen.","Just pretrained once, BT-Adapter can be seamlessly integrated into all image conversation models using this version of CLIP, enabling video conversations without the need for video instructions.","Besides, we develop a unique asymmetric token masking strategy inside the branch with tailor-made training tasks for BT-Adapter, facilitating faster convergence and better results.","Thanks to BT-Adapter, we are able to empower existing multimodal dialogue models with strong video understanding capabilities without incurring excessive GPU costs.","Without bells and whistles, BT-Adapter achieves (1) state-of-the-art zero-shot results on various video tasks using thousands of fewer GPU hours.","(2) better performance than current video chatbots without any video instruction tuning.","(3) state-of-the-art results of video chatting using video instruction tuning, outperforming previous SOTAs by a large margin."],"url":"http://arxiv.org/abs/2309.15785v1"}
{"created":"2023-09-27 16:58:16","title":"Gaussian Process-Enhanced, External and Internal Convertible (EIC) Form-Based Control of Underactuated Balance Robots","abstract":"External and internal convertible (EIC) form-based motion control (i.e., EIC-based control) is one of the effective approaches for underactuated balance robots. By sequentially controller design, trajectory tracking of the actuated subsystem and balance of the unactuated subsystem can be achieved simultaneously. However, with certain conditions, there exists uncontrolled robot motion under the EIC-based control. We first identify these conditions and then propose an enhanced EIC-based control with a Gaussian process data-driven robot dynamic model. Under the new enhanced EIC-based control, the stability and performance of the closed-loop system is guaranteed. We demonstrate the GP-enhanced EIC-based control experimentally using two examples of underactuated balance robots.","sentences":["External and internal convertible (EIC) form-based motion control (i.e., EIC-based control) is one of the effective approaches for underactuated balance robots.","By sequentially controller design, trajectory tracking of the actuated subsystem and balance of the unactuated subsystem can be achieved simultaneously.","However, with certain conditions, there exists uncontrolled robot motion under the EIC-based control.","We first identify these conditions and then propose an enhanced EIC-based control with a Gaussian process data-driven robot dynamic model.","Under the new enhanced EIC-based control, the stability and performance of the closed-loop system is guaranteed.","We demonstrate the GP-enhanced EIC-based control experimentally using two examples of underactuated balance robots."],"url":"http://arxiv.org/abs/2309.15784v1"}
{"created":"2023-09-27 16:57:04","title":"Joint-YODNet: A Light-weight Object Detector for UAVs to Achieve Above 100fps","abstract":"Small object detection via UAV (Unmanned Aerial Vehicle) images captured from drones and radar is a complex task with several formidable challenges. This domain encompasses numerous complexities that impede the accurate detection and localization of small objects. To address these challenges, we propose a novel method called JointYODNet for UAVs to detect small objects, leveraging a joint loss function specifically designed for this task. Our method revolves around the development of a joint loss function tailored to enhance the detection performance of small objects. Through extensive experimentation on a diverse dataset of UAV images captured under varying environmental conditions, we evaluated different variations of the loss function and determined the most effective formulation. The results demonstrate that our proposed joint loss function outperforms existing methods in accurately localizing small objects. Specifically, our method achieves a recall of 0.971, and a F1Score of 0.975, surpassing state-of-the-art techniques. Additionally, our method achieves a mAP@.5(%) of 98.6, indicating its robustness in detecting small objects across varying scales","sentences":["Small object detection via UAV (Unmanned Aerial Vehicle) images captured from drones and radar is a complex task with several formidable challenges.","This domain encompasses numerous complexities that impede the accurate detection and localization of small objects.","To address these challenges, we propose a novel method called JointYODNet for UAVs to detect small objects, leveraging a joint loss function specifically designed for this task.","Our method revolves around the development of a joint loss function tailored to enhance the detection performance of small objects.","Through extensive experimentation on a diverse dataset of UAV images captured under varying environmental conditions, we evaluated different variations of the loss function and determined the most effective formulation.","The results demonstrate that our proposed joint loss function outperforms existing methods in accurately localizing small objects.","Specifically, our method achieves a recall of 0.971, and a F1Score of 0.975, surpassing state-of-the-art techniques.","Additionally, our method achieves a mAP@.5(%) of 98.6, indicating its robustness in detecting small objects across varying scales"],"url":"http://arxiv.org/abs/2309.15782v1"}
{"created":"2023-09-27 16:54:38","title":"AaP-ReID: Improved Attention-Aware Person Re-identification","abstract":"Person re-identification (ReID) is a well-known problem in the field of computer vision. The primary objective is to identify a specific individual within a gallery of images. However, this task is challenging due to various factors, such as pose variations, illumination changes, obstructions, and the presence ofconfusing backgrounds. Existing ReID methods often fail to capture discriminative features (e.g., head, shoes, backpacks) and instead capture irrelevant features when the target is occluded. Motivated by the success of part-based and attention-based ReID methods, we improve AlignedReID++ and present AaP-ReID, a more effective method for person ReID that incorporates channel-wise attention into a ResNet-based architecture. Our method incorporates the Channel-Wise Attention Bottleneck (CWAbottleneck) block and can learn discriminating features by dynamically adjusting the importance ofeach channel in the feature maps. We evaluated Aap-ReID on three benchmark datasets: Market-1501, DukeMTMC-reID, and CUHK03. When compared with state-of-the-art person ReID methods, we achieve competitive results with rank-1 accuracies of 95.6% on Market-1501, 90.6% on DukeMTMC-reID, and 82.4% on CUHK03.","sentences":["Person re-identification (ReID) is a well-known problem in the field of computer vision.","The primary objective is to identify a specific individual within a gallery of images.","However, this task is challenging due to various factors, such as pose variations, illumination changes, obstructions, and the presence ofconfusing backgrounds.","Existing ReID methods often fail to capture discriminative features (e.g., head, shoes, backpacks) and instead capture irrelevant features when the target is occluded.","Motivated by the success of part-based and attention-based ReID methods, we improve AlignedReID++ and present AaP-ReID, a more effective method for person ReID that incorporates channel-wise attention into a ResNet-based architecture.","Our method incorporates the Channel-Wise Attention Bottleneck (CWAbottleneck) block and can learn discriminating features by dynamically adjusting the importance ofeach channel in the feature maps.","We evaluated Aap-ReID on three benchmark datasets: Market-1501, DukeMTMC-reID, and CUHK03.","When compared with state-of-the-art person ReID methods, we achieve competitive results with rank-1 accuracies of 95.6% on Market-1501, 90.6% on DukeMTMC-reID, and 82.4% on CUHK03."],"url":"http://arxiv.org/abs/2309.15780v1"}
{"created":"2023-09-27 16:53:11","title":"Question answering using deep learning in low resource Indian language Marathi","abstract":"Precise answers are extracted from a text for a given input question in a question answering system. Marathi question answering system is created in recent studies by using ontology, rule base and machine learning based approaches. Recently transformer models and transfer learning approaches are used to solve question answering challenges. In this paper we investigate different transformer models for creating a reading comprehension-based Marathi question answering system. We have experimented on different pretrained Marathi language multilingual and monolingual models like Multilingual Representations for Indian Languages (MuRIL), MahaBERT, Indic Bidirectional Encoder Representations from Transformers (IndicBERT) and fine-tuned it on a Marathi reading comprehension-based data set. We got the best accuracy in a MuRIL multilingual model with an EM score of 0.64 and F1 score of 0.74 by fine tuning the model on the Marathi dataset.","sentences":["Precise answers are extracted from a text for a given input question in a question answering system.","Marathi question answering system is created in recent studies by using ontology, rule base and machine learning based approaches.","Recently transformer models and transfer learning approaches are used to solve question answering challenges.","In this paper we investigate different transformer models for creating a reading comprehension-based Marathi question answering system.","We have experimented on different pretrained Marathi language multilingual and monolingual models like Multilingual Representations for Indian Languages (MuRIL), MahaBERT, Indic Bidirectional Encoder Representations from Transformers (IndicBERT) and fine-tuned it on a Marathi reading comprehension-based data set.","We got the best accuracy in a MuRIL multilingual model with an EM score of 0.64 and F1 score of 0.74 by fine tuning the model on the Marathi dataset."],"url":"http://arxiv.org/abs/2309.15779v1"}
{"created":"2023-09-27 16:50:47","title":"Time-Domain Channel Measurements and Small-Scale Fading Characterization for RIS-Assisted Wireless Communication Systems","abstract":"As a potentially revolutionary enabling technology for the sixth generation (6G) mobile communication system, reconfigurable intelligent surfaces (RISs) have attracted extensive attention from industry and academia. In RIS-assisted wireless communication systems, practical channel measurements and modeling serve as the foundation for system design, network optimization, and performance evaluation. In this paper, a RIS time-domain channel measurement system, based on a software defined radio (SDR) platform, is developed for the first time to investigate the small-scale fading characteristics of RIS-assisted channels. We present RIS channel measurements in corridor and laboratory scenarios and compare the power delay profile (PDP) of the channel without RIS, with RIS specular reflection, and with RIS intelligent reflection. The multipath component parameters and cluster parameters based on the Saleh-Valenzuela model are extracted. We find that the PDPs of the RIS-assisted channel fit the power-law decay model and approximate the law of square decay. Through intelligent reflection, the RIS can decrease the delay and concentrate the energy of the virtual line-of-sight (VLOS) path, thereby reducing delay spread and mitigating multipath fading. Furthermore, the cluster characteristics of RIS-assisted channels are highly related to the measurement environment. In the laboratory scenario, a single cluster dominated by the VLOS path with smooth envelope is observed. On the other hand, in the corridor scenario, some additional clusters introduced by the RIS reflection are created.","sentences":["As a potentially revolutionary enabling technology for the sixth generation (6G) mobile communication system, reconfigurable intelligent surfaces (RISs) have attracted extensive attention from industry and academia.","In RIS-assisted wireless communication systems, practical channel measurements and modeling serve as the foundation for system design, network optimization, and performance evaluation.","In this paper, a RIS time-domain channel measurement system, based on a software defined radio (SDR) platform, is developed for the first time to investigate the small-scale fading characteristics of RIS-assisted channels.","We present RIS channel measurements in corridor and laboratory scenarios and compare the power delay profile (PDP) of the channel without RIS, with RIS specular reflection, and with RIS intelligent reflection.","The multipath component parameters and cluster parameters based on the Saleh-Valenzuela model are extracted.","We find that the PDPs of the RIS-assisted channel fit the power-law decay model and approximate the law of square decay.","Through intelligent reflection, the RIS can decrease the delay and concentrate the energy of the virtual line-of-sight (VLOS) path, thereby reducing delay spread and mitigating multipath fading.","Furthermore, the cluster characteristics of RIS-assisted channels are highly related to the measurement environment.","In the laboratory scenario, a single cluster dominated by the VLOS path with smooth envelope is observed.","On the other hand, in the corridor scenario, some additional clusters introduced by the RIS reflection are created."],"url":"http://arxiv.org/abs/2309.15776v1"}
{"created":"2023-09-27 16:49:37","title":"Learning the Efficient Frontier","abstract":"The efficient frontier (EF) is a fundamental resource allocation problem where one has to find an optimal portfolio maximizing a reward at a given level of risk. This optimal solution is traditionally found by solving a convex optimization problem. In this paper, we introduce NeuralEF: a fast neural approximation framework that robustly forecasts the result of the EF convex optimization problem with respect to heterogeneous linear constraints and variable number of optimization inputs. By reformulating an optimization problem as a sequence to sequence problem, we show that NeuralEF is a viable solution to accelerate large-scale simulation while handling discontinuous behavior.","sentences":["The efficient frontier (EF) is a fundamental resource allocation problem where one has to find an optimal portfolio maximizing a reward at a given level of risk.","This optimal solution is traditionally found by solving a convex optimization problem.","In this paper, we introduce NeuralEF: a fast neural approximation framework that robustly forecasts the result of the EF convex optimization problem with respect to heterogeneous linear constraints and variable number of optimization inputs.","By reformulating an optimization problem as a sequence to sequence problem, we show that NeuralEF is a viable solution to accelerate large-scale simulation while handling discontinuous behavior."],"url":"http://arxiv.org/abs/2309.15775v1"}
{"created":"2023-09-27 16:42:10","title":"Importance-Weighted Offline Learning Done Right","abstract":"We study the problem of offline policy optimization in stochastic contextual bandit problems, where the goal is to learn a near-optimal policy based on a dataset of decision data collected by a suboptimal behavior policy. Rather than making any structural assumptions on the reward function, we assume access to a given policy class and aim to compete with the best comparator policy within this class. In this setting, a standard approach is to compute importance-weighted estimators of the value of each policy, and select a policy that minimizes the estimated value up to a \"pessimistic\" adjustment subtracted from the estimates to reduce their random fluctuations. In this paper, we show that a simple alternative approach based on the \"implicit exploration\" estimator of \\citet{Neu2015} yields performance guarantees that are superior in nearly all possible terms to all previous results. Most notably, we remove an extremely restrictive \"uniform coverage\" assumption made in all previous works. These improvements are made possible by the observation that the upper and lower tails importance-weighted estimators behave very differently from each other, and their careful control can massively improve on previous results that were all based on symmetric two-sided concentration inequalities. We also extend our results to infinite policy classes in a PAC-Bayesian fashion, and showcase the robustness of our algorithm to the choice of hyper-parameters by means of numerical simulations.","sentences":["We study the problem of offline policy optimization in stochastic contextual bandit problems, where the goal is to learn a near-optimal policy based on a dataset of decision data collected by a suboptimal behavior policy.","Rather than making any structural assumptions on the reward function, we assume access to a given policy class and aim to compete with the best comparator policy within this class.","In this setting, a standard approach is to compute importance-weighted estimators of the value of each policy, and select a policy that minimizes the estimated value up to a \"pessimistic\" adjustment subtracted from the estimates to reduce their random fluctuations.","In this paper, we show that a simple alternative approach based on the \"implicit exploration\" estimator of \\citet{Neu2015} yields performance guarantees that are superior in nearly all possible terms to all previous results.","Most notably, we remove an extremely restrictive \"uniform coverage\" assumption made in all previous works.","These improvements are made possible by the observation that the upper and lower tails importance-weighted estimators behave very differently from each other, and their careful control can massively improve on previous results that were all based on symmetric two-sided concentration inequalities.","We also extend our results to infinite policy classes in a PAC-Bayesian fashion, and showcase the robustness of our algorithm to the choice of hyper-parameters by means of numerical simulations."],"url":"http://arxiv.org/abs/2309.15771v1"}
{"created":"2023-09-27 16:42:06","title":"Generating Transferable Adversarial Simulation Scenarios for Self-Driving via Neural Rendering","abstract":"Self-driving software pipelines include components that are learned from a significant number of training examples, yet it remains challenging to evaluate the overall system's safety and generalization performance. Together with scaling up the real-world deployment of autonomous vehicles, it is of critical importance to automatically find simulation scenarios where the driving policies will fail. We propose a method that efficiently generates adversarial simulation scenarios for autonomous driving by solving an optimal control problem that aims to maximally perturb the policy from its nominal trajectory.   Given an image-based driving policy, we show that we can inject new objects in a neural rendering representation of the deployment scene, and optimize their texture in order to generate adversarial sensor inputs to the policy. We demonstrate that adversarial scenarios discovered purely in the neural renderer (surrogate scene) can often be successfully transferred to the deployment scene, without further optimization. We demonstrate this transfer occurs both in simulated and real environments, provided the learned surrogate scene is sufficiently close to the deployment scene.","sentences":["Self-driving software pipelines include components that are learned from a significant number of training examples, yet it remains challenging to evaluate the overall system's safety and generalization performance.","Together with scaling up the real-world deployment of autonomous vehicles, it is of critical importance to automatically find simulation scenarios where the driving policies will fail.","We propose a method that efficiently generates adversarial simulation scenarios for autonomous driving by solving an optimal control problem that aims to maximally perturb the policy from its nominal trajectory.   ","Given an image-based driving policy, we show that we can inject new objects in a neural rendering representation of the deployment scene, and optimize their texture in order to generate adversarial sensor inputs to the policy.","We demonstrate that adversarial scenarios discovered purely in the neural renderer (surrogate scene) can often be successfully transferred to the deployment scene, without further optimization.","We demonstrate this transfer occurs both in simulated and real environments, provided the learned surrogate scene is sufficiently close to the deployment scene."],"url":"http://arxiv.org/abs/2309.15770v1"}
{"created":"2023-09-27 16:37:05","title":"AI in Software Engineering: Case Studies and Prospects","abstract":"Artificial intelligence (AI) and software engineering (SE) are two important areas in computer science. In recent years, researchers are trying to apply AI techniques in various stages of software development to improve the overall quality of software products. Moreover, there are also some researchers focus on the intersection between SE and AI. In fact, the relationship between SE and AI is very weak; however, methods and techniques in one area have been adopted in another area. More and more software products are capable of performing intelligent behaviour like human beings. In this paper, two cases studies which are IBM Watson and Google AlphaGo that use different AI techniques in solving real world challenging problems have been analysed, evaluated and compared. Based on the analysis of both case studies, using AI techniques such as deep learning and machine learning in software systems contributes to intelligent systems. Watson adopts 'decision making support' strategy to help human make decisions; whereas AlphaGo uses 'self-decision making' to choose operations that contribute to the best outcome. In addition, Watson learns from man-made resources such as paper; AlphaGo, on the other hand, learns from massive online resources such as photos. AlphaGo uses neural networks and reinforcement learning to mimic human brain, which might be very useful in medical research for diagnosis and treatment. However, there is still a long way to go if we want to reproduce human brain in machine and view computers as thinkers, because human brain and machines are intrinsically different. It would be more promising to see whether computers and software systems will become more and more intelligent to help with real world challenging problems that human beings cannot do.","sentences":["Artificial intelligence (AI) and software engineering (SE) are two important areas in computer science.","In recent years, researchers are trying to apply AI techniques in various stages of software development to improve the overall quality of software products.","Moreover, there are also some researchers focus on the intersection between SE and AI.","In fact, the relationship between SE and AI is very weak; however, methods and techniques in one area have been adopted in another area.","More and more software products are capable of performing intelligent behaviour like human beings.","In this paper, two cases studies which are IBM Watson and Google AlphaGo that use different AI techniques in solving real world challenging problems have been analysed, evaluated and compared.","Based on the analysis of both case studies, using AI techniques such as deep learning and machine learning in software systems contributes to intelligent systems.","Watson adopts 'decision making support' strategy to help human make decisions; whereas AlphaGo uses 'self-decision making' to choose operations that contribute to the best outcome.","In addition, Watson learns from man-made resources such as paper; AlphaGo, on the other hand, learns from massive online resources such as photos.","AlphaGo uses neural networks and reinforcement learning to mimic human brain, which might be very useful in medical research for diagnosis and treatment.","However, there is still a long way to go if we want to reproduce human brain in machine and view computers as thinkers, because human brain and machines are intrinsically different.","It would be more promising to see whether computers and software systems will become more and more intelligent to help with real world challenging problems that human beings cannot do."],"url":"http://arxiv.org/abs/2309.15768v1"}
{"created":"2023-09-27 16:24:11","title":"Consistency and Permission in Deontic Justification Logic","abstract":"Different notions of the consistency of obligations collapse in standard deontic logic. In justification logics, which feature explicit reasons for obligations, the situation is different. Their strength depends on a constant specification and on the available set of operations for combining different reasons. We present different consistency principles in justification logic and compare their logical strength. We propose a novel semantics for which justification logics with the explicit version of axiom D, jd, are complete for arbitrary constant specifications. Consistency is sometimes formulated in terms of permission. We therefore study permission in the context of justification logic, introducing a notion of free-choice permission for the first time. We then discuss the philosophical implications with regard to some deontic paradoxes.","sentences":["Different notions of the consistency of obligations collapse in standard deontic logic.","In justification logics, which feature explicit reasons for obligations, the situation is different.","Their strength depends on a constant specification and on the available set of operations for combining different reasons.","We present different consistency principles in justification logic and compare their logical strength.","We propose a novel semantics for which justification logics with the explicit version of axiom D, jd, are complete for arbitrary constant specifications.","Consistency is sometimes formulated in terms of permission.","We therefore study permission in the context of justification logic, introducing a notion of free-choice permission for the first time.","We then discuss the philosophical implications with regard to some deontic paradoxes."],"url":"http://arxiv.org/abs/2309.15763v1"}
{"created":"2023-09-27 16:20:39","title":"Rapid Network Adaptation: Learning to Adapt Neural Networks Using Test-Time Feedback","abstract":"We propose a method for adapting neural networks to distribution shifts at test-time. In contrast to training-time robustness mechanisms that attempt to anticipate and counter the shift, we create a closed-loop system and make use of a test-time feedback signal to adapt a network on the fly. We show that this loop can be effectively implemented using a learning-based function, which realizes an amortized optimizer for the network. This leads to an adaptation method, named Rapid Network Adaptation (RNA), that is notably more flexible and orders of magnitude faster than the baselines. Through a broad set of experiments using various adaptation signals and target tasks, we study the efficiency and flexibility of this method. We perform the evaluations using various datasets (Taskonomy, Replica, ScanNet, Hypersim, COCO, ImageNet), tasks (depth, optical flow, semantic segmentation, classification), and distribution shifts (Cross-datasets, 2D and 3D Common Corruptions) with promising results. We end with a discussion on general formulations for handling distribution shifts and our observations from comparing with similar approaches from other domains.","sentences":["We propose a method for adapting neural networks to distribution shifts at test-time.","In contrast to training-time robustness mechanisms that attempt to anticipate and counter the shift, we create a closed-loop system and make use of a test-time feedback signal to adapt a network on the fly.","We show that this loop can be effectively implemented using a learning-based function, which realizes an amortized optimizer for the network.","This leads to an adaptation method, named Rapid Network Adaptation (RNA), that is notably more flexible and orders of magnitude faster than the baselines.","Through a broad set of experiments using various adaptation signals and target tasks, we study the efficiency and flexibility of this method.","We perform the evaluations using various datasets (Taskonomy, Replica, ScanNet, Hypersim, COCO, ImageNet), tasks (depth, optical flow, semantic segmentation, classification), and distribution shifts (Cross-datasets, 2D and 3D Common Corruptions) with promising results.","We end with a discussion on general formulations for handling distribution shifts and our observations from comparing with similar approaches from other domains."],"url":"http://arxiv.org/abs/2309.15762v1"}
{"created":"2023-09-27 16:13:36","title":"Latent Graph Powered Semi-Supervised Learning on Biomedical Tabular Data","abstract":"In the domain of semi-supervised learning, the current approaches insufficiently exploit the potential of considering inter-instance relationships among (un)labeled data. In this work, we address this limitation by providing an approach for inferring latent graphs that capture the intrinsic data relationships. By leveraging graph-based representations, our approach facilitates the seamless propagation of information throughout the graph, enabling the effective incorporation of global and local knowledge. Through evaluations on biomedical tabular datasets, we compare the capabilities of our approach to other contemporary methods. Our work demonstrates the significance of inter-instance relationship discovery as practical means for constructing robust latent graphs to enhance semi-supervised learning techniques. Our method achieves state-of-the-art results on three biomedical datasets.","sentences":["In the domain of semi-supervised learning, the current approaches insufficiently exploit the potential of considering inter-instance relationships among (un)labeled data.","In this work, we address this limitation by providing an approach for inferring latent graphs that capture the intrinsic data relationships.","By leveraging graph-based representations, our approach facilitates the seamless propagation of information throughout the graph, enabling the effective incorporation of global and local knowledge.","Through evaluations on biomedical tabular datasets, we compare the capabilities of our approach to other contemporary methods.","Our work demonstrates the significance of inter-instance relationship discovery as practical means for constructing robust latent graphs to enhance semi-supervised learning techniques.","Our method achieves state-of-the-art results on three biomedical datasets."],"url":"http://arxiv.org/abs/2309.15757v1"}
{"created":"2023-09-27 16:12:17","title":"Development of a Whole-body Work Imitation Learning System by a Biped and Bi-armed Humanoid","abstract":"Imitation learning has been actively studied in recent years. In particular, skill acquisition by a robot with a fixed body, whose root link position and posture and camera angle of view do not change, has been realized in many cases. On the other hand, imitation of the behavior of robots with floating links, such as humanoid robots, is still a difficult task. In this study, we develop an imitation learning system using a biped robot with a floating link. There are two main problems in developing such a system. The first is a teleoperation device for humanoids, and the second is a control system that can withstand heavy workloads and long-term data collection. For the first point, we use the whole body control device TABLIS. It can control not only the arms but also the legs and can perform bilateral control with the robot. By connecting this TABLIS with the high-power humanoid robot JAXON, we construct a control system for imitation learning. For the second point, we will build a system that can collect long-term data based on posture optimization, and can simultaneously move the robot's limbs. We combine high-cycle posture generation with posture optimization methods, including whole-body joint torque minimization and contact force optimization. We designed an integrated system with the above two features to achieve various tasks through imitation learning. Finally, we demonstrate the effectiveness of this system by experiments of manipulating flexible fabrics such that not only the hands but also the head and waist move simultaneously, manipulating objects using legs characteristic of humanoids, and lifting heavy objects that require large forces.","sentences":["Imitation learning has been actively studied in recent years.","In particular, skill acquisition by a robot with a fixed body, whose root link position and posture and camera angle of view do not change, has been realized in many cases.","On the other hand, imitation of the behavior of robots with floating links, such as humanoid robots, is still a difficult task.","In this study, we develop an imitation learning system using a biped robot with a floating link.","There are two main problems in developing such a system.","The first is a teleoperation device for humanoids, and the second is a control system that can withstand heavy workloads and long-term data collection.","For the first point, we use the whole body control device TABLIS.","It can control not only the arms but also the legs and can perform bilateral control with the robot.","By connecting this TABLIS with the high-power humanoid robot JAXON, we construct a control system for imitation learning.","For the second point, we will build a system that can collect long-term data based on posture optimization, and can simultaneously move the robot's limbs.","We combine high-cycle posture generation with posture optimization methods, including whole-body joint torque minimization and contact force optimization.","We designed an integrated system with the above two features to achieve various tasks through imitation learning.","Finally, we demonstrate the effectiveness of this system by experiments of manipulating flexible fabrics such that not only the hands but also the head and waist move simultaneously, manipulating objects using legs characteristic of humanoids, and lifting heavy objects that require large forces."],"url":"http://arxiv.org/abs/2309.15756v1"}
{"created":"2023-09-27 16:12:07","title":"CAIT: Triple-Win Compression towards High Accuracy, Fast Inference, and Favorable Transferability For ViTs","abstract":"Vision Transformers (ViTs) have emerged as state-of-the-art models for various vision tasks recently. However, their heavy computation costs remain daunting for resource-limited devices. Consequently, researchers have dedicated themselves to compressing redundant information in ViTs for acceleration. However, they generally sparsely drop redundant image tokens by token pruning or brutally remove channels by channel pruning, leading to a sub-optimal balance between model performance and inference speed. They are also disadvantageous in transferring compressed models to downstream vision tasks that require the spatial structure of images, such as semantic segmentation. To tackle these issues, we propose a joint compression method for ViTs that offers both high accuracy and fast inference speed, while also maintaining favorable transferability to downstream tasks (CAIT). Specifically, we introduce an asymmetric token merging (ATME) strategy to effectively integrate neighboring tokens. It can successfully compress redundant token information while preserving the spatial structure of images. We further employ a consistent dynamic channel pruning (CDCP) strategy to dynamically prune unimportant channels in ViTs. Thanks to CDCP, insignificant channels in multi-head self-attention modules of ViTs can be pruned uniformly, greatly enhancing the model compression. Extensive experiments on benchmark datasets demonstrate that our proposed method can achieve state-of-the-art performance across various ViTs. For example, our pruned DeiT-Tiny and DeiT-Small achieve speedups of 1.7$\\times$ and 1.9$\\times$, respectively, without accuracy drops on ImageNet. On the ADE20k segmentation dataset, our method can enjoy up to 1.31$\\times$ speedups with comparable mIoU. Our code will be publicly available.","sentences":["Vision Transformers (ViTs) have emerged as state-of-the-art models for various vision tasks recently.","However, their heavy computation costs remain daunting for resource-limited devices.","Consequently, researchers have dedicated themselves to compressing redundant information in ViTs for acceleration.","However, they generally sparsely drop redundant image tokens by token pruning or brutally remove channels by channel pruning, leading to a sub-optimal balance between model performance and inference speed.","They are also disadvantageous in transferring compressed models to downstream vision tasks that require the spatial structure of images, such as semantic segmentation.","To tackle these issues, we propose a joint compression method for ViTs that offers both high accuracy and fast inference speed, while also maintaining favorable transferability to downstream tasks (CAIT).","Specifically, we introduce an asymmetric token merging (ATME) strategy to effectively integrate neighboring tokens.","It can successfully compress redundant token information while preserving the spatial structure of images.","We further employ a consistent dynamic channel pruning (CDCP) strategy to dynamically prune unimportant channels in ViTs.","Thanks to CDCP, insignificant channels in multi-head self-attention modules of ViTs can be pruned uniformly, greatly enhancing the model compression.","Extensive experiments on benchmark datasets demonstrate that our proposed method can achieve state-of-the-art performance across various ViTs.","For example, our pruned DeiT-Tiny and DeiT-Small achieve speedups of 1.7$\\times$ and 1.9$\\times$, respectively, without accuracy drops on ImageNet.","On the ADE20k segmentation dataset, our method can enjoy up to 1.31$\\times$ speedups with comparable mIoU. Our code will be publicly available."],"url":"http://arxiv.org/abs/2309.15755v1"}
{"created":"2023-09-27 16:07:43","title":"InfraParis: A multi-modal and multi-task autonomous driving dataset","abstract":"Current deep neural networks (DNNs) for autonomous driving computer vision are typically trained on specific datasets that only involve a single type of data and urban scenes. Consequently, these models struggle to handle new objects, noise, nighttime conditions, and diverse scenarios, which is essential for safety-critical applications. Despite ongoing efforts to enhance the resilience of computer vision DNNs, progress has been sluggish, partly due to the absence of benchmarks featuring multiple modalities. We introduce a novel and versatile dataset named InfraParis that supports multiple tasks across three modalities: RGB, depth, and infrared. We assess various state-of-the-art baseline techniques, encompassing models for the tasks of semantic segmentation, object detection, and depth estimation.","sentences":["Current deep neural networks (DNNs) for autonomous driving computer vision are typically trained on specific datasets that only involve a single type of data and urban scenes.","Consequently, these models struggle to handle new objects, noise, nighttime conditions, and diverse scenarios, which is essential for safety-critical applications.","Despite ongoing efforts to enhance the resilience of computer vision DNNs, progress has been sluggish, partly due to the absence of benchmarks featuring multiple modalities.","We introduce a novel and versatile dataset named InfraParis that supports multiple tasks across three modalities: RGB, depth, and infrared.","We assess various state-of-the-art baseline techniques, encompassing models for the tasks of semantic segmentation, object detection, and depth estimation."],"url":"http://arxiv.org/abs/2309.15751v1"}
{"created":"2023-09-27 16:01:05","title":"Faster Relative Entropy Coding with Greedy Rejection Coding","abstract":"Relative entropy coding (REC) algorithms encode a sample from a target distribution $Q$ using a proposal distribution $P$ using as few bits as possible. Unlike entropy coding, REC does not assume discrete distributions or require quantisation. As such, it can be naturally integrated into communication pipelines such as learnt compression and differentially private federated learning. Unfortunately, despite their practical benefits, REC algorithms have not seen widespread application, due to their prohibitively slow runtimes or restrictive assumptions. In this paper, we make progress towards addressing these issues. We introduce Greedy Rejection Coding (GRC), which generalises the rejection based-algorithm of Harsha et al. (2007) to arbitrary probability spaces and partitioning schemes. We first show that GRC terminates almost surely and returns unbiased samples from $Q$, after which we focus on two of its variants: GRCS and GRCD. We show that for continuous $Q$ and $P$ over $\\mathbb{R}$ with unimodal density ratio $dQ/dP$, the expected runtime of GRCS is upper bounded by $\\beta D_{KL}[Q || P] + O(1)$ where $\\beta \\approx 4.82$, and its expected codelength is optimal. This makes GRCS the first REC algorithm with guaranteed optimal runtime for this class of distributions, up to the multiplicative constant $\\beta$. This significantly improves upon the previous state-of-the-art method, A* coding (Flamich et al., 2022). Under the same assumptions, we experimentally observe and conjecture that the expected runtime and codelength of GRCD are upper bounded by $D_{KL}[Q || P] + O(1)$. Finally, we evaluate GRC in a variational autoencoder-based compression pipeline on MNIST, and show that a modified ELBO and an index-compression method can further improve compression efficiency.","sentences":["Relative entropy coding (REC) algorithms encode a sample from a target distribution $Q$ using a proposal distribution $P$ using as few bits as possible.","Unlike entropy coding, REC does not assume discrete distributions or require quantisation.","As such, it can be naturally integrated into communication pipelines such as learnt compression and differentially private federated learning.","Unfortunately, despite their practical benefits, REC algorithms have not seen widespread application, due to their prohibitively slow runtimes or restrictive assumptions.","In this paper, we make progress towards addressing these issues.","We introduce Greedy Rejection Coding (GRC), which generalises the rejection based-algorithm of Harsha et al.","(2007) to arbitrary probability spaces and partitioning schemes.","We first show that GRC terminates almost surely and returns unbiased samples from $Q$, after which we focus on two of its variants: GRCS and GRCD.","We show that for continuous $Q$ and $P$ over $\\mathbb{R}$ with unimodal density ratio $dQ/dP$, the expected runtime of GRCS is upper bounded by $\\beta D_{KL}[Q || P]","+ O(1)$ where $\\beta \\approx 4.82$, and its expected codelength is optimal.","This makes GRCS the first REC algorithm with guaranteed optimal runtime for this class of distributions, up to the multiplicative constant $\\beta$. This significantly improves upon the previous state-of-the-art method, A* coding (Flamich et al., 2022).","Under the same assumptions, we experimentally observe and conjecture that the expected runtime and codelength of GRCD are upper bounded by $D_{KL}[Q || P] +","O(1)$. Finally, we evaluate GRC in a variational autoencoder-based compression pipeline on MNIST, and show that a modified ELBO and an index-compression method can further improve compression efficiency."],"url":"http://arxiv.org/abs/2309.15746v1"}
{"created":"2023-09-27 15:54:08","title":"T5APR: Empowering Automated Program Repair across Languages through Checkpoint Ensemble","abstract":"Automated program repair (APR) using deep learning techniques has become an important area of research in recent years, aiming to automatically generate bug-fixing patches that can improve software reliability and maintainability. However, most existing methods either target a single language or require high computational resources to train multilingual models. In this paper, we propose T5APR, a novel neural program repair approach that provides a unified solution for bug fixing across multiple programming languages. T5APR leverages CodeT5, a powerful pre-trained text-to-text transformer model, and adopts a checkpoint ensemble strategy to improve patch recommendation. We conduct comprehensive evaluations on six well-known benchmarks in four programming languages (Java, Python, C, JavaScript), demonstrating T5APR's competitiveness against state-of-the-art techniques. T5APR correctly fixes 1,985 bugs, including 1,442 bugs that none of the compared techniques has fixed. We further support the effectiveness of our approach by conducting detailed analyses, such as comparing the correct patch ranking among different techniques. The findings of this study demonstrate the potential of T5APR for use in real-world applications and highlight the importance of multilingual approaches in the field of APR.","sentences":["Automated program repair (APR) using deep learning techniques has become an important area of research in recent years, aiming to automatically generate bug-fixing patches that can improve software reliability and maintainability.","However, most existing methods either target a single language or require high computational resources to train multilingual models.","In this paper, we propose T5APR, a novel neural program repair approach that provides a unified solution for bug fixing across multiple programming languages.","T5APR leverages CodeT5, a powerful pre-trained text-to-text transformer model, and adopts a checkpoint ensemble strategy to improve patch recommendation.","We conduct comprehensive evaluations on six well-known benchmarks in four programming languages (Java, Python, C, JavaScript), demonstrating T5APR's competitiveness against state-of-the-art techniques.","T5APR correctly fixes 1,985 bugs, including 1,442 bugs that none of the compared techniques has fixed.","We further support the effectiveness of our approach by conducting detailed analyses, such as comparing the correct patch ranking among different techniques.","The findings of this study demonstrate the potential of T5APR for use in real-world applications and highlight the importance of multilingual approaches in the field of APR."],"url":"http://arxiv.org/abs/2309.15742v1"}
{"created":"2023-09-27 15:51:18","title":"Data-Driven Latent Space Representation for Robust Bipedal Locomotion Learning","abstract":"This paper presents a novel framework for learning robust bipedal walking by combining a data-driven state representation with a Reinforcement Learning (RL) based locomotion policy. The framework utilizes an autoencoder to learn a low-dimensional latent space that captures the complex dynamics of bipedal locomotion from existing locomotion data. This reduced dimensional state representation is then used as states for training a robust RL-based gait policy, eliminating the need for heuristic state selections or the use of template models for gait planning. The results demonstrate that the learned latent variables are disentangled and directly correspond to different gaits or speeds, such as moving forward, backward, or walking in place. Compared to traditional template model-based approaches, our framework exhibits superior performance and robustness in simulation. The trained policy effectively tracks a wide range of walking speeds and demonstrates good generalization capabilities to unseen scenarios.","sentences":["This paper presents a novel framework for learning robust bipedal walking by combining a data-driven state representation with a Reinforcement Learning (RL) based locomotion policy.","The framework utilizes an autoencoder to learn a low-dimensional latent space that captures the complex dynamics of bipedal locomotion from existing locomotion data.","This reduced dimensional state representation is then used as states for training a robust RL-based gait policy, eliminating the need for heuristic state selections or the use of template models for gait planning.","The results demonstrate that the learned latent variables are disentangled and directly correspond to different gaits or speeds, such as moving forward, backward, or walking in place.","Compared to traditional template model-based approaches, our framework exhibits superior performance and robustness in simulation.","The trained policy effectively tracks a wide range of walking speeds and demonstrates good generalization capabilities to unseen scenarios."],"url":"http://arxiv.org/abs/2309.15740v1"}
{"created":"2023-09-27 15:49:43","title":"Experience and Evidence are the eyes of an excellent summarizer! Towards Knowledge Infused Multi-modal Clinical Conversation Summarization","abstract":"With the advancement of telemedicine, both researchers and medical practitioners are working hand-in-hand to develop various techniques to automate various medical operations, such as diagnosis report generation. In this paper, we first present a multi-modal clinical conversation summary generation task that takes a clinician-patient interaction (both textual and visual information) and generates a succinct synopsis of the conversation. We propose a knowledge-infused, multi-modal, multi-tasking medical domain identification and clinical conversation summary generation (MM-CliConSummation) framework. It leverages an adapter to infuse knowledge and visual features and unify the fused feature vector using a gated mechanism. Furthermore, we developed a multi-modal, multi-intent clinical conversation summarization corpus annotated with intent, symptom, and summary. The extensive set of experiments, both quantitatively and qualitatively, led to the following findings: (a) critical significance of visuals, (b) more precise and medical entity preserving summary with additional knowledge infusion, and (c) a correlation between medical department identification and clinical synopsis generation. Furthermore, the dataset and source code are available at https://github.com/NLP-RL/MM-CliConSummation.","sentences":["With the advancement of telemedicine, both researchers and medical practitioners are working hand-in-hand to develop various techniques to automate various medical operations, such as diagnosis report generation.","In this paper, we first present a multi-modal clinical conversation summary generation task that takes a clinician-patient interaction (both textual and visual information) and generates a succinct synopsis of the conversation.","We propose a knowledge-infused, multi-modal, multi-tasking medical domain identification and clinical conversation summary generation (MM-CliConSummation) framework.","It leverages an adapter to infuse knowledge and visual features and unify the fused feature vector using a gated mechanism.","Furthermore, we developed a multi-modal, multi-intent clinical conversation summarization corpus annotated with intent, symptom, and summary.","The extensive set of experiments, both quantitatively and qualitatively, led to the following findings: (a) critical significance of visuals, (b) more precise and medical entity preserving summary with additional knowledge infusion, and (c) a correlation between medical department identification and clinical synopsis generation.","Furthermore, the dataset and source code are available at https://github.com/NLP-RL/MM-CliConSummation."],"url":"http://arxiv.org/abs/2309.15739v1"}
{"created":"2023-09-27 15:48:36","title":"Provably Efficient Exploration in Constrained Reinforcement Learning:Posterior Sampling Is All You Need","abstract":"We present a new algorithm based on posterior sampling for learning in constrained Markov decision processes (CMDP) in the infinite-horizon undiscounted setting. The algorithm achieves near-optimal regret bounds while being advantageous empirically compared to the existing algorithms. Our main theoretical result is a Bayesian regret bound for each cost component of \\tilde{O} (HS \\sqrt{AT}) for any communicating CMDP with S states, A actions, and bound on the hitting time H. This regret bound matches the lower bound in order of time horizon T and is the best-known regret bound for communicating CMDPs in the infinite-horizon undiscounted setting. Empirical results show that, despite its simplicity, our posterior sampling algorithm outperforms the existing algorithms for constrained reinforcement learning.","sentences":["We present a new algorithm based on posterior sampling for learning in constrained Markov decision processes (CMDP) in the infinite-horizon undiscounted setting.","The algorithm achieves near-optimal regret bounds while being advantageous empirically compared to the existing algorithms.","Our main theoretical result is a Bayesian regret bound for each cost component of \\tilde{O} (HS \\sqrt{AT}) for any communicating CMDP with S states, A actions, and bound on the hitting time H. This regret bound matches the lower bound in order of time horizon T and is the best-known regret bound for communicating CMDPs in the infinite-horizon undiscounted setting.","Empirical results show that, despite its simplicity, our posterior sampling algorithm outperforms the existing algorithms for constrained reinforcement learning."],"url":"http://arxiv.org/abs/2309.15737v1"}
{"created":"2023-09-27 15:47:00","title":"Synthetic Latent Fingerprint Generation Using Style Transfer","abstract":"Limited data availability is a challenging problem in the latent fingerprint domain. Synthetically generated fingerprints are vital for training data-hungry neural network-based algorithms. Conventional methods distort clean fingerprints to generate synthetic latent fingerprints. We propose a simple and effective approach using style transfer and image blending to synthesize realistic latent fingerprints. Our evaluation criteria and experiments demonstrate that the generated synthetic latent fingerprints preserve the identity information from the input contact-based fingerprints while possessing similar characteristics as real latent fingerprints. Additionally, we show that the generated fingerprints exhibit several qualities and styles, suggesting that the proposed method can generate multiple samples from a single fingerprint.","sentences":["Limited data availability is a challenging problem in the latent fingerprint domain.","Synthetically generated fingerprints are vital for training data-hungry neural network-based algorithms.","Conventional methods distort clean fingerprints to generate synthetic latent fingerprints.","We propose a simple and effective approach using style transfer and image blending to synthesize realistic latent fingerprints.","Our evaluation criteria and experiments demonstrate that the generated synthetic latent fingerprints preserve the identity information from the input contact-based fingerprints while possessing similar characteristics as real latent fingerprints.","Additionally, we show that the generated fingerprints exhibit several qualities and styles, suggesting that the proposed method can generate multiple samples from a single fingerprint."],"url":"http://arxiv.org/abs/2309.15734v1"}
{"created":"2023-09-27 15:41:12","title":"Deep Learning-based Analysis of Basins of Attraction","abstract":"This study showcases the effectiveness of convolutional neural networks (CNNs) in characterizing the complexity and unpredictability of basins of attraction for diverse dynamical systems. This novel method is optimal for exploring different parameters of dynamical systems since the conventional methods are computationally expensive for characterizing multiple basins of attraction. Additionally, our research includes a comparison of different CNN architectures for this task showing the superiority of our proposed characterization method over the conventional methods, even with obsolete architectures.","sentences":["This study showcases the effectiveness of convolutional neural networks (CNNs) in characterizing the complexity and unpredictability of basins of attraction for diverse dynamical systems.","This novel method is optimal for exploring different parameters of dynamical systems since the conventional methods are computationally expensive for characterizing multiple basins of attraction.","Additionally, our research includes a comparison of different CNN architectures for this task showing the superiority of our proposed characterization method over the conventional methods, even with obsolete architectures."],"url":"http://arxiv.org/abs/2309.15732v1"}
{"created":"2023-09-27 15:37:29","title":"A user study of visualisations of spatio-temporal eye tracking data","abstract":"Eye movements have a spatial (where people look), but also a temporal (when people look) component. Various types of visualizations have been proposed that take this spatio-temporal nature of the data into account, but it is unclear how well each one can be interpreted and whether such interpretation depends on the question asked about the data or the nature of the data-set that is being visualised. In this study, four spatio-temporal visualization techniques for eye movements (chord diagram, scanpath, scarfplot, space-time cube) were compared in a user study. Participants (N = 25) answered three questions (what region first, what region most, which regions most between) about each visualization, which was based on two types of data-sets (eye movements towards adverts, eye movements towards pairs of gambles). Accuracy of the answers depended on a combination of the data-set, the question that needed to answered, and the type of visualization. For most questions, the scanpath, which did not use area of interest (AOI) information, resulted in lower accuracy than the other graphs. This suggests that AOIs improve the information conveyed by graphs. No effects of experience with reading graphs (for work or not for work) or education on accuracy of the answer was found. The results therefore suggest that there is no single best visualisation of the spatio-temporal aspects of eye movements. When visualising eye movement data, a user study may therefore be beneficial to determine the optimal visualization of the data-set and research question at hand.","sentences":["Eye movements have a spatial (where people look), but also a temporal (when people look) component.","Various types of visualizations have been proposed that take this spatio-temporal nature of the data into account, but it is unclear how well each one can be interpreted and whether such interpretation depends on the question asked about the data or the nature of the data-set that is being visualised.","In this study, four spatio-temporal visualization techniques for eye movements (chord diagram, scanpath, scarfplot, space-time cube) were compared in a user study.","Participants (N = 25) answered three questions (what region first, what region most, which regions most between) about each visualization, which was based on two types of data-sets (eye movements towards adverts, eye movements towards pairs of gambles).","Accuracy of the answers depended on a combination of the data-set, the question that needed to answered, and the type of visualization.","For most questions, the scanpath, which did not use area of interest (AOI) information, resulted in lower accuracy than the other graphs.","This suggests that AOIs improve the information conveyed by graphs.","No effects of experience with reading graphs (for work or not for work) or education on accuracy of the answer was found.","The results therefore suggest that there is no single best visualisation of the spatio-temporal aspects of eye movements.","When visualising eye movement data, a user study may therefore be beneficial to determine the optimal visualization of the data-set and research question at hand."],"url":"http://arxiv.org/abs/2309.15731v1"}
{"created":"2023-09-27 15:36:45","title":"Temporal graph models fail to capture global temporal dynamics","abstract":"A recently released Temporal Graph Benchmark is analyzed in the context of Dynamic Link Property Prediction. We outline our observations and propose a trivial optimization-free baseline of \"recently popular nodes\" outperforming other methods on all medium and large-size datasets in the Temporal Graph Benchmark. We propose two measures based on Wasserstein distance which can quantify the strength of short-term and long-term global dynamics of datasets. By analyzing our unexpectedly strong baseline, we show how standard negative sampling evaluation can be unsuitable for datasets with strong temporal dynamics. We also show how simple negative-sampling can lead to model degeneration during training, resulting in impossible to rank, fully saturated predictions of temporal graph networks. We propose improved negative sampling schemes for both training and evaluation and prove their usefulness. We conduct a comparison with a model trained non-contrastively without negative sampling. Our results provide a challenging baseline and indicate that temporal graph network architectures need deep rethinking for usage in problems with significant global dynamics, such as social media, cryptocurrency markets or e-commerce. We open-source the code for baselines, measures and proposed negative sampling schemes.","sentences":["A recently released Temporal Graph Benchmark is analyzed in the context of Dynamic Link Property Prediction.","We outline our observations and propose a trivial optimization-free baseline of \"recently popular nodes\" outperforming other methods on all medium and large-size datasets in the Temporal Graph Benchmark.","We propose two measures based on Wasserstein distance which can quantify the strength of short-term and long-term global dynamics of datasets.","By analyzing our unexpectedly strong baseline, we show how standard negative sampling evaluation can be unsuitable for datasets with strong temporal dynamics.","We also show how simple negative-sampling can lead to model degeneration during training, resulting in impossible to rank, fully saturated predictions of temporal graph networks.","We propose improved negative sampling schemes for both training and evaluation and prove their usefulness.","We conduct a comparison with a model trained non-contrastively without negative sampling.","Our results provide a challenging baseline and indicate that temporal graph network architectures need deep rethinking for usage in problems with significant global dynamics, such as social media, cryptocurrency markets or e-commerce.","We open-source the code for baselines, measures and proposed negative sampling schemes."],"url":"http://arxiv.org/abs/2309.15730v1"}
{"created":"2023-09-27 15:35:20","title":"MindGPT: Interpreting What You See with Non-invasive Brain Recordings","abstract":"Decoding of seen visual contents with non-invasive brain recordings has important scientific and practical values. Efforts have been made to recover the seen images from brain signals. However, most existing approaches cannot faithfully reflect the visual contents due to insufficient image quality or semantic mismatches. Compared with reconstructing pixel-level visual images, speaking is a more efficient and effective way to explain visual information. Here we introduce a non-invasive neural decoder, termed as MindGPT, which interprets perceived visual stimuli into natural languages from fMRI signals. Specifically, our model builds upon a visually guided neural encoder with a cross-attention mechanism, which permits us to guide latent neural representations towards a desired language semantic direction in an end-to-end manner by the collaborative use of the large language model GPT. By doing so, we found that the neural representations of the MindGPT are explainable, which can be used to evaluate the contributions of visual properties to language semantics. Our experiments show that the generated word sequences truthfully represented the visual information (with essential details) conveyed in the seen stimuli. The results also suggested that with respect to language decoding tasks, the higher visual cortex (HVC) is more semantically informative than the lower visual cortex (LVC), and using only the HVC can recover most of the semantic information. The code of the MindGPT model will be publicly available at https://github.com/JxuanC/MindGPT.","sentences":["Decoding of seen visual contents with non-invasive brain recordings has important scientific and practical values.","Efforts have been made to recover the seen images from brain signals.","However, most existing approaches cannot faithfully reflect the visual contents due to insufficient image quality or semantic mismatches.","Compared with reconstructing pixel-level visual images, speaking is a more efficient and effective way to explain visual information.","Here we introduce a non-invasive neural decoder, termed as MindGPT, which interprets perceived visual stimuli into natural languages from fMRI signals.","Specifically, our model builds upon a visually guided neural encoder with a cross-attention mechanism, which permits us to guide latent neural representations towards a desired language semantic direction in an end-to-end manner by the collaborative use of the large language model GPT.","By doing so, we found that the neural representations of the MindGPT are explainable, which can be used to evaluate the contributions of visual properties to language semantics.","Our experiments show that the generated word sequences truthfully represented the visual information (with essential details) conveyed in the seen stimuli.","The results also suggested that with respect to language decoding tasks, the higher visual cortex (HVC) is more semantically informative than the lower visual cortex (LVC), and using only the HVC can recover most of the semantic information.","The code of the MindGPT model will be publicly available at https://github.com/JxuanC/MindGPT."],"url":"http://arxiv.org/abs/2309.15729v1"}
{"created":"2023-09-27 15:34:44","title":"Line Graph Neural Networks for Link Weight Prediction","abstract":"Link weight prediction is of great practical importance, since real-world networks are often weighted networks. Previous studies have mainly used shallow graph features for link weight prediction, which limits the prediction performance. In this paper, we propose a new link weight prediction algorithm, namely Line Graph Neural Networks for Link Weight Prediction (LGLWP), which learns deeper graph features through deep learning. In our algorithm, we first extract the enclosing subgraph around a target link, and then employ a weighted graph labeling algorithm to label the subgraph nodes. Next, we transform the subgraph into a line graph and apply the graph convolution neural networks to learn the node embedding in the line graph, which can represent the links in the original subgraph. Finally, the link feature vectors are put into a fully-connected neural network to predict the weight of the target link. Our algorithm directly obtain the feature vectors of the target links in the original graph, which is better than the previous methods that splice the node feature vectors for link weight prediction. Experiments results on six real datasets of various network sizes and types show that our algorithm has better prediction performance than the state-of-art methods, while it has fewer parameters and high training efficiency.","sentences":["Link weight prediction is of great practical importance, since real-world networks are often weighted networks.","Previous studies have mainly used shallow graph features for link weight prediction, which limits the prediction performance.","In this paper, we propose a new link weight prediction algorithm, namely Line Graph Neural Networks for Link Weight Prediction (LGLWP), which learns deeper graph features through deep learning.","In our algorithm, we first extract the enclosing subgraph around a target link, and then employ a weighted graph labeling algorithm to label the subgraph nodes.","Next, we transform the subgraph into a line graph and apply the graph convolution neural networks to learn the node embedding in the line graph, which can represent the links in the original subgraph.","Finally, the link feature vectors are put into a fully-connected neural network to predict the weight of the target link.","Our algorithm directly obtain the feature vectors of the target links in the original graph, which is better than the previous methods that splice the node feature vectors for link weight prediction.","Experiments results on six real datasets of various network sizes and types show that our algorithm has better prediction performance than the state-of-art methods, while it has fewer parameters and high training efficiency."],"url":"http://arxiv.org/abs/2309.15728v1"}
{"created":"2023-09-27 15:32:46","title":"Factorized Diffusion Architectures for Unsupervised Image Generation and Segmentation","abstract":"We develop a neural network architecture which, trained in an unsupervised manner as a denoising diffusion model, simultaneously learns to both generate and segment images. Learning is driven entirely by the denoising diffusion objective, without any annotation or prior knowledge about regions during training. A computational bottleneck, built into the neural architecture, encourages the denoising network to partition an input into regions, denoise them in parallel, and combine the results. Our trained model generates both synthetic images and, by simple examination of its internal predicted partitions, a semantic segmentation of those images. Without any finetuning, we directly apply our unsupervised model to the downstream task of segmenting real images via noising and subsequently denoising them. Experiments demonstrate that our model achieves accurate unsupervised image segmentation and high-quality synthetic image generation across multiple datasets.","sentences":["We develop a neural network architecture which, trained in an unsupervised manner as a denoising diffusion model, simultaneously learns to both generate and segment images.","Learning is driven entirely by the denoising diffusion objective, without any annotation or prior knowledge about regions during training.","A computational bottleneck, built into the neural architecture, encourages the denoising network to partition an input into regions, denoise them in parallel, and combine the results.","Our trained model generates both synthetic images and, by simple examination of its internal predicted partitions, a semantic segmentation of those images.","Without any finetuning, we directly apply our unsupervised model to the downstream task of segmenting real images via noising and subsequently denoising them.","Experiments demonstrate that our model achieves accurate unsupervised image segmentation and high-quality synthetic image generation across multiple datasets."],"url":"http://arxiv.org/abs/2309.15726v1"}
{"created":"2023-09-27 15:32:02","title":"Making Logical Relations More Relatable (Proof Pearl)","abstract":"Mechanical proofs by logical relations often involve tedious reasoning about substitution. In this paper, we show that this is not necessarily the case, by developing, in Agda, a proof that all simply typed lambda calculus expressions evaluate to values. A formalization of the proof is remarkably short (~40 lines of code), making for an excellent introduction to the technique of proofs by logical relations not only on paper but also in a mechanized setting. We then show that this process extends to more sophisticated reasoning by also proving the totality of normalization by evaluation. Although these proofs are not new, we believe presenting them will empower both new and experienced programming language theorists in their use of logical relations.","sentences":["Mechanical proofs by logical relations often involve tedious reasoning about substitution.","In this paper, we show that this is not necessarily the case, by developing, in Agda, a proof that all simply typed lambda calculus expressions evaluate to values.","A formalization of the proof is remarkably short (~40 lines of code), making for an excellent introduction to the technique of proofs by logical relations not only on paper but also in a mechanized setting.","We then show that this process extends to more sophisticated reasoning by also proving the totality of normalization by evaluation.","Although these proofs are not new, we believe presenting them will empower both new and experienced programming language theorists in their use of logical relations."],"url":"http://arxiv.org/abs/2309.15724v1"}
{"created":"2023-09-27 15:30:50","title":"Where Are We So Far? Understanding Data Storytelling Tools from the Perspective of Human-AI Collaboration","abstract":"Data storytelling is powerful for communicating data insights, but it requires diverse skills and considerable effort from human creators. Recent research has widely explored the potential for artificial intelligence (AI) to support and augment humans in data storytelling. However, there lacks a systematic review to understand data storytelling tools from the perspective of human-AI collaboration, which hinders researchers from reflecting on the existing collaborative tool designs that promote humans' and AI's advantages and mitigate their shortcomings. This paper investigated existing tools with a framework from two perspectives: the stages in the storytelling workflow where a tool serves, including analysis, planning, implementation, and communication, and the roles of humans and AI in each stage, such as creators, assistants, optimizers, and reviewers. Through our analysis, we recognize the common collaboration patterns in existing tools, summarize lessons learned from these patterns, and further illustrate research opportunities for human-AI collaboration in data storytelling.","sentences":["Data storytelling is powerful for communicating data insights, but it requires diverse skills and considerable effort from human creators.","Recent research has widely explored the potential for artificial intelligence (AI) to support and augment humans in data storytelling.","However, there lacks a systematic review to understand data storytelling tools from the perspective of human-AI collaboration, which hinders researchers from reflecting on the existing collaborative tool designs that promote humans' and AI's advantages and mitigate their shortcomings.","This paper investigated existing tools with a framework from two perspectives: the stages in the storytelling workflow where a tool serves, including analysis, planning, implementation, and communication, and the roles of humans and AI in each stage, such as creators, assistants, optimizers, and reviewers.","Through our analysis, we recognize the common collaboration patterns in existing tools, summarize lessons learned from these patterns, and further illustrate research opportunities for human-AI collaboration in data storytelling."],"url":"http://arxiv.org/abs/2309.15723v1"}
{"created":"2023-09-27 15:24:39","title":"Model Share AI: An Integrated Toolkit for Collaborative Machine Learning Model Development, Provenance Tracking, and Deployment in Python","abstract":"Machine learning (ML) has the potential to revolutionize a wide range of research areas and industries, but many ML projects never progress past the proof-of-concept stage. To address this issue, we introduce Model Share AI (AIMS), an easy-to-use MLOps platform designed to streamline collaborative model development, model provenance tracking, and model deployment, as well as a host of other functions aiming to maximize the real-world impact of ML research. AIMS features collaborative project spaces and a standardized model evaluation process that ranks model submissions based on their performance on unseen evaluation data, enabling collaborative model development and crowd-sourcing. Model performance and various model metadata are automatically captured to facilitate provenance tracking and allow users to learn from and build on previous submissions. Additionally, AIMS allows users to deploy ML models built in Scikit-Learn, TensorFlow Keras, PyTorch, and ONNX into live REST APIs and automatically generated web apps with minimal code. The ability to deploy models with minimal effort and to make them accessible to non-technical end-users through web apps has the potential to make ML research more applicable to real-world challenges.","sentences":["Machine learning (ML) has the potential to revolutionize a wide range of research areas and industries, but many ML projects never progress past the proof-of-concept stage.","To address this issue, we introduce Model Share AI (AIMS), an easy-to-use MLOps platform designed to streamline collaborative model development, model provenance tracking, and model deployment, as well as a host of other functions aiming to maximize the real-world impact of ML research.","AIMS features collaborative project spaces and a standardized model evaluation process that ranks model submissions based on their performance on unseen evaluation data, enabling collaborative model development and crowd-sourcing.","Model performance and various model metadata are automatically captured to facilitate provenance tracking and allow users to learn from and build on previous submissions.","Additionally, AIMS allows users to deploy ML models built in Scikit-Learn, TensorFlow Keras, PyTorch, and ONNX into live REST APIs and automatically generated web apps with minimal code.","The ability to deploy models with minimal effort and to make them accessible to non-technical end-users through web apps has the potential to make ML research more applicable to real-world challenges."],"url":"http://arxiv.org/abs/2309.15719v1"}
{"created":"2023-09-27 15:12:08","title":"ChatGPT-BCI: Word-Level Neural State Classification Using GPT, EEG, and Eye-Tracking Biomarkers in Semantic Inference Reading Comprehension","abstract":"With the recent explosion of large language models (LLMs), such as Generative Pretrained Transformers (GPT), the need to understand the ability of humans and machines to comprehend semantic language meaning has entered a new phase. This requires interdisciplinary research that bridges the fields of cognitive science and natural language processing (NLP). This pilot study aims to provide insights into individuals' neural states during a semantic relation reading-comprehension task. We propose jointly analyzing LLMs, eye-gaze, and electroencephalographic (EEG) data to study how the brain processes words with varying degrees of relevance to a keyword during reading. We also use a feature engineering approach to improve the fixation-related EEG data classification while participants read words with high versus low relevance to the keyword. The best validation accuracy in this word-level classification is over 60\\% across 12 subjects. Words of high relevance to the inference keyword had significantly more eye fixations per word: 1.0584 compared to 0.6576 when excluding no-fixation words, and 1.5126 compared to 1.4026 when including them. This study represents the first attempt to classify brain states at a word level using LLM knowledge. It provides valuable insights into human cognitive abilities and the realm of Artificial General Intelligence (AGI), and offers guidance for developing potential reading-assisted technologies.","sentences":["With the recent explosion of large language models (LLMs), such as Generative Pretrained Transformers (GPT), the need to understand the ability of humans and machines to comprehend semantic language meaning has entered a new phase.","This requires interdisciplinary research that bridges the fields of cognitive science and natural language processing (NLP).","This pilot study aims to provide insights into individuals' neural states during a semantic relation reading-comprehension task.","We propose jointly analyzing LLMs, eye-gaze, and electroencephalographic (EEG) data to study how the brain processes words with varying degrees of relevance to a keyword during reading.","We also use a feature engineering approach to improve the fixation-related EEG data classification while participants read words with high versus low relevance to the keyword.","The best validation accuracy in this word-level classification is over 60\\% across 12 subjects.","Words of high relevance to the inference keyword had significantly more eye fixations per word: 1.0584 compared to 0.6576 when excluding no-fixation words, and 1.5126 compared to 1.4026 when including them.","This study represents the first attempt to classify brain states at a word level using LLM knowledge.","It provides valuable insights into human cognitive abilities and the realm of Artificial General Intelligence (AGI), and offers guidance for developing potential reading-assisted technologies."],"url":"http://arxiv.org/abs/2309.15714v1"}
{"created":"2023-09-27 14:49:29","title":"Distributed Pilot Assignment for Distributed Massive-MIMO Networks","abstract":"Pilot contamination is a critical issue in distributed massive MIMO networks, where the reuse of pilot sequences due to limited availability of orthogonal pilots for channel estimation leads to performance degradation. In this work, we propose a novel distributed pilot assignment scheme to effectively mitigate the impact of pilot contamination. Our proposed scheme not only reduces signaling overhead, but it also enhances fault-tolerance. Extensive numerical simulations are conducted to evaluate the performance of the proposed scheme. Our results establish that the proposed scheme outperforms existing centralized and distributed schemes in terms of mitigating pilot contamination and significantly enhancing network throughput.","sentences":["Pilot contamination is a critical issue in distributed massive MIMO networks, where the reuse of pilot sequences due to limited availability of orthogonal pilots for channel estimation leads to performance degradation.","In this work, we propose a novel distributed pilot assignment scheme to effectively mitigate the impact of pilot contamination.","Our proposed scheme not only reduces signaling overhead, but it also enhances fault-tolerance.","Extensive numerical simulations are conducted to evaluate the performance of the proposed scheme.","Our results establish that the proposed scheme outperforms existing centralized and distributed schemes in terms of mitigating pilot contamination and significantly enhancing network throughput."],"url":"http://arxiv.org/abs/2309.15709v1"}
{"created":"2023-09-27 14:46:10","title":"Maximum Weight Entropy","abstract":"This paper deals with uncertainty quantification and out-of-distribution detection in deep learning using Bayesian and ensemble methods. It proposes a practical solution to the lack of prediction diversity observed recently for standard approaches when used out-of-distribution (Ovadia et al., 2019; Liu et al., 2021). Considering that this issue is mainly related to a lack of weight diversity, we claim that standard methods sample in \"over-restricted\" regions of the weight space due to the use of \"over-regularization\" processes, such as weight decay and zero-mean centered Gaussian priors. We propose to solve the problem by adopting the maximum entropy principle for the weight distribution, with the underlying idea to maximize the weight diversity. Under this paradigm, the epistemic uncertainty is described by the weight distribution of maximal entropy that produces neural networks \"consistent\" with the training observations. Considering stochastic neural networks, a practical optimization is derived to build such a distribution, defined as a trade-off between the average empirical risk and the weight distribution entropy. We develop a novel weight parameterization for the stochastic model, based on the singular value decomposition of the neural network's hidden representations, which enables a large increase of the weight entropy for a small empirical risk penalization. We provide both theoretical and numerical results to assess the efficiency of the approach. In particular, the proposed algorithm appears in the top three best methods in all configurations of an extensive out-of-distribution detection benchmark including more than thirty competitors.","sentences":["This paper deals with uncertainty quantification and out-of-distribution detection in deep learning using Bayesian and ensemble methods.","It proposes a practical solution to the lack of prediction diversity observed recently for standard approaches when used out-of-distribution (Ovadia et al., 2019; Liu et al., 2021).","Considering that this issue is mainly related to a lack of weight diversity, we claim that standard methods sample in \"over-restricted\" regions of the weight space due to the use of \"over-regularization\" processes, such as weight decay and zero-mean centered Gaussian priors.","We propose to solve the problem by adopting the maximum entropy principle for the weight distribution, with the underlying idea to maximize the weight diversity.","Under this paradigm, the epistemic uncertainty is described by the weight distribution of maximal entropy that produces neural networks \"consistent\" with the training observations.","Considering stochastic neural networks, a practical optimization is derived to build such a distribution, defined as a trade-off between the average empirical risk and the weight distribution entropy.","We develop a novel weight parameterization for the stochastic model, based on the singular value decomposition of the neural network's hidden representations, which enables a large increase of the weight entropy for a small empirical risk penalization.","We provide both theoretical and numerical results to assess the efficiency of the approach.","In particular, the proposed algorithm appears in the top three best methods in all configurations of an extensive out-of-distribution detection benchmark including more than thirty competitors."],"url":"http://arxiv.org/abs/2309.15704v1"}
{"created":"2023-09-27 14:46:01","title":"Physics-Based Rigid Body Object Tracking and Friction Filtering From RGB-D Videos","abstract":"Physics-based understanding of object interactions from sensory observations is an essential capability in augmented reality and robotics. It enables capturing the properties of a scene for simulation and control. In this paper, we propose a novel approach for real-to-sim which tracks rigid objects in 3D from RGB-D images and infers physical properties of the objects. We use a differentiable physics simulation as state-transition model in an Extended Kalman Filter which can model contact and friction for arbitrary mesh-based shapes and in this way estimate physically plausible trajectories. We demonstrate that our approach can filter position, orientation, velocities, and concurrently can estimate the coefficient of friction of the objects. We analyse our approach on various sliding scenarios in synthetic image sequences of single objects and colliding objects. We also demonstrate and evaluate our approach on a real-world dataset. We will make our novel benchmark datasets publicly available to foster future research in this novel problem setting and comparison with our method.","sentences":["Physics-based understanding of object interactions from sensory observations is an essential capability in augmented reality and robotics.","It enables capturing the properties of a scene for simulation and control.","In this paper, we propose a novel approach for real-to-sim which tracks rigid objects in 3D from RGB-D images and infers physical properties of the objects.","We use a differentiable physics simulation as state-transition model in an Extended Kalman Filter which can model contact and friction for arbitrary mesh-based shapes and in this way estimate physically plausible trajectories.","We demonstrate that our approach can filter position, orientation, velocities, and concurrently can estimate the coefficient of friction of the objects.","We analyse our approach on various sliding scenarios in synthetic image sequences of single objects and colliding objects.","We also demonstrate and evaluate our approach on a real-world dataset.","We will make our novel benchmark datasets publicly available to foster future research in this novel problem setting and comparison with our method."],"url":"http://arxiv.org/abs/2309.15703v1"}
{"created":"2023-09-27 14:45:29","title":"SGRec3D: Self-Supervised 3D Scene Graph Learning via Object-Level Scene Reconstruction","abstract":"In the field of 3D scene understanding, 3D scene graphs have emerged as a new scene representation that combines geometric and semantic information about objects and their relationships. However, learning semantic 3D scene graphs in a fully supervised manner is inherently difficult as it requires not only object-level annotations but also relationship labels. While pre-training approaches have helped to boost the performance of many methods in various fields, pre-training for 3D scene graph prediction has received little attention. Furthermore, we find in this paper that classical contrastive point cloud-based pre-training approaches are ineffective for 3D scene graph learning. To this end, we present SGRec3D, a novel self-supervised pre-training method for 3D scene graph prediction. We propose to reconstruct the 3D input scene from a graph bottleneck as a pretext task. Pre-training SGRec3D does not require object relationship labels, making it possible to exploit large-scale 3D scene understanding datasets, which were off-limits for 3D scene graph learning before. Our experiments demonstrate that in contrast to recent point cloud-based pre-training approaches, our proposed pre-training improves the 3D scene graph prediction considerably, which results in SOTA performance, outperforming other 3D scene graph models by +10% on object prediction and +4% on relationship prediction. Additionally, we show that only using a small subset of 10% labeled data during fine-tuning is sufficient to outperform the same model without pre-training.","sentences":["In the field of 3D scene understanding, 3D scene graphs have emerged as a new scene representation that combines geometric and semantic information about objects and their relationships.","However, learning semantic 3D scene graphs in a fully supervised manner is inherently difficult as it requires not only object-level annotations but also relationship labels.","While pre-training approaches have helped to boost the performance of many methods in various fields, pre-training for 3D scene graph prediction has received little attention.","Furthermore, we find in this paper that classical contrastive point cloud-based pre-training approaches are ineffective for 3D scene graph learning.","To this end, we present SGRec3D, a novel self-supervised pre-training method for 3D scene graph prediction.","We propose to reconstruct the 3D input scene from a graph bottleneck as a pretext task.","Pre-training SGRec3D does not require object relationship labels, making it possible to exploit large-scale 3D scene understanding datasets, which were off-limits for 3D scene graph learning before.","Our experiments demonstrate that in contrast to recent point cloud-based pre-training approaches, our proposed pre-training improves the 3D scene graph prediction considerably, which results in SOTA performance, outperforming other 3D scene graph models by +10% on object prediction and +4% on relationship prediction.","Additionally, we show that only using a small subset of 10% labeled data during fine-tuning is sufficient to outperform the same model without pre-training."],"url":"http://arxiv.org/abs/2309.15702v1"}
{"created":"2023-09-27 14:44:10","title":"HyPoradise: An Open Baseline for Generative Speech Recognition with Large Language Models","abstract":"Advancements in deep neural networks have allowed automatic speech recognition (ASR) systems to attain human parity on several publicly available clean speech datasets. However, even state-of-the-art ASR systems experience performance degradation when confronted with adverse conditions, as a well-trained acoustic model is sensitive to variations in the speech domain, e.g., background noise. Intuitively, humans address this issue by relying on their linguistic knowledge: the meaning of ambiguous spoken terms is usually inferred from contextual cues thereby reducing the dependency on the auditory system. Inspired by this observation, we introduce the first open-source benchmark to utilize external large language models (LLMs) for ASR error correction, where N-best decoding hypotheses provide informative elements for true transcription prediction. This approach is a paradigm shift from the traditional language model rescoring strategy that can only select one candidate hypothesis as the output transcription. The proposed benchmark contains a novel dataset, HyPoradise (HP), encompassing more than 334,000 pairs of N-best hypotheses and corresponding accurate transcriptions across prevalent speech domains. Given this dataset, we examine three types of error correction techniques based on LLMs with varying amounts of labeled hypotheses-transcription pairs, which gains a significant word error rate (WER) reduction. Experimental evidence demonstrates the proposed technique achieves a breakthrough by surpassing the upper bound of traditional re-ranking based methods. More surprisingly, LLM with reasonable prompt and its generative capability can even correct those tokens that are missing in N-best list. We make our results publicly accessible for reproducible pipelines with released pre-trained models, thus providing a new evaluation paradigm for ASR error correction with LLMs.","sentences":["Advancements in deep neural networks have allowed automatic speech recognition (ASR) systems to attain human parity on several publicly available clean speech datasets.","However, even state-of-the-art ASR systems experience performance degradation when confronted with adverse conditions, as a well-trained acoustic model is sensitive to variations in the speech domain, e.g., background noise.","Intuitively, humans address this issue by relying on their linguistic knowledge: the meaning of ambiguous spoken terms is usually inferred from contextual cues thereby reducing the dependency on the auditory system.","Inspired by this observation, we introduce the first open-source benchmark to utilize external large language models (LLMs) for ASR error correction, where N-best decoding hypotheses provide informative elements for true transcription prediction.","This approach is a paradigm shift from the traditional language model rescoring strategy that can only select one candidate hypothesis as the output transcription.","The proposed benchmark contains a novel dataset, HyPoradise (HP), encompassing more than 334,000 pairs of N-best hypotheses and corresponding accurate transcriptions across prevalent speech domains.","Given this dataset, we examine three types of error correction techniques based on LLMs with varying amounts of labeled hypotheses-transcription pairs, which gains a significant word error rate (WER) reduction.","Experimental evidence demonstrates the proposed technique achieves a breakthrough by surpassing the upper bound of traditional re-ranking based methods.","More surprisingly, LLM with reasonable prompt and its generative capability can even correct those tokens that are missing in N-best list.","We make our results publicly accessible for reproducible pipelines with released pre-trained models, thus providing a new evaluation paradigm for ASR error correction with LLMs."],"url":"http://arxiv.org/abs/2309.15701v1"}
{"created":"2023-09-27 14:42:30","title":"Tracking Snake-like Robots in the Wild Using Only a Single Camera","abstract":"Robot navigation within complex environments requires precise state estimation and localization to ensure robust and safe operations. For ambulating mobile robots like robot snakes, traditional methods for sensing require multiple embedded sensors or markers, leading to increased complexity, cost, and increased points of failure. Alternatively, deploying an external camera in the environment is very easy to do, and marker-less state estimation of the robot from this camera's images is an ideal solution: both simple and cost-effective. However, the challenge in this process is in tracking the robot under larger environments where the cameras may be moved around without extrinsic calibration, or maybe when in motion (e.g., a drone following the robot). The scenario itself presents a complex challenge: single-image reconstruction of robot poses under noisy observations. In this paper, we address the problem of tracking ambulatory mobile robots from a single camera. The method combines differentiable rendering with the Kalman filter. This synergy allows for simultaneous estimation of the robot's joint angle and pose while also providing state uncertainty which could be used later on for robust control. We demonstrate the efficacy of our approach on a snake-like robot in both stationary and non-stationary (moving) cameras, validating its performance in both structured and unstructured scenarios. The results achieved show an average error of 0.05 m in localizing the robot's base position and 6 degrees in joint state estimation. We believe this novel technique opens up possibilities for enhanced robot mobility and navigation in future exploratory and search-and-rescue missions.","sentences":["Robot navigation within complex environments requires precise state estimation and localization to ensure robust and safe operations.","For ambulating mobile robots like robot snakes, traditional methods for sensing require multiple embedded sensors or markers, leading to increased complexity, cost, and increased points of failure.","Alternatively, deploying an external camera in the environment is very easy to do, and marker-less state estimation of the robot from this camera's images is an ideal solution: both simple and cost-effective.","However, the challenge in this process is in tracking the robot under larger environments where the cameras may be moved around without extrinsic calibration, or maybe when in motion (e.g., a drone following the robot).","The scenario itself presents a complex challenge: single-image reconstruction of robot poses under noisy observations.","In this paper, we address the problem of tracking ambulatory mobile robots from a single camera.","The method combines differentiable rendering with the Kalman filter.","This synergy allows for simultaneous estimation of the robot's joint angle and pose while also providing state uncertainty which could be used later on for robust control.","We demonstrate the efficacy of our approach on a snake-like robot in both stationary and non-stationary (moving) cameras, validating its performance in both structured and unstructured scenarios.","The results achieved show an average error of 0.05 m in localizing the robot's base position and 6 degrees in joint state estimation.","We believe this novel technique opens up possibilities for enhanced robot mobility and navigation in future exploratory and search-and-rescue missions."],"url":"http://arxiv.org/abs/2309.15700v1"}
{"created":"2023-09-27 14:40:12","title":"Deep Model Fusion: A Survey","abstract":"Deep model fusion/merging is an emerging technique that merges the parameters or predictions of multiple deep learning models into a single one. It combines the abilities of different models to make up for the biases and errors of a single model to achieve better performance. However, deep model fusion on large-scale deep learning models (e.g., LLMs and foundation models) faces several challenges, including high computational cost, high-dimensional parameter space, interference between different heterogeneous models, etc. Although model fusion has attracted widespread attention due to its potential to solve complex real-world tasks, there is still a lack of complete and detailed survey research on this technique. Accordingly, in order to understand the model fusion method better and promote its development, we present a comprehensive survey to summarize the recent progress. Specifically, we categorize existing deep model fusion methods as four-fold: (1) \"Mode connectivity\", which connects the solutions in weight space via a path of non-increasing loss, in order to obtain better initialization for model fusion; (2) \"Alignment\" matches units between neural networks to create better conditions for fusion; (3) \"Weight average\", a classical model fusion method, averages the weights of multiple models to obtain more accurate results closer to the optimal solution; (4) \"Ensemble learning\" combines the outputs of diverse models, which is a foundational technique for improving the accuracy and robustness of the final model. In addition, we analyze the challenges faced by deep model fusion and propose possible research directions for model fusion in the future. Our review is helpful in deeply understanding the correlation between different model fusion methods and practical application methods, which can enlighten the research in the field of deep model fusion.","sentences":["Deep model fusion/merging is an emerging technique that merges the parameters or predictions of multiple deep learning models into a single one.","It combines the abilities of different models to make up for the biases and errors of a single model to achieve better performance.","However, deep model fusion on large-scale deep learning models (e.g., LLMs and foundation models) faces several challenges, including high computational cost, high-dimensional parameter space, interference between different heterogeneous models, etc.","Although model fusion has attracted widespread attention due to its potential to solve complex real-world tasks, there is still a lack of complete and detailed survey research on this technique.","Accordingly, in order to understand the model fusion method better and promote its development, we present a comprehensive survey to summarize the recent progress.","Specifically, we categorize existing deep model fusion methods as four-fold: (1) \"Mode connectivity\", which connects the solutions in weight space via a path of non-increasing loss, in order to obtain better initialization for model fusion; (2) \"Alignment\" matches units between neural networks to create better conditions for fusion; (3) \"Weight average\", a classical model fusion method, averages the weights of multiple models to obtain more accurate results closer to the optimal solution; (4) \"Ensemble learning\" combines the outputs of diverse models, which is a foundational technique for improving the accuracy and robustness of the final model.","In addition, we analyze the challenges faced by deep model fusion and propose possible research directions for model fusion in the future.","Our review is helpful in deeply understanding the correlation between different model fusion methods and practical application methods, which can enlighten the research in the field of deep model fusion."],"url":"http://arxiv.org/abs/2309.15698v1"}
{"created":"2023-09-27 14:39:41","title":"Physics Inspired Hybrid Attention for SAR Target Recognition","abstract":"There has been a recent emphasis on integrating physical models and deep neural networks (DNNs) for SAR target recognition, to improve performance and achieve a higher level of physical interpretability. The attributed scattering center (ASC) parameters garnered the most interest, being considered as additional input data or features for fusion in most methods. However, the performance greatly depends on the ASC optimization result, and the fusion strategy is not adaptable to different types of physical information. Meanwhile, the current evaluation scheme is inadequate to assess the model's robustness and generalizability. Thus, we propose a physics inspired hybrid attention (PIHA) mechanism and the once-for-all (OFA) evaluation protocol to address the above issues. PIHA leverages the high-level semantics of physical information to activate and guide the feature group aware of local semantics of target, so as to re-weight the feature importance based on knowledge prior. It is flexible and generally applicable to various physical models, and can be integrated into arbitrary DNNs without modifying the original architecture. The experiments involve a rigorous assessment using the proposed OFA, which entails training and validating a model on either sufficient or limited data and evaluating on multiple test sets with different data distributions. Our method outperforms other state-of-the-art approaches in 12 test scenarios with same ASC parameters. Moreover, we analyze the working mechanism of PIHA and evaluate various PIHA enabled DNNs. The experiments also show PIHA is effective for different physical information. The source code together with the adopted physical information is available at https://github.com/XAI4SAR.","sentences":["There has been a recent emphasis on integrating physical models and deep neural networks (DNNs) for SAR target recognition, to improve performance and achieve a higher level of physical interpretability.","The attributed scattering center (ASC) parameters garnered the most interest, being considered as additional input data or features for fusion in most methods.","However, the performance greatly depends on the ASC optimization result, and the fusion strategy is not adaptable to different types of physical information.","Meanwhile, the current evaluation scheme is inadequate to assess the model's robustness and generalizability.","Thus, we propose a physics inspired hybrid attention (PIHA) mechanism and the once-for-all (OFA) evaluation protocol to address the above issues.","PIHA leverages the high-level semantics of physical information to activate and guide the feature group aware of local semantics of target, so as to re-weight the feature importance based on knowledge prior.","It is flexible and generally applicable to various physical models, and can be integrated into arbitrary DNNs without modifying the original architecture.","The experiments involve a rigorous assessment using the proposed OFA, which entails training and validating a model on either sufficient or limited data and evaluating on multiple test sets with different data distributions.","Our method outperforms other state-of-the-art approaches in 12 test scenarios with same ASC parameters.","Moreover, we analyze the working mechanism of PIHA and evaluate various PIHA enabled DNNs.","The experiments also show PIHA is effective for different physical information.","The source code together with the adopted physical information is available at https://github.com/XAI4SAR."],"url":"http://arxiv.org/abs/2309.15697v1"}
{"created":"2023-09-27 14:38:16","title":"A Unified View of Differentially Private Deep Generative Modeling","abstract":"The availability of rich and vast data sources has greatly advanced machine learning applications in various domains. However, data with privacy concerns comes with stringent regulations that frequently prohibited data access and data sharing. Overcoming these obstacles in compliance with privacy considerations is key for technological progress in many real-world application scenarios that involve privacy sensitive data. Differentially private (DP) data publishing provides a compelling solution, where only a sanitized form of the data is publicly released, enabling privacy-preserving downstream analysis and reproducible research in sensitive domains. In recent years, various approaches have been proposed for achieving privacy-preserving high-dimensional data generation by private training on top of deep neural networks. In this paper, we present a novel unified view that systematizes these approaches. Our view provides a joint design space for systematically deriving methods that cater to different use cases. We then discuss the strengths, limitations, and inherent correlations between different approaches, aiming to shed light on crucial aspects and inspire future research. We conclude by presenting potential paths forward for the field of DP data generation, with the aim of steering the community toward making the next important steps in advancing privacy-preserving learning.","sentences":["The availability of rich and vast data sources has greatly advanced machine learning applications in various domains.","However, data with privacy concerns comes with stringent regulations that frequently prohibited data access and data sharing.","Overcoming these obstacles in compliance with privacy considerations is key for technological progress in many real-world application scenarios that involve privacy sensitive data.","Differentially private (DP) data publishing provides a compelling solution, where only a sanitized form of the data is publicly released, enabling privacy-preserving downstream analysis and reproducible research in sensitive domains.","In recent years, various approaches have been proposed for achieving privacy-preserving high-dimensional data generation by private training on top of deep neural networks.","In this paper, we present a novel unified view that systematizes these approaches.","Our view provides a joint design space for systematically deriving methods that cater to different use cases.","We then discuss the strengths, limitations, and inherent correlations between different approaches, aiming to shed light on crucial aspects and inspire future research.","We conclude by presenting potential paths forward for the field of DP data generation, with the aim of steering the community toward making the next important steps in advancing privacy-preserving learning."],"url":"http://arxiv.org/abs/2309.15696v1"}
{"created":"2023-09-27 14:32:39","title":"Breaking NoC Anonymity using Flow Correlation Attack","abstract":"Network-on-Chip (NoC) is widely used as the internal communication fabric in today's multicore System-on-Chip (SoC) designs. Security of the on-chip communication is crucial because exploiting any vulnerability in shared NoC would be a goldmine for an attacker. NoC security relies on effective countermeasures against diverse attacks. We investigate the security strength of existing anonymous routing protocols in NoC architectures. Specifically, this paper makes two important contributions. We show that the existing anonymous routing is vulnerable to machine learning (ML) based flow correlation attacks on NoCs. We propose a lightweight anonymous routing that use traffic obfuscation techniques which can defend against ML-based flow correlation attacks. Experimental studies using both real and synthetic traffic reveal that our proposed attack is successful against state-of-the-art anonymous routing in NoC architectures with a high accuracy (up to 99%) for diverse traffic patterns, while our lightweight countermeasure can defend against ML-based attacks with minor hardware and performance overhead.","sentences":["Network-on-Chip (NoC) is widely used as the internal communication fabric in today's multicore System-on-Chip (SoC) designs.","Security of the on-chip communication is crucial because exploiting any vulnerability in shared NoC would be a goldmine for an attacker.","NoC security relies on effective countermeasures against diverse attacks.","We investigate the security strength of existing anonymous routing protocols in NoC architectures.","Specifically, this paper makes two important contributions.","We show that the existing anonymous routing is vulnerable to machine learning (ML) based flow correlation attacks on NoCs.","We propose a lightweight anonymous routing that use traffic obfuscation techniques which can defend against ML-based flow correlation attacks.","Experimental studies using both real and synthetic traffic reveal that our proposed attack is successful against state-of-the-art anonymous routing in NoC architectures with a high accuracy (up to 99%) for diverse traffic patterns, while our lightweight countermeasure can defend against ML-based attacks with minor hardware and performance overhead."],"url":"http://arxiv.org/abs/2309.15687v1"}
{"created":"2023-09-27 14:32:30","title":"Enhancing End-to-End Conversational Speech Translation Through Target Language Context Utilization","abstract":"Incorporating longer context has been shown to benefit machine translation, but the inclusion of context in end-to-end speech translation (E2E-ST) remains under-studied. To bridge this gap, we introduce target language context in E2E-ST, enhancing coherence and overcoming memory constraints of extended audio segments. Additionally, we propose context dropout to ensure robustness to the absence of context, and further improve performance by adding speaker information. Our proposed contextual E2E-ST outperforms the isolated utterance-based E2E-ST approach. Lastly, we demonstrate that in conversational speech, contextual information primarily contributes to capturing context style, as well as resolving anaphora and named entities.","sentences":["Incorporating longer context has been shown to benefit machine translation, but the inclusion of context in end-to-end speech translation (E2E-ST) remains under-studied.","To bridge this gap, we introduce target language context in E2E-ST, enhancing coherence and overcoming memory constraints of extended audio segments.","Additionally, we propose context dropout to ensure robustness to the absence of context, and further improve performance by adding speaker information.","Our proposed contextual E2E-ST outperforms the isolated utterance-based E2E-ST approach.","Lastly, we demonstrate that in conversational speech, contextual information primarily contributes to capturing context style, as well as resolving anaphora and named entities."],"url":"http://arxiv.org/abs/2309.15686v1"}
{"created":"2023-09-27 14:31:47","title":"Improving Autonomous Driving Safety with POP: A Framework for Accurate Partially Observed Trajectory Predictions","abstract":"Accurate trajectory prediction is crucial for safe and efficient autonomous driving, but handling partial observations presents significant challenges. To address this, we propose a novel trajectory prediction framework called Partial Observations Prediction (POP) for congested urban road scenarios. The framework consists of two stages: self-supervised learning (SSL) and feature distillation. In SSL, a reconstruction branch reconstructs the hidden history of partial observations using a mask procedure and reconstruction head. The feature distillation stage transfers knowledge from a fully observed teacher model to a partially observed student model, improving prediction accuracy. POP achieves comparable results to top-performing methods in open-loop experiments and outperforms the baseline method in closed-loop simulations, including safety metrics. Qualitative results illustrate the superiority of POP in providing reasonable and safe trajectory predictions.","sentences":["Accurate trajectory prediction is crucial for safe and efficient autonomous driving, but handling partial observations presents significant challenges.","To address this, we propose a novel trajectory prediction framework called Partial Observations Prediction (POP) for congested urban road scenarios.","The framework consists of two stages: self-supervised learning (SSL) and feature distillation.","In SSL, a reconstruction branch reconstructs the hidden history of partial observations using a mask procedure and reconstruction head.","The feature distillation stage transfers knowledge from a fully observed teacher model to a partially observed student model, improving prediction accuracy.","POP achieves comparable results to top-performing methods in open-loop experiments and outperforms the baseline method in closed-loop simulations, including safety metrics.","Qualitative results illustrate the superiority of POP in providing reasonable and safe trajectory predictions."],"url":"http://arxiv.org/abs/2309.15685v1"}
{"created":"2023-09-27 14:30:34","title":"End-to-End Streaming Video Temporal Action Segmentation with Reinforce Learning","abstract":"Temporal Action Segmentation (TAS) from video is a kind of frame recognition task for long video with multiple action classes. As an video understanding task for long videos, current methods typically combine multi-modality action recognition models with temporal models to convert feature sequences to label sequences. This approach can only be applied to offline scenarios, which severely limits the TAS application. Therefore, this paper proposes an end-to-end Streaming Video Temporal Action Segmentation with Reinforce Learning (SVTAS-RL). The end-to-end SVTAS which regard TAS as an action segment clustering task can expand the application scenarios of TAS; and RL is used to alleviate the problem of inconsistent optimization objective and direction. Through extensive experiments, the SVTAS-RL model achieves a competitive performance to the state-of-the-art model of TAS on multiple datasets, and shows greater advantages on the ultra-long video dataset EGTEA. This indicates that our method can replace all current TAS models end-to-end and SVTAS-RL is more suitable for long video TAS. Code is availabel at https://github.com/Thinksky5124/SVTAS.","sentences":["Temporal Action Segmentation (TAS) from video is a kind of frame recognition task for long video with multiple action classes.","As an video understanding task for long videos, current methods typically combine multi-modality action recognition models with temporal models to convert feature sequences to label sequences.","This approach can only be applied to offline scenarios, which severely limits the TAS application.","Therefore, this paper proposes an end-to-end Streaming Video Temporal Action Segmentation with Reinforce Learning (SVTAS-RL).","The end-to-end SVTAS which regard TAS as an action segment clustering task can expand the application scenarios of TAS; and RL is used to alleviate the problem of inconsistent optimization objective and direction.","Through extensive experiments, the SVTAS-RL model achieves a competitive performance to the state-of-the-art model of TAS on multiple datasets, and shows greater advantages on the ultra-long video dataset EGTEA.","This indicates that our method can replace all current TAS models end-to-end and SVTAS-RL is more suitable for long video TAS.","Code is availabel at https://github.com/Thinksky5124/SVTAS."],"url":"http://arxiv.org/abs/2309.15683v1"}
{"created":"2023-09-27 14:27:44","title":"Tactile-based Active Inference for Force-Controlled Peg-in-Hole Insertions","abstract":"Reinforcement Learning (RL) has shown great promise for efficiently learning force control policies in peg-in-hole tasks. However, robots often face difficulties due to visual occlusions by the gripper and uncertainties in the initial grasping pose of the peg. These challenges often restrict force-controlled insertion policies to situations where the peg is rigidly fixed to the end-effector. While vision-based tactile sensors offer rich tactile feedback that could potentially address these issues, utilizing them to learn effective tactile policies is both computationally intensive and difficult to generalize. In this paper, we propose a robust tactile insertion policy that can align the tilted peg with the hole using active inference, without the need for extensive training on large datasets. Our approach employs a dual-policy architecture: one policy focuses on insertion, integrating force control and RL to guide the object into the hole, while the other policy performs active inference based on tactile feedback to align the tilted peg with the hole. In real-world experiments, our dual-policy architecture achieved 90% success rate into a hole with a clearance of less than 0.1 mm, significantly outperforming previous methods that lack tactile sensory feedback (5%). To assess the generalizability of our alignment policy, we conducted experiments with five different pegs, demonstrating its effective adaptation to multiple objects.","sentences":["Reinforcement Learning (RL) has shown great promise for efficiently learning force control policies in peg-in-hole tasks.","However, robots often face difficulties due to visual occlusions by the gripper and uncertainties in the initial grasping pose of the peg.","These challenges often restrict force-controlled insertion policies to situations where the peg is rigidly fixed to the end-effector.","While vision-based tactile sensors offer rich tactile feedback that could potentially address these issues, utilizing them to learn effective tactile policies is both computationally intensive and difficult to generalize.","In this paper, we propose a robust tactile insertion policy that can align the tilted peg with the hole using active inference, without the need for extensive training on large datasets.","Our approach employs a dual-policy architecture: one policy focuses on insertion, integrating force control and RL to guide the object into the hole, while the other policy performs active inference based on tactile feedback to align the tilted peg with the hole.","In real-world experiments, our dual-policy architecture achieved 90% success rate into a hole with a clearance of less than 0.1 mm, significantly outperforming previous methods that lack tactile sensory feedback (5%).","To assess the generalizability of our alignment policy, we conducted experiments with five different pegs, demonstrating its effective adaptation to multiple objects."],"url":"http://arxiv.org/abs/2309.15681v1"}
{"created":"2023-09-27 14:21:13","title":"Joint Sampling and Optimisation for Inverse Rendering","abstract":"When dealing with difficult inverse problems such as inverse rendering, using Monte Carlo estimated gradients to optimise parameters can slow down convergence due to variance. Averaging many gradient samples in each iteration reduces this variance trivially. However, for problems that require thousands of optimisation iterations, the computational cost of this approach rises quickly.   We derive a theoretical framework for interleaving sampling and optimisation. We update and reuse past samples with low-variance finite-difference estimators that describe the change in the estimated gradients between each iteration. By combining proportional and finite-difference samples, we continuously reduce the variance of our novel gradient meta-estimators throughout the optimisation process. We investigate how our estimator interlinks with Adam and derive a stable combination.   We implement our method for inverse path tracing and demonstrate how our estimator speeds up convergence on difficult optimisation tasks.","sentences":["When dealing with difficult inverse problems such as inverse rendering, using Monte Carlo estimated gradients to optimise parameters can slow down convergence due to variance.","Averaging many gradient samples in each iteration reduces this variance trivially.","However, for problems that require thousands of optimisation iterations, the computational cost of this approach rises quickly.   ","We derive a theoretical framework for interleaving sampling and optimisation.","We update and reuse past samples with low-variance finite-difference estimators that describe the change in the estimated gradients between each iteration.","By combining proportional and finite-difference samples, we continuously reduce the variance of our novel gradient meta-estimators throughout the optimisation process.","We investigate how our estimator interlinks with Adam and derive a stable combination.   ","We implement our method for inverse path tracing and demonstrate how our estimator speeds up convergence on difficult optimisation tasks."],"url":"http://arxiv.org/abs/2309.15676v1"}
{"created":"2023-09-27 14:18:04","title":"SJTU-TMQA: A quality assessment database for static mesh with texture map","abstract":"In recent years, static meshes with texture maps have become one of the most prevalent digital representations of 3D shapes in various applications, such as animation, gaming, medical imaging, and cultural heritage applications. However, little research has been done on the quality assessment of textured meshes, which hinders the development of quality-oriented applications, such as mesh compression and enhancement. In this paper, we create a large-scale textured mesh quality assessment database, namely SJTU-TMQA, which includes 21 reference meshes and 945 distorted samples. The meshes are rendered into processed video sequences and then conduct subjective experiments to obtain mean opinion scores (MOS). The diversity of content and accuracy of MOS has been shown to validate its heterogeneity and reliability. The impact of various types of distortion on human perception is demonstrated. 13 state-of-the-art objective metrics are evaluated on SJTU-TMQA. The results report the highest correlation of around 0.6, indicating the need for more effective objective metrics. The SJTU-TMQA is available at https://ccccby.github.io","sentences":["In recent years, static meshes with texture maps have become one of the most prevalent digital representations of 3D shapes in various applications, such as animation, gaming, medical imaging, and cultural heritage applications.","However, little research has been done on the quality assessment of textured meshes, which hinders the development of quality-oriented applications, such as mesh compression and enhancement.","In this paper, we create a large-scale textured mesh quality assessment database, namely SJTU-TMQA, which includes 21 reference meshes and 945 distorted samples.","The meshes are rendered into processed video sequences and then conduct subjective experiments to obtain mean opinion scores (MOS).","The diversity of content and accuracy of MOS has been shown to validate its heterogeneity and reliability.","The impact of various types of distortion on human perception is demonstrated.","13 state-of-the-art objective metrics are evaluated on SJTU-TMQA.","The results report the highest correlation of around 0.6, indicating the need for more effective objective metrics.","The SJTU-TMQA is available at https://ccccby.github.io"],"url":"http://arxiv.org/abs/2309.15675v1"}
{"created":"2023-09-27 14:17:53","title":"Speech collage: code-switched audio generation by collaging monolingual corpora","abstract":"Designing effective automatic speech recognition (ASR) systems for Code-Switching (CS) often depends on the availability of the transcribed CS resources. To address data scarcity, this paper introduces Speech Collage, a method that synthesizes CS data from monolingual corpora by splicing audio segments. We further improve the smoothness quality of audio generation using an overlap-add approach. We investigate the impact of generated data on speech recognition in two scenarios: using in-domain CS text and a zero-shot approach with synthesized CS text. Empirical results highlight up to 34.4% and 16.2% relative reductions in Mixed-Error Rate and Word-Error Rate for in-domain and zero-shot scenarios, respectively. Lastly, we demonstrate that CS augmentation bolsters the model's code-switching inclination and reduces its monolingual bias.","sentences":["Designing effective automatic speech recognition (ASR) systems for Code-Switching (CS) often depends on the availability of the transcribed CS resources.","To address data scarcity, this paper introduces Speech Collage, a method that synthesizes CS data from monolingual corpora by splicing audio segments.","We further improve the smoothness quality of audio generation using an overlap-add approach.","We investigate the impact of generated data on speech recognition in two scenarios: using in-domain CS text and a zero-shot approach with synthesized CS text.","Empirical results highlight up to 34.4% and 16.2% relative reductions in Mixed-Error Rate and Word-Error Rate for in-domain and zero-shot scenarios, respectively.","Lastly, we demonstrate that CS augmentation bolsters the model's code-switching inclination and reduces its monolingual bias."],"url":"http://arxiv.org/abs/2309.15674v1"}
{"created":"2023-09-27 14:10:57","title":"MONOVAB : An Annotated Corpus for Bangla Multi-label Emotion Detection","abstract":"In recent years, Sentiment Analysis (SA) and Emotion Recognition (ER) have been increasingly popular in the Bangla language, which is the seventh most spoken language throughout the entire world. However, the language is structurally complicated, which makes this field arduous to extract emotions in an accurate manner. Several distinct approaches such as the extraction of positive and negative sentiments as well as multiclass emotions, have been implemented in this field of study. Nevertheless, the extraction of multiple sentiments is an almost untouched area in this language. Which involves identifying several feelings based on a single piece of text. Therefore, this study demonstrates a thorough method for constructing an annotated corpus based on scrapped data from Facebook to bridge the gaps in this subject area to overcome the challenges. To make this annotation more fruitful, the context-based approach has been used. Bidirectional Encoder Representations from Transformers (BERT), a well-known methodology of transformers, have been shown the best results of all methods implemented. Finally, a web application has been developed to demonstrate the performance of the pre-trained top-performer model (BERT) for multi-label ER in Bangla.","sentences":["In recent years, Sentiment Analysis (SA) and Emotion Recognition (ER) have been increasingly popular in the Bangla language, which is the seventh most spoken language throughout the entire world.","However, the language is structurally complicated, which makes this field arduous to extract emotions in an accurate manner.","Several distinct approaches such as the extraction of positive and negative sentiments as well as multiclass emotions, have been implemented in this field of study.","Nevertheless, the extraction of multiple sentiments is an almost untouched area in this language.","Which involves identifying several feelings based on a single piece of text.","Therefore, this study demonstrates a thorough method for constructing an annotated corpus based on scrapped data from Facebook to bridge the gaps in this subject area to overcome the challenges.","To make this annotation more fruitful, the context-based approach has been used.","Bidirectional Encoder Representations from Transformers (BERT), a well-known methodology of transformers, have been shown the best results of all methods implemented.","Finally, a web application has been developed to demonstrate the performance of the pre-trained top-performer model (BERT) for multi-label ER in Bangla."],"url":"http://arxiv.org/abs/2309.15670v1"}
{"created":"2023-09-27 14:09:15","title":"On Computational Entanglement and Its Interpretation in Adversarial Machine Learning","abstract":"Adversarial examples in machine learning has emerged as a focal point of research due to their remarkable ability to deceive models with seemingly inconspicuous input perturbations, potentially resulting in severe consequences. In this study, we embark on a comprehensive exploration of adversarial machine learning models, shedding light on their intrinsic complexity and interpretability. Our investigation reveals intriguing links between machine learning model complexity and Einstein's theory of special relativity, through the concept of entanglement. More specific, we define entanglement computationally and demonstrate that distant feature samples can exhibit strong correlations, akin to entanglement in quantum realm. This revelation challenges conventional perspectives in describing the phenomenon of adversarial transferability observed in contemporary machine learning models. By drawing parallels with the relativistic effects of time dilation and length contraction during computation, we gain deeper insights into adversarial machine learning, paving the way for more robust and interpretable models in this rapidly evolving field.","sentences":["Adversarial examples in machine learning has emerged as a focal point of research due to their remarkable ability to deceive models with seemingly inconspicuous input perturbations, potentially resulting in severe consequences.","In this study, we embark on a comprehensive exploration of adversarial machine learning models, shedding light on their intrinsic complexity and interpretability.","Our investigation reveals intriguing links between machine learning model complexity and Einstein's theory of special relativity, through the concept of entanglement.","More specific, we define entanglement computationally and demonstrate that distant feature samples can exhibit strong correlations, akin to entanglement in quantum realm.","This revelation challenges conventional perspectives in describing the phenomenon of adversarial transferability observed in contemporary machine learning models.","By drawing parallels with the relativistic effects of time dilation and length contraction during computation, we gain deeper insights into adversarial machine learning, paving the way for more robust and interpretable models in this rapidly evolving field."],"url":"http://arxiv.org/abs/2309.15669v1"}
{"created":"2023-09-27 14:08:01","title":"A New Centralized Multi-Node Repair Scheme of MSR codes with Error-Correcting Capability","abstract":"Minimum storage regenerating (MSR) codes, with the MDS property and the optimal repair bandwidth, are widely used in distributed storage systems (DSS) for data recovery. In this paper, we consider the construction of $(n,k,l)$ MSR codes in the centralized model that can repair $h$ failed nodes simultaneously with $e$ out $d$ helper nodes providing erroneous information. We first propose the new repair scheme, and give a complete proof of the lower bound on the amount of symbols downloaded from the helped nodes, provided that some of helper nodes provide erroneous information. Then we focus on two explicit constructions with the repair scheme proposed. For $2\\leq h\\leq n-k$, $k+2e\\leq d \\leq n-h$ and $d\\equiv k+2e \\;(\\mod{h})$, the first one has the UER $(h, d)$-optimal repair property, and the second one has the UER $(h, d)$-optimal access property. Compared with the original constructions (Ye and Barg, IEEE Tran. Inf. Theory, Vol. 63, April 2017), our constructions have improvements in three aspects: 1) The proposed repair scheme is more feasible than the one-by-one scheme presented by Ye and Barg in a parallel data system; 2) The sub-packetization is reduced from $\\left(\\operatorname{lcm}(d-k+1, d-k+2,\\cdots, d-k+h)\\right)^n$ to $\\left((d-2e-k+h)/h\\right)^n$, which reduces at least by a factor of $(h(d-k+h))^n$; 3) The field size of the first construction is reduced to $|\\mathbb{F}| \\geq n(d-2e-k+h)/h$, which reduces at least by a factor of $h(d-k+h)$. Small sub-packetization and small field size are preferred in practice due to the limited storage capacity and low computation complexity in the process of encoding, decoding and repairing.","sentences":["Minimum storage regenerating (MSR) codes, with the MDS property and the optimal repair bandwidth, are widely used in distributed storage systems (DSS) for data recovery.","In this paper, we consider the construction of $(n,k,l)$ MSR codes in the centralized model that can repair $h$ failed nodes simultaneously with $e$ out $d$ helper nodes providing erroneous information.","We first propose the new repair scheme, and give a complete proof of the lower bound on the amount of symbols downloaded from the helped nodes, provided that some of helper nodes provide erroneous information.","Then we focus on two explicit constructions with the repair scheme proposed.","For $2\\leq h\\leq n-k$, $k+2e\\leq d \\leq n-h$ and $d\\equiv k+2e \\;(\\mod{h})$, the first one has the UER $(h, d)$-optimal repair property, and the second one has the UER $(h, d)$-optimal access property.","Compared with the original constructions (Ye and Barg, IEEE Tran.","Inf.","Theory, Vol. 63, April 2017), our constructions have improvements in three aspects: 1) The proposed repair scheme is more feasible than the one-by-one scheme presented by Ye and Barg in a parallel data system; 2) The sub-packetization is reduced from $\\left(\\operatorname{lcm}(d-k+1, d-k+2,\\cdots, d-k+h)\\right)^n$ to $\\left((d-2e-k+h)/h\\right)^n$, which reduces at least by a factor of $(h(d-k+h))^n$; 3) The field size of the first construction is reduced to $|\\mathbb{F}| \\geq n(d-2e-k+h)/h$, which reduces at least by a factor of $h(d-k+h)$. Small sub-packetization and small field size are preferred in practice due to the limited storage capacity and low computation complexity in the process of encoding, decoding and repairing."],"url":"http://arxiv.org/abs/2309.15668v1"}
{"created":"2023-09-27 13:55:57","title":"Dynamic Prompt Learning: Addressing Cross-Attention Leakage for Text-Based Image Editing","abstract":"Large-scale text-to-image generative models have been a ground-breaking development in generative AI, with diffusion models showing their astounding ability to synthesize convincing images following an input text prompt. The goal of image editing research is to give users control over the generated images by modifying the text prompt. Current image editing techniques are susceptible to unintended modifications of regions outside the targeted area, such as on the background or on distractor objects which have some semantic or visual relationship with the targeted object. According to our experimental findings, inaccurate cross-attention maps are at the root of this problem. Based on this observation, we propose Dynamic Prompt Learning (DPL) to force cross-attention maps to focus on correct noun words in the text prompt. By updating the dynamic tokens for nouns in the textual input with the proposed leakage repairment losses, we achieve fine-grained image editing over particular objects while preventing undesired changes to other image regions. Our method DPL, based on the publicly available Stable Diffusion, is extensively evaluated on a wide range of images, and consistently obtains superior results both quantitatively (CLIP score, Structure-Dist) and qualitatively (on user-evaluation). We show improved prompt editing results for Word-Swap, Prompt Refinement, and Attention Re-weighting, especially for complex multi-object scenes.","sentences":["Large-scale text-to-image generative models have been a ground-breaking development in generative AI, with diffusion models showing their astounding ability to synthesize convincing images following an input text prompt.","The goal of image editing research is to give users control over the generated images by modifying the text prompt.","Current image editing techniques are susceptible to unintended modifications of regions outside the targeted area, such as on the background or on distractor objects which have some semantic or visual relationship with the targeted object.","According to our experimental findings, inaccurate cross-attention maps are at the root of this problem.","Based on this observation, we propose Dynamic Prompt Learning (DPL) to force cross-attention maps to focus on correct noun words in the text prompt.","By updating the dynamic tokens for nouns in the textual input with the proposed leakage repairment losses, we achieve fine-grained image editing over particular objects while preventing undesired changes to other image regions.","Our method DPL, based on the publicly available Stable Diffusion, is extensively evaluated on a wide range of images, and consistently obtains superior results both quantitatively (CLIP score, Structure-Dist) and qualitatively (on user-evaluation).","We show improved prompt editing results for Word-Swap, Prompt Refinement, and Attention Re-weighting, especially for complex multi-object scenes."],"url":"http://arxiv.org/abs/2309.15664v1"}
{"created":"2023-09-27 13:52:53","title":"Human Kinematics-inspired Skeleton-based Video Anomaly Detection","abstract":"Previous approaches to detecting human anomalies in videos have typically relied on implicit modeling by directly applying the model to video or skeleton data, potentially resulting in inaccurate modeling of motion information. In this paper, we conduct an exploratory study and introduce a new idea called HKVAD (Human Kinematic-inspired Video Anomaly Detection) for video anomaly detection, which involves the explicit use of human kinematic features to detect anomalies. To validate the effectiveness and potential of this perspective, we propose a pilot method that leverages the kinematic features of the skeleton pose, with a specific focus on the walking stride, skeleton displacement at feet level, and neck level. Following this, the method employs a normalizing flow model to estimate density and detect anomalies based on the estimated density. Based on the number of kinematic features used, we have devised three straightforward variant methods and conducted experiments on two highly challenging public datasets, ShanghaiTech and UBnormal. Our method achieves good results with minimal computational resources, validating its effectiveness and potential.","sentences":["Previous approaches to detecting human anomalies in videos have typically relied on implicit modeling by directly applying the model to video or skeleton data, potentially resulting in inaccurate modeling of motion information.","In this paper, we conduct an exploratory study and introduce a new idea called HKVAD (Human Kinematic-inspired Video Anomaly Detection) for video anomaly detection, which involves the explicit use of human kinematic features to detect anomalies.","To validate the effectiveness and potential of this perspective, we propose a pilot method that leverages the kinematic features of the skeleton pose, with a specific focus on the walking stride, skeleton displacement at feet level, and neck level.","Following this, the method employs a normalizing flow model to estimate density and detect anomalies based on the estimated density.","Based on the number of kinematic features used, we have devised three straightforward variant methods and conducted experiments on two highly challenging public datasets, ShanghaiTech and UBnormal.","Our method achieves good results with minimal computational resources, validating its effectiveness and potential."],"url":"http://arxiv.org/abs/2309.15662v1"}
{"created":"2023-09-27 13:48:12","title":"Federated Deep Equilibrium Learning: A Compact Shared Representation for Edge Communication Efficiency","abstract":"Federated Learning (FL) is a prominent distributed learning paradigm facilitating collaboration among nodes within an edge network to co-train a global model without centralizing data. By shifting computation to the network edge, FL offers robust and responsive edge-AI solutions and enhance privacy-preservation. However, deploying deep FL models within edge environments is often hindered by communication bottlenecks, data heterogeneity, and memory limitations. To address these challenges jointly, we introduce FeDEQ, a pioneering FL framework that effectively employs deep equilibrium learning and consensus optimization to exploit a compact shared data representation across edge nodes, allowing the derivation of personalized models specific to each node. We delve into a unique model structure composed of an equilibrium layer followed by traditional neural network layers. Here, the equilibrium layer functions as a global feature representation that edge nodes can adapt to personalize their local layers. Capitalizing on FeDEQ's compactness and representation power, we present a novel distributed algorithm rooted in the alternating direction method of multipliers (ADMM) consensus optimization and theoretically establish its convergence for smooth objectives. Experiments across various benchmarks demonstrate that FeDEQ achieves performance comparable to state-of-the-art personalized methods while employing models of up to 4 times smaller in communication size and 1.5 times lower memory footprint during training.","sentences":["Federated Learning (FL) is a prominent distributed learning paradigm facilitating collaboration among nodes within an edge network to co-train a global model without centralizing data.","By shifting computation to the network edge, FL offers robust and responsive edge-AI solutions and enhance privacy-preservation.","However, deploying deep FL models within edge environments is often hindered by communication bottlenecks, data heterogeneity, and memory limitations.","To address these challenges jointly, we introduce FeDEQ, a pioneering FL framework that effectively employs deep equilibrium learning and consensus optimization to exploit a compact shared data representation across edge nodes, allowing the derivation of personalized models specific to each node.","We delve into a unique model structure composed of an equilibrium layer followed by traditional neural network layers.","Here, the equilibrium layer functions as a global feature representation that edge nodes can adapt to personalize their local layers.","Capitalizing on FeDEQ's compactness and representation power, we present a novel distributed algorithm rooted in the alternating direction method of multipliers (ADMM) consensus optimization and theoretically establish its convergence for smooth objectives.","Experiments across various benchmarks demonstrate that FeDEQ achieves performance comparable to state-of-the-art personalized methods while employing models of up to 4 times smaller in communication size and 1.5 times lower memory footprint during training."],"url":"http://arxiv.org/abs/2309.15659v1"}
{"created":"2023-09-27 13:45:38","title":"Conversational Feedback in Scripted versus Spontaneous Dialogues: A Comparative Analysis","abstract":"Scripted dialogues such as movie and TV subtitles constitute a widespread source of training data for conversational NLP models. However, the linguistic characteristics of those dialogues are notably different from those observed in corpora of spontaneous interactions. This difference is particularly marked for communicative feedback and grounding phenomena such as backchannels, acknowledgments, or clarification requests. Such signals are known to constitute a key part of the conversation flow and are used by the dialogue participants to provide feedback to one another on their perception of the ongoing interaction. This paper presents a quantitative analysis of such communicative feedback phenomena in both subtitles and spontaneous conversations. Based on dialogue data in English, French, German, Hungarian, Italian, Japanese, Norwegian and Chinese, we extract both lexical statistics and classification outputs obtained with a neural dialogue act tagger. Two main findings of this empirical study are that (1) conversational feedback is markedly less frequent in subtitles than in spontaneous dialogues and (2) subtitles contain a higher proportion of negative feedback. Furthermore, we show that dialogue responses generated by large language models also follow the same underlying trends and include comparatively few occurrences of communicative feedback, except when those models are explicitly fine-tuned on spontaneous dialogues.","sentences":["Scripted dialogues such as movie and TV subtitles constitute a widespread source of training data for conversational NLP models.","However, the linguistic characteristics of those dialogues are notably different from those observed in corpora of spontaneous interactions.","This difference is particularly marked for communicative feedback and grounding phenomena such as backchannels, acknowledgments, or clarification requests.","Such signals are known to constitute a key part of the conversation flow and are used by the dialogue participants to provide feedback to one another on their perception of the ongoing interaction.","This paper presents a quantitative analysis of such communicative feedback phenomena in both subtitles and spontaneous conversations.","Based on dialogue data in English, French, German, Hungarian, Italian, Japanese, Norwegian and Chinese, we extract both lexical statistics and classification outputs obtained with a neural dialogue act tagger.","Two main findings of this empirical study are that (1) conversational feedback is markedly less frequent in subtitles than in spontaneous dialogues and (2) subtitles contain a higher proportion of negative feedback.","Furthermore, we show that dialogue responses generated by large language models also follow the same underlying trends and include comparatively few occurrences of communicative feedback, except when those models are explicitly fine-tuned on spontaneous dialogues."],"url":"http://arxiv.org/abs/2309.15656v1"}
{"created":"2023-09-27 13:36:03","title":"Generative Speech Recognition Error Correction with Large Language Models","abstract":"We explore the ability of large language models (LLMs) to act as ASR post-processors that perform rescoring and error correction. Our focus is on instruction prompting to let LLMs perform these task without fine-tuning, for which we evaluate different prompting schemes, both zero- and few-shot in-context learning, and a novel task-activating prompting (TAP) method that combines instruction and demonstration. Using a pre-trained first-pass system and rescoring output on two out-of-domain tasks (ATIS and WSJ), we show that rescoring only by in-context learning with frozen LLMs achieves results that are competitive with rescoring by domain-tuned LMs. By combining prompting techniques with fine-tuning we achieve error rates below the N-best oracle level, showcasing the generalization power of the LLMs.","sentences":["We explore the ability of large language models (LLMs) to act as ASR post-processors that perform rescoring and error correction.","Our focus is on instruction prompting to let LLMs perform these task without fine-tuning, for which we evaluate different prompting schemes, both zero- and few-shot in-context learning, and a novel task-activating prompting (TAP) method that combines instruction and demonstration.","Using a pre-trained first-pass system and rescoring output on two out-of-domain tasks (ATIS and WSJ), we show that rescoring only by in-context learning with frozen LLMs achieves results that are competitive with rescoring by domain-tuned LMs.","By combining prompting techniques with fine-tuning we achieve error rates below the N-best oracle level, showcasing the generalization power of the LLMs."],"url":"http://arxiv.org/abs/2309.15649v1"}
{"created":"2023-09-27 13:35:45","title":"SANGEA: Scalable and Attributed Network Generation","abstract":"The topic of synthetic graph generators (SGGs) has recently received much attention due to the wave of the latest breakthroughs in generative modelling. However, many state-of-the-art SGGs do not scale well with the graph size. Indeed, in the generation process, all the possible edges for a fixed number of nodes must often be considered, which scales in $\\mathcal{O}(N^2)$, with $N$ being the number of nodes in the graph. For this reason, many state-of-the-art SGGs are not applicable to large graphs. In this paper, we present SANGEA, a sizeable synthetic graph generation framework which extends the applicability of any SGG to large graphs. By first splitting the large graph into communities, SANGEA trains one SGG per community, then links the community graphs back together to create a synthetic large graph. Our experiments show that the graphs generated by SANGEA have high similarity to the original graph, in terms of both topology and node feature distribution. Additionally, these generated graphs achieve high utility on downstream tasks such as link prediction. Finally, we provide a privacy assessment of the generated graphs to show that, even though they have excellent utility, they also achieve reasonable privacy scores.","sentences":["The topic of synthetic graph generators (SGGs) has recently received much attention due to the wave of the latest breakthroughs in generative modelling.","However, many state-of-the-art SGGs do not scale well with the graph size.","Indeed, in the generation process, all the possible edges for a fixed number of nodes must often be considered, which scales in $\\mathcal{O}(N^2)$, with $N$ being the number of nodes in the graph.","For this reason, many state-of-the-art SGGs are not applicable to large graphs.","In this paper, we present SANGEA, a sizeable synthetic graph generation framework which extends the applicability of any SGG to large graphs.","By first splitting the large graph into communities, SANGEA trains one SGG per community, then links the community graphs back together to create a synthetic large graph.","Our experiments show that the graphs generated by SANGEA have high similarity to the original graph, in terms of both topology and node feature distribution.","Additionally, these generated graphs achieve high utility on downstream tasks such as link prediction.","Finally, we provide a privacy assessment of the generated graphs to show that, even though they have excellent utility, they also achieve reasonable privacy scores."],"url":"http://arxiv.org/abs/2309.15648v1"}
{"created":"2023-09-27 13:32:28","title":"Black-Box Identity Testing of Noncommutative Rational Formulas in Deterministic Quasipolynomial Time","abstract":"Rational Identity Testing (RIT) is the decision problem of determining whether or not a given noncommutative rational formula computes zero in the free skew field. It admits a deterministic polynomial-time white-box algorithm [Garg et al., 2016; Ivanyos et. al., 2018; Hamada and Hirai, 2021], and a randomized polynomial-time black-box algorithm [Derksen and Makam, 2017] via singularity testing of linear matrices over the free skew field.   Designing a subexponential-time deterministic RIT algorithm in black-box is a major open problem in this area. Despite being open for several years, this question has seen very limited progress. In fact, the only known result in this direction is the construction of a quasipolynomial-size hitting set for rational formulas of only inversion height two [Arvind et al., 2022].   In this paper, we settle this problem and obtain a deterministic quasipolynomial-time RIT algorithm for the general case in the black-box setting. Our algorithm uses ideas from the theory of finite dimensional division algebras, algebraic complexity theory, and the theory of generalized formal power series.","sentences":["Rational Identity Testing (RIT) is the decision problem of determining whether or not a given noncommutative rational formula computes zero in the free skew field.","It admits a deterministic polynomial-time white-box algorithm","[Garg et al., 2016; Ivanyos et.","al., 2018; Hamada and Hirai, 2021], and a randomized polynomial-time black-box algorithm","[Derksen and Makam, 2017] via singularity testing of linear matrices over the free skew field.   ","Designing a subexponential-time deterministic RIT algorithm in black-box is a major open problem in this area.","Despite being open for several years, this question has seen very limited progress.","In fact, the only known result in this direction is the construction of a quasipolynomial-size hitting set for rational formulas of only inversion height two","[Arvind et al., 2022].   In this paper, we settle this problem and obtain a deterministic quasipolynomial-time RIT algorithm for the general case in the black-box setting.","Our algorithm uses ideas from the theory of finite dimensional division algebras, algebraic complexity theory, and the theory of generalized formal power series."],"url":"http://arxiv.org/abs/2309.15647v1"}
{"created":"2023-09-27 13:31:43","title":"Cold & Warm Net: Addressing Cold-Start Users in Recommender Systems","abstract":"Cold-start recommendation is one of the major challenges faced by recommender systems (RS). Herein, we focus on the user cold-start problem. Recently, methods utilizing side information or meta-learning have been used to model cold-start users. However, it is difficult to deploy these methods to industrial RS. There has not been much research that pays attention to the user cold-start problem in the matching stage. In this paper, we propose Cold & Warm Net based on expert models who are responsible for modeling cold-start and warm-up users respectively. A gate network is applied to incorporate the results from two experts. Furthermore, dynamic knowledge distillation acting as a teacher selector is introduced to assist experts in better learning user representation. With comprehensive mutual information, features highly relevant to user behavior are selected for the bias net which explicitly models user behavior bias. Finally, we evaluate our Cold & Warm Net on public datasets in comparison to models commonly applied in the matching stage and it outperforms other models on all user types. The proposed model has also been deployed on an industrial short video platform and achieves a significant increase in app dwell time and user retention rate.","sentences":["Cold-start recommendation is one of the major challenges faced by recommender systems (RS).","Herein, we focus on the user cold-start problem.","Recently, methods utilizing side information or meta-learning have been used to model cold-start users.","However, it is difficult to deploy these methods to industrial RS.","There has not been much research that pays attention to the user cold-start problem in the matching stage.","In this paper, we propose Cold & Warm Net based on expert models who are responsible for modeling cold-start and warm-up users respectively.","A gate network is applied to incorporate the results from two experts.","Furthermore, dynamic knowledge distillation acting as a teacher selector is introduced to assist experts in better learning user representation.","With comprehensive mutual information, features highly relevant to user behavior are selected for the bias net which explicitly models user behavior bias.","Finally, we evaluate our Cold & Warm Net on public datasets in comparison to models commonly applied in the matching stage and it outperforms other models on all user types.","The proposed model has also been deployed on an industrial short video platform and achieves a significant increase in app dwell time and user retention rate."],"url":"http://arxiv.org/abs/2309.15646v1"}
{"created":"2023-09-27 13:31:42","title":"Sidestepping Barriers for Dominating Set in Parameterized Complexity","abstract":"We study the classic {\\sc Dominating Set} problem with respect to several prominent parameters. Specifically, we present algorithmic results that sidestep time complexity barriers by the incorporation of either approximation or larger parameterization. Our results span several parameterization regimes, including: (i,ii,iii) time/ratio-tradeoff for the parameters {\\em treewidth}, {\\em vertex modulator to constant treewidth} and {\\em solution size}; (iv,v) FPT-algorithms for the parameters {\\em vertex cover number} and {\\em feedback edge set number}; and (vi) compression for the parameter {\\em feedback edge set number}.","sentences":["We study the classic {\\sc Dominating Set} problem with respect to several prominent parameters.","Specifically, we present algorithmic results that sidestep time complexity barriers by the incorporation of either approximation or larger parameterization.","Our results span several parameterization regimes, including: (i,ii,iii) time/ratio-tradeoff for the parameters {\\em treewidth}, {\\em vertex modulator to constant treewidth} and {\\em solution size}; (iv,v) FPT-algorithms for the parameters {\\em vertex cover number} and {\\em feedback edge set number}; and (vi) compression for the parameter {\\em feedback edge set number}."],"url":"http://arxiv.org/abs/2309.15645v1"}
{"created":"2023-09-27 13:19:30","title":"Efficient Exact Subgraph Matching via GNN-based Path Dominance Embedding (Technical Report)","abstract":"The classic problem of exact subgraph matching returns those subgraphs in a large-scale data graph that are isomorphic to a given query graph, which has gained increasing importance in many real-world applications such as social network analysis, knowledge graph discovery in the Semantic Web, bibliographical network mining, and so on. In this paper, we propose a novel and effective \\textit{graph neural network (GNN)-based path embedding framework} (GNN-PE), which allows efficient exact subgraph matching without introducing false dismissals. Unlike traditional GNN-based graph embeddings that only produce approximate subgraph matching results, in this paper, we carefully devise GNN-based embeddings for paths, such that: if two paths (and 1-hop neighbors of vertices on them) have the subgraph relationship, their corresponding GNN-based embedding vectors will strictly follow the dominance relationship. With such a newly designed property of path dominance embeddings, we are able to propose effective pruning strategies based on path label/dominance embeddings and guarantee no false dismissals for subgraph matching. We build multidimensional indexes over path embedding vectors, and develop an efficient subgraph matching algorithm by traversing indexes over graph partitions in parallel and applying our pruning methods. We also propose a cost-model-based query plan that obtains query paths from the query graph with low query cost. Through extensive experiments, we confirm the efficiency and effectiveness of our proposed GNN-PE approach for exact subgraph matching on both real and synthetic graph data.","sentences":["The classic problem of exact subgraph matching returns those subgraphs in a large-scale data graph that are isomorphic to a given query graph, which has gained increasing importance in many real-world applications such as social network analysis, knowledge graph discovery in the Semantic Web, bibliographical network mining, and so on.","In this paper, we propose a novel and effective \\textit{graph neural network (GNN)-based path embedding framework} (GNN-PE), which allows efficient exact subgraph matching without introducing false dismissals.","Unlike traditional GNN-based graph embeddings that only produce approximate subgraph matching results, in this paper, we carefully devise GNN-based embeddings for paths, such that: if two paths (and 1-hop neighbors of vertices on them) have the subgraph relationship, their corresponding GNN-based embedding vectors will strictly follow the dominance relationship.","With such a newly designed property of path dominance embeddings, we are able to propose effective pruning strategies based on path label/dominance embeddings and guarantee no false dismissals for subgraph matching.","We build multidimensional indexes over path embedding vectors, and develop an efficient subgraph matching algorithm by traversing indexes over graph partitions in parallel and applying our pruning methods.","We also propose a cost-model-based query plan that obtains query paths from the query graph with low query cost.","Through extensive experiments, we confirm the efficiency and effectiveness of our proposed GNN-PE approach for exact subgraph matching on both real and synthetic graph data."],"url":"http://arxiv.org/abs/2309.15641v1"}
{"created":"2023-09-27 13:18:23","title":"Enhancing Sharpness-Aware Optimization Through Variance Suppression","abstract":"Sharpness-aware minimization (SAM) has well documented merits in enhancing generalization of deep neural networks, even without sizable data augmentation. Embracing the geometry of the loss function, where neighborhoods of 'flat minima' heighten generalization ability, SAM seeks 'flat valleys' by minimizing the maximum loss caused by an adversary perturbing parameters within the neighborhood. Although critical to account for sharpness of the loss function, such an 'over-friendly adversary' can curtail the outmost level of generalization. The novel approach of this contribution fosters stabilization of adversaries through variance suppression (VaSSO) to avoid such friendliness. VaSSO's provable stability safeguards its numerical improvement over SAM in model-agnostic tasks, including image classification and machine translation. In addition, experiments confirm that VaSSO endows SAM with robustness against high levels of label noise.","sentences":["Sharpness-aware minimization (SAM) has well documented merits in enhancing generalization of deep neural networks, even without sizable data augmentation.","Embracing the geometry of the loss function, where neighborhoods of 'flat minima' heighten generalization ability, SAM seeks 'flat valleys' by minimizing the maximum loss caused by an adversary perturbing parameters within the neighborhood.","Although critical to account for sharpness of the loss function, such an 'over-friendly adversary' can curtail the outmost level of generalization.","The novel approach of this contribution fosters stabilization of adversaries through variance suppression (VaSSO) to avoid such friendliness.","VaSSO's provable stability safeguards its numerical improvement over SAM in model-agnostic tasks, including image classification and machine translation.","In addition, experiments confirm that VaSSO endows SAM with robustness against high levels of label noise."],"url":"http://arxiv.org/abs/2309.15639v1"}
{"created":"2023-09-27 13:08:15","title":"Position and Orientation-Aware One-Shot Learning for Medical Action Recognition from Signal Data","abstract":"In this work, we propose a position and orientation-aware one-shot learning framework for medical action recognition from signal data. The proposed framework comprises two stages and each stage includes signal-level image generation (SIG), cross-attention (CsA), dynamic time warping (DTW) modules and the information fusion between the proposed privacy-preserved position and orientation features. The proposed SIG method aims to transform the raw skeleton data into privacy-preserved features for training. The CsA module is developed to guide the network in reducing medical action recognition bias and more focusing on important human body parts for each specific action, aimed at addressing similar medical action related issues. Moreover, the DTW module is employed to minimize temporal mismatching between instances and further improve model performance. Furthermore, the proposed privacy-preserved orientation-level features are utilized to assist the position-level features in both of the two stages for enhancing medical action recognition performance. Extensive experimental results on the widely-used and well-known NTU RGB+D 60, NTU RGB+D 120, and PKU-MMD datasets all demonstrate the effectiveness of the proposed method, which outperforms the other state-of-the-art methods with general dataset partitioning by 2.7%, 6.2% and 4.1%, respectively.","sentences":["In this work, we propose a position and orientation-aware one-shot learning framework for medical action recognition from signal data.","The proposed framework comprises two stages and each stage includes signal-level image generation (SIG), cross-attention (CsA), dynamic time warping (DTW) modules and the information fusion between the proposed privacy-preserved position and orientation features.","The proposed SIG method aims to transform the raw skeleton data into privacy-preserved features for training.","The CsA module is developed to guide the network in reducing medical action recognition bias and more focusing on important human body parts for each specific action, aimed at addressing similar medical action related issues.","Moreover, the DTW module is employed to minimize temporal mismatching between instances and further improve model performance.","Furthermore, the proposed privacy-preserved orientation-level features are utilized to assist the position-level features in both of the two stages for enhancing medical action recognition performance.","Extensive experimental results on the widely-used and well-known NTU RGB+D 60, NTU RGB+D 120, and PKU-MMD datasets all demonstrate the effectiveness of the proposed method, which outperforms the other state-of-the-art methods with general dataset partitioning by 2.7%, 6.2% and 4.1%, respectively."],"url":"http://arxiv.org/abs/2309.15635v1"}
{"created":"2023-09-27 13:02:14","title":"Design and Optimization of Residual Neural Network Accelerators for Low-Power FPGAs Using High-Level Synthesis","abstract":"Residual neural networks are widely used in computer vision tasks. They enable the construction of deeper and more accurate models by mitigating the vanishing gradient problem. Their main innovation is the residual block which allows the output of one layer to bypass one or more intermediate layers and be added to the output of a later layer. Their complex structure and the buffering required by the residual block make them difficult to implement on resource-constrained platforms. We present a novel design flow for implementing deep learning models for field programmable gate arrays optimized for ResNets, using a strategy to reduce their buffering overhead to obtain a resource-efficient implementation of the residual layer. Our high-level synthesis (HLS)-based flow encompasses a thorough set of design principles and optimization strategies, exploiting in novel ways standard techniques such as temporal reuse and loop merging to efficiently map ResNet models, and potentially other skip connection-based NN architectures, into FPGA. The models are quantized to 8-bit integers for both weights and activations, 16-bit for biases, and 32-bit for accumulations. The experimental results are obtained on the CIFAR-10 dataset using ResNet8 and ResNet20 implemented with Xilinx FPGAs using HLS on the Ultra96-V2 and Kria KV260 boards. Compared to the state-of-the-art on the Kria KV260 board, our ResNet20 implementation achieves 2.88X speedup with 0.5% higher accuracy of 91.3%, while ResNet8 accuracy improves by 2.8% to 88.7%. The throughputs of ResNet8 and ResNet20 are 12971 FPS and 3254 FPS on the Ultra96 board, and 30153 FPS and 7601 FPS on the Kria KV26, respectively. They Pareto-dominate state-of-the-art solutions concerning accuracy, throughput, and energy.","sentences":["Residual neural networks are widely used in computer vision tasks.","They enable the construction of deeper and more accurate models by mitigating the vanishing gradient problem.","Their main innovation is the residual block which allows the output of one layer to bypass one or more intermediate layers and be added to the output of a later layer.","Their complex structure and the buffering required by the residual block make them difficult to implement on resource-constrained platforms.","We present a novel design flow for implementing deep learning models for field programmable gate arrays optimized for ResNets, using a strategy to reduce their buffering overhead to obtain a resource-efficient implementation of the residual layer.","Our high-level synthesis (HLS)-based flow encompasses a thorough set of design principles and optimization strategies, exploiting in novel ways standard techniques such as temporal reuse and loop merging to efficiently map ResNet models, and potentially other skip connection-based NN architectures, into FPGA.","The models are quantized to 8-bit integers for both weights and activations, 16-bit for biases, and 32-bit for accumulations.","The experimental results are obtained on the CIFAR-10 dataset using ResNet8 and ResNet20 implemented with Xilinx FPGAs using HLS on the Ultra96-V2 and Kria KV260 boards.","Compared to the state-of-the-art on the Kria KV260 board, our ResNet20 implementation achieves 2.88X speedup with 0.5% higher accuracy of 91.3%, while ResNet8 accuracy improves by 2.8% to 88.7%.","The throughputs of ResNet8 and ResNet20 are 12971 FPS and 3254 FPS on the Ultra96 board, and 30153 FPS and 7601 FPS on the Kria KV26, respectively.","They Pareto-dominate state-of-the-art solutions concerning accuracy, throughput, and energy."],"url":"http://arxiv.org/abs/2309.15631v1"}
{"created":"2023-09-27 13:02:06","title":"NLPBench: Evaluating Large Language Models on Solving NLP Problems","abstract":"Recent developments in large language models (LLMs) have shown promise in enhancing the capabilities of natural language processing (NLP). Despite these successes, there remains a dearth of research dedicated to the NLP problem-solving abilities of LLMs. To fill the gap in this area, we present a unique benchmarking dataset, NLPBench, comprising 378 college-level NLP questions spanning various NLP topics sourced from Yale University's prior final exams. NLPBench includes questions with context, in which multiple sub-questions share the same public information, and diverse question types, including multiple choice, short answer, and math. Our evaluation, centered on LLMs such as GPT-3.5/4, PaLM-2, and LLAMA-2, incorporates advanced prompting strategies like the chain-of-thought (CoT) and tree-of-thought (ToT). Our study reveals that the effectiveness of the advanced prompting strategies can be inconsistent, occasionally damaging LLM performance, especially in smaller models like the LLAMA-2 (13b). Furthermore, our manual assessment illuminated specific shortcomings in LLMs' scientific problem-solving skills, with weaknesses in logical decomposition and reasoning notably affecting results.","sentences":["Recent developments in large language models (LLMs) have shown promise in enhancing the capabilities of natural language processing (NLP).","Despite these successes, there remains a dearth of research dedicated to the NLP problem-solving abilities of LLMs.","To fill the gap in this area, we present a unique benchmarking dataset, NLPBench, comprising 378 college-level NLP questions spanning various NLP topics sourced from Yale University's prior final exams.","NLPBench includes questions with context, in which multiple sub-questions share the same public information, and diverse question types, including multiple choice, short answer, and math.","Our evaluation, centered on LLMs such as GPT-3.5/4, PaLM-2, and LLAMA-2, incorporates advanced prompting strategies like the chain-of-thought (CoT) and tree-of-thought (ToT).","Our study reveals that the effectiveness of the advanced prompting strategies can be inconsistent, occasionally damaging LLM performance, especially in smaller models like the LLAMA-2 (13b).","Furthermore, our manual assessment illuminated specific shortcomings in LLMs' scientific problem-solving skills, with weaknesses in logical decomposition and reasoning notably affecting results."],"url":"http://arxiv.org/abs/2309.15630v1"}
{"created":"2023-09-27 12:58:18","title":"Neuromorphic Imaging and Classification with Graph Learning","abstract":"Bio-inspired neuromorphic cameras asynchronously record pixel brightness changes and generate sparse event streams. They can capture dynamic scenes with little motion blur and more details in extreme illumination conditions. Due to the multidimensional address-event structure, most existing vision algorithms cannot properly handle asynchronous event streams. While several event representations and processing methods have been developed to address such an issue, they are typically driven by a large number of events, leading to substantial overheads in runtime and memory. In this paper, we propose a new graph representation of the event data and couple it with a Graph Transformer to perform accurate neuromorphic classification. Extensive experiments show that our approach leads to better results and excels at the challenging realistic situations where only a small number of events and limited computational resources are available, paving the way for neuromorphic applications embedded into mobile facilities.","sentences":["Bio-inspired neuromorphic cameras asynchronously record pixel brightness changes and generate sparse event streams.","They can capture dynamic scenes with little motion blur and more details in extreme illumination conditions.","Due to the multidimensional address-event structure, most existing vision algorithms cannot properly handle asynchronous event streams.","While several event representations and processing methods have been developed to address such an issue, they are typically driven by a large number of events, leading to substantial overheads in runtime and memory.","In this paper, we propose a new graph representation of the event data and couple it with a Graph Transformer to perform accurate neuromorphic classification.","Extensive experiments show that our approach leads to better results and excels at the challenging realistic situations where only a small number of events and limited computational resources are available, paving the way for neuromorphic applications embedded into mobile facilities."],"url":"http://arxiv.org/abs/2309.15627v1"}
