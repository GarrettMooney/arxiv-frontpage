{"created":"2023-09-18 17:59:25","title":"General In-Hand Object Rotation with Vision and Touch","abstract":"We introduce RotateIt, a system that enables fingertip-based object rotation along multiple axes by leveraging multimodal sensory inputs. Our system is trained in simulation, where it has access to ground-truth object shapes and physical properties. Then we distill it to operate on realistic yet noisy simulated visuotactile and proprioceptive sensory inputs. These multimodal inputs are fused via a visuotactile transformer, enabling online inference of object shapes and physical properties during deployment. We show significant performance improvements over prior methods and the importance of visual and tactile sensing.","sentences":["We introduce RotateIt, a system that enables fingertip-based object rotation along multiple axes by leveraging multimodal sensory inputs.","Our system is trained in simulation, where it has access to ground-truth object shapes and physical properties.","Then we distill it to operate on realistic yet noisy simulated visuotactile and proprioceptive sensory inputs.","These multimodal inputs are fused via a visuotactile transformer, enabling online inference of object shapes and physical properties during deployment.","We show significant performance improvements over prior methods and the importance of visual and tactile sensing."],"url":"http://arxiv.org/abs/2309.09979v1"}
{"created":"2023-09-18 17:59:01","title":"A Multi-Token Coordinate Descent Method for Semi-Decentralized Vertical Federated Learning","abstract":"Communication efficiency is a major challenge in federated learning (FL). In client-server schemes, the server constitutes a bottleneck, and while decentralized setups spread communications, they do not necessarily reduce them due to slower convergence. We propose Multi-Token Coordinate Descent (MTCD), a communication-efficient algorithm for semi-decentralized vertical federated learning, exploiting both client-server and client-client communications when each client holds a small subset of features. Our multi-token method can be seen as a parallel Markov chain (block) coordinate descent algorithm and it subsumes the client-server and decentralized setups as special cases. We obtain a convergence rate of $\\mathcal{O}(1/T)$ for nonconvex objectives when tokens roam over disjoint subsets of clients and for convex objectives when they roam over possibly overlapping subsets. Numerical results show that MTCD improves the state-of-the-art communication efficiency and allows for a tunable amount of parallel communications.","sentences":["Communication efficiency is a major challenge in federated learning (FL).","In client-server schemes, the server constitutes a bottleneck, and while decentralized setups spread communications, they do not necessarily reduce them due to slower convergence.","We propose Multi-Token Coordinate Descent (MTCD), a communication-efficient algorithm for semi-decentralized vertical federated learning, exploiting both client-server and client-client communications when each client holds a small subset of features.","Our multi-token method can be seen as a parallel Markov chain (block) coordinate descent algorithm and it subsumes the client-server and decentralized setups as special cases.","We obtain a convergence rate of $\\mathcal{O}(1/T)$ for nonconvex objectives when tokens roam over disjoint subsets of clients and for convex objectives when they roam over possibly overlapping subsets.","Numerical results show that MTCD improves the state-of-the-art communication efficiency and allows for a tunable amount of parallel communications."],"url":"http://arxiv.org/abs/2309.09977v1"}
{"created":"2023-09-18 17:56:06","title":"GEDepth: Ground Embedding for Monocular Depth Estimation","abstract":"Monocular depth estimation is an ill-posed problem as the same 2D image can be projected from infinite 3D scenes. Although the leading algorithms in this field have reported significant improvement, they are essentially geared to the particular compound of pictorial observations and camera parameters (i.e., intrinsics and extrinsics), strongly limiting their generalizability in real-world scenarios. To cope with this challenge, this paper proposes a novel ground embedding module to decouple camera parameters from pictorial cues, thus promoting the generalization capability. Given camera parameters, the proposed module generates the ground depth, which is stacked with the input image and referenced in the final depth prediction. A ground attention is designed in the module to optimally combine ground depth with residual depth. Our ground embedding is highly flexible and lightweight, leading to a plug-in module that is amenable to be integrated into various depth estimation networks. Experiments reveal that our approach achieves the state-of-the-art results on popular benchmarks, and more importantly, renders significant generalization improvement on a wide range of cross-domain tests.","sentences":["Monocular depth estimation is an ill-posed problem as the same 2D image can be projected from infinite 3D scenes.","Although the leading algorithms in this field have reported significant improvement, they are essentially geared to the particular compound of pictorial observations and camera parameters (i.e., intrinsics and extrinsics), strongly limiting their generalizability in real-world scenarios.","To cope with this challenge, this paper proposes a novel ground embedding module to decouple camera parameters from pictorial cues, thus promoting the generalization capability.","Given camera parameters, the proposed module generates the ground depth, which is stacked with the input image and referenced in the final depth prediction.","A ground attention is designed in the module to optimally combine ground depth with residual depth.","Our ground embedding is highly flexible and lightweight, leading to a plug-in module that is amenable to be integrated into various depth estimation networks.","Experiments reveal that our approach achieves the state-of-the-art results on popular benchmarks, and more importantly, renders significant generalization improvement on a wide range of cross-domain tests."],"url":"http://arxiv.org/abs/2309.09975v1"}
{"created":"2023-09-18 17:52:22","title":"MindAgent: Emergent Gaming Interaction","abstract":"Large Language Models (LLMs) have the capacity of performing complex scheduling in a multi-agent system and can coordinate these agents into completing sophisticated tasks that require extensive collaboration. However, despite the introduction of numerous gaming frameworks, the community has insufficient benchmarks towards building general multi-agents collaboration infrastructure that encompass both LLM and human-NPCs collaborations. In this work, we propose a novel infrastructure - MindAgent - to evaluate planning and coordination emergent capabilities for gaming interaction. In particular, our infrastructure leverages existing gaming framework, to i) require understanding of the coordinator for a multi-agent system, ii) collaborate with human players via un-finetuned proper instructions, and iii) establish an in-context learning on few-shot prompt with feedback. Furthermore, we introduce CUISINEWORLD, a new gaming scenario and related benchmark that dispatch a multi-agent collaboration efficiency and supervise multiple agents playing the game simultaneously. We conduct comprehensive evaluations with new auto-metric CoS for calculating the collaboration efficiency. Finally, our infrastructure can be deployed into real-world gaming scenarios in a customized VR version of CUISINEWORLD and adapted in existing broader Minecraft gaming domain. We hope our findings on LLMs and the new infrastructure for general-purpose scheduling and coordination can help shed light on how such skills can be obtained by learning from large language corpora.","sentences":["Large Language Models (LLMs) have the capacity of performing complex scheduling in a multi-agent system and can coordinate these agents into completing sophisticated tasks that require extensive collaboration.","However, despite the introduction of numerous gaming frameworks, the community has insufficient benchmarks towards building general multi-agents collaboration infrastructure that encompass both LLM and human-NPCs collaborations.","In this work, we propose a novel infrastructure - MindAgent - to evaluate planning and coordination emergent capabilities for gaming interaction.","In particular, our infrastructure leverages existing gaming framework, to i) require understanding of the coordinator for a multi-agent system, ii) collaborate with human players via un-finetuned proper instructions, and iii) establish an in-context learning on few-shot prompt with feedback.","Furthermore, we introduce CUISINEWORLD, a new gaming scenario and related benchmark that dispatch a multi-agent collaboration efficiency and supervise multiple agents playing the game simultaneously.","We conduct comprehensive evaluations with new auto-metric CoS for calculating the collaboration efficiency.","Finally, our infrastructure can be deployed into real-world gaming scenarios in a customized VR version of CUISINEWORLD and adapted in existing broader Minecraft gaming domain.","We hope our findings on LLMs and the new infrastructure for general-purpose scheduling and coordination can help shed light on how such skills can be obtained by learning from large language corpora."],"url":"http://arxiv.org/abs/2309.09971v1"}
{"created":"2023-09-18 17:51:47","title":"Empirical Study of Mix-based Data Augmentation Methods in Physiological Time Series Data","abstract":"Data augmentation is a common practice to help generalization in the procedure of deep model training. In the context of physiological time series classification, previous research has primarily focused on label-invariant data augmentation methods. However, another class of augmentation techniques (\\textit{i.e., Mixup}) that emerged in the computer vision field has yet to be fully explored in the time series domain. In this study, we systematically review the mix-based augmentations, including mixup, cutmix, and manifold mixup, on six physiological datasets, evaluating their performance across different sensory data and classification tasks. Our results demonstrate that the three mix-based augmentations can consistently improve the performance on the six datasets. More importantly, the improvement does not rely on expert knowledge or extensive parameter tuning. Lastly, we provide an overview of the unique properties of the mix-based augmentation methods and highlight the potential benefits of using the mix-based augmentation in physiological time series data.","sentences":["Data augmentation is a common practice to help generalization in the procedure of deep model training.","In the context of physiological time series classification, previous research has primarily focused on label-invariant data augmentation methods.","However, another class of augmentation techniques (\\textit{i.e., Mixup}) that emerged in the computer vision field has yet to be fully explored in the time series domain.","In this study, we systematically review the mix-based augmentations, including mixup, cutmix, and manifold mixup, on six physiological datasets, evaluating their performance across different sensory data and classification tasks.","Our results demonstrate that the three mix-based augmentations can consistently improve the performance on the six datasets.","More importantly, the improvement does not rely on expert knowledge or extensive parameter tuning.","Lastly, we provide an overview of the unique properties of the mix-based augmentation methods and highlight the potential benefits of using the mix-based augmentation in physiological time series data."],"url":"http://arxiv.org/abs/2309.09970v1"}
{"created":"2023-09-18 17:50:17","title":"Prompt a Robot to Walk with Large Language Models","abstract":"Large language models (LLMs) pre-trained on vast internet-scale data have showcased remarkable capabilities across diverse domains. Recently, there has been escalating interest in deploying LLMs for robotics, aiming to harness the power of foundation models in real-world settings. However, this approach faces significant challenges, particularly in grounding these models in the physical world and in generating dynamic robot motions. To address these issues, we introduce a novel paradigm in which we use few-shot prompts collected from the physical environment, enabling the LLM to autoregressively generate low-level control commands for robots without task-specific fine-tuning. Experiments across various robots and environments validate that our method can effectively prompt a robot to walk. We thus illustrate how LLMs can proficiently function as low-level feedback controllers for dynamic motion control even in high-dimensional robotic systems. The project website and source code can be found at: https://prompt2walk.github.io/ .","sentences":["Large language models (LLMs) pre-trained on vast internet-scale data have showcased remarkable capabilities across diverse domains.","Recently, there has been escalating interest in deploying LLMs for robotics, aiming to harness the power of foundation models in real-world settings.","However, this approach faces significant challenges, particularly in grounding these models in the physical world and in generating dynamic robot motions.","To address these issues, we introduce a novel paradigm in which we use few-shot prompts collected from the physical environment, enabling the LLM to autoregressively generate low-level control commands for robots without task-specific fine-tuning.","Experiments across various robots and environments validate that our method can effectively prompt a robot to walk.","We thus illustrate how LLMs can proficiently function as low-level feedback controllers for dynamic motion control even in high-dimensional robotic systems.","The project website and source code can be found at: https://prompt2walk.github.io/ ."],"url":"http://arxiv.org/abs/2309.09969v1"}
{"created":"2023-09-18 17:49:09","title":"Generating and Imputing Tabular Data via Diffusion and Flow-based Gradient-Boosted Trees","abstract":"Tabular data is hard to acquire and is subject to missing values. This paper proposes a novel approach to generate and impute mixed-type (continuous and categorical) tabular data using score-based diffusion and conditional flow matching. Contrary to previous work that relies on neural networks as function approximators, we instead utilize XGBoost, a popular Gradient-Boosted Tree (GBT) method. In addition to being elegant, we empirically show on various datasets that our method i) generates highly realistic synthetic data when the training dataset is either clean or tainted by missing data and ii) generates diverse plausible data imputations. Our method often outperforms deep-learning generation methods and can trained in parallel using CPUs without the need for a GPU. To make it easily accessible, we release our code through a Python library on PyPI and an R package on CRAN.","sentences":["Tabular data is hard to acquire and is subject to missing values.","This paper proposes a novel approach to generate and impute mixed-type (continuous and categorical) tabular data using score-based diffusion and conditional flow matching.","Contrary to previous work that relies on neural networks as function approximators, we instead utilize XGBoost, a popular Gradient-Boosted Tree (GBT) method.","In addition to being elegant, we empirically show on various datasets that our method i) generates highly realistic synthetic data when the training dataset is either clean or tainted by missing data and ii) generates diverse plausible data imputations.","Our method often outperforms deep-learning generation methods and can trained in parallel using CPUs without the need for a GPU.","To make it easily accessible, we release our code through a Python library on PyPI and an R package on CRAN."],"url":"http://arxiv.org/abs/2309.09968v1"}
{"created":"2023-09-18 17:46:01","title":"How to Make Knockout Tournaments More Popular?","abstract":"Given a mapping from a set of players to the leaves of a complete binary tree (called a seeding), a knockout tournament is conducted as follows: every round, every two players with a common parent compete against each other, and the winner is promoted to the common parent; then, the leaves are deleted. When only one player remains, it is declared the winner. This is a popular competition format in sports, elections, and decision-making. Over the past decade, it has been studied intensively from both theoretical and practical points of view. Most frequently, the objective is to seed the tournament in a way that \"assists\" (or even guarantees) some particular player to win the competition. We introduce a new objective, which is very sensible from the perspective of the directors of the competition: maximize the profit or popularity of the tournament. Specifically, we associate a \"score\" with every possible match, and aim to seed the tournament to maximize the sum of the scores of the matches that take place. We focus on the case where we assume a total order on the players' strengths, and provide a wide spectrum of results on the computational complexity of the problem.","sentences":["Given a mapping from a set of players to the leaves of a complete binary tree (called a seeding), a knockout tournament is conducted as follows: every round, every two players with a common parent compete against each other, and the winner is promoted to the common parent; then, the leaves are deleted.","When only one player remains, it is declared the winner.","This is a popular competition format in sports, elections, and decision-making.","Over the past decade, it has been studied intensively from both theoretical and practical points of view.","Most frequently, the objective is to seed the tournament in a way that \"assists\" (or even guarantees) some particular player to win the competition.","We introduce a new objective, which is very sensible from the perspective of the directors of the competition: maximize the profit or popularity of the tournament.","Specifically, we associate a \"score\" with every possible match, and aim to seed the tournament to maximize the sum of the scores of the matches that take place.","We focus on the case where we assume a total order on the players' strengths, and provide a wide spectrum of results on the computational complexity of the problem."],"url":"http://arxiv.org/abs/2309.09967v1"}
{"created":"2023-09-18 17:30:46","title":"An Empirical Study of Scaling Instruct-Tuned Large Multimodal Models","abstract":"Visual instruction tuning has recently shown encouraging progress with open-source large multimodal models (LMM) such as LLaVA and MiniGPT-4. However, most existing studies of open-source LMM are performed using models with 13B parameters or smaller. In this paper we present an empirical study of scaling LLaVA up to 33B and 65B/70B, and share our findings from our explorations in image resolution, data mixing and parameter-efficient training methods such as LoRA/QLoRA. These are evaluated by their impact on the multi-modal and language capabilities when completing real-world tasks in the wild.   We find that scaling LMM consistently enhances model performance and improves language capabilities, and performance of LoRA/QLoRA tuning of LMM are comparable to the performance of full-model fine-tuning. Additionally, the study highlights the importance of higher image resolutions and mixing multimodal-language data to improve LMM performance, and visual instruction tuning can sometimes improve LMM's pure language capability. We hope that this study makes state-of-the-art LMM research at a larger scale more accessible, thus helping establish stronger baselines for future research. Code and checkpoints will be made public.","sentences":["Visual instruction tuning has recently shown encouraging progress with open-source large multimodal models (LMM) such as LLaVA and MiniGPT-4.","However, most existing studies of open-source LMM are performed using models with 13B parameters or smaller.","In this paper we present an empirical study of scaling LLaVA up to 33B and 65B/70B, and share our findings from our explorations in image resolution, data mixing and parameter-efficient training methods such as LoRA/QLoRA.","These are evaluated by their impact on the multi-modal and language capabilities when completing real-world tasks in the wild.   ","We find that scaling LMM consistently enhances model performance and improves language capabilities, and performance of LoRA/QLoRA tuning of LMM are comparable to the performance of full-model fine-tuning.","Additionally, the study highlights the importance of higher image resolutions and mixing multimodal-language data to improve LMM performance, and visual instruction tuning can sometimes improve LMM's pure language capability.","We hope that this study makes state-of-the-art LMM research at a larger scale more accessible, thus helping establish stronger baselines for future research.","Code and checkpoints will be made public."],"url":"http://arxiv.org/abs/2309.09958v1"}
{"created":"2023-09-18 17:12:58","title":"How to Generate Popular Post Headlines on Social Media?","abstract":"Posts, as important containers of user-generated-content pieces on social media, are of tremendous social influence and commercial value. As an integral components of a post, the headline has a decisive contribution to the post's popularity. However, current mainstream method for headline generation is still manually writing, which is unstable and requires extensive human effort. This drives us to explore a novel research question: Can we automate the generation of popular headlines on social media? We collect more than 1 million posts of 42,447 celebrities from public data of Xiaohongshu, which is a well-known social media platform in China. We then conduct careful observations on the headlines of these posts. Observation results demonstrate that trends and personal styles are widespread in headlines on social medias and have significant contribution to posts's popularity. Motivated by these insights, we present MEBART, which combines Multiple preference-Extractors with Bidirectional and Auto-Regressive Transformers (BART), capturing trends and personal styles to generate popular headlines on social medias. We perform extensive experiments on real-world datasets and achieve state-of-the-art performance compared with several advanced baselines. In addition, ablation and case studies demonstrate that MEBART advances in capturing trends and personal styles.","sentences":["Posts, as important containers of user-generated-content pieces on social media, are of tremendous social influence and commercial value.","As an integral components of a post, the headline has a decisive contribution to the post's popularity.","However, current mainstream method for headline generation is still manually writing, which is unstable and requires extensive human effort.","This drives us to explore a novel research question: Can we automate the generation of popular headlines on social media?","We collect more than 1 million posts of 42,447 celebrities from public data of Xiaohongshu, which is a well-known social media platform in China.","We then conduct careful observations on the headlines of these posts.","Observation results demonstrate that trends and personal styles are widespread in headlines on social medias and have significant contribution to posts's popularity.","Motivated by these insights, we present MEBART, which combines Multiple preference-Extractors with Bidirectional and Auto-Regressive Transformers (BART), capturing trends and personal styles to generate popular headlines on social medias.","We perform extensive experiments on real-world datasets and achieve state-of-the-art performance compared with several advanced baselines.","In addition, ablation and case studies demonstrate that MEBART advances in capturing trends and personal styles."],"url":"http://arxiv.org/abs/2309.09949v1"}
{"created":"2023-09-18 17:12:43","title":"End-to-End Learned Event- and Image-based Visual Odometry","abstract":"Visual Odometry (VO) is crucial for autonomous robotic navigation, especially in GPS-denied environments like planetary terrains. While standard RGB cameras struggle in low-light or high-speed motion, event-based cameras offer high dynamic range and low latency. However, seamlessly integrating asynchronous event data with synchronous frames remains challenging. We introduce RAMP-VO, the first end-to-end learned event- and image-based VO system. It leverages novel Recurrent, Asynchronous, and Massively Parallel (RAMP) encoders that are 8x faster and 20% more accurate than existing asynchronous encoders. RAMP-VO further employs a novel pose forecasting technique to predict future poses for initialization. Despite being trained only in simulation, RAMP-VO outperforms image- and event-based methods by 52% and 20%, respectively, on traditional, real-world benchmarks as well as newly introduced Apollo and Malapert landing sequences, paving the way for robust and asynchronous VO in space.","sentences":["Visual Odometry (VO) is crucial for autonomous robotic navigation, especially in GPS-denied environments like planetary terrains.","While standard RGB cameras struggle in low-light or high-speed motion, event-based cameras offer high dynamic range and low latency.","However, seamlessly integrating asynchronous event data with synchronous frames remains challenging.","We introduce RAMP-VO, the first end-to-end learned event- and image-based VO system.","It leverages novel Recurrent, Asynchronous, and Massively Parallel (RAMP) encoders that are 8x faster and 20% more accurate than existing asynchronous encoders.","RAMP-VO further employs a novel pose forecasting technique to predict future poses for initialization.","Despite being trained only in simulation, RAMP-VO outperforms image- and event-based methods by 52% and 20%, respectively, on traditional, real-world benchmarks as well as newly introduced Apollo and Malapert landing sequences, paving the way for robust and asynchronous VO in space."],"url":"http://arxiv.org/abs/2309.09947v1"}
{"created":"2023-09-18 17:04:04","title":"What is a Fair Diffusion Model? Designing Generative Text-To-Image Models to Incorporate Various Worldviews","abstract":"Generative text-to-image (GTI) models produce high-quality images from short textual descriptions and are widely used in academic and creative domains. However, GTI models frequently amplify biases from their training data, often producing prejudiced or stereotypical images. Yet, current bias mitigation strategies are limited and primarily focus on enforcing gender parity across occupations. To enhance GTI bias mitigation, we introduce DiffusionWorldViewer, a tool to analyze and manipulate GTI models' attitudes, values, stories, and expectations of the world that impact its generated images. Through an interactive interface deployed as a web-based GUI and Jupyter Notebook plugin, DiffusionWorldViewer categorizes existing demographics of GTI-generated images and provides interactive methods to align image demographics with user worldviews. In a study with 13 GTI users, we find that DiffusionWorldViewer allows users to represent their varied viewpoints about what GTI outputs are fair and, in doing so, challenges current notions of fairness that assume a universal worldview.","sentences":["Generative text-to-image (GTI) models produce high-quality images from short textual descriptions and are widely used in academic and creative domains.","However, GTI models frequently amplify biases from their training data, often producing prejudiced or stereotypical images.","Yet, current bias mitigation strategies are limited and primarily focus on enforcing gender parity across occupations.","To enhance GTI bias mitigation, we introduce DiffusionWorldViewer, a tool to analyze and manipulate GTI models' attitudes, values, stories, and expectations of the world that impact its generated images.","Through an interactive interface deployed as a web-based GUI and Jupyter Notebook plugin, DiffusionWorldViewer categorizes existing demographics of GTI-generated images and provides interactive methods to align image demographics with user worldviews.","In a study with 13 GTI users, we find that DiffusionWorldViewer allows users to represent their varied viewpoints about what GTI outputs are fair and, in doing so, challenges current notions of fairness that assume a universal worldview."],"url":"http://arxiv.org/abs/2309.09944v1"}
{"created":"2023-09-18 17:02:35","title":"Property Graphs in Arachne","abstract":"Analyzing large-scale graphs poses challenges due to their increasing size and the demand for interactive and user-friendly analytics tools. These graphs arise from various domains, including cybersecurity, social sciences, health sciences, and network sciences, where networks can represent interactions between humans, neurons in the brain, or malicious flows in a network. Exploring these large graphs is crucial for revealing hidden structures and metrics that are not easily computable without parallel computing. Currently, Python users can leverage the open-source Arkouda framework to efficiently execute Pandas and NumPy-related tasks on thousands of cores. To address large-scale graph analysis, Arachne, an extension to Arkouda, enables easy transformation of Arkouda dataframes into graphs. This paper proposes and evaluates three distributable data structures for property graphs, implemented in Chapel, that are integrated into Arachne. Enriching Arachne with support for property graphs will empower data scientists to extend their analysis to new problem domains. Property graphs present additional complexities, requiring efficient storage for extra information on vertices and edges, such as labels, relationships, and properties.","sentences":["Analyzing large-scale graphs poses challenges due to their increasing size and the demand for interactive and user-friendly analytics tools.","These graphs arise from various domains, including cybersecurity, social sciences, health sciences, and network sciences, where networks can represent interactions between humans, neurons in the brain, or malicious flows in a network.","Exploring these large graphs is crucial for revealing hidden structures and metrics that are not easily computable without parallel computing.","Currently, Python users can leverage the open-source Arkouda framework to efficiently execute Pandas and NumPy-related tasks on thousands of cores.","To address large-scale graph analysis, Arachne, an extension to Arkouda, enables easy transformation of Arkouda dataframes into graphs.","This paper proposes and evaluates three distributable data structures for property graphs, implemented in Chapel, that are integrated into Arachne.","Enriching Arachne with support for property graphs will empower data scientists to extend their analysis to new problem domains.","Property graphs present additional complexities, requiring efficient storage for extra information on vertices and edges, such as labels, relationships, and properties."],"url":"http://arxiv.org/abs/2309.09943v1"}
{"created":"2023-09-18 17:01:17","title":"OptiRoute: A Heuristic-assisted Deep Reinforcement Learning Framework for UAV-UGV Collaborative Route Planning","abstract":"Unmanned aerial vehicles (UAVs) are capable of surveying expansive areas, but their operational range is constrained by limited battery capacity. The deployment of mobile recharging stations using unmanned ground vehicles (UGVs) significantly extends the endurance and effectiveness of UAVs. However, optimizing the routes of both UAVs and UGVs, known as the UAV-UGV cooperative routing problem, poses substantial challenges, particularly with respect to the selection of recharging locations. Here in this paper, we leverage reinforcement learning (RL) for the purpose of identifying optimal recharging locations while employing constraint programming to determine cooperative routes for the UAV and UGV. Our proposed framework is then benchmarked against a baseline solution that employs Genetic Algorithms (GA) to select rendezvous points. Our findings reveal that RL surpasses GA in terms of reducing overall mission time, minimizing UAV-UGV idle time, and mitigating energy consumption for both the UAV and UGV. These results underscore the efficacy of incorporating heuristics to assist RL, a method we refer to as heuristics-assisted RL, in generating high-quality solutions for intricate routing problems.","sentences":["Unmanned aerial vehicles (UAVs) are capable of surveying expansive areas, but their operational range is constrained by limited battery capacity.","The deployment of mobile recharging stations using unmanned ground vehicles (UGVs) significantly extends the endurance and effectiveness of UAVs.","However, optimizing the routes of both UAVs and UGVs, known as the UAV-UGV cooperative routing problem, poses substantial challenges, particularly with respect to the selection of recharging locations.","Here in this paper, we leverage reinforcement learning (RL) for the purpose of identifying optimal recharging locations while employing constraint programming to determine cooperative routes for the UAV and UGV.","Our proposed framework is then benchmarked against a baseline solution that employs Genetic Algorithms (GA) to select rendezvous points.","Our findings reveal that RL surpasses GA in terms of reducing overall mission time, minimizing UAV-UGV idle time, and mitigating energy consumption for both the UAV and UGV.","These results underscore the efficacy of incorporating heuristics to assist RL, a method we refer to as heuristics-assisted RL, in generating high-quality solutions for intricate routing problems."],"url":"http://arxiv.org/abs/2309.09942v1"}
{"created":"2023-09-18 16:58:36","title":"Model-Based Generation of Attack-Fault Trees","abstract":"Joint safety and security analysis of cyber-physical systems is a necessary step to correctly capture inter-dependencies between these properties. Attack-Fault Trees represent a combination of dynamic Fault Trees and Attack Trees and can be used to model and model-check a holistic view on both safety and security. Manually creating a complete AFT for the whole system is, however, a daunting task. It needs to span multiple abstraction layers, e.g., abstract application architecture and data flow as well as system and library dependencies that are affected by various vulnerabilities. We present an AFT generation tool-chain that facilitates this task using partial Fault and Attack Trees that are either manually created or mined from vulnerability databases. We semi-automatically create two system models that provide the necessary information to automatically combine these partial Fault and Attack Trees into complete AFTs using graph transformation rules.","sentences":["Joint safety and security analysis of cyber-physical systems is a necessary step to correctly capture inter-dependencies between these properties.","Attack-Fault Trees represent a combination of dynamic Fault Trees and Attack Trees and can be used to model and model-check a holistic view on both safety and security.","Manually creating a complete AFT for the whole system is, however, a daunting task.","It needs to span multiple abstraction layers, e.g., abstract application architecture and data flow as well as system and library dependencies that are affected by various vulnerabilities.","We present an AFT generation tool-chain that facilitates this task using partial Fault and Attack Trees that are either manually created or mined from vulnerability databases.","We semi-automatically create two system models that provide the necessary information to automatically combine these partial Fault and Attack Trees into complete AFTs using graph transformation rules."],"url":"http://arxiv.org/abs/2309.09941v1"}
{"created":"2023-09-18 16:52:48","title":"A Concise Overview of Safety Aspects in Human-Robot Interaction","abstract":"As of today, robots exhibit impressive agility but also pose potential hazards to humans using/collaborating with them. Consequently, safety is considered the most paramount factor in human-robot interaction (HRI). This paper presents a multi-layered safety architecture, integrating both physical and cognitive aspects for effective HRI. We outline critical requirements for physical safety layers as service modules that can be arbitrarily queried. Further, we showcase an HRI scheme that addresses human factors and perceived safety as high-level constraints on a validated impact safety paradigm. The aim is to enable safety certification of human-friendly robots across various HRI scenarios.","sentences":["As of today, robots exhibit impressive agility but also pose potential hazards to humans using/collaborating with them.","Consequently, safety is considered the most paramount factor in human-robot interaction (HRI).","This paper presents a multi-layered safety architecture, integrating both physical and cognitive aspects for effective HRI.","We outline critical requirements for physical safety layers as service modules that can be arbitrarily queried.","Further, we showcase an HRI scheme that addresses human factors and perceived safety as high-level constraints on a validated impact safety paradigm.","The aim is to enable safety certification of human-friendly robots across various HRI scenarios."],"url":"http://arxiv.org/abs/2309.09936v1"}
{"created":"2023-09-18 16:51:56","title":"Hierarchical Attention and Graph Neural Networks: Toward Drift-Free Pose Estimation","abstract":"The most commonly used method for addressing 3D geometric registration is the iterative closet-point algorithm, this approach is incremental and prone to drift over multiple consecutive frames. The Common strategy to address the drift is the pose graph optimization subsequent to frame-to-frame registration, incorporating a loop closure process that identifies previously visited places. In this paper, we explore a framework that replaces traditional geometric registration and pose graph optimization with a learned model utilizing hierarchical attention mechanisms and graph neural networks. We propose a strategy to condense the data flow, preserving essential information required for the precise estimation of rigid poses. Our results, derived from tests on the KITTI Odometry dataset, demonstrate a significant improvement in pose estimation accuracy. This improvement is especially notable in determining rotational components when compared with results obtained through conventional multi-way registration via pose graph optimization. The code will be made available upon completion of the review process.","sentences":["The most commonly used method for addressing 3D geometric registration is the iterative closet-point algorithm, this approach is incremental and prone to drift over multiple consecutive frames.","The Common strategy to address the drift is the pose graph optimization subsequent to frame-to-frame registration, incorporating a loop closure process that identifies previously visited places.","In this paper, we explore a framework that replaces traditional geometric registration and pose graph optimization with a learned model utilizing hierarchical attention mechanisms and graph neural networks.","We propose a strategy to condense the data flow, preserving essential information required for the precise estimation of rigid poses.","Our results, derived from tests on the KITTI Odometry dataset, demonstrate a significant improvement in pose estimation accuracy.","This improvement is especially notable in determining rotational components when compared with results obtained through conventional multi-way registration via pose graph optimization.","The code will be made available upon completion of the review process."],"url":"http://arxiv.org/abs/2309.09934v1"}
{"created":"2023-09-18 16:50:11","title":"Algebra of Self-Replication","abstract":"Typical arguments for results like Kleene's Second Recursion Theorem and the existence of self-writing computer programs bear the fingerprints of equational reasoning and combinatory logic. In fact, the connection of combinatory logic and computability theory is very old, and this paper extends this connection in new ways. In one direction, we counter the main trend in both computability theory and combinatory logic of heading straight to undecidability. Instead, this paper proposes using several very small equational logics to examine results in computability theory itself. These logics are decidable via term rewriting. We argue that they have something interesting to say about computability theory. They are closely related to fragments of combinatory logic which are decidable, and so this paper contributes to the study of such fragments. The paper has a few surprising results such as a classification of quine programs (programs which output themselves) in two decidable fragments. The classification goes via examination of normal forms in term rewriting systems, hence the title of the paper. The classification is an explanation of why all quine programs (in any language) are \"pretty much the same, except for inessential details.\" In addition, we study the relational structure whose objects are the programs with the relation \"p expresses q\" meaning that if the program p is run on nothing, then it eventually outputs the program q.","sentences":["Typical arguments for results like Kleene's Second Recursion Theorem and the existence of self-writing computer programs bear the fingerprints of equational reasoning and combinatory logic.","In fact, the connection of combinatory logic and computability theory is very old, and this paper extends this connection in new ways.","In one direction, we counter the main trend in both computability theory and combinatory logic of heading straight to undecidability.","Instead, this paper proposes using several very small equational logics to examine results in computability theory itself.","These logics are decidable via term rewriting.","We argue that they have something interesting to say about computability theory.","They are closely related to fragments of combinatory logic which are decidable, and so this paper contributes to the study of such fragments.","The paper has a few surprising results such as a classification of quine programs (programs which output themselves) in two decidable fragments.","The classification goes via examination of normal forms in term rewriting systems, hence the title of the paper.","The classification is an explanation of why all quine programs (in any language) are \"pretty much the same, except for inessential details.\"","In addition, we study the relational structure whose objects are the programs with the relation \"p expresses q\" meaning that if the program p is run on nothing, then it eventually outputs the program q."],"url":"http://arxiv.org/abs/2309.09931v1"}
{"created":"2023-09-18 16:47:24","title":"Evaluating Adversarial Robustness with Expected Viable Performance","abstract":"We introduce a metric for evaluating the robustness of a classifier, with particular attention to adversarial perturbations, in terms of expected functionality with respect to possible adversarial perturbations. A classifier is assumed to be non-functional (that is, has a functionality of zero) with respect to a perturbation bound if a conventional measure of performance, such as classification accuracy, is less than a minimally viable threshold when the classifier is tested on examples from that perturbation bound. Defining robustness in terms of an expected value is motivated by a domain general approach to robustness quantification.","sentences":["We introduce a metric for evaluating the robustness of a classifier, with particular attention to adversarial perturbations, in terms of expected functionality with respect to possible adversarial perturbations.","A classifier is assumed to be non-functional (that is, has a functionality of zero) with respect to a perturbation bound if a conventional measure of performance, such as classification accuracy, is less than a minimally viable threshold when the classifier is tested on examples from that perturbation bound.","Defining robustness in terms of an expected value is motivated by a domain general approach to robustness quantification."],"url":"http://arxiv.org/abs/2309.09928v1"}
{"created":"2023-09-18 16:39:51","title":"Graph topological property recovery with heat and wave dynamics-based features on graphsD","abstract":"In this paper, we propose Graph Differential Equation Network (GDeNet), an approach that harnesses the expressive power of solutions to PDEs on a graph to obtain continuous node- and graph-level representations for various downstream tasks. We derive theoretical results connecting the dynamics of heat and wave equations to the spectral properties of the graph and to the behavior of continuous-time random walks on graphs. We demonstrate experimentally that these dynamics are able to capture salient aspects of graph geometry and topology by recovering generating parameters of random graphs, Ricci curvature, and persistent homology. Furthermore, we demonstrate the superior performance of GDeNet on real-world datasets including citation graphs, drug-like molecules, and proteins.","sentences":["In this paper, we propose Graph Differential Equation Network (GDeNet), an approach that harnesses the expressive power of solutions to PDEs on a graph to obtain continuous node- and graph-level representations for various downstream tasks.","We derive theoretical results connecting the dynamics of heat and wave equations to the spectral properties of the graph and to the behavior of continuous-time random walks on graphs.","We demonstrate experimentally that these dynamics are able to capture salient aspects of graph geometry and topology by recovering generating parameters of random graphs, Ricci curvature, and persistent homology.","Furthermore, we demonstrate the superior performance of GDeNet on real-world datasets including citation graphs, drug-like molecules, and proteins."],"url":"http://arxiv.org/abs/2309.09924v1"}
{"created":"2023-09-18 16:35:30","title":"A Heterogeneous Graph-Based Multi-Task Learning for Fault Event Diagnosis in Smart Grid","abstract":"Precise and timely fault diagnosis is a prerequisite for a distribution system to ensure minimum downtime and maintain reliable operation. This necessitates access to a comprehensive procedure that can provide the grid operators with insightful information in the case of a fault event. In this paper, we propose a heterogeneous multi-task learning graph neural network (MTL-GNN) capable of detecting, locating and classifying faults in addition to providing an estimate of the fault resistance and current. Using a graph neural network (GNN) allows for learning the topological representation of the distribution system as well as feature learning through a message-passing scheme. We investigate the robustness of our proposed model using the IEEE-123 test feeder system. This work also proposes a novel GNN-based explainability method to identify key nodes in the distribution system which then facilitates informed sparse measurements. Numerical tests validate the performance of the model across all tasks.","sentences":["Precise and timely fault diagnosis is a prerequisite for a distribution system to ensure minimum downtime and maintain reliable operation.","This necessitates access to a comprehensive procedure that can provide the grid operators with insightful information in the case of a fault event.","In this paper, we propose a heterogeneous multi-task learning graph neural network (MTL-GNN) capable of detecting, locating and classifying faults in addition to providing an estimate of the fault resistance and current.","Using a graph neural network (GNN) allows for learning the topological representation of the distribution system as well as feature learning through a message-passing scheme.","We investigate the robustness of our proposed model using the IEEE-123 test feeder system.","This work also proposes a novel GNN-based explainability method to identify key nodes in the distribution system which then facilitates informed sparse measurements.","Numerical tests validate the performance of the model across all tasks."],"url":"http://arxiv.org/abs/2309.09921v1"}
{"created":"2023-09-18 16:33:30","title":"Plug in the Safety Chip: Enforcing Constraints for LLM-driven Robot Agents","abstract":"Recent advancements in large language models (LLMs) have enabled a new research domain, LLM agents, for solving robotics and planning tasks by leveraging the world knowledge and general reasoning abilities of LLMs obtained during pretraining. However, while considerable effort has been made to teach the robot the \"dos,\" the \"don'ts\" received relatively less attention. We argue that, for any practical usage, it is as crucial to teach the robot the \"don'ts\": conveying explicit instructions about prohibited actions, assessing the robot's comprehension of these restrictions, and, most importantly, ensuring compliance. Moreover, verifiable safe operation is essential for deployments that satisfy worldwide standards such as ISO 61508, which defines standards for safely deploying robots in industrial factory environments worldwide. Aiming at deploying the LLM agents in a collaborative environment, we propose a queryable safety constraint module based on linear temporal logic (LTL) that simultaneously enables natural language (NL) to temporal constraints encoding, safety violation reasoning and explaining, and unsafe action pruning. To demonstrate the effectiveness of our system, we conducted experiments in VirtualHome environment and on a real robot. The experimental results show that our system strictly adheres to the safety constraints and scales well with complex safety constraints, highlighting its potential for practical utility.","sentences":["Recent advancements in large language models (LLMs) have enabled a new research domain, LLM agents, for solving robotics and planning tasks by leveraging the world knowledge and general reasoning abilities of LLMs obtained during pretraining.","However, while considerable effort has been made to teach the robot the \"dos,\" the \"don'ts\" received relatively less attention.","We argue that, for any practical usage, it is as crucial to teach the robot the \"don'ts\": conveying explicit instructions about prohibited actions, assessing the robot's comprehension of these restrictions, and, most importantly, ensuring compliance.","Moreover, verifiable safe operation is essential for deployments that satisfy worldwide standards such as ISO 61508, which defines standards for safely deploying robots in industrial factory environments worldwide.","Aiming at deploying the LLM agents in a collaborative environment, we propose a queryable safety constraint module based on linear temporal logic (LTL) that simultaneously enables natural language (NL) to temporal constraints encoding, safety violation reasoning and explaining, and unsafe action pruning.","To demonstrate the effectiveness of our system, we conducted experiments in VirtualHome environment and on a real robot.","The experimental results show that our system strictly adheres to the safety constraints and scales well with complex safety constraints, highlighting its potential for practical utility."],"url":"http://arxiv.org/abs/2309.09919v1"}
{"created":"2023-09-18 16:30:14","title":"Evaluation of Human-Understandability of Global Model Explanations using Decision Tree","abstract":"In explainable artificial intelligence (XAI) research, the predominant focus has been on interpreting models for experts and practitioners. Model agnostic and local explanation approaches are deemed interpretable and sufficient in many applications. However, in domains like healthcare, where end users are patients without AI or domain expertise, there is an urgent need for model explanations that are more comprehensible and instil trust in the model's operations. We hypothesise that generating model explanations that are narrative, patient-specific and global(holistic of the model) would enable better understandability and enable decision-making. We test this using a decision tree model to generate both local and global explanations for patients identified as having a high risk of coronary heart disease. These explanations are presented to non-expert users. We find a strong individual preference for a specific type of explanation. The majority of participants prefer global explanations, while a smaller group prefers local explanations. A task based evaluation of mental models of these participants provide valuable feedback to enhance narrative global explanations. This, in turn, guides the design of health informatics systems that are both trustworthy and actionable.","sentences":["In explainable artificial intelligence (XAI) research, the predominant focus has been on interpreting models for experts and practitioners.","Model agnostic and local explanation approaches are deemed interpretable and sufficient in many applications.","However, in domains like healthcare, where end users are patients without AI or domain expertise, there is an urgent need for model explanations that are more comprehensible and instil trust in the model's operations.","We hypothesise that generating model explanations that are narrative, patient-specific and global(holistic of the model) would enable better understandability and enable decision-making.","We test this using a decision tree model to generate both local and global explanations for patients identified as having a high risk of coronary heart disease.","These explanations are presented to non-expert users.","We find a strong individual preference for a specific type of explanation.","The majority of participants prefer global explanations, while a smaller group prefers local explanations.","A task based evaluation of mental models of these participants provide valuable feedback to enhance narrative global explanations.","This, in turn, guides the design of health informatics systems that are both trustworthy and actionable."],"url":"http://arxiv.org/abs/2309.09917v1"}
{"created":"2023-09-18 16:24:26","title":"Wait, That Feels Familiar: Learning to Extrapolate Human Preferences for Preference Aligned Path Planning","abstract":"Autonomous mobility tasks such as lastmile delivery require reasoning about operator indicated preferences over terrains on which the robot should navigate to ensure both robot safety and mission success. However, coping with out of distribution data from novel terrains or appearance changes due to lighting variations remains a fundamental problem in visual terrain adaptive navigation. Existing solutions either require labor intensive manual data recollection and labeling or use handcoded reward functions that may not align with operator preferences. In this work, we posit that operator preferences for visually novel terrains, which the robot should adhere to, can often be extrapolated from established terrain references within the inertial, proprioceptive, and tactile domain. Leveraging this insight, we introduce Preference extrApolation for Terrain awarE Robot Navigation, PATERN, a novel framework for extrapolating operator terrain preferences for visual navigation. PATERN learns to map inertial, proprioceptive, tactile measurements from the robots observations to a representation space and performs nearest neighbor search in this space to estimate operator preferences over novel terrains. Through physical robot experiments in outdoor environments, we assess PATERNs capability to extrapolate preferences and generalize to novel terrains and challenging lighting conditions. Compared to baseline approaches, our findings indicate that PATERN robustly generalizes to diverse terrains and varied lighting conditions, while navigating in a preference aligned manner.","sentences":["Autonomous mobility tasks such as lastmile delivery require reasoning about operator indicated preferences over terrains on which the robot should navigate to ensure both robot safety and mission success.","However, coping with out of distribution data from novel terrains or appearance changes due to lighting variations remains a fundamental problem in visual terrain adaptive navigation.","Existing solutions either require labor intensive manual data recollection and labeling or use handcoded reward functions that may not align with operator preferences.","In this work, we posit that operator preferences for visually novel terrains, which the robot should adhere to, can often be extrapolated from established terrain references within the inertial, proprioceptive, and tactile domain.","Leveraging this insight, we introduce Preference extrApolation for Terrain awarE Robot Navigation, PATERN, a novel framework for extrapolating operator terrain preferences for visual navigation.","PATERN learns to map inertial, proprioceptive, tactile measurements from the robots observations to a representation space and performs nearest neighbor search in this space to estimate operator preferences over novel terrains.","Through physical robot experiments in outdoor environments, we assess PATERNs capability to extrapolate preferences and generalize to novel terrains and challenging lighting conditions.","Compared to baseline approaches, our findings indicate that PATERN robustly generalizes to diverse terrains and varied lighting conditions, while navigating in a preference aligned manner."],"url":"http://arxiv.org/abs/2309.09912v1"}
{"created":"2023-09-18 16:21:50","title":"Neural Parametric Surfaces for Shape Modeling","abstract":"The recent surge of utilizing deep neural networks for geometric processing and shape modeling has opened up exciting avenues. However, there is a conspicuous lack of research efforts on using powerful neural representations to extend the capabilities of parametric surfaces, which are the prevalent surface representations in product design, CAD/CAM, and computer animation. We present Neural Parametric Surfaces, the first piecewise neural surface representation that allows coarse patch layouts of arbitrary $n$-sided surface patches to model complex surface geometries with high precision, offering greater flexibility over traditional parametric surfaces. By construction, this new surface representation guarantees $G^0$ continuity between adjacent patches and empirically achieves $G^1$ continuity, which cannot be attained by existing neural patch-based methods. The key ingredient of our neural parametric surface is a learnable feature complex $\\mathcal{C}$ that is embedded in a high-dimensional space $\\mathbb{R}^D$ and topologically equivalent to the patch layout of the surface; each face cell of the complex is defined by interpolating feature vectors at its vertices. The learned feature complex is mapped by an MLP-encoded function $f:\\mathcal{C} \\rightarrow \\mathcal{S}$ to produce the neural parametric surface $\\mathcal{S}$. We present a surface fitting algorithm that optimizes the feature complex $\\mathcal{C}$ and trains the neural mapping $f$ to reconstruct given target shapes with high accuracy. We further show that the proposed representation along with a compact-size neural net can learn a plausible shape space from a shape collection, which can be used for shape interpolation or shape completion from noisy and incomplete input data. Extensive experiments show that neural parametric surfaces offer greater modeling capabilities than traditional parametric surfaces.","sentences":["The recent surge of utilizing deep neural networks for geometric processing and shape modeling has opened up exciting avenues.","However, there is a conspicuous lack of research efforts on using powerful neural representations to extend the capabilities of parametric surfaces, which are the prevalent surface representations in product design, CAD/CAM, and computer animation.","We present Neural Parametric Surfaces, the first piecewise neural surface representation that allows coarse patch layouts of arbitrary $n$-sided surface patches to model complex surface geometries with high precision, offering greater flexibility over traditional parametric surfaces.","By construction, this new surface representation guarantees $G^0$ continuity between adjacent patches and empirically achieves $G^1$ continuity, which cannot be attained by existing neural patch-based methods.","The key ingredient of our neural parametric surface is a learnable feature complex $\\mathcal{C}$ that is embedded in a high-dimensional space $\\mathbb{R}^D$ and topologically equivalent to the patch layout of the surface; each face cell of the complex is defined by interpolating feature vectors at its vertices.","The learned feature complex is mapped by an MLP-encoded function $f:\\mathcal{C} \\rightarrow \\mathcal{S}$ to produce the neural parametric surface $\\mathcal{S}$. We present a surface fitting algorithm that optimizes the feature complex $\\mathcal{C}$ and trains the neural mapping $f$ to reconstruct given target shapes with high accuracy.","We further show that the proposed representation along with a compact-size neural net can learn a plausible shape space from a shape collection, which can be used for shape interpolation or shape completion from noisy and incomplete input data.","Extensive experiments show that neural parametric surfaces offer greater modeling capabilities than traditional parametric surfaces."],"url":"http://arxiv.org/abs/2309.09911v1"}
{"created":"2023-09-18 16:06:16","title":"Speaker attribution in German parliamentary debates with QLoRA-adapted large language models","abstract":"The growing body of political texts opens up new opportunities for rich insights into political dynamics and ideologies but also increases the workload for manual analysis. Automated speaker attribution, which detects who said what to whom in a speech event and is closely related to semantic role labeling, is an important processing step for computational text analysis. We study the potential of the large language model family Llama 2 to automate speaker attribution in German parliamentary debates from 2017-2021. We fine-tune Llama 2 with QLoRA, an efficient training strategy, and observe our approach to achieve competitive performance in the GermEval 2023 Shared Task On Speaker Attribution in German News Articles and Parliamentary Debates. Our results shed light on the capabilities of large language models in automating speaker attribution, revealing a promising avenue for computational analysis of political discourse and the development of semantic role labeling systems.","sentences":["The growing body of political texts opens up new opportunities for rich insights into political dynamics and ideologies but also increases the workload for manual analysis.","Automated speaker attribution, which detects who said what to whom in a speech event and is closely related to semantic role labeling, is an important processing step for computational text analysis.","We study the potential of the large language model family Llama 2 to automate speaker attribution in German parliamentary debates from 2017-2021.","We fine-tune Llama 2 with QLoRA, an efficient training strategy, and observe our approach to achieve competitive performance in the GermEval 2023 Shared Task On Speaker Attribution in German News Articles and Parliamentary Debates.","Our results shed light on the capabilities of large language models in automating speaker attribution, revealing a promising avenue for computational analysis of political discourse and the development of semantic role labeling systems."],"url":"http://arxiv.org/abs/2309.09902v1"}
{"created":"2023-09-18 16:05:07","title":"The role of causality in explainable artificial intelligence","abstract":"Causality and eXplainable Artificial Intelligence (XAI) have developed as separate fields in computer science, even though the underlying concepts of causation and explanation share common ancient roots. This is further enforced by the lack of review works jointly covering these two fields. In this paper, we investigate the literature to try to understand how and to what extent causality and XAI are intertwined. More precisely, we seek to uncover what kinds of relationships exist between the two concepts and how one can benefit from them, for instance, in building trust in AI systems. As a result, three main perspectives are identified. In the first one, the lack of causality is seen as one of the major limitations of current AI and XAI approaches, and the \"optimal\" form of explanations is investigated. The second is a pragmatic perspective and considers XAI as a tool to foster scientific exploration for causal inquiry, via the identification of pursue-worthy experimental manipulations. Finally, the third perspective supports the idea that causality is propaedeutic to XAI in three possible manners: exploiting concepts borrowed from causality to support or improve XAI, utilizing counterfactuals for explainability, and considering accessing a causal model as explaining itself. To complement our analysis, we also provide relevant software solutions used to automate causal tasks. We believe our work provides a unified view of the two fields of causality and XAI by highlighting potential domain bridges and uncovering possible limitations.","sentences":["Causality and eXplainable Artificial Intelligence (XAI) have developed as separate fields in computer science, even though the underlying concepts of causation and explanation share common ancient roots.","This is further enforced by the lack of review works jointly covering these two fields.","In this paper, we investigate the literature to try to understand how and to what extent causality and XAI are intertwined.","More precisely, we seek to uncover what kinds of relationships exist between the two concepts and how one can benefit from them, for instance, in building trust in AI systems.","As a result, three main perspectives are identified.","In the first one, the lack of causality is seen as one of the major limitations of current AI and XAI approaches, and the \"optimal\" form of explanations is investigated.","The second is a pragmatic perspective and considers XAI as a tool to foster scientific exploration for causal inquiry, via the identification of pursue-worthy experimental manipulations.","Finally, the third perspective supports the idea that causality is propaedeutic to XAI in three possible manners: exploiting concepts borrowed from causality to support or improve XAI, utilizing counterfactuals for explainability, and considering accessing a causal model as explaining itself.","To complement our analysis, we also provide relevant software solutions used to automate causal tasks.","We believe our work provides a unified view of the two fields of causality and XAI by highlighting potential domain bridges and uncovering possible limitations."],"url":"http://arxiv.org/abs/2309.09901v1"}
{"created":"2023-09-18 15:58:34","title":"Impact of Augmented reality system on elementary school ESL learners in country side of china: Motivations, achievements, behaviors and cognitive attainment","abstract":"The English proficiency of students in rural areas of China tends to be lower than that of their urban counterparts, owing to outdated teaching methods, a lack of advanced technology resources, and low motivation for English learning. This study examines the impact of an Augmented Reality English Words Learning (AREWL) system on the learning motivation, achievement, behavioral patterns, and cognitive attainment of elementary school students in rural China. The study explores whether student motivation varies with their level of achievement and vice versa, and provides an analysis of behavioral patterns and cognitive attainment. The AREWL system employs 3D virtual objects, animations, and assessments to teach English pronunciation and spelling. Instructions are provided in both English and Chinese for ease of use.   The sample group consisted of 20 students from grades 1 and 2, selected based on low pretest scores, along with five non-native teachers. Data were collected through pretests and posttests, questionnaires, surveys, video recordings, and in-app evaluations. Quantitative methods were used to analyze test scores and teacher opinions, while qualitative methods were employed to study student behavior and its relationship with cognitive attainment.   Results indicate that both teachers and students responded favorably to the AREWL system. Students exhibited both intrinsic and extrinsic motivation, which correlated significantly with their learning achievements. While behavioral analysis showed interactive engagement with the AREWL system, cognitive attainment was found to be relatively low. The study concludes that AR-based learning applications can play an important role in motivating English learning among young learners in China. The findings contribute to the field of educational technology by introducing a new AR-based English words learning application.","sentences":["The English proficiency of students in rural areas of China tends to be lower than that of their urban counterparts, owing to outdated teaching methods, a lack of advanced technology resources, and low motivation for English learning.","This study examines the impact of an Augmented Reality English Words Learning (AREWL) system on the learning motivation, achievement, behavioral patterns, and cognitive attainment of elementary school students in rural China.","The study explores whether student motivation varies with their level of achievement and vice versa, and provides an analysis of behavioral patterns and cognitive attainment.","The AREWL system employs 3D virtual objects, animations, and assessments to teach English pronunciation and spelling.","Instructions are provided in both English and Chinese for ease of use.   ","The sample group consisted of 20 students from grades 1 and 2, selected based on low pretest scores, along with five non-native teachers.","Data were collected through pretests and posttests, questionnaires, surveys, video recordings, and in-app evaluations.","Quantitative methods were used to analyze test scores and teacher opinions, while qualitative methods were employed to study student behavior and its relationship with cognitive attainment.   ","Results indicate that both teachers and students responded favorably to the AREWL system.","Students exhibited both intrinsic and extrinsic motivation, which correlated significantly with their learning achievements.","While behavioral analysis showed interactive engagement with the AREWL system, cognitive attainment was found to be relatively low.","The study concludes that AR-based learning applications can play an important role in motivating English learning among young learners in China.","The findings contribute to the field of educational technology by introducing a new AR-based English words learning application."],"url":"http://arxiv.org/abs/2309.09894v1"}
{"created":"2023-09-18 15:51:27","title":"Context $\\approx$ Environment","abstract":"Two lines of work are taking the central stage in AI research. On the one hand, the community is making increasing efforts to build models that discard spurious correlations and generalize better in novel test environments. Unfortunately, the bitter lesson so far is that no proposal convincingly outperforms a simple empirical risk minimization baseline. On the other hand, large language models (LLMs) have erupted as algorithms able to learn in-context, generalizing on-the-fly to the eclectic contextual circumstances that users enforce by means of prompting. In this paper, we argue that context $\\approx$ environment, and posit that in-context learning holds the key to better domain generalization. Via extensive theory and experiments, we show that paying attention to context$\\unicode{x2013}\\unicode{x2013}$unlabeled examples as they arrive$\\unicode{x2013}\\unicode{x2013}$allows our proposed In-Context Risk Minimization (ICRM) algorithm to zoom-in on the test environment risk minimizer, leading to significant out-of-distribution performance improvements. From all of this, two messages are worth taking home. Researchers in domain generalization should consider environment as context, and harness the adaptive power of in-context learning. Researchers in LLMs should consider context as environment to better structure data towards generalization.","sentences":["Two lines of work are taking the central stage in AI research.","On the one hand, the community is making increasing efforts to build models that discard spurious correlations and generalize better in novel test environments.","Unfortunately, the bitter lesson so far is that no proposal convincingly outperforms a simple empirical risk minimization baseline.","On the other hand, large language models (LLMs) have erupted as algorithms able to learn in-context, generalizing on-the-fly to the eclectic contextual circumstances that users enforce by means of prompting.","In this paper, we argue that context $\\approx$ environment, and posit that in-context learning holds the key to better domain generalization.","Via extensive theory and experiments, we show that paying attention to context$\\unicode{x2013}\\unicode{x2013}$unlabeled examples as they arrive$\\unicode{x2013}\\unicode{x2013}$allows our proposed In-Context Risk Minimization (ICRM) algorithm to zoom-in on the test environment risk minimizer, leading to significant out-of-distribution performance improvements.","From all of this, two messages are worth taking home.","Researchers in domain generalization should consider environment as context, and harness the adaptive power of in-context learning.","Researchers in LLMs should consider context as environment to better structure data towards generalization."],"url":"http://arxiv.org/abs/2309.09888v1"}
{"created":"2023-09-18 15:50:38","title":"On Model Explanations with Transferable Neural Pathways","abstract":"Neural pathways as model explanations consist of a sparse set of neurons that provide the same level of prediction performance as the whole model. Existing methods primarily focus on accuracy and sparsity but the generated pathways may offer limited interpretability thus fall short in explaining the model behavior. In this paper, we suggest two interpretability criteria of neural pathways: (i) same-class neural pathways should primarily consist of class-relevant neurons; (ii) each instance's neural pathway sparsity should be optimally determined. To this end, we propose a Generative Class-relevant Neural Pathway (GEN-CNP) model that learns to predict the neural pathways from the target model's feature maps. We propose to learn class-relevant information from features of deep and shallow layers such that same-class neural pathways exhibit high similarity. We further impose a faithfulness criterion for GEN-CNP to generate pathways with instance-specific sparsity. We propose to transfer the class-relevant neural pathways to explain samples of the same class and show experimentally and qualitatively their faithfulness and interpretability.","sentences":["Neural pathways as model explanations consist of a sparse set of neurons that provide the same level of prediction performance as the whole model.","Existing methods primarily focus on accuracy and sparsity but the generated pathways may offer limited interpretability thus fall short in explaining the model behavior.","In this paper, we suggest two interpretability criteria of neural pathways: (i) same-class neural pathways should primarily consist of class-relevant neurons; (ii) each instance's neural pathway sparsity should be optimally determined.","To this end, we propose a Generative Class-relevant Neural Pathway (GEN-CNP) model that learns to predict the neural pathways from the target model's feature maps.","We propose to learn class-relevant information from features of deep and shallow layers such that same-class neural pathways exhibit high similarity.","We further impose a faithfulness criterion for GEN-CNP to generate pathways with instance-specific sparsity.","We propose to transfer the class-relevant neural pathways to explain samples of the same class and show experimentally and qualitatively their faithfulness and interpretability."],"url":"http://arxiv.org/abs/2309.09887v1"}
{"created":"2023-09-18 15:45:57","title":"ROAR-Fed: RIS-Assisted Over-the-Air Adaptive Resource Allocation for Federated Learning","abstract":"Over-the-air federated learning (OTA-FL) integrates communication and model aggregation by exploiting the innate superposition property of wireless channels. The approach renders bandwidth efficient learning, but requires care in handling the wireless physical layer impairments. In this paper, federated edge learning is considered for a network that is heterogeneous with respect to client (edge node) data set distributions and individual client resources, under a general non-convex learning objective. We augment the wireless OTA-FL system with a Reconfigurable Intelligent Surface (RIS) to enable a propagation environment with improved learning performance in a realistic time varying physical layer. Our approach is a cross-layer perspective that jointly optimizes communication, computation and learning resources, in this general heterogeneous setting. We adapt the local computation steps and transmission power of the clients in conjunction with the RIS phase shifts. The resulting joint communication and learning algorithm, RIS-assisted Over-the-air Adaptive Resource Allocation for Federated learning (ROAR-Fed) is shown to be convergent in this general setting. Numerical results demonstrate the effectiveness of ROAR-Fed under heterogeneous (non i.i.d.) data and imperfect CSI, indicating the advantage of RIS assisted learning in this general set up.","sentences":["Over-the-air federated learning (OTA-FL) integrates communication and model aggregation by exploiting the innate superposition property of wireless channels.","The approach renders bandwidth efficient learning, but requires care in handling the wireless physical layer impairments.","In this paper, federated edge learning is considered for a network that is heterogeneous with respect to client (edge node) data set distributions and individual client resources, under a general non-convex learning objective.","We augment the wireless OTA-FL system with a Reconfigurable Intelligent Surface (RIS) to enable a propagation environment with improved learning performance in a realistic time varying physical layer.","Our approach is a cross-layer perspective that jointly optimizes communication, computation and learning resources, in this general heterogeneous setting.","We adapt the local computation steps and transmission power of the clients in conjunction with the RIS phase shifts.","The resulting joint communication and learning algorithm, RIS-assisted Over-the-air Adaptive Resource Allocation for Federated learning (ROAR-Fed) is shown to be convergent in this general setting.","Numerical results demonstrate the effectiveness of ROAR-Fed under heterogeneous (non i.i.d.)","data and imperfect CSI, indicating the advantage of RIS assisted learning in this general set up."],"url":"http://arxiv.org/abs/2309.09883v1"}
{"created":"2023-09-18 15:45:51","title":"Differentiable Boustrophedon Path Plans","abstract":"This paper introduces a differentiable representation for optimization of boustrophedon path plans in convex polygons, explores an additional parameter of these path plans that can be optimized, discusses the properties of this representation that can be leveraged during the optimization process, and shows that the previously published attempt at optimization of these path plans was too coarse to be practically useful. Experiments were conducted to show that this differentiable representation can reproduce the same scores from transitional discrete representations of boustrophedon path plans with high fidelity. Finally, optimization via gradient descent was attempted, but found to fail because the search space is far more non-convex than was previously considered in the literature. The wide range of applications for boustrophedon path plans means that this work has the potential to improve path planning efficiency in numerous areas of robotics including mapping and search tasks using uncrewed aerial systems, environmental sampling tasks using uncrewed marine vehicles, and agricultural tasks using ground vehicles, among numerous others applications.","sentences":["This paper introduces a differentiable representation for optimization of boustrophedon path plans in convex polygons, explores an additional parameter of these path plans that can be optimized, discusses the properties of this representation that can be leveraged during the optimization process, and shows that the previously published attempt at optimization of these path plans was too coarse to be practically useful.","Experiments were conducted to show that this differentiable representation can reproduce the same scores from transitional discrete representations of boustrophedon path plans with high fidelity.","Finally, optimization via gradient descent was attempted, but found to fail because the search space is far more non-convex than was previously considered in the literature.","The wide range of applications for boustrophedon path plans means that this work has the potential to improve path planning efficiency in numerous areas of robotics including mapping and search tasks using uncrewed aerial systems, environmental sampling tasks using uncrewed marine vehicles, and agricultural tasks using ground vehicles, among numerous others applications."],"url":"http://arxiv.org/abs/2309.09882v1"}
{"created":"2023-09-18 15:45:22","title":"Deep Reinforcement Learning for the Joint Control of Traffic Light Signaling and Vehicle Speed Advice","abstract":"Traffic congestion in dense urban centers presents an economical and environmental burden. In recent years, the availability of vehicle-to-anything communication allows for the transmission of detailed vehicle states to the infrastructure that can be used for intelligent traffic light control. The other way around, the infrastructure can provide vehicles with advice on driving behavior, such as appropriate velocities, which can improve the efficacy of the traffic system. Several research works applied deep reinforcement learning to either traffic light control or vehicle speed advice. In this work, we propose a first attempt to jointly learn the control of both. We show this to improve the efficacy of traffic systems. In our experiments, the joint control approach reduces average vehicle trip delays, w.r.t. controlling only traffic lights, in eight out of eleven benchmark scenarios. Analyzing the qualitative behavior of the vehicle speed advice policy, we observe that this is achieved by smoothing out the velocity profile of vehicles nearby a traffic light. Learning joint control of traffic signaling and speed advice in the real world could help to reduce congestion and mitigate the economical and environmental repercussions of today's traffic systems.","sentences":["Traffic congestion in dense urban centers presents an economical and environmental burden.","In recent years, the availability of vehicle-to-anything communication allows for the transmission of detailed vehicle states to the infrastructure that can be used for intelligent traffic light control.","The other way around, the infrastructure can provide vehicles with advice on driving behavior, such as appropriate velocities, which can improve the efficacy of the traffic system.","Several research works applied deep reinforcement learning to either traffic light control or vehicle speed advice.","In this work, we propose a first attempt to jointly learn the control of both.","We show this to improve the efficacy of traffic systems.","In our experiments, the joint control approach reduces average vehicle trip delays, w.r.t. controlling only traffic lights, in eight out of eleven benchmark scenarios.","Analyzing the qualitative behavior of the vehicle speed advice policy, we observe that this is achieved by smoothing out the velocity profile of vehicles nearby a traffic light.","Learning joint control of traffic signaling and speed advice in the real world could help to reduce congestion and mitigate the economical and environmental repercussions of today's traffic systems."],"url":"http://arxiv.org/abs/2309.09881v1"}
{"created":"2023-09-18 15:39:19","title":"DynaPix SLAM: A Pixel-Based Dynamic SLAM Approach","abstract":"In static environments, visual simultaneous localization and mapping (V-SLAM) methods achieve remarkable performance. However, moving objects severely affect core modules of such systems like state estimation and loop closure detection. To address this, dynamic SLAM approaches often use semantic information, geometric constraints, or optical flow to mask features associated with dynamic entities. These are limited by various factors such as a dependency on the quality of the underlying method, poor generalization to unknown or unexpected moving objects, and often produce noisy results, e.g. by masking static but movable objects or making use of predefined thresholds. In this paper, to address these trade-offs, we introduce a novel visual SLAM system, DynaPix, based on per-pixel motion probability values. Our approach consists of a new semantic-free probabilistic pixel-wise motion estimation module and an improved pose optimization process. Our per-pixel motion probability estimation combines a novel static background differencing method on both images and optical flows from splatted frames. DynaPix fully integrates those motion probabilities into both map point selection and weighted bundle adjustment within the tracking and optimization modules of ORB-SLAM2. We evaluate DynaPix against ORB-SLAM2 and DynaSLAM on both GRADE and TUM-RGBD datasets, obtaining lower errors and longer trajectory tracking times. We will release both source code and data upon acceptance of this work.","sentences":["In static environments, visual simultaneous localization and mapping (V-SLAM) methods achieve remarkable performance.","However, moving objects severely affect core modules of such systems like state estimation and loop closure detection.","To address this, dynamic SLAM approaches often use semantic information, geometric constraints, or optical flow to mask features associated with dynamic entities.","These are limited by various factors such as a dependency on the quality of the underlying method, poor generalization to unknown or unexpected moving objects, and often produce noisy results, e.g. by masking static but movable objects or making use of predefined thresholds.","In this paper, to address these trade-offs, we introduce a novel visual SLAM system, DynaPix, based on per-pixel motion probability values.","Our approach consists of a new semantic-free probabilistic pixel-wise motion estimation module and an improved pose optimization process.","Our per-pixel motion probability estimation combines a novel static background differencing method on both images and optical flows from splatted frames.","DynaPix fully integrates those motion probabilities into both map point selection and weighted bundle adjustment within the tracking and optimization modules of ORB-SLAM2.","We evaluate DynaPix against ORB-SLAM2 and DynaSLAM on both GRADE and TUM-RGBD datasets, obtaining lower errors and longer trajectory tracking times.","We will release both source code and data upon acceptance of this work."],"url":"http://arxiv.org/abs/2309.09879v1"}
{"created":"2023-09-18 15:37:30","title":"Not Enough Labeled Data? Just Add Semantics: A Data-Efficient Method for Inferring Online Health Texts","abstract":"User-generated texts available on the web and social platforms are often long and semantically challenging, making them difficult to annotate. Obtaining human annotation becomes increasingly difficult as problem domains become more specialized. For example, many health NLP problems require domain experts to be a part of the annotation pipeline. Thus, it is crucial that we develop low-resource NLP solutions able to work with this set of limited-data problems. In this study, we employ Abstract Meaning Representation (AMR) graphs as a means to model low-resource Health NLP tasks sourced from various online health resources and communities. AMRs are well suited to model online health texts as they can represent multi-sentence inputs, abstract away from complex terminology, and model long-distance relationships between co-referring tokens. AMRs thus improve the ability of pre-trained language models to reason about high-complexity texts. Our experiments show that we can improve performance on 6 low-resource health NLP tasks by augmenting text embeddings with semantic graph embeddings. Our approach is task agnostic and easy to merge into any standard text classification pipeline. We experimentally validate that AMRs are useful in the modeling of complex texts by analyzing performance through the lens of two textual complexity measures: the Flesch Kincaid Reading Level and Syntactic Complexity. Our error analysis shows that AMR-infused language models perform better on complex texts and generally show less predictive variance in the presence of changing complexity.","sentences":["User-generated texts available on the web and social platforms are often long and semantically challenging, making them difficult to annotate.","Obtaining human annotation becomes increasingly difficult as problem domains become more specialized.","For example, many health NLP problems require domain experts to be a part of the annotation pipeline.","Thus, it is crucial that we develop low-resource NLP solutions able to work with this set of limited-data problems.","In this study, we employ Abstract Meaning Representation (AMR) graphs as a means to model low-resource Health NLP tasks sourced from various online health resources and communities.","AMRs are well suited to model online health texts as they can represent multi-sentence inputs, abstract away from complex terminology, and model long-distance relationships between co-referring tokens.","AMRs thus improve the ability of pre-trained language models to reason about high-complexity texts.","Our experiments show that we can improve performance on 6 low-resource health NLP tasks by augmenting text embeddings with semantic graph embeddings.","Our approach is task agnostic and easy to merge into any standard text classification pipeline.","We experimentally validate that AMRs are useful in the modeling of complex texts by analyzing performance through the lens of two textual complexity measures: the Flesch Kincaid Reading Level and Syntactic Complexity.","Our error analysis shows that AMR-infused language models perform better on complex texts and generally show less predictive variance in the presence of changing complexity."],"url":"http://arxiv.org/abs/2309.09877v1"}
{"created":"2023-09-18 15:37:01","title":"RaLF: Flow-based Global and Metric Radar Localization in LiDAR Maps","abstract":"Localization is paramount for autonomous robots. While camera and LiDAR-based approaches have been extensively investigated, they are affected by adverse illumination and weather conditions. Therefore, radar sensors have recently gained attention due to their intrinsic robustness to such conditions. In this paper, we propose RaLF, a novel deep neural network-based approach for localizing radar scans in a LiDAR map of the environment, by jointly learning to address both place recognition and metric localization. RaLF is composed of radar and LiDAR feature encoders, a place recognition head that generates global descriptors, and a metric localization head that predicts the 3-DoF transformation between the radar scan and the map. We tackle the place recognition task by learning a shared embedding space between the two modalities via cross-modal metric learning. Additionally, we perform metric localization by predicting pixel-level flow vectors that align the query radar scan with the LiDAR map. We extensively evaluate our approach on multiple real-world driving datasets and show that RaLF achieves state-of-the-art performance for both place recognition and metric localization. Moreover, we demonstrate that our approach can effectively generalize to different cities and sensor setups than the ones used during training. We make the code and trained models publicly available at http://ralf.cs.uni-freiburg.de.","sentences":["Localization is paramount for autonomous robots.","While camera and LiDAR-based approaches have been extensively investigated, they are affected by adverse illumination and weather conditions.","Therefore, radar sensors have recently gained attention due to their intrinsic robustness to such conditions.","In this paper, we propose RaLF, a novel deep neural network-based approach for localizing radar scans in a LiDAR map of the environment, by jointly learning to address both place recognition and metric localization.","RaLF is composed of radar and LiDAR feature encoders, a place recognition head that generates global descriptors, and a metric localization head that predicts the 3-DoF transformation between the radar scan and the map.","We tackle the place recognition task by learning a shared embedding space between the two modalities via cross-modal metric learning.","Additionally, we perform metric localization by predicting pixel-level flow vectors that align the query radar scan with the LiDAR map.","We extensively evaluate our approach on multiple real-world driving datasets and show that RaLF achieves state-of-the-art performance for both place recognition and metric localization.","Moreover, we demonstrate that our approach can effectively generalize to different cities and sensor setups than the ones used during training.","We make the code and trained models publicly available at http://ralf.cs.uni-freiburg.de."],"url":"http://arxiv.org/abs/2309.09875v1"}
{"created":"2023-09-18 15:30:54","title":"Zero-Shot Policy Transferability for the Control of a Scale Autonomous Vehicle","abstract":"We report on a study that employs an in-house developed simulation infrastructure to accomplish zero shot policy transferability for a control policy associated with a scale autonomous vehicle. We focus on implementing policies that require no real world data to be trained (Zero-Shot Transfer), and are developed in-house as opposed to being validated by previous works. We do this by implementing a Neural Network (NN) controller that is trained only on a family of circular reference trajectories. The sensors used are RTK-GPS and IMU, the latter for providing heading. The NN controller is trained using either a human driver (via human in the loop simulation), or a Model Predictive Control (MPC) strategy. We demonstrate these two approaches in conjunction with two operation scenarios: the vehicle follows a waypoint-defined trajectory at constant speed; and the vehicle follows a speed profile that changes along the vehicle's waypoint-defined trajectory. The primary contribution of this work is the demonstration of Zero-Shot Transfer in conjunction with a novel feed-forward NN controller trained using a general purpose, in-house developed simulation platform.","sentences":["We report on a study that employs an in-house developed simulation infrastructure to accomplish zero shot policy transferability for a control policy associated with a scale autonomous vehicle.","We focus on implementing policies that require no real world data to be trained (Zero-Shot Transfer), and are developed in-house as opposed to being validated by previous works.","We do this by implementing a Neural Network (NN) controller that is trained only on a family of circular reference trajectories.","The sensors used are RTK-GPS and IMU, the latter for providing heading.","The NN controller is trained using either a human driver (via human in the loop simulation), or a Model Predictive Control (MPC) strategy.","We demonstrate these two approaches in conjunction with two operation scenarios: the vehicle follows a waypoint-defined trajectory at constant speed; and the vehicle follows a speed profile that changes along the vehicle's waypoint-defined trajectory.","The primary contribution of this work is the demonstration of Zero-Shot Transfer in conjunction with a novel feed-forward NN controller trained using a general purpose, in-house developed simulation platform."],"url":"http://arxiv.org/abs/2309.09870v1"}
{"created":"2023-09-18 15:28:12","title":"EGFE: End-to-end Grouping of Fragmented Elements in UI Designs with Multimodal Learning","abstract":"When translating UI design prototypes to code in industry, automatically generating code from design prototypes can expedite the development of applications and GUI iterations. However, in design prototypes without strict design specifications, UI components may be composed of fragmented elements. Grouping these fragmented elements can greatly improve the readability and maintainability of the generated code. Current methods employ a two-stage strategy that introduces hand-crafted rules to group fragmented elements. Unfortunately, the performance of these methods is not satisfying due to visually overlapped and tiny UI elements. In this study, we propose EGFE, a novel method for automatically End-to-end Grouping Fragmented Elements via UI sequence prediction. To facilitate the UI understanding, we innovatively construct a Transformer encoder to model the relationship between the UI elements with multi-modal representation learning. The evaluation on a dataset of 4606 UI prototypes collected from professional UI designers shows that our method outperforms the state-of-the-art baselines in the precision (by 29.75\\%), recall (by 31.07\\%), and F1-score (by 30.39\\%) at edit distance threshold of 4. In addition, we conduct an empirical study to assess the improvement of the generated front-end code. The results demonstrate the effectiveness of our method on a real software engineering application. Our end-to-end fragmented elements grouping method creates opportunities for improving UI-related software engineering tasks.","sentences":["When translating UI design prototypes to code in industry, automatically generating code from design prototypes can expedite the development of applications and GUI iterations.","However, in design prototypes without strict design specifications, UI components may be composed of fragmented elements.","Grouping these fragmented elements can greatly improve the readability and maintainability of the generated code.","Current methods employ a two-stage strategy that introduces hand-crafted rules to group fragmented elements.","Unfortunately, the performance of these methods is not satisfying due to visually overlapped and tiny UI elements.","In this study, we propose EGFE, a novel method for automatically End-to-end Grouping Fragmented Elements via UI sequence prediction.","To facilitate the UI understanding, we innovatively construct a Transformer encoder to model the relationship between the UI elements with multi-modal representation learning.","The evaluation on a dataset of 4606 UI prototypes collected from professional UI designers shows that our method outperforms the state-of-the-art baselines in the precision (by 29.75\\%), recall (by 31.07\\%), and F1-score (by 30.39\\%) at edit distance threshold of 4.","In addition, we conduct an empirical study to assess the improvement of the generated front-end code.","The results demonstrate the effectiveness of our method on a real software engineering application.","Our end-to-end fragmented elements grouping method creates opportunities for improving UI-related software engineering tasks."],"url":"http://arxiv.org/abs/2309.09867v1"}
{"created":"2023-09-18 15:25:59","title":"Contrastive Learning for Enhancing Robust Scene Transfer in Vision-based Agile Flight","abstract":"Scene transfer for vision-based mobile robotics applications is a highly relevant and challenging problem. The utility of a robot greatly depends on its ability to perform a task in the real world, outside of a well-controlled lab environment. Existing scene transfer end-to-end policy learning approaches often suffer from poor sample efficiency or limited generalization capabilities, making them unsuitable for mobile robotics applications. This work proposes an adaptive multi-pair contrastive learning strategy for visual representation learning that enables zero-shot scene transfer and real-world deployment. Control policies relying on the embedding are able to operate in unseen environments without the need for finetuning in the deployment environment. We demonstrate the performance of our approach on the task of agile, vision-based quadrotor flight. Extensive simulation and real-world experiments demonstrate that our approach successfully generalizes beyond the training domain and outperforms all baselines.","sentences":["Scene transfer for vision-based mobile robotics applications is a highly relevant and challenging problem.","The utility of a robot greatly depends on its ability to perform a task in the real world, outside of a well-controlled lab environment.","Existing scene transfer end-to-end policy learning approaches often suffer from poor sample efficiency or limited generalization capabilities, making them unsuitable for mobile robotics applications.","This work proposes an adaptive multi-pair contrastive learning strategy for visual representation learning that enables zero-shot scene transfer and real-world deployment.","Control policies relying on the embedding are able to operate in unseen environments without the need for finetuning in the deployment environment.","We demonstrate the performance of our approach on the task of agile, vision-based quadrotor flight.","Extensive simulation and real-world experiments demonstrate that our approach successfully generalizes beyond the training domain and outperforms all baselines."],"url":"http://arxiv.org/abs/2309.09865v1"}
{"created":"2023-09-18 15:24:55","title":"Learning Spatial and Temporal Hierarchies: Hierarchical Active Inference for navigation in Multi-Room Maze Environments","abstract":"Cognitive maps play a crucial role in facilitating flexible behaviour by representing spatial and conceptual relationships within an environment. The ability to learn and infer the underlying structure of the environment is crucial for effective exploration and navigation. This paper introduces a hierarchical active inference model addressing the challenge of inferring structure in the world from pixel-based observations. We propose a three-layer hierarchical model consisting of a cognitive map, an allocentric, and an egocentric world model, combining curiosity-driven exploration with goal-oriented behaviour at the different levels of reasoning from context to place to motion. This allows for efficient exploration and goal-directed search in room-structured mini-grid environments.","sentences":["Cognitive maps play a crucial role in facilitating flexible behaviour by representing spatial and conceptual relationships within an environment.","The ability to learn and infer the underlying structure of the environment is crucial for effective exploration and navigation.","This paper introduces a hierarchical active inference model addressing the challenge of inferring structure in the world from pixel-based observations.","We propose a three-layer hierarchical model consisting of a cognitive map, an allocentric, and an egocentric world model, combining curiosity-driven exploration with goal-oriented behaviour at the different levels of reasoning from context to place to motion.","This allows for efficient exploration and goal-directed search in room-structured mini-grid environments."],"url":"http://arxiv.org/abs/2309.09864v1"}
{"created":"2023-09-18 15:20:13","title":"Unsupervised Open-Vocabulary Object Localization in Videos","abstract":"In this paper, we show that recent advances in video representation learning and pre-trained vision-language models allow for substantial improvements in self-supervised video object localization. We propose a method that first localizes objects in videos via a slot attention approach and then assigns text to the obtained slots. The latter is achieved by an unsupervised way to read localized semantic information from the pre-trained CLIP model. The resulting video object localization is entirely unsupervised apart from the implicit annotation contained in CLIP, and it is effectively the first unsupervised approach that yields good results on regular video benchmarks.","sentences":["In this paper, we show that recent advances in video representation learning and pre-trained vision-language models allow for substantial improvements in self-supervised video object localization.","We propose a method that first localizes objects in videos via a slot attention approach and then assigns text to the obtained slots.","The latter is achieved by an unsupervised way to read localized semantic information from the pre-trained CLIP model.","The resulting video object localization is entirely unsupervised apart from the implicit annotation contained in CLIP, and it is effectively the first unsupervised approach that yields good results on regular video benchmarks."],"url":"http://arxiv.org/abs/2309.09858v1"}
{"created":"2023-09-18 15:15:35","title":"PseudoCal: Towards Initialisation-Free Deep Learning-Based Camera-LiDAR Self-Calibration","abstract":"Camera-LiDAR extrinsic calibration is a critical task for multi-sensor fusion in autonomous systems, such as self-driving vehicles and mobile robots. Traditional techniques often require manual intervention or specific environments, making them labour-intensive and error-prone. Existing deep learning-based self-calibration methods focus on small realignments and still rely on initial estimates, limiting their practicality. In this paper, we present PseudoCal, a novel self-calibration method that overcomes these limitations by leveraging the pseudo-LiDAR concept and working directly in the 3D space instead of limiting itself to the camera field of view. In typical autonomous vehicle and robotics contexts and conventions, PseudoCal is able to perform one-shot calibration quasi-independently of initial parameter estimates, addressing extreme cases that remain unsolved by existing approaches.","sentences":["Camera-LiDAR extrinsic calibration is a critical task for multi-sensor fusion in autonomous systems, such as self-driving vehicles and mobile robots.","Traditional techniques often require manual intervention or specific environments, making them labour-intensive and error-prone.","Existing deep learning-based self-calibration methods focus on small realignments and still rely on initial estimates, limiting their practicality.","In this paper, we present PseudoCal, a novel self-calibration method that overcomes these limitations by leveraging the pseudo-LiDAR concept and working directly in the 3D space instead of limiting itself to the camera field of view.","In typical autonomous vehicle and robotics contexts and conventions, PseudoCal is able to perform one-shot calibration quasi-independently of initial parameter estimates, addressing extreme cases that remain unsolved by existing approaches."],"url":"http://arxiv.org/abs/2309.09855v1"}
{"created":"2023-09-18 14:59:11","title":"CC-SGG: Corner Case Scenario Generation using Learned Scene Graphs","abstract":"Corner case scenarios are an essential tool for testing and validating the safety of autonomous vehicles (AVs). As these scenarios are often insufficiently present in naturalistic driving datasets, augmenting the data with synthetic corner cases greatly enhances the safe operation of AVs in unique situations. However, the generation of synthetic, yet realistic, corner cases poses a significant challenge. In this work, we introduce a novel approach based on Heterogeneous Graph Neural Networks (HGNNs) to transform regular driving scenarios into corner cases. To achieve this, we first generate concise representations of regular driving scenes as scene graphs, minimally manipulating their structure and properties. Our model then learns to perturb those graphs to generate corner cases using attention and triple embeddings. The input and perturbed graphs are then imported back into the simulation to generate corner case scenarios. Our model successfully learned to produce corner cases from input scene graphs, achieving 89.9% prediction accuracy on our testing dataset. We further validate the generated scenarios on baseline autonomous driving methods, demonstrating our model's ability to effectively create critical situations for the baselines.","sentences":["Corner case scenarios are an essential tool for testing and validating the safety of autonomous vehicles (AVs).","As these scenarios are often insufficiently present in naturalistic driving datasets, augmenting the data with synthetic corner cases greatly enhances the safe operation of AVs in unique situations.","However, the generation of synthetic, yet realistic, corner cases poses a significant challenge.","In this work, we introduce a novel approach based on Heterogeneous Graph Neural Networks (HGNNs) to transform regular driving scenarios into corner cases.","To achieve this, we first generate concise representations of regular driving scenes as scene graphs, minimally manipulating their structure and properties.","Our model then learns to perturb those graphs to generate corner cases using attention and triple embeddings.","The input and perturbed graphs are then imported back into the simulation to generate corner case scenarios.","Our model successfully learned to produce corner cases from input scene graphs, achieving 89.9% prediction accuracy on our testing dataset.","We further validate the generated scenarios on baseline autonomous driving methods, demonstrating our model's ability to effectively create critical situations for the baselines."],"url":"http://arxiv.org/abs/2309.09844v1"}
{"created":"2023-09-18 14:59:10","title":"Instruction-Following Speech Recognition","abstract":"Conventional end-to-end Automatic Speech Recognition (ASR) models primarily focus on exact transcription tasks, lacking flexibility for nuanced user interactions. With the advent of Large Language Models (LLMs) in speech processing, more organic, text-prompt-based interactions have become possible. However, the mechanisms behind these models' speech understanding and \"reasoning\" capabilities remain underexplored. To study this question from the data perspective, we introduce instruction-following speech recognition, training a Listen-Attend-Spell model to understand and execute a diverse set of free-form text instructions. This enables a multitude of speech recognition tasks -- ranging from transcript manipulation to summarization -- without relying on predefined command sets. Remarkably, our model, trained from scratch on Librispeech, interprets and executes simple instructions without requiring LLMs or pre-trained speech modules. It also offers selective transcription options based on instructions like \"transcribe first half and then turn off listening,\" providing an additional layer of privacy and safety compared to existing LLMs. Our findings highlight the significant potential of instruction-following training to advance speech foundation models.","sentences":["Conventional end-to-end Automatic Speech Recognition (ASR) models primarily focus on exact transcription tasks, lacking flexibility for nuanced user interactions.","With the advent of Large Language Models (LLMs) in speech processing, more organic, text-prompt-based interactions have become possible.","However, the mechanisms behind these models' speech understanding and \"reasoning\" capabilities remain underexplored.","To study this question from the data perspective, we introduce instruction-following speech recognition, training a Listen-Attend-Spell model to understand and execute a diverse set of free-form text instructions.","This enables a multitude of speech recognition tasks -- ranging from transcript manipulation to summarization -- without relying on predefined command sets.","Remarkably, our model, trained from scratch on Librispeech, interprets and executes simple instructions without requiring LLMs or pre-trained speech modules.","It also offers selective transcription options based on instructions like \"transcribe first half and then turn off listening,\" providing an additional layer of privacy and safety compared to existing LLMs.","Our findings highlight the significant potential of instruction-following training to advance speech foundation models."],"url":"http://arxiv.org/abs/2309.09843v1"}
{"created":"2023-09-18 14:57:40","title":"Mobility Performance Analysis of RACH Optimization Based on Decision Tree Supervised Learning for Conditional Handover in 5G Beamformed Networks","abstract":"In 5G cellular networks, frequency range 2 (FR2) introduces higher frequencies that cause rapid signal degradation and challenge user mobility. In recent studies, a conditional handover procedure has been adopted as an enhancement to baseline handover to enhance user mobility robustness. In this article, the mobility performance of conditional handover is analyzed for a 5G mm-wave network in FR2 that employs beamforming. In addition, a resource-efficient random access procedure is proposed that increases the probability of contention-free random access during a handover. Moreover, a simple yet effective decision tree-based supervised learning method is proposed to minimize the handover failures that are caused by the beam preparation phase of the random access procedure. Results have shown that a tradeoff exists between contention-free random access and handover failures. It is also seen that the optimum operation point of random access is achievable with the proposed learning algorithm for conditional handover. Moreover, a mobility performance comparison of conditional handover with baseline handover is also carried out. Results have shown that while baseline handover causes fewer handover failures than conditional handover, the total number of mobility failures in the latter is less due to the decoupling of the handover preparation and execution phases.","sentences":["In 5G cellular networks, frequency range 2 (FR2) introduces higher frequencies that cause rapid signal degradation and challenge user mobility.","In recent studies, a conditional handover procedure has been adopted as an enhancement to baseline handover to enhance user mobility robustness.","In this article, the mobility performance of conditional handover is analyzed for a 5G mm-wave network in FR2 that employs beamforming.","In addition, a resource-efficient random access procedure is proposed that increases the probability of contention-free random access during a handover.","Moreover, a simple yet effective decision tree-based supervised learning method is proposed to minimize the handover failures that are caused by the beam preparation phase of the random access procedure.","Results have shown that a tradeoff exists between contention-free random access and handover failures.","It is also seen that the optimum operation point of random access is achievable with the proposed learning algorithm for conditional handover.","Moreover, a mobility performance comparison of conditional handover with baseline handover is also carried out.","Results have shown that while baseline handover causes fewer handover failures than conditional handover, the total number of mobility failures in the latter is less due to the decoupling of the handover preparation and execution phases."],"url":"http://arxiv.org/abs/2309.09840v1"}
{"created":"2023-09-18 14:55:21","title":"Hypr: A comprehensive study for ASR hypothesis revising with a reference corpus","abstract":"With the development of deep learning, automatic speech recognition (ASR) has made significant progress. To further enhance the performance, revising recognition results is one of the lightweight but efficient manners. Various methods can be roughly classified into N-best reranking methods and error correction models. The former aims to select the hypothesis with the lowest error rate from a set of candidates generated by ASR for a given input speech. The latter focuses on detecting recognition errors in a given hypothesis and correcting these errors to obtain an enhanced result. However, we observe that these studies are hardly comparable to each other as they are usually evaluated on different corpora, paired with different ASR models, and even use different datasets to train the models. Accordingly, we first concentrate on releasing an ASR hypothesis revising (HypR) dataset in this study. HypR contains several commonly used corpora (AISHELL-1, TED-LIUM 2, and LibriSpeech) and provides 50 recognition hypotheses for each speech utterance. The checkpoint models of the ASR are also published. In addition, we implement and compare several classic and representative methods, showing the recent research progress in revising speech recognition results. We hope the publicly available HypR dataset can become a reference benchmark for subsequent research and promote the school of research to an advanced level.","sentences":["With the development of deep learning, automatic speech recognition (ASR) has made significant progress.","To further enhance the performance, revising recognition results is one of the lightweight but efficient manners.","Various methods can be roughly classified into N-best reranking methods and error correction models.","The former aims to select the hypothesis with the lowest error rate from a set of candidates generated by ASR for a given input speech.","The latter focuses on detecting recognition errors in a given hypothesis and correcting these errors to obtain an enhanced result.","However, we observe that these studies are hardly comparable to each other as they are usually evaluated on different corpora, paired with different ASR models, and even use different datasets to train the models.","Accordingly, we first concentrate on releasing an ASR hypothesis revising (HypR) dataset in this study.","HypR contains several commonly used corpora (AISHELL-1, TED-LIUM 2, and LibriSpeech) and provides 50 recognition hypotheses for each speech utterance.","The checkpoint models of the ASR are also published.","In addition, we implement and compare several classic and representative methods, showing the recent research progress in revising speech recognition results.","We hope the publicly available HypR dataset can become a reference benchmark for subsequent research and promote the school of research to an advanced level."],"url":"http://arxiv.org/abs/2309.09838v1"}
{"created":"2023-09-18 14:54:42","title":"Frame-to-Utterance Convergence: A Spectra-Temporal Approach for Unified Spoofing Detection","abstract":"Voice spoofing attacks pose a significant threat to automated speaker verification systems. Existing anti-spoofing methods often simulate specific attack types, such as synthetic or replay attacks. However, in real-world scenarios, the countermeasures are unaware of the generation schema of the attack, necessitating a unified solution. Current unified solutions struggle to detect spoofing artifacts, especially with recent spoofing mechanisms. For instance, the spoofing algorithms inject spectral or temporal anomalies, which are challenging to identify. To this end, we present a spectra-temporal fusion leveraging frame-level and utterance-level coefficients. We introduce a novel local spectral deviation coefficient (SDC) for frame-level inconsistencies and employ a bi-LSTM-based network for sequential temporal coefficients (STC), which capture utterance-level artifacts. Our spectra-temporal fusion strategy combines these coefficients, and an auto-encoder generates spectra-temporal deviated coefficients (STDC) to enhance robustness. Our proposed approach addresses multiple spoofing categories, including synthetic, replay, and partial deepfake attacks. Extensive evaluation on diverse datasets (ASVspoof2019, ASVspoof2021, VSDC, partial spoofs, and in-the-wild deepfakes) demonstrated its robustness for a wide range of voice applications.","sentences":["Voice spoofing attacks pose a significant threat to automated speaker verification systems.","Existing anti-spoofing methods often simulate specific attack types, such as synthetic or replay attacks.","However, in real-world scenarios, the countermeasures are unaware of the generation schema of the attack, necessitating a unified solution.","Current unified solutions struggle to detect spoofing artifacts, especially with recent spoofing mechanisms.","For instance, the spoofing algorithms inject spectral or temporal anomalies, which are challenging to identify.","To this end, we present a spectra-temporal fusion leveraging frame-level and utterance-level coefficients.","We introduce a novel local spectral deviation coefficient (SDC) for frame-level inconsistencies and employ a bi-LSTM-based network for sequential temporal coefficients (STC), which capture utterance-level artifacts.","Our spectra-temporal fusion strategy combines these coefficients, and an auto-encoder generates spectra-temporal deviated coefficients (STDC) to enhance robustness.","Our proposed approach addresses multiple spoofing categories, including synthetic, replay, and partial deepfake attacks.","Extensive evaluation on diverse datasets (ASVspoof2019, ASVspoof2021, VSDC, partial spoofs, and in-the-wild deepfakes) demonstrated its robustness for a wide range of voice applications."],"url":"http://arxiv.org/abs/2309.09837v1"}
{"created":"2023-09-18 14:52:28","title":"Predictive Uncertainty-based Bias Mitigation in Ranking","abstract":"Societal biases that are contained in retrieved documents have received increased interest. Such biases, which are often prevalent in the training data and learned by the model, can cause societal harms, by misrepresenting certain groups, and by enforcing stereotypes. Mitigating such biases demands algorithms that balance the trade-off between maximized utility for the user with fairness objectives, which incentivize unbiased rankings. Prior work on bias mitigation often assumes that ranking scores, which correspond to the utility that a document holds for a user, can be accurately determined. In reality, there is always a degree of uncertainty in the estimate of expected document utility. This uncertainty can be approximated by viewing ranking models through a Bayesian perspective, where the standard deterministic score becomes a distribution.   In this work, we investigate whether uncertainty estimates can be used to decrease the amount of bias in the ranked results, while minimizing loss in measured utility. We introduce a simple method that uses the uncertainty of the ranking scores for an uncertainty-aware, post hoc approach to bias mitigation. We compare our proposed method with existing baselines for bias mitigation with respect to the utility-fairness trade-off, the controllability of methods, and computational costs. We show that an uncertainty-based approach can provide an intuitive and flexible trade-off that outperforms all baselines without additional training requirements, allowing for the post hoc use of this approach on top of arbitrary retrieval models.","sentences":["Societal biases that are contained in retrieved documents have received increased interest.","Such biases, which are often prevalent in the training data and learned by the model, can cause societal harms, by misrepresenting certain groups, and by enforcing stereotypes.","Mitigating such biases demands algorithms that balance the trade-off between maximized utility for the user with fairness objectives, which incentivize unbiased rankings.","Prior work on bias mitigation often assumes that ranking scores, which correspond to the utility that a document holds for a user, can be accurately determined.","In reality, there is always a degree of uncertainty in the estimate of expected document utility.","This uncertainty can be approximated by viewing ranking models through a Bayesian perspective, where the standard deterministic score becomes a distribution.   ","In this work, we investigate whether uncertainty estimates can be used to decrease the amount of bias in the ranked results, while minimizing loss in measured utility.","We introduce a simple method that uses the uncertainty of the ranking scores for an uncertainty-aware, post hoc approach to bias mitigation.","We compare our proposed method with existing baselines for bias mitigation with respect to the utility-fairness trade-off, the controllability of methods, and computational costs.","We show that an uncertainty-based approach can provide an intuitive and flexible trade-off that outperforms all baselines without additional training requirements, allowing for the post hoc use of this approach on top of arbitrary retrieval models."],"url":"http://arxiv.org/abs/2309.09833v1"}
{"created":"2023-09-18 14:51:51","title":"Task Selection and Assignment for Multi-modal Multi-task Dialogue Act Classification with Non-stationary Multi-armed Bandits","abstract":"Multi-task learning (MTL) aims to improve the performance of a primary task by jointly learning with related auxiliary tasks. Traditional MTL methods select tasks randomly during training. However, both previous studies and our results suggest that such the random selection of tasks may not be helpful, and can even be harmful to performance. Therefore, new strategies for task selection and assignment in MTL need to be explored. This paper studies the multi-modal, multi-task dialogue act classification task, and proposes a method for selecting and assigning tasks based on non-stationary multi-armed bandits (MAB) with discounted Thompson Sampling (TS) using Gaussian priors. Our experimental results show that in different training stages, different tasks have different utility. Our proposed method can effectively identify the task utility, actively avoid useless or harmful tasks, and realise the task assignment during training. Our proposed method is significantly superior in terms of UAR and F1 to the single-task and multi-task baselines with p-values < 0.05. Further analysis of experiments indicates that for the dataset with the data imbalance problem, our proposed method has significantly higher stability and can obtain consistent and decent performance for minority classes. Our proposed method is superior to the current state-of-the-art model.","sentences":["Multi-task learning (MTL) aims to improve the performance of a primary task by jointly learning with related auxiliary tasks.","Traditional MTL methods select tasks randomly during training.","However, both previous studies and our results suggest that such the random selection of tasks may not be helpful, and can even be harmful to performance.","Therefore, new strategies for task selection and assignment in MTL need to be explored.","This paper studies the multi-modal, multi-task dialogue act classification task, and proposes a method for selecting and assigning tasks based on non-stationary multi-armed bandits (MAB) with discounted Thompson Sampling (TS) using Gaussian priors.","Our experimental results show that in different training stages, different tasks have different utility.","Our proposed method can effectively identify the task utility, actively avoid useless or harmful tasks, and realise the task assignment during training.","Our proposed method is significantly superior in terms of UAR and F1 to the single-task and multi-task baselines with p-values < 0.05.","Further analysis of experiments indicates that for the dataset with the data imbalance problem, our proposed method has significantly higher stability and can obtain consistent and decent performance for minority classes.","Our proposed method is superior to the current state-of-the-art model."],"url":"http://arxiv.org/abs/2309.09832v1"}
{"created":"2023-09-18 14:50:46","title":"Clustering of Urban Traffic Patterns by K-Means and Dynamic Time Warping: Case Study","abstract":"Clustering of urban traffic patterns is an essential task in many different areas of traffic management and planning. In this paper, two significant applications in the clustering of urban traffic patterns are described. The first application estimates the missing speed values using the speed of road segments with similar traffic patterns to colorify map tiles. The second one is the estimation of essential road segments for generating addresses for a local point on the map, using the similarity patterns of different road segments. The speed time series extracts the traffic pattern in different road segments. In this paper, we proposed the time series clustering algorithm based on K-Means and Dynamic Time Warping. The case study of our proposed algorithm is based on the Snapp application's driver speed time series data. The results of the two applications illustrate that the proposed method can extract similar urban traffic patterns.","sentences":["Clustering of urban traffic patterns is an essential task in many different areas of traffic management and planning.","In this paper, two significant applications in the clustering of urban traffic patterns are described.","The first application estimates the missing speed values using the speed of road segments with similar traffic patterns to colorify map tiles.","The second one is the estimation of essential road segments for generating addresses for a local point on the map, using the similarity patterns of different road segments.","The speed time series extracts the traffic pattern in different road segments.","In this paper, we proposed the time series clustering algorithm based on K-Means and Dynamic Time Warping.","The case study of our proposed algorithm is based on the Snapp application's driver speed time series data.","The results of the two applications illustrate that the proposed method can extract similar urban traffic patterns."],"url":"http://arxiv.org/abs/2309.09830v1"}
{"created":"2023-09-18 14:49:49","title":"Two Decades of Empirical Research on Trust in AI: A Bibliometric Analysis and HCI Research Agenda","abstract":"Trust is widely regarded as a critical component to build artificial intelligence (AI) systems that people will use and safely rely upon. As research in this area continues to evolve, it becomes imperative that the HCI research community synchronize their empirical efforts and align on the path toward effective knowledge creation. To lay the groundwork toward achieving this objective, we performed a comprehensive bibliometric analysis of two decades of empirical research measuring trust in AI, comprising 538 core articles and 15'548 cited articles across multiple disciplines. A key insight arising from our analysis is the persistence of an exploratory approach across the research landscape. To foster a deeper understanding of trust in AI, we advocate for a contextualized strategy. To pave the way, we outline a research agenda, highlighting questions that require further investigation.","sentences":["Trust is widely regarded as a critical component to build artificial intelligence (AI) systems that people will use and safely rely upon.","As research in this area continues to evolve, it becomes imperative that the HCI research community synchronize their empirical efforts and align on the path toward effective knowledge creation.","To lay the groundwork toward achieving this objective, we performed a comprehensive bibliometric analysis of two decades of empirical research measuring trust in AI, comprising 538 core articles and 15'548 cited articles across multiple disciplines.","A key insight arising from our analysis is the persistence of an exploratory approach across the research landscape.","To foster a deeper understanding of trust in AI, we advocate for a contextualized strategy.","To pave the way, we outline a research agenda, highlighting questions that require further investigation."],"url":"http://arxiv.org/abs/2309.09828v1"}
{"created":"2023-09-18 14:47:34","title":"Efficient Avoidance of Vulnerabilities in Auto-completed Smart Contract Code Using Vulnerability-constrained Decoding","abstract":"Auto-completing code enables developers to speed up coding significantly. Recent advances in transformer-based large language model (LLM) technologies have been applied to code synthesis. However, studies show that many of such synthesized codes contain vulnerabilities. We propose a novel vulnerability-constrained decoding approach to reduce the amount of vulnerable code generated by such models. Using a small dataset of labeled vulnerable lines of code, we fine-tune an LLM to include vulnerability labels when generating code, acting as an embedded classifier. Then, during decoding, we deny the model to generate these labels to avoid generating vulnerable code. To evaluate the method, we chose to automatically complete Ethereum Blockchain smart contracts (SCs) as the case study due to the strict requirements of SC security. We first fine-tuned the 6-billion-parameter GPT-J model using 186,397 Ethereum SCs after removing the duplication from 2,217,692 SCs. The fine-tuning took more than one week using ten GPUs. The results showed that our fine-tuned model could synthesize SCs with an average BLEU (BiLingual Evaluation Understudy) score of 0.557. However, many codes in the auto-completed SCs were vulnerable. Using the code before the vulnerable line of 176 SCs containing different types of vulnerabilities to auto-complete the code, we found that more than 70% of the auto-completed codes were insecure. Thus, we further fine-tuned the model on other 941 vulnerable SCs containing the same types of vulnerabilities and applied vulnerability-constrained decoding. The fine-tuning took only one hour with four GPUs. We then auto-completed the 176 SCs again and found that our approach could identify 62% of the code to be generated as vulnerable and avoid generating 67% of them, indicating the approach could efficiently and effectively avoid vulnerabilities in the auto-completed code.","sentences":["Auto-completing code enables developers to speed up coding significantly.","Recent advances in transformer-based large language model (LLM) technologies have been applied to code synthesis.","However, studies show that many of such synthesized codes contain vulnerabilities.","We propose a novel vulnerability-constrained decoding approach to reduce the amount of vulnerable code generated by such models.","Using a small dataset of labeled vulnerable lines of code, we fine-tune an LLM to include vulnerability labels when generating code, acting as an embedded classifier.","Then, during decoding, we deny the model to generate these labels to avoid generating vulnerable code.","To evaluate the method, we chose to automatically complete Ethereum Blockchain smart contracts (SCs) as the case study due to the strict requirements of SC security.","We first fine-tuned the 6-billion-parameter GPT-J model using 186,397 Ethereum SCs after removing the duplication from 2,217,692 SCs.","The fine-tuning took more than one week using ten GPUs.","The results showed that our fine-tuned model could synthesize SCs with an average BLEU (BiLingual Evaluation Understudy) score of 0.557.","However, many codes in the auto-completed SCs were vulnerable.","Using the code before the vulnerable line of 176 SCs containing different types of vulnerabilities to auto-complete the code, we found that more than 70% of the auto-completed codes were insecure.","Thus, we further fine-tuned the model on other 941 vulnerable SCs containing the same types of vulnerabilities and applied vulnerability-constrained decoding.","The fine-tuning took only one hour with four GPUs.","We then auto-completed the 176 SCs again and found that our approach could identify 62% of the code to be generated as vulnerable and avoid generating 67% of them, indicating the approach could efficiently and effectively avoid vulnerabilities in the auto-completed code."],"url":"http://arxiv.org/abs/2309.09826v1"}
{"created":"2023-09-18 14:47:24","title":"Bias of AI-Generated Content: An Examination of News Produced by Large Language Models","abstract":"Large language models (LLMs) have the potential to transform our lives and work through the content they generate, known as AI-Generated Content (AIGC). To harness this transformation, we need to understand the limitations of LLMs. Here, we investigate the bias of AIGC produced by seven representative LLMs, including ChatGPT and LLaMA. We collect news articles from The New York Times and Reuters, both known for delivering relatively unbiased news. We then apply each examined LLM to generate news content with headlines of these news articles as prompts, and evaluate the gender and racial biases of the AIGC produced by the LLM by comparing the AIGC and the original news articles. We further analyze the gender bias of each LLM under biased prompts by adding gender-biased messages to prompts constructed from these news headlines. Our study reveals that the AIGC produced by each examined LLM demonstrates substantial gender and racial biases. Moreover, the AIGC generated by each LLM exhibits notable discrimination against females and individuals of the Black race. Among the LLMs, the AIGC generated by ChatGPT demonstrates the lowest level of bias, and ChatGPT is the sole model capable of declining content generation when provided with biased prompts.","sentences":["Large language models (LLMs) have the potential to transform our lives and work through the content they generate, known as AI-Generated Content (AIGC).","To harness this transformation, we need to understand the limitations of LLMs.","Here, we investigate the bias of AIGC produced by seven representative LLMs, including ChatGPT and LLaMA.","We collect news articles from The New York Times and Reuters, both known for delivering relatively unbiased news.","We then apply each examined LLM to generate news content with headlines of these news articles as prompts, and evaluate the gender and racial biases of the AIGC produced by the LLM by comparing the AIGC and the original news articles.","We further analyze the gender bias of each LLM under biased prompts by adding gender-biased messages to prompts constructed from these news headlines.","Our study reveals that the AIGC produced by each examined LLM demonstrates substantial gender and racial biases.","Moreover, the AIGC generated by each LLM exhibits notable discrimination against females and individuals of the Black race.","Among the LLMs, the AIGC generated by ChatGPT demonstrates the lowest level of bias, and ChatGPT is the sole model capable of declining content generation when provided with biased prompts."],"url":"http://arxiv.org/abs/2309.09825v1"}
{"created":"2023-09-18 14:44:52","title":"Is the Computing Continuum Already Here?","abstract":"The computing continuum, a novel paradigm that extends beyond the current silos of cloud and edge computing, can enable the seamless and dynamic deployment of applications across diverse infrastructures. By utilizing the cloud-native features and scalability of Kubernetes, this concept promotes deployment transparency, communication transparency, and resource availability transparency. Key features of this paradigm include intent-driven policies, a decentralized architecture, multi-ownership, and a fluid topology. Integral to the computing continuum are the building blocks of dynamic discovery and peering, hierarchical resource continuum, resource and service reflection, network continuum, and storage and data continuum. The implementation of these principles allows organizations to foster an efficient, dynamic, and seamless computing environment, thereby facilitating the deployment of complex distributed applications across varying infrastructures.","sentences":["The computing continuum, a novel paradigm that extends beyond the current silos of cloud and edge computing, can enable the seamless and dynamic deployment of applications across diverse infrastructures.","By utilizing the cloud-native features and scalability of Kubernetes, this concept promotes deployment transparency, communication transparency, and resource availability transparency.","Key features of this paradigm include intent-driven policies, a decentralized architecture, multi-ownership, and a fluid topology.","Integral to the computing continuum are the building blocks of dynamic discovery and peering, hierarchical resource continuum, resource and service reflection, network continuum, and storage and data continuum.","The implementation of these principles allows organizations to foster an efficient, dynamic, and seamless computing environment, thereby facilitating the deployment of complex distributed applications across varying infrastructures."],"url":"http://arxiv.org/abs/2309.09822v1"}
{"created":"2023-09-18 14:39:26","title":"Grasp-Anything: Large-scale Grasp Dataset from Foundation Models","abstract":"Foundation models such as ChatGPT have made significant strides in robotic tasks due to their universal representation of real-world domains. In this paper, we leverage foundation models to tackle grasp detection, a persistent challenge in robotics with broad industrial applications. Despite numerous grasp datasets, their object diversity remains limited compared to real-world figures. Fortunately, foundation models possess an extensive repository of real-world knowledge, including objects we encounter in our daily lives. As a consequence, a promising solution to the limited representation in previous grasp datasets is to harness the universal knowledge embedded in these foundation models. We present Grasp-Anything, a new large-scale grasp dataset synthesized from foundation models to implement this solution. Grasp-Anything excels in diversity and magnitude, boasting 1M samples with text descriptions and more than 3M objects, surpassing prior datasets. Empirically, we show that Grasp-Anything successfully facilitates zero-shot grasp detection on vision-based tasks and real-world robotic experiments. Our dataset and code are available at https://grasp-anything-2023.github.io.","sentences":["Foundation models such as ChatGPT have made significant strides in robotic tasks due to their universal representation of real-world domains.","In this paper, we leverage foundation models to tackle grasp detection, a persistent challenge in robotics with broad industrial applications.","Despite numerous grasp datasets, their object diversity remains limited compared to real-world figures.","Fortunately, foundation models possess an extensive repository of real-world knowledge, including objects we encounter in our daily lives.","As a consequence, a promising solution to the limited representation in previous grasp datasets is to harness the universal knowledge embedded in these foundation models.","We present Grasp-Anything, a new large-scale grasp dataset synthesized from foundation models to implement this solution.","Grasp-Anything excels in diversity and magnitude, boasting 1M samples with text descriptions and more than 3M objects, surpassing prior datasets.","Empirically, we show that Grasp-Anything successfully facilitates zero-shot grasp detection on vision-based tasks and real-world robotic experiments.","Our dataset and code are available at https://grasp-anything-2023.github.io."],"url":"http://arxiv.org/abs/2309.09818v1"}
{"created":"2023-09-18 14:35:35","title":"R2GenGPT: Radiology Report Generation with Frozen LLMs","abstract":"Large Language Models (LLMs) have consistently showcased remarkable generalization capabilities when applied to various language tasks. Nonetheless, harnessing the full potential of LLMs for Radiology Report Generation (R2Gen) still presents a challenge, stemming from the inherent disparity in modality between LLMs and the R2Gen task. To bridge this gap effectively, we propose R2GenGPT, which is a novel solution that aligns visual features with the word embedding space of LLMs using an efficient visual alignment module. This innovative approach empowers the previously static LLM to seamlessly integrate and process image information, marking a step forward in optimizing R2Gen performance. R2GenGPT offers the following benefits. First, it attains state-of-the-art (SOTA) performance by training only the lightweight visual alignment module while freezing all the parameters of LLM. Second, it exhibits high training efficiency, as it requires the training of an exceptionally minimal number of parameters while achieving rapid convergence. By employing delta tuning, our model only trains 5M parameters (which constitute just 0.07\\% of the total parameter count) to achieve performance close to the SOTA levels. Our code is available at https://github.com/wang-zhanyu/R2GenGPT.","sentences":["Large Language Models (LLMs) have consistently showcased remarkable generalization capabilities when applied to various language tasks.","Nonetheless, harnessing the full potential of LLMs for Radiology Report Generation (R2Gen) still presents a challenge, stemming from the inherent disparity in modality between LLMs and the R2Gen task.","To bridge this gap effectively, we propose R2GenGPT, which is a novel solution that aligns visual features with the word embedding space of LLMs using an efficient visual alignment module.","This innovative approach empowers the previously static LLM to seamlessly integrate and process image information, marking a step forward in optimizing R2Gen performance.","R2GenGPT offers the following benefits.","First, it attains state-of-the-art (SOTA) performance by training only the lightweight visual alignment module while freezing all the parameters of LLM.","Second, it exhibits high training efficiency, as it requires the training of an exceptionally minimal number of parameters while achieving rapid convergence.","By employing delta tuning, our model only trains 5M parameters (which constitute just 0.07\\% of the total parameter count) to achieve performance close to the SOTA levels.","Our code is available at https://github.com/wang-zhanyu/R2GenGPT."],"url":"http://arxiv.org/abs/2309.09812v1"}
{"created":"2023-09-18 14:31:37","title":"Learning Inertial Parameter Identification of Unknown Object with Humanoid Robot using Sim-to-Real Adaptation","abstract":"Understanding the dynamics of unknown object is crucial for collaborative robots including humanoids to more safely and accurately interact with humans. Most relevant literature leverage a force/torque sensor, prior knowledge of object, vision system, and a long-horizon trajectory which are often impractical. Moreover, these methods often entail solving non-linear optimization problem, sometimes yielding physically inconsistent results. In this work, we propose a fast learningbased inertial parameter estimation as more practical manner. We acquire a reliable dataset in a high-fidelity simulation and train a time-series data-driven regression model (e.g., LSTM) to estimate the inertial parameter of unknown objects. We also introduce a novel sim-to-real adaptation method combining Robot System Identification and Gaussian Processes to directly transfer the trained model to real-world application. We demonstrate our method with a 4-DOF single manipulator of physical wheeled humanoid robot, SATYRR. Results show that our method can identify the inertial parameters of various unknown objects faster and more accurately than conventional methods.","sentences":["Understanding the dynamics of unknown object is crucial for collaborative robots including humanoids to more safely and accurately interact with humans.","Most relevant literature leverage a force/torque sensor, prior knowledge of object, vision system, and a long-horizon trajectory which are often impractical.","Moreover, these methods often entail solving non-linear optimization problem, sometimes yielding physically inconsistent results.","In this work, we propose a fast learningbased inertial parameter estimation as more practical manner.","We acquire a reliable dataset in a high-fidelity simulation and train a time-series data-driven regression model (e.g., LSTM) to estimate the inertial parameter of unknown objects.","We also introduce a novel sim-to-real adaptation method combining Robot System Identification and Gaussian Processes to directly transfer the trained model to real-world application.","We demonstrate our method with a 4-DOF single manipulator of physical wheeled humanoid robot, SATYRR.","Results show that our method can identify the inertial parameters of various unknown objects faster and more accurately than conventional methods."],"url":"http://arxiv.org/abs/2309.09810v1"}
{"created":"2023-09-18 14:28:47","title":"VisualProg Distiller: Learning to Fine-tune Non-differentiable Visual Programming Frameworks","abstract":"As an interpretable and universal neuro-symbolic paradigm based on Large Language Models, visual programming (VisualProg) can execute compositional visual tasks without training, but its performance is markedly inferior compared to task-specific supervised learning models. To increase its practicality, the performance of VisualProg on specific tasks needs to be improved. However, the non-differentiability of VisualProg limits the possibility of employing the fine-tuning strategy on specific tasks to achieve further improvements. In our analysis, we discovered that significant performance issues in VisualProg's execution originated from errors made by the sub-modules at corresponding visual sub-task steps. To address this, we propose ``VisualProg Distiller\", a method of supplementing and distilling process knowledge to optimize the performance of each VisualProg sub-module on decoupled visual sub-tasks, thus enhancing the overall task performance. Specifically, we choose an end-to-end model that is well-performed on the given task as the teacher and further distill the knowledge of the teacher into the invoked visual sub-modules step-by-step based on the execution flow of the VisualProg-generated programs. In this way, our method is capable of facilitating the fine-tuning of the non-differentiable VisualProg frameworks effectively. Extensive and comprehensive experimental evaluations demonstrate that our method can achieve a substantial performance improvement of VisualProg, and outperforms all the compared state-of-the-art methods by large margins. Furthermore, to provide valuable process supervision for the GQA task, we construct a large-scale dataset by utilizing the distillation process of our method.","sentences":["As an interpretable and universal neuro-symbolic paradigm based on Large Language Models, visual programming (VisualProg) can execute compositional visual tasks without training, but its performance is markedly inferior compared to task-specific supervised learning models.","To increase its practicality, the performance of VisualProg on specific tasks needs to be improved.","However, the non-differentiability of VisualProg limits the possibility of employing the fine-tuning strategy on specific tasks to achieve further improvements.","In our analysis, we discovered that significant performance issues in VisualProg's execution originated from errors made by the sub-modules at corresponding visual sub-task steps.","To address this, we propose ``VisualProg Distiller\", a method of supplementing and distilling process knowledge to optimize the performance of each VisualProg sub-module on decoupled visual sub-tasks, thus enhancing the overall task performance.","Specifically, we choose an end-to-end model that is well-performed on the given task as the teacher and further distill the knowledge of the teacher into the invoked visual sub-modules step-by-step based on the execution flow of the VisualProg-generated programs.","In this way, our method is capable of facilitating the fine-tuning of the non-differentiable VisualProg frameworks effectively.","Extensive and comprehensive experimental evaluations demonstrate that our method can achieve a substantial performance improvement of VisualProg, and outperforms all the compared state-of-the-art methods by large margins.","Furthermore, to provide valuable process supervision for the GQA task, we construct a large-scale dataset by utilizing the distillation process of our method."],"url":"http://arxiv.org/abs/2309.09809v1"}
{"created":"2023-09-18 14:28:38","title":"Coco-LIC: Continuous-Time Tightly-Coupled LiDAR-Inertial-Camera Odometry using Non-Uniform B-spline","abstract":"In this paper, we propose an efficient continuous-time LiDAR-Inertial-Camera Odometry, utilizing non-uniform B-splines to tightly couple measurements from the LiDAR, IMU, and camera. In contrast to uniform B-spline-based continuous-time methods, our non-uniform B-spline approach offers significant advantages in terms of achieving real-time efficiency and high accuracy. This is accomplished by dynamically and adaptively placing control points, taking into account the varying dynamics of the motion. To enable efficient fusion of heterogeneous LiDAR-Inertial-Camera data within a short sliding-window optimization, we assign depth to visual pixels using corresponding map points from a global LiDAR map, and formulate frame-to-map reprojection factors for the associated pixels in the current image frame. This way circumvents the necessity for depth optimization of visual pixels, which typically entails a lengthy sliding window with numerous control points for continuous-time trajectory estimation. We conduct dedicated experiments on real-world datasets to demonstrate the advantage and efficacy of adopting non-uniform continuous-time trajectory representation. Our LiDAR-Inertial-Camera odometry system is also extensively evaluated on both challenging scenarios with sensor degenerations and large-scale scenarios, and has shown comparable or higher accuracy than the state-of-the-art methods. The codebase of this paper will also be open-sourced at https://github.com/APRIL-ZJU/Coco-LIC.","sentences":["In this paper, we propose an efficient continuous-time LiDAR-Inertial-Camera Odometry, utilizing non-uniform B-splines to tightly couple measurements from the LiDAR, IMU, and camera.","In contrast to uniform B-spline-based continuous-time methods, our non-uniform B-spline approach offers significant advantages in terms of achieving real-time efficiency and high accuracy.","This is accomplished by dynamically and adaptively placing control points, taking into account the varying dynamics of the motion.","To enable efficient fusion of heterogeneous LiDAR-Inertial-Camera data within a short sliding-window optimization, we assign depth to visual pixels using corresponding map points from a global LiDAR map, and formulate frame-to-map reprojection factors for the associated pixels in the current image frame.","This way circumvents the necessity for depth optimization of visual pixels, which typically entails a lengthy sliding window with numerous control points for continuous-time trajectory estimation.","We conduct dedicated experiments on real-world datasets to demonstrate the advantage and efficacy of adopting non-uniform continuous-time trajectory representation.","Our LiDAR-Inertial-Camera odometry system is also extensively evaluated on both challenging scenarios with sensor degenerations and large-scale scenarios, and has shown comparable or higher accuracy than the state-of-the-art methods.","The codebase of this paper will also be open-sourced at https://github.com/APRIL-ZJU/Coco-LIC."],"url":"http://arxiv.org/abs/2309.09808v1"}
{"created":"2023-09-18 14:28:18","title":"Efficient Concept Drift Handling for Batch Android Malware Detection Models","abstract":"The rapidly evolving nature of Android apps poses a significant challenge to static batch machine learning algorithms employed in malware detection systems, as they quickly become obsolete. Despite this challenge, the existing literature pays limited attention to addressing this issue, with many advanced Android malware detection approaches, such as Drebin, DroidDet and MaMaDroid, relying on static models. In this work, we show how retraining techniques are able to maintain detector capabilities over time. Particularly, we analyze the effect of two aspects in the efficiency and performance of the detectors: 1) the frequency with which the models are retrained, and 2) the data used for retraining. In the first experiment, we compare periodic retraining with a more advanced concept drift detection method that triggers retraining only when necessary. In the second experiment, we analyze sampling methods to reduce the amount of data used to retrain models. Specifically, we compare fixed sized windows of recent data and state-of-the-art active learning methods that select those apps that help keep the training dataset small but diverse. Our experiments show that concept drift detection and sample selection mechanisms result in very efficient retraining strategies which can be successfully used to maintain the performance of the static Android malware state-of-the-art detectors in changing environments.","sentences":["The rapidly evolving nature of Android apps poses a significant challenge to static batch machine learning algorithms employed in malware detection systems, as they quickly become obsolete.","Despite this challenge, the existing literature pays limited attention to addressing this issue, with many advanced Android malware detection approaches, such as Drebin, DroidDet and MaMaDroid, relying on static models.","In this work, we show how retraining techniques are able to maintain detector capabilities over time.","Particularly, we analyze the effect of two aspects in the efficiency and performance of the detectors: 1) the frequency with which the models are retrained, and 2) the data used for retraining.","In the first experiment, we compare periodic retraining with a more advanced concept drift detection method that triggers retraining only when necessary.","In the second experiment, we analyze sampling methods to reduce the amount of data used to retrain models.","Specifically, we compare fixed sized windows of recent data and state-of-the-art active learning methods that select those apps that help keep the training dataset small but diverse.","Our experiments show that concept drift detection and sample selection mechanisms result in very efficient retraining strategies which can be successfully used to maintain the performance of the static Android malware state-of-the-art detectors in changing environments."],"url":"http://arxiv.org/abs/2309.09807v1"}
{"created":"2023-09-18 14:20:17","title":"Constrained Delaunay Tetrahedrization: A Robust and Practical Approach","abstract":"We present a numerically robust algorithm for computing the constrained Delaunay tetrahedrization (CDT) of a piecewise-linear complex, which has a 100% success rate on the 4408 valid models in the Thingi10k dataset. We build on the underlying theory of the well-known TetGen software, but use a floating-point implementation based on indirect geometric predicates to implicitly represent Steiner points: this new approach dramatically simplifies the implementation, removing the need for ad-hoc tolerances in geometric operations. Our approach leads to a robust and parameter-free implementation, with an empirically manageable number of added Steiner points. Furthermore, our algorithm addresses a major gap in TetGen's theory which may lead to algorithmic failure on valid models, even when assuming perfect precision in the calculations. Our output tetrahedrization conforms with the input geometry without approximations. We can further round our output to floating-point coordinates for downstream applications, which almost always results in valid floating-point meshes unless the input triangulation is very close to being degenerate.","sentences":["We present a numerically robust algorithm for computing the constrained Delaunay tetrahedrization (CDT) of a piecewise-linear complex, which has a 100% success rate on the 4408 valid models in the Thingi10k dataset.","We build on the underlying theory of the well-known TetGen software, but use a floating-point implementation based on indirect geometric predicates to implicitly represent Steiner points: this new approach dramatically simplifies the implementation, removing the need for ad-hoc tolerances in geometric operations.","Our approach leads to a robust and parameter-free implementation, with an empirically manageable number of added Steiner points.","Furthermore, our algorithm addresses a major gap in TetGen's theory which may lead to algorithmic failure on valid models, even when assuming perfect precision in the calculations.","Our output tetrahedrization conforms with the input geometry without approximations.","We can further round our output to floating-point coordinates for downstream applications, which almost always results in valid floating-point meshes unless the input triangulation is very close to being degenerate."],"url":"http://arxiv.org/abs/2309.09805v1"}
{"created":"2023-09-18 14:18:38","title":"DFL-TORO: A One-Shot Demonstration Framework for Learning Time-Optimal Robotic Manufacturing Tasks","abstract":"This paper presents DFL-TORO, a novel Demonstration Framework for Learning Time-Optimal Robotic tasks via One-shot kinesthetic demonstration. It aims at optimizing the process of Learning from Demonstration (LfD), applied in the manufacturing sector. As the effectiveness of LfD is challenged by the quality and efficiency of human demonstrations, our approach offers a streamlined method to intuitively capture task requirements from human teachers, by reducing the need for multiple demonstrations. Furthermore, we propose an optimization-based smoothing algorithm that ensures time-optimal and jerk-regulated demonstration trajectories, while also adhering to the robot's kinematic constraints. The result is a significant reduction in noise, thereby boosting the robot's operation efficiency. Evaluations using a Franka Emika Research 3 (FR3) robot for a reaching task further substantiate the efficacy of our framework, highlighting its potential to transform kinesthetic demonstrations in contemporary manufacturing environments.","sentences":["This paper presents DFL-TORO, a novel Demonstration Framework for Learning Time-Optimal Robotic tasks via One-shot kinesthetic demonstration.","It aims at optimizing the process of Learning from Demonstration (LfD), applied in the manufacturing sector.","As the effectiveness of LfD is challenged by the quality and efficiency of human demonstrations, our approach offers a streamlined method to intuitively capture task requirements from human teachers, by reducing the need for multiple demonstrations.","Furthermore, we propose an optimization-based smoothing algorithm that ensures time-optimal and jerk-regulated demonstration trajectories, while also adhering to the robot's kinematic constraints.","The result is a significant reduction in noise, thereby boosting the robot's operation efficiency.","Evaluations using a Franka Emika Research 3 (FR3) robot for a reaching task further substantiate the efficacy of our framework, highlighting its potential to transform kinesthetic demonstrations in contemporary manufacturing environments."],"url":"http://arxiv.org/abs/2309.09802v1"}
{"created":"2023-09-18 14:18:35","title":"Learning Optimal Contracts: How to Exploit Small Action Spaces","abstract":"We study principal-agent problems in which a principal commits to an outcome-dependent payment scheme -- called contract -- in order to induce an agent to take a costly, unobservable action leading to favorable outcomes. We consider a generalization of the classical (single-round) version of the problem in which the principal interacts with the agent by committing to contracts over multiple rounds. The principal has no information about the agent, and they have to learn an optimal contract by only observing the outcome realized at each round. We focus on settings in which the size of the agent's action space is small. We design an algorithm that learns an approximately-optimal contract with high probability in a number of rounds polynomial in the size of the outcome space, when the number of actions is constant. Our algorithm solves an open problem by Zhu et al.[2022]. Moreover, it can also be employed to provide a $\\tilde{\\mathcal{O}}(T^{4/5})$ regret bound in the related online learning setting in which the principal aims at maximizing their cumulative utility, thus considerably improving previously-known regret bounds.","sentences":["We study principal-agent problems in which a principal commits to an outcome-dependent payment scheme -- called contract -- in order to induce an agent to take a costly, unobservable action leading to favorable outcomes.","We consider a generalization of the classical (single-round) version of the problem in which the principal interacts with the agent by committing to contracts over multiple rounds.","The principal has no information about the agent, and they have to learn an optimal contract by only observing the outcome realized at each round.","We focus on settings in which the size of the agent's action space is small.","We design an algorithm that learns an approximately-optimal contract with high probability in a number of rounds polynomial in the size of the outcome space, when the number of actions is constant.","Our algorithm solves an open problem by Zhu et al.[2022].","Moreover, it can also be employed to provide a $\\tilde{\\mathcal{O}}(T^{4/5})$ regret bound in the related online learning setting in which the principal aims at maximizing their cumulative utility, thus considerably improving previously-known regret bounds."],"url":"http://arxiv.org/abs/2309.09801v1"}
{"created":"2023-09-18 14:18:19","title":"AMuRD: Annotated Multilingual Receipts Dataset for Cross-lingual Key Information Extraction and Classification","abstract":"Key information extraction involves recognizing and extracting text from scanned receipts, enabling retrieval of essential content, and organizing it into structured documents. This paper presents a novel multilingual dataset for receipt extraction, addressing key challenges in information extraction and item classification. The dataset comprises $47,720$ samples, including annotations for item names, attributes like (price, brand, etc.), and classification into $44$ product categories. We introduce the InstructLLaMA approach, achieving an F1 score of $0.76$ and an accuracy of $0.68$ for key information extraction and item classification. We provide code, datasets, and checkpoints.\\footnote{\\url{https://github.com/Update-For-Integrated-Business-AI/AMuRD}}.","sentences":["Key information extraction involves recognizing and extracting text from scanned receipts, enabling retrieval of essential content, and organizing it into structured documents.","This paper presents a novel multilingual dataset for receipt extraction, addressing key challenges in information extraction and item classification.","The dataset comprises $47,720$ samples, including annotations for item names, attributes like (price, brand, etc.), and classification into $44$ product categories.","We introduce the InstructLLaMA approach, achieving an F1 score of $0.76$ and an accuracy of $0.68$ for key information extraction and item classification.","We provide code, datasets, and checkpoints.\\footnote{\\url{https://github.com/Update-For-Integrated-Business-AI/AMuRD}}."],"url":"http://arxiv.org/abs/2309.09800v1"}
{"created":"2023-09-18 14:18:16","title":"Watch the Speakers: A Hybrid Continuous Attribution Network for Emotion Recognition in Conversation With Emotion Disentanglement","abstract":"Emotion Recognition in Conversation (ERC) has attracted widespread attention in the natural language processing field due to its enormous potential for practical applications. Existing ERC methods face challenges in achieving generalization to diverse scenarios due to insufficient modeling of context, ambiguous capture of dialogue relationships and overfitting in speaker modeling. In this work, we present a Hybrid Continuous Attributive Network (HCAN) to address these issues in the perspective of emotional continuation and emotional attribution. Specifically, HCAN adopts a hybrid recurrent and attention-based module to model global emotion continuity. Then a novel Emotional Attribution Encoding (EAE) is proposed to model intra- and inter-emotional attribution for each utterance. Moreover, aiming to enhance the robustness of the model in speaker modeling and improve its performance in different scenarios, A comprehensive loss function emotional cognitive loss $\\mathcal{L}_{\\rm EC}$ is proposed to alleviate emotional drift and overcome the overfitting of the model to speaker modeling. Our model achieves state-of-the-art performance on three datasets, demonstrating the superiority of our work. Another extensive comparative experiments and ablation studies on three benchmarks are conducted to provided evidence to support the efficacy of each module. Further exploration of generalization ability experiments shows the plug-and-play nature of the EAE module in our method.","sentences":["Emotion Recognition in Conversation (ERC) has attracted widespread attention in the natural language processing field due to its enormous potential for practical applications.","Existing ERC methods face challenges in achieving generalization to diverse scenarios due to insufficient modeling of context, ambiguous capture of dialogue relationships and overfitting in speaker modeling.","In this work, we present a Hybrid Continuous Attributive Network (HCAN) to address these issues in the perspective of emotional continuation and emotional attribution.","Specifically, HCAN adopts a hybrid recurrent and attention-based module to model global emotion continuity.","Then a novel Emotional Attribution Encoding (EAE) is proposed to model intra- and inter-emotional attribution for each utterance.","Moreover, aiming to enhance the robustness of the model in speaker modeling and improve its performance in different scenarios, A comprehensive loss function emotional cognitive loss $\\mathcal{L}_{\\rm EC}$ is proposed to alleviate emotional drift and overcome the overfitting of the model to speaker modeling.","Our model achieves state-of-the-art performance on three datasets, demonstrating the superiority of our work.","Another extensive comparative experiments and ablation studies on three benchmarks are conducted to provided evidence to support the efficacy of each module.","Further exploration of generalization ability experiments shows the plug-and-play nature of the EAE module in our method."],"url":"http://arxiv.org/abs/2309.09799v1"}
{"created":"2023-09-18 14:05:04","title":"Harnessing Collective Intelligence Under a Lack of Cultural Consensus","abstract":"Harnessing collective intelligence to drive effective decision-making and collaboration benefits from the ability to detect and characterize heterogeneity in consensus beliefs. This is particularly true in domains such as technology acceptance or leadership perception, where a consensus defines an intersubjective truth, leading to the possibility of multiple \"ground truths\" when subsets of respondents sustain mutually incompatible consensuses. Cultural Consensus Theory (CCT) provides a statistical framework for detecting and characterizing these divergent consensus beliefs. However, it is unworkable in modern applications because it lacks the ability to generalize across even highly similar beliefs, is ineffective with sparse data, and can leverage neither external knowledge bases nor learned machine representations. Here, we overcome these limitations through Infinite Deep Latent Construct Cultural Consensus Theory (iDLC-CCT), a nonparametric Bayesian model that extends CCT with a latent construct that maps between pretrained deep neural network embeddings of entities and the consensus beliefs regarding those entities among one or more subsets of respondents. We validate the method across domains including perceptions of risk sources, food healthiness, leadership, first impressions, and humor. We find that iDLC-CCT better predicts the degree of consensus, generalizes well to out-of-sample entities, and is effective even with sparse data. To improve scalability, we introduce an efficient hard-clustering variant of the iDLC-CCT using an algorithm derived from a small-variance asymptotic analysis of the model. The iDLC-CCT, therefore, provides a workable computational foundation for harnessing collective intelligence under a lack of cultural consensus and may potentially form the basis of consensus-aware information technologies.","sentences":["Harnessing collective intelligence to drive effective decision-making and collaboration benefits from the ability to detect and characterize heterogeneity in consensus beliefs.","This is particularly true in domains such as technology acceptance or leadership perception, where a consensus defines an intersubjective truth, leading to the possibility of multiple \"ground truths\" when subsets of respondents sustain mutually incompatible consensuses.","Cultural Consensus Theory (CCT) provides a statistical framework for detecting and characterizing these divergent consensus beliefs.","However, it is unworkable in modern applications because it lacks the ability to generalize across even highly similar beliefs, is ineffective with sparse data, and can leverage neither external knowledge bases nor learned machine representations.","Here, we overcome these limitations through Infinite Deep Latent Construct Cultural Consensus Theory (iDLC-CCT), a nonparametric Bayesian model that extends CCT with a latent construct that maps between pretrained deep neural network embeddings of entities and the consensus beliefs regarding those entities among one or more subsets of respondents.","We validate the method across domains including perceptions of risk sources, food healthiness, leadership, first impressions, and humor.","We find that iDLC-CCT better predicts the degree of consensus, generalizes well to out-of-sample entities, and is effective even with sparse data.","To improve scalability, we introduce an efficient hard-clustering variant of the iDLC-CCT using an algorithm derived from a small-variance asymptotic analysis of the model.","The iDLC-CCT, therefore, provides a workable computational foundation for harnessing collective intelligence under a lack of cultural consensus and may potentially form the basis of consensus-aware information technologies."],"url":"http://arxiv.org/abs/2309.09787v1"}
{"created":"2023-09-18 14:04:07","title":"2-Colorable Perfect Matching is NP-complete in 2-Connected 3-Regular Planar Graphs","abstract":"The 2-colorable perfect matching problem asks whether a graph can be colored with two colors so that each node has exactly one neighbor with the same color as itself. We prove that this problem is NP-complete, even when restricted to 2-connected 3-regular planar graphs. In 1978, Schaefer proved that this problem is NP-complete in general graphs, and claimed without proof that the same result holds when restricted to 3-regular planar graphs. Thus we fill in the missing proof of this claim, while simultaneously strengthening to 2-connected graphs (which implies existence of a perfect matching). We also prove NP-completeness of $k$-colorable perfect matching, for any fixed $k \\geq 2$.","sentences":["The 2-colorable perfect matching problem asks whether a graph can be colored with two colors so that each node has exactly one neighbor with the same color as itself.","We prove that this problem is NP-complete, even when restricted to 2-connected 3-regular planar graphs.","In 1978, Schaefer proved that this problem is NP-complete in general graphs, and claimed without proof that the same result holds when restricted to 3-regular planar graphs.","Thus we fill in the missing proof of this claim, while simultaneously strengthening to 2-connected graphs (which implies existence of a perfect matching).","We also prove NP-completeness of $k$-colorable perfect matching, for any fixed $k \\geq 2$."],"url":"http://arxiv.org/abs/2309.09786v1"}
{"created":"2023-09-18 14:01:06","title":"The ParlaSent multilingual training dataset for sentiment identification in parliamentary proceedings","abstract":"Sentiments inherently drive politics. How we receive and process information plays an essential role in political decision-making, shaping our judgment with strategic consequences both on the level of legislators and the masses. If sentiment plays such an important role in politics, how can we study and measure it systematically? The paper presents a new dataset of sentiment-annotated sentences, which are used in a series of experiments focused on training a robust sentiment classifier for parliamentary proceedings. The paper also introduces the first domain-specific LLM for political science applications additionally pre-trained on 1.72 billion domain-specific words from proceedings of 27 European parliaments. We present experiments demonstrating how the additional pre-training of LLM on parliamentary data can significantly improve the model downstream performance on the domain-specific tasks, in our case, sentiment detection in parliamentary proceedings. We further show that multilingual models perform very well on unseen languages and that additional data from other languages significantly improves the target parliament's results. The paper makes an important contribution to multiple domains of social sciences and bridges them with computer science and computational linguistics. Lastly, it sets up a more robust approach to sentiment analysis of political texts in general, which allows scholars to study political sentiment from a comparative perspective using standardized tools and techniques.","sentences":["Sentiments inherently drive politics.","How we receive and process information plays an essential role in political decision-making, shaping our judgment with strategic consequences both on the level of legislators and the masses.","If sentiment plays such an important role in politics, how can we study and measure it systematically?","The paper presents a new dataset of sentiment-annotated sentences, which are used in a series of experiments focused on training a robust sentiment classifier for parliamentary proceedings.","The paper also introduces the first domain-specific LLM for political science applications additionally pre-trained on 1.72 billion domain-specific words from proceedings of 27 European parliaments.","We present experiments demonstrating how the additional pre-training of LLM on parliamentary data can significantly improve the model downstream performance on the domain-specific tasks, in our case, sentiment detection in parliamentary proceedings.","We further show that multilingual models perform very well on unseen languages and that additional data from other languages significantly improves the target parliament's results.","The paper makes an important contribution to multiple domains of social sciences and bridges them with computer science and computational linguistics.","Lastly, it sets up a more robust approach to sentiment analysis of political texts in general, which allows scholars to study political sentiment from a comparative perspective using standardized tools and techniques."],"url":"http://arxiv.org/abs/2309.09783v1"}
{"created":"2023-09-18 13:59:57","title":"Modulation to the Rescue: Identifying Sub-Circuitry in the Transistor Morass for Targeted Analysis","abstract":"Physical attacks form one of the most severe threats against secure computing platforms. Their criticality arises from their corresponding threat model: By, e.g., passively measuring an integrated circuit's (IC's) environment during a security-related operation, internal secrets may be disclosed. Furthermore, by actively disturbing the physical runtime environment of an IC, an adversary can cause a specific, exploitable misbehavior. The set of physical attacks consists of techniques that apply either globally or locally. When compared to global techniques, local techniques exhibit a much higher precision, hence having the potential to be used in advanced attack scenarios. However, using physical techniques with additional spatial dependency expands the parameter search space exponentially. In this work, we present and compare two techniques, namely laser logic state imaging (LLSI) and lock-in thermography (LIT), that can be used to discover sub-circuitry of an entirely unknown IC based on optical and thermal principles. We show that the time required to identify specific regions can be drastically reduced, thus lowering the complexity of physical attacks requiring positional information. Our case study on an Intel H610 Platform Controller Hub showcases that, depending on the targeted voltage rail, our technique reduces the search space by around 90 to 98 percent.","sentences":["Physical attacks form one of the most severe threats against secure computing platforms.","Their criticality arises from their corresponding threat model: By, e.g., passively measuring an integrated circuit's (IC's) environment during a security-related operation, internal secrets may be disclosed.","Furthermore, by actively disturbing the physical runtime environment of an IC, an adversary can cause a specific, exploitable misbehavior.","The set of physical attacks consists of techniques that apply either globally or locally.","When compared to global techniques, local techniques exhibit a much higher precision, hence having the potential to be used in advanced attack scenarios.","However, using physical techniques with additional spatial dependency expands the parameter search space exponentially.","In this work, we present and compare two techniques, namely laser logic state imaging (LLSI) and lock-in thermography (LIT), that can be used to discover sub-circuitry of an entirely unknown IC based on optical and thermal principles.","We show that the time required to identify specific regions can be drastically reduced, thus lowering the complexity of physical attacks requiring positional information.","Our case study on an Intel H610 Platform Controller Hub showcases that, depending on the targeted voltage rail, our technique reduces the search space by around 90 to 98 percent."],"url":"http://arxiv.org/abs/2309.09782v1"}
{"created":"2023-09-18 13:59:03","title":"Talking to Data Visualizations: Opportunities and Challenges","abstract":"Speech is one of the interaction modalities that we increasingly come across in natural user interfaces. However, its use in collaborative scenarios has not yet been thoroughly investigated. In this reflection statement, we discuss the opportunities and challenges of integrating speech interaction in multimodal solutions for collaborative work with data visualizations. We discuss related findings from other research communities and how we could build upon their work to explore and make use of speech interaction for data visualizations in co-located, hybrid, and remote settings.","sentences":["Speech is one of the interaction modalities that we increasingly come across in natural user interfaces.","However, its use in collaborative scenarios has not yet been thoroughly investigated.","In this reflection statement, we discuss the opportunities and challenges of integrating speech interaction in multimodal solutions for collaborative work with data visualizations.","We discuss related findings from other research communities and how we could build upon their work to explore and make use of speech interaction for data visualizations in co-located, hybrid, and remote settings."],"url":"http://arxiv.org/abs/2309.09781v1"}
{"created":"2023-09-18 13:58:57","title":"On Random Tree Structures, Their Entropy, and Compression","abstract":"Measuring the complexity of tree structures can be beneficial in areas that use tree data structures for storage, communication, and processing purposes. This complexity can then be used to compress tree data structures to their information-theoretic limit. Additionally, the lack of models for random generation of trees is very much felt in mathematical modeling of trees and graphs. In this paper, a number of existing tree generation models such as simply generated trees are discussed, and their information content is analysed by means of information theory and Shannon's entropy. Subsequently, a new model for generating trees based on practical appearances of trees is introduced, and an upper bound for its entropy is calculated. This model is based on selecting a random tree from possible spanning trees of graphs, which is what happens often in practice. Moving on to tree compression, we find approaches to universal tree compression of the discussed models. These approaches first transform a tree into a sequence of symbols, and then apply a dictionary-based compression method. Conditions for the universality of these method are then studied and analysed.","sentences":["Measuring the complexity of tree structures can be beneficial in areas that use tree data structures for storage, communication, and processing purposes.","This complexity can then be used to compress tree data structures to their information-theoretic limit.","Additionally, the lack of models for random generation of trees is very much felt in mathematical modeling of trees and graphs.","In this paper, a number of existing tree generation models such as simply generated trees are discussed, and their information content is analysed by means of information theory and Shannon's entropy.","Subsequently, a new model for generating trees based on practical appearances of trees is introduced, and an upper bound for its entropy is calculated.","This model is based on selecting a random tree from possible spanning trees of graphs, which is what happens often in practice.","Moving on to tree compression, we find approaches to universal tree compression of the discussed models.","These approaches first transform a tree into a sequence of symbols, and then apply a dictionary-based compression method.","Conditions for the universality of these method are then studied and analysed."],"url":"http://arxiv.org/abs/2309.09779v1"}
{"created":"2023-09-18 13:58:45","title":"Significant improvement of lossy compression rate and speed of HPC data using perceptron parallelized compression","abstract":"The escalating surge in data generation presents formidable challenges to information technology, necessitating advancements in storage, retrieval, and utilization. With the proliferation of artificial intelligence and big data, the \"Data Age 2025\" report forecasts an exponential increase in global data production. The escalating data volumes raise concerns about efficient data processing. The paper addresses the predicament of achieving a lower compression ratio while maintaining or surpassing the compression performance of state-of-the-art techniques.   This paper introduces a lossy compression framework grounded in the perceptron model for data prediction, striving for high compression quality. The contributions of this study encompass the introduction of positive and negative factors within the relative-to-absolute domain transformation algorithm, the utilization of a three-layer perceptron for improved predictive accuracy, and data selection rule modifications for parallelized compression within compression blocks. Comparative experiments with SZ2.1's PW_REL mode demonstrate a maximum compression ratio reduction of 17.78%.   The article is structured as follows: the introduction highlights the data explosion challenge; related work delves into existing solutions; optimization of mapping algorithms in the relative and absolute domains is expounded in Section 3,the design of the new compression framework is detailed in Section 4,In Section 5 we describe the whole process and give pseudo-code, and in Section 6, our solution is evaluated. Finally, in Section 7, we provide an outlook for future work.","sentences":["The escalating surge in data generation presents formidable challenges to information technology, necessitating advancements in storage, retrieval, and utilization.","With the proliferation of artificial intelligence and big data, the \"Data Age 2025\" report forecasts an exponential increase in global data production.","The escalating data volumes raise concerns about efficient data processing.","The paper addresses the predicament of achieving a lower compression ratio while maintaining or surpassing the compression performance of state-of-the-art techniques.   ","This paper introduces a lossy compression framework grounded in the perceptron model for data prediction, striving for high compression quality.","The contributions of this study encompass the introduction of positive and negative factors within the relative-to-absolute domain transformation algorithm, the utilization of a three-layer perceptron for improved predictive accuracy, and data selection rule modifications for parallelized compression within compression blocks.","Comparative experiments with SZ2.1's PW_REL mode demonstrate a maximum compression ratio reduction of 17.78%.   ","The article is structured as follows: the introduction highlights the data explosion challenge; related work delves into existing solutions; optimization of mapping algorithms in the relative and absolute domains is expounded in Section 3,the design of the new compression framework is detailed in Section 4,In Section 5 we describe the whole process and give pseudo-code, and in Section 6, our solution is evaluated.","Finally, in Section 7, we provide an outlook for future work."],"url":"http://arxiv.org/abs/2309.09778v1"}
{"created":"2023-09-18 13:58:42","title":"DriveDreamer: Towards Real-world-driven World Models for Autonomous Driving","abstract":"World models, especially in autonomous driving, are trending and drawing extensive attention due to their capacity for comprehending driving environments. The established world model holds immense potential for the generation of high-quality driving videos, and driving policies for safe maneuvering. However, a critical limitation in relevant research lies in its predominant focus on gaming environments or simulated settings, thereby lacking the representation of real-world driving scenarios. Therefore, we introduce DriveDreamer, a pioneering world model entirely derived from real-world driving scenarios. Regarding that modeling the world in intricate driving scenes entails an overwhelming search space, we propose harnessing the powerful diffusion model to construct a comprehensive representation of the complex environment. Furthermore, we introduce a two-stage training pipeline. In the initial phase, DriveDreamer acquires a deep understanding of structured traffic constraints, while the subsequent stage equips it with the ability to anticipate future states. The proposed DriveDreamer is the first world model established from real-world driving scenarios. We instantiate DriveDreamer on the challenging nuScenes benchmark, and extensive experiments verify that DriveDreamer empowers precise, controllable video generation that faithfully captures the structural constraints of real-world traffic scenarios. Additionally, DriveDreamer enables the generation of realistic and reasonable driving policies, opening avenues for interaction and practical applications.","sentences":["World models, especially in autonomous driving, are trending and drawing extensive attention due to their capacity for comprehending driving environments.","The established world model holds immense potential for the generation of high-quality driving videos, and driving policies for safe maneuvering.","However, a critical limitation in relevant research lies in its predominant focus on gaming environments or simulated settings, thereby lacking the representation of real-world driving scenarios.","Therefore, we introduce DriveDreamer, a pioneering world model entirely derived from real-world driving scenarios.","Regarding that modeling the world in intricate driving scenes entails an overwhelming search space, we propose harnessing the powerful diffusion model to construct a comprehensive representation of the complex environment.","Furthermore, we introduce a two-stage training pipeline.","In the initial phase, DriveDreamer acquires a deep understanding of structured traffic constraints, while the subsequent stage equips it with the ability to anticipate future states.","The proposed DriveDreamer is the first world model established from real-world driving scenarios.","We instantiate DriveDreamer on the challenging nuScenes benchmark, and extensive experiments verify that DriveDreamer empowers precise, controllable video generation that faithfully captures the structural constraints of real-world traffic scenarios.","Additionally, DriveDreamer enables the generation of realistic and reasonable driving policies, opening avenues for interaction and practical applications."],"url":"http://arxiv.org/abs/2309.09777v1"}
{"created":"2023-09-18 13:57:24","title":"ArxNet Model and Data: Building Social Networks from Image Archives","abstract":"A corresponding explosion in digital images has accompanied the rapid adoption of mobile technology around the world. People and their activities are routinely captured in digital image and video files. By their very nature, these images and videos often portray social and professional connections. Individuals in the same picture are often connected in some meaningful way. Our research seeks to identify and model social connections found in images using modern face detection technology and social network analysis. The proposed methods are then demonstrated on the public image repository associated with the 2022 Emmy's Award Presentation.","sentences":["A corresponding explosion in digital images has accompanied the rapid adoption of mobile technology around the world.","People and their activities are routinely captured in digital image and video files.","By their very nature, these images and videos often portray social and professional connections.","Individuals in the same picture are often connected in some meaningful way.","Our research seeks to identify and model social connections found in images using modern face detection technology and social network analysis.","The proposed methods are then demonstrated on the public image repository associated with the 2022 Emmy's Award Presentation."],"url":"http://arxiv.org/abs/2309.09775v1"}
{"created":"2023-09-18 13:57:16","title":"Towards Self-Adaptive Pseudo-Label Filtering for Semi-Supervised Learning","abstract":"Recent semi-supervised learning (SSL) methods typically include a filtering strategy to improve the quality of pseudo labels. However, these filtering strategies are usually hand-crafted and do not change as the model is updated, resulting in a lot of correct pseudo labels being discarded and incorrect pseudo labels being selected during the training process. In this work, we observe that the distribution gap between the confidence values of correct and incorrect pseudo labels emerges at the very beginning of the training, which can be utilized to filter pseudo labels. Based on this observation, we propose a Self-Adaptive Pseudo-Label Filter (SPF), which automatically filters noise in pseudo labels in accordance with model evolvement by modeling the confidence distribution throughout the training process. Specifically, with an online mixture model, we weight each pseudo-labeled sample by the posterior of it being correct, which takes into consideration the confidence distribution at that time. Unlike previous handcrafted filters, our SPF evolves together with the deep neural network without manual tuning. Extensive experiments demonstrate that incorporating SPF into the existing SSL methods can help improve the performance of SSL, especially when the labeled data is extremely scarce.","sentences":["Recent semi-supervised learning (SSL) methods typically include a filtering strategy to improve the quality of pseudo labels.","However, these filtering strategies are usually hand-crafted and do not change as the model is updated, resulting in a lot of correct pseudo labels being discarded and incorrect pseudo labels being selected during the training process.","In this work, we observe that the distribution gap between the confidence values of correct and incorrect pseudo labels emerges at the very beginning of the training, which can be utilized to filter pseudo labels.","Based on this observation, we propose a Self-Adaptive Pseudo-Label Filter (SPF), which automatically filters noise in pseudo labels in accordance with model evolvement by modeling the confidence distribution throughout the training process.","Specifically, with an online mixture model, we weight each pseudo-labeled sample by the posterior of it being correct, which takes into consideration the confidence distribution at that time.","Unlike previous handcrafted filters, our SPF evolves together with the deep neural network without manual tuning.","Extensive experiments demonstrate that incorporating SPF into the existing SSL methods can help improve the performance of SSL, especially when the labeled data is extremely scarce."],"url":"http://arxiv.org/abs/2309.09774v1"}
