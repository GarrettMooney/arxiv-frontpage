{"created":"2023-09-21 17:59:56","title":"Active Stereo Without Pattern Projector","abstract":"This paper proposes a novel framework integrating the principles of active stereo in standard passive camera systems without a physical pattern projector. We virtually project a pattern over the left and right images according to the sparse measurements obtained from a depth sensor. Any such devices can be seamlessly plugged into our framework, allowing for the deployment of a virtual active stereo setup in any possible environment, overcoming the limitation of pattern projectors, such as limited working range or environmental conditions. Experiments on indoor/outdoor datasets, featuring both long and close-range, support the seamless effectiveness of our approach, boosting the accuracy of both stereo algorithms and deep networks.","sentences":["This paper proposes a novel framework integrating the principles of active stereo in standard passive camera systems without a physical pattern projector.","We virtually project a pattern over the left and right images according to the sparse measurements obtained from a depth sensor.","Any such devices can be seamlessly plugged into our framework, allowing for the deployment of a virtual active stereo setup in any possible environment, overcoming the limitation of pattern projectors, such as limited working range or environmental conditions.","Experiments on indoor/outdoor datasets, featuring both long and close-range, support the seamless effectiveness of our approach, boosting the accuracy of both stereo algorithms and deep networks."],"url":"http://arxiv.org/abs/2309.12315v1"}
{"created":"2023-09-21 17:59:53","title":"TinyCLIP: CLIP Distillation via Affinity Mimicking and Weight Inheritance","abstract":"In this paper, we propose a novel cross-modal distillation method, called TinyCLIP, for large-scale language-image pre-trained models. The method introduces two core techniques: affinity mimicking and weight inheritance. Affinity mimicking explores the interaction between modalities during distillation, enabling student models to mimic teachers' behavior of learning cross-modal feature alignment in a visual-linguistic affinity space. Weight inheritance transmits the pre-trained weights from the teacher models to their student counterparts to improve distillation efficiency. Moreover, we extend the method into a multi-stage progressive distillation to mitigate the loss of informative weights during extreme compression. Comprehensive experiments demonstrate the efficacy of TinyCLIP, showing that it can reduce the size of the pre-trained CLIP ViT-B/32 by 50%, while maintaining comparable zero-shot performance. While aiming for comparable performance, distillation with weight inheritance can speed up the training by 1.4 - 7.8 $\\times$ compared to training from scratch. Moreover, our TinyCLIP ViT-8M/16, trained on YFCC-15M, achieves an impressive zero-shot top-1 accuracy of 41.1% on ImageNet, surpassing the original CLIP ViT-B/16 by 3.5% while utilizing only 8.9% parameters. Finally, we demonstrate the good transferability of TinyCLIP in various downstream tasks. Code and models will be open-sourced at https://aka.ms/tinyclip.","sentences":["In this paper, we propose a novel cross-modal distillation method, called TinyCLIP, for large-scale language-image pre-trained models.","The method introduces two core techniques: affinity mimicking and weight inheritance.","Affinity mimicking explores the interaction between modalities during distillation, enabling student models to mimic teachers' behavior of learning cross-modal feature alignment in a visual-linguistic affinity space.","Weight inheritance transmits the pre-trained weights from the teacher models to their student counterparts to improve distillation efficiency.","Moreover, we extend the method into a multi-stage progressive distillation to mitigate the loss of informative weights during extreme compression.","Comprehensive experiments demonstrate the efficacy of TinyCLIP, showing that it can reduce the size of the pre-trained CLIP ViT-B/32 by 50%, while maintaining comparable zero-shot performance.","While aiming for comparable performance, distillation with weight inheritance can speed up the training by 1.4 - 7.8 $\\times$ compared to training from scratch.","Moreover, our TinyCLIP ViT-8M/16, trained on YFCC-15M, achieves an impressive zero-shot top-1 accuracy of 41.1% on ImageNet, surpassing the original CLIP ViT-B/16 by 3.5% while utilizing only 8.9% parameters.","Finally, we demonstrate the good transferability of TinyCLIP in various downstream tasks.","Code and models will be open-sourced at https://aka.ms/tinyclip."],"url":"http://arxiv.org/abs/2309.12314v1"}
{"created":"2023-09-21 17:59:50","title":"ForceSight: Text-Guided Mobile Manipulation with Visual-Force Goals","abstract":"We present ForceSight, a system for text-guided mobile manipulation that predicts visual-force goals using a deep neural network. Given a single RGBD image combined with a text prompt, ForceSight determines a target end-effector pose in the camera frame (kinematic goal) and the associated forces (force goal). Together, these two components form a visual-force goal. Prior work has demonstrated that deep models outputting human-interpretable kinematic goals can enable dexterous manipulation by real robots. Forces are critical to manipulation, yet have typically been relegated to lower-level execution in these systems. When deployed on a mobile manipulator equipped with an eye-in-hand RGBD camera, ForceSight performed tasks such as precision grasps, drawer opening, and object handovers with an 81% success rate in unseen environments with object instances that differed significantly from the training data. In a separate experiment, relying exclusively on visual servoing and ignoring force goals dropped the success rate from 90% to 45%, demonstrating that force goals can significantly enhance performance. The appendix, videos, code, and trained models are available at https://force-sight.github.io/.","sentences":["We present ForceSight, a system for text-guided mobile manipulation that predicts visual-force goals using a deep neural network.","Given a single RGBD image combined with a text prompt, ForceSight determines a target end-effector pose in the camera frame (kinematic goal) and the associated forces (force goal).","Together, these two components form a visual-force goal.","Prior work has demonstrated that deep models outputting human-interpretable kinematic goals can enable dexterous manipulation by real robots.","Forces are critical to manipulation, yet have typically been relegated to lower-level execution in these systems.","When deployed on a mobile manipulator equipped with an eye-in-hand RGBD camera, ForceSight performed tasks such as precision grasps, drawer opening, and object handovers with an 81% success rate in unseen environments with object instances that differed significantly from the training data.","In a separate experiment, relying exclusively on visual servoing and ignoring force goals dropped the success rate from 90% to 45%, demonstrating that force goals can significantly enhance performance.","The appendix, videos, code, and trained models are available at https://force-sight.github.io/."],"url":"http://arxiv.org/abs/2309.12312v1"}
{"created":"2023-09-21 17:59:45","title":"LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent","abstract":"3D visual grounding is a critical skill for household robots, enabling them to navigate, manipulate objects, and answer questions based on their environment. While existing approaches often rely on extensive labeled data or exhibit limitations in handling complex language queries, we propose LLM-Grounder, a novel zero-shot, open-vocabulary, Large Language Model (LLM)-based 3D visual grounding pipeline. LLM-Grounder utilizes an LLM to decompose complex natural language queries into semantic constituents and employs a visual grounding tool, such as OpenScene or LERF, to identify objects in a 3D scene. The LLM then evaluates the spatial and commonsense relations among the proposed objects to make a final grounding decision. Our method does not require any labeled training data and can generalize to novel 3D scenes and arbitrary text queries. We evaluate LLM-Grounder on the ScanRefer benchmark and demonstrate state-of-the-art zero-shot grounding accuracy. Our findings indicate that LLMs significantly improve the grounding capability, especially for complex language queries, making LLM-Grounder an effective approach for 3D vision-language tasks in robotics. Videos and interactive demos can be found on the project website https://chat-with-nerf.github.io/ .","sentences":["3D visual grounding is a critical skill for household robots, enabling them to navigate, manipulate objects, and answer questions based on their environment.","While existing approaches often rely on extensive labeled data or exhibit limitations in handling complex language queries, we propose LLM-Grounder, a novel zero-shot, open-vocabulary, Large Language Model (LLM)-based 3D visual grounding pipeline.","LLM-Grounder utilizes an LLM to decompose complex natural language queries into semantic constituents and employs a visual grounding tool, such as OpenScene or LERF, to identify objects in a 3D scene.","The LLM then evaluates the spatial and commonsense relations among the proposed objects to make a final grounding decision.","Our method does not require any labeled training data and can generalize to novel 3D scenes and arbitrary text queries.","We evaluate LLM-Grounder on the ScanRefer benchmark and demonstrate state-of-the-art zero-shot grounding accuracy.","Our findings indicate that LLMs significantly improve the grounding capability, especially for complex language queries, making LLM-Grounder an effective approach for 3D vision-language tasks in robotics.","Videos and interactive demos can be found on the project website https://chat-with-nerf.github.io/ ."],"url":"http://arxiv.org/abs/2309.12311v1"}
{"created":"2023-09-21 17:59:20","title":"Rehearsal: Simulating Conflict to Teach Conflict Resolution","abstract":"Interpersonal conflict is an uncomfortable but unavoidable fact of life. Navigating conflict successfully is a skill -- one that can be learned through deliberate practice -- but few have access to effective training or feedback. To expand this access, we introduce Rehearsal, a system that allows users to rehearse conflicts with a believable simulated interlocutor, explore counterfactual \"what if?\" scenarios to identify alternative conversational paths, and learn through feedback on how and when to apply specific conflict strategies. Users can utilize Rehearsal to practice handling a variety of predefined conflict scenarios, from office disputes to relationship issues, or they can choose to create their own. To enable Rehearsal, we develop IRP prompting, a method of conditioning output of a large language model on the influential Interest-Rights-Power (IRP) theory from conflict resolution. Rehearsal uses IRP to generate utterances grounded in conflict resolution theory, guiding users towards counterfactual conflict resolution strategies that help de-escalate difficult conversations. In a between-subjects evaluation, 40 participants engaged in an actual conflict with a confederate after training. Compared to a control group with lecture material covering the same IRP theory, participants with simulated training from Rehearsal significantly improved their performance in the unaided conflict: they reduced their use of escalating competitive strategies by an average of 67%, while doubling their use of cooperative strategies. Overall, Rehearsal highlights the potential effectiveness of language models as tools for learning and practicing interpersonal skills.","sentences":["Interpersonal conflict is an uncomfortable but unavoidable fact of life.","Navigating conflict successfully is a skill -- one that can be learned through deliberate practice -- but few have access to effective training or feedback.","To expand this access, we introduce Rehearsal, a system that allows users to rehearse conflicts with a believable simulated interlocutor, explore counterfactual \"what if?\"","scenarios to identify alternative conversational paths, and learn through feedback on how and when to apply specific conflict strategies.","Users can utilize Rehearsal to practice handling a variety of predefined conflict scenarios, from office disputes to relationship issues, or they can choose to create their own.","To enable Rehearsal, we develop IRP prompting, a method of conditioning output of a large language model on the influential Interest-Rights-Power (IRP) theory from conflict resolution.","Rehearsal uses IRP to generate utterances grounded in conflict resolution theory, guiding users towards counterfactual conflict resolution strategies that help de-escalate difficult conversations.","In a between-subjects evaluation, 40 participants engaged in an actual conflict with a confederate after training.","Compared to a control group with lecture material covering the same IRP theory, participants with simulated training from Rehearsal significantly improved their performance in the unaided conflict: they reduced their use of escalating competitive strategies by an average of 67%, while doubling their use of cooperative strategies.","Overall, Rehearsal highlights the potential effectiveness of language models as tools for learning and practicing interpersonal skills."],"url":"http://arxiv.org/abs/2309.12309v1"}
{"created":"2023-09-21 17:59:11","title":"TalkNCE: Improving Active Speaker Detection with Talk-Aware Contrastive Learning","abstract":"The goal of this work is Active Speaker Detection (ASD), a task to determine whether a person is speaking or not in a series of video frames. Previous works have dealt with the task by exploring network architectures while learning effective representations has been less explored. In this work, we propose TalkNCE, a novel talk-aware contrastive loss. The loss is only applied to part of the full segments where a person on the screen is actually speaking. This encourages the model to learn effective representations through the natural correspondence of speech and facial movements. Our loss can be jointly optimized with the existing objectives for training ASD models without the need for additional supervision or training data. The experiments demonstrate that our loss can be easily integrated into the existing ASD frameworks, improving their performance. Our method achieves state-of-the-art performances on AVA-ActiveSpeaker and ASW datasets.","sentences":["The goal of this work is Active Speaker Detection (ASD), a task to determine whether a person is speaking or not in a series of video frames.","Previous works have dealt with the task by exploring network architectures while learning effective representations has been less explored.","In this work, we propose TalkNCE, a novel talk-aware contrastive loss.","The loss is only applied to part of the full segments where a person on the screen is actually speaking.","This encourages the model to learn effective representations through the natural correspondence of speech and facial movements.","Our loss can be jointly optimized with the existing objectives for training ASD models without the need for additional supervision or training data.","The experiments demonstrate that our loss can be easily integrated into the existing ASD frameworks, improving their performance.","Our method achieves state-of-the-art performances on AVA-ActiveSpeaker and ASW datasets."],"url":"http://arxiv.org/abs/2309.12306v1"}
{"created":"2023-09-21 17:59:11","title":"LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models","abstract":"We present LongLoRA, an efficient fine-tuning approach that extends the context sizes of pre-trained large language models (LLMs), with limited computation cost. Typically, training LLMs with long context sizes is computationally expensive, requiring extensive training hours and GPU resources. For example, training on the context length of 8192 needs 16x computational costs in self-attention layers as that of 2048. In this paper, we speed up the context extension of LLMs in two aspects. On the one hand, although dense global attention is needed during inference, fine-tuning the model can be effectively and efficiently done by sparse local attention. The proposed shift short attention effectively enables context extension, leading to non-trivial computation saving with similar performance to fine-tuning with vanilla attention. Particularly, it can be implemented with only two lines of code in training, while being optional in inference. On the other hand, we revisit the parameter-efficient fine-tuning regime for context expansion. Notably, we find that LoRA for context extension works well under the premise of trainable embedding and normalization. LongLoRA demonstrates strong empirical results on various tasks on LLaMA2 models from 7B/13B to 70B. LongLoRA adopts LLaMA2 7B from 4k context to 100k, or LLaMA2 70B to 32k on a single 8x A100 machine. LongLoRA extends models' context while retaining their original architectures, and is compatible with most existing techniques, like FlashAttention-2. In addition, to make LongLoRA practical, we collect a dataset, LongQA, for supervised fine-tuning. It contains more than 3k long context question-answer pairs.","sentences":["We present LongLoRA, an efficient fine-tuning approach that extends the context sizes of pre-trained large language models (LLMs), with limited computation cost.","Typically, training LLMs with long context sizes is computationally expensive, requiring extensive training hours and GPU resources.","For example, training on the context length of 8192 needs 16x computational costs in self-attention layers as that of 2048.","In this paper, we speed up the context extension of LLMs in two aspects.","On the one hand, although dense global attention is needed during inference, fine-tuning the model can be effectively and efficiently done by sparse local attention.","The proposed shift short attention effectively enables context extension, leading to non-trivial computation saving with similar performance to fine-tuning with vanilla attention.","Particularly, it can be implemented with only two lines of code in training, while being optional in inference.","On the other hand, we revisit the parameter-efficient fine-tuning regime for context expansion.","Notably, we find that LoRA for context extension works well under the premise of trainable embedding and normalization.","LongLoRA demonstrates strong empirical results on various tasks on LLaMA2 models from 7B/13B to 70B. LongLoRA adopts LLaMA2 7B from 4k context to 100k, or LLaMA2 70B to 32k on a single 8x A100 machine.","LongLoRA extends models' context while retaining their original architectures, and is compatible with most existing techniques, like FlashAttention-2.","In addition, to make LongLoRA practical, we collect a dataset, LongQA, for supervised fine-tuning.","It contains more than 3k long context question-answer pairs."],"url":"http://arxiv.org/abs/2309.12307v1"}
{"created":"2023-09-21 17:59:04","title":"SlowFast Network for Continuous Sign Language Recognition","abstract":"The objective of this work is the effective extraction of spatial and dynamic features for Continuous Sign Language Recognition (CSLR). To accomplish this, we utilise a two-pathway SlowFast network, where each pathway operates at distinct temporal resolutions to separately capture spatial (hand shapes, facial expressions) and dynamic (movements) information. In addition, we introduce two distinct feature fusion methods, carefully designed for the characteristics of CSLR: (1) Bi-directional Feature Fusion (BFF), which facilitates the transfer of dynamic semantics into spatial semantics and vice versa; and (2) Pathway Feature Enhancement (PFE), which enriches dynamic and spatial representations through auxiliary subnetworks, while avoiding the need for extra inference time. As a result, our model further strengthens spatial and dynamic representations in parallel. We demonstrate that the proposed framework outperforms the current state-of-the-art performance on popular CSLR datasets, including PHOENIX14, PHOENIX14-T, and CSL-Daily.","sentences":["The objective of this work is the effective extraction of spatial and dynamic features for Continuous Sign Language Recognition (CSLR).","To accomplish this, we utilise a two-pathway SlowFast network, where each pathway operates at distinct temporal resolutions to separately capture spatial (hand shapes, facial expressions) and dynamic (movements) information.","In addition, we introduce two distinct feature fusion methods, carefully designed for the characteristics of CSLR: (1) Bi-directional Feature Fusion (BFF), which facilitates the transfer of dynamic semantics into spatial semantics and vice versa; and (2) Pathway Feature Enhancement (PFE), which enriches dynamic and spatial representations through auxiliary subnetworks, while avoiding the need for extra inference time.","As a result, our model further strengthens spatial and dynamic representations in parallel.","We demonstrate that the proposed framework outperforms the current state-of-the-art performance on popular CSLR datasets, including PHOENIX14, PHOENIX14-T, and CSL-Daily."],"url":"http://arxiv.org/abs/2309.12304v1"}
{"created":"2023-09-21 17:59:02","title":"PanoVOS:Bridging Non-panoramic and Panoramic Views with Transformer for Video Segmentation","abstract":"Panoramic videos contain richer spatial information and have attracted tremendous amounts of attention due to their exceptional experience in some fields such as autonomous driving and virtual reality. However, existing datasets for video segmentation only focus on conventional planar images. To address the challenge, in this paper, we present a panoramic video dataset, PanoVOS. The dataset provides 150 videos with high video resolutions and diverse motions. To quantify the domain gap between 2D planar videos and panoramic videos, we evaluate 15 off-the-shelf video object segmentation (VOS) models on PanoVOS. Through error analysis, we found that all of them fail to tackle pixel-level content discontinues of panoramic videos. Thus, we present a Panoramic Space Consistency Transformer (PSCFormer), which can effectively utilize the semantic boundary information of the previous frame for pixel-level matching with the current frame. Extensive experiments demonstrate that compared with the previous SOTA models, our PSCFormer network exhibits a great advantage in terms of segmentation results under the panoramic setting. Our dataset poses new challenges in panoramic VOS and we hope that our PanoVOS can advance the development of panoramic segmentation/tracking.","sentences":["Panoramic videos contain richer spatial information and have attracted tremendous amounts of attention due to their exceptional experience in some fields such as autonomous driving and virtual reality.","However, existing datasets for video segmentation only focus on conventional planar images.","To address the challenge, in this paper, we present a panoramic video dataset, PanoVOS.","The dataset provides 150 videos with high video resolutions and diverse motions.","To quantify the domain gap between 2D planar videos and panoramic videos, we evaluate 15 off-the-shelf video object segmentation (VOS) models on PanoVOS.","Through error analysis, we found that all of them fail to tackle pixel-level content discontinues of panoramic videos.","Thus, we present a Panoramic Space Consistency Transformer (PSCFormer), which can effectively utilize the semantic boundary information of the previous frame for pixel-level matching with the current frame.","Extensive experiments demonstrate that compared with the previous SOTA models, our PSCFormer network exhibits a great advantage in terms of segmentation results under the panoramic setting.","Our dataset poses new challenges in panoramic VOS and we hope that our PanoVOS can advance the development of panoramic segmentation/tracking."],"url":"http://arxiv.org/abs/2309.12303v1"}
{"created":"2023-09-21 17:59:01","title":"Text-Guided Vector Graphics Customization","abstract":"Vector graphics are widely used in digital art and valued by designers for their scalability and layer-wise topological properties. However, the creation and editing of vector graphics necessitate creativity and design expertise, leading to a time-consuming process. In this paper, we propose a novel pipeline that generates high-quality customized vector graphics based on textual prompts while preserving the properties and layer-wise information of a given exemplar SVG. Our method harnesses the capabilities of large pre-trained text-to-image models. By fine-tuning the cross-attention layers of the model, we generate customized raster images guided by textual prompts. To initialize the SVG, we introduce a semantic-based path alignment method that preserves and transforms crucial paths from the exemplar SVG. Additionally, we optimize path parameters using both image-level and vector-level losses, ensuring smooth shape deformation while aligning with the customized raster image. We extensively evaluate our method using multiple metrics from vector-level, image-level, and text-level perspectives. The evaluation results demonstrate the effectiveness of our pipeline in generating diverse customizations of vector graphics with exceptional quality. The project page is https://intchous.github.io/SVGCustomization.","sentences":["Vector graphics are widely used in digital art and valued by designers for their scalability and layer-wise topological properties.","However, the creation and editing of vector graphics necessitate creativity and design expertise, leading to a time-consuming process.","In this paper, we propose a novel pipeline that generates high-quality customized vector graphics based on textual prompts while preserving the properties and layer-wise information of a given exemplar SVG.","Our method harnesses the capabilities of large pre-trained text-to-image models.","By fine-tuning the cross-attention layers of the model, we generate customized raster images guided by textual prompts.","To initialize the SVG, we introduce a semantic-based path alignment method that preserves and transforms crucial paths from the exemplar SVG.","Additionally, we optimize path parameters using both image-level and vector-level losses, ensuring smooth shape deformation while aligning with the customized raster image.","We extensively evaluate our method using multiple metrics from vector-level, image-level, and text-level perspectives.","The evaluation results demonstrate the effectiveness of our pipeline in generating diverse customizations of vector graphics with exceptional quality.","The project page is https://intchous.github.io/SVGCustomization."],"url":"http://arxiv.org/abs/2309.12302v1"}
{"created":"2023-09-21 17:58:26","title":"Environment-biased Feature Ranking for Novelty Detection Robustness","abstract":"We tackle the problem of robust novelty detection, where we aim to detect novelties in terms of semantic content while being invariant to changes in other, irrelevant factors. Specifically, we operate in a setup with multiple environments, where we determine the set of features that are associated more with the environments, rather than to the content relevant for the task. Thus, we propose a method that starts with a pretrained embedding and a multi-env setup and manages to rank the features based on their environment-focus. First, we compute a per-feature score based on the feature distribution variance between envs. Next, we show that by dropping the highly scored ones, we manage to remove spurious correlations and improve the overall performance by up to 6%, both in covariance and sub-population shift cases, both for a real and a synthetic benchmark, that we introduce for this task.","sentences":["We tackle the problem of robust novelty detection, where we aim to detect novelties in terms of semantic content while being invariant to changes in other, irrelevant factors.","Specifically, we operate in a setup with multiple environments, where we determine the set of features that are associated more with the environments, rather than to the content relevant for the task.","Thus, we propose a method that starts with a pretrained embedding and a multi-env setup and manages to rank the features based on their environment-focus.","First, we compute a per-feature score based on the feature distribution variance between envs.","Next, we show that by dropping the highly scored ones, we manage to remove spurious correlations and improve the overall performance by up to 6%, both in covariance and sub-population shift cases, both for a real and a synthetic benchmark, that we introduce for this task."],"url":"http://arxiv.org/abs/2309.12301v1"}
{"created":"2023-09-21 17:58:13","title":"See to Touch: Learning Tactile Dexterity through Visual Incentives","abstract":"Equipping multi-fingered robots with tactile sensing is crucial for achieving the precise, contact-rich, and dexterous manipulation that humans excel at. However, relying solely on tactile sensing fails to provide adequate cues for reasoning about objects' spatial configurations, limiting the ability to correct errors and adapt to changing situations. In this paper, we present Tactile Adaptation from Visual Incentives (TAVI), a new framework that enhances tactile-based dexterity by optimizing dexterous policies using vision-based rewards. First, we use a contrastive-based objective to learn visual representations. Next, we construct a reward function using these visual representations through optimal-transport based matching on one human demonstration. Finally, we use online reinforcement learning on our robot to optimize tactile-based policies that maximize the visual reward. On six challenging tasks, such as peg pick-and-place, unstacking bowls, and flipping slender objects, TAVI achieves a success rate of 73% using our four-fingered Allegro robot hand. The increase in performance is 108% higher than policies using tactile and vision-based rewards and 135% higher than policies without tactile observational input. Robot videos are best viewed on our project website: https://see-to-touch.github.io/.","sentences":["Equipping multi-fingered robots with tactile sensing is crucial for achieving the precise, contact-rich, and dexterous manipulation that humans excel at.","However, relying solely on tactile sensing fails to provide adequate cues for reasoning about objects' spatial configurations, limiting the ability to correct errors and adapt to changing situations.","In this paper, we present Tactile Adaptation from Visual Incentives (TAVI), a new framework that enhances tactile-based dexterity by optimizing dexterous policies using vision-based rewards.","First, we use a contrastive-based objective to learn visual representations.","Next, we construct a reward function using these visual representations through optimal-transport based matching on one human demonstration.","Finally, we use online reinforcement learning on our robot to optimize tactile-based policies that maximize the visual reward.","On six challenging tasks, such as peg pick-and-place, unstacking bowls, and flipping slender objects, TAVI achieves a success rate of 73% using our four-fingered Allegro robot hand.","The increase in performance is 108% higher than policies using tactile and vision-based rewards and 135% higher than policies without tactile observational input.","Robot videos are best viewed on our project website: https://see-to-touch.github.io/."],"url":"http://arxiv.org/abs/2309.12300v1"}
{"created":"2023-09-21 17:55:36","title":"Learning to Drive Anywhere","abstract":"Human drivers can seamlessly adapt their driving decisions across geographical locations with diverse conditions and rules of the road, e.g., left vs. right-hand traffic. In contrast, existing models for autonomous driving have been thus far only deployed within restricted operational domains, i.e., without accounting for varying driving behaviors across locations or model scalability. In this work, we propose AnyD, a single geographically-aware conditional imitation learning (CIL) model that can efficiently learn from heterogeneous and globally distributed data with dynamic environmental, traffic, and social characteristics. Our key insight is to introduce a high-capacity geo-location-based channel attention mechanism that effectively adapts to local nuances while also flexibly modeling similarities among regions in a data-driven manner. By optimizing a contrastive imitation objective, our proposed approach can efficiently scale across inherently imbalanced data distributions and location-dependent events. We demonstrate the benefits of our AnyD agent across multiple datasets, cities, and scalable deployment paradigms, i.e., centralized, semi-supervised, and distributed agent training. Specifically, AnyD outperforms CIL baselines by over 14% in open-loop evaluation and 30% in closed-loop testing on CARLA.","sentences":["Human drivers can seamlessly adapt their driving decisions across geographical locations with diverse conditions and rules of the road, e.g., left vs. right-hand traffic.","In contrast, existing models for autonomous driving have been thus far only deployed within restricted operational domains, i.e., without accounting for varying driving behaviors across locations or model scalability.","In this work, we propose AnyD, a single geographically-aware conditional imitation learning (CIL) model that can efficiently learn from heterogeneous and globally distributed data with dynamic environmental, traffic, and social characteristics.","Our key insight is to introduce a high-capacity geo-location-based channel attention mechanism that effectively adapts to local nuances while also flexibly modeling similarities among regions in a data-driven manner.","By optimizing a contrastive imitation objective, our proposed approach can efficiently scale across inherently imbalanced data distributions and location-dependent events.","We demonstrate the benefits of our AnyD agent across multiple datasets, cities, and scalable deployment paradigms, i.e., centralized, semi-supervised, and distributed agent training.","Specifically, AnyD outperforms CIL baselines by over 14% in open-loop evaluation and 30% in closed-loop testing on CARLA."],"url":"http://arxiv.org/abs/2309.12295v1"}
{"created":"2023-09-21 17:54:58","title":"Reranking for Natural Language Generation from Logical Forms: A Study based on Large Language Models","abstract":"Large language models (LLMs) have demonstrated impressive capabilities in natural language generation. However, their output quality can be inconsistent, posing challenges for generating natural language from logical forms (LFs). This task requires the generated outputs to embody the exact semantics of LFs, without missing any LF semantics or creating any hallucinations. In this work, we tackle this issue by proposing a novel generate-and-rerank approach. Our approach involves initially generating a set of candidate outputs by prompting an LLM and subsequently reranking them using a task-specific reranker model. In addition, we curate a manually collected dataset to evaluate the alignment between different ranking metrics and human judgements. The chosen ranking metrics are utilized to enhance the training and evaluation of the reranker model. By conducting extensive experiments on three diverse datasets, we demonstrate that the candidates selected by our reranker outperform those selected by baseline methods in terms of semantic consistency and fluency, as measured by three comprehensive metrics. Our findings provide strong evidence for the effectiveness of our approach in improving the quality of generated outputs.","sentences":["Large language models (LLMs) have demonstrated impressive capabilities in natural language generation.","However, their output quality can be inconsistent, posing challenges for generating natural language from logical forms (LFs).","This task requires the generated outputs to embody the exact semantics of LFs, without missing any LF semantics or creating any hallucinations.","In this work, we tackle this issue by proposing a novel generate-and-rerank approach.","Our approach involves initially generating a set of candidate outputs by prompting an LLM and subsequently reranking them using a task-specific reranker model.","In addition, we curate a manually collected dataset to evaluate the alignment between different ranking metrics and human judgements.","The chosen ranking metrics are utilized to enhance the training and evaluation of the reranker model.","By conducting extensive experiments on three diverse datasets, we demonstrate that the candidates selected by our reranker outperform those selected by baseline methods in terms of semantic consistency and fluency, as measured by three comprehensive metrics.","Our findings provide strong evidence for the effectiveness of our approach in improving the quality of generated outputs."],"url":"http://arxiv.org/abs/2309.12294v1"}
{"created":"2023-09-21 17:53:18","title":"Linearity of Gray Codes via Schur Product","abstract":"We propose an original approach to investigate the linearity of Gray codes obtained from $\\mathbb{Z}_{2^L}$-additive codes by introducing two related binary codes: the associated and concatenated. Once they are defined, one could perform a straightforward analysis of the Schur product between their codewords and determine the linearity of the respective Gray code. This work expands on earlier contributions from the literature, where the linearity was established with respect to the kernel of a code and/or operations on $\\mathbb{Z}_{2^L}$. The $\\mathbb{Z}_{2^L}$-additive codes we apply the Gray map and check the linearity are the well-known Hadamard, simplex, MacDonald, Kerdock, and Preparata codes. We also present a family of Reed-Muller codes that yield to linear Gray codes and perform a computational verification of our proposed method applied to other $\\mathbb{Z}_{2^L}$-additive codes.","sentences":["We propose an original approach to investigate the linearity of Gray codes obtained from $\\mathbb{Z}_{2^L}$-additive codes by introducing two related binary codes: the associated and concatenated.","Once they are defined, one could perform a straightforward analysis of the Schur product between their codewords and determine the linearity of the respective Gray code.","This work expands on earlier contributions from the literature, where the linearity was established with respect to the kernel of a code and/or operations on $\\mathbb{Z}_{2^L}$. The $\\mathbb{Z}_{2^L}$-additive codes we apply the Gray map and check the linearity are the well-known Hadamard, simplex, MacDonald, Kerdock, and Preparata codes.","We also present a family of Reed-Muller codes that yield to linear Gray codes and perform a computational verification of our proposed method applied to other $\\mathbb{Z}_{2^L}$-additive codes."],"url":"http://arxiv.org/abs/2309.12291v1"}
{"created":"2023-09-21 17:52:20","title":"Real-Time Capable Decision Making for Autonomous Driving Using Reachable Sets","abstract":"Despite large advances in recent years, real-time capable motion planning for autonomous road vehicles remains a huge challenge. In this work, we present a decision module that is based on set-based reachability analysis: First, we identify all possible driving corridors by computing the reachable set for the longitudinal position of the vehicle along the lanelets of the road network, where lane changes are modeled as discrete events. Next, we select the best driving corridor based on a cost function that penalizes lane changes and deviations from a desired velocity profile. Finally, we generate a reference trajectory inside the selected driving corridor, which can be used to guide or warm start low-level trajectory planners. For the numerical evaluation we combine our decision module with a motion-primitive-based and an optimization-based planner and evaluate the performance on 2000 challenging CommonRoad traffic scenarios as well in the realistic CARLA simulator. The results demonstrate that our decision module is real-time capable and yields significant speed-ups compared to executing a motion planner standalone without a decision module.","sentences":["Despite large advances in recent years, real-time capable motion planning for autonomous road vehicles remains a huge challenge.","In this work, we present a decision module that is based on set-based reachability analysis:","First, we identify all possible driving corridors by computing the reachable set for the longitudinal position of the vehicle along the lanelets of the road network, where lane changes are modeled as discrete events.","Next, we select the best driving corridor based on a cost function that penalizes lane changes and deviations from a desired velocity profile.","Finally, we generate a reference trajectory inside the selected driving corridor, which can be used to guide or warm start low-level trajectory planners.","For the numerical evaluation we combine our decision module with a motion-primitive-based and an optimization-based planner and evaluate the performance on 2000 challenging CommonRoad traffic scenarios as well in the realistic CARLA simulator.","The results demonstrate that our decision module is real-time capable and yields significant speed-ups compared to executing a motion planner standalone without a decision module."],"url":"http://arxiv.org/abs/2309.12289v1"}
{"created":"2023-09-21 17:52:19","title":"The Reversal Curse: LLMs trained on \"A is B\" fail to learn \"B is A\"","abstract":"We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form \"A is B\", it will not automatically generalize to the reverse direction \"B is A\". This is the Reversal Curse. For instance, if a model is trained on \"Olaf Scholz was the ninth Chancellor of Germany\", it will not automatically be able to answer the question, \"Who was the ninth Chancellor of Germany?\". Moreover, the likelihood of the correct answer (\"Olaf Scholz\") will not be higher than for a random name. Thus, models exhibit a basic failure of logical deduction and do not generalize a prevalent pattern in their training set (i.e. if \"A is B'' occurs, \"B is A\" is more likely to occur). We provide evidence for the Reversal Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as \"Uriah Hawthorne is the composer of 'Abyssal Melodies'\" and showing that they fail to correctly answer \"Who composed 'Abyssal Melodies?'\". The Reversal Curse is robust across model sizes and model families and is not alleviated by data augmentation. We also evaluate ChatGPT (GPT-3.5 and GPT-4) on questions about real-world celebrities, such as \"Who is Tom Cruise's mother? [A: Mary Lee Pfeiffer]\" and the reverse \"Who is Mary Lee Pfeiffer's son?\". GPT-4 correctly answers questions like the former 79% of the time, compared to 33% for the latter. This shows a failure of logical deduction that we hypothesize is caused by the Reversal Curse. Code is available at https://github.com/lukasberglund/reversal_curse.","sentences":["We expose a surprising failure of generalization in auto-regressive large language models (LLMs).","If a model is trained on a sentence of the form \"A is B\", it will not automatically generalize to the reverse direction \"B is A\".","This is the Reversal Curse.","For instance, if a model is trained on \"Olaf Scholz was the ninth Chancellor of Germany\", it will not automatically be able to answer the question, \"Who was the ninth Chancellor of Germany?\".","Moreover, the likelihood of the correct answer (\"Olaf Scholz\") will not be higher than for a random name.","Thus, models exhibit a basic failure of logical deduction and do not generalize a prevalent pattern in their training set (i.e. if \"A is B'' occurs, \"B is A\" is more likely to occur).","We provide evidence for the Reversal Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as \"Uriah Hawthorne is the composer of 'Abyssal Melodies'\" and showing that they fail to correctly answer \"Who composed 'Abyssal Melodies?'\".","The Reversal Curse is robust across model sizes and model families and is not alleviated by data augmentation.","We also evaluate ChatGPT (GPT-3.5 and GPT-4) on questions about real-world celebrities, such as \"Who is Tom Cruise's mother?","[A: Mary Lee Pfeiffer]\" and the reverse \"Who is Mary Lee Pfeiffer's son?\".","GPT-4 correctly answers questions like the former 79% of the time, compared to 33% for the latter.","This shows a failure of logical deduction that we hypothesize is caused by the Reversal Curse.","Code is available at https://github.com/lukasberglund/reversal_curse."],"url":"http://arxiv.org/abs/2309.12288v1"}
{"created":"2023-09-21 17:45:42","title":"MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models","abstract":"Large language models (LLMs) have pushed the limits of natural language understanding and exhibited excellent problem-solving ability. Despite the great success, most existing open-source LLMs (\\eg, LLaMA-2) are still far away from satisfactory for solving mathematical problem due to the complex reasoning procedures. To bridge this gap, we propose \\emph{MetaMath}, a fine-tuned language model that specializes in mathematical reasoning. Specifically, we start by bootstrapping mathematical questions by rewriting the question from multiple perspectives without extra knowledge, which results in a new dataset called {MetaMathQA}. Then we fine-tune the LLaMA-2 models on MetaMathQA. Experimental results on two popular benchmarks (\\ie, GSM8K and MATH) for mathematical reasoning demonstrate that MetaMath outperforms a suite of open-source LLMs by a significant margin. Our MetaMath-7B model achieves $66.4\\%$ on GSM8K and $19.4\\%$ on MATH, exceeding the state-of-the-art models of the same size by $11.5\\%$ and $8.7\\%$. Particularly, {MetaMath-70B} achieves an accuracy of $82.3\\%$ on {GSM8K}, slightly better than {GPT-3.5-Turbo}. We release the {MetaMathQA} dataset, the {MetaMath} models with different model sizes and the training code for public use.","sentences":["Large language models (LLMs) have pushed the limits of natural language understanding and exhibited excellent problem-solving ability.","Despite the great success, most existing open-source LLMs (\\eg, LLaMA-2) are still far away from satisfactory for solving mathematical problem due to the complex reasoning procedures.","To bridge this gap, we propose \\emph{MetaMath}, a fine-tuned language model that specializes in mathematical reasoning.","Specifically, we start by bootstrapping mathematical questions by rewriting the question from multiple perspectives without extra knowledge, which results in a new dataset called {MetaMathQA}.","Then we fine-tune the LLaMA-2 models on MetaMathQA.","Experimental results on two popular benchmarks (\\ie, GSM8K and MATH) for mathematical reasoning demonstrate that MetaMath outperforms a suite of open-source LLMs by a significant margin.","Our MetaMath-7B model achieves $66.4\\%$ on GSM8K and $19.4\\%$ on MATH, exceeding the state-of-the-art models of the same size by $11.5\\%$ and $8.7\\%$. Particularly, {MetaMath-70B} achieves an accuracy of $82.3\\%$ on {GSM8K}, slightly better than {GPT-3.5-Turbo}.","We release the {MetaMathQA} dataset, the {MetaMath} models with different model sizes and the training code for public use."],"url":"http://arxiv.org/abs/2309.12284v1"}
{"created":"2023-09-21 17:44:57","title":"Performance Conditioning for Diffusion-Based Multi-Instrument Music Synthesis","abstract":"Generating multi-instrument music from symbolic music representations is an important task in Music Information Retrieval (MIR). A central but still largely unsolved problem in this context is musically and acoustically informed control in the generation process. As the main contribution of this work, we propose enhancing control of multi-instrument synthesis by conditioning a generative model on a specific performance and recording environment, thus allowing for better guidance of timbre and style. Building on state-of-the-art diffusion-based music generative models, we introduce performance conditioning - a simple tool indicating the generative model to synthesize music with style and timbre of specific instruments taken from specific performances. Our prototype is evaluated using uncurated performances with diverse instrumentation and achieves state-of-the-art FAD realism scores while allowing novel timbre and style control. Our project page, including samples and demonstrations, is available at benadar293.github.io/midipm","sentences":["Generating multi-instrument music from symbolic music representations is an important task in Music Information Retrieval (MIR).","A central but still largely unsolved problem in this context is musically and acoustically informed control in the generation process.","As the main contribution of this work, we propose enhancing control of multi-instrument synthesis by conditioning a generative model on a specific performance and recording environment, thus allowing for better guidance of timbre and style.","Building on state-of-the-art diffusion-based music generative models, we introduce performance conditioning - a simple tool indicating the generative model to synthesize music with style and timbre of specific instruments taken from specific performances.","Our prototype is evaluated using uncurated performances with diverse instrumentation and achieves state-of-the-art FAD realism scores while allowing novel timbre and style control.","Our project page, including samples and demonstrations, is available at benadar293.github.io/midipm"],"url":"http://arxiv.org/abs/2309.12283v1"}
{"created":"2023-09-21 17:40:44","title":"The Broad Impact of Feature Imitation: Neural Enhancements Across Financial, Speech, and Physiological Domains","abstract":"Initialization of neural network weights plays a pivotal role in determining their performance. Feature Imitating Networks (FINs) offer a novel strategy by initializing weights to approximate specific closed-form statistical features, setting a promising foundation for deep learning architectures. While the applicability of FINs has been chiefly tested in biomedical domains, this study extends its exploration into other time series datasets. Three different experiments are conducted in this study to test the applicability of imitating Tsallis entropy for performance enhancement: Bitcoin price prediction, speech emotion recognition, and chronic neck pain detection. For the Bitcoin price prediction, models embedded with FINs reduced the root mean square error by around 1000 compared to the baseline. In the speech emotion recognition task, the FIN-augmented model increased classification accuracy by over 3 percent. Lastly, in the CNP detection experiment, an improvement of about 7 percent was observed compared to established classifiers. These findings validate the broad utility and potency of FINs in diverse applications.","sentences":["Initialization of neural network weights plays a pivotal role in determining their performance.","Feature Imitating Networks (FINs) offer a novel strategy by initializing weights to approximate specific closed-form statistical features, setting a promising foundation for deep learning architectures.","While the applicability of FINs has been chiefly tested in biomedical domains, this study extends its exploration into other time series datasets.","Three different experiments are conducted in this study to test the applicability of imitating Tsallis entropy for performance enhancement: Bitcoin price prediction, speech emotion recognition, and chronic neck pain detection.","For the Bitcoin price prediction, models embedded with FINs reduced the root mean square error by around 1000 compared to the baseline.","In the speech emotion recognition task, the FIN-augmented model increased classification accuracy by over 3 percent.","Lastly, in the CNP detection experiment, an improvement of about 7 percent was observed compared to established classifiers.","These findings validate the broad utility and potency of FINs in diverse applications."],"url":"http://arxiv.org/abs/2309.12279v1"}
{"created":"2023-09-21 17:39:53","title":"Inspire the Large Language Model by External Knowledge on BioMedical Named Entity Recognition","abstract":"Large language models (LLMs) have demonstrated dominating performance in many NLP tasks, especially on generative tasks. However, they often fall short in some information extraction tasks, particularly those requiring domain-specific knowledge, such as Biomedical Named Entity Recognition (NER). In this paper, inspired by Chain-of-thought, we leverage the LLM to solve the Biomedical NER step-by-step: break down the NER task into entity span extraction and entity type determination. Additionally, for entity type determination, we inject entity knowledge to address the problem that LLM's lack of domain knowledge when predicting entity category. Experimental results show a significant improvement in our two-step BioNER approach compared to previous few-shot LLM baseline. Additionally, the incorporation of external knowledge significantly enhances entity category determination performance.","sentences":["Large language models (LLMs) have demonstrated dominating performance in many NLP tasks, especially on generative tasks.","However, they often fall short in some information extraction tasks, particularly those requiring domain-specific knowledge, such as Biomedical Named Entity Recognition (NER).","In this paper, inspired by Chain-of-thought, we leverage the LLM to solve the Biomedical NER step-by-step: break down the NER task into entity span extraction and entity type determination.","Additionally, for entity type determination, we inject entity knowledge to address the problem that LLM's lack of domain knowledge when predicting entity category.","Experimental results show a significant improvement in our two-step BioNER approach compared to previous few-shot LLM baseline.","Additionally, the incorporation of external knowledge significantly enhances entity category determination performance."],"url":"http://arxiv.org/abs/2309.12278v1"}
{"created":"2023-09-21 17:37:01","title":"LLMR: Real-time Prompting of Interactive Worlds using Large Language Models","abstract":"We present Large Language Model for Mixed Reality (LLMR), a framework for the real-time creation and modification of interactive Mixed Reality experiences using LLMs. LLMR leverages novel strategies to tackle difficult cases where ideal training data is scarce, or where the design goal requires the synthesis of internal dynamics, intuitive analysis, or advanced interactivity. Our framework relies on text interaction and the Unity game engine. By incorporating techniques for scene understanding, task planning, self-debugging, and memory management, LLMR outperforms the standard GPT-4 by 4x in average error rate. We demonstrate LLMR's cross-platform interoperability with several example worlds, and evaluate it on a variety of creation and modification tasks to show that it can produce and edit diverse objects, tools, and scenes. Finally, we conducted a usability study (N=11) with a diverse set that revealed participants had positive experiences with the system and would use it again.","sentences":["We present Large Language Model for Mixed Reality (LLMR), a framework for the real-time creation and modification of interactive Mixed Reality experiences using LLMs.","LLMR leverages novel strategies to tackle difficult cases where ideal training data is scarce, or where the design goal requires the synthesis of internal dynamics, intuitive analysis, or advanced interactivity.","Our framework relies on text interaction and the Unity game engine.","By incorporating techniques for scene understanding, task planning, self-debugging, and memory management, LLMR outperforms the standard GPT-4 by 4x in average error rate.","We demonstrate LLMR's cross-platform interoperability with several example worlds, and evaluate it on a variety of creation and modification tasks to show that it can produce and edit diverse objects, tools, and scenes.","Finally, we conducted a usability study (N=11) with a diverse set that revealed participants had positive experiences with the system and would use it again."],"url":"http://arxiv.org/abs/2309.12276v1"}
{"created":"2023-09-21 17:32:42","title":"AIM: Accelerating Arbitrary-precision Integer Multiplication on Heterogeneous Reconfigurable Computing Platform Versal ACAP","abstract":"Arbitrary-precision integer multiplication is the core kernel of many applications in simulation, cryptography, etc. Existing acceleration of arbitrary-precision integer multiplication includes CPUs, GPUs, FPGAs, and ASICs. Among these accelerators, FPGAs are promised to provide both good energy efficiency and flexibility. Surprisingly, in our implementations, FPGA has the lowest energy efficiency, i.e., 0.29x of the CPU and 0.17x of the GPU with the same generation fabrication. Therefore, key questions arise: Where do the energy efficiency gains of CPUs and GPUs come from? Can reconfigurable computing do better? If can, how to achieve that?   We identify that the biggest energy efficiency gains of the CPUs and GPUs come from the dedicated vector units. FPGA uses DSPs and lookup tables to compose the needed computation, which incurs overhead when compared to using vector units directly. New reconfigurable computing, e.g., 'FPGA+vector units' is a novel and feasible solution to improve energy efficiency. In this paper, we propose to map arbitrary-precision integer multiplication onto such a heterogeneous platform, i.e., AMD/Xilinx Versal ACAP architecture. Designing on Versal ACAP incurs several challenges and we propose AIM: Arbitrary-precision Integer Multiplication on Versal ACAP to automate and optimize the design. AIM framework includes design space exploration and AIM automatic code generation to facilitate the system design and verification. We deploy the AIM framework on three different applications, including large integer multiplication (LIM), RSA, and Mandelbrot, on the AMD/Xilinx Versal ACAP VCK190 evaluation board. Our experimental results show that AIM achieves up to 12.6x, and 2.1x energy efficiency gains over the Intel Xeon Ice Lake 6346 CPU, and NVidia A5000 GPU respectively, which brings reconfigurable computing the most energy-efficient platform among CPUs and GPUs.","sentences":["Arbitrary-precision integer multiplication is the core kernel of many applications in simulation, cryptography, etc.","Existing acceleration of arbitrary-precision integer multiplication includes CPUs, GPUs, FPGAs, and ASICs.","Among these accelerators, FPGAs are promised to provide both good energy efficiency and flexibility.","Surprisingly, in our implementations, FPGA has the lowest energy efficiency, i.e., 0.29x of the CPU and 0.17x of the GPU with the same generation fabrication.","Therefore, key questions arise: Where do the energy efficiency gains of CPUs and GPUs come from?","Can reconfigurable computing do better?","If can, how to achieve that?   ","We identify that the biggest energy efficiency gains of the CPUs and GPUs come from the dedicated vector units.","FPGA uses DSPs and lookup tables to compose the needed computation, which incurs overhead when compared to using vector units directly.","New reconfigurable computing, e.g., 'FPGA+vector units' is a novel and feasible solution to improve energy efficiency.","In this paper, we propose to map arbitrary-precision integer multiplication onto such a heterogeneous platform, i.e., AMD/Xilinx Versal ACAP architecture.","Designing on Versal ACAP incurs several challenges and we propose AIM: Arbitrary-precision Integer Multiplication on Versal ACAP to automate and optimize the design.","AIM framework includes design space exploration and AIM automatic code generation to facilitate the system design and verification.","We deploy the AIM framework on three different applications, including large integer multiplication (LIM), RSA, and Mandelbrot, on the AMD/Xilinx Versal ACAP VCK190 evaluation board.","Our experimental results show that AIM achieves up to 12.6x, and 2.1x energy efficiency gains over the Intel Xeon Ice Lake 6346 CPU, and NVidia A5000 GPU","respectively, which brings reconfigurable computing the most energy-efficient platform among CPUs and GPUs."],"url":"http://arxiv.org/abs/2309.12275v1"}
{"created":"2023-09-21 17:29:37","title":"Improving VTE Identification through Adaptive NLP Model Selection and Clinical Expert Rule-based Classifier from Radiology Reports","abstract":"Rapid and accurate identification of Venous thromboembolism (VTE), a severe cardiovascular condition including deep vein thrombosis (DVT) and pulmonary embolism (PE), is important for effective treatment. Leveraging Natural Language Processing (NLP) on radiology reports, automated methods have shown promising advancements in identifying VTE events from retrospective data cohorts or aiding clinical experts in identifying VTE events from radiology reports. However, effectively training Deep Learning (DL) and the NLP models is challenging due to limited labeled medical text data, the complexity and heterogeneity of radiology reports, and data imbalance. This study proposes novel method combinations of DL methods, along with data augmentation, adaptive pre-trained NLP model selection, and a clinical expert NLP rule-based classifier, to improve the accuracy of VTE identification in unstructured (free-text) radiology reports. Our experimental results demonstrate the model's efficacy, achieving an impressive 97\\% accuracy and 97\\% F1 score in predicting DVT, and an outstanding 98.3\\% accuracy and 98.4\\% F1 score in predicting PE. These findings emphasize the model's robustness and its potential to significantly contribute to VTE research.","sentences":["Rapid and accurate identification of Venous thromboembolism (VTE), a severe cardiovascular condition including deep vein thrombosis (DVT) and pulmonary embolism (PE), is important for effective treatment.","Leveraging Natural Language Processing (NLP) on radiology reports, automated methods have shown promising advancements in identifying VTE events from retrospective data cohorts or aiding clinical experts in identifying VTE events from radiology reports.","However, effectively training Deep Learning (DL) and the NLP models is challenging due to limited labeled medical text data, the complexity and heterogeneity of radiology reports, and data imbalance.","This study proposes novel method combinations of DL methods, along with data augmentation, adaptive pre-trained NLP model selection, and a clinical expert NLP rule-based classifier, to improve the accuracy of VTE identification in unstructured (free-text) radiology reports.","Our experimental results demonstrate the model's efficacy, achieving an impressive 97\\% accuracy and 97\\% F1 score in predicting DVT, and an outstanding 98.3\\% accuracy and 98.4\\% F1 score in predicting PE.","These findings emphasize the model's robustness and its potential to significantly contribute to VTE research."],"url":"http://arxiv.org/abs/2309.12273v1"}
{"created":"2023-09-21 17:24:40","title":"The Cambridge Law Corpus: A Corpus for Legal AI Research","abstract":"We introduce the Cambridge Law Corpus (CLC), a corpus for legal AI research. It consists of over 250 000 court cases from the UK. Most cases are from the 21st century, but the corpus includes cases as old as the 16th century. This paper presents the first release of the corpus, containing the raw text and meta-data. Together with the corpus, we provide annotations on case outcomes for 638 cases, done by legal experts. Using our annotated data, we have trained and evaluated case outcome extraction with GPT-3, GPT-4 and RoBERTa models to provide benchmarks. We include an extensive legal and ethical discussion to address the potentially sensitive nature of this material. As a consequence, the corpus will only be released for research purposes under certain restrictions.","sentences":["We introduce the Cambridge Law Corpus (CLC), a corpus for legal AI research.","It consists of over 250 000 court cases from the UK.","Most cases are from the 21st century, but the corpus includes cases as old as the 16th century.","This paper presents the first release of the corpus, containing the raw text and meta-data.","Together with the corpus, we provide annotations on case outcomes for 638 cases, done by legal experts.","Using our annotated data, we have trained and evaluated case outcome extraction with GPT-3, GPT-4 and RoBERTa models to provide benchmarks.","We include an extensive legal and ethical discussion to address the potentially sensitive nature of this material.","As a consequence, the corpus will only be released for research purposes under certain restrictions."],"url":"http://arxiv.org/abs/2309.12269v1"}
{"created":"2023-09-21 17:17:28","title":"Enabling Quartile-based Estimated-Mean Gradient Aggregation As Baseline for Federated Image Classifications","abstract":"Federated Learning (FL) has revolutionized how we train deep neural networks by enabling decentralized collaboration while safeguarding sensitive data and improving model performance. However, FL faces two crucial challenges: the diverse nature of data held by individual clients and the vulnerability of the FL system to security breaches. This paper introduces an innovative solution named Estimated Mean Aggregation (EMA) that not only addresses these challenges but also provides a fundamental reference point as a $\\mathsf{baseline}$ for advanced aggregation techniques in FL systems. EMA's significance lies in its dual role: enhancing model security by effectively handling malicious outliers through trimmed means and uncovering data heterogeneity to ensure that trained models are adaptable across various client datasets. Through a wealth of experiments, EMA consistently demonstrates high accuracy and area under the curve (AUC) compared to alternative methods, establishing itself as a robust baseline for evaluating the effectiveness and security of FL aggregation methods. EMA's contributions thus offer a crucial step forward in advancing the efficiency, security, and versatility of decentralized deep learning in the context of FL.","sentences":["Federated Learning (FL) has revolutionized how we train deep neural networks by enabling decentralized collaboration while safeguarding sensitive data and improving model performance.","However, FL faces two crucial challenges: the diverse nature of data held by individual clients and the vulnerability of the FL system to security breaches.","This paper introduces an innovative solution named Estimated Mean Aggregation (EMA) that not only addresses these challenges but also provides a fundamental reference point as a $\\mathsf{baseline}$ for advanced aggregation techniques in FL systems.","EMA's significance lies in its dual role: enhancing model security by effectively handling malicious outliers through trimmed means and uncovering data heterogeneity to ensure that trained models are adaptable across various client datasets.","Through a wealth of experiments, EMA consistently demonstrates high accuracy and area under the curve (AUC) compared to alternative methods, establishing itself as a robust baseline for evaluating the effectiveness and security of FL aggregation methods.","EMA's contributions thus offer a crucial step forward in advancing the efficiency, security, and versatility of decentralized deep learning in the context of FL."],"url":"http://arxiv.org/abs/2309.12267v1"}
{"created":"2023-09-21 17:13:21","title":"On the Relationship between Skill Neurons and Robustness in Prompt Tuning","abstract":"Prompt Tuning is a popular parameter-efficient finetuning method for pre-trained large language models (PLMs). Recently, based on experiments with RoBERTa, it has been suggested that Prompt Tuning activates specific neurons in the transformer's feed-forward networks, that are highly predictive and selective for the given task. In this paper, we study the robustness of Prompt Tuning in relation to these \"skill neurons\", using RoBERTa and T5. We show that prompts tuned for a specific task are transferable to tasks of the same type but are not very robust to adversarial data, with higher robustness for T5 than RoBERTa. At the same time, we replicate the existence of skill neurons in RoBERTa and further show that skill neurons also seem to exist in T5. Interestingly, the skill neurons of T5 determined on non-adversarial data are also among the most predictive neurons on the adversarial data, which is not the case for RoBERTa. We conclude that higher adversarial robustness may be related to a model's ability to activate the relevant skill neurons on adversarial data.","sentences":["Prompt Tuning is a popular parameter-efficient finetuning method for pre-trained large language models (PLMs).","Recently, based on experiments with RoBERTa, it has been suggested that Prompt Tuning activates specific neurons in the transformer's feed-forward networks, that are highly predictive and selective for the given task.","In this paper, we study the robustness of Prompt Tuning in relation to these \"skill neurons\", using RoBERTa and T5.","We show that prompts tuned for a specific task are transferable to tasks of the same type but are not very robust to adversarial data, with higher robustness for T5 than RoBERTa.","At the same time, we replicate the existence of skill neurons in RoBERTa and further show that skill neurons also seem to exist in T5.","Interestingly, the skill neurons of T5 determined on non-adversarial data are also among the most predictive neurons on the adversarial data, which is not the case for RoBERTa.","We conclude that higher adversarial robustness may be related to a model's ability to activate the relevant skill neurons on adversarial data."],"url":"http://arxiv.org/abs/2309.12263v1"}
{"created":"2023-09-21 17:08:12","title":"Strong Call-by-Value and Multi Types","abstract":"This paper provides foundations for strong (that is, possibly under abstraction) call-by-value evaluation for the lambda-calculus. Recently, Accattoli et al. proposed a form of call-by-value strong evaluation for the lambda-calculus, the external strategy, and proved it reasonable for time. Here, we study the external strategy using a semantical tool, namely Ehrhard's call-by-value multi types, a variant of intersection types. We show that the external strategy terminates exactly when a term is typable with so-called shrinking multi types, mimicking similar results for strong call-by-name. Additionally, the external strategy is normalizing in the untyped setting, that is, it reaches the normal form whenever it exists.   We also consider the call-by-extended-value approach to strong evaluation shown reasonable for time by Biernacka et al. The two approaches turn out to not be equivalent: terms may be externally divergent but terminating for call-by-extended-value.","sentences":["This paper provides foundations for strong (that is, possibly under abstraction) call-by-value evaluation for the lambda-calculus.","Recently, Accattoli et al. proposed a form of call-by-value strong evaluation for the lambda-calculus, the external strategy, and proved it reasonable for time.","Here, we study the external strategy using a semantical tool, namely Ehrhard's call-by-value multi types, a variant of intersection types.","We show that the external strategy terminates exactly when a term is typable with so-called shrinking multi types, mimicking similar results for strong call-by-name.","Additionally, the external strategy is normalizing in the untyped setting, that is, it reaches the normal form whenever it exists.   ","We also consider the call-by-extended-value approach to strong evaluation shown reasonable for time by Biernacka et al.","The two approaches turn out to not be equivalent: terms may be externally divergent but terminating for call-by-extended-value."],"url":"http://arxiv.org/abs/2309.12261v1"}
{"created":"2023-09-21 17:07:31","title":"Soft Merging: A Flexible and Robust Soft Model Merging Approach for Enhanced Neural Network Performance","abstract":"Stochastic Gradient Descent (SGD), a widely used optimization algorithm in deep learning, is often limited to converging to local optima due to the non-convex nature of the problem. Leveraging these local optima to improve model performance remains a challenging task. Given the inherent complexity of neural networks, the simple arithmetic averaging of the obtained local optima models in undesirable results. This paper proposes a {\\em soft merging} method that facilitates rapid merging of multiple models, simplifies the merging of specific parts of neural networks, and enhances robustness against malicious models with extreme values. This is achieved by learning gate parameters through a surrogate of the $l_0$ norm using hard concrete distribution without modifying the model weights of the given local optima models. This merging process not only enhances the model performance by converging to a better local optimum, but also minimizes computational costs, offering an efficient and explicit learning process integrated with stochastic gradient descent. Thorough experiments underscore the effectiveness and superior performance of the merged neural networks.","sentences":["Stochastic Gradient Descent (SGD), a widely used optimization algorithm in deep learning, is often limited to converging to local optima due to the non-convex nature of the problem.","Leveraging these local optima to improve model performance remains a challenging task.","Given the inherent complexity of neural networks, the simple arithmetic averaging of the obtained local optima models in undesirable results.","This paper proposes a {\\em soft merging} method that facilitates rapid merging of multiple models, simplifies the merging of specific parts of neural networks, and enhances robustness against malicious models with extreme values.","This is achieved by learning gate parameters through a surrogate of the $l_0$ norm using hard concrete distribution without modifying the model weights of the given local optima models.","This merging process not only enhances the model performance by converging to a better local optimum, but also minimizes computational costs, offering an efficient and explicit learning process integrated with stochastic gradient descent.","Thorough experiments underscore the effectiveness and superior performance of the merged neural networks."],"url":"http://arxiv.org/abs/2309.12259v1"}
{"created":"2023-09-21 16:58:35","title":"Variational Quantum Harmonizer: Generating Chord Progressions and Other Sonification Methods with the VQE Algorithm","abstract":"This work investigates a case study of using physical-based sonification of Quadratic Unconstrained Binary Optimization (QUBO) problems, optimized by the Variational Quantum Eigensolver (VQE) algorithm. The VQE approximates the solution of the problem by using an iterative loop between the quantum computer and a classical optimization routine. This work explores the intermediary statevectors found in each VQE iteration as the means of sonifying the optimization process itself. The implementation was realised in the form of a musical interface prototype named Variational Quantum Harmonizer (VQH), providing potential design strategies for musical applications, focusing on chords, chord progressions, and arpeggios. The VQH can be used both to enhance data visualization or to create artistic pieces. The methodology is also relevant in terms of how an artist would gain intuition towards achieving a desired musical sound by carefully designing QUBO cost functions. Flexible mapping strategies could supply a broad portfolio of sounds for QUBO and quantum-inspired musical compositions, as demonstrated in a case study composition, \"Dependent Origination\" by Peter Thomas and Paulo Itaborai.","sentences":["This work investigates a case study of using physical-based sonification of Quadratic Unconstrained Binary Optimization (QUBO) problems, optimized by the Variational Quantum Eigensolver (VQE) algorithm.","The VQE approximates the solution of the problem by using an iterative loop between the quantum computer and a classical optimization routine.","This work explores the intermediary statevectors found in each VQE iteration as the means of sonifying the optimization process itself.","The implementation was realised in the form of a musical interface prototype named Variational Quantum Harmonizer (VQH), providing potential design strategies for musical applications, focusing on chords, chord progressions, and arpeggios.","The VQH can be used both to enhance data visualization or to create artistic pieces.","The methodology is also relevant in terms of how an artist would gain intuition towards achieving a desired musical sound by carefully designing QUBO cost functions.","Flexible mapping strategies could supply a broad portfolio of sounds for QUBO and quantum-inspired musical compositions, as demonstrated in a case study composition, \"Dependent Origination\" by Peter Thomas and Paulo Itaborai."],"url":"http://arxiv.org/abs/2309.12254v1"}
{"created":"2023-09-21 16:57:09","title":"SALSA-CLRS: A Sparse and Scalable Benchmark for Algorithmic Reasoning","abstract":"We introduce an extension to the CLRS algorithmic learning benchmark, prioritizing scalability and the utilization of sparse representations. Many algorithms in CLRS require global memory or information exchange, mirrored in its execution model, which constructs fully connected (not sparse) graphs based on the underlying problem. Despite CLRS's aim of assessing how effectively learned algorithms can generalize to larger instances, the existing execution model becomes a significant constraint due to its demanding memory requirements and runtime (hard to scale). However, many important algorithms do not demand a fully connected graph; these algorithms, primarily distributed in nature, align closely with the message-passing paradigm employed by Graph Neural Networks. Hence, we propose SALSA-CLRS, an extension of the current CLRS benchmark specifically with scalability and sparseness in mind. Our approach includes adapted algorithms from the original CLRS benchmark and introduces new problems from distributed and randomized algorithms. Moreover, we perform a thorough empirical evaluation of our benchmark. Code is publicly available at https://github.com/jkminder/SALSA-CLRS.","sentences":["We introduce an extension to the CLRS algorithmic learning benchmark, prioritizing scalability and the utilization of sparse representations.","Many algorithms in CLRS require global memory or information exchange, mirrored in its execution model, which constructs fully connected (not sparse) graphs based on the underlying problem.","Despite CLRS's aim of assessing how effectively learned algorithms can generalize to larger instances, the existing execution model becomes a significant constraint due to its demanding memory requirements and runtime (hard to scale).","However, many important algorithms do not demand a fully connected graph; these algorithms, primarily distributed in nature, align closely with the message-passing paradigm employed by Graph Neural Networks.","Hence, we propose SALSA-CLRS, an extension of the current CLRS benchmark specifically with scalability and sparseness in mind.","Our approach includes adapted algorithms from the original CLRS benchmark and introduces new problems from distributed and randomized algorithms.","Moreover, we perform a thorough empirical evaluation of our benchmark.","Code is publicly available at https://github.com/jkminder/SALSA-CLRS."],"url":"http://arxiv.org/abs/2309.12253v1"}
{"created":"2023-09-21 16:52:34","title":"Parallelizing non-linear sequential models over the sequence length","abstract":"Sequential models, such as Recurrent Neural Networks and Neural Ordinary Differential Equations, have long suffered from slow training due to their inherent sequential nature. For many years this bottleneck has persisted, as many thought sequential models could not be parallelized. We challenge this long-held belief with our parallel algorithm that accelerates GPU evaluation of sequential models by up to 3 orders of magnitude faster without compromising output accuracy. The algorithm does not need any special structure in the sequential models' architecture, making it applicable to a wide range of architectures. Using our method, training sequential models can be more than 10 times faster than the common sequential method without any meaningful difference in the training results. Leveraging this accelerated training, we discovered the efficacy of the Gated Recurrent Unit in a long time series classification problem with 17k time samples. By overcoming the training bottleneck, our work serves as the first step to unlock the potential of non-linear sequential models for long sequence problems.","sentences":["Sequential models, such as Recurrent Neural Networks and Neural Ordinary Differential Equations, have long suffered from slow training due to their inherent sequential nature.","For many years this bottleneck has persisted, as many thought sequential models could not be parallelized.","We challenge this long-held belief with our parallel algorithm that accelerates GPU evaluation of sequential models by up to 3 orders of magnitude faster without compromising output accuracy.","The algorithm does not need any special structure in the sequential models' architecture, making it applicable to a wide range of architectures.","Using our method, training sequential models can be more than 10 times faster than the common sequential method without any meaningful difference in the training results.","Leveraging this accelerated training, we discovered the efficacy of the Gated Recurrent Unit in a long time series classification problem with 17k time samples.","By overcoming the training bottleneck, our work serves as the first step to unlock the potential of non-linear sequential models for long sequence problems."],"url":"http://arxiv.org/abs/2309.12252v1"}
{"created":"2023-09-21 16:52:29","title":"Planning Optimal Trajectories for Mobile Manipulators under End-effector Trajectory Continuity Constraint","abstract":"Mobile manipulators have been employed in many applications which are usually performed by multiple fixed-base robots or a large-size system, thanks to the mobility of the mobile base. However, the mobile base also brings redundancies to the system, which makes trajectory planning more challenging. One class of problems recently arising from mobile 3D printing is the trajectory-continuous tasks, in which the end-effector is required to follow a designed continuous trajectory (time-parametrized path) in task space. This paper formulates and solves the optimal trajectory planning problem for mobile manipulators under end-effector trajectory continuity constraint, which allows considerations of other constraints and trajectory optimization. To demonstrate our method, a discrete optimal trajectory planning algorithm is proposed to solve mobile 3D printing tasks in multiple experiments.","sentences":["Mobile manipulators have been employed in many applications which are usually performed by multiple fixed-base robots or a large-size system, thanks to the mobility of the mobile base.","However, the mobile base also brings redundancies to the system, which makes trajectory planning more challenging.","One class of problems recently arising from mobile 3D printing is the trajectory-continuous tasks, in which the end-effector is required to follow a designed continuous trajectory (time-parametrized path) in task space.","This paper formulates and solves the optimal trajectory planning problem for mobile manipulators under end-effector trajectory continuity constraint, which allows considerations of other constraints and trajectory optimization.","To demonstrate our method, a discrete optimal trajectory planning algorithm is proposed to solve mobile 3D printing tasks in multiple experiments."],"url":"http://arxiv.org/abs/2309.12251v1"}
{"created":"2023-09-21 16:51:30","title":"SQUARE: Automatic Question Answering Evaluation using Multiple Positive and Negative References","abstract":"Evaluation of QA systems is very challenging and expensive, with the most reliable approach being human annotations of correctness of answers for questions. Recent works (AVA, BEM) have shown that transformer LM encoder based similarity metrics transfer well for QA evaluation, but they are limited by the usage of a single correct reference answer. We propose a new evaluation metric: SQuArE (Sentence-level QUestion AnsweRing Evaluation), using multiple reference answers (combining multiple correct and incorrect references) for sentence-form QA. We evaluate SQuArE on both sentence-level extractive (Answer Selection) and generative (GenQA) QA systems, across multiple academic and industrial datasets, and show that it outperforms previous baselines and obtains the highest correlation with human annotations.","sentences":["Evaluation of QA systems is very challenging and expensive, with the most reliable approach being human annotations of correctness of answers for questions.","Recent works (AVA, BEM) have shown that transformer LM encoder based similarity metrics transfer well for QA evaluation, but they are limited by the usage of a single correct reference answer.","We propose a new evaluation metric: SQuArE (Sentence-level QUestion AnsweRing Evaluation), using multiple reference answers (combining multiple correct and incorrect references) for sentence-form QA.","We evaluate SQuArE on both sentence-level extractive (Answer Selection) and generative (GenQA) QA systems, across multiple academic and industrial datasets, and show that it outperforms previous baselines and obtains the highest correlation with human annotations."],"url":"http://arxiv.org/abs/2309.12250v1"}
{"created":"2023-09-21 16:47:30","title":"Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection","abstract":"Detecting fake news requires both a delicate sense of diverse clues and a profound understanding of the real-world background, which remains challenging for detectors based on small language models (SLMs) due to their knowledge and capability limitations. Recent advances in large language models (LLMs) have shown remarkable performance in various tasks, but whether and how LLMs could help with fake news detection remains underexplored. In this paper, we investigate the potential of LLMs in fake news detection. First, we conduct an empirical study and find that a sophisticated LLM such as GPT 3.5 could generally expose fake news and provide desirable multi-perspective rationales but still underperforms the basic SLM, fine-tuned BERT. Our subsequent analysis attributes such a gap to the LLM's inability to select and integrate rationales properly to conclude. Based on these findings, we propose that current LLMs may not substitute fine-tuned SLMs in fake news detection but can be a good advisor for SLMs by providing multi-perspective instructive rationales. To instantiate this proposal, we design an adaptive rationale guidance network for fake news detection (ARG), in which SLMs selectively acquire insights on news analysis from the LLMs' rationales. We further derive a rationale-free version of ARG by distillation, namely ARG-D, which services cost-sensitive scenarios without inquiring LLMs. Experiments on two real-world datasets demonstrate that ARG and ARG-D outperform three types of baseline methods, including SLM-based, LLM-based, and combinations of small and large language models.","sentences":["Detecting fake news requires both a delicate sense of diverse clues and a profound understanding of the real-world background, which remains challenging for detectors based on small language models (SLMs) due to their knowledge and capability limitations.","Recent advances in large language models (LLMs) have shown remarkable performance in various tasks, but whether and how LLMs could help with fake news detection remains underexplored.","In this paper, we investigate the potential of LLMs in fake news detection.","First, we conduct an empirical study and find that a sophisticated LLM such as GPT 3.5 could generally expose fake news and provide desirable multi-perspective rationales but still underperforms the basic SLM, fine-tuned BERT.","Our subsequent analysis attributes such a gap to the LLM's inability to select and integrate rationales properly to conclude.","Based on these findings, we propose that current LLMs may not substitute fine-tuned SLMs in fake news detection but can be a good advisor for SLMs by providing multi-perspective instructive rationales.","To instantiate this proposal, we design an adaptive rationale guidance network for fake news detection (ARG), in which SLMs selectively acquire insights on news analysis from the LLMs' rationales.","We further derive a rationale-free version of ARG by distillation, namely ARG-D, which services cost-sensitive scenarios without inquiring LLMs.","Experiments on two real-world datasets demonstrate that ARG and ARG-D outperform three types of baseline methods, including SLM-based, LLM-based, and combinations of small and large language models."],"url":"http://arxiv.org/abs/2309.12247v1"}
{"created":"2023-09-21 16:43:17","title":"ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events","abstract":"Children typically learn to identify and express emotions through sharing their stories and feelings with others, particularly their family. However, it is challenging for parents or siblings to have emotional communication with children since children are still developing their communication skills. We present ChaCha, a chatbot that encourages and guides children to share personal events and associated emotions. ChaCha combines a state machine and large language models (LLMs) to keep the dialogue on track while carrying on free-form conversations. Through an exploratory study with 20 children (aged 8-12), we examine how ChaCha prompts children to share personal events and guides them to describe associated emotions. Participants perceived ChaCha as a close friend and shared their stories on various topics, such as family trips and personal achievements. Based on the quantitative and qualitative findings, we discuss opportunities for leveraging LLMs to design child-friendly chatbots to support children in sharing their emotions.","sentences":["Children typically learn to identify and express emotions through sharing their stories and feelings with others, particularly their family.","However, it is challenging for parents or siblings to have emotional communication with children since children are still developing their communication skills.","We present ChaCha, a chatbot that encourages and guides children to share personal events and associated emotions.","ChaCha combines a state machine and large language models (LLMs) to keep the dialogue on track while carrying on free-form conversations.","Through an exploratory study with 20 children (aged 8-12), we examine how ChaCha prompts children to share personal events and guides them to describe associated emotions.","Participants perceived ChaCha as a close friend and shared their stories on various topics, such as family trips and personal achievements.","Based on the quantitative and qualitative findings, we discuss opportunities for leveraging LLMs to design child-friendly chatbots to support children in sharing their emotions."],"url":"http://arxiv.org/abs/2309.12244v1"}
{"created":"2023-09-21 16:40:46","title":"Weakly-supervised Automated Audio Captioning via text only training","abstract":"In recent years, datasets of paired audio and captions have enabled remarkable success in automatically generating descriptions for audio clips, namely Automated Audio Captioning (AAC). However, it is labor-intensive and time-consuming to collect a sufficient number of paired audio and captions. Motivated by the recent advances in Contrastive Language-Audio Pretraining (CLAP), we propose a weakly-supervised approach to train an AAC model assuming only text data and a pre-trained CLAP model, alleviating the need for paired target data. Our approach leverages the similarity between audio and text embeddings in CLAP. During training, we learn to reconstruct the text from the CLAP text embedding, and during inference, we decode using the audio embeddings. To mitigate the modality gap between the audio and text embeddings we employ strategies to bridge the gap during training and inference stages. We evaluate our proposed method on Clotho and AudioCaps datasets demonstrating its ability to achieve a relative performance of up to ~$83\\%$ compared to fully supervised approaches trained with paired target data.","sentences":["In recent years, datasets of paired audio and captions have enabled remarkable success in automatically generating descriptions for audio clips, namely Automated Audio Captioning (AAC).","However, it is labor-intensive and time-consuming to collect a sufficient number of paired audio and captions.","Motivated by the recent advances in Contrastive Language-Audio Pretraining (CLAP), we propose a weakly-supervised approach to train an AAC model assuming only text data and a pre-trained CLAP model, alleviating the need for paired target data.","Our approach leverages the similarity between audio and text embeddings in CLAP.","During training, we learn to reconstruct the text from the CLAP text embedding, and during inference, we decode using the audio embeddings.","To mitigate the modality gap between the audio and text embeddings we employ strategies to bridge the gap during training and inference stages.","We evaluate our proposed method on Clotho and AudioCaps datasets demonstrating its ability to achieve a relative performance of up to ~$83\\%$ compared to fully supervised approaches trained with paired target data."],"url":"http://arxiv.org/abs/2309.12242v1"}
{"created":"2023-09-21 16:37:37","title":"Algorithmic complexity and soficness of shifts in dimension two","abstract":"In this manuscript we study properties of multidimensional shifts. More precisely, we study the necessary and sufficient conditions for a shift to be sofic, i.e. the boundary between sofic shifts and effective ones. To this end, we use different versions of algorithmic complexity (a.k.a. Kolmogorov complexity). In the first part of the work we suggest new necessary conditions of soficness for multidimensional shift. These conditions are expressed in terms of Kolmogorov complexity with bounded ressources. We discuss several applications of this technique. In particular, we construct an example of a two-dimensional effective and non sofic shift that has a very low combinatorial complexity : the number of global admissible N x N patterns grows only polynomially in N. We also show that the technique developed by S.Kass and K.Madden is equivalent to a special case of our method. In the second part, we discuss properties of subshifts defined in terms of density of letters. More specifically, we study two-dimensional subshifts $S(\\rho)$ in the binary alphabet (white and black cells) where a configuration is admissible if every pattern of size N x N contains at most $N^\\rho$ black cells. We show that $S(^\\rho)$ is sofic for every $\\rho<1$. Moreover, all effectif subshifts of these shifts are also sofic. The proof of this result is principally based on the construction of a self-simulating point-fixed tile set, with several new ingredients: an ad hoc model of computation based on a non deterministic cellular automaton (which allows to implement efficiently massively parallel calculations) and some properties of flows in a specific type of planar graphs.","sentences":["In this manuscript we study properties of multidimensional shifts.","More precisely, we study the necessary and sufficient conditions for a shift to be sofic, i.e. the boundary between sofic shifts and effective ones.","To this end, we use different versions of algorithmic complexity (a.k.a.","Kolmogorov complexity).","In the first part of the work we suggest new necessary conditions of soficness for multidimensional shift.","These conditions are expressed in terms of Kolmogorov complexity with bounded ressources.","We discuss several applications of this technique.","In particular, we construct an example of a two-dimensional effective and non sofic shift that has a very low combinatorial complexity : the number of global admissible N x N patterns grows only polynomially in N.","We also show that the technique developed by S.Kass and K.Madden is equivalent to a special case of our method.","In the second part, we discuss properties of subshifts defined in terms of density of letters.","More specifically, we study two-dimensional subshifts $S(\\rho)$ in the binary alphabet (white and black cells) where a configuration is admissible if every pattern of size N x N contains at most $N^\\rho$ black cells.","We show that $S(^\\rho)$ is sofic for every $\\rho<1$. Moreover, all effectif subshifts of these shifts are also sofic.","The proof of this result is principally based on the construction of a self-simulating point-fixed tile set, with several new ingredients: an ad hoc model of computation based on a non deterministic cellular automaton (which allows to implement efficiently massively parallel calculations) and some properties of flows in a specific type of planar graphs."],"url":"http://arxiv.org/abs/2309.12241v1"}
{"created":"2023-09-21 16:34:18","title":"ContTune: Continuous Tuning by Conservative Bayesian Optimization for Distributed Stream Data Processing Systems","abstract":"The past decade has seen rapid growth of distributed stream data processing systems. Under these systems, a stream application is realized as a Directed Acyclic Graph (DAG) of operators, where the level of parallelism of each operator has a substantial impact on its overall performance. However, finding optimal levels of parallelism remains challenging. Most existing methods are heavily coupled with the topological graph of operators, unable to efficiently tune under-provisioned jobs. They either insufficiently use previous tuning experience by treating successively tuning independently, or explore the configuration space aggressively, violating the Service Level Agreements (SLA).   To address the above problems, we propose ContTune, a continuous tuning system for stream applications. It is equipped with a novel Big-small algorithm, in which the Big phase decouples the tuning from the topological graph by decomposing the job tuning problem into sub-problems that can be solved concurrently. We propose a conservative Bayesian Optimization (CBO) technique in the Small phase to speed up the tuning process by utilizing the previous observations. It leverages the state-of-the-art (SOTA) tuning method as conservative exploration to avoid SLA violations. Experimental results show that ContTune reduces up to 60.75% number of reconfigurations under synthetic workloads and up to 57.5% number of reconfigurations under real workloads, compared to the SOTA method DS2.","sentences":["The past decade has seen rapid growth of distributed stream data processing systems.","Under these systems, a stream application is realized as a Directed Acyclic Graph (DAG) of operators, where the level of parallelism of each operator has a substantial impact on its overall performance.","However, finding optimal levels of parallelism remains challenging.","Most existing methods are heavily coupled with the topological graph of operators, unable to efficiently tune under-provisioned jobs.","They either insufficiently use previous tuning experience by treating successively tuning independently, or explore the configuration space aggressively, violating the Service Level Agreements (SLA).   ","To address the above problems, we propose ContTune, a continuous tuning system for stream applications.","It is equipped with a novel Big-small algorithm, in which the Big phase decouples the tuning from the topological graph by decomposing the job tuning problem into sub-problems that can be solved concurrently.","We propose a conservative Bayesian Optimization (CBO) technique in the Small phase to speed up the tuning process by utilizing the previous observations.","It leverages the state-of-the-art (SOTA) tuning method as conservative exploration to avoid SLA violations.","Experimental results show that ContTune reduces up to 60.75% number of reconfigurations under synthetic workloads and up to 57.5% number of reconfigurations under real workloads, compared to the SOTA method DS2."],"url":"http://arxiv.org/abs/2309.12239v1"}
{"created":"2023-09-21 16:30:40","title":"t-EER: Parameter-Free Tandem Evaluation of Countermeasures and Biometric Comparators","abstract":"Presentation attack (spoofing) detection (PAD) typically operates alongside biometric verification to improve reliablity in the face of spoofing attacks. Even though the two sub-systems operate in tandem to solve the single task of reliable biometric verification, they address different detection tasks and are hence typically evaluated separately. Evidence shows that this approach is suboptimal. We introduce a new metric for the joint evaluation of PAD solutions operating in situ with biometric verification. In contrast to the tandem detection cost function proposed recently, the new tandem equal error rate (t-EER) is parameter free. The combination of two classifiers nonetheless leads to a \\emph{set} of operating points at which false alarm and miss rates are equal and also dependent upon the prevalence of attacks. We therefore introduce the \\emph{concurrent} t-EER, a unique operating point which is invariable to the prevalence of attacks. Using both modality (and even application) agnostic simulated scores, as well as real scores for a voice biometrics application, we demonstrate application of the t-EER to a wide range of biometric system evaluations under attack. The proposed approach is a strong candidate metric for the tandem evaluation of PAD systems and biometric comparators.","sentences":["Presentation attack (spoofing) detection (PAD) typically operates alongside biometric verification to improve reliablity in the face of spoofing attacks.","Even though the two sub-systems operate in tandem to solve the single task of reliable biometric verification, they address different detection tasks and are hence typically evaluated separately.","Evidence shows that this approach is suboptimal.","We introduce a new metric for the joint evaluation of PAD solutions operating in situ with biometric verification.","In contrast to the tandem detection cost function proposed recently, the new tandem equal error rate (t-EER) is parameter free.","The combination of two classifiers nonetheless leads to a \\emph{set} of operating points at which false alarm and miss rates are equal and also dependent upon the prevalence of attacks.","We therefore introduce the \\emph{concurrent} t-EER, a unique operating point which is invariable to the prevalence of attacks.","Using both modality (and even application) agnostic simulated scores, as well as real scores for a voice biometrics application, we demonstrate application of the t-EER to a wide range of biometric system evaluations under attack.","The proposed approach is a strong candidate metric for the tandem evaluation of PAD systems and biometric comparators."],"url":"http://arxiv.org/abs/2309.12237v1"}
{"created":"2023-09-21 16:30:22","title":"Smooth ECE: Principled Reliability Diagrams via Kernel Smoothing","abstract":"Calibration measures and reliability diagrams are two fundamental tools for measuring and interpreting the calibration of probabilistic predictors. Calibration measures quantify the degree of miscalibration, and reliability diagrams visualize the structure of this miscalibration. However, the most common constructions of reliability diagrams and calibration measures -- binning and ECE -- both suffer from well-known flaws (e.g. discontinuity). We show that a simple modification fixes both constructions: first smooth the observations using an RBF kernel, then compute the Expected Calibration Error (ECE) of this smoothed function. We prove that with a careful choice of bandwidth, this method yields a calibration measure that is well-behaved in the sense of (B{\\l}asiok, Gopalan, Hu, and Nakkiran 2023a) -- a consistent calibration measure. We call this measure the SmoothECE. Moreover, the reliability diagram obtained from this smoothed function visually encodes the SmoothECE, just as binned reliability diagrams encode the BinnedECE.   We also provide a Python package with simple, hyperparameter-free methods for measuring and plotting calibration: `pip install relplot\\`.","sentences":["Calibration measures and reliability diagrams are two fundamental tools for measuring and interpreting the calibration of probabilistic predictors.","Calibration measures quantify the degree of miscalibration, and reliability diagrams visualize the structure of this miscalibration.","However, the most common constructions of reliability diagrams and calibration measures -- binning and ECE -- both suffer from well-known flaws (e.g. discontinuity).","We show that a simple modification fixes both constructions: first smooth the observations using an RBF kernel, then compute the Expected Calibration Error (ECE) of this smoothed function.","We prove that with a careful choice of bandwidth, this method yields a calibration measure that is well-behaved in the sense of (B{\\l}asiok, Gopalan, Hu, and Nakkiran 2023a) -- a consistent calibration measure.","We call this measure the SmoothECE.","Moreover, the reliability diagram obtained from this smoothed function visually encodes the SmoothECE, just as binned reliability diagrams encode the BinnedECE.   ","We also provide a Python package with simple, hyperparameter-free methods for measuring and plotting calibration: `pip install relplot\\`."],"url":"http://arxiv.org/abs/2309.12236v1"}
{"created":"2023-09-21 16:28:42","title":"Bridging the Gaps of Both Modality and Language: Synchronous Bilingual CTC for Speech Translation and Speech Recognition","abstract":"In this study, we present synchronous bilingual Connectionist Temporal Classification (CTC), an innovative framework that leverages dual CTC to bridge the gaps of both modality and language in the speech translation (ST) task. Utilizing transcript and translation as concurrent objectives for CTC, our model bridges the gap between audio and text as well as between source and target languages. Building upon the recent advances in CTC application, we develop an enhanced variant, BiL-CTC+, that establishes new state-of-the-art performances on the MuST-C ST benchmarks under resource-constrained scenarios. Intriguingly, our method also yields significant improvements in speech recognition performance, revealing the effect of cross-lingual learning on transcription and demonstrating its broad applicability. The source code is available at https://github.com/xuchennlp/S2T.","sentences":["In this study, we present synchronous bilingual Connectionist Temporal Classification (CTC), an innovative framework that leverages dual CTC to bridge the gaps of both modality and language in the speech translation (ST) task.","Utilizing transcript and translation as concurrent objectives for CTC, our model bridges the gap between audio and text as well as between source and target languages.","Building upon the recent advances in CTC application, we develop an enhanced variant, BiL-CTC+, that establishes new state-of-the-art performances on the MuST-C ST benchmarks under resource-constrained scenarios.","Intriguingly, our method also yields significant improvements in speech recognition performance, revealing the effect of cross-lingual learning on transcription and demonstrating its broad applicability.","The source code is available at https://github.com/xuchennlp/S2T."],"url":"http://arxiv.org/abs/2309.12234v1"}
{"created":"2023-09-21 16:22:07","title":"Smooth Nash Equilibria: Algorithms and Complexity","abstract":"A fundamental shortcoming of the concept of Nash equilibrium is its computational intractability: approximating Nash equilibria in normal-form games is PPAD-hard. In this paper, inspired by the ideas of smoothed analysis, we introduce a relaxed variant of Nash equilibrium called $\\sigma$-smooth Nash equilibrium, for a smoothness parameter $\\sigma$. In a $\\sigma$-smooth Nash equilibrium, players only need to achieve utility at least as high as their best deviation to a $\\sigma$-smooth strategy, which is a distribution that does not put too much mass (as parametrized by $\\sigma$) on any fixed action. We distinguish two variants of $\\sigma$-smooth Nash equilibria: strong $\\sigma$-smooth Nash equilibria, in which players are required to play $\\sigma$-smooth strategies under equilibrium play, and weak $\\sigma$-smooth Nash equilibria, where there is no such requirement.   We show that both weak and strong $\\sigma$-smooth Nash equilibria have superior computational properties to Nash equilibria: when $\\sigma$ as well as an approximation parameter $\\epsilon$ and the number of players are all constants, there is a constant-time randomized algorithm to find a weak $\\epsilon$-approximate $\\sigma$-smooth Nash equilibrium in normal-form games. In the same parameter regime, there is a polynomial-time deterministic algorithm to find a strong $\\epsilon$-approximate $\\sigma$-smooth Nash equilibrium in a normal-form game. These results stand in contrast to the optimal algorithm for computing $\\epsilon$-approximate Nash equilibria, which cannot run in faster than quasipolynomial-time. We complement our upper bounds by showing that when either $\\sigma$ or $\\epsilon$ is an inverse polynomial, finding a weak $\\epsilon$-approximate $\\sigma$-smooth Nash equilibria becomes computationally intractable.","sentences":["A fundamental shortcoming of the concept of Nash equilibrium is its computational intractability: approximating Nash equilibria in normal-form games is PPAD-hard.","In this paper, inspired by the ideas of smoothed analysis, we introduce a relaxed variant of Nash equilibrium called $\\sigma$-smooth Nash equilibrium, for a smoothness parameter $\\sigma$. In a $\\sigma$-smooth Nash equilibrium, players only need to achieve utility at least as high as their best deviation to a $\\sigma$-smooth strategy, which is a distribution that does not put too much mass (as parametrized by $\\sigma$) on any fixed action.","We distinguish two variants of $\\sigma$-smooth Nash equilibria: strong $\\sigma$-smooth Nash equilibria, in which players are required to play $\\sigma$-smooth strategies under equilibrium play, and weak $\\sigma$-smooth Nash equilibria, where there is no such requirement.   ","We show that both weak and strong $\\sigma$-smooth Nash equilibria have superior computational properties to Nash equilibria: when $\\sigma$ as well as an approximation parameter $\\epsilon$ and the number of players are all constants, there is a constant-time randomized algorithm to find a weak $\\epsilon$-approximate $\\sigma$-smooth Nash equilibrium in normal-form games.","In the same parameter regime, there is a polynomial-time deterministic algorithm to find a strong $\\epsilon$-approximate $\\sigma$-smooth Nash equilibrium in a normal-form game.","These results stand in contrast to the optimal algorithm for computing $\\epsilon$-approximate Nash equilibria, which cannot run in faster than quasipolynomial-time.","We complement our upper bounds by showing that when either $\\sigma$ or $\\epsilon$ is an inverse polynomial, finding a weak $\\epsilon$-approximate $\\sigma$-smooth Nash equilibria becomes computationally intractable."],"url":"http://arxiv.org/abs/2309.12226v1"}
{"created":"2023-09-21 16:21:28","title":"Towards Answering Health-related Questions from Medical Videos: Datasets and Approaches","abstract":"The increase in the availability of online videos has transformed the way we access information and knowledge. A growing number of individuals now prefer instructional videos as they offer a series of step-by-step procedures to accomplish particular tasks. The instructional videos from the medical domain may provide the best possible visual answers to first aid, medical emergency, and medical education questions. Toward this, this paper is focused on answering health-related questions asked by the public by providing visual answers from medical videos. The scarcity of large-scale datasets in the medical domain is a key challenge that hinders the development of applications that can help the public with their health-related questions. To address this issue, we first proposed a pipelined approach to create two large-scale datasets: HealthVidQA-CRF and HealthVidQA-Prompt. Later, we proposed monomodal and multimodal approaches that can effectively provide visual answers from medical videos to natural language questions. We conducted a comprehensive analysis of the results, focusing on the impact of the created datasets on model training and the significance of visual features in enhancing the performance of the monomodal and multi-modal approaches. Our findings suggest that these datasets have the potential to enhance the performance of medical visual answer localization tasks and provide a promising future direction to further enhance the performance by using pre-trained language-vision models.","sentences":["The increase in the availability of online videos has transformed the way we access information and knowledge.","A growing number of individuals now prefer instructional videos as they offer a series of step-by-step procedures to accomplish particular tasks.","The instructional videos from the medical domain may provide the best possible visual answers to first aid, medical emergency, and medical education questions.","Toward this, this paper is focused on answering health-related questions asked by the public by providing visual answers from medical videos.","The scarcity of large-scale datasets in the medical domain is a key challenge that hinders the development of applications that can help the public with their health-related questions.","To address this issue, we first proposed a pipelined approach to create two large-scale datasets: HealthVidQA-CRF and HealthVidQA-Prompt.","Later, we proposed monomodal and multimodal approaches that can effectively provide visual answers from medical videos to natural language questions.","We conducted a comprehensive analysis of the results, focusing on the impact of the created datasets on model training and the significance of visual features in enhancing the performance of the monomodal and multi-modal approaches.","Our findings suggest that these datasets have the potential to enhance the performance of medical visual answer localization tasks and provide a promising future direction to further enhance the performance by using pre-trained language-vision models."],"url":"http://arxiv.org/abs/2309.12224v1"}
{"created":"2023-09-21 16:18:51","title":"De-authentication using Ambient Light Sensor","abstract":"While user authentication happens before initiating or resuming a login session, de-authentication detects the absence of a previously-authenticated user to revoke her currently active login session. The absence of proper de-authentication can lead to well-known lunchtime attacks, where a nearby adversary takes over a carelessly departed user's running login session. The existing solutions for automatic de-authentication have distinct practical limitations, e.g., extraordinary deployment requirements or high initial cost of external equipment.   In this paper, we propose \"DE-authentication using Ambient Light sensor\" (DEAL), a novel, inexpensive, fast, and user-friendly de-authentication approach. DEAL utilizes the built-in ambient light sensor of a modern computer to determine if the user is leaving her work-desk. DEAL, by design, is resilient to natural shifts in lighting conditions and can be configured to handle abrupt changes in ambient illumination (e.g., due to toggling of room lights). We collected data samples from 4800 sessions with 120 volunteers in 4 typical workplace settings and conducted a series of experiments to evaluate the quality of our proposed approach thoroughly. Our results show that DEAL can de-authenticate a departing user within 4 seconds with a hit rate of 89.15% and a fall-out of 7.35%. Finally, bypassing DEAL to launch a lunchtime attack is practically infeasible as it requires the attacker to either take the user's position within a few seconds or manipulate the sensor readings sophisticatedly in real-time.","sentences":["While user authentication happens before initiating or resuming a login session, de-authentication detects the absence of a previously-authenticated user to revoke her currently active login session.","The absence of proper de-authentication can lead to well-known lunchtime attacks, where a nearby adversary takes over a carelessly departed user's running login session.","The existing solutions for automatic de-authentication have distinct practical limitations, e.g., extraordinary deployment requirements or high initial cost of external equipment.   ","In this paper, we propose \"DE-authentication using Ambient Light sensor\" (DEAL), a novel, inexpensive, fast, and user-friendly de-authentication approach.","DEAL utilizes the built-in ambient light sensor of a modern computer to determine if the user is leaving her work-desk.","DEAL, by design, is resilient to natural shifts in lighting conditions and can be configured to handle abrupt changes in ambient illumination (e.g., due to toggling of room lights).","We collected data samples from 4800 sessions with 120 volunteers in 4 typical workplace settings and conducted a series of experiments to evaluate the quality of our proposed approach thoroughly.","Our results show that DEAL can de-authenticate a departing user within 4 seconds with a hit rate of 89.15% and a fall-out of 7.35%.","Finally, bypassing DEAL to launch a lunchtime attack is practically infeasible as it requires the attacker to either take the user's position within a few seconds or manipulate the sensor readings sophisticatedly in real-time."],"url":"http://arxiv.org/abs/2309.12220v1"}
{"created":"2023-09-21 16:18:33","title":"Generating robotic elliptical excisions with human-like tool-tissue interactions","abstract":"In surgery, the application of appropriate force levels is critical for the success and safety of a given procedure. While many studies are focused on measuring in situ forces, little attention has been devoted to relating these observed forces to surgical techniques. Answering questions like \"Can certain changes to a surgical technique result in lower forces and increased safety margins?\" could lead to improved surgical practice, and importantly, patient outcomes. However, such studies would require a large number of trials and professional surgeons, which is generally impractical to arrange. Instead, we show how robots can learn several variations of a surgical technique from a smaller number of surgical demonstrations and interpolate learnt behaviour via a parameterised skill model. This enables a large number of trials to be performed by a robotic system and the analysis of surgical techniques and their downstream effects on tissue. Here, we introduce a parameterised model of the elliptical excision skill and apply a Bayesian optimisation scheme to optimise the excision behaviour with respect to expert ratings, as well as individual characteristics of excision forces. Results show that the proposed framework can successfully align the generated robot behaviour with subjects across varying levels of proficiency in terms of excision forces.","sentences":["In surgery, the application of appropriate force levels is critical for the success and safety of a given procedure.","While many studies are focused on measuring in situ forces, little attention has been devoted to relating these observed forces to surgical techniques.","Answering questions like \"Can certain changes to a surgical technique result in lower forces and increased safety margins?\" could lead to improved surgical practice, and importantly, patient outcomes.","However, such studies would require a large number of trials and professional surgeons, which is generally impractical to arrange.","Instead, we show how robots can learn several variations of a surgical technique from a smaller number of surgical demonstrations and interpolate learnt behaviour via a parameterised skill model.","This enables a large number of trials to be performed by a robotic system and the analysis of surgical techniques and their downstream effects on tissue.","Here, we introduce a parameterised model of the elliptical excision skill and apply a Bayesian optimisation scheme to optimise the excision behaviour with respect to expert ratings, as well as individual characteristics of excision forces.","Results show that the proposed framework can successfully align the generated robot behaviour with subjects across varying levels of proficiency in terms of excision forces."],"url":"http://arxiv.org/abs/2309.12219v1"}
{"created":"2023-09-21 16:16:22","title":"Regionally Additive Models: Explainable-by-design models minimizing feature interactions","abstract":"Generalized Additive Models (GAMs) are widely used explainable-by-design models in various applications. GAMs assume that the output can be represented as a sum of univariate functions, referred to as components. However, this assumption fails in ML problems where the output depends on multiple features simultaneously. In these cases, GAMs fail to capture the interaction terms of the underlying function, leading to subpar accuracy. To (partially) address this issue, we propose Regionally Additive Models (RAMs), a novel class of explainable-by-design models. RAMs identify subregions within the feature space where interactions are minimized. Within these regions, it is more accurate to express the output as a sum of univariate functions (components). Consequently, RAMs fit one component per subregion of each feature instead of one component per feature. This approach yields a more expressive model compared to GAMs while retaining interpretability. The RAM framework consists of three steps. Firstly, we train a black-box model. Secondly, using Regional Effect Plots, we identify subregions where the black-box model exhibits near-local additivity. Lastly, we fit a GAM component for each identified subregion. We validate the effectiveness of RAMs through experiments on both synthetic and real-world datasets. The results confirm that RAMs offer improved expressiveness compared to GAMs while maintaining interpretability.","sentences":["Generalized Additive Models (GAMs) are widely used explainable-by-design models in various applications.","GAMs assume that the output can be represented as a sum of univariate functions, referred to as components.","However, this assumption fails in ML problems where the output depends on multiple features simultaneously.","In these cases, GAMs fail to capture the interaction terms of the underlying function, leading to subpar accuracy.","To (partially) address this issue, we propose Regionally Additive Models (RAMs), a novel class of explainable-by-design models.","RAMs identify subregions within the feature space where interactions are minimized.","Within these regions, it is more accurate to express the output as a sum of univariate functions (components).","Consequently, RAMs fit one component per subregion of each feature instead of one component per feature.","This approach yields a more expressive model compared to GAMs while retaining interpretability.","The RAM framework consists of three steps.","Firstly, we train a black-box model.","Secondly, using Regional Effect Plots, we identify subregions where the black-box model exhibits near-local additivity.","Lastly, we fit a GAM component for each identified subregion.","We validate the effectiveness of RAMs through experiments on both synthetic and real-world datasets.","The results confirm that RAMs offer improved expressiveness compared to GAMs while maintaining interpretability."],"url":"http://arxiv.org/abs/2309.12215v1"}
{"created":"2023-09-21 16:15:56","title":"Can We Reliably Improve the Robustness to Image Acquisition of Remote Sensing of PV Systems?","abstract":"Photovoltaic (PV) energy is crucial for the decarbonization of energy systems. Due to the lack of centralized data, remote sensing of rooftop PV installations is the best option to monitor the evolution of the rooftop PV installed fleet at a regional scale. However, current techniques lack reliability and are notably sensitive to shifts in the acquisition conditions. To overcome this, we leverage the wavelet scale attribution method (WCAM), which decomposes a model's prediction in the space-scale domain. The WCAM enables us to assess on which scales the representation of a PV model rests and provides insights to derive methods that improve the robustness to acquisition conditions, thus increasing trust in deep learning systems to encourage their use for the safe integration of clean energy in electric systems.","sentences":["Photovoltaic (PV) energy is crucial for the decarbonization of energy systems.","Due to the lack of centralized data, remote sensing of rooftop PV installations is the best option to monitor the evolution of the rooftop PV installed fleet at a regional scale.","However, current techniques lack reliability and are notably sensitive to shifts in the acquisition conditions.","To overcome this, we leverage the wavelet scale attribution method (WCAM), which decomposes a model's prediction in the space-scale domain.","The WCAM enables us to assess on which scales the representation of a PV model rests and provides insights to derive methods that improve the robustness to acquisition conditions, thus increasing trust in deep learning systems to encourage their use for the safe integration of clean energy in electric systems."],"url":"http://arxiv.org/abs/2309.12214v1"}
{"created":"2023-09-21 16:14:42","title":"SupeRBNN: Randomized Binary Neural Network Using Adiabatic Superconductor Josephson Devices","abstract":"Adiabatic Quantum-Flux-Parametron (AQFP) is a superconducting logic with extremely high energy efficiency. By employing the distinct polarity of current to denote logic `0' and `1', AQFP devices serve as excellent carriers for binary neural network (BNN) computations. Although recent research has made initial strides toward developing an AQFP-based BNN accelerator, several critical challenges remain, preventing the design from being a comprehensive solution. In this paper, we propose SupeRBNN, an AQFP-based randomized BNN acceleration framework that leverages software-hardware co-optimization to eventually make the AQFP devices a feasible solution for BNN acceleration. Specifically, we investigate the randomized behavior of the AQFP devices and analyze the impact of crossbar size on current attenuation, subsequently formulating the current amplitude into the values suitable for use in BNN computation. To tackle the accumulation problem and improve overall hardware performance, we propose a stochastic computing-based accumulation module and a clocking scheme adjustment-based circuit optimization method. We validate our SupeRBNN framework across various datasets and network architectures, comparing it with implementations based on different technologies, including CMOS, ReRAM, and superconducting RSFQ/ERSFQ. Experimental results demonstrate that our design achieves an energy efficiency of approximately 7.8x10^4 times higher than that of the ReRAM-based BNN framework while maintaining a similar level of model accuracy. Furthermore, when compared with superconductor-based counterparts, our framework demonstrates at least two orders of magnitude higher energy efficiency.","sentences":["Adiabatic Quantum-Flux-Parametron (AQFP) is a superconducting logic with extremely high energy efficiency.","By employing the distinct polarity of current to denote logic `0' and `1', AQFP devices serve as excellent carriers for binary neural network (BNN) computations.","Although recent research has made initial strides toward developing an AQFP-based BNN accelerator, several critical challenges remain, preventing the design from being a comprehensive solution.","In this paper, we propose SupeRBNN, an AQFP-based randomized BNN acceleration framework that leverages software-hardware co-optimization to eventually make the AQFP devices a feasible solution for BNN acceleration.","Specifically, we investigate the randomized behavior of the AQFP devices and analyze the impact of crossbar size on current attenuation, subsequently formulating the current amplitude into the values suitable for use in BNN computation.","To tackle the accumulation problem and improve overall hardware performance, we propose a stochastic computing-based accumulation module and a clocking scheme adjustment-based circuit optimization method.","We validate our SupeRBNN framework across various datasets and network architectures, comparing it with implementations based on different technologies, including CMOS, ReRAM, and superconducting RSFQ/ERSFQ.","Experimental results demonstrate that our design achieves an energy efficiency of approximately 7.8x10^4 times higher than that of the ReRAM-based BNN framework while maintaining a similar level of model accuracy.","Furthermore, when compared with superconductor-based counterparts, our framework demonstrates at least two orders of magnitude higher energy efficiency."],"url":"http://arxiv.org/abs/2309.12212v1"}
{"created":"2023-09-21 16:14:36","title":"Physics-informed State-space Neural Networks for Transport Phenomena","abstract":"This work introduces Physics-informed State-space neural network Models (PSMs), a novel solution to achieving real-time optimization, flexibility, and fault tolerance in autonomous systems, particularly in transport-dominated systems such as chemical, biomedical, and power plants. Traditional data-driven methods fall short due to a lack of physical constraints like mass conservation; PSMs address this issue by training deep neural networks with sensor data and physics-informing using components' Partial Differential Equations (PDEs), resulting in a physics-constrained, end-to-end differentiable forward dynamics model. Through two in silico experiments - a heated channel and a cooling system loop - we demonstrate that PSMs offer a more accurate approach than purely data-driven models.   Beyond accuracy, there are several compelling use cases for PSMs. In this work, we showcase two: the creation of a nonlinear supervisory controller through a sequentially updated state-space representation and the proposal of a diagnostic algorithm using residuals from each of the PDEs. The former demonstrates the ability of PSMs to handle both constant and time-dependent constraints, while the latter illustrates their value in system diagnostics and fault detection. We further posit that PSMs could serve as a foundation for Digital Twins, constantly updated digital representations of physical systems.","sentences":["This work introduces Physics-informed State-space neural network Models (PSMs), a novel solution to achieving real-time optimization, flexibility, and fault tolerance in autonomous systems, particularly in transport-dominated systems such as chemical, biomedical, and power plants.","Traditional data-driven methods fall short due to a lack of physical constraints like mass conservation; PSMs address this issue by training deep neural networks with sensor data and physics-informing using components' Partial Differential Equations (PDEs), resulting in a physics-constrained, end-to-end differentiable forward dynamics model.","Through two in silico experiments - a heated channel and a cooling system loop - we demonstrate that PSMs offer a more accurate approach than purely data-driven models.   ","Beyond accuracy, there are several compelling use cases for PSMs.","In this work, we showcase two: the creation of a nonlinear supervisory controller through a sequentially updated state-space representation and the proposal of a diagnostic algorithm using residuals from each of the PDEs.","The former demonstrates the ability of PSMs to handle both constant and time-dependent constraints, while the latter illustrates their value in system diagnostics and fault detection.","We further posit that PSMs could serve as a foundation for Digital Twins, constantly updated digital representations of physical systems."],"url":"http://arxiv.org/abs/2309.12211v1"}
{"created":"2023-09-21 16:11:38","title":"Boolformer: Symbolic Regression of Logic Functions with Transformers","abstract":"In this work, we introduce Boolformer, the first Transformer architecture trained to perform end-to-end symbolic regression of Boolean functions. First, we show that it can predict compact formulas for complex functions which were not seen during training, when provided a clean truth table. Then, we demonstrate its ability to find approximate expressions when provided incomplete and noisy observations. We evaluate the Boolformer on a broad set of real-world binary classification datasets, demonstrating its potential as an interpretable alternative to classic machine learning methods. Finally, we apply it to the widespread task of modelling the dynamics of gene regulatory networks. Using a recent benchmark, we show that Boolformer is competitive with state-of-the art genetic algorithms with a speedup of several orders of magnitude. Our code and models are available publicly.","sentences":["In this work, we introduce Boolformer, the first Transformer architecture trained to perform end-to-end symbolic regression of Boolean functions.","First, we show that it can predict compact formulas for complex functions which were not seen during training, when provided a clean truth table.","Then, we demonstrate its ability to find approximate expressions when provided incomplete and noisy observations.","We evaluate the Boolformer on a broad set of real-world binary classification datasets, demonstrating its potential as an interpretable alternative to classic machine learning methods.","Finally, we apply it to the widespread task of modelling the dynamics of gene regulatory networks.","Using a recent benchmark, we show that Boolformer is competitive with state-of-the art genetic algorithms with a speedup of several orders of magnitude.","Our code and models are available publicly."],"url":"http://arxiv.org/abs/2309.12207v1"}
{"created":"2023-09-21 16:11:00","title":"BOMs Away! Inside the Minds of Stakeholders: A Comprehensive Study of Bills of Materials for Software Systems","abstract":"Software Bills of Materials (SBOMs) have emerged as tools to facilitate the management of software dependencies, vulnerabilities, licenses, and the supply chain. While significant effort has been devoted to increasing SBOM awareness and developing SBOM formats and tools, recent studies have shown that SBOMs are still an early technology not yet adequately adopted in practice. Expanding on previous research, this paper reports a comprehensive study that investigates the current challenges stakeholders encounter when creating and using SBOMs. The study surveyed 138 practitioners belonging to five stakeholder groups (practitioners familiar with SBOMs, members of critical open source projects, AI/ML, cyber-physical systems, and legal practitioners) using differentiated questionnaires, and interviewed 8 survey respondents to gather further insights about their experience. We identified 12 major challenges facing the creation and use of SBOMs, including those related to the SBOM content, deficiencies in SBOM tools, SBOM maintenance and verification, and domain-specific challenges. We propose and discuss 4 actionable solutions to the identified challenges and present the major avenues for future research and development.","sentences":["Software Bills of Materials (SBOMs) have emerged as tools to facilitate the management of software dependencies, vulnerabilities, licenses, and the supply chain.","While significant effort has been devoted to increasing SBOM awareness and developing SBOM formats and tools, recent studies have shown that SBOMs are still an early technology not yet adequately adopted in practice.","Expanding on previous research, this paper reports a comprehensive study that investigates the current challenges stakeholders encounter when creating and using SBOMs.","The study surveyed 138 practitioners belonging to five stakeholder groups (practitioners familiar with SBOMs, members of critical open source projects, AI/ML, cyber-physical systems, and legal practitioners) using differentiated questionnaires, and interviewed 8 survey respondents to gather further insights about their experience.","We identified 12 major challenges facing the creation and use of SBOMs, including those related to the SBOM content, deficiencies in SBOM tools, SBOM maintenance and verification, and domain-specific challenges.","We propose and discuss 4 actionable solutions to the identified challenges and present the major avenues for future research and development."],"url":"http://arxiv.org/abs/2309.12206v1"}
{"created":"2023-09-21 16:01:32","title":"Empowering People with Intellectual and Developmental Disabilities through Cognitively Accessible Visualizations","abstract":"Data has transformative potential to empower people with Intellectual and Developmental Disabilities (IDD). However, conventional data visualizations often rely on complex cognitive processes, and existing approaches for day-to-day analysis scenarios fail to consider neurodivergent capabilities, creating barriers for people with IDD to access data and leading to even further marginalization. We argue that visualizations could be an equalizer for people with IDD to participate in data-driven conversations. Drawing on preliminary research findings and our experiences working with people with IDD and their data, we introduce and expand on the concept of cognitively accessible visualizations, unpack its meaning and roles in increasing IDD individuals' access to data, and discuss two immediate research objectives. Specifically, we argue that cognitively accessible visualizations should support people with IDD in personal data storytelling for effective self-advocacy and self-expression, and balance novelty and familiarity in data design to accommodate cognitive diversity and promote inclusivity.","sentences":["Data has transformative potential to empower people with Intellectual and Developmental Disabilities (IDD).","However, conventional data visualizations often rely on complex cognitive processes, and existing approaches for day-to-day analysis scenarios fail to consider neurodivergent capabilities, creating barriers for people with IDD to access data and leading to even further marginalization.","We argue that visualizations could be an equalizer for people with IDD to participate in data-driven conversations.","Drawing on preliminary research findings and our experiences working with people with IDD and their data, we introduce and expand on the concept of cognitively accessible visualizations, unpack its meaning and roles in increasing IDD individuals' access to data, and discuss two immediate research objectives.","Specifically, we argue that cognitively accessible visualizations should support people with IDD in personal data storytelling for effective self-advocacy and self-expression, and balance novelty and familiarity in data design to accommodate cognitive diversity and promote inclusivity."],"url":"http://arxiv.org/abs/2309.12194v1"}
{"created":"2023-09-21 15:54:33","title":"SG-Bot: Object Rearrangement via Coarse-to-Fine Robotic Imagination on Scene Graphs","abstract":"Object rearrangement is pivotal in robotic-environment interactions, representing a significant capability in embodied AI. In this paper, we present SG-Bot, a novel rearrangement framework that utilizes a coarse-to-fine scheme with a scene graph as the scene representation. Unlike previous methods that rely on either known goal priors or zero-shot large models, SG-Bot exemplifies lightweight, real-time, and user-controllable characteristics, seamlessly blending the consideration of commonsense knowledge with automatic generation capabilities. SG-Bot employs a three-fold procedure--observation, imagination, and execution--to adeptly address the task. Initially, objects are discerned and extracted from a cluttered scene during the observation. These objects are first coarsely organized and depicted within a scene graph, guided by either commonsense or user-defined criteria. Then, this scene graph subsequently informs a generative model, which forms a fine-grained goal scene considering the shape information from the initial scene and object semantics. Finally, for execution, the initial and envisioned goal scenes are matched to formulate robotic action policies. Experimental results demonstrate that SG-Bot outperforms competitors by a large margin.","sentences":["Object rearrangement is pivotal in robotic-environment interactions, representing a significant capability in embodied AI.","In this paper, we present SG-Bot, a novel rearrangement framework that utilizes a coarse-to-fine scheme with a scene graph as the scene representation.","Unlike previous methods that rely on either known goal priors or zero-shot large models, SG-Bot exemplifies lightweight, real-time, and user-controllable characteristics, seamlessly blending the consideration of commonsense knowledge with automatic generation capabilities.","SG-Bot employs a three-fold procedure--observation, imagination, and execution--to adeptly address the task.","Initially, objects are discerned and extracted from a cluttered scene during the observation.","These objects are first coarsely organized and depicted within a scene graph, guided by either commonsense or user-defined criteria.","Then, this scene graph subsequently informs a generative model, which forms a fine-grained goal scene considering the shape information from the initial scene and object semantics.","Finally, for execution, the initial and envisioned goal scenes are matched to formulate robotic action policies.","Experimental results demonstrate that SG-Bot outperforms competitors by a large margin."],"url":"http://arxiv.org/abs/2309.12188v1"}
{"created":"2023-09-21 15:50:04","title":"ORTexME: Occlusion-Robust Human Shape and Pose via Temporal Average Texture and Mesh Encoding","abstract":"In 3D human shape and pose estimation from a monocular video, models trained with limited labeled data cannot generalize well to videos with occlusion, which is common in the wild videos. The recent human neural rendering approaches focusing on novel view synthesis initialized by the off-the-shelf human shape and pose methods have the potential to correct the initial human shape. However, the existing methods have some drawbacks such as, erroneous in handling occlusion, sensitive to inaccurate human segmentation, and ineffective loss computation due to the non-regularized opacity field. To address these problems, we introduce ORTexME, an occlusion-robust temporal method that utilizes temporal information from the input video to better regularize the occluded body parts. While our ORTexME is based on NeRF, to determine the reliable regions for the NeRF ray sampling, we utilize our novel average texture learning approach to learn the average appearance of a person, and to infer a mask based on the average texture. In addition, to guide the opacity-field updates in NeRF to suppress blur and noise, we propose the use of human body mesh. The quantitative evaluation demonstrates that our method achieves significant improvement on the challenging multi-person 3DPW dataset, where our method achieves 1.8 P-MPJPE error reduction. The SOTA rendering-based methods fail and enlarge the error up to 5.6 on the same dataset.","sentences":["In 3D human shape and pose estimation from a monocular video, models trained with limited labeled data cannot generalize well to videos with occlusion, which is common in the wild videos.","The recent human neural rendering approaches focusing on novel view synthesis initialized by the off-the-shelf human shape and pose methods have the potential to correct the initial human shape.","However, the existing methods have some drawbacks such as, erroneous in handling occlusion, sensitive to inaccurate human segmentation, and ineffective loss computation due to the non-regularized opacity field.","To address these problems, we introduce ORTexME, an occlusion-robust temporal method that utilizes temporal information from the input video to better regularize the occluded body parts.","While our ORTexME is based on NeRF, to determine the reliable regions for the NeRF ray sampling, we utilize our novel average texture learning approach to learn the average appearance of a person, and to infer a mask based on the average texture.","In addition, to guide the opacity-field updates in NeRF to suppress blur and noise, we propose the use of human body mesh.","The quantitative evaluation demonstrates that our method achieves significant improvement on the challenging multi-person 3DPW dataset, where our method achieves 1.8 P-MPJPE error reduction.","The SOTA rendering-based methods fail and enlarge the error up to 5.6 on the same dataset."],"url":"http://arxiv.org/abs/2309.12183v1"}
{"created":"2023-09-21 15:46:01","title":"Autoregressive Sign Language Production: A Gloss-Free Approach with Discrete Representations","abstract":"Gloss-free Sign Language Production (SLP) offers a direct translation of spoken language sentences into sign language, bypassing the need for gloss intermediaries. This paper presents the Sign language Vector Quantization Network, a novel approach to SLP that leverages Vector Quantization to derive discrete representations from sign pose sequences. Our method, rooted in both manual and non-manual elements of signing, supports advanced decoding methods and integrates latent-level alignment for enhanced linguistic coherence. Through comprehensive evaluations, we demonstrate superior performance of our method over prior SLP methods and highlight the reliability of Back-Translation and Fr\\'echet Gesture Distance as evaluation metrics.","sentences":["Gloss-free Sign Language Production (SLP) offers a direct translation of spoken language sentences into sign language, bypassing the need for gloss intermediaries.","This paper presents the Sign language Vector Quantization Network, a novel approach to SLP that leverages Vector Quantization to derive discrete representations from sign pose sequences.","Our method, rooted in both manual and non-manual elements of signing, supports advanced decoding methods and integrates latent-level alignment for enhanced linguistic coherence.","Through comprehensive evaluations, we demonstrate superior performance of our method over prior SLP methods and highlight the reliability of Back-Translation and Fr\\'echet Gesture Distance as evaluation metrics."],"url":"http://arxiv.org/abs/2309.12179v1"}
{"created":"2023-09-21 15:36:06","title":"Explainable Artificial Intelligence for Drug Discovery and Development -- A Comprehensive Survey","abstract":"The field of drug discovery has experienced a remarkable transformation with the advent of artificial intelligence (AI) and machine learning (ML) technologies. However, as these AI and ML models are becoming more complex, there is a growing need for transparency and interpretability of the models. Explainable Artificial Intelligence (XAI) is a novel approach that addresses this issue and provides a more interpretable understanding of the predictions made by machine learning models. In recent years, there has been an increasing interest in the application of XAI techniques to drug discovery. This review article provides a comprehensive overview of the current state-of-the-art in XAI for drug discovery, including various XAI methods, their application in drug discovery, and the challenges and limitations of XAI techniques in drug discovery. The article also covers the application of XAI in drug discovery, including target identification, compound design, and toxicity prediction. Furthermore, the article suggests potential future research directions for the application of XAI in drug discovery. The aim of this review article is to provide a comprehensive understanding of the current state of XAI in drug discovery and its potential to transform the field.","sentences":["The field of drug discovery has experienced a remarkable transformation with the advent of artificial intelligence (AI) and machine learning (ML) technologies.","However, as these AI and ML models are becoming more complex, there is a growing need for transparency and interpretability of the models.","Explainable Artificial Intelligence (XAI) is a novel approach that addresses this issue and provides a more interpretable understanding of the predictions made by machine learning models.","In recent years, there has been an increasing interest in the application of XAI techniques to drug discovery.","This review article provides a comprehensive overview of the current state-of-the-art in XAI for drug discovery, including various XAI methods, their application in drug discovery, and the challenges and limitations of XAI techniques in drug discovery.","The article also covers the application of XAI in drug discovery, including target identification, compound design, and toxicity prediction.","Furthermore, the article suggests potential future research directions for the application of XAI in drug discovery.","The aim of this review article is to provide a comprehensive understanding of the current state of XAI in drug discovery and its potential to transform the field."],"url":"http://arxiv.org/abs/2309.12177v1"}
{"created":"2023-09-21 15:28:04","title":"SANPO: A Scene Understanding, Accessibility, Navigation, Pathfinding, Obstacle Avoidance Dataset","abstract":"We introduce SANPO, a large-scale egocentric video dataset focused on dense prediction in outdoor environments. It contains stereo video sessions collected across diverse outdoor environments, as well as rendered synthetic video sessions. (Synthetic data was provided by Parallel Domain.) All sessions have (dense) depth and odometry labels. All synthetic sessions and a subset of real sessions have temporally consistent dense panoptic segmentation labels. To our knowledge, this is the first human egocentric video dataset with both large scale dense panoptic segmentation and depth annotations. In addition to the dataset we also provide zero-shot baselines and SANPO benchmarks for future research. We hope that the challenging nature of SANPO will help advance the state-of-the-art in video segmentation, depth estimation, multi-task visual modeling, and synthetic-to-real domain adaptation, while enabling human navigation systems.   SANPO is available here: https://google-research-datasets.github.io/sanpo_dataset/","sentences":["We introduce SANPO, a large-scale egocentric video dataset focused on dense prediction in outdoor environments.","It contains stereo video sessions collected across diverse outdoor environments, as well as rendered synthetic video sessions.","(Synthetic data was provided by Parallel Domain.)","All sessions have (dense) depth and odometry labels.","All synthetic sessions and a subset of real sessions have temporally consistent dense panoptic segmentation labels.","To our knowledge, this is the first human egocentric video dataset with both large scale dense panoptic segmentation and depth annotations.","In addition to the dataset we also provide zero-shot baselines and SANPO benchmarks for future research.","We hope that the challenging nature of SANPO will help advance the state-of-the-art in video segmentation, depth estimation, multi-task visual modeling, and synthetic-to-real domain adaptation, while enabling human navigation systems.   ","SANPO is available here: https://google-research-datasets.github.io/sanpo_dataset/"],"url":"http://arxiv.org/abs/2309.12172v1"}
{"created":"2023-09-21 15:26:27","title":"A Click Ahead: Real-Time Forecasting of Keyboard and Mouse Actions using RNNs and Computer Vision","abstract":"Computer input is more complex than a sequence of single mouse clicks and keyboard presses. We introduce a novel method to identify and represent the user interactions and build a system which predicts - in real-time - the action a user is most likely going to take next. For this, a recurrent neural network (RNN) is trained on a person's usage of the computer. We demonstrate that it is enough to train the RNN on a user's activity over approximately a week to achieve an accuracy of 34.63 % when predicting the next action from a set of almost 500 possible actions. Specific examples for how these predictions may be leveraged to build tools for improving and speeding up workflows of computer users are discussed.","sentences":["Computer input is more complex than a sequence of single mouse clicks and keyboard presses.","We introduce a novel method to identify and represent the user interactions and build a system which predicts - in real-time - the action a user is most likely going to take next.","For this, a recurrent neural network (RNN) is trained on a person's usage of the computer.","We demonstrate that it is enough to train the RNN on a user's activity over approximately a week to achieve an accuracy of 34.63 % when predicting the next action from a set of almost 500 possible actions.","Specific examples for how these predictions may be leveraged to build tools for improving and speeding up workflows of computer users are discussed."],"url":"http://arxiv.org/abs/2309.12170v1"}
{"created":"2023-09-21 15:26:06","title":"Estimation of the angular position of a two-wheeled balancing robot using a real IMU with selected filters","abstract":"A low-cost measurement system using filtering of measurements for two-wheeled balancing robot stabilisation purposes has been addressed in this paper. In particular, a measurement system based on gyroscope, accelerometer, and encoder has been considered. The measurements have been corrected for deterministic disturbances and then filtered with Kalman, $\\alpha$-$\\beta$ type, and complementary filters. A quantitative assessment of selected filters has been given. As a result, the complete structure of a measurement system has been obtained. The performance of the proposed measurement system has been validated experimentally by using a dedicated research rig.","sentences":["A low-cost measurement system using filtering of measurements for two-wheeled balancing robot stabilisation purposes has been addressed in this paper.","In particular, a measurement system based on gyroscope, accelerometer, and encoder has been considered.","The measurements have been corrected for deterministic disturbances and then filtered with Kalman, $\\alpha$-$\\beta$ type, and complementary filters.","A quantitative assessment of selected filters has been given.","As a result, the complete structure of a measurement system has been obtained.","The performance of the proposed measurement system has been validated experimentally by using a dedicated research rig."],"url":"http://arxiv.org/abs/2309.12169v1"}
{"created":"2023-09-21 15:25:46","title":"This is the Table I Want! Interactive Data Transformation on Desktop and in Virtual Reality","abstract":"Data transformation is an essential step in data science. While experts primarily use programming to transform their data, there is an increasing need to support non-programmers with user interface-based tools. With the rapid development in interaction techniques and computing environments, we report our empirical findings about the effects of interaction techniques and environments on performing data transformation tasks. Specifically, we studied the potential benefits of direct interaction and virtual reality (VR) for data transformation. We compared gesture interaction versus a standard WIMP user interface, each on the desktop and in VR. With the tested data and tasks, we found time performance was similar between desktop and VR. Meanwhile, VR demonstrates preliminary evidence to better support provenance and sense-making throughout the data transformation process. Our exploration of performing data transformation in VR also provides initial affirmation for enabling an iterative and fully immersive data science workflow.","sentences":["Data transformation is an essential step in data science.","While experts primarily use programming to transform their data, there is an increasing need to support non-programmers with user interface-based tools.","With the rapid development in interaction techniques and computing environments, we report our empirical findings about the effects of interaction techniques and environments on performing data transformation tasks.","Specifically, we studied the potential benefits of direct interaction and virtual reality (VR) for data transformation.","We compared gesture interaction versus a standard WIMP user interface, each on the desktop and in VR.","With the tested data and tasks, we found time performance was similar between desktop and VR.","Meanwhile, VR demonstrates preliminary evidence to better support provenance and sense-making throughout the data transformation process.","Our exploration of performing data transformation in VR also provides initial affirmation for enabling an iterative and fully immersive data science workflow."],"url":"http://arxiv.org/abs/2309.12168v1"}
{"created":"2023-09-21 15:25:18","title":"Revealing Performance Issues in Server-side WebAssembly Runtimes via Differential Testing","abstract":"WebAssembly (Wasm) is a bytecode format originally serving as a compilation target for Web applications. It has recently been used increasingly on the server side, e.g., providing a safer, faster, and more portable alternative to Linux containers. With the popularity of server-side Wasm applications, it is essential to study performance issues (i.e., abnormal latency) in Wasm runtimes, as they may cause a significant impact on server-side applications. However, there is still a lack of attention to performance issues in server-side Wasm runtimes. In this paper, we design a novel differential testing approach WarpDiff to identify performance issues in server-side Wasm runtimes. The key insight is that in normal cases, the execution time of the same test case on different Wasm runtimes should follow an oracle ratio. We identify abnormal cases where the execution time ratio significantly deviates from the oracle ratio and subsequently locate the Wasm runtimes that cause the performance issues. We apply WarpDiff to test five popular server-side Wasm runtimes using 123 test cases from the LLVM test suite and demonstrate the top 10 abnormal cases we identified. We further conduct an in-depth analysis of these abnormal cases and summarize seven performance issues, all of which have been confirmed by the developers. We hope our work can inspire future investigation on improving Wasm runtime implementation and thus promoting the development of server-side Wasm applications.","sentences":["WebAssembly (Wasm) is a bytecode format originally serving as a compilation target for Web applications.","It has recently been used increasingly on the server side, e.g., providing a safer, faster, and more portable alternative to Linux containers.","With the popularity of server-side Wasm applications, it is essential to study performance issues (i.e., abnormal latency) in Wasm runtimes, as they may cause a significant impact on server-side applications.","However, there is still a lack of attention to performance issues in server-side Wasm runtimes.","In this paper, we design a novel differential testing approach WarpDiff to identify performance issues in server-side Wasm runtimes.","The key insight is that in normal cases, the execution time of the same test case on different Wasm runtimes should follow an oracle ratio.","We identify abnormal cases where the execution time ratio significantly deviates from the oracle ratio and subsequently locate the Wasm runtimes that cause the performance issues.","We apply WarpDiff to test five popular server-side Wasm runtimes using 123 test cases from the LLVM test suite and demonstrate the top 10 abnormal cases we identified.","We further conduct an in-depth analysis of these abnormal cases and summarize seven performance issues, all of which have been confirmed by the developers.","We hope our work can inspire future investigation on improving Wasm runtime implementation and thus promoting the development of server-side Wasm applications."],"url":"http://arxiv.org/abs/2309.12167v1"}
{"created":"2023-09-21 15:22:04","title":"Stratified Type Theory","abstract":"To exploit the expressivity of being able to refer to the type of types, such as for large elimination, dependent type systems will either employ a universe hierarchy or else contend with an inconsistent type-in-type rule. However, these are not be the only possible options. Taking inspiration from Stratified System F, we introduce Stratified Type Theory (StraTT), where rather than stratifying universes by levels, we stratify typing judgements and restrict the domain of dependent function types to some fixed level strictly lower than that of the overall type. Even in the presence of type-in-type, this restriction suffices to enforce consistency of the system.   We explore the expressivity of several extensions atop this design. First, the subsystem subStraTT employs McBride's crude-but-effective stratification (also known as displacement) as a simple form of level polymorphism where top-level definitions can be displaced uniformly to any higher level as needed, which is valid due to level cumulativity and plays well with stratified judgements. Second, to recover some expressivity lost due to the restriction on dependent function domains, the full StraTT system includes a separate nondependent function type with floating domains, whose level instead matches that of the overall type. Finally, we have implemented a prototype type checker for StraTT extended with datatypes along with a small type checked core library.   While it's possible to show that the subsystem is consistent, showing consistency for the full system with floating nondependent functions remains open. Nevertheless, we believe that the full system is also consistent and have mechanized a syntactic proof of subject reduction. Furthermore, we use our implementation to investigate various well-known type-theoretic type-in-type paradoxes. These examples all fail to type check in expected ways as evidence towards consistency.","sentences":["To exploit the expressivity of being able to refer to the type of types, such as for large elimination, dependent type systems will either employ a universe hierarchy or else contend with an inconsistent type-in-type rule.","However, these are not be the only possible options.","Taking inspiration from Stratified System F, we introduce Stratified Type Theory (StraTT), where rather than stratifying universes by levels, we stratify typing judgements and restrict the domain of dependent function types to some fixed level strictly lower than that of the overall type.","Even in the presence of type-in-type, this restriction suffices to enforce consistency of the system.   ","We explore the expressivity of several extensions atop this design.","First, the subsystem subStraTT employs McBride's crude-but-effective stratification (also known as displacement) as a simple form of level polymorphism where top-level definitions can be displaced uniformly to any higher level as needed, which is valid due to level cumulativity and plays well with stratified judgements.","Second, to recover some expressivity lost due to the restriction on dependent function domains, the full StraTT system includes a separate nondependent function type with floating domains, whose level instead matches that of the overall type.","Finally, we have implemented a prototype type checker for StraTT extended with datatypes along with a small type checked core library.   ","While it's possible to show that the subsystem is consistent, showing consistency for the full system with floating nondependent functions remains open.","Nevertheless, we believe that the full system is also consistent and have mechanized a syntactic proof of subject reduction.","Furthermore, we use our implementation to investigate various well-known type-theoretic type-in-type paradoxes.","These examples all fail to type check in expected ways as evidence towards consistency."],"url":"http://arxiv.org/abs/2309.12164v1"}
{"created":"2023-09-21 15:16:58","title":"Code Soliloquies for Accurate Calculations in Large Language Models","abstract":"High-quality conversational datasets are integral to the successful development of Intelligent Tutoring Systems (ITS) that employ a Large Language Model (LLM) backend. These datasets, when used to fine-tune the LLM backend, significantly enhance the quality of interactions between students and ITS. A common strategy for developing these datasets involves generating synthetic student-teacher dialogues using advanced GPT-4 models. However, challenges arise when these dialogues demand complex calculations, common in subjects like physics. Despite its advanced capabilities, GPT-4's performance falls short in reliably handling even simple multiplication tasks, marking a significant limitation in its utility for these subjects. To address these challenges, this paper introduces an innovative stateful prompt design. Our approach generates a mock conversation between a student and a tutorbot, both roles simulated by GPT-4. Each student response triggers a soliloquy (an inner monologue) in the GPT-tutorbot, which assesses whether its response would necessitate calculations. If so, it proceeds to script the required code in Python and then uses the resulting output to construct its response to the student. Our approach notably enhances the quality of synthetic conversation datasets, especially for subjects that are calculation-intensive. Our findings show that our Higgs model -- a LLaMA finetuned with datasets generated through our novel stateful prompt design -- proficiently utilizes Python for computations. Consequently, finetuning with our datasets enriched with code soliloquies enhances not just the accuracy but also the computational reliability of Higgs' responses.","sentences":["High-quality conversational datasets are integral to the successful development of Intelligent Tutoring Systems (ITS) that employ a Large Language Model (LLM) backend.","These datasets, when used to fine-tune the LLM backend, significantly enhance the quality of interactions between students and ITS.","A common strategy for developing these datasets involves generating synthetic student-teacher dialogues using advanced GPT-4 models.","However, challenges arise when these dialogues demand complex calculations, common in subjects like physics.","Despite its advanced capabilities, GPT-4's performance falls short in reliably handling even simple multiplication tasks, marking a significant limitation in its utility for these subjects.","To address these challenges, this paper introduces an innovative stateful prompt design.","Our approach generates a mock conversation between a student and a tutorbot, both roles simulated by GPT-4.","Each student response triggers a soliloquy (an inner monologue) in the GPT-tutorbot, which assesses whether its response would necessitate calculations.","If so, it proceeds to script the required code in Python and then uses the resulting output to construct its response to the student.","Our approach notably enhances the quality of synthetic conversation datasets, especially for subjects that are calculation-intensive.","Our findings show that our Higgs model -- a LLaMA finetuned with datasets generated through our novel stateful prompt design -- proficiently utilizes Python for computations.","Consequently, finetuning with our datasets enriched with code soliloquies enhances not just the accuracy but also the computational reliability of Higgs' responses."],"url":"http://arxiv.org/abs/2309.12161v1"}
{"created":"2023-09-21 15:13:35","title":"Information Forensics and Security: A quarter-century-long journey","abstract":"Information Forensics and Security (IFS) is an active R&D area whose goal is to ensure that people use devices, data, and intellectual properties for authorized purposes and to facilitate the gathering of solid evidence to hold perpetrators accountable. For over a quarter century since the 1990s, the IFS research area has grown tremendously to address the societal needs of the digital information era. The IEEE Signal Processing Society (SPS) has emerged as an important hub and leader in this area, and the article below celebrates some landmark technical contributions. In particular, we highlight the major technological advances on some selected focus areas in the field developed in the last 25 years from the research community and present future trends.","sentences":["Information Forensics and Security (IFS) is an active R&D area whose goal is to ensure that people use devices, data, and intellectual properties for authorized purposes and to facilitate the gathering of solid evidence to hold perpetrators accountable.","For over a quarter century since the 1990s, the IFS research area has grown tremendously to address the societal needs of the digital information era.","The IEEE Signal Processing Society (SPS) has emerged as an important hub and leader in this area, and the article below celebrates some landmark technical contributions.","In particular, we highlight the major technological advances on some selected focus areas in the field developed in the last 25 years from the research community and present future trends."],"url":"http://arxiv.org/abs/2309.12159v1"}
{"created":"2023-09-21 15:11:16","title":"Towards Robust and Truly Large-Scale Audio-Sheet Music Retrieval","abstract":"A range of applications of multi-modal music information retrieval is centred around the problem of connecting large collections of sheet music (images) to corresponding audio recordings, that is, identifying pairs of audio and score excerpts that refer to the same musical content. One of the typical and most recent approaches to this task employs cross-modal deep learning architectures to learn joint embedding spaces that link the two distinct modalities - audio and sheet music images. While there has been steady improvement on this front over the past years, a number of open problems still prevent large-scale employment of this methodology. In this article we attempt to provide an insightful examination of the current developments on audio-sheet music retrieval via deep learning methods. We first identify a set of main challenges on the road towards robust and large-scale cross-modal music retrieval in real scenarios. We then highlight the steps we have taken so far to address some of these challenges, documenting step-by-step improvement along several dimensions. We conclude by analysing the remaining challenges and present ideas for solving these, in order to pave the way to a unified and robust methodology for cross-modal music retrieval.","sentences":["A range of applications of multi-modal music information retrieval is centred around the problem of connecting large collections of sheet music (images) to corresponding audio recordings, that is, identifying pairs of audio and score excerpts that refer to the same musical content.","One of the typical and most recent approaches to this task employs cross-modal deep learning architectures to learn joint embedding spaces that link the two distinct modalities - audio and sheet music images.","While there has been steady improvement on this front over the past years, a number of open problems still prevent large-scale employment of this methodology.","In this article we attempt to provide an insightful examination of the current developments on audio-sheet music retrieval via deep learning methods.","We first identify a set of main challenges on the road towards robust and large-scale cross-modal music retrieval in real scenarios.","We then highlight the steps we have taken so far to address some of these challenges, documenting step-by-step improvement along several dimensions.","We conclude by analysing the remaining challenges and present ideas for solving these, in order to pave the way to a unified and robust methodology for cross-modal music retrieval."],"url":"http://arxiv.org/abs/2309.12158v1"}
{"created":"2023-09-21 15:05:52","title":"Semantics for a Turing-complete Reversible Programming Language with Inductive Types","abstract":"This paper is concerned with the expressivity and denotational semantics of a functional higher-order reversible programming language based on Theseus. In this language, pattern-matching is used to ensure the reversibility of functions. We show how one can encode any Reversible Turing Machine in said language. We then build a sound and adequate categorical semantics based on join inverse categories, with additional structures to capture pattern-matching. We then derive a full completeness result, stating that any computable, partial injective function is the image of a term in the language.","sentences":["This paper is concerned with the expressivity and denotational semantics of a functional higher-order reversible programming language based on Theseus.","In this language, pattern-matching is used to ensure the reversibility of functions.","We show how one can encode any Reversible Turing Machine in said language.","We then build a sound and adequate categorical semantics based on join inverse categories, with additional structures to capture pattern-matching.","We then derive a full completeness result, stating that any computable, partial injective function is the image of a term in the language."],"url":"http://arxiv.org/abs/2309.12151v1"}
{"created":"2023-09-21 15:04:50","title":"Performance Model for Similarity Caching","abstract":"Similarity caching allows requests for an item to be served by a similar item. Applications include recommendation systems, multimedia retrieval, and machine learning. Recently, many similarity caching policies have been proposed, like SIM-LRU and RND-LRU, but the performance analysis of their hit rate is still wanting. In this paper, we show how to extend the popular time-to-live approximation in classic caching to similarity caching. In particular, we propose a method to estimate the hit rate of the similarity caching policy RND-LRU. Our method, the RND-TTL approximation, introduces the RND-TTL cache model and then tunes its parameters in such a way to mimic the behavior of RND-LRU. The parameter tuning involves solving a fixed point system of equations for which we provide an algorithm for numerical resolution and sufficient conditions for its convergence. Our approach for approximating the hit rate of RND-LRU is evaluated on both synthetic and real world traces.","sentences":["Similarity caching allows requests for an item to be served by a similar item.","Applications include recommendation systems, multimedia retrieval, and machine learning.","Recently, many similarity caching policies have been proposed, like SIM-LRU and RND-LRU, but the performance analysis of their hit rate is still wanting.","In this paper, we show how to extend the popular time-to-live approximation in classic caching to similarity caching.","In particular, we propose a method to estimate the hit rate of the similarity caching policy RND-LRU.","Our method, the RND-TTL approximation, introduces the RND-TTL cache model and then tunes its parameters in such a way to mimic the behavior of RND-LRU.","The parameter tuning involves solving a fixed point system of equations for which we provide an algorithm for numerical resolution and sufficient conditions for its convergence.","Our approach for approximating the hit rate of RND-LRU is evaluated on both synthetic and real world traces."],"url":"http://arxiv.org/abs/2309.12149v1"}
{"created":"2023-09-21 15:04:42","title":"Neural Modelling of Dynamic Systems with Time Delays Based on an Adjusted NEAT Algorithm","abstract":"A problem related to the development of an algorithm designed to find an architecture of artificial neural network used for black-box modelling of dynamic systems with time delays has been addressed in this paper. The proposed algorithm is based on a well-known NeuroEvolution of Augmenting Topologies (NEAT) algorithm. The NEAT algorithm has been adjusted by allowing additional connections within an artificial neural network and developing original specialised evolutionary operators. This resulted in a compromise between the size of neural network and its accuracy in capturing the response of the mathematical model under which it has been learnt. The research involved an extended validation study based on data generated from a mathematical model of an exemplary system as well as the fast processes occurring in a pressurised water nuclear reactor. The obtaining simulation results demonstrate the high effectiveness of the devised neural (black-box) models of dynamic systems with time delays.","sentences":["A problem related to the development of an algorithm designed to find an architecture of artificial neural network used for black-box modelling of dynamic systems with time delays has been addressed in this paper.","The proposed algorithm is based on a well-known NeuroEvolution of Augmenting Topologies (NEAT) algorithm.","The NEAT algorithm has been adjusted by allowing additional connections within an artificial neural network and developing original specialised evolutionary operators.","This resulted in a compromise between the size of neural network and its accuracy in capturing the response of the mathematical model under which it has been learnt.","The research involved an extended validation study based on data generated from a mathematical model of an exemplary system as well as the fast processes occurring in a pressurised water nuclear reactor.","The obtaining simulation results demonstrate the high effectiveness of the devised neural (black-box) models of dynamic systems with time delays."],"url":"http://arxiv.org/abs/2309.12148v1"}
{"created":"2023-09-21 15:00:31","title":"Unsupervised Domain Adaptation for Self-Driving from Past Traversal Features","abstract":"The rapid development of 3D object detection systems for self-driving cars has significantly improved accuracy. However, these systems struggle to generalize across diverse driving environments, which can lead to safety-critical failures in detecting traffic participants. To address this, we propose a method that utilizes unlabeled repeated traversals of multiple locations to adapt object detectors to new driving environments. By incorporating statistics computed from repeated LiDAR scans, we guide the adaptation process effectively. Our approach enhances LiDAR-based detection models using spatial quantized historical features and introduces a lightweight regression head to leverage the statistics for feature regularization. Additionally, we leverage the statistics for a novel self-training process to stabilize the training. The framework is detector model-agnostic and experiments on real-world datasets demonstrate significant improvements, achieving up to a 20-point performance gain, especially in detecting pedestrians and distant objects. Code is available at https://github.com/zhangtravis/Hist-DA.","sentences":["The rapid development of 3D object detection systems for self-driving cars has significantly improved accuracy.","However, these systems struggle to generalize across diverse driving environments, which can lead to safety-critical failures in detecting traffic participants.","To address this, we propose a method that utilizes unlabeled repeated traversals of multiple locations to adapt object detectors to new driving environments.","By incorporating statistics computed from repeated LiDAR scans, we guide the adaptation process effectively.","Our approach enhances LiDAR-based detection models using spatial quantized historical features and introduces a lightweight regression head to leverage the statistics for feature regularization.","Additionally, we leverage the statistics for a novel self-training process to stabilize the training.","The framework is detector model-agnostic and experiments on real-world datasets demonstrate significant improvements, achieving up to a 20-point performance gain, especially in detecting pedestrians and distant objects.","Code is available at https://github.com/zhangtravis/Hist-DA."],"url":"http://arxiv.org/abs/2309.12140v1"}
{"created":"2023-09-21 14:59:36","title":"On the relationship between Benchmarking, Standards and Certification in Robotics and AI","abstract":"Benchmarking, standards and certification are closely related processes. Standards can provide normative requirements that robotics and AI systems may or may not conform to. Certification generally relies upon conformance with one or more standards as the key determinant of granting a certificate to operate. And benchmarks are sets of standardised tests against which robots and AI systems can be measured. Benchmarks therefore can be thought of as informal standards. In this paper we will develop these themes with examples from benchmarking, standards and certification, and argue that these three linked processes are not only useful but vital to the broader practice of Responsible Innovation.","sentences":["Benchmarking, standards and certification are closely related processes.","Standards can provide normative requirements that robotics and AI systems may or may not conform to.","Certification generally relies upon conformance with one or more standards as the key determinant of granting a certificate to operate.","And benchmarks are sets of standardised tests against which robots and AI systems can be measured.","Benchmarks therefore can be thought of as informal standards.","In this paper we will develop these themes with examples from benchmarking, standards and certification, and argue that these three linked processes are not only useful but vital to the broader practice of Responsible Innovation."],"url":"http://arxiv.org/abs/2309.12139v1"}
{"created":"2023-09-21 14:58:50","title":"OSN-MDAD: Machine Translation Dataset for Arabic Multi-Dialectal Conversations on Online Social Media","abstract":"While resources for English language are fairly sufficient to understand content on social media, similar resources in Arabic are still immature. The main reason that the resources in Arabic are insufficient is that Arabic has many dialects in addition to the standard version (MSA). Arabs do not use MSA in their daily communications; rather, they use dialectal versions. Unfortunately, social users transfer this phenomenon into their use of social media platforms, which in turn has raised an urgent need for building suitable AI models for language-dependent applications. Existing machine translation (MT) systems designed for MSA fail to work well with Arabic dialects. In light of this, it is necessary to adapt to the informal nature of communication on social networks by developing MT systems that can effectively handle the various dialects of Arabic. Unlike for MSA that shows advanced progress in MT systems, little effort has been exerted to utilize Arabic dialects for MT systems. While few attempts have been made to build translation datasets for dialectal Arabic, they are domain dependent and are not OSN cultural-language friendly. In this work, we attempt to alleviate these limitations by proposing an online social network-based multidialect Arabic dataset that is crafted by contextually translating English tweets into four Arabic dialects: Gulf, Yemeni, Iraqi, and Levantine. To perform the translation, we followed our proposed guideline framework for content translation, which could be universally applicable for translation between foreign languages and local dialects. We validated the authenticity of our proposed dataset by developing neural MT models for four Arabic dialects. Our results have shown a superior performance of our NMT models trained using our dataset. We believe that our dataset can reliably serve as an Arabic multidialectal translation dataset for informal MT tasks.","sentences":["While resources for English language are fairly sufficient to understand content on social media, similar resources in Arabic are still immature.","The main reason that the resources in Arabic are insufficient is that Arabic has many dialects in addition to the standard version (MSA).","Arabs do not use MSA in their daily communications; rather, they use dialectal versions.","Unfortunately, social users transfer this phenomenon into their use of social media platforms, which in turn has raised an urgent need for building suitable AI models for language-dependent applications.","Existing machine translation (MT) systems designed for MSA fail to work well with Arabic dialects.","In light of this, it is necessary to adapt to the informal nature of communication on social networks by developing MT systems that can effectively handle the various dialects of Arabic.","Unlike for MSA that shows advanced progress in MT systems, little effort has been exerted to utilize Arabic dialects for MT systems.","While few attempts have been made to build translation datasets for dialectal Arabic, they are domain dependent and are not OSN cultural-language friendly.","In this work, we attempt to alleviate these limitations by proposing an online social network-based multidialect Arabic dataset that is crafted by contextually translating English tweets into four Arabic dialects: Gulf, Yemeni, Iraqi, and Levantine.","To perform the translation, we followed our proposed guideline framework for content translation, which could be universally applicable for translation between foreign languages and local dialects.","We validated the authenticity of our proposed dataset by developing neural MT models for four Arabic dialects.","Our results have shown a superior performance of our NMT models trained using our dataset.","We believe that our dataset can reliably serve as an Arabic multidialectal translation dataset for informal MT tasks."],"url":"http://arxiv.org/abs/2309.12137v1"}
{"created":"2023-09-21 14:54:48","title":"Self-Supervised Contrastive Learning for Robust Audio-Sheet Music Retrieval Systems","abstract":"Linking sheet music images to audio recordings remains a key problem for the development of efficient cross-modal music retrieval systems. One of the fundamental approaches toward this task is to learn a cross-modal embedding space via deep neural networks that is able to connect short snippets of audio and sheet music. However, the scarcity of annotated data from real musical content affects the capability of such methods to generalize to real retrieval scenarios. In this work, we investigate whether we can mitigate this limitation with self-supervised contrastive learning, by exposing a network to a large amount of real music data as a pre-training step, by contrasting randomly augmented views of snippets of both modalities, namely audio and sheet images. Through a number of experiments on synthetic and real piano data, we show that pre-trained models are able to retrieve snippets with better precision in all scenarios and pre-training configurations. Encouraged by these results, we employ the snippet embeddings in the higher-level task of cross-modal piece identification and conduct more experiments on several retrieval configurations. In this task, we observe that the retrieval quality improves from 30% up to 100% when real music data is present. We then conclude by arguing for the potential of self-supervised contrastive learning for alleviating the annotated data scarcity in multi-modal music retrieval models.","sentences":["Linking sheet music images to audio recordings remains a key problem for the development of efficient cross-modal music retrieval systems.","One of the fundamental approaches toward this task is to learn a cross-modal embedding space via deep neural networks that is able to connect short snippets of audio and sheet music.","However, the scarcity of annotated data from real musical content affects the capability of such methods to generalize to real retrieval scenarios.","In this work, we investigate whether we can mitigate this limitation with self-supervised contrastive learning, by exposing a network to a large amount of real music data as a pre-training step, by contrasting randomly augmented views of snippets of both modalities, namely audio and sheet images.","Through a number of experiments on synthetic and real piano data, we show that pre-trained models are able to retrieve snippets with better precision in all scenarios and pre-training configurations.","Encouraged by these results, we employ the snippet embeddings in the higher-level task of cross-modal piece identification and conduct more experiments on several retrieval configurations.","In this task, we observe that the retrieval quality improves from 30% up to 100% when real music data is present.","We then conclude by arguing for the potential of self-supervised contrastive learning for alleviating the annotated data scarcity in multi-modal music retrieval models."],"url":"http://arxiv.org/abs/2309.12134v1"}
{"created":"2023-09-21 14:53:36","title":"A knowledge representation approach for construction contract knowledge modeling","abstract":"The emergence of large language models (LLMs) presents an unprecedented opportunity to automate construction contract management, reducing human errors and saving significant time and costs. However, LLMs may produce convincing yet inaccurate and misleading content due to a lack of domain expertise. To address this issue, expert-driven contract knowledge can be represented in a structured manner to constrain the automatic contract management process. This paper introduces the Nested Contract Knowledge Graph (NCKG), a knowledge representation approach that captures the complexity of contract knowledge using a nested structure. It includes a nested knowledge representation framework, a NCKG ontology built on the framework, and an implementation method. Furthermore, we present the LLM-assisted contract review pipeline enhanced with external knowledge in NCKG. Our pipeline achieves a promising performance in contract risk reviewing, shedding light on the combination of LLM and KG towards more reliable and interpretable contract management.","sentences":["The emergence of large language models (LLMs) presents an unprecedented opportunity to automate construction contract management, reducing human errors and saving significant time and costs.","However, LLMs may produce convincing yet inaccurate and misleading content due to a lack of domain expertise.","To address this issue, expert-driven contract knowledge can be represented in a structured manner to constrain the automatic contract management process.","This paper introduces the Nested Contract Knowledge Graph (NCKG), a knowledge representation approach that captures the complexity of contract knowledge using a nested structure.","It includes a nested knowledge representation framework, a NCKG ontology built on the framework, and an implementation method.","Furthermore, we present the LLM-assisted contract review pipeline enhanced with external knowledge in NCKG.","Our pipeline achieves a promising performance in contract risk reviewing, shedding light on the combination of LLM and KG towards more reliable and interpretable contract management."],"url":"http://arxiv.org/abs/2309.12132v1"}
{"created":"2023-09-21 14:48:02","title":"Convergence and Recovery Guarantees of Unsupervised Neural Networks for Inverse Problems","abstract":"Neural networks have become a prominent approach to solve inverse problems in recent years. While a plethora of such methods was developed to solve inverse problems empirically, we are still lacking clear theoretical guarantees for these methods. On the other hand, many works proved convergence to optimal solutions of neural networks in a more general setting using overparametrization as a way to control the Neural Tangent Kernel. In this work we investigate how to bridge these two worlds and we provide deterministic convergence and recovery guarantees for the class of unsupervised feedforward multilayer neural networks trained to solve inverse problems. We also derive overparametrization bounds under which a two-layers Deep Inverse Prior network with smooth activation function will benefit from our guarantees.","sentences":["Neural networks have become a prominent approach to solve inverse problems in recent years.","While a plethora of such methods was developed to solve inverse problems empirically, we are still lacking clear theoretical guarantees for these methods.","On the other hand, many works proved convergence to optimal solutions of neural networks in a more general setting using overparametrization as a way to control the Neural Tangent Kernel.","In this work we investigate how to bridge these two worlds and we provide deterministic convergence and recovery guarantees for the class of unsupervised feedforward multilayer neural networks trained to solve inverse problems.","We also derive overparametrization bounds under which a two-layers Deep Inverse Prior network with smooth activation function will benefit from our guarantees."],"url":"http://arxiv.org/abs/2309.12128v1"}
{"created":"2023-09-21 14:41:41","title":"Sustainability indicators in an open online community","abstract":"Software is often abandoned or shut down, for one reason or another, and whilst research on academic open source software is sparse, there seems little reason to assume it is any different. While some reasons may be straightforward, e.g. a sole maintainer has moved on, or grant funding has ceased - some projects are able to withstand these barriers and may remain active and maintained despite adversity. This study monitored open source projects over the period of a year, measuring common performance indicators, using both subjective and qualitative measures (participant surveys), as well as using scripts to analyse indicators associated with these projects' online source control codebases. We find that these health indicators can not be used as cross project benchmarks, due to the significant variation in context for each project. They can, however, often be useful in signifying changes in a single project's health, providing they are not used to compare between different unrelated projects.","sentences":["Software is often abandoned or shut down, for one reason or another, and whilst research on academic open source software is sparse, there seems little reason to assume it is any different.","While some reasons may be straightforward, e.g. a sole maintainer has moved on, or grant funding has ceased - some projects are able to withstand these barriers and may remain active and maintained despite adversity.","This study monitored open source projects over the period of a year, measuring common performance indicators, using both subjective and qualitative measures (participant surveys), as well as using scripts to analyse indicators associated with these projects' online source control codebases.","We find that these health indicators can not be used as cross project benchmarks, due to the significant variation in context for each project.","They can, however, often be useful in signifying changes in a single project's health, providing they are not used to compare between different unrelated projects."],"url":"http://arxiv.org/abs/2309.12120v1"}
{"created":"2023-09-21 14:36:10","title":"Vulnerability of 3D Face Recognition Systems to Morphing Attacks","abstract":"In recent years face recognition systems have been brought to the mainstream due to development in hardware and software. Consistent efforts are being made to make them better and more secure. This has also brought developments in 3D face recognition systems at a rapid pace. These 3DFR systems are expected to overcome certain vulnerabilities of 2DFR systems. One such problem that the domain of 2DFR systems face is face image morphing. A substantial amount of research is being done for generation of high quality face morphs along with detection of attacks from these morphs. Comparatively the understanding of vulnerability of 3DFR systems against 3D face morphs is less. But at the same time an expectation is set from 3DFR systems to be more robust against such attacks. This paper attempts to research and gain more information on this matter. The paper describes a couple of methods that can be used to generate 3D face morphs. The face morphs that are generated using this method are then compared to the contributing faces to obtain similarity scores. The highest MMPMR is obtained around 40% with RMMR of 41.76% when 3DFRS are attacked with look-a-like morphs.","sentences":["In recent years face recognition systems have been brought to the mainstream due to development in hardware and software.","Consistent efforts are being made to make them better and more secure.","This has also brought developments in 3D face recognition systems at a rapid pace.","These 3DFR systems are expected to overcome certain vulnerabilities of 2DFR systems.","One such problem that the domain of 2DFR systems face is face image morphing.","A substantial amount of research is being done for generation of high quality face morphs along with detection of attacks from these morphs.","Comparatively the understanding of vulnerability of 3DFR systems against 3D face morphs is less.","But at the same time an expectation is set from 3DFR systems to be more robust against such attacks.","This paper attempts to research and gain more information on this matter.","The paper describes a couple of methods that can be used to generate 3D face morphs.","The face morphs that are generated using this method are then compared to the contributing faces to obtain similarity scores.","The highest MMPMR is obtained around 40% with RMMR of 41.76% when 3DFRS are attacked with look-a-like morphs."],"url":"http://arxiv.org/abs/2309.12118v1"}
{"created":"2023-09-21 14:35:42","title":"How-to Guides for Specific Audiences: A Corpus and Initial Findings","abstract":"Instructional texts for specific target groups should ideally take into account the prior knowledge and needs of the readers in order to guide them efficiently to their desired goals. However, targeting specific groups also carries the risk of reflecting disparate social norms and subtle stereotypes. In this paper, we investigate the extent to which how-to guides from one particular platform, wikiHow, differ in practice depending on the intended audience. We conduct two case studies in which we examine qualitative features of texts written for specific audiences. In a generalization study, we investigate which differences can also be systematically demonstrated using computational methods. The results of our studies show that guides from wikiHow, like other text genres, are subject to subtle biases. We aim to raise awareness of these inequalities as a first step to addressing them in future work.","sentences":["Instructional texts for specific target groups should ideally take into account the prior knowledge and needs of the readers in order to guide them efficiently to their desired goals.","However, targeting specific groups also carries the risk of reflecting disparate social norms and subtle stereotypes.","In this paper, we investigate the extent to which how-to guides from one particular platform, wikiHow, differ in practice depending on the intended audience.","We conduct two case studies in which we examine qualitative features of texts written for specific audiences.","In a generalization study, we investigate which differences can also be systematically demonstrated using computational methods.","The results of our studies show that guides from wikiHow, like other text genres, are subject to subtle biases.","We aim to raise awareness of these inequalities as a first step to addressing them in future work."],"url":"http://arxiv.org/abs/2309.12117v1"}
{"created":"2023-09-21 14:35:34","title":"MeetScript: Designing Transcript-based Interactions to Support Active Participation in Group Video Meetings","abstract":"While videoconferencing is prevalent, concurrent participation channels are limited. People experience challenges keeping up with the discussion, and misunderstanding frequently occurs. Through a formative study, we probed into the design space of providing real-time transcripts as an extra communication space for video meeting attendees. We then present MeetScript, a system that provides parallel participation channels through real-time interactive transcripts. MeetScript visualizes the discussion through a chat-alike interface and allows meeting attendees to make real-time collaborative annotations. Over time, MeetScript gradually hides extraneous content to retain the most essential information on the transcript, with the goal of reducing the cognitive load required on users to process the information in real time. In an experiment with 80 users in 22 teams, we compared MeetScript with two baseline conditions where participants used Zoom alone (business-as-usual), or Zoom with an adds-on transcription service (Otter.ai). We found that MeetScript significantly enhanced people's non-verbal participation and recollection of their teams' decision-making processes compared to the baselines. Users liked that MeetScript allowed them to easily navigate the transcript and contextualize feedback and new ideas with existing ones.","sentences":["While videoconferencing is prevalent, concurrent participation channels are limited.","People experience challenges keeping up with the discussion, and misunderstanding frequently occurs.","Through a formative study, we probed into the design space of providing real-time transcripts as an extra communication space for video meeting attendees.","We then present MeetScript, a system that provides parallel participation channels through real-time interactive transcripts.","MeetScript visualizes the discussion through a chat-alike interface and allows meeting attendees to make real-time collaborative annotations.","Over time, MeetScript gradually hides extraneous content to retain the most essential information on the transcript, with the goal of reducing the cognitive load required on users to process the information in real time.","In an experiment with 80 users in 22 teams, we compared MeetScript with two baseline conditions where participants used Zoom alone (business-as-usual), or Zoom with an adds-on transcription service (Otter.ai).","We found that MeetScript significantly enhanced people's non-verbal participation and recollection of their teams' decision-making processes compared to the baselines.","Users liked that MeetScript allowed them to easily navigate the transcript and contextualize feedback and new ideas with existing ones."],"url":"http://arxiv.org/abs/2309.12115v1"}
{"created":"2023-09-21 14:30:42","title":"Incentivizing Massive Unknown Workers for Budget-Limited Crowdsensing: From Off-Line and On-Line Perspectives","abstract":"Although the uncertainties of the workers can be addressed by the standard Combinatorial Multi-Armed Bandit (CMAB) framework in existing proposals through a trade-off between exploration and exploitation, we may not have sufficient budget to enable the trade-off among the individual workers, especially when the number of the workers is huge while the budget is limited. Moreover, the standard CMAB usually assumes the workers always stay in the system, whereas the workers may join in or depart from the system over time, such that what we have learnt for an individual worker cannot be applied after the worker leaves. To address the above challenging issues, in this paper, we first propose an off-line Context-Aware CMAB-based Incentive (CACI) mechanism. We innovate in leveraging the exploration-exploitation trade-off in a elaborately partitioned context space instead of the individual workers, to effectively incentivize the massive unknown workers with very limited budget. We also extend the above basic idea to the on-line setting where unknown workers may join in or depart from the systems dynamically, and propose an on-line version of the CACI mechanism. Specifically, by the exploitation-exploration trade-off in the context space, we learn to estimate the sensing ability of any unknown worker (even it never appeared in the system before) according to its context information. We perform rigorous theoretical analysis to reveal the upper bounds on the regrets of our CACI mechanisms and to prove their truthfulness and individual rationality, respectively. Extensive experiments on both synthetic and real datasets are also conducted to verify the efficacy of our mechanisms.","sentences":["Although the uncertainties of the workers can be addressed by the standard Combinatorial Multi-Armed Bandit (CMAB) framework in existing proposals through a trade-off between exploration and exploitation, we may not have sufficient budget to enable the trade-off among the individual workers, especially when the number of the workers is huge while the budget is limited.","Moreover, the standard CMAB usually assumes the workers always stay in the system, whereas the workers may join in or depart from the system over time, such that what we have learnt for an individual worker cannot be applied after the worker leaves.","To address the above challenging issues, in this paper, we first propose an off-line Context-Aware CMAB-based Incentive (CACI) mechanism.","We innovate in leveraging the exploration-exploitation trade-off in a elaborately partitioned context space instead of the individual workers, to effectively incentivize the massive unknown workers with very limited budget.","We also extend the above basic idea to the on-line setting where unknown workers may join in or depart from the systems dynamically, and propose an on-line version of the CACI mechanism.","Specifically, by the exploitation-exploration trade-off in the context space, we learn to estimate the sensing ability of any unknown worker (even it never appeared in the system before) according to its context information.","We perform rigorous theoretical analysis to reveal the upper bounds on the regrets of our CACI mechanisms and to prove their truthfulness and individual rationality, respectively.","Extensive experiments on both synthetic and real datasets are also conducted to verify the efficacy of our mechanisms."],"url":"http://arxiv.org/abs/2309.12113v1"}
{"created":"2023-09-21 14:30:14","title":"Confluence Criteria for Logically Constrained Rewrite Systems (Full Version)","abstract":"Numerous confluence criteria for plain term rewrite systems are known. For logically constrained rewrite system, an attractive extension of term rewriting in which rules are equipped with logical constraints, much less is known. In this paper we extend the strongly-closed and (almost) parallel-closed critical pair criteria of Huet and Toyama to the logically constrained setting. We discuss the challenges for automation and present crest, a new tool for logically constrained rewriting in which the confluence criteria are implemented, together with experimental data.","sentences":["Numerous confluence criteria for plain term rewrite systems are known.","For logically constrained rewrite system, an attractive extension of term rewriting in which rules are equipped with logical constraints, much less is known.","In this paper we extend the strongly-closed and (almost) parallel-closed critical pair criteria of Huet and Toyama to the logically constrained setting.","We discuss the challenges for automation and present crest, a new tool for logically constrained rewriting in which the confluence criteria are implemented, together with experimental data."],"url":"http://arxiv.org/abs/2309.12112v1"}
{"created":"2023-09-21 14:30:02","title":"Passage Summarization with Recurrent Models for Audio-Sheet Music Retrieval","abstract":"Many applications of cross-modal music retrieval are related to connecting sheet music images to audio recordings. A typical and recent approach to this is to learn, via deep neural networks, a joint embedding space that correlates short fixed-size snippets of audio and sheet music by means of an appropriate similarity structure. However, two challenges that arise out of this strategy are the requirement of strongly aligned data to train the networks, and the inherent discrepancies of musical content between audio and sheet music snippets caused by local and global tempo differences. In this paper, we address these two shortcomings by designing a cross-modal recurrent network that learns joint embeddings that can summarize longer passages of corresponding audio and sheet music. The benefits of our method are that it only requires weakly aligned audio-sheet music pairs, as well as that the recurrent network handles the non-linearities caused by tempo variations between audio and sheet music. We conduct a number of experiments on synthetic and real piano data and scores, showing that our proposed recurrent method leads to more accurate retrieval in all possible configurations.","sentences":["Many applications of cross-modal music retrieval are related to connecting sheet music images to audio recordings.","A typical and recent approach to this is to learn, via deep neural networks, a joint embedding space that correlates short fixed-size snippets of audio and sheet music by means of an appropriate similarity structure.","However, two challenges that arise out of this strategy are the requirement of strongly aligned data to train the networks, and the inherent discrepancies of musical content between audio and sheet music snippets caused by local and global tempo differences.","In this paper, we address these two shortcomings by designing a cross-modal recurrent network that learns joint embeddings that can summarize longer passages of corresponding audio and sheet music.","The benefits of our method are that it only requires weakly aligned audio-sheet music pairs, as well as that the recurrent network handles the non-linearities caused by tempo variations between audio and sheet music.","We conduct a number of experiments on synthetic and real piano data and scores, showing that our proposed recurrent method leads to more accurate retrieval in all possible configurations."],"url":"http://arxiv.org/abs/2309.12111v1"}
{"created":"2023-09-21 14:29:44","title":"Exploiting CLIP-based Multi-modal Approach for Artwork Classification and Retrieval","abstract":"Given the recent advances in multimodal image pretraining where visual models trained with semantically dense textual supervision tend to have better generalization capabilities than those trained using categorical attributes or through unsupervised techniques, in this work we investigate how recent CLIP model can be applied in several tasks in artwork domain. We perform exhaustive experiments on the NoisyArt dataset which is a dataset of artwork images crawled from public resources on the web. On such dataset CLIP achieves impressive results on (zero-shot) classification and promising results in both artwork-to-artwork and description-to-artwork domain.","sentences":["Given the recent advances in multimodal image pretraining where visual models trained with semantically dense textual supervision tend to have better generalization capabilities than those trained using categorical attributes or through unsupervised techniques, in this work we investigate how recent CLIP model can be applied in several tasks in artwork domain.","We perform exhaustive experiments on the NoisyArt dataset which is a dataset of artwork images crawled from public resources on the web.","On such dataset CLIP achieves impressive results on (zero-shot) classification and promising results in both artwork-to-artwork and description-to-artwork domain."],"url":"http://arxiv.org/abs/2309.12110v1"}
{"created":"2023-09-21 14:29:23","title":"PEFTT: Parameter-Efficient Fine-Tuning for low-resource Tibetan pre-trained language models","abstract":"In this era of large language models (LLMs), the traditional training of models has become increasingly unimaginable for regular users and institutions. The exploration of efficient fine-tuning for high-resource languages on these models is an undeniable trend that is gradually gaining popularity. However, there has been very little exploration for various low-resource languages, such as Tibetan. Research in Tibetan NLP is inherently scarce and limited. While there is currently no existing large language model for Tibetan due to its low-resource nature, that day will undoubtedly arrive. Therefore, research on efficient fine-tuning for low-resource language models like Tibetan is highly necessary. Our research can serve as a reference to fill this crucial gap. Efficient fine-tuning strategies for pre-trained language models (PLMs) in Tibetan have seen minimal exploration. We conducted three types of efficient fine-tuning experiments on the publicly available TNCC-title dataset: \"prompt-tuning,\" \"Adapter lightweight fine-tuning,\" and \"prompt-tuning + Adapter fine-tuning.\" The experimental results demonstrate significant improvements using these methods, providing valuable insights for advancing Tibetan language applications in the context of pre-trained models.","sentences":["In this era of large language models (LLMs), the traditional training of models has become increasingly unimaginable for regular users and institutions.","The exploration of efficient fine-tuning for high-resource languages on these models is an undeniable trend that is gradually gaining popularity.","However, there has been very little exploration for various low-resource languages, such as Tibetan.","Research in Tibetan NLP is inherently scarce and limited.","While there is currently no existing large language model for Tibetan due to its low-resource nature, that day will undoubtedly arrive.","Therefore, research on efficient fine-tuning for low-resource language models like Tibetan is highly necessary.","Our research can serve as a reference to fill this crucial gap.","Efficient fine-tuning strategies for pre-trained language models (PLMs) in Tibetan have seen minimal exploration.","We conducted three types of efficient fine-tuning experiments on the publicly available TNCC-title dataset: \"prompt-tuning,\" \"Adapter lightweight fine-tuning,\" and \"prompt-tuning + Adapter fine-tuning.\"","The experimental results demonstrate significant improvements using these methods, providing valuable insights for advancing Tibetan language applications in the context of pre-trained models."],"url":"http://arxiv.org/abs/2309.12109v1"}
{"created":"2023-09-21 14:26:04","title":"A Computational Analysis of Vagueness in Revisions of Instructional Texts","abstract":"WikiHow is an open-domain repository of instructional articles for a variety of tasks, which can be revised by users. In this paper, we extract pairwise versions of an instruction before and after a revision was made. Starting from a noisy dataset of revision histories, we specifically extract and analyze edits that involve cases of vagueness in instructions. We further investigate the ability of a neural model to distinguish between two versions of an instruction in our data by adopting a pairwise ranking task from previous work and showing improvements over existing baselines.","sentences":["WikiHow is an open-domain repository of instructional articles for a variety of tasks, which can be revised by users.","In this paper, we extract pairwise versions of an instruction before and after a revision was made.","Starting from a noisy dataset of revision histories, we specifically extract and analyze edits that involve cases of vagueness in instructions.","We further investigate the ability of a neural model to distinguish between two versions of an instruction in our data by adopting a pairwise ranking task from previous work and showing improvements over existing baselines."],"url":"http://arxiv.org/abs/2309.12107v1"}
{"created":"2023-09-21 14:23:10","title":"FourierLoss: Shape-Aware Loss Function with Fourier Descriptors","abstract":"Encoder-decoder networks become a popular choice for various medical image segmentation tasks. When they are trained with a standard loss function, these networks are not explicitly enforced to preserve the shape integrity of an object in an image. However, this ability of the network is important to obtain more accurate results, especially when there is a low-contrast difference between the object and its surroundings. In response to this issue, this work introduces a new shape-aware loss function, which we name FourierLoss. This loss function relies on quantifying the shape dissimilarity between the ground truth and the predicted segmentation maps through the Fourier descriptors calculated on their objects, and penalizing this dissimilarity in network training. Different than the previous studies, FourierLoss offers an adaptive loss function with trainable hyperparameters that control the importance of the level of the shape details that the network is enforced to learn in the training process. This control is achieved by the proposed adaptive loss update mechanism, which end-to-end learns the hyperparameters simultaneously with the network weights by backpropagation. As a result of using this mechanism, the network can dynamically change its attention from learning the general outline of an object to learning the details of its contour points, or vice versa, in different training epochs. Working on 2879 computed tomography images of 93 subjects, our experiments revealed that the proposed adaptive shape-aware loss function led to statistically significantly better results for liver segmentation, compared to its counterparts.","sentences":["Encoder-decoder networks become a popular choice for various medical image segmentation tasks.","When they are trained with a standard loss function, these networks are not explicitly enforced to preserve the shape integrity of an object in an image.","However, this ability of the network is important to obtain more accurate results, especially when there is a low-contrast difference between the object and its surroundings.","In response to this issue, this work introduces a new shape-aware loss function, which we name FourierLoss.","This loss function relies on quantifying the shape dissimilarity between the ground truth and the predicted segmentation maps through the Fourier descriptors calculated on their objects, and penalizing this dissimilarity in network training.","Different than the previous studies, FourierLoss offers an adaptive loss function with trainable hyperparameters that control the importance of the level of the shape details that the network is enforced to learn in the training process.","This control is achieved by the proposed adaptive loss update mechanism, which end-to-end learns the hyperparameters simultaneously with the network weights by backpropagation.","As a result of using this mechanism, the network can dynamically change its attention from learning the general outline of an object to learning the details of its contour points, or vice versa, in different training epochs.","Working on 2879 computed tomography images of 93 subjects, our experiments revealed that the proposed adaptive shape-aware loss function led to statistically significantly better results for liver segmentation, compared to its counterparts."],"url":"http://arxiv.org/abs/2309.12106v1"}
