{"created":"2023-09-13 17:59:56","title":"Text-Guided Generation and Editing of Compositional 3D Avatars","abstract":"Our goal is to create a realistic 3D facial avatar with hair and accessories using only a text description. While this challenge has attracted significant recent interest, existing methods either lack realism, produce unrealistic shapes, or do not support editing, such as modifications to the hairstyle. We argue that existing methods are limited because they employ a monolithic modeling approach, using a single representation for the head, face, hair, and accessories. Our observation is that the hair and face, for example, have very different structural qualities that benefit from different representations. Building on this insight, we generate avatars with a compositional model, in which the head, face, and upper body are represented with traditional 3D meshes, and the hair, clothing, and accessories with neural radiance fields (NeRF). The model-based mesh representation provides a strong geometric prior for the face region, improving realism while enabling editing of the person's appearance. By using NeRFs to represent the remaining components, our method is able to model and synthesize parts with complex geometry and appearance, such as curly hair and fluffy scarves. Our novel system synthesizes these high-quality compositional avatars from text descriptions. The experimental results demonstrate that our method, Text-guided generation and Editing of Compositional Avatars (TECA), produces avatars that are more realistic than those of recent methods while being editable because of their compositional nature. For example, our TECA enables the seamless transfer of compositional features like hairstyles, scarves, and other accessories between avatars. This capability supports applications such as virtual try-on.","sentences":["Our goal is to create a realistic 3D facial avatar with hair and accessories using only a text description.","While this challenge has attracted significant recent interest, existing methods either lack realism, produce unrealistic shapes, or do not support editing, such as modifications to the hairstyle.","We argue that existing methods are limited because they employ a monolithic modeling approach, using a single representation for the head, face, hair, and accessories.","Our observation is that the hair and face, for example, have very different structural qualities that benefit from different representations.","Building on this insight, we generate avatars with a compositional model, in which the head, face, and upper body are represented with traditional 3D meshes, and the hair, clothing, and accessories with neural radiance fields (NeRF).","The model-based mesh representation provides a strong geometric prior for the face region, improving realism while enabling editing of the person's appearance.","By using NeRFs to represent the remaining components, our method is able to model and synthesize parts with complex geometry and appearance, such as curly hair and fluffy scarves.","Our novel system synthesizes these high-quality compositional avatars from text descriptions.","The experimental results demonstrate that our method, Text-guided generation and Editing of Compositional Avatars (TECA), produces avatars that are more realistic than those of recent methods while being editable because of their compositional nature.","For example, our TECA enables the seamless transfer of compositional features like hairstyles, scarves, and other accessories between avatars.","This capability supports applications such as virtual try-on."],"url":"http://arxiv.org/abs/2309.07125v1"}
{"created":"2023-09-13 17:59:09","title":"RAIN: Your Language Models Can Align Themselves without Finetuning","abstract":"Large language models (LLMs) often demonstrate inconsistencies with human preferences. Previous research gathered human preference data and then aligned the pre-trained models using reinforcement learning or instruction tuning, the so-called finetuning step. In contrast, aligning frozen LLMs without any extra data is more appealing. This work explores the potential of the latter setting. We discover that by integrating self-evaluation and rewind mechanisms, unaligned LLMs can directly produce responses consistent with human preferences via self-boosting. We introduce a novel inference method, Rewindable Auto-regressive INference (RAIN), that allows pre-trained LLMs to evaluate their own generation and use the evaluation results to guide backward rewind and forward generation for AI safety. Notably, RAIN operates without the need of extra data for model alignment and abstains from any training, gradient computation, or parameter updates; during the self-evaluation phase, the model receives guidance on which human preference to align with through a fixed-template prompt, eliminating the need to modify the initial prompt. Experimental results evaluated by GPT-4 and humans demonstrate the effectiveness of RAIN: on the HH dataset, RAIN improves the harmlessness rate of LLaMA 30B over vanilla inference from 82% to 97%, while maintaining the helpfulness rate. Under the leading adversarial attack llm-attacks on Vicuna 33B, RAIN establishes a new defense baseline by reducing the attack success rate from 94% to 19%.","sentences":["Large language models (LLMs) often demonstrate inconsistencies with human preferences.","Previous research gathered human preference data and then aligned the pre-trained models using reinforcement learning or instruction tuning, the so-called finetuning step.","In contrast, aligning frozen LLMs without any extra data is more appealing.","This work explores the potential of the latter setting.","We discover that by integrating self-evaluation and rewind mechanisms, unaligned LLMs can directly produce responses consistent with human preferences via self-boosting.","We introduce a novel inference method, Rewindable Auto-regressive INference (RAIN), that allows pre-trained LLMs to evaluate their own generation and use the evaluation results to guide backward rewind and forward generation for AI safety.","Notably, RAIN operates without the need of extra data for model alignment and abstains from any training, gradient computation, or parameter updates; during the self-evaluation phase, the model receives guidance on which human preference to align with through a fixed-template prompt, eliminating the need to modify the initial prompt.","Experimental results evaluated by GPT-4 and humans demonstrate the effectiveness of RAIN: on the HH dataset, RAIN improves the harmlessness rate of LLaMA 30B over vanilla inference from 82% to 97%, while maintaining the helpfulness rate.","Under the leading adversarial attack llm-attacks on Vicuna 33B, RAIN establishes a new defense baseline by reducing the attack success rate from 94% to 19%."],"url":"http://arxiv.org/abs/2309.07124v1"}
{"created":"2023-09-13 17:57:55","title":"Tree-Structured Shading Decomposition","abstract":"We study inferring a tree-structured representation from a single image for object shading. Prior work typically uses the parametric or measured representation to model shading, which is neither interpretable nor easily editable. We propose using the shade tree representation, which combines basic shading nodes and compositing methods to factorize object surface shading. The shade tree representation enables novice users who are unfamiliar with the physical shading process to edit object shading in an efficient and intuitive manner. A main challenge in inferring the shade tree is that the inference problem involves both the discrete tree structure and the continuous parameters of the tree nodes. We propose a hybrid approach to address this issue. We introduce an auto-regressive inference model to generate a rough estimation of the tree structure and node parameters, and then we fine-tune the inferred shade tree through an optimization algorithm. We show experiments on synthetic images, captured reflectance, real images, and non-realistic vector drawings, allowing downstream applications such as material editing, vectorized shading, and relighting. Project website: https://chen-geng.com/inv-shade-trees","sentences":["We study inferring a tree-structured representation from a single image for object shading.","Prior work typically uses the parametric or measured representation to model shading, which is neither interpretable nor easily editable.","We propose using the shade tree representation, which combines basic shading nodes and compositing methods to factorize object surface shading.","The shade tree representation enables novice users who are unfamiliar with the physical shading process to edit object shading in an efficient and intuitive manner.","A main challenge in inferring the shade tree is that the inference problem involves both the discrete tree structure and the continuous parameters of the tree nodes.","We propose a hybrid approach to address this issue.","We introduce an auto-regressive inference model to generate a rough estimation of the tree structure and node parameters, and then we fine-tune the inferred shade tree through an optimization algorithm.","We show experiments on synthetic images, captured reflectance, real images, and non-realistic vector drawings, allowing downstream applications such as material editing, vectorized shading, and relighting.","Project website: https://chen-geng.com/inv-shade-trees"],"url":"http://arxiv.org/abs/2309.07122v1"}
{"created":"2023-09-13 17:57:21","title":"Sight Beyond Text: Multi-Modal Training Enhances LLMs in Truthfulness and Ethics","abstract":"Multi-modal large language models (MLLMs) are trained based on large language models (LLM), with an enhanced capability to comprehend multi-modal inputs and generate textual responses. While they excel in multi-modal tasks, the pure NLP abilities of MLLMs are often underestimated and left untested. In this study, we get out of the box and unveil an intriguing characteristic of MLLMs -- our preliminary results suggest that visual instruction tuning, a prevailing strategy for transitioning LLMs into MLLMs, unexpectedly and interestingly helps models attain both improved truthfulness and ethical alignment in the pure NLP context. For example, a visual-instruction-tuned LLaMA2 7B model surpasses the performance of the LLaMA2-chat 7B model, fine-tuned with over one million human annotations, on TruthfulQA-mc and Ethics benchmarks. Further analysis reveals that the improved alignment can be attributed to the superior instruction quality inherent to visual-text data. In releasing our code at github.com/UCSC-VLAA/Sight-Beyond-Text, we aspire to foster further exploration into the intrinsic value of visual-text synergies and, in a broader scope, multi-modal interactions in alignment research.","sentences":["Multi-modal large language models (MLLMs) are trained based on large language models (LLM), with an enhanced capability to comprehend multi-modal inputs and generate textual responses.","While they excel in multi-modal tasks, the pure NLP abilities of MLLMs are often underestimated and left untested.","In this study, we get out of the box and unveil an intriguing characteristic of MLLMs -- our preliminary results suggest that visual instruction tuning, a prevailing strategy for transitioning LLMs into MLLMs, unexpectedly and interestingly helps models attain both improved truthfulness and ethical alignment in the pure NLP context.","For example, a visual-instruction-tuned LLaMA2 7B model surpasses the performance of the LLaMA2-chat 7B model, fine-tuned with over one million human annotations, on TruthfulQA-mc and Ethics benchmarks.","Further analysis reveals that the improved alignment can be attributed to the superior instruction quality inherent to visual-text data.","In releasing our code at github.com/UCSC-VLAA/Sight-Beyond-Text, we aspire to foster further exploration into the intrinsic value of visual-text synergies and, in a broader scope, multi-modal interactions in alignment research."],"url":"http://arxiv.org/abs/2309.07120v1"}
{"created":"2023-09-13 17:55:11","title":"PILOT: A Pre-Trained Model-Based Continual Learning Toolbox","abstract":"While traditional machine learning can effectively tackle a wide range of problems, it primarily operates within a closed-world setting, which presents limitations when dealing with streaming data. As a solution, incremental learning emerges to address real-world scenarios involving new data's arrival. Recently, pre-training has made significant advancements and garnered the attention of numerous researchers. The strong performance of these pre-trained models (PTMs) presents a promising avenue for developing continual learning algorithms that can effectively adapt to real-world scenarios. Consequently, exploring the utilization of PTMs in incremental learning has become essential. This paper introduces a pre-trained model-based continual learning toolbox known as PILOT. On the one hand, PILOT implements some state-of-the-art class-incremental learning algorithms based on pre-trained models, such as L2P, DualPrompt, and CODA-Prompt. On the other hand, PILOT also fits typical class-incremental learning algorithms (e.g., DER, FOSTER, and MEMO) within the context of pre-trained models to evaluate their effectiveness.","sentences":["While traditional machine learning can effectively tackle a wide range of problems, it primarily operates within a closed-world setting, which presents limitations when dealing with streaming data.","As a solution, incremental learning emerges to address real-world scenarios involving new data's arrival.","Recently, pre-training has made significant advancements and garnered the attention of numerous researchers.","The strong performance of these pre-trained models (PTMs) presents a promising avenue for developing continual learning algorithms that can effectively adapt to real-world scenarios.","Consequently, exploring the utilization of PTMs in incremental learning has become essential.","This paper introduces a pre-trained model-based continual learning toolbox known as PILOT.","On the one hand, PILOT implements some state-of-the-art class-incremental learning algorithms based on pre-trained models, such as L2P, DualPrompt, and CODA-Prompt.","On the other hand, PILOT also fits typical class-incremental learning algorithms (e.g., DER, FOSTER, and MEMO) within the context of pre-trained models to evaluate their effectiveness."],"url":"http://arxiv.org/abs/2309.07117v1"}
{"created":"2023-09-13 17:45:41","title":"Weakly-Supervised Multi-Task Learning for Audio-Visual Speaker Verification","abstract":"In this paper, we present a methodology for achieving robust multimodal person representations optimized for open-set audio-visual speaker verification. Distance Metric Learning (DML) approaches have typically dominated this problem space, owing to strong performance on new and unseen classes. In our work, we explored multitask learning techniques to further boost performance of the DML approach and show that an auxiliary task with weak labels can increase the compactness of the learned speaker representation. We also extend the Generalized end-to-end loss (GE2E) to multimodal inputs and demonstrate that it can achieve competitive performance in an audio-visual space. Finally, we introduce a non-synchronous audio-visual sampling random strategy during training time that has shown to improve generalization. Our network achieves state of the art performance for speaker verification, reporting 0.244%, 0.252%, 0.441% Equal Error Rate (EER) on the three official trial lists of VoxCeleb1-O/E/H, which is to our knowledge, the best published results on VoxCeleb1-E and VoxCeleb1-H.","sentences":["In this paper, we present a methodology for achieving robust multimodal person representations optimized for open-set audio-visual speaker verification.","Distance Metric Learning (DML) approaches have typically dominated this problem space, owing to strong performance on new and unseen classes.","In our work, we explored multitask learning techniques to further boost performance of the DML approach and show that an auxiliary task with weak labels can increase the compactness of the learned speaker representation.","We also extend the Generalized end-to-end loss (GE2E) to multimodal inputs and demonstrate that it can achieve competitive performance in an audio-visual space.","Finally, we introduce a non-synchronous audio-visual sampling random strategy during training time that has shown to improve generalization.","Our network achieves state of the art performance for speaker verification, reporting 0.244%, 0.252%, 0.441% Equal Error Rate (EER) on the three official trial lists of VoxCeleb1-O/E/H, which is to our knowledge, the best published results on VoxCeleb1-E and VoxCeleb1-H."],"url":"http://arxiv.org/abs/2309.07115v1"}
{"created":"2023-09-13 17:37:19","title":"Contrastive Deep Encoding Enables Uncertainty-aware Machine-learning-assisted Histopathology","abstract":"Deep neural network models can learn clinically relevant features from millions of histopathology images. However generating high-quality annotations to train such models for each hospital, each cancer type, and each diagnostic task is prohibitively laborious. On the other hand, terabytes of training data -- while lacking reliable annotations -- are readily available in the public domain in some cases. In this work, we explore how these large datasets can be consciously utilized to pre-train deep networks to encode informative representations. We then fine-tune our pre-trained models on a fraction of annotated training data to perform specific downstream tasks. We show that our approach can reach the state-of-the-art (SOTA) for patch-level classification with only 1-10% randomly selected annotations compared to other SOTA approaches. Moreover, we propose an uncertainty-aware loss function, to quantify the model confidence during inference. Quantified uncertainty helps experts select the best instances to label for further training. Our uncertainty-aware labeling reaches the SOTA with significantly fewer annotations compared to random labeling. Last, we demonstrate how our pre-trained encoders can surpass current SOTA for whole-slide image classification with weak supervision. Our work lays the foundation for data and task-agnostic pre-trained deep networks with quantified uncertainty.","sentences":["Deep neural network models can learn clinically relevant features from millions of histopathology images.","However generating high-quality annotations to train such models for each hospital, each cancer type, and each diagnostic task is prohibitively laborious.","On the other hand, terabytes of training data -- while lacking reliable annotations -- are readily available in the public domain in some cases.","In this work, we explore how these large datasets can be consciously utilized to pre-train deep networks to encode informative representations.","We then fine-tune our pre-trained models on a fraction of annotated training data to perform specific downstream tasks.","We show that our approach can reach the state-of-the-art (SOTA) for patch-level classification with only 1-10% randomly selected annotations compared to other SOTA approaches.","Moreover, we propose an uncertainty-aware loss function, to quantify the model confidence during inference.","Quantified uncertainty helps experts select the best instances to label for further training.","Our uncertainty-aware labeling reaches the SOTA with significantly fewer annotations compared to random labeling.","Last, we demonstrate how our pre-trained encoders can surpass current SOTA for whole-slide image classification with weak supervision.","Our work lays the foundation for data and task-agnostic pre-trained deep networks with quantified uncertainty."],"url":"http://arxiv.org/abs/2309.07113v1"}
{"created":"2023-09-13 17:26:36","title":"Characterizing Speed Performance of Multi-Agent Reinforcement Learning","abstract":"Multi-Agent Reinforcement Learning (MARL) has achieved significant success in large-scale AI systems and big-data applications such as smart grids, surveillance, etc. Existing advancements in MARL algorithms focus on improving the rewards obtained by introducing various mechanisms for inter-agent cooperation. However, these optimizations are usually compute- and memory-intensive, thus leading to suboptimal speed performance in end-to-end training time. In this work, we analyze the speed performance (i.e., latency-bounded throughput) as the key metric in MARL implementations. Specifically, we first introduce a taxonomy of MARL algorithms from an acceleration perspective categorized by (1) training scheme and (2) communication method. Using our taxonomy, we identify three state-of-the-art MARL algorithms - Multi-Agent Deep Deterministic Policy Gradient (MADDPG), Target-oriented Multi-agent Communication and Cooperation (ToM2C), and Networked Multi-Agent RL (NeurComm) - as target benchmark algorithms, and provide a systematic analysis of their performance bottlenecks on a homogeneous multi-core CPU platform. We justify the need for MARL latency-bounded throughput to be a key performance metric in future literature while also addressing opportunities for parallelization and acceleration.","sentences":["Multi-Agent Reinforcement Learning (MARL) has achieved significant success in large-scale AI systems and big-data applications such as smart grids, surveillance, etc.","Existing advancements in MARL algorithms focus on improving the rewards obtained by introducing various mechanisms for inter-agent cooperation.","However, these optimizations are usually compute- and memory-intensive, thus leading to suboptimal speed performance in end-to-end training time.","In this work, we analyze the speed performance (i.e., latency-bounded throughput) as the key metric in MARL implementations.","Specifically, we first introduce a taxonomy of MARL algorithms from an acceleration perspective categorized by (1) training scheme and (2) communication method.","Using our taxonomy, we identify three state-of-the-art MARL algorithms - Multi-Agent Deep Deterministic Policy Gradient (MADDPG), Target-oriented Multi-agent Communication and Cooperation (ToM2C), and Networked Multi-Agent RL (NeurComm) - as target benchmark algorithms, and provide a systematic analysis of their performance bottlenecks on a homogeneous multi-core CPU platform.","We justify the need for MARL latency-bounded throughput to be a key performance metric in future literature while also addressing opportunities for parallelization and acceleration."],"url":"http://arxiv.org/abs/2309.07108v1"}
{"created":"2023-09-13 17:25:52","title":"Hardening RGB-D Object Recognition Systems against Adversarial Patch Attacks","abstract":"RGB-D object recognition systems improve their predictive performances by fusing color and depth information, outperforming neural network architectures that rely solely on colors. While RGB-D systems are expected to be more robust to adversarial examples than RGB-only systems, they have also been proven to be highly vulnerable. Their robustness is similar even when the adversarial examples are generated by altering only the original images' colors. Different works highlighted the vulnerability of RGB-D systems; however, there is a lacking of technical explanations for this weakness. Hence, in our work, we bridge this gap by investigating the learned deep representation of RGB-D systems, discovering that color features make the function learned by the network more complex and, thus, more sensitive to small perturbations. To mitigate this problem, we propose a defense based on a detection mechanism that makes RGB-D systems more robust against adversarial examples. We empirically show that this defense improves the performances of RGB-D systems against adversarial examples even when they are computed ad-hoc to circumvent this detection mechanism, and that is also more effective than adversarial training.","sentences":["RGB-D object recognition systems improve their predictive performances by fusing color and depth information, outperforming neural network architectures that rely solely on colors.","While RGB-D systems are expected to be more robust to adversarial examples than RGB-only systems, they have also been proven to be highly vulnerable.","Their robustness is similar even when the adversarial examples are generated by altering only the original images' colors.","Different works highlighted the vulnerability of RGB-D systems; however, there is a lacking of technical explanations for this weakness.","Hence, in our work, we bridge this gap by investigating the learned deep representation of RGB-D systems, discovering that color features make the function learned by the network more complex and, thus, more sensitive to small perturbations.","To mitigate this problem, we propose a defense based on a detection mechanism that makes RGB-D systems more robust against adversarial examples.","We empirically show that this defense improves the performances of RGB-D systems against adversarial examples even when they are computed ad-hoc to circumvent this detection mechanism, and that is also more effective than adversarial training."],"url":"http://arxiv.org/abs/2309.07106v1"}
{"created":"2023-09-13 17:25:06","title":"Polygon Intersection-over-Union Loss for Viewpoint-Agnostic Monocular 3D Vehicle Detection","abstract":"Monocular 3D object detection is a challenging task because depth information is difficult to obtain from 2D images. A subset of viewpoint-agnostic monocular 3D detection methods also do not explicitly leverage scene homography or geometry during training, meaning that a model trained thusly can detect objects in images from arbitrary viewpoints. Such works predict the projections of the 3D bounding boxes on the image plane to estimate the location of the 3D boxes, but these projections are not rectangular so the calculation of IoU between these projected polygons is not straightforward. This work proposes an efficient, fully differentiable algorithm for the calculation of IoU between two convex polygons, which can be utilized to compute the IoU between two 3D bounding box footprints viewed from an arbitrary angle. We test the performance of the proposed polygon IoU loss (PIoU loss) on three state-of-the-art viewpoint-agnostic 3D detection models. Experiments demonstrate that the proposed PIoU loss converges faster than L1 loss and that in 3D detection models, a combination of PIoU loss and L1 loss gives better results than L1 loss alone (+1.64% AP70 for MonoCon on cars, +0.18% AP70 for RTM3D on cars, and +0.83%/+2.46% AP50/AP25 for MonoRCNN on cyclists).","sentences":["Monocular 3D object detection is a challenging task because depth information is difficult to obtain from 2D images.","A subset of viewpoint-agnostic monocular 3D detection methods also do not explicitly leverage scene homography or geometry during training, meaning that a model trained thusly can detect objects in images from arbitrary viewpoints.","Such works predict the projections of the 3D bounding boxes on the image plane to estimate the location of the 3D boxes, but these projections are not rectangular so the calculation of IoU between these projected polygons is not straightforward.","This work proposes an efficient, fully differentiable algorithm for the calculation of IoU between two convex polygons, which can be utilized to compute the IoU between two 3D bounding box footprints viewed from an arbitrary angle.","We test the performance of the proposed polygon IoU loss (PIoU loss) on three state-of-the-art viewpoint-agnostic 3D detection models.","Experiments demonstrate that the proposed PIoU loss converges faster than L1 loss and that in 3D detection models, a combination of PIoU loss and L1 loss gives better results than L1 loss alone (+1.64% AP70 for MonoCon on cars, +0.18% AP70 for RTM3D on cars, and +0.83%/+2.46% AP50/AP25 for MonoRCNN on cyclists)."],"url":"http://arxiv.org/abs/2309.07104v1"}
{"created":"2023-09-13 17:15:27","title":"Mitigating Hallucinations and Off-target Machine Translation with Source-Contrastive and Language-Contrastive Decoding","abstract":"Hallucinations and off-target translation remain unsolved problems in machine translation, especially for low-resource languages and massively multilingual models. In this paper, we introduce methods to mitigate both failure cases with a modified decoding objective, without requiring retraining or external models. In source-contrastive decoding, we search for a translation that is probable given the correct input, but improbable given a random input segment, hypothesising that hallucinations will be similarly probable given either. In language-contrastive decoding, we search for a translation that is probable, but improbable given the wrong language indicator token. In experiments on M2M-100 (418M) and SMaLL-100, we find that these methods effectively suppress hallucinations and off-target translations, improving chrF2 by 1.7 and 1.4 points on average across 57 tested translation directions. In a proof of concept on English--German, we also show that we can suppress off-target translations with the Llama 2 chat models, demonstrating the applicability of the method to machine translation with LLMs. We release our source code at https://github.com/ZurichNLP/ContraDecode.","sentences":["Hallucinations and off-target translation remain unsolved problems in machine translation, especially for low-resource languages and massively multilingual models.","In this paper, we introduce methods to mitigate both failure cases with a modified decoding objective, without requiring retraining or external models.","In source-contrastive decoding, we search for a translation that is probable given the correct input, but improbable given a random input segment, hypothesising that hallucinations will be similarly probable given either.","In language-contrastive decoding, we search for a translation that is probable, but improbable given the wrong language indicator token.","In experiments on M2M-100 (418M) and SMaLL-100, we find that these methods effectively suppress hallucinations and off-target translations, improving chrF2 by 1.7 and 1.4 points on average across 57 tested translation directions.","In a proof of concept on English--German, we also show that we can suppress off-target translations with the Llama 2 chat models, demonstrating the applicability of the method to machine translation with LLMs.","We release our source code at https://github.com/ZurichNLP/ContraDecode."],"url":"http://arxiv.org/abs/2309.07098v1"}
{"created":"2023-09-13 17:10:23","title":"RadarLCD: Learnable Radar-based Loop Closure Detection Pipeline","abstract":"Loop Closure Detection (LCD) is an essential task in robotics and computer vision, serving as a fundamental component for various applications across diverse domains. These applications encompass object recognition, image retrieval, and video analysis. LCD consists in identifying whether a robot has returned to a previously visited location, referred to as a loop, and then estimating the related roto-translation with respect to the analyzed location. Despite the numerous advantages of radar sensors, such as their ability to operate under diverse weather conditions and provide a wider range of view compared to other commonly used sensors (e.g., cameras or LiDARs), integrating radar data remains an arduous task due to intrinsic noise and distortion. To address this challenge, this research introduces RadarLCD, a novel supervised deep learning pipeline specifically designed for Loop Closure Detection using the FMCW Radar (Frequency Modulated Continuous Wave) sensor. RadarLCD, a learning-based LCD methodology explicitly designed for radar systems, makes a significant contribution by leveraging the pre-trained HERO (Hybrid Estimation Radar Odometry) model. Being originally developed for radar odometry, HERO's features are used to select key points crucial for LCD tasks. The methodology undergoes evaluation across a variety of FMCW Radar dataset scenes, and it is compared to state-of-the-art systems such as Scan Context for Place Recognition and ICP for Loop Closure. The results demonstrate that RadarLCD surpasses the alternatives in multiple aspects of Loop Closure Detection.","sentences":["Loop Closure Detection (LCD) is an essential task in robotics and computer vision, serving as a fundamental component for various applications across diverse domains.","These applications encompass object recognition, image retrieval, and video analysis.","LCD consists in identifying whether a robot has returned to a previously visited location, referred to as a loop, and then estimating the related roto-translation with respect to the analyzed location.","Despite the numerous advantages of radar sensors, such as their ability to operate under diverse weather conditions and provide a wider range of view compared to other commonly used sensors (e.g., cameras or LiDARs), integrating radar data remains an arduous task due to intrinsic noise and distortion.","To address this challenge, this research introduces RadarLCD, a novel supervised deep learning pipeline specifically designed for Loop Closure Detection using the FMCW Radar (Frequency Modulated Continuous Wave) sensor.","RadarLCD, a learning-based LCD methodology explicitly designed for radar systems, makes a significant contribution by leveraging the pre-trained HERO (Hybrid Estimation Radar Odometry) model.","Being originally developed for radar odometry, HERO's features are used to select key points crucial for LCD tasks.","The methodology undergoes evaluation across a variety of FMCW Radar dataset scenes, and it is compared to state-of-the-art systems such as Scan Context for Place Recognition and ICP for Loop Closure.","The results demonstrate that RadarLCD surpasses the alternatives in multiple aspects of Loop Closure Detection."],"url":"http://arxiv.org/abs/2309.07094v1"}
{"created":"2023-09-13 16:59:50","title":"Developing a Novel Image Marker to Predict the Responses of Neoadjuvant Chemotherapy (NACT) for Ovarian Cancer Patients","abstract":"Objective: Neoadjuvant chemotherapy (NACT) is one kind of treatment for advanced stage ovarian cancer patients. However, due to the nature of tumor heterogeneity, the patients' responses to NACT varies significantly among different subgroups. To address this clinical challenge, the purpose of this study is to develop a novel image marker to achieve high accuracy response prediction of the NACT at an early stage. Methods: For this purpose, we first computed a total of 1373 radiomics features to quantify the tumor characteristics, which can be grouped into three categories: geometric, intensity, and texture features. Second, all these features were optimized by principal component analysis algorithm to generate a compact and informative feature cluster. Using this cluster as the input, an SVM based classifier was developed and optimized to create a final marker, indicating the likelihood of the patient being responsive to the NACT treatment. To validate this scheme, a total of 42 ovarian cancer patients were retrospectively collected. A nested leave-one-out cross-validation was adopted for model performance assessment. Results: The results demonstrate that the new method yielded an AUC (area under the ROC [receiver characteristic operation] curve) of 0.745. Meanwhile, the model achieved overall accuracy of 76.2%, positive predictive value of 70%, and negative predictive value of 78.1%. Conclusion: This study provides meaningful information for the development of radiomics based image markers in NACT response prediction.","sentences":["Objective: Neoadjuvant chemotherapy (NACT) is one kind of treatment for advanced stage ovarian cancer patients.","However, due to the nature of tumor heterogeneity, the patients' responses to NACT varies significantly among different subgroups.","To address this clinical challenge, the purpose of this study is to develop a novel image marker to achieve high accuracy response prediction of the NACT at an early stage.","Methods: For this purpose, we first computed a total of 1373 radiomics features to quantify the tumor characteristics, which can be grouped into three categories: geometric, intensity, and texture features.","Second, all these features were optimized by principal component analysis algorithm to generate a compact and informative feature cluster.","Using this cluster as the input, an SVM based classifier was developed and optimized to create a final marker, indicating the likelihood of the patient being responsive to the NACT treatment.","To validate this scheme, a total of 42 ovarian cancer patients were retrospectively collected.","A nested leave-one-out cross-validation was adopted for model performance assessment.","Results:","The results demonstrate that the new method yielded an AUC (area under the ROC","[receiver characteristic operation] curve) of 0.745.","Meanwhile, the model achieved overall accuracy of 76.2%, positive predictive value of 70%, and negative predictive value of 78.1%.","Conclusion:","This study provides meaningful information for the development of radiomics based image markers in NACT response prediction."],"url":"http://arxiv.org/abs/2309.07087v1"}
{"created":"2023-09-13 16:53:48","title":"Mitigating Group Bias in Federated Learning for Heterogeneous Devices","abstract":"Federated Learning is emerging as a privacy-preserving model training approach in distributed edge applications. As such, most edge deployments are heterogeneous in nature i.e., their sensing capabilities and environments vary across deployments. This edge heterogeneity violates the independence and identical distribution (IID) property of local data across clients and produces biased global models i.e. models that contribute to unfair decision-making and discrimination against a particular community or a group. Existing bias mitigation techniques only focus on bias generated from label heterogeneity in non-IID data without accounting for domain variations due to feature heterogeneity and do not address global group-fairness property.   Our work proposes a group-fair FL framework that minimizes group-bias while preserving privacy and without resource utilization overhead. Our main idea is to leverage average conditional probabilities to compute a cross-domain group \\textit{importance weights} derived from heterogeneous training data to optimize the performance of the worst-performing group using a modified multiplicative weights update method. Additionally, we propose regularization techniques to minimize the difference between the worst and best-performing groups while making sure through our thresholding mechanism to strike a balance between bias reduction and group performance degradation. Our evaluation of human emotion recognition and image classification benchmarks assesses the fair decision-making of our framework in real-world heterogeneous settings.","sentences":["Federated Learning is emerging as a privacy-preserving model training approach in distributed edge applications.","As such, most edge deployments are heterogeneous in nature i.e., their sensing capabilities and environments vary across deployments.","This edge heterogeneity violates the independence and identical distribution (IID) property of local data across clients and produces biased global models i.e. models that contribute to unfair decision-making and discrimination against a particular community or a group.","Existing bias mitigation techniques only focus on bias generated from label heterogeneity in non-IID data without accounting for domain variations due to feature heterogeneity and do not address global group-fairness property.   ","Our work proposes a group-fair FL framework that minimizes group-bias while preserving privacy and without resource utilization overhead.","Our main idea is to leverage average conditional probabilities to compute a cross-domain group \\textit{importance weights} derived from heterogeneous training data to optimize the performance of the worst-performing group using a modified multiplicative weights update method.","Additionally, we propose regularization techniques to minimize the difference between the worst and best-performing groups while making sure through our thresholding mechanism to strike a balance between bias reduction and group performance degradation.","Our evaluation of human emotion recognition and image classification benchmarks assesses the fair decision-making of our framework in real-world heterogeneous settings."],"url":"http://arxiv.org/abs/2309.07085v1"}
{"created":"2023-09-13 16:52:23","title":"SupFusion: Supervised LiDAR-Camera Fusion for 3D Object Detection","abstract":"In this paper, we propose a novel training strategy called SupFusion, which provides an auxiliary feature level supervision for effective LiDAR-Camera fusion and significantly boosts detection performance. Our strategy involves a data enhancement method named Polar Sampling, which densifies sparse objects and trains an assistant model to generate high-quality features as the supervision. These features are then used to train the LiDAR-Camera fusion model, where the fusion feature is optimized to simulate the generated high-quality features. Furthermore, we propose a simple yet effective deep fusion module, which contiguously gains superior performance compared with previous fusion methods with SupFusion strategy. In such a manner, our proposal shares the following advantages. Firstly, SupFusion introduces auxiliary feature-level supervision which could boost LiDAR-Camera detection performance without introducing extra inference costs. Secondly, the proposed deep fusion could continuously improve the detector's abilities. Our proposed SupFusion and deep fusion module is plug-and-play, we make extensive experiments to demonstrate its effectiveness. Specifically, we gain around 2% 3D mAP improvements on KITTI benchmark based on multiple LiDAR-Camera 3D detectors.","sentences":["In this paper, we propose a novel training strategy called SupFusion, which provides an auxiliary feature level supervision for effective LiDAR-Camera fusion and significantly boosts detection performance.","Our strategy involves a data enhancement method named Polar Sampling, which densifies sparse objects and trains an assistant model to generate high-quality features as the supervision.","These features are then used to train the LiDAR-Camera fusion model, where the fusion feature is optimized to simulate the generated high-quality features.","Furthermore, we propose a simple yet effective deep fusion module, which contiguously gains superior performance compared with previous fusion methods with SupFusion strategy.","In such a manner, our proposal shares the following advantages.","Firstly, SupFusion introduces auxiliary feature-level supervision which could boost LiDAR-Camera detection performance without introducing extra inference costs.","Secondly, the proposed deep fusion could continuously improve the detector's abilities.","Our proposed SupFusion and deep fusion module is plug-and-play, we make extensive experiments to demonstrate its effectiveness.","Specifically, we gain around 2% 3D mAP improvements on KITTI benchmark based on multiple LiDAR-Camera 3D detectors."],"url":"http://arxiv.org/abs/2309.07084v1"}
{"created":"2023-09-13 16:33:27","title":"The Boundaries of Verifiable Accuracy, Robustness, and Generalisation in Deep Learning","abstract":"In this work, we assess the theoretical limitations of determining guaranteed stability and accuracy of neural networks in classification tasks. We consider classical distribution-agnostic framework and algorithms minimising empirical risks and potentially subjected to some weights regularisation. We show that there is a large family of tasks for which computing and verifying ideal stable and accurate neural networks in the above settings is extremely challenging, if at all possible, even when such ideal solutions exist within the given class of neural architectures.","sentences":["In this work, we assess the theoretical limitations of determining guaranteed stability and accuracy of neural networks in classification tasks.","We consider classical distribution-agnostic framework and algorithms minimising empirical risks and potentially subjected to some weights regularisation.","We show that there is a large family of tasks for which computing and verifying ideal stable and accurate neural networks in the above settings is extremely challenging, if at all possible, even when such ideal solutions exist within the given class of neural architectures."],"url":"http://arxiv.org/abs/2309.07072v1"}
{"created":"2023-09-13 16:28:43","title":"FAIR: Frequency-aware Image Restoration for Industrial Visual Anomaly Detection","abstract":"Image reconstruction-based anomaly detection models are widely explored in industrial visual inspection. However, existing models usually suffer from the trade-off between normal reconstruction fidelity and abnormal reconstruction distinguishability, which damages the performance. In this paper, we find that the above trade-off can be better mitigated by leveraging the distinct frequency biases between normal and abnormal reconstruction errors. To this end, we propose Frequency-aware Image Restoration (FAIR), a novel self-supervised image restoration task that restores images from their high-frequency components. It enables precise reconstruction of normal patterns while mitigating unfavorable generalization to anomalies. Using only a simple vanilla UNet, FAIR achieves state-of-the-art performance with higher efficiency on various defect detection datasets. Code: https://github.com/liutongkun/FAIR.","sentences":["Image reconstruction-based anomaly detection models are widely explored in industrial visual inspection.","However, existing models usually suffer from the trade-off between normal reconstruction fidelity and abnormal reconstruction distinguishability, which damages the performance.","In this paper, we find that the above trade-off can be better mitigated by leveraging the distinct frequency biases between normal and abnormal reconstruction errors.","To this end, we propose Frequency-aware Image Restoration (FAIR), a novel self-supervised image restoration task that restores images from their high-frequency components.","It enables precise reconstruction of normal patterns while mitigating unfavorable generalization to anomalies.","Using only a simple vanilla UNet, FAIR achieves state-of-the-art performance with higher efficiency on various defect detection datasets.","Code: https://github.com/liutongkun/FAIR."],"url":"http://arxiv.org/abs/2309.07068v1"}
{"created":"2023-09-13 16:28:10","title":"Data Pipeline Quality: Influencing Factors, Root Causes of Data-related Issues, and Processing Problem Areas for Developers","abstract":"Data pipelines are an integral part of various modern data-driven systems. However, despite their importance, they are often unreliable and deliver poor-quality data. A critical step toward improving this situation is a solid understanding of the aspects contributing to the quality of data pipelines. Therefore, this article first introduces a taxonomy of 41 factors that influence the ability of data pipelines to provide quality data. The taxonomy is based on a multivocal literature review and validated by eight interviews with experts from the data engineering domain. Data, infrastructure, life cycle management, development & deployment, and processing were found to be the main influencing themes. Second, we investigate the root causes of data-related issues, their location in data pipelines, and the main topics of data pipeline processing issues for developers by mining GitHub projects and Stack Overflow posts. We found data-related issues to be primarily caused by incorrect data types (33%), mainly occurring in the data cleaning stage of pipelines (35%). Data integration and ingestion tasks were found to be the most asked topics of developers, accounting for nearly half (47%) of all questions. Compatibility issues were found to be a separate problem area in addition to issues corresponding to the usual data pipeline processing areas (i.e., data loading, ingestion, integration, cleaning, and transformation). These findings suggest that future research efforts should focus on analyzing compatibility and data type issues in more depth and assisting developers in data integration and ingestion tasks. The proposed taxonomy is valuable to practitioners in the context of quality assurance activities and fosters future research into data pipeline quality.","sentences":["Data pipelines are an integral part of various modern data-driven systems.","However, despite their importance, they are often unreliable and deliver poor-quality data.","A critical step toward improving this situation is a solid understanding of the aspects contributing to the quality of data pipelines.","Therefore, this article first introduces a taxonomy of 41 factors that influence the ability of data pipelines to provide quality data.","The taxonomy is based on a multivocal literature review and validated by eight interviews with experts from the data engineering domain.","Data, infrastructure, life cycle management, development & deployment, and processing were found to be the main influencing themes.","Second, we investigate the root causes of data-related issues, their location in data pipelines, and the main topics of data pipeline processing issues for developers by mining GitHub projects and Stack Overflow posts.","We found data-related issues to be primarily caused by incorrect data types (33%), mainly occurring in the data cleaning stage of pipelines (35%).","Data integration and ingestion tasks were found to be the most asked topics of developers, accounting for nearly half (47%) of all questions.","Compatibility issues were found to be a separate problem area in addition to issues corresponding to the usual data pipeline processing areas (i.e., data loading, ingestion, integration, cleaning, and transformation).","These findings suggest that future research efforts should focus on analyzing compatibility and data type issues in more depth and assisting developers in data integration and ingestion tasks.","The proposed taxonomy is valuable to practitioners in the context of quality assurance activities and fosters future research into data pipeline quality."],"url":"http://arxiv.org/abs/2309.07067v1"}
{"created":"2023-09-13 16:26:48","title":"CLiFF-LHMP: Using Spatial Dynamics Patterns for Long-Term Human Motion Prediction","abstract":"Human motion prediction is important for mobile service robots and intelligent vehicles to operate safely and smoothly around people. The more accurate predictions are, particularly over extended periods of time, the better a system can, e.g., assess collision risks and plan ahead. In this paper, we propose to exploit maps of dynamics (MoDs, a class of general representations of place-dependent spatial motion patterns, learned from prior observations) for long-term human motion prediction (LHMP). We present a new MoD-informed human motion prediction approach, named CLiFF-LHMP, which is data efficient, explainable, and insensitive to errors from an upstream tracking system. Our approach uses CLiFF-map, a specific MoD trained with human motion data recorded in the same environment. We bias a constant velocity prediction with samples from the CLiFF-map to generate multi-modal trajectory predictions. In two public datasets we show that this algorithm outperforms the state of the art for predictions over very extended periods of time, achieving 45% more accurate prediction performance at 50s compared to the baseline.","sentences":["Human motion prediction is important for mobile service robots and intelligent vehicles to operate safely and smoothly around people.","The more accurate predictions are, particularly over extended periods of time, the better a system can, e.g., assess collision risks and plan ahead.","In this paper, we propose to exploit maps of dynamics (MoDs, a class of general representations of place-dependent spatial motion patterns, learned from prior observations) for long-term human motion prediction (LHMP).","We present a new MoD-informed human motion prediction approach, named CLiFF-LHMP, which is data efficient, explainable, and insensitive to errors from an upstream tracking system.","Our approach uses CLiFF-map, a specific MoD trained with human motion data recorded in the same environment.","We bias a constant velocity prediction with samples from the CLiFF-map to generate multi-modal trajectory predictions.","In two public datasets we show that this algorithm outperforms the state of the art for predictions over very extended periods of time, achieving 45% more accurate prediction performance at 50s compared to the baseline."],"url":"http://arxiv.org/abs/2309.07066v1"}
{"created":"2023-09-13 16:23:53","title":"A Comprehensive Analysis of the Role of Artificial Intelligence and Machine Learning in Modern Digital Forensics and Incident Response","abstract":"In the dynamic landscape of digital forensics, the integration of Artificial Intelligence (AI) and Machine Learning (ML) stands as a transformative technology, poised to amplify the efficiency and precision of digital forensics investigations. However, the use of ML and AI in digital forensics is still in its nascent stages. As a result, this paper gives a thorough and in-depth analysis that goes beyond a simple survey and review. The goal is to look closely at how AI and ML techniques are used in digital forensics and incident response. This research explores cutting-edge research initiatives that cross domains such as data collection and recovery, the intricate reconstruction of cybercrime timelines, robust big data analysis, pattern recognition, safeguarding the chain of custody, and orchestrating responsive strategies to hacking incidents. This endeavour digs far beneath the surface to unearth the intricate ways AI-driven methodologies are shaping these crucial facets of digital forensics practice. While the promise of AI in digital forensics is evident, the challenges arising from increasing database sizes and evolving criminal tactics necessitate ongoing collaborative research and refinement within the digital forensics profession. This study examines the contributions, limitations, and gaps in the existing research, shedding light on the potential and limitations of AI and ML techniques. By exploring these different research areas, we highlight the critical need for strategic planning, continual research, and development to unlock AI's full potential in digital forensics and incident response. Ultimately, this paper underscores the significance of AI and ML integration in digital forensics, offering insights into their benefits, drawbacks, and broader implications for tackling modern cyber threats.","sentences":["In the dynamic landscape of digital forensics, the integration of Artificial Intelligence (AI) and Machine Learning (ML) stands as a transformative technology, poised to amplify the efficiency and precision of digital forensics investigations.","However, the use of ML and AI in digital forensics is still in its nascent stages.","As a result, this paper gives a thorough and in-depth analysis that goes beyond a simple survey and review.","The goal is to look closely at how AI and ML techniques are used in digital forensics and incident response.","This research explores cutting-edge research initiatives that cross domains such as data collection and recovery, the intricate reconstruction of cybercrime timelines, robust big data analysis, pattern recognition, safeguarding the chain of custody, and orchestrating responsive strategies to hacking incidents.","This endeavour digs far beneath the surface to unearth the intricate ways AI-driven methodologies are shaping these crucial facets of digital forensics practice.","While the promise of AI in digital forensics is evident, the challenges arising from increasing database sizes and evolving criminal tactics necessitate ongoing collaborative research and refinement within the digital forensics profession.","This study examines the contributions, limitations, and gaps in the existing research, shedding light on the potential and limitations of AI and ML techniques.","By exploring these different research areas, we highlight the critical need for strategic planning, continual research, and development to unlock AI's full potential in digital forensics and incident response.","Ultimately, this paper underscores the significance of AI and ML integration in digital forensics, offering insights into their benefits, drawbacks, and broader implications for tackling modern cyber threats."],"url":"http://arxiv.org/abs/2309.07064v1"}
{"created":"2023-09-13 16:13:13","title":"Geospatial Tessellation in the Agent-In-Cell Model: A Framework for Agent-Based Modeling of Pandemic","abstract":"Agent-based simulation is a versatile and potent computational modeling technique employed to analyze intricate systems and phenomena spanning diverse fields. However, due to their computational intensity, agent-based models become more resource-demanding when geographic considerations are introduced. This study delves into diverse strategies for crafting a series of Agent-Based Models, named \"agent-in-the-cell,\" which emulate a city. These models, incorporating geographical attributes of the city and employing real-world open-source mobility data from Safegraph's publicly available dataset, simulate the dynamics of COVID spread under varying scenarios. The \"agent-in-the-cell\" concept designates that our representative agents, called meta-agents, are linked to specific home cells in the city's tessellation. We scrutinize tessellations of the mobility map with varying complexities and experiment with the agent density, ranging from matching the actual population to reducing the number of (meta-) agents for computational efficiency. Our findings demonstrate that tessellations constructed according to the Voronoi Diagram of specific location types on the street network better preserve dynamics compared to Census Block Group tessellations and better than Euclidean-based tessellations. Furthermore, the Voronoi Diagram tessellation and also a hybrid -- Voronoi Diagram - and Census Block Group - based -- tessellation require fewer meta-agents to adequately approximate full-scale dynamics. Our analysis spans a range of city sizes in the United States, encompassing small (Santa Fe, NM), medium (Seattle, WA), and large (Chicago, IL) urban areas. This examination also provides valuable insights into the effects of agent count reduction, varying sensitivity metrics, and the influence of city-specific factors.","sentences":["Agent-based simulation is a versatile and potent computational modeling technique employed to analyze intricate systems and phenomena spanning diverse fields.","However, due to their computational intensity, agent-based models become more resource-demanding when geographic considerations are introduced.","This study delves into diverse strategies for crafting a series of Agent-Based Models, named \"agent-in-the-cell,\" which emulate a city.","These models, incorporating geographical attributes of the city and employing real-world open-source mobility data from Safegraph's publicly available dataset, simulate the dynamics of COVID spread under varying scenarios.","The \"agent-in-the-cell\" concept designates that our representative agents, called meta-agents, are linked to specific home cells in the city's tessellation.","We scrutinize tessellations of the mobility map with varying complexities and experiment with the agent density, ranging from matching the actual population to reducing the number of (meta-) agents for computational efficiency.","Our findings demonstrate that tessellations constructed according to the Voronoi Diagram of specific location types on the street network better preserve dynamics compared to Census Block Group tessellations and better than Euclidean-based tessellations.","Furthermore, the Voronoi Diagram tessellation and also a hybrid -- Voronoi Diagram - and Census Block Group - based -- tessellation require fewer meta-agents to adequately approximate full-scale dynamics.","Our analysis spans a range of city sizes in the United States, encompassing small (Santa Fe, NM), medium (Seattle, WA), and large (Chicago, IL) urban areas.","This examination also provides valuable insights into the effects of agent count reduction, varying sensitivity metrics, and the influence of city-specific factors."],"url":"http://arxiv.org/abs/2309.07055v1"}
{"created":"2023-09-13 16:12:11","title":"Aggregating Long-term Sharp Features via Hybrid Transformers for Video Deblurring","abstract":"Video deblurring methods, aiming at recovering consecutive sharp frames from a given blurry video, usually assume that the input video suffers from consecutively blurry frames. However, in real-world blurry videos taken by modern imaging devices, sharp frames usually appear in the given video, thus making temporal long-term sharp features available for facilitating the restoration of a blurry frame. In this work, we propose a video deblurring method that leverages both neighboring frames and present sharp frames using hybrid Transformers for feature aggregation. Specifically, we first train a blur-aware detector to distinguish between sharp and blurry frames. Then, a window-based local Transformer is employed for exploiting features from neighboring frames, where cross attention is beneficial for aggregating features from neighboring frames without explicit spatial alignment. To aggregate long-term sharp features from detected sharp frames, we utilize a global Transformer with multi-scale matching capability. Moreover, our method can easily be extended to event-driven video deblurring by incorporating an event fusion module into the global Transformer. Extensive experiments on benchmark datasets demonstrate that our proposed method outperforms state-of-the-art video deblurring methods as well as event-driven video deblurring methods in terms of quantitative metrics and visual quality. The source code and trained models are available at https://github.com/shangwei5/STGTN.","sentences":["Video deblurring methods, aiming at recovering consecutive sharp frames from a given blurry video, usually assume that the input video suffers from consecutively blurry frames.","However, in real-world blurry videos taken by modern imaging devices, sharp frames usually appear in the given video, thus making temporal long-term sharp features available for facilitating the restoration of a blurry frame.","In this work, we propose a video deblurring method that leverages both neighboring frames and present sharp frames using hybrid Transformers for feature aggregation.","Specifically, we first train a blur-aware detector to distinguish between sharp and blurry frames.","Then, a window-based local Transformer is employed for exploiting features from neighboring frames, where cross attention is beneficial for aggregating features from neighboring frames without explicit spatial alignment.","To aggregate long-term sharp features from detected sharp frames, we utilize a global Transformer with multi-scale matching capability.","Moreover, our method can easily be extended to event-driven video deblurring by incorporating an event fusion module into the global Transformer.","Extensive experiments on benchmark datasets demonstrate that our proposed method outperforms state-of-the-art video deblurring methods as well as event-driven video deblurring methods in terms of quantitative metrics and visual quality.","The source code and trained models are available at https://github.com/shangwei5/STGTN."],"url":"http://arxiv.org/abs/2309.07054v1"}
{"created":"2023-09-13 16:09:13","title":"Pearl's and Jeffrey's Update as Modes of Learning in Probabilistic Programming","abstract":"The concept of updating a probability distribution in the light of new evidence lies at the heart of statistics and machine learning. Pearl's and Jeffrey's rule are two natural update mechanisms which lead to different outcomes, yet the similarities and differences remain mysterious. This paper clarifies their relationship in several ways: via separate descriptions of the two update mechanisms in terms of probabilistic programs and sampling semantics, and via different notions of likelihood (for Pearl and for Jeffrey). Moreover, it is shown that Jeffrey's update rule arises via variational inference. In terms of categorical probability theory, this amounts to an analysis of the situation in terms of the behaviour of the multiset functor, extended to the Kleisli category of the distribution monad.","sentences":["The concept of updating a probability distribution in the light of new evidence lies at the heart of statistics and machine learning.","Pearl's and Jeffrey's rule are two natural update mechanisms which lead to different outcomes, yet the similarities and differences remain mysterious.","This paper clarifies their relationship in several ways: via separate descriptions of the two update mechanisms in terms of probabilistic programs and sampling semantics, and via different notions of likelihood (for Pearl and for Jeffrey).","Moreover, it is shown that Jeffrey's update rule arises via variational inference.","In terms of categorical probability theory, this amounts to an analysis of the situation in terms of the behaviour of the multiset functor, extended to the Kleisli category of the distribution monad."],"url":"http://arxiv.org/abs/2309.07053v1"}
{"created":"2023-09-13 16:07:25","title":"UnifiedGesture: A Unified Gesture Synthesis Model for Multiple Skeletons","abstract":"The automatic co-speech gesture generation draws much attention in computer animation. Previous works designed network structures on individual datasets, which resulted in a lack of data volume and generalizability across different motion capture standards. In addition, it is a challenging task due to the weak correlation between speech and gestures. To address these problems, we present UnifiedGesture, a novel diffusion model-based speech-driven gesture synthesis approach, trained on multiple gesture datasets with different skeletons. Specifically, we first present a retargeting network to learn latent homeomorphic graphs for different motion capture standards, unifying the representations of various gestures while extending the dataset. We then capture the correlation between speech and gestures based on a diffusion model architecture using cross-local attention and self-attention to generate better speech-matched and realistic gestures. To further align speech and gesture and increase diversity, we incorporate reinforcement learning on the discrete gesture units with a learned reward function. Extensive experiments show that UnifiedGesture outperforms recent approaches on speech-driven gesture generation in terms of CCA, FGD, and human-likeness. All code, pre-trained models, databases, and demos are available to the public at https://github.com/YoungSeng/UnifiedGesture.","sentences":["The automatic co-speech gesture generation draws much attention in computer animation.","Previous works designed network structures on individual datasets, which resulted in a lack of data volume and generalizability across different motion capture standards.","In addition, it is a challenging task due to the weak correlation between speech and gestures.","To address these problems, we present UnifiedGesture, a novel diffusion model-based speech-driven gesture synthesis approach, trained on multiple gesture datasets with different skeletons.","Specifically, we first present a retargeting network to learn latent homeomorphic graphs for different motion capture standards, unifying the representations of various gestures while extending the dataset.","We then capture the correlation between speech and gestures based on a diffusion model architecture using cross-local attention and self-attention to generate better speech-matched and realistic gestures.","To further align speech and gesture and increase diversity, we incorporate reinforcement learning on the discrete gesture units with a learned reward function.","Extensive experiments show that UnifiedGesture outperforms recent approaches on speech-driven gesture generation in terms of CCA, FGD, and human-likeness.","All code, pre-trained models, databases, and demos are available to the public at https://github.com/YoungSeng/UnifiedGesture."],"url":"http://arxiv.org/abs/2309.07051v1"}
{"created":"2023-09-13 15:59:41","title":"Multi-Robot Informative Path Planning from Regression with Sparse Gaussian Processes","abstract":"This paper addresses multi-robot informative path planning (IPP) for environmental monitoring. The problem involves determining informative regions in the environment that should be visited by robots in order to gather the most information about the environment. We propose an efficient sparse Gaussian process-based approach that uses gradient descent to optimize paths in continuous environments. Our approach efficiently scales to both spatially and spatio-temporally correlated environments. Moreover, our approach can simultaneously optimize the informative paths while accounting for routing constraints, such as a distance budget and limits on the robot's velocity and acceleration. Our approach can be used for IPP with both discrete and continuous sensing robots, with point and non-point field-of-view sensing shapes, and for multi-robot IPP. The proposed approach is demonstrated to be fast and accurate on real-world data.","sentences":["This paper addresses multi-robot informative path planning (IPP) for environmental monitoring.","The problem involves determining informative regions in the environment that should be visited by robots in order to gather the most information about the environment.","We propose an efficient sparse Gaussian process-based approach that uses gradient descent to optimize paths in continuous environments.","Our approach efficiently scales to both spatially and spatio-temporally correlated environments.","Moreover, our approach can simultaneously optimize the informative paths while accounting for routing constraints, such as a distance budget and limits on the robot's velocity and acceleration.","Our approach can be used for IPP with both discrete and continuous sensing robots, with point and non-point field-of-view sensing shapes, and for multi-robot IPP.","The proposed approach is demonstrated to be fast and accurate on real-world data."],"url":"http://arxiv.org/abs/2309.07050v1"}
{"created":"2023-09-13 15:56:50","title":"SafetyBench: Evaluating the Safety of Large Language Models with Multiple Choice Questions","abstract":"With the rapid development of Large Language Models (LLMs), increasing attention has been paid to their safety concerns. Consequently, evaluating the safety of LLMs has become an essential task for facilitating the broad applications of LLMs. Nevertheless, the absence of comprehensive safety evaluation benchmarks poses a significant impediment to effectively assess and enhance the safety of LLMs. In this work, we present SafetyBench, a comprehensive benchmark for evaluating the safety of LLMs, which comprises 11,435 diverse multiple choice questions spanning across 7 distinct categories of safety concerns. Notably, SafetyBench also incorporates both Chinese and English data, facilitating the evaluation in both languages. Our extensive tests over 25 popular Chinese and English LLMs in both zero-shot and few-shot settings reveal a substantial performance advantage for GPT-4 over its counterparts, and there is still significant room for improving the safety of current LLMs. We believe SafetyBench will enable fast and comprehensive evaluation of LLMs' safety, and foster the development of safer LLMs. Data and evaluation guidelines are available at https://github.com/thu-coai/SafetyBench. Submission entrance and leaderboard are available at https://llmbench.ai/safety.","sentences":["With the rapid development of Large Language Models (LLMs), increasing attention has been paid to their safety concerns.","Consequently, evaluating the safety of LLMs has become an essential task for facilitating the broad applications of LLMs.","Nevertheless, the absence of comprehensive safety evaluation benchmarks poses a significant impediment to effectively assess and enhance the safety of LLMs.","In this work, we present SafetyBench, a comprehensive benchmark for evaluating the safety of LLMs, which comprises 11,435 diverse multiple choice questions spanning across 7 distinct categories of safety concerns.","Notably, SafetyBench also incorporates both Chinese and English data, facilitating the evaluation in both languages.","Our extensive tests over 25 popular Chinese and English LLMs in both zero-shot and few-shot settings reveal a substantial performance advantage for GPT-4 over its counterparts, and there is still significant room for improving the safety of current LLMs.","We believe SafetyBench will enable fast and comprehensive evaluation of LLMs' safety, and foster the development of safer LLMs.","Data and evaluation guidelines are available at https://github.com/thu-coai/SafetyBench.","Submission entrance and leaderboard are available at https://llmbench.ai/safety."],"url":"http://arxiv.org/abs/2309.07045v1"}
{"created":"2023-09-13 15:46:40","title":"Efficient Reinforcement Learning for Jumping Monopods","abstract":"In this work, we consider the complex control problem of making a monopod reach a target with a jump. The monopod can jump in any direction and the terrain underneath its foot can be uneven. This is a template of a much larger class of problems, which are extremely challenging and computationally expensive to solve using standard optimisation-based techniques. Reinforcement Learning (RL) could be an interesting alternative, but the application of an end-to-end approach in which the controller must learn everything from scratch, is impractical. The solution advocated in this paper is to guide the learning process within an RL framework by injecting physical knowledge. This expedient brings to widespread benefits, such as a drastic reduction of the learning time, and the ability to learn and compensate for possible errors in the low-level controller executing the motion. We demonstrate the advantage of our approach with respect to both optimization-based and end-to-end RL approaches.","sentences":["In this work, we consider the complex control problem of making a monopod reach a target with a jump.","The monopod can jump in any direction and the terrain underneath its foot can be uneven.","This is a template of a much larger class of problems, which are extremely challenging and computationally expensive to solve using standard optimisation-based techniques.","Reinforcement Learning (RL) could be an interesting alternative, but the application of an end-to-end approach in which the controller must learn everything from scratch, is impractical.","The solution advocated in this paper is to guide the learning process within an RL framework by injecting physical knowledge.","This expedient brings to widespread benefits, such as a drastic reduction of the learning time, and the ability to learn and compensate for possible errors in the low-level controller executing the motion.","We demonstrate the advantage of our approach with respect to both optimization-based and end-to-end RL approaches."],"url":"http://arxiv.org/abs/2309.07038v1"}
{"created":"2023-09-13 15:42:06","title":"How (Not) to Use Sociodemographic Information for Subjective NLP Tasks","abstract":"Annotators' sociodemographic backgrounds (i.e., the individual compositions of their gender, age, educational background, etc.) have a strong impact on their decisions when working on subjective NLP tasks, such as hate speech detection. Often, heterogeneous backgrounds result in high disagreements. To model this variation, recent work has explored sociodemographic prompting, a technique, which steers the output of prompt-based models towards answers that humans with specific sociodemographic profiles would give. However, the available NLP literature disagrees on the efficacy of this technique -- it remains unclear, for which tasks and scenarios it can help and evaluations are limited to specific tasks only. We address this research gap by presenting the largest and most comprehensive study of sociodemographic prompting today. Concretely, we evaluate several prompt formulations across seven datasets and six instruction-tuned model families. We find that (1) while sociodemographic prompting can be beneficial for improving zero-shot learning in subjective NLP tasks, (2) its outcomes largely vary for different model types, sizes, and datasets, (3) are subject to large variance with regards to prompt formulations. Thus, sociodemographic prompting is not a reliable proxy for traditional data annotation with a sociodemographically heterogeneous group of annotators. Instead, we propose (4) to use it for identifying ambiguous instances resulting in more informed annotation efforts.","sentences":["Annotators' sociodemographic backgrounds (i.e., the individual compositions of their gender, age, educational background, etc.) have a strong impact on their decisions when working on subjective NLP tasks, such as hate speech detection.","Often, heterogeneous backgrounds result in high disagreements.","To model this variation, recent work has explored sociodemographic prompting, a technique, which steers the output of prompt-based models towards answers that humans with specific sociodemographic profiles would give.","However, the available NLP literature disagrees on the efficacy of this technique -- it remains unclear, for which tasks and scenarios it can help and evaluations are limited to specific tasks only.","We address this research gap by presenting the largest and most comprehensive study of sociodemographic prompting today.","Concretely, we evaluate several prompt formulations across seven datasets and six instruction-tuned model families.","We find that (1) while sociodemographic prompting can be beneficial for improving zero-shot learning in subjective NLP tasks, (2) its outcomes largely vary for different model types, sizes, and datasets, (3) are subject to large variance with regards to prompt formulations.","Thus, sociodemographic prompting is not a reliable proxy for traditional data annotation with a sociodemographically heterogeneous group of annotators.","Instead, we propose (4) to use it for identifying ambiguous instances resulting in more informed annotation efforts."],"url":"http://arxiv.org/abs/2309.07034v1"}
{"created":"2023-09-13 15:41:16","title":"Human-Robot Co-creativity: A Scoping Review -- Informing a Research Agenda for Human-Robot Co-Creativity with Older Adults","abstract":"This review is the first step in a long-term research project exploring how social robotics and AI-generated content can contribute to the creative experiences of older adults, with a focus on collaborative drawing and painting. We systematically searched and selected literature on human-robot co-creativity, and analyzed articles to identify methods and strategies for researching co-creative robotics. We found that none of the studies involved older adults, which shows the gap in the literature for this often involved participant group in robotics research. The analyzed literature provides valuable insights into the design of human-robot co-creativity and informs a research agenda to further investigate the topic with older adults. We argue that future research should focus on ecological and developmental perspectives on creativity, on how system behavior can be aligned with the values of older adults, and on the system structures that support this best.","sentences":["This review is the first step in a long-term research project exploring how social robotics and AI-generated content can contribute to the creative experiences of older adults, with a focus on collaborative drawing and painting.","We systematically searched and selected literature on human-robot co-creativity, and analyzed articles to identify methods and strategies for researching co-creative robotics.","We found that none of the studies involved older adults, which shows the gap in the literature for this often involved participant group in robotics research.","The analyzed literature provides valuable insights into the design of human-robot co-creativity and informs a research agenda to further investigate the topic with older adults.","We argue that future research should focus on ecological and developmental perspectives on creativity, on how system behavior can be aligned with the values of older adults, and on the system structures that support this best."],"url":"http://arxiv.org/abs/2309.07033v1"}
{"created":"2023-09-13 15:36:39","title":"Optimal transport distances for directed, weighted graphs: a case study with cell-cell communication networks","abstract":"Comparing graphs of optimal transport has recently gained significant attention, as the distances induced by optimal transport provide both a principled metric between graphs as well as an interpretable description of the associated changes between graphs in terms of a transport plan. As the lack of symmetry introduces challenges in the typically considered formulations, optimal transport distances for graphs have mostly been developed for undirected graphs. Here, we propose two distance measures to compare directed graphs based on variants of optimal transport: (i) an earth movers distance (Wasserstein) and (ii) a Gromov-Wasserstein (GW) distance. We evaluate these two distances and discuss their relative performance for both simulated graph data and real-world directed cell-cell communication graphs, inferred from single-cell RNA-seq data.","sentences":["Comparing graphs of optimal transport has recently gained significant attention, as the distances induced by optimal transport provide both a principled metric between graphs as well as an interpretable description of the associated changes between graphs in terms of a transport plan.","As the lack of symmetry introduces challenges in the typically considered formulations, optimal transport distances for graphs have mostly been developed for undirected graphs.","Here, we propose two distance measures to compare directed graphs based on variants of optimal transport: (i) an earth movers distance (Wasserstein) and (ii) a Gromov-Wasserstein (GW) distance.","We evaluate these two distances and discuss their relative performance for both simulated graph data and real-world directed cell-cell communication graphs, inferred from single-cell RNA-seq data."],"url":"http://arxiv.org/abs/2309.07030v1"}
{"created":"2023-09-13 15:33:29","title":"Human-Machine Co-Creativity with Older Adults -- A Learning Community to Study Explainable Dialogues","abstract":"This position paper is part of a long-term research project on human-machine co-creativity with older adults. The goal is to investigate how robots and AI-generated content can contribute to older adults' creative experiences, with a focus on collaborative drawing and painting. The research has recently started, and current activities are centred around literature studies, interviews with seniors and artists, and developing initial prototypes. In addition, a course \"Drawing with Robots\", is being developed to establish collaboration between human and machine learners: older adults, artists, students, researchers, and artificial agents. We present this course as a learning community and as an opportunity for studying how explainable AI and creative dialogues can be intertwined in human-machine co-creativity with older adults.","sentences":["This position paper is part of a long-term research project on human-machine co-creativity with older adults.","The goal is to investigate how robots and AI-generated content can contribute to older adults' creative experiences, with a focus on collaborative drawing and painting.","The research has recently started, and current activities are centred around literature studies, interviews with seniors and artists, and developing initial prototypes.","In addition, a course \"Drawing with Robots\", is being developed to establish collaboration between human and machine learners: older adults, artists, students, researchers, and artificial agents.","We present this course as a learning community and as an opportunity for studying how explainable AI and creative dialogues can be intertwined in human-machine co-creativity with older adults."],"url":"http://arxiv.org/abs/2309.07028v1"}
{"created":"2023-09-13 15:31:50","title":"APICom: Automatic API Completion via Prompt Learning and Adversarial Training-based Data Augmentation","abstract":"Based on developer needs and usage scenarios, API (Application Programming Interface) recommendation is the process of assisting developers in finding the required API among numerous candidate APIs. Previous studies mainly modeled API recommendation as the recommendation task, which can recommend multiple candidate APIs for the given query, and developers may not yet be able to find what they need. Motivated by the neural machine translation research domain, we can model this problem as the generation task, which aims to directly generate the required API for the developer query. After our preliminary investigation, we find the performance of this intuitive approach is not promising. The reason is that there exists an error when generating the prefixes of the API. However, developers may know certain API prefix information during actual development in most cases. Therefore, we model this problem as the automatic completion task and propose a novel approach APICom based on prompt learning, which can generate API related to the query according to the prompts (i.e., API prefix information). Moreover, the effectiveness of APICom highly depends on the quality of the training dataset. In this study, we further design a novel gradient-based adversarial training method {\\atpart} for data augmentation, which can improve the normalized stability when generating adversarial examples. To evaluate the effectiveness of APICom, we consider a corpus of 33k developer queries and corresponding APIs. Compared with the state-of-the-art baselines, our experimental results show that APICom can outperform all baselines by at least 40.02\\%, 13.20\\%, and 16.31\\% in terms of the performance measures EM@1, MRR, and MAP. Finally, our ablation studies confirm the effectiveness of our component setting (such as our designed adversarial training method, our used pre-trained model, and prompt learning) in APICom.","sentences":["Based on developer needs and usage scenarios, API (Application Programming Interface) recommendation is the process of assisting developers in finding the required API among numerous candidate APIs.","Previous studies mainly modeled API recommendation as the recommendation task, which can recommend multiple candidate APIs for the given query, and developers may not yet be able to find what they need.","Motivated by the neural machine translation research domain, we can model this problem as the generation task, which aims to directly generate the required API for the developer query.","After our preliminary investigation, we find the performance of this intuitive approach is not promising.","The reason is that there exists an error when generating the prefixes of the API.","However, developers may know certain API prefix information during actual development in most cases.","Therefore, we model this problem as the automatic completion task and propose a novel approach APICom based on prompt learning, which can generate API related to the query according to the prompts (i.e., API prefix information).","Moreover, the effectiveness of APICom highly depends on the quality of the training dataset.","In this study, we further design a novel gradient-based adversarial training method {\\atpart} for data augmentation, which can improve the normalized stability when generating adversarial examples.","To evaluate the effectiveness of APICom, we consider a corpus of 33k developer queries and corresponding APIs.","Compared with the state-of-the-art baselines, our experimental results show that APICom can outperform all baselines by at least 40.02\\%, 13.20\\%, and 16.31\\% in terms of the performance measures EM@1, MRR, and MAP.","Finally, our ablation studies confirm the effectiveness of our component setting (such as our designed adversarial training method, our used pre-trained model, and prompt learning) in APICom."],"url":"http://arxiv.org/abs/2309.07026v1"}
{"created":"2023-09-13 15:29:52","title":"Cryptography: Against AI and QAI Odds","abstract":"Artificial Intelligence (AI) presents prodigious technological prospects for development, however, all that glitters is not gold! The cyber-world faces the worst nightmare with the advent of AI and quantum computers. Together with Quantum Artificial Intelligence (QAI), they pose a catastrophic threat to modern cryptography. It would also increase the capability of cryptanalysts manifold, with its built-in persistent and extensive predictive intelligence. This prediction ability incapacitates the constrained message space in device cryptography. With the comparison of these assumptions and the intercepted ciphertext, the code-cracking process will considerably accelerate. Before the vigorous and robust developments in AI, we have never faced and never had to prepare for such a plaintext-originating attack. The supremacy of AI can be challenged by creating ciphertexts that would give the AI attacker erroneous responses stymied by randomness and misdirect them. AI threat is deterred by deviating from the conventional use of small, known-size keys and pattern-loaded ciphers. The strategy is vested in implementing larger secret size keys, supplemented by ad-hoc unilateral randomness of unbound limitations and a pattern-devoid technique. The very large key size can be handled with low processing and computational burden to achieve desired unicity distances. The strategy against AI odds is feasible by implementing non-algorithmic randomness, large and inexpensive memory chips, and wide-area communication networks. The strength of AI, i.e., randomness and pattern detection can be used to generate highly optimized ciphers and algorithms. These pattern-devoid, randomness-rich ciphers also provide a timely and plausible solution for NIST's proactive approach toward the quantum challenge.","sentences":["Artificial Intelligence (AI) presents prodigious technological prospects for development, however, all that glitters is not gold!","The cyber-world faces the worst nightmare with the advent of AI and quantum computers.","Together with Quantum Artificial Intelligence (QAI), they pose a catastrophic threat to modern cryptography.","It would also increase the capability of cryptanalysts manifold, with its built-in persistent and extensive predictive intelligence.","This prediction ability incapacitates the constrained message space in device cryptography.","With the comparison of these assumptions and the intercepted ciphertext, the code-cracking process will considerably accelerate.","Before the vigorous and robust developments in AI, we have never faced and never had to prepare for such a plaintext-originating attack.","The supremacy of AI can be challenged by creating ciphertexts that would give the AI attacker erroneous responses stymied by randomness and misdirect them.","AI threat is deterred by deviating from the conventional use of small, known-size keys and pattern-loaded ciphers.","The strategy is vested in implementing larger secret size keys, supplemented by ad-hoc unilateral randomness of unbound limitations and a pattern-devoid technique.","The very large key size can be handled with low processing and computational burden to achieve desired unicity distances.","The strategy against AI odds is feasible by implementing non-algorithmic randomness, large and inexpensive memory chips, and wide-area communication networks.","The strength of AI, i.e., randomness and pattern detection can be used to generate highly optimized ciphers and algorithms.","These pattern-devoid, randomness-rich ciphers also provide a timely and plausible solution for NIST's proactive approach toward the quantum challenge."],"url":"http://arxiv.org/abs/2309.07022v1"}
{"created":"2023-09-13 15:23:43","title":"Exploiting Multiple Priors for Neural 3D Indoor Reconstruction","abstract":"Neural implicit modeling permits to achieve impressive 3D reconstruction results on small objects, while it exhibits significant limitations in large indoor scenes. In this work, we propose a novel neural implicit modeling method that leverages multiple regularization strategies to achieve better reconstructions of large indoor environments, while relying only on images. A sparse but accurate depth prior is used to anchor the scene to the initial model. A dense but less accurate depth prior is also introduced, flexible enough to still let the model diverge from it to improve the estimated geometry. Then, a novel self-supervised strategy to regularize the estimated surface normals is presented. Finally, a learnable exposure compensation scheme permits to cope with challenging lighting conditions. Experimental results show that our approach produces state-of-the-art 3D reconstructions in challenging indoor scenarios.","sentences":["Neural implicit modeling permits to achieve impressive 3D reconstruction results on small objects, while it exhibits significant limitations in large indoor scenes.","In this work, we propose a novel neural implicit modeling method that leverages multiple regularization strategies to achieve better reconstructions of large indoor environments, while relying only on images.","A sparse but accurate depth prior is used to anchor the scene to the initial model.","A dense but less accurate depth prior is also introduced, flexible enough to still let the model diverge from it to improve the estimated geometry.","Then, a novel self-supervised strategy to regularize the estimated surface normals is presented.","Finally, a learnable exposure compensation scheme permits to cope with challenging lighting conditions.","Experimental results show that our approach produces state-of-the-art 3D reconstructions in challenging indoor scenarios."],"url":"http://arxiv.org/abs/2309.07021v1"}
{"created":"2023-09-13 15:23:30","title":"Beyond original Research Articles Categorization via NLP","abstract":"This work proposes a novel approach to text categorization -- for unknown categories -- in the context of scientific literature, using Natural Language Processing techniques. The study leverages the power of pre-trained language models, specifically SciBERT, to extract meaningful representations of abstracts from the ArXiv dataset. Text categorization is performed using the K-Means algorithm, and the optimal number of clusters is determined based on the Silhouette score. The results demonstrate that the proposed approach captures subject information more effectively than the traditional arXiv labeling system, leading to improved text categorization. The approach offers potential for better navigation and recommendation systems in the rapidly growing landscape of scientific research literature.","sentences":["This work proposes a novel approach to text categorization -- for unknown categories -- in the context of scientific literature, using Natural Language Processing techniques.","The study leverages the power of pre-trained language models, specifically SciBERT, to extract meaningful representations of abstracts from the ArXiv dataset.","Text categorization is performed using the K-Means algorithm, and the optimal number of clusters is determined based on the Silhouette score.","The results demonstrate that the proposed approach captures subject information more effectively than the traditional arXiv labeling system, leading to improved text categorization.","The approach offers potential for better navigation and recommendation systems in the rapidly growing landscape of scientific research literature."],"url":"http://arxiv.org/abs/2309.07020v1"}
{"created":"2023-09-13 15:19:03","title":"Perfect Roman Domination and Unique Response Roman Domination","abstract":"The idea of enumeration algorithms with polynomial delay is to polynomially bound the running time between any two subsequent solutions output by the enumeration algorithm. While it is open for more than four decades if all minimal dominating sets of a graph can be enumerated in output-polynomial time, it has recently been proven that pointwise-minimal Roman dominating functions can be enumerated even with polynomial delay. The idea of the enumeration algorithm was to use polynomial-time solvable extension problems. We use this as a motivation to prove that also two variants of Roman dominating functions studied in the literature, named perfect and unique response, can be enumerated with polynomial delay. This is interesting since Extension Perfect Roman Domination is W[1]-complete if parameterized by the weight of the given function and even W[2]-complete if parameterized by the number vertices assigned 0 in the pre-solution, as we prove. Otherwise, efficient solvability of extension problems and enumerability with polynomial delay tend to go hand-in-hand. We achieve our enumeration result by constructing a bijection to Roman dominating functions, where the corresponding extension problem is polynomimaltime solvable. Furthermore, we show that Unique Response Roman Domination is solvable in polynomial time on split graphs, while Perfect Roman Domination is NP-complete on this graph class, which proves that both variations, albeit coming with a very similar definition, do differ in some complexity aspects. This way, we also solve an open problem from the literature.","sentences":["The idea of enumeration algorithms with polynomial delay is to polynomially bound the running time between any two subsequent solutions output by the enumeration algorithm.","While it is open for more than four decades if all minimal dominating sets of a graph can be enumerated in output-polynomial time, it has recently been proven that pointwise-minimal Roman dominating functions can be enumerated even with polynomial delay.","The idea of the enumeration algorithm was to use polynomial-time solvable extension problems.","We use this as a motivation to prove that also two variants of Roman dominating functions studied in the literature, named perfect and unique response, can be enumerated with polynomial delay.","This is interesting since Extension Perfect Roman Domination is W[1]-complete if parameterized by the weight of the given function and even W[2]-complete if parameterized by the number vertices assigned 0 in the pre-solution, as we prove.","Otherwise, efficient solvability of extension problems and enumerability with polynomial delay tend to go hand-in-hand.","We achieve our enumeration result by constructing a bijection to Roman dominating functions, where the corresponding extension problem is polynomimaltime solvable.","Furthermore, we show that Unique Response Roman Domination is solvable in polynomial time on split graphs, while Perfect Roman Domination is NP-complete on this graph class, which proves that both variations, albeit coming with a very similar definition, do differ in some complexity aspects.","This way, we also solve an open problem from the literature."],"url":"http://arxiv.org/abs/2309.07018v1"}
{"created":"2023-09-13 15:17:29","title":"R\u00e9sum\u00e9 Parsing as Hierarchical Sequence Labeling: An Empirical Study","abstract":"Extracting information from r\\'esum\\'es is typically formulated as a two-stage problem, where the document is first segmented into sections and then each section is processed individually to extract the target entities. Instead, we cast the whole problem as sequence labeling in two levels -- lines and tokens -- and study model architectures for solving both tasks simultaneously. We build high-quality r\\'esum\\'e parsing corpora in English, French, Chinese, Spanish, German, Portuguese, and Swedish. Based on these corpora, we present experimental results that demonstrate the effectiveness of the proposed models for the information extraction task, outperforming approaches introduced in previous work. We conduct an ablation study of the proposed architectures. We also analyze both model performance and resource efficiency, and describe the trade-offs for model deployment in the context of a production environment.","sentences":["Extracting information from r\\'esum\\'es is typically formulated as a two-stage problem, where the document is first segmented into sections and then each section is processed individually to extract the target entities.","Instead, we cast the whole problem as sequence labeling in two levels -- lines and tokens -- and study model architectures for solving both tasks simultaneously.","We build high-quality r\\'esum\\'e parsing corpora in English, French, Chinese, Spanish, German, Portuguese, and Swedish.","Based on these corpora, we present experimental results that demonstrate the effectiveness of the proposed models for the information extraction task, outperforming approaches introduced in previous work.","We conduct an ablation study of the proposed architectures.","We also analyze both model performance and resource efficiency, and describe the trade-offs for model deployment in the context of a production environment."],"url":"http://arxiv.org/abs/2309.07015v1"}
{"created":"2023-09-13 15:12:52","title":"Using Lidar Intensity for Robot Navigation","abstract":"We present Multi-Layer Intensity Map, a novel 3D object representation for robot perception and autonomous navigation. They consist of multiple stacked layers of 2D grid maps each derived from reflected point cloud intensities corresponding to a certain height interval. The different layers of the intensity maps can be used to simultaneously estimate obstacles' height, solidity/density, and opacity. We demonstrate that they can help accurately differentiate obstacles that are safe to navigate through (e.g. beaded/string curtains, pliable tall grass), from ones that must be avoided (e.g. transparent surfaces such as glass walls, bushes, trees, etc.) in indoor and outdoor environments. Further, to handle narrow passages, and navigate through non-solid obstacles in dense environments, we propose an approach to adaptively inflate or enlarge the obstacles detected on intensity maps based on their solidity, and the robot's preferred velocity direction. We demonstrate these improved navigation capabilities in real-world narrow, dense environments using a real Turtlebot and Boston Dynamics Spot. We observe significant increases in success rates (up to 50%), a 9.55% decrease in trajectory length, and up to a 10.9% increase in the F-score compared to current navigation methods using other sensor modalities.","sentences":["We present Multi-Layer Intensity Map, a novel 3D object representation for robot perception and autonomous navigation.","They consist of multiple stacked layers of 2D grid maps each derived from reflected point cloud intensities corresponding to a certain height interval.","The different layers of the intensity maps can be used to simultaneously estimate obstacles' height, solidity/density, and opacity.","We demonstrate that they can help accurately differentiate obstacles that are safe to navigate through (e.g. beaded/string curtains, pliable tall grass), from ones that must be avoided (e.g. transparent surfaces such as glass walls, bushes, trees, etc.)","in indoor and outdoor environments.","Further, to handle narrow passages, and navigate through non-solid obstacles in dense environments, we propose an approach to adaptively inflate or enlarge the obstacles detected on intensity maps based on their solidity, and the robot's preferred velocity direction.","We demonstrate these improved navigation capabilities in real-world narrow, dense environments using a real Turtlebot and Boston Dynamics Spot.","We observe significant increases in success rates (up to 50%), a 9.55% decrease in trajectory length, and up to a 10.9% increase in the F-score compared to current navigation methods using other sensor modalities."],"url":"http://arxiv.org/abs/2309.07014v1"}
{"created":"2023-09-13 15:03:18","title":"Asynchronous Collective Tree Exploration by Tree-Mining","abstract":"We investigate the problem of collaborative tree exploration with complete communication introduced by [FGKP06], in which a group of $k$ agents is assigned to collectively go through all edges of an unknown tree in an efficient manner and then return to the origin. The agents have unrestricted communication and computation capabilities. The algorithm's runtime is typically compared to the cost of offline traversal, which is at least $\\max\\{2n/k,2D\\}$ where $n$ is the number of nodes and $D$ is the tree depth. Since its introduction, two types of guarantee have emerged on the topic: the first is of the form $r(k)(n/k+D)$, where $r(k)$ is called the competitive ratio, and the other is of the form $2n/k+f(k,D)$, where $f(k,D)$ is called the competitive overhead. In this paper, we present the first algorithm with linear-in-$D$ competitive overhead, thereby reconciling both approaches. Specifically, our bound is in $2n/k + O(k^{\\log_2 k} D)$ and thus leads to a competitive ratio in $O(k/\\exp(0.8\\sqrt{\\ln k}))$. This is the first improvement over the $O(k/\\ln k)$-competitive algorithm known since the introduction of the problem in 2004. Our algorithm is obtained for an asynchronous generalization of collective tree exploration (ACTE). It is an instance of a general class of locally-greedy exploration algorithms that we define. We show that the additive overhead analysis of locally-greedy algorithms can be seen through the lens of a 2-player game that we call the tree-mining game and that could be of independent interest.","sentences":["We investigate the problem of collaborative tree exploration with complete communication introduced by [FGKP06], in which a group of $k$ agents is assigned to collectively go through all edges of an unknown tree in an efficient manner and then return to the origin.","The agents have unrestricted communication and computation capabilities.","The algorithm's runtime is typically compared to the cost of offline traversal, which is at least $\\max\\{2n/k,2D\\}$ where $n$ is the number of nodes and $D$ is the tree depth.","Since its introduction, two types of guarantee have emerged on the topic: the first is of the form $r(k)(n/k+D)$, where $r(k)$ is called the competitive ratio, and the other is of the form $2n/k+f(k,D)$, where $f(k,D)$ is called the competitive overhead.","In this paper, we present the first algorithm with linear-in-$D$ competitive overhead, thereby reconciling both approaches.","Specifically, our bound is in $2n/k + O(k^{\\log_2 k} D)$ and thus leads to a competitive ratio in $O(k/\\exp(0.8\\sqrt{\\ln k}))$.","This is the first improvement over the $O(k/\\ln k)$-competitive algorithm known since the introduction of the problem in 2004.","Our algorithm is obtained for an asynchronous generalization of collective tree exploration (ACTE).","It is an instance of a general class of locally-greedy exploration algorithms that we define.","We show that the additive overhead analysis of locally-greedy algorithms can be seen through the lens of a 2-player game that we call the tree-mining game and that could be of independent interest."],"url":"http://arxiv.org/abs/2309.07011v1"}
{"created":"2023-09-13 15:00:56","title":"OYXOY: A Modern NLP Test Suite for Modern Greek","abstract":"This paper serves as a foundational step towards the development of a linguistically motivated and technically relevant evaluation suite for Greek NLP. We initiate this endeavor by introducing four expert-verified evaluation tasks, specifically targeted at natural language inference, word sense disambiguation (through example comparison or sense selection) and metaphor detection. More than language-adapted replicas of existing tasks, we contribute two innovations which will resonate with the broader resource and evaluation community. Firstly, our inference dataset is the first of its kind, marking not just \\textit{one}, but rather \\textit{all} possible inference labels, accounting for possible shifts due to e.g. ambiguity or polysemy. Secondly, we demonstrate a cost-efficient method to obtain datasets for under-resourced languages. Using ChatGPT as a language-neutral parser, we transform the Dictionary of Standard Modern Greek into a structured format, from which we derive the other three tasks through simple projections. Alongside each task, we conduct experiments using currently available state of the art machinery. Our experimental baselines affirm the challenging nature of our tasks and highlight the need for expedited progress in order for the Greek NLP ecosystem to keep pace with contemporary mainstream research.","sentences":["This paper serves as a foundational step towards the development of a linguistically motivated and technically relevant evaluation suite for Greek NLP.","We initiate this endeavor by introducing four expert-verified evaluation tasks, specifically targeted at natural language inference, word sense disambiguation (through example comparison or sense selection) and metaphor detection.","More than language-adapted replicas of existing tasks, we contribute two innovations which will resonate with the broader resource and evaluation community.","Firstly, our inference dataset is the first of its kind, marking not just \\textit{one}, but rather \\textit{all} possible inference labels, accounting for possible shifts due to e.g. ambiguity or polysemy.","Secondly, we demonstrate a cost-efficient method to obtain datasets for under-resourced languages.","Using ChatGPT as a language-neutral parser, we transform the Dictionary of Standard Modern Greek into a structured format, from which we derive the other three tasks through simple projections.","Alongside each task, we conduct experiments using currently available state of the art machinery.","Our experimental baselines affirm the challenging nature of our tasks and highlight the need for expedited progress in order for the Greek NLP ecosystem to keep pace with contemporary mainstream research."],"url":"http://arxiv.org/abs/2309.07009v1"}
{"created":"2023-09-13 14:54:54","title":"Finding Morton-Like Layouts for Multi-Dimensional Arrays Using Evolutionary Algorithms","abstract":"The layout of multi-dimensional data can have a significant impact on the efficacy of hardware caches and, by extension, the performance of applications. Common multi-dimensional layouts include the canonical row-major and column-major layouts as well as the Morton curve layout. In this paper, we describe how the Morton layout can be generalized to a very large family of multi-dimensional data layouts with widely varying performance characteristics. We posit that this design space can be efficiently explored using a combinatorial evolutionary methodology based on genetic algorithms. To this end, we propose a chromosomal representation for such layouts as well as a methodology for estimating the fitness of array layouts using cache simulation. We show that our fitness function correlates to kernel running time in real hardware, and that our evolutionary strategy allows us to find candidates with favorable simulated cache properties in four out of the eight real-world applications under consideration in a small number of generations. Finally, we demonstrate that the array layouts found using our evolutionary method perform well not only in simulated environments but that they can effect significant performance gains -- up to a factor ten in extreme cases -- in real hardware.","sentences":["The layout of multi-dimensional data can have a significant impact on the efficacy of hardware caches and, by extension, the performance of applications.","Common multi-dimensional layouts include the canonical row-major and column-major layouts as well as the Morton curve layout.","In this paper, we describe how the Morton layout can be generalized to a very large family of multi-dimensional data layouts with widely varying performance characteristics.","We posit that this design space can be efficiently explored using a combinatorial evolutionary methodology based on genetic algorithms.","To this end, we propose a chromosomal representation for such layouts as well as a methodology for estimating the fitness of array layouts using cache simulation.","We show that our fitness function correlates to kernel running time in real hardware, and that our evolutionary strategy allows us to find candidates with favorable simulated cache properties in four out of the eight real-world applications under consideration in a small number of generations.","Finally, we demonstrate that the array layouts found using our evolutionary method perform well not only in simulated environments but that they can effect significant performance gains -- up to a factor ten in extreme cases -- in real hardware."],"url":"http://arxiv.org/abs/2309.07002v1"}
{"created":"2023-09-13 14:54:51","title":"Dynamic Analysis of Corporate ESG Reports: A Model of Evolutionary Trends","abstract":"Environmental, social, and governance (ESG) reports are globally recognized as a keystone in sustainable enterprise development. This study aims to map the changing landscape of ESG topics within firms in the global market. A dynamic framework is developed to analyze ESG strategic management for individual classes, across multiple classes, and in alignment with a specific sustainability index. The output of these analytical processes forms the foundation of an ESG strategic model. Utilizing a rich collection of 21st-century ESG reports from technology companies, our experiment elucidates the changes in ESG perspectives by incorporating analytical keywords into the proposed framework. This work thus provides an empirical method that reveals the concurrent evolution of ESG topics over recent years.","sentences":["Environmental, social, and governance (ESG) reports are globally recognized as a keystone in sustainable enterprise development.","This study aims to map the changing landscape of ESG topics within firms in the global market.","A dynamic framework is developed to analyze ESG strategic management for individual classes, across multiple classes, and in alignment with a specific sustainability index.","The output of these analytical processes forms the foundation of an ESG strategic model.","Utilizing a rich collection of 21st-century ESG reports from technology companies, our experiment elucidates the changes in ESG perspectives by incorporating analytical keywords into the proposed framework.","This work thus provides an empirical method that reveals the concurrent evolution of ESG topics over recent years."],"url":"http://arxiv.org/abs/2309.07001v1"}
{"created":"2023-09-13 14:36:26","title":"Unsupervised Contrast-Consistent Ranking with Language Models","abstract":"Language models contain ranking-based knowledge and are powerful solvers of in-context ranking tasks. For instance, they may have parametric knowledge about the ordering of countries by size or may be able to rank reviews by sentiment. Recent work focuses on pairwise, pointwise, and listwise prompting techniques to elicit a language model's ranking knowledge. However, we find that even with careful calibration and constrained decoding, prompting-based techniques may not always be self-consistent in the rankings they produce. This motivates us to explore an alternative approach that is inspired by an unsupervised probing method called Contrast-Consistent Search (CCS). The idea is to train a probing model guided by a logical constraint: a model's representation of a statement and its negation must be mapped to contrastive true-false poles consistently across multiple statements. We hypothesize that similar constraints apply to ranking tasks where all items are related via consistent pairwise or listwise comparisons. To this end, we extend the binary CCS method to Contrast-Consistent Ranking (CCR) by adapting existing ranking methods such as the Max-Margin Loss, Triplet Loss, and Ordinal Regression objective. Our results confirm that, for the same language model, CCR probing outperforms prompting and even performs on a par with prompting much larger language models.","sentences":["Language models contain ranking-based knowledge and are powerful solvers of in-context ranking tasks.","For instance, they may have parametric knowledge about the ordering of countries by size or may be able to rank reviews by sentiment.","Recent work focuses on pairwise, pointwise, and listwise prompting techniques to elicit a language model's ranking knowledge.","However, we find that even with careful calibration and constrained decoding, prompting-based techniques may not always be self-consistent in the rankings they produce.","This motivates us to explore an alternative approach that is inspired by an unsupervised probing method called Contrast-Consistent Search (CCS).","The idea is to train a probing model guided by a logical constraint: a model's representation of a statement and its negation must be mapped to contrastive true-false poles consistently across multiple statements.","We hypothesize that similar constraints apply to ranking tasks where all items are related via consistent pairwise or listwise comparisons.","To this end, we extend the binary CCS method to Contrast-Consistent Ranking (CCR) by adapting existing ranking methods such as the Max-Margin Loss, Triplet Loss, and Ordinal Regression objective.","Our results confirm that, for the same language model, CCR probing outperforms prompting and even performs on a par with prompting much larger language models."],"url":"http://arxiv.org/abs/2309.06991v1"}
{"created":"2023-09-13 14:30:30","title":"Remote Inference of Cognitive Scores in ALS Patients Using a Picture Description","abstract":"Amyotrophic lateral sclerosis is a fatal disease that not only affects movement, speech, and breath but also cognition. Recent studies have focused on the use of language analysis techniques to detect ALS and infer scales for monitoring functional progression. In this paper, we focused on another important aspect, cognitive impairment, which affects 35-50% of the ALS population. In an effort to reach the ALS population, which frequently exhibits mobility limitations, we implemented the digital version of the Edinburgh Cognitive and Behavioral ALS Screen (ECAS) test for the first time. This test which is designed to measure cognitive impairment was remotely performed by 56 participants from the EverythingALS Speech Study. As part of the study, participants (ALS and non-ALS) were asked to describe weekly one picture from a pool of many pictures with complex scenes displayed on their computer at home. We analyze the descriptions performed within +/- 60 days from the day the ECAS test was administered and extract different types of linguistic and acoustic features. We input those features into linear regression models to infer 5 ECAS sub-scores and the total score. Speech samples from the picture description are reliable enough to predict the ECAS subs-scores, achieving statistically significant Spearman correlation values between 0.32 and 0.51 for the model's performance using 10-fold cross-validation.","sentences":["Amyotrophic lateral sclerosis is a fatal disease that not only affects movement, speech, and breath but also cognition.","Recent studies have focused on the use of language analysis techniques to detect ALS and infer scales for monitoring functional progression.","In this paper, we focused on another important aspect, cognitive impairment, which affects 35-50% of the ALS population.","In an effort to reach the ALS population, which frequently exhibits mobility limitations, we implemented the digital version of the Edinburgh Cognitive and Behavioral ALS Screen (ECAS) test for the first time.","This test which is designed to measure cognitive impairment was remotely performed by 56 participants from the EverythingALS Speech Study.","As part of the study, participants (ALS and non-ALS) were asked to describe weekly one picture from a pool of many pictures with complex scenes displayed on their computer at home.","We analyze the descriptions performed within +/- 60 days from the day the ECAS test was administered and extract different types of linguistic and acoustic features.","We input those features into linear regression models to infer 5 ECAS sub-scores and the total score.","Speech samples from the picture description are reliable enough to predict the ECAS subs-scores, achieving statistically significant Spearman correlation values between 0.32 and 0.51 for the model's performance using 10-fold cross-validation."],"url":"http://arxiv.org/abs/2309.06989v1"}
{"created":"2023-09-13 14:26:03","title":"Instance Adaptive Prototypical Contrastive Embedding for Generalized Zero Shot Learning","abstract":"Generalized zero-shot learning(GZSL) aims to classify samples from seen and unseen labels, assuming unseen labels are not accessible during training. Recent advancements in GZSL have been expedited by incorporating contrastive-learning-based (instance-based) embedding in generative networks and leveraging the semantic relationship between data points. However, existing embedding architectures suffer from two limitations: (1) limited discriminability of synthetic features' embedding without considering fine-grained cluster structures; (2) inflexible optimization due to restricted scaling mechanisms on existing contrastive embedding networks, leading to overlapped representations in the embedding space. To enhance the quality of representations in the embedding space, as mentioned in (1), we propose a margin-based prototypical contrastive learning embedding network that reaps the benefits of prototype-data (cluster quality enhancement) and implicit data-data (fine-grained representations) interaction while providing substantial cluster supervision to the embedding network and the generator. To tackle (2), we propose an instance adaptive contrastive loss that leads to generalized representations for unseen labels with increased inter-class margin. Through comprehensive experimental evaluation, we show that our method can outperform the current state-of-the-art on three benchmark datasets. Our approach also consistently achieves the best unseen performance in the GZSL setting.","sentences":["Generalized zero-shot learning(GZSL) aims to classify samples from seen and unseen labels, assuming unseen labels are not accessible during training.","Recent advancements in GZSL have been expedited by incorporating contrastive-learning-based (instance-based) embedding in generative networks and leveraging the semantic relationship between data points.","However, existing embedding architectures suffer from two limitations: (1) limited discriminability of synthetic features' embedding without considering fine-grained cluster structures; (2) inflexible optimization due to restricted scaling mechanisms on existing contrastive embedding networks, leading to overlapped representations in the embedding space.","To enhance the quality of representations in the embedding space, as mentioned in (1), we propose a margin-based prototypical contrastive learning embedding network that reaps the benefits of prototype-data (cluster quality enhancement) and implicit data-data (fine-grained representations) interaction while providing substantial cluster supervision to the embedding network and the generator.","To tackle (2), we propose an instance adaptive contrastive loss that leads to generalized representations for unseen labels with increased inter-class margin.","Through comprehensive experimental evaluation, we show that our method can outperform the current state-of-the-art on three benchmark datasets.","Our approach also consistently achieves the best unseen performance in the GZSL setting."],"url":"http://arxiv.org/abs/2309.06987v1"}
{"created":"2023-09-13 14:24:32","title":"Learning to Explore Indoor Environments using Autonomous Micro Aerial Vehicles","abstract":"In this paper, we address the challenge of exploring unknown indoor aerial environments using autonomous aerial robots with Size Weight and Power (SWaP) constraints. The SWaP constraints induce limits on mission time requiring efficiency in exploration. We present a novel exploration framework that uses Deep Learning (DL) to predict the most likely indoor map given the previous observations, and Deep Reinforcement Learning (DRL) for exploration, designed to run on modern SWaP constraints neural processors. The DL-based map predictor provides a prediction of the occupancy of the unseen environment while the DRL-based planner determines the best navigation goals that can be safely reached to provide the most information. The two modules are tightly coupled and run onboard allowing the vehicle to safely map an unknown environment. Extensive experimental and simulation results show that our approach surpasses state-of-the-art methods by 50-60% in efficiency, which we measure by the fraction of the explored space as a function of the length of the trajectory traveled.","sentences":["In this paper, we address the challenge of exploring unknown indoor aerial environments using autonomous aerial robots with Size Weight and Power (SWaP) constraints.","The SWaP constraints induce limits on mission time requiring efficiency in exploration.","We present a novel exploration framework that uses Deep Learning (DL) to predict the most likely indoor map given the previous observations, and Deep Reinforcement Learning (DRL) for exploration, designed to run on modern SWaP constraints neural processors.","The DL-based map predictor provides a prediction of the occupancy of the unseen environment while the DRL-based planner determines the best navigation goals that can be safely reached to provide the most information.","The two modules are tightly coupled and run onboard allowing the vehicle to safely map an unknown environment.","Extensive experimental and simulation results show that our approach surpasses state-of-the-art methods by 50-60% in efficiency, which we measure by the fraction of the explored space as a function of the length of the trajectory traveled."],"url":"http://arxiv.org/abs/2309.06986v1"}
{"created":"2023-09-13 14:17:54","title":"Communication-Efficient Laplace Mechanism for Differential Privacy via Random Quantization","abstract":"We propose the first method that realizes the Laplace mechanism exactly (i.e., a Laplace noise is added to the data) that requires only a finite amount of communication (whereas the original Laplace mechanism requires the transmission of a real number) while guaranteeing privacy against the server and database. Our mechanism can serve as a drop-in replacement for local or centralized differential privacy applications where the Laplace mechanism is used. Our mechanism is constructed using a random quantization technique. Unlike the simple and prevalent Laplace-mechanism-then-quantize approach, the quantization in our mechanism does not result in any distortion or degradation of utility. Unlike existing dithered quantization and channel simulation schemes for simulating additive Laplacian noise, our mechanism guarantees privacy not only against the database and downstream, but also against the honest but curious server which attempts to decode the data using the dither signals.","sentences":["We propose the first method that realizes the Laplace mechanism exactly (i.e., a Laplace noise is added to the data) that requires only a finite amount of communication (whereas the original Laplace mechanism requires the transmission of a real number) while guaranteeing privacy against the server and database.","Our mechanism can serve as a drop-in replacement for local or centralized differential privacy applications where the Laplace mechanism is used.","Our mechanism is constructed using a random quantization technique.","Unlike the simple and prevalent Laplace-mechanism-then-quantize approach, the quantization in our mechanism does not result in any distortion or degradation of utility.","Unlike existing dithered quantization and channel simulation schemes for simulating additive Laplacian noise, our mechanism guarantees privacy not only against the database and downstream, but also against the honest but curious server which attempts to decode the data using the dither signals."],"url":"http://arxiv.org/abs/2309.06982v1"}
{"created":"2023-09-13 14:15:54","title":"MASTERKEY: Practical Backdoor Attack Against Speaker Verification Systems","abstract":"Speaker Verification (SV) is widely deployed in mobile systems to authenticate legitimate users by using their voice traits. In this work, we propose a backdoor attack MASTERKEY, to compromise the SV models. Different from previous attacks, we focus on a real-world practical setting where the attacker possesses no knowledge of the intended victim. To design MASTERKEY, we investigate the limitation of existing poisoning attacks against unseen targets. Then, we optimize a universal backdoor that is capable of attacking arbitrary targets. Next, we embed the speaker's characteristics and semantics information into the backdoor, making it imperceptible. Finally, we estimate the channel distortion and integrate it into the backdoor. We validate our attack on 6 popular SV models. Specifically, we poison a total of 53 models and use our trigger to attack 16,430 enrolled speakers, composed of 310 target speakers enrolled in 53 poisoned models. Our attack achieves 100% attack success rate with a 15% poison rate. By decreasing the poison rate to 3%, the attack success rate remains around 50%. We validate our attack in 3 real-world scenarios and successfully demonstrate the attack through both over-the-air and over-the-telephony-line scenarios.","sentences":["Speaker Verification (SV) is widely deployed in mobile systems to authenticate legitimate users by using their voice traits.","In this work, we propose a backdoor attack MASTERKEY, to compromise the SV models.","Different from previous attacks, we focus on a real-world practical setting where the attacker possesses no knowledge of the intended victim.","To design MASTERKEY, we investigate the limitation of existing poisoning attacks against unseen targets.","Then, we optimize a universal backdoor that is capable of attacking arbitrary targets.","Next, we embed the speaker's characteristics and semantics information into the backdoor, making it imperceptible.","Finally, we estimate the channel distortion and integrate it into the backdoor.","We validate our attack on 6 popular SV models.","Specifically, we poison a total of 53 models and use our trigger to attack 16,430 enrolled speakers, composed of 310 target speakers enrolled in 53 poisoned models.","Our attack achieves 100% attack success rate with a 15% poison rate.","By decreasing the poison rate to 3%, the attack success rate remains around 50%.","We validate our attack in 3 real-world scenarios and successfully demonstrate the attack through both over-the-air and over-the-telephony-line scenarios."],"url":"http://arxiv.org/abs/2309.06981v1"}
{"created":"2023-09-13 14:15:03","title":"Auto-Regressive Next-Token Predictors are Universal Learners","abstract":"Large language models display remarkable capabilities in logical and mathematical reasoning, allowing them to solve complex tasks. Interestingly, these abilities emerge in networks trained on the simple task of next-token prediction. In this work, we present a theoretical framework for studying auto-regressive next-token predictors. We demonstrate that even simple models such as linear next-token predictors, trained on Chain-of-Thought (CoT) data, can approximate any function efficiently computed by a Turing machine. We introduce a new complexity measure -- length complexity -- which measures the number of intermediate tokens in a CoT sequence required to approximate some target function, and analyze the interplay between length complexity and other notions of complexity. Finally, we show experimentally that simple next-token predictors, such as linear networks and shallow Multi-Layer Perceptrons (MLPs), display non-trivial performance on text generation and arithmetic tasks. Our results demonstrate that the power of language models can be attributed, to a great extent, to the auto-regressive next-token training scheme, and not necessarily to a particular choice of architecture.","sentences":["Large language models display remarkable capabilities in logical and mathematical reasoning, allowing them to solve complex tasks.","Interestingly, these abilities emerge in networks trained on the simple task of next-token prediction.","In this work, we present a theoretical framework for studying auto-regressive next-token predictors.","We demonstrate that even simple models such as linear next-token predictors, trained on Chain-of-Thought (CoT) data, can approximate any function efficiently computed by a Turing machine.","We introduce a new complexity measure -- length complexity -- which measures the number of intermediate tokens in a CoT sequence required to approximate some target function, and analyze the interplay between length complexity and other notions of complexity.","Finally, we show experimentally that simple next-token predictors, such as linear networks and shallow Multi-Layer Perceptrons (MLPs), display non-trivial performance on text generation and arithmetic tasks.","Our results demonstrate that the power of language models can be attributed, to a great extent, to the auto-regressive next-token training scheme, and not necessarily to a particular choice of architecture."],"url":"http://arxiv.org/abs/2309.06979v1"}
{"created":"2023-09-13 14:13:08","title":"Differentiable JPEG: The Devil is in the Details","abstract":"JPEG remains one of the most widespread lossy image coding methods. However, the non-differentiable nature of JPEG restricts the application in deep learning pipelines. Several differentiable approximations of JPEG have recently been proposed to address this issue. This paper conducts a comprehensive review of existing diff. JPEG approaches and identifies critical details that have been missed by previous methods. To this end, we propose a novel diff. JPEG approach, overcoming previous limitations. Our approach is differentiable w.r.t. the input image, the JPEG quality, the quantization tables, and the color conversion parameters. We evaluate the forward and backward performance of our diff. JPEG approach against existing methods. Additionally, extensive ablations are performed to evaluate crucial design choices. Our proposed diff. JPEG resembles the (non-diff.) reference implementation best, significantly surpassing the recent-best diff. approach by $3.47$dB (PSNR) on average. For strong compression rates, we can even improve PSNR by $9.51$dB. Strong adversarial attack results are yielded by our diff. JPEG, demonstrating the effective gradient approximation. Our code is available at https://github.com/necla-ml/Diff-JPEG.","sentences":["JPEG remains one of the most widespread lossy image coding methods.","However, the non-differentiable nature of JPEG restricts the application in deep learning pipelines.","Several differentiable approximations of JPEG have recently been proposed to address this issue.","This paper conducts a comprehensive review of existing diff.","JPEG approaches and identifies critical details that have been missed by previous methods.","To this end, we propose a novel diff.","JPEG approach, overcoming previous limitations.","Our approach is differentiable w.r.t.","the input image, the JPEG quality, the quantization tables, and the color conversion parameters.","We evaluate the forward and backward performance of our diff.","JPEG approach against existing methods.","Additionally, extensive ablations are performed to evaluate crucial design choices.","Our proposed diff.","JPEG resembles the (non-diff.)","reference implementation best, significantly surpassing the recent-best diff.","approach by $3.47$dB (PSNR) on average.","For strong compression rates, we can even improve PSNR by $9.51$dB. Strong adversarial attack results are yielded by our diff.","JPEG, demonstrating the effective gradient approximation.","Our code is available at https://github.com/necla-ml/Diff-JPEG."],"url":"http://arxiv.org/abs/2309.06978v1"}
{"created":"2023-09-13 14:05:50","title":"DNNShifter: An Efficient DNN Pruning System for Edge Computing","abstract":"Deep neural networks (DNNs) underpin many machine learning applications. Production quality DNN models achieve high inference accuracy by training millions of DNN parameters which has a significant resource footprint. This presents a challenge for resources operating at the extreme edge of the network, such as mobile and embedded devices that have limited computational and memory resources. To address this, models are pruned to create lightweight, more suitable variants for these devices. Existing pruning methods are unable to provide similar quality models compared to their unpruned counterparts without significant time costs and overheads or are limited to offline use cases. Our work rapidly derives suitable model variants while maintaining the accuracy of the original model. The model variants can be swapped quickly when system and network conditions change to match workload demand. This paper presents DNNShifter, an end-to-end DNN training, spatial pruning, and model switching system that addresses the challenges mentioned above. At the heart of DNNShifter is a novel methodology that prunes sparse models using structured pruning. The pruned model variants generated by DNNShifter are smaller in size and thus faster than dense and sparse model predecessors, making them suitable for inference at the edge while retaining near similar accuracy as of the original dense model. DNNShifter generates a portfolio of model variants that can be swiftly interchanged depending on operational conditions. DNNShifter produces pruned model variants up to 93x faster than conventional training methods. Compared to sparse models, the pruned model variants are up to 5.14x smaller and have a 1.67x inference latency speedup, with no compromise to sparse model accuracy. In addition, DNNShifter has up to 11.9x lower overhead for switching models and up to 3.8x lower memory utilisation than existing approaches.","sentences":["Deep neural networks (DNNs) underpin many machine learning applications.","Production quality DNN models achieve high inference accuracy by training millions of DNN parameters which has a significant resource footprint.","This presents a challenge for resources operating at the extreme edge of the network, such as mobile and embedded devices that have limited computational and memory resources.","To address this, models are pruned to create lightweight, more suitable variants for these devices.","Existing pruning methods are unable to provide similar quality models compared to their unpruned counterparts without significant time costs and overheads or are limited to offline use cases.","Our work rapidly derives suitable model variants while maintaining the accuracy of the original model.","The model variants can be swapped quickly when system and network conditions change to match workload demand.","This paper presents DNNShifter, an end-to-end DNN training, spatial pruning, and model switching system that addresses the challenges mentioned above.","At the heart of DNNShifter is a novel methodology that prunes sparse models using structured pruning.","The pruned model variants generated by DNNShifter are smaller in size and thus faster than dense and sparse model predecessors, making them suitable for inference at the edge while retaining near similar accuracy as of the original dense model.","DNNShifter generates a portfolio of model variants that can be swiftly interchanged depending on operational conditions.","DNNShifter produces pruned model variants up to 93x faster than conventional training methods.","Compared to sparse models, the pruned model variants are up to 5.14x smaller and have a 1.67x inference latency speedup, with no compromise to sparse model accuracy.","In addition, DNNShifter has up to 11.9x lower overhead for switching models and up to 3.8x lower memory utilisation than existing approaches."],"url":"http://arxiv.org/abs/2309.06973v1"}
{"created":"2023-09-13 14:04:15","title":"Setting the Right Expectations: Algorithmic Recourse Over Time","abstract":"Algorithmic systems are often called upon to assist in high-stakes decision making. In light of this, algorithmic recourse, the principle wherein individuals should be able to take action against an undesirable outcome made by an algorithmic system, is receiving growing attention. The bulk of the literature on algorithmic recourse to-date focuses primarily on how to provide recourse to a single individual, overlooking a critical element: the effects of a continuously changing context. Disregarding these effects on recourse is a significant oversight, since, in almost all cases, recourse consists of an individual making a first, unfavorable attempt, and then being given an opportunity to make one or several attempts at a later date - when the context might have changed. This can create false expectations, as initial recourse recommendations may become less reliable over time due to model drift and competition for access to the favorable outcome between individuals.   In this work we propose an agent-based simulation framework for studying the effects of a continuously changing environment on algorithmic recourse. In particular, we identify two main effects that can alter the reliability of recourse for individuals represented by the agents: (1) competition with other agents acting upon recourse, and (2) competition with new agents entering the environment. Our findings highlight that only a small set of specific parameterizations result in algorithmic recourse that is reliable for agents over time. Consequently, we argue that substantial additional work is needed to understand recourse reliability over time, and to develop recourse methods that reward agents' effort.","sentences":["Algorithmic systems are often called upon to assist in high-stakes decision making.","In light of this, algorithmic recourse, the principle wherein individuals should be able to take action against an undesirable outcome made by an algorithmic system, is receiving growing attention.","The bulk of the literature on algorithmic recourse to-date focuses primarily on how to provide recourse to a single individual, overlooking a critical element: the effects of a continuously changing context.","Disregarding these effects on recourse is a significant oversight, since, in almost all cases, recourse consists of an individual making a first, unfavorable attempt, and then being given an opportunity to make one or several attempts at a later date - when the context might have changed.","This can create false expectations, as initial recourse recommendations may become less reliable over time due to model drift and competition for access to the favorable outcome between individuals.   ","In this work we propose an agent-based simulation framework for studying the effects of a continuously changing environment on algorithmic recourse.","In particular, we identify two main effects that can alter the reliability of recourse for individuals represented by the agents: (1) competition with other agents acting upon recourse, and (2) competition with new agents entering the environment.","Our findings highlight that only a small set of specific parameterizations result in algorithmic recourse that is reliable for agents over time.","Consequently, we argue that substantial additional work is needed to understand recourse reliability over time, and to develop recourse methods that reward agents' effort."],"url":"http://arxiv.org/abs/2309.06969v1"}
{"created":"2023-09-13 14:03:24","title":"Robustness in Metric Spaces over Continuous Quantales and the Hausdorff-Smyth Monad","abstract":"Generalized metric spaces are obtained by weakening the requirements (e.g., symmetry) on the distance function and by allowing it to take values in structures (e.g., quantales) that are more general than the set of non-negative real numbers. Quantale-valued metric spaces have gained prominence due to their use in quantitative reasoning on programs/systems, and for defining various notions of behavioral metrics.   We investigate imprecision and robustness in the framework of quantale-valued metric spaces, when the quantale is continuous. In particular, we study the relation between the robust topology, which captures robustness of analyses, and the Hausdorff-Smyth hemi-metric. To this end, we define a preorder-enriched monad $\\mathsf{P}_S$, called the Hausdorff-Smyth monad, and when $Q$ is a continuous quantale and $X$ is a $Q$-metric space, we relate the topology induced by the metric on $\\mathsf{P}_S(X)$ with the robust topology on the powerset $\\mathsf{P}(X)$ defined in terms of the metric on $X$.","sentences":["Generalized metric spaces are obtained by weakening the requirements (e.g., symmetry) on the distance function and by allowing it to take values in structures (e.g., quantales) that are more general than the set of non-negative real numbers.","Quantale-valued metric spaces have gained prominence due to their use in quantitative reasoning on programs/systems, and for defining various notions of behavioral metrics.   ","We investigate imprecision and robustness in the framework of quantale-valued metric spaces, when the quantale is continuous.","In particular, we study the relation between the robust topology, which captures robustness of analyses, and the Hausdorff-Smyth hemi-metric.","To this end, we define a preorder-enriched monad $\\mathsf{P}_S$, called the Hausdorff-Smyth monad, and when $Q$ is a continuous quantale and $X$ is a $Q$-metric space, we relate the topology induced by the metric on $\\mathsf{P}_S(X)$ with the robust topology on the powerset $\\mathsf{P}(X)$ defined in terms of the metric on $X$."],"url":"http://arxiv.org/abs/2309.06968v1"}
{"created":"2023-09-13 13:54:32","title":"Towards Reliable Dermatology Evaluation Benchmarks","abstract":"Benchmark datasets for digital dermatology unwittingly contain inaccuracies that reduce trust in model performance estimates. We propose a resource-efficient data cleaning protocol to identify issues that escaped previous curation. The protocol leverages an existing algorithmic cleaning strategy and is followed by a confirmation process terminated by an intuitive stopping criterion. Based on confirmation by multiple dermatologists, we remove irrelevant samples and near duplicates and estimate the percentage of label errors in six dermatology image datasets for model evaluation promoted by the International Skin Imaging Collaboration. Along with this paper, we publish revised file lists for each dataset which should be used for model evaluation. Our work paves the way for more trustworthy performance assessment in digital dermatology.","sentences":["Benchmark datasets for digital dermatology unwittingly contain inaccuracies that reduce trust in model performance estimates.","We propose a resource-efficient data cleaning protocol to identify issues that escaped previous curation.","The protocol leverages an existing algorithmic cleaning strategy and is followed by a confirmation process terminated by an intuitive stopping criterion.","Based on confirmation by multiple dermatologists, we remove irrelevant samples and near duplicates and estimate the percentage of label errors in six dermatology image datasets for model evaluation promoted by the International Skin Imaging Collaboration.","Along with this paper, we publish revised file lists for each dataset which should be used for model evaluation.","Our work paves the way for more trustworthy performance assessment in digital dermatology."],"url":"http://arxiv.org/abs/2309.06961v1"}
{"created":"2023-09-13 13:50:41","title":"PhantomSound: Black-Box, Query-Efficient Audio Adversarial Attack via Split-Second Phoneme Injection","abstract":"In this paper, we propose PhantomSound, a query-efficient black-box attack toward voice assistants. Existing black-box adversarial attacks on voice assistants either apply substitution models or leverage the intermediate model output to estimate the gradients for crafting adversarial audio samples. However, these attack approaches require a significant amount of queries with a lengthy training stage. PhantomSound leverages the decision-based attack to produce effective adversarial audios, and reduces the number of queries by optimizing the gradient estimation. In the experiments, we perform our attack against 4 different speech-to-text APIs under 3 real-world scenarios to demonstrate the real-time attack impact. The results show that PhantomSound is practical and robust in attacking 5 popular commercial voice controllable devices over the air, and is able to bypass 3 liveness detection mechanisms with >95% success rate. The benchmark result shows that PhantomSound can generate adversarial examples and launch the attack in a few minutes. We significantly enhance the query efficiency and reduce the cost of a successful untargeted and targeted adversarial attack by 93.1% and 65.5% compared with the state-of-the-art black-box attacks, using merely ~300 queries (~5 minutes) and ~1,500 queries (~25 minutes), respectively.","sentences":["In this paper, we propose PhantomSound, a query-efficient black-box attack toward voice assistants.","Existing black-box adversarial attacks on voice assistants either apply substitution models or leverage the intermediate model output to estimate the gradients for crafting adversarial audio samples.","However, these attack approaches require a significant amount of queries with a lengthy training stage.","PhantomSound leverages the decision-based attack to produce effective adversarial audios, and reduces the number of queries by optimizing the gradient estimation.","In the experiments, we perform our attack against 4 different speech-to-text APIs under 3 real-world scenarios to demonstrate the real-time attack impact.","The results show that PhantomSound is practical and robust in attacking 5 popular commercial voice controllable devices over the air, and is able to bypass 3 liveness detection mechanisms with >95% success rate.","The benchmark result shows that PhantomSound can generate adversarial examples and launch the attack in a few minutes.","We significantly enhance the query efficiency and reduce the cost of a successful untargeted and targeted adversarial attack by 93.1% and 65.5% compared with the state-of-the-art black-box attacks, using merely ~300 queries (~5 minutes) and ~1,500 queries (~25 minutes), respectively."],"url":"http://arxiv.org/abs/2309.06960v1"}
{"created":"2023-09-13 13:47:52","title":"Neural network-based coronary dominance classification of RCA angiograms","abstract":"Background. Cardiac dominance classification is essential for SYNTAX score estimation, which is a tool used to determine the complexity of coronary artery disease and guide patient selection toward optimal revascularization strategy. Objectives. Cardiac dominance classification algorithm based on the analysis of right coronary artery (RCA) angiograms using neural network Method. We employed convolutional neural network ConvNext and Swin transformer for 2D image (frames) classification, along with a majority vote for cardio angiographic view classification. An auxiliary network was also used to detect irrelevant images which were then excluded from the data set. Our data set consisted of 828 angiographic studies, 192 of them being patients with left dominance. Results. 5-fold cross validation gave the following dominance classification metrics (p=95%): macro recall=93.1%, accuracy=93.5%, macro F1=89.2%. The most common case in which the model regularly failed was RCA occlusion, as it requires utilization of LCA information. Another cause for false prediction is a small diameter combined with poor quality cardio angiographic view. In such cases, cardiac dominance classification can be complex and may require discussion among specialists to reach an accurate conclusion. Conclusion. The use of machine learning approaches to classify cardiac dominance based on RCA alone has been shown to be successful with satisfactory accuracy. However, for higher accuracy, it is necessary to utilize LCA information in the case of an occluded RCA and detect cases where there is high uncertainty.","sentences":["Background.","Cardiac dominance classification is essential for SYNTAX score estimation, which is a tool used to determine the complexity of coronary artery disease and guide patient selection toward optimal revascularization strategy.","Objectives.","Cardiac dominance classification algorithm based on the analysis of right coronary artery (RCA) angiograms using neural network Method.","We employed convolutional neural network ConvNext and Swin transformer for 2D image (frames) classification, along with a majority vote for cardio angiographic view classification.","An auxiliary network was also used to detect irrelevant images which were then excluded from the data set.","Our data set consisted of 828 angiographic studies, 192 of them being patients with left dominance.","Results.","5-fold cross validation gave the following dominance classification metrics (p=95%): macro recall=93.1%, accuracy=93.5%, macro F1=89.2%.","The most common case in which the model regularly failed was RCA occlusion, as it requires utilization of LCA information.","Another cause for false prediction is a small diameter combined with poor quality cardio angiographic view.","In such cases, cardiac dominance classification can be complex and may require discussion among specialists to reach an accurate conclusion.","Conclusion.","The use of machine learning approaches to classify cardiac dominance based on RCA alone has been shown to be successful with satisfactory accuracy.","However, for higher accuracy, it is necessary to utilize LCA information in the case of an occluded RCA and detect cases where there is high uncertainty."],"url":"http://arxiv.org/abs/2309.06958v1"}
{"created":"2023-09-13 13:43:36","title":"Harvesting Brownian Motion: Zero Energy Computational Sampling","abstract":"The key factor currently limiting the advancement of computational power of electronic computation is no longer the manufacturing density and speed of components, but rather their high energy consumption. While it has been widely argued that reversible computation can escape the fundamental Landauer limit of $k_B T\\ln(2)$ Joules per irreversible computational step, there is disagreement around whether indefinitely reusable computation can be achieved without energy dissipation. Here we focus on the relatively simpler context of sampling problems, which take no input, so avoids modeling the energy costs of the observer perturbing the machine to change its input. Given an algorithm $A$ for generating samples from a distribution, we desire a device that can perpetually generate samples from that distribution driven entirely by Brownian motion. We show that such a device can efficiently execute algorithm $A$ in the sense that we must wait only $O(\\text{time}(A)^2)$ between samples. We consider two output models: Las Vegas, which samples from the exact probability distribution every $4$ tries in expectation, and Monte Carlo, in which every try succeeds but the distribution is only approximated. We base our model on continuous-time random walks over the state space graph of a general computational machine, with a space-bounded Turing machine as one instantiation. The problem of sampling a computationally complex probability distribution with no energy dissipation informs our understanding of the energy requirements of computation, and may lead to more energy efficient randomized algorithms.","sentences":["The key factor currently limiting the advancement of computational power of electronic computation is no longer the manufacturing density and speed of components, but rather their high energy consumption.","While it has been widely argued that reversible computation can escape the fundamental Landauer limit of $k_B T\\ln(2)$ Joules per irreversible computational step, there is disagreement around whether indefinitely reusable computation can be achieved without energy dissipation.","Here we focus on the relatively simpler context of sampling problems, which take no input, so avoids modeling the energy costs of the observer perturbing the machine to change its input.","Given an algorithm $A$ for generating samples from a distribution, we desire a device that can perpetually generate samples from that distribution driven entirely by Brownian motion.","We show that such a device can efficiently execute algorithm $A$ in the sense that we must wait only $O(\\text{time}(A)^2)$ between samples.","We consider two output models: Las Vegas, which samples from the exact probability distribution every $4$ tries in expectation, and Monte Carlo, in which every try succeeds but the distribution is only approximated.","We base our model on continuous-time random walks over the state space graph of a general computational machine, with a space-bounded Turing machine as one instantiation.","The problem of sampling a computationally complex probability distribution with no energy dissipation informs our understanding of the energy requirements of computation, and may lead to more energy efficient randomized algorithms."],"url":"http://arxiv.org/abs/2309.06957v1"}
{"created":"2023-09-13 13:41:34","title":"Real-Time Motion Planning for In-Hand Manipulation with a Multi-Fingered Hand","abstract":"Dexterous manipulation of objects once held in hand remains a challenge. Such skills are, however, necessary for robotics to move beyond gripper-based manipulation and use all the dexterity offered by anthropomorphic robotic hands. One major challenge when manipulating an object within the hand is that fingers must move around the object while avoiding collision with other fingers or the object. Such collision-free paths must be computed in real-time, as the smallest deviation from the original plan can easily lead to collisions. We present a real-time approach to computing collision-free paths in a high-dimensional space. To guide the exploration, we learn an explicit representation of the free space, retrievable in real-time. We further combine this representation with closed-loop control via dynamical systems and sampling-based motion planning and show that the combination increases performance compared to alternatives, offering efficient search of feasible paths and real-time obstacle avoidance in a multi-fingered robotic hand.","sentences":["Dexterous manipulation of objects once held in hand remains a challenge.","Such skills are, however, necessary for robotics to move beyond gripper-based manipulation and use all the dexterity offered by anthropomorphic robotic hands.","One major challenge when manipulating an object within the hand is that fingers must move around the object while avoiding collision with other fingers or the object.","Such collision-free paths must be computed in real-time, as the smallest deviation from the original plan can easily lead to collisions.","We present a real-time approach to computing collision-free paths in a high-dimensional space.","To guide the exploration, we learn an explicit representation of the free space, retrievable in real-time.","We further combine this representation with closed-loop control via dynamical systems and sampling-based motion planning and show that the combination increases performance compared to alternatives, offering efficient search of feasible paths and real-time obstacle avoidance in a multi-fingered robotic hand."],"url":"http://arxiv.org/abs/2309.06955v1"}
{"created":"2023-09-13 13:34:22","title":"TransNet: A Transfer Learning-Based Network for Human Action Recognition","abstract":"Human action recognition (HAR) is a high-level and significant research area in computer vision due to its ubiquitous applications. The main limitations of the current HAR models are their complex structures and lengthy training time. In this paper, we propose a simple yet versatile and effective end-to-end deep learning architecture, coined as TransNet, for HAR. TransNet decomposes the complex 3D-CNNs into 2D- and 1D-CNNs, where the 2D- and 1D-CNN components extract spatial features and temporal patterns in videos, respectively. Benefiting from its concise architecture, TransNet is ideally compatible with any pretrained state-of-the-art 2D-CNN models in other fields, being transferred to serve the HAR task. In other words, it naturally leverages the power and success of transfer learning for HAR, bringing huge advantages in terms of efficiency and effectiveness. Extensive experimental results and the comparison with the state-of-the-art models demonstrate the superior performance of the proposed TransNet in HAR in terms of flexibility, model complexity, training speed and classification accuracy.","sentences":["Human action recognition (HAR) is a high-level and significant research area in computer vision due to its ubiquitous applications.","The main limitations of the current HAR models are their complex structures and lengthy training time.","In this paper, we propose a simple yet versatile and effective end-to-end deep learning architecture, coined as TransNet, for HAR.","TransNet decomposes the complex 3D-CNNs into 2D- and 1D-CNNs, where the 2D- and 1D-CNN components extract spatial features and temporal patterns in videos, respectively.","Benefiting from its concise architecture, TransNet is ideally compatible with any pretrained state-of-the-art 2D-CNN models in other fields, being transferred to serve the HAR task.","In other words, it naturally leverages the power and success of transfer learning for HAR, bringing huge advantages in terms of efficiency and effectiveness.","Extensive experimental results and the comparison with the state-of-the-art models demonstrate the superior performance of the proposed TransNet in HAR in terms of flexibility, model complexity, training speed and classification accuracy."],"url":"http://arxiv.org/abs/2309.06951v1"}
{"created":"2023-09-13 13:33:03","title":"3D Active Metric-Semantic SLAM","abstract":"In this letter, we address the problem of exploration and metric-semantic mapping of multi-floor GPS-denied indoor environments using Size Weight and Power (SWaP) constrained aerial robots. Most previous work in exploration assumes that robot localization is solved. However, neglecting the state uncertainty of the agent can ultimately lead to cascading errors both in the resulting map and in the state of the agent itself. Furthermore, actions that reduce localization errors may be at direct odds with the exploration task. We propose a framework that balances the efficiency of exploration with actions that reduce the state uncertainty of the agent. In particular, our algorithmic approach for active metric-semantic SLAM is built upon sparse information abstracted from raw problem data, to make it suitable for SWaP-constrained robots. Furthermore, we integrate this framework within a fully autonomous aerial robotic system that achieves autonomous exploration in cluttered, 3D environments. From extensive real-world experiments, we showed that by including Semantic Loop Closure (SLC), we can reduce the robot pose estimation errors by over 90% in translation and approximately 75% in yaw, and the uncertainties in pose estimates and semantic maps by over 70% and 65%, respectively. Although discussed in the context of indoor multi-floor exploration, our system can be used for various other applications, such as infrastructure inspection and precision agriculture where reliable GPS data may not be available.","sentences":["In this letter, we address the problem of exploration and metric-semantic mapping of multi-floor GPS-denied indoor environments using Size Weight and Power (SWaP) constrained aerial robots.","Most previous work in exploration assumes that robot localization is solved.","However, neglecting the state uncertainty of the agent can ultimately lead to cascading errors both in the resulting map and in the state of the agent itself.","Furthermore, actions that reduce localization errors may be at direct odds with the exploration task.","We propose a framework that balances the efficiency of exploration with actions that reduce the state uncertainty of the agent.","In particular, our algorithmic approach for active metric-semantic SLAM is built upon sparse information abstracted from raw problem data, to make it suitable for SWaP-constrained robots.","Furthermore, we integrate this framework within a fully autonomous aerial robotic system that achieves autonomous exploration in cluttered, 3D environments.","From extensive real-world experiments, we showed that by including Semantic Loop Closure (SLC), we can reduce the robot pose estimation errors by over 90% in translation and approximately 75% in yaw, and the uncertainties in pose estimates and semantic maps by over 70% and 65%, respectively.","Although discussed in the context of indoor multi-floor exploration, our system can be used for various other applications, such as infrastructure inspection and precision agriculture where reliable GPS data may not be available."],"url":"http://arxiv.org/abs/2309.06950v1"}
{"created":"2023-09-13 13:24:27","title":"DEFormer: DCT-driven Enhancement Transformer for Low-light Image and Dark Vision","abstract":"The goal of low-light image enhancement is to restore the color and details of the image and is of great significance for high-level visual tasks in autonomous driving. However, it is difficult to restore the lost details in the dark area by relying only on the RGB domain. In this paper we introduce frequency as a new clue into the network and propose a novel DCT-driven enhancement transformer (DEFormer). First, we propose a learnable frequency branch (LFB) for frequency enhancement contains DCT processing and curvature-based frequency enhancement (CFE). CFE calculates the curvature of each channel to represent the detail richness of different frequency bands, then we divides the frequency features, which focuses on frequency bands with richer textures. In addition, we propose a cross domain fusion (CDF) for reducing the differences between the RGB domain and the frequency domain. We also adopt DEFormer as a preprocessing in dark detection, DEFormer effectively improves the performance of the detector, bringing 2.1% and 3.4% improvement in ExDark and DARK FACE datasets on mAP respectively.","sentences":["The goal of low-light image enhancement is to restore the color and details of the image and is of great significance for high-level visual tasks in autonomous driving.","However, it is difficult to restore the lost details in the dark area by relying only on the RGB domain.","In this paper we introduce frequency as a new clue into the network and propose a novel DCT-driven enhancement transformer (DEFormer).","First, we propose a learnable frequency branch (LFB) for frequency enhancement contains DCT processing and curvature-based frequency enhancement (CFE).","CFE calculates the curvature of each channel to represent the detail richness of different frequency bands, then we divides the frequency features, which focuses on frequency bands with richer textures.","In addition, we propose a cross domain fusion (CDF) for reducing the differences between the RGB domain and the frequency domain.","We also adopt DEFormer as a preprocessing in dark detection, DEFormer effectively improves the performance of the detector, bringing 2.1% and 3.4% improvement in ExDark and DARK FACE datasets on mAP respectively."],"url":"http://arxiv.org/abs/2309.06941v1"}
{"created":"2023-09-13 13:24:12","title":"Enhancing the Performance of Multi-Agent Reinforcement Learning for Controlling HVAC Systems","abstract":"Systems for heating, ventilation and air-conditioning (HVAC) of buildings are traditionally controlled by a rule-based approach. In order to reduce the energy consumption and the environmental impact of HVAC systems more advanced control methods such as reinforcement learning are promising. Reinforcement learning (RL) strategies offer a good alternative, as user feedback can be integrated more easily and presence can also be incorporated. Moreover, multi-agent RL approaches scale well and can be generalized. In this paper, we propose a multi-agent RL framework based on existing work that learns reducing on one hand energy consumption by optimizing HVAC control and on the other hand user feedback by occupants about uncomfortable room temperatures. Second, we show how to reduce training time required for proper RL-agent-training by using parameter sharing between the multiple agents and apply different pretraining techniques. Results show that our framework is capable of reducing the energy by around 6% when controlling a complete building or 8% for a single room zone. The occupants complaints are acceptable or even better compared to a rule-based baseline. Additionally, our performance analysis show that the training time can be drastically reduced by using parameter sharing.","sentences":["Systems for heating, ventilation and air-conditioning (HVAC) of buildings are traditionally controlled by a rule-based approach.","In order to reduce the energy consumption and the environmental impact of HVAC systems more advanced control methods such as reinforcement learning are promising.","Reinforcement learning (RL) strategies offer a good alternative, as user feedback can be integrated more easily and presence can also be incorporated.","Moreover, multi-agent RL approaches scale well and can be generalized.","In this paper, we propose a multi-agent RL framework based on existing work that learns reducing on one hand energy consumption by optimizing HVAC control and on the other hand user feedback by occupants about uncomfortable room temperatures.","Second, we show how to reduce training time required for proper RL-agent-training by using parameter sharing between the multiple agents and apply different pretraining techniques.","Results show that our framework is capable of reducing the energy by around 6% when controlling a complete building or 8% for a single room zone.","The occupants complaints are acceptable or even better compared to a rule-based baseline.","Additionally, our performance analysis show that the training time can be drastically reduced by using parameter sharing."],"url":"http://arxiv.org/abs/2309.06940v1"}
{"created":"2023-09-13 13:20:17","title":"Collectionless Artificial Intelligence","abstract":"By and large, the professional handling of huge data collections is regarded as a fundamental ingredient of the progress of machine learning and of its spectacular results in related disciplines, with a growing agreement on risks connected to the centralization of such data collections. This paper sustains the position that the time has come for thinking of new learning protocols where machines conquer cognitive skills in a truly human-like context centered on environmental interactions. This comes with specific restrictions on the learning protocol according to the collectionless principle, which states that, at each time instant, data acquired from the environment is processed with the purpose of contributing to update the current internal representation of the environment, and that the agent is not given the privilege of recording the temporal stream. Basically, there is neither permission to store the temporal information coming from the sensors, thus promoting the development of self-organized memorization skills at a more abstract level, instead of relying on bare storage to simulate learning dynamics that are typical of offline learning algorithms. This purposely extreme position is intended to stimulate the development of machines that learn to dynamically organize the information by following human-based schemes. The proposition of this challenge suggests developing new foundations on computational processes of learning and reasoning that might open the doors to a truly orthogonal competitive track on AI technologies that avoid data accumulation by design, thus offering a framework which is better suited concerning privacy issues, control and customizability. Finally, pushing towards massively distributed computation, the collectionless approach to AI will likely reduce the concentration of power in companies and governments, thus better facing geopolitical issues.","sentences":["By and large, the professional handling of huge data collections is regarded as a fundamental ingredient of the progress of machine learning and of its spectacular results in related disciplines, with a growing agreement on risks connected to the centralization of such data collections.","This paper sustains the position that the time has come for thinking of new learning protocols where machines conquer cognitive skills in a truly human-like context centered on environmental interactions.","This comes with specific restrictions on the learning protocol according to the collectionless principle, which states that, at each time instant, data acquired from the environment is processed with the purpose of contributing to update the current internal representation of the environment, and that the agent is not given the privilege of recording the temporal stream.","Basically, there is neither permission to store the temporal information coming from the sensors, thus promoting the development of self-organized memorization skills at a more abstract level, instead of relying on bare storage to simulate learning dynamics that are typical of offline learning algorithms.","This purposely extreme position is intended to stimulate the development of machines that learn to dynamically organize the information by following human-based schemes.","The proposition of this challenge suggests developing new foundations on computational processes of learning and reasoning that might open the doors to a truly orthogonal competitive track on AI technologies that avoid data accumulation by design, thus offering a framework which is better suited concerning privacy issues, control and customizability.","Finally, pushing towards massively distributed computation, the collectionless approach to AI will likely reduce the concentration of power in companies and governments, thus better facing geopolitical issues."],"url":"http://arxiv.org/abs/2309.06938v1"}
{"created":"2023-09-13 13:13:29","title":"DreamStyler: Paint by Style Inversion with Text-to-Image Diffusion Models","abstract":"Recent progresses in large-scale text-to-image models have yielded remarkable accomplishments, finding various applications in art domain. However, expressing unique characteristics of an artwork (e.g. brushwork, colortone, or composition) with text prompts alone may encounter limitations due to the inherent constraints of verbal description. To this end, we introduce DreamStyler, a novel framework designed for artistic image synthesis, proficient in both text-to-image synthesis and style transfer. DreamStyler optimizes a multi-stage textual embedding with a context-aware text prompt, resulting in prominent image quality. In addition, with content and style guidance, DreamStyler exhibits flexibility to accommodate a range of style references. Experimental results demonstrate its superior performance across multiple scenarios, suggesting its promising potential in artistic product creation.","sentences":["Recent progresses in large-scale text-to-image models have yielded remarkable accomplishments, finding various applications in art domain.","However, expressing unique characteristics of an artwork (e.g. brushwork, colortone, or composition) with text prompts alone may encounter limitations due to the inherent constraints of verbal description.","To this end, we introduce DreamStyler, a novel framework designed for artistic image synthesis, proficient in both text-to-image synthesis and style transfer.","DreamStyler optimizes a multi-stage textual embedding with a context-aware text prompt, resulting in prominent image quality.","In addition, with content and style guidance, DreamStyler exhibits flexibility to accommodate a range of style references.","Experimental results demonstrate its superior performance across multiple scenarios, suggesting its promising potential in artistic product creation."],"url":"http://arxiv.org/abs/2309.06933v1"}
{"created":"2023-09-13 12:58:09","title":"Dynamic Causal Disentanglement Model for Dialogue Emotion Detection","abstract":"Emotion detection is a critical technology extensively employed in diverse fields. While the incorporation of commonsense knowledge has proven beneficial for existing emotion detection methods, dialogue-based emotion detection encounters numerous difficulties and challenges due to human agency and the variability of dialogue content.In dialogues, human emotions tend to accumulate in bursts. However, they are often implicitly expressed. This implies that many genuine emotions remain concealed within a plethora of unrelated words and dialogues.In this paper, we propose a Dynamic Causal Disentanglement Model based on hidden variable separation, which is founded on the separation of hidden variables. This model effectively decomposes the content of dialogues and investigates the temporal accumulation of emotions, thereby enabling more precise emotion recognition. First, we introduce a novel Causal Directed Acyclic Graph (DAG) to establish the correlation between hidden emotional information and other observed elements. Subsequently, our approach utilizes pre-extracted personal attributes and utterance topics as guiding factors for the distribution of hidden variables, aiming to separate irrelevant ones. Specifically, we propose a dynamic temporal disentanglement model to infer the propagation of utterances and hidden variables, enabling the accumulation of emotion-related information throughout the conversation. To guide this disentanglement process, we leverage the ChatGPT-4.0 and LSTM networks to extract utterance topics and personal attributes as observed information.Finally, we test our approach on two popular datasets in dialogue emotion detection and relevant experimental results verified the model's superiority.","sentences":["Emotion detection is a critical technology extensively employed in diverse fields.","While the incorporation of commonsense knowledge has proven beneficial for existing emotion detection methods, dialogue-based emotion detection encounters numerous difficulties and challenges due to human agency and the variability of dialogue content.","In dialogues, human emotions tend to accumulate in bursts.","However, they are often implicitly expressed.","This implies that many genuine emotions remain concealed within a plethora of unrelated words and dialogues.","In this paper, we propose a Dynamic Causal Disentanglement Model based on hidden variable separation, which is founded on the separation of hidden variables.","This model effectively decomposes the content of dialogues and investigates the temporal accumulation of emotions, thereby enabling more precise emotion recognition.","First, we introduce a novel Causal Directed Acyclic Graph (DAG) to establish the correlation between hidden emotional information and other observed elements.","Subsequently, our approach utilizes pre-extracted personal attributes and utterance topics as guiding factors for the distribution of hidden variables, aiming to separate irrelevant ones.","Specifically, we propose a dynamic temporal disentanglement model to infer the propagation of utterances and hidden variables, enabling the accumulation of emotion-related information throughout the conversation.","To guide this disentanglement process, we leverage the ChatGPT-4.0 and LSTM networks to extract utterance topics and personal attributes as observed information.","Finally, we test our approach on two popular datasets in dialogue emotion detection and relevant experimental results verified the model's superiority."],"url":"http://arxiv.org/abs/2309.06928v1"}
{"created":"2023-09-13 12:56:30","title":"OMOD: An open-source tool for creating disaggregated mobility demand based on OpenStreetMap","abstract":"In this paper, we introduce the OpenStreetMap Mobility Demand Generator (OMOD), a new open-source activity-based mobility demand generation tool. OMOD creates a population of agents and detailed daily activity schedules that state what activities each agent plans to conduct, where, and for how long. The temporal aspect of the output is wholly disaggregated, while the spatial aspect is given on the level of individual buildings. In contrast to other existing models, OMOD is freely available, open-source, works out-of-the-box, can be applied to any region on earth, and only requires freely available OpenStreetMap (OSM) data from the user. With OMOD, it is easy for non-experts to create realistic mobility demand, which can be used in transportation studies, energy system modeling, communications system research, et cetera. OMOD uses a data-driven approach to generate mobility demand that has been calibrated with household travel survey data. This paper describes OMOD's architecture and validates the model for three cities ranging from 200,000 to 2.5 million inhabitants.","sentences":["In this paper, we introduce the OpenStreetMap Mobility Demand Generator (OMOD), a new open-source activity-based mobility demand generation tool.","OMOD creates a population of agents and detailed daily activity schedules that state what activities each agent plans to conduct, where, and for how long.","The temporal aspect of the output is wholly disaggregated, while the spatial aspect is given on the level of individual buildings.","In contrast to other existing models, OMOD is freely available, open-source, works out-of-the-box, can be applied to any region on earth, and only requires freely available OpenStreetMap (OSM) data from the user.","With OMOD, it is easy for non-experts to create realistic mobility demand, which can be used in transportation studies, energy system modeling, communications system research, et cetera.","OMOD uses a data-driven approach to generate mobility demand that has been calibrated with household travel survey data.","This paper describes OMOD's architecture and validates the model for three cities ranging from 200,000 to 2.5 million inhabitants."],"url":"http://arxiv.org/abs/2309.06927v1"}
{"created":"2023-09-13 12:53:47","title":"Regular Representations of Uniform TC^0","abstract":"The circuit complexity class DLOGTIME-uniform AC^0 is known to be a modest subclass of DLOGTIME-uniform TC^0. The weakness of AC^0 is caused by the fact that AC^0 is not closed under restricting AC^0-computable queries into simple subsequences of the input. Analogously, in descriptive complexity, the logics corresponding to DLOGTIME-uniform AC^0 do not have the relativization property and hence they are not regular. This weakness of DLOGTIME-uniform AC^0 has been elaborated in the line of research on the Crane Beach Conjecture. The conjecture (which was refuted by Barrington, Immerman, Lautemann, Schweikardt and Th{\\'e}rien) was that if a language L has a neutral letter, then L can be defined in first-order logic with the collection of all numerical built-in relations, if and only if L can be already defined in FO with order.   In the first part of this article we consider logics in the range of AC^0 and TC^0. First we formulate a combinatorial criterion for a cardinality quantifier C_S implying that all languages in DLOGTIME-uniform TC^0 can be defined in FO(C_S). For instance, this criterion is satisfied by C_S if S is the range of some polynomial with positive integer coefficients of degree at least two. In the second part of the paper we first adapt the key properties of abstract logics to accommodate built-in relations. Then we define the regular interior R-int(L) and regular closure R-cl(L), of a logic L, and show that the Crane Beach Conjecture can be interpreted as a statement concerning the regular interior of first-order logic with built-in relations B. We show that if B={+}, or B contains only unary relations besides the order, then R-int(FO_B) collapses to FO with order. In contrast, our results imply that if B contains the order and the range of a polynomial of degree at least two, then R-cl(FO_B) includes all languages in DLOGTIME-uniform TC^0.","sentences":["The circuit complexity class DLOGTIME-uniform AC^0 is known to be a modest subclass of DLOGTIME-uniform TC^0.","The weakness of AC^0 is caused by the fact that AC^0 is not closed under restricting AC^0-computable queries into simple subsequences of the input.","Analogously, in descriptive complexity, the logics corresponding to DLOGTIME-uniform AC^0 do not have the relativization property and hence they are not regular.","This weakness of DLOGTIME-uniform AC^0 has been elaborated in the line of research on the Crane Beach Conjecture.","The conjecture (which was refuted by Barrington, Immerman, Lautemann, Schweikardt and Th{\\'e}rien) was that if a language L has a neutral letter, then L can be defined in first-order logic with the collection of all numerical built-in relations, if and only if L can be already defined in FO with order.   ","In the first part of this article we consider logics in the range of AC^0 and TC^0.","First we formulate a combinatorial criterion for a cardinality quantifier C_S implying that all languages in DLOGTIME-uniform TC^0 can be defined in FO(C_S).","For instance, this criterion is satisfied by C_S if S is the range of some polynomial with positive integer coefficients of degree at least two.","In the second part of the paper we first adapt the key properties of abstract logics to accommodate built-in relations.","Then we define the regular interior R-int(L) and regular closure R-cl(L), of a logic L, and show that the Crane Beach Conjecture can be interpreted as a statement concerning the regular interior of first-order logic with built-in relations","B. We show that if B={+}, or B contains only unary relations besides the order, then R-int(FO_B) collapses to FO with order.","In contrast, our results imply that if B contains the order and the range of a polynomial of degree at least two, then R-cl(FO_B) includes all languages in DLOGTIME-uniform TC^0."],"url":"http://arxiv.org/abs/2309.06926v1"}
{"created":"2023-09-13 12:50:21","title":"Contrast-Phys+: Unsupervised and Weakly-supervised Video-based Remote Physiological Measurement via Spatiotemporal Contrast","abstract":"Video-based remote physiological measurement utilizes facial videos to measure the blood volume change signal, which is also called remote photoplethysmography (rPPG). Supervised methods for rPPG measurements have been shown to achieve good performance. However, the drawback of these methods is that they require facial videos with ground truth (GT) physiological signals, which are often costly and difficult to obtain. In this paper, we propose Contrast-Phys+, a method that can be trained in both unsupervised and weakly-supervised settings. We employ a 3DCNN model to generate multiple spatiotemporal rPPG signals and incorporate prior knowledge of rPPG into a contrastive loss function. We further incorporate the GT signals into contrastive learning to adapt to partial or misaligned labels. The contrastive loss encourages rPPG/GT signals from the same video to be grouped together, while pushing those from different videos apart. We evaluate our methods on five publicly available datasets that include both RGB and Near-infrared videos. Contrast-Phys+ outperforms the state-of-the-art supervised methods, even when using partially available or misaligned GT signals, or no labels at all. Additionally, we highlight the advantages of our methods in terms of computational efficiency, noise robustness, and generalization.","sentences":["Video-based remote physiological measurement utilizes facial videos to measure the blood volume change signal, which is also called remote photoplethysmography (rPPG).","Supervised methods for rPPG measurements have been shown to achieve good performance.","However, the drawback of these methods is that they require facial videos with ground truth (GT) physiological signals, which are often costly and difficult to obtain.","In this paper, we propose Contrast-Phys+, a method that can be trained in both unsupervised and weakly-supervised settings.","We employ a 3DCNN model to generate multiple spatiotemporal rPPG signals and incorporate prior knowledge of rPPG into a contrastive loss function.","We further incorporate the GT signals into contrastive learning to adapt to partial or misaligned labels.","The contrastive loss encourages rPPG/GT signals from the same video to be grouped together, while pushing those from different videos apart.","We evaluate our methods on five publicly available datasets that include both RGB and Near-infrared videos.","Contrast-Phys+ outperforms the state-of-the-art supervised methods, even when using partially available or misaligned GT signals, or no labels at all.","Additionally, we highlight the advantages of our methods in terms of computational efficiency, noise robustness, and generalization."],"url":"http://arxiv.org/abs/2309.06924v1"}
{"created":"2023-09-13 12:47:40","title":"Native Language Identification with Big Bird Embeddings","abstract":"Native Language Identification (NLI) intends to classify an author's native language based on their writing in another language. Historically, the task has heavily relied on time-consuming linguistic feature engineering, and transformer-based NLI models have thus far failed to offer effective, practical alternatives. The current work investigates if input size is a limiting factor, and shows that classifiers trained using Big Bird embeddings outperform linguistic feature engineering models by a large margin on the Reddit-L2 dataset. Additionally, we provide further insight into input length dependencies, show consistent out-of-sample performance, and qualitatively analyze the embedding space. Given the effectiveness and computational efficiency of this method, we believe it offers a promising avenue for future NLI work.","sentences":["Native Language Identification (NLI) intends to classify an author's native language based on their writing in another language.","Historically, the task has heavily relied on time-consuming linguistic feature engineering, and transformer-based NLI models have thus far failed to offer effective, practical alternatives.","The current work investigates if input size is a limiting factor, and shows that classifiers trained using Big Bird embeddings outperform linguistic feature engineering models by a large margin on the Reddit-L2 dataset.","Additionally, we provide further insight into input length dependencies, show consistent out-of-sample performance, and qualitatively analyze the embedding space.","Given the effectiveness and computational efficiency of this method, we believe it offers a promising avenue for future NLI work."],"url":"http://arxiv.org/abs/2309.06923v1"}
{"created":"2023-09-13 12:46:06","title":"Hydra: Multi-head Low-rank Adaptation for Parameter Efficient Fine-tuning","abstract":"The recent surge in large-scale foundation models has spurred the development of efficient methods for adapting these models to various downstream tasks. Low-rank adaptation methods, such as LoRA, have gained significant attention due to their outstanding parameter efficiency and no additional inference latency. This paper investigates a more general form of adapter module based on the analysis that parallel and sequential adaptation branches learn novel and general features during fine-tuning, respectively. The proposed method, named Hydra, due to its multi-head computational branches, combines parallel and sequential branch to integrate capabilities, which is more expressive than existing single branch methods and enables the exploration of a broader range of optimal points in the fine-tuning process. In addition, the proposed adaptation method explicitly leverages the pre-trained weights by performing a linear combination of the pre-trained features. It allows the learned features to have better generalization performance across diverse downstream tasks. Furthermore, we perform a comprehensive analysis of the characteristics of each adaptation branch with empirical evidence. Through an extensive range of experiments, encompassing comparisons and ablation studies, we substantiate the efficiency and demonstrate the superior performance of Hydra. This comprehensive evaluation underscores the potential impact and effectiveness of Hydra in a variety of applications. Our code is available on \\url{https://github.com/extremebird/Hydra}","sentences":["The recent surge in large-scale foundation models has spurred the development of efficient methods for adapting these models to various downstream tasks.","Low-rank adaptation methods, such as LoRA, have gained significant attention due to their outstanding parameter efficiency and no additional inference latency.","This paper investigates a more general form of adapter module based on the analysis that parallel and sequential adaptation branches learn novel and general features during fine-tuning, respectively.","The proposed method, named Hydra, due to its multi-head computational branches, combines parallel and sequential branch to integrate capabilities, which is more expressive than existing single branch methods and enables the exploration of a broader range of optimal points in the fine-tuning process.","In addition, the proposed adaptation method explicitly leverages the pre-trained weights by performing a linear combination of the pre-trained features.","It allows the learned features to have better generalization performance across diverse downstream tasks.","Furthermore, we perform a comprehensive analysis of the characteristics of each adaptation branch with empirical evidence.","Through an extensive range of experiments, encompassing comparisons and ablation studies, we substantiate the efficiency and demonstrate the superior performance of Hydra.","This comprehensive evaluation underscores the potential impact and effectiveness of Hydra in a variety of applications.","Our code is available on \\url{https://github.com/extremebird/Hydra}"],"url":"http://arxiv.org/abs/2309.06922v1"}
{"created":"2023-09-13 12:41:45","title":"Investigating the Impact of Action Representations in Policy Gradient Algorithms","abstract":"Reinforcement learning~(RL) is a versatile framework for learning to solve complex real-world tasks. However, influences on the learning performance of RL algorithms are often poorly understood in practice. We discuss different analysis techniques and assess their effectiveness for investigating the impact of action representations in RL. Our experiments demonstrate that the action representation can significantly influence the learning performance on popular RL benchmark tasks. The analysis results indicate that some of the performance differences can be attributed to changes in the complexity of the optimization landscape. Finally, we discuss open challenges of analysis techniques for RL algorithms.","sentences":["Reinforcement learning~(RL) is a versatile framework for learning to solve complex real-world tasks.","However, influences on the learning performance of RL algorithms are often poorly understood in practice.","We discuss different analysis techniques and assess their effectiveness for investigating the impact of action representations in RL.","Our experiments demonstrate that the action representation can significantly influence the learning performance on popular RL benchmark tasks.","The analysis results indicate that some of the performance differences can be attributed to changes in the complexity of the optimization landscape.","Finally, we discuss open challenges of analysis techniques for RL algorithms."],"url":"http://arxiv.org/abs/2309.06921v1"}
{"created":"2023-09-13 12:30:27","title":"Lotaru: Locally Predicting Workflow Task Runtimes for Resource Management on Heterogeneous Infrastructures","abstract":"Many resource management techniques for task scheduling, energy and carbon efficiency, and cost optimization in workflows rely on a-priori task runtime knowledge. Building runtime prediction models on historical data is often not feasible in practice as workflows, their input data, and the cluster infrastructure change. Online methods, on the other hand, which estimate task runtimes on specific machines while the workflow is running, have to cope with a lack of measurements during start-up. Frequently, scientific workflows are executed on heterogeneous infrastructures consisting of machines with different CPU, I/O, and memory configurations, further complicating predicting runtimes due to different task runtimes on different machine types.   This paper presents Lotaru, a method for locally predicting the runtimes of scientific workflow tasks before they are executed on heterogeneous compute clusters. Crucially, our approach does not rely on historical data and copes with a lack of training data during the start-up. To this end, we use microbenchmarks, reduce the input data to quickly profile the workflow locally, and predict a task's runtime with a Bayesian linear regression based on the gathered data points from the local workflow execution and the microbenchmarks. Due to its Bayesian approach, Lotaru provides uncertainty estimates that can be used for advanced scheduling methods on distributed cluster infrastructures.   In our evaluation with five real-world scientific workflows, our method outperforms two state-of-the-art runtime prediction baselines and decreases the absolute prediction error by more than 12.5%. In a second set of experiments, the prediction performance of our method, using the predicted runtimes for state-of-the-art scheduling, carbon reduction, and cost prediction, enables results close to those achieved with perfect prior knowledge of runtimes.","sentences":["Many resource management techniques for task scheduling, energy and carbon efficiency, and cost optimization in workflows rely on a-priori task runtime knowledge.","Building runtime prediction models on historical data is often not feasible in practice as workflows, their input data, and the cluster infrastructure change.","Online methods, on the other hand, which estimate task runtimes on specific machines while the workflow is running, have to cope with a lack of measurements during start-up.","Frequently, scientific workflows are executed on heterogeneous infrastructures consisting of machines with different CPU, I/O, and memory configurations, further complicating predicting runtimes due to different task runtimes on different machine types.   ","This paper presents Lotaru, a method for locally predicting the runtimes of scientific workflow tasks before they are executed on heterogeneous compute clusters.","Crucially, our approach does not rely on historical data and copes with a lack of training data during the start-up.","To this end, we use microbenchmarks, reduce the input data to quickly profile the workflow locally, and predict a task's runtime with a Bayesian linear regression based on the gathered data points from the local workflow execution and the microbenchmarks.","Due to its Bayesian approach, Lotaru provides uncertainty estimates that can be used for advanced scheduling methods on distributed cluster infrastructures.   ","In our evaluation with five real-world scientific workflows, our method outperforms two state-of-the-art runtime prediction baselines and decreases the absolute prediction error by more than 12.5%.","In a second set of experiments, the prediction performance of our method, using the predicted runtimes for state-of-the-art scheduling, carbon reduction, and cost prediction, enables results close to those achieved with perfect prior knowledge of runtimes."],"url":"http://arxiv.org/abs/2309.06918v1"}
{"created":"2023-09-13 12:30:03","title":"Continual Learning with Dirichlet Generative-based Rehearsal","abstract":"Recent advancements in data-driven task-oriented dialogue systems (ToDs) struggle with incremental learning due to computational constraints and time-consuming issues. Continual Learning (CL) attempts to solve this by avoiding intensive pre-training, but it faces the problem of catastrophic forgetting (CF). While generative-based rehearsal CL methods have made significant strides, generating pseudo samples that accurately reflect the underlying task-specific distribution is still a challenge. In this paper, we present Dirichlet Continual Learning (DCL), a novel generative-based rehearsal strategy for CL. Unlike the traditionally used Gaussian latent variable in the Conditional Variational Autoencoder (CVAE), DCL leverages the flexibility and versatility of the Dirichlet distribution to model the latent prior variable. This enables it to efficiently capture sentence-level features of previous tasks and effectively guide the generation of pseudo samples. In addition, we introduce Jensen-Shannon Knowledge Distillation (JSKD), a robust logit-based knowledge distillation method that enhances knowledge transfer during pseudo sample generation. Our experiments confirm the efficacy of our approach in both intent detection and slot-filling tasks, outperforming state-of-the-art methods.","sentences":["Recent advancements in data-driven task-oriented dialogue systems (ToDs) struggle with incremental learning due to computational constraints and time-consuming issues.","Continual Learning (CL) attempts to solve this by avoiding intensive pre-training, but it faces the problem of catastrophic forgetting (CF).","While generative-based rehearsal CL methods have made significant strides, generating pseudo samples that accurately reflect the underlying task-specific distribution is still a challenge.","In this paper, we present Dirichlet Continual Learning (DCL), a novel generative-based rehearsal strategy for CL.","Unlike the traditionally used Gaussian latent variable in the Conditional Variational Autoencoder (CVAE), DCL leverages the flexibility and versatility of the Dirichlet distribution to model the latent prior variable.","This enables it to efficiently capture sentence-level features of previous tasks and effectively guide the generation of pseudo samples.","In addition, we introduce Jensen-Shannon Knowledge Distillation (JSKD), a robust logit-based knowledge distillation method that enhances knowledge transfer during pseudo sample generation.","Our experiments confirm the efficacy of our approach in both intent detection and slot-filling tasks, outperforming state-of-the-art methods."],"url":"http://arxiv.org/abs/2309.06917v1"}
{"created":"2023-09-13 12:22:14","title":"Multi-behavior Recommendation with SVD Graph Neural Networks","abstract":"Graph Neural Networks (GNNs) has been extensively employed in the field of recommender systems, offering users personalized recommendations and yielding remarkable outcomes. Recently, GNNs incorporating contrastive learning have demonstrated promising performance in handling sparse data problem of recommendation system. However, existing contrastive learning methods still have limitations in addressing the cold-start problem and resisting noise interference especially for multi-behavior recommendation. To mitigate the aforementioned issues, the present research posits a GNNs based multi-behavior recommendation model MB-SVD that utilizes Singular Value Decomposition (SVD) graphs to enhance model performance. In particular, MB-SVD considers user preferences under different behaviors, improving recommendation effectiveness while better addressing the cold-start problem. Our model introduces an innovative methodology, which subsume multi-behavior contrastive learning paradigm to proficiently discern the intricate interconnections among heterogeneous manifestations of user behavior and generates SVD graphs to automate the distillation of crucial multi-behavior self-supervised information for robust graph augmentation. Furthermore, the SVD based framework reduces the embedding dimensions and computational load. Thorough experimentation showcases the remarkable performance of our proposed MB-SVD approach in multi-behavior recommendation endeavors across diverse real-world datasets.","sentences":["Graph Neural Networks (GNNs) has been extensively employed in the field of recommender systems, offering users personalized recommendations and yielding remarkable outcomes.","Recently, GNNs incorporating contrastive learning have demonstrated promising performance in handling sparse data problem of recommendation system.","However, existing contrastive learning methods still have limitations in addressing the cold-start problem and resisting noise interference especially for multi-behavior recommendation.","To mitigate the aforementioned issues, the present research posits a GNNs based multi-behavior recommendation model MB-SVD that utilizes Singular Value Decomposition (SVD) graphs to enhance model performance.","In particular, MB-SVD considers user preferences under different behaviors, improving recommendation effectiveness while better addressing the cold-start problem.","Our model introduces an innovative methodology, which subsume multi-behavior contrastive learning paradigm to proficiently discern the intricate interconnections among heterogeneous manifestations of user behavior and generates SVD graphs to automate the distillation of crucial multi-behavior self-supervised information for robust graph augmentation.","Furthermore, the SVD based framework reduces the embedding dimensions and computational load.","Thorough experimentation showcases the remarkable performance of our proposed MB-SVD approach in multi-behavior recommendation endeavors across diverse real-world datasets."],"url":"http://arxiv.org/abs/2309.06912v1"}
