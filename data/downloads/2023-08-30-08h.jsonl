{"created":"2023-08-29 17:58:55","title":"3D Adversarial Augmentations for Robust Out-of-Domain Predictions","abstract":"Since real-world training datasets cannot properly sample the long tail of the underlying data distribution, corner cases and rare out-of-domain samples can severely hinder the performance of state-of-the-art models. This problem becomes even more severe for dense tasks, such as 3D semantic segmentation, where points of non-standard objects can be confidently associated to the wrong class. In this work, we focus on improving the generalization to out-of-domain data. We achieve this by augmenting the training set with adversarial examples. First, we learn a set of vectors that deform the objects in an adversarial fashion. To prevent the adversarial examples from being too far from the existing data distribution, we preserve their plausibility through a series of constraints, ensuring sensor-awareness and shapes smoothness. Then, we perform adversarial augmentation by applying the learned sample-independent vectors to the available objects when training a model. We conduct extensive experiments across a variety of scenarios on data from KITTI, Waymo, and CrashD for 3D object detection, and on data from SemanticKITTI, Waymo, and nuScenes for 3D semantic segmentation. Despite training on a standard single dataset, our approach substantially improves the robustness and generalization of both 3D object detection and 3D semantic segmentation methods to out-of-domain data.","sentences":["Since real-world training datasets cannot properly sample the long tail of the underlying data distribution, corner cases and rare out-of-domain samples can severely hinder the performance of state-of-the-art models.","This problem becomes even more severe for dense tasks, such as 3D semantic segmentation, where points of non-standard objects can be confidently associated to the wrong class.","In this work, we focus on improving the generalization to out-of-domain data.","We achieve this by augmenting the training set with adversarial examples.","First, we learn a set of vectors that deform the objects in an adversarial fashion.","To prevent the adversarial examples from being too far from the existing data distribution, we preserve their plausibility through a series of constraints, ensuring sensor-awareness and shapes smoothness.","Then, we perform adversarial augmentation by applying the learned sample-independent vectors to the available objects when training a model.","We conduct extensive experiments across a variety of scenarios on data from KITTI, Waymo, and CrashD for 3D object detection, and on data from SemanticKITTI, Waymo, and nuScenes for 3D semantic segmentation.","Despite training on a standard single dataset, our approach substantially improves the robustness and generalization of both 3D object detection and 3D semantic segmentation methods to out-of-domain data."],"url":"http://arxiv.org/abs/2308.15479v1"}
{"created":"2023-08-29 17:57:20","title":"An Adaptive Tangent Feature Perspective of Neural Networks","abstract":"In order to better understand feature learning in neural networks, we propose a framework for understanding linear models in tangent feature space where the features are allowed to be transformed during training. We consider linear transformations of features, resulting in a joint optimization over parameters and transformations with a bilinear interpolation constraint. We show that this optimization problem has an equivalent linearly constrained optimization with structured regularization that encourages approximately low rank solutions. Specializing to neural network structure, we gain insights into how the features and thus the kernel function change, providing additional nuance to the phenomenon of kernel alignment when the target function is poorly represented using tangent features. In addition to verifying our theoretical observations in real neural networks on a simple regression problem, we empirically show that an adaptive feature implementation of tangent feature classification has an order of magnitude lower sample complexity than the fixed tangent feature model on MNIST and CIFAR-10.","sentences":["In order to better understand feature learning in neural networks, we propose a framework for understanding linear models in tangent feature space where the features are allowed to be transformed during training.","We consider linear transformations of features, resulting in a joint optimization over parameters and transformations with a bilinear interpolation constraint.","We show that this optimization problem has an equivalent linearly constrained optimization with structured regularization that encourages approximately low rank solutions.","Specializing to neural network structure, we gain insights into how the features and thus the kernel function change, providing additional nuance to the phenomenon of kernel alignment when the target function is poorly represented using tangent features.","In addition to verifying our theoretical observations in real neural networks on a simple regression problem, we empirically show that an adaptive feature implementation of tangent feature classification has an order of magnitude lower sample complexity than the fixed tangent feature model on MNIST and CIFAR-10."],"url":"http://arxiv.org/abs/2308.15478v1"}
{"created":"2023-08-29 17:52:10","title":"A General-Purpose Self-Supervised Model for Computational Pathology","abstract":"Tissue phenotyping is a fundamental computational pathology (CPath) task in learning objective characterizations of histopathologic biomarkers in anatomic pathology. However, whole-slide imaging (WSI) poses a complex computer vision problem in which the large-scale image resolutions of WSIs and the enormous diversity of morphological phenotypes preclude large-scale data annotation. Current efforts have proposed using pretrained image encoders with either transfer learning from natural image datasets or self-supervised pretraining on publicly-available histopathology datasets, but have not been extensively developed and evaluated across diverse tissue types at scale. We introduce UNI, a general-purpose self-supervised model for pathology, pretrained using over 100 million tissue patches from over 100,000 diagnostic haematoxylin and eosin-stained WSIs across 20 major tissue types, and evaluated on 33 representative CPath clinical tasks in CPath of varying diagnostic difficulties. In addition to outperforming previous state-of-the-art models, we demonstrate new modeling capabilities in CPath such as resolution-agnostic tissue classification, slide classification using few-shot class prototypes, and disease subtyping generalization in classifying up to 108 cancer types in the OncoTree code classification system. UNI advances unsupervised representation learning at scale in CPath in terms of both pretraining data and downstream evaluation, enabling data-efficient AI models that can generalize and transfer to a gamut of diagnostically-challenging tasks and clinical workflows in anatomic pathology.","sentences":["Tissue phenotyping is a fundamental computational pathology (CPath) task in learning objective characterizations of histopathologic biomarkers in anatomic pathology.","However, whole-slide imaging (WSI) poses a complex computer vision problem in which the large-scale image resolutions of WSIs and the enormous diversity of morphological phenotypes preclude large-scale data annotation.","Current efforts have proposed using pretrained image encoders with either transfer learning from natural image datasets or self-supervised pretraining on publicly-available histopathology datasets, but have not been extensively developed and evaluated across diverse tissue types at scale.","We introduce UNI, a general-purpose self-supervised model for pathology, pretrained using over 100 million tissue patches from over 100,000 diagnostic haematoxylin and eosin-stained WSIs across 20 major tissue types, and evaluated on 33 representative CPath clinical tasks in CPath of varying diagnostic difficulties.","In addition to outperforming previous state-of-the-art models, we demonstrate new modeling capabilities in CPath such as resolution-agnostic tissue classification, slide classification using few-shot class prototypes, and disease subtyping generalization in classifying up to 108 cancer types in the OncoTree code classification system.","UNI advances unsupervised representation learning at scale in CPath in terms of both pretraining data and downstream evaluation, enabling data-efficient AI models that can generalize and transfer to a gamut of diagnostically-challenging tasks and clinical workflows in anatomic pathology."],"url":"http://arxiv.org/abs/2308.15474v1"}
{"created":"2023-08-29 17:51:51","title":"Graph Theory and its Uses in Graph Algorithms and Beyond","abstract":"Graphs are fundamental objects that find widespread applications across computer science and beyond. Graph Theory has yielded deep insights about structural properties of various families of graphs, which are leveraged in the design and analysis of algorithms for graph optimization problems and other computational optimization problems. These insights have also proved helpful in understanding the limits of efficient computation by providing constructions of hard problem instances. At the same time, algorithmic tools and techniques provide a fresh perspective on graph theoretic problems, often leading to novel discoveries. In this thesis, we exploit this symbiotic relationship between graph theory and algorithms for graph optimization problems and beyond. This thesis consists of three parts.   In the first part, we study a graph routing problem called the Node-Disjoint Paths (NDP) problem. Given a graph and a set of source-destination pairs of its vertices, the goal is to route the maximum number of pairs via node-disjoint paths. We come close to resolving the approximability of NDP by showing that it is $n^{\\Omega(1/poly\\log\\log n)}$-hard to approximate, even on grid graphs, where n is the number of vertices. In the second part of this thesis, we use graph decomposition techniques developed for efficient algorithms to derive a graph theoretic result. We show that for every n-vertex expander graph G, if H is any graph with at most $O(n/\\log n)$ vertices and edges, then H is a minor of G. In the last part, we show that the graph theoretic tools and graph algorithmic techniques can shed light on problems seemingly unrelated to graphs. We show that the randomized space complexity of the Longest Increasing Subsequence (LIS) problem in the streaming model is intrinsically tied to the query-complexity of the Non-Crossing Matching problem on graphs in a new model of computation that we define.","sentences":["Graphs are fundamental objects that find widespread applications across computer science and beyond.","Graph Theory has yielded deep insights about structural properties of various families of graphs, which are leveraged in the design and analysis of algorithms for graph optimization problems and other computational optimization problems.","These insights have also proved helpful in understanding the limits of efficient computation by providing constructions of hard problem instances.","At the same time, algorithmic tools and techniques provide a fresh perspective on graph theoretic problems, often leading to novel discoveries.","In this thesis, we exploit this symbiotic relationship between graph theory and algorithms for graph optimization problems and beyond.","This thesis consists of three parts.   ","In the first part, we study a graph routing problem called the Node-Disjoint Paths (NDP) problem.","Given a graph and a set of source-destination pairs of its vertices, the goal is to route the maximum number of pairs via node-disjoint paths.","We come close to resolving the approximability of NDP by showing that it is $n^{\\Omega(1/poly\\log\\log n)}$-hard to approximate, even on grid graphs, where n is the number of vertices.","In the second part of this thesis, we use graph decomposition techniques developed for efficient algorithms to derive a graph theoretic result.","We show that for every n-vertex expander graph G, if H is any graph with at most $O(n/\\log n)$ vertices and edges, then H is a minor of G.","In the last part, we show that the graph theoretic tools and graph algorithmic techniques can shed light on problems seemingly unrelated to graphs.","We show that the randomized space complexity of the Longest Increasing Subsequence (LIS) problem in the streaming model is intrinsically tied to the query-complexity of the Non-Crossing Matching problem on graphs in a new model of computation that we define."],"url":"http://arxiv.org/abs/2308.15473v1"}
{"created":"2023-08-29 17:51:22","title":"Learning Modulated Transformation in GANs","abstract":"The success of style-based generators largely benefits from style modulation, which helps take care of the cross-instance variation within data. However, the instance-wise stochasticity is typically introduced via regular convolution, where kernels interact with features at some fixed locations, limiting its capacity for modeling geometric variation. To alleviate this problem, we equip the generator in generative adversarial networks (GANs) with a plug-and-play module, termed as modulated transformation module (MTM). This module predicts spatial offsets under the control of latent codes, based on which the convolution operation can be applied at variable locations for different instances, and hence offers the model an additional degree of freedom to handle geometry deformation. Extensive experiments suggest that our approach can be faithfully generalized to various generative tasks, including image generation, 3D-aware image synthesis, and video generation, and get compatible with state-of-the-art frameworks without any hyper-parameter tuning. It is noteworthy that, towards human generation on the challenging TaiChi dataset, we improve the FID of StyleGAN3 from 21.36 to 13.60, demonstrating the efficacy of learning modulated geometry transformation.","sentences":["The success of style-based generators largely benefits from style modulation, which helps take care of the cross-instance variation within data.","However, the instance-wise stochasticity is typically introduced via regular convolution, where kernels interact with features at some fixed locations, limiting its capacity for modeling geometric variation.","To alleviate this problem, we equip the generator in generative adversarial networks (GANs) with a plug-and-play module, termed as modulated transformation module (MTM).","This module predicts spatial offsets under the control of latent codes, based on which the convolution operation can be applied at variable locations for different instances, and hence offers the model an additional degree of freedom to handle geometry deformation.","Extensive experiments suggest that our approach can be faithfully generalized to various generative tasks, including image generation, 3D-aware image synthesis, and video generation, and get compatible with state-of-the-art frameworks without any hyper-parameter tuning.","It is noteworthy that, towards human generation on the challenging TaiChi dataset, we improve the FID of StyleGAN3 from 21.36 to 13.60, demonstrating the efficacy of learning modulated geometry transformation."],"url":"http://arxiv.org/abs/2308.15472v1"}
{"created":"2023-08-29 17:50:27","title":"Policy composition in reinforcement learning via multi-objective policy optimization","abstract":"We enable reinforcement learning agents to learn successful behavior policies by utilizing relevant pre-existing teacher policies. The teacher policies are introduced as objectives, in addition to the task objective, in a multi-objective policy optimization setting. Using the Multi-Objective Maximum a Posteriori Policy Optimization algorithm \\citep{abdolmaleki2020distributional}, we show that teacher policies can help speed up learning, particularly in the absence of shaping rewards. In two domains with continuous observation and action spaces, our agents successfully compose teacher policies in sequence and in parallel, and are also able to further extend the policies of the teachers in order to solve the task.   Depending on the specified combination of task and teacher(s), teacher(s) may naturally act to limit the final performance of an agent. The extent to which agents are required to adhere to teacher policies are determined by hyperparameters which determine both the effect of teachers on learning speed and the eventual performance of the agent on the task. In the {\\tt humanoid} domain \\citep{deepmindcontrolsuite2018}, we also equip agents with the ability to control the selection of teachers. With this ability, agents are able to meaningfully compose from the teacher policies to achieve a superior task reward on the {\\tt walk} task than in cases without access to the teacher policies. We show the resemblance of composed task policies with the corresponding teacher policies through videos.","sentences":["We enable reinforcement learning agents to learn successful behavior policies by utilizing relevant pre-existing teacher policies.","The teacher policies are introduced as objectives, in addition to the task objective, in a multi-objective policy optimization setting.","Using the Multi-Objective Maximum a Posteriori Policy Optimization algorithm \\citep{abdolmaleki2020distributional}, we show that teacher policies can help speed up learning, particularly in the absence of shaping rewards.","In two domains with continuous observation and action spaces, our agents successfully compose teacher policies in sequence and in parallel, and are also able to further extend the policies of the teachers in order to solve the task.   ","Depending on the specified combination of task and teacher(s), teacher(s) may naturally act to limit the final performance of an agent.","The extent to which agents are required to adhere to teacher policies are determined by hyperparameters which determine both the effect of teachers on learning speed and the eventual performance of the agent on the task.","In the {\\tt humanoid} domain \\citep{deepmindcontrolsuite2018}, we also equip agents with the ability to control the selection of teachers.","With this ability, agents are able to meaningfully compose from the teacher policies to achieve a superior task reward on the {\\tt walk} task than in cases without access to the teacher policies.","We show the resemblance of composed task policies with the corresponding teacher policies through videos."],"url":"http://arxiv.org/abs/2308.15470v1"}
{"created":"2023-08-29 17:48:33","title":"Multimodal Contrastive Learning and Tabular Attention for Automated Alzheimer's Disease Prediction","abstract":"Alongside neuroimaging such as MRI scans and PET, Alzheimer's disease (AD) datasets contain valuable tabular data including AD biomarkers and clinical assessments. Existing computer vision approaches struggle to utilize this additional information. To address these needs, we propose a generalizable framework for multimodal contrastive learning of image data and tabular data, a novel tabular attention module for amplifying and ranking salient features in tables, and the application of these techniques onto Alzheimer's disease prediction. Experimental evaulations demonstrate the strength of our framework by detecting Alzheimer's disease (AD) from over 882 MR image slices from the ADNI database. We take advantage of the high interpretability of tabular data and our novel tabular attention approach and through attribution of the attention scores for each row of the table, we note and rank the most predominant features. Results show that the model is capable of an accuracy of over 83.8%, almost a 10% increase from previous state of the art.","sentences":["Alongside neuroimaging such as MRI scans and PET, Alzheimer's disease (AD) datasets contain valuable tabular data including AD biomarkers and clinical assessments.","Existing computer vision approaches struggle to utilize this additional information.","To address these needs, we propose a generalizable framework for multimodal contrastive learning of image data and tabular data, a novel tabular attention module for amplifying and ranking salient features in tables, and the application of these techniques onto Alzheimer's disease prediction.","Experimental evaulations demonstrate the strength of our framework by detecting Alzheimer's disease (AD) from over 882 MR image slices from the ADNI database.","We take advantage of the high interpretability of tabular data and our novel tabular attention approach and through attribution of the attention scores for each row of the table, we note and rank the most predominant features.","Results show that the model is capable of an accuracy of over 83.8%, almost a 10% increase from previous state of the art."],"url":"http://arxiv.org/abs/2308.15469v1"}
{"created":"2023-08-29 17:47:42","title":"Input margins can predict generalization too","abstract":"Understanding generalization in deep neural networks is an active area of research. A promising avenue of exploration has been that of margin measurements: the shortest distance to the decision boundary for a given sample or its representation internal to the network. While margins have been shown to be correlated with the generalization ability of a model when measured at its hidden representations (hidden margins), no such link between large margins and generalization has been established for input margins. We show that while input margins are not generally predictive of generalization, they can be if the search space is appropriately constrained. We develop such a measure based on input margins, which we refer to as `constrained margins'. The predictive power of this new measure is demonstrated on the 'Predicting Generalization in Deep Learning' (PGDL) dataset and contrasted with hidden representation margins. We find that constrained margins achieve highly competitive scores and outperform other margin measurements in general. This provides a novel insight on the relationship between generalization and classification margins, and highlights the importance of considering the data manifold for investigations of generalization in DNNs.","sentences":["Understanding generalization in deep neural networks is an active area of research.","A promising avenue of exploration has been that of margin measurements: the shortest distance to the decision boundary for a given sample or its representation internal to the network.","While margins have been shown to be correlated with the generalization ability of a model when measured at its hidden representations (hidden margins), no such link between large margins and generalization has been established for input margins.","We show that while input margins are not generally predictive of generalization, they can be if the search space is appropriately constrained.","We develop such a measure based on input margins, which we refer to as `constrained margins'.","The predictive power of this new measure is demonstrated on the 'Predicting Generalization in Deep Learning' (PGDL) dataset and contrasted with hidden representation margins.","We find that constrained margins achieve highly competitive scores and outperform other margin measurements in general.","This provides a novel insight on the relationship between generalization and classification margins, and highlights the importance of considering the data manifold for investigations of generalization in DNNs."],"url":"http://arxiv.org/abs/2308.15466v1"}
{"created":"2023-08-29 17:45:01","title":"Sharing proofs with predicative theories through universe polymorphic elaboration","abstract":"As the development of formal proofs is a time-consuming task, it is important to devise ways of sharing the already written proofs to prevent wasting time redoing them. One of the challenges in this domain is to translate proofs written in proof assistants based on impredicative logics to proof assistants based on predicative logics, whenever impredicativity is not used in an essential way.   In this paper we present a transformation for sharing proofs with a core predicative system supporting prenex universe polymorphism (like in Agda). It consists in trying to elaborate a potentially impredicative term into a predicative universe polymorphic term as general as possible. The use of universe polymorphism is justified by the fact that mapping each universe to a fixed one in the target theory is not sufficient in most cases. During the algorithm, we need to solve unification problems in the equational theory of universe levels. In order to do this, we give a complete characterization of when a single equation admits a most general unifier. This characterization is then employed in an algorithm which uses a constraint-postponement strategy to solve unification problems.   The proposed translation is of course partial, but in practice allows one to translate many proofs that do not use impredicativity in an essential way. Indeed, it was implemented in the tool Predicativize and then used to translate semi-automatically many non-trivial developments from Matita's arithmetic library to Agda, including proofs of Bertrand's Postulate and Fermat's Little Theorem, which (as far as we know) were not available in Agda yet.","sentences":["As the development of formal proofs is a time-consuming task, it is important to devise ways of sharing the already written proofs to prevent wasting time redoing them.","One of the challenges in this domain is to translate proofs written in proof assistants based on impredicative logics to proof assistants based on predicative logics, whenever impredicativity is not used in an essential way.   ","In this paper we present a transformation for sharing proofs with a core predicative system supporting prenex universe polymorphism (like in Agda).","It consists in trying to elaborate a potentially impredicative term into a predicative universe polymorphic term as general as possible.","The use of universe polymorphism is justified by the fact that mapping each universe to a fixed one in the target theory is not sufficient in most cases.","During the algorithm, we need to solve unification problems in the equational theory of universe levels.","In order to do this, we give a complete characterization of when a single equation admits a most general unifier.","This characterization is then employed in an algorithm which uses a constraint-postponement strategy to solve unification problems.   ","The proposed translation is of course partial, but in practice allows one to translate many proofs that do not use impredicativity in an essential way.","Indeed, it was implemented in the tool Predicativize and then used to translate semi-automatically many non-trivial developments from Matita's arithmetic library to Agda, including proofs of Bertrand's Postulate and Fermat's Little Theorem, which (as far as we know) were not available in Agda yet."],"url":"http://arxiv.org/abs/2308.15465v1"}
{"created":"2023-08-29 17:44:02","title":"A Comparative Study of Loss Functions: Traffic Predictions in Regular and Congestion Scenarios","abstract":"Spatiotemporal graph neural networks have achieved state-of-the-art performance in traffic forecasting. However, they often struggle to forecast congestion accurately due to the limitations of traditional loss functions. While accurate forecasting of regular traffic conditions is crucial, a reliable AI system must also accurately forecast congestion scenarios to maintain safe and efficient transportation. In this paper, we explore various loss functions inspired by heavy tail analysis and imbalanced classification problems to address this issue. We evaluate the efficacy of these loss functions in forecasting traffic speed, with an emphasis on congestion scenarios. Through extensive experiments on real-world traffic datasets, we discovered that when optimizing for Mean Absolute Error (MAE), the MAE-Focal Loss function stands out as the most effective. When optimizing Mean Squared Error (MSE), Gumbel Loss proves to be the superior choice. These choices effectively forecast traffic congestion events without compromising the accuracy of regular traffic speed forecasts. This research enhances deep learning models' capabilities in forecasting sudden speed changes due to congestion and underscores the need for more research in this direction. By elevating the accuracy of congestion forecasting, we advocate for AI systems that are reliable, secure, and resilient in practical traffic management scenarios.","sentences":["Spatiotemporal graph neural networks have achieved state-of-the-art performance in traffic forecasting.","However, they often struggle to forecast congestion accurately due to the limitations of traditional loss functions.","While accurate forecasting of regular traffic conditions is crucial, a reliable AI system must also accurately forecast congestion scenarios to maintain safe and efficient transportation.","In this paper, we explore various loss functions inspired by heavy tail analysis and imbalanced classification problems to address this issue.","We evaluate the efficacy of these loss functions in forecasting traffic speed, with an emphasis on congestion scenarios.","Through extensive experiments on real-world traffic datasets, we discovered that when optimizing for Mean Absolute Error (MAE), the MAE-Focal Loss function stands out as the most effective.","When optimizing Mean Squared Error (MSE), Gumbel Loss proves to be the superior choice.","These choices effectively forecast traffic congestion events without compromising the accuracy of regular traffic speed forecasts.","This research enhances deep learning models' capabilities in forecasting sudden speed changes due to congestion and underscores the need for more research in this direction.","By elevating the accuracy of congestion forecasting, we advocate for AI systems that are reliable, secure, and resilient in practical traffic management scenarios."],"url":"http://arxiv.org/abs/2308.15464v1"}
{"created":"2023-08-29 17:40:57","title":"Online Overexposed Pixels Hallucination in Videos with Adaptive Reference Frame Selection","abstract":"Low dynamic range (LDR) cameras cannot deal with wide dynamic range inputs, frequently leading to local overexposure issues. We present a learning-based system to reduce these artifacts without resorting to complex acquisition mechanisms like alternating exposures or costly processing that are typical of high dynamic range (HDR) imaging. We propose a transformer-based deep neural network (DNN) to infer the missing HDR details. In an ablation study, we show the importance of using a multiscale DNN and train it with the proper cost function to achieve state-of-the-art quality. To aid the reconstruction of the overexposed areas, our DNN takes a reference frame from the past as an additional input. This leverages the commonly occurring temporal instabilities of autoexposure to our advantage: since well-exposed details in the current frame may be overexposed in the future, we use reinforcement learning to train a reference frame selection DNN that decides whether to adopt the current frame as a future reference. Without resorting to alternating exposures, we obtain therefore a causal, HDR hallucination algorithm with potential application in common video acquisition settings. Our demo video can be found at https://drive.google.com/file/d/1-r12BKImLOYCLUoPzdebnMyNjJ4Rk360/view","sentences":["Low dynamic range (LDR) cameras cannot deal with wide dynamic range inputs, frequently leading to local overexposure issues.","We present a learning-based system to reduce these artifacts without resorting to complex acquisition mechanisms like alternating exposures or costly processing that are typical of high dynamic range (HDR) imaging.","We propose a transformer-based deep neural network (DNN) to infer the missing HDR details.","In an ablation study, we show the importance of using a multiscale DNN and train it with the proper cost function to achieve state-of-the-art quality.","To aid the reconstruction of the overexposed areas, our DNN takes a reference frame from the past as an additional input.","This leverages the commonly occurring temporal instabilities of autoexposure to our advantage: since well-exposed details in the current frame may be overexposed in the future, we use reinforcement learning to train a reference frame selection DNN that decides whether to adopt the current frame as a future reference.","Without resorting to alternating exposures, we obtain therefore a causal, HDR hallucination algorithm with potential application in common video acquisition settings.","Our demo video can be found at https://drive.google.com/file/d/1-r12BKImLOYCLUoPzdebnMyNjJ4Rk360/view"],"url":"http://arxiv.org/abs/2308.15462v1"}
{"created":"2023-08-29 17:38:33","title":"Canonical Factors for Hybrid Neural Fields","abstract":"Factored feature volumes offer a simple way to build more compact, efficient, and intepretable neural fields, but also introduce biases that are not necessarily beneficial for real-world data. In this work, we (1) characterize the undesirable biases that these architectures have for axis-aligned signals -- they can lead to radiance field reconstruction differences of as high as 2 PSNR -- and (2) explore how learning a set of canonicalizing transformations can improve representations by removing these biases. We prove in a two-dimensional model problem that simultaneously learning these transformations together with scene appearance succeeds with drastically improved efficiency. We validate the resulting architectures, which we call TILTED, using image, signed distance, and radiance field reconstruction tasks, where we observe improvements across quality, robustness, compactness, and runtime. Results demonstrate that TILTED can enable capabilities comparable to baselines that are 2x larger, while highlighting weaknesses of neural field evaluation procedures.","sentences":["Factored feature volumes offer a simple way to build more compact, efficient, and intepretable neural fields, but also introduce biases that are not necessarily beneficial for real-world data.","In this work, we (1) characterize the undesirable biases that these architectures have for axis-aligned signals -- they can lead to radiance field reconstruction differences of as high as 2 PSNR -- and (2) explore how learning a set of canonicalizing transformations can improve representations by removing these biases.","We prove in a two-dimensional model problem that simultaneously learning these transformations together with scene appearance succeeds with drastically improved efficiency.","We validate the resulting architectures, which we call TILTED, using image, signed distance, and radiance field reconstruction tasks, where we observe improvements across quality, robustness, compactness, and runtime.","Results demonstrate that TILTED can enable capabilities comparable to baselines that are 2x larger, while highlighting weaknesses of neural field evaluation procedures."],"url":"http://arxiv.org/abs/2308.15461v1"}
{"created":"2023-08-29 17:36:02","title":"ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer","abstract":"Textual style transfer is the task of transforming stylistic properties of text while preserving meaning. Target \"styles\" can be defined in numerous ways, ranging from single attributes (e.g, formality) to authorship (e.g, Shakespeare). Previous unsupervised style-transfer approaches generally rely on significant amounts of labeled data for only a fixed set of styles or require large language models. In contrast, we introduce a novel diffusion-based framework for general-purpose style transfer that can be flexibly adapted to arbitrary target styles at inference time. Our parameter-efficient approach, ParaGuide, leverages paraphrase-conditioned diffusion models alongside gradient-based guidance from both off-the-shelf classifiers and strong existing style embedders to transform the style of text while preserving semantic information. We validate the method on the Enron Email Corpus, with both human and automatic evaluations, and find that it outperforms strong baselines on formality, sentiment, and even authorship style transfer.","sentences":["Textual style transfer is the task of transforming stylistic properties of text while preserving meaning.","Target \"styles\" can be defined in numerous ways, ranging from single attributes (e.g, formality) to authorship (e.g, Shakespeare).","Previous unsupervised style-transfer approaches generally rely on significant amounts of labeled data for only a fixed set of styles or require large language models.","In contrast, we introduce a novel diffusion-based framework for general-purpose style transfer that can be flexibly adapted to arbitrary target styles at inference time.","Our parameter-efficient approach, ParaGuide, leverages paraphrase-conditioned diffusion models alongside gradient-based guidance from both off-the-shelf classifiers and strong existing style embedders to transform the style of text while preserving semantic information.","We validate the method on the Enron Email Corpus, with both human and automatic evaluations, and find that it outperforms strong baselines on formality, sentiment, and even authorship style transfer."],"url":"http://arxiv.org/abs/2308.15459v1"}
{"created":"2023-08-29 17:31:26","title":"From SMOTE to Mixup for Deep Imbalanced Classification","abstract":"Given imbalanced data, it is hard to train a good classifier using deep learning because of the poor generalization of minority classes. Traditionally, the well-known synthetic minority oversampling technique (SMOTE) for data augmentation, a data mining approach for imbalanced learning, has been used to improve this generalization. However, it is unclear whether SMOTE also benefits deep learning. In this work, we study why the original SMOTE is insufficient for deep learning, and enhance SMOTE using soft labels. Connecting the resulting soft SMOTE with Mixup, a modern data augmentation technique, leads to a unified framework that puts traditional and modern data augmentation techniques under the same umbrella. A careful study within this framework shows that Mixup improves generalization by implicitly achieving uneven margins between majority and minority classes. We then propose a novel margin-aware Mixup technique that more explicitly achieves uneven margins. Extensive experimental results demonstrate that our proposed technique yields state-of-the-art performance on deep imbalanced classification while achieving superior performance on extremely imbalanced data. The code is open-sourced in our developed package https://github.com/ntucllab/imbalanced-DL to foster future research in this direction.","sentences":["Given imbalanced data, it is hard to train a good classifier using deep learning because of the poor generalization of minority classes.","Traditionally, the well-known synthetic minority oversampling technique (SMOTE) for data augmentation, a data mining approach for imbalanced learning, has been used to improve this generalization.","However, it is unclear whether SMOTE also benefits deep learning.","In this work, we study why the original SMOTE is insufficient for deep learning, and enhance SMOTE using soft labels.","Connecting the resulting soft SMOTE with Mixup, a modern data augmentation technique, leads to a unified framework that puts traditional and modern data augmentation techniques under the same umbrella.","A careful study within this framework shows that Mixup improves generalization by implicitly achieving uneven margins between majority and minority classes.","We then propose a novel margin-aware Mixup technique that more explicitly achieves uneven margins.","Extensive experimental results demonstrate that our proposed technique yields state-of-the-art performance on deep imbalanced classification while achieving superior performance on extremely imbalanced data.","The code is open-sourced in our developed package https://github.com/ntucllab/imbalanced-DL to foster future research in this direction."],"url":"http://arxiv.org/abs/2308.15457v1"}
{"created":"2023-08-29 17:31:03","title":"Timely Multi-Goal Transmissions With an Intermittently Failing Sensor","abstract":"A sensor observes a random phenomenon and transmits updates about the observed phenomenon to a remote monitor. The sensor may experience intermittent failures in which case the monitor will not receive any updates until the sensor has recovered. The monitor wants to keep a timely view of the observed process, as well as to detect any sensor failures, using the timings of the updates. We analyze this system model from a goal-oriented and semantic communication point of view, where the communication has multiple goals and multiple meanings/semantics. For the first goal, the performance is quantified by the age of information of the observed process at the monitor. For the second goal, the performance is quantified by the probability of error of the monitor's estimation of the sensor's failure status. Each arriving update packet brings both an information update and an indication about the sensor's status. The monitor estimates the failure status of the sensor by using the timings of the received updates. This estimation is subject to error, since a long period without any update receptions may be due to a low update rate or a failure of the sensor. We examine the trade-off between these two goals. We show that the probability of error of estimating a sensor failure decreases with increased update rate, however, the age of information is minimized with an intermediate update rate (not too low or high).","sentences":["A sensor observes a random phenomenon and transmits updates about the observed phenomenon to a remote monitor.","The sensor may experience intermittent failures in which case the monitor will not receive any updates until the sensor has recovered.","The monitor wants to keep a timely view of the observed process, as well as to detect any sensor failures, using the timings of the updates.","We analyze this system model from a goal-oriented and semantic communication point of view, where the communication has multiple goals and multiple meanings/semantics.","For the first goal, the performance is quantified by the age of information of the observed process at the monitor.","For the second goal, the performance is quantified by the probability of error of the monitor's estimation of the sensor's failure status.","Each arriving update packet brings both an information update and an indication about the sensor's status.","The monitor estimates the failure status of the sensor by using the timings of the received updates.","This estimation is subject to error, since a long period without any update receptions may be due to a low update rate or a failure of the sensor.","We examine the trade-off between these two goals.","We show that the probability of error of estimating a sensor failure decreases with increased update rate, however, the age of information is minimized with an intermediate update rate (not too low or high)."],"url":"http://arxiv.org/abs/2308.15456v1"}
{"created":"2023-08-29 17:23:33","title":"Pseudo-Boolean Polynomials Approach To Edge Detection And Image Segmentation","abstract":"We introduce a deterministic approach to edge detection and image segmentation by formulating pseudo-Boolean polynomials on image patches. The approach works by applying a binary classification of blob and edge regions in an image based on the degrees of pseudo-Boolean polynomials calculated on patches extracted from the provided image. We test our method on simple images containing primitive shapes of constant and contrasting colour and establish the feasibility before applying it to complex instances like aerial landscape images. The proposed method is based on the exploitation of the reduction, polynomial degree, and equivalence properties of penalty-based pseudo-Boolean polynomials.","sentences":["We introduce a deterministic approach to edge detection and image segmentation by formulating pseudo-Boolean polynomials on image patches.","The approach works by applying a binary classification of blob and edge regions in an image based on the degrees of pseudo-Boolean polynomials calculated on patches extracted from the provided image.","We test our method on simple images containing primitive shapes of constant and contrasting colour and establish the feasibility before applying it to complex instances like aerial landscape images.","The proposed method is based on the exploitation of the reduction, polynomial degree, and equivalence properties of penalty-based pseudo-Boolean polynomials."],"url":"http://arxiv.org/abs/2308.15453v1"}
{"created":"2023-08-29 17:22:39","title":"When Do Program-of-Thoughts Work for Reasoning?","abstract":"The reasoning capabilities of Large Language Models (LLMs) play a pivotal role in the realm of embodied artificial intelligence. Although there are effective methods like program-of-thought prompting for LLMs which uses programming language to tackle complex reasoning tasks, the specific impact of code data on the improvement of reasoning capabilities remains under-explored. To address this gap, we propose complexity-impacted reasoning score (CIRS), which combines structural and logical attributes, to measure the correlation between code and reasoning abilities. Specifically, we use the abstract syntax tree to encode the structural information and calculate logical complexity by considering the difficulty and the cyclomatic complexity. Through an empirical analysis, we find not all code data of complexity can be learned or understood by LLMs. Optimal level of complexity is critical to the improvement of reasoning abilities by program-aided prompting. Then we design an auto-synthesizing and stratifying algorithm, and apply it to instruction generation for mathematical reasoning and code data filtering for code generation tasks. Extensive results demonstrates the effectiveness of our proposed approach. Code will be integrated into the EasyInstruct framework at https://github.com/zjunlp/EasyInstruct.","sentences":["The reasoning capabilities of Large Language Models (LLMs) play a pivotal role in the realm of embodied artificial intelligence.","Although there are effective methods like program-of-thought prompting for LLMs which uses programming language to tackle complex reasoning tasks, the specific impact of code data on the improvement of reasoning capabilities remains under-explored.","To address this gap, we propose complexity-impacted reasoning score (CIRS), which combines structural and logical attributes, to measure the correlation between code and reasoning abilities.","Specifically, we use the abstract syntax tree to encode the structural information and calculate logical complexity by considering the difficulty and the cyclomatic complexity.","Through an empirical analysis, we find not all code data of complexity can be learned or understood by LLMs.","Optimal level of complexity is critical to the improvement of reasoning abilities by program-aided prompting.","Then we design an auto-synthesizing and stratifying algorithm, and apply it to instruction generation for mathematical reasoning and code data filtering for code generation tasks.","Extensive results demonstrates the effectiveness of our proposed approach.","Code will be integrated into the EasyInstruct framework at https://github.com/zjunlp/EasyInstruct."],"url":"http://arxiv.org/abs/2308.15452v1"}
{"created":"2023-08-29 17:20:35","title":"PEM: Representing Binary Program Semantics for Similarity Analysis via a Probabilistic Execution Model","abstract":"Binary similarity analysis determines if two binary executables are from the same source program. Existing techniques leverage static and dynamic program features and may utilize advanced Deep Learning techniques. Although they have demonstrated great potential, the community believes that a more effective representation of program semantics can further improve similarity analysis. In this paper, we propose a new method to represent binary program semantics. It is based on a novel probabilistic execution engine that can effectively sample the input space and the program path space of subject binaries. More importantly, it ensures that the collected samples are comparable across binaries, addressing the substantial variations of input specifications. Our evaluation on 9 real-world projects with 35k functions, and comparison with 6 state-of-the-art techniques show that PEM can achieve a precision of 96% with common settings, outperforming the baselines by 10-20%.","sentences":["Binary similarity analysis determines if two binary executables are from the same source program.","Existing techniques leverage static and dynamic program features and may utilize advanced Deep Learning techniques.","Although they have demonstrated great potential, the community believes that a more effective representation of program semantics can further improve similarity analysis.","In this paper, we propose a new method to represent binary program semantics.","It is based on a novel probabilistic execution engine that can effectively sample the input space and the program path space of subject binaries.","More importantly, it ensures that the collected samples are comparable across binaries, addressing the substantial variations of input specifications.","Our evaluation on 9 real-world projects with 35k functions, and comparison with 6 state-of-the-art techniques show that PEM can achieve a precision of 96% with common settings, outperforming the baselines by 10-20%."],"url":"http://arxiv.org/abs/2308.15449v1"}
{"created":"2023-08-29 17:19:32","title":"Vulgar Remarks Detection in Chittagonian Dialect of Bangla","abstract":"The negative effects of online bullying and harassment are increasing with Internet popularity, especially in social media. One solution is using natural language processing (NLP) and machine learning (ML) methods for the automatic detection of harmful remarks, but these methods are limited in low-resource languages like the Chittagonian dialect of Bangla.This study focuses on detecting vulgar remarks in social media using supervised ML and deep learning algorithms.Logistic Regression achieved promising accuracy (0.91) while simple RNN with Word2vec and fastTex had lower accuracy (0.84-0.90), highlighting the issue that NN algorithms require more data.","sentences":["The negative effects of online bullying and harassment are increasing with Internet popularity, especially in social media.","One solution is using natural language processing (NLP) and machine learning (ML) methods for the automatic detection of harmful remarks, but these methods are limited in low-resource languages like the Chittagonian dialect of Bangla.","This study focuses on detecting vulgar remarks in social media using supervised ML and deep learning algorithms.","Logistic Regression achieved promising accuracy (0.91) while simple RNN with Word2vec and fastTex had lower accuracy (0.84-0.90), highlighting the issue that NN algorithms require more data."],"url":"http://arxiv.org/abs/2308.15448v1"}
{"created":"2023-08-29 17:11:55","title":"On the hardness of inclusion-wise minimal separators enumeration","abstract":"Enumeration problems are often encountered as key subroutines in the exact computation of graph parameters such as chromatic number, treewidth, or treedepth. In the case of treedepth computation, the enumeration of inclusion-wise minimal separators plays a crucial role. However and quite surprisingly, the complexity status of this problem has not been settled since it has been posed as an open direction by Kloks and Kratsch in 1998. Recently at the PACE 2020 competition dedicated to treedepth computation, solvers have been circumventing that by listing all minimal $a$-$b$ separators and filtering out those that are not inclusion-wise minimal, at the cost of efficiency. Naturally, having an efficient algorithm for listing inclusion-wise minimal separators would drastically improve such practical algorithms. In this note, however, we show that no efficient algorithm is to be expected from an output-sensitive perspective, namely, we prove that there is no output-polynomial time algorithm for inclusion-wise minimal separators enumeration unless P = NP.","sentences":["Enumeration problems are often encountered as key subroutines in the exact computation of graph parameters such as chromatic number, treewidth, or treedepth.","In the case of treedepth computation, the enumeration of inclusion-wise minimal separators plays a crucial role.","However and quite surprisingly, the complexity status of this problem has not been settled since it has been posed as an open direction by Kloks and Kratsch in 1998.","Recently at the PACE 2020 competition dedicated to treedepth computation, solvers have been circumventing that by listing all minimal $a$-$b$ separators and filtering out those that are not inclusion-wise minimal, at the cost of efficiency.","Naturally, having an efficient algorithm for listing inclusion-wise minimal separators would drastically improve such practical algorithms.","In this note, however, we show that no efficient algorithm is to be expected from an output-sensitive perspective, namely, we prove that there is no output-polynomial time algorithm for inclusion-wise minimal separators enumeration unless P = NP."],"url":"http://arxiv.org/abs/2308.15444v1"}
{"created":"2023-08-29 17:05:40","title":"Adversarial Low Degree Testing","abstract":"In the $t$-online-erasure model in property testing, an adversary is allowed to erase $t$ values of a queried function for each query the tester makes. This model was recently formulated by Kalemaj, Raskhodnikova andVarma, who showed that the properties of linearity of functions as well as quadraticity can be tested in$O_t(1)$ many queries: $O(\\log (t))$ for linearity and $2^{2^{O(t)}}$ for quadraticity. They asked whether the more general property of low-degreeness can be tested in the online erasure model, whether better testers exist for quadraticity, and if similar results hold when ``erasures'' are replaced with ``corruptions''.   We show that, in the $t$-online-erasure model, for a prime power $q$, given query access to a function $f: \\mathbb{F}_q^n \\xrightarrow[]{} \\mathbb{F}_q$, one can distinguish in $\\mathrm{poly}(\\log^{d+q}(t)/\\delta)$ queries between the case that $f$ is degree at most $d$, and the case that $f$ is $\\delta$-far from any degree $d$ function (with respect to the fractional hamming distance). This answers the aforementioned questions and brings the query complexity to nearly match the query complexity of low-degree testing in the classical property testing model. Our results are based on the observation that the property of low-degreeness admits a large and versatile family of query efficient testers. Our testers operates by querying a uniformly random, sufficiently large set of points in a large enough affine subspace, and finding a tester for low-degreeness that only utilizes queries from that set of points.   We believe that this tester may find other applications to algorithms in the online-erasure model or other related models, and may be of independent interest.","sentences":["In the $t$-online-erasure model in property testing, an adversary is allowed to erase $t$ values of a queried function for each query the tester makes.","This model was recently formulated by Kalemaj, Raskhodnikova andVarma, who showed that the properties of linearity of functions as well as quadraticity can be tested in$O_t(1)$ many queries: $O(\\log (t))$ for linearity and $2^{2^{O(t)}}$ for quadraticity.","They asked whether the more general property of low-degreeness can be tested in the online erasure model, whether better testers exist for quadraticity, and if similar results hold when ``erasures'' are replaced with ``corruptions''.   ","We show that, in the $t$-online-erasure model, for a prime power $q$, given query access to a function $f: \\mathbb{F}_q^n \\xrightarrow[]{} \\mathbb{F}_q$, one can distinguish in $\\mathrm{poly}(\\log^{d+q}(t)/\\delta)$ queries between the case that $f$ is degree at most $d$, and the case that $f$ is $\\delta$-far from any degree $d$ function (with respect to the fractional hamming distance).","This answers the aforementioned questions and brings the query complexity to nearly match the query complexity of low-degree testing in the classical property testing model.","Our results are based on the observation that the property of low-degreeness admits a large and versatile family of query efficient testers.","Our testers operates by querying a uniformly random, sufficiently large set of points in a large enough affine subspace, and finding a tester for low-degreeness that only utilizes queries from that set of points.   ","We believe that this tester may find other applications to algorithms in the online-erasure model or other related models, and may be of independent interest."],"url":"http://arxiv.org/abs/2308.15441v1"}
{"created":"2023-08-29 16:56:03","title":"Random feature approximation for general spectral methods","abstract":"Random feature approximation is arguably one of the most popular techniques to speed up kernel methods in large scale algorithms and provides a theoretical approach to the analysis of deep neural networks. We analyze generalization properties for a large class of spectral regularization methods combined with random features, containing kernel methods with implicit regularization such as gradient descent or explicit methods like Tikhonov regularization. For our estimators we obtain optimal learning rates over regularity classes (even for classes that are not included in the reproducing kernel Hilbert space), which are defined through appropriate source conditions. This improves or completes previous results obtained in related settings for specific kernel algorithms.","sentences":["Random feature approximation is arguably one of the most popular techniques to speed up kernel methods in large scale algorithms and provides a theoretical approach to the analysis of deep neural networks.","We analyze generalization properties for a large class of spectral regularization methods combined with random features, containing kernel methods with implicit regularization such as gradient descent or explicit methods like Tikhonov regularization.","For our estimators we obtain optimal learning rates over regularity classes (even for classes that are not included in the reproducing kernel Hilbert space), which are defined through appropriate source conditions.","This improves or completes previous results obtained in related settings for specific kernel algorithms."],"url":"http://arxiv.org/abs/2308.15434v1"}
{"created":"2023-08-29 16:43:43","title":"Only YOU Can Make IEEE VIS Environmentally Sustainable","abstract":"The IEEE VIS Conference (or VIS) hosts more than 1000 people annually. It brings together visualization researchers and practitioners from across the world to share new research and knowledge. Behind the scenes, a team of volunteers puts together the entire conference and makes sure it runs smoothly. Organizing involves logistics of the conference, ensuring that the attendees have an enjoyable time, allocating rooms to multiple concurrent tracks, and keeping the conference within budget. In recent years, the COVID-19 pandemic has abruptly disrupted plans, forcing organizers to switch to virtual, hybrid, and satellite formats. These alternatives offer many benefits: fewer costs (e.g., travel, venue, institutional), greater accessibility (who can physically travel, who can get visas, who can get child care), and a lower carbon footprint (as people do not need to fly to attend). As many conferences begin to revert to the pre-pandemic status quo of primarily in-person conferences, we suggest that it is an opportune moment to reflect on the benefits and drawbacks of lower-carbon conference formats. To learn more about the logistics of conference organizing, we talked to 6 senior executive-level VIS organizers. We review some of the many considerations that go into planning, particularly with regard to how they influence decisions about alternative formats. We aim to start a discussion about the sustainability of VIS -- including sustainability for finance, volunteers, and, central to this work, the environment -- for the next three years and the next three hundred years.","sentences":["The IEEE VIS Conference (or VIS) hosts more than 1000 people annually.","It brings together visualization researchers and practitioners from across the world to share new research and knowledge.","Behind the scenes, a team of volunteers puts together the entire conference and makes sure it runs smoothly.","Organizing involves logistics of the conference, ensuring that the attendees have an enjoyable time, allocating rooms to multiple concurrent tracks, and keeping the conference within budget.","In recent years, the COVID-19 pandemic has abruptly disrupted plans, forcing organizers to switch to virtual, hybrid, and satellite formats.","These alternatives offer many benefits: fewer costs (e.g., travel, venue, institutional), greater accessibility (who can physically travel, who can get visas, who can get child care), and a lower carbon footprint (as people do not need to fly to attend).","As many conferences begin to revert to the pre-pandemic status quo of primarily in-person conferences, we suggest that it is an opportune moment to reflect on the benefits and drawbacks of lower-carbon conference formats.","To learn more about the logistics of conference organizing, we talked to 6 senior executive-level VIS organizers.","We review some of the many considerations that go into planning, particularly with regard to how they influence decisions about alternative formats.","We aim to start a discussion about the sustainability of VIS -- including sustainability for finance, volunteers, and, central to this work, the environment -- for the next three years and the next three hundred years."],"url":"http://arxiv.org/abs/2308.15429v1"}
{"created":"2023-08-29 16:33:16","title":"Complementing Onboard Sensors with Satellite Map: A New Perspective for HD Map Construction","abstract":"High-Definition (HD) maps play a crucial role in autonomous driving systems. Recent methods have attempted to construct HD maps in real-time based on information obtained from vehicle onboard sensors. However, the performance of these methods is significantly susceptible to the environment surrounding the vehicle due to the inherent limitation of onboard sensors, such as weak capacity for long-range detection. In this study, we demonstrate that supplementing onboard sensors with satellite maps can enhance the performance of HD map construction methods, leveraging the broad coverage capability of satellite maps. For the purpose of further research, we release the satellite map tiles as a complementary dataset of nuScenes dataset. Meanwhile, we propose a hierarchical fusion module that enables better fusion of satellite maps information with existing methods. Specifically, we design an attention mask based on segmentation and distance, applying the cross-attention mechanism to fuse onboard Bird's Eye View (BEV) features and satellite features in feature-level fusion. An alignment module is introduced before concatenation in BEV-level fusion to mitigate the impact of misalignment between the two features. The experimental results on the augmented nuScenes dataset showcase the seamless integration of our module into three existing HD map construction methods. It notably enhances their performance in both HD map semantic segmentation and instance detection tasks.","sentences":["High-Definition (HD) maps play a crucial role in autonomous driving systems.","Recent methods have attempted to construct HD maps in real-time based on information obtained from vehicle onboard sensors.","However, the performance of these methods is significantly susceptible to the environment surrounding the vehicle due to the inherent limitation of onboard sensors, such as weak capacity for long-range detection.","In this study, we demonstrate that supplementing onboard sensors with satellite maps can enhance the performance of HD map construction methods, leveraging the broad coverage capability of satellite maps.","For the purpose of further research, we release the satellite map tiles as a complementary dataset of nuScenes dataset.","Meanwhile, we propose a hierarchical fusion module that enables better fusion of satellite maps information with existing methods.","Specifically, we design an attention mask based on segmentation and distance, applying the cross-attention mechanism to fuse onboard Bird's Eye View (BEV) features and satellite features in feature-level fusion.","An alignment module is introduced before concatenation in BEV-level fusion to mitigate the impact of misalignment between the two features.","The experimental results on the augmented nuScenes dataset showcase the seamless integration of our module into three existing HD map construction methods.","It notably enhances their performance in both HD map semantic segmentation and instance detection tasks."],"url":"http://arxiv.org/abs/2308.15427v1"}
{"created":"2023-08-29 16:29:06","title":"A Review of Differentiable Digital Signal Processing for Music & Speech Synthesis","abstract":"The term \"differentiable digital signal processing\" describes a family of techniques in which loss function gradients are backpropagated through digital signal processors, facilitating their integration into neural networks. This article surveys the literature on differentiable audio signal processing, focusing on its use in music & speech synthesis. We catalogue applications to tasks including music performance rendering, sound matching, and voice transformation, discussing the motivations for and implications of the use of this methodology. This is accompanied by an overview of digital signal processing operations that have been implemented differentiably. Finally, we highlight open challenges, including optimisation pathologies, robustness to real-world conditions, and design trade-offs, and discuss directions for future research.","sentences":["The term \"differentiable digital signal processing\" describes a family of techniques in which loss function gradients are backpropagated through digital signal processors, facilitating their integration into neural networks.","This article surveys the literature on differentiable audio signal processing, focusing on its use in music & speech synthesis.","We catalogue applications to tasks including music performance rendering, sound matching, and voice transformation, discussing the motivations for and implications of the use of this methodology.","This is accompanied by an overview of digital signal processing operations that have been implemented differentiably.","Finally, we highlight open challenges, including optimisation pathologies, robustness to real-world conditions, and design trade-offs, and discuss directions for future research."],"url":"http://arxiv.org/abs/2308.15422v1"}
{"created":"2023-08-29 16:24:09","title":"Characterizing Learning Curves During Language Model Pre-Training: Learning, Forgetting, and Stability","abstract":"How do language models learn to make predictions during pre-training? To study this question, we extract learning curves from five autoregressive English language model pre-training runs, for 1M tokens in context. We observe that the language models generate short repetitive phrases before learning to generate longer and more coherent text. We quantify the final surprisal, within-run variability, age of acquisition, forgettability, and cross-run variability of learning curves for individual tokens in context. More frequent tokens reach lower final surprisals, exhibit less variability within and across pre-training runs, are learned earlier, and are less likely to be \"forgotten\" during pre-training. Higher n-gram probabilities further accentuate these effects. Independent of the target token, shorter and more frequent contexts correlate with marginally more stable and quickly acquired predictions. Effects of part-of-speech are also small, although nouns tend to be acquired later and less stably than verbs, adverbs, and adjectives. Our work contributes to a better understanding of language model pre-training dynamics and informs the deployment of stable language models in practice.","sentences":["How do language models learn to make predictions during pre-training?","To study this question, we extract learning curves from five autoregressive English language model pre-training runs, for 1M tokens in context.","We observe that the language models generate short repetitive phrases before learning to generate longer and more coherent text.","We quantify the final surprisal, within-run variability, age of acquisition, forgettability, and cross-run variability of learning curves for individual tokens in context.","More frequent tokens reach lower final surprisals, exhibit less variability within and across pre-training runs, are learned earlier, and are less likely to be \"forgotten\" during pre-training.","Higher n-gram probabilities further accentuate these effects.","Independent of the target token, shorter and more frequent contexts correlate with marginally more stable and quickly acquired predictions.","Effects of part-of-speech are also small, although nouns tend to be acquired later and less stably than verbs, adverbs, and adjectives.","Our work contributes to a better understanding of language model pre-training dynamics and informs the deployment of stable language models in practice."],"url":"http://arxiv.org/abs/2308.15419v1"}
{"created":"2023-08-29 16:21:08","title":"The Parametrized Complexity of the Segment Number","abstract":"Given a straight-line drawing of a graph, a {\\em segment} is a maximal set of edges that form a line segment. Given a planar graph $G$, the {\\em segment number} of $G$ is the minimum number of segments that can be achieved by any planar straight-line drawing of $G$. The {\\em line cover number} of $G$ is the minimum number of lines that support all the edges of a planar straight-line drawing of $G$. Computing the segment number or the line cover number of a planar graph is $\\exists\\mathbb{R}$-complete and, thus, NP-hard.   We study the problem of computing the segment number from the perspective of parameterized complexity. We show that this problem is fixed-parameter tractable with respect to each of the following parameters: the vertex cover number, the segment number, and the line cover number. We also consider colored versions of the segment and the line cover number.","sentences":["Given a straight-line drawing of a graph, a {\\em segment} is a maximal set of edges that form a line segment.","Given a planar graph $G$, the {\\em segment number} of $G$ is the minimum number of segments that can be achieved by any planar straight-line drawing of $G$. The {\\em line cover number} of $G$ is the minimum number of lines that support all the edges of a planar straight-line drawing of $G$. Computing the segment number or the line cover number of a planar graph is $\\exists\\mathbb{R}$-complete","and, thus, NP-hard.   ","We study the problem of computing the segment number from the perspective of parameterized complexity.","We show that this problem is fixed-parameter tractable with respect to each of the following parameters: the vertex cover number, the segment number, and the line cover number.","We also consider colored versions of the segment and the line cover number."],"url":"http://arxiv.org/abs/2308.15416v1"}
{"created":"2023-08-29 16:13:04","title":"WrappingNet: Mesh Autoencoder via Deep Sphere Deformation","abstract":"There have been recent efforts to learn more meaningful representations via fixed length codewords from mesh data, since a mesh serves as a complete model of underlying 3D shape compared to a point cloud. However, the mesh connectivity presents new difficulties when constructing a deep learning pipeline for meshes. Previous mesh unsupervised learning approaches typically assume category-specific templates, e.g., human face/body templates. It restricts the learned latent codes to only be meaningful for objects in a specific category, so the learned latent spaces are unable to be used across different types of objects. In this work, we present WrappingNet, the first mesh autoencoder enabling general mesh unsupervised learning over heterogeneous objects. It introduces a novel base graph in the bottleneck dedicated to representing mesh connectivity, which is shown to facilitate learning a shared latent space representing object shape. The superiority of WrappingNet mesh learning is further demonstrated via improved reconstruction quality and competitive classification compared to point cloud learning, as well as latent interpolation between meshes of different categories.","sentences":["There have been recent efforts to learn more meaningful representations via fixed length codewords from mesh data, since a mesh serves as a complete model of underlying 3D shape compared to a point cloud.","However, the mesh connectivity presents new difficulties when constructing a deep learning pipeline for meshes.","Previous mesh unsupervised learning approaches typically assume category-specific templates, e.g., human face/body templates.","It restricts the learned latent codes to only be meaningful for objects in a specific category, so the learned latent spaces are unable to be used across different types of objects.","In this work, we present WrappingNet, the first mesh autoencoder enabling general mesh unsupervised learning over heterogeneous objects.","It introduces a novel base graph in the bottleneck dedicated to representing mesh connectivity, which is shown to facilitate learning a shared latent space representing object shape.","The superiority of WrappingNet mesh learning is further demonstrated via improved reconstruction quality and competitive classification compared to point cloud learning, as well as latent interpolation between meshes of different categories."],"url":"http://arxiv.org/abs/2308.15413v1"}
{"created":"2023-08-29 16:07:18","title":"Robust Long-Tailed Learning via Label-Aware Bounded CVaR","abstract":"Data in the real-world classification problems are always imbalanced or long-tailed, wherein the majority classes have the most of the samples that dominate the model training. In such setting, the naive model tends to have poor performance on the minority classes. Previously, a variety of loss modifications have been proposed to address the long-tailed leaning problem, while these methods either treat the samples in the same class indiscriminatingly or lack a theoretical guarantee. In this paper, we propose two novel approaches based on CVaR (Conditional Value at Risk) to improve the performance of long-tailed learning with a solid theoretical ground. Specifically, we firstly introduce a Label-Aware Bounded CVaR (LAB-CVaR) loss to overcome the pessimistic result of the original CVaR, and further design the optimal weight bounds for LAB-CVaR theoretically. Based on LAB-CVaR, we additionally propose a LAB-CVaR with logit adjustment (LAB-CVaR-logit) loss to stabilize the optimization process, where we also offer the theoretical support. Extensive experiments on real-world datasets with long-tailed label distributions verify the superiority of our proposed methods.","sentences":["Data in the real-world classification problems are always imbalanced or long-tailed, wherein the majority classes have the most of the samples that dominate the model training.","In such setting, the naive model tends to have poor performance on the minority classes.","Previously, a variety of loss modifications have been proposed to address the long-tailed leaning problem, while these methods either treat the samples in the same class indiscriminatingly or lack a theoretical guarantee.","In this paper, we propose two novel approaches based on CVaR (Conditional Value at Risk) to improve the performance of long-tailed learning with a solid theoretical ground.","Specifically, we firstly introduce a Label-Aware Bounded CVaR (LAB-CVaR) loss to overcome the pessimistic result of the original CVaR, and further design the optimal weight bounds for LAB-CVaR theoretically.","Based on LAB-CVaR, we additionally propose a LAB-CVaR with logit adjustment (LAB-CVaR-logit) loss to stabilize the optimization process, where we also offer the theoretical support.","Extensive experiments on real-world datasets with long-tailed label distributions verify the superiority of our proposed methods."],"url":"http://arxiv.org/abs/2308.15405v1"}
{"created":"2023-08-29 16:00:57","title":"A Near-Cubic Lower Bound for 3-Query Locally Decodable Codes from Semirandom CSP Refutation","abstract":"A code $C \\colon \\{0,1\\}^k \\to \\{0,1\\}^n$ is a $q$-locally decodable code ($q$-LDC) if one can recover any chosen bit $b_i$ of the message $b \\in \\{0,1\\}^k$ with good confidence by randomly querying the encoding $x := C(b)$ on at most $q$ coordinates. Existing constructions of $2$-LDCs achieve $n = \\exp(O(k))$, and lower bounds show that this is in fact tight. However, when $q = 3$, far less is known: the best constructions achieve $n = \\exp(k^{o(1)})$, while the best known results only show a quadratic lower bound $n \\geq \\tilde{\\Omega}(k^2)$ on the blocklength.   In this paper, we prove a near-cubic lower bound of $n \\geq \\tilde{\\Omega}(k^3)$ on the blocklength of $3$-query LDCs. This improves on the best known prior works by a polynomial factor in $k$. Our proof relies on a new connection between LDCs and refuting constraint satisfaction problems with limited randomness. Our quantitative improvement builds on the new techniques for refuting semirandom instances of CSPs developed in [GKM22, HKM23] and, in particular, relies on bounding the spectral norm of appropriate Kikuchi matrices.","sentences":["A code $C \\colon \\{0,1\\}^k \\to \\{0,1\\}^n$ is a $q$-locally decodable code ($q$-LDC) if one can recover any chosen bit $b_i$ of the message $b \\in \\{0,1\\}^k$ with good confidence by randomly querying the encoding $x := C(b)$ on at most $q$ coordinates.","Existing constructions of $2$-LDCs achieve $n = \\exp(O(k))$, and lower bounds show that this is in fact tight.","However, when $q = 3$, far less is known: the best constructions achieve $n = \\exp(k^{o(1)})$, while the best known results only show a quadratic lower bound $n \\geq \\tilde{\\Omega}(k^2)$ on the blocklength.   ","In this paper, we prove a near-cubic lower bound of $n \\geq \\tilde{\\Omega}(k^3)$ on the blocklength of $3$-query LDCs.","This improves on the best known prior works by a polynomial factor in $k$. Our proof relies on a new connection between LDCs and refuting constraint satisfaction problems with limited randomness.","Our quantitative improvement builds on the new techniques for refuting semirandom instances of CSPs developed in [GKM22, HKM23] and, in particular, relies on bounding the spectral norm of appropriate Kikuchi matrices."],"url":"http://arxiv.org/abs/2308.15403v1"}
{"created":"2023-08-29 16:00:06","title":"Bornil: An open-source sign language data crowdsourcing platform for AI enabled dialect-agnostic communication","abstract":"The absence of annotated sign language datasets has hindered the development of sign language recognition and translation technologies. In this paper, we introduce Bornil; a crowdsource-friendly, multilingual sign language data collection, annotation, and validation platform. Bornil allows users to record sign language gestures and lets annotators perform sentence and gloss-level annotation. It also allows validators to make sure of the quality of both the recorded videos and the annotations through manual validation to develop high-quality datasets for deep learning-based Automatic Sign Language Recognition. To demonstrate the system's efficacy; we collected the largest sign language dataset for Bangladeshi Sign Language dialect, perform deep learning based Sign Language Recognition modeling, and report the benchmark performance. The Bornil platform, BornilDB v1.0 Dataset, and the codebases are available on https://bornil.bengali.ai","sentences":["The absence of annotated sign language datasets has hindered the development of sign language recognition and translation technologies.","In this paper, we introduce Bornil; a crowdsource-friendly, multilingual sign language data collection, annotation, and validation platform.","Bornil allows users to record sign language gestures and lets annotators perform sentence and gloss-level annotation.","It also allows validators to make sure of the quality of both the recorded videos and the annotations through manual validation to develop high-quality datasets for deep learning-based Automatic Sign Language Recognition.","To demonstrate the system's efficacy; we collected the largest sign language dataset for Bangladeshi Sign Language dialect, perform deep learning based Sign Language Recognition modeling, and report the benchmark performance.","The Bornil platform, BornilDB v1.0 Dataset, and the codebases are available on https://bornil.bengali.ai"],"url":"http://arxiv.org/abs/2308.15402v1"}
{"created":"2023-08-29 15:59:51","title":"Sampling for Remote Estimation of an Ornstein-Uhlenbeck Process through Channel with Unknown Delay Statistics","abstract":"In this paper, we consider sampling an Ornstein-Uhlenbeck (OU) process through a channel for remote estimation. The goal is to minimize the mean square error (MSE) at the estimator under a sampling frequency constraint when the channel delay statistics is unknown. Sampling for MSE minimization is reformulated into an optimal stopping problem. By revisiting the threshold structure of the optimal stopping policy when the delay statistics is known, we propose an online sampling algorithm to learn the optimum threshold using stochastic approximation algorithm and the virtual queue method. We prove that with probability 1, the MSE of the proposed online algorithm converges to the minimum MSE that is achieved when the channel delay statistics is known. The cumulative MSE gap of our proposed algorithm compared with the minimum MSE up to the $(k+1)$-th sample grows with rate at most $\\mathcal{O}(\\ln k)$. Our proposed online algorithm can satisfy the sampling frequency constraint theoretically. Finally, simulation results are provided to demonstrate the performance of the proposed algorithm.","sentences":["In this paper, we consider sampling an Ornstein-Uhlenbeck (OU) process through a channel for remote estimation.","The goal is to minimize the mean square error (MSE) at the estimator under a sampling frequency constraint when the channel delay statistics is unknown.","Sampling for MSE minimization is reformulated into an optimal stopping problem.","By revisiting the threshold structure of the optimal stopping policy when the delay statistics is known, we propose an online sampling algorithm to learn the optimum threshold using stochastic approximation algorithm and the virtual queue method.","We prove that with probability 1, the MSE of the proposed online algorithm converges to the minimum MSE that is achieved when the channel delay statistics is known.","The cumulative MSE gap of our proposed algorithm compared with the minimum MSE up to the $(k+1)$-th sample grows with rate at most $\\mathcal{O}(\\ln k)$.","Our proposed online algorithm can satisfy the sampling frequency constraint theoretically.","Finally, simulation results are provided to demonstrate the performance of the proposed algorithm."],"url":"http://arxiv.org/abs/2308.15401v1"}
{"created":"2023-08-29 15:57:32","title":"Rethinking Machine Ethics -- Can LLMs Perform Moral Reasoning through the Lens of Moral Theories?","abstract":"Making moral judgments is an essential step toward developing ethical AI systems. Prevalent approaches are mostly implemented in a bottom-up manner, which uses a large set of annotated data to train models based on crowd-sourced opinions about morality. These approaches have been criticized for potentially overgeneralizing a limited group of annotators' moral stances and lacking explainability. In contrast, top-down approaches make moral judgments grounded in a set of principles. However, it remains conceptual due to the incapability of previous language models and the unsolved debate among moral principles. In this study, we propose a flexible framework to steer Large Language Models (LLMs) to perform moral reasoning with well-established moral theories from interdisciplinary research. The theory-guided top-down framework can incorporate various moral theories. Our experiments demonstrate the effectiveness of the proposed framework on datasets derived from moral theories. Furthermore, we show the alignment between different moral theories and existing morality datasets. Our analysis exhibits the potentials and flaws in existing resources (models and datasets) in developing explainable moral judgment-making systems.","sentences":["Making moral judgments is an essential step toward developing ethical AI systems.","Prevalent approaches are mostly implemented in a bottom-up manner, which uses a large set of annotated data to train models based on crowd-sourced opinions about morality.","These approaches have been criticized for potentially overgeneralizing a limited group of annotators' moral stances and lacking explainability.","In contrast, top-down approaches make moral judgments grounded in a set of principles.","However, it remains conceptual due to the incapability of previous language models and the unsolved debate among moral principles.","In this study, we propose a flexible framework to steer Large Language Models (LLMs) to perform moral reasoning with well-established moral theories from interdisciplinary research.","The theory-guided top-down framework can incorporate various moral theories.","Our experiments demonstrate the effectiveness of the proposed framework on datasets derived from moral theories.","Furthermore, we show the alignment between different moral theories and existing morality datasets.","Our analysis exhibits the potentials and flaws in existing resources (models and datasets) in developing explainable moral judgment-making systems."],"url":"http://arxiv.org/abs/2308.15399v1"}
{"created":"2023-08-29 15:56:38","title":"Color Aesthetics: Fuzzy based User-driven Method for Harmony and Preference Prediction","abstract":"Color is the most important intrinsic sensory feature that has a powerful impact on product sales. Color is even responsible for raising the aesthetic senses in our brains. Account for individual differences is crucial in color aesthetics. It requires user-driven mechanisms for various e-commerce applications. We propose a method for quantitative evaluation of all types of perceptual responses to color(s): distinct color preference, color harmony, and color combination preference. Preference for color schemes can be predicted by combining preferences for the basic colors and ratings of color harmony. Harmonious pallets are extracted from big data set using comparison algorithms based on fuzzy similarity and grouping. The proposed model results in useful predictions of harmony and preference of multicolored images. For example, in the context of apparel coordination, it allows predicting a preference for a look based on clothing colors. Our approach differs from standard aesthetic models, since in accounts for a personal variation. In addition, it can process not only lower-order color pairs, but also groups of several colors.","sentences":["Color is the most important intrinsic sensory feature that has a powerful impact on product sales.","Color is even responsible for raising the aesthetic senses in our brains.","Account for individual differences is crucial in color aesthetics.","It requires user-driven mechanisms for various e-commerce applications.","We propose a method for quantitative evaluation of all types of perceptual responses to color(s): distinct color preference, color harmony, and color combination preference.","Preference for color schemes can be predicted by combining preferences for the basic colors and ratings of color harmony.","Harmonious pallets are extracted from big data set using comparison algorithms based on fuzzy similarity and grouping.","The proposed model results in useful predictions of harmony and preference of multicolored images.","For example, in the context of apparel coordination, it allows predicting a preference for a look based on clothing colors.","Our approach differs from standard aesthetic models, since in accounts for a personal variation.","In addition, it can process not only lower-order color pairs, but also groups of several colors."],"url":"http://arxiv.org/abs/2308.15397v1"}
{"created":"2023-08-29 15:54:15","title":"The CausalBench challenge: A machine learning contest for gene network inference from single-cell perturbation data","abstract":"In drug discovery, mapping interactions between genes within cellular systems is a crucial early step. This helps formulate hypotheses regarding molecular mechanisms that could potentially be targeted by future medicines. The CausalBench Challenge was an initiative to invite the machine learning community to advance the state of the art in constructing gene-gene interaction networks. These networks, derived from large-scale, real-world datasets of single cells under various perturbations, are crucial for understanding the causal mechanisms underlying disease biology. Using the framework provided by the CausalBench benchmark, participants were tasked with enhancing the capacity of the state of the art methods to leverage large-scale genetic perturbation data. This report provides an analysis and summary of the methods submitted during the challenge to give a partial image of the state of the art at the time of the challenge. The winning solutions significantly improved performance compared to previous baselines, establishing a new state of the art for this critical task in biology and medicine.","sentences":["In drug discovery, mapping interactions between genes within cellular systems is a crucial early step.","This helps formulate hypotheses regarding molecular mechanisms that could potentially be targeted by future medicines.","The CausalBench Challenge was an initiative to invite the machine learning community to advance the state of the art in constructing gene-gene interaction networks.","These networks, derived from large-scale, real-world datasets of single cells under various perturbations, are crucial for understanding the causal mechanisms underlying disease biology.","Using the framework provided by the CausalBench benchmark, participants were tasked with enhancing the capacity of the state of the art methods to leverage large-scale genetic perturbation data.","This report provides an analysis and summary of the methods submitted during the challenge to give a partial image of the state of the art at the time of the challenge.","The winning solutions significantly improved performance compared to previous baselines, establishing a new state of the art for this critical task in biology and medicine."],"url":"http://arxiv.org/abs/2308.15395v1"}
{"created":"2023-08-29 15:48:49","title":"Decentralized Multi-agent Reinforcement Learning based State-of-Charge Balancing Strategy for Distributed Energy Storage System","abstract":"This paper develops a Decentralized Multi-Agent Reinforcement Learning (Dec-MARL) method to solve the SoC balancing problem in the distributed energy storage system (DESS). First, the SoC balancing problem is formulated into a finite Markov decision process with action constraints derived from demand balance, which can be solved by Dec-MARL. Specifically, the first-order average consensus algorithm is utilized to expand the observations of the DESS state in a fully-decentralized way, and the initial actions (i.e., output power) are decided by the agents (i.e., energy storage units) according to these observations. In order to get the final actions in the allowable range, a counterfactual demand balance algorithm is proposed to balance the total demand and the initial actions. Next, the agents execute the final actions and get local rewards from the environment, and the DESS steps into the next state. Finally, through the first-order average consensus algorithm, the agents get the average reward and the expended observation of the next state for later training. By the above procedure, Dec-MARL reveals outstanding performance in a fully-decentralized system without any expert experience or constructing any complicated model. Besides, it is flexible and can be extended to other decentralized multi-agent systems straightforwardly. Extensive simulations have validated the effectiveness and efficiency of Dec-MARL.","sentences":["This paper develops a Decentralized Multi-Agent Reinforcement Learning (Dec-MARL) method to solve the SoC balancing problem in the distributed energy storage system (DESS).","First, the SoC balancing problem is formulated into a finite Markov decision process with action constraints derived from demand balance, which can be solved by Dec-MARL.","Specifically, the first-order average consensus algorithm is utilized to expand the observations of the DESS state in a fully-decentralized way, and the initial actions (i.e., output power) are decided by the agents (i.e., energy storage units) according to these observations.","In order to get the final actions in the allowable range, a counterfactual demand balance algorithm is proposed to balance the total demand and the initial actions.","Next, the agents execute the final actions and get local rewards from the environment, and the DESS steps into the next state.","Finally, through the first-order average consensus algorithm, the agents get the average reward and the expended observation of the next state for later training.","By the above procedure, Dec-MARL reveals outstanding performance in a fully-decentralized system without any expert experience or constructing any complicated model.","Besides, it is flexible and can be extended to other decentralized multi-agent systems straightforwardly.","Extensive simulations have validated the effectiveness and efficiency of Dec-MARL."],"url":"http://arxiv.org/abs/2308.15394v1"}
{"created":"2023-08-29 15:33:51","title":"Bayesian Integration of Information Using Top-Down Modulated WTA Networks","abstract":"Winner Take All (WTA) circuits a type of Spiking Neural Networks (SNN) have been suggested as facilitating the brain's ability to process information in a Bayesian manner. Research has shown that WTA circuits are capable of approximating hierarchical Bayesian models via Expectation Maximization (EM). So far, research in this direction has focused on bottom up processes. This is contrary to neuroscientific evidence that shows that, besides bottom up processes, top down processes too play a key role in information processing by the human brain. Several functions ascribed to top down processes include direction of attention, adjusting for expectations, facilitation of encoding and recall of learned information, and imagery. This paper explores whether WTA circuits are suitable for further integrating information represented in separate WTA networks. Furthermore, it explores whether, and under what circumstances, top down processes can improve WTA network performance with respect to inference and learning. The results show that WTA circuits are capable of integrating the probabilistic information represented by other WTA networks, and that top down processes can improve a WTA network's inference and learning performance. Notably, it is able to do this according to key neuromorphic principles, making it ideal for low-latency and energy efficient implementation on neuromorphic hardware.","sentences":["Winner Take All (WTA) circuits a type of Spiking Neural Networks (SNN) have been suggested as facilitating the brain's ability to process information in a Bayesian manner.","Research has shown that WTA circuits are capable of approximating hierarchical Bayesian models via Expectation Maximization (EM).","So far, research in this direction has focused on bottom up processes.","This is contrary to neuroscientific evidence that shows that, besides bottom up processes, top down processes too play a key role in information processing by the human brain.","Several functions ascribed to top down processes include direction of attention, adjusting for expectations, facilitation of encoding and recall of learned information, and imagery.","This paper explores whether WTA circuits are suitable for further integrating information represented in separate WTA networks.","Furthermore, it explores whether, and under what circumstances, top down processes can improve WTA network performance with respect to inference and learning.","The results show that WTA circuits are capable of integrating the probabilistic information represented by other WTA networks, and that top down processes can improve a WTA network's inference and learning performance.","Notably, it is able to do this according to key neuromorphic principles, making it ideal for low-latency and energy efficient implementation on neuromorphic hardware."],"url":"http://arxiv.org/abs/2308.15390v1"}
{"created":"2023-08-29 15:16:51","title":"On the Robustness of Object Detection Models in Aerial Images","abstract":"The robustness of object detection models is a major concern when applied to real-world scenarios. However, the performance of most object detection models degrades when applied to images subjected to corruptions, since they are usually trained and evaluated on clean datasets. Enhancing the robustness of object detection models is of utmost importance, especially for those designed for aerial images, which feature complex backgrounds, substantial variations in scales and orientations of objects. This paper addresses the challenge of assessing the robustness of object detection models in aerial images, with a specific emphasis on scenarios where images are affected by clouds. In this study, we introduce two novel benchmarks based on DOTA-v1.0. The first benchmark encompasses 19 prevalent corruptions, while the second focuses on cloud-corrupted images-a phenomenon uncommon in natural pictures yet frequent in aerial photography. We systematically evaluate the robustness of mainstream object detection models and perform numerous ablation experiments. Through our investigations, we find that enhanced model architectures, larger networks, well-crafted modules, and judicious data augmentation strategies collectively enhance the robustness of aerial object detection models. The benchmarks we propose and our comprehensive experimental analyses can facilitate research on robust object detection in aerial images. Codes and datasets are available at: (https://github.com/hehaodong530/DOTA-C)","sentences":["The robustness of object detection models is a major concern when applied to real-world scenarios.","However, the performance of most object detection models degrades when applied to images subjected to corruptions, since they are usually trained and evaluated on clean datasets.","Enhancing the robustness of object detection models is of utmost importance, especially for those designed for aerial images, which feature complex backgrounds, substantial variations in scales and orientations of objects.","This paper addresses the challenge of assessing the robustness of object detection models in aerial images, with a specific emphasis on scenarios where images are affected by clouds.","In this study, we introduce two novel benchmarks based on DOTA-v1.0.","The first benchmark encompasses 19 prevalent corruptions, while the second focuses on cloud-corrupted images-a phenomenon uncommon in natural pictures yet frequent in aerial photography.","We systematically evaluate the robustness of mainstream object detection models and perform numerous ablation experiments.","Through our investigations, we find that enhanced model architectures, larger networks, well-crafted modules, and judicious data augmentation strategies collectively enhance the robustness of aerial object detection models.","The benchmarks we propose and our comprehensive experimental analyses can facilitate research on robust object detection in aerial images.","Codes and datasets are available at: (https://github.com/hehaodong530/DOTA-C)"],"url":"http://arxiv.org/abs/2308.15378v1"}
{"created":"2023-08-29 15:04:08","title":"RED: A Systematic Real-Time Scheduling Approach for Robotic Environmental Dynamics","abstract":"Intelligent robots are designed to effectively navigate dynamic and unpredictable environments laden with moving mechanical elements and objects. Such environment-induced dynamics, including moving obstacles, can readily alter the computational demand (e.g., the creation of new tasks) and the structure of workloads (e.g., precedence constraints among tasks) during runtime, thereby adversely affecting overall system performance. This challenge is amplified when multi-task inference is expected on robots operating under stringent resource and real-time constraints. To address such a challenge, we introduce RED, a systematic real-time scheduling approach designed to support multi-task deep neural network workloads in resource-limited robotic systems. It is designed to adaptively manage the Robotic Environmental Dynamics (RED) while adhering to real-time constraints. At the core of RED lies a deadline-based scheduler that employs an intermediate deadline assignment policy, effectively managing to change workloads and asynchronous inference prompted by complex, unpredictable environments. This scheduling framework also facilitates the flexible deployment of MIMONet (multi-input multi-output neural networks), which are commonly utilized in multi-tasking robotic systems to circumvent memory bottlenecks. Building on this scheduling framework, RED recognizes and leverages a unique characteristic of MIMONet: its weight-shared architecture. To further accommodate and exploit this feature, RED devises a novel and effective workload refinement and reconstruction process. This process ensures the scheduling framework's compatibility with MIMONet and maximizes efficiency.","sentences":["Intelligent robots are designed to effectively navigate dynamic and unpredictable environments laden with moving mechanical elements and objects.","Such environment-induced dynamics, including moving obstacles, can readily alter the computational demand (e.g., the creation of new tasks) and the structure of workloads (e.g., precedence constraints among tasks) during runtime, thereby adversely affecting overall system performance.","This challenge is amplified when multi-task inference is expected on robots operating under stringent resource and real-time constraints.","To address such a challenge, we introduce RED, a systematic real-time scheduling approach designed to support multi-task deep neural network workloads in resource-limited robotic systems.","It is designed to adaptively manage the Robotic Environmental Dynamics (RED) while adhering to real-time constraints.","At the core of RED lies a deadline-based scheduler that employs an intermediate deadline assignment policy, effectively managing to change workloads and asynchronous inference prompted by complex, unpredictable environments.","This scheduling framework also facilitates the flexible deployment of MIMONet (multi-input multi-output neural networks), which are commonly utilized in multi-tasking robotic systems to circumvent memory bottlenecks.","Building on this scheduling framework, RED recognizes and leverages a unique characteristic of MIMONet: its weight-shared architecture.","To further accommodate and exploit this feature, RED devises a novel and effective workload refinement and reconstruction process.","This process ensures the scheduling framework's compatibility with MIMONet and maximizes efficiency."],"url":"http://arxiv.org/abs/2308.15368v1"}
{"created":"2023-08-29 15:03:05","title":"Efficient Model Personalization in Federated Learning via Client-Specific Prompt Generation","abstract":"Federated learning (FL) emerges as a decentralized learning framework which trains models from multiple distributed clients without sharing their data to preserve privacy. Recently, large-scale pre-trained models (e.g., Vision Transformer) have shown a strong capability of deriving robust representations. However, the data heterogeneity among clients, the limited computation resources, and the communication bandwidth restrict the deployment of large-scale models in FL frameworks. To leverage robust representations from large-scale models while enabling efficient model personalization for heterogeneous clients, we propose a novel personalized FL framework of client-specific Prompt Generation (pFedPG), which learns to deploy a personalized prompt generator at the server for producing client-specific visual prompts that efficiently adapts frozen backbones to local data distributions. Our proposed framework jointly optimizes the stages of personalized prompt adaptation locally and personalized prompt generation globally. The former aims to train visual prompts that adapt foundation models to each client, while the latter observes local optimization directions to generate personalized prompts for all clients. Through extensive experiments on benchmark datasets, we show that our pFedPG is favorable against state-of-the-art personalized FL methods under various types of data heterogeneity, allowing computation and communication efficient model personalization.","sentences":["Federated learning (FL) emerges as a decentralized learning framework which trains models from multiple distributed clients without sharing their data to preserve privacy.","Recently, large-scale pre-trained models (e.g., Vision Transformer) have shown a strong capability of deriving robust representations.","However, the data heterogeneity among clients, the limited computation resources, and the communication bandwidth restrict the deployment of large-scale models in FL frameworks.","To leverage robust representations from large-scale models while enabling efficient model personalization for heterogeneous clients, we propose a novel personalized FL framework of client-specific Prompt Generation (pFedPG), which learns to deploy a personalized prompt generator at the server for producing client-specific visual prompts that efficiently adapts frozen backbones to local data distributions.","Our proposed framework jointly optimizes the stages of personalized prompt adaptation locally and personalized prompt generation globally.","The former aims to train visual prompts that adapt foundation models to each client, while the latter observes local optimization directions to generate personalized prompts for all clients.","Through extensive experiments on benchmark datasets, we show that our pFedPG is favorable against state-of-the-art personalized FL methods under various types of data heterogeneity, allowing computation and communication efficient model personalization."],"url":"http://arxiv.org/abs/2308.15367v1"}
{"created":"2023-08-29 15:02:53","title":"AnomalyGPT: Detecting Industrial Anomalies using Large Vision-Language Models","abstract":"Large Vision-Language Models (LVLMs) such as MiniGPT-4 and LLaVA have demonstrated the capability of understanding images and achieved remarkable performance in various visual tasks. Despite their strong abilities in recognizing common objects due to extensive training datasets, they lack specific domain knowledge and have a weaker understanding of localized details within objects, which hinders their effectiveness in the Industrial Anomaly Detection (IAD) task. On the other hand, most existing IAD methods only provide anomaly scores and necessitate the manual setting of thresholds to distinguish between normal and abnormal samples, which restricts their practical implementation. In this paper, we explore the utilization of LVLM to address the IAD problem and propose AnomalyGPT, a novel IAD approach based on LVLM. We generate training data by simulating anomalous images and producing corresponding textual descriptions for each image. We also employ an image decoder to provide fine-grained semantic and design a prompt learner to fine-tune the LVLM using prompt embeddings. Our AnomalyGPT eliminates the need for manual threshold adjustments, thus directly assesses the presence and locations of anomalies. Additionally, AnomalyGPT supports multi-turn dialogues and exhibits impressive few-shot in-context learning capabilities. With only one normal shot, AnomalyGPT achieves the state-of-the-art performance with an accuracy of 86.1%, an image-level AUC of 94.1%, and a pixel-level AUC of 95.3% on the MVTec-AD dataset. Code is available at https://github.com/CASIA-IVA-Lab/AnomalyGPT.","sentences":["Large Vision-Language Models (LVLMs) such as MiniGPT-4 and LLaVA have demonstrated the capability of understanding images and achieved remarkable performance in various visual tasks.","Despite their strong abilities in recognizing common objects due to extensive training datasets, they lack specific domain knowledge and have a weaker understanding of localized details within objects, which hinders their effectiveness in the Industrial Anomaly Detection (IAD) task.","On the other hand, most existing IAD methods only provide anomaly scores and necessitate the manual setting of thresholds to distinguish between normal and abnormal samples, which restricts their practical implementation.","In this paper, we explore the utilization of LVLM to address the IAD problem and propose AnomalyGPT, a novel IAD approach based on LVLM.","We generate training data by simulating anomalous images and producing corresponding textual descriptions for each image.","We also employ an image decoder to provide fine-grained semantic and design a prompt learner to fine-tune the LVLM using prompt embeddings.","Our AnomalyGPT eliminates the need for manual threshold adjustments, thus directly assesses the presence and locations of anomalies.","Additionally, AnomalyGPT supports multi-turn dialogues and exhibits impressive few-shot in-context learning capabilities.","With only one normal shot, AnomalyGPT achieves the state-of-the-art performance with an accuracy of 86.1%, an image-level AUC of 94.1%, and a pixel-level AUC of 95.3% on the MVTec-AD dataset.","Code is available at https://github.com/CASIA-IVA-Lab/AnomalyGPT."],"url":"http://arxiv.org/abs/2308.15366v1"}
{"created":"2023-08-29 15:01:01","title":"Heterogeneous Multi-Task Gaussian Cox Processes","abstract":"This paper presents a novel extension of multi-task Gaussian Cox processes for modeling multiple heterogeneous correlated tasks jointly, e.g., classification and regression, via multi-output Gaussian processes (MOGP). A MOGP prior over the parameters of the dedicated likelihoods for classification, regression and point process tasks can facilitate sharing of information between heterogeneous tasks, while allowing for nonparametric parameter estimation. To circumvent the non-conjugate Bayesian inference in the MOGP modulated heterogeneous multi-task framework, we employ the data augmentation technique and derive a mean-field approximation to realize closed-form iterative updates for estimating model parameters. We demonstrate the performance and inference on both 1D synthetic data as well as 2D urban data of Vancouver.","sentences":["This paper presents a novel extension of multi-task Gaussian Cox processes for modeling multiple heterogeneous correlated tasks jointly, e.g., classification and regression, via multi-output Gaussian processes (MOGP).","A MOGP prior over the parameters of the dedicated likelihoods for classification, regression and point process tasks can facilitate sharing of information between heterogeneous tasks, while allowing for nonparametric parameter estimation.","To circumvent the non-conjugate Bayesian inference in the MOGP modulated heterogeneous multi-task framework, we employ the data augmentation technique and derive a mean-field approximation to realize closed-form iterative updates for estimating model parameters.","We demonstrate the performance and inference on both 1D synthetic data as well as 2D urban data of Vancouver."],"url":"http://arxiv.org/abs/2308.15364v1"}
{"created":"2023-08-29 14:59:54","title":"Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation","abstract":"Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL task. However, the absence of a systematical benchmark inhibits the development of designing effective, efficient and economic LLM-based Text-to-SQL solutions. To address this challenge, in this paper, we first conduct a systematical and extensive comparison over existing prompt engineering methods, including question representation, example selection and example organization, and with these experimental results, we elaborates their pros and cons. Based on these findings, we propose a new integrated solution, named DAIL-SQL, which refreshes the Spider leaderboard with 86.6% execution accuracy and sets a new bar. Towards an efficient and economic LLM-based Text-to-SQL solution, we emphasize the token efficiency in prompt engineering and compare the prior studies under this metric. Additionally, we investigate open-source LLMs in in-context learning, and further enhance their performance with task-specific supervised fine-tuning. Our explorations highlight open-source LLMs' potential in Text-to-SQL, as well as the advantages and disadvantages of the task-specific supervised fine-tuning. We hope that our work provides a deeper understanding of Text-to-SQL with LLMs, and inspire further investigations and broad applications.","sentences":["Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL task.","However, the absence of a systematical benchmark inhibits the development of designing effective, efficient and economic LLM-based Text-to-SQL solutions.","To address this challenge, in this paper, we first conduct a systematical and extensive comparison over existing prompt engineering methods, including question representation, example selection and example organization, and with these experimental results, we elaborates their pros and cons.","Based on these findings, we propose a new integrated solution, named DAIL-SQL, which refreshes the Spider leaderboard with 86.6% execution accuracy and sets a new bar.","Towards an efficient and economic LLM-based Text-to-SQL solution, we emphasize the token efficiency in prompt engineering and compare the prior studies under this metric.","Additionally, we investigate open-source LLMs in in-context learning, and further enhance their performance with task-specific supervised fine-tuning.","Our explorations highlight open-source LLMs' potential in Text-to-SQL, as well as the advantages and disadvantages of the task-specific supervised fine-tuning.","We hope that our work provides a deeper understanding of Text-to-SQL with LLMs, and inspire further investigations and broad applications."],"url":"http://arxiv.org/abs/2308.15363v1"}
{"created":"2023-08-29 14:53:16","title":"Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection","abstract":"New 3+1D high-resolution radar sensors are gaining importance for 3D object detection in the automotive domain due to their relative affordability and improved detection compared to classic low-resolution radar sensors. One limitation of high-resolution radar sensors, compared to lidar sensors, is the sparsity of the generated point cloud. This sparsity could be partially overcome by accumulating radar point clouds of subsequent time steps. This contribution analyzes limitations of accumulating radar point clouds on the View-of-Delft dataset. By employing different ego-motion estimation approaches, the dataset's inherent constraints, and possible solutions are analyzed. Additionally, a learning-based instance motion estimation approach is deployed to investigate the influence of dynamic motion on the accumulated point cloud for object detection. Experiments document an improved object detection performance by applying an ego-motion estimation and dynamic motion correction approach.","sentences":["New 3+1D high-resolution radar sensors are gaining importance for 3D object detection in the automotive domain due to their relative affordability and improved detection compared to classic low-resolution radar sensors.","One limitation of high-resolution radar sensors, compared to lidar sensors, is the sparsity of the generated point cloud.","This sparsity could be partially overcome by accumulating radar point clouds of subsequent time steps.","This contribution analyzes limitations of accumulating radar point clouds on the View-of-Delft dataset.","By employing different ego-motion estimation approaches, the dataset's inherent constraints, and possible solutions are analyzed.","Additionally, a learning-based instance motion estimation approach is deployed to investigate the influence of dynamic motion on the accumulated point cloud for object detection.","Experiments document an improved object detection performance by applying an ego-motion estimation and dynamic motion correction approach."],"url":"http://arxiv.org/abs/2308.15357v1"}
{"created":"2023-08-29 14:48:29","title":"Detect, Augment, Compose, and Adapt: Four Steps for Unsupervised Domain Adaptation in Object Detection","abstract":"Unsupervised domain adaptation (UDA) plays a crucial role in object detection when adapting a source-trained detector to a target domain without annotated data. In this paper, we propose a novel and effective four-step UDA approach that leverages self-supervision and trains source and target data concurrently. We harness self-supervised learning to mitigate the lack of ground truth in the target domain. Our method consists of the following steps: (1) identify the region with the highest-confidence set of detections in each target image, which serve as our pseudo-labels; (2) crop the identified region and generate a collection of its augmented versions; (3) combine these latter into a composite image; (4) adapt the network to the target domain using the composed image. Through extensive experiments under cross-camera, cross-weather, and synthetic-to-real scenarios, our approach achieves state-of-the-art performance, improving upon the nearest competitor by more than 2% in terms of mean Average Precision (mAP). The code is available at https://github.com/MohamedTEV/DACA.","sentences":["Unsupervised domain adaptation (UDA) plays a crucial role in object detection when adapting a source-trained detector to a target domain without annotated data.","In this paper, we propose a novel and effective four-step UDA approach that leverages self-supervision and trains source and target data concurrently.","We harness self-supervised learning to mitigate the lack of ground truth in the target domain.","Our method consists of the following steps: (1) identify the region with the highest-confidence set of detections in each target image, which serve as our pseudo-labels; (2) crop the identified region and generate a collection of its augmented versions; (3) combine these latter into a composite image; (4) adapt the network to the target domain using the composed image.","Through extensive experiments under cross-camera, cross-weather, and synthetic-to-real scenarios, our approach achieves state-of-the-art performance, improving upon the nearest competitor by more than 2% in terms of mean Average Precision (mAP).","The code is available at https://github.com/MohamedTEV/DACA."],"url":"http://arxiv.org/abs/2308.15353v1"}
{"created":"2023-08-29 14:47:08","title":"Historical patterns of rice farming explain modern-day language use in China and Japan more than modernization and urbanization","abstract":"We used natural language processing to analyze a billion words to study cultural differences on Weibo, one of China's largest social media platforms. We compared predictions from two common explanations about cultural differences in China (economic development and urban-rural differences) against the less-obvious legacy of rice versus wheat farming. Rice farmers had to coordinate shared irrigation networks and exchange labor to cope with higher labor requirements. In contrast, wheat relied on rainfall and required half as much labor. We test whether this legacy made southern China more interdependent. Across all word categories, rice explained twice as much variance as economic development and urbanization. Rice areas used more words reflecting tight social ties, holistic thought, and a cautious, prevention orientation. We then used Twitter data comparing prefectures in Japan, which largely replicated the results from China. This provides crucial evidence of the rice theory in a different nation, language, and platform.","sentences":["We used natural language processing to analyze a billion words to study cultural differences on Weibo, one of China's largest social media platforms.","We compared predictions from two common explanations about cultural differences in China (economic development and urban-rural differences) against the less-obvious legacy of rice versus wheat farming.","Rice farmers had to coordinate shared irrigation networks and exchange labor to cope with higher labor requirements.","In contrast, wheat relied on rainfall and required half as much labor.","We test whether this legacy made southern China more interdependent.","Across all word categories, rice explained twice as much variance as economic development and urbanization.","Rice areas used more words reflecting tight social ties, holistic thought, and a cautious, prevention orientation.","We then used Twitter data comparing prefectures in Japan, which largely replicated the results from China.","This provides crucial evidence of the rice theory in a different nation, language, and platform."],"url":"http://arxiv.org/abs/2308.15352v1"}
{"created":"2023-08-29 14:45:23","title":"Lie-Poisson Neural Networks (LPNets): Data-Based Computing of Hamiltonian Systems with Symmetries","abstract":"An accurate data-based prediction of the long-term evolution of Hamiltonian systems requires a network that preserves the appropriate structure under each time step. Every Hamiltonian system contains two essential ingredients: the Poisson bracket and the Hamiltonian. Hamiltonian systems with symmetries, whose paradigm examples are the Lie-Poisson systems, have been shown to describe a broad category of physical phenomena, from satellite motion to underwater vehicles, fluids, geophysical applications, complex fluids, and plasma physics. The Poisson bracket in these systems comes from the symmetries, while the Hamiltonian comes from the underlying physics. We view the symmetry of the system as primary, hence the Lie-Poisson bracket is known exactly, whereas the Hamiltonian is regarded as coming from physics and is considered not known, or known approximately. Using this approach, we develop a network based on transformations that exactly preserve the Poisson bracket and the special functions of the Lie-Poisson systems (Casimirs) to machine precision. We present two flavors of such systems: one, where the parameters of transformations are computed from data using a dense neural network (LPNets), and another, where the composition of transformations is used as building blocks (G-LPNets). We also show how to adapt these methods to a larger class of Poisson brackets. We apply the resulting methods to several examples, such as rigid body (satellite) motion, underwater vehicles, a particle in a magnetic field, and others. The methods developed in this paper are important for the construction of accurate data-based methods for simulating the long-term dynamics of physical systems.","sentences":["An accurate data-based prediction of the long-term evolution of Hamiltonian systems requires a network that preserves the appropriate structure under each time step.","Every Hamiltonian system contains two essential ingredients: the Poisson bracket and the Hamiltonian.","Hamiltonian systems with symmetries, whose paradigm examples are the Lie-Poisson systems, have been shown to describe a broad category of physical phenomena, from satellite motion to underwater vehicles, fluids, geophysical applications, complex fluids, and plasma physics.","The Poisson bracket in these systems comes from the symmetries, while the Hamiltonian comes from the underlying physics.","We view the symmetry of the system as primary, hence the Lie-Poisson bracket is known exactly, whereas the Hamiltonian is regarded as coming from physics and is considered not known, or known approximately.","Using this approach, we develop a network based on transformations that exactly preserve the Poisson bracket and the special functions of the Lie-Poisson systems (Casimirs) to machine precision.","We present two flavors of such systems: one, where the parameters of transformations are computed from data using a dense neural network (LPNets), and another, where the composition of transformations is used as building blocks (G-LPNets).","We also show how to adapt these methods to a larger class of Poisson brackets.","We apply the resulting methods to several examples, such as rigid body (satellite) motion, underwater vehicles, a particle in a magnetic field, and others.","The methods developed in this paper are important for the construction of accurate data-based methods for simulating the long-term dynamics of physical systems."],"url":"http://arxiv.org/abs/2308.15349v1"}
{"created":"2023-08-29 14:42:43","title":"Masquerade: Simple and Lightweight Transaction Reordering Mitigation in Blockchains","abstract":"Blockchains offer strong security gurarantees, but cannot protect users against the ordering of transactions. Players such as miners, bots and validators can reorder various transactions and reap significant profits, called the Maximal Extractable Value (MEV). In this paper, we propose an MEV aware protocol design called Masquerade, and show that it will increase user satisfaction and confidence in the system. We propose a strict per-transaction level of ordering to ensure that a transaction is committed either way even if it is revealed. In this protocol, we introduce the notion of a \"token\" to mitigate the actions taken by an adversary in an attack scenario. Such tokens can be purchased voluntarily by users, who can then choose to include the token numbers in their transactions. If the users include the token in their transactions, then our protocol requires the block-builder to order the transactions strictly according to token numbers. We show through extensive simulations that this reduces the probability that the adversaries can benefit from MEV transactions as compared to existing current practices.","sentences":["Blockchains offer strong security gurarantees, but cannot protect users against the ordering of transactions.","Players such as miners, bots and validators can reorder various transactions and reap significant profits, called the Maximal Extractable Value (MEV).","In this paper, we propose an MEV aware protocol design called Masquerade, and show that it will increase user satisfaction and confidence in the system.","We propose a strict per-transaction level of ordering to ensure that a transaction is committed either way even if it is revealed.","In this protocol, we introduce the notion of a \"token\" to mitigate the actions taken by an adversary in an attack scenario.","Such tokens can be purchased voluntarily by users, who can then choose to include the token numbers in their transactions.","If the users include the token in their transactions, then our protocol requires the block-builder to order the transactions strictly according to token numbers.","We show through extensive simulations that this reduces the probability that the adversaries can benefit from MEV transactions as compared to existing current practices."],"url":"http://arxiv.org/abs/2308.15347v1"}
{"created":"2023-08-29 14:41:40","title":"Enhancing Mobile Face Anti-Spoofing: A Robust Framework for Diverse Attack Types under Screen Flash","abstract":"Face anti-spoofing (FAS) is crucial for securing face recognition systems. However, existing FAS methods with handcrafted binary or pixel-wise labels have limitations due to diverse presentation attacks (PAs). In this paper, we propose an attack type robust face anti-spoofing framework under light flash, called ATR-FAS. Due to imaging differences caused by various attack types, traditional FAS methods based on single binary classification network may result in excessive intra-class distance of spoof faces, leading to a challenge of decision boundary learning. Therefore, we employed multiple networks to reconstruct multi-frame depth maps as auxiliary supervision, and each network experts in one type of attack. A dual gate module (DGM) consisting of a type gate and a frame-attention gate is introduced, which perform attack type recognition and multi-frame attention generation, respectively. The outputs of DGM are utilized as weight to mix the result of multiple expert networks. The multi-experts mixture enables ATR-FAS to generate spoof-differentiated depth maps, and stably detects spoof faces without being affected by different types of PAs. Moreover, we design a differential normalization procedure to convert original flash frames into differential frames. This simple but effective processing enhances the details in flash frames, aiding in the generation of depth maps. To verify the effectiveness of our framework, we collected a large-scale dataset containing 12,660 live and spoof videos with diverse PAs under dynamic flash from the smartphone screen. Extensive experiments illustrate that the proposed ATR-FAS significantly outperforms existing state-of-the-art methods. The code and dataset will be available at https://github.com/Chaochao-Lin/ATR-FAS.","sentences":["Face anti-spoofing (FAS) is crucial for securing face recognition systems.","However, existing FAS methods with handcrafted binary or pixel-wise labels have limitations due to diverse presentation attacks (PAs).","In this paper, we propose an attack type robust face anti-spoofing framework under light flash, called ATR-FAS.","Due to imaging differences caused by various attack types, traditional FAS methods based on single binary classification network may result in excessive intra-class distance of spoof faces, leading to a challenge of decision boundary learning.","Therefore, we employed multiple networks to reconstruct multi-frame depth maps as auxiliary supervision, and each network experts in one type of attack.","A dual gate module (DGM) consisting of a type gate and a frame-attention gate is introduced, which perform attack type recognition and multi-frame attention generation, respectively.","The outputs of DGM are utilized as weight to mix the result of multiple expert networks.","The multi-experts mixture enables ATR-FAS to generate spoof-differentiated depth maps, and stably detects spoof faces without being affected by different types of PAs.","Moreover, we design a differential normalization procedure to convert original flash frames into differential frames.","This simple but effective processing enhances the details in flash frames, aiding in the generation of depth maps.","To verify the effectiveness of our framework, we collected a large-scale dataset containing 12,660 live and spoof videos with diverse PAs under dynamic flash from the smartphone screen.","Extensive experiments illustrate that the proposed ATR-FAS significantly outperforms existing state-of-the-art methods.","The code and dataset will be available at https://github.com/Chaochao-Lin/ATR-FAS."],"url":"http://arxiv.org/abs/2308.15346v1"}
{"created":"2023-08-29 14:41:10","title":"IndGIC: Supervised Action Recognition under Low Illumination","abstract":"Technologies of human action recognition in the dark are gaining more and more attention as huge demand in surveillance, motion control and human-computer interaction. However, because of limitation in image enhancement method and low-lighting video datasets, e.g. labeling cost, existing methods meet some problems. Some video-based approached are effect and efficient in specific datasets but cannot generalize to most cases while others methods using multiple sensors rely heavily to prior knowledge to deal with noisy nature from video stream. In this paper, we proposes action recognition method using deep multi-input network. Furthermore, we proposed a Independent Gamma Intensity Corretion (Ind-GIC) to enhance poor-illumination video, generating one gamma for one frame to increase enhancement performance. To prove our method is effective, there is some evaluation and comparison between our method and existing methods. Experimental results show that our model achieves high accuracy in on ARID dataset.","sentences":["Technologies of human action recognition in the dark are gaining more and more attention as huge demand in surveillance, motion control and human-computer interaction.","However, because of limitation in image enhancement method and low-lighting video datasets, e.g. labeling cost, existing methods meet some problems.","Some video-based approached are effect and efficient in specific datasets but cannot generalize to most cases while others methods using multiple sensors rely heavily to prior knowledge to deal with noisy nature from video stream.","In this paper, we proposes action recognition method using deep multi-input network.","Furthermore, we proposed a Independent Gamma Intensity Corretion (Ind-GIC) to enhance poor-illumination video, generating one gamma for one frame to increase enhancement performance.","To prove our method is effective, there is some evaluation and comparison between our method and existing methods.","Experimental results show that our model achieves high accuracy in on ARID dataset."],"url":"http://arxiv.org/abs/2308.15345v1"}
{"created":"2023-08-29 14:41:05","title":"Imperceptible Adversarial Attack on Deep Neural Networks from Image Boundary","abstract":"Although Deep Neural Networks (DNNs), such as the convolutional neural networks (CNN) and Vision Transformers (ViTs), have been successfully applied in the field of computer vision, they are demonstrated to be vulnerable to well-sought Adversarial Examples (AEs) that can easily fool the DNNs. The research in AEs has been active, and many adversarial attacks and explanations have been proposed since they were discovered in 2014. The mystery of the AE's existence is still an open question, and many studies suggest that DNN training algorithms have blind spots. The salient objects usually do not overlap with boundaries; hence, the boundaries are not the DNN model's attention. Nevertheless, recent studies show that the boundaries can dominate the behavior of the DNN models. Hence, this study aims to look at the AEs from a different perspective and proposes an imperceptible adversarial attack that systemically attacks the input image boundary for finding the AEs. The experimental results have shown that the proposed boundary attacking method effectively attacks six CNN models and the ViT using only 32% of the input image content (from the boundaries) with an average success rate (SR) of 95.2% and an average peak signal-to-noise ratio of 41.37 dB. Correlation analyses are conducted, including the relation between the adversarial boundary's width and the SR and how the adversarial boundary changes the DNN model's attention. This paper's discoveries can potentially advance the understanding of AEs and provide a different perspective on how AEs can be constructed.","sentences":["Although Deep Neural Networks (DNNs), such as the convolutional neural networks (CNN) and Vision Transformers (ViTs), have been successfully applied in the field of computer vision, they are demonstrated to be vulnerable to well-sought Adversarial Examples (AEs) that can easily fool the DNNs.","The research in AEs has been active, and many adversarial attacks and explanations have been proposed since they were discovered in 2014.","The mystery of the AE's existence is still an open question, and many studies suggest that DNN training algorithms have blind spots.","The salient objects usually do not overlap with boundaries; hence, the boundaries are not the DNN model's attention.","Nevertheless, recent studies show that the boundaries can dominate the behavior of the DNN models.","Hence, this study aims to look at the AEs from a different perspective and proposes an imperceptible adversarial attack that systemically attacks the input image boundary for finding the AEs.","The experimental results have shown that the proposed boundary attacking method effectively attacks six CNN models and the ViT using only 32% of the input image content (from the boundaries) with an average success rate (SR) of 95.2% and an average peak signal-to-noise ratio of 41.37 dB. Correlation analyses are conducted, including the relation between the adversarial boundary's width and the SR and how the adversarial boundary changes the DNN model's attention.","This paper's discoveries can potentially advance the understanding of AEs and provide a different perspective on how AEs can be constructed."],"url":"http://arxiv.org/abs/2308.15344v1"}
{"created":"2023-08-29 14:33:38","title":"AI Framework for Early Diagnosis of Coronary Artery Disease: An Integration of Borderline SMOTE, Autoencoders and Convolutional Neural Networks Approach","abstract":"The accuracy of coronary artery disease (CAD) diagnosis is dependent on a variety of factors, including demographic, symptom, and medical examination, ECG, and echocardiography data, among others. In this context, artificial intelligence (AI) can help clinicians identify high-risk patients early in the diagnostic process, by synthesizing information from multiple factors. To this aim, Machine Learning algorithms are used to classify patients based on their CAD disease risk. In this study, we contribute to this research filed by developing a methodology for balancing and augmenting data for more accurate prediction when the data is imbalanced and the sample size is small. The methodology can be used in a variety of other situations, particularly when data collection is expensive and the sample size is small. The experimental results revealed that the average accuracy of our proposed method for CAD prediction was 95.36, and was higher than random forest (RF), decision tree (DT), support vector machine (SVM), logistic regression (LR), and artificial neural network (ANN).","sentences":["The accuracy of coronary artery disease (CAD) diagnosis is dependent on a variety of factors, including demographic, symptom, and medical examination, ECG, and echocardiography data, among others.","In this context, artificial intelligence (AI) can help clinicians identify high-risk patients early in the diagnostic process, by synthesizing information from multiple factors.","To this aim, Machine Learning algorithms are used to classify patients based on their CAD disease risk.","In this study, we contribute to this research filed by developing a methodology for balancing and augmenting data for more accurate prediction when the data is imbalanced and the sample size is small.","The methodology can be used in a variety of other situations, particularly when data collection is expensive and the sample size is small.","The experimental results revealed that the average accuracy of our proposed method for CAD prediction was 95.36, and was higher than random forest (RF), decision tree (DT), support vector machine (SVM), logistic regression (LR), and artificial neural network (ANN)."],"url":"http://arxiv.org/abs/2308.15339v1"}
{"created":"2023-08-29 14:29:57","title":"A Framework for Responsible Development of Automated Student Feedback with Generative AI","abstract":"Providing rich feedback to students is essential for supporting student learning. Recent advances in generative AI, particularly within large language modelling (LLM), provide the opportunity to deliver repeatable, scalable and instant automatically generated feedback to students, making abundant a previously scarce and expensive learning resource. Such an approach is feasible from a technical perspective due to these recent advances in Artificial Intelligence (AI) and Natural Language Processing (NLP); while the potential upside is a strong motivator, doing so introduces a range of potential ethical issues that must be considered as we apply these technologies. The attractiveness of AI systems is that they can effectively automate the most mundane tasks; but this risks introducing a \"tyranny of the majority\", where the needs of minorities in the long tail are overlooked because they are difficult to automate.   Developing machine learning models that can generate valuable and authentic feedback requires the input of human domain experts. The choices we make in capturing this expertise -- whose, which, when, and how -- will have significant consequences for the nature of the resulting feedback. How we maintain our models will affect how that feedback remains relevant given temporal changes in context, theory, and prior learning profiles of student cohorts. These questions are important from an ethical perspective; but they are also important from an operational perspective. Unless they can be answered, our AI generated systems will lack the trust necessary for them to be useful features in the contemporary learning environment.   This article will outline the frontiers of automated feedback, identify the ethical issues involved in the provision of automated feedback and present a framework to assist academics to develop such systems responsibly.","sentences":["Providing rich feedback to students is essential for supporting student learning.","Recent advances in generative AI, particularly within large language modelling (LLM), provide the opportunity to deliver repeatable, scalable and instant automatically generated feedback to students, making abundant a previously scarce and expensive learning resource.","Such an approach is feasible from a technical perspective due to these recent advances in Artificial Intelligence (AI) and Natural Language Processing (NLP); while the potential upside is a strong motivator, doing so introduces a range of potential ethical issues that must be considered as we apply these technologies.","The attractiveness of AI systems is that they can effectively automate the most mundane tasks; but this risks introducing a \"tyranny of the majority\", where the needs of minorities in the long tail are overlooked because they are difficult to automate.   ","Developing machine learning models that can generate valuable and authentic feedback requires the input of human domain experts.","The choices we make in capturing this expertise -- whose, which, when, and how -- will have significant consequences for the nature of the resulting feedback.","How we maintain our models will affect how that feedback remains relevant given temporal changes in context, theory, and prior learning profiles of student cohorts.","These questions are important from an ethical perspective; but they are also important from an operational perspective.","Unless they can be answered, our AI generated systems will lack the trust necessary for them to be useful features in the contemporary learning environment.   ","This article will outline the frontiers of automated feedback, identify the ethical issues involved in the provision of automated feedback and present a framework to assist academics to develop such systems responsibly."],"url":"http://arxiv.org/abs/2308.15334v1"}
{"created":"2023-08-29 14:23:44","title":"Enhancing Robot Learning through Learned Human-Attention Feature Maps","abstract":"Robust and efficient learning remains a challenging problem in robotics, in particular with complex visual inputs. Inspired by human attention mechanism, with which we quickly process complex visual scenes and react to changes in the environment, we think that embedding auxiliary information about focus point into robot learning would enhance efficiency and robustness of the learning process. In this paper, we propose a novel approach to model and emulate the human attention with an approximate prediction model. We then leverage this output and feed it as a structured auxiliary feature map into downstream learning tasks. We validate this idea by learning a prediction model from human-gaze recordings of manual driving in the real world. We test our approach on two learning tasks - object detection and imitation learning. Our experiments demonstrate that the inclusion of predicted human attention leads to improved robustness of the trained models to out-of-distribution samples and faster learning in low-data regime settings. Our work highlights the potential of incorporating structured auxiliary information in representation learning for robotics and opens up new avenues for research in this direction. All code and data are available online.","sentences":["Robust and efficient learning remains a challenging problem in robotics, in particular with complex visual inputs.","Inspired by human attention mechanism, with which we quickly process complex visual scenes and react to changes in the environment, we think that embedding auxiliary information about focus point into robot learning would enhance efficiency and robustness of the learning process.","In this paper, we propose a novel approach to model and emulate the human attention with an approximate prediction model.","We then leverage this output and feed it as a structured auxiliary feature map into downstream learning tasks.","We validate this idea by learning a prediction model from human-gaze recordings of manual driving in the real world.","We test our approach on two learning tasks - object detection and imitation learning.","Our experiments demonstrate that the inclusion of predicted human attention leads to improved robustness of the trained models to out-of-distribution samples and faster learning in low-data regime settings.","Our work highlights the potential of incorporating structured auxiliary information in representation learning for robotics and opens up new avenues for research in this direction.","All code and data are available online."],"url":"http://arxiv.org/abs/2308.15327v1"}
{"created":"2023-08-29 14:20:17","title":"FedLogic: Interpretable Federated Multi-Domain Chain-of-Thought Prompt Selection for Large Language Models","abstract":"Leveraging ``chain-of-thought (CoT)'' reasoning to elicit rapid and precise responses from large language models (LLMs) is rapidly attracting research interest. A notable challenge here is how to design or select optimal prompts. The process of prompt selection relies on trial and error, involving continuous adjustments and combinations of input prompts by users based on the corresponding new responses generated from LLMs. Furthermore, minimal research has been conducted to explore how LLMs employ the mathematical problem-solving capabilities learned from user interactions to address issues in narrative writing. To improve interpretability and explore the balance principle between generality and personalization under a multi-domain CoT prompt selection scenario, we propose the Federated Logic rule learning approach (FedLogic). We introduce a theoretical formalization and interactive emulation of the multi-domain CoT prompt selection dilemma in the context of federated LLMs. We cast the problem of joint probability modeling as a bilevel program, where the CoT prompt selection intricacy can be likened to a fuzzy score-based rule selection with the LLMs function as rule generators. FedLogic solves this problem through variational expectation maximization (V-EM). In addition, we incorporate two KL-divergence constraints within this probabilistic modeling framework to surmount the intricacies of managing extensive search spaces and accomplishing cross-domain personalization of CoTs. To the best of our knowledge, FedLogic is the first interpretable and principled federated multi-domain CoT prompt selection approach for LLMs.","sentences":["Leveraging ``chain-of-thought (CoT)'' reasoning to elicit rapid and precise responses from large language models (LLMs) is rapidly attracting research interest.","A notable challenge here is how to design or select optimal prompts.","The process of prompt selection relies on trial and error, involving continuous adjustments and combinations of input prompts by users based on the corresponding new responses generated from LLMs.","Furthermore, minimal research has been conducted to explore how LLMs employ the mathematical problem-solving capabilities learned from user interactions to address issues in narrative writing.","To improve interpretability and explore the balance principle between generality and personalization under a multi-domain CoT prompt selection scenario, we propose the Federated Logic rule learning approach (FedLogic).","We introduce a theoretical formalization and interactive emulation of the multi-domain CoT prompt selection dilemma in the context of federated LLMs.","We cast the problem of joint probability modeling as a bilevel program, where the CoT prompt selection intricacy can be likened to a fuzzy score-based rule selection with the LLMs function as rule generators.","FedLogic solves this problem through variational expectation maximization (V-EM).","In addition, we incorporate two KL-divergence constraints within this probabilistic modeling framework to surmount the intricacies of managing extensive search spaces and accomplishing cross-domain personalization of CoTs.","To the best of our knowledge, FedLogic is the first interpretable and principled federated multi-domain CoT prompt selection approach for LLMs."],"url":"http://arxiv.org/abs/2308.15324v1"}
{"created":"2023-08-29 14:20:13","title":"Occlusion-Aware Deep Convolutional Neural Network via Homogeneous Tanh-transforms for Face Parsing","abstract":"Face parsing infers a pixel-wise label map for each semantic facial component. Previous methods generally work well for uncovered faces, however overlook the facial occlusion and ignore some contextual area outside a single face, especially when facial occlusion has become a common situation during the COVID-19 epidemic. Inspired by the illumination theory of image, we propose a novel homogeneous tanh-transforms for image preprocessing, which made up of four tanh-transforms, that fuse the central vision and the peripheral vision together. Our proposed method addresses the dilemma of face parsing under occlusion and compresses more information of surrounding context. Based on homogeneous tanh-transforms, we propose an occlusion-aware convolutional neural network for occluded face parsing. It combines the information both in Tanh-polar space and Tanh-Cartesian space, capable of enhancing receptive fields. Furthermore, we introduce an occlusion-aware loss to focus on the boundaries of occluded regions. The network is simple and flexible, and can be trained end-to-end. To facilitate future research of occluded face parsing, we also contribute a new cleaned face parsing dataset, which is manually purified from several academic or industrial datasets, including CelebAMask-HQ, Short-video Face Parsing as well as Helen dataset and will make it public. Experiments demonstrate that our method surpasses state-of-art methods of face parsing under occlusion.","sentences":["Face parsing infers a pixel-wise label map for each semantic facial component.","Previous methods generally work well for uncovered faces, however overlook the facial occlusion and ignore some contextual area outside a single face, especially when facial occlusion has become a common situation during the COVID-19 epidemic.","Inspired by the illumination theory of image, we propose a novel homogeneous tanh-transforms for image preprocessing, which made up of four tanh-transforms, that fuse the central vision and the peripheral vision together.","Our proposed method addresses the dilemma of face parsing under occlusion and compresses more information of surrounding context.","Based on homogeneous tanh-transforms, we propose an occlusion-aware convolutional neural network for occluded face parsing.","It combines the information both in Tanh-polar space and Tanh-Cartesian space, capable of enhancing receptive fields.","Furthermore, we introduce an occlusion-aware loss to focus on the boundaries of occluded regions.","The network is simple and flexible, and can be trained end-to-end.","To facilitate future research of occluded face parsing, we also contribute a new cleaned face parsing dataset, which is manually purified from several academic or industrial datasets, including CelebAMask-HQ, Short-video Face Parsing as well as Helen dataset and will make it public.","Experiments demonstrate that our method surpasses state-of-art methods of face parsing under occlusion."],"url":"http://arxiv.org/abs/2308.15323v1"}
{"created":"2023-08-29 14:16:09","title":"Elucidating the Exposure Bias in Diffusion Models","abstract":"Diffusion models have demonstrated impressive generative capabilities, but their 'exposure bias' problem, described as the input mismatch between training and sampling, lacks in-depth exploration. In this paper, we systematically investigate the exposure bias problem in diffusion models by first analytically modelling the sampling distribution, based on which we then attribute the prediction error at each sampling step as the root cause of the exposure bias issue. Furthermore, we discuss potential solutions to this issue and propose an intuitive metric for it. Along with the elucidation of exposure bias, we propose a simple, yet effective, training-free method called Epsilon Scaling to alleviate the exposure bias. We show that Epsilon Scaling explicitly moves the sampling trajectory closer to the vector field learned in the training phase by scaling down the network output (Epsilon), mitigating the input mismatch between training and sampling. Experiments on various diffusion frameworks (ADM, DDPM/DDIM, LDM), unconditional and conditional settings, and deterministic vs. stochastic sampling verify the effectiveness of our method.","sentences":["Diffusion models have demonstrated impressive generative capabilities, but their 'exposure bias' problem, described as the input mismatch between training and sampling, lacks in-depth exploration.","In this paper, we systematically investigate the exposure bias problem in diffusion models by first analytically modelling the sampling distribution, based on which we then attribute the prediction error at each sampling step as the root cause of the exposure bias issue.","Furthermore, we discuss potential solutions to this issue and propose an intuitive metric for it.","Along with the elucidation of exposure bias, we propose a simple, yet effective, training-free method called Epsilon Scaling to alleviate the exposure bias.","We show that Epsilon Scaling explicitly moves the sampling trajectory closer to the vector field learned in the training phase by scaling down the network output (Epsilon), mitigating the input mismatch between training and sampling.","Experiments on various diffusion frameworks (ADM, DDPM/DDIM, LDM), unconditional and conditional settings, and deterministic vs. stochastic sampling verify the effectiveness of our method."],"url":"http://arxiv.org/abs/2308.15321v1"}
{"created":"2023-08-29 14:04:49","title":"When Can You Tile an Integer Rectangle with Integer Squares?","abstract":"This paper characterizes when an $m \\times n$ rectangle, where $m$ and $n$ are integers, can be tiled (exactly packed) by squares where each has an integer side length of at least 2. In particular, we prove that tiling is always possible when both $m$ and $n$ are sufficiently large (at least 10). When one dimension $m$ is small, the behavior is eventually periodic in $n$ with period 1, 2, or 3. When both dimensions $m,n$ are small, the behavior is determined computationally by an exhaustive search.","sentences":["This paper characterizes when an $m \\times n$ rectangle, where $m$ and $n$ are integers, can be tiled (exactly packed) by squares where each has an integer side length of at least 2.","In particular, we prove that tiling is always possible when both $m$ and $n$ are sufficiently large (at least 10).","When one dimension $m$ is small, the behavior is eventually periodic in $n$ with period 1, 2, or 3.","When both dimensions $m,n$ are small, the behavior is determined computationally by an exhaustive search."],"url":"http://arxiv.org/abs/2308.15317v1"}
{"created":"2023-08-29 14:02:27","title":"3D-MuPPET: 3D Multi-Pigeon Pose Estimation and Tracking","abstract":"Markerless methods for animal posture tracking have been developing recently, but frameworks and benchmarks for tracking large animal groups in 3D are still lacking. To overcome this gap in the literature, we present 3D-MuPPET, a framework to estimate and track 3D poses of up to 10 pigeons at interactive speed using multiple-views. We train a pose estimator to infer 2D keypoints and bounding boxes of multiple pigeons, then triangulate the keypoints to 3D. For correspondence matching, we first dynamically match 2D detections to global identities in the first frame, then use a 2D tracker to maintain correspondences accross views in subsequent frames. We achieve comparable accuracy to a state of the art 3D pose estimator for Root Mean Square Error (RMSE) and Percentage of Correct Keypoints (PCK). We also showcase a novel use case where our model trained with data of single pigeons provides comparable results on data containing multiple pigeons. This can simplify the domain shift to new species because annotating single animal data is less labour intensive than multi-animal data. Additionally, we benchmark the inference speed of 3D-MuPPET, with up to 10 fps in 2D and 1.5 fps in 3D, and perform quantitative tracking evaluation, which yields encouraging results. Finally, we show that 3D-MuPPET also works in natural environments without model fine-tuning on additional annotations. To the best of our knowledge we are the first to present a framework for 2D/3D posture and trajectory tracking that works in both indoor and outdoor environments.","sentences":["Markerless methods for animal posture tracking have been developing recently, but frameworks and benchmarks for tracking large animal groups in 3D are still lacking.","To overcome this gap in the literature, we present 3D-MuPPET, a framework to estimate and track 3D poses of up to 10 pigeons at interactive speed using multiple-views.","We train a pose estimator to infer 2D keypoints and bounding boxes of multiple pigeons, then triangulate the keypoints to 3D. For correspondence matching, we first dynamically match 2D detections to global identities in the first frame, then use a 2D tracker to maintain correspondences accross views in subsequent frames.","We achieve comparable accuracy to a state of the art 3D pose estimator for Root Mean Square Error (RMSE) and Percentage of Correct Keypoints (PCK).","We also showcase a novel use case where our model trained with data of single pigeons provides comparable results on data containing multiple pigeons.","This can simplify the domain shift to new species because annotating single animal data is less labour intensive than multi-animal data.","Additionally, we benchmark the inference speed of 3D-MuPPET, with up to 10 fps in 2D and 1.5 fps in 3D, and perform quantitative tracking evaluation, which yields encouraging results.","Finally, we show that 3D-MuPPET also works in natural environments without model fine-tuning on additional annotations.","To the best of our knowledge we are the first to present a framework for 2D/3D posture and trajectory tracking that works in both indoor and outdoor environments."],"url":"http://arxiv.org/abs/2308.15316v1"}
{"created":"2023-08-29 14:02:17","title":"Practice of Alibaba Cloud on Elastic Resource Provisioning for Large-scale Microservices Cluster","abstract":"Cloud-native architecture is becoming increasingly crucial for today's cloud computing environments due to the need for speed and flexibility in developing applications. It utilizes microservice technology to break down traditional monolithic applications into light-weight and self-contained microservice components. However, as microservices grow in scale and have dynamic inter-dependencies, they also pose new challenges in resource provisioning that cannot be fully addressed by traditional resource scheduling approaches. The various microservices with different resource needs and latency requirements can create complex calling chains, making it difficult to provide fine-grained and accurate resource allocation to each component while maintaining the overall quality of service in the chain. In this work, we aim to address the research problem on how to efficiently provision resources for the growing scale of microservice platform and ensure the performance of latency-critical microservices. To address the problem, we present in-depth analyses of Alibaba's microservice cluster and propose optimized resource provisioning algorithms to enhance resource utilization while ensuring the latency requirement. First, we analyze the distinct features of microservices in Alibaba's cluster compared to traditional applications. Then we present Alibaba's resource capacity provisioning workflow and framework to address challenges in resource provisioning for large-scale and latency-critical microservice clusters. Finally, we propose enhanced resource provisioning algorithms over Alibaba's current practice by making both proactive and reactive scheduling decisions based on different workloads patterns, which can improve resource usage by 10-15% in Alibaba's clusters, while maintaining the necessary latency for microservices.","sentences":["Cloud-native architecture is becoming increasingly crucial for today's cloud computing environments due to the need for speed and flexibility in developing applications.","It utilizes microservice technology to break down traditional monolithic applications into light-weight and self-contained microservice components.","However, as microservices grow in scale and have dynamic inter-dependencies, they also pose new challenges in resource provisioning that cannot be fully addressed by traditional resource scheduling approaches.","The various microservices with different resource needs and latency requirements can create complex calling chains, making it difficult to provide fine-grained and accurate resource allocation to each component while maintaining the overall quality of service in the chain.","In this work, we aim to address the research problem on how to efficiently provision resources for the growing scale of microservice platform and ensure the performance of latency-critical microservices.","To address the problem, we present in-depth analyses of Alibaba's microservice cluster and propose optimized resource provisioning algorithms to enhance resource utilization while ensuring the latency requirement.","First, we analyze the distinct features of microservices in Alibaba's cluster compared to traditional applications.","Then we present Alibaba's resource capacity provisioning workflow and framework to address challenges in resource provisioning for large-scale and latency-critical microservice clusters.","Finally, we propose enhanced resource provisioning algorithms over Alibaba's current practice by making both proactive and reactive scheduling decisions based on different workloads patterns, which can improve resource usage by 10-15% in Alibaba's clusters, while maintaining the necessary latency for microservices."],"url":"http://arxiv.org/abs/2308.15315v1"}
{"created":"2023-08-29 14:00:55","title":"Spatio-temporal MLP-graph network for 3D human pose estimation","abstract":"Graph convolutional networks and their variants have shown significant promise in 3D human pose estimation. Despite their success, most of these methods only consider spatial correlations between body joints and do not take into account temporal correlations, thereby limiting their ability to capture relationships in the presence of occlusions and inherent ambiguity. To address this potential weakness, we propose a spatio-temporal network architecture composed of a joint-mixing multi-layer perceptron block that facilitates communication among different joints and a graph weighted Jacobi network block that enables communication among various feature channels. The major novelty of our approach lies in a new weighted Jacobi feature propagation rule obtained through graph filtering with implicit fairing. We leverage temporal information from the 2D pose sequences, and integrate weight modulation into the model to enable untangling of the feature transformations of distinct nodes. We also employ adjacency modulation with the aim of learning meaningful correlations beyond defined linkages between body joints by altering the graph topology through a learnable modulation matrix. Extensive experiments on two benchmark datasets demonstrate the effectiveness of our model, outperforming recent state-of-the-art methods for 3D human pose estimation.","sentences":["Graph convolutional networks and their variants have shown significant promise in 3D human pose estimation.","Despite their success, most of these methods only consider spatial correlations between body joints and do not take into account temporal correlations, thereby limiting their ability to capture relationships in the presence of occlusions and inherent ambiguity.","To address this potential weakness, we propose a spatio-temporal network architecture composed of a joint-mixing multi-layer perceptron block that facilitates communication among different joints and a graph weighted Jacobi network block that enables communication among various feature channels.","The major novelty of our approach lies in a new weighted Jacobi feature propagation rule obtained through graph filtering with implicit fairing.","We leverage temporal information from the 2D pose sequences, and integrate weight modulation into the model to enable untangling of the feature transformations of distinct nodes.","We also employ adjacency modulation with the aim of learning meaningful correlations beyond defined linkages between body joints by altering the graph topology through a learnable modulation matrix.","Extensive experiments on two benchmark datasets demonstrate the effectiveness of our model, outperforming recent state-of-the-art methods for 3D human pose estimation."],"url":"http://arxiv.org/abs/2308.15313v1"}
{"created":"2023-08-29 13:59:42","title":"Longest-chain Attacks: Difficulty Adjustment and Timestamp Verifiability","abstract":"We study an adversary who attacks a Proof-of-Work (POW) blockchain by selfishly constructing an alternative longest chain. We characterize optimal strategies employed by the adversary when a difficulty adjustment rule al\\`a Bitcoin applies. As time (namely the times-tamp specified in each block) in most permissionless POW blockchains is somewhat subjective, we focus on two extreme scenarios: when time is completely verifiable, and when it is completely unverifiable. We conclude that an adversary who faces a difficulty adjustment rule will find a longest-chain attack very challenging when timestamps are verifiable. POW blockchains with frequent difficulty adjustments relative to time reporting flexibility will be substantially more vulnerable to longest-chain attacks. Our main fining provides guidance on the design of difficulty adjustment rules and demonstrates the importance of timestamp verifiability.","sentences":["We study an adversary who attacks a Proof-of-Work (POW) blockchain by selfishly constructing an alternative longest chain.","We characterize optimal strategies employed by the adversary when a difficulty adjustment rule al\\`a Bitcoin applies.","As time (namely the times-tamp specified in each block) in most permissionless POW blockchains is somewhat subjective, we focus on two extreme scenarios: when time is completely verifiable, and when it is completely unverifiable.","We conclude that an adversary who faces a difficulty adjustment rule will find a longest-chain attack very challenging when timestamps are verifiable.","POW blockchains with frequent difficulty adjustments relative to time reporting flexibility will be substantially more vulnerable to longest-chain attacks.","Our main fining provides guidance on the design of difficulty adjustment rules and demonstrates the importance of timestamp verifiability."],"url":"http://arxiv.org/abs/2308.15312v1"}
{"created":"2023-08-29 13:53:42","title":"Understanding the Privacy Risks of Popular Search Engine Advertising Systems","abstract":"We present the first extensive measurement of the privacy properties of the advertising systems used by privacy-focused search engines. We propose an automated methodology to study the impact of clicking on search ads on three popular private search engines which have advertising-based business models: StartPage, Qwant, and DuckDuckGo, and we compare them to two dominant data-harvesting ones: Google and Bing. We investigate the possibility of third parties tracking users when clicking on ads by analyzing first-party storage, redirection domain paths, and requests sent before, when, and after the clicks. Our results show that privacy-focused search engines fail to protect users' privacy when clicking ads. Users' requests are sent through redirectors on 4% of ad clicks on Bing, 86% of ad clicks on Qwant, and 100% of ad clicks on Google, DuckDuckGo, and StartPage. Even worse, advertising systems collude with advertisers across all search engines by passing unique IDs to advertisers in most ad clicks. These IDs allow redirectors to aggregate users' activity on ads' destination websites in addition to the activity they record when users are redirected through them. Overall, we observe that both privacy-focused and traditional search engines engage in privacy-harming behaviors allowing cross-site tracking, even in privacy-enhanced browsers.","sentences":["We present the first extensive measurement of the privacy properties of the advertising systems used by privacy-focused search engines.","We propose an automated methodology to study the impact of clicking on search ads on three popular private search engines which have advertising-based business models: StartPage, Qwant, and DuckDuckGo, and we compare them to two dominant data-harvesting ones:","Google and Bing.","We investigate the possibility of third parties tracking users when clicking on ads by analyzing first-party storage, redirection domain paths, and requests sent before, when, and after the clicks.","Our results show that privacy-focused search engines fail to protect users' privacy when clicking ads.","Users' requests are sent through redirectors on 4% of ad clicks on Bing, 86% of ad clicks on Qwant, and 100% of ad clicks on Google, DuckDuckGo, and StartPage.","Even worse, advertising systems collude with advertisers across all search engines by passing unique IDs to advertisers in most ad clicks.","These IDs allow redirectors to aggregate users' activity on ads' destination websites in addition to the activity they record when users are redirected through them.","Overall, we observe that both privacy-focused and traditional search engines engage in privacy-harming behaviors allowing cross-site tracking, even in privacy-enhanced browsers."],"url":"http://arxiv.org/abs/2308.15309v1"}
{"created":"2023-08-29 13:48:35","title":"On-Device Learning with Binary Neural Networks","abstract":"Existing Continual Learning (CL) solutions only partially address the constraints on power, memory and computation of the deep learning models when deployed on low-power embedded CPUs. In this paper, we propose a CL solution that embraces the recent advancements in CL field and the efficiency of the Binary Neural Networks (BNN), that use 1-bit for weights and activations to efficiently execute deep learning models. We propose a hybrid quantization of CWR* (an effective CL approach) that considers differently forward and backward pass in order to retain more precision during gradient update step and at the same time minimizing the latency overhead. The choice of a binary network as backbone is essential to meet the constraints of low power devices and, to the best of authors' knowledge, this is the first attempt to prove on-device learning with BNN. The experimental validation carried out confirms the validity and the suitability of the proposed method.","sentences":["Existing Continual Learning (CL) solutions only partially address the constraints on power, memory and computation of the deep learning models when deployed on low-power embedded CPUs.","In this paper, we propose a CL solution that embraces the recent advancements in CL field and the efficiency of the Binary Neural Networks (BNN), that use 1-bit for weights and activations to efficiently execute deep learning models.","We propose a hybrid quantization of CWR* (an effective CL approach) that considers differently forward and backward pass in order to retain more precision during gradient update step and at the same time minimizing the latency overhead.","The choice of a binary network as backbone is essential to meet the constraints of low power devices and, to the best of authors' knowledge, this is the first attempt to prove on-device learning with BNN.","The experimental validation carried out confirms the validity and the suitability of the proposed method."],"url":"http://arxiv.org/abs/2308.15308v1"}
{"created":"2023-08-29 13:42:19","title":"Approximate Monotone Local Search for Weighted Problems","abstract":"In a recent work, Esmer et al. describe a simple method - Approximate Monotone Local Search - to obtain exponential approximation algorithms from existing parameterized exact algorithms, polynomial-time approximation algorithms and, more generally, parameterized approximation algorithms. In this work, we generalize those results to the weighted setting.   More formally, we consider monotone subset minimization problems over a weighted universe of size $n$ (e.g., Vertex Cover, $d$-Hitting Set and Feedback Vertex Set). We consider a model where the algorithm is only given access to a subroutine that finds a solution of weight at most $\\alpha \\cdot W$ (and of arbitrary cardinality) in time $c^k \\cdot n^{O(1)}$ where $W$ is the minimum weight of a solution of cardinality at most $k$. In the unweighted setting, Esmer et al. determine the smallest value $d$ for which a $\\beta$-approximation algorithm running in time $d^n \\cdot n^{O(1)}$ can be obtained in this model. We show that the same dependencies also hold in a weighted setting in this model: for every fixed $\\varepsilon>0$ we obtain a $\\beta$-approximation algorithm running in time $O\\left((d+\\varepsilon)^{n}\\right)$, for the same $d$ as in the unweighted setting.   Similarly, we also extend a $\\beta$-approximate brute-force search (in a model which only provides access to a membership oracle) to the weighted setting. Using existing approximation algorithms and exact parameterized algorithms for weighted problems, we obtain the first exponential-time $\\beta$-approximation algorithms that are better than brute force for a variety of problems including Weighted Vertex Cover, Weighted $d$-Hitting Set, Weighted Feedback Vertex Set and Weighted Multicut.","sentences":["In a recent work, Esmer et al. describe a simple method - Approximate Monotone Local Search - to obtain exponential approximation algorithms from existing parameterized exact algorithms, polynomial-time approximation algorithms and, more generally, parameterized approximation algorithms.","In this work, we generalize those results to the weighted setting.   ","More formally, we consider monotone subset minimization problems over a weighted universe of size $n$ (e.g., Vertex Cover, $d$-Hitting Set and Feedback Vertex Set).","We consider a model where the algorithm is only given access to a subroutine that finds a solution of weight at most $\\alpha \\cdot W$ (and of arbitrary cardinality) in time $c^k \\cdot n^{O(1)}$ where $W$ is the minimum weight of a solution of cardinality at most $k$. In the unweighted setting, Esmer et al. determine the smallest value $d$ for which a $\\beta$-approximation algorithm running in time $d^n \\cdot n^{O(1)}$ can be obtained in this model.","We show that the same dependencies also hold in a weighted setting in this model: for every fixed $\\varepsilon>0$ we obtain a $\\beta$-approximation algorithm running in time $O\\left((d+\\varepsilon)^{n}\\right)$, for the same $d$ as in the unweighted setting.   ","Similarly, we also extend a $\\beta$-approximate brute-force search (in a model which only provides access to a membership oracle) to the weighted setting.","Using existing approximation algorithms and exact parameterized algorithms for weighted problems, we obtain the first exponential-time $\\beta$-approximation algorithms that are better than brute force for a variety of problems including Weighted Vertex Cover, Weighted $d$-Hitting Set, Weighted Feedback Vertex Set and Weighted Multicut."],"url":"http://arxiv.org/abs/2308.15306v1"}
{"created":"2023-08-29 13:38:35","title":"MSFlow: Multi-Scale Flow-based Framework for Unsupervised Anomaly Detection","abstract":"Unsupervised anomaly detection (UAD) attracts a lot of research interest and drives widespread applications, where only anomaly-free samples are available for training. Some UAD applications intend to further locate the anomalous regions without any anomaly information.   Although the absence of anomalous samples and annotations deteriorates the UAD performance, an inconspicuous yet powerful statistics model, the normalizing flows, is appropriate for anomaly detection and localization in an unsupervised fashion. The flow-based probabilistic models, only trained on anomaly-free data, can efficiently distinguish unpredictable anomalies by assigning them much lower likelihoods than normal data.   Nevertheless, the size variation of unpredictable anomalies introduces another inconvenience to the flow-based methods for high-precision anomaly detection and localization. To generalize the anomaly size variation, we propose a novel Multi-Scale Flow-based framework dubbed MSFlow composed of asymmetrical parallel flows followed by a fusion flow to exchange multi-scale perceptions. Moreover, different multi-scale aggregation strategies are adopted for image-wise anomaly detection and pixel-wise anomaly localization according to the discrepancy between them. The proposed MSFlow is evaluated on three anomaly detection datasets, significantly outperforming existing methods. Notably, on the challenging MVTec AD benchmark, our MSFlow achieves a new state-of-the-art with a detection AUORC score of up to 99.7%, localization AUCROC score of 98.8%, and PRO score of 97.1%. The reproducible code is available at https://github.com/cool-xuan/msflow.","sentences":["Unsupervised anomaly detection (UAD) attracts a lot of research interest and drives widespread applications, where only anomaly-free samples are available for training.","Some UAD applications intend to further locate the anomalous regions without any anomaly information.   ","Although the absence of anomalous samples and annotations deteriorates the UAD performance, an inconspicuous yet powerful statistics model, the normalizing flows, is appropriate for anomaly detection and localization in an unsupervised fashion.","The flow-based probabilistic models, only trained on anomaly-free data, can efficiently distinguish unpredictable anomalies by assigning them much lower likelihoods than normal data.   ","Nevertheless, the size variation of unpredictable anomalies introduces another inconvenience to the flow-based methods for high-precision anomaly detection and localization.","To generalize the anomaly size variation, we propose a novel Multi-Scale Flow-based framework dubbed MSFlow composed of asymmetrical parallel flows followed by a fusion flow to exchange multi-scale perceptions.","Moreover, different multi-scale aggregation strategies are adopted for image-wise anomaly detection and pixel-wise anomaly localization according to the discrepancy between them.","The proposed MSFlow is evaluated on three anomaly detection datasets, significantly outperforming existing methods.","Notably, on the challenging MVTec AD benchmark, our MSFlow achieves a new state-of-the-art with a detection AUORC score of up to 99.7%, localization AUCROC score of 98.8%, and PRO score of 97.1%.","The reproducible code is available at https://github.com/cool-xuan/msflow."],"url":"http://arxiv.org/abs/2308.15300v1"}
{"created":"2023-08-29 13:36:45","title":"TaskLAMA: Probing the Complex Task Understanding of Language Models","abstract":"Structured Complex Task Decomposition (SCTD) is the problem of breaking down a complex real-world task (such as planning a wedding) into a directed acyclic graph over individual steps that contribute to achieving the task, with edges specifying temporal dependencies between them. SCTD is an important component of assistive planning tools, and a challenge for commonsense reasoning systems. We probe how accurately SCTD can be done with the knowledge extracted from Large Language Models (LLMs). We introduce a high-quality human-annotated dataset for this problem and novel metrics to fairly assess performance of LLMs against several baselines. Our experiments reveal that LLMs are able to decompose complex tasks into individual steps effectively, with a relative improvement of 15% to 280% over the best baseline. We also propose a number of approaches to further improve their performance, with a relative improvement of 7% to 37% over the base model. However, we find that LLMs still struggle to predict pairwise temporal dependencies, which reveals a gap in their understanding of complex tasks.","sentences":["Structured Complex Task Decomposition (SCTD) is the problem of breaking down a complex real-world task (such as planning a wedding) into a directed acyclic graph over individual steps that contribute to achieving the task, with edges specifying temporal dependencies between them.","SCTD is an important component of assistive planning tools, and a challenge for commonsense reasoning systems.","We probe how accurately SCTD can be done with the knowledge extracted from Large Language Models (LLMs).","We introduce a high-quality human-annotated dataset for this problem and novel metrics to fairly assess performance of LLMs against several baselines.","Our experiments reveal that LLMs are able to decompose complex tasks into individual steps effectively, with a relative improvement of 15% to 280% over the best baseline.","We also propose a number of approaches to further improve their performance, with a relative improvement of 7% to 37% over the base model.","However, we find that LLMs still struggle to predict pairwise temporal dependencies, which reveals a gap in their understanding of complex tasks."],"url":"http://arxiv.org/abs/2308.15299v1"}
{"created":"2023-08-29 13:35:51","title":"KGConv, a Conversational Corpus grounded in Wikidata","abstract":"We present KGConv, a large, conversational corpus of 71k conversations where each question-answer pair is grounded in a Wikidata fact. Conversations contain on average 8.6 questions and for each Wikidata fact, we provide multiple variants (12 on average) of the corresponding question using templates, human annotations, hand-crafted rules and a question rewriting neural model. We provide baselines for the task of Knowledge-Based, Conversational Question Generation. KGConv can further be used for other generation and analysis tasks such as single-turn question generation from Wikidata triples, question rewriting, question answering from conversation or from knowledge graphs and quiz generation.","sentences":["We present KGConv, a large, conversational corpus of 71k conversations where each question-answer pair is grounded in a Wikidata fact.","Conversations contain on average 8.6 questions and for each Wikidata fact, we provide multiple variants (12 on average) of the corresponding question using templates, human annotations, hand-crafted rules and a question rewriting neural model.","We provide baselines for the task of Knowledge-Based, Conversational Question Generation.","KGConv can further be used for other generation and analysis tasks such as single-turn question generation from Wikidata triples, question rewriting, question answering from conversation or from knowledge graphs and quiz generation."],"url":"http://arxiv.org/abs/2308.15298v1"}
{"created":"2023-08-29 13:30:48","title":"A Hybrid Membership Latent Distance Model for Unsigned and Signed Integer Weighted Networks","abstract":"Graph representation learning (GRL) has become a prominent tool for furthering the understanding of complex networks providing tools for network embedding, link prediction, and node classification. In this paper, we propose the Hybrid Membership-Latent Distance Model (HM-LDM) by exploring how a Latent Distance Model (LDM) can be constrained to a latent simplex. By controlling the edge lengths of the corners of the simplex, the volume of the latent space can be systematically controlled. Thereby communities are revealed as the space becomes more constrained, with hard memberships being recovered as the simplex volume goes to zero. We further explore a recent likelihood formulation for signed networks utilizing the Skellam distribution to account for signed weighted networks and extend the HM-LDM to the signed Hybrid Membership-Latent Distance Model (sHM-LDM). Importantly, the induced likelihood function explicitly attracts nodes with positive links and deters nodes from having negative interactions. We demonstrate the utility of HM-LDM and sHM-LDM on several real networks. We find that the procedures successfully identify prominent distinct structures, as well as how nodes relate to the extracted aspects providing favorable performances in terms of link prediction when compared to prominent baselines. Furthermore, the learned soft memberships enable easily interpretable network visualizations highlighting distinct patterns.","sentences":["Graph representation learning (GRL) has become a prominent tool for furthering the understanding of complex networks providing tools for network embedding, link prediction, and node classification.","In this paper, we propose the Hybrid Membership-Latent Distance Model (HM-LDM) by exploring how a Latent Distance Model (LDM) can be constrained to a latent simplex.","By controlling the edge lengths of the corners of the simplex, the volume of the latent space can be systematically controlled.","Thereby communities are revealed as the space becomes more constrained, with hard memberships being recovered as the simplex volume goes to zero.","We further explore a recent likelihood formulation for signed networks utilizing the Skellam distribution to account for signed weighted networks and extend the HM-LDM to the signed Hybrid Membership-Latent Distance Model (sHM-LDM).","Importantly, the induced likelihood function explicitly attracts nodes with positive links and deters nodes from having negative interactions.","We demonstrate the utility of HM-LDM and sHM-LDM on several real networks.","We find that the procedures successfully identify prominent distinct structures, as well as how nodes relate to the extracted aspects providing favorable performances in terms of link prediction when compared to prominent baselines.","Furthermore, the learned soft memberships enable easily interpretable network visualizations highlighting distinct patterns."],"url":"http://arxiv.org/abs/2308.15293v1"}
{"created":"2023-08-29 13:15:13","title":"ARTxAI: Explainable Artificial Intelligence Curates Deep Representation Learning for Artistic Images using Fuzzy Techniques","abstract":"Automatic art analysis employs different image processing techniques to classify and categorize works of art. When working with artistic images, we need to take into account further considerations compared to classical image processing. This is because such artistic paintings change drastically depending on the author, the scene depicted, and their artistic style. This can result in features that perform very well in a given task but do not grasp the whole of the visual and symbolic information contained in a painting. In this paper, we show how the features obtained from different tasks in artistic image classification are suitable to solve other ones of similar nature. We present different methods to improve the generalization capabilities and performance of artistic classification systems. Furthermore, we propose an explainable artificial intelligence method to map known visual traits of an image with the features used by the deep learning model considering fuzzy rules. These rules show the patterns and variables that are relevant to solve each task and how effective is each of the patterns found. Our results show that our proposed context-aware features can achieve up to $6\\%$ and $26\\%$ more accurate results than other context- and non-context-aware solutions, respectively, depending on the specific task. We also show that some of the features used by these models can be more clearly correlated to visual traits in the original image than others.","sentences":["Automatic art analysis employs different image processing techniques to classify and categorize works of art.","When working with artistic images, we need to take into account further considerations compared to classical image processing.","This is because such artistic paintings change drastically depending on the author, the scene depicted, and their artistic style.","This can result in features that perform very well in a given task but do not grasp the whole of the visual and symbolic information contained in a painting.","In this paper, we show how the features obtained from different tasks in artistic image classification are suitable to solve other ones of similar nature.","We present different methods to improve the generalization capabilities and performance of artistic classification systems.","Furthermore, we propose an explainable artificial intelligence method to map known visual traits of an image with the features used by the deep learning model considering fuzzy rules.","These rules show the patterns and variables that are relevant to solve each task and how effective is each of the patterns found.","Our results show that our proposed context-aware features can achieve up to $6\\%$ and $26\\%$ more accurate results than other context- and non-context-aware solutions, respectively, depending on the specific task.","We also show that some of the features used by these models can be more clearly correlated to visual traits in the original image than others."],"url":"http://arxiv.org/abs/2308.15284v1"}
{"created":"2023-08-29 13:14:53","title":"Structural Node Embeddings with Homomorphism Counts","abstract":"Graph homomorphism counts, first explored by Lov\\'asz in 1967, have recently garnered interest as a powerful tool in graph-based machine learning. Grohe (PODS 2020) proposed the theoretical foundations for using homomorphism counts in machine learning on graph level as well as node level tasks. By their very nature, these capture local structural information, which enables the creation of robust structural embeddings. While a first approach for graph level tasks has been made by Nguyen and Maehara (ICML 2020), we experimentally show the effectiveness of homomorphism count based node embeddings. Enriched with node labels, node weights, and edge weights, these offer an interpretable representation of graph data, allowing for enhanced explainability of machine learning models.   We propose a theoretical framework for isomorphism-invariant homomorphism count based embeddings which lend themselves to a wide variety of downstream tasks. Our approach capitalises on the efficient computability of graph homomorphism counts for bounded treewidth graph classes, rendering it a practical solution for real-world applications. We demonstrate their expressivity through experiments on benchmark datasets. Although our results do not match the accuracy of state-of-the-art neural architectures, they are comparable to other advanced graph learning models. Remarkably, our approach demarcates itself by ensuring explainability for each individual feature. By integrating interpretable machine learning algorithms like SVMs or Random Forests, we establish a seamless, end-to-end explainable pipeline. Our study contributes to the advancement of graph-based techniques that offer both performance and interpretability.","sentences":["Graph homomorphism counts, first explored by Lov\\'asz in 1967, have recently garnered interest as a powerful tool in graph-based machine learning.","Grohe (PODS 2020) proposed the theoretical foundations for using homomorphism counts in machine learning on graph level as well as node level tasks.","By their very nature, these capture local structural information, which enables the creation of robust structural embeddings.","While a first approach for graph level tasks has been made by Nguyen and Maehara (ICML 2020), we experimentally show the effectiveness of homomorphism count based node embeddings.","Enriched with node labels, node weights, and edge weights, these offer an interpretable representation of graph data, allowing for enhanced explainability of machine learning models.   ","We propose a theoretical framework for isomorphism-invariant homomorphism count based embeddings which lend themselves to a wide variety of downstream tasks.","Our approach capitalises on the efficient computability of graph homomorphism counts for bounded treewidth graph classes, rendering it a practical solution for real-world applications.","We demonstrate their expressivity through experiments on benchmark datasets.","Although our results do not match the accuracy of state-of-the-art neural architectures, they are comparable to other advanced graph learning models.","Remarkably, our approach demarcates itself by ensuring explainability for each individual feature.","By integrating interpretable machine learning algorithms like SVMs or Random Forests, we establish a seamless, end-to-end explainable pipeline.","Our study contributes to the advancement of graph-based techniques that offer both performance and interpretability."],"url":"http://arxiv.org/abs/2308.15283v1"}
{"created":"2023-08-29 13:12:23","title":"Back to the Future: From Microservice to Monolith","abstract":"Recently the trend of companies switching from microservice back to monolith has increased, leading to intense debate in the industry. We conduct a multivocal literature review, to investigate reasons for the phenomenon and key aspects to pay attention to during the switching back and analyze the opinions of other practitioners. The results pave the way for further research and provide guidance for industrial companies switching from microservice back to monolith.","sentences":["Recently the trend of companies switching from microservice back to monolith has increased, leading to intense debate in the industry.","We conduct a multivocal literature review, to investigate reasons for the phenomenon and key aspects to pay attention to during the switching back and analyze the opinions of other practitioners.","The results pave the way for further research and provide guidance for industrial companies switching from microservice back to monolith."],"url":"http://arxiv.org/abs/2308.15281v1"}
{"created":"2023-08-29 13:10:53","title":"ADFA: Attention-augmented Differentiable top-k Feature Adaptation for Unsupervised Medical Anomaly Detection","abstract":"The scarcity of annotated data, particularly for rare diseases, limits the variability of training data and the range of detectable lesions, presenting a significant challenge for supervised anomaly detection in medical imaging. To solve this problem, we propose a novel unsupervised method for medical image anomaly detection: Attention-Augmented Differentiable top-k Feature Adaptation (ADFA). The method utilizes Wide-ResNet50-2 (WR50) network pre-trained on ImageNet to extract initial feature representations. To reduce the channel dimensionality while preserving relevant channel information, we employ an attention-augmented patch descriptor on the extracted features. We then apply differentiable top-k feature adaptation to train the patch descriptor, mapping the extracted feature representations to a new vector space, enabling effective detection of anomalies. Experiments show that ADFA outperforms state-of-the-art (SOTA) methods on multiple challenging medical image datasets, confirming its effectiveness in medical anomaly detection.","sentences":["The scarcity of annotated data, particularly for rare diseases, limits the variability of training data and the range of detectable lesions, presenting a significant challenge for supervised anomaly detection in medical imaging.","To solve this problem, we propose a novel unsupervised method for medical image anomaly detection: Attention-Augmented Differentiable top-k Feature Adaptation (ADFA).","The method utilizes Wide-ResNet50-2 (WR50) network pre-trained on ImageNet to extract initial feature representations.","To reduce the channel dimensionality while preserving relevant channel information, we employ an attention-augmented patch descriptor on the extracted features.","We then apply differentiable top-k feature adaptation to train the patch descriptor, mapping the extracted feature representations to a new vector space, enabling effective detection of anomalies.","Experiments show that ADFA outperforms state-of-the-art (SOTA) methods on multiple challenging medical image datasets, confirming its effectiveness in medical anomaly detection."],"url":"http://arxiv.org/abs/2308.15280v1"}
