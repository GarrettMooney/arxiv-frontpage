{"created":"2023-11-15 18:59:56","title":"Single-Image 3D Human Digitization with Shape-Guided Diffusion","abstract":"We present an approach to generate a 360-degree view of a person with a consistent, high-resolution appearance from a single input image. NeRF and its variants typically require videos or images from different viewpoints. Most existing approaches taking monocular input either rely on ground-truth 3D scans for supervision or lack 3D consistency. While recent 3D generative models show promise of 3D consistent human digitization, these approaches do not generalize well to diverse clothing appearances, and the results lack photorealism. Unlike existing work, we utilize high-capacity 2D diffusion models pretrained for general image synthesis tasks as an appearance prior of clothed humans. To achieve better 3D consistency while retaining the input identity, we progressively synthesize multiple views of the human in the input image by inpainting missing regions with shape-guided diffusion conditioned on silhouette and surface normal. We then fuse these synthesized multi-view images via inverse rendering to obtain a fully textured high-resolution 3D mesh of the given person. Experiments show that our approach outperforms prior methods and achieves photorealistic 360-degree synthesis of a wide range of clothed humans with complex textures from a single image.","sentences":["We present an approach to generate a 360-degree view of a person with a consistent, high-resolution appearance from a single input image.","NeRF and its variants typically require videos or images from different viewpoints.","Most existing approaches taking monocular input either rely on ground-truth 3D scans for supervision or lack 3D consistency.","While recent 3D generative models show promise of 3D consistent human digitization, these approaches do not generalize well to diverse clothing appearances, and the results lack photorealism.","Unlike existing work, we utilize high-capacity 2D diffusion models pretrained for general image synthesis tasks as an appearance prior of clothed humans.","To achieve better 3D consistency while retaining the input identity, we progressively synthesize multiple views of the human in the input image by inpainting missing regions with shape-guided diffusion conditioned on silhouette and surface normal.","We then fuse these synthesized multi-view images via inverse rendering to obtain a fully textured high-resolution 3D mesh of the given person.","Experiments show that our approach outperforms prior methods and achieves photorealistic 360-degree synthesis of a wide range of clothed humans with complex textures from a single image."],"url":"http://arxiv.org/abs/2311.09221v1"}
{"created":"2023-11-15 18:58:41","title":"DMV3D: Denoising Multi-View Diffusion using 3D Large Reconstruction Model","abstract":"We propose \\textbf{DMV3D}, a novel 3D generation approach that uses a transformer-based 3D large reconstruction model to denoise multi-view diffusion. Our reconstruction model incorporates a triplane NeRF representation and can denoise noisy multi-view images via NeRF reconstruction and rendering, achieving single-stage 3D generation in $\\sim$30s on single A100 GPU. We train \\textbf{DMV3D} on large-scale multi-view image datasets of highly diverse objects using only image reconstruction losses, without accessing 3D assets. We demonstrate state-of-the-art results for the single-image reconstruction problem where probabilistic modeling of unseen object parts is required for generating diverse reconstructions with sharp textures. We also show high-quality text-to-3D generation results outperforming previous 3D diffusion models. Our project website is at: https://justimyhxu.github.io/projects/dmv3d/ .","sentences":["We propose \\textbf{DMV3D}, a novel 3D generation approach that uses a transformer-based 3D large reconstruction model to denoise multi-view diffusion.","Our reconstruction model incorporates a triplane NeRF representation and can denoise noisy multi-view images via NeRF reconstruction and rendering, achieving single-stage 3D generation in $\\sim$30s on single A100 GPU.","We train \\textbf{DMV3D} on large-scale multi-view image datasets of highly diverse objects using only image reconstruction losses, without accessing 3D assets.","We demonstrate state-of-the-art results for the single-image reconstruction problem where probabilistic modeling of unseen object parts is required for generating diverse reconstructions with sharp textures.","We also show high-quality text-to-3D generation results outperforming previous 3D diffusion models.","Our project website is at: https://justimyhxu.github.io/projects/dmv3d/ ."],"url":"http://arxiv.org/abs/2311.09217v1"}
{"created":"2023-11-15 18:58:19","title":"Assessing Translation capabilities of Large Language Models involving English and Indian Languages","abstract":"Generative Large Language Models (LLMs) have achieved remarkable advancements in various NLP tasks. In this work, our aim is to explore the multilingual capabilities of large language models by using machine translation as a task involving English and 22 Indian languages. We first investigate the translation capabilities of raw large language models, followed by exploring the in-context learning capabilities of the same raw models. We fine-tune these large language models using parameter efficient fine-tuning methods such as LoRA and additionally with full fine-tuning. Through our study, we have identified the best performing large language model for the translation task involving LLMs, which is based on LLaMA.   Our results demonstrate significant progress, with average BLEU scores of 13.42, 15.93, 12.13, 12.30, and 12.07, as well as CHRF scores of 43.98, 46.99, 42.55, 42.42, and 45.39, respectively, using 2-stage fine-tuned LLaMA-13b for English to Indian languages on IN22 (conversational), IN22 (general), flores200-dev, flores200-devtest, and newstest2019 testsets. Similarly, for Indian languages to English, we achieved average BLEU scores of 14.03, 16.65, 16.17, 15.35 and 12.55 along with chrF scores of 36.71, 40.44, 40.26, 39.51, and 36.20, respectively, using fine-tuned LLaMA-13b on IN22 (conversational), IN22 (general), flores200-dev, flores200-devtest, and newstest2019 testsets. Overall, our findings highlight the potential and strength of large language models for machine translation capabilities, including for languages that are currently underrepresented in LLMs.","sentences":["Generative Large Language Models (LLMs) have achieved remarkable advancements in various NLP tasks.","In this work, our aim is to explore the multilingual capabilities of large language models by using machine translation as a task involving English and 22 Indian languages.","We first investigate the translation capabilities of raw large language models, followed by exploring the in-context learning capabilities of the same raw models.","We fine-tune these large language models using parameter efficient fine-tuning methods such as LoRA and additionally with full fine-tuning.","Through our study, we have identified the best performing large language model for the translation task involving LLMs, which is based on LLaMA.   ","Our results demonstrate significant progress, with average BLEU scores of 13.42, 15.93, 12.13, 12.30, and 12.07, as well as CHRF scores of 43.98, 46.99, 42.55, 42.42, and 45.39, respectively, using 2-stage fine-tuned LLaMA-13b for English to Indian languages on IN22 (conversational), IN22 (general), flores200-dev, flores200-devtest, and newstest2019 testsets.","Similarly, for Indian languages to English, we achieved average BLEU scores of 14.03, 16.65, 16.17, 15.35 and 12.55 along with chrF scores of 36.71, 40.44, 40.26, 39.51, and 36.20, respectively, using fine-tuned LLaMA-13b on IN22 (conversational), IN22 (general), flores200-dev, flores200-devtest, and newstest2019 testsets.","Overall, our findings highlight the potential and strength of large language models for machine translation capabilities, including for languages that are currently underrepresented in LLMs."],"url":"http://arxiv.org/abs/2311.09216v1"}
{"created":"2023-11-15 18:56:51","title":"ConvNet vs Transformer, Supervised vs CLIP: Beyond ImageNet Accuracy","abstract":"Modern computer vision offers a great variety of models to practitioners, and selecting a model from multiple options for specific applications can be challenging. Conventionally, competing model architectures and training protocols are compared by their classification accuracy on ImageNet. However, this single metric does not fully capture performance nuances critical for specialized tasks. In this work, we conduct an in-depth comparative analysis of model behaviors beyond ImageNet accuracy, for both ConvNet and Vision Transformer architectures, each across supervised and CLIP training paradigms. Although our selected models have similar ImageNet accuracies and compute requirements, we find that they differ in many other aspects: types of mistakes, output calibration, transferability, and feature invariance, among others. This diversity in model characteristics, not captured by traditional metrics, highlights the need for more nuanced analysis when choosing among different models. Our code is available at https://github.com/kirill-vish/Beyond-INet.","sentences":["Modern computer vision offers a great variety of models to practitioners, and selecting a model from multiple options for specific applications can be challenging.","Conventionally, competing model architectures and training protocols are compared by their classification accuracy on ImageNet.","However, this single metric does not fully capture performance nuances critical for specialized tasks.","In this work, we conduct an in-depth comparative analysis of model behaviors beyond ImageNet accuracy, for both ConvNet and Vision Transformer architectures, each across supervised and CLIP training paradigms.","Although our selected models have similar ImageNet accuracies and compute requirements, we find that they differ in many other aspects: types of mistakes, output calibration, transferability, and feature invariance, among others.","This diversity in model characteristics, not captured by traditional metrics, highlights the need for more nuanced analysis when choosing among different models.","Our code is available at https://github.com/kirill-vish/Beyond-INet."],"url":"http://arxiv.org/abs/2311.09215v1"}
{"created":"2023-11-15 18:56:23","title":"Mind's Mirror: Distilling Self-Evaluation Capability and Comprehensive Thinking from Large Language Models","abstract":"Large language models (LLMs) have achieved remarkable advancements in the field of natural language processing. However, the sheer scale and computational demands of these models present formidable challenges when considering their practical deployment in resource-constrained contexts. While techniques such as chain-of-thought (CoT) distillation have displayed promise in distilling LLMs into small language models (SLMs), there is a risk that distilled SLMs may still carry over flawed reasoning or hallucinations inherited from their LLM counterparts. To address these issues, we propose a twofold methodology: First, we introduce a novel method for distilling the self-evaluation capability inherent in LLMs into SLMs, which aims to mitigate the adverse effects of erroneous reasoning and reduce hallucinations. Second, we advocate for a comprehensive distillation process that incorporates multiple distinct chain-of-thought and self-evaluation paradigms and ensures a more holistic and robust knowledge transfer into SLMs. Experiments on three NLP benchmarks demonstrate that our method significantly improves the performance of distilled SLMs and sheds light on the path towards developing smaller models closely aligned with human cognition.","sentences":["Large language models (LLMs) have achieved remarkable advancements in the field of natural language processing.","However, the sheer scale and computational demands of these models present formidable challenges when considering their practical deployment in resource-constrained contexts.","While techniques such as chain-of-thought (CoT) distillation have displayed promise in distilling LLMs into small language models (SLMs), there is a risk that distilled SLMs may still carry over flawed reasoning or hallucinations inherited from their LLM counterparts.","To address these issues, we propose a twofold methodology:","First, we introduce a novel method for distilling the self-evaluation capability inherent in LLMs into SLMs, which aims to mitigate the adverse effects of erroneous reasoning and reduce hallucinations.","Second, we advocate for a comprehensive distillation process that incorporates multiple distinct chain-of-thought and self-evaluation paradigms and ensures a more holistic and robust knowledge transfer into SLMs.","Experiments on three NLP benchmarks demonstrate that our method significantly improves the performance of distilled SLMs and sheds light on the path towards developing smaller models closely aligned with human cognition."],"url":"http://arxiv.org/abs/2311.09214v1"}
{"created":"2023-11-15 18:55:45","title":"GRIM: GRaph-based Interactive narrative visualization for gaMes","abstract":"Dialogue-based Role Playing Games (RPGs) require powerful storytelling. The narratives of these may take years to write and typically involve a large creative team. In this work, we demonstrate the potential of large generative text models to assist this process. \\textbf{GRIM}, a prototype \\textbf{GR}aph-based \\textbf{I}nteractive narrative visualization system for ga\\textbf{M}es, generates a rich narrative graph with branching storylines that match a high-level narrative description and constraints provided by the designer. Game designers can interactively edit the graph by automatically generating new sub-graphs that fit the edits within the original narrative and constraints. We illustrate the use of \\textbf{GRIM} in conjunction with GPT-4, generating branching narratives for four well-known stories with different contextual constraints.","sentences":["Dialogue-based Role Playing Games (RPGs) require powerful storytelling.","The narratives of these may take years to write and typically involve a large creative team.","In this work, we demonstrate the potential of large generative text models to assist this process.","\\textbf{GRIM}, a prototype \\textbf{GR}aph-based \\textbf{I}nteractive narrative visualization system for ga\\textbf{M}es, generates a rich narrative graph with branching storylines that match a high-level narrative description and constraints provided by the designer.","Game designers can interactively edit the graph by automatically generating new sub-graphs that fit the edits within the original narrative and constraints.","We illustrate the use of \\textbf{GRIM} in conjunction with GPT-4, generating branching narratives for four well-known stories with different contextual constraints."],"url":"http://arxiv.org/abs/2311.09213v1"}
{"created":"2023-11-15 18:55:43","title":"Controllable Text Summarization: Unraveling Challenges, Approaches, and Prospects -- A Survey","abstract":"Generic text summarization approaches often fail to address the specific intent and needs of individual users. Recently, scholarly attention has turned to the development of summarization methods that are more closely tailored and controlled to align with specific objectives and user needs. While a growing corpus of research is devoted towards a more controllable summarization, there is no comprehensive survey available that thoroughly explores the diverse controllable aspects or attributes employed in this context, delves into the associated challenges, and investigates the existing solutions. In this survey, we formalize the Controllable Text Summarization (CTS) task, categorize controllable aspects according to their shared characteristics and objectives, and present a thorough examination of existing methods and datasets within each category. Moreover, based on our findings, we uncover limitations and research gaps, while also delving into potential solutions and future directions for CTS.","sentences":["Generic text summarization approaches often fail to address the specific intent and needs of individual users.","Recently, scholarly attention has turned to the development of summarization methods that are more closely tailored and controlled to align with specific objectives and user needs.","While a growing corpus of research is devoted towards a more controllable summarization, there is no comprehensive survey available that thoroughly explores the diverse controllable aspects or attributes employed in this context, delves into the associated challenges, and investigates the existing solutions.","In this survey, we formalize the Controllable Text Summarization (CTS) task, categorize controllable aspects according to their shared characteristics and objectives, and present a thorough examination of existing methods and datasets within each category.","Moreover, based on our findings, we uncover limitations and research gaps, while also delving into potential solutions and future directions for CTS."],"url":"http://arxiv.org/abs/2311.09212v1"}
{"created":"2023-11-15 18:55:14","title":"Digitally reproducing the artistic style of XVI century artist Antonio Campelo in Alegoria Prudencia","abstract":"In this work, the artistic style of the sixteenth century Portuguese artist Ant\\'onio Campelo in Alegoria \\`a Prud\\^encia is analyzed in order to create a computational tool that allows one to transform any 3D digital sculpture model into an image that resembles the modeled style. From this analysis the problem is divided into two parts: detection and drawing of contour lines and the shading of the scene. Several techniques from Non Photorealistic Rendering (NPR) and from Photorealistic Rendering that can resolve the problem are presented and, based on this study, a possible solution is presented. Each modeled rendering component is then analyzed using image based methods against the proposed artistic style and parameters are adjusted for a closer match. In the final stage a group of people was asked to answer a questionnaire where the similarity between the renderings of different objects and the original style was classified according to their personal opinion. One of our findings is that although the source 3D objects cannot be readily found for a direct comparison, nor can the paper medium with centuries old damage be the same, the comparison of sub -parts of both images of the same topology was still possible validating our method and discarding other styles from the comparison.","sentences":["In this work, the artistic style of the sixteenth century Portuguese artist Ant\\'onio Campelo in Alegoria \\`a Prud\\^encia is analyzed in order to create a computational tool that allows one to transform any 3D digital sculpture model into an image that resembles the modeled style.","From this analysis the problem is divided into two parts: detection and drawing of contour lines and the shading of the scene.","Several techniques from Non Photorealistic Rendering (NPR) and from Photorealistic Rendering that can resolve the problem are presented and, based on this study, a possible solution is presented.","Each modeled rendering component is then analyzed using image based methods against the proposed artistic style and parameters are adjusted for a closer match.","In the final stage a group of people was asked to answer a questionnaire where the similarity between the renderings of different objects and the original style was classified according to their personal opinion.","One of our findings is that although the source 3D objects cannot be readily found for a direct comparison, nor can the paper medium with centuries old damage be the same, the comparison of sub -parts of both images of the same topology was still possible validating our method and discarding other styles from the comparison."],"url":"http://arxiv.org/abs/2311.09211v1"}
{"created":"2023-11-15 18:54:53","title":"Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models","abstract":"Retrieval-augmented language models (RALMs) represent a substantial advancement in the capabilities of large language models, notably in reducing factual hallucination by leveraging external knowledge sources. However, the reliability of the retrieved information is not always guaranteed. The retrieval of irrelevant data can lead to misguided responses, and potentially causing the model to overlook its inherent knowledge, even when it possesses adequate information to address the query. Moreover, standard RALMs often struggle to assess whether they possess adequate knowledge, both intrinsic and retrieved, to provide an accurate answer. In situations where knowledge is lacking, these systems should ideally respond with \"unknown\" when the answer is unattainable. In response to these challenges, we introduces Chain-of-Noting (CoN), a novel approach aimed at improving the robustness of RALMs in facing noisy, irrelevant documents and in handling unknown scenarios. The core idea of CoN is to generate sequential reading notes for retrieved documents, enabling a thorough evaluation of their relevance to the given question and integrating this information to formulate the final answer. We employed ChatGPT to create training data for CoN, which was subsequently trained on an LLaMa-2 7B model. Our experiments across four open-domain QA benchmarks show that RALMs equipped with CoN significantly outperform standard RALMs. Notably, CoN achieves an average improvement of +7.9 in EM score given entirely noisy retrieved documents and +10.5 in rejection rates for real-time questions that fall outside the pre-training knowledge scope.","sentences":["Retrieval-augmented language models (RALMs) represent a substantial advancement in the capabilities of large language models, notably in reducing factual hallucination by leveraging external knowledge sources.","However, the reliability of the retrieved information is not always guaranteed.","The retrieval of irrelevant data can lead to misguided responses, and potentially causing the model to overlook its inherent knowledge, even when it possesses adequate information to address the query.","Moreover, standard RALMs often struggle to assess whether they possess adequate knowledge, both intrinsic and retrieved, to provide an accurate answer.","In situations where knowledge is lacking, these systems should ideally respond with \"unknown\" when the answer is unattainable.","In response to these challenges, we introduces Chain-of-Noting (CoN), a novel approach aimed at improving the robustness of RALMs in facing noisy, irrelevant documents and in handling unknown scenarios.","The core idea of CoN is to generate sequential reading notes for retrieved documents, enabling a thorough evaluation of their relevance to the given question and integrating this information to formulate the final answer.","We employed ChatGPT to create training data for CoN, which was subsequently trained on an LLaMa-2 7B model.","Our experiments across four open-domain QA benchmarks show that RALMs equipped with CoN significantly outperform standard RALMs.","Notably, CoN achieves an average improvement of +7.9 in EM score given entirely noisy retrieved documents and +10.5 in rejection rates for real-time questions that fall outside the pre-training knowledge scope."],"url":"http://arxiv.org/abs/2311.09210v1"}
{"created":"2023-11-15 18:47:52","title":"TableLlama: Towards Open Large Generalist Models for Tables","abstract":"Semi-structured tables are ubiquitous. There has been a variety of tasks that aim to automatically interpret, augment, and query tables. Current methods often require pretraining on tables or special model architecture design, are restricted to specific table types, or have simplifying assumptions about tables and tasks. This paper makes the first step towards developing open-source large language models (LLMs) as generalists for a diversity of table-based tasks. Towards that end, we construct TableInstruct, a new dataset with a variety of realistic tables and tasks, for instruction tuning and evaluating LLMs. We further develop the first open-source generalist model for tables, TableLlama, by fine-tuning Llama 2 (7B) with LongLoRA to address the long context challenge. We experiment under both in-domain setting and out-of-domain setting. On 7 out of 8 in-domain tasks, TableLlama achieves comparable or better performance than the SOTA for each task, despite the latter often has task-specific design. On 6 out-of-domain datasets, it achieves 6-48 absolute point gains compared with the base model, showing that training on TableInstruct enhances the model's generalizability. We will open-source our dataset and trained model to boost future work on developing open generalist models for tables.","sentences":["Semi-structured tables are ubiquitous.","There has been a variety of tasks that aim to automatically interpret, augment, and query tables.","Current methods often require pretraining on tables or special model architecture design, are restricted to specific table types, or have simplifying assumptions about tables and tasks.","This paper makes the first step towards developing open-source large language models (LLMs) as generalists for a diversity of table-based tasks.","Towards that end, we construct TableInstruct, a new dataset with a variety of realistic tables and tasks, for instruction tuning and evaluating LLMs.","We further develop the first open-source generalist model for tables, TableLlama, by fine-tuning Llama 2 (7B) with LongLoRA to address the long context challenge.","We experiment under both in-domain setting and out-of-domain setting.","On 7 out of 8 in-domain tasks, TableLlama achieves comparable or better performance than the SOTA for each task, despite the latter often has task-specific design.","On 6 out-of-domain datasets, it achieves 6-48 absolute point gains compared with the base model, showing that training on TableInstruct enhances the model's generalizability.","We will open-source our dataset and trained model to boost future work on developing open generalist models for tables."],"url":"http://arxiv.org/abs/2311.09206v1"}
{"created":"2023-11-15 18:47:42","title":"When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages","abstract":"Multilingual language models are widely used to extend NLP systems to low-resource languages. However, concrete evidence for the effects of multilinguality on language modeling performance in individual languages remains scarce. Here, we pre-train over 10,000 monolingual and multilingual language models for over 250 languages, including multiple language families that are under-studied in NLP. We assess how language modeling performance in each language varies as a function of (1) monolingual dataset size, (2) added multilingual dataset size, (3) linguistic similarity of the added languages, and (4) model size (up to 45M parameters). We find that in moderation, adding multilingual data improves low-resource language modeling performance, similar to increasing low-resource dataset sizes by up to 33%. Improvements depend on the syntactic similarity of the added multilingual data, with marginal additional effects of vocabulary overlap. However, high-resource languages consistently perform worse in multilingual pre-training scenarios. As dataset sizes increase, adding multilingual data begins to hurt performance for both low-resource and high-resource languages, likely due to limited model capacity (the \"curse of multilinguality\"). These results suggest that massively multilingual pre-training may not be optimal for any languages involved, but that more targeted models can significantly improve performance.","sentences":["Multilingual language models are widely used to extend NLP systems to low-resource languages.","However, concrete evidence for the effects of multilinguality on language modeling performance in individual languages remains scarce.","Here, we pre-train over 10,000 monolingual and multilingual language models for over 250 languages, including multiple language families that are under-studied in NLP.","We assess how language modeling performance in each language varies as a function of (1) monolingual dataset size, (2) added multilingual dataset size, (3) linguistic similarity of the added languages, and (4) model size (up to 45M parameters).","We find that in moderation, adding multilingual data improves low-resource language modeling performance, similar to increasing low-resource dataset sizes by up to 33%.","Improvements depend on the syntactic similarity of the added multilingual data, with marginal additional effects of vocabulary overlap.","However, high-resource languages consistently perform worse in multilingual pre-training scenarios.","As dataset sizes increase, adding multilingual data begins to hurt performance for both low-resource and high-resource languages, likely due to limited model capacity (the \"curse of multilinguality\").","These results suggest that massively multilingual pre-training may not be optimal for any languages involved, but that more targeted models can significantly improve performance."],"url":"http://arxiv.org/abs/2311.09205v1"}
{"created":"2023-11-15 18:46:56","title":"Fusion-Eval: Integrating Evaluators with LLMs","abstract":"Evaluating Large Language Models (LLMs) is a complex task, especially considering the intricacies of natural language understanding and the expectations for high-level reasoning. Traditional evaluations typically lean on human-based, model-based, or automatic-metrics-based paradigms, each with its own advantages and shortcomings. We introduce \"Fusion-Eval\", a system that employs LLMs not solely for direct evaluations, but to skillfully integrate insights from diverse evaluators. This gives Fusion-Eval flexibility, enabling it to work effectively across diverse tasks and make optimal use of multiple references. In testing on the SummEval dataset, Fusion-Eval achieved a Spearman correlation of 0.96, outperforming other evaluators. The success of Fusion-Eval underscores the potential of LLMs to produce evaluations that closely align human perspectives, setting a new standard in the field of LLM evaluation.","sentences":["Evaluating Large Language Models (LLMs) is a complex task, especially considering the intricacies of natural language understanding and the expectations for high-level reasoning.","Traditional evaluations typically lean on human-based, model-based, or automatic-metrics-based paradigms, each with its own advantages and shortcomings.","We introduce \"Fusion-Eval\", a system that employs LLMs not solely for direct evaluations, but to skillfully integrate insights from diverse evaluators.","This gives Fusion-Eval flexibility, enabling it to work effectively across diverse tasks and make optimal use of multiple references.","In testing on the SummEval dataset, Fusion-Eval achieved a Spearman correlation of 0.96, outperforming other evaluators.","The success of Fusion-Eval underscores the potential of LLMs to produce evaluations that closely align human perspectives, setting a new standard in the field of LLM evaluation."],"url":"http://arxiv.org/abs/2311.09204v1"}
{"created":"2023-11-15 18:42:44","title":"Never Lost in the Middle: Improving Large Language Models via Attention Strengthening Question Answering","abstract":"While large language models (LLMs) are equipped with longer text input capabilities than before, they are struggling to seek correct information in long contexts. The \"lost in the middle\" problem challenges most LLMs, referring to the dramatic decline in accuracy when correct information is located in the middle. To overcome this crucial issue, this paper proposes to enhance the information searching and reflection ability of LLMs in long contexts via specially designed tasks called Attention Strengthening Multi-doc QA (ASM QA). Following these tasks, our model excels in focusing more precisely on the desired information. Experimental results show substantial improvement in Multi-doc QA and other benchmarks, superior to state-of-the-art models by 13.7% absolute gain in shuffled settings, by 21.5% in passage retrieval task. We release our model, Ziya-Reader to promote related research in the community.","sentences":["While large language models (LLMs) are equipped with longer text input capabilities than before, they are struggling to seek correct information in long contexts.","The \"lost in the middle\" problem challenges most LLMs, referring to the dramatic decline in accuracy when correct information is located in the middle.","To overcome this crucial issue, this paper proposes to enhance the information searching and reflection ability of LLMs in long contexts via specially designed tasks called Attention Strengthening Multi-doc QA (ASM QA).","Following these tasks, our model excels in focusing more precisely on the desired information.","Experimental results show substantial improvement in Multi-doc QA and other benchmarks, superior to state-of-the-art models by 13.7% absolute gain in shuffled settings, by 21.5% in passage retrieval task.","We release our model, Ziya-Reader to promote related research in the community."],"url":"http://arxiv.org/abs/2311.09198v1"}
{"created":"2023-11-15 18:41:19","title":"A Unified Approach to Learning Ising Models: Beyond Independence and Bounded Width","abstract":"We revisit the problem of efficiently learning the underlying parameters of Ising models from data. Current algorithmic approaches achieve essentially optimal sample complexity when given i.i.d. samples from the stationary measure and the underlying model satisfies \"width\" bounds on the total $\\ell_1$ interaction involving each node. We show that a simple existing approach based on node-wise logistic regression provably succeeds at recovering the underlying model in several new settings where these assumptions are violated:   (1) Given dynamically generated data from a wide variety of local Markov chains, like block or round-robin dynamics, logistic regression recovers the parameters with optimal sample complexity up to $\\log\\log n$ factors. This generalizes the specialized algorithm of Bresler, Gamarnik, and Shah [IEEE Trans. Inf. Theory'18] for structure recovery in bounded degree graphs from Glauber dynamics.   (2) For the Sherrington-Kirkpatrick model of spin glasses, given $\\mathsf{poly}(n)$ independent samples, logistic regression recovers the parameters in most of the known high-temperature regime via a simple reduction to weaker structural properties of the measure. This improves on recent work of Anari, Jain, Koehler, Pham, and Vuong [ArXiv'23] which gives distribution learning at higher temperature.   (3) As a simple byproduct of our techniques, logistic regression achieves an exponential improvement in learning from samples in the M-regime of data considered by Dutt, Lokhov, Vuffray, and Misra [ICML'21] as well as novel guarantees for learning from the adversarial Glauber dynamics of Chin, Moitra, Mossel, and Sandon [ArXiv'23].   Our approach thus significantly generalizes the elegant analysis of Wu, Sanghavi, and Dimakis [Neurips'19] without any algorithmic modification.","sentences":["We revisit the problem of efficiently learning the underlying parameters of Ising models from data.","Current algorithmic approaches achieve essentially optimal sample complexity when given i.i.d. samples from the stationary measure and the underlying model satisfies \"width\" bounds on the total $\\ell_1$ interaction involving each node.","We show that a simple existing approach based on node-wise logistic regression provably succeeds at recovering the underlying model in several new settings where these assumptions are violated:   (1) Given dynamically generated data from a wide variety of local Markov chains, like block or round-robin dynamics, logistic regression recovers the parameters with optimal sample complexity up to $\\log\\log n$ factors.","This generalizes the specialized algorithm of Bresler, Gamarnik, and","Shah [IEEE Trans.","Inf.","Theory'18] for structure recovery in bounded degree graphs from Glauber dynamics.   ","(2) For the Sherrington-Kirkpatrick model of spin glasses, given $\\mathsf{poly}(n)$ independent samples, logistic regression recovers the parameters in most of the known high-temperature regime via a simple reduction to weaker structural properties of the measure.","This improves on recent work of Anari, Jain, Koehler, Pham, and Vuong","[ArXiv'23] which gives distribution learning at higher temperature.   ","(3) As a simple byproduct of our techniques, logistic regression achieves an exponential improvement in learning from samples in the M-regime of data considered by Dutt, Lokhov, Vuffray, and Misra","[ICML'21] as well as novel guarantees for learning from the adversarial Glauber dynamics of Chin, Moitra, Mossel, and Sandon [ArXiv'23].   ","Our approach thus significantly generalizes the elegant analysis of Wu, Sanghavi, and Dimakis","[Neurips'19] without any algorithmic modification."],"url":"http://arxiv.org/abs/2311.09197v1"}
{"created":"2023-11-15 18:40:34","title":"Finding polarised communities and tracking information diffusion on Twitter: The Irish Abortion Referendum","abstract":"The analysis of social networks enables the understanding of social interactions, polarisation of ideas, and the spread of information and therefore plays an important role in society. We use Twitter data - as it is a popular venue for the expression of opinion and dissemination of information - to identify opposing sides of a debate and, importantly, to observe how information spreads between these groups in our current polarised climate.   To achieve this, we collected over 688,000 Tweets from the Irish Abortion Referendum of 2018 to build a conversation network from users mentions with sentiment-based homophily. From this network, community detection methods allow us to isolate yes- or no-aligned supporters with high accuracy (90.9%). We supplement this by tracking how information cascades spread via over 31,000 retweet-cascades. We found that very little information spread between polarised communities. This provides a valuable methodology for extracting and studying information diffusion on large networks by isolating ideologically polarised groups and exploring the propagation of information within and between these groups.","sentences":["The analysis of social networks enables the understanding of social interactions, polarisation of ideas, and the spread of information and therefore plays an important role in society.","We use Twitter data - as it is a popular venue for the expression of opinion and dissemination of information - to identify opposing sides of a debate and, importantly, to observe how information spreads between these groups in our current polarised climate.   ","To achieve this, we collected over 688,000 Tweets from the Irish Abortion Referendum of 2018 to build a conversation network from users mentions with sentiment-based homophily.","From this network, community detection methods allow us to isolate yes- or no-aligned supporters with high accuracy (90.9%).","We supplement this by tracking how information cascades spread via over 31,000 retweet-cascades.","We found that very little information spread between polarised communities.","This provides a valuable methodology for extracting and studying information diffusion on large networks by isolating ideologically polarised groups and exploring the propagation of information within and between these groups."],"url":"http://arxiv.org/abs/2311.09196v1"}
{"created":"2023-11-15 18:40:10","title":"Self-Supervised Curriculum Generation for Autonomous Reinforcement Learning without Task-Specific Knowledge","abstract":"A significant bottleneck in applying current reinforcement learning algorithms to real-world scenarios is the need to reset the environment between every episode. This reset process demands substantial human intervention, making it difficult for the agent to learn continuously and autonomously. Several recent works have introduced autonomous reinforcement learning (ARL) algorithms that generate curricula for jointly training reset and forward policies. While their curricula can reduce the number of required manual resets by taking into account the agent's learning progress, they rely on task-specific knowledge, such as predefined initial states or reset reward functions. In this paper, we propose a novel ARL algorithm that can generate a curriculum adaptive to the agent's learning progress without task-specific knowledge. Our curriculum empowers the agent to autonomously reset to diverse and informative initial states. To achieve this, we introduce a success discriminator that estimates the success probability from each initial state when the agent follows the forward policy. The success discriminator is trained with relabeled transitions in a self-supervised manner. Our experimental results demonstrate that our ARL algorithm can generate an adaptive curriculum and enable the agent to efficiently bootstrap to solve sparse-reward maze navigation tasks, outperforming baselines with significantly fewer manual resets.","sentences":["A significant bottleneck in applying current reinforcement learning algorithms to real-world scenarios is the need to reset the environment between every episode.","This reset process demands substantial human intervention, making it difficult for the agent to learn continuously and autonomously.","Several recent works have introduced autonomous reinforcement learning (ARL) algorithms that generate curricula for jointly training reset and forward policies.","While their curricula can reduce the number of required manual resets by taking into account the agent's learning progress, they rely on task-specific knowledge, such as predefined initial states or reset reward functions.","In this paper, we propose a novel ARL algorithm that can generate a curriculum adaptive to the agent's learning progress without task-specific knowledge.","Our curriculum empowers the agent to autonomously reset to diverse and informative initial states.","To achieve this, we introduce a success discriminator that estimates the success probability from each initial state when the agent follows the forward policy.","The success discriminator is trained with relabeled transitions in a self-supervised manner.","Our experimental results demonstrate that our ARL algorithm can generate an adaptive curriculum and enable the agent to efficiently bootstrap to solve sparse-reward maze navigation tasks, outperforming baselines with significantly fewer manual resets."],"url":"http://arxiv.org/abs/2311.09195v1"}
{"created":"2023-11-15 18:39:56","title":"Structural Priming Demonstrates Abstract Grammatical Representations in Multilingual Language Models","abstract":"Abstract grammatical knowledge - of parts of speech and grammatical patterns - is key to the capacity for linguistic generalization in humans. But how abstract is grammatical knowledge in large language models? In the human literature, compelling evidence for grammatical abstraction comes from structural priming. A sentence that shares the same grammatical structure as a preceding sentence is processed and produced more readily. Because confounds exist when using stimuli in a single language, evidence of abstraction is even more compelling from crosslingual structural priming, where use of a syntactic structure in one language primes an analogous structure in another language. We measure crosslingual structural priming in large language models, comparing model behavior to human experimental results from eight crosslingual experiments covering six languages, and four monolingual structural priming experiments in three non-English languages. We find evidence for abstract monolingual and crosslingual grammatical representations in the models that function similarly to those found in humans. These results demonstrate that grammatical representations in multilingual language models are not only similar across languages, but they can causally influence text produced in different languages.","sentences":["Abstract grammatical knowledge - of parts of speech and grammatical patterns - is key to the capacity for linguistic generalization in humans.","But how abstract is grammatical knowledge in large language models?","In the human literature, compelling evidence for grammatical abstraction comes from structural priming.","A sentence that shares the same grammatical structure as a preceding sentence is processed and produced more readily.","Because confounds exist when using stimuli in a single language, evidence of abstraction is even more compelling from crosslingual structural priming, where use of a syntactic structure in one language primes an analogous structure in another language.","We measure crosslingual structural priming in large language models, comparing model behavior to human experimental results from eight crosslingual experiments covering six languages, and four monolingual structural priming experiments in three non-English languages.","We find evidence for abstract monolingual and crosslingual grammatical representations in the models that function similarly to those found in humans.","These results demonstrate that grammatical representations in multilingual language models are not only similar across languages, but they can causally influence text produced in different languages."],"url":"http://arxiv.org/abs/2311.09194v1"}
{"created":"2023-11-15 18:39:21","title":"The Role of Chain-of-Thought in Complex Vision-Language Reasoning Task","abstract":"The study explores the effectiveness of the Chain-of-Thought approach, known for its proficiency in language tasks by breaking them down into sub-tasks and intermediate steps, in improving vision-language tasks that demand sophisticated perception and reasoning. We present the \"Description then Decision\" strategy, which is inspired by how humans process signals. This strategy significantly improves probing task performance by 50%, establishing the groundwork for future research on reasoning paradigms in complex vision-language tasks.","sentences":["The study explores the effectiveness of the Chain-of-Thought approach, known for its proficiency in language tasks by breaking them down into sub-tasks and intermediate steps, in improving vision-language tasks that demand sophisticated perception and reasoning.","We present the \"Description then Decision\" strategy, which is inspired by how humans process signals.","This strategy significantly improves probing task performance by 50%, establishing the groundwork for future research on reasoning paradigms in complex vision-language tasks."],"url":"http://arxiv.org/abs/2311.09193v1"}
{"created":"2023-11-15 18:34:26","title":"Domain Aligned CLIP for Few-shot Classification","abstract":"Large vision-language representation learning models like CLIP have demonstrated impressive performance for zero-shot transfer to downstream tasks while largely benefiting from inter-modal (image-text) alignment via contrastive objectives. This downstream performance can further be enhanced by full-scale fine-tuning which is often compute intensive, requires large labelled data, and can reduce out-of-distribution (OOD) robustness. Furthermore, sole reliance on inter-modal alignment might overlook the rich information embedded within each individual modality. In this work, we introduce a sample-efficient domain adaptation strategy for CLIP, termed Domain Aligned CLIP (DAC), which improves both intra-modal (image-image) and inter-modal alignment on target distributions without fine-tuning the main model. For intra-modal alignment, we introduce a lightweight adapter that is specifically trained with an intra-modal contrastive objective. To improve inter-modal alignment, we introduce a simple framework to modulate the precomputed class text embeddings. The proposed few-shot fine-tuning framework is computationally efficient, robust to distribution shifts, and does not alter CLIP's parameters. We study the effectiveness of DAC by benchmarking on 11 widely used image classification tasks with consistent improvements in 16-shot classification upon strong baselines by about 2.3% and demonstrate competitive performance on 4 OOD robustness benchmarks.","sentences":["Large vision-language representation learning models like CLIP have demonstrated impressive performance for zero-shot transfer to downstream tasks while largely benefiting from inter-modal (image-text) alignment via contrastive objectives.","This downstream performance can further be enhanced by full-scale fine-tuning which is often compute intensive, requires large labelled data, and can reduce out-of-distribution (OOD) robustness.","Furthermore, sole reliance on inter-modal alignment might overlook the rich information embedded within each individual modality.","In this work, we introduce a sample-efficient domain adaptation strategy for CLIP, termed Domain Aligned CLIP (DAC), which improves both intra-modal (image-image) and inter-modal alignment on target distributions without fine-tuning the main model.","For intra-modal alignment, we introduce a lightweight adapter that is specifically trained with an intra-modal contrastive objective.","To improve inter-modal alignment, we introduce a simple framework to modulate the precomputed class text embeddings.","The proposed few-shot fine-tuning framework is computationally efficient, robust to distribution shifts, and does not alter CLIP's parameters.","We study the effectiveness of DAC by benchmarking on 11 widely used image classification tasks with consistent improvements in 16-shot classification upon strong baselines by about 2.3% and demonstrate competitive performance on 4 OOD robustness benchmarks."],"url":"http://arxiv.org/abs/2311.09191v1"}
{"created":"2023-11-15 18:34:03","title":"On the Computation of the Gaussian Rate-Distortion-Perception Function","abstract":"In this paper, we study the computation of the rate-distortion-perception function (RDPF) for a multivariate Gaussian source under mean squared error (MSE) distortion and, respectively, Kullback-Leibler divergence, geometric Jensen-Shannon divergence, squared Hellinger distance, and squared Wasserstein-2 distance perception metrics. To this end, we first characterize the analytical bounds of the scalar Gaussian RDPF for the aforementioned divergence functions, also providing the RDPF-achieving forward \"test-channel\" realization. Focusing on the multivariate case, we establish that, for tensorizable distortion and perception metrics, the optimal solution resides on the vector space spanned by the eigenvector of the source covariance matrix. Consequently, the multivariate optimization problem can be expressed as a function of the scalar Gaussian RDPFs of the source marginals, constrained by global distortion and perception levels. Leveraging this characterization, we design an alternating minimization scheme based on the block nonlinear Gauss-Seidel method, which optimally solves the problem while identifying the Gaussian RDPF-achieving realization. Furthermore, the associated algorithmic embodiment is provided, as well as the convergence and the rate of convergence characterization. Lastly, for the \"perfect realism\" regime, the analytical solution for the multivariate Gaussian RDPF is obtained. We corroborate our results with numerical simulations and draw connections to existing results.","sentences":["In this paper, we study the computation of the rate-distortion-perception function (RDPF) for a multivariate Gaussian source under mean squared error (MSE) distortion and, respectively, Kullback-Leibler divergence, geometric Jensen-Shannon divergence, squared Hellinger distance, and squared Wasserstein-2 distance perception metrics.","To this end, we first characterize the analytical bounds of the scalar Gaussian RDPF for the aforementioned divergence functions, also providing the RDPF-achieving forward \"test-channel\" realization.","Focusing on the multivariate case, we establish that, for tensorizable distortion and perception metrics, the optimal solution resides on the vector space spanned by the eigenvector of the source covariance matrix.","Consequently, the multivariate optimization problem can be expressed as a function of the scalar Gaussian RDPFs of the source marginals, constrained by global distortion and perception levels.","Leveraging this characterization, we design an alternating minimization scheme based on the block nonlinear Gauss-Seidel method, which optimally solves the problem while identifying the Gaussian RDPF-achieving realization.","Furthermore, the associated algorithmic embodiment is provided, as well as the convergence and the rate of convergence characterization.","Lastly, for the \"perfect realism\" regime, the analytical solution for the multivariate Gaussian RDPF is obtained.","We corroborate our results with numerical simulations and draw connections to existing results."],"url":"http://arxiv.org/abs/2311.09190v1"}
{"created":"2023-11-15 18:32:27","title":"PsyEval: A Comprehensive Large Language Model Evaluation Benchmark for Mental Health","abstract":"Recently, there has been a growing interest in utilizing large language models (LLMs) in mental health research, with studies showcasing their remarkable capabilities, such as disease detection. However, there is currently a lack of a comprehensive benchmark for evaluating the capability of LLMs in this domain. Therefore, we address this gap by introducing the first comprehensive benchmark tailored to the unique characteristics of the mental health domain. This benchmark encompasses a total of six sub-tasks, covering three dimensions, to systematically assess the capabilities of LLMs in the realm of mental health. We have designed corresponding concise prompts for each sub-task. And we comprehensively evaluate a total of eight advanced LLMs using our benchmark. Experiment results not only demonstrate significant room for improvement in current LLMs concerning mental health but also unveil potential directions for future model optimization.","sentences":["Recently, there has been a growing interest in utilizing large language models (LLMs) in mental health research, with studies showcasing their remarkable capabilities, such as disease detection.","However, there is currently a lack of a comprehensive benchmark for evaluating the capability of LLMs in this domain.","Therefore, we address this gap by introducing the first comprehensive benchmark tailored to the unique characteristics of the mental health domain.","This benchmark encompasses a total of six sub-tasks, covering three dimensions, to systematically assess the capabilities of LLMs in the realm of mental health.","We have designed corresponding concise prompts for each sub-task.","And we comprehensively evaluate a total of eight advanced LLMs using our benchmark.","Experiment results not only demonstrate significant room for improvement in current LLMs concerning mental health but also unveil potential directions for future model optimization."],"url":"http://arxiv.org/abs/2311.09189v1"}
{"created":"2023-11-15 18:28:29","title":"Towards Verifiable Text Generation with Symbolic References","abstract":"Large language models (LLMs) have demonstrated an impressive ability to synthesize plausible and fluent text. However they remain vulnerable to hallucinations, and thus their outputs generally require manual human verification for high-stakes applications, which can be time-consuming and difficult. This paper proposes symbolically grounded generation (SymGen) as a simple approach for enabling easier validation of an LLM's output. SymGen prompts an LLM to interleave its regular output text with explicit symbolic references to fields present in some conditioning data (e.g., a table in JSON format). The references can be used to display the provenance of different spans of text in the generation, reducing the effort required for manual verification. Across data-to-text and question answering experiments, we find that LLMs are able to directly output text that makes use of symbolic references while maintaining fluency and accuracy.","sentences":["Large language models (LLMs) have demonstrated an impressive ability to synthesize plausible and fluent text.","However they remain vulnerable to hallucinations, and thus their outputs generally require manual human verification for high-stakes applications, which can be time-consuming and difficult.","This paper proposes symbolically grounded generation (SymGen) as a simple approach for enabling easier validation of an LLM's output.","SymGen prompts an LLM to interleave its regular output text with explicit symbolic references to fields present in some conditioning data (e.g., a table in JSON format).","The references can be used to display the provenance of different spans of text in the generation, reducing the effort required for manual verification.","Across data-to-text and question answering experiments, we find that LLMs are able to directly output text that makes use of symbolic references while maintaining fluency and accuracy."],"url":"http://arxiv.org/abs/2311.09188v1"}
{"created":"2023-11-15 18:25:26","title":"Benchmarking Generation and Evaluation Capabilities of Large Language Models for Instruction Controllable Summarization","abstract":"While large language models (LLMs) already achieve strong performance on standard generic summarization benchmarks, their performance on more complex summarization task settings is less studied. Therefore, we benchmark LLMs on instruction controllable text summarization, where the model input consists of both a source article and a natural language requirement for the desired summary characteristics. To this end, we curate an evaluation-only dataset for this task setting and conduct human evaluation on 5 LLM-based summarization systems. We then benchmark LLM-based automatic evaluation for this task with 4 different evaluation protocols and 11 LLMs, resulting in 40 evaluation methods in total. Our study reveals that instruction controllable text summarization remains a challenging task for LLMs, since (1) all LLMs evaluated still make factual and other types of errors in their summaries; (2) all LLM-based evaluation methods cannot achieve a strong alignment with human annotators when judging the quality of candidate summaries; (3) different LLMs show large performance gaps in summary generation and evaluation. We make our collected benchmark, InstruSum, publicly available to facilitate future research in this direction.","sentences":["While large language models (LLMs) already achieve strong performance on standard generic summarization benchmarks, their performance on more complex summarization task settings is less studied.","Therefore, we benchmark LLMs on instruction controllable text summarization, where the model input consists of both a source article and a natural language requirement for the desired summary characteristics.","To this end, we curate an evaluation-only dataset for this task setting and conduct human evaluation on 5 LLM-based summarization systems.","We then benchmark LLM-based automatic evaluation for this task with 4 different evaluation protocols and 11 LLMs, resulting in 40 evaluation methods in total.","Our study reveals that instruction controllable text summarization remains a challenging task for LLMs, since (1) all LLMs evaluated still make factual and other types of errors in their summaries; (2) all LLM-based evaluation methods cannot achieve a strong alignment with human annotators when judging the quality of candidate summaries; (3) different LLMs show large performance gaps in summary generation and evaluation.","We make our collected benchmark, InstruSum, publicly available to facilitate future research in this direction."],"url":"http://arxiv.org/abs/2311.09184v1"}
{"created":"2023-11-15 18:23:17","title":"ContraDoc: Understanding Self-Contradictions in Documents with Large Language Models","abstract":"In recent times, large language models (LLMs) have shown impressive performance on various document-level tasks such as document classification, summarization, and question-answering. However, research on understanding their capabilities on the task of self-contradictions in long documents has been very limited. In this work, we introduce ContraDoc, the first human-annotated dataset to study self-contradictions in long documents across multiple domains, varying document lengths, self-contradictions types, and scope. We then analyze the current capabilities of four state-of-the-art open-source and commercially available LLMs: GPT3.5, GPT4, PaLM2, and LLaMAv2 on this dataset. While GPT4 performs the best and can outperform humans on this task, we find that it is still unreliable and struggles with self-contradictions that require more nuance and context. We release the dataset and all the code associated with the experiments.","sentences":["In recent times, large language models (LLMs) have shown impressive performance on various document-level tasks such as document classification, summarization, and question-answering.","However, research on understanding their capabilities on the task of self-contradictions in long documents has been very limited.","In this work, we introduce ContraDoc, the first human-annotated dataset to study self-contradictions in long documents across multiple domains, varying document lengths, self-contradictions types, and scope.","We then analyze the current capabilities of four state-of-the-art open-source and commercially available LLMs: GPT3.5, GPT4, PaLM2, and LLaMAv2 on this dataset.","While GPT4 performs the best and can outperform humans on this task, we find that it is still unreliable and struggles with self-contradictions that require more nuance and context.","We release the dataset and all the code associated with the experiments."],"url":"http://arxiv.org/abs/2311.09182v1"}
{"created":"2023-11-15 18:19:58","title":"PEARL: Personalizing Large Language Model Writing Assistants with Generation-Calibrated Retrievers","abstract":"Powerful large language models have facilitated the development of writing assistants that promise to significantly improve the quality and efficiency of composition and communication. However, a barrier to effective assistance is the lack of personalization in LLM outputs to the author's communication style and specialized knowledge. In this paper, we address this challenge by proposing PEARL, a retrieval-augmented LLM writing assistant personalized with a generation-calibrated retriever. Our retriever is trained to select historic user-authored documents for prompt augmentation, such that they are likely to best personalize LLM generations for a user request. We propose two key novelties for training our retriever: 1) A training data selection method that identifies user requests likely to benefit from personalization and documents that provide that benefit; and 2) A scale-calibrating KL-divergence objective that ensures that our retriever closely tracks the benefit of a document for personalized generation. We demonstrate the effectiveness of PEARL in generating personalized workplace social media posts and Reddit comments. Finally, we showcase the potential of a generation-calibrated retriever to double as a performance predictor and further improve low-quality generations via LLM chaining.","sentences":["Powerful large language models have facilitated the development of writing assistants that promise to significantly improve the quality and efficiency of composition and communication.","However, a barrier to effective assistance is the lack of personalization in LLM outputs to the author's communication style and specialized knowledge.","In this paper, we address this challenge by proposing PEARL, a retrieval-augmented LLM writing assistant personalized with a generation-calibrated retriever.","Our retriever is trained to select historic user-authored documents for prompt augmentation, such that they are likely to best personalize LLM generations for a user request.","We propose two key novelties for training our retriever: 1) A training data selection method that identifies user requests likely to benefit from personalization and documents that provide that benefit; and 2) A scale-calibrating KL-divergence objective that ensures that our retriever closely tracks the benefit of a document for personalized generation.","We demonstrate the effectiveness of PEARL in generating personalized workplace social media posts and Reddit comments.","Finally, we showcase the potential of a generation-calibrated retriever to double as a performance predictor and further improve low-quality generations via LLM chaining."],"url":"http://arxiv.org/abs/2311.09180v1"}
{"created":"2023-11-15 18:15:37","title":"SiRA: Sparse Mixture of Low Rank Adaptation","abstract":"Parameter Efficient Tuning has been an prominent approach to adapt the Large Language Model to downstream tasks. Most previous works considers adding the dense trainable parameters, where all parameters are used to adapt certain task. We found this less effective empirically using the example of LoRA that introducing more trainable parameters does not help. Motivated by this we investigate the importance of leveraging \"sparse\" computation and propose SiRA: sparse mixture of low rank adaption. SiRA leverages the Sparse Mixture of Expert(SMoE) to boost the performance of LoRA. Specifically it enforces the top $k$ experts routing with a capacity limit restricting the maximum number of tokens each expert can process. We propose a novel and simple expert dropout on top of gating network to reduce the over-fitting issue. Through extensive experiments, we verify SiRA performs better than LoRA and other mixture of expert approaches across different single tasks and multitask settings.","sentences":["Parameter Efficient Tuning has been an prominent approach to adapt the Large Language Model to downstream tasks.","Most previous works considers adding the dense trainable parameters, where all parameters are used to adapt certain task.","We found this less effective empirically using the example of LoRA that introducing more trainable parameters does not help.","Motivated by this we investigate the importance of leveraging \"sparse\" computation and propose SiRA: sparse mixture of low rank adaption.","SiRA leverages the Sparse Mixture of Expert(SMoE) to boost the performance of LoRA.","Specifically it enforces the top $k$ experts routing with a capacity limit restricting the maximum number of tokens each expert can process.","We propose a novel and simple expert dropout on top of gating network to reduce the over-fitting issue.","Through extensive experiments, we verify SiRA performs better than LoRA and other mixture of expert approaches across different single tasks and multitask settings."],"url":"http://arxiv.org/abs/2311.09179v1"}
{"created":"2023-11-15 18:15:30","title":"RBPGAN: Recurrent Back-Projection GAN for Video Super Resolution","abstract":"Recently, video super resolution (VSR) has become a very impactful task in the area of Computer Vision due to its various applications. In this paper, we propose Recurrent Back-Projection Generative Adversarial Network (RBPGAN) for VSR in an attempt to generate temporally coherent solutions while preserving spatial details. RBPGAN integrates two state-of-the-art models to get the best in both worlds without compromising the accuracy of produced video. The generator of the model is inspired by RBPN system, while the discriminator is inspired by TecoGAN. We also utilize Ping-Pong loss to increase temporal consistency over time. Our contribution together results in a model that outperforms earlier work in terms of temporally consistent details, as we will demonstrate qualitatively and quantitatively using different datasets.","sentences":["Recently, video super resolution (VSR) has become a very impactful task in the area of Computer Vision due to its various applications.","In this paper, we propose Recurrent Back-Projection Generative Adversarial Network (RBPGAN) for VSR in an attempt to generate temporally coherent solutions while preserving spatial details.","RBPGAN integrates two state-of-the-art models to get the best in both worlds without compromising the accuracy of produced video.","The generator of the model is inspired by RBPN system, while the discriminator is inspired by TecoGAN.","We also utilize Ping-Pong loss to increase temporal consistency over time.","Our contribution together results in a model that outperforms earlier work in terms of temporally consistent details, as we will demonstrate qualitatively and quantitatively using different datasets."],"url":"http://arxiv.org/abs/2311.09178v1"}
{"created":"2023-11-15 18:11:41","title":"Generate, Filter, and Fuse: Query Expansion via Multi-Step Keyword Generation for Zero-Shot Neural Rankers","abstract":"Query expansion has been proved to be effective in improving recall and precision of first-stage retrievers, and yet its influence on a complicated, state-of-the-art cross-encoder ranker remains under-explored. We first show that directly applying the expansion techniques in the current literature to state-of-the-art neural rankers can result in deteriorated zero-shot performance. To this end, we propose GFF, a pipeline that includes a large language model and a neural ranker, to Generate, Filter, and Fuse query expansions more effectively in order to improve the zero-shot ranking metrics such as nDCG@10. Specifically, GFF first calls an instruction-following language model to generate query-related keywords through a reasoning chain. Leveraging self-consistency and reciprocal rank weighting, GFF further filters and combines the ranking results of each expanded query dynamically. By utilizing this pipeline, we show that GFF can improve the zero-shot nDCG@10 on BEIR and TREC DL 2019/2020. We also analyze different modelling choices in the GFF pipeline and shed light on the future directions in query expansion for zero-shot neural rankers.","sentences":["Query expansion has been proved to be effective in improving recall and precision of first-stage retrievers, and yet its influence on a complicated, state-of-the-art cross-encoder ranker remains under-explored.","We first show that directly applying the expansion techniques in the current literature to state-of-the-art neural rankers can result in deteriorated zero-shot performance.","To this end, we propose GFF, a pipeline that includes a large language model and a neural ranker, to Generate, Filter, and Fuse query expansions more effectively in order to improve the zero-shot ranking metrics such as nDCG@10.","Specifically, GFF first calls an instruction-following language model to generate query-related keywords through a reasoning chain.","Leveraging self-consistency and reciprocal rank weighting, GFF further filters and combines the ranking results of each expanded query dynamically.","By utilizing this pipeline, we show that GFF can improve the zero-shot nDCG@10 on BEIR and TREC DL 2019/2020.","We also analyze different modelling choices in the GFF pipeline and shed light on the future directions in query expansion for zero-shot neural rankers."],"url":"http://arxiv.org/abs/2311.09175v1"}
{"created":"2023-11-15 18:11:23","title":"AbsPyramid: Benchmarking the Abstraction Ability of Language Models with a Unified Entailment Graph","abstract":"Cognitive research indicates that abstraction ability is essential in human intelligence, which remains under-explored in language models. In this paper, we present AbsPyramid, a unified entailment graph of 221K textual descriptions of abstraction knowledge. While existing resources only touch nouns or verbs within simplified events or specific domains, AbsPyramid collects abstract knowledge for three components of diverse events to comprehensively evaluate the abstraction ability of language models in the open domain. Experimental results demonstrate that current LLMs face challenges comprehending abstraction knowledge in zero-shot and few-shot settings. By training on our rich abstraction knowledge, we find LLMs can acquire basic abstraction abilities and generalize to unseen events. In the meantime, we empirically show that our benchmark is comprehensive to enhance LLMs across two previous abstraction tasks.","sentences":["Cognitive research indicates that abstraction ability is essential in human intelligence, which remains under-explored in language models.","In this paper, we present AbsPyramid, a unified entailment graph of 221K textual descriptions of abstraction knowledge.","While existing resources only touch nouns or verbs within simplified events or specific domains, AbsPyramid collects abstract knowledge for three components of diverse events to comprehensively evaluate the abstraction ability of language models in the open domain.","Experimental results demonstrate that current LLMs face challenges comprehending abstraction knowledge in zero-shot and few-shot settings.","By training on our rich abstraction knowledge, we find LLMs can acquire basic abstraction abilities and generalize to unseen events.","In the meantime, we empirically show that our benchmark is comprehensive to enhance LLMs across two previous abstraction tasks."],"url":"http://arxiv.org/abs/2311.09174v2"}
{"created":"2023-11-15 18:11:16","title":"Design Theory for Societal Digital Transformation: The Case of Digital Global Health","abstract":"With societal challenges, including but not limited to human development, equity, social justice, and climate change, societal-level digital transformation (SDT) is of imminent relevance and theoretical interest. While building on local-level efforts, societal-level transformation is a nonlinear extension of the local level. Unfortunately, academic discourse on digital transformation has largely left SDT unaccounted for. Drawing on more than 25 years of intensive, interventionist research engagement with the digital transformation of public healthcare information management and delivery in more than 80 countries in the Global South, we contribute to theorizing SDT in the form of a design theory consisting of six interconnected design principles. These design principles articulate the interplay and tensions of accommodating over time increased diversity and flexibility in digital solutions, while simultaneously connecting local, national, and regional/ global efforts.","sentences":["With societal challenges, including but not limited to human development, equity, social justice, and climate change, societal-level digital transformation (SDT) is of imminent relevance and theoretical interest.","While building on local-level efforts, societal-level transformation is a nonlinear extension of the local level.","Unfortunately, academic discourse on digital transformation has largely left SDT unaccounted for.","Drawing on more than 25 years of intensive, interventionist research engagement with the digital transformation of public healthcare information management and delivery in more than 80 countries in the Global South, we contribute to theorizing SDT in the form of a design theory consisting of six interconnected design principles.","These design principles articulate the interplay and tensions of accommodating over time increased diversity and flexibility in digital solutions, while simultaneously connecting local, national, and regional/ global efforts."],"url":"http://arxiv.org/abs/2311.09173v1"}
{"created":"2023-11-15 18:09:52","title":"Enhancing AmBC Systems with Deep Learning for Joint Channel Estimation and Signal Detection","abstract":"The era of ubiquitous, affordable wireless connectivity has opened doors to countless practical applications. In this context, ambient backscatter communication (AmBC) stands out, utilizing passive tags to establish connections with readers by harnessing reflected ambient radio frequency (RF) signals. However, conventional data detectors face limitations due to their inadequate knowledge of channel and RF-source parameters. To address this challenge, we propose an innovative approach using a deep neural network (DNN) for channel state estimation (CSI) and signal detection within AmBC systems. Unlike traditional methods that separate CSI estimation and data detection, our approach leverages a DNN to implicitly estimate CSI and simultaneously detect data. The DNN model, trained offline using simulated data derived from channel statistics, excels in online data recovery, ensuring robust performance in practical scenarios. Comprehensive evaluations validate the superiority of our proposed DNN method over traditional detectors, particularly in terms of bit error rate (BER). In high signal-to-noise ratio (SNR) conditions, our method exhibits an impressive approximately 20% improvement in BER performance compared to the maximum likelihood (ML) approach. These results underscore the effectiveness of our developed approach for AmBC channel estimation and signal detection. In summary, our method outperforms traditional detectors, bolstering the reliability and efficiency of AmBC systems, even in challenging channel conditions.","sentences":["The era of ubiquitous, affordable wireless connectivity has opened doors to countless practical applications.","In this context, ambient backscatter communication (AmBC) stands out, utilizing passive tags to establish connections with readers by harnessing reflected ambient radio frequency (RF) signals.","However, conventional data detectors face limitations due to their inadequate knowledge of channel and RF-source parameters.","To address this challenge, we propose an innovative approach using a deep neural network (DNN) for channel state estimation (CSI) and signal detection within AmBC systems.","Unlike traditional methods that separate CSI estimation and data detection, our approach leverages a DNN to implicitly estimate CSI and simultaneously detect data.","The DNN model, trained offline using simulated data derived from channel statistics, excels in online data recovery, ensuring robust performance in practical scenarios.","Comprehensive evaluations validate the superiority of our proposed DNN method over traditional detectors, particularly in terms of bit error rate (BER).","In high signal-to-noise ratio (SNR) conditions, our method exhibits an impressive approximately 20% improvement in BER performance compared to the maximum likelihood (ML) approach.","These results underscore the effectiveness of our developed approach for AmBC channel estimation and signal detection.","In summary, our method outperforms traditional detectors, bolstering the reliability and efficiency of AmBC systems, even in challenging channel conditions."],"url":"http://arxiv.org/abs/2311.09172v1"}
{"created":"2023-11-15 18:06:25","title":"Generalized Neighbor Search using Commodity Hardware Acceleration","abstract":"Tree-based Nearest Neighbor Search (NNS) is hard to parallelize on GPUs. However, newer Nvidia GPUs are equipped with Ray Tracing (RT) cores that can build a spatial tree called Bounding Volume Hierarchy (BVH) to accelerate graphics rendering. Recent work proposed using RT cores to implement NNS, but they all have a hardware-imposed constraint on the type of distance metric, which is the Euclidean distance. We propose and implement two approaches for generalized distance computations: filter-refine, and monotone transformation, each of which allows non-euclidean nearest neighbor queries to be performed in terms of Euclidean distances. We find that our reductions improve the time taken to perform distance computations during the search, thereby improving the overall performance of the NNS.","sentences":["Tree-based Nearest Neighbor Search (NNS) is hard to parallelize on GPUs.","However, newer Nvidia GPUs are equipped with Ray Tracing (RT) cores that can build a spatial tree called Bounding Volume Hierarchy (BVH) to accelerate graphics rendering.","Recent work proposed using RT cores to implement NNS, but they all have a hardware-imposed constraint on the type of distance metric, which is the Euclidean distance.","We propose and implement two approaches for generalized distance computations: filter-refine, and monotone transformation, each of which allows non-euclidean nearest neighbor queries to be performed in terms of Euclidean distances.","We find that our reductions improve the time taken to perform distance computations during the search, thereby improving the overall performance of the NNS."],"url":"http://arxiv.org/abs/2311.09168v1"}
{"created":"2023-11-15 17:50:30","title":"CLEAN-EVAL: Clean Evaluation on Contaminated Large Language Models","abstract":"We are currently in an era of fierce competition among various large language models (LLMs) continuously pushing the boundaries of benchmark performance. However, genuinely assessing the capabilities of these LLMs has become a challenging and critical issue due to potential data contamination, and it wastes dozens of time and effort for researchers and engineers to download and try those contaminated models. To save our precious time, we propose a novel and useful method, Clean-Eval, which mitigates the issue of data contamination and evaluates the LLMs in a cleaner manner. Clean-Eval employs an LLM to paraphrase and back-translate the contaminated data into a candidate set, generating expressions with the same meaning but in different surface forms. A semantic detector is then used to filter the generated low-quality samples to narrow down this candidate set. The best candidate is finally selected from this set based on the BLEURT score. According to human assessment, this best candidate is semantically similar to the original contamination data but expressed differently. All candidates can form a new benchmark to evaluate the model. Our experiments illustrate that Clean-Eval substantially restores the actual evaluation results on contaminated LLMs under both few-shot learning and fine-tuning scenarios.","sentences":["We are currently in an era of fierce competition among various large language models (LLMs) continuously pushing the boundaries of benchmark performance.","However, genuinely assessing the capabilities of these LLMs has become a challenging and critical issue due to potential data contamination, and it wastes dozens of time and effort for researchers and engineers to download and try those contaminated models.","To save our precious time, we propose a novel and useful method, Clean-Eval, which mitigates the issue of data contamination and evaluates the LLMs in a cleaner manner.","Clean-Eval employs an LLM to paraphrase and back-translate the contaminated data into a candidate set, generating expressions with the same meaning but in different surface forms.","A semantic detector is then used to filter the generated low-quality samples to narrow down this candidate set.","The best candidate is finally selected from this set based on the BLEURT score.","According to human assessment, this best candidate is semantically similar to the original contamination data but expressed differently.","All candidates can form a new benchmark to evaluate the model.","Our experiments illustrate that Clean-Eval substantially restores the actual evaluation results on contaminated LLMs under both few-shot learning and fine-tuning scenarios."],"url":"http://arxiv.org/abs/2311.09154v1"}
{"created":"2023-11-15 17:46:39","title":"Temporal Knowledge Question Answering via Abstract Reasoning Induction","abstract":"In this paper, we tackle the significant challenge of temporal knowledge reasoning in Large Language Models (LLMs), an area where such models frequently encounter difficulties. These difficulties often result in the generation of misleading or incorrect information, primarily due to their limited capacity to process evolving factual knowledge and complex temporal logic. In response, we propose a novel, constructivism-based approach that advocates for a paradigm shift in LLM learning towards an active, ongoing process of knowledge synthesis and customization. At the heart of our proposal is the Abstract Reasoning Induction ARI framework, which divides temporal reasoning into two distinct phases: Knowledge-agnostic and Knowledge-based. This division aims to reduce instances of hallucinations and improve LLMs' capacity for integrating abstract methodologies derived from historical data. Our approach achieves remarkable improvements, with relative gains of 29.7\\% and 9.27\\% on two temporal QA datasets, underscoring its efficacy in advancing temporal reasoning in LLMs. The code will be released at https://github.com/czy1999/ARI.","sentences":["In this paper, we tackle the significant challenge of temporal knowledge reasoning in Large Language Models (LLMs), an area where such models frequently encounter difficulties.","These difficulties often result in the generation of misleading or incorrect information, primarily due to their limited capacity to process evolving factual knowledge and complex temporal logic.","In response, we propose a novel, constructivism-based approach that advocates for a paradigm shift in LLM learning towards an active, ongoing process of knowledge synthesis and customization.","At the heart of our proposal is the Abstract Reasoning Induction ARI framework, which divides temporal reasoning into two distinct phases: Knowledge-agnostic and Knowledge-based.","This division aims to reduce instances of hallucinations and improve LLMs' capacity for integrating abstract methodologies derived from historical data.","Our approach achieves remarkable improvements, with relative gains of 29.7\\% and 9.27\\% on two temporal QA datasets, underscoring its efficacy in advancing temporal reasoning in LLMs.","The code will be released at https://github.com/czy1999/ARI."],"url":"http://arxiv.org/abs/2311.09149v1"}
{"created":"2023-11-15 17:40:48","title":"Model Agnostic Explainable Selective Regression via Uncertainty Estimation","abstract":"With the wide adoption of machine learning techniques, requirements have evolved beyond sheer high performance, often requiring models to be trustworthy. A common approach to increase the trustworthiness of such systems is to allow them to refrain from predicting. Such a framework is known as selective prediction. While selective prediction for classification tasks has been widely analyzed, the problem of selective regression is understudied. This paper presents a novel approach to selective regression that utilizes model-agnostic non-parametric uncertainty estimation. Our proposed framework showcases superior performance compared to state-of-the-art selective regressors, as demonstrated through comprehensive benchmarking on 69 datasets. Finally, we use explainable AI techniques to gain an understanding of the drivers behind selective regression. We implement our selective regression method in the open-source Python package doubt and release the code used to reproduce our experiments.","sentences":["With the wide adoption of machine learning techniques, requirements have evolved beyond sheer high performance, often requiring models to be trustworthy.","A common approach to increase the trustworthiness of such systems is to allow them to refrain from predicting.","Such a framework is known as selective prediction.","While selective prediction for classification tasks has been widely analyzed, the problem of selective regression is understudied.","This paper presents a novel approach to selective regression that utilizes model-agnostic non-parametric uncertainty estimation.","Our proposed framework showcases superior performance compared to state-of-the-art selective regressors, as demonstrated through comprehensive benchmarking on 69 datasets.","Finally, we use explainable AI techniques to gain an understanding of the drivers behind selective regression.","We implement our selective regression method in the open-source Python package doubt and release the code used to reproduce our experiments."],"url":"http://arxiv.org/abs/2311.09145v1"}
{"created":"2023-11-15 17:40:27","title":"Grounding or Guesswork? Large Language Models are Presumptive Grounders","abstract":"Effective conversation requires common ground: a shared understanding between the participants. Common ground, however, does not emerge spontaneously in conversation. Speakers and listeners work together to both identify and construct a shared basis while avoiding misunderstanding. To accomplish grounding, humans rely on a range of dialogue acts, like clarification (What do you mean?) and acknowledgment (I understand.). In domains like teaching and emotional support, carefully constructing grounding prevents misunderstanding. However, it is unclear whether large language models (LLMs) leverage these dialogue acts in constructing common ground. To this end, we curate a set of grounding acts and propose corresponding metrics that quantify attempted grounding. We study whether LLMs use these grounding acts, simulating them taking turns from several dialogue datasets, and comparing the results to humans. We find that current LLMs are presumptive grounders, biased towards assuming common ground without using grounding acts. To understand the roots of this behavior, we examine the role of instruction tuning and reinforcement learning with human feedback (RLHF), finding that RLHF leads to less grounding. Altogether, our work highlights the need for more research investigating grounding in human-AI interaction.","sentences":["Effective conversation requires common ground: a shared understanding between the participants.","Common ground, however, does not emerge spontaneously in conversation.","Speakers and listeners work together to both identify and construct a shared basis while avoiding misunderstanding.","To accomplish grounding, humans rely on a range of dialogue acts, like clarification (What do you mean?)","and acknowledgment (I understand.).","In domains like teaching and emotional support, carefully constructing grounding prevents misunderstanding.","However, it is unclear whether large language models (LLMs) leverage these dialogue acts in constructing common ground.","To this end, we curate a set of grounding acts and propose corresponding metrics that quantify attempted grounding.","We study whether LLMs use these grounding acts, simulating them taking turns from several dialogue datasets, and comparing the results to humans.","We find that current LLMs are presumptive grounders, biased towards assuming common ground without using grounding acts.","To understand the roots of this behavior, we examine the role of instruction tuning and reinforcement learning with human feedback (RLHF), finding that RLHF leads to less grounding.","Altogether, our work highlights the need for more research investigating grounding in human-AI interaction."],"url":"http://arxiv.org/abs/2311.09144v1"}
{"created":"2023-11-15 17:39:25","title":"Machine-learning parameter tracking with partial state observation","abstract":"Complex and nonlinear dynamical systems often involve parameters that change with time, accurate tracking of which is essential to tasks such as state estimation, prediction, and control. Existing machine-learning methods require full state observation of the underlying system and tacitly assume adiabatic changes in the parameter. Formulating an inverse problem and exploiting reservoir computing, we develop a model-free and fully data-driven framework to accurately track time-varying parameters from partial state observation in real time. In particular, with training data from a subset of the dynamical variables of the system for a small number of known parameter values, the framework is able to accurately predict the parameter variations in time. Low- and high-dimensional, Markovian and non-Markovian nonlinear dynamical systems are used to demonstrate the power of the machine-learning based parameter-tracking framework. Pertinent issues affecting the tracking performance are addressed.","sentences":["Complex and nonlinear dynamical systems often involve parameters that change with time, accurate tracking of which is essential to tasks such as state estimation, prediction, and control.","Existing machine-learning methods require full state observation of the underlying system and tacitly assume adiabatic changes in the parameter.","Formulating an inverse problem and exploiting reservoir computing, we develop a model-free and fully data-driven framework to accurately track time-varying parameters from partial state observation in real time.","In particular, with training data from a subset of the dynamical variables of the system for a small number of known parameter values, the framework is able to accurately predict the parameter variations in time.","Low- and high-dimensional, Markovian and non-Markovian nonlinear dynamical systems are used to demonstrate the power of the machine-learning based parameter-tracking framework.","Pertinent issues affecting the tracking performance are addressed."],"url":"http://arxiv.org/abs/2311.09142v1"}
{"created":"2023-11-15 17:35:04","title":"Prophet Inequalities Require Only a Constant Number of Samples","abstract":"In a prophet inequality problem, $n$ independent random variables are presented to a gambler one by one. The gambler decides when to stop the sequence and obtains the most recent value as reward. We evaluate a stopping rule by the worst-case ratio between its expected reward and the expectation of the maximum variable. In the classic setting, the order is fixed, and the optimal ratio is known to be 1/2. Three variants of this problem have been extensively studied: the prophet-secretary model, where variables arrive in uniformly random order; the free-order model, where the gambler chooses the arrival order; and the i.i.d. model, where the distributions are all the same, rendering the arrival order irrelevant.   Most of the literature assumes that distributions are known to the gambler. Recent work has considered the question of what is achievable when the gambler has access only to a few samples per distribution. Surprisingly, in the fixed-order case, a single sample from each distribution is enough to approximate the optimal ratio, but this is not the case in any of the three variants.   We provide a unified proof that for all three variants of the problem, a constant number of samples (independent of n) for each distribution is good enough to approximate the optimal ratios.   Prior to our work, this was known to be the case only in the i.i.d. variant. We complement our result showing that our algorithms can be implemented in polynomial time.   A key ingredient in our proof is an existential result based on a minimax argument, which states that there must exist an algorithm that attains the optimal ratio and does not rely on the knowledge of the upper tail of the distributions. A second key ingredient is a refined sample-based version of a decomposition of the instance into \"small\" and \"large\" variables, first introduced by Liu et al. [EC'21].","sentences":["In a prophet inequality problem, $n$ independent random variables are presented to a gambler one by one.","The gambler decides when to stop the sequence and obtains the most recent value as reward.","We evaluate a stopping rule by the worst-case ratio between its expected reward and the expectation of the maximum variable.","In the classic setting, the order is fixed, and the optimal ratio is known to be 1/2.","Three variants of this problem have been extensively studied: the prophet-secretary model, where variables arrive in uniformly random order; the free-order model, where the gambler chooses the arrival order; and the i.i.d. model, where the distributions are all the same, rendering the arrival order irrelevant.   ","Most of the literature assumes that distributions are known to the gambler.","Recent work has considered the question of what is achievable when the gambler has access only to a few samples per distribution.","Surprisingly, in the fixed-order case, a single sample from each distribution is enough to approximate the optimal ratio, but this is not the case in any of the three variants.   ","We provide a unified proof that for all three variants of the problem, a constant number of samples (independent of n) for each distribution is good enough to approximate the optimal ratios.   ","Prior to our work, this was known to be the case only in the i.i.d. variant.","We complement our result showing that our algorithms can be implemented in polynomial time.   ","A key ingredient in our proof is an existential result based on a minimax argument, which states that there must exist an algorithm that attains the optimal ratio and does not rely on the knowledge of the upper tail of the distributions.","A second key ingredient is a refined sample-based version of a decomposition of the instance into \"small\" and \"large\" variables, first introduced by Liu et al.","[EC'21]."],"url":"http://arxiv.org/abs/2311.09141v1"}
{"created":"2023-11-15 17:29:24","title":"Causal prediction models for medication safety monitoring: The diagnosis of vancomycin-induced acute kidney injury","abstract":"The current best practice approach for the retrospective diagnosis of adverse drug events (ADEs) in hospitalized patients relies on a full patient chart review and a formal causality assessment by multiple medical experts. This evaluation serves to qualitatively estimate the probability of causation (PC); the probability that a drug was a necessary cause of an adverse event. This practice is manual, resource intensive and prone to human biases, and may thus benefit from data-driven decision support. Here, we pioneer a causal modeling approach using observational data to estimate a lower bound of the PC (PC$_{low}$). This method includes two key causal inference components: (1) the target trial emulation framework and (2) estimation of individualized treatment effects using machine learning. We apply our method to the clinically relevant use-case of vancomycin-induced acute kidney injury in intensive care patients, and compare our causal model-based PC$_{low}$ estimates to qualitative estimates of the PC provided by a medical expert. Important limitations and potential improvements are discussed, and we conclude that future improved causal models could provide essential data-driven support for medication safety monitoring in hospitalized patients.","sentences":["The current best practice approach for the retrospective diagnosis of adverse drug events (ADEs) in hospitalized patients relies on a full patient chart review and a formal causality assessment by multiple medical experts.","This evaluation serves to qualitatively estimate the probability of causation (PC); the probability that a drug was a necessary cause of an adverse event.","This practice is manual, resource intensive and prone to human biases, and may thus benefit from data-driven decision support.","Here, we pioneer a causal modeling approach using observational data to estimate a lower bound of the PC (PC$_{low}$).","This method includes two key causal inference components: (1) the target trial emulation framework and (2) estimation of individualized treatment effects using machine learning.","We apply our method to the clinically relevant use-case of vancomycin-induced acute kidney injury in intensive care patients, and compare our causal model-based PC$_{low}$ estimates to qualitative estimates of the PC provided by a medical expert.","Important limitations and potential improvements are discussed, and we conclude that future improved causal models could provide essential data-driven support for medication safety monitoring in hospitalized patients."],"url":"http://arxiv.org/abs/2311.09137v1"}
{"created":"2023-11-15 17:27:14","title":"RRescue: Ranking LLM Responses to Enhance Reasoning Over Context","abstract":"Effectively using a given context is paramount for large language models. A context window can include task specifications, retrieved documents, previous conversations, and even model self-reflections, functioning similarly to episodic memory. While efforts are being made to expand the context window, studies indicate that LLMs do not use their context optimally for response generation. In this paper, we present a novel approach to optimize LLMs using ranking metrics, which teaches LLMs to rank a collection of contextually-grounded candidate responses. Rather than a traditional full ordering, we advocate for a partial ordering. This is because achieving consensus on the perfect order for system responses can be challenging. Our partial ordering is more robust, less sensitive to noise, and can be acquired through human labelers, heuristic functions, or model distillation. We test our system's improved contextual understanding using the latest benchmarks, including a new multi-document question answering dataset. We conduct ablation studies to understand crucial factors, such as how to gather candidate responses, determine their most suitable order, and balance supervised fine-tuning with ranking metrics. Our approach, named RRescue, suggests a promising avenue for enhancing LLMs' contextual understanding via response ranking.","sentences":["Effectively using a given context is paramount for large language models.","A context window can include task specifications, retrieved documents, previous conversations, and even model self-reflections, functioning similarly to episodic memory.","While efforts are being made to expand the context window, studies indicate that LLMs do not use their context optimally for response generation.","In this paper, we present a novel approach to optimize LLMs using ranking metrics, which teaches LLMs to rank a collection of contextually-grounded candidate responses.","Rather than a traditional full ordering, we advocate for a partial ordering.","This is because achieving consensus on the perfect order for system responses can be challenging.","Our partial ordering is more robust, less sensitive to noise, and can be acquired through human labelers, heuristic functions, or model distillation.","We test our system's improved contextual understanding using the latest benchmarks, including a new multi-document question answering dataset.","We conduct ablation studies to understand crucial factors, such as how to gather candidate responses, determine their most suitable order, and balance supervised fine-tuning with ranking metrics.","Our approach, named RRescue, suggests a promising avenue for enhancing LLMs' contextual understanding via response ranking."],"url":"http://arxiv.org/abs/2311.09136v1"}
{"created":"2023-11-15 17:26:28","title":"Scalable and Effective Generative Information Retrieval","abstract":"Recent research has shown that transformer networks can be used as differentiable search indexes by representing each document as a sequences of document ID tokens. These generative retrieval models cast the retrieval problem to a document ID generation problem for each given query. Despite their elegant design, existing generative retrieval models only perform well on artificially-constructed and small-scale collections. This has led to serious skepticism in the research community on their real-world impact. This paper represents an important milestone in generative retrieval research by showing, for the first time, that generative retrieval models can be trained to perform effectively on large-scale standard retrieval benchmarks. For doing so, we propose RIPOR- an optimization framework for generative retrieval that can be adopted by any encoder-decoder architecture. RIPOR is designed based on two often-overlooked fundamental design considerations in generative retrieval. First, given the sequential decoding nature of document ID generation, assigning accurate relevance scores to documents based on the whole document ID sequence is not sufficient. To address this issue, RIPOR introduces a novel prefix-oriented ranking optimization algorithm. Second, initial document IDs should be constructed based on relevance associations between queries and documents, instead of the syntactic and semantic information in the documents. RIPOR addresses this issue using a relevance-based document ID construction approach that quantizes relevance-based representations learned for documents. Evaluation on MSMARCO and TREC Deep Learning Track reveals that RIPOR surpasses state-of-the-art generative retrieval models by a large margin (e.g., 30.5% MRR improvements on MS MARCO Dev Set), and perform better on par with popular dense retrieval models.","sentences":["Recent research has shown that transformer networks can be used as differentiable search indexes by representing each document as a sequences of document ID tokens.","These generative retrieval models cast the retrieval problem to a document ID generation problem for each given query.","Despite their elegant design, existing generative retrieval models only perform well on artificially-constructed and small-scale collections.","This has led to serious skepticism in the research community on their real-world impact.","This paper represents an important milestone in generative retrieval research by showing, for the first time, that generative retrieval models can be trained to perform effectively on large-scale standard retrieval benchmarks.","For doing so, we propose RIPOR-","an optimization framework for generative retrieval that can be adopted by any encoder-decoder architecture.","RIPOR is designed based on two often-overlooked fundamental design considerations in generative retrieval.","First, given the sequential decoding nature of document ID generation, assigning accurate relevance scores to documents based on the whole document ID sequence is not sufficient.","To address this issue, RIPOR introduces a novel prefix-oriented ranking optimization algorithm.","Second, initial document IDs should be constructed based on relevance associations between queries and documents, instead of the syntactic and semantic information in the documents.","RIPOR addresses this issue using a relevance-based document ID construction approach that quantizes relevance-based representations learned for documents.","Evaluation on MSMARCO and TREC Deep Learning Track reveals that RIPOR surpasses state-of-the-art generative retrieval models by a large margin (e.g., 30.5% MRR improvements on MS MARCO Dev Set), and perform better on par with popular dense retrieval models."],"url":"http://arxiv.org/abs/2311.09134v1"}
{"created":"2023-11-15 17:21:58","title":"Aligning Neural Machine Translation Models: Human Feedback in Training and Inference","abstract":"Reinforcement learning from human feedback (RLHF) is a recent technique to improve the quality of the text generated by a language model, making it closer to what humans would generate. A core ingredient in RLHF's success in aligning and improving large language models (LLMs) is its reward model, trained using human feedback on model outputs. In machine translation (MT), where metrics trained from human annotations can readily be used as reward models, recent methods using minimum Bayes risk decoding and reranking have succeeded in improving the final quality of translation. In this study, we comprehensively explore and compare techniques for integrating quality metrics as reward models into the MT pipeline. This includes using the reward model for data filtering, during the training phase through RL, and at inference time by employing reranking techniques, and we assess the effects of combining these in a unified approach. Our experimental results, conducted across multiple translation tasks, underscore the crucial role of effective data filtering, based on estimated quality, in harnessing the full potential of RL in enhancing MT quality. Furthermore, our findings demonstrate the effectiveness of combining RL training with reranking techniques, showcasing substantial improvements in translation quality.","sentences":["Reinforcement learning from human feedback (RLHF) is a recent technique to improve the quality of the text generated by a language model, making it closer to what humans would generate.","A core ingredient in RLHF's success in aligning and improving large language models (LLMs) is its reward model, trained using human feedback on model outputs.","In machine translation (MT), where metrics trained from human annotations can readily be used as reward models, recent methods using minimum Bayes risk decoding and reranking have succeeded in improving the final quality of translation.","In this study, we comprehensively explore and compare techniques for integrating quality metrics as reward models into the MT pipeline.","This includes using the reward model for data filtering, during the training phase through RL, and at inference time by employing reranking techniques, and we assess the effects of combining these in a unified approach.","Our experimental results, conducted across multiple translation tasks, underscore the crucial role of effective data filtering, based on estimated quality, in harnessing the full potential of RL in enhancing MT quality.","Furthermore, our findings demonstrate the effectiveness of combining RL training with reranking techniques, showcasing substantial improvements in translation quality."],"url":"http://arxiv.org/abs/2311.09132v1"}
{"created":"2023-11-15 17:20:20","title":"Social Meme-ing: Measuring Linguistic Variation in Memes","abstract":"Much work in the space of NLP has used computational methods to explore sociolinguistic variation in text. In this paper, we argue that memes, as multimodal forms of language comprised of visual templates and text, also exhibit meaningful social variation. We construct a computational pipeline to cluster individual instances of memes into templates and semantic variables, taking advantage of their multimodal structure in doing so. We apply this method to a large collection of meme images from Reddit and make available the resulting \\textsc{SemanticMemes} dataset of 3.8M images clustered by their semantic function. We use these clusters to analyze linguistic variation in memes, discovering not only that socially meaningful variation in meme usage exists between subreddits, but that patterns of meme innovation and acculturation within these communities align with previous findings on written language.","sentences":["Much work in the space of NLP has used computational methods to explore sociolinguistic variation in text.","In this paper, we argue that memes, as multimodal forms of language comprised of visual templates and text, also exhibit meaningful social variation.","We construct a computational pipeline to cluster individual instances of memes into templates and semantic variables, taking advantage of their multimodal structure in doing so.","We apply this method to a large collection of meme images from Reddit and make available the resulting \\textsc{SemanticMemes} dataset of 3.8M images clustered by their semantic function.","We use these clusters to analyze linguistic variation in memes, discovering not only that socially meaningful variation in meme usage exists between subreddits, but that patterns of meme innovation and acculturation within these communities align with previous findings on written language."],"url":"http://arxiv.org/abs/2311.09130v1"}
{"created":"2023-11-15 17:17:49","title":"Fast Detection of Phase Transitions with Multi-Task Learning-by-Confusion","abstract":"Machine learning has been successfully used to study phase transitions. One of the most popular approaches to identifying critical points from data without prior knowledge of the underlying phases is the learning-by-confusion scheme. As input, it requires system samples drawn from a grid of the parameter whose change is associated with potential phase transitions. Up to now, the scheme required training a distinct binary classifier for each possible splitting of the grid into two sides, resulting in a computational cost that scales linearly with the number of grid points. In this work, we propose and showcase an alternative implementation that only requires the training of a single multi-class classifier. Ideally, such multi-task learning eliminates the scaling with respect to the number of grid points. In applications to the Ising model and an image dataset generated with Stable Diffusion, we find significant speedups that closely correspond to the ideal case, with only minor deviations.","sentences":["Machine learning has been successfully used to study phase transitions.","One of the most popular approaches to identifying critical points from data without prior knowledge of the underlying phases is the learning-by-confusion scheme.","As input, it requires system samples drawn from a grid of the parameter whose change is associated with potential phase transitions.","Up to now, the scheme required training a distinct binary classifier for each possible splitting of the grid into two sides, resulting in a computational cost that scales linearly with the number of grid points.","In this work, we propose and showcase an alternative implementation that only requires the training of a single multi-class classifier.","Ideally, such multi-task learning eliminates the scaling with respect to the number of grid points.","In applications to the Ising model and an image dataset generated with Stable Diffusion, we find significant speedups that closely correspond to the ideal case, with only minor deviations."],"url":"http://arxiv.org/abs/2311.09128v1"}
{"created":"2023-11-15 17:17:39","title":"Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts","abstract":"Existing work on jailbreak Multimodal Large Language Models (MLLMs) has focused primarily on adversarial examples in model inputs, with less attention to vulnerabilities in model APIs. To fill the research gap, we carry out the following work: 1) We discover a system prompt leakage vulnerability in GPT-4V. Through carefully designed dialogue, we successfully steal the internal system prompts of GPT-4V. This finding indicates potential exploitable security risks in MLLMs; 2)Based on the acquired system prompts, we propose a novel MLLM jailbreaking attack method termed SASP (Self-Adversarial Attack via System Prompt). By employing GPT-4 as a red teaming tool against itself, we aim to search for potential jailbreak prompts leveraging stolen system prompts. Furthermore, in pursuit of better performance, we also add human modification based on GPT-4's analysis, which further improves the attack success rate to 98.7\\%; 3) We evaluated the effect of modifying system prompts to defend against jailbreaking attacks. Results show that appropriately designed system prompts can significantly reduce jailbreak success rates. Overall, our work provides new insights into enhancing MLLM security, demonstrating the important role of system prompts in jailbreaking, which could be leveraged to greatly facilitate jailbreak success rates while also holding the potential for defending against jailbreaks.","sentences":["Existing work on jailbreak Multimodal Large Language Models (MLLMs) has focused primarily on adversarial examples in model inputs, with less attention to vulnerabilities in model APIs.","To fill the research gap, we carry out the following work: 1) We discover a system prompt leakage vulnerability in GPT-4V. Through carefully designed dialogue, we successfully steal the internal system prompts of GPT-4V. This finding indicates potential exploitable security risks in MLLMs; 2)Based on the acquired system prompts, we propose a novel MLLM jailbreaking attack method termed SASP (Self-Adversarial Attack via System Prompt).","By employing GPT-4 as a red teaming tool against itself, we aim to search for potential jailbreak prompts leveraging stolen system prompts.","Furthermore, in pursuit of better performance, we also add human modification based on GPT-4's analysis, which further improves the attack success rate to 98.7\\%; 3) We evaluated the effect of modifying system prompts to defend against jailbreaking attacks.","Results show that appropriately designed system prompts can significantly reduce jailbreak success rates.","Overall, our work provides new insights into enhancing MLLM security, demonstrating the important role of system prompts in jailbreaking, which could be leveraged to greatly facilitate jailbreak success rates while also holding the potential for defending against jailbreaks."],"url":"http://arxiv.org/abs/2311.09127v1"}
{"created":"2023-11-15 17:09:54","title":"Universal NER: A Gold-Standard Multilingual Named Entity Recognition Benchmark","abstract":"We introduce Universal NER (UNER), an open, community-driven project to develop gold-standard NER benchmarks in many languages. The overarching goal of UNER is to provide high-quality, cross-lingually consistent annotations to facilitate and standardize multilingual NER research. UNER v1 contains 18 datasets annotated with named entities in a cross-lingual consistent schema across 12 diverse languages. In this paper, we detail the dataset creation and composition of UNER; we also provide initial modeling baselines on both in-language and cross-lingual learning settings. We release the data, code, and fitted models to the public.","sentences":["We introduce Universal NER (UNER), an open, community-driven project to develop gold-standard NER benchmarks in many languages.","The overarching goal of UNER is to provide high-quality, cross-lingually consistent annotations to facilitate and standardize multilingual NER research.","UNER v1 contains 18 datasets annotated with named entities in a cross-lingual consistent schema across 12 diverse languages.","In this paper, we detail the dataset creation and composition of UNER; we also provide initial modeling baselines on both in-language and cross-lingual learning settings.","We release the data, code, and fitted models to the public."],"url":"http://arxiv.org/abs/2311.09122v1"}
{"created":"2023-11-15 17:08:09","title":"WildlifeDatasets: An open-source toolkit for animal re-identification","abstract":"In this paper, we present WildlifeDatasets (https://github.com/WildlifeDatasets/wildlife-datasets) - an open-source toolkit intended primarily for ecologists and computer-vision / machine-learning researchers. The WildlifeDatasets is written in Python, allows straightforward access to publicly available wildlife datasets, and provides a wide variety of methods for dataset pre-processing, performance analysis, and model fine-tuning. We showcase the toolkit in various scenarios and baseline experiments, including, to the best of our knowledge, the most comprehensive experimental comparison of datasets and methods for wildlife re-identification, including both local descriptors and deep learning approaches. Furthermore, we provide the first-ever foundation model for individual re-identification within a wide range of species - MegaDescriptor - that provides state-of-the-art performance on animal re-identification datasets and outperforms other pre-trained models such as CLIP and DINOv2 by a significant margin. To make the model available to the general public and to allow easy integration with any existing wildlife monitoring applications, we provide multiple MegaDescriptor flavors (i.e., Small, Medium, and Large) through the HuggingFace hub (https://huggingface.co/BVRA).","sentences":["In this paper, we present WildlifeDatasets (https://github.com/WildlifeDatasets/wildlife-datasets) - an open-source toolkit intended primarily for ecologists and computer-vision / machine-learning researchers.","The WildlifeDatasets is written in Python, allows straightforward access to publicly available wildlife datasets, and provides a wide variety of methods for dataset pre-processing, performance analysis, and model fine-tuning.","We showcase the toolkit in various scenarios and baseline experiments, including, to the best of our knowledge, the most comprehensive experimental comparison of datasets and methods for wildlife re-identification, including both local descriptors and deep learning approaches.","Furthermore, we provide the first-ever foundation model for individual re-identification within a wide range of species - MegaDescriptor - that provides state-of-the-art performance on animal re-identification datasets and outperforms other pre-trained models such as CLIP and DINOv2 by a significant margin.","To make the model available to the general public and to allow easy integration with any existing wildlife monitoring applications, we provide multiple MegaDescriptor flavors (i.e., Small, Medium, and Large) through the HuggingFace hub (https://huggingface.co/BVRA)."],"url":"http://arxiv.org/abs/2311.09118v1"}
{"created":"2023-11-15 17:07:44","title":"R-Spin: Efficient Speaker and Noise-invariant Representation Learning with Acoustic Pieces","abstract":"This paper introduces Robust Spin (R-Spin), a data-efficient self-supervised fine-tuning framework for speaker and noise-invariant speech representations by learning discrete acoustic units with speaker-invariant clustering (Spin). R-Spin resolves Spin's issues and enhances content representations by learning to predict acoustic pieces. R-Spin offers a 12X reduction in computational resources compared to previous state-of-the-art methods while outperforming them in severely distorted speech scenarios. This paper provides detailed analyses to show how discrete units contribute to speech encoder training and improving robustness in diverse acoustic environments.","sentences":["This paper introduces Robust Spin (R-Spin), a data-efficient self-supervised fine-tuning framework for speaker and noise-invariant speech representations by learning discrete acoustic units with speaker-invariant clustering (Spin).","R-Spin resolves Spin's issues and enhances content representations by learning to predict acoustic pieces.","R-Spin offers a 12X reduction in computational resources compared to previous state-of-the-art methods while outperforming them in severely distorted speech scenarios.","This paper provides detailed analyses to show how discrete units contribute to speech encoder training and improving robustness in diverse acoustic environments."],"url":"http://arxiv.org/abs/2311.09117v1"}
{"created":"2023-11-15 17:06:26","title":"HEALNet -- Hybrid Multi-Modal Fusion for Heterogeneous Biomedical Data","abstract":"Technological advances in medical data collection such as high-resolution histopathology and high-throughput genomic sequencing have contributed to the rising requirement for multi-modal biomedical modelling, specifically for image, tabular, and graph data. Most multi-modal deep learning approaches use modality-specific architectures that are trained separately and cannot capture the crucial cross-modal information that motivates the integration of different data sources. This paper presents the Hybrid Early-fusion Attention Learning Network (HEALNet): a flexible multi-modal fusion architecture, which a) preserves modality-specific structural information, b) captures the cross-modal interactions and structural information in a shared latent space, c) can effectively handle missing modalities during training and inference, and d) enables intuitive model inspection by learning on the raw data input instead of opaque embeddings. We conduct multi-modal survival analysis on Whole Slide Images and Multi-omic data on four cancer cohorts of The Cancer Genome Atlas (TCGA). HEALNet achieves state-of-the-art performance, substantially improving over both uni-modal and recent multi-modal baselines, whilst being robust in scenarios with missing modalities.","sentences":["Technological advances in medical data collection such as high-resolution histopathology and high-throughput genomic sequencing have contributed to the rising requirement for multi-modal biomedical modelling, specifically for image, tabular, and graph data.","Most multi-modal deep learning approaches use modality-specific architectures that are trained separately and cannot capture the crucial cross-modal information that motivates the integration of different data sources.","This paper presents the Hybrid Early-fusion Attention Learning Network (HEALNet): a flexible multi-modal fusion architecture, which a) preserves modality-specific structural information, b) captures the cross-modal interactions and structural information in a shared latent space, c) can effectively handle missing modalities during training and inference, and d) enables intuitive model inspection by learning on the raw data input instead of opaque embeddings.","We conduct multi-modal survival analysis on Whole Slide Images and Multi-omic data on four cancer cohorts of The Cancer Genome Atlas (TCGA).","HEALNet achieves state-of-the-art performance, substantially improving over both uni-modal and recent multi-modal baselines, whilst being robust in scenarios with missing modalities."],"url":"http://arxiv.org/abs/2311.09115v1"}
{"created":"2023-11-15 17:04:56","title":"Ever: Mitigating Hallucination in Large Language Models through Real-Time Verification and Rectification","abstract":"Large Language Models (LLMs) have demonstrated remarkable proficiency in generating fluent text. However, they often encounter the challenge of generating inaccurate or hallucinated content. This issue is common in both non-retrieval-based generation and retrieval-augmented generation approaches, and existing post-hoc rectification methods may not address the accumulated hallucination errors that may be caused by the \"snowballing\" issue, especially in reasoning tasks. To tackle these challenges, we introduce a novel approach called Real-time Verification and Rectification (Ever). Instead of waiting until the end of the generation process to rectify hallucinations, Ever employs a real-time, step-wise generation and hallucination rectification strategy. The primary objective is to detect and rectify hallucinations as they occur during the text generation process. When compared to both retrieval-based and non-retrieval-based baselines, Ever demonstrates a significant improvement in generating trustworthy and factually accurate text across a diverse range of tasks, including short-form QA, biography generation, and multi-hop reasoning.","sentences":["Large Language Models (LLMs) have demonstrated remarkable proficiency in generating fluent text.","However, they often encounter the challenge of generating inaccurate or hallucinated content.","This issue is common in both non-retrieval-based generation and retrieval-augmented generation approaches, and existing post-hoc rectification methods may not address the accumulated hallucination errors that may be caused by the \"snowballing\" issue, especially in reasoning tasks.","To tackle these challenges, we introduce a novel approach called Real-time Verification and Rectification (Ever).","Instead of waiting until the end of the generation process to rectify hallucinations, Ever employs a real-time, step-wise generation and hallucination rectification strategy.","The primary objective is to detect and rectify hallucinations as they occur during the text generation process.","When compared to both retrieval-based and non-retrieval-based baselines, Ever demonstrates a significant improvement in generating trustworthy and factually accurate text across a diverse range of tasks, including short-form QA, biography generation, and multi-hop reasoning."],"url":"http://arxiv.org/abs/2311.09114v1"}
{"created":"2023-11-15 17:01:25","title":"Graph Compression with Side Information at the Decoder","abstract":"In this paper, we study the problem of graph compression with side information at the decoder. The focus is on the situation when an unlabelled graph (which is also referred to as a structure) is to be compressed or is available as side information. For correlated Erd\\H{o}s-R\\'enyi weighted random graphs, we give a precise characterization of the smallest rate at which a labelled graph or its structure can be compressed with aid of a correlated labelled graph or its structure at the decoder. We approach this problem by using the entropy-spectrum framework and establish some convergence results for conditional distributions involving structures, which play a key role in the construction of an optimal encoding and decoding scheme. Our proof essentially uses the fact that, in the considered correlated Erd\\H{o}s-R\\'enyi model, the structure retains most of the information about the labelled graph. Furthermore, we consider the case of unweighted graphs and present how the optimal decoding can be done using the notion of graph alignment.","sentences":["In this paper, we study the problem of graph compression with side information at the decoder.","The focus is on the situation when an unlabelled graph (which is also referred to as a structure) is to be compressed or is available as side information.","For correlated Erd\\H{o}s-R\\'enyi weighted random graphs, we give a precise characterization of the smallest rate at which a labelled graph or its structure can be compressed with aid of a correlated labelled graph or its structure at the decoder.","We approach this problem by using the entropy-spectrum framework and establish some convergence results for conditional distributions involving structures, which play a key role in the construction of an optimal encoding and decoding scheme.","Our proof essentially uses the fact that, in the considered correlated Erd\\H{o}s-R\\'enyi model, the structure retains most of the information about the labelled graph.","Furthermore, we consider the case of unweighted graphs and present how the optimal decoding can be done using the notion of graph alignment."],"url":"http://arxiv.org/abs/2311.09111v1"}
{"created":"2023-11-15 16:56:49","title":"Does Pre-trained Language Model Actually Infer Unseen Links in Knowledge Graph Completion?","abstract":"Knowledge graphs (KGs) consist of links that describe relationships between entities. Due to the difficulty of manually enumerating all relationships between entities, automatically completing them is essential for KGs. Knowledge Graph Completion (KGC) is a task that infers unseen relationships between entities in a KG. Traditional embedding-based KGC methods, such as RESCAL, TransE, DistMult, ComplEx, RotatE, HAKE, HousE, etc., infer missing links using only the knowledge from training data. In contrast, the recent Pre-trained Language Model (PLM)-based KGC utilizes knowledge obtained during pre-training. Therefore, PLM-based KGC can estimate missing links between entities by reusing memorized knowledge from pre-training without inference. This approach is problematic because building KGC models aims to infer unseen links between entities. However, conventional evaluations in KGC do not consider inference and memorization abilities separately. Thus, a PLM-based KGC method, which achieves high performance in current KGC evaluations, may be ineffective in practical applications. To address this issue, we analyze whether PLM-based KGC methods make inferences or merely access memorized knowledge. For this purpose, we propose a method for constructing synthetic datasets specified in this analysis and conclude that PLMs acquire the inference abilities required for KGC through pre-training, even though the performance improvements mostly come from textual information of entities and relations.","sentences":["Knowledge graphs (KGs) consist of links that describe relationships between entities.","Due to the difficulty of manually enumerating all relationships between entities, automatically completing them is essential for KGs.","Knowledge Graph Completion (KGC) is a task that infers unseen relationships between entities in a KG.","Traditional embedding-based KGC methods, such as RESCAL, TransE, DistMult, ComplEx, RotatE, HAKE, HousE, etc., infer missing links using only the knowledge from training data.","In contrast, the recent Pre-trained Language Model (PLM)-based KGC utilizes knowledge obtained during pre-training.","Therefore, PLM-based KGC can estimate missing links between entities by reusing memorized knowledge from pre-training without inference.","This approach is problematic because building KGC models aims to infer unseen links between entities.","However, conventional evaluations in KGC do not consider inference and memorization abilities separately.","Thus, a PLM-based KGC method, which achieves high performance in current KGC evaluations, may be ineffective in practical applications.","To address this issue, we analyze whether PLM-based KGC methods make inferences or merely access memorized knowledge.","For this purpose, we propose a method for constructing synthetic datasets specified in this analysis and conclude that PLMs acquire the inference abilities required for KGC through pre-training, even though the performance improvements mostly come from textual information of entities and relations."],"url":"http://arxiv.org/abs/2311.09109v1"}
{"created":"2023-11-15 16:53:35","title":"\"We Demand Justice!\": Towards Grounding Political Text in Social Context","abstract":"Social media discourse from US politicians frequently consists of 'seemingly similar language used by opposing sides of the political spectrum'. But often, it translates to starkly contrasting real-world actions. For instance, \"We need to keep our students safe from mass shootings\" may signal either \"arming teachers to stop the shooter\" or \"banning guns to reduce mass shootings\" depending on who says it and their political stance on the issue. In this paper, we define and characterize the context that is required to fully understand such ambiguous statements in a computational setting and ground them in real-world entities, actions, and attitudes. To that end, we propose two challenging datasets that require an understanding of the real-world context of the text to be solved effectively. We benchmark these datasets against baselines built upon large pre-trained models such as BERT, RoBERTa, GPT-3, etc. Additionally, we develop and benchmark more structured baselines building upon existing 'Discourse Contextualization Framework' and 'Political Actor Representation' models. We perform analysis of the datasets and baseline predictions to obtain further insights into the pragmatic language understanding challenges posed by the proposed social grounding tasks.","sentences":["Social media discourse from US politicians frequently consists of 'seemingly similar language used by opposing sides of the political spectrum'.","But often, it translates to starkly contrasting real-world actions.","For instance, \"We need to keep our students safe from mass shootings\" may signal either \"arming teachers to stop the shooter\" or \"banning guns to reduce mass shootings\" depending on who says it and their political stance on the issue.","In this paper, we define and characterize the context that is required to fully understand such ambiguous statements in a computational setting and ground them in real-world entities, actions, and attitudes.","To that end, we propose two challenging datasets that require an understanding of the real-world context of the text to be solved effectively.","We benchmark these datasets against baselines built upon large pre-trained models such as BERT, RoBERTa, GPT-3, etc.","Additionally, we develop and benchmark more structured baselines building upon existing 'Discourse Contextualization Framework' and 'Political Actor Representation' models.","We perform analysis of the datasets and baseline predictions to obtain further insights into the pragmatic language understanding challenges posed by the proposed social grounding tasks."],"url":"http://arxiv.org/abs/2311.09106v1"}
{"created":"2023-11-15 16:52:14","title":"MAVEN-Arg: Completing the Puzzle of All-in-One Event Understanding Dataset with Event Argument Annotation","abstract":"Understanding events in texts is a core objective of natural language understanding, which requires detecting event occurrences, extracting event arguments, and analyzing inter-event relationships. However, due to the annotation challenges brought by task complexity, a large-scale dataset covering the full process of event understanding has long been absent. In this paper, we introduce MAVEN-Arg, which augments MAVEN datasets with event argument annotations, making the first all-in-one dataset supporting event detection, event argument extraction (EAE), and event relation extraction. As an EAE benchmark, MAVEN-Arg offers three main advantages: (1) a comprehensive schema covering 162 event types and 612 argument roles, all with expert-written definitions and examples; (2) a large data scale, containing 98,591 events and 290,613 arguments obtained with laborious human annotation; (3) the exhaustive annotation supporting all task variants of EAE, which annotates both entity and non-entity event arguments in document level. Experiments indicate that MAVEN-Arg is quite challenging for both fine-tuned EAE models and proprietary large language models (LLMs). Furthermore, to demonstrate the benefits of an all-in-one dataset, we preliminarily explore a potential application, future event prediction, with LLMs. MAVEN-Arg and our code can be obtained from https://github.com/THU-KEG/MAVEN-Argument.","sentences":["Understanding events in texts is a core objective of natural language understanding, which requires detecting event occurrences, extracting event arguments, and analyzing inter-event relationships.","However, due to the annotation challenges brought by task complexity, a large-scale dataset covering the full process of event understanding has long been absent.","In this paper, we introduce MAVEN-Arg, which augments MAVEN datasets with event argument annotations, making the first all-in-one dataset supporting event detection, event argument extraction (EAE), and event relation extraction.","As an EAE benchmark, MAVEN-Arg offers three main advantages: (1) a comprehensive schema covering 162 event types and 612 argument roles, all with expert-written definitions and examples; (2) a large data scale, containing 98,591 events and 290,613 arguments obtained with laborious human annotation; (3) the exhaustive annotation supporting all task variants of EAE, which annotates both entity and non-entity event arguments in document level.","Experiments indicate that MAVEN-Arg is quite challenging for both fine-tuned EAE models and proprietary large language models (LLMs).","Furthermore, to demonstrate the benefits of an all-in-one dataset, we preliminarily explore a potential application, future event prediction, with LLMs.","MAVEN-Arg and our code can be obtained from https://github.com/THU-KEG/MAVEN-Argument."],"url":"http://arxiv.org/abs/2311.09105v1"}
{"created":"2023-11-15 16:51:18","title":"Cross-view and Cross-pose Completion for 3D Human Understanding","abstract":"Human perception and understanding is a major domain of computer vision which, like many other vision subdomains recently, stands to gain from the use of large models pre-trained on large datasets. We hypothesize that the most common pre-training strategy of relying on general purpose, object-centric image datasets such as ImageNet, is limited by an important domain shift. On the other hand, collecting domain specific ground truth such as 2D or 3D labels does not scale well. Therefore, we propose a pre-training approach based on self-supervised learning that works on human-centric data using only images. Our method uses pairs of images of humans: the first is partially masked and the model is trained to reconstruct the masked parts given the visible ones and a second image. It relies on both stereoscopic (cross-view) pairs, and temporal (cross-pose) pairs taken from videos, in order to learn priors about 3D as well as human motion. We pre-train a model for body-centric tasks and one for hand-centric tasks. With a generic transformer architecture, these models outperform existing self-supervised pre-training methods on a wide set of human-centric downstream tasks, and obtain state-of-the-art performance for instance when fine-tuning for model-based and model-free human mesh recovery.","sentences":["Human perception and understanding is a major domain of computer vision which, like many other vision subdomains recently, stands to gain from the use of large models pre-trained on large datasets.","We hypothesize that the most common pre-training strategy of relying on general purpose, object-centric image datasets such as ImageNet, is limited by an important domain shift.","On the other hand, collecting domain specific ground truth such as 2D or 3D labels does not scale well.","Therefore, we propose a pre-training approach based on self-supervised learning that works on human-centric data using only images.","Our method uses pairs of images of humans: the first is partially masked and the model is trained to reconstruct the masked parts given the visible ones and a second image.","It relies on both stereoscopic (cross-view) pairs, and temporal (cross-pose) pairs taken from videos, in order to learn priors about 3D as well as human motion.","We pre-train a model for body-centric tasks and one for hand-centric tasks.","With a generic transformer architecture, these models outperform existing self-supervised pre-training methods on a wide set of human-centric downstream tasks, and obtain state-of-the-art performance for instance when fine-tuning for model-based and model-free human mesh recovery."],"url":"http://arxiv.org/abs/2311.09104v1"}
{"created":"2023-11-15 16:50:01","title":"Guided Scale Space Radon Transform for linear structures detection","abstract":"Using integral transforms to the end of lines detection in images with complex background, makes the detection a hard task needing additional processing to manage the detection. As an integral transform, the Scale Space Radon Transform (SSRT) suffers from such drawbacks, even with its great abilities for thick lines detection. In this work, we propose a method to address this issue for automatic detection of thick linear structures in gray scale and binary images using the SSRT, whatever the image background content. This method involves the calculated Hessian orientations of the investigated image while computing its SSRT, in such a way that linear structures are emphasized in the SSRT space. As a consequence, the subsequent maxima detection in the SSRT space is done on a modified transform space freed from unwanted parts and, consequently, from irrelevant peaks that usually drown the peaks representing lines. Besides, highlighting the linear structure in the SSRT space permitting, thus, to efficiently detect lines of different thickness in synthetic and real images, the experiments show also the method robustness against noise and complex background.","sentences":["Using integral transforms to the end of lines detection in images with complex background, makes the detection a hard task needing additional processing to manage the detection.","As an integral transform, the Scale Space Radon Transform (SSRT) suffers from such drawbacks, even with its great abilities for thick lines detection.","In this work, we propose a method to address this issue for automatic detection of thick linear structures in gray scale and binary images using the SSRT, whatever the image background content.","This method involves the calculated Hessian orientations of the investigated image while computing its SSRT, in such a way that linear structures are emphasized in the SSRT space.","As a consequence, the subsequent maxima detection in the SSRT space is done on a modified transform space freed from unwanted parts and, consequently, from irrelevant peaks that usually drown the peaks representing lines.","Besides, highlighting the linear structure in the SSRT space permitting, thus, to efficiently detect lines of different thickness in synthetic and real images, the experiments show also the method robustness against noise and complex background."],"url":"http://arxiv.org/abs/2311.09103v1"}
{"created":"2023-11-15 16:47:57","title":"Towards A Unified View of Answer Calibration for Multi-Step Reasoning","abstract":"Large Language Models (LLMs) employing Chain-of-Thought (CoT) prompting have broadened the scope for improving multi-step reasoning capabilities. Usually, answer calibration strategies such as step-level or path-level calibration play a vital role in multi-step reasoning. While effective, there remains a significant gap in our understanding of the key factors that drive their success. In this paper, we break down the design of recent answer calibration strategies and present a unified view which establishes connections between them. We then conduct a thorough evaluation on these strategies from a unified view, systematically scrutinizing step-level and path-level answer calibration across multiple paths. Our study holds the potential to illuminate key insights for optimizing multi-step reasoning with answer calibration.","sentences":["Large Language Models (LLMs) employing Chain-of-Thought (CoT) prompting have broadened the scope for improving multi-step reasoning capabilities.","Usually, answer calibration strategies such as step-level or path-level calibration play a vital role in multi-step reasoning.","While effective, there remains a significant gap in our understanding of the key factors that drive their success.","In this paper, we break down the design of recent answer calibration strategies and present a unified view which establishes connections between them.","We then conduct a thorough evaluation on these strategies from a unified view, systematically scrutinizing step-level and path-level answer calibration across multiple paths.","Our study holds the potential to illuminate key insights for optimizing multi-step reasoning with answer calibration."],"url":"http://arxiv.org/abs/2311.09101v1"}
{"created":"2023-11-15 16:42:29","title":"Defending Large Language Models Against Jailbreaking Attacks Through Goal Prioritization","abstract":"Large Language Models (LLMs) continue to advance in their capabilities, yet this progress is accompanied by a growing array of safety risks. While significant attention has been dedicated to exploiting weaknesses in LLMs through jailbreaking attacks, there remains a paucity of exploration into defending against these attacks. We point out a pivotal factor contributing to the success of jailbreaks: the inherent conflict between the goals of being helpful and ensuring safety. To counter jailbreaking attacks, we propose to integrate goal prioritization at both training and inference stages. Implementing goal prioritization during inference substantially diminishes the Attack Success Rate (ASR) of jailbreaking attacks, reducing it from 66.4% to 2.0% for ChatGPT and from 68.2% to 19.4% for Vicuna-33B, without compromising general performance. Furthermore, integrating the concept of goal prioritization into the training phase reduces the ASR from 71.0% to 6.6% for LLama2-13B. Remarkably, even in scenarios where no jailbreaking samples are included during training, our approach slashes the ASR by half, decreasing it from 71.0% to 34.0%. Additionally, our findings reveal that while stronger LLMs face greater safety risks, they also possess a greater capacity to be steered towards defending against such attacks. We hope our work could contribute to the comprehension of jailbreaking attacks and defenses, and shed light on the relationship between LLMs' capability and safety. Our code will be available at \\url{https://github.com/thu-coai/JailbreakDefense_GoalPriority}.","sentences":["Large Language Models (LLMs) continue to advance in their capabilities, yet this progress is accompanied by a growing array of safety risks.","While significant attention has been dedicated to exploiting weaknesses in LLMs through jailbreaking attacks, there remains a paucity of exploration into defending against these attacks.","We point out a pivotal factor contributing to the success of jailbreaks: the inherent conflict between the goals of being helpful and ensuring safety.","To counter jailbreaking attacks, we propose to integrate goal prioritization at both training and inference stages.","Implementing goal prioritization during inference substantially diminishes the Attack Success Rate (ASR) of jailbreaking attacks, reducing it from 66.4% to 2.0% for ChatGPT and from 68.2% to 19.4% for Vicuna-33B, without compromising general performance.","Furthermore, integrating the concept of goal prioritization into the training phase reduces the ASR from 71.0% to 6.6% for LLama2-13B. Remarkably, even in scenarios where no jailbreaking samples are included during training, our approach slashes the ASR by half, decreasing it from 71.0% to 34.0%.","Additionally, our findings reveal that while stronger LLMs face greater safety risks, they also possess a greater capacity to be steered towards defending against such attacks.","We hope our work could contribute to the comprehension of jailbreaking attacks and defenses, and shed light on the relationship between LLMs' capability and safety.","Our code will be available at \\url{https://github.com/thu-coai/JailbreakDefense_GoalPriority}."],"url":"http://arxiv.org/abs/2311.09096v1"}
{"created":"2023-11-15 16:42:18","title":"New Graph Decompositions and Combinatorial Boolean Matrix Multiplication Algorithms","abstract":"We revisit the fundamental Boolean Matrix Multiplication (BMM) problem. With the invention of algebraic fast matrix multiplication over 50 years ago, it also became known that BMM can be solved in truly subcubic $O(n^\\omega)$ time, where $\\omega<3$; much work has gone into bringing $\\omega$ closer to $2$. Since then, a parallel line of work has sought comparably fast combinatorial algorithms but with limited success. The naive $O(n^3)$-time algorithm was initially improved by a $\\log^2{n}$ factor [Arlazarov et al.; RAS'70], then by $\\log^{2.25}{n}$ [Bansal and Williams; FOCS'09], then by $\\log^3{n}$ [Chan; SODA'15], and finally by $\\log^4{n}$ [Yu; ICALP'15].   We design a combinatorial algorithm for BMM running in time $n^3 / 2^{\\Omega(\\sqrt[7]{\\log n})}$ -- a speed-up over cubic time that is stronger than any poly-log factor. This comes tantalizingly close to refuting the conjecture from the 90s that truly subcubic combinatorial algorithms for BMM are impossible. This popular conjecture is the basis for dozens of fine-grained hardness results.   Our main technical contribution is a new regularity decomposition theorem for Boolean matrices (or equivalently, bipartite graphs) under a notion of regularity that was recently introduced and analyzed analytically in the context of communication complexity [Kelley, Lovett, Meka; arXiv'23], and is related to a similar notion from the recent work on $3$-term arithmetic progression free sets [Kelley, Meka; FOCS'23].","sentences":["We revisit the fundamental Boolean Matrix Multiplication (BMM) problem.","With the invention of algebraic fast matrix multiplication over 50 years ago, it also became known that BMM can be solved in truly subcubic $O(n^\\omega)$ time, where $\\omega<3$; much work has gone into bringing $\\omega$ closer to $2$. Since then, a parallel line of work has sought comparably fast combinatorial algorithms but with limited success.","The naive $O(n^3)$-time algorithm was initially improved by a $\\log^2{n}$ factor [Arlazarov et al.; RAS'70], then by $\\log^{2.25}{n}$","[Bansal and Williams; FOCS'09], then by $\\log^3{n}$ [Chan; SODA'15], and finally by $\\log^4{n}$","[Yu; ICALP'15].   ","We design a combinatorial algorithm for BMM running in time $n^3 / 2^{\\Omega(\\sqrt[7]{\\log n})}$ -- a speed-up over cubic time that is stronger than any poly-log factor.","This comes tantalizingly close to refuting the conjecture from the 90s that truly subcubic combinatorial algorithms for BMM are impossible.","This popular conjecture is the basis for dozens of fine-grained hardness results.   ","Our main technical contribution is a new regularity decomposition theorem for Boolean matrices (or equivalently, bipartite graphs) under a notion of regularity that was recently introduced and analyzed analytically in the context of communication complexity","[Kelley, Lovett, Meka; arXiv'23], and is related to a similar notion from the recent work on $3$-term arithmetic progression free sets [Kelley, Meka; FOCS'23]."],"url":"http://arxiv.org/abs/2311.09095v1"}
{"created":"2023-11-15 16:41:56","title":"Can MusicGen Create Training Data for MIR Tasks?","abstract":"We are investigating the broader concept of using AI-based generative music systems to generate training data for Music Information Retrieval (MIR) tasks. To kick off this line of work, we ran an initial experiment in which we trained a genre classifier on a fully artificial music dataset created with MusicGen. We constructed over 50 000 genre- conditioned textual descriptions and generated a collection of music excerpts that covers five musical genres. Our preliminary results show that the proposed model can learn genre-specific characteristics from artificial music tracks that generalise well to real-world music recordings.","sentences":["We are investigating the broader concept of using AI-based generative music systems to generate training data for Music Information Retrieval (MIR) tasks.","To kick off this line of work, we ran an initial experiment in which we trained a genre classifier on a fully artificial music dataset created with MusicGen.","We constructed over 50 000 genre- conditioned textual descriptions and generated a collection of music excerpts that covers five musical genres.","Our preliminary results show that the proposed model can learn genre-specific characteristics from artificial music tracks that generalise well to real-world music recordings."],"url":"http://arxiv.org/abs/2311.09094v1"}
{"created":"2023-11-15 16:41:18","title":"Applications of Computer Vision in Autonomous Vehicles: Methods, Challenges and Future Directions","abstract":"Autonomous vehicle refers to a vehicle capable of perceiving its surrounding environment and driving with little or no human driver input. The perception system is a fundamental component which enables the autonomous vehicle to collect data and extract relevant information from the environment to drive safely. Benefit from the recent advances in computer vision, the perception task can be achieved by using sensors, such as camera, LiDAR, radar, and ultrasonic sensor. This paper reviews publications on computer vision and autonomous driving that are published during the last ten years. In particular, we first investigate the development of autonomous driving systems and summarize these systems that are developed by the major automotive manufacturers from different countries. Second, we investigate the sensors and benchmark data sets that are commonly utilized for autonomous driving. Then, a comprehensive overview of computer vision applications for autonomous driving such as depth estimation, object detection, lane detection, and traffic sign recognition are discussed. Additionally, we review public opinions and concerns on autonomous vehicles. Based on the discussion, we analyze the current technological challenges that autonomous vehicles meet with. Finally, we present our insights and point out some promising directions for future research. This paper will help the reader to understand autonomous vehicles from the perspectives of academia and industry.","sentences":["Autonomous vehicle refers to a vehicle capable of perceiving its surrounding environment and driving with little or no human driver input.","The perception system is a fundamental component which enables the autonomous vehicle to collect data and extract relevant information from the environment to drive safely.","Benefit from the recent advances in computer vision, the perception task can be achieved by using sensors, such as camera, LiDAR, radar, and ultrasonic sensor.","This paper reviews publications on computer vision and autonomous driving that are published during the last ten years.","In particular, we first investigate the development of autonomous driving systems and summarize these systems that are developed by the major automotive manufacturers from different countries.","Second, we investigate the sensors and benchmark data sets that are commonly utilized for autonomous driving.","Then, a comprehensive overview of computer vision applications for autonomous driving such as depth estimation, object detection, lane detection, and traffic sign recognition are discussed.","Additionally, we review public opinions and concerns on autonomous vehicles.","Based on the discussion, we analyze the current technological challenges that autonomous vehicles meet with.","Finally, we present our insights and point out some promising directions for future research.","This paper will help the reader to understand autonomous vehicles from the perspectives of academia and industry."],"url":"http://arxiv.org/abs/2311.09093v2"}
{"created":"2023-11-15 16:35:59","title":"Social Bias Probing: Fairness Benchmarking for Language Models","abstract":"Large language models have been shown to encode a variety of social biases, which carries the risk of downstream harms. While the impact of these biases has been recognized, prior methods for bias evaluation have been limited to binary association tests on small datasets, offering a constrained view of the nature of societal biases within language models. In this paper, we propose an original framework for probing language models for societal biases. We collect a probing dataset to analyze language models' general associations, as well as along the axes of societal categories, identities, and stereotypes. To this end, we leverage a novel perplexity-based fairness score. We curate a large-scale benchmarking dataset addressing drawbacks and limitations of existing fairness collections, expanding to a variety of different identities and stereotypes. When comparing our methodology with prior work, we demonstrate that biases within language models are more nuanced than previously acknowledged. In agreement with recent findings, we find that larger model variants exhibit a higher degree of bias. Moreover, we expose how identities expressing different religions lead to the most pronounced disparate treatments across all models.","sentences":["Large language models have been shown to encode a variety of social biases, which carries the risk of downstream harms.","While the impact of these biases has been recognized, prior methods for bias evaluation have been limited to binary association tests on small datasets, offering a constrained view of the nature of societal biases within language models.","In this paper, we propose an original framework for probing language models for societal biases.","We collect a probing dataset to analyze language models' general associations, as well as along the axes of societal categories, identities, and stereotypes.","To this end, we leverage a novel perplexity-based fairness score.","We curate a large-scale benchmarking dataset addressing drawbacks and limitations of existing fairness collections, expanding to a variety of different identities and stereotypes.","When comparing our methodology with prior work, we demonstrate that biases within language models are more nuanced than previously acknowledged.","In agreement with recent findings, we find that larger model variants exhibit a higher degree of bias.","Moreover, we expose how identities expressing different religions lead to the most pronounced disparate treatments across all models."],"url":"http://arxiv.org/abs/2311.09090v1"}
{"created":"2023-11-15 16:32:35","title":"Co-ML: Collaborative Machine Learning Model Building for Developing Dataset Design Practices","abstract":"Machine learning (ML) models are fundamentally shaped by data, and building inclusive ML systems requires significant considerations around how to design representative datasets. Yet, few novice-oriented ML modeling tools are designed to foster hands-on learning of dataset design practices, including how to design for data diversity and inspect for data quality.   To this end, we outline a set of four data design practices (DDPs) for designing inclusive ML models and share how we designed a tablet-based application called Co-ML to foster learning of DDPs through a collaborative ML model building experience. With Co-ML, beginners can build image classifiers through a distributed experience where data is synchronized across multiple devices, enabling multiple users to iteratively refine ML datasets in discussion and coordination with their peers.   We deployed Co-ML in a 2-week-long educational AIML Summer Camp, where youth ages 13-18 worked in groups to build custom ML-powered mobile applications. Our analysis reveals how multi-user model building with Co-ML, in the context of student-driven projects created during the summer camp, supported development of DDPs involving incorporating data diversity, evaluating model performance, and inspecting for data quality. Additionally, we found that students' attempts to improve model performance often prioritized learnability over class balance. Through this work, we highlight how the combination of collaboration, model testing interfaces, and student-driven projects can empower learners to actively engage in exploring the role of data in ML systems.","sentences":["Machine learning (ML) models are fundamentally shaped by data, and building inclusive ML systems requires significant considerations around how to design representative datasets.","Yet, few novice-oriented ML modeling tools are designed to foster hands-on learning of dataset design practices, including how to design for data diversity and inspect for data quality.   ","To this end, we outline a set of four data design practices (DDPs) for designing inclusive ML models and share how we designed a tablet-based application called Co-ML to foster learning of DDPs through a collaborative ML model building experience.","With Co-ML, beginners can build image classifiers through a distributed experience where data is synchronized across multiple devices, enabling multiple users to iteratively refine ML datasets in discussion and coordination with their peers.   ","We deployed Co-ML in a 2-week-long educational AIML Summer Camp, where youth ages 13-18 worked in groups to build custom ML-powered mobile applications.","Our analysis reveals how multi-user model building with Co-ML, in the context of student-driven projects created during the summer camp, supported development of DDPs involving incorporating data diversity, evaluating model performance, and inspecting for data quality.","Additionally, we found that students' attempts to improve model performance often prioritized learnability over class balance.","Through this work, we highlight how the combination of collaboration, model testing interfaces, and student-driven projects can empower learners to actively engage in exploring the role of data in ML systems."],"url":"http://arxiv.org/abs/2311.09088v1"}
{"created":"2023-11-15 16:30:44","title":"The Uli Dataset: An Exercise in Experience Led Annotation of oGBV","abstract":"Online gender based violence has grown concomitantly with adoption of the internet and social media. Its effects are worse in the Global majority where many users use social media in languages other than English. The scale and volume of conversations on the internet has necessitated the need for automated detection of hate speech, and more specifically gendered abuse. There is, however, a lack of language specific and contextual data to build such automated tools. In this paper we present a dataset on gendered abuse in three languages- Hindi, Tamil and Indian English. The dataset comprises of tweets annotated along three questions pertaining to the experience of gender abuse, by experts who identify as women or a member of the LGBTQIA community in South Asia. Through this dataset we demonstrate a participatory approach to creating datasets that drive AI systems.","sentences":["Online gender based violence has grown concomitantly with adoption of the internet and social media.","Its effects are worse in the Global majority where many users use social media in languages other than English.","The scale and volume of conversations on the internet has necessitated the need for automated detection of hate speech, and more specifically gendered abuse.","There is, however, a lack of language specific and contextual data to build such automated tools.","In this paper we present a dataset on gendered abuse in three languages- Hindi, Tamil and Indian English.","The dataset comprises of tweets annotated along three questions pertaining to the experience of gender abuse, by experts who identify as women or a member of the LGBTQIA community in South Asia.","Through this dataset we demonstrate a participatory approach to creating datasets that drive AI systems."],"url":"http://arxiv.org/abs/2311.09086v1"}
{"created":"2023-11-15 16:26:49","title":"Contrastive Transformer Learning with Proximity Data Generation for Text-Based Person Search","abstract":"Given a descriptive text query, text-based person search (TBPS) aims to retrieve the best-matched target person from an image gallery. Such a cross-modal retrieval task is quite challenging due to significant modality gap, fine-grained differences and insufficiency of annotated data. To better align the two modalities, most existing works focus on introducing sophisticated network structures and auxiliary tasks, which are complex and hard to implement. In this paper, we propose a simple yet effective dual Transformer model for text-based person search. By exploiting a hardness-aware contrastive learning strategy, our model achieves state-of-the-art performance without any special design for local feature alignment or side information. Moreover, we propose a proximity data generation (PDG) module to automatically produce more diverse data for cross-modal training. The PDG module first introduces an automatic generation algorithm based on a text-to-image diffusion model, which generates new text-image pair samples in the proximity space of original ones. Then it combines approximate text generation and feature-level mixup during training to further strengthen the data diversity. The PDG module can largely guarantee the reasonability of the generated samples that are directly used for training without any human inspection for noise rejection. It improves the performance of our model significantly, providing a feasible solution to the data insufficiency problem faced by such fine-grained visual-linguistic tasks. Extensive experiments on two popular datasets of the TBPS task (i.e., CUHK-PEDES and ICFG-PEDES) show that the proposed approach outperforms state-of-the-art approaches evidently, e.g., improving by 3.88%, 4.02%, 2.92% in terms of Top1, Top5, Top10 on CUHK-PEDES. The codes will be available at https://github.com/HCPLab-SYSU/PersonSearch-CTLG","sentences":["Given a descriptive text query, text-based person search (TBPS) aims to retrieve the best-matched target person from an image gallery.","Such a cross-modal retrieval task is quite challenging due to significant modality gap, fine-grained differences and insufficiency of annotated data.","To better align the two modalities, most existing works focus on introducing sophisticated network structures and auxiliary tasks, which are complex and hard to implement.","In this paper, we propose a simple yet effective dual Transformer model for text-based person search.","By exploiting a hardness-aware contrastive learning strategy, our model achieves state-of-the-art performance without any special design for local feature alignment or side information.","Moreover, we propose a proximity data generation (PDG) module to automatically produce more diverse data for cross-modal training.","The PDG module first introduces an automatic generation algorithm based on a text-to-image diffusion model, which generates new text-image pair samples in the proximity space of original ones.","Then it combines approximate text generation and feature-level mixup during training to further strengthen the data diversity.","The PDG module can largely guarantee the reasonability of the generated samples that are directly used for training without any human inspection for noise rejection.","It improves the performance of our model significantly, providing a feasible solution to the data insufficiency problem faced by such fine-grained visual-linguistic tasks.","Extensive experiments on two popular datasets of the TBPS task (i.e., CUHK-PEDES and ICFG-PEDES) show that the proposed approach outperforms state-of-the-art approaches evidently, e.g., improving by 3.88%, 4.02%, 2.92% in terms of Top1, Top5, Top10 on CUHK-PEDES.","The codes will be available at https://github.com/HCPLab-SYSU/PersonSearch-CTLG"],"url":"http://arxiv.org/abs/2311.09084v1"}
{"created":"2023-11-15 16:19:13","title":"Spiking NeRF: Representing the Real-World Geometry by a Discontinuous Representation","abstract":"A crucial reason for the success of existing NeRF-based methods is to build a neural density field for the geometry representation via multiple perceptron layers (MLPs). MLPs are continuous functions, however, real geometry or density field is frequently discontinuous at the interface between the air and the surface. Such a contrary brings the problem of unfaithful geometry representation. To this end, this paper proposes spiking NeRF, which leverages spiking neuron and a hybrid Artificial Neural Network (ANN)-Spiking Neural Network (SNN) framework to build a discontinuous density field for faithful geometry representation. Specifically, we first demonstrate the reason why continuous density fields will bring inaccuracy. Then, we propose to use the spiking neurons to build a discontinuous density field. We conduct comprehensive analysis for the problem of existing spiking neuron models and then provide the numerical relationship between the parameter of spiking neuron and the theoretical accuracy of geometry, Based on this, we propose a bounded spiking neuron to build the discontinuous density field. Our results achieve SOTA performance. Our code and data will be released to the public.","sentences":["A crucial reason for the success of existing NeRF-based methods is to build a neural density field for the geometry representation via multiple perceptron layers (MLPs).","MLPs are continuous functions, however, real geometry or density field is frequently discontinuous at the interface between the air and the surface.","Such a contrary brings the problem of unfaithful geometry representation.","To this end, this paper proposes spiking NeRF, which leverages spiking neuron and a hybrid Artificial Neural Network (ANN)-Spiking Neural Network (SNN) framework to build a discontinuous density field for faithful geometry representation.","Specifically, we first demonstrate the reason why continuous density fields will bring inaccuracy.","Then, we propose to use the spiking neurons to build a discontinuous density field.","We conduct comprehensive analysis for the problem of existing spiking neuron models and then provide the numerical relationship between the parameter of spiking neuron and the theoretical accuracy of geometry, Based on this, we propose a bounded spiking neuron to build the discontinuous density field.","Our results achieve SOTA performance.","Our code and data will be released to the public."],"url":"http://arxiv.org/abs/2311.09077v1"}
{"created":"2023-11-15 16:18:17","title":"Self-stabilizing Byzantine Multivalued Consensus","abstract":"Consensus, abstracting a myriad of problems in which processes have to agree on a single value, is one of the most celebrated problems of fault-tolerant distributed computing. Consensus applications include fundamental services for the environments of the Cloud and Blockchain, and in such challenging environments, malicious behaviors are often modeled as adversarial Byzantine faults.   At OPODIS 2010, Mostefaoui and Raynal (in short MR) presented a Byzantine-tolerant solution to consensus in which the decided value cannot be a value proposed only by Byzantine processes. MR has optimal resilience coping with up to t < n/3 Byzantine nodes over n processes. MR provides this multivalued consensus object (which accepts proposals taken from a finite set of values) assuming the availability of a single Binary consensus object (which accepts proposals taken from the set {0,1}).   This work, which focuses on multivalued consensus, aims at the design of an even more robust solution than MR. Our proposal expands MR's fault-model with self-stabilization, a vigorous notion of fault-tolerance. In addition to tolerating Byzantine, self-stabilizing systems can automatically recover after the occurrence of arbitrary transient-faults. These faults represent any violation of the assumptions according to which the system was designed to operate (provided that the algorithm code remains intact).   To the best of our knowledge, we propose the first self-stabilizing solution for intrusion-tolerant multivalued consensus for asynchronous message-passing systems prone to Byzantine failures. Our solution has a O(t) stabilization time from arbitrary transient faults.","sentences":["Consensus, abstracting a myriad of problems in which processes have to agree on a single value, is one of the most celebrated problems of fault-tolerant distributed computing.","Consensus applications include fundamental services for the environments of the Cloud and Blockchain, and in such challenging environments, malicious behaviors are often modeled as adversarial Byzantine faults.   ","At OPODIS 2010, Mostefaoui and Raynal (in short MR) presented a Byzantine-tolerant solution to consensus in which the decided value cannot be a value proposed only by Byzantine processes.","MR has optimal resilience coping with up to t < n/3 Byzantine nodes over n processes.","MR provides this multivalued consensus object (which accepts proposals taken from a finite set of values) assuming the availability of a single Binary consensus object (which accepts proposals taken from the set {0,1}).   ","This work, which focuses on multivalued consensus, aims at the design of an even more robust solution than MR.","Our proposal expands MR's fault-model with self-stabilization, a vigorous notion of fault-tolerance.","In addition to tolerating Byzantine, self-stabilizing systems can automatically recover after the occurrence of arbitrary transient-faults.","These faults represent any violation of the assumptions according to which the system was designed to operate (provided that the algorithm code remains intact).   ","To the best of our knowledge, we propose the first self-stabilizing solution for intrusion-tolerant multivalued consensus for asynchronous message-passing systems prone to Byzantine failures.","Our solution has a O(t) stabilization time from arbitrary transient faults."],"url":"http://arxiv.org/abs/2311.09075v1"}
{"created":"2023-11-15 16:13:14","title":"How Multilingual is Multilingual LLM?","abstract":"Large Language Models (LLMs), trained predominantly on extensive English data, often exhibit limitations when applied to other languages. Current research is primarily focused on enhancing the multilingual capabilities of these models by employing various tuning strategies. Despite their effectiveness in certain languages, the understanding of the multilingual abilities of LLMs remains incomplete. This study endeavors to evaluate the multilingual capacity of LLMs by conducting an exhaustive analysis across 101 languages, and classifies languages with similar characteristics into four distinct quadrants. By delving into each quadrant, we shed light on the rationale behind their categorization and offer actionable guidelines for tuning these languages. Extensive experiments reveal that existing LLMs possess multilingual capabilities that surpass our expectations, and we can significantly improve the multilingual performance of LLMs by focusing on these distinct attributes present in each quadrant.","sentences":["Large Language Models (LLMs), trained predominantly on extensive English data, often exhibit limitations when applied to other languages.","Current research is primarily focused on enhancing the multilingual capabilities of these models by employing various tuning strategies.","Despite their effectiveness in certain languages, the understanding of the multilingual abilities of LLMs remains incomplete.","This study endeavors to evaluate the multilingual capacity of LLMs by conducting an exhaustive analysis across 101 languages, and classifies languages with similar characteristics into four distinct quadrants.","By delving into each quadrant, we shed light on the rationale behind their categorization and offer actionable guidelines for tuning these languages.","Extensive experiments reveal that existing LLMs possess multilingual capabilities that surpass our expectations, and we can significantly improve the multilingual performance of LLMs by focusing on these distinct attributes present in each quadrant."],"url":"http://arxiv.org/abs/2311.09071v1"}
{"created":"2023-11-15 16:11:27","title":"How Well Do Large Language Models Truly Ground?","abstract":"Reliance on the inherent knowledge of Large Language Models (LLMs) can cause issues such as hallucinations, lack of control, and difficulties in integrating variable knowledge. To mitigate this, LLMs can be probed to generate responses by grounding on external context, often given as input (knowledge-augmented models). Yet, previous research is often confined to a narrow view of the term \"grounding\", often only focusing on whether the response contains the correct answer or not, which does not ensure the reliability of the entire response. To address this limitation, we introduce a strict definition of grounding: a model is considered truly grounded when its responses (1) fully utilize necessary knowledge from the provided context, and (2) don't exceed the knowledge within the contexts. We introduce a new dataset and a grounding metric to assess this new definition and perform experiments across 13 LLMs of different sizes and training methods to provide insights into the factors that influence grounding performance. Our findings contribute to a better understanding of how to improve grounding capabilities and suggest an area of improvement toward more reliable and controllable LLM applications.","sentences":["Reliance on the inherent knowledge of Large Language Models (LLMs) can cause issues such as hallucinations, lack of control, and difficulties in integrating variable knowledge.","To mitigate this, LLMs can be probed to generate responses by grounding on external context, often given as input (knowledge-augmented models).","Yet, previous research is often confined to a narrow view of the term \"grounding\", often only focusing on whether the response contains the correct answer or not, which does not ensure the reliability of the entire response.","To address this limitation, we introduce a strict definition of grounding: a model is considered truly grounded when its responses (1) fully utilize necessary knowledge from the provided context, and (2) don't exceed the knowledge within the contexts.","We introduce a new dataset and a grounding metric to assess this new definition and perform experiments across 13 LLMs of different sizes and training methods to provide insights into the factors that influence grounding performance.","Our findings contribute to a better understanding of how to improve grounding capabilities and suggest an area of improvement toward more reliable and controllable LLM applications."],"url":"http://arxiv.org/abs/2311.09069v1"}
{"created":"2023-11-15 16:10:34","title":"Learning Fair Division from Bandit Feedback","abstract":"This work addresses learning online fair division under uncertainty, where a central planner sequentially allocates items without precise knowledge of agents' values or utilities. Departing from conventional online algorithm, the planner here relies on noisy, estimated values obtained after allocating items. We introduce wrapper algorithms utilizing \\textit{dual averaging}, enabling gradual learning of both the type distribution of arriving items and agents' values through bandit feedback. This approach enables the algorithms to asymptotically achieve optimal Nash social welfare in linear Fisher markets with agents having additive utilities. We establish regret bounds in Nash social welfare and empirically validate the superior performance of our proposed algorithms across synthetic and empirical datasets.","sentences":["This work addresses learning online fair division under uncertainty, where a central planner sequentially allocates items without precise knowledge of agents' values or utilities.","Departing from conventional online algorithm, the planner here relies on noisy, estimated values obtained after allocating items.","We introduce wrapper algorithms utilizing \\textit{dual averaging}, enabling gradual learning of both the type distribution of arriving items and agents' values through bandit feedback.","This approach enables the algorithms to asymptotically achieve optimal Nash social welfare in linear Fisher markets with agents having additive utilities.","We establish regret bounds in Nash social welfare and empirically validate the superior performance of our proposed algorithms across synthetic and empirical datasets."],"url":"http://arxiv.org/abs/2311.09068v1"}
{"created":"2023-11-15 16:05:55","title":"Identifying Self-Disclosures of Use, Misuse and Addiction in Community-based Social Media Posts","abstract":"In the last decade, the United States has lost more than 500,000 people from an overdose involving prescription and illicit opioids (https://www.cdc.gov/drugoverdose/epidemic/index.html) making it a national public health emergency (USDHHS, 2017). To more effectively prevent unintentional opioid overdoses, medical practitioners require robust and timely tools that can effectively identify at-risk patients. Community-based social media platforms such as Reddit allow self-disclosure for users to discuss otherwise sensitive drug-related behaviors, often acting as indicators for opioid use disorder. Towards this, we present a moderate size corpus of 2500 opioid-related posts from various subreddits spanning 6 different phases of opioid use: Medical Use, Misuse, Addiction, Recovery, Relapse, Not Using. For every post, we annotate span-level extractive explanations and crucially study their role both in annotation quality and model development. We evaluate several state-of-the-art models in a supervised, few-shot, or zero-shot setting. Experimental results and error analysis show that identifying the phases of opioid use disorder is highly contextual and challenging. However, we find that using explanations during modeling leads to a significant boost in classification accuracy demonstrating their beneficial role in a high-stakes domain such as studying the opioid use disorder continuum. The dataset will be made available for research on Github in the formal version.","sentences":["In the last decade, the United States has lost more than 500,000 people from an overdose involving prescription and illicit opioids (https://www.cdc.gov/drugoverdose/epidemic/index.html) making it a national public health emergency (USDHHS, 2017).","To more effectively prevent unintentional opioid overdoses, medical practitioners require robust and timely tools that can effectively identify at-risk patients.","Community-based social media platforms such as Reddit allow self-disclosure for users to discuss otherwise sensitive drug-related behaviors, often acting as indicators for opioid use disorder.","Towards this, we present a moderate size corpus of 2500 opioid-related posts from various subreddits spanning 6 different phases of opioid use: Medical Use, Misuse, Addiction, Recovery, Relapse, Not Using.","For every post, we annotate span-level extractive explanations and crucially study their role both in annotation quality and model development.","We evaluate several state-of-the-art models in a supervised, few-shot, or zero-shot setting.","Experimental results and error analysis show that identifying the phases of opioid use disorder is highly contextual and challenging.","However, we find that using explanations during modeling leads to a significant boost in classification accuracy demonstrating their beneficial role in a high-stakes domain such as studying the opioid use disorder continuum.","The dataset will be made available for research on Github in the formal version."],"url":"http://arxiv.org/abs/2311.09066v1"}
{"created":"2023-11-15 16:02:13","title":"Imagine the Unseen World: A Benchmark for Systematic Generalization in Visual World Models","abstract":"Systematic compositionality, or the ability to adapt to novel situations by creating a mental model of the world using reusable pieces of knowledge, remains a significant challenge in machine learning. While there has been considerable progress in the language domain, efforts towards systematic visual imagination, or envisioning the dynamical implications of a visual observation, are in their infancy. We introduce the Systematic Visual Imagination Benchmark (SVIB), the first benchmark designed to address this problem head-on. SVIB offers a novel framework for a minimal world modeling problem, where models are evaluated based on their ability to generate one-step image-to-image transformations under a latent world dynamics. The framework provides benefits such as the possibility to jointly optimize for systematic perception and imagination, a range of difficulty levels, and the ability to control the fraction of possible factor combinations used during training. We provide a comprehensive evaluation of various baseline models on SVIB, offering insight into the current state-of-the-art in systematic visual imagination. We hope that this benchmark will help advance visual systematic compositionality.","sentences":["Systematic compositionality, or the ability to adapt to novel situations by creating a mental model of the world using reusable pieces of knowledge, remains a significant challenge in machine learning.","While there has been considerable progress in the language domain, efforts towards systematic visual imagination, or envisioning the dynamical implications of a visual observation, are in their infancy.","We introduce the Systematic Visual Imagination Benchmark (SVIB), the first benchmark designed to address this problem head-on.","SVIB offers a novel framework for a minimal world modeling problem, where models are evaluated based on their ability to generate one-step image-to-image transformations under a latent world dynamics.","The framework provides benefits such as the possibility to jointly optimize for systematic perception and imagination, a range of difficulty levels, and the ability to control the fraction of possible factor combinations used during training.","We provide a comprehensive evaluation of various baseline models on SVIB, offering insight into the current state-of-the-art in systematic visual imagination.","We hope that this benchmark will help advance visual systematic compositionality."],"url":"http://arxiv.org/abs/2311.09064v1"}
{"created":"2023-11-15 15:54:15","title":"Brain Functional Connectivity under Teleoperation Latency: a fNIRS Study","abstract":"Objective: This study aims to understand the cognitive impact of latency in teleoperation and the related mitigation methods, using functional Near-Infrared Spectroscopy (fNIRS) to analyze functional connectivity. Background: Latency between command, execution, and feedback in teleoperation can impair performance and affect operators mental state. The neural underpinnings of these effects are not well understood. Method: A human subject experiment (n = 41) of a simulated remote robot manipulation task was performed. Three conditions were tested: no latency, with visual and haptic latency, with visual latency and no haptic latency. fNIRS and performance data were recorded and analyzed. Results: The presence of latency in teleoperation significantly increased functional connectivity within and between prefrontal and motor cortexes. Maintaining visual latency while providing real-time haptic feedback reduced the average functional connectivity in all cortical networks and showed a significantly different connectivity ratio within prefrontal and motor cortical networks. The performance results showed the worst performance in the all-delayed condition and best performance in no latency condition, which echoes the neural activity patterns. Conclusion: The study provides neurological evidence that latency in teleoperation increases cognitive load, anxiety, and challenges in motion planning and control. Real-time haptic feedback, however, positively influences neural pathways related to cognition, decision-making, and sensorimotor processes. Application: This research can inform the design of ergonomic teleoperation systems that mitigate the effects of latency.","sentences":["Objective: This study aims to understand the cognitive impact of latency in teleoperation and the related mitigation methods, using functional Near-Infrared Spectroscopy (fNIRS) to analyze functional connectivity.","Background: Latency between command, execution, and feedback in teleoperation can impair performance and affect operators mental state.","The neural underpinnings of these effects are not well understood.","Method: A human subject experiment (n = 41) of a simulated remote robot manipulation task was performed.","Three conditions were tested: no latency, with visual and haptic latency, with visual latency and no haptic latency.","fNIRS and performance data were recorded and analyzed.","Results:","The presence of latency in teleoperation significantly increased functional connectivity within and between prefrontal and motor cortexes.","Maintaining visual latency while providing real-time haptic feedback reduced the average functional connectivity in all cortical networks and showed a significantly different connectivity ratio within prefrontal and motor cortical networks.","The performance results showed the worst performance in the all-delayed condition and best performance in no latency condition, which echoes the neural activity patterns.","Conclusion: The study provides neurological evidence that latency in teleoperation increases cognitive load, anxiety, and challenges in motion planning and control.","Real-time haptic feedback, however, positively influences neural pathways related to cognition, decision-making, and sensorimotor processes.","Application:","This research can inform the design of ergonomic teleoperation systems that mitigate the effects of latency."],"url":"http://arxiv.org/abs/2311.09062v1"}
{"created":"2023-11-15 15:53:25","title":"Automatic cable harness layout routing in a customizable 3D environment","abstract":"Designing cable harnesses can be time-consuming and complex due to many design and manufacturing aspects and rules. Automating the design process can help to fulfil these rules, speed up the process, and optimize the design. To accommodate this, we formulate a harness routing optimization problem to minimize cable lengths, maximize bundling by rewarding shared paths, and optimize the cables' spatial location with respect to case-specific information of the routing environment, e.g., zones to avoid. A deterministic and computationally effective cable harness routing algorithm has been developed to solve the routing problem and is used to generate a set of cable harness topology candidates and approximate the Pareto front. Our approach was tested against a stochastic and an exact solver and our routing algorithm generated objective function values better than the stochastic approach and close to the exact solver. Our algorithm was able to find solutions, some of them being proven to be near-optimal, for three industrial-sized 3D cases within reasonable time (in magnitude of seconds to minutes) and the computation times were comparable to those of the stochastic approach.","sentences":["Designing cable harnesses can be time-consuming and complex due to many design and manufacturing aspects and rules.","Automating the design process can help to fulfil these rules, speed up the process, and optimize the design.","To accommodate this, we formulate a harness routing optimization problem to minimize cable lengths, maximize bundling by rewarding shared paths, and optimize the cables' spatial location with respect to case-specific information of the routing environment, e.g., zones to avoid.","A deterministic and computationally effective cable harness routing algorithm has been developed to solve the routing problem and is used to generate a set of cable harness topology candidates and approximate the Pareto front.","Our approach was tested against a stochastic and an exact solver and our routing algorithm generated objective function values better than the stochastic approach and close to the exact solver.","Our algorithm was able to find solutions, some of them being proven to be near-optimal, for three industrial-sized 3D cases within reasonable time (in magnitude of seconds to minutes) and the computation times were comparable to those of the stochastic approach."],"url":"http://arxiv.org/abs/2311.09061v1"}
{"created":"2023-11-15 15:52:40","title":"Do Localization Methods Actually Localize Memorized Data in LLMs?","abstract":"Large language models (LLMs) can memorize many pretrained sequences verbatim. This paper studies if we can locate a small set of neurons in LLMs responsible for memorizing a given sequence. While the concept of localization is often mentioned in prior work, methods for localization have never been systematically and directly evaluated; we address this with two benchmarking approaches. In our INJ Benchmark, we actively inject a piece of new information into a small subset of LLM weights and measure whether localization methods can identify these \"ground truth\" weights. In the DEL Benchmark, we study localization of pretrained data that LLMs have already memorized; while this setting lacks ground truth, we can still evaluate localization by measuring whether dropping out located neurons erases a memorized sequence from the model. We evaluate five localization methods on our two benchmarks, and both show similar rankings. All methods exhibit promising localization ability, especially for pruning-based methods, though the neurons they identify are not necessarily specific to a single memorized sequence.","sentences":["Large language models (LLMs) can memorize many pretrained sequences verbatim.","This paper studies if we can locate a small set of neurons in LLMs responsible for memorizing a given sequence.","While the concept of localization is often mentioned in prior work, methods for localization have never been systematically and directly evaluated; we address this with two benchmarking approaches.","In our INJ Benchmark, we actively inject a piece of new information into a small subset of LLM weights and measure whether localization methods can identify these \"ground truth\" weights.","In the DEL Benchmark, we study localization of pretrained data that LLMs have already memorized; while this setting lacks ground truth, we can still evaluate localization by measuring whether dropping out located neurons erases a memorized sequence from the model.","We evaluate five localization methods on our two benchmarks, and both show similar rankings.","All methods exhibit promising localization ability, especially for pruning-based methods, though the neurons they identify are not necessarily specific to a single memorized sequence."],"url":"http://arxiv.org/abs/2311.09060v1"}
{"created":"2023-11-15 15:50:34","title":"New Horizons in Parameter Regularization: A Constraint Approach","abstract":"This work presents constrained parameter regularization (CPR), an alternative to traditional weight decay. Instead of applying a constant penalty uniformly to all parameters, we enforce an upper bound on a statistical measure (e.g., the L$_2$-norm) of individual parameter groups. This reformulates learning as a constrained optimization problem. To solve this, we utilize an adaptation of the augmented Lagrangian method. Our approach allows for varying regularization strengths across different parameter groups, removing the need for explicit penalty coefficients in the regularization terms. CPR only requires two hyperparameters and introduces no measurable runtime overhead. We offer empirical evidence of CPR's effectiveness through experiments in the \"grokking\" phenomenon, image classification, and language modeling. Our findings show that CPR can counteract the effects of grokking, and it consistently matches or surpasses the performance of traditional weight decay.","sentences":["This work presents constrained parameter regularization (CPR), an alternative to traditional weight decay.","Instead of applying a constant penalty uniformly to all parameters, we enforce an upper bound on a statistical measure (e.g., the L$_2$-norm) of individual parameter groups.","This reformulates learning as a constrained optimization problem.","To solve this, we utilize an adaptation of the augmented Lagrangian method.","Our approach allows for varying regularization strengths across different parameter groups, removing the need for explicit penalty coefficients in the regularization terms.","CPR only requires two hyperparameters and introduces no measurable runtime overhead.","We offer empirical evidence of CPR's effectiveness through experiments in the \"grokking\" phenomenon, image classification, and language modeling.","Our findings show that CPR can counteract the effects of grokking, and it consistently matches or surpasses the performance of traditional weight decay."],"url":"http://arxiv.org/abs/2311.09058v1"}
{"created":"2023-11-15 15:49:27","title":"Range-Visual-Inertial Sensor Fusion for Micro Aerial Vehicle Localization and Navigation","abstract":"We propose a fixed-lag smoother-based sensor fusion architecture to leverage the complementary benefits of range-based sensors and visual-inertial odometry (VIO) for localization. We use two fixed-lag smoothers (FLS) to decouple accurate state estimation and high-rate pose generation for closed-loop control. The first FLS combines ultrawideband (UWB)-based range measurements and VIO to estimate the robot trajectory and any systematic biases that affect the range measurements in cluttered environments. The second FLS estimates smooth corrections to VIO to generate pose estimates at a high rate for online control. The proposed method is lightweight and can run on a computationally constrained micro-aerial vehicle (MAV). We validate our approach through closed-loop flight tests involving dynamic trajectories in multiple real-world cluttered indoor environments. Our method achieves decimeter-to-sub-decimeter-level positioning accuracy using off-the-shelf sensors and decimeter-level tracking accuracy with minimally-tuned open-source controllers.","sentences":["We propose a fixed-lag smoother-based sensor fusion architecture to leverage the complementary benefits of range-based sensors and visual-inertial odometry (VIO) for localization.","We use two fixed-lag smoothers (FLS) to decouple accurate state estimation and high-rate pose generation for closed-loop control.","The first FLS combines ultrawideband (UWB)-based range measurements and VIO to estimate the robot trajectory and any systematic biases that affect the range measurements in cluttered environments.","The second FLS estimates smooth corrections to VIO to generate pose estimates at a high rate for online control.","The proposed method is lightweight and can run on a computationally constrained micro-aerial vehicle (MAV).","We validate our approach through closed-loop flight tests involving dynamic trajectories in multiple real-world cluttered indoor environments.","Our method achieves decimeter-to-sub-decimeter-level positioning accuracy using off-the-shelf sensors and decimeter-level tracking accuracy with minimally-tuned open-source controllers."],"url":"http://arxiv.org/abs/2311.09056v1"}
{"created":"2023-11-15 15:44:42","title":"Assessing Knowledge Editing in Language Models via Relation Perspective","abstract":"Knowledge Editing (KE) for modifying factual knowledge in Large Language Models (LLMs) has been receiving increasing attention. However, existing knowledge editing methods are entity-centric, and it is unclear whether this approach is suitable for a relation-centric perspective. To address this gap, this paper constructs a new benchmark named RaKE, which focuses on Relation based Knowledge Editing. In this paper, we establish a suite of innovative metrics for evaluation and conduct comprehensive experiments involving various knowledge editing baselines. We notice that existing knowledge editing methods exhibit the potential difficulty in their ability to edit relations. Therefore, we further explore the role of relations in factual triplets within the transformer. Our research results confirm that knowledge related to relations is not only stored in the FFN network but also in the attention layers. This provides experimental support for future relation-based knowledge editing methods.","sentences":["Knowledge Editing (KE) for modifying factual knowledge in Large Language Models (LLMs) has been receiving increasing attention.","However, existing knowledge editing methods are entity-centric, and it is unclear whether this approach is suitable for a relation-centric perspective.","To address this gap, this paper constructs a new benchmark named RaKE, which focuses on Relation based Knowledge Editing.","In this paper, we establish a suite of innovative metrics for evaluation and conduct comprehensive experiments involving various knowledge editing baselines.","We notice that existing knowledge editing methods exhibit the potential difficulty in their ability to edit relations.","Therefore, we further explore the role of relations in factual triplets within the transformer.","Our research results confirm that knowledge related to relations is not only stored in the FFN network but also in the attention layers.","This provides experimental support for future relation-based knowledge editing methods."],"url":"http://arxiv.org/abs/2311.09053v1"}
{"created":"2023-11-15 15:41:48","title":"Network-Level Integrated Sensing and Communication: Interference Management and BS Coordination Using Stochastic Geometry","abstract":"In this work, we study integrated sensing and communication (ISAC) networks with the aim of effectively balancing sensing and communication (S&C) performance at the network level. Focusing on monostatic sensing, the tool of stochastic geometry is exploited to capture the S&C performance, which facilitates us to illuminate key cooperative dependencies in the ISAC network and optimize key network-level parameters. Based on the derived tractable expression of area spectral efficiency (ASE), we formulate the optimization problem to maximize the network performance from the view point of two joint S&C metrics. Towards this end, we further jointly optimize the cooperative BS cluster sizes for S&C and the serving/probing numbers of users/targets to achieve a flexible tradeoff between S&C at the network level. It is verified that interference nulling can effectively improve the average data rate and radar information rate. Surprisingly, the optimal communication tradeoff for the case of the ASE maximization tends to employ all spacial resources towards multiplexing and diversity gain, without interference nulling. By contrast, for the sensing objectives, resource allocation tends to eliminate certain interference especially when the antenna resources are sufficient, because the inter-cell interference becomes a more dominant factor affecting sensing performance. Furthermore, we prove that the ratio of the optimal number of users and the number of transmit antennas is a constant value when the communication performance is optimal. Simulation results demonstrate that the proposed cooperative ISAC scheme achieves a substantial gain in S&C performance at the network level.","sentences":["In this work, we study integrated sensing and communication (ISAC) networks with the aim of effectively balancing sensing and communication (S&C) performance at the network level.","Focusing on monostatic sensing, the tool of stochastic geometry is exploited to capture the S&C performance, which facilitates us to illuminate key cooperative dependencies in the ISAC network and optimize key network-level parameters.","Based on the derived tractable expression of area spectral efficiency (ASE), we formulate the optimization problem to maximize the network performance from the view point of two joint S&C metrics.","Towards this end, we further jointly optimize the cooperative BS cluster sizes for S&C and the serving/probing numbers of users/targets to achieve a flexible tradeoff between S&C at the network level.","It is verified that interference nulling can effectively improve the average data rate and radar information rate.","Surprisingly, the optimal communication tradeoff for the case of the ASE maximization tends to employ all spacial resources towards multiplexing and diversity gain, without interference nulling.","By contrast, for the sensing objectives, resource allocation tends to eliminate certain interference especially when the antenna resources are sufficient, because the inter-cell interference becomes a more dominant factor affecting sensing performance.","Furthermore, we prove that the ratio of the optimal number of users and the number of transmit antennas is a constant value when the communication performance is optimal.","Simulation results demonstrate that the proposed cooperative ISAC scheme achieves a substantial gain in S&C performance at the network level."],"url":"http://arxiv.org/abs/2311.09052v1"}
{"created":"2023-11-15 15:40:46","title":"Improving Zero-shot Visual Question Answering via Large Language Models with Reasoning Question Prompts","abstract":"Zero-shot Visual Question Answering (VQA) is a prominent vision-language task that examines both the visual and textual understanding capability of systems in the absence of training data. Recently, by converting the images into captions, information across multi-modalities is bridged and Large Language Models (LLMs) can apply their strong zero-shot generalization capability to unseen questions. To design ideal prompts for solving VQA via LLMs, several studies have explored different strategies to select or generate question-answer pairs as the exemplar prompts, which guide LLMs to answer the current questions effectively. However, they totally ignore the role of question prompts. The original questions in VQA tasks usually encounter ellipses and ambiguity which require intermediate reasoning. To this end, we present Reasoning Question Prompts for VQA tasks, which can further activate the potential of LLMs in zero-shot scenarios. Specifically, for each question, we first generate self-contained questions as reasoning question prompts via an unsupervised question edition module considering sentence fluency, semantic integrity and syntactic invariance. Each reasoning question prompt clearly indicates the intent of the original question. This results in a set of candidate answers. Then, the candidate answers associated with their confidence scores acting as answer heuristics are fed into LLMs and produce the final answer. We evaluate reasoning question prompts on three VQA challenges, experimental results demonstrate that they can significantly improve the results of LLMs on zero-shot setting and outperform existing state-of-the-art zero-shot methods on three out of four data sets. Our source code is publicly released at \\url{https://github.com/ECNU-DASE-NLP/RQP}.","sentences":["Zero-shot Visual Question Answering (VQA) is a prominent vision-language task that examines both the visual and textual understanding capability of systems in the absence of training data.","Recently, by converting the images into captions, information across multi-modalities is bridged and Large Language Models (LLMs) can apply their strong zero-shot generalization capability to unseen questions.","To design ideal prompts for solving VQA via LLMs, several studies have explored different strategies to select or generate question-answer pairs as the exemplar prompts, which guide LLMs to answer the current questions effectively.","However, they totally ignore the role of question prompts.","The original questions in VQA tasks usually encounter ellipses and ambiguity which require intermediate reasoning.","To this end, we present Reasoning Question Prompts for VQA tasks, which can further activate the potential of LLMs in zero-shot scenarios.","Specifically, for each question, we first generate self-contained questions as reasoning question prompts via an unsupervised question edition module considering sentence fluency, semantic integrity and syntactic invariance.","Each reasoning question prompt clearly indicates the intent of the original question.","This results in a set of candidate answers.","Then, the candidate answers associated with their confidence scores acting as answer heuristics are fed into LLMs and produce the final answer.","We evaluate reasoning question prompts on three VQA challenges, experimental results demonstrate that they can significantly improve the results of LLMs on zero-shot setting and outperform existing state-of-the-art zero-shot methods on three out of four data sets.","Our source code is publicly released at \\url{https://github.com/ECNU-DASE-NLP/RQP}."],"url":"http://arxiv.org/abs/2311.09050v1"}
{"created":"2023-11-15 15:39:33","title":"Adapting Large Language Models by Integrating Collaborative Semantics for Recommendation","abstract":"Recently, large language models (LLMs) have shown great potential in recommender systems, either improving existing recommendation models or serving as the backbone. However, there exists a large semantic gap between LLMs and recommender systems, since items to be recommended are often indexed by discrete identifiers (item ID) out of the LLM's vocabulary. In essence, LLMs capture language semantics while recommender systems imply collaborative semantics, making it difficult to sufficiently leverage the model capacity of LLMs for recommendation. To address this challenge, in this paper, we propose a new LLM-based recommendation model called LC-Rec, which can better integrate language and collaborative semantics for recommender systems. Our approach can directly generate items from the entire item set for recommendation, without relying on candidate items. Specifically, we make two major contributions in our approach. For item indexing, we design a learning-based vector quantization method with uniform semantic mapping, which can assign meaningful and non-conflicting IDs (called item indices) for items. For alignment tuning, we propose a series of specially designed tuning tasks to enhance the integration of collaborative semantics in LLMs. Our fine-tuning tasks enforce LLMs to deeply integrate language and collaborative semantics (characterized by the learned item indices), so as to achieve an effective adaptation to recommender systems. Extensive experiments demonstrate the effectiveness of our method, showing that our approach can outperform a number of competitive baselines including traditional recommenders and existing LLM-based recommenders. Our code is available at https://github.com/RUCAIBox/LC-Rec/.","sentences":["Recently, large language models (LLMs) have shown great potential in recommender systems, either improving existing recommendation models or serving as the backbone.","However, there exists a large semantic gap between LLMs and recommender systems, since items to be recommended are often indexed by discrete identifiers (item ID) out of the LLM's vocabulary.","In essence, LLMs capture language semantics while recommender systems imply collaborative semantics, making it difficult to sufficiently leverage the model capacity of LLMs for recommendation.","To address this challenge, in this paper, we propose a new LLM-based recommendation model called LC-Rec, which can better integrate language and collaborative semantics for recommender systems.","Our approach can directly generate items from the entire item set for recommendation, without relying on candidate items.","Specifically, we make two major contributions in our approach.","For item indexing, we design a learning-based vector quantization method with uniform semantic mapping, which can assign meaningful and non-conflicting IDs (called item indices) for items.","For alignment tuning, we propose a series of specially designed tuning tasks to enhance the integration of collaborative semantics in LLMs.","Our fine-tuning tasks enforce LLMs to deeply integrate language and collaborative semantics (characterized by the learned item indices), so as to achieve an effective adaptation to recommender systems.","Extensive experiments demonstrate the effectiveness of our method, showing that our approach can outperform a number of competitive baselines including traditional recommenders and existing LLM-based recommenders.","Our code is available at https://github.com/RUCAIBox/LC-Rec/."],"url":"http://arxiv.org/abs/2311.09049v1"}
{"created":"2023-11-15 15:38:28","title":"GRASP: A novel benchmark for evaluating language GRounding And Situated Physics understanding in multimodal language models","abstract":"This paper presents GRASP, a novel benchmark to evaluate the language grounding and physical understanding capabilities of video-based multimodal large language models (LLMs). This evaluation is accomplished via a two-tier approach leveraging Unity simulations. The initial level tests for language grounding by assessing a model's ability to relate simple textual descriptions with visual information. The second level evaluates the model's understanding of 'Intuitive Physics' principles, such as object permanence and continuity. In addition to releasing the benchmark, we use it to evaluate several state-of-the-art multimodal LLMs. Our evaluation reveals significant shortcomings in current models' language grounding and intuitive physics. These identified limitations underline the importance of benchmarks like GRASP to monitor the progress of future models in developing these competencies.","sentences":["This paper presents GRASP, a novel benchmark to evaluate the language grounding and physical understanding capabilities of video-based multimodal large language models (LLMs).","This evaluation is accomplished via a two-tier approach leveraging Unity simulations.","The initial level tests for language grounding by assessing a model's ability to relate simple textual descriptions with visual information.","The second level evaluates the model's understanding of 'Intuitive Physics' principles, such as object permanence and continuity.","In addition to releasing the benchmark, we use it to evaluate several state-of-the-art multimodal LLMs.","Our evaluation reveals significant shortcomings in current models' language grounding and intuitive physics.","These identified limitations underline the importance of benchmarks like GRASP to monitor the progress of future models in developing these competencies."],"url":"http://arxiv.org/abs/2311.09048v1"}
{"created":"2023-11-15 15:38:26","title":"6G Non-Terrestrial Networks Enabled Low-Altitude Economy: Opportunities and Challenges","abstract":"The unprecedented development of non-terrestrial networks (NTN) utilizes the low-altitude airspace for commercial and social flying activities. The integration of NTN and terres- trial networks leads to the emergence of low-altitude economy (LAE). A series of LAE application scenarios are enabled by the sensing, communication, and transportation functionalities of the aircrafts. The prerequisite technologies supporting LAE are introduced in this paper, including the network coverage and aircrafts detection. The LAE functionalities assisted by aircrafts with respect to sensing and communication are then summarized, including the terrestrial and non-terrestrial targets sensing, ubiquitous coverage, relaying, and traffic offloading. Finally, several future directions are identified, including aircrafts collaboration, energy efficiency, and artificial intelligence enabled LAE.","sentences":["The unprecedented development of non-terrestrial networks (NTN) utilizes the low-altitude airspace for commercial and social flying activities.","The integration of NTN and terres- trial networks leads to the emergence of low-altitude economy (LAE).","A series of LAE application scenarios are enabled by the sensing, communication, and transportation functionalities of the aircrafts.","The prerequisite technologies supporting LAE are introduced in this paper, including the network coverage and aircrafts detection.","The LAE functionalities assisted by aircrafts with respect to sensing and communication are then summarized, including the terrestrial and non-terrestrial targets sensing, ubiquitous coverage, relaying, and traffic offloading.","Finally, several future directions are identified, including aircrafts collaboration, energy efficiency, and artificial intelligence enabled LAE."],"url":"http://arxiv.org/abs/2311.09047v1"}
{"created":"2023-11-15 15:31:53","title":"Modeling Health Video Consumption Behaviors on Social Media: Activities, Challenges, and Characteristics","abstract":"Many people now watch health videos, such as diet, exercise, mental health, COVID-19, and chronic disease videos, on social media. Most existing studies focused on video creators, leaving the motivations and practices of viewers underexplored. We interviewed 18 participants, surveyed 121 respondents, and derived a model characterizing consumers' video consumption practices on social media. The practices include five main activities: deciding to watch videos driven by various motivations, accessing videos on social media through a socio-technical ecosystem, watching videos to meet informational, emotional, and entertainment needs, evaluating the credibility and interestingness of videos, and using videos to achieve health goals. The five activities do not necessarily proceed in a linear fashion; rather, their arrangement is situational, depending on individuals' motivations and their social and technological environments. We further identified challenges that consumers face while consuming health videos on social media and discussed design implications and directions for future research.","sentences":["Many people now watch health videos, such as diet, exercise, mental health, COVID-19, and chronic disease videos, on social media.","Most existing studies focused on video creators, leaving the motivations and practices of viewers underexplored.","We interviewed 18 participants, surveyed 121 respondents, and derived a model characterizing consumers' video consumption practices on social media.","The practices include five main activities: deciding to watch videos driven by various motivations, accessing videos on social media through a socio-technical ecosystem, watching videos to meet informational, emotional, and entertainment needs, evaluating the credibility and interestingness of videos, and using videos to achieve health goals.","The five activities do not necessarily proceed in a linear fashion; rather, their arrangement is situational, depending on individuals' motivations and their social and technological environments.","We further identified challenges that consumers face while consuming health videos on social media and discussed design implications and directions for future research."],"url":"http://arxiv.org/abs/2311.09040v1"}
{"created":"2023-11-15 15:25:28","title":"MELA: Multilingual Evaluation of Linguistic Acceptability","abstract":"Recent benchmarks for Large Language Models (LLMs) have mostly focused on application-driven tasks such as complex reasoning and code generation, and this has led to a scarcity in purely linguistic evaluation of LLMs. Against this background, we introduce Multilingual Evaluation of Linguistic Acceptability -- MELA, the first multilingual benchmark on linguistic acceptability with 48K samples covering 10 languages from a diverse set of language families. We establish baselines of commonly used LLMs along with supervised models, and conduct cross-lingual transfer and multi-task learning experiments with XLM-R. In pursuit of multilingual interpretability, we analyze the weights of fine-tuned XLM-R to explore the possibility of identifying transfer difficulty between languages. Our results show that ChatGPT benefits much from in-context examples but still lags behind fine-tuned XLM-R, while the performance of GPT-4 is on par with fine-tuned XLM-R even in zero-shot setting. Cross-lingual and multi-task learning experiments show that unlike semantic tasks, in-language training data is crucial in acceptability judgements. Results in layerwise probing indicate that the upper layers of XLM-R become a task-specific but language-agnostic region for multilingual acceptability judgment. We also introduce the concept of conflicting weight, which could be a potential indicator for the difficulty of cross-lingual transfer between languages. Our data will be available at https://github.com/sjtu-compling/MELA.","sentences":["Recent benchmarks for Large Language Models (LLMs) have mostly focused on application-driven tasks such as complex reasoning and code generation, and this has led to a scarcity in purely linguistic evaluation of LLMs.","Against this background, we introduce Multilingual Evaluation of Linguistic Acceptability -- MELA, the first multilingual benchmark on linguistic acceptability with 48K samples covering 10 languages from a diverse set of language families.","We establish baselines of commonly used LLMs along with supervised models, and conduct cross-lingual transfer and multi-task learning experiments with XLM-R. In pursuit of multilingual interpretability, we analyze the weights of fine-tuned XLM-R to explore the possibility of identifying transfer difficulty between languages.","Our results show that ChatGPT benefits much from in-context examples but still lags behind fine-tuned XLM-R, while the performance of GPT-4 is on par with fine-tuned XLM-R even in zero-shot setting.","Cross-lingual and multi-task learning experiments show that unlike semantic tasks, in-language training data is crucial in acceptability judgements.","Results in layerwise probing indicate that the upper layers of XLM-R become a task-specific but language-agnostic region for multilingual acceptability judgment.","We also introduce the concept of conflicting weight, which could be a potential indicator for the difficulty of cross-lingual transfer between languages.","Our data will be available at https://github.com/sjtu-compling/MELA."],"url":"http://arxiv.org/abs/2311.09033v1"}
{"created":"2023-11-15 15:25:08","title":"Nahida: In-Band Distributed Tracing with eBPF","abstract":"Microservices are commonly used in modern cloud-native applications to achieve agility. However, the complexity of service dependencies in large-scale microservices systems can lead to anomaly propagation, making fault troubleshooting a challenge. To address this issue, distributed tracing systems have been proposed to trace complete request execution paths, enabling developers to troubleshoot anomalous services. However, existing distributed tracing systems have limitations such as invasive instrumentation, trace loss, or inaccurate trace correlation. To overcome these limitations, we propose a new tracing system based on eBPF (extended Berkeley Packet Filter), named Nahida, that can track complete requests in the kernel without intrusion, regardless of programming language or implementation. Our evaluation results show that Nahida can track over 92% of requests with stable accuracy, even under the high concurrency of user requests, while the state-of-the-art non-invasive approaches can not track any of the requests. Importantly, Nahida can track requests served by a multi-threaded application that none of the existing invasive tracing systems can handle by instrumenting tracing codes into libraries. Moreover, the overhead introduced by Nahida is negligible, increasing service latency by only 1.55%-2.1%. Overall, Nahida provides an effective and non-invasive solution for distributed tracing.","sentences":["Microservices are commonly used in modern cloud-native applications to achieve agility.","However, the complexity of service dependencies in large-scale microservices systems can lead to anomaly propagation, making fault troubleshooting a challenge.","To address this issue, distributed tracing systems have been proposed to trace complete request execution paths, enabling developers to troubleshoot anomalous services.","However, existing distributed tracing systems have limitations such as invasive instrumentation, trace loss, or inaccurate trace correlation.","To overcome these limitations, we propose a new tracing system based on eBPF (extended Berkeley Packet Filter), named Nahida, that can track complete requests in the kernel without intrusion, regardless of programming language or implementation.","Our evaluation results show that Nahida can track over 92% of requests with stable accuracy, even under the high concurrency of user requests, while the state-of-the-art non-invasive approaches can not track any of the requests.","Importantly, Nahida can track requests served by a multi-threaded application that none of the existing invasive tracing systems can handle by instrumenting tracing codes into libraries.","Moreover, the overhead introduced by Nahida is negligible, increasing service latency by only 1.55%-2.1%.","Overall, Nahida provides an effective and non-invasive solution for distributed tracing."],"url":"http://arxiv.org/abs/2311.09032v1"}
{"created":"2023-11-15 15:24:57","title":"Integrating Sensing, Communication, and Power Transfer: From Theory to Practice","abstract":"To support the development of internet-of-things applications, an enormous population of low-power devices are expected to be incorporated in wireless networks performing sensing and communication tasks. As a key technology for improving the data collection efficiency, integrated sensing and communication (ISAC) enables simultaneous data transmission and radar sensing by reusing the same radio signals. In addition to information carriers, wireless signals can also serve as energy delivers, which enables simultaneous wireless information and power transfer (SWIPT). To improve the energy and spectrum efficiency, the advantages of ISAC and SWIPT are expected to be exploited, leading to the emerging technology of integrating sensing, communication, and power transfer (ISCPT). In this article, a timely overview of ISCPT is provided with the description of the fundamentals, the characterization of the theoretical boundary, the discussion on the key technologies, and the demonstration of the implementation platform.","sentences":["To support the development of internet-of-things applications, an enormous population of low-power devices are expected to be incorporated in wireless networks performing sensing and communication tasks.","As a key technology for improving the data collection efficiency, integrated sensing and communication (ISAC) enables simultaneous data transmission and radar sensing by reusing the same radio signals.","In addition to information carriers, wireless signals can also serve as energy delivers, which enables simultaneous wireless information and power transfer (SWIPT).","To improve the energy and spectrum efficiency, the advantages of ISAC and SWIPT are expected to be exploited, leading to the emerging technology of integrating sensing, communication, and power transfer (ISCPT).","In this article, a timely overview of ISCPT is provided with the description of the fundamentals, the characterization of the theoretical boundary, the discussion on the key technologies, and the demonstration of the implementation platform."],"url":"http://arxiv.org/abs/2311.09031v1"}
{"created":"2023-11-15 15:20:24","title":"Self-Annotated 3D Geometric Learning for Smeared Points Removal","abstract":"There has been significant progress in improving the accuracy and quality of consumer-level dense depth sensors. Nevertheless, there remains a common depth pixel artifact which we call smeared points. These are points not on any 3D surface and typically occur as interpolations between foreground and background objects. As they cause fictitious surfaces, these points have the potential to harm applications dependent on the depth maps. Statistical outlier removal methods fare poorly in removing these points as they tend also to remove actual surface points. Trained network-based point removal faces difficulty in obtaining sufficient annotated data. To address this, we propose a fully self-annotated method to train a smeared point removal classifier. Our approach relies on gathering 3D geometric evidence from multiple perspectives to automatically detect and annotate smeared points and valid points. To validate the effectiveness of our method, we present a new benchmark dataset: the Real Azure-Kinect dataset. Experimental results and ablation studies show that our method outperforms traditional filters and other self-annotated methods. Our work is publicly available at https://github.com/wangmiaowei/wacv2024_smearedremover.git.","sentences":["There has been significant progress in improving the accuracy and quality of consumer-level dense depth sensors.","Nevertheless, there remains a common depth pixel artifact which we call smeared points.","These are points not on any 3D surface and typically occur as interpolations between foreground and background objects.","As they cause fictitious surfaces, these points have the potential to harm applications dependent on the depth maps.","Statistical outlier removal methods fare poorly in removing these points as they tend also to remove actual surface points.","Trained network-based point removal faces difficulty in obtaining sufficient annotated data.","To address this, we propose a fully self-annotated method to train a smeared point removal classifier.","Our approach relies on gathering 3D geometric evidence from multiple perspectives to automatically detect and annotate smeared points and valid points.","To validate the effectiveness of our method, we present a new benchmark dataset: the Real Azure-Kinect dataset.","Experimental results and ablation studies show that our method outperforms traditional filters and other self-annotated methods.","Our work is publicly available at https://github.com/wangmiaowei/wacv2024_smearedremover.git."],"url":"http://arxiv.org/abs/2311.09029v1"}
{"created":"2023-11-15 15:16:24","title":"Integrating Sensing, Communication, and Power Transfer: Multiuser Beamforming Design","abstract":"In the sixth-generation (6G) networks, massive low-power devices are expected to sense environment and deliver tremendous data. To enhance the radio resource efficiency, the integrated sensing and communication (ISAC) technique exploits the sensing and communication functionalities of signals, while the simultaneous wireless information and power transfer (SWIPT) techniques utilizes the same signals as the carriers for both information and power delivery. The further combination of ISAC and SWIPT leads to the advanced technology namely integrated sensing, communication, and power transfer (ISCPT). In this paper, a multi-user multiple-input multiple-output (MIMO) ISCPT system is considered, where a base station equipped with multiple antennas transmits messages to multiple information receivers (IRs), transfers power to multiple energy receivers (ERs), and senses a target simultaneously. The sensing target can be regarded as a point or an extended surface. When the locations of IRs and ERs are separated, the MIMO beamforming designs are optimized to improve the sensing performance while meeting the communication and power transfer requirements. The resultant non-convex optimization problems are solved based on a series of techniques including Schur complement transformation and rank reduction. Moreover, when the IRs and ERs are co-located, the power splitting factors are jointly optimized together with the beamformers to balance the performance of communication and power transfer. To better understand the performance of ISCPT, the target positioning problem is further investigated. Simulations are conducted to verify the effectiveness of our proposed designs, which also reveal a performance tradeoff among sensing, communication, and power transfer.","sentences":["In the sixth-generation (6G) networks, massive low-power devices are expected to sense environment and deliver tremendous data.","To enhance the radio resource efficiency, the integrated sensing and communication (ISAC) technique exploits the sensing and communication functionalities of signals, while the simultaneous wireless information and power transfer (SWIPT) techniques utilizes the same signals as the carriers for both information and power delivery.","The further combination of ISAC and SWIPT leads to the advanced technology namely integrated sensing, communication, and power transfer (ISCPT).","In this paper, a multi-user multiple-input multiple-output (MIMO) ISCPT system is considered, where a base station equipped with multiple antennas transmits messages to multiple information receivers (IRs), transfers power to multiple energy receivers (ERs), and senses a target simultaneously.","The sensing target can be regarded as a point or an extended surface.","When the locations of IRs and ERs are separated, the MIMO beamforming designs are optimized to improve the sensing performance while meeting the communication and power transfer requirements.","The resultant non-convex optimization problems are solved based on a series of techniques including Schur complement transformation and rank reduction.","Moreover, when the IRs and ERs are co-located, the power splitting factors are jointly optimized together with the beamformers to balance the performance of communication and power transfer.","To better understand the performance of ISCPT, the target positioning problem is further investigated.","Simulations are conducted to verify the effectiveness of our proposed designs, which also reveal a performance tradeoff among sensing, communication, and power transfer."],"url":"http://arxiv.org/abs/2311.09028v1"}
{"created":"2023-11-15 15:15:57","title":"Assessing the Robustness of Intelligence-Driven Reinforcement Learning","abstract":"Robustness to noise is of utmost importance in reinforcement learning systems, particularly in military contexts where high stakes and uncertain environments prevail. Noise and uncertainty are inherent features of military operations, arising from factors such as incomplete information, adversarial actions, or unpredictable battlefield conditions. In RL, noise can critically impact decision-making, mission success, and the safety of personnel. Reward machines offer a powerful tool to express complex reward structures in RL tasks, enabling the design of tailored reinforcement signals that align with mission objectives. This paper considers the problem of the robustness of intelligence-driven reinforcement learning based on reward machines. The preliminary results presented suggest the need for further research in evidential reasoning and learning to harden current state-of-the-art reinforcement learning approaches before being mission-critical-ready.","sentences":["Robustness to noise is of utmost importance in reinforcement learning systems, particularly in military contexts where high stakes and uncertain environments prevail.","Noise and uncertainty are inherent features of military operations, arising from factors such as incomplete information, adversarial actions, or unpredictable battlefield conditions.","In RL, noise can critically impact decision-making, mission success, and the safety of personnel.","Reward machines offer a powerful tool to express complex reward structures in RL tasks, enabling the design of tailored reinforcement signals that align with mission objectives.","This paper considers the problem of the robustness of intelligence-driven reinforcement learning based on reward machines.","The preliminary results presented suggest the need for further research in evidential reasoning and learning to harden current state-of-the-art reinforcement learning approaches before being mission-critical-ready."],"url":"http://arxiv.org/abs/2311.09027v1"}
{"created":"2023-11-15 15:14:16","title":"Fast Certification of Vision-Language Models Using Incremental Randomized Smoothing","abstract":"A key benefit of deep vision-language models such as CLIP is that they enable zero-shot open vocabulary classification; the user has the ability to define novel class labels via natural language prompts at inference time. However, while CLIP-based zero-shot classifiers have demonstrated competitive performance across a range of domain shifts, they remain highly vulnerable to adversarial attacks. Therefore, ensuring the robustness of such models is crucial for their reliable deployment in the wild.   In this work, we introduce Open Vocabulary Certification (OVC), a fast certification method designed for open-vocabulary models like CLIP via randomized smoothing techniques. Given a base \"training\" set of prompts and their corresponding certified CLIP classifiers, OVC relies on the observation that a classifier with a novel prompt can be viewed as a perturbed version of nearby classifiers in the base training set. Therefore, OVC can rapidly certify the novel classifier using a variation of incremental randomized smoothing. By using a caching trick, we achieve approximately two orders of magnitude acceleration in the certification process for novel prompts. To achieve further (heuristic) speedups, OVC approximates the embedding space at a given input using a multivariate normal distribution bypassing the need for sampling via forward passes through the vision backbone. We demonstrate the effectiveness of OVC on through experimental evaluation using multiple vision-language backbones on the CIFAR-10 and ImageNet test datasets.","sentences":["A key benefit of deep vision-language models such as CLIP is that they enable zero-shot open vocabulary classification; the user has the ability to define novel class labels via natural language prompts at inference time.","However, while CLIP-based zero-shot classifiers have demonstrated competitive performance across a range of domain shifts, they remain highly vulnerable to adversarial attacks.","Therefore, ensuring the robustness of such models is crucial for their reliable deployment in the wild.   ","In this work, we introduce Open Vocabulary Certification (OVC), a fast certification method designed for open-vocabulary models like CLIP via randomized smoothing techniques.","Given a base \"training\" set of prompts and their corresponding certified CLIP classifiers, OVC relies on the observation that a classifier with a novel prompt can be viewed as a perturbed version of nearby classifiers in the base training set.","Therefore, OVC can rapidly certify the novel classifier using a variation of incremental randomized smoothing.","By using a caching trick, we achieve approximately two orders of magnitude acceleration in the certification process for novel prompts.","To achieve further (heuristic) speedups, OVC approximates the embedding space at a given input using a multivariate normal distribution bypassing the need for sampling via forward passes through the vision backbone.","We demonstrate the effectiveness of OVC on through experimental evaluation using multiple vision-language backbones on the CIFAR-10 and ImageNet test datasets."],"url":"http://arxiv.org/abs/2311.09024v1"}
{"created":"2023-11-15 15:12:15","title":"Exploring the Potential of Large Language Models in Computational Argumentation","abstract":"Computational argumentation has become an essential tool in various fields, including artificial intelligence, law, and public policy. It is an emerging research field in natural language processing (NLP) that attracts increasing attention. Research on computational argumentation mainly involves two types of tasks: argument mining and argument generation. As large language models (LLMs) have demonstrated strong abilities in understanding context and generating natural language, it is worthwhile to evaluate the performance of LLMs on various computational argumentation tasks. This work aims to embark on an assessment of LLMs, such as ChatGPT, Flan models and LLaMA2 models, under zero-shot and few-shot settings within the realm of computational argumentation. We organize existing tasks into 6 main classes and standardise the format of 14 open-sourced datasets. In addition, we present a new benchmark dataset on counter speech generation, that aims to holistically evaluate the end-to-end performance of LLMs on argument mining and argument generation. Extensive experiments show that LLMs exhibit commendable performance across most of these datasets, demonstrating their capabilities in the field of argumentation. We also highlight the limitations in evaluating computational argumentation and provide suggestions for future research directions in this field.","sentences":["Computational argumentation has become an essential tool in various fields, including artificial intelligence, law, and public policy.","It is an emerging research field in natural language processing (NLP) that attracts increasing attention.","Research on computational argumentation mainly involves two types of tasks: argument mining and argument generation.","As large language models (LLMs) have demonstrated strong abilities in understanding context and generating natural language, it is worthwhile to evaluate the performance of LLMs on various computational argumentation tasks.","This work aims to embark on an assessment of LLMs, such as ChatGPT, Flan models and LLaMA2 models, under zero-shot and few-shot settings within the realm of computational argumentation.","We organize existing tasks into 6 main classes and standardise the format of 14 open-sourced datasets.","In addition, we present a new benchmark dataset on counter speech generation, that aims to holistically evaluate the end-to-end performance of LLMs on argument mining and argument generation.","Extensive experiments show that LLMs exhibit commendable performance across most of these datasets, demonstrating their capabilities in the field of argumentation.","We also highlight the limitations in evaluating computational argumentation and provide suggestions for future research directions in this field."],"url":"http://arxiv.org/abs/2311.09022v1"}
{"created":"2023-11-15 15:08:38","title":"Explaining Explanation: An Empirical Study on Explanation in Code Reviews","abstract":"Code review is an important process for quality assurance in software development. For an effective code review, the reviewers must explain their feedback to enable the authors of the code change to act on them. However, the explanation needs may differ among developers, who may require different types of explanations. It is therefore crucial to understand what kind of explanations reviewers usually use in code reviews. To the best of our knowledge, no study published to date has analyzed the types of explanations used in code review. In this study, we present the first analysis of explanations in useful code reviews. We extracted a set of code reviews based on their usefulness and labeled them based on whether they contained an explanation, a solution, or both a proposed solution and an explanation thereof.   Based on our analysis, we found that a significant portion of the code review comments (46%) only include solutions without providing an explanation. We further investigated the remaining 54% of code review comments containing an explanation and conducted an open card sorting to categorize the reviewers' explanations. We distilled seven distinct categories of explanations based on the expression forms developers used. Then, we utilize large language models, specifically ChatGPT, to assist developers in getting a code review explanation that suits their preferences. Specifically, we created prompts to transform a code review explanation into a specific type of explanation. Our evaluation results show that ChatGPT correctly generated the specified type of explanation in 88/90 cases and that 89/90 of the cases have the correct explanation. Overall, our study provides insights into the types of explanations that developers use in code review and showcases how ChatGPT can be leveraged during the code review process to generate a specific type of explanation.","sentences":["Code review is an important process for quality assurance in software development.","For an effective code review, the reviewers must explain their feedback to enable the authors of the code change to act on them.","However, the explanation needs may differ among developers, who may require different types of explanations.","It is therefore crucial to understand what kind of explanations reviewers usually use in code reviews.","To the best of our knowledge, no study published to date has analyzed the types of explanations used in code review.","In this study, we present the first analysis of explanations in useful code reviews.","We extracted a set of code reviews based on their usefulness and labeled them based on whether they contained an explanation, a solution, or both a proposed solution and an explanation thereof.   ","Based on our analysis, we found that a significant portion of the code review comments (46%) only include solutions without providing an explanation.","We further investigated the remaining 54% of code review comments containing an explanation and conducted an open card sorting to categorize the reviewers' explanations.","We distilled seven distinct categories of explanations based on the expression forms developers used.","Then, we utilize large language models, specifically ChatGPT, to assist developers in getting a code review explanation that suits their preferences.","Specifically, we created prompts to transform a code review explanation into a specific type of explanation.","Our evaluation results show that ChatGPT correctly generated the specified type of explanation in 88/90 cases and that 89/90 of the cases have the correct explanation.","Overall, our study provides insights into the types of explanations that developers use in code review and showcases how ChatGPT can be leveraged during the code review process to generate a specific type of explanation."],"url":"http://arxiv.org/abs/2311.09020v1"}
{"created":"2023-11-15 15:02:23","title":"On the Foundation of Distributionally Robust Reinforcement Learning","abstract":"Motivated by the need for a robust policy in the face of environment shifts between training and the deployment, we contribute to the theoretical foundation of distributionally robust reinforcement learning (DRRL). This is accomplished through a comprehensive modeling framework centered around distributionally robust Markov decision processes (DRMDPs). This framework obliges the decision maker to choose an optimal policy under the worst-case distributional shift orchestrated by an adversary. By unifying and extending existing formulations, we rigorously construct DRMDPs that embraces various modeling attributes for both the decision maker and the adversary. These attributes include adaptability granularity, exploring history-dependent, Markov, and Markov time-homogeneous decision maker and adversary dynamics. Additionally, we delve into the flexibility of shifts induced by the adversary, examining SA and S-rectangularity. Within this DRMDP framework, we investigate conditions for the existence or absence of the dynamic programming principle (DPP). From an algorithmic standpoint, the existence of DPP holds significant implications, as the vast majority of existing data and computationally efficiency RL algorithms are reliant on the DPP. To study its existence, we comprehensively examine combinations of controller and adversary attributes, providing streamlined proofs grounded in a unified methodology. We also offer counterexamples for settings in which a DPP with full generality is absent.","sentences":["Motivated by the need for a robust policy in the face of environment shifts between training and the deployment, we contribute to the theoretical foundation of distributionally robust reinforcement learning (DRRL).","This is accomplished through a comprehensive modeling framework centered around distributionally robust Markov decision processes (DRMDPs).","This framework obliges the decision maker to choose an optimal policy under the worst-case distributional shift orchestrated by an adversary.","By unifying and extending existing formulations, we rigorously construct DRMDPs that embraces various modeling attributes for both the decision maker and the adversary.","These attributes include adaptability granularity, exploring history-dependent, Markov, and Markov time-homogeneous decision maker and adversary dynamics.","Additionally, we delve into the flexibility of shifts induced by the adversary, examining SA and S-rectangularity.","Within this DRMDP framework, we investigate conditions for the existence or absence of the dynamic programming principle (DPP).","From an algorithmic standpoint, the existence of DPP holds significant implications, as the vast majority of existing data and computationally efficiency RL algorithms are reliant on the DPP.","To study its existence, we comprehensively examine combinations of controller and adversary attributes, providing streamlined proofs grounded in a unified methodology.","We also offer counterexamples for settings in which a DPP with full generality is absent."],"url":"http://arxiv.org/abs/2311.09018v1"}
