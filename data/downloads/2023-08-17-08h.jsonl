{"created":"2023-08-16 17:59:13","title":"TeCH: Text-guided Reconstruction of Lifelike Clothed Humans","abstract":"Despite recent research advancements in reconstructing clothed humans from a single image, accurately restoring the \"unseen regions\" with high-level details remains an unsolved challenge that lacks attention. Existing methods often generate overly smooth back-side surfaces with a blurry texture. But how to effectively capture all visual attributes of an individual from a single image, which are sufficient to reconstruct unseen areas (e.g., the back view)? Motivated by the power of foundation models, TeCH reconstructs the 3D human by leveraging 1) descriptive text prompts (e.g., garments, colors, hairstyles) which are automatically generated via a garment parsing model and Visual Question Answering (VQA), 2) a personalized fine-tuned Text-to-Image diffusion model (T2I) which learns the \"indescribable\" appearance. To represent high-resolution 3D clothed humans at an affordable cost, we propose a hybrid 3D representation based on DMTet, which consists of an explicit body shape grid and an implicit distance field. Guided by the descriptive prompts + personalized T2I diffusion model, the geometry and texture of the 3D humans are optimized through multi-view Score Distillation Sampling (SDS) and reconstruction losses based on the original observation. TeCH produces high-fidelity 3D clothed humans with consistent & delicate texture, and detailed full-body geometry. Quantitative and qualitative experiments demonstrate that TeCH outperforms the state-of-the-art methods in terms of reconstruction accuracy and rendering quality. The code will be publicly available for research purposes at https://huangyangyi.github.io/tech","sentences":["Despite recent research advancements in reconstructing clothed humans from a single image, accurately restoring the \"unseen regions\" with high-level details remains an unsolved challenge that lacks attention.","Existing methods often generate overly smooth back-side surfaces with a blurry texture.","But how to effectively capture all visual attributes of an individual from a single image, which are sufficient to reconstruct unseen areas (e.g., the back view)?","Motivated by the power of foundation models, TeCH reconstructs the 3D human by leveraging 1) descriptive text prompts (e.g., garments, colors, hairstyles) which are automatically generated via a garment parsing model and Visual Question Answering (VQA), 2) a personalized fine-tuned Text-to-Image diffusion model (T2I) which learns the \"indescribable\" appearance.","To represent high-resolution 3D clothed humans at an affordable cost, we propose a hybrid 3D representation based on DMTet, which consists of an explicit body shape grid and an implicit distance field.","Guided by the descriptive prompts + personalized T2I diffusion model, the geometry and texture of the 3D humans are optimized through multi-view Score Distillation Sampling (SDS) and reconstruction losses based on the original observation.","TeCH produces high-fidelity 3D clothed humans with consistent & delicate texture, and detailed full-body geometry.","Quantitative and qualitative experiments demonstrate that TeCH outperforms the state-of-the-art methods in terms of reconstruction accuracy and rendering quality.","The code will be publicly available for research purposes at https://huangyangyi.github.io/tech"],"url":"http://arxiv.org/abs/2308.08545v1"}
{"created":"2023-08-16 17:58:34","title":"MeViS: A Large-scale Benchmark for Video Segmentation with Motion Expressions","abstract":"This paper strives for motion expressions guided video segmentation, which focuses on segmenting objects in video content based on a sentence describing the motion of the objects. Existing referring video object datasets typically focus on salient objects and use language expressions that contain excessive static attributes that could potentially enable the target object to be identified in a single frame. These datasets downplay the importance of motion in video content for language-guided video object segmentation. To investigate the feasibility of using motion expressions to ground and segment objects in videos, we propose a large-scale dataset called MeViS, which contains numerous motion expressions to indicate target objects in complex environments. We benchmarked 5 existing referring video object segmentation (RVOS) methods and conducted a comprehensive comparison on the MeViS dataset. The results show that current RVOS methods cannot effectively address motion expression-guided video segmentation. We further analyze the challenges and propose a baseline approach for the proposed MeViS dataset. The goal of our benchmark is to provide a platform that enables the development of effective language-guided video segmentation algorithms that leverage motion expressions as a primary cue for object segmentation in complex video scenes. The proposed MeViS dataset has been released at https://henghuiding.github.io/MeViS.","sentences":["This paper strives for motion expressions guided video segmentation, which focuses on segmenting objects in video content based on a sentence describing the motion of the objects.","Existing referring video object datasets typically focus on salient objects and use language expressions that contain excessive static attributes that could potentially enable the target object to be identified in a single frame.","These datasets downplay the importance of motion in video content for language-guided video object segmentation.","To investigate the feasibility of using motion expressions to ground and segment objects in videos, we propose a large-scale dataset called MeViS, which contains numerous motion expressions to indicate target objects in complex environments.","We benchmarked 5 existing referring video object segmentation (RVOS) methods and conducted a comprehensive comparison on the MeViS dataset.","The results show that current RVOS methods cannot effectively address motion expression-guided video segmentation.","We further analyze the challenges and propose a baseline approach for the proposed MeViS dataset.","The goal of our benchmark is to provide a platform that enables the development of effective language-guided video segmentation algorithms that leverage motion expressions as a primary cue for object segmentation in complex video scenes.","The proposed MeViS dataset has been released at https://henghuiding.github.io/MeViS."],"url":"http://arxiv.org/abs/2308.08544v1"}
{"created":"2023-08-16 17:58:28","title":"InsightMapper: A Closer Look at Inner-instance Information for Vectorized High-Definition Mapping","abstract":"Vectorized high-definition (HD) maps contain detailed information about surrounding road elements, which are crucial for various downstream tasks in modern autonomous driving vehicles, such as vehicle planning and control. Recent works have attempted to directly detect the vectorized HD map as a point set prediction task, resulting in significant improvements in detection performance. However, these approaches fail to analyze and exploit the inner-instance correlations between predicted points, impeding further advancements. To address these challenges, we investigate the utilization of inner-$\\textbf{INS}$tance information for vectorized h$\\textbf{IGH}$-definition mapping through $\\textbf{T}$ransformers and introduce InsightMapper. This paper presents three novel designs within InsightMapper that leverage inner-instance information in distinct ways, including hybrid query generation, inner-instance query fusion, and inner-instance feature aggregation. Comparative experiments are conducted on the NuScenes dataset, showcasing the superiority of our proposed method. InsightMapper surpasses previous state-of-the-art (SOTA) methods by 5.78 mAP and 5.12 TOPO, which assess topology correctness. Simultaneously, InsightMapper maintains high efficiency during both training and inference phases, resulting in remarkable comprehensive performance. The project page for this work is available at https://tonyxuqaq.github.io/projects/InsightMapper .","sentences":["Vectorized high-definition (HD) maps contain detailed information about surrounding road elements, which are crucial for various downstream tasks in modern autonomous driving vehicles, such as vehicle planning and control.","Recent works have attempted to directly detect the vectorized HD map as a point set prediction task, resulting in significant improvements in detection performance.","However, these approaches fail to analyze and exploit the inner-instance correlations between predicted points, impeding further advancements.","To address these challenges, we investigate the utilization of inner-$\\textbf{INS}$tance information for vectorized h$\\textbf{IGH}$-definition mapping through $\\textbf{T}$ransformers and introduce InsightMapper.","This paper presents three novel designs within InsightMapper that leverage inner-instance information in distinct ways, including hybrid query generation, inner-instance query fusion, and inner-instance feature aggregation.","Comparative experiments are conducted on the NuScenes dataset, showcasing the superiority of our proposed method.","InsightMapper surpasses previous state-of-the-art (SOTA) methods by 5.78 mAP and 5.12 TOPO, which assess topology correctness.","Simultaneously, InsightMapper maintains high efficiency during both training and inference phases, resulting in remarkable comprehensive performance.","The project page for this work is available at https://tonyxuqaq.github.io/projects/InsightMapper ."],"url":"http://arxiv.org/abs/2308.08543v1"}
{"created":"2023-08-16 17:53:40","title":"Proprioceptive Learning with Soft Polyhedral Networks","abstract":"Proprioception is the \"sixth sense\" that detects limb postures with motor neurons. It requires a natural integration between the musculoskeletal systems and sensory receptors, which is challenging among modern robots that aim for lightweight, adaptive, and sensitive designs at a low cost. Here, we present the Soft Polyhedral Network with an embedded vision for physical interactions, capable of adaptive kinesthesia and viscoelastic proprioception by learning kinetic features. This design enables passive adaptations to omni-directional interactions, visually captured by a miniature high-speed motion tracking system embedded inside for proprioceptive learning. The results show that the soft network can infer real-time 6D forces and torques with accuracies of 0.25/0.24/0.35 N and 0.025/0.034/0.006 Nm in dynamic interactions. We also incorporate viscoelasticity in proprioception during static adaptation by adding a creep and relaxation modifier to refine the predicted results. The proposed soft network combines simplicity in design, omni-adaptation, and proprioceptive sensing with high accuracy, making it a versatile solution for robotics at a low cost with more than 1 million use cycles for tasks such as sensitive and competitive grasping, and touch-based geometry reconstruction. This study offers new insights into vision-based proprioception for soft robots in adaptive grasping, soft manipulation, and human-robot interaction.","sentences":["Proprioception is the \"sixth sense\" that detects limb postures with motor neurons.","It requires a natural integration between the musculoskeletal systems and sensory receptors, which is challenging among modern robots that aim for lightweight, adaptive, and sensitive designs at a low cost.","Here, we present the Soft Polyhedral Network with an embedded vision for physical interactions, capable of adaptive kinesthesia and viscoelastic proprioception by learning kinetic features.","This design enables passive adaptations to omni-directional interactions, visually captured by a miniature high-speed motion tracking system embedded inside for proprioceptive learning.","The results show that the soft network can infer real-time 6D forces and torques with accuracies of 0.25/0.24/0.35 N and 0.025/0.034/0.006 Nm in dynamic interactions.","We also incorporate viscoelasticity in proprioception during static adaptation by adding a creep and relaxation modifier to refine the predicted results.","The proposed soft network combines simplicity in design, omni-adaptation, and proprioceptive sensing with high accuracy, making it a versatile solution for robotics at a low cost with more than 1 million use cycles for tasks such as sensitive and competitive grasping, and touch-based geometry reconstruction.","This study offers new insights into vision-based proprioception for soft robots in adaptive grasping, soft manipulation, and human-robot interaction."],"url":"http://arxiv.org/abs/2308.08538v1"}
{"created":"2023-08-16 17:40:18","title":"Ref-DVGO: Reflection-Aware Direct Voxel Grid Optimization for an Improved Quality-Efficiency Trade-Off in Reflective Scene Reconstructio","abstract":"Neural Radiance Fields (NeRFs) have revolutionized the field of novel view synthesis, demonstrating remarkable performance. However, the modeling and rendering of reflective objects remain challenging problems. Recent methods have shown significant improvements over the baselines in handling reflective scenes, albeit at the expense of efficiency. In this work, we aim to strike a balance between efficiency and quality. To this end, we investigate an implicit-explicit approach based on conventional volume rendering to enhance the reconstruction quality and accelerate the training and rendering processes. We adopt an efficient density-based grid representation and reparameterize the reflected radiance in our pipeline. Our proposed reflection-aware approach achieves a competitive quality efficiency trade-off compared to competing methods. Based on our experimental results, we propose and discuss hypotheses regarding the factors influencing the results of density-based methods for reconstructing reflective objects. The source code is available at: https://github.com/gkouros/ref-dvgo","sentences":["Neural Radiance Fields (NeRFs) have revolutionized the field of novel view synthesis, demonstrating remarkable performance.","However, the modeling and rendering of reflective objects remain challenging problems.","Recent methods have shown significant improvements over the baselines in handling reflective scenes, albeit at the expense of efficiency.","In this work, we aim to strike a balance between efficiency and quality.","To this end, we investigate an implicit-explicit approach based on conventional volume rendering to enhance the reconstruction quality and accelerate the training and rendering processes.","We adopt an efficient density-based grid representation and reparameterize the reflected radiance in our pipeline.","Our proposed reflection-aware approach achieves a competitive quality efficiency trade-off compared to competing methods.","Based on our experimental results, we propose and discuss hypotheses regarding the factors influencing the results of density-based methods for reconstructing reflective objects.","The source code is available at: https://github.com/gkouros/ref-dvgo"],"url":"http://arxiv.org/abs/2308.08530v1"}
{"created":"2023-08-16 17:39:15","title":"Diagnosing Human-object Interaction Detectors","abstract":"Although we have witnessed significant progress in human-object interaction (HOI) detection with increasingly high mAP (mean Average Precision), a single mAP score is too concise to obtain an informative summary of a model's performance and to understand why one approach is better than another. In this paper, we introduce a diagnosis toolbox for analyzing the error sources of the existing HOI detection models. We first conduct holistic investigations in the pipeline of HOI detection, consisting of human-object pair detection and then interaction classification. We define a set of errors and the oracles to fix each of them. By measuring the mAP improvement obtained from fixing an error using its oracle, we can have a detailed analysis of the significance of different errors. We then delve into the human-object detection and interaction classification, respectively, and check the model's behavior. For the first detection task, we investigate both recall and precision, measuring the coverage of ground-truth human-object pairs as well as the noisiness level in the detections. For the second classification task, we compute mAP for interaction classification only, without considering the detection scores. We also measure the performance of the models in differentiating human-object pairs with and without actual interactions using the AP (Average Precision) score. Our toolbox is applicable for different methods across different datasets and available at https://github.com/neu-vi/Diag-HOI.","sentences":["Although we have witnessed significant progress in human-object interaction (HOI) detection with increasingly high mAP (mean Average Precision), a single mAP score is too concise to obtain an informative summary of a model's performance and to understand why one approach is better than another.","In this paper, we introduce a diagnosis toolbox for analyzing the error sources of the existing HOI detection models.","We first conduct holistic investigations in the pipeline of HOI detection, consisting of human-object pair detection and then interaction classification.","We define a set of errors and the oracles to fix each of them.","By measuring the mAP improvement obtained from fixing an error using its oracle, we can have a detailed analysis of the significance of different errors.","We then delve into the human-object detection and interaction classification, respectively, and check the model's behavior.","For the first detection task, we investigate both recall and precision, measuring the coverage of ground-truth human-object pairs as well as the noisiness level in the detections.","For the second classification task, we compute mAP for interaction classification only, without considering the detection scores.","We also measure the performance of the models in differentiating human-object pairs with and without actual interactions using the AP (Average Precision) score.","Our toolbox is applicable for different methods across different datasets and available at https://github.com/neu-vi/Diag-HOI."],"url":"http://arxiv.org/abs/2308.08529v1"}
{"created":"2023-08-16 17:31:08","title":"Patterns and Pathways: Applying Social Network Analysis to Understand User Behavior in the Tourism Industry Websites","abstract":"The contemporary tourism landscape is undergoing rapid digitization, necessitating a nuanced comprehension of online user behavior to guide data-driven decision-making. This research bridges an existing gap by investigating the tourism website ecosystem through social network analysis. It focuses specifically on inter-website communication patterns based on user navigation. Data mining facilitates the identification of 162 core Iranian tourism websites, which are visualized as an interconnected network with websites as nodes and user transitions as weighted directed edges. By implementing community detection, eight key clusters are discerned, encompassing domains like ticket/tour bookings, accommodations, location services, and cuisine. Further analysis of inter-community relationships reveals website groupings frequently accessed together by users, highlighting complementary services sought during travel planning. The research derives invaluable insights into user preferences and information propagation within the tourism ecosystem. The methodology and findings contribute original perspectives to academia while offering pragmatic strategic recommendations to industry stakeholders like service providers, investors, and policymakers. This pioneering exploration of latent user behavior patterns advances comprehension of the evolving digital tourism landscape in Iran. It contributes pathways toward a sustainable future vision of the ecosystem, guiding stakeholders in targeted decision-making based on empirical evidence derived from social network analysis of websites and consumption patterns. The innovative methodology expands the toolkit for data-driven tourism research within academia.","sentences":["The contemporary tourism landscape is undergoing rapid digitization, necessitating a nuanced comprehension of online user behavior to guide data-driven decision-making.","This research bridges an existing gap by investigating the tourism website ecosystem through social network analysis.","It focuses specifically on inter-website communication patterns based on user navigation.","Data mining facilitates the identification of 162 core Iranian tourism websites, which are visualized as an interconnected network with websites as nodes and user transitions as weighted directed edges.","By implementing community detection, eight key clusters are discerned, encompassing domains like ticket/tour bookings, accommodations, location services, and cuisine.","Further analysis of inter-community relationships reveals website groupings frequently accessed together by users, highlighting complementary services sought during travel planning.","The research derives invaluable insights into user preferences and information propagation within the tourism ecosystem.","The methodology and findings contribute original perspectives to academia while offering pragmatic strategic recommendations to industry stakeholders like service providers, investors, and policymakers.","This pioneering exploration of latent user behavior patterns advances comprehension of the evolving digital tourism landscape in Iran.","It contributes pathways toward a sustainable future vision of the ecosystem, guiding stakeholders in targeted decision-making based on empirical evidence derived from social network analysis of websites and consumption patterns.","The innovative methodology expands the toolkit for data-driven tourism research within academia."],"url":"http://arxiv.org/abs/2308.08527v1"}
{"created":"2023-08-16 17:26:47","title":"Likelihood-Based Text-to-Image Evaluation with Patch-Level Perceptual and Semantic Credit Assignment","abstract":"Text-to-image synthesis has made encouraging progress and attracted lots of public attention recently. However, popular evaluation metrics in this area, like the Inception Score and Fr'echet Inception Distance, incur several issues. First of all, they cannot explicitly assess the perceptual quality of generated images and poorly reflect the semantic alignment of each text-image pair. Also, they are inefficient and need to sample thousands of images to stabilise their evaluation results. In this paper, we propose to evaluate text-to-image generation performance by directly estimating the likelihood of the generated images using a pre-trained likelihood-based text-to-image generative model, i.e., a higher likelihood indicates better perceptual quality and better text-image alignment. To prevent the likelihood of being dominated by the non-crucial part of the generated image, we propose several new designs to develop a credit assignment strategy based on the semantic and perceptual significance of the image patches. In the experiments, we evaluate the proposed metric on multiple popular text-to-image generation models and datasets in accessing both the perceptual quality and the text-image alignment. Moreover, it can successfully assess the generation ability of these models with as few as a hundred samples, making it very efficient in practice.","sentences":["Text-to-image synthesis has made encouraging progress and attracted lots of public attention recently.","However, popular evaluation metrics in this area, like the Inception Score and Fr'echet Inception Distance, incur several issues.","First of all, they cannot explicitly assess the perceptual quality of generated images and poorly reflect the semantic alignment of each text-image pair.","Also, they are inefficient and need to sample thousands of images to stabilise their evaluation results.","In this paper, we propose to evaluate text-to-image generation performance by directly estimating the likelihood of the generated images using a pre-trained likelihood-based text-to-image generative model, i.e., a higher likelihood indicates better perceptual quality and better text-image alignment.","To prevent the likelihood of being dominated by the non-crucial part of the generated image, we propose several new designs to develop a credit assignment strategy based on the semantic and perceptual significance of the image patches.","In the experiments, we evaluate the proposed metric on multiple popular text-to-image generation models and datasets in accessing both the perceptual quality and the text-image alignment.","Moreover, it can successfully assess the generation ability of these models with as few as a hundred samples, making it very efficient in practice."],"url":"http://arxiv.org/abs/2308.08525v1"}
{"created":"2023-08-16 17:20:46","title":"Improved Approximations for Translational Packing of Convex Polygons","abstract":"Optimal packing of objects in containers is a critical problem in various real-life and industrial applications. This paper investigates the two-dimensional packing of convex polygons without rotations, where only translations are allowed. We study different settings depending on the type of containers used, including minimizing the number of containers or the size of the container based on an objective function.   Building on prior research in the field, we develop polynomial-time algorithms with improved approximation guarantees upon the best-known results by Alt, de Berg and Knauer, as well as Aamand, Abrahamsen, Beretta and Kleist, for problems such as Polygon Area Minimization, Polygon Perimeter Minimization, Polygon Strip Packing, and Polygon Bin Packing. Our approach utilizes a sequence of object transformations that allows sorting by height and orientation, thus enhancing the effectiveness of shelf packing algorithms for polygon packing problems. In addition, we present efficient approximation algorithms for special cases of the Polygon Bin Packing problem, progressing toward solving an open question concerning an O(1)-approximation algorithm for arbitrary polygons.","sentences":["Optimal packing of objects in containers is a critical problem in various real-life and industrial applications.","This paper investigates the two-dimensional packing of convex polygons without rotations, where only translations are allowed.","We study different settings depending on the type of containers used, including minimizing the number of containers or the size of the container based on an objective function.   ","Building on prior research in the field, we develop polynomial-time algorithms with improved approximation guarantees upon the best-known results by Alt, de Berg and Knauer, as well as Aamand, Abrahamsen, Beretta and Kleist, for problems such as Polygon Area Minimization, Polygon Perimeter Minimization, Polygon Strip Packing, and Polygon Bin Packing.","Our approach utilizes a sequence of object transformations that allows sorting by height and orientation, thus enhancing the effectiveness of shelf packing algorithms for polygon packing problems.","In addition, we present efficient approximation algorithms for special cases of the Polygon Bin Packing problem, progressing toward solving an open question concerning an O(1)-approximation algorithm for arbitrary polygons."],"url":"http://arxiv.org/abs/2308.08523v1"}
{"created":"2023-08-16 17:18:30","title":"Painter: Teaching Auto-regressive Language Models to Draw Sketches","abstract":"Large language models (LLMs) have made tremendous progress in natural language understanding and they have also been successfully adopted in other domains such as computer vision, robotics, reinforcement learning, etc. In this work, we apply LLMs to image generation tasks by directly generating the virtual brush strokes to paint an image. We present Painter, an LLM that can convert user prompts in text description format to sketches by generating the corresponding brush strokes in an auto-regressive way. We construct Painter based on off-the-shelf LLM that is pre-trained on a large text corpus, by fine-tuning it on the new task while preserving language understanding capabilities. We create a dataset of diverse multi-object sketches paired with textual prompts that covers several object types and tasks. Painter can generate sketches from text descriptions, remove objects from canvas, and detect and classify objects in sketches. Although this is an unprecedented pioneering work in using LLMs for auto-regressive image generation, the results are very encouraging.","sentences":["Large language models (LLMs) have made tremendous progress in natural language understanding and they have also been successfully adopted in other domains such as computer vision, robotics, reinforcement learning, etc.","In this work, we apply LLMs to image generation tasks by directly generating the virtual brush strokes to paint an image.","We present Painter, an LLM that can convert user prompts in text description format to sketches by generating the corresponding brush strokes in an auto-regressive way.","We construct Painter based on off-the-shelf LLM that is pre-trained on a large text corpus, by fine-tuning it on the new task while preserving language understanding capabilities.","We create a dataset of diverse multi-object sketches paired with textual prompts that covers several object types and tasks.","Painter can generate sketches from text descriptions, remove objects from canvas, and detect and classify objects in sketches.","Although this is an unprecedented pioneering work in using LLMs for auto-regressive image generation, the results are very encouraging."],"url":"http://arxiv.org/abs/2308.08520v1"}
{"created":"2023-08-16 17:13:45","title":"Exploiting Point-Wise Attention in 6D Object Pose Estimation Based on Bidirectional Prediction","abstract":"Traditional geometric registration based estimation methods only exploit the CAD model implicitly, which leads to their dependence on observation quality and deficiency to occlusion.To address the problem,the paper proposes a bidirectional correspondence prediction network with a point-wise attention-aware mechanism. This network not only requires the model points to predict the correspondence but also explicitly models the geometric similarities between observations and the model prior.} Our key insight is that the correlations between each model point and scene point provide essential information for learning point-pair matches. To further tackle the correlation noises brought by feature distribution divergence, we design a simple but effective pseudo-siamese network to improve feature homogeneity.Experimental results on the public datasets of LineMOD, YCB-Video, and Occ-LineMOD show that the proposed method achieves better performance than other state-of-the-art methods under the same evaluation criteria. Its robustness in estimating poses is greatly improved, especially in an environment with severe occlusions.","sentences":["Traditional geometric registration based estimation methods only exploit the CAD model implicitly, which leads to their dependence on observation quality and deficiency to occlusion.","To address the problem,the paper proposes a bidirectional correspondence prediction network with a point-wise attention-aware mechanism.","This network not only requires the model points to predict the correspondence but also explicitly models the geometric similarities between observations and the model prior.}","Our key insight is that the correlations between each model point and scene point provide essential information for learning point-pair matches.","To further tackle the correlation noises brought by feature distribution divergence, we design a simple but effective pseudo-siamese network to improve feature homogeneity.","Experimental results on the public datasets of LineMOD, YCB-Video, and Occ-LineMOD show that the proposed method achieves better performance than other state-of-the-art methods under the same evaluation criteria.","Its robustness in estimating poses is greatly improved, especially in an environment with severe occlusions."],"url":"http://arxiv.org/abs/2308.08518v1"}
{"created":"2023-08-16 17:07:37","title":"Autoencoding a Soft Touch to Learn Grasping from On-land to Underwater","abstract":"Robots play a critical role as the physical agent of human operators in exploring the ocean. However, it remains challenging to grasp objects reliably while fully submerging under a highly pressurized aquatic environment with little visible light, mainly due to the fluidic interference on the tactile mechanics between the finger and object surfaces. This study investigates the transferability of grasping knowledge from on-land to underwater via a vision-based soft robotic finger that learns 6D forces and torques (FT) using a Supervised Variational Autoencoder (SVAE). A high-framerate camera captures the whole-body deformations while a soft robotic finger interacts with physical objects on-land and underwater. Results show that the trained SVAE model learned a series of latent representations of the soft mechanics transferrable from land to water, presenting a superior adaptation to the changing environments against commercial FT sensors. Soft, delicate, and reactive grasping enabled by tactile intelligence enhances the gripper's underwater interaction with improved reliability and robustness at a much-reduced cost, paving the path for learning-based intelligent grasping to support fundamental scientific discoveries in environmental and ocean research.","sentences":["Robots play a critical role as the physical agent of human operators in exploring the ocean.","However, it remains challenging to grasp objects reliably while fully submerging under a highly pressurized aquatic environment with little visible light, mainly due to the fluidic interference on the tactile mechanics between the finger and object surfaces.","This study investigates the transferability of grasping knowledge from on-land to underwater via a vision-based soft robotic finger that learns 6D forces and torques (FT) using a Supervised Variational Autoencoder (SVAE).","A high-framerate camera captures the whole-body deformations while a soft robotic finger interacts with physical objects on-land and underwater.","Results show that the trained SVAE model learned a series of latent representations of the soft mechanics transferrable from land to water, presenting a superior adaptation to the changing environments against commercial FT sensors.","Soft, delicate, and reactive grasping enabled by tactile intelligence enhances the gripper's underwater interaction with improved reliability and robustness at a much-reduced cost, paving the path for learning-based intelligent grasping to support fundamental scientific discoveries in environmental and ocean research."],"url":"http://arxiv.org/abs/2308.08510v1"}
{"created":"2023-08-16 17:00:32","title":"Test-Time Poisoning Attacks Against Test-Time Adaptation Models","abstract":"Deploying machine learning (ML) models in the wild is challenging as it suffers from distribution shifts, where the model trained on an original domain cannot generalize well to unforeseen diverse transfer domains. To address this challenge, several test-time adaptation (TTA) methods have been proposed to improve the generalization ability of the target pre-trained models under test data to cope with the shifted distribution. The success of TTA can be credited to the continuous fine-tuning of the target model according to the distributional hint from the test samples during test time. Despite being powerful, it also opens a new attack surface, i.e., test-time poisoning attacks, which are substantially different from previous poisoning attacks that occur during the training time of ML models (i.e., adversaries cannot intervene in the training process). In this paper, we perform the first test-time poisoning attack against four mainstream TTA methods, including TTT, DUA, TENT, and RPL. Concretely, we generate poisoned samples based on the surrogate models and feed them to the target TTA models. Experimental results show that the TTA methods are generally vulnerable to test-time poisoning attacks. For instance, the adversary can feed as few as 10 poisoned samples to degrade the performance of the target model from 76.20% to 41.83%. Our results demonstrate that TTA algorithms lacking a rigorous security assessment are unsuitable for deployment in real-life scenarios. As such, we advocate for the integration of defenses against test-time poisoning attacks into the design of TTA methods.","sentences":["Deploying machine learning (ML) models in the wild is challenging as it suffers from distribution shifts, where the model trained on an original domain cannot generalize well to unforeseen diverse transfer domains.","To address this challenge, several test-time adaptation (TTA) methods have been proposed to improve the generalization ability of the target pre-trained models under test data to cope with the shifted distribution.","The success of TTA can be credited to the continuous fine-tuning of the target model according to the distributional hint from the test samples during test time.","Despite being powerful, it also opens a new attack surface, i.e., test-time poisoning attacks, which are substantially different from previous poisoning attacks that occur during the training time of ML models (i.e., adversaries cannot intervene in the training process).","In this paper, we perform the first test-time poisoning attack against four mainstream TTA methods, including TTT, DUA, TENT, and RPL.","Concretely, we generate poisoned samples based on the surrogate models and feed them to the target TTA models.","Experimental results show that the TTA methods are generally vulnerable to test-time poisoning attacks.","For instance, the adversary can feed as few as 10 poisoned samples to degrade the performance of the target model from 76.20% to 41.83%.","Our results demonstrate that TTA algorithms lacking a rigorous security assessment are unsuitable for deployment in real-life scenarios.","As such, we advocate for the integration of defenses against test-time poisoning attacks into the design of TTA methods."],"url":"http://arxiv.org/abs/2308.08505v1"}
{"created":"2023-08-16 16:58:25","title":"ResBuilder: Automated Learning of Depth with Residual Structures","abstract":"In this work, we develop a neural architecture search algorithm, termed Resbuilder, that develops ResNet architectures from scratch that achieve high accuracy at moderate computational cost. It can also be used to modify existing architectures and has the capability to remove and insert ResNet blocks, in this way searching for suitable architectures in the space of ResNet architectures. In our experiments on different image classification datasets, Resbuilder achieves close to state-of-the-art performance while saving computational cost compared to off-the-shelf ResNets. Noteworthy, we once tune the parameters on CIFAR10 which yields a suitable default choice for all other datasets. We demonstrate that this property generalizes even to industrial applications by applying our method with default parameters on a proprietary fraud detection dataset.","sentences":["In this work, we develop a neural architecture search algorithm, termed Resbuilder, that develops ResNet architectures from scratch that achieve high accuracy at moderate computational cost.","It can also be used to modify existing architectures and has the capability to remove and insert ResNet blocks, in this way searching for suitable architectures in the space of ResNet architectures.","In our experiments on different image classification datasets, Resbuilder achieves close to state-of-the-art performance while saving computational cost compared to off-the-shelf ResNets.","Noteworthy, we once tune the parameters on CIFAR10 which yields a suitable default choice for all other datasets.","We demonstrate that this property generalizes even to industrial applications by applying our method with default parameters on a proprietary fraud detection dataset."],"url":"http://arxiv.org/abs/2308.08504v1"}
{"created":"2023-08-16 16:49:50","title":"Self-Supervised Online Camera Calibration for Automated Driving and Parking Applications","abstract":"Camera-based perception systems play a central role in modern autonomous vehicles. These camera based perception algorithms require an accurate calibration to map the real world distances to image pixels. In practice, calibration is a laborious procedure requiring specialised data collection and careful tuning. This process must be repeated whenever the parameters of the camera change, which can be a frequent occurrence in autonomous vehicles. Hence there is a need to calibrate at regular intervals to ensure the camera is accurate. Proposed is a deep learning framework to learn intrinsic and extrinsic calibration of the camera in real time. The framework is self-supervised and doesn't require any labelling or supervision to learn the calibration parameters. The framework learns calibration without the need for any physical targets or to drive the car on special planar surfaces.","sentences":["Camera-based perception systems play a central role in modern autonomous vehicles.","These camera based perception algorithms require an accurate calibration to map the real world distances to image pixels.","In practice, calibration is a laborious procedure requiring specialised data collection and careful tuning.","This process must be repeated whenever the parameters of the camera change, which can be a frequent occurrence in autonomous vehicles.","Hence there is a need to calibrate at regular intervals to ensure the camera is accurate.","Proposed is a deep learning framework to learn intrinsic and extrinsic calibration of the camera in real time.","The framework is self-supervised and doesn't require any labelling or supervision to learn the calibration parameters.","The framework learns calibration without the need for any physical targets or to drive the car on special planar surfaces."],"url":"http://arxiv.org/abs/2308.08495v1"}
{"created":"2023-08-16 16:48:57","title":"Time Travel in LLMs: Tracing Data Contamination in Large Language Models","abstract":"Data contamination, i.e., the presence of test data from downstream tasks in the training data of large language models (LLMs), is a potential major issue in understanding LLMs' effectiveness on other tasks. We propose a straightforward yet effective method for identifying data contamination within LLMs. At its core, our approach starts by identifying potential contamination in individual instances that are drawn from a small random sample; using this information, our approach then assesses if an entire dataset partition is contaminated. To estimate contamination of individual instances, we employ \"guided instruction:\" a prompt consisting of the dataset name, partition type, and the initial segment of a reference instance, asking the LLM to complete it. An instance is flagged as contaminated if the LLM's output either exactly or closely matches the latter segment of the reference. To understand if an entire partition is contaminated, we propose two ideas. The first idea marks a dataset partition as contaminated if the average overlap score with the reference instances (as measured by ROUGE or BLEURT) is statistically significantly better with the guided instruction vs. a general instruction that does not include the dataset and partition name. The second idea marks a dataset as contaminated if a classifier based on GPT-4 with in-context learning prompting marks multiple instances as contaminated. Our best method achieves an accuracy between 92% and 100% in detecting if an LLM is contaminated with seven datasets, containing train and test/validation partitions, when contrasted with manual evaluation by human expert. Further, our findings indicate that GPT-4 is contaminated with AG News, WNLI, and XSum datasets.","sentences":["Data contamination, i.e., the presence of test data from downstream tasks in the training data of large language models (LLMs), is a potential major issue in understanding LLMs' effectiveness on other tasks.","We propose a straightforward yet effective method for identifying data contamination within LLMs.","At its core, our approach starts by identifying potential contamination in individual instances that are drawn from a small random sample; using this information, our approach then assesses if an entire dataset partition is contaminated.","To estimate contamination of individual instances, we employ \"guided instruction:\" a prompt consisting of the dataset name, partition type, and the initial segment of a reference instance, asking the LLM to complete it.","An instance is flagged as contaminated if the LLM's output either exactly or closely matches the latter segment of the reference.","To understand if an entire partition is contaminated, we propose two ideas.","The first idea marks a dataset partition as contaminated if the average overlap score with the reference instances (as measured by ROUGE or BLEURT) is statistically significantly better with the guided instruction vs. a general instruction that does not include the dataset and partition name.","The second idea marks a dataset as contaminated if a classifier based on GPT-4 with in-context learning prompting marks multiple instances as contaminated.","Our best method achieves an accuracy between 92% and 100% in detecting if an LLM is contaminated with seven datasets, containing train and test/validation partitions, when contrasted with manual evaluation by human expert.","Further, our findings indicate that GPT-4 is contaminated with AG News, WNLI, and XSum datasets."],"url":"http://arxiv.org/abs/2308.08493v1"}
{"created":"2023-08-16 16:40:16","title":"Taming Horizontal Instability in Merge Trees: On the Computation of a Comprehensive Deformation-based Edit Distance","abstract":"Comparative analysis of scalar fields in scientific visualization often involves distance functions on topological abstractions. This paper focuses on the merge tree abstraction (representing the nesting of sub- or superlevel sets) and proposes the application of the unconstrained deformation-based edit distance. Previous approaches on merge trees often suffer from instability: small perturbations in the data can lead to large distances of the abstractions. While some existing methods can handle so-called vertical instability, the unconstrained deformation-based edit distance addresses both vertical and horizontal instabilities, also called saddle swaps. We establish the computational complexity as NP-complete, and provide an integer linear program formulation for computation. Experimental results on the TOSCA shape matching ensemble provide evidence for the stability of the proposed distance. We thereby showcase the potential of handling saddle swaps for comparison of scalar fields through merge trees.","sentences":["Comparative analysis of scalar fields in scientific visualization often involves distance functions on topological abstractions.","This paper focuses on the merge tree abstraction (representing the nesting of sub- or superlevel sets) and proposes the application of the unconstrained deformation-based edit distance.","Previous approaches on merge trees often suffer from instability: small perturbations in the data can lead to large distances of the abstractions.","While some existing methods can handle so-called vertical instability, the unconstrained deformation-based edit distance addresses both vertical and horizontal instabilities, also called saddle swaps.","We establish the computational complexity as NP-complete, and provide an integer linear program formulation for computation.","Experimental results on the TOSCA shape matching ensemble provide evidence for the stability of the proposed distance.","We thereby showcase the potential of handling saddle swaps for comparison of scalar fields through merge trees."],"url":"http://arxiv.org/abs/2308.08484v1"}
{"created":"2023-08-16 16:38:03","title":"Label Propagation Techniques for Artifact Detection in Imbalanced Classes using Photoplethysmogram Signals","abstract":"Photoplethysmogram (PPG) signals are widely used in healthcare for monitoring vital signs, but they are susceptible to motion artifacts that can lead to inaccurate interpretations. In this study, the use of label propagation techniques to propagate labels among PPG samples is explored, particularly in imbalanced class scenarios where clean PPG samples are significantly outnumbered by artifact-contaminated samples. With a precision of 91%, a recall of 90% and an F1 score of 90% for the class without artifacts, the results demonstrate its effectiveness in labeling a medical dataset, even when clean samples are rare. For the classification of artifacts our study compares supervised classifiers such as conventional classifiers and neural networks (MLP, Transformers, FCN) with the semi-supervised label propagation algorithm. With a precision of 89%, a recall of 95% and an F1 score of 92%, the KNN supervised model gives good results, but the semi-supervised algorithm performs better in detecting artifacts. The findings suggest that the semi-supervised algorithm label propagation hold promise for artifact detection in PPG signals, which can enhance the reliability of PPG-based health monitoring systems in real-world applications.","sentences":["Photoplethysmogram (PPG) signals are widely used in healthcare for monitoring vital signs, but they are susceptible to motion artifacts that can lead to inaccurate interpretations.","In this study, the use of label propagation techniques to propagate labels among PPG samples is explored, particularly in imbalanced class scenarios where clean PPG samples are significantly outnumbered by artifact-contaminated samples.","With a precision of 91%, a recall of 90% and an F1 score of 90% for the class without artifacts, the results demonstrate its effectiveness in labeling a medical dataset, even when clean samples are rare.","For the classification of artifacts our study compares supervised classifiers such as conventional classifiers and neural networks (MLP, Transformers, FCN) with the semi-supervised label propagation algorithm.","With a precision of 89%, a recall of 95% and an F1 score of 92%, the KNN supervised model gives good results, but the semi-supervised algorithm performs better in detecting artifacts.","The findings suggest that the semi-supervised algorithm label propagation hold promise for artifact detection in PPG signals, which can enhance the reliability of PPG-based health monitoring systems in real-world applications."],"url":"http://arxiv.org/abs/2308.08480v1"}
{"created":"2023-08-16 16:37:02","title":"DeDoDe: Detect, Don't Describe -- Describe, Don't Detect for Local Feature Matching","abstract":"Keypoint detection is a pivotal step in 3D reconstruction, whereby sets of (up to) K points are detected in each view of a scene. Crucially, the detected points need to be consistent between views, i.e., correspond to the same 3D point in the scene. One of the main challenges with keypoint detection is the formulation of the learning objective. Previous learning-based methods typically jointly learn descriptors with keypoints, and treat the keypoint detection as a binary classification task on mutual nearest neighbours. However, basing keypoint detection on descriptor nearest neighbours is a proxy task, which is not guaranteed to produce 3D-consistent keypoints. Furthermore, this ties the keypoints to a specific descriptor, complicating downstream usage. In this work, we instead learn keypoints directly from 3D consistency. To this end, we train the detector to detect tracks from large-scale SfM. As these points are often overly sparse, we derive a semi-supervised two-view detection objective to expand this set to a desired number of detections. To train a descriptor, we maximize the mutual nearest neighbour objective over the keypoints with a separate network. Results show that our approach, DeDoDe, achieves significant gains on multiple geometry benchmarks. Code is provided at https://github.com/Parskatt/DeDoDe .","sentences":["Keypoint detection is a pivotal step in 3D reconstruction, whereby sets of (up to) K points are detected in each view of a scene.","Crucially, the detected points need to be consistent between views, i.e., correspond to the same 3D point in the scene.","One of the main challenges with keypoint detection is the formulation of the learning objective.","Previous learning-based methods typically jointly learn descriptors with keypoints, and treat the keypoint detection as a binary classification task on mutual nearest neighbours.","However, basing keypoint detection on descriptor nearest neighbours is a proxy task, which is not guaranteed to produce 3D-consistent keypoints.","Furthermore, this ties the keypoints to a specific descriptor, complicating downstream usage.","In this work, we instead learn keypoints directly from 3D consistency.","To this end, we train the detector to detect tracks from large-scale SfM.","As these points are often overly sparse, we derive a semi-supervised two-view detection objective to expand this set to a desired number of detections.","To train a descriptor, we maximize the mutual nearest neighbour objective over the keypoints with a separate network.","Results show that our approach, DeDoDe, achieves significant gains on multiple geometry benchmarks.","Code is provided at https://github.com/Parskatt/DeDoDe ."],"url":"http://arxiv.org/abs/2308.08479v1"}
{"created":"2023-08-16 16:31:36","title":"Classification Committee for Active Deep Object Detection","abstract":"In object detection, the cost of labeling is much high because it needs not only to confirm the categories of multiple objects in an image but also to accurately determine the bounding boxes of each object. Thus, integrating active learning into object detection will raise pretty positive significance. In this paper, we propose a classification committee for active deep object detection method by introducing a discrepancy mechanism of multiple classifiers for samples' selection when training object detectors. The model contains a main detector and a classification committee. The main detector denotes the target object detector trained from a labeled pool composed of the selected informative images. The role of the classification committee is to select the most informative images according to their uncertainty values from the view of classification, which is expected to focus more on the discrepancy and representative of instances. Specifically, they compute the uncertainty for a specified instance within the image by measuring its discrepancy output by the committee pre-trained via the proposed Maximum Classifiers Discrepancy Group Loss (MCDGL). The most informative images are finally determined by selecting the ones with many high-uncertainty instances. Besides, to mitigate the impact of interference instances, we design a Focus on Positive Instances Loss (FPIL) to make the committee the ability to automatically focus on the representative instances as well as precisely encode their discrepancies for the same instance. Experiments are conducted on Pascal VOC and COCO datasets versus some popular object detectors. And results show that our method outperforms the state-of-the-art active learning methods, which verifies the effectiveness of the proposed method.","sentences":["In object detection, the cost of labeling is much high because it needs not only to confirm the categories of multiple objects in an image but also to accurately determine the bounding boxes of each object.","Thus, integrating active learning into object detection will raise pretty positive significance.","In this paper, we propose a classification committee for active deep object detection method by introducing a discrepancy mechanism of multiple classifiers for samples' selection when training object detectors.","The model contains a main detector and a classification committee.","The main detector denotes the target object detector trained from a labeled pool composed of the selected informative images.","The role of the classification committee is to select the most informative images according to their uncertainty values from the view of classification, which is expected to focus more on the discrepancy and representative of instances.","Specifically, they compute the uncertainty for a specified instance within the image by measuring its discrepancy output by the committee pre-trained via the proposed Maximum Classifiers Discrepancy Group Loss (MCDGL).","The most informative images are finally determined by selecting the ones with many high-uncertainty instances.","Besides, to mitigate the impact of interference instances, we design a Focus on Positive Instances Loss (FPIL) to make the committee the ability to automatically focus on the representative instances as well as precisely encode their discrepancies for the same instance.","Experiments are conducted on Pascal VOC and COCO datasets versus some popular object detectors.","And results show that our method outperforms the state-of-the-art active learning methods, which verifies the effectiveness of the proposed method."],"url":"http://arxiv.org/abs/2308.08476v1"}
{"created":"2023-08-16 16:28:36","title":"Data Navigator: An accessibility-centered data navigation toolkit","abstract":"Making data visualizations accessible for people with disabilities remains a significant challenge in current practitioner efforts. Existing visualizations often lack an underlying navigable structure, fail to engage necessary input modalities, and rely heavily on visual-only rendering practices. These limitations exclude people with disabilities, especially users of assistive technologies. To address these challenges, we present Data Navigator: a system built on a dynamic graph structure, enabling developers to construct navigable lists, trees, graphs, and flows as well as spatial, diagrammatic, and geographic relations. Data Navigator supports a wide range of input modalities: screen reader, keyboard, speech, gesture detection, and even fabricated assistive devices. We present 3 case examples with Data Navigator, demonstrating we can provide accessible navigation structures on top of raster images, integrate with existing toolkits at scale, and rapidly develop novel prototypes. Data Navigator is a step towards making accessible data visualizations easier to design and implement.","sentences":["Making data visualizations accessible for people with disabilities remains a significant challenge in current practitioner efforts.","Existing visualizations often lack an underlying navigable structure, fail to engage necessary input modalities, and rely heavily on visual-only rendering practices.","These limitations exclude people with disabilities, especially users of assistive technologies.","To address these challenges, we present Data Navigator: a system built on a dynamic graph structure, enabling developers to construct navigable lists, trees, graphs, and flows as well as spatial, diagrammatic, and geographic relations.","Data Navigator supports a wide range of input modalities: screen reader, keyboard, speech, gesture detection, and even fabricated assistive devices.","We present 3 case examples with Data Navigator, demonstrating we can provide accessible navigation structures on top of raster images, integrate with existing toolkits at scale, and rapidly develop novel prototypes.","Data Navigator is a step towards making accessible data visualizations easier to design and implement."],"url":"http://arxiv.org/abs/2308.08475v1"}
{"created":"2023-08-16 16:23:13","title":"DataRaceBench V1.4.1 and DataRaceBench-ML V0.1: Benchmark Suites for Data Race Detection","abstract":"Data races pose a significant threat in multi-threaded parallel applications due to their negative impact on program correctness. DataRaceBench, an open-source benchmark suite, is specifically crafted to assess these data race detection tools in a systematic and measurable manner. Machine learning techniques have recently demonstrated considerable potential in high-performance computing (HPC) program analysis and optimization. However, these techniques require specialized data formats for training and refinement. This paper presents the latest update to DataRaceBench, incorporating new data race contributions from Wu et al. \\cite{wu2023model}, and introduces a derived dataset named DataRaceBench-ML (DRB-ML) \\cite{drbml}. DRB-ML aligns with the emerging trend of machine learning and large language models. Originating from DataRaceBench, this dataset includes detailed labels that denote the presence of a data race and provides comprehensive details of associated variables, such as variable names, line numbers, and the operation (read/write). Unique to DRB-ML, we have also integrated a series of tailored prompt-response pairs specifically designed for LLM fine-tuning.","sentences":["Data races pose a significant threat in multi-threaded parallel applications due to their negative impact on program correctness.","DataRaceBench, an open-source benchmark suite, is specifically crafted to assess these data race detection tools in a systematic and measurable manner.","Machine learning techniques have recently demonstrated considerable potential in high-performance computing (HPC) program analysis and optimization.","However, these techniques require specialized data formats for training and refinement.","This paper presents the latest update to DataRaceBench, incorporating new data race contributions from Wu et al. \\cite{wu2023model}, and introduces a derived dataset named DataRaceBench-ML (DRB-ML) \\cite{drbml}.","DRB-ML aligns with the emerging trend of machine learning and large language models.","Originating from DataRaceBench, this dataset includes detailed labels that denote the presence of a data race and provides comprehensive details of associated variables, such as variable names, line numbers, and the operation (read/write).","Unique to DRB-ML, we have also integrated a series of tailored prompt-response pairs specifically designed for LLM fine-tuning."],"url":"http://arxiv.org/abs/2308.08473v1"}
{"created":"2023-08-16 16:21:43","title":"An Ambient Intelligence-based Approach For Longitudinal Monitoring of Verbal and Vocal Depression Symptoms","abstract":"Automatic speech recognition (ASR) technology can aid in the detection, monitoring, and assessment of depressive symptoms in individuals. ASR systems have been used as a tool to analyze speech patterns and characteristics that are indicative of depression. Depression affects not only a person's mood but also their speech patterns. Individuals with depression may exhibit changes in speech, such as slower speech rate, longer pauses, reduced pitch variability, and decreased overall speech fluency. Despite the growing use of machine learning in diagnosing depression, there is a lack of studies addressing the issue of relapse. Furthermore, previous research on relapse prediction has primarily focused on clinical variables and has not taken into account other factors such as verbal and non-verbal cues. Another major challenge in depression relapse research is the scarcity of publicly available datasets. To overcome these issues, we propose a one-shot learning framework for detecting depression relapse from speech. We define depression relapse as the similarity between the speech audio and textual encoding of a subject and that of a depressed individual. To detect depression relapse based on this definition, we employ a Siamese neural network that models the similarity between of two instances. Our proposed approach shows promising results and represents a new advancement in the field of automatic depression relapse detection and mental disorders monitoring.","sentences":["Automatic speech recognition (ASR) technology can aid in the detection, monitoring, and assessment of depressive symptoms in individuals.","ASR systems have been used as a tool to analyze speech patterns and characteristics that are indicative of depression.","Depression affects not only a person's mood but also their speech patterns.","Individuals with depression may exhibit changes in speech, such as slower speech rate, longer pauses, reduced pitch variability, and decreased overall speech fluency.","Despite the growing use of machine learning in diagnosing depression, there is a lack of studies addressing the issue of relapse.","Furthermore, previous research on relapse prediction has primarily focused on clinical variables and has not taken into account other factors such as verbal and non-verbal cues.","Another major challenge in depression relapse research is the scarcity of publicly available datasets.","To overcome these issues, we propose a one-shot learning framework for detecting depression relapse from speech.","We define depression relapse as the similarity between the speech audio and textual encoding of a subject and that of a depressed individual.","To detect depression relapse based on this definition, we employ a Siamese neural network that models the similarity between of two instances.","Our proposed approach shows promising results and represents a new advancement in the field of automatic depression relapse detection and mental disorders monitoring."],"url":"http://arxiv.org/abs/2308.08472v1"}
{"created":"2023-08-16 16:19:50","title":"LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with Pre-Trained LLMs","abstract":"In this work, we leverage pre-trained Large Language Models (LLMs) to enhance time-series forecasting. Mirroring the growing interest in unifying models for Natural Language Processing and Computer Vision, we envision creating an analogous model for long-term time-series forecasting. Due to limited large-scale time-series data for building robust foundation models, our approach LLM4TS focuses on leveraging the strengths of pre-trained LLMs. By combining time-series patching with temporal encoding, we have enhanced the capability of LLMs to handle time-series data effectively. Inspired by the supervised fine-tuning in chatbot domains, we prioritize a two-stage fine-tuning process: first conducting supervised fine-tuning to orient the LLM towards time-series data, followed by task-specific downstream fine-tuning. Furthermore, to unlock the flexibility of pre-trained LLMs without extensive parameter adjustments, we adopt several Parameter-Efficient Fine-Tuning (PEFT) techniques. Drawing on these innovations, LLM4TS has yielded state-of-the-art results in long-term forecasting. Our model has also shown exceptional capabilities as both a robust representation learner and an effective few-shot learner, thanks to the knowledge transferred from the pre-trained LLM.","sentences":["In this work, we leverage pre-trained Large Language Models (LLMs) to enhance time-series forecasting.","Mirroring the growing interest in unifying models for Natural Language Processing and Computer Vision, we envision creating an analogous model for long-term time-series forecasting.","Due to limited large-scale time-series data for building robust foundation models, our approach LLM4TS focuses on leveraging the strengths of pre-trained LLMs.","By combining time-series patching with temporal encoding, we have enhanced the capability of LLMs to handle time-series data effectively.","Inspired by the supervised fine-tuning in chatbot domains, we prioritize a two-stage fine-tuning process: first conducting supervised fine-tuning to orient the LLM towards time-series data, followed by task-specific downstream fine-tuning.","Furthermore, to unlock the flexibility of pre-trained LLMs without extensive parameter adjustments, we adopt several Parameter-Efficient Fine-Tuning (PEFT) techniques.","Drawing on these innovations, LLM4TS has yielded state-of-the-art results in long-term forecasting.","Our model has also shown exceptional capabilities as both a robust representation learner and an effective few-shot learner, thanks to the knowledge transferred from the pre-trained LLM."],"url":"http://arxiv.org/abs/2308.08469v1"}
{"created":"2023-08-16 16:19:25","title":"An Expert's Guide to Training Physics-informed Neural Networks","abstract":"Physics-informed neural networks (PINNs) have been popularized as a deep learning framework that can seamlessly synthesize observational data and partial differential equation (PDE) constraints. Their practical effectiveness however can be hampered by training pathologies, but also oftentimes by poor choices made by users who lack deep learning expertise. In this paper we present a series of best practices that can significantly improve the training efficiency and overall accuracy of PINNs. We also put forth a series of challenging benchmark problems that highlight some of the most prominent difficulties in training PINNs, and present comprehensive and fully reproducible ablation studies that demonstrate how different architecture choices and training strategies affect the test accuracy of the resulting models. We show that the methods and guiding principles put forth in this study lead to state-of-the-art results and provide strong baselines that future studies should use for comparison purposes. To this end, we also release a highly optimized library in JAX that can be used to reproduce all results reported in this paper, enable future research studies, as well as facilitate easy adaptation to new use-case scenarios.","sentences":["Physics-informed neural networks (PINNs) have been popularized as a deep learning framework that can seamlessly synthesize observational data and partial differential equation (PDE) constraints.","Their practical effectiveness however can be hampered by training pathologies, but also oftentimes by poor choices made by users who lack deep learning expertise.","In this paper we present a series of best practices that can significantly improve the training efficiency and overall accuracy of PINNs.","We also put forth a series of challenging benchmark problems that highlight some of the most prominent difficulties in training PINNs, and present comprehensive and fully reproducible ablation studies that demonstrate how different architecture choices and training strategies affect the test accuracy of the resulting models.","We show that the methods and guiding principles put forth in this study lead to state-of-the-art results and provide strong baselines that future studies should use for comparison purposes.","To this end, we also release a highly optimized library in JAX that can be used to reproduce all results reported in this paper, enable future research studies, as well as facilitate easy adaptation to new use-case scenarios."],"url":"http://arxiv.org/abs/2308.08468v1"}
{"created":"2023-08-16 15:51:05","title":"High-Fidelity Lake Extraction via Two-Stage Prompt Enhancement: Establishing a Novel Baseline and Benchmark","abstract":"The extraction of lakes from remote sensing images is a complex challenge due to the varied lake shapes and data noise. Current methods rely on multispectral image datasets, making it challenging to learn lake features accurately from pixel arrangements. This, in turn, affects model learning and the creation of accurate segmentation masks. This paper introduces a unified prompt-based dataset construction approach that provides approximate lake locations using point, box, and mask prompts. We also propose a two-stage prompt enhancement framework, LEPrompter, which involves prompt-based and prompt-free stages during training. The prompt-based stage employs a prompt encoder to extract prior information, integrating prompt tokens and image embeddings through self- and cross-attention in the prompt decoder. Prompts are deactivated once the model is trained to ensure independence during inference, enabling automated lake extraction. Evaluations on Surface Water and Qinghai-Tibet Plateau Lake datasets show consistent performance improvements compared to the previous state-of-the-art method. LEPrompter achieves mIoU scores of 91.48% and 97.43% on the respective datasets without introducing additional parameters or GFLOPs. Supplementary materials provide the source code, pre-trained models, and detailed user studies.","sentences":["The extraction of lakes from remote sensing images is a complex challenge due to the varied lake shapes and data noise.","Current methods rely on multispectral image datasets, making it challenging to learn lake features accurately from pixel arrangements.","This, in turn, affects model learning and the creation of accurate segmentation masks.","This paper introduces a unified prompt-based dataset construction approach that provides approximate lake locations using point, box, and mask prompts.","We also propose a two-stage prompt enhancement framework, LEPrompter, which involves prompt-based and prompt-free stages during training.","The prompt-based stage employs a prompt encoder to extract prior information, integrating prompt tokens and image embeddings through self- and cross-attention in the prompt decoder.","Prompts are deactivated once the model is trained to ensure independence during inference, enabling automated lake extraction.","Evaluations on Surface Water and Qinghai-Tibet Plateau Lake datasets show consistent performance improvements compared to the previous state-of-the-art method.","LEPrompter achieves mIoU scores of 91.48% and 97.43% on the respective datasets without introducing additional parameters or GFLOPs.","Supplementary materials provide the source code, pre-trained models, and detailed user studies."],"url":"http://arxiv.org/abs/2308.08443v1"}
{"created":"2023-08-16 15:49:36","title":"Mitigating the Exposure Bias in Sentence-Level Grapheme-to-Phoneme (G2P) Transduction","abstract":"Text-to-Text Transfer Transformer (T5) has recently been considered for the Grapheme-to-Phoneme (G2P) transduction. As a follow-up, a tokenizer-free byte-level model based on T5 referred to as ByT5, recently gave promising results on word-level G2P conversion by representing each input character with its corresponding UTF-8 encoding. Although it is generally understood that sentence-level or paragraph-level G2P can improve usability in real-world applications as it is better suited to perform on heteronyms and linking sounds between words, we find that using ByT5 for these scenarios is nontrivial. Since ByT5 operates on the character level, it requires longer decoding steps, which deteriorates the performance due to the exposure bias commonly observed in auto-regressive generation models. This paper shows that the performance of sentence-level and paragraph-level G2P can be improved by mitigating such exposure bias using our proposed loss-based sampling method.","sentences":["Text-to-Text Transfer Transformer (T5) has recently been considered for the Grapheme-to-Phoneme (G2P) transduction.","As a follow-up, a tokenizer-free byte-level model based on T5 referred to as ByT5, recently gave promising results on word-level G2P conversion by representing each input character with its corresponding UTF-8 encoding.","Although it is generally understood that sentence-level or paragraph-level G2P can improve usability in real-world applications as it is better suited to perform on heteronyms and linking sounds between words, we find that using ByT5 for these scenarios is nontrivial.","Since ByT5 operates on the character level, it requires longer decoding steps, which deteriorates the performance due to the exposure bias commonly observed in auto-regressive generation models.","This paper shows that the performance of sentence-level and paragraph-level G2P can be improved by mitigating such exposure bias using our proposed loss-based sampling method."],"url":"http://arxiv.org/abs/2308.08442v1"}
{"created":"2023-08-16 15:49:28","title":"Probabilistic Ray-Tracing Aided Positioning at mmWave frequencies","abstract":"We consider the following positioning problem where several base stations (BS) try to locate a user equipment (UE): The UE sends a positioning signal to several BS. Each BS performs Angle of Arrival (AoA) measurements on the received signal. These AoA measurements as well as a 3D model of the environment are then used to locate the UE. We propose a method to exploit not only the geometrical characteristics of the environment by a ray-tracing simulation, but also the statistical characteristics of the measurements to enhance the positioning accuracy.","sentences":["We consider the following positioning problem where several base stations (BS) try to locate a user equipment (UE): The UE sends a positioning signal to several BS.","Each BS performs Angle of Arrival (AoA) measurements on the received signal.","These AoA measurements as well as a 3D model of the environment are then used to locate the UE.","We propose a method to exploit not only the geometrical characteristics of the environment by a ray-tracing simulation, but also the statistical characteristics of the measurements to enhance the positioning accuracy."],"url":"http://arxiv.org/abs/2308.08441v1"}
{"created":"2023-08-16 15:42:24","title":"Accurate synthesis of Dysarthric Speech for ASR data augmentation","abstract":"Dysarthria is a motor speech disorder often characterized by reduced speech intelligibility through slow, uncoordinated control of speech production muscles. Automatic Speech recognition (ASR) systems can help dysarthric talkers communicate more effectively. However, robust dysarthria-specific ASR requires a significant amount of training speech, which is not readily available for dysarthric talkers. This paper presents a new dysarthric speech synthesis method for the purpose of ASR training data augmentation. Differences in prosodic and acoustic characteristics of dysarthric spontaneous speech at varying severity levels are important components for dysarthric speech modeling, synthesis, and augmentation. For dysarthric speech synthesis, a modified neural multi-talker TTS is implemented by adding a dysarthria severity level coefficient and a pause insertion model to synthesize dysarthric speech for varying severity levels. To evaluate the effectiveness for synthesis of training data for ASR, dysarthria-specific speech recognition was used. Results show that a DNN-HMM model trained on additional synthetic dysarthric speech achieves WER improvement of 12.2% compared to the baseline, and that the addition of the severity level and pause insertion controls decrease WER by 6.5%, showing the effectiveness of adding these parameters. Overall results on the TORGO database demonstrate that using dysarthric synthetic speech to increase the amount of dysarthric-patterned speech for training has significant impact on the dysarthric ASR systems. In addition, we have conducted a subjective evaluation to evaluate the dysarthric-ness and similarity of synthesized speech. Our subjective evaluation shows that the perceived dysartrhic-ness of synthesized speech is similar to that of true dysarthric speech, especially for higher levels of dysarthria","sentences":["Dysarthria is a motor speech disorder often characterized by reduced speech intelligibility through slow, uncoordinated control of speech production muscles.","Automatic Speech recognition (ASR) systems can help dysarthric talkers communicate more effectively.","However, robust dysarthria-specific ASR requires a significant amount of training speech, which is not readily available for dysarthric talkers.","This paper presents a new dysarthric speech synthesis method for the purpose of ASR training data augmentation.","Differences in prosodic and acoustic characteristics of dysarthric spontaneous speech at varying severity levels are important components for dysarthric speech modeling, synthesis, and augmentation.","For dysarthric speech synthesis, a modified neural multi-talker TTS is implemented by adding a dysarthria severity level coefficient and a pause insertion model to synthesize dysarthric speech for varying severity levels.","To evaluate the effectiveness for synthesis of training data for ASR, dysarthria-specific speech recognition was used.","Results show that a DNN-HMM model trained on additional synthetic dysarthric speech achieves WER improvement of 12.2% compared to the baseline, and that the addition of the severity level and pause insertion controls decrease WER by 6.5%, showing the effectiveness of adding these parameters.","Overall results on the TORGO database demonstrate that using dysarthric synthetic speech to increase the amount of dysarthric-patterned speech for training has significant impact on the dysarthric ASR systems.","In addition, we have conducted a subjective evaluation to evaluate the dysarthric-ness and similarity of synthesized speech.","Our subjective evaluation shows that the perceived dysartrhic-ness of synthesized speech is similar to that of true dysarthric speech, especially for higher levels of dysarthria"],"url":"http://arxiv.org/abs/2308.08438v1"}
{"created":"2023-08-16 15:35:45","title":"Voxlines: Streamline Transparency through Voxelization and View-Dependent Line Orders","abstract":"As tractography datasets continue to grow in size, there is a need for improved visualization methods that can capture structural patterns occurring in large tractography datasets. Transparency is an increasingly important aspect of finding these patterns in large datasets but is inaccessible to tractography due to performance limitations. In this paper, we propose a rendering method that achieves performant rendering of transparent streamlines, allowing for exploration of deeper brain structures interactively. The method achieves this through a novel approximate order-independent transparency method that utilizes voxelization and caching view-dependent line orders per voxel. We compare our transparency method with existing tractography visualization software in terms of performance and the ability to capture deeper structures in the dataset.","sentences":["As tractography datasets continue to grow in size, there is a need for improved visualization methods that can capture structural patterns occurring in large tractography datasets.","Transparency is an increasingly important aspect of finding these patterns in large datasets but is inaccessible to tractography due to performance limitations.","In this paper, we propose a rendering method that achieves performant rendering of transparent streamlines, allowing for exploration of deeper brain structures interactively.","The method achieves this through a novel approximate order-independent transparency method that utilizes voxelization and caching view-dependent line orders per voxel.","We compare our transparency method with existing tractography visualization software in terms of performance and the ability to capture deeper structures in the dataset."],"url":"http://arxiv.org/abs/2308.08436v1"}
{"created":"2023-08-16 15:28:22","title":"A Bi-Step Grounding Paradigm for Large Language Models in Recommendation Systems","abstract":"As the focus on Large Language Models (LLMs) in the field of recommendation intensifies, the optimization of LLMs for recommendation purposes (referred to as LLM4Rec) assumes a crucial role in augmenting their effectiveness in providing recommendations. However, existing approaches for LLM4Rec often assess performance using restricted sets of candidates, which may not accurately reflect the models' overall ranking capabilities. In this paper, our objective is to investigate the comprehensive ranking capacity of LLMs and propose a two-step grounding framework known as BIGRec (Bi-step Grounding Paradigm for Recommendation). It initially grounds LLMs to the recommendation space by fine-tuning them to generate meaningful tokens for items and subsequently identifies appropriate actual items that correspond to the generated tokens. By conducting extensive experiments on two datasets, we substantiate the superior performance, capacity for handling few-shot scenarios, and versatility across multiple domains exhibited by BIGRec. Furthermore, we observe that the marginal benefits derived from increasing the quantity of training samples are modest for BIGRec, implying that LLMs possess the limited capability to assimilate statistical information, such as popularity and collaborative filtering, due to their robust semantic priors. These findings also underline the efficacy of integrating diverse statistical information into the LLM4Rec framework, thereby pointing towards a potential avenue for future research. Our code and data are available at https://github.com/SAI990323/Grounding4Rec.","sentences":["As the focus on Large Language Models (LLMs) in the field of recommendation intensifies, the optimization of LLMs for recommendation purposes (referred to as LLM4Rec) assumes a crucial role in augmenting their effectiveness in providing recommendations.","However, existing approaches for LLM4Rec often assess performance using restricted sets of candidates, which may not accurately reflect the models' overall ranking capabilities.","In this paper, our objective is to investigate the comprehensive ranking capacity of LLMs and propose a two-step grounding framework known as BIGRec (Bi-step Grounding Paradigm for Recommendation).","It initially grounds LLMs to the recommendation space by fine-tuning them to generate meaningful tokens for items and subsequently identifies appropriate actual items that correspond to the generated tokens.","By conducting extensive experiments on two datasets, we substantiate the superior performance, capacity for handling few-shot scenarios, and versatility across multiple domains exhibited by BIGRec.","Furthermore, we observe that the marginal benefits derived from increasing the quantity of training samples are modest for BIGRec, implying that LLMs possess the limited capability to assimilate statistical information, such as popularity and collaborative filtering, due to their robust semantic priors.","These findings also underline the efficacy of integrating diverse statistical information into the LLM4Rec framework, thereby pointing towards a potential avenue for future research.","Our code and data are available at https://github.com/SAI990323/Grounding4Rec."],"url":"http://arxiv.org/abs/2308.08434v1"}
{"created":"2023-08-16 15:25:15","title":"Performance Analysis of Relay Selection Schemes in Multi-Hop Decode-and-Forward Networks","abstract":"This paper analyses the data rate achieved by various relay selection schemes in a single-user multi-hop relay network with decode-and-forward (DF) relaying. While the single-user relay selection problem is well studied in the literature, research on achievable rate maximization is limited to dual-hop networks and multi-hop networks with a single relay per hop. We fill this important gap by focusing on achievable rate maximization in multi-hop, multi-relay networks. First, we consider optimal relay selection and obtain two approximations to the achievable rate. Next, we consider three existing sub-optimal relay selection strategies namely hop-by-hop, ad-hoc and block-by-block relay selection and obtain exact expressions for the achievable rate under each of these strategies. We also extend the sliding window based relay selection to the DF relay network and derive an approximation to the achievable rate. Further, we investigate the impact of window size in sliding window based relay selection and show that a window size of three is sufficient to achieve most of the possible performance gains. Finally, we extend this analysis to a noise limited multi-user network where the number of available relay nodes is large compared to the number of users and derive approximations to the achievable sum-rate.","sentences":["This paper analyses the data rate achieved by various relay selection schemes in a single-user multi-hop relay network with decode-and-forward (DF) relaying.","While the single-user relay selection problem is well studied in the literature, research on achievable rate maximization is limited to dual-hop networks and multi-hop networks with a single relay per hop.","We fill this important gap by focusing on achievable rate maximization in multi-hop, multi-relay networks.","First, we consider optimal relay selection and obtain two approximations to the achievable rate.","Next, we consider three existing sub-optimal relay selection strategies namely hop-by-hop, ad-hoc and block-by-block relay selection and obtain exact expressions for the achievable rate under each of these strategies.","We also extend the sliding window based relay selection to the DF relay network and derive an approximation to the achievable rate.","Further, we investigate the impact of window size in sliding window based relay selection and show that a window size of three is sufficient to achieve most of the possible performance gains.","Finally, we extend this analysis to a noise limited multi-user network where the number of available relay nodes is large compared to the number of users and derive approximations to the achievable sum-rate."],"url":"http://arxiv.org/abs/2308.08433v1"}
{"created":"2023-08-16 15:23:14","title":"Integrating Visual and Semantic Similarity Using Hierarchies for Image Retrieval","abstract":"Most of the research in content-based image retrieval (CBIR) focus on developing robust feature representations that can effectively retrieve instances from a database of images that are visually similar to a query. However, the retrieved images sometimes contain results that are not semantically related to the query. To address this, we propose a method for CBIR that captures both visual and semantic similarity using a visual hierarchy. The hierarchy is constructed by merging classes with overlapping features in the latent space of a deep neural network trained for classification, assuming that overlapping classes share high visual and semantic similarities. Finally, the constructed hierarchy is integrated into the distance calculation metric for similarity search. Experiments on standard datasets: CUB-200-2011 and CIFAR100, and a real-life use case using diatom microscopy images show that our method achieves superior performance compared to the existing methods on image retrieval.","sentences":["Most of the research in content-based image retrieval (CBIR) focus on developing robust feature representations that can effectively retrieve instances from a database of images that are visually similar to a query.","However, the retrieved images sometimes contain results that are not semantically related to the query.","To address this, we propose a method for CBIR that captures both visual and semantic similarity using a visual hierarchy.","The hierarchy is constructed by merging classes with overlapping features in the latent space of a deep neural network trained for classification, assuming that overlapping classes share high visual and semantic similarities.","Finally, the constructed hierarchy is integrated into the distance calculation metric for similarity search.","Experiments on standard datasets: CUB-200-2011 and CIFAR100, and a real-life use case using diatom microscopy images show that our method achieves superior performance compared to the existing methods on image retrieval."],"url":"http://arxiv.org/abs/2308.08431v1"}
{"created":"2023-08-16 15:19:52","title":"ALIP: Adaptive Language-Image Pre-training with Synthetic Caption","abstract":"Contrastive Language-Image Pre-training (CLIP) has significantly boosted the performance of various vision-language tasks by scaling up the dataset with image-text pairs collected from the web. However, the presence of intrinsic noise and unmatched image-text pairs in web data can potentially affect the performance of representation learning. To address this issue, we first utilize the OFA model to generate synthetic captions that focus on the image content. The generated captions contain complementary information that is beneficial for pre-training. Then, we propose an Adaptive Language-Image Pre-training (ALIP), a bi-path model that integrates supervision from both raw text and synthetic caption. As the core components of ALIP, the Language Consistency Gate (LCG) and Description Consistency Gate (DCG) dynamically adjust the weights of samples and image-text/caption pairs during the training process. Meanwhile, the adaptive contrastive loss can effectively reduce the impact of noise data and enhances the efficiency of pre-training data. We validate ALIP with experiments on different scales of models and pre-training datasets. Experiments results show that ALIP achieves state-of-the-art performance on multiple downstream tasks including zero-shot image-text retrieval and linear probe. To facilitate future research, the code and pre-trained models are released at https://github.com/deepglint/ALIP.","sentences":["Contrastive Language-Image Pre-training (CLIP) has significantly boosted the performance of various vision-language tasks by scaling up the dataset with image-text pairs collected from the web.","However, the presence of intrinsic noise and unmatched image-text pairs in web data can potentially affect the performance of representation learning.","To address this issue, we first utilize the OFA model to generate synthetic captions that focus on the image content.","The generated captions contain complementary information that is beneficial for pre-training.","Then, we propose an Adaptive Language-Image Pre-training (ALIP), a bi-path model that integrates supervision from both raw text and synthetic caption.","As the core components of ALIP, the Language Consistency Gate (LCG) and Description Consistency Gate (DCG) dynamically adjust the weights of samples and image-text/caption pairs during the training process.","Meanwhile, the adaptive contrastive loss can effectively reduce the impact of noise data and enhances the efficiency of pre-training data.","We validate ALIP with experiments on different scales of models and pre-training datasets.","Experiments results show that ALIP achieves state-of-the-art performance on multiple downstream tasks including zero-shot image-text retrieval and linear probe.","To facilitate future research, the code and pre-trained models are released at https://github.com/deepglint/ALIP."],"url":"http://arxiv.org/abs/2308.08428v1"}
{"created":"2023-08-16 15:05:13","title":"Porting Batched Iterative Solvers onto Intel GPUs with SYCL","abstract":"Batched linear solvers play a vital role in computational sciences, especially in the fields of plasma physics and combustion simulations. With the imminent deployment of the Aurora Supercomputer and other upcoming systems equipped with Intel GPUs, there is a compelling demand to expand the capabilities of these solvers for Intel GPU architectures. In this paper, we present our efforts in porting and optimizing the batched iterative solvers on Intel GPUs using the SYCL programming model. The SYCL-based implementation exhibits impressive performance and scalability on the Intel GPU Max 1550s (Ponte Vecchio GPUs). The solvers outperform our previous CUDA implementation on NVIDIA H100 GPUs by an average of 2.4x for the PeleLM application inputs. The batched solvers are ready for production use in real-world scientific applications through the Ginkgo library.","sentences":["Batched linear solvers play a vital role in computational sciences, especially in the fields of plasma physics and combustion simulations.","With the imminent deployment of the Aurora Supercomputer and other upcoming systems equipped with Intel GPUs, there is a compelling demand to expand the capabilities of these solvers for Intel GPU architectures.","In this paper, we present our efforts in porting and optimizing the batched iterative solvers on Intel GPUs using the SYCL programming model.","The SYCL-based implementation exhibits impressive performance and scalability on the Intel GPU Max 1550s (Ponte Vecchio GPUs).","The solvers outperform our previous CUDA implementation on NVIDIA H100 GPUs by an average of 2.4x for the PeleLM application inputs.","The batched solvers are ready for production use in real-world scientific applications through the Ginkgo library."],"url":"http://arxiv.org/abs/2308.08417v1"}
{"created":"2023-08-16 15:00:50","title":"Tem-adapter: Adapting Image-Text Pretraining for Video Question Answer","abstract":"Video-language pre-trained models have shown remarkable success in guiding video question-answering (VideoQA) tasks. However, due to the length of video sequences, training large-scale video-based models incurs considerably higher costs than training image-based ones. This motivates us to leverage the knowledge from image-based pretraining, despite the obvious gaps between image and video domains. To bridge these gaps, in this paper, we propose Tem-Adapter, which enables the learning of temporal dynamics and complex semantics by a visual Temporal Aligner and a textual Semantic Aligner. Unlike conventional pretrained knowledge adaptation methods that only concentrate on the downstream task objective, the Temporal Aligner introduces an extra language-guided autoregressive task aimed at facilitating the learning of temporal dependencies, with the objective of predicting future states based on historical clues and language guidance that describes event progression. Besides, to reduce the semantic gap and adapt the textual representation for better event description, we introduce a Semantic Aligner that first designs a template to fuse question and answer pairs as event descriptions and then learns a Transformer decoder with the whole video sequence as guidance for refinement. We evaluate Tem-Adapter and different pre-train transferring methods on two VideoQA benchmarks, and the significant performance improvement demonstrates the effectiveness of our method.","sentences":["Video-language pre-trained models have shown remarkable success in guiding video question-answering (VideoQA) tasks.","However, due to the length of video sequences, training large-scale video-based models incurs considerably higher costs than training image-based ones.","This motivates us to leverage the knowledge from image-based pretraining, despite the obvious gaps between image and video domains.","To bridge these gaps, in this paper, we propose Tem-Adapter, which enables the learning of temporal dynamics and complex semantics by a visual Temporal Aligner and a textual Semantic Aligner.","Unlike conventional pretrained knowledge adaptation methods that only concentrate on the downstream task objective, the Temporal Aligner introduces an extra language-guided autoregressive task aimed at facilitating the learning of temporal dependencies, with the objective of predicting future states based on historical clues and language guidance that describes event progression.","Besides, to reduce the semantic gap and adapt the textual representation for better event description, we introduce a Semantic Aligner that first designs a template to fuse question and answer pairs as event descriptions and then learns a Transformer decoder with the whole video sequence as guidance for refinement.","We evaluate Tem-Adapter and different pre-train transferring methods on two VideoQA benchmarks, and the significant performance improvement demonstrates the effectiveness of our method."],"url":"http://arxiv.org/abs/2308.08414v1"}
{"created":"2023-08-16 14:58:12","title":"Knowledge-Enhanced Multi-Label Few-Shot Product Attribute-Value Extraction","abstract":"Existing attribute-value extraction (AVE) models require large quantities of labeled data for training. However, new products with new attribute-value pairs enter the market every day in real-world e-Commerce. Thus, we formulate AVE in multi-label few-shot learning (FSL), aiming to extract unseen attribute value pairs based on a small number of training examples. We propose a Knowledge-Enhanced Attentive Framework (KEAF) based on prototypical networks, leveraging the generated label description and category information to learn more discriminative prototypes. Besides, KEAF integrates with hybrid attention to reduce noise and capture more informative semantics for each class by calculating the label-relevant and query-related weights. To achieve multi-label inference, KEAF further learns a dynamic threshold by integrating the semantic information from both the support set and the query set. Extensive experiments with ablation studies conducted on two datasets demonstrate that KEAF outperforms other SOTA models for information extraction in FSL. The code can be found at: https://github.com/gjiaying/KEAF","sentences":["Existing attribute-value extraction (AVE) models require large quantities of labeled data for training.","However, new products with new attribute-value pairs enter the market every day in real-world e-Commerce.","Thus, we formulate AVE in multi-label few-shot learning (FSL), aiming to extract unseen attribute value pairs based on a small number of training examples.","We propose a Knowledge-Enhanced Attentive Framework (KEAF) based on prototypical networks, leveraging the generated label description and category information to learn more discriminative prototypes.","Besides, KEAF integrates with hybrid attention to reduce noise and capture more informative semantics for each class by calculating the label-relevant and query-related weights.","To achieve multi-label inference, KEAF further learns a dynamic threshold by integrating the semantic information from both the support set and the query set.","Extensive experiments with ablation studies conducted on two datasets demonstrate that KEAF outperforms other SOTA models for information extraction in FSL.","The code can be found at: https://github.com/gjiaying/KEAF"],"url":"http://arxiv.org/abs/2308.08413v1"}
{"created":"2023-08-16 14:51:51","title":"Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities","abstract":"Recent advancements in AI applications to healthcare have shown incredible promise in surpassing human performance in diagnosis and disease prognosis. With the increasing complexity of AI models, however, concerns regarding their opacity, potential biases, and the need for interpretability. To ensure trust and reliability in AI systems, especially in clinical risk prediction models, explainability becomes crucial. Explainability is usually referred to as an AI system's ability to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders. In clinical risk prediction, other aspects of explainability like fairness, bias, trust, and transparency also represent important concepts beyond just interpretability. In this review, we address the relationship between these concepts as they are often used together or interchangeably. This review also discusses recent progress in developing explainable models for clinical risk prediction, highlighting the importance of quantitative and clinical evaluation and validation across multiple common modalities in clinical practice. It emphasizes the need for external validation and the combination of diverse interpretability methods to enhance trust and fairness. Adopting rigorous testing, such as using synthetic datasets with known generative factors, can further improve the reliability of explainability methods. Open access and code-sharing resources are essential for transparency and reproducibility, enabling the growth and trustworthiness of explainable research. While challenges exist, an end-to-end approach to explainability in clinical risk prediction, incorporating stakeholders from clinicians to developers, is essential for success.","sentences":["Recent advancements in AI applications to healthcare have shown incredible promise in surpassing human performance in diagnosis and disease prognosis.","With the increasing complexity of AI models, however, concerns regarding their opacity, potential biases, and the need for interpretability.","To ensure trust and reliability in AI systems, especially in clinical risk prediction models, explainability becomes crucial.","Explainability is usually referred to as an AI system's ability to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders.","In clinical risk prediction, other aspects of explainability like fairness, bias, trust, and transparency also represent important concepts beyond just interpretability.","In this review, we address the relationship between these concepts as they are often used together or interchangeably.","This review also discusses recent progress in developing explainable models for clinical risk prediction, highlighting the importance of quantitative and clinical evaluation and validation across multiple common modalities in clinical practice.","It emphasizes the need for external validation and the combination of diverse interpretability methods to enhance trust and fairness.","Adopting rigorous testing, such as using synthetic datasets with known generative factors, can further improve the reliability of explainability methods.","Open access and code-sharing resources are essential for transparency and reproducibility, enabling the growth and trustworthiness of explainable research.","While challenges exist, an end-to-end approach to explainability in clinical risk prediction, incorporating stakeholders from clinicians to developers, is essential for success."],"url":"http://arxiv.org/abs/2308.08407v1"}
{"created":"2023-08-16 14:50:51","title":"Content-based Recommendation Engine for Video Streaming Platform","abstract":"Recommendation engine suggest content, product or services to the user by using machine learning algorithm. This paper proposed a content-based recommendation engine for providing video suggestion to the user based on their previous interests and choices. We will use TF-IDF text vectorization method to determine the relevance of words in a document. Then we will find out the similarity between each content by calculating cosine similarity between them. Finally, engine will recommend videos to the users based on the obtained similarity score value. In addition, we will measure the engine's performance by computing precision, recall, and F1 core of the proposed system.","sentences":["Recommendation engine suggest content, product or services to the user by using machine learning algorithm.","This paper proposed a content-based recommendation engine for providing video suggestion to the user based on their previous interests and choices.","We will use TF-IDF text vectorization method to determine the relevance of words in a document.","Then we will find out the similarity between each content by calculating cosine similarity between them.","Finally, engine will recommend videos to the users based on the obtained similarity score value.","In addition, we will measure the engine's performance by computing precision, recall, and F1 core of the proposed system."],"url":"http://arxiv.org/abs/2308.08406v1"}
{"created":"2023-08-16 14:48:09","title":"A topological counterpart of well-founded trees in dependent type theory","abstract":"Within dependent type theory, we provide a topological counterpart of well-founded trees (for short, W-types) by using a proof-relevant version of the notion of inductively generated suplattices introduced in the context of formal topology under the name of inductively generated basic covers. In more detail, we show, firstly, that in Homotopy Type Theory, W-types and proof relevant inductively generated basic covers are propositionally mutually encodable. Secondly, we prove they are definitionally mutually encodable in the Agda implementation of intensional Martin-Loef's type theory. Finally, we reframe the equivalence in the Minimalist Foundation framework by introducing well-founded predicates as the logical counterpart for predicates of dependent W-types. All the results have been checked in the Agda proof-assistant.","sentences":["Within dependent type theory, we provide a topological counterpart of well-founded trees (for short, W-types) by using a proof-relevant version of the notion of inductively generated suplattices introduced in the context of formal topology under the name of inductively generated basic covers.","In more detail, we show, firstly, that in Homotopy Type Theory, W-types and proof relevant inductively generated basic covers are propositionally mutually encodable.","Secondly, we prove they are definitionally mutually encodable in the Agda implementation of intensional Martin-Loef's type theory.","Finally, we reframe the equivalence in the Minimalist Foundation framework by introducing well-founded predicates as the logical counterpart for predicates of dependent W-types.","All the results have been checked in the Agda proof-assistant."],"url":"http://arxiv.org/abs/2308.08404v1"}
{"created":"2023-08-16 14:41:30","title":"The Simplest Walking Robot: A bipedal robot with one actuator and two rigid bodies","abstract":"We present the design and experimental results of the first 1-DOF, hip-actuated bipedal robot. While passive dynamic walking is simple by nature, many existing bipeds inspired by this form of walking are complex in control, mechanical design, or both. Our design using only two rigid bodies connected by a single motor aims to enable exploration of walking at smaller sizes where more complex designs cannot be constructed. The walker, \"Mugatu\", is self-contained and autonomous, open-loop stable over a range of input parameters, able to stop and start from standing, and able to control its heading left and right. We analyze the mechanical design and distill down a set of design rules that enable these behaviors. Experimental evaluations measure speed, energy consumption, and steering.","sentences":["We present the design and experimental results of the first 1-DOF, hip-actuated bipedal robot.","While passive dynamic walking is simple by nature, many existing bipeds inspired by this form of walking are complex in control, mechanical design, or both.","Our design using only two rigid bodies connected by a single motor aims to enable exploration of walking at smaller sizes where more complex designs cannot be constructed.","The walker, \"Mugatu\", is self-contained and autonomous, open-loop stable over a range of input parameters, able to stop and start from standing, and able to control its heading left and right.","We analyze the mechanical design and distill down a set of design rules that enable these behaviors.","Experimental evaluations measure speed, energy consumption, and steering."],"url":"http://arxiv.org/abs/2308.08401v1"}
{"created":"2023-08-16 14:25:30","title":"SIGMA: Scale-Invariant Global Sparse Shape Matching","abstract":"We propose a novel mixed-integer programming (MIP) formulation for generating precise sparse correspondences for highly non-rigid shapes. To this end, we introduce a projected Laplace-Beltrami operator (PLBO) which combines intrinsic and extrinsic geometric information to measure the deformation quality induced by predicted correspondences. We integrate the PLBO, together with an orientation-aware regulariser, into a novel MIP formulation that can be solved to global optimality for many practical problems. In contrast to previous methods, our approach is provably invariant to rigid transformations and global scaling, initialisation-free, has optimality guarantees, and scales to high resolution meshes with (empirically observed) linear time. We show state-of-the-art results for sparse non-rigid matching on several challenging 3D datasets, including data with inconsistent meshing, as well as applications in mesh-to-point-cloud matching.","sentences":["We propose a novel mixed-integer programming (MIP) formulation for generating precise sparse correspondences for highly non-rigid shapes.","To this end, we introduce a projected Laplace-Beltrami operator (PLBO) which combines intrinsic and extrinsic geometric information to measure the deformation quality induced by predicted correspondences.","We integrate the PLBO, together with an orientation-aware regulariser, into a novel MIP formulation that can be solved to global optimality for many practical problems.","In contrast to previous methods, our approach is provably invariant to rigid transformations and global scaling, initialisation-free, has optimality guarantees, and scales to high resolution meshes with (empirically observed) linear time.","We show state-of-the-art results for sparse non-rigid matching on several challenging 3D datasets, including data with inconsistent meshing, as well as applications in mesh-to-point-cloud matching."],"url":"http://arxiv.org/abs/2308.08393v1"}
{"created":"2023-08-16 14:23:24","title":"Fast Uncertainty Quantification of Spent Nuclear Fuel with Neural Networks","abstract":"The accurate calculation and uncertainty quantification of the characteristics of spent nuclear fuel (SNF) play a crucial role in ensuring the safety, efficiency, and sustainability of nuclear energy production, waste management, and nuclear safeguards. State of the art physics-based models, while reliable, are computationally intensive and time-consuming. This paper presents a surrogate modeling approach using neural networks (NN) to predict a number of SNF characteristics with reduced computational costs compared to physics-based models. An NN is trained using data generated from CASMO5 lattice calculations. The trained NN accurately predicts decay heat and nuclide concentrations of SNF, as a function of key input parameters, such as enrichment, burnup, cooling time between cycles, mean boron concentration and fuel temperature. The model is validated against physics-based decay heat simulations and measurements of different uranium oxide fuel assemblies from two different pressurized water reactors. In addition, the NN is used to perform sensitivity analysis and uncertainty quantification. The results are in very good alignment to CASMO5, while the computational costs (taking into account the costs of generating training samples) are reduced by a factor of 10 or more. Our findings demonstrate the feasibility of using NNs as surrogate models for fast characterization of SNF, providing a promising avenue for improving computational efficiency in assessing nuclear fuel behavior and associated risks.","sentences":["The accurate calculation and uncertainty quantification of the characteristics of spent nuclear fuel (SNF) play a crucial role in ensuring the safety, efficiency, and sustainability of nuclear energy production, waste management, and nuclear safeguards.","State of the art physics-based models, while reliable, are computationally intensive and time-consuming.","This paper presents a surrogate modeling approach using neural networks (NN) to predict a number of SNF characteristics with reduced computational costs compared to physics-based models.","An NN is trained using data generated from CASMO5 lattice calculations.","The trained NN accurately predicts decay heat and nuclide concentrations of SNF, as a function of key input parameters, such as enrichment, burnup, cooling time between cycles, mean boron concentration and fuel temperature.","The model is validated against physics-based decay heat simulations and measurements of different uranium oxide fuel assemblies from two different pressurized water reactors.","In addition, the NN is used to perform sensitivity analysis and uncertainty quantification.","The results are in very good alignment to CASMO5, while the computational costs (taking into account the costs of generating training samples) are reduced by a factor of 10 or more.","Our findings demonstrate the feasibility of using NNs as surrogate models for fast characterization of SNF, providing a promising avenue for improving computational efficiency in assessing nuclear fuel behavior and associated risks."],"url":"http://arxiv.org/abs/2308.08391v1"}
{"created":"2023-08-16 14:09:48","title":"Precision and Recall Reject Curves for Classification","abstract":"For some classification scenarios, it is desirable to use only those classification instances that a trained model associates with a high certainty. To obtain such high-certainty instances, previous work has proposed accuracy-reject curves. Reject curves allow to evaluate and compare the performance of different certainty measures over a range of thresholds for accepting or rejecting classifications. However, the accuracy may not be the most suited evaluation metric for all applications, and instead precision or recall may be preferable. This is the case, for example, for data with imbalanced class distributions. We therefore propose reject curves that evaluate precision and recall, the recall-reject curve and the precision-reject curve. Using prototype-based classifiers from learning vector quantization, we first validate the proposed curves on artificial benchmark data against the accuracy reject curve as a baseline. We then show on imbalanced benchmarks and medical, real-world data that for these scenarios, the proposed precision- and recall-curves yield more accurate insights into classifier performance than accuracy reject curves.","sentences":["For some classification scenarios, it is desirable to use only those classification instances that a trained model associates with a high certainty.","To obtain such high-certainty instances, previous work has proposed accuracy-reject curves.","Reject curves allow to evaluate and compare the performance of different certainty measures over a range of thresholds for accepting or rejecting classifications.","However, the accuracy may not be the most suited evaluation metric for all applications, and instead precision or recall may be preferable.","This is the case, for example, for data with imbalanced class distributions.","We therefore propose reject curves that evaluate precision and recall, the recall-reject curve and the precision-reject curve.","Using prototype-based classifiers from learning vector quantization, we first validate the proposed curves on artificial benchmark data against the accuracy reject curve as a baseline.","We then show on imbalanced benchmarks and medical, real-world data that for these scenarios, the proposed precision- and recall-curves yield more accurate insights into classifier performance than accuracy reject curves."],"url":"http://arxiv.org/abs/2308.08381v1"}
{"created":"2023-08-16 14:09:39","title":"Robust Autonomous Vehicle Pursuit without Expert Steering Labels","abstract":"In this work, we present a learning method for lateral and longitudinal motion control of an ego-vehicle for vehicle pursuit. The car being controlled does not have a pre-defined route, rather it reactively adapts to follow a target vehicle while maintaining a safety distance. To train our model, we do not rely on steering labels recorded from an expert driver but effectively leverage a classical controller as an offline label generation tool. In addition, we account for the errors in the predicted control values, which can lead to a loss of tracking and catastrophic crashes of the controlled vehicle. To this end, we propose an effective data augmentation approach, which allows to train a network capable of handling different views of the target vehicle. During the pursuit, the target vehicle is firstly localized using a Convolutional Neural Network. The network takes a single RGB image along with cars' velocities and estimates the target vehicle's pose with respect to the ego-vehicle. This information is then fed to a Multi-Layer Perceptron, which regresses the control commands for the ego-vehicle, namely throttle and steering angle. We extensively validate our approach using the CARLA simulator on a wide range of terrains. Our method demonstrates real-time performance and robustness to different scenarios including unseen trajectories and high route completion. The project page containing code and multimedia can be publicly accessed here: https://changyaozhou.github.io/Autonomous-Vehicle-Pursuit/.","sentences":["In this work, we present a learning method for lateral and longitudinal motion control of an ego-vehicle for vehicle pursuit.","The car being controlled does not have a pre-defined route, rather it reactively adapts to follow a target vehicle while maintaining a safety distance.","To train our model, we do not rely on steering labels recorded from an expert driver but effectively leverage a classical controller as an offline label generation tool.","In addition, we account for the errors in the predicted control values, which can lead to a loss of tracking and catastrophic crashes of the controlled vehicle.","To this end, we propose an effective data augmentation approach, which allows to train a network capable of handling different views of the target vehicle.","During the pursuit, the target vehicle is firstly localized using a Convolutional Neural Network.","The network takes a single RGB image along with cars' velocities and estimates the target vehicle's pose with respect to the ego-vehicle.","This information is then fed to a Multi-Layer Perceptron, which regresses the control commands for the ego-vehicle, namely throttle and steering angle.","We extensively validate our approach using the CARLA simulator on a wide range of terrains.","Our method demonstrates real-time performance and robustness to different scenarios including unseen trajectories and high route completion.","The project page containing code and multimedia can be publicly accessed here: https://changyaozhou.github.io/Autonomous-Vehicle-Pursuit/."],"url":"http://arxiv.org/abs/2308.08380v1"}
{"created":"2023-08-16 14:04:50","title":"A distributed neural network architecture for dynamic sensor selection with application to bandwidth-constrained body-sensor networks","abstract":"We propose a dynamic sensor selection approach for deep neural networks (DNNs), which is able to derive an optimal sensor subset selection for each specific input sample instead of a fixed selection for the entire dataset. This dynamic selection is jointly learned with the task model in an end-to-end way, using the Gumbel-Softmax trick to allow the discrete decisions to be learned through standard backpropagation. We then show how we can use this dynamic selection to increase the lifetime of a wireless sensor network (WSN) by imposing constraints on how often each node is allowed to transmit. We further improve performance by including a dynamic spatial filter that makes the task-DNN more robust against the fact that it now needs to be able to handle a multitude of possible node subsets. Finally, we explain how the selection of the optimal channels can be distributed across the different nodes in a WSN. We validate this method on a use case in the context of body-sensor networks, where we use real electroencephalography (EEG) sensor data to emulate an EEG sensor network. We analyze the resulting trade-offs between transmission load and task accuracy.","sentences":["We propose a dynamic sensor selection approach for deep neural networks (DNNs), which is able to derive an optimal sensor subset selection for each specific input sample instead of a fixed selection for the entire dataset.","This dynamic selection is jointly learned with the task model in an end-to-end way, using the Gumbel-Softmax trick to allow the discrete decisions to be learned through standard backpropagation.","We then show how we can use this dynamic selection to increase the lifetime of a wireless sensor network (WSN) by imposing constraints on how often each node is allowed to transmit.","We further improve performance by including a dynamic spatial filter that makes the task-DNN more robust against the fact that it now needs to be able to handle a multitude of possible node subsets.","Finally, we explain how the selection of the optimal channels can be distributed across the different nodes in a WSN.","We validate this method on a use case in the context of body-sensor networks, where we use real electroencephalography (EEG) sensor data to emulate an EEG sensor network.","We analyze the resulting trade-offs between transmission load and task accuracy."],"url":"http://arxiv.org/abs/2308.08379v1"}
{"created":"2023-08-16 14:01:25","title":"Advancing continual lifelong learning in neural information retrieval: definition, dataset, framework, and empirical evaluation","abstract":"Continual learning refers to the capability of a machine learning model to learn and adapt to new information, without compromising its performance on previously learned tasks. Although several studies have investigated continual learning methods for information retrieval tasks, a well-defined task formulation is still lacking, and it is unclear how typical learning strategies perform in this context. To address this challenge, a systematic task formulation of continual neural information retrieval is presented, along with a multiple-topic dataset that simulates continuous information retrieval. A comprehensive continual neural information retrieval framework consisting of typical retrieval models and continual learning strategies is then proposed. Empirical evaluations illustrate that the proposed framework can successfully prevent catastrophic forgetting in neural information retrieval and enhance performance on previously learned tasks. The results indicate that embedding-based retrieval models experience a decline in their continual learning performance as the topic shift distance and dataset volume of new tasks increase. In contrast, pretraining-based models do not show any such correlation. Adopting suitable learning strategies can mitigate the effects of topic shift and data augmentation.","sentences":["Continual learning refers to the capability of a machine learning model to learn and adapt to new information, without compromising its performance on previously learned tasks.","Although several studies have investigated continual learning methods for information retrieval tasks, a well-defined task formulation is still lacking, and it is unclear how typical learning strategies perform in this context.","To address this challenge, a systematic task formulation of continual neural information retrieval is presented, along with a multiple-topic dataset that simulates continuous information retrieval.","A comprehensive continual neural information retrieval framework consisting of typical retrieval models and continual learning strategies is then proposed.","Empirical evaluations illustrate that the proposed framework can successfully prevent catastrophic forgetting in neural information retrieval and enhance performance on previously learned tasks.","The results indicate that embedding-based retrieval models experience a decline in their continual learning performance as the topic shift distance and dataset volume of new tasks increase.","In contrast, pretraining-based models do not show any such correlation.","Adopting suitable learning strategies can mitigate the effects of topic shift and data augmentation."],"url":"http://arxiv.org/abs/2308.08378v1"}
{"created":"2023-08-16 13:59:43","title":"Automated Semiconductor Defect Inspection in Scanning Electron Microscope Images: a Systematic Review","abstract":"A growing need exists for efficient and accurate methods for detecting defects in semiconductor materials and devices. These defects can have a detrimental impact on the efficiency of the manufacturing process, because they cause critical failures and wafer-yield limitations. As nodes and patterns get smaller, even high-resolution imaging techniques such as Scanning Electron Microscopy (SEM) produce noisy images due to operating close to sensitivity levels and due to varying physical properties of different underlayers or resist materials. This inherent noise is one of the main challenges for defect inspection. One promising approach is the use of machine learning algorithms, which can be trained to accurately classify and locate defects in semiconductor samples. Recently, convolutional neural networks have proved to be particularly useful in this regard. This systematic review provides a comprehensive overview of the state of automated semiconductor defect inspection on SEM images, including the most recent innovations and developments. 38 publications were selected on this topic, indexed in IEEE Xplore and SPIE databases. For each of these, the application, methodology, dataset, results, limitations and future work were summarized. A comprehensive overview and analysis of their methods is provided. Finally, promising avenues for future work in the field of SEM-based defect inspection are suggested.","sentences":["A growing need exists for efficient and accurate methods for detecting defects in semiconductor materials and devices.","These defects can have a detrimental impact on the efficiency of the manufacturing process, because they cause critical failures and wafer-yield limitations.","As nodes and patterns get smaller, even high-resolution imaging techniques such as Scanning Electron Microscopy (SEM) produce noisy images due to operating close to sensitivity levels and due to varying physical properties of different underlayers or resist materials.","This inherent noise is one of the main challenges for defect inspection.","One promising approach is the use of machine learning algorithms, which can be trained to accurately classify and locate defects in semiconductor samples.","Recently, convolutional neural networks have proved to be particularly useful in this regard.","This systematic review provides a comprehensive overview of the state of automated semiconductor defect inspection on SEM images, including the most recent innovations and developments.","38 publications were selected on this topic, indexed in IEEE Xplore and SPIE databases.","For each of these, the application, methodology, dataset, results, limitations and future work were summarized.","A comprehensive overview and analysis of their methods is provided.","Finally, promising avenues for future work in the field of SEM-based defect inspection are suggested."],"url":"http://arxiv.org/abs/2308.08376v1"}
{"created":"2023-08-16 13:56:45","title":"Matching Patterns with Variables Under Simon's Congruence","abstract":"We introduce and investigate a series of matching problems for patterns with variables under Simon's congruence. Our results provide a thorough picture of these problems' computational complexity.","sentences":["We introduce and investigate a series of matching problems for patterns with variables under Simon's congruence.","Our results provide a thorough picture of these problems' computational complexity."],"url":"http://arxiv.org/abs/2308.08374v1"}
{"created":"2023-08-16 13:55:10","title":"Approximation Algorithms for Norm Multiway Cut","abstract":"We consider variants of the classic Multiway Cut problem. Multiway Cut asks to partition a graph $G$ into $k$ parts so as to separate $k$ given terminals. Recently, Chandrasekaran and Wang (ESA 2021) introduced $\\ell_p$-norm Multiway, a generalization of the problem, in which the goal is to minimize the $\\ell_p$ norm of the edge boundaries of $k$ parts. We provide an $O(\\log^{1/2} n\\log^{1/2+1/p} k)$ approximation algorithm for this problem, improving upon the approximation guarantee of $O(\\log^{3/2} n \\log^{1/2} k)$ due to Chandrasekaran and Wang.   We also introduce and study Norm Multiway Cut, a further generalization of Multiway Cut. We assume that we are given access to an oracle, which answers certain queries about the norm. We present an $O(\\log^{1/2} n \\log^{7/2} k)$ approximation algorithm with a weaker oracle and an $O(\\log^{1/2} n \\log^{5/2} k)$ approximation algorithm with a stronger oracle. Additionally, we show that without any oracle access, there is no $n^{1/4-\\varepsilon}$ approximation algorithm for every $\\varepsilon > 0$ assuming the Hypergraph Dense-vs-Random Conjecture.","sentences":["We consider variants of the classic Multiway Cut problem.","Multiway Cut asks to partition a graph $G$ into $k$ parts so as to separate $k$ given terminals.","Recently, Chandrasekaran and Wang (ESA 2021) introduced $\\ell_p$-norm Multiway, a generalization of the problem, in which the goal is to minimize the $\\ell_p$ norm of the edge boundaries of $k$ parts.","We provide an $O(\\log^{1/2} n\\log^{1/2+1/p} k)$ approximation algorithm for this problem, improving upon the approximation guarantee of $O(\\log^{3/2} n \\log^{1/2} k)$ due to Chandrasekaran and Wang.   ","We also introduce and study Norm Multiway Cut, a further generalization of Multiway Cut.","We assume that we are given access to an oracle, which answers certain queries about the norm.","We present an $O(\\log^{1/2} n \\log^{7/2} k)$ approximation algorithm with a weaker oracle and an $O(\\log^{1/2} n \\log^{5/2} k)$ approximation algorithm with a stronger oracle.","Additionally, we show that without any oracle access, there is no $n^{1/4-\\varepsilon}$ approximation algorithm for every $\\varepsilon > 0$ assuming the Hypergraph Dense-vs-Random Conjecture."],"url":"http://arxiv.org/abs/2308.08373v1"}
{"created":"2023-08-16 13:50:23","title":"PDPK: A Framework to Synthesise Process Data and Corresponding Procedural Knowledge for Manufacturing","abstract":"Procedural knowledge describes how to accomplish tasks and mitigate problems. Such knowledge is commonly held by domain experts, e.g. operators in manufacturing who adjust parameters to achieve quality targets. To the best of our knowledge, no real-world datasets containing process data and corresponding procedural knowledge are publicly available, possibly due to corporate apprehensions regarding the loss of knowledge advances. Therefore, we provide a framework to generate synthetic datasets that can be adapted to different domains. The design choices are inspired by two real-world datasets of procedural knowledge we have access to. Apart from containing representations of procedural knowledge in Resource Description Framework (RDF)-compliant knowledge graphs, the framework simulates parametrisation processes and provides consistent process data. We compare established embedding methods on the resulting knowledge graphs, detailing which out-of-the-box methods have the potential to represent procedural knowledge. This provides a baseline which can be used to increase the comparability of future work. Furthermore, we validate the overall characteristics of a synthesised dataset by comparing the results to those achievable on a real-world dataset. The framework and evaluation code, as well as the dataset used in the evaluation, are available open source.","sentences":["Procedural knowledge describes how to accomplish tasks and mitigate problems.","Such knowledge is commonly held by domain experts, e.g. operators in manufacturing who adjust parameters to achieve quality targets.","To the best of our knowledge, no real-world datasets containing process data and corresponding procedural knowledge are publicly available, possibly due to corporate apprehensions regarding the loss of knowledge advances.","Therefore, we provide a framework to generate synthetic datasets that can be adapted to different domains.","The design choices are inspired by two real-world datasets of procedural knowledge we have access to.","Apart from containing representations of procedural knowledge in Resource Description Framework (RDF)-compliant knowledge graphs, the framework simulates parametrisation processes and provides consistent process data.","We compare established embedding methods on the resulting knowledge graphs, detailing which out-of-the-box methods have the potential to represent procedural knowledge.","This provides a baseline which can be used to increase the comparability of future work.","Furthermore, we validate the overall characteristics of a synthesised dataset by comparing the results to those achievable on a real-world dataset.","The framework and evaluation code, as well as the dataset used in the evaluation, are available open source."],"url":"http://arxiv.org/abs/2308.08371v1"}
{"created":"2023-08-16 13:48:02","title":"Agglomerative Transformer for Human-Object Interaction Detection","abstract":"We propose an agglomerative Transformer (AGER) that enables Transformer-based human-object interaction (HOI) detectors to flexibly exploit extra instance-level cues in a single-stage and end-to-end manner for the first time. AGER acquires instance tokens by dynamically clustering patch tokens and aligning cluster centers to instances with textual guidance, thus enjoying two benefits: 1) Integrality: each instance token is encouraged to contain all discriminative feature regions of an instance, which demonstrates a significant improvement in the extraction of different instance-level cues and subsequently leads to a new state-of-the-art performance of HOI detection with 36.75 mAP on HICO-Det. 2) Efficiency: the dynamical clustering mechanism allows AGER to generate instance tokens jointly with the feature learning of the Transformer encoder, eliminating the need of an additional object detector or instance decoder in prior methods, thus allowing the extraction of desirable extra cues for HOI detection in a single-stage and end-to-end pipeline. Concretely, AGER reduces GFLOPs by 8.5% and improves FPS by 36%, even compared to a vanilla DETR-like pipeline without extra cue extraction.","sentences":["We propose an agglomerative Transformer (AGER) that enables Transformer-based human-object interaction (HOI) detectors to flexibly exploit extra instance-level cues in a single-stage and end-to-end manner for the first time.","AGER acquires instance tokens by dynamically clustering patch tokens and aligning cluster centers to instances with textual guidance, thus enjoying two benefits: 1) Integrality: each instance token is encouraged to contain all discriminative feature regions of an instance, which demonstrates a significant improvement in the extraction of different instance-level cues and subsequently leads to a new state-of-the-art performance of HOI detection with 36.75 mAP on HICO-Det. 2) Efficiency: the dynamical clustering mechanism allows AGER to generate instance tokens jointly with the feature learning of the Transformer encoder, eliminating the need of an additional object detector or instance decoder in prior methods, thus allowing the extraction of desirable extra cues for HOI detection in a single-stage and end-to-end pipeline.","Concretely, AGER reduces GFLOPs by 8.5% and improves FPS by 36%, even compared to a vanilla DETR-like pipeline without extra cue extraction."],"url":"http://arxiv.org/abs/2308.08370v1"}
{"created":"2023-08-16 13:41:29","title":"Diff-CAPTCHA: An Image-based CAPTCHA with Security Enhanced by Denoising Diffusion Model","abstract":"To enhance the security of text CAPTCHAs, various methods have been employed, such as adding the interference lines on the text, randomly distorting the characters, and overlapping multiple characters. These methods partly increase the difficulty of automated segmentation and recognition attacks. However, facing the rapid development of the end-to-end breaking algorithms, their security has been greatly weakened. The diffusion model is a novel image generation model that can generate the text images with deep fusion of characters and background images. In this paper, an image-click CAPTCHA scheme called Diff-CAPTCHA is proposed based on denoising diffusion models. The background image and characters of the CAPTCHA are treated as a whole to guide the generation process of a diffusion model, thus weakening the character features available for machine learning, enhancing the diversity of character features in the CAPTCHA, and increasing the difficulty of breaking algorithms. To evaluate the security of Diff-CAPTCHA, this paper develops several attack methods, including end-to-end attacks based on Faster R-CNN and two-stage attacks, and Diff-CAPTCHA is compared with three baseline schemes, including commercial CAPTCHA scheme and security-enhanced CAPTCHA scheme based on style transfer. The experimental results show that diffusion models can effectively enhance CAPTCHA security while maintaining good usability in human testing.","sentences":["To enhance the security of text CAPTCHAs, various methods have been employed, such as adding the interference lines on the text, randomly distorting the characters, and overlapping multiple characters.","These methods partly increase the difficulty of automated segmentation and recognition attacks.","However, facing the rapid development of the end-to-end breaking algorithms, their security has been greatly weakened.","The diffusion model is a novel image generation model that can generate the text images with deep fusion of characters and background images.","In this paper, an image-click CAPTCHA scheme called Diff-CAPTCHA is proposed based on denoising diffusion models.","The background image and characters of the CAPTCHA are treated as a whole to guide the generation process of a diffusion model, thus weakening the character features available for machine learning, enhancing the diversity of character features in the CAPTCHA, and increasing the difficulty of breaking algorithms.","To evaluate the security of Diff-CAPTCHA, this paper develops several attack methods, including end-to-end attacks based on Faster R-CNN and two-stage attacks, and Diff-CAPTCHA is compared with three baseline schemes, including commercial CAPTCHA scheme and security-enhanced CAPTCHA scheme based on style transfer.","The experimental results show that diffusion models can effectively enhance CAPTCHA security while maintaining good usability in human testing."],"url":"http://arxiv.org/abs/2308.08367v1"}
{"created":"2023-08-16 13:40:58","title":"Dual-Branch Temperature Scaling Calibration for Long-Tailed Recognition","abstract":"The calibration for deep neural networks is currently receiving widespread attention and research. Miscalibration usually leads to overconfidence of the model. While, under the condition of long-tailed distribution of data, the problem of miscalibration is more prominent due to the different confidence levels of samples in minority and majority categories, and it will result in more serious overconfidence. To address this problem, some current research have designed diverse temperature coefficients for different categories based on temperature scaling (TS) method. However, in the case of rare samples in minority classes, the temperature coefficient is not generalizable, and there is a large difference between the temperature coefficients of the training set and the validation set. To solve this challenge, this paper proposes a dual-branch temperature scaling calibration model (Dual-TS), which considers the diversities in temperature parameters of different categories and the non-generalizability of temperature parameters for rare samples in minority classes simultaneously. Moreover, we noticed that the traditional calibration evaluation metric, Excepted Calibration Error (ECE), gives a higher weight to low-confidence samples in the minority classes, which leads to inaccurate evaluation of model calibration. Therefore, we also propose Equal Sample Bin Excepted Calibration Error (Esbin-ECE) as a new calibration evaluation metric. Through experiments, we demonstrate that our model yields state-of-the-art in both traditional ECE and Esbin-ECE metrics.","sentences":["The calibration for deep neural networks is currently receiving widespread attention and research.","Miscalibration usually leads to overconfidence of the model.","While, under the condition of long-tailed distribution of data, the problem of miscalibration is more prominent due to the different confidence levels of samples in minority and majority categories, and it will result in more serious overconfidence.","To address this problem, some current research have designed diverse temperature coefficients for different categories based on temperature scaling (TS) method.","However, in the case of rare samples in minority classes, the temperature coefficient is not generalizable, and there is a large difference between the temperature coefficients of the training set and the validation set.","To solve this challenge, this paper proposes a dual-branch temperature scaling calibration model (Dual-TS), which considers the diversities in temperature parameters of different categories and the non-generalizability of temperature parameters for rare samples in minority classes simultaneously.","Moreover, we noticed that the traditional calibration evaluation metric, Excepted Calibration Error (ECE), gives a higher weight to low-confidence samples in the minority classes, which leads to inaccurate evaluation of model calibration.","Therefore, we also propose Equal Sample Bin Excepted Calibration Error (Esbin-ECE) as a new calibration evaluation metric.","Through experiments, we demonstrate that our model yields state-of-the-art in both traditional ECE and Esbin-ECE metrics."],"url":"http://arxiv.org/abs/2308.08366v1"}
{"created":"2023-08-16 13:39:06","title":"SummHelper: Collaborative Human-Computer Summarization","abstract":"Current approaches for text summarization are predominantly automatic, with rather limited space for human intervention and control over the process. In this paper, we introduce SummHelper, a 2-phase summarization assistant designed to foster human-machine collaboration. The initial phase involves content selection, where the system recommends potential content, allowing users to accept, modify, or introduce additional selections. The subsequent phase, content consolidation, involves SummHelper generating a coherent summary from these selections, which users can then refine using visual mappings between the summary and the source text. Small-scale user studies reveal the effectiveness of our application, with participants being especially appreciative of the balance between automated guidance and opportunities for personal input.","sentences":["Current approaches for text summarization are predominantly automatic, with rather limited space for human intervention and control over the process.","In this paper, we introduce SummHelper, a 2-phase summarization assistant designed to foster human-machine collaboration.","The initial phase involves content selection, where the system recommends potential content, allowing users to accept, modify, or introduce additional selections.","The subsequent phase, content consolidation, involves SummHelper generating a coherent summary from these selections, which users can then refine using visual mappings between the summary and the source text.","Small-scale user studies reveal the effectiveness of our application, with participants being especially appreciative of the balance between automated guidance and opportunities for personal input."],"url":"http://arxiv.org/abs/2308.08363v1"}
{"created":"2023-08-16 13:38:56","title":"Functional Consistency across Retail Central Bank Digital Currency and Commercial Bank Money","abstract":"Central banks are actively exploring central bank digital currencies (CBDCs) by conducting research, proofs of concept and pilots. However, adoption of a retail CBDC can risk fragmenting both payments markets and retail deposits if the retail CBDC and commercial bank money do not have common operational characteristics. In this paper, we focus on a potential UK retail CBDC, the 'digital pound', and the Bank of England's 'platform model'. We first explore how the concept of functional consistency could mitigate the risk of fragmentation. We next identify the common operational characteristics that are required to achieve functional consistency across all forms of regulated retail digital money. We identify four design options based on the provision of these common operational characteristics by the central bank, payment interface providers (PIPs), technical service providers (TSPs) or a financial market infrastructure (FMI). We next identify architecturally-significant use cases and select key capabilities that support these use cases and the common operational characteristics. We evaluate the suitability of the design options to provide these key capabilities and draw insights. We conclude that no single design option could provide functional consistency across digital pounds and commercial bank money and, instead, a complete solution would need to combine the suitable design option(s) for each key capability and include common ecosystem services provided by an FMI and TSPs.","sentences":["Central banks are actively exploring central bank digital currencies (CBDCs) by conducting research, proofs of concept and pilots.","However, adoption of a retail CBDC can risk fragmenting both payments markets and retail deposits if the retail CBDC and commercial bank money do not have common operational characteristics.","In this paper, we focus on a potential UK retail CBDC, the 'digital pound', and the Bank of England's 'platform model'.","We first explore how the concept of functional consistency could mitigate the risk of fragmentation.","We next identify the common operational characteristics that are required to achieve functional consistency across all forms of regulated retail digital money.","We identify four design options based on the provision of these common operational characteristics by the central bank, payment interface providers (PIPs), technical service providers (TSPs) or a financial market infrastructure (FMI).","We next identify architecturally-significant use cases and select key capabilities that support these use cases and the common operational characteristics.","We evaluate the suitability of the design options to provide these key capabilities and draw insights.","We conclude that no single design option could provide functional consistency across digital pounds and commercial bank money and, instead, a complete solution would need to combine the suitable design option(s) for each key capability and include common ecosystem services provided by an FMI and TSPs."],"url":"http://arxiv.org/abs/2308.08362v1"}
{"created":"2023-08-16 13:35:09","title":"KernelWarehouse: Towards Parameter-Efficient Dynamic Convolution","abstract":"Dynamic convolution learns a linear mixture of $n$ static kernels weighted with their sample-dependent attentions, demonstrating superior performance compared to normal convolution. However, existing designs are parameter-inefficient: they increase the number of convolutional parameters by $n$ times. This and the optimization difficulty lead to no research progress in dynamic convolution that can allow us to use a significant large value of $n$ (e.g., $n>100$ instead of typical setting $n<10$) to push forward the performance boundary. In this paper, we propose $KernelWarehouse$, a more general form of dynamic convolution, which can strike a favorable trade-off between parameter efficiency and representation power. Its key idea is to redefine the basic concepts of \"$kernels$\" and \"$assembling$ $kernels$\" in dynamic convolution from the perspective of reducing kernel dimension and increasing kernel number significantly. In principle, KernelWarehouse enhances convolutional parameter dependencies within the same layer and across successive layers via tactful kernel partition and warehouse sharing, yielding a high degree of freedom to fit a desired parameter budget. We validate our method on ImageNet and MS-COCO datasets with different ConvNet architectures, and show that it attains state-of-the-art results. For instance, the ResNet18|ResNet50|MobileNetV2|ConvNeXt-Tiny model trained with KernelWarehouse on ImageNet reaches 76.05%|81.05%|75.52%|82.51% top-1 accuracy. Thanks to its flexible design, KernelWarehouse can even reduce the model size of a ConvNet while improving the accuracy, e.g., our ResNet18 model with 36.45%|65.10% parameter reduction to the baseline shows 2.89%|2.29% absolute improvement to top-1 accuracy.","sentences":["Dynamic convolution learns a linear mixture of $n$ static kernels weighted with their sample-dependent attentions, demonstrating superior performance compared to normal convolution.","However, existing designs are parameter-inefficient: they increase the number of convolutional parameters by $n$ times.","This and the optimization difficulty lead to no research progress in dynamic convolution that can allow us to use a significant large value of $n$ (e.g., $n>100$ instead of typical setting $n<10$) to push forward the performance boundary.","In this paper, we propose $KernelWarehouse$, a more general form of dynamic convolution, which can strike a favorable trade-off between parameter efficiency and representation power.","Its key idea is to redefine the basic concepts of \"$kernels$\" and \"$assembling$ $kernels$\" in dynamic convolution from the perspective of reducing kernel dimension and increasing kernel number significantly.","In principle, KernelWarehouse enhances convolutional parameter dependencies within the same layer and across successive layers via tactful kernel partition and warehouse sharing, yielding a high degree of freedom to fit a desired parameter budget.","We validate our method on ImageNet and MS-COCO datasets with different ConvNet architectures, and show that it attains state-of-the-art results.","For instance, the ResNet18|ResNet50|MobileNetV2|ConvNeXt-Tiny model trained with KernelWarehouse on ImageNet reaches 76.05%|81.05%|75.52%|82.51% top-1 accuracy.","Thanks to its flexible design, KernelWarehouse can even reduce the model size of a ConvNet while improving the accuracy, e.g., our ResNet18 model with 36.45%|65.10% parameter reduction to the baseline shows 2.89%|2.29% absolute improvement to top-1 accuracy."],"url":"http://arxiv.org/abs/2308.08361v1"}
{"created":"2023-08-16 13:32:43","title":"Independent Distribution Regularization for Private Graph Embedding","abstract":"Learning graph embeddings is a crucial task in graph mining tasks. An effective graph embedding model can learn low-dimensional representations from graph-structured data for data publishing benefiting various downstream applications such as node classification, link prediction, etc. However, recent studies have revealed that graph embeddings are susceptible to attribute inference attacks, which allow attackers to infer private node attributes from the learned graph embeddings. To address these concerns, privacy-preserving graph embedding methods have emerged, aiming to simultaneously consider primary learning and privacy protection through adversarial learning. However, most existing methods assume that representation models have access to all sensitive attributes in advance during the training stage, which is not always the case due to diverse privacy preferences. Furthermore, the commonly used adversarial learning technique in privacy-preserving representation learning suffers from unstable training issues. In this paper, we propose a novel approach called Private Variational Graph AutoEncoders (PVGAE) with the aid of independent distribution penalty as a regularization term. Specifically, we split the original variational graph autoencoder (VGAE) to learn sensitive and non-sensitive latent representations using two sets of encoders. Additionally, we introduce a novel regularization to enforce the independence of the encoders. We prove the theoretical effectiveness of regularization from the perspective of mutual information. Experimental results on three real-world datasets demonstrate that PVGAE outperforms other baselines in private embedding learning regarding utility performance and privacy protection.","sentences":["Learning graph embeddings is a crucial task in graph mining tasks.","An effective graph embedding model can learn low-dimensional representations from graph-structured data for data publishing benefiting various downstream applications such as node classification, link prediction, etc.","However, recent studies have revealed that graph embeddings are susceptible to attribute inference attacks, which allow attackers to infer private node attributes from the learned graph embeddings.","To address these concerns, privacy-preserving graph embedding methods have emerged, aiming to simultaneously consider primary learning and privacy protection through adversarial learning.","However, most existing methods assume that representation models have access to all sensitive attributes in advance during the training stage, which is not always the case due to diverse privacy preferences.","Furthermore, the commonly used adversarial learning technique in privacy-preserving representation learning suffers from unstable training issues.","In this paper, we propose a novel approach called Private Variational Graph AutoEncoders (PVGAE) with the aid of independent distribution penalty as a regularization term.","Specifically, we split the original variational graph autoencoder (VGAE) to learn sensitive and non-sensitive latent representations using two sets of encoders.","Additionally, we introduce a novel regularization to enforce the independence of the encoders.","We prove the theoretical effectiveness of regularization from the perspective of mutual information.","Experimental results on three real-world datasets demonstrate that PVGAE outperforms other baselines in private embedding learning regarding utility performance and privacy protection."],"url":"http://arxiv.org/abs/2308.08360v1"}
{"created":"2023-08-16 13:32:03","title":"Membrane Potential Batch Normalization for Spiking Neural Networks","abstract":"As one of the energy-efficient alternatives of conventional neural networks (CNNs), spiking neural networks (SNNs) have gained more and more interest recently. To train the deep models, some effective batch normalization (BN) techniques are proposed in SNNs. All these BNs are suggested to be used after the convolution layer as usually doing in CNNs. However, the spiking neuron is much more complex with the spatio-temporal dynamics. The regulated data flow after the BN layer will be disturbed again by the membrane potential updating operation before the firing function, i.e., the nonlinear activation. Therefore, we advocate adding another BN layer before the firing function to normalize the membrane potential again, called MPBN. To eliminate the induced time cost of MPBN, we also propose a training-inference-decoupled re-parameterization technique to fold the trained MPBN into the firing threshold. With the re-parameterization technique, the MPBN will not introduce any extra time burden in the inference. Furthermore, the MPBN can also adopt the element-wised form, while these BNs after the convolution layer can only use the channel-wised form. Experimental results show that the proposed MPBN performs well on both popular non-spiking static and neuromorphic datasets. Our code is open-sourced at \\href{https://github.com/yfguo91/MPBN}{MPBN}.","sentences":["As one of the energy-efficient alternatives of conventional neural networks (CNNs), spiking neural networks (SNNs) have gained more and more interest recently.","To train the deep models, some effective batch normalization (BN) techniques are proposed in SNNs.","All these BNs are suggested to be used after the convolution layer as usually doing in CNNs.","However, the spiking neuron is much more complex with the spatio-temporal dynamics.","The regulated data flow after the BN layer will be disturbed again by the membrane potential updating operation before the firing function, i.e., the nonlinear activation.","Therefore, we advocate adding another BN layer before the firing function to normalize the membrane potential again, called MPBN.","To eliminate the induced time cost of MPBN, we also propose a training-inference-decoupled re-parameterization technique to fold the trained MPBN into the firing threshold.","With the re-parameterization technique, the MPBN will not introduce any extra time burden in the inference.","Furthermore, the MPBN can also adopt the element-wised form, while these BNs after the convolution layer can only use the channel-wised form.","Experimental results show that the proposed MPBN performs well on both popular non-spiking static and neuromorphic datasets.","Our code is open-sourced at \\href{https://github.com/yfguo91/MPBN}{MPBN}."],"url":"http://arxiv.org/abs/2308.08359v1"}
{"created":"2023-08-16 13:30:45","title":"Convergence of Two-Layer Regression with Nonlinear Units","abstract":"Large language models (LLMs), such as ChatGPT and GPT4, have shown outstanding performance in many human life task. Attention computation plays an important role in training LLMs. Softmax unit and ReLU unit are the key structure in attention computation. Inspired by them, we put forward a softmax ReLU regression problem. Generally speaking, our goal is to find an optimal solution to the regression problem involving the ReLU unit. In this work, we calculate a close form representation for the Hessian of the loss function. Under certain assumptions, we prove the Lipschitz continuous and the PSDness of the Hessian. Then, we introduce an greedy algorithm based on approximate Newton method, which converges in the sense of the distance to optimal solution. Last, We relax the Lipschitz condition and prove the convergence in the sense of loss value.","sentences":["Large language models (LLMs), such as ChatGPT and GPT4, have shown outstanding performance in many human life task.","Attention computation plays an important role in training LLMs.","Softmax unit and ReLU unit are the key structure in attention computation.","Inspired by them, we put forward a softmax ReLU regression problem.","Generally speaking, our goal is to find an optimal solution to the regression problem involving the ReLU unit.","In this work, we calculate a close form representation for the Hessian of the loss function.","Under certain assumptions, we prove the Lipschitz continuous and the PSDness of the Hessian.","Then, we introduce an greedy algorithm based on approximate Newton method, which converges in the sense of the distance to optimal solution.","Last, We relax the Lipschitz condition and prove the convergence in the sense of loss value."],"url":"http://arxiv.org/abs/2308.08358v1"}
{"created":"2023-08-16 13:29:28","title":"Evaluating IP Blacklists Effectiveness","abstract":"IP blacklists are widely used to increase network security by preventing communications with peers that have been marked as malicious. There are several commercial offerings as well as several free-of-charge blacklists maintained by volunteers on the web. Despite their wide adoption, the effectiveness of the different IP blacklists in real-world scenarios is still not clear. In this paper, we conduct a large-scale network monitoring study which provides insightful findings regarding the effectiveness of blacklists. The results collected over several hundred thousand IP hosts belonging to three distinct large production networks highlight that blacklists are often tuned for precision, with the result that many malicious activities, such as scanning, are completely undetected. The proposed instrumentation approach to detect IP scanning and suspicious activities is implemented with home-grown and open-source software. Our tools enable the creation of blacklists without the security risks posed by the deployment of honeypots.","sentences":["IP blacklists are widely used to increase network security by preventing communications with peers that have been marked as malicious.","There are several commercial offerings as well as several free-of-charge blacklists maintained by volunteers on the web.","Despite their wide adoption, the effectiveness of the different IP blacklists in real-world scenarios is still not clear.","In this paper, we conduct a large-scale network monitoring study which provides insightful findings regarding the effectiveness of blacklists.","The results collected over several hundred thousand IP hosts belonging to three distinct large production networks highlight that blacklists are often tuned for precision, with the result that many malicious activities, such as scanning, are completely undetected.","The proposed instrumentation approach to detect IP scanning and suspicious activities is implemented with home-grown and open-source software.","Our tools enable the creation of blacklists without the security risks posed by the deployment of honeypots."],"url":"http://arxiv.org/abs/2308.08356v1"}
{"created":"2023-08-16 13:24:47","title":"Is Meta-Learning the Right Approach for the Cold-Start Problem in Recommender Systems?","abstract":"Recommender systems have become fundamental building blocks of modern online products and services, and have a substantial impact on user experience. In the past few years, deep learning methods have attracted a lot of research, and are now heavily used in modern real-world recommender systems. Nevertheless, dealing with recommendations in the cold-start setting, e.g., when a user has done limited interactions in the system, is a problem that remains far from solved. Meta-learning techniques, and in particular optimization-based meta-learning, have recently become the most popular approaches in the academic research literature for tackling the cold-start problem in deep learning models for recommender systems. However, current meta-learning approaches are not practical for real-world recommender systems, which have billions of users and items, and strict latency requirements. In this paper we show that it is possible to obtaining similar, or higher, performance on commonly used benchmarks for the cold-start problem without using meta-learning techniques. In more detail, we show that, when tuned correctly, standard and widely adopted deep learning models perform just as well as newer meta-learning models. We further show that an extremely simple modular approach using common representation learning techniques, can perform comparably to meta-learning techniques specifically designed for the cold-start setting while being much more easily deployable in real-world applications.","sentences":["Recommender systems have become fundamental building blocks of modern online products and services, and have a substantial impact on user experience.","In the past few years, deep learning methods have attracted a lot of research, and are now heavily used in modern real-world recommender systems.","Nevertheless, dealing with recommendations in the cold-start setting, e.g., when a user has done limited interactions in the system, is a problem that remains far from solved.","Meta-learning techniques, and in particular optimization-based meta-learning, have recently become the most popular approaches in the academic research literature for tackling the cold-start problem in deep learning models for recommender systems.","However, current meta-learning approaches are not practical for real-world recommender systems, which have billions of users and items, and strict latency requirements.","In this paper we show that it is possible to obtaining similar, or higher, performance on commonly used benchmarks for the cold-start problem without using meta-learning techniques.","In more detail, we show that, when tuned correctly, standard and widely adopted deep learning models perform just as well as newer meta-learning models.","We further show that an extremely simple modular approach using common representation learning techniques, can perform comparably to meta-learning techniques specifically designed for the cold-start setting while being much more easily deployable in real-world applications."],"url":"http://arxiv.org/abs/2308.08354v1"}
{"created":"2023-08-16 13:15:33","title":"Continuing WebAssembly with Effect Handlers","abstract":"WebAssembly (Wasm) is a low-level portable code format offering near native performance. It is intended as a compilation target for a wide variety of source languages. However, Wasm provides no direct support for non-local control flow features such as async/await, generators/iterators, lightweight threads, first-class continuations, etc. This means that compilers for source languages with such features must ceremoniously transform whole source programs in order to target Wasm. We present WasmFX, an extension to Wasm which provides a universal target for non-local control features via effect handlers, enabling compilers to translate such features directly into Wasm. Our extension is minimal and only adds three main instructions for creating, suspending, and resuming continuations. Moreover, our primitive instructions are type-safe providing typed continuations which are well-aligned with the design principles of Wasm whose stacks are typed. We present a formal specification of WasmFX and show that the extension is sound. We have implemented WasmFX as an extension to the Wasm reference interpreter and also built a prototype WasmFX extension for Wasmtime, a production-grade Wasm engine, piggybacking on Wasmtime's existing fibers API. The preliminary performance results for our prototype are encouraging, and we outline future plans to realise a native implementation","sentences":["WebAssembly (Wasm) is a low-level portable code format offering near native performance.","It is intended as a compilation target for a wide variety of source languages.","However, Wasm provides no direct support for non-local control flow features such as async/await, generators/iterators, lightweight threads, first-class continuations, etc.","This means that compilers for source languages with such features must ceremoniously transform whole source programs in order to target Wasm.","We present WasmFX, an extension to Wasm which provides a universal target for non-local control features via effect handlers, enabling compilers to translate such features directly into Wasm.","Our extension is minimal and only adds three main instructions for creating, suspending, and resuming continuations.","Moreover, our primitive instructions are type-safe providing typed continuations which are well-aligned with the design principles of Wasm whose stacks are typed.","We present a formal specification of WasmFX and show that the extension is sound.","We have implemented WasmFX as an extension to the Wasm reference interpreter and also built a prototype WasmFX extension for Wasmtime, a production-grade Wasm engine, piggybacking on Wasmtime's existing fibers API.","The preliminary performance results for our prototype are encouraging, and we outline future plans to realise a native implementation"],"url":"http://arxiv.org/abs/2308.08347v1"}
{"created":"2023-08-16 13:10:27","title":"Graph Out-of-Distribution Generalization with Controllable Data Augmentation","abstract":"Graph Neural Network (GNN) has demonstrated extraordinary performance in classifying graph properties. However, due to the selection bias of training and testing data (e.g., training on small graphs and testing on large graphs, or training on dense graphs and testing on sparse graphs), distribution deviation is widespread. More importantly, we often observe \\emph{hybrid structure distribution shift} of both scale and density, despite of one-sided biased data partition. The spurious correlations over hybrid distribution deviation degrade the performance of previous GNN methods and show large instability among different datasets. To alleviate this problem, we propose \\texttt{OOD-GMixup} to jointly manipulate the training distribution with \\emph{controllable data augmentation} in metric space. Specifically, we first extract the graph rationales to eliminate the spurious correlations due to irrelevant information. Secondly, we generate virtual samples with perturbation on graph rationale representation domain to obtain potential OOD training samples. Finally, we propose OOD calibration to measure the distribution deviation of virtual samples by leveraging Extreme Value Theory, and further actively control the training distribution by emphasizing the impact of virtual OOD samples. Extensive studies on several real-world datasets on graph classification demonstrate the superiority of our proposed method over state-of-the-art baselines.","sentences":["Graph Neural Network (GNN) has demonstrated extraordinary performance in classifying graph properties.","However, due to the selection bias of training and testing data (e.g., training on small graphs and testing on large graphs, or training on dense graphs and testing on sparse graphs), distribution deviation is widespread.","More importantly, we often observe \\emph{hybrid structure distribution shift} of both scale and density, despite of one-sided biased data partition.","The spurious correlations over hybrid distribution deviation degrade the performance of previous GNN methods and show large instability among different datasets.","To alleviate this problem, we propose \\texttt{OOD-GMixup} to jointly manipulate the training distribution with \\emph{controllable data augmentation} in metric space.","Specifically, we first extract the graph rationales to eliminate the spurious correlations due to irrelevant information.","Secondly, we generate virtual samples with perturbation on graph rationale representation domain to obtain potential OOD training samples.","Finally, we propose OOD calibration to measure the distribution deviation of virtual samples by leveraging Extreme Value Theory, and further actively control the training distribution by emphasizing the impact of virtual OOD samples.","Extensive studies on several real-world datasets on graph classification demonstrate the superiority of our proposed method over state-of-the-art baselines."],"url":"http://arxiv.org/abs/2308.08344v1"}
{"created":"2023-08-16 13:09:27","title":"Optimizing Noise for $f$-Differential Privacy via Anti-Concentration and Stochastic Dominance","abstract":"In this paper, we establish anti-concentration inequalities for additive noise mechanisms which achieve $f$-differential privacy ($f$-DP), a notion of privacy phrased in terms of a tradeoff function (a.k.a. ROC curve) $f$ which limits the ability of an adversary to determine which individuals were in the database. We show that canonical noise distributions (CNDs), proposed by Awan and Vadhan (2023), match the anti-concentration bounds at half-integer values, indicating that their tail behavior is near-optimal. We also show that all CNDs are sub-exponential, regardless of the $f$-DP guarantee. In the case of log-concave CNDs, we show that they are the stochastically smallest noise compared to any other noise distributions with the same privacy guarantee. In terms of integer-valued noise, we propose a new notion of discrete CND and prove that a discrete CND always exists, can be constructed by rounding a continuous CND, and that the discrete CND is unique when designed for a statistic with sensitivity 1. We further show that the discrete CND at sensitivity 1 is stochastically smallest compared to other integer-valued noises. Our theoretical results shed light on the different types of privacy guarantees possible in the $f$-DP framework and can be incorporated in more complex mechanisms to optimize performance.","sentences":["In this paper, we establish anti-concentration inequalities for additive noise mechanisms which achieve $f$-differential privacy ($f$-DP), a notion of privacy phrased in terms of a tradeoff function (a.k.a. ROC curve) $f$ which limits the ability of an adversary to determine which individuals were in the database.","We show that canonical noise distributions (CNDs), proposed by Awan and Vadhan (2023), match the anti-concentration bounds at half-integer values, indicating that their tail behavior is near-optimal.","We also show that all CNDs are sub-exponential, regardless of the $f$-DP guarantee.","In the case of log-concave CNDs, we show that they are the stochastically smallest noise compared to any other noise distributions with the same privacy guarantee.","In terms of integer-valued noise, we propose a new notion of discrete CND and prove that a discrete CND always exists, can be constructed by rounding a continuous CND, and that the discrete CND is unique when designed for a statistic with sensitivity 1.","We further show that the discrete CND at sensitivity 1 is stochastically smallest compared to other integer-valued noises.","Our theoretical results shed light on the different types of privacy guarantees possible in the $f$-DP framework and can be incorporated in more complex mechanisms to optimize performance."],"url":"http://arxiv.org/abs/2308.08343v1"}
{"created":"2023-08-16 12:50:10","title":"Learning Logic Programs by Discovering Higher-Order Abstractions","abstract":"Discovering novel abstractions is important for human-level AI. We introduce an approach to discover higher-order abstractions, such as map, filter, and fold. We focus on inductive logic programming, which induces logic programs from examples and background knowledge. We introduce the higher-order refactoring problem, where the goal is to compress a logic program by introducing higher-order abstractions. We implement our approach in STEVIE, which formulates the higher-order refactoring problem as a constraint optimisation problem. Our experimental results on multiple domains, including program synthesis and visual reasoning, show that, compared to no refactoring, STEVIE can improve predictive accuracies by 27% and reduce learning times by 47%. We also show that STEVIE can discover abstractions that transfer to different domains","sentences":["Discovering novel abstractions is important for human-level AI.","We introduce an approach to discover higher-order abstractions, such as map, filter, and fold.","We focus on inductive logic programming, which induces logic programs from examples and background knowledge.","We introduce the higher-order refactoring problem, where the goal is to compress a logic program by introducing higher-order abstractions.","We implement our approach in STEVIE, which formulates the higher-order refactoring problem as a constraint optimisation problem.","Our experimental results on multiple domains, including program synthesis and visual reasoning, show that, compared to no refactoring, STEVIE can improve predictive accuracies by 27% and reduce learning times by 47%.","We also show that STEVIE can discover abstractions that transfer to different domains"],"url":"http://arxiv.org/abs/2308.08334v1"}
{"created":"2023-08-16 12:46:52","title":"Improving Depth Gradient Continuity in Transformers: A Comparative Study on Monocular Depth Estimation with CNN","abstract":"Monocular depth estimation is an ongoing challenge in computer vision. Recent progress with Transformer models has demonstrated notable advantages over conventional CNNs in this area. However, there's still a gap in understanding how these models prioritize different regions in 2D images and how these regions affect depth estimation performance. To explore the differences between Transformers and CNNs, we employ a sparse pixel approach to contrastively analyze the distinctions between the two. Our findings suggest that while Transformers excel in handling global context and intricate textures, they lag behind CNNs in preserving depth gradient continuity. To further enhance the performance of Transformer models in monocular depth estimation, we propose the Depth Gradient Refinement (DGR) module that refines depth estimation through high-order differentiation, feature fusion, and recalibration. Additionally, we leverage optimal transport theory, treating depth maps as spatial probability distributions, and employ the optimal transport distance as a loss function to optimize our model. Experimental results demonstrate that models integrated with the plug-and-play Depth Gradient Refinement (DGR) module and the proposed loss function enhance performance without increasing complexity and computational costs. This research not only offers fresh insights into the distinctions between Transformers and CNNs in depth estimation but also paves the way for novel depth estimation methodologies.","sentences":["Monocular depth estimation is an ongoing challenge in computer vision.","Recent progress with Transformer models has demonstrated notable advantages over conventional CNNs in this area.","However, there's still a gap in understanding how these models prioritize different regions in 2D images and how these regions affect depth estimation performance.","To explore the differences between Transformers and CNNs, we employ a sparse pixel approach to contrastively analyze the distinctions between the two.","Our findings suggest that while Transformers excel in handling global context and intricate textures, they lag behind CNNs in preserving depth gradient continuity.","To further enhance the performance of Transformer models in monocular depth estimation, we propose the Depth Gradient Refinement (DGR) module that refines depth estimation through high-order differentiation, feature fusion, and recalibration.","Additionally, we leverage optimal transport theory, treating depth maps as spatial probability distributions, and employ the optimal transport distance as a loss function to optimize our model.","Experimental results demonstrate that models integrated with the plug-and-play Depth Gradient Refinement (DGR) module and the proposed loss function enhance performance without increasing complexity and computational costs.","This research not only offers fresh insights into the distinctions between Transformers and CNNs in depth estimation but also paves the way for novel depth estimation methodologies."],"url":"http://arxiv.org/abs/2308.08333v1"}
{"created":"2023-08-16 12:42:28","title":"Phase Retrieval with Background Information: Decreased References and Efficient Methods","abstract":"Fourier phase retrieval(PR) is a severely ill-posed inverse problem that arises in various applications. To guarantee a unique solution and relieve the dependence on the initialization, background information can be exploited as a structural priors. However, the requirement for the background information may be challenging when moving to the high-resolution imaging. At the same time, the previously proposed projected gradient descent(PGD) method also demands much background information.   In this paper, we present an improved theoretical result about the demand for the background information, along with two Douglas Rachford(DR) based methods. Analytically, we demonstrate that the background required to ensure a unique solution can be decreased by nearly $1/2$ for the 2-D signals compared to the 1-D signals. By generalizing the results into $d$-dimension, we show that the length of the background information more than $(2^{\\frac{d+1}{d}}-1)$ folds of the signal is sufficient to ensure the uniqueness. At the same time, we also analyze the stability and robustness of the model when measurements and background information are corrupted by the noise. Furthermore, two methods called Background Douglas-Rachford (BDR) and Convex Background Douglas-Rachford (CBDR) are proposed. BDR which is a kind of non-convex method is proven to have the local R-linear convergence rate under mild assumptions. Instead, CBDR method uses the techniques of convexification and can be proven to own a global convergence guarantee as long as the background information is sufficient. To support this, a new property called F-RIP is established. We test the performance of the proposed methods through simulations as well as real experimental measurements, and demonstrate that they achieve a higher recovery rate with less background information compared to the PGD method.","sentences":["Fourier phase retrieval(PR) is a severely ill-posed inverse problem that arises in various applications.","To guarantee a unique solution and relieve the dependence on the initialization, background information can be exploited as a structural priors.","However, the requirement for the background information may be challenging when moving to the high-resolution imaging.","At the same time, the previously proposed projected gradient descent(PGD) method also demands much background information.   ","In this paper, we present an improved theoretical result about the demand for the background information, along with two Douglas Rachford(DR) based methods.","Analytically, we demonstrate that the background required to ensure a unique solution can be decreased by nearly $1/2$ for the 2-D signals compared to the 1-D signals.","By generalizing the results into $d$-dimension, we show that the length of the background information more than $(2^{\\frac{d+1}{d}}-1)$ folds of the signal is sufficient to ensure the uniqueness.","At the same time, we also analyze the stability and robustness of the model when measurements and background information are corrupted by the noise.","Furthermore, two methods called Background Douglas-Rachford (BDR) and Convex Background Douglas-Rachford (CBDR) are proposed.","BDR which is a kind of non-convex method is proven to have the local R-linear convergence rate under mild assumptions.","Instead, CBDR method uses the techniques of convexification and can be proven to own a global convergence guarantee as long as the background information is sufficient.","To support this, a new property called F-RIP is established.","We test the performance of the proposed methods through simulations as well as real experimental measurements, and demonstrate that they achieve a higher recovery rate with less background information compared to the PGD method."],"url":"http://arxiv.org/abs/2308.08328v1"}
{"created":"2023-08-16 12:40:47","title":"AdaBrowse: Adaptive Video Browser for Efficient Continuous Sign Language Recognition","abstract":"Raw videos have been proven to own considerable feature redundancy where in many cases only a portion of frames can already meet the requirements for accurate recognition. In this paper, we are interested in whether such redundancy can be effectively leveraged to facilitate efficient inference in continuous sign language recognition (CSLR). We propose a novel adaptive model (AdaBrowse) to dynamically select a most informative subsequence from input video sequences by modelling this problem as a sequential decision task. In specific, we first utilize a lightweight network to quickly scan input videos to extract coarse features. Then these features are fed into a policy network to intelligently select a subsequence to process. The corresponding subsequence is finally inferred by a normal CSLR model for sentence prediction. As only a portion of frames are processed in this procedure, the total computations can be considerably saved. Besides temporal redundancy, we are also interested in whether the inherent spatial redundancy can be seamlessly integrated together to achieve further efficiency, i.e., dynamically selecting a lowest input resolution for each sample, whose model is referred to as AdaBrowse+. Extensive experimental results on four large-scale CSLR datasets, i.e., PHOENIX14, PHOENIX14-T, CSL-Daily and CSL, demonstrate the effectiveness of AdaBrowse and AdaBrowse+ by achieving comparable accuracy with state-of-the-art methods with 1.44$\\times$ throughput and 2.12$\\times$ fewer FLOPs. Comparisons with other commonly-used 2D CNNs and adaptive efficient methods verify the effectiveness of AdaBrowse. Code is available at \\url{https://github.com/hulianyuyy/AdaBrowse}.","sentences":["Raw videos have been proven to own considerable feature redundancy where in many cases only a portion of frames can already meet the requirements for accurate recognition.","In this paper, we are interested in whether such redundancy can be effectively leveraged to facilitate efficient inference in continuous sign language recognition (CSLR).","We propose a novel adaptive model (AdaBrowse) to dynamically select a most informative subsequence from input video sequences by modelling this problem as a sequential decision task.","In specific, we first utilize a lightweight network to quickly scan input videos to extract coarse features.","Then these features are fed into a policy network to intelligently select a subsequence to process.","The corresponding subsequence is finally inferred by a normal CSLR model for sentence prediction.","As only a portion of frames are processed in this procedure, the total computations can be considerably saved.","Besides temporal redundancy, we are also interested in whether the inherent spatial redundancy can be seamlessly integrated together to achieve further efficiency, i.e., dynamically selecting a lowest input resolution for each sample, whose model is referred to as AdaBrowse+.","Extensive experimental results on four large-scale CSLR datasets, i.e., PHOENIX14, PHOENIX14-T, CSL-Daily and CSL, demonstrate the effectiveness of AdaBrowse and AdaBrowse+ by achieving comparable accuracy with state-of-the-art methods with 1.44$\\times$ throughput and 2.12$\\times$ fewer FLOPs.","Comparisons with other commonly-used 2D CNNs and adaptive efficient methods verify the effectiveness of AdaBrowse.","Code is available at \\url{https://github.com/hulianyuyy/AdaBrowse}."],"url":"http://arxiv.org/abs/2308.08327v1"}
{"created":"2023-08-16 12:39:55","title":"Soft-Information Post-Processing for Chase-Pyndiah Decoding Based on Generalized Mutual Information","abstract":"Chase-Pyndiah decoding is widely used for decoding product codes. However, this method is suboptimal and requires scaling the soft information exchanged during the iterative processing. In this paper, we propose a framework for obtaining the scaling coefficients based on maximizing the generalized mutual information. Our approach yields gains up to 0.11 dB for product codes with two-error correcting extended BCH component codes over the binary-input additive white Gaussian noise channel compared to the original Chase-Pyndiah decoder with heuristically obtained coefficients. We also introduce an extrinsic version of the Chase-Pyndiah decoder and associate product codes with a turbo-like code ensemble to derive a Monte Carlo-based density evolution analysis. The resulting iterative decoding thresholds accurately predict the onset of the waterfall region.","sentences":["Chase-Pyndiah decoding is widely used for decoding product codes.","However, this method is suboptimal and requires scaling the soft information exchanged during the iterative processing.","In this paper, we propose a framework for obtaining the scaling coefficients based on maximizing the generalized mutual information.","Our approach yields gains up to 0.11 dB for product codes with two-error correcting extended BCH component codes over the binary-input additive white Gaussian noise channel compared to the original Chase-Pyndiah decoder with heuristically obtained coefficients.","We also introduce an extrinsic version of the Chase-Pyndiah decoder and associate product codes with a turbo-like code ensemble to derive a Monte Carlo-based density evolution analysis.","The resulting iterative decoding thresholds accurately predict the onset of the waterfall region."],"url":"http://arxiv.org/abs/2308.08326v1"}
{"created":"2023-08-16 12:39:39","title":"Visually-Aware Context Modeling for News Image Captioning","abstract":"The goal of News Image Captioning is to generate an image caption according to the content of both a news article and an image. To leverage the visual information effectively, it is important to exploit the connection between the context in the articles/captions and the images. Psychological studies indicate that human faces in images draw higher attention priorities. On top of that, humans often play a central role in news stories, as also proven by the face-name co-occurrence pattern we discover in existing News Image Captioning datasets. Therefore, we design a face-naming module for faces in images and names in captions/articles to learn a better name embedding. Apart from names, which can be directly linked to an image area (faces), news image captions mostly contain context information that can only be found in the article. Humans typically address this by searching for relevant information from the article based on the image. To emulate this thought process, we design a retrieval strategy using CLIP to retrieve sentences that are semantically close to the image. We conduct extensive experiments to demonstrate the efficacy of our framework. Without using additional paired data, we establish the new state-of-the-art performance on two News Image Captioning datasets, exceeding the previous state-of-the-art by 5 CIDEr points. We will release code upon acceptance.","sentences":["The goal of News Image Captioning is to generate an image caption according to the content of both a news article and an image.","To leverage the visual information effectively, it is important to exploit the connection between the context in the articles/captions and the images.","Psychological studies indicate that human faces in images draw higher attention priorities.","On top of that, humans often play a central role in news stories, as also proven by the face-name co-occurrence pattern we discover in existing News Image Captioning datasets.","Therefore, we design a face-naming module for faces in images and names in captions/articles to learn a better name embedding.","Apart from names, which can be directly linked to an image area (faces), news image captions mostly contain context information that can only be found in the article.","Humans typically address this by searching for relevant information from the article based on the image.","To emulate this thought process, we design a retrieval strategy using CLIP to retrieve sentences that are semantically close to the image.","We conduct extensive experiments to demonstrate the efficacy of our framework.","Without using additional paired data, we establish the new state-of-the-art performance on two News Image Captioning datasets, exceeding the previous state-of-the-art by 5 CIDEr points.","We will release code upon acceptance."],"url":"http://arxiv.org/abs/2308.08325v1"}
{"created":"2023-08-16 12:38:17","title":"Incremental Collaborative Beam Alignment for Millimeter Wave Cell-Free MIMO Systems","abstract":"Millimeter wave (mmWave) cell-free MIMO achieves an extremely high rate while its beam alignment (BA) suffers from excessive overhead due to a large number of transceivers. Recently, user location and probing measurements are utilized for BA based on machine learning (ML) models, e.g., deep neural network (DNN). However, most of these ML models are centralized with high communication and computational overhead and give no specific consideration to practical issues, e.g., limited training data and real-time model updates. In this paper, we study the {probing} beam-based BA for mmWave cell-free MIMO downlink with the help of broad learning (BL). For channels without and with uplink-downlink reciprocity, we propose the user-side and base station (BS)-side BL-aided incremental collaborative BA approaches. Via transforming the centralized BL into a distributed learning with data and feature splitting respectively, the user-side and BS-side schemes realize implicit sharing of multiple user data and multiple BS features. Simulations confirm that the user-side scheme is applicable to fast time-varying and/or non-stationary channels, while the BS-side scheme is suitable for systems with low-bandwidth fronthaul links and a central unit with limited computing power. The advantages of proposed schemes are also demonstrated compared to traditional and DNN-aided BA schemes.","sentences":["Millimeter wave (mmWave) cell-free MIMO achieves an extremely high rate while its beam alignment (BA) suffers from excessive overhead due to a large number of transceivers.","Recently, user location and probing measurements are utilized for BA based on machine learning (ML) models, e.g., deep neural network (DNN).","However, most of these ML models are centralized with high communication and computational overhead and give no specific consideration to practical issues, e.g., limited training data and real-time model updates.","In this paper, we study the {probing} beam-based BA for mmWave cell-free MIMO downlink with the help of broad learning (BL).","For channels without and with uplink-downlink reciprocity, we propose the user-side and base station (BS)-side BL-aided incremental collaborative BA approaches.","Via transforming the centralized BL into a distributed learning with data and feature splitting respectively, the user-side and BS-side schemes realize implicit sharing of multiple user data and multiple BS features.","Simulations confirm that the user-side scheme is applicable to fast time-varying and/or non-stationary channels, while the BS-side scheme is suitable for systems with low-bandwidth fronthaul links and a central unit with limited computing power.","The advantages of proposed schemes are also demonstrated compared to traditional and DNN-aided BA schemes."],"url":"http://arxiv.org/abs/2308.08324v1"}
{"created":"2023-08-16 12:33:13","title":"Towards Valid and Reliable Privacy Concern Scales: The Example of IUIPC-8","abstract":"Valid and reliable measurement instruments are crucial for human factors in privacy research. We expect them to measure what they purport to measure, yielding validity, and to measure this consistently, offering us reliability. While there is a range of privacy concern instruments available in the field and their investigation continues unabated, we shall focus on a brief form of the scale Internet Users? Information Privacy Concerns (IUIPC-8) as an example. We not only present IUIPC-8 itself, but also consider methods for the evaluation of valid and reliable measurement instruments. In this, confirmatory factor analysis (CFA) serves us as a valuable tool. Our inquiry takes into account the ordinal and non-normal data yielded by the IUIPC questionnaire, compares multiple models to confirm the three-dimensionality of the scale, examines global and local fit and, finally, estimates construct validity and internal consistency reliability metrics. We offer a comparison between IUIPC-10 and IUIPC-8 drawing on two independent samples. In conclusion, we highlight properties of the scale and considerations for its use in practice.","sentences":["Valid and reliable measurement instruments are crucial for human factors in privacy research.","We expect them to measure what they purport to measure, yielding validity, and to measure this consistently, offering us reliability.","While there is a range of privacy concern instruments available in the field and their investigation continues unabated, we shall focus on a brief form of the scale Internet Users?","Information Privacy Concerns (IUIPC-8) as an example.","We not only present IUIPC-8 itself, but also consider methods for the evaluation of valid and reliable measurement instruments.","In this, confirmatory factor analysis (CFA) serves us as a valuable tool.","Our inquiry takes into account the ordinal and non-normal data yielded by the IUIPC questionnaire, compares multiple models to confirm the three-dimensionality of the scale, examines global and local fit and, finally, estimates construct validity and internal consistency reliability metrics.","We offer a comparison between IUIPC-10 and IUIPC-8 drawing on two independent samples.","In conclusion, we highlight properties of the scale and considerations for its use in practice."],"url":"http://arxiv.org/abs/2308.08322v1"}
{"created":"2023-08-16 12:30:17","title":"Stable and Causal Inference for Discriminative Self-supervised Deep Visual Representations","abstract":"In recent years, discriminative self-supervised methods have made significant strides in advancing various visual tasks. The central idea of learning a data encoder that is robust to data distortions/augmentations is straightforward yet highly effective. Although many studies have demonstrated the empirical success of various learning methods, the resulting learned representations can exhibit instability and hinder downstream performance. In this study, we analyze discriminative self-supervised methods from a causal perspective to explain these unstable behaviors and propose solutions to overcome them. Our approach draws inspiration from prior works that empirically demonstrate the ability of discriminative self-supervised methods to demix ground truth causal sources to some extent. Unlike previous work on causality-empowered representation learning, we do not apply our solutions during the training process but rather during the inference process to improve time efficiency. Through experiments on both controlled image datasets and realistic image datasets, we show that our proposed solutions, which involve tempering a linear transformation with controlled synthetic data, are effective in addressing these issues.","sentences":["In recent years, discriminative self-supervised methods have made significant strides in advancing various visual tasks.","The central idea of learning a data encoder that is robust to data distortions/augmentations is straightforward yet highly effective.","Although many studies have demonstrated the empirical success of various learning methods, the resulting learned representations can exhibit instability and hinder downstream performance.","In this study, we analyze discriminative self-supervised methods from a causal perspective to explain these unstable behaviors and propose solutions to overcome them.","Our approach draws inspiration from prior works that empirically demonstrate the ability of discriminative self-supervised methods to demix ground truth causal sources to some extent.","Unlike previous work on causality-empowered representation learning, we do not apply our solutions during the training process but rather during the inference process to improve time efficiency.","Through experiments on both controlled image datasets and realistic image datasets, we show that our proposed solutions, which involve tempering a linear transformation with controlled synthetic data, are effective in addressing these issues."],"url":"http://arxiv.org/abs/2308.08321v1"}
