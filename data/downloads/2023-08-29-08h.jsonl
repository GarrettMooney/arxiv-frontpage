{"created":"2023-08-28 17:59:47","title":"Efficient Discovery and Effective Evaluation of Visual Perceptual Similarity: A Benchmark and Beyond","abstract":"Visual similarities discovery (VSD) is an important task with broad e-commerce applications. Given an image of a certain object, the goal of VSD is to retrieve images of different objects with high perceptual visual similarity. Although being a highly addressed problem, the evaluation of proposed methods for VSD is often based on a proxy of an identification-retrieval task, evaluating the ability of a model to retrieve different images of the same object. We posit that evaluating VSD methods based on identification tasks is limited, and faithful evaluation must rely on expert annotations. In this paper, we introduce the first large-scale fashion visual similarity benchmark dataset, consisting of more than 110K expert-annotated image pairs. Besides this major contribution, we share insight from the challenges we faced while curating this dataset. Based on these insights, we propose a novel and efficient labeling procedure that can be applied to any dataset. Our analysis examines its limitations and inductive biases, and based on these findings, we propose metrics to mitigate those limitations. Though our primary focus lies on visual similarity, the methodologies we present have broader applications for discovering and evaluating perceptual similarity across various domains.","sentences":["Visual similarities discovery (VSD) is an important task with broad e-commerce applications.","Given an image of a certain object, the goal of VSD is to retrieve images of different objects with high perceptual visual similarity.","Although being a highly addressed problem, the evaluation of proposed methods for VSD is often based on a proxy of an identification-retrieval task, evaluating the ability of a model to retrieve different images of the same object.","We posit that evaluating VSD methods based on identification tasks is limited, and faithful evaluation must rely on expert annotations.","In this paper, we introduce the first large-scale fashion visual similarity benchmark dataset, consisting of more than 110K expert-annotated image pairs.","Besides this major contribution, we share insight from the challenges we faced while curating this dataset.","Based on these insights, we propose a novel and efficient labeling procedure that can be applied to any dataset.","Our analysis examines its limitations and inductive biases, and based on these findings, we propose metrics to mitigate those limitations.","Though our primary focus lies on visual similarity, the methodologies we present have broader applications for discovering and evaluating perceptual similarity across various domains."],"url":"http://arxiv.org/abs/2308.14753v1"}
{"created":"2023-08-28 17:59:35","title":"AI Deception: A Survey of Examples, Risks, and Potential Solutions","abstract":"This paper argues that a range of current AI systems have learned how to deceive humans. We define deception as the systematic inducement of false beliefs in the pursuit of some outcome other than the truth. We first survey empirical examples of AI deception, discussing both special-use AI systems (including Meta's CICERO) built for specific competitive situations, and general-purpose AI systems (such as large language models). Next, we detail several risks from AI deception, such as fraud, election tampering, and losing control of AI systems. Finally, we outline several potential solutions to the problems posed by AI deception: first, regulatory frameworks should subject AI systems that are capable of deception to robust risk-assessment requirements; second, policymakers should implement bot-or-not laws; and finally, policymakers should prioritize the funding of relevant research, including tools to detect AI deception and to make AI systems less deceptive. Policymakers, researchers, and the broader public should work proactively to prevent AI deception from destabilizing the shared foundations of our society.","sentences":["This paper argues that a range of current AI systems have learned how to deceive humans.","We define deception as the systematic inducement of false beliefs in the pursuit of some outcome other than the truth.","We first survey empirical examples of AI deception, discussing both special-use AI systems (including Meta's CICERO) built for specific competitive situations, and general-purpose AI systems (such as large language models).","Next, we detail several risks from AI deception, such as fraud, election tampering, and losing control of AI systems.","Finally, we outline several potential solutions to the problems posed by AI deception: first, regulatory frameworks should subject AI systems that are capable of deception to robust risk-assessment requirements; second, policymakers should implement bot-or-not laws; and finally, policymakers should prioritize the funding of relevant research, including tools to detect AI deception and to make AI systems less deceptive.","Policymakers, researchers, and the broader public should work proactively to prevent AI deception from destabilizing the shared foundations of our society."],"url":"http://arxiv.org/abs/2308.14752v1"}
{"created":"2023-08-28 17:56:22","title":"MagicEdit: High-Fidelity and Temporally Coherent Video Editing","abstract":"In this report, we present MagicEdit, a surprisingly simple yet effective solution to the text-guided video editing task. We found that high-fidelity and temporally coherent video-to-video translation can be achieved by explicitly disentangling the learning of content, structure and motion signals during training. This is in contradict to most existing methods which attempt to jointly model both the appearance and temporal representation within a single framework, which we argue, would lead to degradation in per-frame quality. Despite its simplicity, we show that MagicEdit supports various downstream video editing tasks, including video stylization, local editing, video-MagicMix and video outpainting.","sentences":["In this report, we present MagicEdit, a surprisingly simple yet effective solution to the text-guided video editing task.","We found that high-fidelity and temporally coherent video-to-video translation can be achieved by explicitly disentangling the learning of content, structure and motion signals during training.","This is in contradict to most existing methods which attempt to jointly model both the appearance and temporal representation within a single framework, which we argue, would lead to degradation in per-frame quality.","Despite its simplicity, we show that MagicEdit supports various downstream video editing tasks, including video stylization, local editing, video-MagicMix and video outpainting."],"url":"http://arxiv.org/abs/2308.14749v1"}
{"created":"2023-08-28 17:56:18","title":"MagicAvatar: Multimodal Avatar Generation and Animation","abstract":"This report presents MagicAvatar, a framework for multimodal video generation and animation of human avatars. Unlike most existing methods that generate avatar-centric videos directly from multimodal inputs (e.g., text prompts), MagicAvatar explicitly disentangles avatar video generation into two stages: (1) multimodal-to-motion and (2) motion-to-video generation. The first stage translates the multimodal inputs into motion/ control signals (e.g., human pose, depth, DensePose); while the second stage generates avatar-centric video guided by these motion signals. Additionally, MagicAvatar supports avatar animation by simply providing a few images of the target person. This capability enables the animation of the provided human identity according to the specific motion derived from the first stage. We demonstrate the flexibility of MagicAvatar through various applications, including text-guided and video-guided avatar generation, as well as multimodal avatar animation.","sentences":["This report presents MagicAvatar, a framework for multimodal video generation and animation of human avatars.","Unlike most existing methods that generate avatar-centric videos directly from multimodal inputs (e.g., text prompts), MagicAvatar explicitly disentangles avatar video generation into two stages: (1) multimodal-to-motion and (2) motion-to-video generation.","The first stage translates the multimodal inputs into motion/ control signals (e.g., human pose, depth, DensePose); while the second stage generates avatar-centric video guided by these motion signals.","Additionally, MagicAvatar supports avatar animation by simply providing a few images of the target person.","This capability enables the animation of the provided human identity according to the specific motion derived from the first stage.","We demonstrate the flexibility of MagicAvatar through various applications, including text-guided and video-guided avatar generation, as well as multimodal avatar animation."],"url":"http://arxiv.org/abs/2308.14748v1"}
{"created":"2023-08-28 17:55:33","title":"CoVR: Learning Composed Video Retrieval from Web Video Captions","abstract":"Composed Image Retrieval (CoIR) has recently gained popularity as a task that considers both text and image queries together, to search for relevant images in a database. Most CoIR approaches require manually annotated datasets, comprising image-text-image triplets, where the text describes a modification from the query image to the target image. However, manual curation of CoIR triplets is expensive and prevents scalability. In this work, we instead propose a scalable automatic dataset creation methodology that generates triplets given video-caption pairs, while also expanding the scope of the task to include composed video retrieval (CoVR). To this end, we mine paired videos with a similar caption from a large database, and leverage a large language model to generate the corresponding modification text. Applying this methodology to the extensive WebVid2M collection, we automatically construct our WebVid-CoVR dataset, resulting in 1.6 million triplets. Moreover, we introduce a new benchmark for CoVR with a manually annotated evaluation set, along with baseline results. Our experiments further demonstrate that training a CoVR model on our dataset effectively transfers to CoIR, leading to improved state-of-the-art performance in the zero-shot setup on both the CIRR and FashionIQ benchmarks. Our code, datasets, and models are publicly available at https://imagine.enpc.fr/~ventural/covr.","sentences":["Composed Image Retrieval (CoIR) has recently gained popularity as a task that considers both text and image queries together, to search for relevant images in a database.","Most CoIR approaches require manually annotated datasets, comprising image-text-image triplets, where the text describes a modification from the query image to the target image.","However, manual curation of CoIR triplets is expensive and prevents scalability.","In this work, we instead propose a scalable automatic dataset creation methodology that generates triplets given video-caption pairs, while also expanding the scope of the task to include composed video retrieval (CoVR).","To this end, we mine paired videos with a similar caption from a large database, and leverage a large language model to generate the corresponding modification text.","Applying this methodology to the extensive WebVid2M collection, we automatically construct our WebVid-CoVR dataset, resulting in 1.6 million triplets.","Moreover, we introduce a new benchmark for CoVR with a manually annotated evaluation set, along with baseline results.","Our experiments further demonstrate that training a CoVR model on our dataset effectively transfers to CoIR, leading to improved state-of-the-art performance in the zero-shot setup on both the CIRR and FashionIQ benchmarks.","Our code, datasets, and models are publicly available at https://imagine.enpc.fr/~ventural/covr."],"url":"http://arxiv.org/abs/2308.14746v1"}
{"created":"2023-08-28 17:42:53","title":"Advancement on Security Applications of Private Intersection Sum Protocol","abstract":"Secure computation protocols combine inputs from involved parties to generate an output while keeping their inputs private. Private Set Intersection (PSI) is a secure computation protocol that allows two parties, who each hold a set of items, to learn the intersection of their sets without revealing anything else about the items. Private Intersection Sum (PIS) extends PSI when the two parties want to learn the cardinality of the intersection, as well as the sum of the associated integer values for each identifier in the intersection, but nothing more. Finally, Private Join and Compute (PJC) is a scalable extension of PIS protocol to help organizations work together with confidential data sets. The extensions proposed in this paper include: (a) extending PJC protocol to additional data columns and applying columnar aggregation based on supported homomorphic operations, (b) exploring Ring Learning with Errors (RLWE) homomorphic encryption schemes to apply arithmetic operations such as sum and sum of squares, (c) ensuring stronger security using mutual authentication of communicating parties using certificates, and (d) developing a Website to operationalize such a service offering. We applied our results to develop a Proof-of-Concept solution called JingBing, a voter list validation service that allows different states to register, acquire secure communication modules, install it, and then conduct authenticated peer-to-peer communication. We conclude our paper with directions for future research to make such a solution scalable for practical real-life scenarios.","sentences":["Secure computation protocols combine inputs from involved parties to generate an output while keeping their inputs private.","Private Set Intersection (PSI) is a secure computation protocol that allows two parties, who each hold a set of items, to learn the intersection of their sets without revealing anything else about the items.","Private Intersection Sum (PIS) extends PSI when the two parties want to learn the cardinality of the intersection, as well as the sum of the associated integer values for each identifier in the intersection, but nothing more.","Finally, Private Join and Compute (PJC) is a scalable extension of PIS protocol to help organizations work together with confidential data sets.","The extensions proposed in this paper include: (a) extending PJC protocol to additional data columns and applying columnar aggregation based on supported homomorphic operations, (b) exploring Ring Learning with Errors (RLWE) homomorphic encryption schemes to apply arithmetic operations such as sum and sum of squares, (c) ensuring stronger security using mutual authentication of communicating parties using certificates, and (d) developing a Website to operationalize such a service offering.","We applied our results to develop a Proof-of-Concept solution called JingBing, a voter list validation service that allows different states to register, acquire secure communication modules, install it, and then conduct authenticated peer-to-peer communication.","We conclude our paper with directions for future research to make such a solution scalable for practical real-life scenarios."],"url":"http://arxiv.org/abs/2308.14741v1"}
{"created":"2023-08-28 17:41:14","title":"Total Selfie: Generating Full-Body Selfies","abstract":"We present a method to generate full-body selfies -- photos that you take of yourself, but capturing your whole body as if someone else took the photo of you from a few feet away. Our approach takes as input a pre-captured video of your body, a target pose photo, and a selfie + background pair for each location. We introduce a novel diffusion-based approach to combine all of this information into high quality, well-composed photos of you with the desired pose and background.","sentences":["We present a method to generate full-body selfies -- photos that you take of yourself, but capturing your whole body as if someone else took the photo of you from a few feet away.","Our approach takes as input a pre-captured video of your body, a target pose photo, and a selfie + background pair for each location.","We introduce a novel diffusion-based approach to combine all of this information into high quality, well-composed photos of you with the desired pose and background."],"url":"http://arxiv.org/abs/2308.14740v1"}
{"created":"2023-08-28 17:38:31","title":"Flexible Techniques for Differentiable Rendering with 3D Gaussians","abstract":"Fast, reliable shape reconstruction is an essential ingredient in many computer vision applications. Neural Radiance Fields demonstrated that photorealistic novel view synthesis is within reach, but was gated by performance requirements for fast reconstruction of real scenes and objects. Several recent approaches have built on alternative shape representations, in particular, 3D Gaussians. We develop extensions to these renderers, such as integrating differentiable optical flow, exporting watertight meshes and rendering per-ray normals. Additionally, we show how two of the recent methods are interoperable with each other. These reconstructions are quick, robust, and easily performed on GPU or CPU. For code and visual examples, see https://leonidk.github.io/fmb-plus","sentences":["Fast, reliable shape reconstruction is an essential ingredient in many computer vision applications.","Neural Radiance Fields demonstrated that photorealistic novel view synthesis is within reach, but was gated by performance requirements for fast reconstruction of real scenes and objects.","Several recent approaches have built on alternative shape representations, in particular, 3D Gaussians.","We develop extensions to these renderers, such as integrating differentiable optical flow, exporting watertight meshes and rendering per-ray normals.","Additionally, we show how two of the recent methods are interoperable with each other.","These reconstructions are quick, robust, and easily performed on GPU or CPU.","For code and visual examples, see https://leonidk.github.io/fmb-plus"],"url":"http://arxiv.org/abs/2308.14737v1"}
{"created":"2023-08-28 17:34:52","title":"Differentially Private Aggregation via Imperfect Shuffling","abstract":"In this paper, we introduce the imperfect shuffle differential privacy model, where messages sent from users are shuffled in an almost uniform manner before being observed by a curator for private aggregation. We then consider the private summation problem. We show that the standard split-and-mix protocol by Ishai et. al. [FOCS 2006] can be adapted to achieve near-optimal utility bounds in the imperfect shuffle model. Specifically, we show that surprisingly, there is no additional error overhead necessary in the imperfect shuffle model.","sentences":["In this paper, we introduce the imperfect shuffle differential privacy model, where messages sent from users are shuffled in an almost uniform manner before being observed by a curator for private aggregation.","We then consider the private summation problem.","We show that the standard split-and-mix protocol by Ishai et. al.","[FOCS 2006] can be adapted to achieve near-optimal utility bounds in the imperfect shuffle model.","Specifically, we show that surprisingly, there is no additional error overhead necessary in the imperfect shuffle model."],"url":"http://arxiv.org/abs/2308.14733v1"}
{"created":"2023-08-28 17:34:07","title":"Distilled GPT for Source Code Summarization","abstract":"A code summary is a brief natural language description of source code. Summaries are usually only a single sentence long, and yet form the backbone of developer documentation. A short descriptions such as \"changes all visible polygons to the color blue\" can give a programmer a high-level idea of what code does without the effort of reading the code itself. Recently, products based on Large Language Models such as ChatGPT have demonstrated a strong ability to write these descriptions automatically. However, to use these tools, programmers must send their code to untrusted third parties for processing (e.g., via an API call). This loss of custody is not acceptable to many organizations. In this paper, we present an alternative: we train an open source model using sample output generated by GPT-3.5 in a process related to knowledge distillation. Our model is small enough (350m parameters) to be run on a single 16gb GPU, yet we show in our evaluation that it is large enough to mimic GPT-3.5 on this task.","sentences":["A code summary is a brief natural language description of source code.","Summaries are usually only a single sentence long, and yet form the backbone of developer documentation.","A short descriptions such as \"changes all visible polygons to the color blue\" can give a programmer a high-level idea of what code does without the effort of reading the code itself.","Recently, products based on Large Language Models such as ChatGPT have demonstrated a strong ability to write these descriptions automatically.","However, to use these tools, programmers must send their code to untrusted third parties for processing (e.g., via an API call).","This loss of custody is not acceptable to many organizations.","In this paper, we present an alternative: we train an open source model using sample output generated by GPT-3.5 in a process related to knowledge distillation.","Our model is small enough (350m parameters) to be run on a single 16gb GPU, yet we show in our evaluation that it is large enough to mimic GPT-3.5 on this task."],"url":"http://arxiv.org/abs/2308.14731v1"}
{"created":"2023-08-28 17:30:44","title":"Faster Min-Cost Flow on Bounded Treewidth Graphs","abstract":"We present a $\\widetilde{O}(m\\sqrt{\\tau}+n\\tau)$ time algorithm for finding a minimum-cost flow in graphs with $n$ vertices and $m$ edges, given a tree decomposition of width $\\tau$ and polynomially bounded integer costs and capacities. This improves upon the current best algorithms for general linear programs bounded by treewidth which run in $\\widetilde{O}(m \\tau^{(\\omega+1)/2})$ time by [Dong-Lee-Ye,21] and [Gu-Song,22], where $\\omega \\approx 2.37$ is the matrix multiplication exponent. Our approach leverages recent advances in structured linear program solvers and robust interior point methods.   As a corollary, for any graph $G$ with $n$ vertices, $m$ edges, and treewidth $\\tau$, we obtain a $\\widetilde{O}(\\tau^3 \\cdot m)$ time algorithm to compute a tree decomposition of $G$ with width $O(\\tau \\cdot \\log n)$.","sentences":["We present a $\\widetilde{O}(m\\sqrt{\\tau}+n\\tau)$ time algorithm for finding a minimum-cost flow in graphs with $n$ vertices and $m$ edges, given a tree decomposition of width $\\tau$ and polynomially bounded integer costs and capacities.","This improves upon the current best algorithms for general linear programs bounded by treewidth which run in $\\widetilde{O}(m \\tau^{(\\omega+1)/2})$ time by [Dong-Lee-Ye,21] and [Gu-Song,22], where $\\omega \\approx 2.37$ is the matrix multiplication exponent.","Our approach leverages recent advances in structured linear program solvers and robust interior point methods.   ","As a corollary, for any graph $G$ with $n$ vertices, $m$ edges, and treewidth $\\tau$, we obtain a $\\widetilde{O}(\\tau^3 \\cdot m)$ time algorithm to compute a tree decomposition of $G$ with width $O(\\tau \\cdot \\log n)$."],"url":"http://arxiv.org/abs/2308.14727v1"}
{"created":"2023-08-28 17:30:14","title":"PanoSwin: a Pano-style Swin Transformer for Panorama Understanding","abstract":"In panorama understanding, the widely used equirectangular projection (ERP) entails boundary discontinuity and spatial distortion. It severely deteriorates the conventional CNNs and vision Transformers on panoramas. In this paper, we propose a simple yet effective architecture named PanoSwin to learn panorama representations with ERP. To deal with the challenges brought by equirectangular projection, we explore a pano-style shift windowing scheme and novel pitch attention to address the boundary discontinuity and the spatial distortion, respectively. Besides, based on spherical distance and Cartesian coordinates, we adapt absolute positional embeddings and relative positional biases for panoramas to enhance panoramic geometry information. Realizing that planar image understanding might share some common knowledge with panorama understanding, we devise a novel two-stage learning framework to facilitate knowledge transfer from the planar images to panoramas. We conduct experiments against the state-of-the-art on various panoramic tasks, i.e., panoramic object detection, panoramic classification, and panoramic layout estimation. The experimental results demonstrate the effectiveness of PanoSwin in panorama understanding.","sentences":["In panorama understanding, the widely used equirectangular projection (ERP) entails boundary discontinuity and spatial distortion.","It severely deteriorates the conventional CNNs and vision Transformers on panoramas.","In this paper, we propose a simple yet effective architecture named PanoSwin to learn panorama representations with ERP.","To deal with the challenges brought by equirectangular projection, we explore a pano-style shift windowing scheme and novel pitch attention to address the boundary discontinuity and the spatial distortion, respectively.","Besides, based on spherical distance and Cartesian coordinates, we adapt absolute positional embeddings and relative positional biases for panoramas to enhance panoramic geometry information.","Realizing that planar image understanding might share some common knowledge with panorama understanding, we devise a novel two-stage learning framework to facilitate knowledge transfer from the planar images to panoramas.","We conduct experiments against the state-of-the-art on various panoramic tasks, i.e., panoramic object detection, panoramic classification, and panoramic layout estimation.","The experimental results demonstrate the effectiveness of PanoSwin in panorama understanding."],"url":"http://arxiv.org/abs/2308.14726v1"}
{"created":"2023-08-28 17:29:28","title":"Conceptual articles may disrupt the field of marketing but continue to decline in numbers: Evidence from a GPT-assisted study","abstract":"The present paper addresses if and how an article's academic impact varies by knowledge development approaches. Specifically, it classifies conceptual and empirical articles published in four marketing journals - Journal of Marketing, Journal of Marketing Research, Journal of Consumer Research, and Marketing Science - with the aid of a large language model, GPT. The Kolmogorov-Smirnov (KS) test is implemented for each journal to compare the disruption scores of conceptual and empirical articles. The results show that conceptual research is more likely to disrupt the field of marketing while it tends to decline in its publication quantity. Our paper highlights the importance of conceptual articles and contributes to the understanding of how marketing articles are developed and disseminated to advance knowledge.","sentences":["The present paper addresses if and how an article's academic impact varies by knowledge development approaches.","Specifically, it classifies conceptual and empirical articles published in four marketing journals - Journal of Marketing, Journal of Marketing Research, Journal of Consumer Research, and Marketing Science - with the aid of a large language model, GPT.","The Kolmogorov-Smirnov (KS) test is implemented for each journal to compare the disruption scores of conceptual and empirical articles.","The results show that conceptual research is more likely to disrupt the field of marketing while it tends to decline in its publication quantity.","Our paper highlights the importance of conceptual articles and contributes to the understanding of how marketing articles are developed and disseminated to advance knowledge."],"url":"http://arxiv.org/abs/2308.14724v1"}
{"created":"2023-08-28 17:20:47","title":"Hierarchical Time Series Forecasting with Bayesian Modeling","abstract":"We encounter time series data in many domains such as finance, physics, business, and weather. One of the main tasks of time series analysis, one that helps to take informed decisions under uncertainty, is forecasting. Time series are often hierarchically structured, e.g., a company sales might be broken down into different regions, and each region into different stores. In some cases the number of series in the hierarchy is too big to fit in a single model to produce forecasts in relevant time, and a decentralized approach is beneficial.   One way to do this is to train independent forecasting models for each series and for some summary statistics series implied by the hierarchy (e.g. the sum of all series) and to pass those models to a reconciliation algorithm to improve those forecasts by sharing information between the series.   In this work we focus on the reconciliation step, and propose a method to do so from a Bayesian perspective - Bayesian forecast reconciliation. We also define the common case of linear Gaussian reconciliation, where the forecasts are Gaussian and the hierarchy has linear structure, and show that we can compute reconciliation in closed form. We evaluate these methods on synthetic and real data sets, and compare them to other work in this field.","sentences":["We encounter time series data in many domains such as finance, physics, business, and weather.","One of the main tasks of time series analysis, one that helps to take informed decisions under uncertainty, is forecasting.","Time series are often hierarchically structured, e.g., a company sales might be broken down into different regions, and each region into different stores.","In some cases the number of series in the hierarchy is too big to fit in a single model to produce forecasts in relevant time, and a decentralized approach is beneficial.   ","One way to do this is to train independent forecasting models for each series and for some summary statistics series implied by the hierarchy (e.g. the sum of all series) and to pass those models to a reconciliation algorithm to improve those forecasts by sharing information between the series.   ","In this work we focus on the reconciliation step, and propose a method to do so from a Bayesian perspective - Bayesian forecast reconciliation.","We also define the common case of linear Gaussian reconciliation, where the forecasts are Gaussian and the hierarchy has linear structure, and show that we can compute reconciliation in closed form.","We evaluate these methods on synthetic and real data sets, and compare them to other work in this field."],"url":"http://arxiv.org/abs/2308.14719v1"}
{"created":"2023-08-28 17:16:37","title":"Local Lipschitz Filters for Bounded-Range Functions","abstract":"We study local filters for the Lipschitz property of real-valued functions $f: V \\to [0,r]$, where the Lipschitz property is defined with respect to an arbitrary undirected graph $G=(V,E)$. We give nearly optimal local Lipschitz filters both with respect to $\\ell_1$ distance and $\\ell_0$ distance. Previous work only considered unbounded-range functions over $[n]^d$. Jha and Raskhodnikova (SICOMP `13) gave an algorithm for such functions with lookup complexity exponential in $d$, which Awasthi et al.\\ (ACM Trans. Comput. Theory) showed was necessary in this setting. By considering the natural class of functions whose range is bounded in $[0,r]$, we circumvent this lower bound and achieve running time $(d^r\\log n)^{O(\\log r)}$ for the $\\ell_1$-respecting filter and $d^{O(r)}\\text{polylog }n$ for the $\\ell_0$-respecting filter for functions over $[n]^d$. Furthermore, we show that our algorithms are nearly optimal in terms of the dependence on $r$ for the domain $\\{0,1\\}^d$, an important special case of the domain $[n]^d$. In addition, our lower bound resolves an open question of Awasthi et al., removing one of the conditions necessary for their lower bound for general range. We prove our lower bound via a reduction from distribution-free Lipschitz testing. Finally, we provide two applications of our local filters. First, they can be used in conjunction with the Laplace mechanism for differential privacy to provide filter mechanisms for privately releasing outputs of black box functions even in the presence of malicious clients. Second, we use them to obtain the first tolerant testers for the Lipschitz property.","sentences":["We study local filters for the Lipschitz property of real-valued functions $f: V \\to","[0,r]$, where the Lipschitz property is defined with respect to an arbitrary undirected graph $G=(V,E)$. We give nearly optimal local Lipschitz filters both with respect to $\\ell_1$ distance and $\\ell_0$ distance.","Previous work only considered unbounded-range functions over $[n]^d$. Jha and Raskhodnikova (SICOMP `13) gave an algorithm for such functions with lookup complexity exponential in $d$, which Awasthi et al.\\ (ACM Trans.","Comput.","Theory) showed was necessary in this setting.","By considering the natural class of functions whose range is bounded in $[0,r]$, we circumvent this lower bound and achieve running time $(d^r\\log n)^{O(\\log r)}$ for the $\\ell_1$-respecting filter and $d^{O(r)}\\text{polylog }n$ for the $\\ell_0$-respecting filter for functions over $[n]^d$. Furthermore, we show that our algorithms are nearly optimal in terms of the dependence on $r$ for the domain $\\{0,1\\}^d$, an important special case of the domain $[n]^d$. In addition, our lower bound resolves an open question of Awasthi et al., removing one of the conditions necessary for their lower bound for general range.","We prove our lower bound via a reduction from distribution-free Lipschitz testing.","Finally, we provide two applications of our local filters.","First, they can be used in conjunction with the Laplace mechanism for differential privacy to provide filter mechanisms for privately releasing outputs of black box functions even in the presence of malicious clients.","Second, we use them to obtain the first tolerant testers for the Lipschitz property."],"url":"http://arxiv.org/abs/2308.14716v1"}
{"created":"2023-08-28 17:13:49","title":"R3D3: Dense 3D Reconstruction of Dynamic Scenes from Multiple Cameras","abstract":"Dense 3D reconstruction and ego-motion estimation are key challenges in autonomous driving and robotics. Compared to the complex, multi-modal systems deployed today, multi-camera systems provide a simpler, low-cost alternative. However, camera-based 3D reconstruction of complex dynamic scenes has proven extremely difficult, as existing solutions often produce incomplete or incoherent results. We propose R3D3, a multi-camera system for dense 3D reconstruction and ego-motion estimation. Our approach iterates between geometric estimation that exploits spatial-temporal information from multiple cameras, and monocular depth refinement. We integrate multi-camera feature correlation and dense bundle adjustment operators that yield robust geometric depth and pose estimates. To improve reconstruction where geometric depth is unreliable, e.g. for moving objects or low-textured regions, we introduce learnable scene priors via a depth refinement network. We show that this design enables a dense, consistent 3D reconstruction of challenging, dynamic outdoor environments. Consequently, we achieve state-of-the-art dense depth prediction on the DDAD and NuScenes benchmarks.","sentences":["Dense 3D reconstruction and ego-motion estimation are key challenges in autonomous driving and robotics.","Compared to the complex, multi-modal systems deployed today, multi-camera systems provide a simpler, low-cost alternative.","However, camera-based 3D reconstruction of complex dynamic scenes has proven extremely difficult, as existing solutions often produce incomplete or incoherent results.","We propose R3D3, a multi-camera system for dense 3D reconstruction and ego-motion estimation.","Our approach iterates between geometric estimation that exploits spatial-temporal information from multiple cameras, and monocular depth refinement.","We integrate multi-camera feature correlation and dense bundle adjustment operators that yield robust geometric depth and pose estimates.","To improve reconstruction where geometric depth is unreliable, e.g. for moving objects or low-textured regions, we introduce learnable scene priors via a depth refinement network.","We show that this design enables a dense, consistent 3D reconstruction of challenging, dynamic outdoor environments.","Consequently, we achieve state-of-the-art dense depth prediction on the DDAD and NuScenes benchmarks."],"url":"http://arxiv.org/abs/2308.14713v1"}
{"created":"2023-08-28 17:11:41","title":"Fast Feedforward Networks","abstract":"We break the linear link between the layer size and its inference cost by introducing the fast feedforward (FFF) architecture, a logarithmic-time alternative to feedforward networks.   We show that FFFs give comparable performance to feedforward networks at an exponential fraction of their inference cost, are quicker to deliver performance compared to mixture-of-expert networks, and can readily take the place of either in transformers.   Pushing FFFs to the absolute limit, we train a vision transformer to perform single-neuron inferences at the cost of only 5.8% performance decrease against the full-width variant.   Our implementation is available as a Python package; just use \"pip install fastfeedforward\".","sentences":["We break the linear link between the layer size and its inference cost by introducing the fast feedforward (FFF) architecture, a logarithmic-time alternative to feedforward networks.   ","We show that FFFs give comparable performance to feedforward networks at an exponential fraction of their inference cost, are quicker to deliver performance compared to mixture-of-expert networks, and can readily take the place of either in transformers.   ","Pushing FFFs to the absolute limit, we train a vision transformer to perform single-neuron inferences at the cost of only 5.8% performance decrease against the full-width variant.   ","Our implementation is available as a Python package; just use \"pip install fastfeedforward\"."],"url":"http://arxiv.org/abs/2308.14711v1"}
{"created":"2023-08-28 17:10:12","title":"VideoCutLER: Surprisingly Simple Unsupervised Video Instance Segmentation","abstract":"Existing approaches to unsupervised video instance segmentation typically rely on motion estimates and experience difficulties tracking small or divergent motions. We present VideoCutLER, a simple method for unsupervised multi-instance video segmentation without using motion-based learning signals like optical flow or training on natural videos. Our key insight is that using high-quality pseudo masks and a simple video synthesis method for model training is surprisingly sufficient to enable the resulting video model to effectively segment and track multiple instances across video frames. We show the first competitive unsupervised learning results on the challenging YouTubeVIS-2019 benchmark, achieving 50.7% APvideo^50 , surpassing the previous state-of-the-art by a large margin. VideoCutLER can also serve as a strong pretrained model for supervised video instance segmentation tasks, exceeding DINO by 15.9% on YouTubeVIS-2019 in terms of APvideo.","sentences":["Existing approaches to unsupervised video instance segmentation typically rely on motion estimates and experience difficulties tracking small or divergent motions.","We present VideoCutLER, a simple method for unsupervised multi-instance video segmentation without using motion-based learning signals like optical flow or training on natural videos.","Our key insight is that using high-quality pseudo masks and a simple video synthesis method for model training is surprisingly sufficient to enable the resulting video model to effectively segment and track multiple instances across video frames.","We show the first competitive unsupervised learning results on the challenging YouTubeVIS-2019 benchmark, achieving 50.7% APvideo^50 , surpassing the previous state-of-the-art by a large margin.","VideoCutLER can also serve as a strong pretrained model for supervised video instance segmentation tasks, exceeding DINO by 15.9% on YouTubeVIS-2019 in terms of APvideo."],"url":"http://arxiv.org/abs/2308.14710v1"}
{"created":"2023-08-28 17:08:34","title":"Heterogeneous Drone Small Cells: Optimal 3D Placement for Downlink Power Efficiency and Rate Satisfaction","abstract":"In this paper, we consider a heterogeneous repository of drone-enabled aerial base stations with varying transmit powers that provide downlink wireless coverage for ground users. One particular challenge is optimal selection and deployment of a subset of available drone base stations (DBSs) to satisfy the downlink data rate requirements while minimizing the overall power consumption. In order to address this challenge, we formulate an optimization problem to select the best subset of available DBSs so as to guarantee wireless coverage with some acceptable transmission rate in the downlink path. In addition to the selection of DBSs, we determine their 3D position so as to minimize their overall power consumption. Moreover, assuming that the DBSs operate in the same frequency band, we develop a novel and computationally efficient beamforming method to alleviate the inter-cell interference impact on the downlink. We propose a Kalai-Smorodinsky bargaining solution to determine the optimal beamforming strategy in the downlink path to compensate for the impairment caused by the interference. Simulation results demonstrate the effectiveness of the proposed solution and provide valuable insights into the performance of the heterogeneous drone-based small cell networks.","sentences":["In this paper, we consider a heterogeneous repository of drone-enabled aerial base stations with varying transmit powers that provide downlink wireless coverage for ground users.","One particular challenge is optimal selection and deployment of a subset of available drone base stations (DBSs) to satisfy the downlink data rate requirements while minimizing the overall power consumption.","In order to address this challenge, we formulate an optimization problem to select the best subset of available DBSs so as to guarantee wireless coverage with some acceptable transmission rate in the downlink path.","In addition to the selection of DBSs, we determine their 3D position so as to minimize their overall power consumption.","Moreover, assuming that the DBSs operate in the same frequency band, we develop a novel and computationally efficient beamforming method to alleviate the inter-cell interference impact on the downlink.","We propose a Kalai-Smorodinsky bargaining solution to determine the optimal beamforming strategy in the downlink path to compensate for the impairment caused by the interference.","Simulation results demonstrate the effectiveness of the proposed solution and provide valuable insights into the performance of the heterogeneous drone-based small cell networks."],"url":"http://arxiv.org/abs/2308.14708v1"}
{"created":"2023-08-28 16:58:44","title":"TRIVEA: Transparent Ranking Interpretation using Visual Explanation of Black-Box Algorithmic Rankers","abstract":"Ranking schemes drive many real-world decisions, like, where to study, whom to hire, what to buy, etc. Many of these decisions often come with high consequences. For example, a university can be deemed less prestigious if not featured in a top-k list, and consumers might not even explore products that do not get recommended to buyers. At the heart of most of these decisions are opaque ranking schemes, which dictate the ordering of data entities, but their internal logic is inaccessible or proprietary. Drawing inferences about the ranking differences is like a guessing game to the stakeholders, like, the rankees (i.e., the entities who are ranked, like product companies) and the decision-makers (i.e., who use the rankings, like buyers). In this paper, we aim to enable transparency in ranking interpretation by using algorithmic rankers that learn from available data and by enabling human reasoning about the learned ranking differences using explainable AI (XAI) methods. To realize this aim, we leverage the exploration-explanation paradigm of human-data interaction to let human stakeholders explore subsets and groupings of complex multi-attribute ranking data using visual explanations of model fit and attribute influence on rankings. We realize this explanation paradigm for transparent ranking interpretation in TRIVEA, a visual analytic system that is fueled by: i) visualizations of model fit derived from algorithmic rankers that learn the associations between attributes and rankings from available data and ii) visual explanations derived from XAI methods that help abstract important patterns, like, the relative influence of attributes in different ranking ranges. Using TRIVEA, end users not trained in data science have the agency to transparently reason about the global and local behavior of the rankings without the need to open black-box ranking models and develop confidence in the resulting attribute-based inferences. We demonstrate the efficacy of TRIVEA using multiple usage scenarios and subjective feedback from researchers with diverse domain expertise. Keywords: Visual Analytics, Learning-to-Rank, Explainable ML, Ranking","sentences":["Ranking schemes drive many real-world decisions, like, where to study, whom to hire, what to buy, etc.","Many of these decisions often come with high consequences.","For example, a university can be deemed less prestigious if not featured in a top-k list, and consumers might not even explore products that do not get recommended to buyers.","At the heart of most of these decisions are opaque ranking schemes, which dictate the ordering of data entities, but their internal logic is inaccessible or proprietary.","Drawing inferences about the ranking differences is like a guessing game to the stakeholders, like, the rankees (i.e., the entities who are ranked, like product companies) and the decision-makers (i.e., who use the rankings, like buyers).","In this paper, we aim to enable transparency in ranking interpretation by using algorithmic rankers that learn from available data and by enabling human reasoning about the learned ranking differences using explainable AI (XAI) methods.","To realize this aim, we leverage the exploration-explanation paradigm of human-data interaction to let human stakeholders explore subsets and groupings of complex multi-attribute ranking data using visual explanations of model fit and attribute influence on rankings.","We realize this explanation paradigm for transparent ranking interpretation in TRIVEA, a visual analytic system that is fueled by: i) visualizations of model fit derived from algorithmic rankers that learn the associations between attributes and rankings from available data and ii) visual explanations derived from XAI methods that help abstract important patterns, like, the relative influence of attributes in different ranking ranges.","Using TRIVEA, end users not trained in data science have the agency to transparently reason about the global and local behavior of the rankings without the need to open black-box ranking models and develop confidence in the resulting attribute-based inferences.","We demonstrate the efficacy of TRIVEA using multiple usage scenarios and subjective feedback from researchers with diverse domain expertise.","Keywords: Visual Analytics, Learning-to-Rank, Explainable ML, Ranking"],"url":"http://arxiv.org/abs/2308.14622v1"}
{"created":"2023-08-28 16:39:22","title":"Assessing Trust in Construction AI-Powered Collaborative Robots using Structural Equation Modeling","abstract":"This study aimed to investigate the key technical and psychological factors that impact the architecture, engineering, and construction (AEC) professionals' trust in collaborative robots (cobots) powered by artificial intelligence (AI). The study employed a nationwide survey of 600 AEC industry practitioners to gather in-depth responses and valuable insights into the future opportunities for promoting the adoption, cultivation, and training of a skilled workforce to leverage this technology effectively. A Structural Equation Modeling (SEM) analysis revealed that safety and reliability are significant factors for the adoption of AI-powered cobots in construction. Fear of being replaced resulting from the use of cobots can have a substantial effect on the mental health of the affected workers. A lower error rate in jobs involving cobots, safety measurements, and security of data collected by cobots from jobsites significantly impact reliability, while the transparency of cobots' inner workings can benefit accuracy, robustness, security, privacy, and communication, and results in higher levels of automation, all of which demonstrated as contributors to trust. The study's findings provide critical insights into the perceptions and experiences of AEC professionals towards adoption of cobots in construction and help project teams determine the adoption approach that aligns with the company's goals workers' welfare.","sentences":["This study aimed to investigate the key technical and psychological factors that impact the architecture, engineering, and construction (AEC) professionals' trust in collaborative robots (cobots) powered by artificial intelligence (AI).","The study employed a nationwide survey of 600 AEC industry practitioners to gather in-depth responses and valuable insights into the future opportunities for promoting the adoption, cultivation, and training of a skilled workforce to leverage this technology effectively.","A Structural Equation Modeling (SEM) analysis revealed that safety and reliability are significant factors for the adoption of AI-powered cobots in construction.","Fear of being replaced resulting from the use of cobots can have a substantial effect on the mental health of the affected workers.","A lower error rate in jobs involving cobots, safety measurements, and security of data collected by cobots from jobsites significantly impact reliability, while the transparency of cobots' inner workings can benefit accuracy, robustness, security, privacy, and communication, and results in higher levels of automation, all of which demonstrated as contributors to trust.","The study's findings provide critical insights into the perceptions and experiences of AEC professionals towards adoption of cobots in construction and help project teams determine the adoption approach that aligns with the company's goals workers' welfare."],"url":"http://arxiv.org/abs/2308.14697v1"}
{"created":"2023-08-28 16:38:27","title":"The Effect of Stereotypes on Perceived Competence of Indigenous Software Practitioners: A Professional Photo","abstract":"Context: Potential employers can readily find job candidates' photos through various online sources such as former employers' websites or professional and social networks. The alignment or 'fit' between a candidate and an organization is inferred in online photos through dress style and presentations of self. On the other hand, for candidates from under-represented groups like Indigenous people traditional clothing is an important and lively aspect that allows them to express belonging, enter ceremony, and show resistance.Objective: This exploratory study aims to empirically demonstrate whether traditional clothing in a picture affects the evaluation of candidates' competence for a position like a software developer in which clothing should not be crucial. Method: We plan a quasi-experimental design with both candidates (photo models) and participants (evaluators) from IT companies. It follows a 2 x 2 x 2 design with dress style (traditional / non-traditional clothing), gender and race/ethnicity of the candidates as within-subjects factors. In addition, we will explore the evaluator's gender and experience in hiring as between-subjects factors.","sentences":["Context: Potential employers can readily find job candidates' photos through various online sources such as former employers' websites or professional and social networks.","The alignment or 'fit' between a candidate and an organization is inferred in online photos through dress style and presentations of self.","On the other hand, for candidates from under-represented groups like Indigenous people traditional clothing is an important and lively aspect that allows them to express belonging, enter ceremony, and show resistance.","Objective:","This exploratory study aims to empirically demonstrate whether traditional clothing in a picture affects the evaluation of candidates' competence for a position like a software developer in which clothing should not be crucial.","Method: We plan a quasi-experimental design with both candidates (photo models) and participants (evaluators) from IT companies.","It follows a 2 x 2 x 2 design with dress style (traditional / non-traditional clothing), gender and race/ethnicity of the candidates as within-subjects factors.","In addition, we will explore the evaluator's gender and experience in hiring as between-subjects factors."],"url":"http://arxiv.org/abs/2308.14695v1"}
{"created":"2023-08-28 16:21:52","title":"MELT: Mining Effective Lightweight Transformations from Pull Requests","abstract":"Software developers often struggle to update APIs, leading to manual, time-consuming, and error-prone processes. We introduce MELT, a new approach that generates lightweight API migration rules directly from pull requests in popular library repositories. Our key insight is that pull requests merged into open-source libraries are a rich source of information sufficient to mine API migration rules. By leveraging code examples mined from the library source and automatically generated code examples based on the pull requests, we infer transformation rules in \\comby, a language for structural code search and replace. Since inferred rules from single code examples may be too specific, we propose a generalization procedure to make the rules more applicable to client projects. MELT rules are syntax-driven, interpretable, and easily adaptable. Moreover, unlike previous work, our approach enables rule inference to seamlessly integrate into the library workflow, removing the need to wait for client code migrations. We evaluated MELT on pull requests from four popular libraries, successfully mining 461 migration rules from code examples in pull requests and 114 rules from auto-generated code examples. Our generalization procedure increases the number of matches for mined rules by 9x. We applied these rules to client projects and ran their tests, which led to an overall decrease in the number of warnings and fixing some test cases demonstrating MELT's effectiveness in real-world scenarios.","sentences":["Software developers often struggle to update APIs, leading to manual, time-consuming, and error-prone processes.","We introduce MELT, a new approach that generates lightweight API migration rules directly from pull requests in popular library repositories.","Our key insight is that pull requests merged into open-source libraries are a rich source of information sufficient to mine API migration rules.","By leveraging code examples mined from the library source and automatically generated code examples based on the pull requests, we infer transformation rules in \\comby, a language for structural code search and replace.","Since inferred rules from single code examples may be too specific, we propose a generalization procedure to make the rules more applicable to client projects.","MELT rules are syntax-driven, interpretable, and easily adaptable.","Moreover, unlike previous work, our approach enables rule inference to seamlessly integrate into the library workflow, removing the need to wait for client code migrations.","We evaluated MELT on pull requests from four popular libraries, successfully mining 461 migration rules from code examples in pull requests and 114 rules from auto-generated code examples.","Our generalization procedure increases the number of matches for mined rules by 9x.","We applied these rules to client projects and ran their tests, which led to an overall decrease in the number of warnings and fixing some test cases demonstrating MELT's effectiveness in real-world scenarios."],"url":"http://arxiv.org/abs/2308.14687v1"}
{"created":"2023-08-28 16:21:51","title":"360-Degree Panorama Generation from Few Unregistered NFoV Images","abstract":"360$^\\circ$ panoramas are extensively utilized as environmental light sources in computer graphics. However, capturing a 360$^\\circ$ $\\times$ 180$^\\circ$ panorama poses challenges due to the necessity of specialized and costly equipment, and additional human resources. Prior studies develop various learning-based generative methods to synthesize panoramas from a single Narrow Field-of-View (NFoV) image, but they are limited in alterable input patterns, generation quality, and controllability. To address these issues, we propose a novel pipeline called PanoDiff, which efficiently generates complete 360$^\\circ$ panoramas using one or more unregistered NFoV images captured from arbitrary angles. Our approach has two primary components to overcome the limitations. Firstly, a two-stage angle prediction module to handle various numbers of NFoV inputs. Secondly, a novel latent diffusion-based panorama generation model uses incomplete panorama and text prompts as control signals and utilizes several geometric augmentation schemes to ensure geometric properties in generated panoramas. Experiments show that PanoDiff achieves state-of-the-art panoramic generation quality and high controllability, making it suitable for applications such as content editing.","sentences":["360$^\\circ$ panoramas are extensively utilized as environmental light sources in computer graphics.","However, capturing a 360$^\\circ$ $\\times$ 180$^\\circ$ panorama poses challenges due to the necessity of specialized and costly equipment, and additional human resources.","Prior studies develop various learning-based generative methods to synthesize panoramas from a single Narrow Field-of-View (NFoV) image, but they are limited in alterable input patterns, generation quality, and controllability.","To address these issues, we propose a novel pipeline called PanoDiff, which efficiently generates complete 360$^\\circ$ panoramas using one or more unregistered NFoV images captured from arbitrary angles.","Our approach has two primary components to overcome the limitations.","Firstly, a two-stage angle prediction module to handle various numbers of NFoV inputs.","Secondly, a novel latent diffusion-based panorama generation model uses incomplete panorama and text prompts as control signals and utilizes several geometric augmentation schemes to ensure geometric properties in generated panoramas.","Experiments show that PanoDiff achieves state-of-the-art panoramic generation quality and high controllability, making it suitable for applications such as content editing."],"url":"http://arxiv.org/abs/2308.14686v1"}
{"created":"2023-08-28 16:18:50","title":"Fine-Tuning Llama 2 Large Language Models for Detecting Online Sexual Predatory Chats and Abusive Texts","abstract":"Detecting online sexual predatory behaviours and abusive language on social media platforms has become a critical area of research due to the growing concerns about online safety, especially for vulnerable populations such as children and adolescents. Researchers have been exploring various techniques and approaches to develop effective detection systems that can identify and mitigate these risks. Recent development of large language models (LLMs) has opened a new opportunity to address this problem more effectively. This paper proposes an approach to detection of online sexual predatory chats and abusive language using the open-source pretrained Llama 2 7B-parameter model, recently released by Meta GenAI. We fine-tune the LLM using datasets with different sizes, imbalance degrees, and languages (i.e., English, Roman Urdu and Urdu). Based on the power of LLMs, our approach is generic and automated without a manual search for a synergy between feature extraction and classifier design steps like conventional methods in this domain. Experimental results show a strong performance of the proposed approach, which performs proficiently and consistently across three distinct datasets with five sets of experiments. This study's outcomes indicate that the proposed method can be implemented in real-world applications (even with non-English languages) for flagging sexual predators, offensive or toxic content, hate speech, and discriminatory language in online discussions and comments to maintain respectful internet or digital communities. Furthermore, it can be employed for solving text classification problems with other potential applications such as sentiment analysis, spam and phishing detection, sorting legal documents, fake news detection, language identification, user intent recognition, text-based product categorization, medical record analysis, and resume screening.","sentences":["Detecting online sexual predatory behaviours and abusive language on social media platforms has become a critical area of research due to the growing concerns about online safety, especially for vulnerable populations such as children and adolescents.","Researchers have been exploring various techniques and approaches to develop effective detection systems that can identify and mitigate these risks.","Recent development of large language models (LLMs) has opened a new opportunity to address this problem more effectively.","This paper proposes an approach to detection of online sexual predatory chats and abusive language using the open-source pretrained Llama 2 7B-parameter model, recently released by Meta GenAI.","We fine-tune the LLM using datasets with different sizes, imbalance degrees, and languages (i.e., English, Roman Urdu and Urdu).","Based on the power of LLMs, our approach is generic and automated without a manual search for a synergy between feature extraction and classifier design steps like conventional methods in this domain.","Experimental results show a strong performance of the proposed approach, which performs proficiently and consistently across three distinct datasets with five sets of experiments.","This study's outcomes indicate that the proposed method can be implemented in real-world applications (even with non-English languages) for flagging sexual predators, offensive or toxic content, hate speech, and discriminatory language in online discussions and comments to maintain respectful internet or digital communities.","Furthermore, it can be employed for solving text classification problems with other potential applications such as sentiment analysis, spam and phishing detection, sorting legal documents, fake news detection, language identification, user intent recognition, text-based product categorization, medical record analysis, and resume screening."],"url":"http://arxiv.org/abs/2308.14683v1"}
{"created":"2023-08-28 16:15:23","title":"Video-Based Hand Pose Estimation for Remote Assessment of Bradykinesia in Parkinson's Disease","abstract":"There is a growing interest in using pose estimation algorithms for video-based assessment of Bradykinesia in Parkinson's Disease (PD) to facilitate remote disease assessment and monitoring. However, the accuracy of pose estimation algorithms in videos from video streaming services during Telehealth appointments has not been studied. In this study, we used seven off-the-shelf hand pose estimation models to estimate the movement of the thumb and index fingers in videos of the finger-tapping (FT) test recorded from Healthy Controls (HC) and participants with PD and under two different conditions: streaming (videos recorded during a live Zoom meeting) and on-device (videos recorded locally with high-quality cameras). The accuracy and reliability of the models were estimated by comparing the models' output with manual results. Three of the seven models demonstrated good accuracy for on-device recordings, and the accuracy decreased significantly for streaming recordings. We observed a negative correlation between movement speed and the model's accuracy for the streaming recordings. Additionally, we evaluated the reliability of ten movement features related to bradykinesia extracted from video recordings of PD patients performing the FT test. While most of the features demonstrated excellent reliability for on-device recordings, most of the features demonstrated poor to moderate reliability for streaming recordings. Our findings highlight the limitations of pose estimation algorithms when applied to video recordings obtained during Telehealth visits, and demonstrate that on-device recordings can be used for automatic video-assessment of bradykinesia in PD.","sentences":["There is a growing interest in using pose estimation algorithms for video-based assessment of Bradykinesia in Parkinson's Disease (PD) to facilitate remote disease assessment and monitoring.","However, the accuracy of pose estimation algorithms in videos from video streaming services during Telehealth appointments has not been studied.","In this study, we used seven off-the-shelf hand pose estimation models to estimate the movement of the thumb and index fingers in videos of the finger-tapping (FT) test recorded from Healthy Controls (HC) and participants with PD and under two different conditions: streaming (videos recorded during a live Zoom meeting) and on-device (videos recorded locally with high-quality cameras).","The accuracy and reliability of the models were estimated by comparing the models' output with manual results.","Three of the seven models demonstrated good accuracy for on-device recordings, and the accuracy decreased significantly for streaming recordings.","We observed a negative correlation between movement speed and the model's accuracy for the streaming recordings.","Additionally, we evaluated the reliability of ten movement features related to bradykinesia extracted from video recordings of PD patients performing the FT test.","While most of the features demonstrated excellent reliability for on-device recordings, most of the features demonstrated poor to moderate reliability for streaming recordings.","Our findings highlight the limitations of pose estimation algorithms when applied to video recordings obtained during Telehealth visits, and demonstrate that on-device recordings can be used for automatic video-assessment of bradykinesia in PD."],"url":"http://arxiv.org/abs/2308.14679v1"}
{"created":"2023-08-28 15:55:57","title":"Symmetric Models for Visual Force Policy Learning","abstract":"While it is generally acknowledged that force feedback is beneficial to robotic control, applications of policy learning to robotic manipulation typically only leverage visual feedback. Recently, symmetric neural models have been used to significantly improve the sample efficiency and performance of policy learning across a variety of robotic manipulation domains. This paper explores an application of symmetric policy learning to visual-force problems. We present Symmetric Visual Force Learning (SVFL), a novel method for robotic control which leverages visual and force feedback. We demonstrate that SVFL can significantly outperform state of the art baselines for visual force learning and report several interesting empirical findings related to the utility of learning force feedback control policies in both general manipulation tasks and scenarios with low visual acuity.","sentences":["While it is generally acknowledged that force feedback is beneficial to robotic control, applications of policy learning to robotic manipulation typically only leverage visual feedback.","Recently, symmetric neural models have been used to significantly improve the sample efficiency and performance of policy learning across a variety of robotic manipulation domains.","This paper explores an application of symmetric policy learning to visual-force problems.","We present Symmetric Visual Force Learning (SVFL), a novel method for robotic control which leverages visual and force feedback.","We demonstrate that SVFL can significantly outperform state of the art baselines for visual force learning and report several interesting empirical findings related to the utility of learning force feedback control policies in both general manipulation tasks and scenarios with low visual acuity."],"url":"http://arxiv.org/abs/2308.14670v1"}
{"created":"2023-08-28 15:54:48","title":"ANER: Arabic and Arabizi Named Entity Recognition using Transformer-Based Approach","abstract":"One of the main tasks of Natural Language Processing (NLP), is Named Entity Recognition (NER). It is used in many applications and also can be used as an intermediate step for other tasks. We present ANER, a web-based named entity recognizer for the Arabic, and Arabizi languages. The model is built upon BERT, which is a transformer-based encoder. It can recognize 50 different entity classes, covering various fields. We trained our model on the WikiFANE\\_Gold dataset which consists of Wikipedia articles. We achieved an F1 score of 88.7\\%, which beats CAMeL Tools' F1 score of 83\\% on the ANERcorp dataset, which has only 4 classes. We also got an F1 score of 77.7\\% on the NewsFANE\\_Gold dataset which contains out-of-domain data from News articles. The system is deployed on a user-friendly web interface that accepts users' inputs in Arabic, or Arabizi. It allows users to explore the entities in the text by highlighting them. It can also direct users to get information about entities through Wikipedia directly. We added the ability to do NER using our model, or CAMeL Tools' model through our website. ANER is publicly accessible at \\url{http://www.aner.online}. We also deployed our model on HuggingFace at https://huggingface.co/boda/ANER, to allow developers to test and use it.","sentences":["One of the main tasks of Natural Language Processing (NLP), is Named Entity Recognition (NER).","It is used in many applications and also can be used as an intermediate step for other tasks.","We present ANER, a web-based named entity recognizer for the Arabic, and Arabizi languages.","The model is built upon BERT, which is a transformer-based encoder.","It can recognize 50 different entity classes, covering various fields.","We trained our model on the WikiFANE\\_Gold dataset which consists of Wikipedia articles.","We achieved an F1 score of 88.7\\%, which beats CAMeL Tools' F1 score of 83\\% on the ANERcorp dataset, which has only 4 classes.","We also got an F1 score of 77.7\\% on the NewsFANE\\_Gold dataset which contains out-of-domain data from News articles.","The system is deployed on a user-friendly web interface that accepts users' inputs in Arabic, or Arabizi.","It allows users to explore the entities in the text by highlighting them.","It can also direct users to get information about entities through Wikipedia directly.","We added the ability to do NER using our model, or CAMeL Tools' model through our website.","ANER is publicly accessible at \\url{http://www.aner.online}.","We also deployed our model on HuggingFace at https://huggingface.co/boda/ANER, to allow developers to test and use it."],"url":"http://arxiv.org/abs/2308.14669v1"}
{"created":"2023-08-28 15:54:14","title":"Neural Network-Based Histologic Remission Prediction In Ulcerative Colitis","abstract":"BACKGROUND & AIMS: Histological remission (HR) is advocated and considered as a new therapeutic target in ulcerative colitis (UC). Diagnosis of histologic remission currently relies on biopsy; during this process, patients are at risk for bleeding, infection, and post-biopsy fibrosis. In addition, histologic response scoring is complex and time-consuming, and there is heterogeneity among pathologists. Endocytoscopy (EC) is a novel ultra-high magnification endoscopic technique that can provide excellent in vivo assessment of glands. Based on the EC technique, we propose a neural network model that can assess histological disease activity in UC using EC images to address the above issues. The experiment results demonstrate that the proposed method can assist patients in precise treatment and prognostic assessment.   METHODS: We construct a neural network model for UC evaluation. A total of 5105 images of 154 intestinal segments from 87 patients undergoing EC treatment at a center in China between March 2022 and March 2023 are scored according to the Geboes score. Subsequently, 103 intestinal segments are used as the training set, 16 intestinal segments are used as the validation set for neural network training, and the remaining 35 intestinal segments are used as the test set to measure the model performance together with the validation set.   RESULTS: By treating HR as a negative category and histologic activity as a positive category, the proposed neural network model can achieve an accuracy of 0.9, a specificity of 0.95, a sensitivity of 0.75, and an area under the curve (AUC) of 0.81.   CONCLUSION: We develop a specific neural network model that can distinguish histologic remission/activity in EC images of UC, which helps to accelerate clinical histological diagnosis.   keywords: ulcerative colitis; Endocytoscopy; Geboes score; neural network.","sentences":["BACKGROUND & AIMS:","Histological remission (HR) is advocated and considered as a new therapeutic target in ulcerative colitis (UC).","Diagnosis of histologic remission currently relies on biopsy; during this process, patients are at risk for bleeding, infection, and post-biopsy fibrosis.","In addition, histologic response scoring is complex and time-consuming, and there is heterogeneity among pathologists.","Endocytoscopy (EC) is a novel ultra-high magnification endoscopic technique that can provide excellent in vivo assessment of glands.","Based on the EC technique, we propose a neural network model that can assess histological disease activity in UC using EC images to address the above issues.","The experiment results demonstrate that the proposed method can assist patients in precise treatment and prognostic assessment.   ","METHODS:","We construct a neural network model for UC evaluation.","A total of 5105 images of 154 intestinal segments from 87 patients undergoing EC treatment at a center in China between March 2022 and March 2023 are scored according to the Geboes score.","Subsequently, 103 intestinal segments are used as the training set, 16 intestinal segments are used as the validation set for neural network training, and the remaining 35 intestinal segments are used as the test set to measure the model performance together with the validation set.   ","RESULTS:","By treating HR as a negative category and histologic activity as a positive category, the proposed neural network model can achieve an accuracy of 0.9, a specificity of 0.95, a sensitivity of 0.75, and an area under the curve (AUC) of 0.81.   ","CONCLUSION:","We develop a specific neural network model that can distinguish histologic remission/activity in EC images of UC, which helps to accelerate clinical histological diagnosis.   ","keywords: ulcerative colitis; Endocytoscopy; Geboes score; neural network."],"url":"http://arxiv.org/abs/2308.14667v1"}
{"created":"2023-08-28 15:52:00","title":"Active Pose Refinement for Textureless Shiny Objects using the Structured Light Camera","abstract":"6D pose estimation of textureless shiny objects has become an essential problem in many robotic applications. Many pose estimators require high-quality depth data, often measured by structured light cameras. However, when objects have shiny surfaces (e.g., metal parts), these cameras fail to sense complete depths from a single viewpoint due to the specular reflection, resulting in a significant drop in the final pose accuracy. To mitigate this issue, we present a complete active vision framework for 6D object pose refinement and next-best-view prediction. Specifically, we first develop an optimization-based pose refinement module for the structured light camera. Our system then selects the next best camera viewpoint to collect depth measurements by minimizing the predicted uncertainty of the object pose. Compared to previous approaches, we additionally predict measurement uncertainties of future viewpoints by online rendering, which significantly improves the next-best-view prediction performance. We test our approach on the challenging real-world ROBI dataset. The results demonstrate that our pose refinement method outperforms the traditional ICP-based approach when given the same input depth data, and our next-best-view strategy can achieve high object pose accuracy with significantly fewer viewpoints than the heuristic-based policies.","sentences":["6D pose estimation of textureless shiny objects has become an essential problem in many robotic applications.","Many pose estimators require high-quality depth data, often measured by structured light cameras.","However, when objects have shiny surfaces (e.g., metal parts), these cameras fail to sense complete depths from a single viewpoint due to the specular reflection, resulting in a significant drop in the final pose accuracy.","To mitigate this issue, we present a complete active vision framework for 6D object pose refinement and next-best-view prediction.","Specifically, we first develop an optimization-based pose refinement module for the structured light camera.","Our system then selects the next best camera viewpoint to collect depth measurements by minimizing the predicted uncertainty of the object pose.","Compared to previous approaches, we additionally predict measurement uncertainties of future viewpoints by online rendering, which significantly improves the next-best-view prediction performance.","We test our approach on the challenging real-world ROBI dataset.","The results demonstrate that our pose refinement method outperforms the traditional ICP-based approach when given the same input depth data, and our next-best-view strategy can achieve high object pose accuracy with significantly fewer viewpoints than the heuristic-based policies."],"url":"http://arxiv.org/abs/2308.14665v1"}
{"created":"2023-08-28 15:47:40","title":"Formal Modelling and Analysis of a Self-Adaptive Robotic System","abstract":"Self-adaptation is a crucial feature of autonomous systems that must cope with uncertainties in, e.g., their environment and their internal state. Self-adaptive systems are often modelled as two-layered systems with a managed subsystem handling the domain concerns and a managing subsystem implementing the adaptation logic. We consider a case study of a self-adaptive robotic system; more concretely, an autonomous underwater vehicle (AUV) used for pipeline inspection. In this paper, we model and analyse it with the feature-aware probabilistic model checker ProFeat. The functionalities of the AUV are modelled in a feature model, capturing the AUV's variability. This allows us to model the managed subsystem of the AUV as a family of systems, where each family member corresponds to a valid feature configuration of the AUV. The managing subsystem of the AUV is modelled as a control layer capable of dynamically switching between such valid feature configurations, depending both on environmental and internal conditions. We use this model to analyse probabilistic reward and safety properties for the AUV.","sentences":["Self-adaptation is a crucial feature of autonomous systems that must cope with uncertainties in, e.g., their environment and their internal state.","Self-adaptive systems are often modelled as two-layered systems with a managed subsystem handling the domain concerns and a managing subsystem implementing the adaptation logic.","We consider a case study of a self-adaptive robotic system; more concretely, an autonomous underwater vehicle (AUV) used for pipeline inspection.","In this paper, we model and analyse it with the feature-aware probabilistic model checker ProFeat.","The functionalities of the AUV are modelled in a feature model, capturing the AUV's variability.","This allows us to model the managed subsystem of the AUV as a family of systems, where each family member corresponds to a valid feature configuration of the AUV.","The managing subsystem of the AUV is modelled as a control layer capable of dynamically switching between such valid feature configurations, depending both on environmental and internal conditions.","We use this model to analyse probabilistic reward and safety properties for the AUV."],"url":"http://arxiv.org/abs/2308.14663v1"}
{"created":"2023-08-28 15:41:30","title":"RESTORE: Graph Embedding Assessment Through Reconstruction","abstract":"Following the success of Word2Vec embeddings, graph embeddings (GEs) have gained substantial traction. GEs are commonly generated and evaluated extrinsically on downstream applications, but intrinsic evaluations of the original graph properties in terms of topological structure and semantic information have been lacking. Understanding these will help identify the deficiency of the various families of GE methods when vectorizing graphs in terms of preserving the relevant knowledge or learning incorrect knowledge. To address this, we propose RESTORE, a framework for intrinsic GEs assessment through graph reconstruction. We show that reconstructing the original graph from the underlying GEs yields insights into the relative amount of information preserved in a given vector form. We first introduce the graph reconstruction task. We generate GEs from three GE families based on factorization methods, random walks, and deep learning (with representative algorithms from each family) on the CommonSense Knowledge Graph (CSKG). We analyze their effectiveness in preserving the (a) topological structure of node-level graph reconstruction with an increasing number of hops and (b) semantic information on various word semantic and analogy tests. Our evaluations show deep learning-based GE algorithm (SDNE) is overall better at preserving (a) with a mean average precision (mAP) of 0.54 and 0.35 for 2 and 3-hop reconstruction respectively, while the factorization-based algorithm (HOPE) is better at encapsulating (b) with an average Euclidean distance of 0.14, 0.17, and 0.11 for 1, 2, and 3-hop reconstruction respectively. The modest performance of these GEs leaves room for further research avenues on better graph representation learning.","sentences":["Following the success of Word2Vec embeddings, graph embeddings (GEs) have gained substantial traction.","GEs are commonly generated and evaluated extrinsically on downstream applications, but intrinsic evaluations of the original graph properties in terms of topological structure and semantic information have been lacking.","Understanding these will help identify the deficiency of the various families of GE methods when vectorizing graphs in terms of preserving the relevant knowledge or learning incorrect knowledge.","To address this, we propose RESTORE, a framework for intrinsic GEs assessment through graph reconstruction.","We show that reconstructing the original graph from the underlying GEs yields insights into the relative amount of information preserved in a given vector form.","We first introduce the graph reconstruction task.","We generate GEs from three GE families based on factorization methods, random walks, and deep learning (with representative algorithms from each family) on the CommonSense Knowledge Graph (CSKG).","We analyze their effectiveness in preserving the (a) topological structure of node-level graph reconstruction with an increasing number of hops and (b) semantic information on various word semantic and analogy tests.","Our evaluations show deep learning-based GE algorithm (SDNE) is overall better at preserving (a) with a mean average precision (mAP) of 0.54 and 0.35 for 2 and 3-hop reconstruction respectively, while the factorization-based algorithm (HOPE) is better at encapsulating (b) with an average Euclidean distance of 0.14, 0.17, and 0.11 for 1, 2, and 3-hop reconstruction respectively.","The modest performance of these GEs leaves room for further research avenues on better graph representation learning."],"url":"http://arxiv.org/abs/2308.14659v1"}
{"created":"2023-08-28 15:40:50","title":"Adversarial Predictions of Data Distributions Across Federated Internet-of-Things Devices","abstract":"Federated learning (FL) is increasingly becoming the default approach for training machine learning models across decentralized Internet-of-Things (IoT) devices. A key advantage of FL is that no raw data are communicated across the network, providing an immediate layer of privacy. Despite this, recent works have demonstrated that data reconstruction can be done with the locally trained model updates which are communicated across the network. However, many of these works have limitations with regard to how the gradients are computed in backpropagation. In this work, we demonstrate that the model weights shared in FL can expose revealing information about the local data distributions of IoT devices. This leakage could expose sensitive information to malicious actors in a distributed system. We further discuss results which show that injecting noise into model weights is ineffective at preventing data leakage without seriously harming the global model accuracy.","sentences":["Federated learning (FL) is increasingly becoming the default approach for training machine learning models across decentralized Internet-of-Things (IoT) devices.","A key advantage of FL is that no raw data are communicated across the network, providing an immediate layer of privacy.","Despite this, recent works have demonstrated that data reconstruction can be done with the locally trained model updates which are communicated across the network.","However, many of these works have limitations with regard to how the gradients are computed in backpropagation.","In this work, we demonstrate that the model weights shared in FL can expose revealing information about the local data distributions of IoT devices.","This leakage could expose sensitive information to malicious actors in a distributed system.","We further discuss results which show that injecting noise into model weights is ineffective at preventing data leakage without seriously harming the global model accuracy."],"url":"http://arxiv.org/abs/2308.14658v1"}
{"created":"2023-08-28 15:40:31","title":"DeepHealthNet: Adolescent Obesity Prediction System Based on a Deep Learning Framework","abstract":"Childhood and adolescent obesity rates are a global concern because obesity is associated with chronic diseases and long-term health risks. Artificial intelligence technology has emerged as a promising solution to accurately predict obesity rates and provide personalized feedback to adolescents. This study emphasizes the importance of early identification and prevention of obesity-related health issues. Factors such as height, weight, waist circumference, calorie intake, physical activity levels, and other relevant health information need to be considered for developing robust algorithms for obesity rate prediction and delivering personalized feedback. Hence, by collecting health datasets from 321 adolescents, we proposed an adolescent obesity prediction system that provides personalized predictions and assists individuals in making informed health decisions. Our proposed deep learning framework, DeepHealthNet, effectively trains the model using data augmentation techniques, even when daily health data are limited, resulting in improved prediction accuracy (acc: 0.8842). Additionally, the study revealed variations in the prediction of the obesity rate between boys (acc: 0.9320) and girls (acc: 0.9163), allowing the identification of disparities and the determination of the optimal time to provide feedback. The proposed system shows significant potential in effectively addressing childhood and adolescent obesity.","sentences":["Childhood and adolescent obesity rates are a global concern because obesity is associated with chronic diseases and long-term health risks.","Artificial intelligence technology has emerged as a promising solution to accurately predict obesity rates and provide personalized feedback to adolescents.","This study emphasizes the importance of early identification and prevention of obesity-related health issues.","Factors such as height, weight, waist circumference, calorie intake, physical activity levels, and other relevant health information need to be considered for developing robust algorithms for obesity rate prediction and delivering personalized feedback.","Hence, by collecting health datasets from 321 adolescents, we proposed an adolescent obesity prediction system that provides personalized predictions and assists individuals in making informed health decisions.","Our proposed deep learning framework, DeepHealthNet, effectively trains the model using data augmentation techniques, even when daily health data are limited, resulting in improved prediction accuracy (acc: 0.8842).","Additionally, the study revealed variations in the prediction of the obesity rate between boys (acc: 0.9320) and girls (acc: 0.9163), allowing the identification of disparities and the determination of the optimal time to provide feedback.","The proposed system shows significant potential in effectively addressing childhood and adolescent obesity."],"url":"http://arxiv.org/abs/2308.14657v1"}
{"created":"2023-08-28 15:36:33","title":"Joint Multiple Intent Detection and Slot Filling with Supervised Contrastive Learning and Self-Distillation","abstract":"Multiple intent detection and slot filling are two fundamental and crucial tasks in spoken language understanding. Motivated by the fact that the two tasks are closely related, joint models that can detect intents and extract slots simultaneously are preferred to individual models that perform each task independently. The accuracy of a joint model depends heavily on the ability of the model to transfer information between the two tasks so that the result of one task can correct the result of the other. In addition, since a joint model has multiple outputs, how to train the model effectively is also challenging. In this paper, we present a method for multiple intent detection and slot filling by addressing these challenges. First, we propose a bidirectional joint model that explicitly employs intent information to recognize slots and slot features to detect intents. Second, we introduce a novel method for training the proposed joint model using supervised contrastive learning and self-distillation. Experimental results on two benchmark datasets MixATIS and MixSNIPS show that our method outperforms state-of-the-art models in both tasks. The results also demonstrate the contributions of both bidirectional design and the training method to the accuracy improvement. Our source code is available at https://github.com/anhtunguyen98/BiSLU","sentences":["Multiple intent detection and slot filling are two fundamental and crucial tasks in spoken language understanding.","Motivated by the fact that the two tasks are closely related, joint models that can detect intents and extract slots simultaneously are preferred to individual models that perform each task independently.","The accuracy of a joint model depends heavily on the ability of the model to transfer information between the two tasks so that the result of one task can correct the result of the other.","In addition, since a joint model has multiple outputs, how to train the model effectively is also challenging.","In this paper, we present a method for multiple intent detection and slot filling by addressing these challenges.","First, we propose a bidirectional joint model that explicitly employs intent information to recognize slots and slot features to detect intents.","Second, we introduce a novel method for training the proposed joint model using supervised contrastive learning and self-distillation.","Experimental results on two benchmark datasets MixATIS and MixSNIPS show that our method outperforms state-of-the-art models in both tasks.","The results also demonstrate the contributions of both bidirectional design and the training method to the accuracy improvement.","Our source code is available at https://github.com/anhtunguyen98/BiSLU"],"url":"http://arxiv.org/abs/2308.14654v1"}
{"created":"2023-08-28 15:34:43","title":"Learning Visual Tracking and Reaching with Deep Reinforcement Learning on a UR10e Robotic Arm","abstract":"As technology progresses, industrial and scientific robots are increasingly being used in diverse settings. In many cases, however, programming the robot to perform such tasks is technically complex and costly. To maximize the utility of robots in industrial and scientific settings, they require the ability to quickly shift from one task to another. Reinforcement learning algorithms provide the potential to enable robots to learn optimal solutions to complete new tasks without directly reprogramming them. The current state-of-the-art in reinforcement learning, however, generally relies on fast simulations and parallelization to achieve optimal performance. These are often not possible in robotics applications. Thus, a significant amount of research is required to facilitate the efficient and safe, training and deployment of industrial and scientific reinforcement learning robots. This technical report outlines our initial research into the application of deep reinforcement learning on an industrial UR10e robot. The report describes the reinforcement learning environments created to facilitate policy learning with the UR10e, a robotic arm from Universal Robots, and presents our initial results in training deep Q-learning and proximal policy optimization agents on the developed reinforcement learning environments. Our results show that proximal policy optimization learns a better, more stable policy with less data than deep Q-learning. The corresponding code for this work is available at \\url{https://github.com/cbellinger27/bendRL_reacher_tracker}","sentences":["As technology progresses, industrial and scientific robots are increasingly being used in diverse settings.","In many cases, however, programming the robot to perform such tasks is technically complex and costly.","To maximize the utility of robots in industrial and scientific settings, they require the ability to quickly shift from one task to another.","Reinforcement learning algorithms provide the potential to enable robots to learn optimal solutions to complete new tasks without directly reprogramming them.","The current state-of-the-art in reinforcement learning, however, generally relies on fast simulations and parallelization to achieve optimal performance.","These are often not possible in robotics applications.","Thus, a significant amount of research is required to facilitate the efficient and safe, training and deployment of industrial and scientific reinforcement learning robots.","This technical report outlines our initial research into the application of deep reinforcement learning on an industrial UR10e robot.","The report describes the reinforcement learning environments created to facilitate policy learning with the UR10e, a robotic arm from Universal Robots, and presents our initial results in training deep Q-learning and proximal policy optimization agents on the developed reinforcement learning environments.","Our results show that proximal policy optimization learns a better, more stable policy with less data than deep Q-learning.","The corresponding code for this work is available at \\url{https://github.com/cbellinger27/bendRL_reacher_tracker}"],"url":"http://arxiv.org/abs/2308.14652v1"}
{"created":"2023-08-28 15:21:16","title":"Composition in Differential Privacy for General Granularity Notions (Long Version)","abstract":"The composition theorems of differential privacy (DP) allow data curators to combine different algorithms to obtain a new algorithm that continues to satisfy DP. However, new granularity notions (i.e., neighborhood definitions), data domains, and composition settings have appeared in the literature that the classical composition theorems do not cover. For instance, the parallel composition theorem does not apply to general granularity notions. This complicates the opportunity of composing DP mechanisms in new settings and obtaining accurate estimates of the incurred privacy loss after composition.   To overcome these limitations, we study the composability of DP in a general framework and for any kind of data domain or neighborhood definition. We give a general composition theorem in both independent and adaptive versions and we provide analogous composition results for approximate, zero-concentrated, and Gaussian DP. Besides, we study the hypothesis needed to obtain the best composition bounds. Our theorems cover both parallel and sequential composition settings. Importantly, they also cover every setting in between, allowing us to compute the final privacy loss of a composition with greatly improved accuracy.","sentences":["The composition theorems of differential privacy (DP) allow data curators to combine different algorithms to obtain a new algorithm that continues to satisfy DP.","However, new granularity notions (i.e., neighborhood definitions), data domains, and composition settings have appeared in the literature that the classical composition theorems do not cover.","For instance, the parallel composition theorem does not apply to general granularity notions.","This complicates the opportunity of composing DP mechanisms in new settings and obtaining accurate estimates of the incurred privacy loss after composition.   ","To overcome these limitations, we study the composability of DP in a general framework and for any kind of data domain or neighborhood definition.","We give a general composition theorem in both independent and adaptive versions and we provide analogous composition results for approximate, zero-concentrated, and Gaussian DP.","Besides, we study the hypothesis needed to obtain the best composition bounds.","Our theorems cover both parallel and sequential composition settings.","Importantly, they also cover every setting in between, allowing us to compute the final privacy loss of a composition with greatly improved accuracy."],"url":"http://arxiv.org/abs/2308.14649v1"}
{"created":"2023-08-28 15:19:18","title":"Edge Generation Scheduling for DAG Tasks using Deep Reinforcement Learning","abstract":"Directed acyclic graph (DAG) tasks are currently adopted in the real-time domain to model complex applications from the automotive, avionics, and industrial domain that implement their functionalities through chains of intercommunicating tasks. This paper studies the problem of scheduling real-time DAG tasks by presenting a novel schedulability test based on the concept of trivial schedulability. Using this schedulability test, we propose a new DAG scheduling framework (edge generation scheduling -- EGS) that attempts to minimize the DAG width by iteratively generating edges while guaranteeing the deadline constraint. We study how to efficiently solve the problem of generating edges by developing a deep reinforcement learning algorithm combined with a graph representation neural network to learn an efficient edge generation policy for EGS. We evaluate the effectiveness of the proposed algorithm by comparing it with state-of-the-art DAG scheduling heuristics and an optimal mixed-integer linear programming baseline. Experimental results show that the proposed algorithm outperforms the state-of-the-art by requiring fewer processors to schedule the same DAG tasks.","sentences":["Directed acyclic graph (DAG) tasks are currently adopted in the real-time domain to model complex applications from the automotive, avionics, and industrial domain that implement their functionalities through chains of intercommunicating tasks.","This paper studies the problem of scheduling real-time DAG tasks by presenting a novel schedulability test based on the concept of trivial schedulability.","Using this schedulability test, we propose a new DAG scheduling framework (edge generation scheduling -- EGS) that attempts to minimize the DAG width by iteratively generating edges while guaranteeing the deadline constraint.","We study how to efficiently solve the problem of generating edges by developing a deep reinforcement learning algorithm combined with a graph representation neural network to learn an efficient edge generation policy for EGS.","We evaluate the effectiveness of the proposed algorithm by comparing it with state-of-the-art DAG scheduling heuristics and an optimal mixed-integer linear programming baseline.","Experimental results show that the proposed algorithm outperforms the state-of-the-art by requiring fewer processors to schedule the same DAG tasks."],"url":"http://arxiv.org/abs/2308.14647v1"}
{"created":"2023-08-28 15:16:43","title":"On the Achievable Rate of MIMO Narrowband PLC with Spatio-Temporal Correlated Noise","abstract":"Narrowband power line communication (NB-PLC) systems are an attractive solution for supporting current and future smart grids. A technology proposed to enhance data rate in NB-PLC is multiple-input multiple-output (MIMO) transmission over multiple power line phases. To achieve reliable communication over MIMO NB-PLC, a key challenge is to take into account and mitigate the effects of temporally and spatially correlated cyclostationary noise. Noise samples in a cycle can be divided into three classes with different distributions, i.e. Gaussian, moderate impulsive, and strong impulsive. However, in this paper we first show that the impulsive classes in their turn can be divided into sub-classes with normal distributions and, after deriving the theoretical capacity, two noise sample sets with such characteristics are used to evaluate achievable information rates: one sample set is the measured noise in laboratory and the other is produced through MIMO frequency-shift (FRESH) filtering. The achievable information rates are attained by means of a spatio-temporal whitening of the portions of the cyclostationary correlated noise samples that belong to the Gaussian sub-classes. The proposed approach can be useful to design the optimal receiver in terms of bit allocation using waterfilling algorithm and to adapt modulation order.","sentences":["Narrowband power line communication (NB-PLC) systems are an attractive solution for supporting current and future smart grids.","A technology proposed to enhance data rate in NB-PLC is multiple-input multiple-output (MIMO) transmission over multiple power line phases.","To achieve reliable communication over MIMO NB-PLC, a key challenge is to take into account and mitigate the effects of temporally and spatially correlated cyclostationary noise.","Noise samples in a cycle can be divided into three classes with different distributions, i.e. Gaussian, moderate impulsive, and strong impulsive.","However, in this paper we first show that the impulsive classes in their turn can be divided into sub-classes with normal distributions and, after deriving the theoretical capacity, two noise sample sets with such characteristics are used to evaluate achievable information rates: one sample set is the measured noise in laboratory and the other is produced through MIMO frequency-shift (FRESH) filtering.","The achievable information rates are attained by means of a spatio-temporal whitening of the portions of the cyclostationary correlated noise samples that belong to the Gaussian sub-classes.","The proposed approach can be useful to design the optimal receiver in terms of bit allocation using waterfilling algorithm and to adapt modulation order."],"url":"http://arxiv.org/abs/2308.14645v1"}
{"created":"2023-08-28 15:16:35","title":"Human Comfortability Index Estimation in Industrial Human-Robot Collaboration Task","abstract":"Fluent human-robot collaboration requires a robot teammate to understand, learn, and adapt to the human's psycho-physiological state. Such collaborations require a computing system that monitors human physiological signals during human-robot collaboration (HRC) to quantitatively estimate a human's level of comfort, which we have termed in this research as comfortability index (CI) and uncomfortability index (unCI). Subjective metrics (surprise, anxiety, boredom, calmness, and comfortability) and physiological signals were collected during a human-robot collaboration experiment that varied robot behavior. The emotion circumplex model is adapted to calculate the CI from the participant's quantitative data as well as physiological data. To estimate CI/unCI from physiological signals, time features were extracted from electrocardiogram (ECG), galvanic skin response (GSR), and pupillometry signals. In this research, we successfully adapt the circumplex model to find the location (axis) of 'comfortability' and 'uncomfortability' on the circumplex model, and its location match with the closest emotions on the circumplex model. Finally, the study showed that the proposed approach can estimate human comfortability/uncomfortability from physiological signals.","sentences":["Fluent human-robot collaboration requires a robot teammate to understand, learn, and adapt to the human's psycho-physiological state.","Such collaborations require a computing system that monitors human physiological signals during human-robot collaboration (HRC) to quantitatively estimate a human's level of comfort, which we have termed in this research as comfortability index (CI) and uncomfortability index (unCI).","Subjective metrics (surprise, anxiety, boredom, calmness, and comfortability) and physiological signals were collected during a human-robot collaboration experiment that varied robot behavior.","The emotion circumplex model is adapted to calculate the CI from the participant's quantitative data as well as physiological data.","To estimate CI/unCI from physiological signals, time features were extracted from electrocardiogram (ECG), galvanic skin response (GSR), and pupillometry signals.","In this research, we successfully adapt the circumplex model to find the location (axis) of 'comfortability' and 'uncomfortability' on the circumplex model, and its location match with the closest emotions on the circumplex model.","Finally, the study showed that the proposed approach can estimate human comfortability/uncomfortability from physiological signals."],"url":"http://arxiv.org/abs/2308.14644v1"}
{"created":"2023-08-28 15:16:09","title":"Rate-Optimal Policy Optimization for Linear Markov Decision Processes","abstract":"We study regret minimization in online episodic linear Markov Decision Processes, and obtain rate-optimal $\\widetilde O (\\sqrt K)$ regret where $K$ denotes the number of episodes. Our work is the first to establish the optimal (w.r.t.~$K$) rate of convergence in the stochastic setting with bandit feedback using a policy optimization based approach, and the first to establish the optimal (w.r.t.~$K$) rate in the adversarial setup with full information feedback, for which no algorithm with an optimal rate guarantee is currently known.","sentences":["We study regret minimization in online episodic linear Markov Decision Processes, and obtain rate-optimal $\\widetilde O (\\sqrt K)$ regret where $K$ denotes the number of episodes.","Our work is the first to establish the optimal (w.r.t.~$K$) rate of convergence in the stochastic setting with bandit feedback using a policy optimization based approach, and the first to establish the optimal (w.r.t.~$K$) rate in the adversarial setup with full information feedback, for which no algorithm with an optimal rate guarantee is currently known."],"url":"http://arxiv.org/abs/2308.14642v1"}
{"created":"2023-08-28 15:12:34","title":"Challenges of GPT-3-based Conversational Agents for Healthca","abstract":"The potential to provide patients with faster information access while allowing medical specialists to concentrate on critical tasks makes medical domain dialog agents appealing. However, the integration of large-language models (LLMs) into these agents presents certain limitations that may result in serious consequences. This paper investigates the challenges and risks of using GPT-3-based models for medical question-answering (MedQA). We perform several evaluations contextualized in terms of standard medical principles. We provide a procedure for manually designing patient queries to stress-test high-risk limitations of LLMs in MedQA systems. Our analysis reveals that LLMs fail to respond adequately to these queries, generating erroneous medical information, unsafe recommendations, and content that may be considered offensive.","sentences":["The potential to provide patients with faster information access while allowing medical specialists to concentrate on critical tasks makes medical domain dialog agents appealing.","However, the integration of large-language models (LLMs) into these agents presents certain limitations that may result in serious consequences.","This paper investigates the challenges and risks of using GPT-3-based models for medical question-answering (MedQA).","We perform several evaluations contextualized in terms of standard medical principles.","We provide a procedure for manually designing patient queries to stress-test high-risk limitations of LLMs in MedQA systems.","Our analysis reveals that LLMs fail to respond adequately to these queries, generating erroneous medical information, unsafe recommendations, and content that may be considered offensive."],"url":"http://arxiv.org/abs/2308.14641v1"}
{"created":"2023-08-28 15:07:21","title":"Joint Active User Detection, Channel Estimation, and Data Detection for Massive Grant-Free Transmission in Cell-Free Systems","abstract":"Cell-free communication has the potential to significantly improve grant-free transmission in massive machine-type communication, wherein multiple access points jointly serve a large number of user equipments to improve coverage and spectral efficiency. In this paper, we propose a novel framework for joint active user detection (AUD), channel estimation (CE), and data detection (DD) for massive grant-free transmission in cell-free systems. We formulate an optimization problem for joint AUD, CE, and DD by considering both the sparsity of the data matrix, which arises from intermittent user activity, and the sparsity of the effective channel matrix, which arises from intermittent user activity and large-scale fading. We approximately solve this optimization problem with a box-constrained forward-backward splitting algorithm, which significantly improves AUD, CE, and DD performance. We demonstrate the effectiveness of the proposed framework through simulation experiments.","sentences":["Cell-free communication has the potential to significantly improve grant-free transmission in massive machine-type communication, wherein multiple access points jointly serve a large number of user equipments to improve coverage and spectral efficiency.","In this paper, we propose a novel framework for joint active user detection (AUD), channel estimation (CE), and data detection (DD) for massive grant-free transmission in cell-free systems.","We formulate an optimization problem for joint AUD, CE, and DD by considering both the sparsity of the data matrix, which arises from intermittent user activity, and the sparsity of the effective channel matrix, which arises from intermittent user activity and large-scale fading.","We approximately solve this optimization problem with a box-constrained forward-backward splitting algorithm, which significantly improves AUD, CE, and DD performance.","We demonstrate the effectiveness of the proposed framework through simulation experiments."],"url":"http://arxiv.org/abs/2308.14637v1"}
{"created":"2023-08-28 15:04:32","title":"Towards Standardized Disturbance Rejection Testing of Legged Robot Locomotion with Linear Impactor: A Preliminary Study, Observations, and Implications","abstract":"Dynamic locomotion in legged robots is close to industrial collaboration, but a lack of standardized testing obstructs commercialization. The issues are not merely political, theoretical, or algorithmic but also physical, indicating limited studies and comprehension regarding standard testing infrastructure and equipment. For decades, the approaches we have been testing legged robots were rarely standardizable with hand-pushing, foot-kicking, rope-dragging, stick-poking, and ball-swinging. This paper aims to bridge the gap by proposing the use of the linear impactor, a well-established tool in other standardized testing disciplines, to serve as an adaptive, repeatable, and fair disturbance rejection testing equipment for legged robots. A pneumatic linear impactor is also adopted for the case study involving the humanoid robot Digit. Three locomotion controllers are examined, including a commercial one, using a walking-in-place task against frontal impacts. The statistically best controller was able to withstand the impact momentum (26.376 kg$\\cdot$m/s) on par with a reported average effective momentum from straight punches by Olympic boxers (26.506 kg$\\cdot$m/s). Moreover, the case study highlights other anti-intuitive observations, demonstrations, and implications that, to the best of the authors' knowledge, are first-of-its-kind revealed in real-world testing of legged robots.","sentences":["Dynamic locomotion in legged robots is close to industrial collaboration, but a lack of standardized testing obstructs commercialization.","The issues are not merely political, theoretical, or algorithmic but also physical, indicating limited studies and comprehension regarding standard testing infrastructure and equipment.","For decades, the approaches we have been testing legged robots were rarely standardizable with hand-pushing, foot-kicking, rope-dragging, stick-poking, and ball-swinging.","This paper aims to bridge the gap by proposing the use of the linear impactor, a well-established tool in other standardized testing disciplines, to serve as an adaptive, repeatable, and fair disturbance rejection testing equipment for legged robots.","A pneumatic linear impactor is also adopted for the case study involving the humanoid robot Digit.","Three locomotion controllers are examined, including a commercial one, using a walking-in-place task against frontal impacts.","The statistically best controller was able to withstand the impact momentum (26.376 kg$\\cdot$m/s) on par with a reported average effective momentum from straight punches by Olympic boxers (26.506 kg$\\cdot$m/s).","Moreover, the case study highlights other anti-intuitive observations, demonstrations, and implications that, to the best of the authors' knowledge, are first-of-its-kind revealed in real-world testing of legged robots."],"url":"http://arxiv.org/abs/2308.14636v1"}
{"created":"2023-08-28 15:04:16","title":"Breaking the Bank with ChatGPT: Few-Shot Text Classification for Finance","abstract":"We propose the use of conversational GPT models for easy and quick few-shot text classification in the financial domain using the Banking77 dataset. Our approach involves in-context learning with GPT-3.5 and GPT-4, which minimizes the technical expertise required and eliminates the need for expensive GPU computing while yielding quick and accurate results. Additionally, we fine-tune other pre-trained, masked language models with SetFit, a recent contrastive learning technique, to achieve state-of-the-art results both in full-data and few-shot settings. Our findings show that querying GPT-3.5 and GPT-4 can outperform fine-tuned, non-generative models even with fewer examples. However, subscription fees associated with these solutions may be considered costly for small organizations. Lastly, we find that generative models perform better on the given task when shown representative samples selected by a human expert rather than when shown random ones. We conclude that a) our proposed methods offer a practical solution for few-shot tasks in datasets with limited label availability, and b) our state-of-the-art results can inspire future work in the area.","sentences":["We propose the use of conversational GPT models for easy and quick few-shot text classification in the financial domain using the Banking77 dataset.","Our approach involves in-context learning with GPT-3.5 and GPT-4, which minimizes the technical expertise required and eliminates the need for expensive GPU computing while yielding quick and accurate results.","Additionally, we fine-tune other pre-trained, masked language models with SetFit, a recent contrastive learning technique, to achieve state-of-the-art results both in full-data and few-shot settings.","Our findings show that querying GPT-3.5 and GPT-4 can outperform fine-tuned, non-generative models even with fewer examples.","However, subscription fees associated with these solutions may be considered costly for small organizations.","Lastly, we find that generative models perform better on the given task when shown representative samples selected by a human expert rather than when shown random ones.","We conclude that a) our proposed methods offer a practical solution for few-shot tasks in datasets with limited label availability, and b) our state-of-the-art results can inspire future work in the area."],"url":"http://arxiv.org/abs/2308.14634v1"}
{"created":"2023-08-28 14:57:29","title":"Comparing AutoML and Deep Learning Methods for Condition Monitoring using Realistic Validation Scenarios","abstract":"This study extensively compares conventional machine learning methods and deep learning for condition monitoring tasks using an AutoML toolbox. The experiments reveal consistent high accuracy in random K-fold cross-validation scenarios across all tested models. However, when employing leave-one-group-out (LOGO) cross-validation on the same datasets, no clear winner emerges, indicating the presence of domain shift in real-world scenarios. Additionally, the study assesses the scalability and interpretability of conventional methods and neural networks. Conventional methods offer explainability with their modular structure aiding feature identification. In contrast, neural networks require specialized interpretation techniques like occlusion maps to visualize important regions in the input data. Finally, the paper highlights the significance of feature selection, particularly in condition monitoring tasks with limited class variations. Low-complexity models prove sufficient for such tasks, as only a few features from the input signal are typically needed. In summary, these findings offer crucial insights into the strengths and limitations of various approaches, providing valuable benchmarks and identifying the most suitable methods for condition monitoring applications, thereby enhancing their applicability in real-world scenarios.","sentences":["This study extensively compares conventional machine learning methods and deep learning for condition monitoring tasks using an AutoML toolbox.","The experiments reveal consistent high accuracy in random K-fold cross-validation scenarios across all tested models.","However, when employing leave-one-group-out (LOGO) cross-validation on the same datasets, no clear winner emerges, indicating the presence of domain shift in real-world scenarios.","Additionally, the study assesses the scalability and interpretability of conventional methods and neural networks.","Conventional methods offer explainability with their modular structure aiding feature identification.","In contrast, neural networks require specialized interpretation techniques like occlusion maps to visualize important regions in the input data.","Finally, the paper highlights the significance of feature selection, particularly in condition monitoring tasks with limited class variations.","Low-complexity models prove sufficient for such tasks, as only a few features from the input signal are typically needed.","In summary, these findings offer crucial insights into the strengths and limitations of various approaches, providing valuable benchmarks and identifying the most suitable methods for condition monitoring applications, thereby enhancing their applicability in real-world scenarios."],"url":"http://arxiv.org/abs/2308.14632v1"}
{"created":"2023-08-28 14:51:43","title":"Zip to Zip-it: Compression to Achieve Local Differential Privacy","abstract":"Local differential privacy techniques for numerical data typically transform a dataset to ensure a bound on the likelihood that, given a query, a malicious user could infer information on the original samples. Queries are often solely based on users and their requirements, limiting the design of the perturbation to processes that, while privatizing the results, do not jeopardize their usefulness. In this paper, we propose a privatization technique called Zeal, where perturbator and aggregator are designed as a unit, resulting in a locally differentially private mechanism that, by-design, improves the compressibility of the perturbed dataset compared to the original, saves on transmitted bits for data collection and protects against a privacy vulnerabilities due to floating point arithmetic that affect other state-of-the-art schemes. We prove that the utility error on querying the average is invariant to the bias introduced by Zeal in a wide range of conditions, and that under the same circumstances, Zeal also guarantee protection against the aforementioned vulnerability. Our numerical results show up to 94% improvements in compression and up to 95% more efficient data transmissions, while keeping utility errors within 2%.","sentences":["Local differential privacy techniques for numerical data typically transform a dataset to ensure a bound on the likelihood that, given a query, a malicious user could infer information on the original samples.","Queries are often solely based on users and their requirements, limiting the design of the perturbation to processes that, while privatizing the results, do not jeopardize their usefulness.","In this paper, we propose a privatization technique called Zeal, where perturbator and aggregator are designed as a unit, resulting in a locally differentially private mechanism that, by-design, improves the compressibility of the perturbed dataset compared to the original, saves on transmitted bits for data collection and protects against a privacy vulnerabilities due to floating point arithmetic that affect other state-of-the-art schemes.","We prove that the utility error on querying the average is invariant to the bias introduced by Zeal in a wide range of conditions, and that under the same circumstances, Zeal also guarantee protection against the aforementioned vulnerability.","Our numerical results show up to 94% improvements in compression and up to 95% more efficient data transmissions, while keeping utility errors within 2%."],"url":"http://arxiv.org/abs/2308.14627v1"}
{"created":"2023-08-28 14:47:45","title":"Accelerating package expansion in Rust through development of a semantic versioning tool","abstract":"In many programming languages there exist countless nuances, making developers accidentally release new versions of their packages that are not backwards-compatible. Such releases can directly impact projects which are using their packages, causing bugs or even compilation errors when using the latest version. One of the affected languages is Rust, which also lacks (itself) a built-in mechanism for enforcing semantic versioning.   The aim of this thesis is to describe the development of a tool for Rust programmers to reduce the chances of publishing a new version of the code that violates semantic versioning.   There are already on-going plans to bundle this tool into the language's standard development toolchain. It would make it commonly used and therefore help users to safely get bug fixes, security patches and new functionality, without worrying about their app being broken by a dependency change.","sentences":["In many programming languages there exist countless nuances, making developers accidentally release new versions of their packages that are not backwards-compatible.","Such releases can directly impact projects which are using their packages, causing bugs or even compilation errors when using the latest version.","One of the affected languages is Rust, which also lacks (itself) a built-in mechanism for enforcing semantic versioning.   ","The aim of this thesis is to describe the development of a tool for Rust programmers to reduce the chances of publishing a new version of the code that violates semantic versioning.   ","There are already on-going plans to bundle this tool into the language's standard development toolchain.","It would make it commonly used and therefore help users to safely get bug fixes, security patches and new functionality, without worrying about their app being broken by a dependency change."],"url":"http://arxiv.org/abs/2308.14623v1"}
{"created":"2023-08-28 14:43:36","title":"Compositional Semantic Mix for Domain Adaptation in Point Cloud Segmentation","abstract":"Deep-learning models for 3D point cloud semantic segmentation exhibit limited generalization capabilities when trained and tested on data captured with different sensors or in varying environments due to domain shift. Domain adaptation methods can be employed to mitigate this domain shift, for instance, by simulating sensor noise, developing domain-agnostic generators, or training point cloud completion networks. Often, these methods are tailored for range view maps or necessitate multi-modal input. In contrast, domain adaptation in the image domain can be executed through sample mixing, which emphasizes input data manipulation rather than employing distinct adaptation modules. In this study, we introduce compositional semantic mixing for point cloud domain adaptation, representing the first unsupervised domain adaptation technique for point cloud segmentation based on semantic and geometric sample mixing. We present a two-branch symmetric network architecture capable of concurrently processing point clouds from a source domain (e.g. synthetic) and point clouds from a target domain (e.g. real-world). Each branch operates within one domain by integrating selected data fragments from the other domain and utilizing semantic information derived from source labels and target (pseudo) labels. Additionally, our method can leverage a limited number of human point-level annotations (semi-supervised) to further enhance performance. We assess our approach in both synthetic-to-real and real-to-real scenarios using LiDAR datasets and demonstrate that it significantly outperforms state-of-the-art methods in both unsupervised and semi-supervised settings.","sentences":["Deep-learning models for 3D point cloud semantic segmentation exhibit limited generalization capabilities when trained and tested on data captured with different sensors or in varying environments due to domain shift.","Domain adaptation methods can be employed to mitigate this domain shift, for instance, by simulating sensor noise, developing domain-agnostic generators, or training point cloud completion networks.","Often, these methods are tailored for range view maps or necessitate multi-modal input.","In contrast, domain adaptation in the image domain can be executed through sample mixing, which emphasizes input data manipulation rather than employing distinct adaptation modules.","In this study, we introduce compositional semantic mixing for point cloud domain adaptation, representing the first unsupervised domain adaptation technique for point cloud segmentation based on semantic and geometric sample mixing.","We present a two-branch symmetric network architecture capable of concurrently processing point clouds from a source domain (e.g. synthetic) and point clouds from a target domain (e.g. real-world).","Each branch operates within one domain by integrating selected data fragments from the other domain and utilizing semantic information derived from source labels and target (pseudo) labels.","Additionally, our method can leverage a limited number of human point-level annotations (semi-supervised) to further enhance performance.","We assess our approach in both synthetic-to-real and real-to-real scenarios using LiDAR datasets and demonstrate that it significantly outperforms state-of-the-art methods in both unsupervised and semi-supervised settings."],"url":"http://arxiv.org/abs/2308.14619v1"}
{"created":"2023-08-28 14:38:06","title":"Towards \"all-inclusive\" Data Preparation to ensure Data Quality","abstract":"Data preparation, especially data cleaning, is very important to ensure data quality and to improve the output of automated decision systems. Since there is no single tool that covers all steps required, a combination of tools -- namely a data preparation pipeline -- is required. Such process comes with a number of challenges. We outline the challenges and describe the different tasks we want to analyze in our future research to address these. A test data generator which we implemented to constitute the basis for our future work will also be introduced in detail.","sentences":["Data preparation, especially data cleaning, is very important to ensure data quality and to improve the output of automated decision systems.","Since there is no single tool that covers all steps required, a combination of tools -- namely a data preparation pipeline -- is required.","Such process comes with a number of challenges.","We outline the challenges and describe the different tasks we want to analyze in our future research to address these.","A test data generator which we implemented to constitute the basis for our future work will also be introduced in detail."],"url":"http://arxiv.org/abs/2308.14617v1"}
{"created":"2023-08-28 14:35:58","title":"VoroMesh: Learning Watertight Surface Meshes with Voronoi Diagrams","abstract":"In stark contrast to the case of images, finding a concise, learnable discrete representation of 3D surfaces remains a challenge. In particular, while polygon meshes are arguably the most common surface representation used in geometry processing, their irregular and combinatorial structure often make them unsuitable for learning-based applications. In this work, we present VoroMesh, a novel and differentiable Voronoi-based representation of watertight 3D shape surfaces. From a set of 3D points (called generators) and their associated occupancy, we define our boundary representation through the Voronoi diagram of the generators as the subset of Voronoi faces whose two associated (equidistant) generators are of opposite occupancy: the resulting polygon mesh forms a watertight approximation of the target shape's boundary. To learn the position of the generators, we propose a novel loss function, dubbed VoroLoss, that minimizes the distance from ground truth surface samples to the closest faces of the Voronoi diagram which does not require an explicit construction of the entire Voronoi diagram. A direct optimization of the Voroloss to obtain generators on the Thingi32 dataset demonstrates the geometric efficiency of our representation compared to axiomatic meshing algorithms and recent learning-based mesh representations. We further use VoroMesh in a learning-based mesh prediction task from input SDF grids on the ABC dataset, and show comparable performance to state-of-the-art methods while guaranteeing closed output surfaces free of self-intersections.","sentences":["In stark contrast to the case of images, finding a concise, learnable discrete representation of 3D surfaces remains a challenge.","In particular, while polygon meshes are arguably the most common surface representation used in geometry processing, their irregular and combinatorial structure often make them unsuitable for learning-based applications.","In this work, we present VoroMesh, a novel and differentiable Voronoi-based representation of watertight 3D shape surfaces.","From a set of 3D points (called generators) and their associated occupancy, we define our boundary representation through the Voronoi diagram of the generators as the subset of Voronoi faces whose two associated (equidistant) generators are of opposite occupancy: the resulting polygon mesh forms a watertight approximation of the target shape's boundary.","To learn the position of the generators, we propose a novel loss function, dubbed VoroLoss, that minimizes the distance from ground truth surface samples to the closest faces of the Voronoi diagram which does not require an explicit construction of the entire Voronoi diagram.","A direct optimization of the Voroloss to obtain generators on the Thingi32 dataset demonstrates the geometric efficiency of our representation compared to axiomatic meshing algorithms and recent learning-based mesh representations.","We further use VoroMesh in a learning-based mesh prediction task from input SDF grids on the ABC dataset, and show comparable performance to state-of-the-art methods while guaranteeing closed output surfaces free of self-intersections."],"url":"http://arxiv.org/abs/2308.14616v1"}
{"created":"2023-08-28 14:28:50","title":"MS-Net: A Multi-modal Self-supervised Network for Fine-Grained Classification of Aircraft in SAR Images","abstract":"Synthetic aperture radar (SAR) imaging technology is commonly used to provide 24-hour all-weather earth observation. However, it still has some drawbacks in SAR target classification, especially in fine-grained classification of aircraft: aircrafts in SAR images have large intra-class diversity and inter-class similarity; the number of effective samples is insufficient and it's hard to annotate. To address these issues, this article proposes a novel multi-modal self-supervised network (MS-Net) for fine-grained classification of aircraft. Firstly, in order to entirely exploit the potential of multi-modal information, a two-sided path feature extraction network (TSFE-N) is constructed to enhance the image feature of the target and obtain the domain knowledge feature of text mode. Secondly, a contrastive self-supervised learning (CSSL) framework is employed to effectively learn useful label-independent feature from unbalanced data, a similarity per-ception loss (SPloss) is proposed to avoid network overfitting. Finally, TSFE-N is used as the encoder of CSSL to obtain the classification results. Through a large number of experiments, our MS-Net can effectively reduce the difficulty of classifying similar types of aircrafts. In the case of no label, the proposed algorithm achieves an accuracy of 88.46% for 17 types of air-craft classification task, which has pioneering significance in the field of fine-grained classification of aircraft in SAR images.","sentences":["Synthetic aperture radar (SAR) imaging technology is commonly used to provide 24-hour all-weather earth observation.","However, it still has some drawbacks in SAR target classification, especially in fine-grained classification of aircraft: aircrafts in SAR images have large intra-class diversity and inter-class similarity; the number of effective samples is insufficient and it's hard to annotate.","To address these issues, this article proposes a novel multi-modal self-supervised network (MS-Net) for fine-grained classification of aircraft.","Firstly, in order to entirely exploit the potential of multi-modal information, a two-sided path feature extraction network (TSFE-N) is constructed to enhance the image feature of the target and obtain the domain knowledge feature of text mode.","Secondly, a contrastive self-supervised learning (CSSL) framework is employed to effectively learn useful label-independent feature from unbalanced data, a similarity per-ception loss (SPloss) is proposed to avoid network overfitting.","Finally, TSFE-N is used as the encoder of CSSL to obtain the classification results.","Through a large number of experiments, our MS-Net can effectively reduce the difficulty of classifying similar types of aircrafts.","In the case of no label, the proposed algorithm achieves an accuracy of 88.46% for 17 types of air-craft classification task, which has pioneering significance in the field of fine-grained classification of aircraft in SAR images."],"url":"http://arxiv.org/abs/2308.14613v1"}
{"created":"2023-08-28 14:23:04","title":"AI in the Gray: Exploring Moderation Policies in Dialogic Large Language Models vs. Human Answers in Controversial Topics","abstract":"The introduction of ChatGPT and the subsequent improvement of Large Language Models (LLMs) have prompted more and more individuals to turn to the use of ChatBots, both for information and assistance with decision-making. However, the information the user is after is often not formulated by these ChatBots objectively enough to be provided with a definite, globally accepted answer.   Controversial topics, such as \"religion\", \"gender identity\", \"freedom of speech\", and \"equality\", among others, can be a source of conflict as partisan or biased answers can reinforce preconceived notions or promote disinformation. By exposing ChatGPT to such debatable questions, we aim to understand its level of awareness and if existing models are subject to socio-political and/or economic biases. We also aim to explore how AI-generated answers compare to human ones. For exploring this, we use a dataset of a social media platform created for the purpose of debating human-generated claims on polemic subjects among users, dubbed Kialo.   Our results show that while previous versions of ChatGPT have had important issues with controversial topics, more recent versions of ChatGPT (gpt-3.5-turbo) are no longer manifesting significant explicit biases in several knowledge areas. In particular, it is well-moderated regarding economic aspects. However, it still maintains degrees of implicit libertarian leaning toward right-winged ideals which suggest the need for increased moderation from the socio-political point of view. In terms of domain knowledge on controversial topics, with the exception of the \"Philosophical\" category, ChatGPT is performing well in keeping up with the collective human level of knowledge. Finally, we see that sources of Bing AI have slightly more tendency to the center when compared to human answers. All the analyses we make are generalizable to other types of biases and domains.","sentences":["The introduction of ChatGPT and the subsequent improvement of Large Language Models (LLMs) have prompted more and more individuals to turn to the use of ChatBots, both for information and assistance with decision-making.","However, the information the user is after is often not formulated by these ChatBots objectively enough to be provided with a definite, globally accepted answer.   ","Controversial topics, such as \"religion\", \"gender identity\", \"freedom of speech\", and \"equality\", among others, can be a source of conflict as partisan or biased answers can reinforce preconceived notions or promote disinformation.","By exposing ChatGPT to such debatable questions, we aim to understand its level of awareness and if existing models are subject to socio-political and/or economic biases.","We also aim to explore how AI-generated answers compare to human ones.","For exploring this, we use a dataset of a social media platform created for the purpose of debating human-generated claims on polemic subjects among users, dubbed Kialo.   ","Our results show that while previous versions of ChatGPT have had important issues with controversial topics, more recent versions of ChatGPT (gpt-3.5-turbo) are no longer manifesting significant explicit biases in several knowledge areas.","In particular, it is well-moderated regarding economic aspects.","However, it still maintains degrees of implicit libertarian leaning toward right-winged ideals which suggest the need for increased moderation from the socio-political point of view.","In terms of domain knowledge on controversial topics, with the exception of the \"Philosophical\" category, ChatGPT is performing well in keeping up with the collective human level of knowledge.","Finally, we see that sources of Bing AI have slightly more tendency to the center when compared to human answers.","All the analyses we make are generalizable to other types of biases and domains."],"url":"http://arxiv.org/abs/2308.14608v1"}
{"created":"2023-08-28 14:20:53","title":"On the Tradeoff between Privacy Preservation and Byzantine-Robustness in Decentralized Learning","abstract":"This paper jointly considers privacy preservation and Byzantine-robustness in decentralized learning. In a decentralized network, honest-but-curious agents faithfully follow the prescribed algorithm, but expect to infer their neighbors' private data from messages received during the learning process, while dishonest-and-Byzantine agents disobey the prescribed algorithm, and deliberately disseminate wrong messages to their neighbors so as to bias the learning process. For this novel setting, we investigate a generic privacy-preserving and Byzantine-robust decentralized stochastic gradient descent (SGD) framework, in which Gaussian noise is injected to preserve privacy and robust aggregation rules are adopted to counteract Byzantine attacks. We analyze its learning error and privacy guarantee, discovering an essential tradeoff between privacy preservation and Byzantine-robustness in decentralized learning -- the learning error caused by defending against Byzantine attacks is exacerbated by the Gaussian noise added to preserve privacy. Numerical experiments are conducted and corroborate our theoretical findings.","sentences":["This paper jointly considers privacy preservation and Byzantine-robustness in decentralized learning.","In a decentralized network, honest-but-curious agents faithfully follow the prescribed algorithm, but expect to infer their neighbors' private data from messages received during the learning process, while dishonest-and-Byzantine agents disobey the prescribed algorithm, and deliberately disseminate wrong messages to their neighbors so as to bias the learning process.","For this novel setting, we investigate a generic privacy-preserving and Byzantine-robust decentralized stochastic gradient descent (SGD) framework, in which Gaussian noise is injected to preserve privacy and robust aggregation rules are adopted to counteract Byzantine attacks.","We analyze its learning error and privacy guarantee, discovering an essential tradeoff between privacy preservation and Byzantine-robustness in decentralized learning -- the learning error caused by defending against Byzantine attacks is exacerbated by the Gaussian noise added to preserve privacy.","Numerical experiments are conducted and corroborate our theoretical findings."],"url":"http://arxiv.org/abs/2308.14606v1"}
{"created":"2023-08-28 14:19:13","title":"A Generalization of Continuous Relaxation in Structured Pruning","abstract":"Deep learning harnesses massive parallel floating-point processing to train and evaluate large neural networks. Trends indicate that deeper and larger neural networks with an increasing number of parameters achieve higher accuracy than smaller neural networks. This performance improvement, which often requires heavy compute for both training and evaluation, eventually needs to translate well to resource-constrained hardware for practical value. Structured pruning asserts that while large networks enable us to find solutions to complex computer vision problems, a smaller, computationally efficient sub-network can be derived from the large neural network that retains model accuracy but significantly improves computational efficiency.   We generalize structured pruning with algorithms for network augmentation, pruning, sub-network collapse and removal. In addition, we demonstrate efficient and stable convergence up to 93% sparsity and 95% FLOPs reduction without loss of inference accuracy using with continuous relaxation matching or exceeding the state of the art for all structured pruning methods. The resulting CNN executes efficiently on GPU hardware without computationally expensive sparse matrix operations. We achieve this with routine automatable operations on classification and segmentation problems using CIFAR-10, ImageNet, and CityScapes datasets with the ResNet and U-NET network architectures.","sentences":["Deep learning harnesses massive parallel floating-point processing to train and evaluate large neural networks.","Trends indicate that deeper and larger neural networks with an increasing number of parameters achieve higher accuracy than smaller neural networks.","This performance improvement, which often requires heavy compute for both training and evaluation, eventually needs to translate well to resource-constrained hardware for practical value.","Structured pruning asserts that while large networks enable us to find solutions to complex computer vision problems, a smaller, computationally efficient sub-network can be derived from the large neural network that retains model accuracy but significantly improves computational efficiency.   ","We generalize structured pruning with algorithms for network augmentation, pruning, sub-network collapse and removal.","In addition, we demonstrate efficient and stable convergence up to 93% sparsity and 95% FLOPs reduction without loss of inference accuracy using with continuous relaxation matching or exceeding the state of the art for all structured pruning methods.","The resulting CNN executes efficiently on GPU hardware without computationally expensive sparse matrix operations.","We achieve this with routine automatable operations on classification and segmentation problems using CIFAR-10, ImageNet, and CityScapes datasets with the ResNet and U-NET network architectures."],"url":"http://arxiv.org/abs/2308.14605v1"}
{"created":"2023-08-28 14:17:16","title":"SAM-PARSER: Fine-tuning SAM Efficiently by Parameter Space Reconstruction","abstract":"Segment Anything Model (SAM) has received remarkable attention as it offers a powerful and versatile solution for object segmentation in images. However, fine-tuning SAM for downstream segmentation tasks under different scenarios remains a challenge, as the varied characteristics of different scenarios naturally requires diverse model parameter spaces. Most existing fine-tuning methods attempt to bridge the gaps among different scenarios by introducing a set of new parameters to modify SAM's original parameter space. Unlike these works, in this paper, we propose fine-tuning SAM efficiently by parameter space reconstruction (SAM-PARSER), which introduce nearly zero trainable parameters during fine-tuning. In SAM-PARSER, we assume that SAM's original parameter space is relatively complete, so that its bases are able to reconstruct the parameter space of a new scenario. We obtain the bases by matrix decomposition, and fine-tuning the coefficients to reconstruct the parameter space tailored to the new scenario by an optimal linear combination of the bases. Experimental results show that SAM-PARSER exhibits superior segmentation performance across various scenarios, while reducing the number of trainable parameters by $\\approx 290$ times compared with current parameter-efficient fine-tuning methods.","sentences":["Segment Anything Model (SAM) has received remarkable attention as it offers a powerful and versatile solution for object segmentation in images.","However, fine-tuning SAM for downstream segmentation tasks under different scenarios remains a challenge, as the varied characteristics of different scenarios naturally requires diverse model parameter spaces.","Most existing fine-tuning methods attempt to bridge the gaps among different scenarios by introducing a set of new parameters to modify SAM's original parameter space.","Unlike these works, in this paper, we propose fine-tuning SAM efficiently by parameter space reconstruction (SAM-PARSER), which introduce nearly zero trainable parameters during fine-tuning.","In SAM-PARSER, we assume that SAM's original parameter space is relatively complete, so that its bases are able to reconstruct the parameter space of a new scenario.","We obtain the bases by matrix decomposition, and fine-tuning the coefficients to reconstruct the parameter space tailored to the new scenario by an optimal linear combination of the bases.","Experimental results show that SAM-PARSER exhibits superior segmentation performance across various scenarios, while reducing the number of trainable parameters by $\\approx 290$ times compared with current parameter-efficient fine-tuning methods."],"url":"http://arxiv.org/abs/2308.14604v1"}
{"created":"2023-08-28 14:12:25","title":"Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery","abstract":"As online music platforms grow, music recommender systems play a vital role in helping users navigate and discover content within their vast musical databases. At odds with this larger goal, is the presence of popularity bias, which causes algorithmic systems to favor mainstream content over, potentially more relevant, but niche items. In this work we explore the intrinsic relationship between music discovery and popularity bias. To mitigate this issue we propose a domain-aware, individual fairness-based approach which addresses popularity bias in graph neural network (GNNs) based recommender systems. Our approach uses individual fairness to reflect a ground truth listening experience, i.e., if two songs sound similar, this similarity should be reflected in their representations. In doing so, we facilitate meaningful music discovery that is robust to popularity bias and grounded in the music domain. We apply our BOOST methodology to two discovery based tasks, performing recommendations at both the playlist level and user level. Then, we ground our evaluation in the cold start setting, showing that our approach outperforms existing fairness benchmarks in both performance and recommendation of lesser-known content. Finally, our analysis explains why our proposed methodology is a novel and promising approach to mitigating popularity bias and improving the discovery of new and niche content in music recommender systems.","sentences":["As online music platforms grow, music recommender systems play a vital role in helping users navigate and discover content within their vast musical databases.","At odds with this larger goal, is the presence of popularity bias, which causes algorithmic systems to favor mainstream content over, potentially more relevant, but niche items.","In this work we explore the intrinsic relationship between music discovery and popularity bias.","To mitigate this issue we propose a domain-aware, individual fairness-based approach which addresses popularity bias in graph neural network (GNNs) based recommender systems.","Our approach uses individual fairness to reflect a ground truth listening experience, i.e., if two songs sound similar, this similarity should be reflected in their representations.","In doing so, we facilitate meaningful music discovery that is robust to popularity bias and grounded in the music domain.","We apply our BOOST methodology to two discovery based tasks, performing recommendations at both the playlist level and user level.","Then, we ground our evaluation in the cold start setting, showing that our approach outperforms existing fairness benchmarks in both performance and recommendation of lesser-known content.","Finally, our analysis explains why our proposed methodology is a novel and promising approach to mitigating popularity bias and improving the discovery of new and niche content in music recommender systems."],"url":"http://arxiv.org/abs/2308.14601v1"}
{"created":"2023-08-28 14:09:03","title":"S-TREK: Sequential Translation and Rotation Equivariant Keypoints for local feature extraction","abstract":"In this work we introduce S-TREK, a novel local feature extractor that combines a deep keypoint detector, which is both translation and rotation equivariant by design, with a lightweight deep descriptor extractor. We train the S-TREK keypoint detector within a framework inspired by reinforcement learning, where we leverage a sequential procedure to maximize a reward directly related to keypoint repeatability. Our descriptor network is trained following a \"detect, then describe\" approach, where the descriptor loss is evaluated only at those locations where keypoints have been selected by the already trained detector. Extensive experiments on multiple benchmarks confirm the effectiveness of our proposed method, with S-TREK often outperforming other state-of-the-art methods in terms of repeatability and quality of the recovered poses, especially when dealing with in-plane rotations.","sentences":["In this work we introduce S-TREK, a novel local feature extractor that combines a deep keypoint detector, which is both translation and rotation equivariant by design, with a lightweight deep descriptor extractor.","We train the S-TREK keypoint detector within a framework inspired by reinforcement learning, where we leverage a sequential procedure to maximize a reward directly related to keypoint repeatability.","Our descriptor network is trained following a \"detect, then describe\" approach, where the descriptor loss is evaluated only at those locations where keypoints have been selected by the already trained detector.","Extensive experiments on multiple benchmarks confirm the effectiveness of our proposed method, with S-TREK often outperforming other state-of-the-art methods in terms of repeatability and quality of the recovered poses, especially when dealing with in-plane rotations."],"url":"http://arxiv.org/abs/2308.14598v1"}
{"created":"2023-08-28 14:09:02","title":"Adversarial Attacks on Foundational Vision Models","abstract":"Rapid progress is being made in developing large, pretrained, task-agnostic foundational vision models such as CLIP, ALIGN, DINOv2, etc. In fact, we are approaching the point where these models do not have to be finetuned downstream, and can simply be used in zero-shot or with a lightweight probing head. Critically, given the complexity of working at this scale, there is a bottleneck where relatively few organizations in the world are executing the training then sharing the models on centralized platforms such as HuggingFace and torch.hub. The goal of this work is to identify several key adversarial vulnerabilities of these models in an effort to make future designs more robust. Intuitively, our attacks manipulate deep feature representations to fool an out-of-distribution (OOD) detector which will be required when using these open-world-aware models to solve closed-set downstream tasks. Our methods reliably make in-distribution (ID) images (w.r.t. a downstream task) be predicted as OOD and vice versa while existing in extremely low-knowledge-assumption threat models. We show our attacks to be potent in whitebox and blackbox settings, as well as when transferred across foundational model types (e.g., attack DINOv2 with CLIP)! This work is only just the beginning of a long journey towards adversarially robust foundational vision models.","sentences":["Rapid progress is being made in developing large, pretrained, task-agnostic foundational vision models such as CLIP, ALIGN, DINOv2, etc.","In fact, we are approaching the point where these models do not have to be finetuned downstream, and can simply be used in zero-shot or with a lightweight probing head.","Critically, given the complexity of working at this scale, there is a bottleneck where relatively few organizations in the world are executing the training then sharing the models on centralized platforms such as HuggingFace and torch.hub.","The goal of this work is to identify several key adversarial vulnerabilities of these models in an effort to make future designs more robust.","Intuitively, our attacks manipulate deep feature representations to fool an out-of-distribution (OOD) detector which will be required when using these open-world-aware models to solve closed-set downstream tasks.","Our methods reliably make in-distribution (ID) images (w.r.t. a downstream task) be predicted as OOD and vice versa while existing in extremely low-knowledge-assumption threat models.","We show our attacks to be potent in whitebox and blackbox settings, as well as when transferred across foundational model types (e.g., attack DINOv2 with CLIP)!","This work is only just the beginning of a long journey towards adversarially robust foundational vision models."],"url":"http://arxiv.org/abs/2308.14597v1"}
{"created":"2023-08-28 14:08:42","title":"LatentDR: Improving Model Generalization Through Sample-Aware Latent Degradation and Restoration","abstract":"Despite significant advances in deep learning, models often struggle to generalize well to new, unseen domains, especially when training data is limited. To address this challenge, we propose a novel approach for distribution-aware latent augmentation that leverages the relationships across samples to guide the augmentation procedure. Our approach first degrades the samples stochastically in the latent space, mapping them to augmented labels, and then restores the samples from their corrupted versions during training. This process confuses the classifier in the degradation step and restores the overall class distribution of the original samples, promoting diverse intra-class/cross-domain variability. We extensively evaluate our approach on a diverse set of datasets and tasks, including domain generalization benchmarks and medical imaging datasets with strong domain shift, where we show our approach achieves significant improvements over existing methods for latent space augmentation. We further show that our method can be flexibly adapted to long-tail recognition tasks, demonstrating its versatility in building more generalizable models. Code is available at https://github.com/nerdslab/LatentDR.","sentences":["Despite significant advances in deep learning, models often struggle to generalize well to new, unseen domains, especially when training data is limited.","To address this challenge, we propose a novel approach for distribution-aware latent augmentation that leverages the relationships across samples to guide the augmentation procedure.","Our approach first degrades the samples stochastically in the latent space, mapping them to augmented labels, and then restores the samples from their corrupted versions during training.","This process confuses the classifier in the degradation step and restores the overall class distribution of the original samples, promoting diverse intra-class/cross-domain variability.","We extensively evaluate our approach on a diverse set of datasets and tasks, including domain generalization benchmarks and medical imaging datasets with strong domain shift, where we show our approach achieves significant improvements over existing methods for latent space augmentation.","We further show that our method can be flexibly adapted to long-tail recognition tasks, demonstrating its versatility in building more generalizable models.","Code is available at https://github.com/nerdslab/LatentDR."],"url":"http://arxiv.org/abs/2308.14596v1"}
{"created":"2023-08-28 14:06:36","title":"Neural Network Training Strategy to Enhance Anomaly Detection Performance: A Perspective on Reconstruction Loss Amplification","abstract":"Unsupervised anomaly detection (UAD) is a widely adopted approach in industry due to rare anomaly occurrences and data imbalance. A desirable characteristic of an UAD model is contained generalization ability which excels in the reconstruction of seen normal patterns but struggles with unseen anomalies. Recent studies have pursued to contain the generalization capability of their UAD models in reconstruction from different perspectives, such as design of neural network (NN) structure and training strategy. In contrast, we note that containing of generalization ability in reconstruction can also be obtained simply from steep-shaped loss landscape. Motivated by this, we propose a loss landscape sharpening method by amplifying the reconstruction loss, dubbed Loss AMPlification (LAMP). LAMP deforms the loss landscape into a steep shape so the reconstruction error on unseen anomalies becomes greater. Accordingly, the anomaly detection performance is improved without any change of the NN architecture. Our findings suggest that LAMP can be easily applied to any reconstruction error metrics in UAD settings where the reconstruction model is trained with anomaly-free samples only.","sentences":["Unsupervised anomaly detection (UAD) is a widely adopted approach in industry due to rare anomaly occurrences and data imbalance.","A desirable characteristic of an UAD model is contained generalization ability which excels in the reconstruction of seen normal patterns but struggles with unseen anomalies.","Recent studies have pursued to contain the generalization capability of their UAD models in reconstruction from different perspectives, such as design of neural network (NN) structure and training strategy.","In contrast, we note that containing of generalization ability in reconstruction can also be obtained simply from steep-shaped loss landscape.","Motivated by this, we propose a loss landscape sharpening method by amplifying the reconstruction loss, dubbed Loss AMPlification (LAMP).","LAMP deforms the loss landscape into a steep shape so the reconstruction error on unseen anomalies becomes greater.","Accordingly, the anomaly detection performance is improved without any change of the NN architecture.","Our findings suggest that LAMP can be easily applied to any reconstruction error metrics in UAD settings where the reconstruction model is trained with anomaly-free samples only."],"url":"http://arxiv.org/abs/2308.14595v1"}
{"created":"2023-08-28 14:00:09","title":"Skip, Skip, Skip, Accept!!!: A Study on the Usability of Smartphone Manufacturer Provided Default Features and User Privacy","abstract":"Smartphone manufacturer provided default features (e.g., default location services, iCloud, Google Assistant, ad tracking) enhance the usability and extend the functionality of these devices. Prior studies have highlighted smartphone vulnerabilities and how users' data can be harvested without their knowledge. However, little is known about manufacturer provided default features in this regard -- their usability concerning configuring them during usage, and how users perceive them with regards to privacy. To bridge this gap, we conducted a task-based study with 27 Android and iOS smartphone users in order to learn about their perceptions, concerns and practices, and to understand the usability of these features with regards to privacy. We explored the following: users' awareness of these features, why and when do they change the settings of these features, the challenges they face while configuring these features, and finally the mitigation strategies they adopt. Our findings reveal that users of both platforms have limited awareness of these features and their privacy implications. Awareness of these features does not imply that a user can easily locate and adjust them when needed.   Furthermore, users attribute their failure to configure default features to hidden controls and insufficient knowledge on how to configure them. To cope with difficulties of finding controls, users employ various coping strategies, some of which are platform specific but most often applicable to both platforms. However, some of these coping strategies leave users vulnerable.","sentences":["Smartphone manufacturer provided default features (e.g., default location services, iCloud, Google Assistant, ad tracking) enhance the usability and extend the functionality of these devices.","Prior studies have highlighted smartphone vulnerabilities and how users' data can be harvested without their knowledge.","However, little is known about manufacturer provided default features in this regard -- their usability concerning configuring them during usage, and how users perceive them with regards to privacy.","To bridge this gap, we conducted a task-based study with 27 Android and iOS smartphone users in order to learn about their perceptions, concerns and practices, and to understand the usability of these features with regards to privacy.","We explored the following: users' awareness of these features, why and when do they change the settings of these features, the challenges they face while configuring these features, and finally the mitigation strategies they adopt.","Our findings reveal that users of both platforms have limited awareness of these features and their privacy implications.","Awareness of these features does not imply that a user can easily locate and adjust them when needed.   ","Furthermore, users attribute their failure to configure default features to hidden controls and insufficient knowledge on how to configure them.","To cope with difficulties of finding controls, users employ various coping strategies, some of which are platform specific but most often applicable to both platforms.","However, some of these coping strategies leave users vulnerable."],"url":"http://arxiv.org/abs/2308.14593v1"}
{"created":"2023-08-28 13:56:05","title":"Towards Evolution Capabilities in Data Pipelines","abstract":"Evolutionary change over time in the context of data pipelines is certain, especially with regard to the structure and semantics of data as well as to the pipeline operators. Dealing with these changes, i.e. providing long-term maintenance, is costly. The present work explores the need for evolution capabilities within pipeline frameworks. In this context dealing with evolution is defined as a two-step process consisting of self-awareness and self-adaption. Furthermore, a conceptual requirements model is provided, which encompasses criteria for self-awareness and self-adaption as well as covering the dimensions data, operator, pipeline and environment. A lack of said capabilities in existing frameworks exposes a major gap. Filling this gap will be a significant contribution for practitioners and scientists alike. The present work envisions and lays the foundation for a framework which can handle evolutionary change.","sentences":["Evolutionary change over time in the context of data pipelines is certain, especially with regard to the structure and semantics of data as well as to the pipeline operators.","Dealing with these changes, i.e. providing long-term maintenance, is costly.","The present work explores the need for evolution capabilities within pipeline frameworks.","In this context dealing with evolution is defined as a two-step process consisting of self-awareness and self-adaption.","Furthermore, a conceptual requirements model is provided, which encompasses criteria for self-awareness and self-adaption as well as covering the dimensions data, operator, pipeline and environment.","A lack of said capabilities in existing frameworks exposes a major gap.","Filling this gap will be a significant contribution for practitioners and scientists alike.","The present work envisions and lays the foundation for a framework which can handle evolutionary change."],"url":"http://arxiv.org/abs/2308.14591v1"}
{"created":"2023-08-28 13:49:08","title":"Learning to Read Analog Gauges from Synthetic Data","abstract":"Manually reading and logging gauge data is time inefficient, and the effort increases according to the number of gauges available. We present a computer vision pipeline that automates the reading of analog gauges. We propose a two-stage CNN pipeline that identifies the key structural components of an analog gauge and outputs an angular reading. To facilitate the training of our approach, a synthetic dataset is generated thus obtaining a set of realistic analog gauges with their corresponding annotation. To validate our proposal, an additional real-world dataset was collected with 4.813 manually curated images. When compared against state-of-the-art methodologies, our method shows a significant improvement of 4.55 in the average error, which is a 52% relative improvement. The resources for this project will be made available at: https://github.com/fuankarion/automatic-gauge-reading.","sentences":["Manually reading and logging gauge data is time inefficient, and the effort increases according to the number of gauges available.","We present a computer vision pipeline that automates the reading of analog gauges.","We propose a two-stage CNN pipeline that identifies the key structural components of an analog gauge and outputs an angular reading.","To facilitate the training of our approach, a synthetic dataset is generated thus obtaining a set of realistic analog gauges with their corresponding annotation.","To validate our proposal, an additional real-world dataset was collected with 4.813 manually curated images.","When compared against state-of-the-art methodologies, our method shows a significant improvement of 4.55 in the average error, which is a 52% relative improvement.","The resources for this project will be made available at: https://github.com/fuankarion/automatic-gauge-reading."],"url":"http://arxiv.org/abs/2308.14583v1"}
{"created":"2023-08-28 13:47:36","title":"Many-valued coalgebraic logic over semi-primal varieties","abstract":"We study many-valued coalgebraic logics with semi-primal algebras of truth-degrees. We provide a systematic way to lift endofunctors defined on the variety of Boolean algebras to endofunctors on the variety generated by a semi-primal algebra. We show that this can be extended to a technique to lift classical coalgebraic logics to many-valued ones, and that (one-step) completeness and expressivity are preserved under this lifting. For specific classes of endofunctors, we also describe how to obtain an axiomatization of the lifted many-valued logic directly from an axiomatization of the original classical one. In particular, we apply all of these techniques to classical modal logic.","sentences":["We study many-valued coalgebraic logics with semi-primal algebras of truth-degrees.","We provide a systematic way to lift endofunctors defined on the variety of Boolean algebras to endofunctors on the variety generated by a semi-primal algebra.","We show that this can be extended to a technique to lift classical coalgebraic logics to many-valued ones, and that (one-step) completeness and expressivity are preserved under this lifting.","For specific classes of endofunctors, we also describe how to obtain an axiomatization of the lifted many-valued logic directly from an axiomatization of the original classical one.","In particular, we apply all of these techniques to classical modal logic."],"url":"http://arxiv.org/abs/2308.14581v1"}
{"created":"2023-08-28 13:45:10","title":"Flexible-Position MIMO for Wireless Communications: Fundamentals, Challenges, and Future Directions","abstract":"The flexible-position multiple-input multiple-output (MIMO), such as fluid antennas and movable antennas, is a promising technology for future wireless communications. This is due to the fact that the positions of antennas at the transceiver and reflector can be dynamically optimized to achieve better channel conditions and, as such, can provide high spectral efficiency (SE) and energy efficiency (EE) gains with fewer antennas. In this article, we introduce the fundamentals of flexibleposition MIMO systems, including hardware design, structure design, and potential applications. We shall demonstrate that flexible-position MIMO, using fewer flexible antennas, can match the channel hardening achieved by a large number of fixed antennas. We will then analyze the SE-EE relationship for flexible-position MIMO and fixed-position MIMO. Furthermore, we will design the optimal trajectory of flexible antennas to maximize system sum SE or total EE at a fixed travel distance of each antenna. Finally, several important research directions regarding flexible-position MIMO communications are presented to facilitate further investigation.","sentences":["The flexible-position multiple-input multiple-output (MIMO), such as fluid antennas and movable antennas, is a promising technology for future wireless communications.","This is due to the fact that the positions of antennas at the transceiver and reflector can be dynamically optimized to achieve better channel conditions and, as such, can provide high spectral efficiency (SE) and energy efficiency (EE) gains with fewer antennas.","In this article, we introduce the fundamentals of flexibleposition MIMO systems, including hardware design, structure design, and potential applications.","We shall demonstrate that flexible-position MIMO, using fewer flexible antennas, can match the channel hardening achieved by a large number of fixed antennas.","We will then analyze the SE-EE relationship for flexible-position MIMO and fixed-position MIMO.","Furthermore, we will design the optimal trajectory of flexible antennas to maximize system sum SE or total EE at a fixed travel distance of each antenna.","Finally, several important research directions regarding flexible-position MIMO communications are presented to facilitate further investigation."],"url":"http://arxiv.org/abs/2308.14578v1"}
{"created":"2023-08-28 13:43:24","title":"Quantitative Data Analysis: CRASAR Small Unmanned Aerial Systems at Hurricane Ian","abstract":"This paper provides a summary of the 281 sorties that were flown by the 10 different models of small unmanned aerial systems (sUAS) at Hurricane Ian, and the failures made in the field. These 281 sorties, supporting 44 missions, represents the largest use of sUAS in a disaster to date (previously Hurricane Florence with 260 sorties). The sUAS operations at Hurricane Ian differ slightly from prior operations as they included the first documented uses of drones performing interior search for victims, and the first use of a VTOL fixed wing aircraft during a large scale disaster. However, there are substantive similarities to prior drone operations. Most notably, rotorcraft continue to perform the vast majority of flights, wireless data transmission capacity continues to be a limitation, and the lack of centralized control for unmanned and manned aerial systems continues to cause operational friction. This work continues by documenting the failures, both human and technological made in the field and concludes with a discussion summarizing potential areas for further work to improve sUAS response to large scale disasters.","sentences":["This paper provides a summary of the 281 sorties that were flown by the 10 different models of small unmanned aerial systems (sUAS) at Hurricane Ian, and the failures made in the field.","These 281 sorties, supporting 44 missions, represents the largest use of sUAS in a disaster to date (previously Hurricane Florence with 260 sorties).","The sUAS operations at Hurricane Ian differ slightly from prior operations as they included the first documented uses of drones performing interior search for victims, and the first use of a VTOL fixed wing aircraft during a large scale disaster.","However, there are substantive similarities to prior drone operations.","Most notably, rotorcraft continue to perform the vast majority of flights, wireless data transmission capacity continues to be a limitation, and the lack of centralized control for unmanned and manned aerial systems continues to cause operational friction.","This work continues by documenting the failures, both human and technological made in the field and concludes with a discussion summarizing potential areas for further work to improve sUAS response to large scale disasters."],"url":"http://arxiv.org/abs/2308.14577v1"}
{"created":"2023-08-28 13:41:34","title":"Turnkey Technology: A Powerful Tool for Cyber Warfare","abstract":"Turnkey technology has emerged as a game-changing tool in cyber warfare, offering state and non-state actors unprecedented access to advanced cyber capabilities. The advantages of turnkey technology include rapid deployment and adaptability, lower costs and resource requirements, the democratization of cyber warfare capabilities, and enhanced offensive and defensive strategies. However, turnkey technology also introduces significant risks, such as the proliferation of cyber weapons, ethical considerations, potential collateral damage, escalation of conflicts, and legal ramifications. This paper provides a unique perspective on the implications of turnkey technology in cyber warfare, highlighting its advantages, risks, and challenges, as well as the potential strategies for mitigating these concerns. The research's novelty lies in examining real-world examples and proposing a multifaceted approach to address the challenges associated with turnkey technology in cyber warfare. This approach focuses on developing effective cybersecurity measures, establishing international norms and regulations, promoting responsible use and development of turnkey technology, and enhancing global cooperation on cyber warfare issues. By adopting this accountable and balanced approach, governments, organizations, and the international community can work together to create a more secure and stable digital environment, leveraging the benefits of turnkey technology while minimizing the associated risks and challenges.","sentences":["Turnkey technology has emerged as a game-changing tool in cyber warfare, offering state and non-state actors unprecedented access to advanced cyber capabilities.","The advantages of turnkey technology include rapid deployment and adaptability, lower costs and resource requirements, the democratization of cyber warfare capabilities, and enhanced offensive and defensive strategies.","However, turnkey technology also introduces significant risks, such as the proliferation of cyber weapons, ethical considerations, potential collateral damage, escalation of conflicts, and legal ramifications.","This paper provides a unique perspective on the implications of turnkey technology in cyber warfare, highlighting its advantages, risks, and challenges, as well as the potential strategies for mitigating these concerns.","The research's novelty lies in examining real-world examples and proposing a multifaceted approach to address the challenges associated with turnkey technology in cyber warfare.","This approach focuses on developing effective cybersecurity measures, establishing international norms and regulations, promoting responsible use and development of turnkey technology, and enhancing global cooperation on cyber warfare issues.","By adopting this accountable and balanced approach, governments, organizations, and the international community can work together to create a more secure and stable digital environment, leveraging the benefits of turnkey technology while minimizing the associated risks and challenges."],"url":"http://arxiv.org/abs/2308.14576v1"}
{"created":"2023-08-28 13:40:47","title":"Referring Image Segmentation Using Text Supervision","abstract":"Existing Referring Image Segmentation (RIS) methods typically require expensive pixel-level or box-level annotations for supervision. In this paper, we observe that the referring texts used in RIS already provide sufficient information to localize the target object. Hence, we propose a novel weakly-supervised RIS framework to formulate the target localization problem as a classification process to differentiate between positive and negative text expressions. While the referring text expressions for an image are used as positive expressions, the referring text expressions from other images can be used as negative expressions for this image. Our framework has three main novelties. First, we propose a bilateral prompt method to facilitate the classification process, by harmonizing the domain discrepancy between visual and linguistic features. Second, we propose a calibration method to reduce noisy background information and improve the correctness of the response maps for target object localization. Third, we propose a positive response map selection strategy to generate high-quality pseudo-labels from the enhanced response maps, for training a segmentation network for RIS inference. For evaluation, we propose a new metric to measure localization accuracy. Experiments on four benchmarks show that our framework achieves promising performances to existing fully-supervised RIS methods while outperforming state-of-the-art weakly-supervised methods adapted from related areas. Code is available at https://github.com/fawnliu/TRIS.","sentences":["Existing Referring Image Segmentation (RIS) methods typically require expensive pixel-level or box-level annotations for supervision.","In this paper, we observe that the referring texts used in RIS already provide sufficient information to localize the target object.","Hence, we propose a novel weakly-supervised RIS framework to formulate the target localization problem as a classification process to differentiate between positive and negative text expressions.","While the referring text expressions for an image are used as positive expressions, the referring text expressions from other images can be used as negative expressions for this image.","Our framework has three main novelties.","First, we propose a bilateral prompt method to facilitate the classification process, by harmonizing the domain discrepancy between visual and linguistic features.","Second, we propose a calibration method to reduce noisy background information and improve the correctness of the response maps for target object localization.","Third, we propose a positive response map selection strategy to generate high-quality pseudo-labels from the enhanced response maps, for training a segmentation network for RIS inference.","For evaluation, we propose a new metric to measure localization accuracy.","Experiments on four benchmarks show that our framework achieves promising performances to existing fully-supervised RIS methods while outperforming state-of-the-art weakly-supervised methods adapted from related areas.","Code is available at https://github.com/fawnliu/TRIS."],"url":"http://arxiv.org/abs/2308.14575v1"}
{"created":"2023-08-28 13:35:07","title":"SAAN: Similarity-aware attention flow network for change detection with VHR remote sensing images","abstract":"Change detection (CD) is a fundamental and important task for monitoring the land surface dynamics in the earth observation field. Existing deep learning-based CD methods typically extract bi-temporal image features using a weight-sharing Siamese encoder network and identify change regions using a decoder network. These CD methods, however, still perform far from satisfactorily as we observe that 1) deep encoder layers focus on irrelevant background regions and 2) the models' confidence in the change regions is inconsistent at different decoder stages. The first problem is because deep encoder layers cannot effectively learn from imbalanced change categories using the sole output supervision, while the second problem is attributed to the lack of explicit semantic consistency preservation. To address these issues, we design a novel similarity-aware attention flow network (SAAN). SAAN incorporates a similarity-guided attention flow module with deeply supervised similarity optimization to achieve effective change detection. Specifically, we counter the first issue by explicitly guiding deep encoder layers to discover semantic relations from bi-temporal input images using deeply supervised similarity optimization. The extracted features are optimized to be semantically similar in the unchanged regions and dissimilar in the changing regions. The second drawback can be alleviated by the proposed similarity-guided attention flow module, which incorporates similarity-guided attention modules and attention flow mechanisms to guide the model to focus on discriminative channels and regions. We evaluated the effectiveness and generalization ability of the proposed method by conducting experiments on a wide range of CD tasks. The experimental results demonstrate that our method achieves excellent performance on several CD tasks, with discriminative features and semantic consistency preserved.","sentences":["Change detection (CD) is a fundamental and important task for monitoring the land surface dynamics in the earth observation field.","Existing deep learning-based CD methods typically extract bi-temporal image features using a weight-sharing Siamese encoder network and identify change regions using a decoder network.","These CD methods, however, still perform far from satisfactorily as we observe that 1) deep encoder layers focus on irrelevant background regions and 2) the models' confidence in the change regions is inconsistent at different decoder stages.","The first problem is because deep encoder layers cannot effectively learn from imbalanced change categories using the sole output supervision, while the second problem is attributed to the lack of explicit semantic consistency preservation.","To address these issues, we design a novel similarity-aware attention flow network (SAAN).","SAAN incorporates a similarity-guided attention flow module with deeply supervised similarity optimization to achieve effective change detection.","Specifically, we counter the first issue by explicitly guiding deep encoder layers to discover semantic relations from bi-temporal input images using deeply supervised similarity optimization.","The extracted features are optimized to be semantically similar in the unchanged regions and dissimilar in the changing regions.","The second drawback can be alleviated by the proposed similarity-guided attention flow module, which incorporates similarity-guided attention modules and attention flow mechanisms to guide the model to focus on discriminative channels and regions.","We evaluated the effectiveness and generalization ability of the proposed method by conducting experiments on a wide range of CD tasks.","The experimental results demonstrate that our method achieves excellent performance on several CD tasks, with discriminative features and semantic consistency preserved."],"url":"http://arxiv.org/abs/2308.14570v1"}
{"created":"2023-08-28 13:34:39","title":"Solving Fr\u00e9chet Distance Problems by Algebraic Geometric Methods","abstract":"We study several polygonal curve problems under the Fr\\'{e}chet distance via algebraic geometric methods. Let $\\mathbb{X}_m^d$ and $\\mathbb{X}_k^d$ be the spaces of all polygonal curves of $m$ and $k$ vertices in $\\mathbb{R}^d$, respectively. We assume that $k \\leq m$. Let $\\mathcal{R}^d_{k,m}$ be the set of ranges in $\\mathbb{X}_m^d$ for all possible metric balls of polygonal curves in $\\mathbb{X}_k^d$ under the Fr\\'{e}chet distance. We prove a nearly optimal bound of $O(dk\\log (km))$ on the VC dimension of the range space $(\\mathbb{X}_m^d,\\mathcal{R}_{k,m}^d)$, improving on the previous $O(d^2k^2\\log(dkm))$ upper bound and approaching the current $\\Omega(dk\\log k)$ lower bound. Our upper bound also holds for the weak Fr\\'{e}chet distance. We also obtain exact solutions that are hitherto unknown for curve simplification, range searching, nearest neighbor search, and distance oracle.","sentences":["We study several polygonal curve problems under the Fr\\'{e}chet distance via algebraic geometric methods.","Let $\\mathbb{X}_m^d$ and $\\mathbb{X}_k^d$ be the spaces of all polygonal curves of $m$ and $k$ vertices in $\\mathbb{R}^d$, respectively.","We assume that $k \\leq m$. Let $\\mathcal{R}^d_{k,m}$ be the set of ranges in $\\mathbb{X}_m^d$ for all possible metric balls of polygonal curves in $\\mathbb{X}_k^d$ under the Fr\\'{e}chet distance.","We prove a nearly optimal bound of $O(dk\\log (km))$ on the VC dimension of the range space $(\\mathbb{X}_m^d,\\mathcal{R}_{k,m}^d)$, improving on the previous $O(d^2k^2\\log(dkm))$ upper bound and approaching the current $\\Omega(dk\\log k)$ lower bound.","Our upper bound also holds for the weak Fr\\'{e}chet distance.","We also obtain exact solutions that are hitherto unknown for curve simplification, range searching, nearest neighbor search, and distance oracle."],"url":"http://arxiv.org/abs/2308.14569v1"}
{"created":"2023-08-28 13:34:02","title":"Time-Frequency Transformer: A Novel Time Frequency Joint Learning Method for Speech Emotion Recognition","abstract":"In this paper, we propose a novel time-frequency joint learning method for speech emotion recognition, called Time-Frequency Transformer. Its advantage is that the Time-Frequency Transformer can excavate global emotion patterns in the time-frequency domain of speech signal while modeling the local emotional correlations in the time domain and frequency domain respectively. For the purpose, we first design a Time Transformer and Frequency Transformer to capture the local emotion patterns between frames and inside frequency bands respectively, so as to ensure the integrity of the emotion information modeling in both time and frequency domains. Then, a Time-Frequency Transformer is proposed to mine the time-frequency emotional correlations through the local time-domain and frequency-domain emotion features for learning more discriminative global speech emotion representation. The whole process is a time-frequency joint learning process implemented by a series of Transformer models. Experiments on IEMOCAP and CASIA databases indicate that our proposed method outdoes the state-of-the-art methods.","sentences":["In this paper, we propose a novel time-frequency joint learning method for speech emotion recognition, called Time-Frequency Transformer.","Its advantage is that the Time-Frequency Transformer can excavate global emotion patterns in the time-frequency domain of speech signal while modeling the local emotional correlations in the time domain and frequency domain respectively.","For the purpose, we first design a Time Transformer and Frequency Transformer to capture the local emotion patterns between frames and inside frequency bands respectively, so as to ensure the integrity of the emotion information modeling in both time and frequency domains.","Then, a Time-Frequency Transformer is proposed to mine the time-frequency emotional correlations through the local time-domain and frequency-domain emotion features for learning more discriminative global speech emotion representation.","The whole process is a time-frequency joint learning process implemented by a series of Transformer models.","Experiments on IEMOCAP and CASIA databases indicate that our proposed method outdoes the state-of-the-art methods."],"url":"http://arxiv.org/abs/2308.14568v1"}
{"created":"2023-08-28 13:24:58","title":"Data-Efficient Online Learning of Ball Placement in Robot Table Tennis","abstract":"We present an implementation of an online optimization algorithm for hitting a predefined target when returning ping-pong balls with a table tennis robot. The online algorithm optimizes over so-called interception policies, which define the manner in which the robot arm intercepts the ball. In our case, these are composed of the state of the robot arm (position and velocity) at interception time. Gradient information is provided to the optimization algorithm via the mapping from the interception policy to the landing point of the ball on the table, which is approximated with a black-box and a grey-box approach. Our algorithm is applied to a robotic arm with four degrees of freedom that is driven by pneumatic artificial muscles. As a result, the robot arm is able to return the ball onto any predefined target on the table after about 2-5 iterations. We highlight the robustness of our approach by showing rapid convergence with both the black-box and the grey-box gradients. In addition, the small number of iterations required to reach close proximity to the target also underlines the sample efficiency. A demonstration video can be found here: https://youtu.be/VC3KJoCss0k.","sentences":["We present an implementation of an online optimization algorithm for hitting a predefined target when returning ping-pong balls with a table tennis robot.","The online algorithm optimizes over so-called interception policies, which define the manner in which the robot arm intercepts the ball.","In our case, these are composed of the state of the robot arm (position and velocity) at interception time.","Gradient information is provided to the optimization algorithm via the mapping from the interception policy to the landing point of the ball on the table, which is approximated with a black-box and a grey-box approach.","Our algorithm is applied to a robotic arm with four degrees of freedom that is driven by pneumatic artificial muscles.","As a result, the robot arm is able to return the ball onto any predefined target on the table after about 2-5 iterations.","We highlight the robustness of our approach by showing rapid convergence with both the black-box and the grey-box gradients.","In addition, the small number of iterations required to reach close proximity to the target also underlines the sample efficiency.","A demonstration video can be found here: https://youtu.be/VC3KJoCss0k."],"url":"http://arxiv.org/abs/2308.14562v1"}
{"created":"2023-08-28 13:20:00","title":"Storage codes and recoverable systems on lines and grids","abstract":"A storage code is an assignment of symbols to the vertices of a connected graph $G(V,E)$ with the property that the value of each vertex is a function of the values of its neighbors, or more generally, of a certain neighborhood of the vertex in $G$. In this work we introduce a new construction method of storage codes, enabling one to construct new codes from known ones via an interleaving procedure driven by resolvable designs. We also study storage codes on $\\mathbb Z$ and ${\\mathbb Z}^2$ (lines and grids), finding closed-form expressions for the capacity of several one and two-dimensional systems depending on their recovery set, using connections between storage codes, graphs, anticodes, and difference-avoiding sets.","sentences":["A storage code is an assignment of symbols to the vertices of a connected graph $G(V,E)$ with the property that the value of each vertex is a function of the values of its neighbors, or more generally, of a certain neighborhood of the vertex in $G$.","In this work we introduce a new construction method of storage codes, enabling one to construct new codes from known ones via an interleaving procedure driven by resolvable designs.","We also study storage codes on $\\mathbb Z$ and ${\\mathbb Z}^2$ (lines and grids), finding closed-form expressions for the capacity of several one and two-dimensional systems depending on their recovery set, using connections between storage codes, graphs, anticodes, and difference-avoiding sets."],"url":"http://arxiv.org/abs/2308.14558v1"}
{"created":"2023-08-28 13:17:39","title":"Kernel Limit of Recurrent Neural Networks Trained on Ergodic Data Sequences","abstract":"Mathematical methods are developed to characterize the asymptotics of recurrent neural networks (RNN) as the number of hidden units, data samples in the sequence, hidden state updates, and training steps simultaneously grow to infinity. In the case of an RNN with a simplified weight matrix, we prove the convergence of the RNN to the solution of an infinite-dimensional ODE coupled with the fixed point of a random algebraic equation. The analysis requires addressing several challenges which are unique to RNNs. In typical mean-field applications (e.g., feedforward neural networks), discrete updates are of magnitude $\\mathcal{O}(\\frac{1}{N})$ and the number of updates is $\\mathcal{O}(N)$. Therefore, the system can be represented as an Euler approximation of an appropriate ODE/PDE, which it will converge to as $N \\rightarrow \\infty$. However, the RNN hidden layer updates are $\\mathcal{O}(1)$. Therefore, RNNs cannot be represented as a discretization of an ODE/PDE and standard mean-field techniques cannot be applied. Instead, we develop a fixed point analysis for the evolution of the RNN memory states, with convergence estimates in terms of the number of update steps and the number of hidden units. The RNN hidden layer is studied as a function in a Sobolev space, whose evolution is governed by the data sequence (a Markov chain), the parameter updates, and its dependence on the RNN hidden layer at the previous time step. Due to the strong correlation between updates, a Poisson equation must be used to bound the fluctuations of the RNN around its limit equation. These mathematical methods give rise to the neural tangent kernel (NTK) limits for RNNs trained on data sequences as the number of data samples and size of the neural network grow to infinity.","sentences":["Mathematical methods are developed to characterize the asymptotics of recurrent neural networks (RNN) as the number of hidden units, data samples in the sequence, hidden state updates, and training steps simultaneously grow to infinity.","In the case of an RNN with a simplified weight matrix, we prove the convergence of the RNN to the solution of an infinite-dimensional ODE coupled with the fixed point of a random algebraic equation.","The analysis requires addressing several challenges which are unique to RNNs.","In typical mean-field applications (e.g., feedforward neural networks), discrete updates are of magnitude $\\mathcal{O}(\\frac{1}{N})$ and the number of updates is $\\mathcal{O}(N)$. Therefore, the system can be represented as an Euler approximation of an appropriate ODE/PDE, which it will converge to as $N \\rightarrow \\infty$. However, the RNN hidden layer updates are $\\mathcal{O}(1)$. Therefore, RNNs cannot be represented as a discretization of an ODE/PDE and standard mean-field techniques cannot be applied.","Instead, we develop a fixed point analysis for the evolution of the RNN memory states, with convergence estimates in terms of the number of update steps and the number of hidden units.","The RNN hidden layer is studied as a function in a Sobolev space, whose evolution is governed by the data sequence (a Markov chain), the parameter updates, and its dependence on the RNN hidden layer at the previous time step.","Due to the strong correlation between updates, a Poisson equation must be used to bound the fluctuations of the RNN around its limit equation.","These mathematical methods give rise to the neural tangent kernel (NTK) limits for RNNs trained on data sequences as the number of data samples and size of the neural network grow to infinity."],"url":"http://arxiv.org/abs/2308.14555v1"}
{"created":"2023-08-28 13:11:05","title":"Face Presentation Attack Detection by Excavating Causal Clues and Adapting Embedding Statistics","abstract":"Recent face presentation attack detection (PAD) leverages domain adaptation (DA) and domain generalization (DG) techniques to address performance degradation on unknown domains. However, DA-based PAD methods require access to unlabeled target data, while most DG-based PAD solutions rely on a priori, i.e., known domain labels. Moreover, most DA-/DG-based methods are computationally intensive, demanding complex model architectures and/or multi-stage training processes. This paper proposes to model face PAD as a compound DG task from a causal perspective, linking it to model optimization. We excavate the causal factors hidden in the high-level representation via counterfactual intervention. Moreover, we introduce a class-guided MixStyle to enrich feature-level data distribution within classes instead of focusing on domain information. Both class-guided MixStyle and counterfactual intervention components introduce no extra trainable parameters and negligible computational resources. Extensive cross-dataset and analytic experiments demonstrate the effectiveness and efficiency of our method compared to state-of-the-art PADs. The implementation and the trained weights are publicly available.","sentences":["Recent face presentation attack detection (PAD) leverages domain adaptation (DA) and domain generalization (DG) techniques to address performance degradation on unknown domains.","However, DA-based PAD methods require access to unlabeled target data, while most DG-based PAD solutions rely on a priori, i.e., known domain labels.","Moreover, most DA-/DG-based methods are computationally intensive, demanding complex model architectures and/or multi-stage training processes.","This paper proposes to model face PAD as a compound DG task from a causal perspective, linking it to model optimization.","We excavate the causal factors hidden in the high-level representation via counterfactual intervention.","Moreover, we introduce a class-guided MixStyle to enrich feature-level data distribution within classes instead of focusing on domain information.","Both class-guided MixStyle and counterfactual intervention components introduce no extra trainable parameters and negligible computational resources.","Extensive cross-dataset and analytic experiments demonstrate the effectiveness and efficiency of our method compared to state-of-the-art PADs.","The implementation and the trained weights are publicly available."],"url":"http://arxiv.org/abs/2308.14551v1"}
