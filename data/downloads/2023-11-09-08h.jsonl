{"created":"2023-11-08 18:59:54","title":"Beyond Size: How Gradients Shape Pruning Decisions in Large Language Models","abstract":"Large Language Models (LLMs) with a billion or more parameters are prime targets for network pruning, which aims to reduce a portion of the network weights without compromising performance. Prior approaches such as Weights Magnitude, SparseGPT, and Wanda, either concentrated solely on weights or integrated weights with activations for sparsity. However, they overlooked the informative gradients derived from pretrained large language models. In this paper, we present a novel sparsity-centric pruning method for pretrained LLMs, termed Gradient-based Language Model Pruner (GBLM-Pruner). GBLM-Pruner leverages the first-order term of the Taylor expansion, operating in a training-free manner by harnessing properly normalized gradients from a few calibration samples to determine the importance pruning score, and substantially outperforms competitive counterparts like SparseGPT and Wanda in multiple benchmarks. Intriguing, after incorporating gradients, the unstructured pruning method tends to reveal some structural patterns post-pruning, which mirrors the geometric interdependence inherent in the LLMs' parameter structure. Additionally, GBLM-Pruner functions without any subsequent retraining or weight updates to maintain its simplicity as other counterparts. Extensive evaluations on LLaMA-1 and LLaMA-2 across various language benchmarks and perplexity show that GBLM-Pruner surpasses magnitude pruning, Wanda (weights+activations) and SparseGPT (weights+activations+weight update) by significant margins. Our code and models are available at https://github.com/RocktimJyotiDas/GBLM-Pruner.","sentences":["Large Language Models (LLMs) with a billion or more parameters are prime targets for network pruning, which aims to reduce a portion of the network weights without compromising performance.","Prior approaches such as Weights Magnitude, SparseGPT, and Wanda, either concentrated solely on weights or integrated weights with activations for sparsity.","However, they overlooked the informative gradients derived from pretrained large language models.","In this paper, we present a novel sparsity-centric pruning method for pretrained LLMs, termed Gradient-based Language Model Pruner (GBLM-Pruner).","GBLM-Pruner leverages the first-order term of the Taylor expansion, operating in a training-free manner by harnessing properly normalized gradients from a few calibration samples to determine the importance pruning score, and substantially outperforms competitive counterparts like SparseGPT and Wanda in multiple benchmarks.","Intriguing, after incorporating gradients, the unstructured pruning method tends to reveal some structural patterns post-pruning, which mirrors the geometric interdependence inherent in the LLMs' parameter structure.","Additionally, GBLM-Pruner functions without any subsequent retraining or weight updates to maintain its simplicity as other counterparts.","Extensive evaluations on LLaMA-1 and LLaMA-2 across various language benchmarks and perplexity show that GBLM-Pruner surpasses magnitude pruning, Wanda (weights+activations) and SparseGPT (weights+activations+weight update) by significant margins.","Our code and models are available at https://github.com/RocktimJyotiDas/GBLM-Pruner."],"url":"http://arxiv.org/abs/2311.04902v1"}
{"created":"2023-11-08 18:59:05","title":"GENOME: GenerativE Neuro-symbOlic visual reasoning by growing and reusing ModulEs","abstract":"Recent works have shown that Large Language Models (LLMs) could empower traditional neuro-symbolic models via programming capabilities to translate language into module descriptions, thus achieving strong visual reasoning results while maintaining the model's transparency and efficiency. However, these models usually exhaustively generate the entire code snippet given each new instance of a task, which is extremely ineffective. We propose generative neuro-symbolic visual reasoning by growing and reusing modules. Specifically, our model consists of three unique stages, module initialization, module generation, and module execution. First, given a vision-language task, we adopt LLMs to examine whether we could reuse and grow over established modules to handle this new task. If not, we initialize a new module needed by the task and specify the inputs and outputs of this new module. After that, the new module is created by querying LLMs to generate corresponding code snippets that match the requirements. In order to get a better sense of the new module's ability, we treat few-shot training examples as test cases to see if our new module could pass these cases. If yes, the new module is added to the module library for future reuse. Finally, we evaluate the performance of our model on the testing set by executing the parsed programs with the newly made visual modules to get the results. We find the proposed model possesses several advantages. First, it performs competitively on standard tasks like visual question answering and referring expression comprehension; Second, the modules learned from one task can be seamlessly transferred to new tasks; Last but not least, it is able to adapt to new visual reasoning tasks by observing a few training examples and reusing modules.","sentences":["Recent works have shown that Large Language Models (LLMs) could empower traditional neuro-symbolic models via programming capabilities to translate language into module descriptions, thus achieving strong visual reasoning results while maintaining the model's transparency and efficiency.","However, these models usually exhaustively generate the entire code snippet given each new instance of a task, which is extremely ineffective.","We propose generative neuro-symbolic visual reasoning by growing and reusing modules.","Specifically, our model consists of three unique stages, module initialization, module generation, and module execution.","First, given a vision-language task, we adopt LLMs to examine whether we could reuse and grow over established modules to handle this new task.","If not, we initialize a new module needed by the task and specify the inputs and outputs of this new module.","After that, the new module is created by querying LLMs to generate corresponding code snippets that match the requirements.","In order to get a better sense of the new module's ability, we treat few-shot training examples as test cases to see if our new module could pass these cases.","If yes, the new module is added to the module library for future reuse.","Finally, we evaluate the performance of our model on the testing set by executing the parsed programs with the newly made visual modules to get the results.","We find the proposed model possesses several advantages.","First, it performs competitively on standard tasks like visual question answering and referring expression comprehension; Second, the modules learned from one task can be seamlessly transferred to new tasks; Last but not least, it is able to adapt to new visual reasoning tasks by observing a few training examples and reusing modules."],"url":"http://arxiv.org/abs/2311.04901v1"}
{"created":"2023-11-08 18:58:43","title":"How Abstract Is Linguistic Generalization in Large Language Models? Experiments with Argument Structure","abstract":"Language models are typically evaluated on their success at predicting the distribution of specific words in specific contexts. Yet linguistic knowledge also encodes relationships between contexts, allowing inferences between word distributions. We investigate the degree to which pre-trained Transformer-based large language models (LLMs) represent such relationships, focusing on the domain of argument structure. We find that LLMs perform well in generalizing the distribution of a novel noun argument between related contexts that were seen during pre-training (e.g., the active object and passive subject of the verb spray), succeeding by making use of the semantically-organized structure of the embedding space for word embeddings. However, LLMs fail at generalizations between related contexts that have not been observed during pre-training, but which instantiate more abstract, but well-attested structural generalizations (e.g., between the active object and passive subject of an arbitrary verb). Instead, in this case, LLMs show a bias to generalize based on linear order. This finding points to a limitation with current models and points to a reason for which their training is data-intensive.s reported here are available at https://github.com/clay-lab/structural-alternations.","sentences":["Language models are typically evaluated on their success at predicting the distribution of specific words in specific contexts.","Yet linguistic knowledge also encodes relationships between contexts, allowing inferences between word distributions.","We investigate the degree to which pre-trained Transformer-based large language models (LLMs) represent such relationships, focusing on the domain of argument structure.","We find that LLMs perform well in generalizing the distribution of a novel noun argument between related contexts that were seen during pre-training (e.g., the active object and passive subject of the verb spray), succeeding by making use of the semantically-organized structure of the embedding space for word embeddings.","However, LLMs fail at generalizations between related contexts that have not been observed during pre-training, but which instantiate more abstract, but well-attested structural generalizations (e.g., between the active object and passive subject of an arbitrary verb).","Instead, in this case, LLMs show a bias to generalize based on linear order.","This finding points to a limitation with current models and points to a reason for which their training is data-intensive.s reported here are available at https://github.com/clay-lab/structural-alternations."],"url":"http://arxiv.org/abs/2311.04900v1"}
{"created":"2023-11-08 18:57:19","title":"Two Complementary Perspectives to Continual Learning: Ask Not Only What to Optimize, But Also How","abstract":"Recent years have seen considerable progress in the continual training of deep neural networks, predominantly thanks to approaches that add replay or regularization terms to the loss function to approximate the joint loss over all tasks so far. However, we show that even with a perfect approximation to the joint loss, these approaches still suffer from temporary but substantial forgetting when starting to train on a new task. Motivated by this 'stability gap', we propose that continual learning strategies should focus not only on the optimization objective, but also on the way this objective is optimized. While there is some continual learning work that alters the optimization trajectory (e.g., using gradient projection techniques), this line of research is positioned as alternative to improving the optimization objective, while we argue it should be complementary. To evaluate the merits of our proposition, we plan to combine replay-approximated joint objectives with gradient projection-based optimization routines to test whether the addition of the latter provides benefits in terms of (1) alleviating the stability gap, (2) increasing the learning efficiency and (3) improving the final learning outcome.","sentences":["Recent years have seen considerable progress in the continual training of deep neural networks, predominantly thanks to approaches that add replay or regularization terms to the loss function to approximate the joint loss over all tasks so far.","However, we show that even with a perfect approximation to the joint loss, these approaches still suffer from temporary but substantial forgetting when starting to train on a new task.","Motivated by this 'stability gap', we propose that continual learning strategies should focus not only on the optimization objective, but also on the way this objective is optimized.","While there is some continual learning work that alters the optimization trajectory (e.g., using gradient projection techniques), this line of research is positioned as alternative to improving the optimization objective, while we argue it should be complementary.","To evaluate the merits of our proposition, we plan to combine replay-approximated joint objectives with gradient projection-based optimization routines to test whether the addition of the latter provides benefits in terms of (1) alleviating the stability gap, (2) increasing the learning efficiency and (3) improving the final learning outcome."],"url":"http://arxiv.org/abs/2311.04898v1"}
{"created":"2023-11-08 18:56:35","title":"Future Lens: Anticipating Subsequent Tokens from a Single Hidden State","abstract":"We conjecture that hidden state vectors corresponding to individual input tokens encode information sufficient to accurately predict several tokens ahead. More concretely, in this paper we ask: Given a hidden (internal) representation of a single token at position $t$ in an input, can we reliably anticipate the tokens that will appear at positions $\\geq t + 2$? To test this, we measure linear approximation and causal intervention methods in GPT-J-6B to evaluate the degree to which individual hidden states in the network contain signal rich enough to predict future hidden states and, ultimately, token outputs. We find that, at some layers, we can approximate a model's output with more than 48% accuracy with respect to its prediction of subsequent tokens through a single hidden state. Finally we present a \"Future Lens\" visualization that uses these methods to create a new view of transformer states.","sentences":["We conjecture that hidden state vectors corresponding to individual input tokens encode information sufficient to accurately predict several tokens ahead.","More concretely, in this paper we ask: Given a hidden (internal) representation of a single token at position $t$ in an input, can we reliably anticipate the tokens that will appear at positions $\\geq t + 2$?","To test this, we measure linear approximation and causal intervention methods in GPT-J-6B to evaluate the degree to which individual hidden states in the network contain signal rich enough to predict future hidden states and, ultimately, token outputs.","We find that, at some layers, we can approximate a model's output with more than 48% accuracy with respect to its prediction of subsequent tokens through a single hidden state.","Finally we present a \"Future Lens\" visualization that uses these methods to create a new view of transformer states."],"url":"http://arxiv.org/abs/2311.04897v1"}
{"created":"2023-11-08 18:56:29","title":"Optimized measurements of chaotic dynamical systems via the information bottleneck","abstract":"Deterministic chaos permits a precise notion of a \"perfect measurement\" as one that, when obtained repeatedly, captures all of the information created by the system's evolution with minimal redundancy. Finding an optimal measurement is challenging, and has generally required intimate knowledge of the dynamics in the few cases where it has been done. We establish an equivalence between a perfect measurement and a variant of the information bottleneck. As a consequence, we can employ machine learning to optimize measurement processes that efficiently extract information from trajectory data. We obtain approximately optimal measurements for multiple chaotic maps and lay the necessary groundwork for efficient information extraction from general time series.","sentences":["Deterministic chaos permits a precise notion of a \"perfect measurement\" as one that, when obtained repeatedly, captures all of the information created by the system's evolution with minimal redundancy.","Finding an optimal measurement is challenging, and has generally required intimate knowledge of the dynamics in the few cases where it has been done.","We establish an equivalence between a perfect measurement and a variant of the information bottleneck.","As a consequence, we can employ machine learning to optimize measurement processes that efficiently extract information from trajectory data.","We obtain approximately optimal measurements for multiple chaotic maps and lay the necessary groundwork for efficient information extraction from general time series."],"url":"http://arxiv.org/abs/2311.04896v1"}
{"created":"2023-11-08 18:55:33","title":"The Monadic Theory of Toric Words","abstract":"For which unary predicates $P_1, \\ldots, P_m$ is the MSO theory of the structure $\\langle \\mathbb{N}; <, P_1, \\ldots, P_m \\rangle$ decidable? We survey the state of the art, leading us to investigate combinatorial properties of almost-periodic, morphic, and toric words. In doing so, we show that if each $P_i$ can be generated by a toric dynamical system of a certain kind, then the attendant MSO theory is decidable.","sentences":["For which unary predicates $P_1, \\ldots, P_m$ is the MSO theory of the structure $\\langle \\mathbb{N}; <, P_1, \\ldots, P_m \\rangle$ decidable?","We survey the state of the art, leading us to investigate combinatorial properties of almost-periodic, morphic, and toric words.","In doing so, we show that if each $P_i$ can be generated by a toric dynamical system of a certain kind, then the attendant MSO theory is decidable."],"url":"http://arxiv.org/abs/2311.04895v1"}
{"created":"2023-11-08 18:55:24","title":"DAMEX: Dataset-aware Mixture-of-Experts for visual understanding of mixture-of-datasets","abstract":"Construction of a universal detector poses a crucial question: How can we most effectively train a model on a large mixture of datasets? The answer lies in learning dataset-specific features and ensembling their knowledge but do all this in a single model. Previous methods achieve this by having separate detection heads on a common backbone but that results in a significant increase in parameters. In this work, we present Mixture-of-Experts as a solution, highlighting that MoEs are much more than a scalability tool. We propose Dataset-Aware Mixture-of-Experts, DAMEX where we train the experts to become an `expert' of a dataset by learning to route each dataset tokens to its mapped expert. Experiments on Universal Object-Detection Benchmark show that we outperform the existing state-of-the-art by average +10.2 AP score and improve over our non-MoE baseline by average +2.0 AP score. We also observe consistent gains while mixing datasets with (1) limited availability, (2) disparate domains and (3) divergent label sets. Further, we qualitatively show that DAMEX is robust against expert representation collapse.","sentences":["Construction of a universal detector poses a crucial question: How can we most effectively train a model on a large mixture of datasets?","The answer lies in learning dataset-specific features and ensembling their knowledge but do all this in a single model.","Previous methods achieve this by having separate detection heads on a common backbone but that results in a significant increase in parameters.","In this work, we present Mixture-of-Experts as a solution, highlighting that MoEs are much more than a scalability tool.","We propose Dataset-Aware Mixture-of-Experts, DAMEX where we train the experts to become an `expert' of a dataset by learning to route each dataset tokens to its mapped expert.","Experiments on Universal Object-Detection Benchmark show that we outperform the existing state-of-the-art by average +10.2 AP score and improve over our non-MoE baseline by average +2.0 AP score.","We also observe consistent gains while mixing datasets with (1) limited availability, (2) disparate domains and (3) divergent label sets.","Further, we qualitatively show that DAMEX is robust against expert representation collapse."],"url":"http://arxiv.org/abs/2311.04894v1"}
{"created":"2023-11-08 18:52:17","title":"Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs","abstract":"Recent works have showcased the ability of large-scale language models (LLMs) to embody diverse personas in their responses, exemplified by prompts like 'You are Yoda. Explain the Theory of Relativity.' While this ability allows personalization of LLMs and enables human behavior simulation, its effect on LLMs' capabilities remain unclear. To fill this gap, we present the first extensive study of the unintended side-effects of persona assignment on the ability of LLMs, specifically ChatGPT, to perform basic reasoning tasks. Our study covers 24 reasoning datasets and 16 diverse personas spanning 5 socio-demographic groups: race, gender, religion, disability, and political affiliation. Our experiments unveil that ChatGPT carries deep rooted bias against various socio-demographics underneath a veneer of fairness. While it overtly rejects stereotypes when explicitly asked ('Are Black people less skilled at mathematics?'), it manifests stereotypical and often erroneous presumptions when prompted to answer questions while taking on a persona. These can be observed as abstentions in the model responses, e.g., 'As a Black person, I am unable to answer this question as it requires math knowledge', and generally result in a substantial drop in performance on reasoning tasks. We find that this inherent deep bias is ubiquitous - 80% of our personas demonstrated bias; it is significant - certain datasets had relative drops in performance of 70%+; and can be especially harmful for certain groups - certain personas had stat. sign. drops on more than 80% of the datasets. Further analysis shows that these persona-induced errors can be hard-to-discern and hard-to-avoid. Our findings serve as a cautionary tale that the practice of assigning personas to LLMs - a trend on the rise - can surface their deep-rooted biases and have unforeseeable and detrimental side-effects.","sentences":["Recent works have showcased the ability of large-scale language models (LLMs) to embody diverse personas in their responses, exemplified by prompts like 'You are Yoda.","Explain the Theory of Relativity.'","While this ability allows personalization of LLMs and enables human behavior simulation, its effect on LLMs' capabilities remain unclear.","To fill this gap, we present the first extensive study of the unintended side-effects of persona assignment on the ability of LLMs, specifically ChatGPT, to perform basic reasoning tasks.","Our study covers 24 reasoning datasets and 16 diverse personas spanning 5 socio-demographic groups: race, gender, religion, disability, and political affiliation.","Our experiments unveil that ChatGPT carries deep rooted bias against various socio-demographics underneath a veneer of fairness.","While it overtly rejects stereotypes when explicitly asked ('Are Black people less skilled at mathematics?'), it manifests stereotypical and often erroneous presumptions when prompted to answer questions while taking on a persona.","These can be observed as abstentions in the model responses, e.g., 'As a Black person, I am unable to answer this question as it requires math knowledge', and generally result in a substantial drop in performance on reasoning tasks.","We find that this inherent deep bias is ubiquitous - 80% of our personas demonstrated bias; it is significant - certain datasets had relative drops in performance of 70%+; and can be especially harmful for certain groups - certain personas had stat.","sign.","drops on more than 80% of the datasets.","Further analysis shows that these persona-induced errors can be hard-to-discern and hard-to-avoid.","Our findings serve as a cautionary tale that the practice of assigning personas to LLMs - a trend on the rise - can surface their deep-rooted biases and have unforeseeable and detrimental side-effects."],"url":"http://arxiv.org/abs/2311.04892v1"}
{"created":"2023-11-08 18:50:04","title":"Towards Few-Annotation Learning in Computer Vision: Application to Image Classification and Object Detection tasks","abstract":"In this thesis, we develop theoretical, algorithmic and experimental contributions for Machine Learning with limited labels, and more specifically for the tasks of Image Classification and Object Detection in Computer Vision. In a first contribution, we are interested in bridging the gap between theory and practice for popular Meta-Learning algorithms used in Few-Shot Classification. We make connections to Multi-Task Representation Learning, which benefits from solid theoretical foundations, to verify the best conditions for a more efficient meta-learning. Then, to leverage unlabeled data when training object detectors based on the Transformer architecture, we propose both an unsupervised pretraining and a semi-supervised learning method in two other separate contributions. For pretraining, we improve Contrastive Learning for object detectors by introducing the localization information. Finally, our semi-supervised method is the first tailored to transformer-based detectors.","sentences":["In this thesis, we develop theoretical, algorithmic and experimental contributions for Machine Learning with limited labels, and more specifically for the tasks of Image Classification and Object Detection in Computer Vision.","In a first contribution, we are interested in bridging the gap between theory and practice for popular Meta-Learning algorithms used in Few-Shot Classification.","We make connections to Multi-Task Representation Learning, which benefits from solid theoretical foundations, to verify the best conditions for a more efficient meta-learning.","Then, to leverage unlabeled data when training object detectors based on the Transformer architecture, we propose both an unsupervised pretraining and a semi-supervised learning method in two other separate contributions.","For pretraining, we improve Contrastive Learning for object detectors by introducing the localization information.","Finally, our semi-supervised method is the first tailored to transformer-based detectors."],"url":"http://arxiv.org/abs/2311.04888v1"}
{"created":"2023-11-08 18:46:39","title":"AutoChip: Automating HDL Generation Using LLM Feedback","abstract":"Traditionally, designs are written in Verilog hardware description language (HDL) and debugged by hardware engineers. While this approach is effective, it is time-consuming and error-prone for complex designs. Large language models (LLMs) are promising in automating HDL code generation. LLMs are trained on massive datasets of text and code, and they can learn to generate code that compiles and is functionally accurate. We aim to evaluate the ability of LLMs to generate functionally correct HDL models. We build AutoChip by combining the interactive capabilities of LLMs and the output from Verilog simulations to generate Verilog modules. We start with a design prompt for a module and the context from compilation errors and debugging messages, which highlight differences between the expected and actual outputs. This ensures that accurate Verilog code can be generated without human intervention. We evaluate AutoChip using problem sets from HDLBits. We conduct a comprehensive analysis of the AutoChip using several LLMs and problem categories. The results show that incorporating context from compiler tools, such as Icarus Verilog, improves the effectiveness, yielding 24.20% more accurate Verilog. We release our evaluation scripts and datasets as open-source contributions at the following link https://github.com/shailja-thakur/AutoChip.","sentences":["Traditionally, designs are written in Verilog hardware description language (HDL) and debugged by hardware engineers.","While this approach is effective, it is time-consuming and error-prone for complex designs.","Large language models (LLMs) are promising in automating HDL code generation.","LLMs are trained on massive datasets of text and code, and they can learn to generate code that compiles and is functionally accurate.","We aim to evaluate the ability of LLMs to generate functionally correct HDL models.","We build AutoChip by combining the interactive capabilities of LLMs and the output from Verilog simulations to generate Verilog modules.","We start with a design prompt for a module and the context from compilation errors and debugging messages, which highlight differences between the expected and actual outputs.","This ensures that accurate Verilog code can be generated without human intervention.","We evaluate AutoChip using problem sets from HDLBits.","We conduct a comprehensive analysis of the AutoChip using several LLMs and problem categories.","The results show that incorporating context from compiler tools, such as Icarus Verilog, improves the effectiveness, yielding 24.20% more accurate Verilog.","We release our evaluation scripts and datasets as open-source contributions at the following link https://github.com/shailja-thakur/AutoChip."],"url":"http://arxiv.org/abs/2311.04887v1"}
{"created":"2023-11-08 18:46:32","title":"SEMQA: Semi-Extractive Multi-Source Question Answering","abstract":"Recently proposed long-form question answering (QA) systems, supported by large language models (LLMs), have shown promising capabilities. Yet, attributing and verifying their generated abstractive answers can be difficult, and automatically evaluating their accuracy remains an ongoing challenge.   In this work, we introduce a new QA task for answering multi-answer questions by summarizing multiple diverse sources in a semi-extractive fashion. Specifically, Semi-extractive Multi-source QA (SEMQA) requires models to output a comprehensive answer, while mixing factual quoted spans -- copied verbatim from given input sources -- and non-factual free-text connectors that glue these spans together into a single cohesive passage. This setting bridges the gap between the outputs of well-grounded but constrained extractive QA systems and more fluent but harder to attribute fully abstractive answers. Particularly, it enables a new mode for language models that leverages their advanced language generation capabilities, while also producing fine in-line attributions by-design that are easy to verify, interpret, and evaluate.   To study this task, we create the first dataset of this kind, QuoteSum, with human-written semi-extractive answers to natural and generated questions, and define text-based evaluation metrics. Experimenting with several LLMs in various settings, we find this task to be surprisingly challenging, demonstrating the importance of QuoteSum for developing and studying such consolidation capabilities.","sentences":["Recently proposed long-form question answering (QA) systems, supported by large language models (LLMs), have shown promising capabilities.","Yet, attributing and verifying their generated abstractive answers can be difficult, and automatically evaluating their accuracy remains an ongoing challenge.   ","In this work, we introduce a new QA task for answering multi-answer questions by summarizing multiple diverse sources in a semi-extractive fashion.","Specifically, Semi-extractive Multi-source QA (SEMQA) requires models to output a comprehensive answer, while mixing factual quoted spans -- copied verbatim from given input sources -- and non-factual free-text connectors that glue these spans together into a single cohesive passage.","This setting bridges the gap between the outputs of well-grounded but constrained extractive QA systems and more fluent but harder to attribute fully abstractive answers.","Particularly, it enables a new mode for language models that leverages their advanced language generation capabilities, while also producing fine in-line attributions by-design that are easy to verify, interpret, and evaluate.   ","To study this task, we create the first dataset of this kind, QuoteSum, with human-written semi-extractive answers to natural and generated questions, and define text-based evaluation metrics.","Experimenting with several LLMs in various settings, we find this task to be surprisingly challenging, demonstrating the importance of QuoteSum for developing and studying such consolidation capabilities."],"url":"http://arxiv.org/abs/2311.04886v1"}
{"created":"2023-11-08 18:44:47","title":"Profiling Irony & Stereotype: Exploring Sentiment, Topic, and Lexical Features","abstract":"Social media has become a very popular source of information. With this popularity comes an interest in systems that can classify the information produced. This study tries to create such a system detecting irony in Twitter users. Recent work emphasize the importance of lexical features, sentiment features and the contrast herein along with TF-IDF and topic models. Based on a thorough feature selection process, the resulting model contains specific sub-features from these areas. Our model reaches an F1-score of 0.84, which is above the baseline. We find that lexical features, especially TF-IDF, contribute the most to our models while sentiment and topic modeling features contribute less to overall performance. Lastly, we highlight multiple interesting and important paths for further exploration.","sentences":["Social media has become a very popular source of information.","With this popularity comes an interest in systems that can classify the information produced.","This study tries to create such a system detecting irony in Twitter users.","Recent work emphasize the importance of lexical features, sentiment features and the contrast herein along with TF-IDF and topic models.","Based on a thorough feature selection process, the resulting model contains specific sub-features from these areas.","Our model reaches an F1-score of 0.84, which is above the baseline.","We find that lexical features, especially TF-IDF, contribute the most to our models while sentiment and topic modeling features contribute less to overall performance.","Lastly, we highlight multiple interesting and important paths for further exploration."],"url":"http://arxiv.org/abs/2311.04885v1"}
{"created":"2023-11-08 18:36:54","title":"Joint Transmit Signal and Beamforming Design for Integrated Sensing and Power Transfer Systems","abstract":"Integrating different functionalities, conventionally implemented as dedicated systems, into a single platform allows utilising the available resources more efficiently. We consider an integrated sensing and power transfer (ISAPT) system and propose the joint optimisation of the rectangular pulse-shaped transmit signal and the beamforming design to combine sensing and wireless power transfer (WPT) functionalities efficiently. In contrast to prior works, we adopt an accurate non-linear circuit-based energy harvesting (EH) model. We formulate a non-convex optimisation problem for a general number of EH receivers and a single sensing target (ST) and solve the problem via a grid search over the pulse duration, semidefinite relaxation (SDR), and successive convex approximation (SCA). The average harvested power is shown to monotonically increase with the pulse duration when the average transmit power budget is large. We discuss the trade-off between sensing performance and power transfer of the ISAPT system. The proposed approach significantly outperforms a heuristic baseline scheme based on a linear EH model, which linearly combines energy beamforming with the beamsteering vector in the direction to the ST as its transmit strategy.","sentences":["Integrating different functionalities, conventionally implemented as dedicated systems, into a single platform allows utilising the available resources more efficiently.","We consider an integrated sensing and power transfer (ISAPT) system and propose the joint optimisation of the rectangular pulse-shaped transmit signal and the beamforming design to combine sensing and wireless power transfer (WPT) functionalities efficiently.","In contrast to prior works, we adopt an accurate non-linear circuit-based energy harvesting (EH) model.","We formulate a non-convex optimisation problem for a general number of EH receivers and a single sensing target (ST) and solve the problem via a grid search over the pulse duration, semidefinite relaxation (SDR), and successive convex approximation (SCA).","The average harvested power is shown to monotonically increase with the pulse duration when the average transmit power budget is large.","We discuss the trade-off between sensing performance and power transfer of the ISAPT system.","The proposed approach significantly outperforms a heuristic baseline scheme based on a linear EH model, which linearly combines energy beamforming with the beamsteering vector in the direction to the ST as its transmit strategy."],"url":"http://arxiv.org/abs/2311.04881v1"}
{"created":"2023-11-08 18:33:06","title":"LongQLoRA: Efficient and Effective Method to Extend Context Length of Large Language Models","abstract":"We present LongQLoRA, an efficient and effective method to extend context length of large language models with less training resources. LongQLoRA combines the advantages of Position Interpolation, QLoRA and Shift Short Attention of LongLoRA. With a single 32GB V100 GPU, LongQLoRA can extend the context length of LLaMA2 7B and 13B from 4096 to 8192 and even to 12k within 1000 finetuning steps. LongQLoRA achieves competitive perplexity performance on PG19 and Proof-pile datasets, our model outperforms LongLoRA and is very close to MPT-7B-8K within the evaluation context length of 8192. We collect and build 39k long instruction data to extend context length of Vicuna-13B from 4096 to 8192 and achieve good performance both in long and short context generation task. We also do some ablation experiments to study the effect of LoRA rank, finetuning steps and attention patterns in inference.The model weights, training data and code are avaliable at https://github.com/yangjianxin1/LongQLoRA.","sentences":["We present LongQLoRA, an efficient and effective method to extend context length of large language models with less training resources.","LongQLoRA combines the advantages of Position Interpolation, QLoRA and Shift Short Attention of LongLoRA.","With a single 32GB V100 GPU, LongQLoRA can extend the context length of LLaMA2 7B and 13B from 4096 to 8192 and even to 12k within 1000 finetuning steps.","LongQLoRA achieves competitive perplexity performance on PG19 and Proof-pile datasets, our model outperforms LongLoRA and is very close to MPT-7B-8K within the evaluation context length of 8192.","We collect and build 39k long instruction data to extend context length of Vicuna-13B from 4096 to 8192 and achieve good performance both in long and short context generation task.","We also do some ablation experiments to study the effect of LoRA rank, finetuning steps and attention patterns in inference.","The model weights, training data and code are avaliable at https://github.com/yangjianxin1/LongQLoRA."],"url":"http://arxiv.org/abs/2311.04879v1"}
{"created":"2023-11-08 18:22:42","title":"Fusionize++: Improving Serverless Application Performance Using Dynamic Task Inlining and Infrastructure Optimization","abstract":"The Function-as-a-Service (FaaS) execution model increases developer productivity by removing operational concerns such as managing hardware or software runtimes. Developers, however, still need to partition their applications into FaaS functions, which is error-prone and complex: Encapsulating only the smallest logical unit of an application as a FaaS function maximizes flexibility and reusability. Yet, it also leads to invocation overheads, additional cold starts, and may increase cost due to double billing during synchronous invocations. Conversely, deploying an entire application as a single FaaS function avoids these overheads but decreases flexibility. In this paper we present Fusionize, a framework that automates optimizing for this trade-off by automatically fusing application code into an optimized multi-function composition. Developers only need to write fine-grained application code following the serverless model, while Fusionize automatically fuses different parts of the application into FaaS functions, manages their interactions, and configures the underlying infrastructure. At runtime, it monitors application performance and adapts it to minimize request-response latency and costs. Real-world use cases show that Fusionize can improve the deployment artifacts of the application, reducing both median request-response latency and cost of an example IoT application by more than 35%.","sentences":["The Function-as-a-Service (FaaS) execution model increases developer productivity by removing operational concerns such as managing hardware or software runtimes.","Developers, however, still need to partition their applications into FaaS functions, which is error-prone and complex: Encapsulating only the smallest logical unit of an application as a FaaS function maximizes flexibility and reusability.","Yet, it also leads to invocation overheads, additional cold starts, and may increase cost due to double billing during synchronous invocations.","Conversely, deploying an entire application as a single FaaS function avoids these overheads but decreases flexibility.","In this paper we present Fusionize, a framework that automates optimizing for this trade-off by automatically fusing application code into an optimized multi-function composition.","Developers only need to write fine-grained application code following the serverless model, while Fusionize automatically fuses different parts of the application into FaaS functions, manages their interactions, and configures the underlying infrastructure.","At runtime, it monitors application performance and adapts it to minimize request-response latency and costs.","Real-world use cases show that Fusionize can improve the deployment artifacts of the application, reducing both median request-response latency and cost of an example IoT application by more than 35%."],"url":"http://arxiv.org/abs/2311.04875v1"}
{"created":"2023-11-08 18:21:14","title":"A Framework for Programmability in Digital Currency","abstract":"Programmable money, enabled by digital currencies, facilitates outcomes beyond simple payments by allowing users to attach conditions to the movement of funds through code. However, there is a lack of clarity on defining programmable money, where programmability can be implemented, and the resulting tradeoffs. This paper provides a definition of programmable money with four key components: a format for representing value, a set of programmable instructions, an execution environment providing a coherence guarantee, and rules around permissioning. We discuss programmability primitives, categorizing them into levels based on expressiveness. We outline four locations programmability could be offered - hardcoded into system rules, via client-supplied programs/smart contracts, in client code, or via intermediaries - analyzing benefits and risks of each. For policymakers evaluating central bank digital currencies, we recommend considering these aspects holistically and their interplay with regulation in system design. Our framework and vocabulary enable more nuanced analysis of implementing programmability.","sentences":["Programmable money, enabled by digital currencies, facilitates outcomes beyond simple payments by allowing users to attach conditions to the movement of funds through code.","However, there is a lack of clarity on defining programmable money, where programmability can be implemented, and the resulting tradeoffs.","This paper provides a definition of programmable money with four key components: a format for representing value, a set of programmable instructions, an execution environment providing a coherence guarantee, and rules around permissioning.","We discuss programmability primitives, categorizing them into levels based on expressiveness.","We outline four locations programmability could be offered - hardcoded into system rules, via client-supplied programs/smart contracts, in client code, or via intermediaries - analyzing benefits and risks of each.","For policymakers evaluating central bank digital currencies, we recommend considering these aspects holistically and their interplay with regulation in system design.","Our framework and vocabulary enable more nuanced analysis of implementing programmability."],"url":"http://arxiv.org/abs/2311.04874v1"}
{"created":"2023-11-08 18:19:45","title":"Computing with Residue Numbers in High-Dimensional Representation","abstract":"We introduce Residue Hyperdimensional Computing, a computing framework that unifies residue number systems with an algebra defined over random, high-dimensional vectors. We show how residue numbers can be represented as high-dimensional vectors in a manner that allows algebraic operations to be performed with component-wise, parallelizable operations on the vector elements. The resulting framework, when combined with an efficient method for factorizing high-dimensional vectors, can represent and operate on numerical values over a large dynamic range using vastly fewer resources than previous methods, and it exhibits impressive robustness to noise. We demonstrate the potential for this framework to solve computationally difficult problems in visual perception and combinatorial optimization, showing improvement over baseline methods. More broadly, the framework provides a possible account for the computational operations of grid cells in the brain, and it suggests new machine learning architectures for representing and manipulating numerical data.","sentences":["We introduce Residue Hyperdimensional Computing, a computing framework that unifies residue number systems with an algebra defined over random, high-dimensional vectors.","We show how residue numbers can be represented as high-dimensional vectors in a manner that allows algebraic operations to be performed with component-wise, parallelizable operations on the vector elements.","The resulting framework, when combined with an efficient method for factorizing high-dimensional vectors, can represent and operate on numerical values over a large dynamic range using vastly fewer resources than previous methods, and it exhibits impressive robustness to noise.","We demonstrate the potential for this framework to solve computationally difficult problems in visual perception and combinatorial optimization, showing improvement over baseline methods.","More broadly, the framework provides a possible account for the computational operations of grid cells in the brain, and it suggests new machine learning architectures for representing and manipulating numerical data."],"url":"http://arxiv.org/abs/2311.04872v1"}
{"created":"2023-11-08 18:05:30","title":"Computing the $5$-Edge-Connected Components in Linear Time","abstract":"We provide a deterministic algorithm for computing the $5$-edge-connected components of an undirected multigraph in linear time. There were probably good indications that this computation can be performed in linear time, but no such algorithm was actually known prior to this work. Thus, our paper answers a theoretical question, and sheds light on the possibility that a solution may exist for general $k$. A key component in our algorithm is an oracle for answering connectivity queries for pairs of vertices in the presence of at most four edge-failures. Specifically, the oracle has size $O(n)$, it can be constructed in linear time, and it answers connectivity queries in the presence of at most four edge-failures in worst-case constant time, where $n$ denotes the number of vertices of the graph. We note that this is a result of independent interest. Our paper can be considered as a follow-up of recent work on computing the $4$-edge-connected components in linear time. However, in dealing with the computation of the $5$-edge-connected components, we are faced with unique challenges that do not appear when dealing with lower connectivity. The problem is that the $4$-edge cuts in $3$-edge-connected graphs are entangled in various complicated ways, that make it difficult to organize them in a compact way. Here we provide a novel analysis of those cuts, that reveals the existence of various interesting structures. These can be exploited so that we can disentangle and collect only those cuts that are essential in computing the $5$-edge-connected components. This analysis may provide a clue for a general solution for the $k$-edge-connected components, or other related graph connectivity problems.","sentences":["We provide a deterministic algorithm for computing the $5$-edge-connected components of an undirected multigraph in linear time.","There were probably good indications that this computation can be performed in linear time, but no such algorithm was actually known prior to this work.","Thus, our paper answers a theoretical question, and sheds light on the possibility that a solution may exist for general $k$. A key component in our algorithm is an oracle for answering connectivity queries for pairs of vertices in the presence of at most four edge-failures.","Specifically, the oracle has size $O(n)$, it can be constructed in linear time, and it answers connectivity queries in the presence of at most four edge-failures in worst-case constant time, where $n$ denotes the number of vertices of the graph.","We note that this is a result of independent interest.","Our paper can be considered as a follow-up of recent work on computing the $4$-edge-connected components in linear time.","However, in dealing with the computation of the $5$-edge-connected components, we are faced with unique challenges that do not appear when dealing with lower connectivity.","The problem is that the $4$-edge cuts in $3$-edge-connected graphs are entangled in various complicated ways, that make it difficult to organize them in a compact way.","Here we provide a novel analysis of those cuts, that reveals the existence of various interesting structures.","These can be exploited so that we can disentangle and collect only those cuts that are essential in computing the $5$-edge-connected components.","This analysis may provide a clue for a general solution for the $k$-edge-connected components, or other related graph connectivity problems."],"url":"http://arxiv.org/abs/2311.04865v1"}
{"created":"2023-11-08 17:56:56","title":"Sandi: A System for Accountability and Applications in Direct Communication (Extended Abstract)","abstract":"Reputation systems guide our decision making both in life and work: which restaurant to eat at, which vendor to buy from, which software dependencies to use, and who or what to trust. These systems are often based on old ideas and are failing in the face of modern threats. Fraudsters have found ways to manipulate them, undermining their integrity and utility. Generative AI adds to the problem by enabling the creation of real-looking fake narratives at scale, creating a false sense of consensus. Meanwhile, the need for reliable reputation concepts is more important than ever, as wrong decisions lead to increasingly severe outcomes: wasted time, poor service, and a feeling of injustice at best, fraud, identity theft, and ransomware at worst.   In this extended abstract we introduce Sandi, a new kind of reputation system with a single well-defined purpose: to create trust through accountability in one-to-one transactions. Examples of such transactions include sending an email or making a purchase online. Sandi has strong security and privacy properties that make it suitable for use also in sensitive contexts. Furthermore, Sandi can guarantee reputation integrity and transparency for its registered users.   As a primary application, we envision how Sandi could counter fraud and abuse in direct communication. Concretely, message senders request a cryptographic tag from Sandi that they send along with their message. If the receiver finds the message inappropriate, they can report the sender using this tag. Notably, only senders need registered accounts and do not need to manage long-term keys. The design of Sandi ensures compatibility with any communication system that allows for small binary data transmission.","sentences":["Reputation systems guide our decision making both in life and work: which restaurant to eat at, which vendor to buy from, which software dependencies to use, and who or what to trust.","These systems are often based on old ideas and are failing in the face of modern threats.","Fraudsters have found ways to manipulate them, undermining their integrity and utility.","Generative AI adds to the problem by enabling the creation of real-looking fake narratives at scale, creating a false sense of consensus.","Meanwhile, the need for reliable reputation concepts is more important than ever, as wrong decisions lead to increasingly severe outcomes: wasted time, poor service, and a feeling of injustice at best, fraud, identity theft, and ransomware at worst.   ","In this extended abstract we introduce Sandi, a new kind of reputation system with a single well-defined purpose: to create trust through accountability in one-to-one transactions.","Examples of such transactions include sending an email or making a purchase online.","Sandi has strong security and privacy properties that make it suitable for use also in sensitive contexts.","Furthermore, Sandi can guarantee reputation integrity and transparency for its registered users.   ","As a primary application, we envision how Sandi could counter fraud and abuse in direct communication.","Concretely, message senders request a cryptographic tag from Sandi that they send along with their message.","If the receiver finds the message inappropriate, they can report the sender using this tag.","Notably, only senders need registered accounts and do not need to manage long-term keys.","The design of Sandi ensures compatibility with any communication system that allows for small binary data transmission."],"url":"http://arxiv.org/abs/2311.04861v1"}
{"created":"2023-11-08 17:39:07","title":"Learning to Control under Uncertainty with Data-Based Iterative Linear Quadratic Regulator","abstract":"This paper studies the learning-to-control problem under process and sensing uncertainties for dynamical systems. In our previous work, we developed a data-based generalization of the iterative linear quadratic regulator (iLQR) to design closed-loop feedback control for high-dimensional dynamical systems with partial state observation. This method required perfect simulation rollouts which are not realistic in real applications. In this work, we briefly introduce this method and explore its efficacy under process and sensing uncertainties. We prove that in the fully observed case where the system dynamics are corrupted with noise but the measurements are perfect, it still converges to the global minimum. However, in the partially observed case where both process and measurement noise exist in the system, this method converges to a biased \"optimum\". Thus multiple rollouts need to be averaged to retrieve the true optimum. The analysis is verified in two nonlinear robotic examples simulated in the above cases.","sentences":["This paper studies the learning-to-control problem under process and sensing uncertainties for dynamical systems.","In our previous work, we developed a data-based generalization of the iterative linear quadratic regulator (iLQR) to design closed-loop feedback control for high-dimensional dynamical systems with partial state observation.","This method required perfect simulation rollouts which are not realistic in real applications.","In this work, we briefly introduce this method and explore its efficacy under process and sensing uncertainties.","We prove that in the fully observed case where the system dynamics are corrupted with noise but the measurements are perfect, it still converges to the global minimum.","However, in the partially observed case where both process and measurement noise exist in the system, this method converges to a biased \"optimum\".","Thus multiple rollouts need to be averaged to retrieve the true optimum.","The analysis is verified in two nonlinear robotic examples simulated in the above cases."],"url":"http://arxiv.org/abs/2311.04852v1"}
{"created":"2023-11-08 17:35:20","title":"Rethinking Benchmark and Contamination for Language Models with Rephrased Samples","abstract":"Large language models are increasingly trained on all the data ever produced by humans. Many have raised concerns about the trustworthiness of public benchmarks due to potential contamination in pre-training or fine-tuning datasets. While most data decontamination efforts apply string matching (e.g., n-gram overlap) to remove benchmark data, we show that these methods are insufficient, and simple variations of test data (e.g., paraphrasing, translation) can easily bypass these decontamination measures. Furthermore, we demonstrate that if such variation of test data is not eliminated, a 13B model can easily overfit a test benchmark and achieve drastically high performance, on par with GPT-4. We validate such observations in widely used benchmarks such as MMLU, GSK8k, and HumanEval. To address this growing risk, we propose a stronger LLM-based decontamination method and apply it to widely used pre-training and fine-tuning datasets, revealing significant previously unknown test overlap. For example, in pre-training sets such as RedPajama-Data-1T and StarCoder-Data, we identified that 8-18\\% of the HumanEval benchmark overlaps. Interestingly, we also find such contamination in synthetic dataset generated by GPT-3.5/4, suggesting a potential risk of unintentional contamination. We urge the community to adopt stronger decontamination approaches when using public benchmarks. Moreover, we call for the community to actively develop fresh one-time exams to evaluate models accurately. Our decontamination tool is publicly available at https://github.com/lm-sys/llm-decontaminator.","sentences":["Large language models are increasingly trained on all the data ever produced by humans.","Many have raised concerns about the trustworthiness of public benchmarks due to potential contamination in pre-training or fine-tuning datasets.","While most data decontamination efforts apply string matching (e.g., n-gram overlap) to remove benchmark data, we show that these methods are insufficient, and simple variations of test data (e.g., paraphrasing, translation) can easily bypass these decontamination measures.","Furthermore, we demonstrate that if such variation of test data is not eliminated, a 13B model can easily overfit a test benchmark and achieve drastically high performance, on par with GPT-4.","We validate such observations in widely used benchmarks such as MMLU, GSK8k, and HumanEval.","To address this growing risk, we propose a stronger LLM-based decontamination method and apply it to widely used pre-training and fine-tuning datasets, revealing significant previously unknown test overlap.","For example, in pre-training sets such as RedPajama-Data-1T and StarCoder-Data, we identified that 8-18\\% of the HumanEval benchmark overlaps.","Interestingly, we also find such contamination in synthetic dataset generated by GPT-3.5/4, suggesting a potential risk of unintentional contamination.","We urge the community to adopt stronger decontamination approaches when using public benchmarks.","Moreover, we call for the community to actively develop fresh one-time exams to evaluate models accurately.","Our decontamination tool is publicly available at https://github.com/lm-sys/llm-decontaminator."],"url":"http://arxiv.org/abs/2311.04850v1"}
{"created":"2023-11-08 17:29:41","title":"Incorporating temporal dynamics of mutations to enhance the prediction capability of antiretroviral therapy's outcome for HIV-1","abstract":"Motivation: In predicting HIV therapy outcomes, a critical clinical question is whether using historical information can enhance predictive capabilities compared with current or latest available data analysis. This study analyses whether historical knowledge, which includes viral mutations detected in all genotypic tests before therapy, their temporal occurrence, and concomitant viral load measurements, can bring improvements. We introduce a method to weigh mutations, considering the previously enumerated factors and the reference mutation-drug Stanford resistance tables. We compare a model encompassing history (H) with one not using it (NH). Results: The H-model demonstrates superior discriminative ability, with a higher ROC-AUC score (76.34%) than the NH-model (74.98%). Significant Wilcoxon test results confirm that incorporating historical information improves consistently predictive accuracy for treatment outcomes. The better performance of the H-model might be attributed to its consideration of latent HIV reservoirs, probably obtained when leveraging historical information. The findings emphasize the importance of temporal dynamics in mutations, offering insights into HIV infection complexities. However, our result also shows that prediction accuracy remains relatively high even when no historical information is available. Supplementary information: Supplementary material is available.","sentences":["Motivation: In predicting HIV therapy outcomes, a critical clinical question is whether using historical information can enhance predictive capabilities compared with current or latest available data analysis.","This study analyses whether historical knowledge, which includes viral mutations detected in all genotypic tests before therapy, their temporal occurrence, and concomitant viral load measurements, can bring improvements.","We introduce a method to weigh mutations, considering the previously enumerated factors and the reference mutation-drug Stanford resistance tables.","We compare a model encompassing history (H) with one not using it (NH).","Results:","The H-model demonstrates superior discriminative ability, with a higher ROC-AUC score (76.34%) than the NH-model (74.98%).","Significant Wilcoxon test results confirm that incorporating historical information improves consistently predictive accuracy for treatment outcomes.","The better performance of the H-model might be attributed to its consideration of latent HIV reservoirs, probably obtained when leveraging historical information.","The findings emphasize the importance of temporal dynamics in mutations, offering insights into HIV infection complexities.","However, our result also shows that prediction accuracy remains relatively high even when no historical information is available.","Supplementary information: Supplementary material is available."],"url":"http://arxiv.org/abs/2311.04846v1"}
{"created":"2023-11-08 17:26:38","title":"Bridging Dimensions: Confident Reachability for High-Dimensional Controllers","abstract":"Autonomous systems are increasingly implemented using end-end-end trained controllers. Such controllers make decisions that are executed on the real system with images as one of the primary sensing modalities. Deep neural networks form a fundamental building block of such controllers. Unfortunately, the existing neural-network verification tools do not scale to inputs with thousands of dimensions. Especially when the individual inputs (such as pixels) are devoid of clear physical meaning. This paper takes a step towards connecting exhaustive closed-loop verification with high-dimensional controllers. Our key insight is that the behavior of a high-dimensional controller can be approximated with several low-dimensional controllers in different regions of the state space. To balance approximation and verifiability, we leverage the latest verification-aware knowledge distillation. Then, if low-dimensional reachability results are inflated with statistical approximation errors, they yield a high-confidence reachability guarantee for the high-dimensional controller. We investigate two inflation techniques -- based on trajectories and actions -- both of which show convincing performance in two OpenAI gym benchmarks.","sentences":["Autonomous systems are increasingly implemented using end-end-end trained controllers.","Such controllers make decisions that are executed on the real system with images as one of the primary sensing modalities.","Deep neural networks form a fundamental building block of such controllers.","Unfortunately, the existing neural-network verification tools do not scale to inputs with thousands of dimensions.","Especially when the individual inputs (such as pixels) are devoid of clear physical meaning.","This paper takes a step towards connecting exhaustive closed-loop verification with high-dimensional controllers.","Our key insight is that the behavior of a high-dimensional controller can be approximated with several low-dimensional controllers in different regions of the state space.","To balance approximation and verifiability, we leverage the latest verification-aware knowledge distillation.","Then, if low-dimensional reachability results are inflated with statistical approximation errors, they yield a high-confidence reachability guarantee for the high-dimensional controller.","We investigate two inflation techniques -- based on trajectories and actions -- both of which show convincing performance in two OpenAI gym benchmarks."],"url":"http://arxiv.org/abs/2311.04843v1"}
{"created":"2023-11-08 17:01:35","title":"Identifying Semantic Component for Robust Molecular Property Prediction","abstract":"Although graph neural networks have achieved great success in the task of molecular property prediction in recent years, their generalization ability under out-of-distribution (OOD) settings is still under-explored. Different from existing methods that learn discriminative representations for prediction, we propose a generative model with semantic-components identifiability, named SCI. We demonstrate that the latent variables in this generative model can be explicitly identified into semantic-relevant (SR) and semantic-irrelevant (SI) components, which contributes to better OOD generalization by involving minimal change properties of causal mechanisms. Specifically, we first formulate the data generation process from the atom level to the molecular level, where the latent space is split into SI substructures, SR substructures, and SR atom variables. Sequentially, to reduce misidentification, we restrict the minimal changes of the SR atom variables and add a semantic latent substructure regularization to mitigate the variance of the SR substructure under augmented domain changes. Under mild assumptions, we prove the block-wise identifiability of the SR substructure and the comment-wise identifiability of SR atom variables. Experimental studies achieve state-of-the-art performance and show general improvement on 21 datasets in 3 mainstream benchmarks. Moreover, the visualization results of the proposed SCI method provide insightful case studies and explanations for the prediction results. The code is available at: https://github.com/DMIRLAB-Group/SCI.","sentences":["Although graph neural networks have achieved great success in the task of molecular property prediction in recent years, their generalization ability under out-of-distribution (OOD) settings is still under-explored.","Different from existing methods that learn discriminative representations for prediction, we propose a generative model with semantic-components identifiability, named SCI.","We demonstrate that the latent variables in this generative model can be explicitly identified into semantic-relevant (SR) and semantic-irrelevant (SI) components, which contributes to better OOD generalization by involving minimal change properties of causal mechanisms.","Specifically, we first formulate the data generation process from the atom level to the molecular level, where the latent space is split into SI substructures, SR substructures, and SR atom variables.","Sequentially, to reduce misidentification, we restrict the minimal changes of the SR atom variables and add a semantic latent substructure regularization to mitigate the variance of the SR substructure under augmented domain changes.","Under mild assumptions, we prove the block-wise identifiability of the SR substructure and the comment-wise identifiability of SR atom variables.","Experimental studies achieve state-of-the-art performance and show general improvement on 21 datasets in 3 mainstream benchmarks.","Moreover, the visualization results of the proposed SCI method provide insightful case studies and explanations for the prediction results.","The code is available at: https://github.com/DMIRLAB-Group/SCI."],"url":"http://arxiv.org/abs/2311.04837v1"}
{"created":"2023-11-08 17:00:05","title":"Sparcle: Boosting the Accuracy of Data Cleaning Systems through Spatial Awareness","abstract":"Though data cleaning systems have earned great success and wide spread in both academia and industry, they fall short when trying to clean spatial data. The main reason is that state-of-the-art data cleaning systems mainly rely on functional dependency rules where there is sufficient co-occurrence of value pairs to learn that a certain value of an attribute leads to a corresponding value of another attribute. However, for spatial attributes that represent locations on the form of <latitude, longitude>, there is very little chance that two records would have the same exact coordinates, and hence co-occurrence would unlikely to exist. This paper presents Sparcle~(SPatially-AwaRe CLEaning); a novel framework that injects spatial awareness into the core engine of rule-based data cleaning systems as a means of boosting their accuracy. Sparcle injects two main spatial concepts into the core engine of data cleaning systems: (1) Spatial Neighborhood, where co-occurrence is relaxed to be within a certain spatial proximity rather than same exact value, and (2) Distance Weighting, where records are given different weights of whether they satisfy a dependency rule, based on their relative distance. Experimental results using a real deployment of Sparcle inside a state-of-the-art data cleaning system, and real and synthetic datasets, show that Sparcle significantly boosts the accuracy of data cleaning systems when dealing with spatial data.","sentences":["Though data cleaning systems have earned great success and wide spread in both academia and industry, they fall short when trying to clean spatial data.","The main reason is that state-of-the-art data cleaning systems mainly rely on functional dependency rules where there is sufficient co-occurrence of value pairs to learn that a certain value of an attribute leads to a corresponding value of another attribute.","However, for spatial attributes that represent locations on the form of <latitude, longitude>, there is very little chance that two records would have the same exact coordinates, and hence co-occurrence would unlikely to exist.","This paper presents Sparcle~(SPatially-AwaRe CLEaning); a novel framework that injects spatial awareness into the core engine of rule-based data cleaning systems as a means of boosting their accuracy.","Sparcle injects two main spatial concepts into the core engine of data cleaning systems: (1) Spatial Neighborhood, where co-occurrence is relaxed to be within a certain spatial proximity rather than same exact value, and (2) Distance Weighting, where records are given different weights of whether they satisfy a dependency rule, based on their relative distance.","Experimental results using a real deployment of Sparcle inside a state-of-the-art data cleaning system, and real and synthetic datasets, show that Sparcle significantly boosts the accuracy of data cleaning systems when dealing with spatial data."],"url":"http://arxiv.org/abs/2311.04836v1"}
{"created":"2023-11-08 16:59:26","title":"Self-Supervised Learning for Visual Relationship Detection through Masked Bounding Box Reconstruction","abstract":"We present a novel self-supervised approach for representation learning, particularly for the task of Visual Relationship Detection (VRD). Motivated by the effectiveness of Masked Image Modeling (MIM), we propose Masked Bounding Box Reconstruction (MBBR), a variation of MIM where a percentage of the entities/objects within a scene are masked and subsequently reconstructed based on the unmasked objects. The core idea is that, through object-level masked modeling, the network learns context-aware representations that capture the interaction of objects within a scene and thus are highly predictive of visual object relationships. We extensively evaluate learned representations, both qualitatively and quantitatively, in a few-shot setting and demonstrate the efficacy of MBBR for learning robust visual representations, particularly tailored for VRD. The proposed method is able to surpass state-of-the-art VRD methods on the Predicate Detection (PredDet) evaluation setting, using only a few annotated samples. We make our code available at https://github.com/deeplab-ai/SelfSupervisedVRD.","sentences":["We present a novel self-supervised approach for representation learning, particularly for the task of Visual Relationship Detection (VRD).","Motivated by the effectiveness of Masked Image Modeling (MIM), we propose Masked Bounding Box Reconstruction (MBBR), a variation of MIM where a percentage of the entities/objects within a scene are masked and subsequently reconstructed based on the unmasked objects.","The core idea is that, through object-level masked modeling, the network learns context-aware representations that capture the interaction of objects within a scene and thus are highly predictive of visual object relationships.","We extensively evaluate learned representations, both qualitatively and quantitatively, in a few-shot setting and demonstrate the efficacy of MBBR for learning robust visual representations, particularly tailored for VRD.","The proposed method is able to surpass state-of-the-art VRD methods on the Predicate Detection (PredDet) evaluation setting, using only a few annotated samples.","We make our code available at https://github.com/deeplab-ai/SelfSupervisedVRD."],"url":"http://arxiv.org/abs/2311.04834v1"}
{"created":"2023-11-08 16:58:58","title":"Anonymizing medical case-based explanations through disentanglement","abstract":"Case-based explanations are an intuitive method to gain insight into the decision-making process of deep learning models in clinical contexts. However, medical images cannot be shared as explanations due to privacy concerns. To address this problem, we propose a novel method for disentangling identity and medical characteristics of images and apply it to anonymize medical images. The disentanglement mechanism replaces some feature vectors in an image while ensuring that the remaining features are preserved, obtaining independent feature vectors that encode the images' identity and medical characteristics. We also propose a model to manufacture synthetic privacy-preserving identities to replace the original image's identity and achieve anonymization. The models are applied to medical and biometric datasets, demonstrating their capacity to generate realistic-looking anonymized images that preserve their original medical content. Additionally, the experiments show the network's inherent capacity to generate counterfactual images through the replacement of medical features.","sentences":["Case-based explanations are an intuitive method to gain insight into the decision-making process of deep learning models in clinical contexts.","However, medical images cannot be shared as explanations due to privacy concerns.","To address this problem, we propose a novel method for disentangling identity and medical characteristics of images and apply it to anonymize medical images.","The disentanglement mechanism replaces some feature vectors in an image while ensuring that the remaining features are preserved, obtaining independent feature vectors that encode the images' identity and medical characteristics.","We also propose a model to manufacture synthetic privacy-preserving identities to replace the original image's identity and achieve anonymization.","The models are applied to medical and biometric datasets, demonstrating their capacity to generate realistic-looking anonymized images that preserve their original medical content.","Additionally, the experiments show the network's inherent capacity to generate counterfactual images through the replacement of medical features."],"url":"http://arxiv.org/abs/2311.04833v1"}
{"created":"2023-11-08 16:57:01","title":"A contribution to the MMSE conjecture","abstract":"We investigate the so-called \"MMSE conjecture\" from Guo et al. (2011) which asserts that two distributions on the real line with the same entropy along the heat flow coincide up to translation and symmetry. Our approach follows the path breaking contribution Ledoux (1995) which gave algebraic representations of the derivatives of said entropy in terms of multivariate polynomials. The main contributions in this note are (i) we obtain the leading terms in the polynomials from Ledoux (1995), and (ii) we provide new conditions on the source distributions ensuring the MMSE conjecture holds. As illustrating examples, our findings cover the cases of uniform and Rademacher distributions, for which previous results in the literature were inapplicable.","sentences":["We investigate the so-called \"MMSE conjecture\" from Guo et al. (2011) which asserts that two distributions on the real line with the same entropy along the heat flow coincide up to translation and symmetry.","Our approach follows the path breaking contribution Ledoux (1995) which gave algebraic representations of the derivatives of said entropy in terms of multivariate polynomials.","The main contributions in this note are (i) we obtain the leading terms in the polynomials from Ledoux (1995), and (ii) we provide new conditions on the source distributions ensuring the MMSE conjecture holds.","As illustrating examples, our findings cover the cases of uniform and Rademacher distributions, for which previous results in the literature were inapplicable."],"url":"http://arxiv.org/abs/2311.04831v1"}
{"created":"2023-11-08 16:56:16","title":"Real-Time Recurrent Reinforcement Learning","abstract":"Recent advances in reinforcement learning, for partially-observable Markov decision processes (POMDPs), rely on the biologically implausible backpropagation through time algorithm (BPTT) to perform gradient-descent optimisation. In this paper we propose a novel reinforcement learning algorithm that makes use of random feedback local online learning (RFLO), a biologically plausible approximation of realtime recurrent learning (RTRL) to compute the gradients of the parameters of a recurrent neural network in an online manner. By combining it with TD($\\lambda$), a variant of temporaldifference reinforcement learning with eligibility traces, we create a biologically plausible, recurrent actor-critic algorithm, capable of solving discrete and continuous control tasks in POMDPs. We compare BPTT, RTRL and RFLO as well as different network architectures, and find that RFLO can perform just as well as RTRL while exceeding even BPTT in terms of complexity. The proposed method, called real-time recurrent reinforcement learning (RTRRL), serves as a model of learning in biological neural networks mimicking reward pathways in the mammalian brain.","sentences":["Recent advances in reinforcement learning, for partially-observable Markov decision processes (POMDPs), rely on the biologically implausible backpropagation through time algorithm (BPTT) to perform gradient-descent optimisation.","In this paper we propose a novel reinforcement learning algorithm that makes use of random feedback local online learning (RFLO), a biologically plausible approximation of realtime recurrent learning (RTRL) to compute the gradients of the parameters of a recurrent neural network in an online manner.","By combining it with TD($\\lambda$), a variant of temporaldifference reinforcement learning with eligibility traces, we create a biologically plausible, recurrent actor-critic algorithm, capable of solving discrete and continuous control tasks in POMDPs.","We compare BPTT, RTRL and RFLO as well as different network architectures, and find that RFLO can perform just as well as RTRL while exceeding even BPTT in terms of complexity.","The proposed method, called real-time recurrent reinforcement learning (RTRRL), serves as a model of learning in biological neural networks mimicking reward pathways in the mammalian brain."],"url":"http://arxiv.org/abs/2311.04830v1"}
{"created":"2023-11-08 16:54:23","title":"Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data","abstract":"Tucker decomposition is a powerful tensor model to handle multi-aspect data. It demonstrates the low-rank property by decomposing the grid-structured data as interactions between a core tensor and a set of object representations (factors). A fundamental assumption of such decomposition is that there were finite objects in each aspect or mode, corresponding to discrete indexes of data entries. However, many real-world data are not naturally posed in the setting. For example, geographic data is represented as continuous indexes of latitude and longitude coordinates, and cannot fit tensor models directly. To generalize Tucker decomposition to such scenarios, we propose Functional Bayesian Tucker Decomposition (FunBaT). We treat the continuous-indexed data as the interaction between the Tucker core and a group of latent functions. We use Gaussian processes (GP) as functional priors to model the latent functions, and then convert the GPs into a state-space prior by constructing an equivalent stochastic differential equation (SDE) to reduce computational cost. An efficient inference algorithm is further developed for scalable posterior approximation based on advanced message-passing techniques. The advantage of our method is shown in both synthetic data and several real-world applications.","sentences":["Tucker decomposition is a powerful tensor model to handle multi-aspect data.","It demonstrates the low-rank property by decomposing the grid-structured data as interactions between a core tensor and a set of object representations (factors).","A fundamental assumption of such decomposition is that there were finite objects in each aspect or mode, corresponding to discrete indexes of data entries.","However, many real-world data are not naturally posed in the setting.","For example, geographic data is represented as continuous indexes of latitude and longitude coordinates, and cannot fit tensor models directly.","To generalize Tucker decomposition to such scenarios, we propose Functional Bayesian Tucker Decomposition (FunBaT).","We treat the continuous-indexed data as the interaction between the Tucker core and a group of latent functions.","We use Gaussian processes (GP) as functional priors to model the latent functions, and then convert the GPs into a state-space prior by constructing an equivalent stochastic differential equation (SDE) to reduce computational cost.","An efficient inference algorithm is further developed for scalable posterior approximation based on advanced message-passing techniques.","The advantage of our method is shown in both synthetic data and several real-world applications."],"url":"http://arxiv.org/abs/2311.04829v1"}
{"created":"2023-11-08 16:53:44","title":"SODAWideNet -- Salient Object Detection with an Attention augmented Wide Encoder Decoder network without ImageNet pre-training","abstract":"Developing a new Salient Object Detection (SOD) model involves selecting an ImageNet pre-trained backbone and creating novel feature refinement modules to use backbone features. However, adding new components to a pre-trained backbone needs retraining the whole network on the ImageNet dataset, which requires significant time. Hence, we explore developing a neural network from scratch directly trained on SOD without ImageNet pre-training. Such a formulation offers full autonomy to design task-specific components. To that end, we propose SODAWideNet, an encoder-decoder-style network for Salient Object Detection. We deviate from the commonly practiced paradigm of narrow and deep convolutional models to a wide and shallow architecture, resulting in a parameter-efficient deep neural network. To achieve a shallower network, we increase the receptive field from the beginning of the network using a combination of dilated convolutions and self-attention. Therefore, we propose Multi Receptive Field Feature Aggregation Module (MRFFAM) that efficiently obtains discriminative features from farther regions at higher resolutions using dilated convolutions. Next, we propose Multi-Scale Attention (MSA), which creates a feature pyramid and efficiently computes attention across multiple resolutions to extract global features from larger feature maps. Finally, we propose two variants, SODAWideNet-S (3.03M) and SODAWideNet (9.03M), that achieve competitive performance against state-of-the-art models on five datasets.","sentences":["Developing a new Salient Object Detection (SOD) model involves selecting an ImageNet pre-trained backbone and creating novel feature refinement modules to use backbone features.","However, adding new components to a pre-trained backbone needs retraining the whole network on the ImageNet dataset, which requires significant time.","Hence, we explore developing a neural network from scratch directly trained on SOD without ImageNet pre-training.","Such a formulation offers full autonomy to design task-specific components.","To that end, we propose SODAWideNet, an encoder-decoder-style network for Salient Object Detection.","We deviate from the commonly practiced paradigm of narrow and deep convolutional models to a wide and shallow architecture, resulting in a parameter-efficient deep neural network.","To achieve a shallower network, we increase the receptive field from the beginning of the network using a combination of dilated convolutions and self-attention.","Therefore, we propose Multi Receptive Field Feature Aggregation Module (MRFFAM) that efficiently obtains discriminative features from farther regions at higher resolutions using dilated convolutions.","Next, we propose Multi-Scale Attention (MSA), which creates a feature pyramid and efficiently computes attention across multiple resolutions to extract global features from larger feature maps.","Finally, we propose two variants, SODAWideNet-S (3.03M) and SODAWideNet (9.03M), that achieve competitive performance against state-of-the-art models on five datasets."],"url":"http://arxiv.org/abs/2311.04828v1"}
{"created":"2023-11-08 16:50:15","title":"Bilevel Relations and Their Applications to Data Insights","abstract":"Many data-insight analytic tasks in anomaly detection, metric attribution, and experimentation analysis can be modeled as searching in a large space of tables and finding important ones, where the notion of importance is defined in some adhoc manner. While various frameworks have been proposed (e.g., DIFF, VLDB 2019), a systematic and general treatment is lacking. This paper describes bilevel relations and operators. While a relation (i.e., table) models a set of tuples, a bilevel relation is a dictionary that explicitly models a set of tables, where each ``value'' table is identified by a ``key'' of a (region, features) pair, where region specifies key attributes of the table, and features specify columns of the table. Bilevel relational operators are BilevelRelation-to-BilevelRelation transformations and directly analyze a set of tables. Bilevel relations and operators provide higher level abstractions for creating and manipulating a set of tables, and are compatible with the classic relational algebra. Together, they allow us to construct bilevel queries, which can express succinctly a range of insight-analytical questions with ``search+eval'' character. We have implemented and deployed a query engine for bilevel queries as a service, which is a first of its kind. Bilevel queries pose a rich algorithm and system design space, such as query optimization and data format, in order to evaluate them efficiently. We describe our current designs and lessons, and report empirical evaluations. Bilevel queries have found many useful applications, and have attracted more than 30 internal teams to build data-insight applications with it.","sentences":["Many data-insight analytic tasks in anomaly detection, metric attribution, and experimentation analysis can be modeled as searching in a large space of tables and finding important ones, where the notion of importance is defined in some adhoc manner.","While various frameworks have been proposed (e.g., DIFF, VLDB 2019), a systematic and general treatment is lacking.","This paper describes bilevel relations and operators.","While a relation (i.e., table) models a set of tuples, a bilevel relation is a dictionary that explicitly models a set of tables, where each ``value'' table is identified by a ``key'' of a (region, features) pair, where region specifies key attributes of the table, and features specify columns of the table.","Bilevel relational operators are BilevelRelation-to-BilevelRelation transformations and directly analyze a set of tables.","Bilevel relations and operators provide higher level abstractions for creating and manipulating a set of tables, and are compatible with the classic relational algebra.","Together, they allow us to construct bilevel queries, which can express succinctly a range of insight-analytical questions with ``search+eval'' character.","We have implemented and deployed a query engine for bilevel queries as a service, which is a first of its kind.","Bilevel queries pose a rich algorithm and system design space, such as query optimization and data format, in order to evaluate them efficiently.","We describe our current designs and lessons, and report empirical evaluations.","Bilevel queries have found many useful applications, and have attracted more than 30 internal teams to build data-insight applications with it."],"url":"http://arxiv.org/abs/2311.04824v1"}
{"created":"2023-11-08 16:50:05","title":"Hierarchically Gated Recurrent Neural Network for Sequence Modeling","abstract":"Transformers have surpassed RNNs in popularity due to their superior abilities in parallel training and long-term dependency modeling. Recently, there has been a renewed interest in using linear RNNs for efficient sequence modeling. These linear RNNs often employ gating mechanisms in the output of the linear recurrence layer while ignoring the significance of using forget gates within the recurrence. In this paper, we propose a gated linear RNN model dubbed Hierarchically Gated Recurrent Neural Network (HGRN), which includes forget gates that are lower bounded by a learnable value. The lower bound increases monotonically when moving up layers. This allows the upper layers to model long-term dependencies and the lower layers to model more local, short-term dependencies. Experiments on language modeling, image classification, and long-range arena benchmarks showcase the efficiency and effectiveness of our proposed model. The source code is available at https://github.com/OpenNLPLab/HGRN.","sentences":["Transformers have surpassed RNNs in popularity due to their superior abilities in parallel training and long-term dependency modeling.","Recently, there has been a renewed interest in using linear RNNs for efficient sequence modeling.","These linear RNNs often employ gating mechanisms in the output of the linear recurrence layer while ignoring the significance of using forget gates within the recurrence.","In this paper, we propose a gated linear RNN model dubbed Hierarchically Gated Recurrent Neural Network (HGRN), which includes forget gates that are lower bounded by a learnable value.","The lower bound increases monotonically when moving up layers.","This allows the upper layers to model long-term dependencies and the lower layers to model more local, short-term dependencies.","Experiments on language modeling, image classification, and long-range arena benchmarks showcase the efficiency and effectiveness of our proposed model.","The source code is available at https://github.com/OpenNLPLab/HGRN."],"url":"http://arxiv.org/abs/2311.04823v1"}
{"created":"2023-11-08 16:42:14","title":"Cross-Silo Federated Learning Across Divergent Domains with Iterative Parameter Alignment","abstract":"Learning from the collective knowledge of data dispersed across private sources can provide neural networks with enhanced generalization capabilities. Federated learning, a method for collaboratively training a machine learning model across remote clients, achieves this by combining client models via the orchestration of a central server. However, current approaches face two critical limitations: i) they struggle to converge when client domains are sufficiently different, and ii) current aggregation techniques produce an identical global model for each client. In this work, we address these issues by reformulating the typical federated learning setup: rather than learning a single global model, we learn N models each optimized for a common objective. To achieve this, we apply a weighted distance minimization to model parameters shared in a peer-to-peer topology. The resulting framework, Iterative Parameter Alignment, applies naturally to the cross-silo setting, and has the following properties: (i) a unique solution for each participant, with the option to globally converge each model in the federation, and (ii) an optional early-stopping mechanism to elicit fairness among peers in collaborative learning settings. These characteristics jointly provide a flexible new framework for iteratively learning from peer models trained on disparate datasets. We find that the technique achieves competitive results on a variety of data partitions compared to state-of-the-art approaches. Further, we show that the method is robust to divergent domains (i.e. disjoint classes across peers) where existing approaches struggle.","sentences":["Learning from the collective knowledge of data dispersed across private sources can provide neural networks with enhanced generalization capabilities.","Federated learning, a method for collaboratively training a machine learning model across remote clients, achieves this by combining client models via the orchestration of a central server.","However, current approaches face two critical limitations: i) they struggle to converge when client domains are sufficiently different, and ii) current aggregation techniques produce an identical global model for each client.","In this work, we address these issues by reformulating the typical federated learning setup: rather than learning a single global model, we learn N models each optimized for a common objective.","To achieve this, we apply a weighted distance minimization to model parameters shared in a peer-to-peer topology.","The resulting framework, Iterative Parameter Alignment, applies naturally to the cross-silo setting, and has the following properties: (i) a unique solution for each participant, with the option to globally converge each model in the federation, and (ii) an optional early-stopping mechanism to elicit fairness among peers in collaborative learning settings.","These characteristics jointly provide a flexible new framework for iteratively learning from peer models trained on disparate datasets.","We find that the technique achieves competitive results on a variety of data partitions compared to state-of-the-art approaches.","Further, we show that the method is robust to divergent domains (i.e. disjoint classes across peers) where existing approaches struggle."],"url":"http://arxiv.org/abs/2311.04818v1"}
{"created":"2023-11-08 16:42:10","title":"Decentralized Personalized Online Federated Learning","abstract":"Vanilla federated learning does not support learning in an online environment, learning a personalized model on each client, and learning in a decentralized setting. There are existing methods extending federated learning in each of the three aspects. However, some important applications on enterprise edge servers (e.g. online item recommendation at global scale) involve the three aspects at the same time. Therefore, we propose a new learning setting \\textit{Decentralized Personalized Online Federated Learning} that considers all the three aspects at the same time.   In this new setting for learning, the first technical challenge is how to aggregate the shared model parameters from neighboring clients to obtain a personalized local model with good performance on each client. We propose to directly learn an aggregation by optimizing the performance of the local model with respect to the aggregation weights. This not only improves personalization of each local model but also helps the local model adapting to potential data shift by intelligently incorporating the right amount of information from its neighbors. The second challenge is how to select the neighbors for each client. We propose a peer selection method based on the learned aggregation weights enabling each client to select the most helpful neighbors and reduce communication cost at the same time. We verify the effectiveness and robustness of our proposed method on three real-world item recommendation datasets and one air quality prediction dataset.","sentences":["Vanilla federated learning does not support learning in an online environment, learning a personalized model on each client, and learning in a decentralized setting.","There are existing methods extending federated learning in each of the three aspects.","However, some important applications on enterprise edge servers (e.g. online item recommendation at global scale) involve the three aspects at the same time.","Therefore, we propose a new learning setting \\textit{Decentralized Personalized Online Federated Learning} that considers all the three aspects at the same time.   ","In this new setting for learning, the first technical challenge is how to aggregate the shared model parameters from neighboring clients to obtain a personalized local model with good performance on each client.","We propose to directly learn an aggregation by optimizing the performance of the local model with respect to the aggregation weights.","This not only improves personalization of each local model but also helps the local model adapting to potential data shift by intelligently incorporating the right amount of information from its neighbors.","The second challenge is how to select the neighbors for each client.","We propose a peer selection method based on the learned aggregation weights enabling each client to select the most helpful neighbors and reduce communication cost at the same time.","We verify the effectiveness and robustness of our proposed method on three real-world item recommendation datasets and one air quality prediction dataset."],"url":"http://arxiv.org/abs/2311.04817v1"}
{"created":"2023-11-08 16:41:37","title":"MTGER: Multi-view Temporal Graph Enhanced Temporal Reasoning over Time-Involved Document","abstract":"The facts and time in the document are intricately intertwined, making temporal reasoning over documents challenging. Previous work models time implicitly, making it difficult to handle such complex relationships. To address this issue, we propose MTGER, a novel Multi-view Temporal Graph Enhanced Temporal Reasoning framework for temporal reasoning over time-involved documents. Concretely, MTGER explicitly models the temporal relationships among facts by multi-view temporal graphs. On the one hand, the heterogeneous temporal graphs explicitly model the temporal and discourse relationships among facts; on the other hand, the multi-view mechanism captures both time-focused and fact-focused information, allowing the two views to complement each other through adaptive fusion. To further improve the implicit reasoning capability of the model, we design a self-supervised time-comparing objective. Extensive experimental results demonstrate the effectiveness of our method on the TimeQA and SituatedQA datasets. Furthermore, MTGER gives more consistent answers under question perturbations.","sentences":["The facts and time in the document are intricately intertwined, making temporal reasoning over documents challenging.","Previous work models time implicitly, making it difficult to handle such complex relationships.","To address this issue, we propose MTGER, a novel Multi-view Temporal Graph Enhanced Temporal Reasoning framework for temporal reasoning over time-involved documents.","Concretely, MTGER explicitly models the temporal relationships among facts by multi-view temporal graphs.","On the one hand, the heterogeneous temporal graphs explicitly model the temporal and discourse relationships among facts; on the other hand, the multi-view mechanism captures both time-focused and fact-focused information, allowing the two views to complement each other through adaptive fusion.","To further improve the implicit reasoning capability of the model, we design a self-supervised time-comparing objective.","Extensive experimental results demonstrate the effectiveness of our method on the TimeQA and SituatedQA datasets.","Furthermore, MTGER gives more consistent answers under question perturbations."],"url":"http://arxiv.org/abs/2311.04816v1"}
{"created":"2023-11-08 16:40:53","title":"Domain Adaptive Object Detection via Balancing Between Self-Training and Adversarial Learning","abstract":"Deep learning based object detectors struggle generalizing to a new target domain bearing significant variations in object and background. Most current methods align domains by using image or instance-level adversarial feature alignment. This often suffers due to unwanted background and lacks class-specific alignment. A straightforward approach to promote class-level alignment is to use high confidence predictions on unlabeled domain as pseudo-labels. These predictions are often noisy since model is poorly calibrated under domain shift. In this paper, we propose to leverage model's predictive uncertainty to strike the right balance between adversarial feature alignment and class-level alignment. We develop a technique to quantify predictive uncertainty on class assignments and bounding-box predictions. Model predictions with low uncertainty are used to generate pseudo-labels for self-training, whereas the ones with higher uncertainty are used to generate tiles for adversarial feature alignment. This synergy between tiling around uncertain object regions and generating pseudo-labels from highly certain object regions allows capturing both image and instance-level context during the model adaptation. We report thorough ablation study to reveal the impact of different components in our approach. Results on five diverse and challenging adaptation scenarios show that our approach outperforms existing state-of-the-art methods with noticeable margins.","sentences":["Deep learning based object detectors struggle generalizing to a new target domain bearing significant variations in object and background.","Most current methods align domains by using image or instance-level adversarial feature alignment.","This often suffers due to unwanted background and lacks class-specific alignment.","A straightforward approach to promote class-level alignment is to use high confidence predictions on unlabeled domain as pseudo-labels.","These predictions are often noisy since model is poorly calibrated under domain shift.","In this paper, we propose to leverage model's predictive uncertainty to strike the right balance between adversarial feature alignment and class-level alignment.","We develop a technique to quantify predictive uncertainty on class assignments and bounding-box predictions.","Model predictions with low uncertainty are used to generate pseudo-labels for self-training, whereas the ones with higher uncertainty are used to generate tiles for adversarial feature alignment.","This synergy between tiling around uncertain object regions and generating pseudo-labels from highly certain object regions allows capturing both image and instance-level context during the model adaptation.","We report thorough ablation study to reveal the impact of different components in our approach.","Results on five diverse and challenging adaptation scenarios show that our approach outperforms existing state-of-the-art methods with noticeable margins."],"url":"http://arxiv.org/abs/2311.04815v1"}
{"created":"2023-11-08 16:39:13","title":"Be Careful When Evaluating Explanations Regarding Ground Truth","abstract":"Evaluating explanations of image classifiers regarding ground truth, e.g. segmentation masks defined by human perception, primarily evaluates the quality of the models under consideration rather than the explanation methods themselves. Driven by this observation, we propose a framework for $\\textit{jointly}$ evaluating the robustness of safety-critical systems that $\\textit{combine}$ a deep neural network with an explanation method. These are increasingly used in real-world applications like medical image analysis or robotics. We introduce a fine-tuning procedure to (mis)align model$\\unicode{x2013}$explanation pipelines with ground truth and use it to quantify the potential discrepancy between worst and best-case scenarios of human alignment. Experiments across various model architectures and post-hoc local interpretation methods provide insights into the robustness of vision transformers and the overall vulnerability of such AI systems to potential adversarial attacks.","sentences":["Evaluating explanations of image classifiers regarding ground truth, e.g. segmentation masks defined by human perception, primarily evaluates the quality of the models under consideration rather than the explanation methods themselves.","Driven by this observation, we propose a framework for $\\textit{jointly}$ evaluating the robustness of safety-critical systems that $\\textit{combine}$ a deep neural network with an explanation method.","These are increasingly used in real-world applications like medical image analysis or robotics.","We introduce a fine-tuning procedure to (mis)align model$\\unicode{x2013}$explanation pipelines with ground truth and use it to quantify the potential discrepancy between worst and best-case scenarios of human alignment.","Experiments across various model architectures and post-hoc local interpretation methods provide insights into the robustness of vision transformers and the overall vulnerability of such AI systems to potential adversarial attacks."],"url":"http://arxiv.org/abs/2311.04813v1"}
{"created":"2023-11-08 16:34:18","title":"Image-Based Virtual Try-On: A Survey","abstract":"Image-based virtual try-on aims to synthesize a naturally dressed person image with a clothing image, which revolutionizes online shopping and inspires related topics within image generation, showing both research significance and commercial potentials. However, there is a great gap between current research progress and commercial applications and an absence of comprehensive overview towards this field to accelerate the development. In this survey, we provide a comprehensive analysis of the state-of-the-art techniques and methodologies in aspects of pipeline architecture, person representation and key modules such as try-on indication, clothing warping and try-on stage. We propose a new semantic criteria with CLIP, and evaluate representative methods with uniformly implemented evaluation metrics on the same dataset. In addition to quantitative and qualitative evaluation of current open-source methods, we also utilize ControlNet to fine-tune a recent large image generation model (PBE) to show future potentials of large-scale models on image-based virtual try-on task. Finally, unresolved issues are revealed and future research directions are prospected to identify key trends and inspire further exploration. The uniformly implemented evaluation metrics, dataset and collected methods will be made public available at https://github.com/little-misfit/Survey-Of-Virtual-Try-On.","sentences":["Image-based virtual try-on aims to synthesize a naturally dressed person image with a clothing image, which revolutionizes online shopping and inspires related topics within image generation, showing both research significance and commercial potentials.","However, there is a great gap between current research progress and commercial applications and an absence of comprehensive overview towards this field to accelerate the development.","In this survey, we provide a comprehensive analysis of the state-of-the-art techniques and methodologies in aspects of pipeline architecture, person representation and key modules such as try-on indication, clothing warping and try-on stage.","We propose a new semantic criteria with CLIP, and evaluate representative methods with uniformly implemented evaluation metrics on the same dataset.","In addition to quantitative and qualitative evaluation of current open-source methods, we also utilize ControlNet to fine-tune a recent large image generation model (PBE) to show future potentials of large-scale models on image-based virtual try-on task.","Finally, unresolved issues are revealed and future research directions are prospected to identify key trends and inspire further exploration.","The uniformly implemented evaluation metrics, dataset and collected methods will be made public available at https://github.com/little-misfit/Survey-Of-Virtual-Try-On."],"url":"http://arxiv.org/abs/2311.04811v1"}
{"created":"2023-11-08 16:30:52","title":"A Lightweight Architecture for Real-Time Neuronal-Spike Classification","abstract":"Electrophysiological recordings of neural activity in a mouse's brain are very popular among neuroscientists for understanding brain function. One particular area of interest is acquiring recordings from the Purkinje cells in the cerebellum in order to understand brain injuries and the loss of motor functions. However, current setups for such experiments do not allow the mouse to move freely and, thus, do not capture its natural behaviour since they have a wired connection between the animal's head stage and an acquisition device. In this work, we propose a lightweight neuronal-spike detection and classification architecture that leverages on the unique characteristics of the Purkinje cells to discard unneeded information from the sparse neural data in real time. This allows the (condensed) data to be easily stored on a removable storage device on the head stage, alleviating the need for wires. Our proposed implementation shows a >95% overall classification accuracy while still resulting in a small-form-factor design, which allows for the free movement of mice during experiments. Moreover, the power-efficient nature of the design and the usage of STT-RAM (Spin Transfer Torque Magnetic Random Access Memory) as the removable storage allows the head stage to easily operate on a tiny battery for up to approximately 4 days.","sentences":["Electrophysiological recordings of neural activity in a mouse's brain are very popular among neuroscientists for understanding brain function.","One particular area of interest is acquiring recordings from the Purkinje cells in the cerebellum in order to understand brain injuries and the loss of motor functions.","However, current setups for such experiments do not allow the mouse to move freely and, thus, do not capture its natural behaviour since they have a wired connection between the animal's head stage and an acquisition device.","In this work, we propose a lightweight neuronal-spike detection and classification architecture that leverages on the unique characteristics of the Purkinje cells to discard unneeded information from the sparse neural data in real time.","This allows the (condensed) data to be easily stored on a removable storage device on the head stage, alleviating the need for wires.","Our proposed implementation shows a >95% overall classification accuracy while still resulting in a small-form-factor design, which allows for the free movement of mice during experiments.","Moreover, the power-efficient nature of the design and the usage of STT-RAM (Spin Transfer Torque Magnetic Random Access Memory) as the removable storage allows the head stage to easily operate on a tiny battery for up to approximately 4 days."],"url":"http://arxiv.org/abs/2311.04808v1"}
{"created":"2023-11-08 16:30:12","title":"The PetShop Dataset -- Finding Causes of Performance Issues across Microservices","abstract":"Identifying root causes for unexpected or undesirable behavior in complex systems is a prevalent challenge. This issue becomes especially crucial in modern cloud applications that employ numerous microservices. Although the machine learning and systems research communities have proposed various techniques to tackle this problem, there is currently a lack of standardized datasets for quantitative benchmarking. Consequently, research groups are compelled to create their own datasets for experimentation. This paper introduces a dataset specifically designed for evaluating root cause analyses in microservice-based applications. The dataset encompasses latency, requests, and availability metrics emitted in 5-minute intervals from a distributed application. In addition to normal operation metrics, the dataset includes 68 injected performance issues, which increase latency and reduce availability throughout the system. We showcase how this dataset can be used to evaluate the accuracy of a variety of methods spanning different causal and non-causal characterisations of the root cause analysis problem. We hope the new dataset, available at https://github.com/amazon-science/petshop-root-cause-analysis/ enables further development of techniques in this important area.","sentences":["Identifying root causes for unexpected or undesirable behavior in complex systems is a prevalent challenge.","This issue becomes especially crucial in modern cloud applications that employ numerous microservices.","Although the machine learning and systems research communities have proposed various techniques to tackle this problem, there is currently a lack of standardized datasets for quantitative benchmarking.","Consequently, research groups are compelled to create their own datasets for experimentation.","This paper introduces a dataset specifically designed for evaluating root cause analyses in microservice-based applications.","The dataset encompasses latency, requests, and availability metrics emitted in 5-minute intervals from a distributed application.","In addition to normal operation metrics, the dataset includes 68 injected performance issues, which increase latency and reduce availability throughout the system.","We showcase how this dataset can be used to evaluate the accuracy of a variety of methods spanning different causal and non-causal characterisations of the root cause analysis problem.","We hope the new dataset, available at https://github.com/amazon-science/petshop-root-cause-analysis/ enables further development of techniques in this important area."],"url":"http://arxiv.org/abs/2311.04806v1"}
{"created":"2023-11-08 16:18:32","title":"DACBERT: Leveraging Dependency Agreement for Cost-Efficient Bert Pretraining","abstract":"Building on the cost-efficient pretraining advancements brought about by Crammed BERT, we enhance its performance and interpretability further by introducing a novel pretrained model Dependency Agreement Crammed BERT (DACBERT) and its two-stage pretraining framework - Dependency Agreement Pretraining. This framework, grounded by linguistic theories, seamlessly weaves syntax and semantic information into the pretraining process. The first stage employs four dedicated submodels to capture representative dependency agreements at the chunk level, effectively converting these agreements into embeddings. The second stage uses these refined embeddings, in tandem with conventional BERT embeddings, to guide the pretraining of the rest of the model. Evaluated on the GLUE benchmark, our DACBERT demonstrates notable improvement across various tasks, surpassing Crammed BERT by 3.13% in the RTE task and by 2.26% in the MRPC task. Furthermore, our method boosts the average GLUE score by 0.83%, underscoring its significant potential. The pretraining process can be efficiently executed on a single GPU within a 24-hour cycle, necessitating no supplementary computational resources or extending the pretraining duration compared with the Crammed BERT. Extensive studies further illuminate our approach's instrumental role in bolstering the interpretability of pretrained language models for natural language understanding tasks.","sentences":["Building on the cost-efficient pretraining advancements brought about by Crammed BERT, we enhance its performance and interpretability further by introducing a novel pretrained model Dependency Agreement Crammed BERT (DACBERT) and its two-stage pretraining framework - Dependency Agreement Pretraining.","This framework, grounded by linguistic theories, seamlessly weaves syntax and semantic information into the pretraining process.","The first stage employs four dedicated submodels to capture representative dependency agreements at the chunk level, effectively converting these agreements into embeddings.","The second stage uses these refined embeddings, in tandem with conventional BERT embeddings, to guide the pretraining of the rest of the model.","Evaluated on the GLUE benchmark, our DACBERT demonstrates notable improvement across various tasks, surpassing Crammed BERT by 3.13% in the RTE task and by 2.26% in the MRPC task.","Furthermore, our method boosts the average GLUE score by 0.83%, underscoring its significant potential.","The pretraining process can be efficiently executed on a single GPU within a 24-hour cycle, necessitating no supplementary computational resources or extending the pretraining duration compared with the Crammed BERT.","Extensive studies further illuminate our approach's instrumental role in bolstering the interpretability of pretrained language models for natural language understanding tasks."],"url":"http://arxiv.org/abs/2311.04799v1"}
{"created":"2023-11-08 16:18:21","title":"Tools for Refactoring to Microservices: A Preliminary Usability Report","abstract":"While Microservices are a preferred choice for modern cloud-based applications, the migration and architectural refactoring of existing legacy systems is still a major challenge in industry. To address this, academia has proposed many strategies and approaches that aim to automate the process of decomposing a monolith into functional units. In this study, we review existing migration approaches regarding techniques used and tool support. From 91 publications, we extracted 22 tools, 7 of which address service decomposition. To assess them from an end-user perspective, we investigated their underlying techniques, installation, documentation, usability and support. For 5 of them, we generated service cuts using reference applications. The results of our preliminary work suggest that the inspected tools pursue promising concepts, but lack maturity and generalizability for reliable use by industry.","sentences":["While Microservices are a preferred choice for modern cloud-based applications, the migration and architectural refactoring of existing legacy systems is still a major challenge in industry.","To address this, academia has proposed many strategies and approaches that aim to automate the process of decomposing a monolith into functional units.","In this study, we review existing migration approaches regarding techniques used and tool support.","From 91 publications, we extracted 22 tools, 7 of which address service decomposition.","To assess them from an end-user perspective, we investigated their underlying techniques, installation, documentation, usability and support.","For 5 of them, we generated service cuts using reference applications.","The results of our preliminary work suggest that the inspected tools pursue promising concepts, but lack maturity and generalizability for reliable use by industry."],"url":"http://arxiv.org/abs/2311.04798v1"}
{"created":"2023-11-08 16:16:44","title":"CloverLeaf on Intel Multi-Core CPUs: A Case Study in Write-Allocate Evasion","abstract":"In this paper we analyze the MPI-only version of the CloverLeaf code from the SPEChpc 2021 benchmark suite on recent Intel Xeon \"Ice Lake\" and \"Sapphire Rapids\" server CPUs. We observe peculiar breakdowns in performance when the number of processes is prime. Investigating this effect, we create first-principles data traffic models for each of the stencil-like hotspot loops. With application measurements and microbenchmarks to study memory data traffic behavior, we can connect the breakdowns to SpecI2M, a new write-allocate evasion feature in current Intel CPUs. We identify conditions under which SpecI2M works as intended and where it fails to avoid write-allocate transfers. Write-allocate evasion works best if large arrays are written consecutively; in the CloverLeaf code, non-temporal stores can be employed on top for best results. For serial and full-node cases we are able to predict the memory data volume analytically with an error of a few percent. We find that if the number of processes is prime, SpecI2M fails to work properly, which we can attribute to short inner loops emerging from the one-dimensional domain decomposition in this case. We can also rule out other possible causes of the prime number effect, such as breaking layer conditions, MPI communication overhead, and load imbalance.","sentences":["In this paper we analyze the MPI-only version of the CloverLeaf code from the SPEChpc 2021 benchmark suite on recent Intel Xeon \"Ice Lake\" and \"Sapphire Rapids\" server CPUs.","We observe peculiar breakdowns in performance when the number of processes is prime.","Investigating this effect, we create first-principles data traffic models for each of the stencil-like hotspot loops.","With application measurements and microbenchmarks to study memory data traffic behavior, we can connect the breakdowns to SpecI2M, a new write-allocate evasion feature in current Intel CPUs.","We identify conditions under which SpecI2M works as intended and where it fails to avoid write-allocate transfers.","Write-allocate evasion works best if large arrays are written consecutively; in the CloverLeaf code, non-temporal stores can be employed on top for best results.","For serial and full-node cases we are able to predict the memory data volume analytically with an error of a few percent.","We find that if the number of processes is prime, SpecI2M fails to work properly, which we can attribute to short inner loops emerging from the one-dimensional domain decomposition in this case.","We can also rule out other possible causes of the prime number effect, such as breaking layer conditions, MPI communication overhead, and load imbalance."],"url":"http://arxiv.org/abs/2311.04797v1"}
{"created":"2023-11-08 16:10:28","title":"Determination of toxic comments and unintended model bias minimization using Deep learning approach","abstract":"Online conversations can be toxic and subjected to threats, abuse, or harassment. To identify toxic text comments, several deep learning and machine learning models have been proposed throughout the years. However, recent studies demonstrate that because of the imbalances in the training data, some models are more likely to show unintended biases including gender bias and identity bias. In this research, our aim is to detect toxic comment and reduce the unintended bias concerning identity features such as race, gender, sex, religion by fine-tuning an attention based model called BERT(Bidirectional Encoder Representation from Transformers). We apply weighted loss to address the issue of unbalanced data and compare the performance of a fine-tuned BERT model with a traditional Logistic Regression model in terms of classification and bias minimization. The Logistic Regression model with the TFIDF vectorizer achieve 57.1% accuracy, and fine-tuned BERT model's accuracy is 89%. Code is available at https://github.com/zim10/Determine_Toxic_comment_and_identity_bias.git","sentences":["Online conversations can be toxic and subjected to threats, abuse, or harassment.","To identify toxic text comments, several deep learning and machine learning models have been proposed throughout the years.","However, recent studies demonstrate that because of the imbalances in the training data, some models are more likely to show unintended biases including gender bias and identity bias.","In this research, our aim is to detect toxic comment and reduce the unintended bias concerning identity features such as race, gender, sex, religion by fine-tuning an attention based model called BERT(Bidirectional Encoder Representation from Transformers).","We apply weighted loss to address the issue of unbalanced data and compare the performance of a fine-tuned BERT model with a traditional Logistic Regression model in terms of classification and bias minimization.","The Logistic Regression model with the TFIDF vectorizer achieve 57.1% accuracy, and fine-tuned BERT model's accuracy is 89%.","Code is available at https://github.com/zim10/Determine_Toxic_comment_and_identity_bias.git"],"url":"http://arxiv.org/abs/2311.04789v1"}
{"created":"2023-11-08 16:10:17","title":"Energy-efficient Wireless Image Retrieval for IoT Devices by Transmitting a TinyML Model","abstract":"This work considers a scenario in which an edge server collects data from Internet of Things (IoT) devices equipped with wake-up receivers. Although this procedure enables on-demand data collection, there is still energy waste if the content of the transmitted data following the wake-up is irrelevant. To mitigate this, we advocate the use of Tiny Machine Learning (ML) to enable a semantic response from the IoT devices, so they can send only semantically relevant data. Nevertheless, receiving the ML model and the ML processing at the IoT devices consumes additional energy. We consider the specific instance of image retrieval and investigate the gain brought by the proposed scheme in terms of energy efficiency, considering both the energy cost of introducing the ML model as well as that of wireless communication. The numerical evaluation shows that, compared to a baseline scheme, the proposed scheme can realize both high retrieval accuracy and high energy efficiency, which reaches up to 70% energy reduction when the number of stored images is equal to or larger than 8.","sentences":["This work considers a scenario in which an edge server collects data from Internet of Things (IoT) devices equipped with wake-up receivers.","Although this procedure enables on-demand data collection, there is still energy waste if the content of the transmitted data following the wake-up is irrelevant.","To mitigate this, we advocate the use of Tiny Machine Learning (ML) to enable a semantic response from the IoT devices, so they can send only semantically relevant data.","Nevertheless, receiving the ML model and the ML processing at the IoT devices consumes additional energy.","We consider the specific instance of image retrieval and investigate the gain brought by the proposed scheme in terms of energy efficiency, considering both the energy cost of introducing the ML model as well as that of wireless communication.","The numerical evaluation shows that, compared to a baseline scheme, the proposed scheme can realize both high retrieval accuracy and high energy efficiency, which reaches up to 70% energy reduction when the number of stored images is equal to or larger than 8."],"url":"http://arxiv.org/abs/2311.04788v1"}
{"created":"2023-11-08 16:09:25","title":"Why Do Clinical Probabilistic Models Fail To Transport Between Sites?","abstract":"The rising popularity of artificial intelligence in healthcare is highlighting the problem that a computational model achieving super-human clinical performance at its training sites may perform substantially worse at new sites. In this perspective, we present common sources for this failure to transport, which we divide into sources under the control of the experimenter and sources inherent to the clinical data-generating process. Of the inherent sources we look a little deeper into site-specific clinical practices that can affect the data distribution, and propose a potential solution intended to isolate the imprint of those practices on the data from the patterns of disease cause and effect that are the usual target of clinical models.","sentences":["The rising popularity of artificial intelligence in healthcare is highlighting the problem that a computational model achieving super-human clinical performance at its training sites may perform substantially worse at new sites.","In this perspective, we present common sources for this failure to transport, which we divide into sources under the control of the experimenter and sources inherent to the clinical data-generating process.","Of the inherent sources we look a little deeper into site-specific clinical practices that can affect the data distribution, and propose a potential solution intended to isolate the imprint of those practices on the data from the patterns of disease cause and effect that are the usual target of clinical models."],"url":"http://arxiv.org/abs/2311.04787v1"}
{"created":"2023-11-08 16:01:15","title":"VioLA: Aligning Videos to 2D LiDAR Scans","abstract":"We study the problem of aligning a video that captures a local portion of an environment to the 2D LiDAR scan of the entire environment. We introduce a method (VioLA) that starts with building a semantic map of the local scene from the image sequence, then extracts points at a fixed height for registering to the LiDAR map. Due to reconstruction errors or partial coverage of the camera scan, the reconstructed semantic map may not contain sufficient information for registration. To address this problem, VioLA makes use of a pre-trained text-to-image inpainting model paired with a depth completion model for filling in the missing scene content in a geometrically consistent fashion to support pose registration. We evaluate VioLA on two real-world RGB-D benchmarks, as well as a self-captured dataset of a large office scene. Notably, our proposed scene completion module improves the pose registration performance by up to 20%.","sentences":["We study the problem of aligning a video that captures a local portion of an environment to the 2D LiDAR scan of the entire environment.","We introduce a method (VioLA) that starts with building a semantic map of the local scene from the image sequence, then extracts points at a fixed height for registering to the LiDAR map.","Due to reconstruction errors or partial coverage of the camera scan, the reconstructed semantic map may not contain sufficient information for registration.","To address this problem, VioLA makes use of a pre-trained text-to-image inpainting model paired with a depth completion model for filling in the missing scene content in a geometrically consistent fashion to support pose registration.","We evaluate VioLA on two real-world RGB-D benchmarks, as well as a self-captured dataset of a large office scene.","Notably, our proposed scene completion module improves the pose registration performance by up to 20%."],"url":"http://arxiv.org/abs/2311.04783v1"}
{"created":"2023-11-08 15:57:26","title":"On the Multiple Roles of Ontologies in Explainable AI","abstract":"This paper discusses the different roles that explicit knowledge, in particular ontologies, can play in Explainable AI and in the development of human-centric explainable systems and intelligible explanations. We consider three main perspectives in which ontologies can contribute significantly, namely reference modelling, common-sense reasoning, and knowledge refinement and complexity management. We overview some of the existing approaches in the literature, and we position them according to these three proposed perspectives. The paper concludes by discussing what challenges still need to be addressed to enable ontology-based approaches to explanation and to evaluate their human-understandability and effectiveness.","sentences":["This paper discusses the different roles that explicit knowledge, in particular ontologies, can play in Explainable AI and in the development of human-centric explainable systems and intelligible explanations.","We consider three main perspectives in which ontologies can contribute significantly, namely reference modelling, common-sense reasoning, and knowledge refinement and complexity management.","We overview some of the existing approaches in the literature, and we position them according to these three proposed perspectives.","The paper concludes by discussing what challenges still need to be addressed to enable ontology-based approaches to explanation and to evaluate their human-understandability and effectiveness."],"url":"http://arxiv.org/abs/2311.04778v1"}
{"created":"2023-11-08 15:55:18","title":"Lidar Annotation Is All You Need","abstract":"In recent years, computer vision has transformed fields such as medical imaging, object recognition, and geospatial analytics. One of the fundamental tasks in computer vision is semantic image segmentation, which is vital for precise object delineation. Autonomous driving represents one of the key areas where computer vision algorithms are applied. The task of road surface segmentation is crucial in self-driving systems, but it requires a labor-intensive annotation process in several data domains. The work described in this paper aims to improve the efficiency of image segmentation using a convolutional neural network in a multi-sensor setup. This approach leverages lidar (Light Detection and Ranging) annotations to directly train image segmentation models on RGB images. Lidar supplements the images by emitting laser pulses and measuring reflections to provide depth information. However, lidar's sparse point clouds often create difficulties for accurate object segmentation. Segmentation of point clouds requires time-consuming preliminary data preparation and a large amount of computational resources. The key innovation of our approach is the masked loss, addressing sparse ground-truth masks from point clouds. By calculating loss exclusively where lidar points exist, the model learns road segmentation on images by using lidar points as ground truth. This approach allows for blending of different ground-truth data types during model training. Experimental validation of the approach on benchmark datasets shows comparable performance to a high-quality image segmentation model. Incorporating lidar reduces the load on annotations and enables training of image-segmentation models without loss of segmentation quality. The methodology is tested on diverse datasets, both publicly available and proprietary. The strengths and weaknesses of the proposed method are also discussed in the paper.","sentences":["In recent years, computer vision has transformed fields such as medical imaging, object recognition, and geospatial analytics.","One of the fundamental tasks in computer vision is semantic image segmentation, which is vital for precise object delineation.","Autonomous driving represents one of the key areas where computer vision algorithms are applied.","The task of road surface segmentation is crucial in self-driving systems, but it requires a labor-intensive annotation process in several data domains.","The work described in this paper aims to improve the efficiency of image segmentation using a convolutional neural network in a multi-sensor setup.","This approach leverages lidar (Light Detection and Ranging) annotations to directly train image segmentation models on RGB images.","Lidar supplements the images by emitting laser pulses and measuring reflections to provide depth information.","However, lidar's sparse point clouds often create difficulties for accurate object segmentation.","Segmentation of point clouds requires time-consuming preliminary data preparation and a large amount of computational resources.","The key innovation of our approach is the masked loss, addressing sparse ground-truth masks from point clouds.","By calculating loss exclusively where lidar points exist, the model learns road segmentation on images by using lidar points as ground truth.","This approach allows for blending of different ground-truth data types during model training.","Experimental validation of the approach on benchmark datasets shows comparable performance to a high-quality image segmentation model.","Incorporating lidar reduces the load on annotations and enables training of image-segmentation models without loss of segmentation quality.","The methodology is tested on diverse datasets, both publicly available and proprietary.","The strengths and weaknesses of the proposed method are also discussed in the paper."],"url":"http://arxiv.org/abs/2311.04777v1"}
{"created":"2023-11-08 15:52:32","title":"Towards a Unified Framework of Contrastive Learning for Disentangled Representations","abstract":"Contrastive learning has recently emerged as a promising approach for learning data representations that discover and disentangle the explanatory factors of the data. Previous analyses of such approaches have largely focused on individual contrastive losses, such as noise-contrastive estimation (NCE) and InfoNCE, and rely on specific assumptions about the data generating process. This paper extends the theoretical guarantees for disentanglement to a broader family of contrastive methods, while also relaxing the assumptions about the data distribution. Specifically, we prove identifiability of the true latents for four contrastive losses studied in this paper, without imposing common independence assumptions. The theoretical findings are validated on several benchmark datasets. Finally, practical limitations of these methods are also investigated.","sentences":["Contrastive learning has recently emerged as a promising approach for learning data representations that discover and disentangle the explanatory factors of the data.","Previous analyses of such approaches have largely focused on individual contrastive losses, such as noise-contrastive estimation (NCE) and InfoNCE, and rely on specific assumptions about the data generating process.","This paper extends the theoretical guarantees for disentanglement to a broader family of contrastive methods, while also relaxing the assumptions about the data distribution.","Specifically, we prove identifiability of the true latents for four contrastive losses studied in this paper, without imposing common independence assumptions.","The theoretical findings are validated on several benchmark datasets.","Finally, practical limitations of these methods are also investigated."],"url":"http://arxiv.org/abs/2311.04774v1"}
{"created":"2023-11-08 15:47:58","title":"Vital Sign Forecasting for Sepsis Patients in ICUs","abstract":"Sepsis and septic shock are a critical medical condition affecting millions globally, with a substantial mortality rate. This paper uses state-of-the-art deep learning (DL) architectures to introduce a multi-step forecasting system to predict vital signs indicative of septic shock progression in Intensive Care Units (ICUs). Our approach utilizes a short window of historical vital sign data to forecast future physiological conditions. We introduce a DL-based vital sign forecasting system that predicts up to 3 hours of future vital signs from 6 hours of past data. We further adopt the DILATE loss function to capture better the shape and temporal dynamics of vital signs, which are critical for clinical decision-making. We compare three DL models, N-BEATS, N-HiTS, and Temporal Fusion Transformer (TFT), using the publicly available eICU Collaborative Research Database (eICU-CRD), highlighting their forecasting capabilities in a critical care setting. We evaluate the performance of our models using mean squared error (MSE) and dynamic time warping (DTW) metrics. Our findings show that while TFT excels in capturing overall trends, N-HiTS is superior in retaining short-term fluctuations within a predefined range. This paper demonstrates the potential of deep learning in transforming the monitoring systems in ICUs, potentially leading to significant improvements in patient care and outcomes by accurately forecasting vital signs to assist healthcare providers in detecting early signs of physiological instability and anticipating septic shock.","sentences":["Sepsis and septic shock are a critical medical condition affecting millions globally, with a substantial mortality rate.","This paper uses state-of-the-art deep learning (DL) architectures to introduce a multi-step forecasting system to predict vital signs indicative of septic shock progression in Intensive Care Units (ICUs).","Our approach utilizes a short window of historical vital sign data to forecast future physiological conditions.","We introduce a DL-based vital sign forecasting system that predicts up to 3 hours of future vital signs from 6 hours of past data.","We further adopt the DILATE loss function to capture better the shape and temporal dynamics of vital signs, which are critical for clinical decision-making.","We compare three DL models, N-BEATS, N-HiTS, and Temporal Fusion Transformer (TFT), using the publicly available eICU Collaborative Research Database (eICU-CRD), highlighting their forecasting capabilities in a critical care setting.","We evaluate the performance of our models using mean squared error (MSE) and dynamic time warping (DTW) metrics.","Our findings show that while TFT excels in capturing overall trends, N-HiTS is superior in retaining short-term fluctuations within a predefined range.","This paper demonstrates the potential of deep learning in transforming the monitoring systems in ICUs, potentially leading to significant improvements in patient care and outcomes by accurately forecasting vital signs to assist healthcare providers in detecting early signs of physiological instability and anticipating septic shock."],"url":"http://arxiv.org/abs/2311.04770v1"}
{"created":"2023-11-08 15:40:10","title":"Interpersonal Trust in OSS: Exploring Dimensions of Trust in GitHub Pull Requests","abstract":"Interpersonal trust plays a crucial role in facilitating collaborative tasks, such as software development. While previous research recognizes the significance of trust in an organizational setting, there is a lack of understanding in how trust is exhibited in OSS distributed teams, where there is an absence of direct, in-person communications. To foster trust and collaboration in OSS teams, we need to understand what trust is and how it is exhibited in written developer communications (e.g., pull requests, chats). In this paper, we first investigate various dimensions of trust to identify the ways trusting behavior can be observed in OSS. Next, we sample a set of 100 GitHub pull requests from Apache Software Foundation (ASF) projects, to analyze and demonstrate how each dimension of trust can be exhibited. Our findings provide preliminary insights into cues that might be helpful to automatically assess team dynamics and establish interpersonal trust in OSS teams, leading to successful and sustainable OSS.","sentences":["Interpersonal trust plays a crucial role in facilitating collaborative tasks, such as software development.","While previous research recognizes the significance of trust in an organizational setting, there is a lack of understanding in how trust is exhibited in OSS distributed teams, where there is an absence of direct, in-person communications.","To foster trust and collaboration in OSS teams, we need to understand what trust is and how it is exhibited in written developer communications (e.g., pull requests, chats).","In this paper, we first investigate various dimensions of trust to identify the ways trusting behavior can be observed in OSS.","Next, we sample a set of 100","GitHub pull requests from Apache Software Foundation (ASF) projects, to analyze and demonstrate how each dimension of trust can be exhibited.","Our findings provide preliminary insights into cues that might be helpful to automatically assess team dynamics and establish interpersonal trust in OSS teams, leading to successful and sustainable OSS."],"url":"http://arxiv.org/abs/2311.04767v1"}
{"created":"2023-11-08 15:39:56","title":"DualTalker: A Cross-Modal Dual Learning Approach for Speech-Driven 3D Facial Animation","abstract":"In recent years, audio-driven 3D facial animation has gained significant attention, particularly in applications such as virtual reality, gaming, and video conferencing. However, accurately modeling the intricate and subtle dynamics of facial expressions remains a challenge. Most existing studies approach the facial animation task as a single regression problem, which often fail to capture the intrinsic inter-modal relationship between speech signals and 3D facial animation and overlook their inherent consistency. Moreover, due to the limited availability of 3D-audio-visual datasets, approaches learning with small-size samples have poor generalizability that decreases the performance. To address these issues, in this study, we propose a cross-modal dual-learning framework, termed DualTalker, aiming at improving data usage efficiency as well as relating cross-modal dependencies. The framework is trained jointly with the primary task (audio-driven facial animation) and its dual task (lip reading) and shares common audio/motion encoder components. Our joint training framework facilitates more efficient data usage by leveraging information from both tasks and explicitly capitalizing on the complementary relationship between facial motion and audio to improve performance. Furthermore, we introduce an auxiliary cross-modal consistency loss to mitigate the potential over-smoothing underlying the cross-modal complementary representations, enhancing the mapping of subtle facial expression dynamics. Through extensive experiments and a perceptual user study conducted on the VOCA and BIWI datasets, we demonstrate that our approach outperforms current state-of-the-art methods both qualitatively and quantitatively. We have made our code and video demonstrations available at https://github.com/sabrina-su/iadf.git.","sentences":["In recent years, audio-driven 3D facial animation has gained significant attention, particularly in applications such as virtual reality, gaming, and video conferencing.","However, accurately modeling the intricate and subtle dynamics of facial expressions remains a challenge.","Most existing studies approach the facial animation task as a single regression problem, which often fail to capture the intrinsic inter-modal relationship between speech signals and 3D facial animation and overlook their inherent consistency.","Moreover, due to the limited availability of 3D-audio-visual datasets, approaches learning with small-size samples have poor generalizability that decreases the performance.","To address these issues, in this study, we propose a cross-modal dual-learning framework, termed DualTalker, aiming at improving data usage efficiency as well as relating cross-modal dependencies.","The framework is trained jointly with the primary task (audio-driven facial animation) and its dual task (lip reading) and shares common audio/motion encoder components.","Our joint training framework facilitates more efficient data usage by leveraging information from both tasks and explicitly capitalizing on the complementary relationship between facial motion and audio to improve performance.","Furthermore, we introduce an auxiliary cross-modal consistency loss to mitigate the potential over-smoothing underlying the cross-modal complementary representations, enhancing the mapping of subtle facial expression dynamics.","Through extensive experiments and a perceptual user study conducted on the VOCA and BIWI datasets, we demonstrate that our approach outperforms current state-of-the-art methods both qualitatively and quantitatively.","We have made our code and video demonstrations available at https://github.com/sabrina-su/iadf.git."],"url":"http://arxiv.org/abs/2311.04766v1"}
{"created":"2023-11-08 15:39:27","title":"The voraus-AD Dataset for Anomaly Detection in Robot Applications","abstract":"During the operation of industrial robots, unusual events may endanger the safety of humans and the quality of production. When collecting data to detect such cases, it is not ensured that data from all potentially occurring errors is included as unforeseeable events may happen over time. Therefore, anomaly detection (AD) delivers a practical solution, using only normal data to learn to detect unusual events. We introduce a dataset that allows training and benchmarking of anomaly detection methods for robotic applications based on machine data which will be made publicly available to the research community. As a typical robot task the dataset includes a pick-and-place application which involves movement, actions of the end effector and interactions with the objects of the environment. Since several of the contained anomalies are not task-specific but general, evaluations on our dataset are transferable to other robotics applications as well. Additionally, we present MVT-Flow (multivariate time-series flow) as a new baseline method for anomaly detection: It relies on deep-learning-based density estimation with normalizing flows, tailored to the data domain by taking its structure into account for the architecture. Our evaluation shows that MVT-Flow outperforms baselines from previous work by a large margin of 6.2% in area under ROC.","sentences":["During the operation of industrial robots, unusual events may endanger the safety of humans and the quality of production.","When collecting data to detect such cases, it is not ensured that data from all potentially occurring errors is included as unforeseeable events may happen over time.","Therefore, anomaly detection (AD) delivers a practical solution, using only normal data to learn to detect unusual events.","We introduce a dataset that allows training and benchmarking of anomaly detection methods for robotic applications based on machine data which will be made publicly available to the research community.","As a typical robot task the dataset includes a pick-and-place application which involves movement, actions of the end effector and interactions with the objects of the environment.","Since several of the contained anomalies are not task-specific but general, evaluations on our dataset are transferable to other robotics applications as well.","Additionally, we present MVT-Flow (multivariate time-series flow) as a new baseline method for anomaly detection: It relies on deep-learning-based density estimation with normalizing flows, tailored to the data domain by taking its structure into account for the architecture.","Our evaluation shows that MVT-Flow outperforms baselines from previous work by a large margin of 6.2% in area under ROC."],"url":"http://arxiv.org/abs/2311.04765v1"}
{"created":"2023-11-08 15:39:00","title":"AutoWS: Automate Weights Streaming in Layer-wise Pipelined DNN Accelerators","abstract":"With the great success of Deep Neural Networks (DNN), the design of efficient hardware accelerators has triggered wide interest in the research community. Existing research explores two architectural strategies: sequential layer execution and layer-wise pipelining. While the former supports a wider range of models, the latter is favoured for its enhanced customization and efficiency. A challenge for the layer-wise pipelining architecture is its substantial demand for the on-chip memory for weights storage, impeding the deployment of large-scale networks on resource-constrained devices. This paper introduces AutoWS, a pioneering memory management methodology that exploits both on-chip and off-chip memory to optimize weight storage within a layer-wise pipelining architecture, taking advantage of its static schedule. Through a comprehensive investigation on both the hardware design and the Design Space Exploration, our methodology is fully automated and enables the deployment of large-scale DNN models on resource-constrained devices, which was not possible in existing works that target layer-wise pipelining architectures. AutoWS is open-source: https://github.com/Yu-Zhewen/AutoWS","sentences":["With the great success of Deep Neural Networks (DNN), the design of efficient hardware accelerators has triggered wide interest in the research community.","Existing research explores two architectural strategies: sequential layer execution and layer-wise pipelining.","While the former supports a wider range of models, the latter is favoured for its enhanced customization and efficiency.","A challenge for the layer-wise pipelining architecture is its substantial demand for the on-chip memory for weights storage, impeding the deployment of large-scale networks on resource-constrained devices.","This paper introduces AutoWS, a pioneering memory management methodology that exploits both on-chip and off-chip memory to optimize weight storage within a layer-wise pipelining architecture, taking advantage of its static schedule.","Through a comprehensive investigation on both the hardware design and the Design Space Exploration, our methodology is fully automated and enables the deployment of large-scale DNN models on resource-constrained devices, which was not possible in existing works that target layer-wise pipelining architectures.","AutoWS is open-source: https://github.com/Yu-Zhewen/AutoWS"],"url":"http://arxiv.org/abs/2311.04764v1"}
{"created":"2023-11-08 15:34:15","title":"FAIR Knowledge Graphs with Semantic Units: a Prototype","abstract":"Knowledge graphs and ontologies are becoming increasingly important in the context of making data and metadata findable, accessible, interoperable, and reusable (FAIR). We introduce the concept of Semantic Units for organizing Knowledge Graphs into identifiable and semantically meaningful subgraphs. Each Semantic Unit is represented in the graph by its own resource that instantiates a Semantic Unit class. Different types of Semantic Units are distinguished, and together they can organize a Knowledge Graph into different levels of representational granularity with partially overlapping, partially enclosed subgraphs that users of Knowledge Graphs can refer to for making statements about statements. The use of Semantic Units in Knowledge Graphs supports making them FAIR and increases the human-reader-actionability of their data and metadata by increasing the graph's cognitive interoperability by increasing its explorability for a human reader. We introduce a minimal prototype web application for a user-driven FAIR Knowledge Graph that is based on Semantic Units.","sentences":["Knowledge graphs and ontologies are becoming increasingly important in the context of making data and metadata findable, accessible, interoperable, and reusable (FAIR).","We introduce the concept of Semantic Units for organizing Knowledge Graphs into identifiable and semantically meaningful subgraphs.","Each Semantic Unit is represented in the graph by its own resource that instantiates a Semantic Unit class.","Different types of Semantic Units are distinguished, and together they can organize a Knowledge Graph into different levels of representational granularity with partially overlapping, partially enclosed subgraphs that users of Knowledge Graphs can refer to for making statements about statements.","The use of Semantic Units in Knowledge Graphs supports making them FAIR and increases the human-reader-actionability of their data and metadata by increasing the graph's cognitive interoperability by increasing its explorability for a human reader.","We introduce a minimal prototype web application for a user-driven FAIR Knowledge Graph that is based on Semantic Units."],"url":"http://arxiv.org/abs/2311.04761v1"}
{"created":"2023-11-08 15:33:06","title":"Towards Open-world Cross-Domain Sequential Recommendation: A Model-Agnostic Contrastive Denoising Approach","abstract":"Cross-domain sequential recommendation (CDSR) aims to address the data sparsity problems that exist in traditional sequential recommendation (SR) systems.   The existing approaches aim to design a specific cross-domain unit that can transfer and propagate information across multiple domains by relying on overlapping users with abundant behaviors. However, in real-world recommender systems, CDSR scenarios usually consist of a majority of long-tailed users with sparse behaviors and cold-start users who only exist in one domain. This leads to a drop in the performance of existing CDSR methods in the real-world industry platform. Therefore, improving the consistency and effectiveness of models in open-world CDSR scenarios is crucial for constructing CDSR models (\\textit{1st} CH). Recently, some SR approaches have utilized auxiliary behaviors to complement the information for long-tailed users. However, these multi-behavior SR methods cannot deliver promising performance in CDSR, as they overlook the semantic gap between target and auxiliary behaviors, as well as user interest deviation across domains (\\textit{2nd} CH).","sentences":["Cross-domain sequential recommendation (CDSR) aims to address the data sparsity problems that exist in traditional sequential recommendation (SR) systems.   ","The existing approaches aim to design a specific cross-domain unit that can transfer and propagate information across multiple domains by relying on overlapping users with abundant behaviors.","However, in real-world recommender systems, CDSR scenarios usually consist of a majority of long-tailed users with sparse behaviors and cold-start users who only exist in one domain.","This leads to a drop in the performance of existing CDSR methods in the real-world industry platform.","Therefore, improving the consistency and effectiveness of models in open-world CDSR scenarios is crucial for constructing CDSR models (\\textit{1st} CH).","Recently, some SR approaches have utilized auxiliary behaviors to complement the information for long-tailed users.","However, these multi-behavior SR methods cannot deliver promising performance in CDSR, as they overlook the semantic gap between target and auxiliary behaviors, as well as user interest deviation across domains (\\textit{2nd} CH)."],"url":"http://arxiv.org/abs/2311.04760v1"}
{"created":"2023-11-08 15:29:33","title":"Towards Understanding Emotions in Informal Developer Interactions: A Gitter Chat Study","abstract":"Emotions play a significant role in teamwork and collaborative activities like software development. While researchers have analyzed developer emotions in various software artifacts (e.g., issues, pull requests), few studies have focused on understanding the broad spectrum of emotions expressed in chats. As one of the most widely used means of communication, chats contain valuable information in the form of informal conversations, such as negative perspectives about adopting a tool. In this paper, we present a dataset of developer chat messages manually annotated with a wide range of emotion labels (and sub-labels), and analyze the type of information present in those messages. We also investigate the unique signals of emotions specific to chats and distinguish them from other forms of software communication. Our findings suggest that chats have fewer expressions of Approval and Fear but more expressions of Curiosity compared to GitHub comments. We also notice that Confusion is frequently observed when discussing programming-related information such as unexpected software behavior. Overall, our study highlights the potential of mining emotions in developer chats for supporting software maintenance and evolution tools.","sentences":["Emotions play a significant role in teamwork and collaborative activities like software development.","While researchers have analyzed developer emotions in various software artifacts (e.g., issues, pull requests), few studies have focused on understanding the broad spectrum of emotions expressed in chats.","As one of the most widely used means of communication, chats contain valuable information in the form of informal conversations, such as negative perspectives about adopting a tool.","In this paper, we present a dataset of developer chat messages manually annotated with a wide range of emotion labels (and sub-labels), and analyze the type of information present in those messages.","We also investigate the unique signals of emotions specific to chats and distinguish them from other forms of software communication.","Our findings suggest that chats have fewer expressions of Approval and Fear but more expressions of Curiosity compared to GitHub comments.","We also notice that Confusion is frequently observed when discussing programming-related information such as unexpected software behavior.","Overall, our study highlights the potential of mining emotions in developer chats for supporting software maintenance and evolution tools."],"url":"http://arxiv.org/abs/2311.04755v1"}
{"created":"2023-11-08 15:18:09","title":"Online Min Cost Circulation for Multi-Object Tracking on Fragments","abstract":"Multi-object tracking (MOT) or global data association problem is commonly approached as a minimum-cost-flow or minimum-cost-circulation problem on a graph. While there have been numerous studies aimed at enhancing algorithm efficiency, most of them focus on the batch problem, where all the data must be available simultaneously to construct a static graph. However, with the growing number of applications that generate streaming data, an efficient online algorithm is required to handle the streaming nature of the input. In this paper, we present an online extension of the well-known negative cycle canceling algorithm for solving the multi-object tracking problem with streaming fragmented data. We provide a proof of correctness for the proposed algorithm and demonstrate its efficiency through numerical experiments.","sentences":["Multi-object tracking (MOT) or global data association problem is commonly approached as a minimum-cost-flow or minimum-cost-circulation problem on a graph.","While there have been numerous studies aimed at enhancing algorithm efficiency, most of them focus on the batch problem, where all the data must be available simultaneously to construct a static graph.","However, with the growing number of applications that generate streaming data, an efficient online algorithm is required to handle the streaming nature of the input.","In this paper, we present an online extension of the well-known negative cycle canceling algorithm for solving the multi-object tracking problem with streaming fragmented data.","We provide a proof of correctness for the proposed algorithm and demonstrate its efficiency through numerical experiments."],"url":"http://arxiv.org/abs/2311.04749v1"}
{"created":"2023-11-08 15:15:56","title":"Exchanging... Watch out!","abstract":"During a conversation, individuals take turns speaking and engage in exchanges, which can occur smoothly or involve interruptions. Listeners have various ways of participating, such as displaying backchannels, signalling the aim to take a turn, waiting for the speaker to yield the floor, or even interrupting and taking over the conversation.   These exchanges are commonplace in natural interactions. To create realistic and engaging interactions between human participants and embodied conversational agents (ECAs), it is crucial to equip virtual agents with the ability to manage these exchanges. This includes being able to initiate or respond to signals from the human user. In order to achieve this, we annotate, analyze and characterize these exchanges in human-human conversations. In this paper, we present an analysis of multimodal features, with a focus on prosodic features such as pitch (F0) and loudness, as well as facial expressions, to describe different types of exchanges.","sentences":["During a conversation, individuals take turns speaking and engage in exchanges, which can occur smoothly or involve interruptions.","Listeners have various ways of participating, such as displaying backchannels, signalling the aim to take a turn, waiting for the speaker to yield the floor, or even interrupting and taking over the conversation.   ","These exchanges are commonplace in natural interactions.","To create realistic and engaging interactions between human participants and embodied conversational agents (ECAs), it is crucial to equip virtual agents with the ability to manage these exchanges.","This includes being able to initiate or respond to signals from the human user.","In order to achieve this, we annotate, analyze and characterize these exchanges in human-human conversations.","In this paper, we present an analysis of multimodal features, with a focus on prosodic features such as pitch (F0) and loudness, as well as facial expressions, to describe different types of exchanges."],"url":"http://arxiv.org/abs/2311.04747v1"}
{"created":"2023-11-08 15:12:31","title":"Euclidean, Projective, Conformal: Choosing a Geometric Algebra for Equivariant Transformers","abstract":"The Geometric Algebra Transformer (GATr) is a versatile architecture for geometric deep learning based on projective geometric algebra. We generalize this architecture into a blueprint that allows one to construct a scalable transformer architecture given any geometric (or Clifford) algebra. We study versions of this architecture for Euclidean, projective, and conformal algebras, all of which are suited to represent 3D data, and evaluate them in theory and practice. The simplest Euclidean architecture is computationally cheap, but has a smaller symmetry group and is not as sample-efficient, while the projective model is not sufficiently expressive. Both the conformal algebra and an improved version of the projective algebra define powerful, performant architectures.","sentences":["The Geometric Algebra Transformer (GATr) is a versatile architecture for geometric deep learning based on projective geometric algebra.","We generalize this architecture into a blueprint that allows one to construct a scalable transformer architecture given any geometric (or Clifford) algebra.","We study versions of this architecture for Euclidean, projective, and conformal algebras, all of which are suited to represent 3D data, and evaluate them in theory and practice.","The simplest Euclidean architecture is computationally cheap, but has a smaller symmetry group and is not as sample-efficient, while the projective model is not sufficiently expressive.","Both the conformal algebra and an improved version of the projective algebra define powerful, performant architectures."],"url":"http://arxiv.org/abs/2311.04744v1"}
{"created":"2023-11-08 15:11:57","title":"Using large language models to study human memory for meaningful narratives","abstract":"One of the most impressive achievements of the AI revolution is the development of large language models that can generate meaningful text and respond to instructions in plain English with no additional training necessary. Here we show that language models can be used as a scientific instrument for studying human memory for meaningful material. We developed a pipeline for designing large scale memory experiments and analyzing the obtained results. We performed online memory experiments with a large number of participants and collected recognition and recall data for narratives of different lengths. We found that both recall and recognition performance scale linearly with narrative length. Furthermore, in order to investigate the role of narrative comprehension in memory, we repeated these experiments using scrambled versions of the presented stories. We found that even though recall performance declined significantly, recognition remained largely unaffected. Interestingly, recalls in this condition seem to follow the original narrative order rather than the scrambled presentation, pointing to a contextual reconstruction of the story in memory.","sentences":["One of the most impressive achievements of the AI revolution is the development of large language models that can generate meaningful text and respond to instructions in plain English with no additional training necessary.","Here we show that language models can be used as a scientific instrument for studying human memory for meaningful material.","We developed a pipeline for designing large scale memory experiments and analyzing the obtained results.","We performed online memory experiments with a large number of participants and collected recognition and recall data for narratives of different lengths.","We found that both recall and recognition performance scale linearly with narrative length.","Furthermore, in order to investigate the role of narrative comprehension in memory, we repeated these experiments using scrambled versions of the presented stories.","We found that even though recall performance declined significantly, recognition remained largely unaffected.","Interestingly, recalls in this condition seem to follow the original narrative order rather than the scrambled presentation, pointing to a contextual reconstruction of the story in memory."],"url":"http://arxiv.org/abs/2311.04742v1"}
{"created":"2023-11-08 15:08:55","title":"Enhancing Multi-Agent Coordination through Common Operating Picture Integration","abstract":"In multi-agent systems, agents possess only local observations of the environment. Communication between teammates becomes crucial for enhancing coordination. Past research has primarily focused on encoding local information into embedding messages which are unintelligible to humans. We find that using these messages in agent's policy learning leads to brittle policies when tested on out-of-distribution initial states. We present an approach to multi-agent coordination, where each agent is equipped with the capability to integrate its (history of) observations, actions and messages received into a Common Operating Picture (COP) and disseminate the COP. This process takes into account the dynamic nature of the environment and the shared mission. We conducted experiments in the StarCraft2 environment to validate our approach. Our results demonstrate the efficacy of COP integration, and show that COP-based training leads to robust policies compared to state-of-the-art Multi-Agent Reinforcement Learning (MARL) methods when faced with out-of-distribution initial states.","sentences":["In multi-agent systems, agents possess only local observations of the environment.","Communication between teammates becomes crucial for enhancing coordination.","Past research has primarily focused on encoding local information into embedding messages which are unintelligible to humans.","We find that using these messages in agent's policy learning leads to brittle policies when tested on out-of-distribution initial states.","We present an approach to multi-agent coordination, where each agent is equipped with the capability to integrate its (history of) observations, actions and messages received into a Common Operating Picture (COP) and disseminate the COP.","This process takes into account the dynamic nature of the environment and the shared mission.","We conducted experiments in the StarCraft2 environment to validate our approach.","Our results demonstrate the efficacy of COP integration, and show that COP-based training leads to robust policies compared to state-of-the-art Multi-Agent Reinforcement Learning (MARL) methods when faced with out-of-distribution initial states."],"url":"http://arxiv.org/abs/2311.04740v1"}
{"created":"2023-11-08 14:58:11","title":"Robust Best-arm Identification in Linear Bandits","abstract":"We study the robust best-arm identification problem (RBAI) in the case of linear rewards. The primary objective is to identify a near-optimal robust arm, which involves selecting arms at every round and assessing their robustness by exploring potential adversarial actions. This approach is particularly relevant when utilizing a simulator and seeking to identify a robust solution for real-world transfer. To this end, we present an instance-dependent lower bound for the robust best-arm identification problem with linear rewards. Furthermore, we propose both static and adaptive bandit algorithms that achieve sample complexity that matches the lower bound. In synthetic experiments, our algorithms effectively identify the best robust arm and perform similarly to the oracle strategy. As an application, we examine diabetes care and the process of learning insulin dose recommendations that are robust with respect to inaccuracies in standard calculators. Our algorithms prove to be effective in identifying robust dosage values across various age ranges of patients.","sentences":["We study the robust best-arm identification problem (RBAI) in the case of linear rewards.","The primary objective is to identify a near-optimal robust arm, which involves selecting arms at every round and assessing their robustness by exploring potential adversarial actions.","This approach is particularly relevant when utilizing a simulator and seeking to identify a robust solution for real-world transfer.","To this end, we present an instance-dependent lower bound for the robust best-arm identification problem with linear rewards.","Furthermore, we propose both static and adaptive bandit algorithms that achieve sample complexity that matches the lower bound.","In synthetic experiments, our algorithms effectively identify the best robust arm and perform similarly to the oracle strategy.","As an application, we examine diabetes care and the process of learning insulin dose recommendations that are robust with respect to inaccuracies in standard calculators.","Our algorithms prove to be effective in identifying robust dosage values across various age ranges of patients."],"url":"http://arxiv.org/abs/2311.04731v1"}
{"created":"2023-11-08 14:57:35","title":"Predicting Properties of Nodes via Community-Aware Features","abstract":"A community structure that is often present in complex networks plays an important role not only in their formation but also shapes dynamics of these networks, affecting properties of their nodes. In this paper, we propose a family of community-aware node features and then investigate their properties. We show that they have high predictive power for classification tasks. We also verify that they contain information that cannot be recovered neither by classical node features nor by node embeddings (both classical as well as structural).","sentences":["A community structure that is often present in complex networks plays an important role not only in their formation but also shapes dynamics of these networks, affecting properties of their nodes.","In this paper, we propose a family of community-aware node features and then investigate their properties.","We show that they have high predictive power for classification tasks.","We also verify that they contain information that cannot be recovered neither by classical node features nor by node embeddings (both classical as well as structural)."],"url":"http://arxiv.org/abs/2311.04730v1"}
{"created":"2023-11-08 14:51:17","title":"Social Motion Prediction with Cognitive Hierarchies","abstract":"Humans exhibit a remarkable capacity for anticipating the actions of others and planning their own actions accordingly. In this study, we strive to replicate this ability by addressing the social motion prediction problem. We introduce a new benchmark, a novel formulation, and a cognition-inspired framework. We present Wusi, a 3D multi-person motion dataset under the context of team sports, which features intense and strategic human interactions and diverse pose distributions. By reformulating the problem from a multi-agent reinforcement learning perspective, we incorporate behavioral cloning and generative adversarial imitation learning to boost learning efficiency and generalization. Furthermore, we take into account the cognitive aspects of the human social action planning process and develop a cognitive hierarchy framework to predict strategic human social interactions. We conduct comprehensive experiments to validate the effectiveness of our proposed dataset and approach. Code and data are available at https://walter0807.github.io/Social-CH/.","sentences":["Humans exhibit a remarkable capacity for anticipating the actions of others and planning their own actions accordingly.","In this study, we strive to replicate this ability by addressing the social motion prediction problem.","We introduce a new benchmark, a novel formulation, and a cognition-inspired framework.","We present Wusi, a 3D multi-person motion dataset under the context of team sports, which features intense and strategic human interactions and diverse pose distributions.","By reformulating the problem from a multi-agent reinforcement learning perspective, we incorporate behavioral cloning and generative adversarial imitation learning to boost learning efficiency and generalization.","Furthermore, we take into account the cognitive aspects of the human social action planning process and develop a cognitive hierarchy framework to predict strategic human social interactions.","We conduct comprehensive experiments to validate the effectiveness of our proposed dataset and approach.","Code and data are available at https://walter0807.github.io/Social-CH/."],"url":"http://arxiv.org/abs/2311.04726v1"}
{"created":"2023-11-08 14:38:10","title":"Training CLIP models on Data from Scientific Papers","abstract":"Contrastive Language-Image Pretraining (CLIP) models are able to capture the semantic relationship of images and texts and have enabled a wide range of applications, from image retrieval to classification. These models are trained with datasets extracted from web crawls, which are of large quantity but limited quality. This paper explores whether limited amounts higher quality data in a specific domain improve the general performance of CLIP models. To this purpose, we extract text-image data from scientific papers hosted in the arXiv and PubMed Central repositories. Experiments on small-scale CLIP models (ViT B/32) show that model performance increases on average, but only moderately. This result indicates that using the data sources considered in the paper to train large-scale CLIP models is a worthwile research direction.","sentences":["Contrastive Language-Image Pretraining (CLIP) models are able to capture the semantic relationship of images and texts and have enabled a wide range of applications, from image retrieval to classification.","These models are trained with datasets extracted from web crawls, which are of large quantity but limited quality.","This paper explores whether limited amounts higher quality data in a specific domain improve the general performance of CLIP models.","To this purpose, we extract text-image data from scientific papers hosted in the arXiv and PubMed Central repositories.","Experiments on small-scale CLIP models (ViT B/32) show that model performance increases on average, but only moderately.","This result indicates that using the data sources considered in the paper to train large-scale CLIP models is a worthwile research direction."],"url":"http://arxiv.org/abs/2311.04711v1"}
{"created":"2023-11-08 14:37:49","title":"The Quest for Content: A Survey of Search-Based Procedural Content Generation for Video Games","abstract":"Video games demand is constantly increasing, which requires the costly production of large amounts of content. Towards this challenge, researchers have developed Search-Based Procedural Content Generation (SBPCG), that is, the (semi-)automated creation of content through search algorithms. We survey the current state of SBPCG, reporting work appeared in the field between 2011-2022 and identifying open research challenges. The results lead to recommendations for practitioners and to the identification of several potential future research avenues for SBPCG.","sentences":["Video games demand is constantly increasing, which requires the costly production of large amounts of content.","Towards this challenge, researchers have developed Search-Based Procedural Content Generation (SBPCG), that is, the (semi-)automated creation of content through search algorithms.","We survey the current state of SBPCG, reporting work appeared in the field between 2011-2022 and identifying open research challenges.","The results lead to recommendations for practitioners and to the identification of several potential future research avenues for SBPCG."],"url":"http://arxiv.org/abs/2311.04710v1"}
{"created":"2023-11-08 14:27:56","title":"Where Do We Meet? Key Factors Influencing Collaboration Across Meeting Spaces","abstract":"Over the past years, there has been a shift towards online and hybrid meeting forms in workplace environments, partly as a consequence of various COVID-19 restrictions. However, the decision-making process on how to best collaborate with team members is predominantly driven by practical concerns. While there is a significant body of literature about where to best meet, this knowledge is fragmented across various disciplines and hard to use in novel meeting solutions. We present the Cross-Space Collaboration model which identifies the main factors that drive the features of in-person collaboration and the meeting aspects that influence these factors such as cognitive load. We designed the model to give guidance to teams and individuals on how to meet in order to have a higher collaboration effectiveness. Finally, we outline how the model can bring added value within new meeting solutions, next generation virtual reality meeting spaces and educational settings.","sentences":["Over the past years, there has been a shift towards online and hybrid meeting forms in workplace environments, partly as a consequence of various COVID-19 restrictions.","However, the decision-making process on how to best collaborate with team members is predominantly driven by practical concerns.","While there is a significant body of literature about where to best meet, this knowledge is fragmented across various disciplines and hard to use in novel meeting solutions.","We present the Cross-Space Collaboration model which identifies the main factors that drive the features of in-person collaboration and the meeting aspects that influence these factors such as cognitive load.","We designed the model to give guidance to teams and individuals on how to meet in order to have a higher collaboration effectiveness.","Finally, we outline how the model can bring added value within new meeting solutions, next generation virtual reality meeting spaces and educational settings."],"url":"http://arxiv.org/abs/2311.04707v1"}
{"created":"2023-11-08 14:22:12","title":"Negotiation Strategies in Ubiquitous Human-Computer Interaction: A Novel Storyboards Scale & Field Study","abstract":"In today's connected society, self-tracking technologies (STTs), such as wearables and mobile fitness apps, empower humans to improve their health and well-being through ubiquitous physical activity monitoring, with several personal and societal benefits. Despite the advances in such technologies' hardware, low user engagement and decreased effectiveness limitations demand more informed and theoretically-founded Human-Computer Interaction designs. To address these challenges, we build upon the previously unexplored Leisure Constraints Negotiation Model and the Transtheoretical Model to systematically define and assess the effectiveness of STTs' features that acknowledge users' contextual constraints and establish human-negotiated STTs narratives. Specifically, we introduce and validate a human-centric scale, StoryWear, which exploits and explores eleven dimensions of negotiation strategies that humans utilize to overcome constraints regarding exercise participation, captured through an inclusive storyboards format. Based on our preliminary studies, StoryWear shows high reliability, rendering it suitable for future work in ubiquitous computing. Our results indicate that negotiation strategies vary in perceived effectiveness and have higher appeal for existing STTs' users, with self-motivation, commitment, and understanding of the negative impact of non-exercise placed at the top. Finally, we give actionable guidelines for real-world implementation and a commentary on the future of personalized training.","sentences":["In today's connected society, self-tracking technologies (STTs), such as wearables and mobile fitness apps, empower humans to improve their health and well-being through ubiquitous physical activity monitoring, with several personal and societal benefits.","Despite the advances in such technologies' hardware, low user engagement and decreased effectiveness limitations demand more informed and theoretically-founded Human-Computer Interaction designs.","To address these challenges, we build upon the previously unexplored Leisure Constraints Negotiation Model and the Transtheoretical Model to systematically define and assess the effectiveness of STTs' features that acknowledge users' contextual constraints and establish human-negotiated STTs narratives.","Specifically, we introduce and validate a human-centric scale, StoryWear, which exploits and explores eleven dimensions of negotiation strategies that humans utilize to overcome constraints regarding exercise participation, captured through an inclusive storyboards format.","Based on our preliminary studies, StoryWear shows high reliability, rendering it suitable for future work in ubiquitous computing.","Our results indicate that negotiation strategies vary in perceived effectiveness and have higher appeal for existing STTs' users, with self-motivation, commitment, and understanding of the negative impact of non-exercise placed at the top.","Finally, we give actionable guidelines for real-world implementation and a commentary on the future of personalized training."],"url":"http://arxiv.org/abs/2311.04705v1"}
