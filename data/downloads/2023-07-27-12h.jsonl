{"created":"2023-07-26 17:59:20","title":"Virtual Mirrors: Non-Line-of-Sight Imaging Beyond the Third Bounce","abstract":"Non-line-of-sight (NLOS) imaging methods are capable of reconstructing complex scenes that are not visible to an observer using indirect illumination. However, they assume only third-bounce illumination, so they are currently limited to single-corner configurations, and present limited visibility when imaging surfaces at certain orientations. To reason about and tackle these limitations, we make the key observation that planar diffuse surfaces behave specularly at wavelengths used in the computational wave-based NLOS imaging domain. We call such surfaces virtual mirrors. We leverage this observation to expand the capabilities of NLOS imaging using illumination beyond the third bounce, addressing two problems: imaging single-corner objects at limited visibility angles, and imaging objects hidden behind two corners. To image objects at limited visibility angles, we first analyze the reflections of the known illuminated point on surfaces of the scene as an estimator of the position and orientation of objects with limited visibility. We then image those limited visibility objects by computationally building secondary apertures at other surfaces that observe the target object from a direct visibility perspective. Beyond single-corner NLOS imaging, we exploit the specular behavior of virtual mirrors to image objects hidden behind a second corner by imaging the space behind such virtual mirrors, where the mirror image of objects hidden around two corners is formed. No specular surfaces were involved in the making of this paper.","sentences":["Non-line-of-sight (NLOS) imaging methods are capable of reconstructing complex scenes that are not visible to an observer using indirect illumination.","However, they assume only third-bounce illumination, so they are currently limited to single-corner configurations, and present limited visibility when imaging surfaces at certain orientations.","To reason about and tackle these limitations, we make the key observation that planar diffuse surfaces behave specularly at wavelengths used in the computational wave-based NLOS imaging domain.","We call such surfaces virtual mirrors.","We leverage this observation to expand the capabilities of NLOS imaging using illumination beyond the third bounce, addressing two problems: imaging single-corner objects at limited visibility angles, and imaging objects hidden behind two corners.","To image objects at limited visibility angles, we first analyze the reflections of the known illuminated point on surfaces of the scene as an estimator of the position and orientation of objects with limited visibility.","We then image those limited visibility objects by computationally building secondary apertures at other surfaces that observe the target object from a direct visibility perspective.","Beyond single-corner NLOS imaging, we exploit the specular behavior of virtual mirrors to image objects hidden behind a second corner by imaging the space behind such virtual mirrors, where the mirror image of objects hidden around two corners is formed.","No specular surfaces were involved in the making of this paper."],"url":"http://arxiv.org/abs/2307.14341v1"}
{"created":"2023-07-26 17:58:07","title":"TabR: Unlocking the Power of Retrieval-Augmented Tabular Deep Learning","abstract":"Deep learning (DL) models for tabular data problems are receiving increasingly more attention, while the algorithms based on gradient-boosted decision trees (GBDT) remain a strong go-to solution. Following the recent trends in other domains, such as natural language processing and computer vision, several retrieval-augmented tabular DL models have been recently proposed. For a given target object, a retrieval-based model retrieves other relevant objects, such as the nearest neighbors, from the available (training) data and uses their features or even labels to make a better prediction. However, we show that the existing retrieval-based tabular DL solutions provide only minor, if any, benefits over the properly tuned simple retrieval-free baselines. Thus, it remains unclear whether the retrieval-based approach is a worthy direction for tabular DL.   In this work, we give a strong positive answer to this question. We start by incrementally augmenting a simple feed-forward architecture with an attention-like retrieval component similar to those of many (tabular) retrieval-based models. Then, we highlight several details of the attention mechanism that turn out to have a massive impact on the performance on tabular data problems, but that were not explored in prior work. As a result, we design TabR -- a simple retrieval-based tabular DL model which, on a set of public benchmarks, demonstrates the best average performance among tabular DL models, becomes the new state-of-the-art on several datasets, and even outperforms GBDT models on the recently proposed ``GBDT-friendly'' benchmark (see the first figure).","sentences":["Deep learning (DL) models for tabular data problems are receiving increasingly more attention, while the algorithms based on gradient-boosted decision trees (GBDT) remain a strong go-to solution.","Following the recent trends in other domains, such as natural language processing and computer vision, several retrieval-augmented tabular DL models have been recently proposed.","For a given target object, a retrieval-based model retrieves other relevant objects, such as the nearest neighbors, from the available (training) data and uses their features or even labels to make a better prediction.","However, we show that the existing retrieval-based tabular DL solutions provide only minor, if any, benefits over the properly tuned simple retrieval-free baselines.","Thus, it remains unclear whether the retrieval-based approach is a worthy direction for tabular DL.   ","In this work, we give a strong positive answer to this question.","We start by incrementally augmenting a simple feed-forward architecture with an attention-like retrieval component similar to those of many (tabular) retrieval-based models.","Then, we highlight several details of the attention mechanism that turn out to have a massive impact on the performance on tabular data problems, but that were not explored in prior work.","As a result, we design TabR -- a simple retrieval-based tabular DL model which, on a set of public benchmarks, demonstrates the best average performance among tabular DL models, becomes the new state-of-the-art on several datasets, and even outperforms GBDT models on the recently proposed ``GBDT-friendly'' benchmark (see the first figure)."],"url":"http://arxiv.org/abs/2307.14338v1"}
{"created":"2023-07-26 17:55:32","title":"MAMo: Leveraging Memory and Attention for Monocular Video Depth Estimation","abstract":"We propose MAMo, a novel memory and attention frame-work for monocular video depth estimation. MAMo can augment and improve any single-image depth estimation networks into video depth estimation models, enabling them to take advantage of the temporal information to predict more accurate depth. In MAMo, we augment model with memory which aids the depth prediction as the model streams through the video. Specifically, the memory stores learned visual and displacement tokens of the previous time instances. This allows the depth network to cross-reference relevant features from the past when predicting depth on the current frame. We introduce a novel scheme to continuously update the memory, optimizing it to keep tokens that correspond with both the past and the present visual information. We adopt attention-based approach to process memory features where we first learn the spatio-temporal relation among the resultant visual and displacement memory tokens using self-attention module. Further, the output features of self-attention are aggregated with the current visual features through cross-attention. The cross-attended features are finally given to a decoder to predict depth on the current frame. Through extensive experiments on several benchmarks, including KITTI, NYU-Depth V2, and DDAD, we show that MAMo consistently improves monocular depth estimation networks and sets new state-of-the-art (SOTA) accuracy. Notably, our MAMo video depth estimation provides higher accuracy with lower latency, when omparing to SOTA cost-volume-based video depth models.","sentences":["We propose MAMo, a novel memory and attention frame-work for monocular video depth estimation.","MAMo can augment and improve any single-image depth estimation networks into video depth estimation models, enabling them to take advantage of the temporal information to predict more accurate depth.","In MAMo, we augment model with memory which aids the depth prediction as the model streams through the video.","Specifically, the memory stores learned visual and displacement tokens of the previous time instances.","This allows the depth network to cross-reference relevant features from the past when predicting depth on the current frame.","We introduce a novel scheme to continuously update the memory, optimizing it to keep tokens that correspond with both the past and the present visual information.","We adopt attention-based approach to process memory features where we first learn the spatio-temporal relation among the resultant visual and displacement memory tokens using self-attention module.","Further, the output features of self-attention are aggregated with the current visual features through cross-attention.","The cross-attended features are finally given to a decoder to predict depth on the current frame.","Through extensive experiments on several benchmarks, including KITTI, NYU-Depth V2, and DDAD, we show that MAMo consistently improves monocular depth estimation networks and sets new state-of-the-art (SOTA) accuracy.","Notably, our MAMo video depth estimation provides higher accuracy with lower latency, when omparing to SOTA cost-volume-based video depth models."],"url":"http://arxiv.org/abs/2307.14336v1"}
{"created":"2023-07-26 17:54:04","title":"WavJourney: Compositional Audio Creation with Large Language Models","abstract":"Large Language Models (LLMs) have shown great promise in integrating diverse expert models to tackle intricate language and vision tasks. Despite their significance in advancing the field of Artificial Intelligence Generated Content (AIGC), their potential in intelligent audio content creation remains unexplored. In this work, we tackle the problem of creating audio content with storylines encompassing speech, music, and sound effects, guided by text instructions. We present WavJourney, a system that leverages LLMs to connect various audio models for audio content generation. Given a text description of an auditory scene, WavJourney first prompts LLMs to generate a structured script dedicated to audio storytelling. The audio script incorporates diverse audio elements, organized based on their spatio-temporal relationships. As a conceptual representation of audio, the audio script provides an interactive and interpretable rationale for human engagement. Afterward, the audio script is fed into a script compiler, converting it into a computer program. Each line of the program calls a task-specific audio generation model or computational operation function (e.g., concatenate, mix). The computer program is then executed to obtain an explainable solution for audio generation. We demonstrate the practicality of WavJourney across diverse real-world scenarios, including science fiction, education, and radio play. The explainable and interactive design of WavJourney fosters human-machine co-creation in multi-round dialogues, enhancing creative control and adaptability in audio production. WavJourney audiolizes the human imagination, opening up new avenues for creativity in multimedia content creation.","sentences":["Large Language Models (LLMs) have shown great promise in integrating diverse expert models to tackle intricate language and vision tasks.","Despite their significance in advancing the field of Artificial Intelligence Generated Content (AIGC), their potential in intelligent audio content creation remains unexplored.","In this work, we tackle the problem of creating audio content with storylines encompassing speech, music, and sound effects, guided by text instructions.","We present WavJourney, a system that leverages LLMs to connect various audio models for audio content generation.","Given a text description of an auditory scene, WavJourney first prompts LLMs to generate a structured script dedicated to audio storytelling.","The audio script incorporates diverse audio elements, organized based on their spatio-temporal relationships.","As a conceptual representation of audio, the audio script provides an interactive and interpretable rationale for human engagement.","Afterward, the audio script is fed into a script compiler, converting it into a computer program.","Each line of the program calls a task-specific audio generation model or computational operation function (e.g., concatenate, mix).","The computer program is then executed to obtain an explainable solution for audio generation.","We demonstrate the practicality of WavJourney across diverse real-world scenarios, including science fiction, education, and radio play.","The explainable and interactive design of WavJourney fosters human-machine co-creation in multi-round dialogues, enhancing creative control and adaptability in audio production.","WavJourney audiolizes the human imagination, opening up new avenues for creativity in multimedia content creation."],"url":"http://arxiv.org/abs/2307.14335v1"}
{"created":"2023-07-26 17:52:22","title":"Towards Generalist Biomedical AI","abstract":"Medicine is inherently multimodal, with rich data modalities spanning text, imaging, genomics, and more. Generalist biomedical artificial intelligence (AI) systems that flexibly encode, integrate, and interpret this data at scale can potentially enable impactful applications ranging from scientific discovery to care delivery. To enable the development of these models, we first curate MultiMedBench, a new multimodal biomedical benchmark. MultiMedBench encompasses 14 diverse tasks such as medical question answering, mammography and dermatology image interpretation, radiology report generation and summarization, and genomic variant calling. We then introduce Med-PaLM Multimodal (Med-PaLM M), our proof of concept for a generalist biomedical AI system. Med-PaLM M is a large multimodal generative model that flexibly encodes and interprets biomedical data including clinical language, imaging, and genomics with the same set of model weights. Med-PaLM M reaches performance competitive with or exceeding the state of the art on all MultiMedBench tasks, often surpassing specialist models by a wide margin. We also report examples of zero-shot generalization to novel medical concepts and tasks, positive transfer learning across tasks, and emergent zero-shot medical reasoning. To further probe the capabilities and limitations of Med-PaLM M, we conduct a radiologist evaluation of model-generated (and human) chest X-ray reports and observe encouraging performance across model scales. In a side-by-side ranking on 246 retrospective chest X-rays, clinicians express a pairwise preference for Med-PaLM M reports over those produced by radiologists in up to 40.50% of cases, suggesting potential clinical utility. While considerable work is needed to validate these models in real-world use cases, our results represent a milestone towards the development of generalist biomedical AI systems.","sentences":["Medicine is inherently multimodal, with rich data modalities spanning text, imaging, genomics, and more.","Generalist biomedical artificial intelligence (AI) systems that flexibly encode, integrate, and interpret this data at scale can potentially enable impactful applications ranging from scientific discovery to care delivery.","To enable the development of these models, we first curate MultiMedBench, a new multimodal biomedical benchmark.","MultiMedBench encompasses 14 diverse tasks such as medical question answering, mammography and dermatology image interpretation, radiology report generation and summarization, and genomic variant calling.","We then introduce Med-PaLM Multimodal (Med-PaLM M), our proof of concept for a generalist biomedical AI system.","Med-PaLM M is a large multimodal generative model that flexibly encodes and interprets biomedical data including clinical language, imaging, and genomics with the same set of model weights.","Med-PaLM M reaches performance competitive with or exceeding the state of the art on all MultiMedBench tasks, often surpassing specialist models by a wide margin.","We also report examples of zero-shot generalization to novel medical concepts and tasks, positive transfer learning across tasks, and emergent zero-shot medical reasoning.","To further probe the capabilities and limitations of Med-PaLM M, we conduct a radiologist evaluation of model-generated (and human) chest X-ray reports and observe encouraging performance across model scales.","In a side-by-side ranking on 246 retrospective chest X-rays, clinicians express a pairwise preference for Med-PaLM M reports over those produced by radiologists in up to 40.50% of cases, suggesting potential clinical utility.","While considerable work is needed to validate these models in real-world use cases, our results represent a milestone towards the development of generalist biomedical AI systems."],"url":"http://arxiv.org/abs/2307.14334v1"}
{"created":"2023-07-26 17:50:17","title":"Event-based Vision for Early Prediction of Manipulation Actions","abstract":"Neuromorphic visual sensors are artificial retinas that output sequences of asynchronous events when brightness changes occur in the scene. These sensors offer many advantages including very high temporal resolution, no motion blur and smart data compression ideal for real-time processing. In this study, we introduce an event-based dataset on fine-grained manipulation actions and perform an experimental study on the use of transformers for action prediction with events. There is enormous interest in the fields of cognitive robotics and human-robot interaction on understanding and predicting human actions as early as possible. Early prediction allows anticipating complex stages for planning, enabling effective and real-time interaction. Our Transformer network uses events to predict manipulation actions as they occur, using online inference. The model succeeds at predicting actions early on, building up confidence over time and achieving state-of-the-art classification. Moreover, the attention-based transformer architecture allows us to study the role of the spatio-temporal patterns selected by the model. Our experiments show that the Transformer network captures action dynamic features outperforming video-based approaches and succeeding with scenarios where the differences between actions lie in very subtle cues. Finally, we release the new event dataset, which is the first in the literature for manipulation action recognition. Code will be available at https://github.com/DaniDeniz/EventVisionTransformer.","sentences":["Neuromorphic visual sensors are artificial retinas that output sequences of asynchronous events when brightness changes occur in the scene.","These sensors offer many advantages including very high temporal resolution, no motion blur and smart data compression ideal for real-time processing.","In this study, we introduce an event-based dataset on fine-grained manipulation actions and perform an experimental study on the use of transformers for action prediction with events.","There is enormous interest in the fields of cognitive robotics and human-robot interaction on understanding and predicting human actions as early as possible.","Early prediction allows anticipating complex stages for planning, enabling effective and real-time interaction.","Our Transformer network uses events to predict manipulation actions as they occur, using online inference.","The model succeeds at predicting actions early on, building up confidence over time and achieving state-of-the-art classification.","Moreover, the attention-based transformer architecture allows us to study the role of the spatio-temporal patterns selected by the model.","Our experiments show that the Transformer network captures action dynamic features outperforming video-based approaches and succeeding with scenarios where the differences between actions lie in very subtle cues.","Finally, we release the new event dataset, which is the first in the literature for manipulation action recognition.","Code will be available at https://github.com/DaniDeniz/EventVisionTransformer."],"url":"http://arxiv.org/abs/2307.14332v1"}
{"created":"2023-07-26 17:50:10","title":"Visual Instruction Inversion: Image Editing via Visual Prompting","abstract":"Text-conditioned image editing has emerged as a powerful tool for editing images. However, in many situations, language can be ambiguous and ineffective in describing specific image edits. When faced with such challenges, visual prompts can be a more informative and intuitive way to convey ideas. We present a method for image editing via visual prompting. Given pairs of example that represent the \"before\" and \"after\" images of an edit, our goal is to learn a text-based editing direction that can be used to perform the same edit on new images. We leverage the rich, pretrained editing capabilities of text-to-image diffusion models by inverting visual prompts into editing instructions. Our results show that with just one example pair, we can achieve competitive results compared to state-of-the-art text-conditioned image editing frameworks.","sentences":["Text-conditioned image editing has emerged as a powerful tool for editing images.","However, in many situations, language can be ambiguous and ineffective in describing specific image edits.","When faced with such challenges, visual prompts can be a more informative and intuitive way to convey ideas.","We present a method for image editing via visual prompting.","Given pairs of example that represent the \"before\" and \"after\" images of an edit, our goal is to learn a text-based editing direction that can be used to perform the same edit on new images.","We leverage the rich, pretrained editing capabilities of text-to-image diffusion models by inverting visual prompts into editing instructions.","Our results show that with just one example pair, we can achieve competitive results compared to state-of-the-art text-conditioned image editing frameworks."],"url":"http://arxiv.org/abs/2307.14331v1"}
{"created":"2023-07-26 17:45:55","title":"Waypoint-Based Imitation Learning for Robotic Manipulation","abstract":"While imitation learning methods have seen a resurgent interest for robotic manipulation, the well-known problem of compounding errors continues to afflict behavioral cloning (BC). Waypoints can help address this problem by reducing the horizon of the learning problem for BC, and thus, the errors compounded over time. However, waypoint labeling is underspecified, and requires additional human supervision. Can we generate waypoints automatically without any additional human supervision? Our key insight is that if a trajectory segment can be approximated by linear motion, the endpoints can be used as waypoints. We propose Automatic Waypoint Extraction (AWE) for imitation learning, a preprocessing module to decompose a demonstration into a minimal set of waypoints which when interpolated linearly can approximate the trajectory up to a specified error threshold. AWE can be combined with any BC algorithm, and we find that AWE can increase the success rate of state-of-the-art algorithms by up to 25% in simulation and by 4-28% on real-world bimanual manipulation tasks, reducing the decision making horizon by up to a factor of 10. Videos and code are available at https://lucys0.github.io/awe/","sentences":["While imitation learning methods have seen a resurgent interest for robotic manipulation, the well-known problem of compounding errors continues to afflict behavioral cloning (BC).","Waypoints can help address this problem by reducing the horizon of the learning problem for BC, and thus, the errors compounded over time.","However, waypoint labeling is underspecified, and requires additional human supervision.","Can we generate waypoints automatically without any additional human supervision?","Our key insight is that if a trajectory segment can be approximated by linear motion, the endpoints can be used as waypoints.","We propose Automatic Waypoint Extraction (AWE) for imitation learning, a preprocessing module to decompose a demonstration into a minimal set of waypoints which when interpolated linearly can approximate the trajectory up to a specified error threshold.","AWE can be combined with any BC algorithm, and we find that AWE can increase the success rate of state-of-the-art algorithms by up to 25% in simulation and by 4-28% on real-world bimanual manipulation tasks, reducing the decision making horizon by up to a factor of 10.","Videos and code are available at https://lucys0.github.io/awe/"],"url":"http://arxiv.org/abs/2307.14326v1"}
{"created":"2023-07-26 17:42:43","title":"Evaluating the Moral Beliefs Encoded in LLMs","abstract":"This paper presents a case study on the design, administration, post-processing, and evaluation of surveys on large language models (LLMs). It comprises two components: (1) A statistical method for eliciting beliefs encoded in LLMs. We introduce statistical measures and evaluation metrics that quantify the probability of an LLM \"making a choice\", the associated uncertainty, and the consistency of that choice. (2) We apply this method to study what moral beliefs are encoded in different LLMs, especially in ambiguous cases where the right choice is not obvious. We design a large-scale survey comprising 680 high-ambiguity moral scenarios (e.g., \"Should I tell a white lie?\") and 687 low-ambiguity moral scenarios (e.g., \"Should I stop for a pedestrian on the road?\"). Each scenario includes a description, two possible actions, and auxiliary labels indicating violated rules (e.g., \"do not kill\"). We administer the survey to 28 open- and closed-source LLMs. We find that (a) in unambiguous scenarios, most models \"choose\" actions that align with commonsense. In ambiguous cases, most models express uncertainty. (b) Some models are uncertain about choosing the commonsense action because their responses are sensitive to the question-wording. (c) Some models reflect clear preferences in ambiguous scenarios. Specifically, closed-source models tend to agree with each other.","sentences":["This paper presents a case study on the design, administration, post-processing, and evaluation of surveys on large language models (LLMs).","It comprises two components: (1) A statistical method for eliciting beliefs encoded in LLMs.","We introduce statistical measures and evaluation metrics that quantify the probability of an LLM \"making a choice\", the associated uncertainty, and the consistency of that choice.","(2) We apply this method to study what moral beliefs are encoded in different LLMs, especially in ambiguous cases where the right choice is not obvious.","We design a large-scale survey comprising 680 high-ambiguity moral scenarios (e.g., \"Should I tell a white lie?\") and 687 low-ambiguity moral scenarios (e.g., \"Should I stop for a pedestrian on the road?\").","Each scenario includes a description, two possible actions, and auxiliary labels indicating violated rules (e.g., \"do not kill\").","We administer the survey to 28 open- and closed-source LLMs.","We find that (a) in unambiguous scenarios, most models \"choose\" actions that align with commonsense.","In ambiguous cases, most models express uncertainty.","(b) Some models are uncertain about choosing the commonsense action because their responses are sensitive to the question-wording.","(c) Some models reflect clear preferences in ambiguous scenarios.","Specifically, closed-source models tend to agree with each other."],"url":"http://arxiv.org/abs/2307.14324v1"}
{"created":"2023-07-26 17:26:21","title":"Reinforcement Learning by Guided Safe Exploration","abstract":"Safety is critical to broadening the application of reinforcement learning (RL). Often, we train RL agents in a controlled environment, such as a laboratory, before deploying them in the real world. However, the real-world target task might be unknown prior to deployment. Reward-free RL trains an agent without the reward to adapt quickly once the reward is revealed. We consider the constrained reward-free setting, where an agent (the guide) learns to explore safely without the reward signal. This agent is trained in a controlled environment, which allows unsafe interactions and still provides the safety signal. After the target task is revealed, safety violations are not allowed anymore. Thus, the guide is leveraged to compose a safe behaviour policy. Drawing from transfer learning, we also regularize a target policy (the student) towards the guide while the student is unreliable and gradually eliminate the influence of the guide as training progresses. The empirical analysis shows that this method can achieve safe transfer learning and helps the student solve the target task faster.","sentences":["Safety is critical to broadening the application of reinforcement learning (RL).","Often, we train RL agents in a controlled environment, such as a laboratory, before deploying them in the real world.","However, the real-world target task might be unknown prior to deployment.","Reward-free RL trains an agent without the reward to adapt quickly once the reward is revealed.","We consider the constrained reward-free setting, where an agent (the guide) learns to explore safely without the reward signal.","This agent is trained in a controlled environment, which allows unsafe interactions and still provides the safety signal.","After the target task is revealed, safety violations are not allowed anymore.","Thus, the guide is leveraged to compose a safe behaviour policy.","Drawing from transfer learning, we also regularize a target policy (the student) towards the guide while the student is unreliable and gradually eliminate the influence of the guide as training progresses.","The empirical analysis shows that this method can achieve safe transfer learning and helps the student solve the target task faster."],"url":"http://arxiv.org/abs/2307.14316v1"}
{"created":"2023-07-26 17:23:33","title":"LiDAR-based drone navigation with reinforcement learning","abstract":"Reinforcement learning is of increasing importance in the field of robot control and simulation plays a~key role in this process. In the unmanned aerial vehicles (UAVs, drones), there is also an increase in the number of published scientific papers involving this approach. In this work, an autonomous drone control system was prepared to fly forward (according to its coordinates system) and pass the trees encountered in the forest based on the data from a rotating LiDAR sensor. The Proximal Policy Optimization (PPO) algorithm, an example of reinforcement learning (RL), was used to prepare it. A custom simulator in the Python language was developed for this purpose. The Gazebo environment, integrated with the Robot Operating System (ROS), was also used to test the resulting control algorithm. Finally, the prepared solution was implemented in the Nvidia Jetson Nano eGPU and verified in the real tests scenarios. During them, the drone successfully completed the set task and was able to repeatably avoid trees and fly through the forest.","sentences":["Reinforcement learning is of increasing importance in the field of robot control and simulation plays a~key role in this process.","In the unmanned aerial vehicles (UAVs, drones), there is also an increase in the number of published scientific papers involving this approach.","In this work, an autonomous drone control system was prepared to fly forward (according to its coordinates system) and pass the trees encountered in the forest based on the data from a rotating LiDAR sensor.","The Proximal Policy Optimization (PPO) algorithm, an example of reinforcement learning (RL), was used to prepare it.","A custom simulator in the Python language was developed for this purpose.","The Gazebo environment, integrated with the Robot Operating System (ROS), was also used to test the resulting control algorithm.","Finally, the prepared solution was implemented in the Nvidia Jetson Nano eGPU and verified in the real tests scenarios.","During them, the drone successfully completed the set task and was able to repeatably avoid trees and fly through the forest."],"url":"http://arxiv.org/abs/2307.14313v1"}
{"created":"2023-07-26 17:21:59","title":"Empirical Investigation of Factors influencing Function as a Service Performance in Different Cloud/Edge System Setups","abstract":"Experimental data can aid in gaining insights about a system operation, as well as determining critical aspects of a modelling or simulation process. In this paper, we analyze the data acquired from an extensive experimentation process in a serverless Function as a Service system (based on the open source Apache Openwhisk) that has been deployed across 3 available cloud/edge locations with different system setups. Thus, they can be used to model distribution of functions through multi-location aware scheduling mechanisms. The experiments include different traffic arrival rates, different setups for the FaaS system, as well as different configurations for the hardware and platform used. We analyse the acquired data for the three FaaS system setups and discuss their differences presenting interesting conclusions with relation to transient effects of the system, such as the effect on wait and execution time. We also demonstrate interesting trade-offs with relation to system setup and indicate a number of factors that can affect system performance and should be taken under consideration in modelling attempts of such systems.","sentences":["Experimental data can aid in gaining insights about a system operation, as well as determining critical aspects of a modelling or simulation process.","In this paper, we analyze the data acquired from an extensive experimentation process in a serverless Function as a Service system (based on the open source Apache Openwhisk) that has been deployed across 3 available cloud/edge locations with different system setups.","Thus, they can be used to model distribution of functions through multi-location aware scheduling mechanisms.","The experiments include different traffic arrival rates, different setups for the FaaS system, as well as different configurations for the hardware and platform used.","We analyse the acquired data for the three FaaS system setups and discuss their differences presenting interesting conclusions with relation to transient effects of the system, such as the effect on wait and execution time.","We also demonstrate interesting trade-offs with relation to system setup and indicate a number of factors that can affect system performance and should be taken under consideration in modelling attempts of such systems."],"url":"http://arxiv.org/abs/2307.14312v1"}
{"created":"2023-07-26 17:21:53","title":"Comparative Analysis of Libraries for the Sentimental Analysis","abstract":"This study is main goal is to provide a comparative comparison of libraries using machine learning methods. Experts in natural language processing (NLP) are becoming more and more interested in sentiment analysis (SA) of text changes. The objective of employing NLP text analysis techniques is to recognize and categorize feelings related to twitter users utterances. In this examination, issues with SA and the libraries utilized are also looked at. provides a number of cooperative methods to classify emotional polarity. The Naive Bayes Classifier, Decision Tree Classifier, Maxent Classifier, Sklearn Classifier, Sklearn Classifier MultinomialNB, and other conjoint learning algorithms, according to recent research, are very effective. In the project will use Five Python and R libraries NLTK, TextBlob, Vader, Transformers (GPT and BERT pretrained), and Tidytext will be used in the study to apply sentiment analysis techniques. Four machine learning models Tree of Decisions (DT), Support Vector Machine (SVM), Naive Bayes (NB), and K-Nearest Neighbor (KNN) will also be used. To evaluate how well libraries for SA operate in the social network environment, comparative study was also carried out. The measures to assess the best algorithms in this experiment, which used a single data set for each method, were precision, recall, and F1 score. We conclude that the BERT transformer method with an Accuracy: 0.973 is recommended for sentiment analysis.","sentences":["This study is main goal is to provide a comparative comparison of libraries using machine learning methods.","Experts in natural language processing (NLP) are becoming more and more interested in sentiment analysis (SA) of text changes.","The objective of employing NLP text analysis techniques is to recognize and categorize feelings related to twitter users utterances.","In this examination, issues with SA and the libraries utilized are also looked at.","provides a number of cooperative methods to classify emotional polarity.","The Naive Bayes Classifier, Decision Tree Classifier, Maxent Classifier, Sklearn Classifier, Sklearn Classifier MultinomialNB, and other conjoint learning algorithms, according to recent research, are very effective.","In the project will use Five Python and R libraries NLTK, TextBlob, Vader, Transformers (GPT and BERT pretrained), and Tidytext will be used in the study to apply sentiment analysis techniques.","Four machine learning models Tree of Decisions (DT), Support Vector Machine (SVM), Naive Bayes (NB), and K-Nearest Neighbor (KNN) will also be used.","To evaluate how well libraries for SA operate in the social network environment, comparative study was also carried out.","The measures to assess the best algorithms in this experiment, which used a single data set for each method, were precision, recall, and F1 score.","We conclude that the BERT transformer method with an Accuracy: 0.973 is recommended for sentiment analysis."],"url":"http://arxiv.org/abs/2307.14311v1"}
{"created":"2023-07-26 17:13:00","title":"Automatically Evaluating Opinion Prevalence in Opinion Summarization","abstract":"When faced with a large number of product reviews, it is not clear that a human can remember all of them and weight opinions representatively to write a good reference summary. We propose an automatic metric to test the prevalence of the opinions that a summary expresses, based on counting the number of reviews that are consistent with each statement in the summary, while discrediting trivial or redundant statements. To formulate this opinion prevalence metric, we consider several existing methods to score the factual consistency of a summary statement with respect to each individual source review. On a corpus of Amazon product reviews, we gather multiple human judgments of the opinion consistency, to determine which automatic metric best expresses consistency in product reviews. Using the resulting opinion prevalence metric, we show that a human authored summary has only slightly better opinion prevalence than randomly selected extracts from the source reviews, and previous extractive and abstractive unsupervised opinion summarization methods perform worse than humans. We demonstrate room for improvement with a greedy construction of extractive summaries with twice the opinion prevalence achieved by humans. Finally, we show that preprocessing source reviews by simplification can raise the opinion prevalence achieved by existing abstractive opinion summarization systems to the level of human performance.","sentences":["When faced with a large number of product reviews, it is not clear that a human can remember all of them and weight opinions representatively to write a good reference summary.","We propose an automatic metric to test the prevalence of the opinions that a summary expresses, based on counting the number of reviews that are consistent with each statement in the summary, while discrediting trivial or redundant statements.","To formulate this opinion prevalence metric, we consider several existing methods to score the factual consistency of a summary statement with respect to each individual source review.","On a corpus of Amazon product reviews, we gather multiple human judgments of the opinion consistency, to determine which automatic metric best expresses consistency in product reviews.","Using the resulting opinion prevalence metric, we show that a human authored summary has only slightly better opinion prevalence than randomly selected extracts from the source reviews, and previous extractive and abstractive unsupervised opinion summarization methods perform worse than humans.","We demonstrate room for improvement with a greedy construction of extractive summaries with twice the opinion prevalence achieved by humans.","Finally, we show that preprocessing source reviews by simplification can raise the opinion prevalence achieved by existing abstractive opinion summarization systems to the level of human performance."],"url":"http://arxiv.org/abs/2307.14305v1"}
{"created":"2023-07-26 17:05:18","title":"A Discontinuous Galerkin Finite Element Model for Compound Flood Simulations","abstract":"Recent tropical cyclones, e.g., Hurricane Harvey (2017), have lead to significant rainfall and resulting runoff with accompanying flooding. When the runoff interacts with storm surge, the resulting floods can be greatly amplified and lead to effects that cannot be modeled by simple superposition of its distinctive sources. In an effort to develop accurate numerical simulations of runoff, surge, and compounding floods, we develop a local discontinuous Galerkin method for modified shallow water equations. In this modification, nonzero sources to the continuity equation are included to incorporate rainfall into the model using parametric rainfall models from literature as well as hindcast data. The discontinuous Galerkin spatial discretization is accompanied with a strong stability preserving explicit Runge Kutta time integrator. Hence, temporal stability is ensured through the CFL condition and we exploit the embarrassingly parallel nature of the developed method using MPI parallelization. We demonstrate the capabilities of the developed method though a sequence of physically relevant numerical tests, including small scale test cases based on laboratory measurements and large scale experiments with Hurricane Harvey in the Gulf of Mexico. The results highlight the conservation properties and robustness of the developed method and show the potential of compound flood modeling using our approach.","sentences":["Recent tropical cyclones, e.g., Hurricane Harvey (2017), have lead to significant rainfall and resulting runoff with accompanying flooding.","When the runoff interacts with storm surge, the resulting floods can be greatly amplified and lead to effects that cannot be modeled by simple superposition of its distinctive sources.","In an effort to develop accurate numerical simulations of runoff, surge, and compounding floods, we develop a local discontinuous Galerkin method for modified shallow water equations.","In this modification, nonzero sources to the continuity equation are included to incorporate rainfall into the model using parametric rainfall models from literature as well as hindcast data.","The discontinuous Galerkin spatial discretization is accompanied with a strong stability preserving explicit Runge Kutta time integrator.","Hence, temporal stability is ensured through the CFL condition and we exploit the embarrassingly parallel nature of the developed method using MPI parallelization.","We demonstrate the capabilities of the developed method though a sequence of physically relevant numerical tests, including small scale test cases based on laboratory measurements and large scale experiments with Hurricane Harvey in the Gulf of Mexico.","The results highlight the conservation properties and robustness of the developed method and show the potential of compound flood modeling using our approach."],"url":"http://arxiv.org/abs/2307.14302v1"}
{"created":"2023-07-26 17:01:46","title":"Dual and Hull code in the first two generic constructions and relationship with the Walsh transform of cryptographic functions","abstract":"We contribute to the knowledge of linear codes from special polynomials and functions, which have been studied intensively in the past few years. Such codes have several applications in secret sharing, authentication codes, association schemes and strongly regular graphs.   This is the first work in which we study the dual codes in the framework of the two generic constructions; in particular, we propose a Gram-Schmidt (complexity of $\\mathcal{O}(n^3)$) process to compute them explicitly. The originality of this contribution is in the study of the existence or not of defining sets $D'$, which can be used as ingredients to construct the dual code $\\mathcal{C}'$ for a given code $\\mathcal{C}$ in the context of the second generic construction. We also determine a necessary condition expressed by employing the Walsh transform for a codeword of $\\mathcal{C}$ to belong in the dual. This achievement was done in general and when the involved functions are weakly regularly bent. We shall give a novel description of the Hull code in the framework of the two generic constructions. Our primary interest is constructing linear codes of fixed Hull dimension and determining the (Hamming) weight of the codewords in their duals.","sentences":["We contribute to the knowledge of linear codes from special polynomials and functions, which have been studied intensively in the past few years.","Such codes have several applications in secret sharing, authentication codes, association schemes and strongly regular graphs.   ","This is the first work in which we study the dual codes in the framework of the two generic constructions; in particular, we propose a Gram-Schmidt (complexity of $\\mathcal{O}(n^3)$) process to compute them explicitly.","The originality of this contribution is in the study of the existence or not of defining sets $D'$, which can be used as ingredients to construct the dual code $\\mathcal{C}'$ for a given code $\\mathcal{C}$ in the context of the second generic construction.","We also determine a necessary condition expressed by employing the Walsh transform for a codeword of $\\mathcal{C}$ to belong in the dual.","This achievement was done in general and when the involved functions are weakly regularly bent.","We shall give a novel description of the Hull code in the framework of the two generic constructions.","Our primary interest is constructing linear codes of fixed Hull dimension and determining the (Hamming) weight of the codewords in their duals."],"url":"http://arxiv.org/abs/2307.14300v1"}
{"created":"2023-07-26 16:58:10","title":"ChatGPT and Persuasive Technologies for the Management and Delivery of Personalized Recommendations in Hotel Hospitality","abstract":"Recommender systems have become indispensable tools in the hotel hospitality industry, enabling personalized and tailored experiences for guests. Recent advancements in large language models (LLMs), such as ChatGPT, and persuasive technologies, have opened new avenues for enhancing the effectiveness of those systems. This paper explores the potential of integrating ChatGPT and persuasive technologies for automating and improving hotel hospitality recommender systems. First, we delve into the capabilities of ChatGPT, which can understand and generate human-like text, enabling more accurate and context-aware recommendations. We discuss the integration of ChatGPT into recommender systems, highlighting the ability to analyze user preferences, extract valuable insights from online reviews, and generate personalized recommendations based on guest profiles. Second, we investigate the role of persuasive technology in influencing user behavior and enhancing the persuasive impact of hotel recommendations. By incorporating persuasive techniques, such as social proof, scarcity and personalization, recommender systems can effectively influence user decision-making and encourage desired actions, such as booking a specific hotel or upgrading their room. To investigate the efficacy of ChatGPT and persuasive technologies, we present a pilot experi-ment with a case study involving a hotel recommender system. We aim to study the impact of integrating ChatGPT and persua-sive techniques on user engagement, satisfaction, and conversion rates. The preliminary results demonstrate the potential of these technologies in enhancing the overall guest experience and business performance. Overall, this paper contributes to the field of hotel hospitality by exploring the synergistic relationship between LLMs and persuasive technology in recommender systems, ultimately influencing guest satisfaction and hotel revenue.","sentences":["Recommender systems have become indispensable tools in the hotel hospitality industry, enabling personalized and tailored experiences for guests.","Recent advancements in large language models (LLMs), such as ChatGPT, and persuasive technologies, have opened new avenues for enhancing the effectiveness of those systems.","This paper explores the potential of integrating ChatGPT and persuasive technologies for automating and improving hotel hospitality recommender systems.","First, we delve into the capabilities of ChatGPT, which can understand and generate human-like text, enabling more accurate and context-aware recommendations.","We discuss the integration of ChatGPT into recommender systems, highlighting the ability to analyze user preferences, extract valuable insights from online reviews, and generate personalized recommendations based on guest profiles.","Second, we investigate the role of persuasive technology in influencing user behavior and enhancing the persuasive impact of hotel recommendations.","By incorporating persuasive techniques, such as social proof, scarcity and personalization, recommender systems can effectively influence user decision-making and encourage desired actions, such as booking a specific hotel or upgrading their room.","To investigate the efficacy of ChatGPT and persuasive technologies, we present a pilot experi-ment with a case study involving a hotel recommender system.","We aim to study the impact of integrating ChatGPT and persua-sive techniques on user engagement, satisfaction, and conversion rates.","The preliminary results demonstrate the potential of these technologies in enhancing the overall guest experience and business performance.","Overall, this paper contributes to the field of hotel hospitality by exploring the synergistic relationship between LLMs and persuasive technology in recommender systems, ultimately influencing guest satisfaction and hotel revenue."],"url":"http://arxiv.org/abs/2307.14298v1"}
{"created":"2023-07-26 16:51:18","title":"Unraveling the Complexity of Splitting Sequential Data: Tackling Challenges in Video and Time Series Analysis","abstract":"Splitting of sequential data, such as videos and time series, is an essential step in various data analysis tasks, including object tracking and anomaly detection. However, splitting sequential data presents a variety of challenges that can impact the accuracy and reliability of subsequent analyses. This concept article examines the challenges associated with splitting sequential data, including data acquisition, data representation, split ratio selection, setting up quality criteria, and choosing suitable selection strategies. We explore these challenges through two real-world examples: motor test benches and particle tracking in liquids.","sentences":["Splitting of sequential data, such as videos and time series, is an essential step in various data analysis tasks, including object tracking and anomaly detection.","However, splitting sequential data presents a variety of challenges that can impact the accuracy and reliability of subsequent analyses.","This concept article examines the challenges associated with splitting sequential data, including data acquisition, data representation, split ratio selection, setting up quality criteria, and choosing suitable selection strategies.","We explore these challenges through two real-world examples: motor test benches and particle tracking in liquids."],"url":"http://arxiv.org/abs/2307.14294v1"}
{"created":"2023-07-26 16:49:39","title":"Distributed Certification for Classes of Dense Graphs","abstract":"A proof-labeling scheme (PLS) for a boolean predicate $\\Pi$ on labeled graphs is a mechanism used for certifying the legality with respect to $\\Pi$ of global network states in a distributed manner. In a PLS, a certificate is assigned to each processing node of the network, and the nodes are in charge of checking that the collection of certificates forms a global proof that the system is in a correct state, by exchanging the certificates once, between neighbors only. The main measure of complexity is the size of the certificates. Many PLSs have been designed for certifying specific predicates, including cycle-freeness, minimum-weight spanning tree, planarity, etc.   In 2021, a breakthrough has been obtained, as a meta-theorem stating that a large set of properties have compact PLSs in a large class of networks. Namely, for every $\\mathrm{MSO}_2$ property $\\Pi$ on labeled graphs, there exists a PLS for $\\Pi$ with $O(\\log n)$-bit certificates for all graphs of bounded tree-depth. This result has been extended to the larger class of graphs with bounded {tree-width}, using certificates on $O(\\log^2 n)$ bits.   We extend this result even further, to the larger class of graphs with bounded clique-width, which, as opposed to the other two aforementioned classes, includes dense graphs. We show that, for every $\\mathrm{MSO}_1$ property $\\Pi$ on labeled graphs, there exists a PLS for $\\Pi$ with $O(\\log^2 n)$ bit certificates for all graphs of bounded clique-width.","sentences":["A proof-labeling scheme (PLS) for a boolean predicate $\\Pi$ on labeled graphs is a mechanism used for certifying the legality with respect to $\\Pi$ of global network states in a distributed manner.","In a PLS, a certificate is assigned to each processing node of the network, and the nodes are in charge of checking that the collection of certificates forms a global proof that the system is in a correct state, by exchanging the certificates once, between neighbors only.","The main measure of complexity is the size of the certificates.","Many PLSs have been designed for certifying specific predicates, including cycle-freeness, minimum-weight spanning tree, planarity, etc.   ","In 2021, a breakthrough has been obtained, as a meta-theorem stating that a large set of properties have compact PLSs in a large class of networks.","Namely, for every $\\mathrm{MSO}_2$ property $\\Pi$ on labeled graphs, there exists a PLS for $\\Pi$ with $O(\\log n)$-bit certificates for all graphs of bounded tree-depth.","This result has been extended to the larger class of graphs with bounded {tree-width}, using certificates on $O(\\log^2 n)$ bits.   ","We extend this result even further, to the larger class of graphs with bounded clique-width, which, as opposed to the other two aforementioned classes, includes dense graphs.","We show that, for every $\\mathrm{MSO}_1$ property $\\Pi$ on labeled graphs, there exists a PLS for $\\Pi$ with $O(\\log^2 n)$ bit certificates for all graphs of bounded clique-width."],"url":"http://arxiv.org/abs/2307.14292v1"}
{"created":"2023-07-26 16:49:11","title":"Founding a mathematical diffusion model in linguistics. The case study of German syntactic features in the North-Eastern Italian dialects","abstract":"We take as a case study the spread of Germanic syntactic features into Romance dialects of North-Eastern Italy, which occurred after the immigration of German people in the Tyrol during the High Middle Ages.   An interactive map is produced using tools of what is called Geographic Data Science. A smooth two-dimensional surface $\\mathcal{G}$ expresses locally which fraction of territory uses a given German language feature: it is obtained by interpolating a discrete function that says if at any surveyed locality that feature is used or not.\\newline   This surface $\\mathcal{G}$ is thought of as the value at the present time of a function describing a diffusion-convection phenomenon in two dimensions (here said \\emph{tidal} mode), which is subjected in a very natural way to the same equation, suitably contextualized, used in physics for a number of phenomenological facts like the heat diffusion. It is shown that solutions of this equation, evaluated at the present time, fit well with the data as interpolated by $\\mathcal{G}$, thus providing convincing pictures of diffusion-convection of the linguistic features of the case study, albeit simplifications and approximations.\\newline   Very importantly, it is shown that Schmidt's 'waves' can be counted among the solutions of the diffusion equation: superimposing Schmidt 'waves' to a 'tidal flooding' can reproduce complexities of real linguistic diffusion events.","sentences":["We take as a case study the spread of Germanic syntactic features into Romance dialects of North-Eastern Italy, which occurred after the immigration of German people in the Tyrol during the High Middle Ages.   ","An interactive map is produced using tools of what is called Geographic Data Science.","A smooth two-dimensional surface $\\mathcal{G}$ expresses locally which fraction of territory uses a given German language feature: it is obtained by interpolating a discrete function that says if at any surveyed locality that feature is used or not.\\newline   This surface $\\mathcal{G}$ is thought of as the value at the present time of a function describing a diffusion-convection phenomenon in two dimensions (here said \\emph{tidal} mode), which is subjected in a very natural way to the same equation, suitably contextualized, used in physics for a number of phenomenological facts like the heat diffusion.","It is shown that solutions of this equation, evaluated at the present time, fit well with the data as interpolated by $\\mathcal{G}$, thus providing convincing pictures of diffusion-convection of the linguistic features of the case study, albeit simplifications and approximations.\\newline   Very importantly, it is shown that Schmidt's 'waves' can be counted among the solutions of the diffusion equation: superimposing Schmidt 'waves' to a 'tidal flooding' can reproduce complexities of real linguistic diffusion events."],"url":"http://arxiv.org/abs/2307.14291v1"}
{"created":"2023-07-26 16:49:06","title":"Cumulative Information Generating Function and Generalized Gini Functions","abstract":"We introduce and study the cumulative information generating function, which provides a unifying mathematical tool suitable to deal with classical and fractional entropies based on the cumulative distribution function and on the survival function. Specifically, after establishing its main properties and some bounds, we show that it is a variability measure itself that extends the Gini mean semi-difference. We also provide (i) an extension of such a measure, based on distortion functions, and (ii) a weighted version based on a mixture distribution. Furthermore, we explore some connections with the reliability of $k$-out-of-$n$ systems and with stress-strength models for multi-component systems. Also, we address the problem of extending the cumulative information generating function to higher dimensions.","sentences":["We introduce and study the cumulative information generating function, which provides a unifying mathematical tool suitable to deal with classical and fractional entropies based on the cumulative distribution function and on the survival function.","Specifically, after establishing its main properties and some bounds, we show that it is a variability measure itself that extends the Gini mean semi-difference.","We also provide (i) an extension of such a measure, based on distortion functions, and (ii) a weighted version based on a mixture distribution.","Furthermore, we explore some connections with the reliability of $k$-out-of-$n$ systems and with stress-strength models for multi-component systems.","Also, we address the problem of extending the cumulative information generating function to higher dimensions."],"url":"http://arxiv.org/abs/2307.14290v1"}
{"created":"2023-07-26 16:43:22","title":"US & MR Image-Fusion Based on Skin Co-Registration","abstract":"The study and development of innovative solutions for the advanced visualisation, representation and analysis of medical images offer different research directions. Current practice in medical imaging consists in combining real-time US with imaging modalities that allow internal anatomy acquisitions, such as CT, MRI, PET or similar. Application of image-fusion approaches can be found in tracking surgical tools and/or needles, in real-time during interventions. Thus, this work proposes a fusion imaging system for the registration of CT and MRI images with real-time US acquisition leveraging a 3D camera sensor. The main focus of the work is the portability of the system and its applicability to different anatomical districts.","sentences":["The study and development of innovative solutions for the advanced visualisation, representation and analysis of medical images offer different research directions.","Current practice in medical imaging consists in combining real-time US with imaging modalities that allow internal anatomy acquisitions, such as CT, MRI, PET or similar.","Application of image-fusion approaches can be found in tracking surgical tools and/or needles, in real-time during interventions.","Thus, this work proposes a fusion imaging system for the registration of CT and MRI images with real-time US acquisition leveraging a 3D camera sensor.","The main focus of the work is the portability of the system and its applicability to different anatomical districts."],"url":"http://arxiv.org/abs/2307.14288v1"}
{"created":"2023-07-26 16:43:00","title":"Evaluation of Data Enrichment Methods for Distributed Stream Processing Systems","abstract":"Stream processing has become a critical component in the architecture of modern applications. With the exponential growth of data generation from sources such as the Internet of Things, business intelligence, and telecommunications, real-time processing of unbounded data streams has become a necessity. DSP systems provide a solution to this challenge, offering high horizontal scalability, fault-tolerant execution, and the ability to process data streams from multiple sources in a single DSP job. Often enough though, data streams need to be enriched with extra information for correct processing, which introduces additional dependencies and potential bottlenecks.   In this paper, we present an in-depth evaluation of data enrichment methods for DSP systems and identify the different use cases for stream processing in modern systems. Using a representative DSP system and conducting the evaluation in a realistic cloud environment, we found that outsourcing enrichment data to the DSP system can improve performance for specific use cases. However, this increased resource consumption highlights the need for stream processing solutions specifically designed for the performance-intensive workloads of cloud-based applications.","sentences":["Stream processing has become a critical component in the architecture of modern applications.","With the exponential growth of data generation from sources such as the Internet of Things, business intelligence, and telecommunications, real-time processing of unbounded data streams has become a necessity.","DSP systems provide a solution to this challenge, offering high horizontal scalability, fault-tolerant execution, and the ability to process data streams from multiple sources in a single DSP job.","Often enough though, data streams need to be enriched with extra information for correct processing, which introduces additional dependencies and potential bottlenecks.   ","In this paper, we present an in-depth evaluation of data enrichment methods for DSP systems and identify the different use cases for stream processing in modern systems.","Using a representative DSP system and conducting the evaluation in a realistic cloud environment, we found that outsourcing enrichment data to the DSP system can improve performance for specific use cases.","However, this increased resource consumption highlights the need for stream processing solutions specifically designed for the performance-intensive workloads of cloud-based applications."],"url":"http://arxiv.org/abs/2307.14287v1"}
{"created":"2023-07-26 16:35:48","title":"General Purpose Artificial Intelligence Systems (GPAIS): Properties, Definition, Taxonomy, Open Challenges and Implications","abstract":"Most applications of Artificial Intelligence (AI) are designed for a confined and specific task. However, there are many scenarios that call for a more general AI, capable of solving a wide array of tasks without being specifically designed for them. The term General-Purpose Artificial Intelligence Systems (GPAIS) has been defined to refer to these AI systems. To date, the possibility of an Artificial General Intelligence, powerful enough to perform any intellectual task as if it were human, or even improve it, has remained an aspiration, fiction, and considered a risk for our society. Whilst we might still be far from achieving that, GPAIS is a reality and sitting at the forefront of AI research.   This work discusses existing definitions for GPAIS and proposes a new definition that allows for a gradual differentiation among types of GPAIS according to their properties and limitations. We distinguish between closed-world and open-world GPAIS, characterising their degree of autonomy and ability based on several factors such as adaptation to new tasks, competence in domains not intentionally trained for, ability to learn from few data, or proactive acknowledgment of their own limitations. We then propose a taxonomy of approaches to realise GPAIS, describing research trends such as the use of AI techniques to improve another AI or foundation models. As a prime example, we delve into generative AI, aligning them with the terms and concepts presented in the taxonomy. Through the proposed definition and taxonomy, our aim is to facilitate research collaboration across different areas that are tackling general-purpose tasks, as they share many common aspects. Finally, we discuss the current state of GPAIS, its challenges and prospects, implications for our society, and the need for responsible and trustworthy AI systems and regulation, with the goal of providing a holistic view of GPAIS.","sentences":["Most applications of Artificial Intelligence (AI) are designed for a confined and specific task.","However, there are many scenarios that call for a more general AI, capable of solving a wide array of tasks without being specifically designed for them.","The term General-Purpose Artificial Intelligence Systems (GPAIS) has been defined to refer to these AI systems.","To date, the possibility of an Artificial General Intelligence, powerful enough to perform any intellectual task as if it were human, or even improve it, has remained an aspiration, fiction, and considered a risk for our society.","Whilst we might still be far from achieving that, GPAIS is a reality and sitting at the forefront of AI research.   ","This work discusses existing definitions for GPAIS and proposes a new definition that allows for a gradual differentiation among types of GPAIS according to their properties and limitations.","We distinguish between closed-world and open-world GPAIS, characterising their degree of autonomy and ability based on several factors such as adaptation to new tasks, competence in domains not intentionally trained for, ability to learn from few data, or proactive acknowledgment of their own limitations.","We then propose a taxonomy of approaches to realise GPAIS, describing research trends such as the use of AI techniques to improve another AI or foundation models.","As a prime example, we delve into generative AI, aligning them with the terms and concepts presented in the taxonomy.","Through the proposed definition and taxonomy, our aim is to facilitate research collaboration across different areas that are tackling general-purpose tasks, as they share many common aspects.","Finally, we discuss the current state of GPAIS, its challenges and prospects, implications for our society, and the need for responsible and trustworthy AI systems and regulation, with the goal of providing a holistic view of GPAIS."],"url":"http://arxiv.org/abs/2307.14283v1"}
{"created":"2023-07-26 16:32:20","title":"Moments of Autocorrelation Demerit Factors of Binary Sequences","abstract":"Sequences with low aperiodic autocorrelation are used in communications and remote sensing for synchronization and ranging. The autocorrelation demerit factor of a sequence is the sum of the squared magnitudes of its autocorrelation values at every nonzero shift when we normalize the sequence to have unit Euclidean length. The merit factor, introduced by Golay, is the reciprocal of the demerit factor. We consider the uniform probability measure on the $2^\\ell$ binary sequences of length $\\ell$ and investigate the distribution of the demerit factors of these sequences. Previous researchers have calculated the mean and variance of this distribution. We develop new combinatorial techniques to calculate the $p$th central moment of the demerit factor for binary sequences of length $\\ell$. These techniques prove that for $p\\geq 2$ and $\\ell \\geq 4$, all the central moments are strictly positive. For any given $p$, one may use the technique to obtain an exact formula for the $p$th central moment of the demerit factor as a function of the length $\\ell$. The previously obtained formula for variance is confirmed by our technique with a short calculation, and we demonstrate that our techniques go beyond this by also deriving an exact formula for the skewness.","sentences":["Sequences with low aperiodic autocorrelation are used in communications and remote sensing for synchronization and ranging.","The autocorrelation demerit factor of a sequence is the sum of the squared magnitudes of its autocorrelation values at every nonzero shift when we normalize the sequence to have unit Euclidean length.","The merit factor, introduced by Golay, is the reciprocal of the demerit factor.","We consider the uniform probability measure on the $2^\\ell$ binary sequences of length $\\ell$ and investigate the distribution of the demerit factors of these sequences.","Previous researchers have calculated the mean and variance of this distribution.","We develop new combinatorial techniques to calculate the $p$th central moment of the demerit factor for binary sequences of length $\\ell$. These techniques prove that for $p\\geq 2$ and $\\ell \\geq 4$, all the central moments are strictly positive.","For any given $p$, one may use the technique to obtain an exact formula for the $p$th central moment of the demerit factor as a function of the length $\\ell$. The previously obtained formula for variance is confirmed by our technique with a short calculation, and we demonstrate that our techniques go beyond this by also deriving an exact formula for the skewness."],"url":"http://arxiv.org/abs/2307.14281v1"}
{"created":"2023-07-26 16:30:32","title":"Differentiable Programming & Network Calculus: Configuration Synthesis under Delay Constraints","abstract":"With the advent of standards for deterministic network behavior, synthesizing network designs under delay constraints becomes the natural next task to tackle. Network Calculus (NC) has become a key method for validating industrial networks, as it computes formally verified end-to-end delay bounds. However, analyses from the NC framework have been designed to bound the delay of one flow at a time. Attempts to use classical analyses to derive a network configuration have shown that this approach is poorly suited to practical use cases. Consider finding a delay-optimal routing configuration: one model had to be created for each routing alternative, then each flow delay had to be bounded, and then the bounds had to be compared to the given constraints. To overcome this three-step process, we introduce Differential Network Calculus. We extend NC to allow the differentiation of delay bounds w.r.t. to a wide range of network parameters - such as flow paths or priority. This opens up NC to a class of efficient nonlinear optimization techniques that exploit the gradient of the delay bound. Our numerical evaluation on the routing and priority assignment problem shows that our novel method can synthesize flow paths and priorities in a matter of seconds, outperforming existing methods by several orders of magnitude.","sentences":["With the advent of standards for deterministic network behavior, synthesizing network designs under delay constraints becomes the natural next task to tackle.","Network Calculus (NC) has become a key method for validating industrial networks, as it computes formally verified end-to-end delay bounds.","However, analyses from the NC framework have been designed to bound the delay of one flow at a time.","Attempts to use classical analyses to derive a network configuration have shown that this approach is poorly suited to practical use cases.","Consider finding a delay-optimal routing configuration: one model had to be created for each routing alternative, then each flow delay had to be bounded, and then the bounds had to be compared to the given constraints.","To overcome this three-step process, we introduce Differential Network Calculus.","We extend NC to allow the differentiation of delay bounds w.r.t.","to a wide range of network parameters - such as flow paths or priority.","This opens up NC to a class of efficient nonlinear optimization techniques that exploit the gradient of the delay bound.","Our numerical evaluation on the routing and priority assignment problem shows that our novel method can synthesize flow paths and priorities in a matter of seconds, outperforming existing methods by several orders of magnitude."],"url":"http://arxiv.org/abs/2307.14280v1"}
{"created":"2023-07-26 16:19:19","title":"Large-scale Fully-Unsupervised Re-Identification","abstract":"Fully-unsupervised Person and Vehicle Re-Identification have received increasing attention due to their broad applicability in surveillance, forensics, event understanding, and smart cities, without requiring any manual annotation. However, most of the prior art has been evaluated in datasets that have just a couple thousand samples. Such small-data setups often allow the use of costly techniques in time and memory footprints, such as Re-Ranking, to improve clustering results. Moreover, some previous work even pre-selects the best clustering hyper-parameters for each dataset, which is unrealistic in a large-scale fully-unsupervised scenario. In this context, this work tackles a more realistic scenario and proposes two strategies to learn from large-scale unlabeled data. The first strategy performs a local neighborhood sampling to reduce the dataset size in each iteration without violating neighborhood relationships. A second strategy leverages a novel Re-Ranking technique, which has a lower time upper bound complexity and reduces the memory complexity from O(n^2) to O(kn) with k << n. To avoid the pre-selection of specific hyper-parameter values for the clustering algorithm, we also present a novel scheduling algorithm that adjusts the density parameter during training, to leverage the diversity of samples and keep the learning robust to noisy labeling. Finally, due to the complementary knowledge learned by different models, we also introduce a co-training strategy that relies upon the permutation of predicted pseudo-labels, among the backbones, with no need for any hyper-parameters or weighting optimization. The proposed methodology outperforms the state-of-the-art methods in well-known benchmarks and in the challenging large-scale Veri-Wild dataset, with a faster and memory-efficient Re-Ranking strategy, and a large-scale, noisy-robust, and ensemble-based learning approach.","sentences":["Fully-unsupervised Person and Vehicle Re-Identification have received increasing attention due to their broad applicability in surveillance, forensics, event understanding, and smart cities, without requiring any manual annotation.","However, most of the prior art has been evaluated in datasets that have just a couple thousand samples.","Such small-data setups often allow the use of costly techniques in time and memory footprints, such as Re-Ranking, to improve clustering results.","Moreover, some previous work even pre-selects the best clustering hyper-parameters for each dataset, which is unrealistic in a large-scale fully-unsupervised scenario.","In this context, this work tackles a more realistic scenario and proposes two strategies to learn from large-scale unlabeled data.","The first strategy performs a local neighborhood sampling to reduce the dataset size in each iteration without violating neighborhood relationships.","A second strategy leverages a novel Re-Ranking technique, which has a lower time upper bound complexity and reduces the memory complexity from O(n^2) to O(kn) with k << n. To avoid the pre-selection of specific hyper-parameter values for the clustering algorithm, we also present a novel scheduling algorithm that adjusts the density parameter during training, to leverage the diversity of samples and keep the learning robust to noisy labeling.","Finally, due to the complementary knowledge learned by different models, we also introduce a co-training strategy that relies upon the permutation of predicted pseudo-labels, among the backbones, with no need for any hyper-parameters or weighting optimization.","The proposed methodology outperforms the state-of-the-art methods in well-known benchmarks and in the challenging large-scale Veri-Wild dataset, with a faster and memory-efficient Re-Ranking strategy, and a large-scale, noisy-robust, and ensemble-based learning approach."],"url":"http://arxiv.org/abs/2307.14278v1"}
{"created":"2023-07-26 16:14:21","title":"G2L: Semantically Aligned and Uniform Video Grounding via Geodesic and Game Theory","abstract":"The recent video grounding works attempt to introduce vanilla contrastive learning into video grounding. However, we claim that this naive solution is suboptimal. Contrastive learning requires two key properties: (1) \\emph{alignment} of features of similar samples, and (2) \\emph{uniformity} of the induced distribution of the normalized features on the hypersphere. Due to two annoying issues in video grounding: (1) the co-existence of some visual entities in both ground truth and other moments, \\ie semantic overlapping; (2) only a few moments in the video are annotated, \\ie sparse annotation dilemma, vanilla contrastive learning is unable to model the correlations between temporally distant moments and learned inconsistent video representations. Both characteristics lead to vanilla contrastive learning being unsuitable for video grounding. In this paper, we introduce Geodesic and Game Localization (G2L), a semantically aligned and uniform video grounding framework via geodesic and game theory. We quantify the correlations among moments leveraging the geodesic distance that guides the model to learn the correct cross-modal representations. Furthermore, from the novel perspective of game theory, we propose semantic Shapley interaction based on geodesic distance sampling to learn fine-grained semantic alignment in similar moments. Experiments on three benchmarks demonstrate the effectiveness of our method.","sentences":["The recent video grounding works attempt to introduce vanilla contrastive learning into video grounding.","However, we claim that this naive solution is suboptimal.","Contrastive learning requires two key properties: (1) \\emph{alignment} of features of similar samples, and (2) \\emph{uniformity} of the induced distribution of the normalized features on the hypersphere.","Due to two annoying issues in video grounding: (1) the co-existence of some visual entities in both ground truth and other moments, \\ie semantic overlapping; (2) only a few moments in the video are annotated, \\ie sparse annotation dilemma, vanilla contrastive learning is unable to model the correlations between temporally distant moments and learned inconsistent video representations.","Both characteristics lead to vanilla contrastive learning being unsuitable for video grounding.","In this paper, we introduce Geodesic and Game Localization (G2L), a semantically aligned and uniform video grounding framework via geodesic and game theory.","We quantify the correlations among moments leveraging the geodesic distance that guides the model to learn the correct cross-modal representations.","Furthermore, from the novel perspective of game theory, we propose semantic Shapley interaction based on geodesic distance sampling to learn fine-grained semantic alignment in similar moments.","Experiments on three benchmarks demonstrate the effectiveness of our method."],"url":"http://arxiv.org/abs/2307.14277v1"}
{"created":"2023-07-26 16:08:57","title":"Sim-to-Real Model-Based and Model-Free Deep Reinforcement Learning for Tactile Pushing","abstract":"Object pushing presents a key non-prehensile manipulation problem that is illustrative of more complex robotic manipulation tasks. While deep reinforcement learning (RL) methods have demonstrated impressive learning capabilities using visual input, a lack of tactile sensing limits their capability for fine and reliable control during manipulation. Here we propose a deep RL approach to object pushing using tactile sensing without visual input, namely tactile pushing. We present a goal-conditioned formulation that allows both model-free and model-based RL to obtain accurate policies for pushing an object to a goal. To achieve real-world performance, we adopt a sim-to-real approach. Our results demonstrate that it is possible to train on a single object and a limited sample of goals to produce precise and reliable policies that can generalize to a variety of unseen objects and pushing scenarios without domain randomization. We experiment with the trained agents in harsh pushing conditions, and show that with significantly more training samples, a model-free policy can outperform a model-based planner, generating shorter and more reliable pushing trajectories despite large disturbances. The simplicity of our training environment and effective real-world performance highlights the value of rich tactile information for fine manipulation. Code and videos are available at https://sites.google.com/view/tactile-rl-pushing/.","sentences":["Object pushing presents a key non-prehensile manipulation problem that is illustrative of more complex robotic manipulation tasks.","While deep reinforcement learning (RL) methods have demonstrated impressive learning capabilities using visual input, a lack of tactile sensing limits their capability for fine and reliable control during manipulation.","Here we propose a deep RL approach to object pushing using tactile sensing without visual input, namely tactile pushing.","We present a goal-conditioned formulation that allows both model-free and model-based RL to obtain accurate policies for pushing an object to a goal.","To achieve real-world performance, we adopt a sim-to-real approach.","Our results demonstrate that it is possible to train on a single object and a limited sample of goals to produce precise and reliable policies that can generalize to a variety of unseen objects and pushing scenarios without domain randomization.","We experiment with the trained agents in harsh pushing conditions, and show that with significantly more training samples, a model-free policy can outperform a model-based planner, generating shorter and more reliable pushing trajectories despite large disturbances.","The simplicity of our training environment and effective real-world performance highlights the value of rich tactile information for fine manipulation.","Code and videos are available at https://sites.google.com/view/tactile-rl-pushing/."],"url":"http://arxiv.org/abs/2307.14272v1"}
{"created":"2023-07-26 15:57:55","title":"A Clustering Strategy for Enhanced FL-Based Intrusion Detection in IoT Networks","abstract":"The Internet of Things (IoT) is growing rapidly and so the need of ensuring protection against cybersecurity attacks to IoT devices. In this scenario, Intrusion Detection Systems (IDSs) play a crucial role and data-driven IDSs based on machine learning (ML) have recently attracted more and more interest by the research community. While conventional ML-based IDSs are based on a centralized architecture where IoT devices share their data with a central server for model training, we propose a novel approach that is based on federated learning (FL). However, conventional FL is ineffective in the considered scenario, due to the high statistical heterogeneity of data collected by IoT devices. To overcome this limitation, we propose a three-tier FL-based architecture where IoT devices are clustered together based on their statistical properties. Clustering decisions are taken by means of a novel entropy-based strategy, which helps improve model training performance. We tested our solution on the CIC-ToN-IoT dataset: our clustering strategy increases intrusion detection performance with respect to a conventional FL approach up to +17% in terms of F1-score, along with a significant reduction of the number of training rounds.","sentences":["The Internet of Things (IoT) is growing rapidly and so the need of ensuring protection against cybersecurity attacks to IoT devices.","In this scenario, Intrusion Detection Systems (IDSs) play a crucial role and data-driven IDSs based on machine learning (ML) have recently attracted more and more interest by the research community.","While conventional ML-based IDSs are based on a centralized architecture where IoT devices share their data with a central server for model training, we propose a novel approach that is based on federated learning (FL).","However, conventional FL is ineffective in the considered scenario, due to the high statistical heterogeneity of data collected by IoT devices.","To overcome this limitation, we propose a three-tier FL-based architecture where IoT devices are clustered together based on their statistical properties.","Clustering decisions are taken by means of a novel entropy-based strategy, which helps improve model training performance.","We tested our solution on the CIC-ToN-IoT dataset: our clustering strategy increases intrusion detection performance with respect to a conventional FL approach up to +17% in terms of F1-score, along with a significant reduction of the number of training rounds."],"url":"http://arxiv.org/abs/2307.14268v1"}
{"created":"2023-07-26 15:53:26","title":"Improving International Climate Policy via Mutually Conditional Binding Commitments","abstract":"The Paris Agreement, considered a significant milestone in climate negotiations, has faced challenges in effectively addressing climate change due to the unconditional nature of most Nationally Determined Contributions (NDCs). This has resulted in a prevalence of free-riding behavior among major polluters and a lack of concrete conditionality in NDCs. To address this issue, we propose the implementation of a decentralized, bottom-up approach called the Conditional Commitment Mechanism. This mechanism, inspired by the National Popular Vote Interstate Compact, offers flexibility and incentives for early adopters, aiming to formalize conditional cooperation in international climate policy. In this paper, we provide an overview of the mechanism, its performance in the AI4ClimateCooperation challenge, and discuss potential real-world implementation aspects. Prior knowledge of the climate mitigation collective action problem, basic economic principles, and game theory concepts are assumed.","sentences":["The Paris Agreement, considered a significant milestone in climate negotiations, has faced challenges in effectively addressing climate change due to the unconditional nature of most Nationally Determined Contributions (NDCs).","This has resulted in a prevalence of free-riding behavior among major polluters and a lack of concrete conditionality in NDCs.","To address this issue, we propose the implementation of a decentralized, bottom-up approach called the Conditional Commitment Mechanism.","This mechanism, inspired by the National Popular Vote Interstate Compact, offers flexibility and incentives for early adopters, aiming to formalize conditional cooperation in international climate policy.","In this paper, we provide an overview of the mechanism, its performance in the AI4ClimateCooperation challenge, and discuss potential real-world implementation aspects.","Prior knowledge of the climate mitigation collective action problem, basic economic principles, and game theory concepts are assumed."],"url":"http://arxiv.org/abs/2307.14267v1"}
{"created":"2023-07-26 15:53:21","title":"Improving International Climate Policy via Mutually Conditional Binding Commitments","abstract":"This paper proposes enhancements to the RICE-N simulation and multi-agent reinforcement learning framework to improve the realism of international climate policy negotiations. Acknowledging the framework's value, we highlight the necessity of significant enhancements to address the diverse array of factors in modeling climate negotiations. Building upon our previous work on the \"Conditional Commitments Mechanism\" (CCF mechanism) we discuss ways to bridge the gap between simulation and reality. We suggest the inclusion of a recommender or planner agent to enhance coordination, address the Real2Sim gap by incorporating social factors and non-party stakeholder sub-agents, and propose enhancements to the underlying Reinforcement Learning solution algorithm. These proposed improvements aim to advance the evaluation and formulation of negotiation protocols for more effective international climate policy decision-making in Rice-N. However, further experimentation and testing are required to determine the implications and effectiveness of these suggestions.","sentences":["This paper proposes enhancements to the RICE-N simulation and multi-agent reinforcement learning framework to improve the realism of international climate policy negotiations.","Acknowledging the framework's value, we highlight the necessity of significant enhancements to address the diverse array of factors in modeling climate negotiations.","Building upon our previous work on the \"Conditional Commitments Mechanism\" (CCF mechanism) we discuss ways to bridge the gap between simulation and reality.","We suggest the inclusion of a recommender or planner agent to enhance coordination, address the Real2Sim gap by incorporating social factors and non-party stakeholder sub-agents, and propose enhancements to the underlying Reinforcement Learning solution algorithm.","These proposed improvements aim to advance the evaluation and formulation of negotiation protocols for more effective international climate policy decision-making in Rice-N.","However, further experimentation and testing are required to determine the implications and effectiveness of these suggestions."],"url":"http://arxiv.org/abs/2307.14266v1"}
{"created":"2023-07-26 15:51:49","title":"A tight Monte-Carlo algorithm for Steiner Tree parameterized by clique-width","abstract":"Recently, Hegerfeld and Kratsch [ESA 2023] obtained the first tight algorithmic results for hard connectivity problems parameterized by clique-width. Concretely, they gave one-sided error Monte-Carlo algorithms that given a $k$-clique-expression solve Connected Vertex Cover in time $6^kn^{O(1)}$ and Connected Dominating Set in time $5^kn^{O(1)}$. Moreover, under the Strong Exponential-Time Hypothesis (SETH) these results were showed to be tight. However, they leave open several important benchmark problems, whose complexity relative to treewidth had been settled by Cygan et al. [SODA 2011 & TALG 2018]. Among which is the Steiner Tree problem. As a key obstruction they point out the exponential gap between the rank of certain compatibility matrices, which is often used for algorithms, and the largest triangular submatrix therein, which is essential for current lower bound methods. Concretely, for Steiner Tree the $GF(2)$-rank is $4^k$, while no triangular submatrix larger than $3^k$ was known. This yields time $4^kn^{O(1)}$, while the obtainable impossibility of time $(3-\\varepsilon)^kn^{O(1)}$ under SETH was already known relative to pathwidth.   We close this gap by showing that Steiner Tree can be solved in time $3^kn^{O(1)}$ given a $k$-clique-expression. Hence, for all parameters between cutwidth and clique-width it has the same tight complexity. We first show that there is a ``representative submatrix'' of GF(2)-rank $3^k$ (ruling out larger triangular submatrices). At first glance, this only allows to count (modulo 2) the number of representations of valid solutions, but not the number of solutions (even if a unique solution exists). We show how to overcome this problem by isolating a unique representative of a unique solution, if one exists. We believe that our approach will be instrumental for settling further open problems in this research program.","sentences":["Recently, Hegerfeld and Kratsch [ESA 2023] obtained the first tight algorithmic results for hard connectivity problems parameterized by clique-width.","Concretely, they gave one-sided error Monte-Carlo algorithms that given a $k$-clique-expression solve Connected Vertex Cover in time $6^kn^{O(1)}$ and Connected Dominating Set in time $5^kn^{O(1)}$. Moreover, under the Strong Exponential-Time Hypothesis (SETH) these results were showed to be tight.","However, they leave open several important benchmark problems, whose complexity relative to treewidth had been settled by Cygan et al.","[SODA 2011 & TALG 2018].","Among which is the Steiner Tree problem.","As a key obstruction they point out the exponential gap between the rank of certain compatibility matrices, which is often used for algorithms, and the largest triangular submatrix therein, which is essential for current lower bound methods.","Concretely, for Steiner Tree the $GF(2)$-rank is $4^k$, while no triangular submatrix larger than $3^k$ was known.","This yields time $4^kn^{O(1)}$, while the obtainable impossibility of time $(3-\\varepsilon)^kn^{O(1)}$ under SETH was already known relative to pathwidth.   ","We close this gap by showing that Steiner Tree can be solved in time $3^kn^{O(1)}$ given a $k$-clique-expression.","Hence, for all parameters between cutwidth and clique-width it has the same tight complexity.","We first show that there is a ``representative submatrix'' of GF(2)-rank $3^k$ (ruling out larger triangular submatrices).","At first glance, this only allows to count (modulo 2) the number of representations of valid solutions, but not the number of solutions (even if a unique solution exists).","We show how to overcome this problem by isolating a unique representative of a unique solution, if one exists.","We believe that our approach will be instrumental for settling further open problems in this research program."],"url":"http://arxiv.org/abs/2307.14264v1"}
{"created":"2023-07-26 15:33:35","title":"Sparse Double Descent in Vision Transformers: real or phantom threat?","abstract":"Vision transformers (ViT) have been of broad interest in recent theoretical and empirical works. They are state-of-the-art thanks to their attention-based approach, which boosts the identification of key features and patterns within images thanks to the capability of avoiding inductive bias, resulting in highly accurate image analysis. Meanwhile, neoteric studies have reported a ``sparse double descent'' phenomenon that can occur in modern deep-learning models, where extremely over-parametrized models can generalize well. This raises practical questions about the optimal size of the model and the quest over finding the best trade-off between sparsity and performance is launched: are Vision Transformers also prone to sparse double descent? Can we find a way to avoid such a phenomenon? Our work tackles the occurrence of sparse double descent on ViTs. Despite some works that have shown that traditional architectures, like Resnet, are condemned to the sparse double descent phenomenon, for ViTs we observe that an optimally-tuned $\\ell_2$ regularization relieves such a phenomenon. However, everything comes at a cost: optimal lambda will sacrifice the potential compression of the ViT.","sentences":["Vision transformers (ViT) have been of broad interest in recent theoretical and empirical works.","They are state-of-the-art thanks to their attention-based approach, which boosts the identification of key features and patterns within images thanks to the capability of avoiding inductive bias, resulting in highly accurate image analysis.","Meanwhile, neoteric studies have reported a ``sparse double descent'' phenomenon that can occur in modern deep-learning models, where extremely over-parametrized models can generalize well.","This raises practical questions about the optimal size of the model and the quest over finding the best trade-off between sparsity and performance is launched: are Vision Transformers also prone to sparse double descent?","Can we find a way to avoid such a phenomenon?","Our work tackles the occurrence of sparse double descent on ViTs.","Despite some works that have shown that traditional architectures, like Resnet, are condemned to the sparse double descent phenomenon, for ViTs we observe that an optimally-tuned $\\ell_2$ regularization relieves such a phenomenon.","However, everything comes at a cost: optimal lambda will sacrifice the potential compression of the ViT."],"url":"http://arxiv.org/abs/2307.14253v1"}
{"created":"2023-07-26 15:19:17","title":"CBGL: Fast Monte Carlo Passive Global Localisation of 2D LIDAR Sensor","abstract":"Navigation of a mobile robot is conditioned on the knowledge of its pose. In observer-based localisation configurations its initial pose may not be knowable in advance, leading to the need of its estimation. Solutions to the problem of global localisation are either robust against noise and environment arbitrariness but require motion and time, which may (need to) be economised on, or require minimal estimation time but assume environmental structure, may be sensitive to noise, and demand preprocessing and tuning. This article proposes a method that retains the strengths and avoids the weaknesses of the two approaches. The method leverages properties of the Cumulative Absolute Error per Ray metric with respect to the errors of pose estimates of a 2D LIDAR sensor, and utilises scan--to--map-scan matching for fine(r) pose approximations. A large number of tests, in real and simulated conditions, involving disparate environments and sensor properties, illustrate that the proposed method outperforms state-of-the-art methods of both classes of solutions in terms of pose discovery rate and execution time. The source code is available for download.","sentences":["Navigation of a mobile robot is conditioned on the knowledge of its pose.","In observer-based localisation configurations its initial pose may not be knowable in advance, leading to the need of its estimation.","Solutions to the problem of global localisation are either robust against noise and environment arbitrariness but require motion and time, which may (need to) be economised on, or require minimal estimation time but assume environmental structure, may be sensitive to noise, and demand preprocessing and tuning.","This article proposes a method that retains the strengths and avoids the weaknesses of the two approaches.","The method leverages properties of the Cumulative Absolute Error per Ray metric with respect to the errors of pose estimates of a 2D LIDAR sensor, and utilises scan--to--map-scan matching for fine(r) pose approximations.","A large number of tests, in real and simulated conditions, involving disparate environments and sensor properties, illustrate that the proposed method outperforms state-of-the-art methods of both classes of solutions in terms of pose discovery rate and execution time.","The source code is available for download."],"url":"http://arxiv.org/abs/2307.14247v1"}
{"created":"2023-07-26 15:15:44","title":"A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)","abstract":"Within the field of Requirements Engineering (RE), the increasing significance of Explainable Artificial Intelligence (XAI) in aligning AI-supported systems with user needs, societal expectations, and regulatory standards has garnered recognition. In general, explainability has emerged as an important non-functional requirement that impacts system quality. However, the supposed trade-off between explainability and performance challenges the presumed positive influence of explainability. If meeting the requirement of explainability entails a reduction in system performance, then careful consideration must be given to which of these quality aspects takes precedence and how to compromise between them. In this paper, we critically examine the alleged trade-off. We argue that it is best approached in a nuanced way that incorporates resource availability, domain characteristics, and considerations of risk. By providing a foundation for future research and best practices, this work aims to advance the field of RE for AI.","sentences":["Within the field of Requirements Engineering (RE), the increasing significance of Explainable Artificial Intelligence (XAI) in aligning AI-supported systems with user needs, societal expectations, and regulatory standards has garnered recognition.","In general, explainability has emerged as an important non-functional requirement that impacts system quality.","However, the supposed trade-off between explainability and performance challenges the presumed positive influence of explainability.","If meeting the requirement of explainability entails a reduction in system performance, then careful consideration must be given to which of these quality aspects takes precedence and how to compromise between them.","In this paper, we critically examine the alleged trade-off.","We argue that it is best approached in a nuanced way that incorporates resource availability, domain characteristics, and considerations of risk.","By providing a foundation for future research and best practices, this work aims to advance the field of RE for AI."],"url":"http://arxiv.org/abs/2307.14246v1"}
{"created":"2023-07-26 15:15:13","title":"Neural-based Cross-modal Search and Retrieval of Artwork","abstract":"Creating an intelligent search and retrieval system for artwork images, particularly paintings, is crucial for documenting cultural heritage, fostering wider public engagement, and advancing artistic analysis and interpretation. Visual-Semantic Embedding (VSE) networks are deep learning models used for information retrieval, which learn joint representations of textual and visual data, enabling 1) cross-modal search and retrieval tasks, such as image-to-text and text-to-image retrieval; and 2) relation-focused retrieval to capture entity relationships and provide more contextually relevant search results. Although VSE networks have played a significant role in cross-modal information retrieval, their application to painting datasets, such as ArtUK, remains unexplored. This paper introduces BoonArt, a VSE-based cross-modal search engine that allows users to search for images using textual queries, and to obtain textual descriptions along with the corresponding images when using image queries. The performance of BoonArt was evaluated using the ArtUK dataset. Experimental evaluations revealed that BoonArt achieved 97% Recall@10 for image-to-text retrieval, and 97.4% Recall@10 for text-to-image Retrieval. By bridging the gap between textual and visual modalities, BoonArt provides a much-improved search performance compared to traditional search engines, such as the one provided by the ArtUK website. BoonArt can be utilised to work with other artwork datasets.","sentences":["Creating an intelligent search and retrieval system for artwork images, particularly paintings, is crucial for documenting cultural heritage, fostering wider public engagement, and advancing artistic analysis and interpretation.","Visual-Semantic Embedding (VSE) networks are deep learning models used for information retrieval, which learn joint representations of textual and visual data, enabling 1) cross-modal search and retrieval tasks, such as image-to-text and text-to-image retrieval; and 2) relation-focused retrieval to capture entity relationships and provide more contextually relevant search results.","Although VSE networks have played a significant role in cross-modal information retrieval, their application to painting datasets, such as ArtUK, remains unexplored.","This paper introduces BoonArt, a VSE-based cross-modal search engine that allows users to search for images using textual queries, and to obtain textual descriptions along with the corresponding images when using image queries.","The performance of BoonArt was evaluated using the ArtUK dataset.","Experimental evaluations revealed that BoonArt achieved 97% Recall@10 for image-to-text retrieval, and 97.4% Recall@10 for text-to-image Retrieval.","By bridging the gap between textual and visual modalities, BoonArt provides a much-improved search performance compared to traditional search engines, such as the one provided by the ArtUK website.","BoonArt can be utilised to work with other artwork datasets."],"url":"http://arxiv.org/abs/2307.14244v1"}
{"created":"2023-07-26 15:14:10","title":"Fluorescent Neuronal Cells v2: Multi-Task, Multi-Format Annotations for Deep Learning in Microscopy","abstract":"Fluorescent Neuronal Cells v2 is a collection of fluorescence microscopy images and the corresponding ground-truth annotations, designed to foster innovative research in the domains of Life Sciences and Deep Learning. This dataset encompasses three image collections in which rodent neuronal cells' nuclei and cytoplasm are stained with diverse markers to highlight their anatomical or functional characteristics. Alongside the images, we provide ground-truth annotations for several learning tasks, including semantic segmentation, object detection, and counting. The contribution is two-fold. First, given the variety of annotations and their accessible formats, we envision our work facilitating methodological advancements in computer vision approaches for segmentation, detection, feature learning, unsupervised and self-supervised learning, transfer learning, and related areas. Second, by enabling extensive exploration and benchmarking, we hope Fluorescent Neuronal Cells v2 will catalyze breakthroughs in fluorescence microscopy analysis and promote cutting-edge discoveries in life sciences. The data are available at: https://amsacta.unibo.it/id/eprint/7347","sentences":["Fluorescent Neuronal Cells v2 is a collection of fluorescence microscopy images and the corresponding ground-truth annotations, designed to foster innovative research in the domains of Life Sciences and Deep Learning.","This dataset encompasses three image collections in which rodent neuronal cells' nuclei and cytoplasm are stained with diverse markers to highlight their anatomical or functional characteristics.","Alongside the images, we provide ground-truth annotations for several learning tasks, including semantic segmentation, object detection, and counting.","The contribution is two-fold.","First, given the variety of annotations and their accessible formats, we envision our work facilitating methodological advancements in computer vision approaches for segmentation, detection, feature learning, unsupervised and self-supervised learning, transfer learning, and related areas.","Second, by enabling extensive exploration and benchmarking, we hope Fluorescent Neuronal Cells v2 will catalyze breakthroughs in fluorescence microscopy analysis and promote cutting-edge discoveries in life sciences.","The data are available at: https://amsacta.unibo.it/id/eprint/7347"],"url":"http://arxiv.org/abs/2307.14243v1"}
{"created":"2023-07-26 15:11:51","title":"Defending Adversarial Patches via Joint Region Localizing and Inpainting","abstract":"Deep neural networks are successfully used in various applications, but show their vulnerability to adversarial examples. With the development of adversarial patches, the feasibility of attacks in physical scenes increases, and the defenses against patch attacks are urgently needed. However, defending such adversarial patch attacks is still an unsolved problem. In this paper, we analyse the properties of adversarial patches, and find that: on the one hand, adversarial patches will lead to the appearance or contextual inconsistency in the target objects; on the other hand, the patch region will show abnormal changes on the high-level feature maps of the objects extracted by a backbone network. Considering the above two points, we propose a novel defense method based on a ``localizing and inpainting\" mechanism to pre-process the input examples. Specifically, we design an unified framework, where the ``localizing\" sub-network utilizes a two-branch structure to represent the above two aspects to accurately detect the adversarial patch region in the image. For the ``inpainting\" sub-network, it utilizes the surrounding contextual cues to recover the original content covered by the adversarial patch. The quality of inpainted images is also evaluated by measuring the appearance consistency and the effects of adversarial attacks. These two sub-networks are then jointly trained via an iterative optimization manner. In this way, the ``localizing\" and ``inpainting\" modules can interact closely with each other, and thus learn a better solution. A series of experiments versus traffic sign classification and detection tasks are conducted to defend against various adversarial patch attacks.","sentences":["Deep neural networks are successfully used in various applications, but show their vulnerability to adversarial examples.","With the development of adversarial patches, the feasibility of attacks in physical scenes increases, and the defenses against patch attacks are urgently needed.","However, defending such adversarial patch attacks is still an unsolved problem.","In this paper, we analyse the properties of adversarial patches, and find that: on the one hand, adversarial patches will lead to the appearance or contextual inconsistency in the target objects; on the other hand, the patch region will show abnormal changes on the high-level feature maps of the objects extracted by a backbone network.","Considering the above two points, we propose a novel defense method based on a ``localizing and inpainting\" mechanism to pre-process the input examples.","Specifically, we design an unified framework, where the ``localizing\" sub-network utilizes a two-branch structure to represent the above two aspects to accurately detect the adversarial patch region in the image.","For the ``inpainting\" sub-network, it utilizes the surrounding contextual cues to recover the original content covered by the adversarial patch.","The quality of inpainted images is also evaluated by measuring the appearance consistency and the effects of adversarial attacks.","These two sub-networks are then jointly trained via an iterative optimization manner.","In this way, the ``localizing\" and ``inpainting\" modules can interact closely with each other, and thus learn a better solution.","A series of experiments versus traffic sign classification and detection tasks are conducted to defend against various adversarial patch attacks."],"url":"http://arxiv.org/abs/2307.14242v1"}
{"created":"2023-07-26 15:10:54","title":"DisguisOR: Holistic Face Anonymization for the Operating Room","abstract":"Purpose: Recent advances in Surgical Data Science (SDS) have contributed to an increase in video recordings from hospital environments. While methods such as surgical workflow recognition show potential in increasing the quality of patient care, the quantity of video data has surpassed the scale at which images can be manually anonymized. Existing automated 2D anonymization methods under-perform in Operating Rooms (OR), due to occlusions and obstructions. We propose to anonymize multi-view OR recordings using 3D data from multiple camera streams. Methods: RGB and depth images from multiple cameras are fused into a 3D point cloud representation of the scene. We then detect each individual's face in 3D by regressing a parametric human mesh model onto detected 3D human keypoints and aligning the face mesh with the fused 3D point cloud. The mesh model is rendered into every acquired camera view, replacing each individual's face. Results: Our method shows promise in locating faces at a higher rate than existing approaches. DisguisOR produces geometrically consistent anonymizations for each camera view, enabling more realistic anonymization that is less detrimental to downstream tasks. Conclusion: Frequent obstructions and crowding in operating rooms leaves significant room for improvement for off-the-shelf anonymization methods. DisguisOR addresses privacy on a scene level and has the potential to facilitate further research in SDS.","sentences":["Purpose:","Recent advances in Surgical Data Science (SDS) have contributed to an increase in video recordings from hospital environments.","While methods such as surgical workflow recognition show potential in increasing the quality of patient care, the quantity of video data has surpassed the scale at which images can be manually anonymized.","Existing automated 2D anonymization methods under-perform in Operating Rooms (OR), due to occlusions and obstructions.","We propose to anonymize multi-view OR recordings using 3D data from multiple camera streams.","Methods: RGB and depth images from multiple cameras are fused into a 3D point cloud representation of the scene.","We then detect each individual's face in 3D by regressing a parametric human mesh model onto detected 3D human keypoints and aligning the face mesh with the fused 3D point cloud.","The mesh model is rendered into every acquired camera view, replacing each individual's face.","Results:","Our method shows promise in locating faces at a higher rate than existing approaches.","DisguisOR produces geometrically consistent anonymizations for each camera view, enabling more realistic anonymization that is less detrimental to downstream tasks.","Conclusion: Frequent obstructions and crowding in operating rooms leaves significant room for improvement for off-the-shelf anonymization methods.","DisguisOR","addresses privacy on a scene level and has the potential to facilitate further research in SDS."],"url":"http://arxiv.org/abs/2307.14241v1"}
{"created":"2023-07-26 15:08:02","title":"Boon: A Neural Search Engine for Cross-Modal Information Retrieval","abstract":"Visual-Semantic Embedding (VSE) networks can help search engines better understand the meaning behind visual content and associate it with relevant textual information, leading to more accurate search results. VSE networks can be used in cross-modal search engines to embed image and textual descriptions in a shared space, enabling image-to-text and text-to-image retrieval tasks. However, the full potential of VSE networks for search engines has yet to be fully explored. This paper presents Boon, a novel cross-modal search engine that combines two state-of-the-art networks: the GPT-3.5-turbo large language model, and the VSE network VITR (VIsion Transformers with Relation-focused learning) to enhance the engine's capabilities in extracting and reasoning with regional relationships in images. VITR employs encoders from CLIP that were trained with 400 million image-description pairs and it was fine-turned on the RefCOCOg dataset. Boon's neural-based components serve as its main functionalities: 1) a 'cross-modal search engine' that enables end-users to perform image-to-text and text-to-image retrieval. 2) a 'multi-lingual conversational AI' component that enables the end-user to converse about one or more images selected by the end-user. Such a feature makes the search engine accessible to a wide audience, including those with visual impairments. 3) Boon is multi-lingual and can take queries and handle conversations about images in multiple languages. Boon was implemented using the Django and PyTorch frameworks. The interface and capabilities of the Boon search engine are demonstrated using the RefCOCOg dataset, and the engine's ability to search for multimedia through the web is facilitated by Google's API.","sentences":["Visual-Semantic Embedding (VSE) networks can help search engines better understand the meaning behind visual content and associate it with relevant textual information, leading to more accurate search results.","VSE networks can be used in cross-modal search engines to embed image and textual descriptions in a shared space, enabling image-to-text and text-to-image retrieval tasks.","However, the full potential of VSE networks for search engines has yet to be fully explored.","This paper presents Boon, a novel cross-modal search engine that combines two state-of-the-art networks: the GPT-3.5-turbo large language model, and the VSE network VITR (VIsion Transformers with Relation-focused learning) to enhance the engine's capabilities in extracting and reasoning with regional relationships in images.","VITR employs encoders from CLIP that were trained with 400 million image-description pairs and it was fine-turned on the RefCOCOg dataset.","Boon's neural-based components serve as its main functionalities: 1) a 'cross-modal search engine' that enables end-users to perform image-to-text and text-to-image retrieval.","2) a 'multi-lingual conversational AI' component that enables the end-user to converse about one or more images selected by the end-user.","Such a feature makes the search engine accessible to a wide audience, including those with visual impairments.","3) Boon is multi-lingual and can take queries and handle conversations about images in multiple languages.","Boon was implemented using the Django and PyTorch frameworks.","The interface and capabilities of the Boon search engine are demonstrated using the RefCOCOg dataset, and the engine's ability to search for multimedia through the web is facilitated by Google's API."],"url":"http://arxiv.org/abs/2307.14240v1"}
{"created":"2023-07-26 15:07:40","title":"Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)","abstract":"Within the field of Requirements Engineering (RE), the increasing significance of Explainable Artificial Intelligence (XAI) in aligning AI-supported systems with user needs, societal expectations, and regulatory standards has garnered recognition. In general, explainability has emerged as an important non-functional requirement that impacts system quality. However, the supposed trade-off between explainability and performance challenges the presumed positive influence of explainability. If meeting the requirement of explainability entails a reduction in system performance, then careful consideration must be given to which of these quality aspects takes precedence and how to compromise between them. In this paper, we critically examine the alleged trade-off. We argue that it is best approached in a nuanced way that incorporates resource availability, domain characteristics, and considerations of risk. By providing a foundation for future research and best practices, this work aims to advance the field of RE for AI.","sentences":["Within the field of Requirements Engineering (RE), the increasing significance of Explainable Artificial Intelligence (XAI) in aligning AI-supported systems with user needs, societal expectations, and regulatory standards has garnered recognition.","In general, explainability has emerged as an important non-functional requirement that impacts system quality.","However, the supposed trade-off between explainability and performance challenges the presumed positive influence of explainability.","If meeting the requirement of explainability entails a reduction in system performance, then careful consideration must be given to which of these quality aspects takes precedence and how to compromise between them.","In this paper, we critically examine the alleged trade-off.","We argue that it is best approached in a nuanced way that incorporates resource availability, domain characteristics, and considerations of risk.","By providing a foundation for future research and best practices, this work aims to advance the field of RE for AI."],"url":"http://arxiv.org/abs/2307.14239v1"}
{"created":"2023-07-26 15:05:17","title":"Evolving Multi-Objective Neural Network Controllers for Robot Swarms","abstract":"Many swarm robotics tasks consist of multiple conflicting objectives. This research proposes a multi-objective evolutionary neural network approach to developing controllers for swarms of robots. The swarm robot controllers are trained in a low-fidelity Python simulator and then tested in a high-fidelity simulated environment using Webots. Simulations are then conducted to test the scalability of the evolved multi-objective robot controllers to environments with a larger number of robots. The results presented demonstrate that the proposed approach can effectively control each of the robots. The robot swarm exhibits different behaviours as the weighting for each objective is adjusted. The results also confirm that multi-objective neural network controllers evolved in a low-fidelity simulator can be transferred to high-fidelity simulated environments and that the controllers can scale to environments with a larger number of robots without further retraining needed.","sentences":["Many swarm robotics tasks consist of multiple conflicting objectives.","This research proposes a multi-objective evolutionary neural network approach to developing controllers for swarms of robots.","The swarm robot controllers are trained in a low-fidelity Python simulator and then tested in a high-fidelity simulated environment using Webots.","Simulations are then conducted to test the scalability of the evolved multi-objective robot controllers to environments with a larger number of robots.","The results presented demonstrate that the proposed approach can effectively control each of the robots.","The robot swarm exhibits different behaviours as the weighting for each objective is adjusted.","The results also confirm that multi-objective neural network controllers evolved in a low-fidelity simulator can be transferred to high-fidelity simulated environments and that the controllers can scale to environments with a larger number of robots without further retraining needed."],"url":"http://arxiv.org/abs/2307.14237v1"}
{"created":"2023-07-26 15:04:24","title":"UnScientify: Detecting Scientific Uncertainty in Scholarly Full Text","abstract":"This demo paper presents UnScientify, an interactive system designed to detect scientific uncertainty in scholarly full text. The system utilizes a weakly supervised technique that employs a fine-grained annotation scheme to identify verbally formulated uncertainty at the sentence level in scientific texts. The pipeline for the system includes a combination of pattern matching, complex sentence checking, and authorial reference checking. Our approach automates labeling and annotation tasks for scientific uncertainty identification, taking into account different types of scientific uncertainty, that can serve various applications such as information retrieval, text mining, and scholarly document processing. Additionally, UnScientify provides interpretable results, aiding in the comprehension of identified instances of scientific uncertainty in text.","sentences":["This demo paper presents UnScientify, an interactive system designed to detect scientific uncertainty in scholarly full text.","The system utilizes a weakly supervised technique that employs a fine-grained annotation scheme to identify verbally formulated uncertainty at the sentence level in scientific texts.","The pipeline for the system includes a combination of pattern matching, complex sentence checking, and authorial reference checking.","Our approach automates labeling and annotation tasks for scientific uncertainty identification, taking into account different types of scientific uncertainty, that can serve various applications such as information retrieval, text mining, and scholarly document processing.","Additionally, UnScientify provides interpretable results, aiding in the comprehension of identified instances of scientific uncertainty in text."],"url":"http://arxiv.org/abs/2307.14236v1"}
{"created":"2023-07-26 15:00:38","title":"Sources of Opacity in Computer Systems: Towards a Comprehensive Taxonomy","abstract":"Modern computer systems are ubiquitous in contemporary life yet many of them remain opaque. This poses significant challenges in domains where desiderata such as fairness or accountability are crucial. We suggest that the best strategy for achieving system transparency varies depending on the specific source of opacity prevalent in a given context. Synthesizing and extending existing discussions, we propose a taxonomy consisting of eight sources of opacity that fall into three main categories: architectural, analytical, and socio-technical. For each source, we provide initial suggestions as to how to address the resulting opacity in practice. The taxonomy provides a starting point for requirements engineers and other practitioners to understand contextually prevalent sources of opacity, and to select or develop appropriate strategies for overcoming them.","sentences":["Modern computer systems are ubiquitous in contemporary life yet many of them remain opaque.","This poses significant challenges in domains where desiderata such as fairness or accountability are crucial.","We suggest that the best strategy for achieving system transparency varies depending on the specific source of opacity prevalent in a given context.","Synthesizing and extending existing discussions, we propose a taxonomy consisting of eight sources of opacity that fall into three main categories: architectural, analytical, and socio-technical.","For each source, we provide initial suggestions as to how to address the resulting opacity in practice.","The taxonomy provides a starting point for requirements engineers and other practitioners to understand contextually prevalent sources of opacity, and to select or develop appropriate strategies for overcoming them."],"url":"http://arxiv.org/abs/2307.14232v1"}
{"created":"2023-07-26 14:50:01","title":"Computational Approaches for Traditional Chinese Painting: From the \"Six Principles of Painting\" Perspective","abstract":"Traditional Chinese Painting (TCP) is an invaluable cultural heritage resource and a unique visual art style. In recent years, increasing interest has been placed on digitalizing TCPs to preserve and revive the culture. The resulting digital copies have enabled the advancement of computational methods for structured and systematic understanding of TCPs. To explore this topic, we conducted an in-depth analysis of 92 pieces of literature. We examined the current use of computer technologies on TCPs from three perspectives, based on numerous conversations with specialists. First, in light of the \"Six Principles of Painting\" theory, we categorized the articles according to their research focus on artistic elements. Second, we created a four-stage framework to illustrate the purposes of TCP applications. Third, we summarized the popular computational techniques applied to TCPs. The framework also provides insights into potential applications and future prospects, with professional opinion. The list of surveyed publications and related information is available online at https://ca4tcp.com.","sentences":["Traditional Chinese Painting (TCP) is an invaluable cultural heritage resource and a unique visual art style.","In recent years, increasing interest has been placed on digitalizing TCPs to preserve and revive the culture.","The resulting digital copies have enabled the advancement of computational methods for structured and systematic understanding of TCPs.","To explore this topic, we conducted an in-depth analysis of 92 pieces of literature.","We examined the current use of computer technologies on TCPs from three perspectives, based on numerous conversations with specialists.","First, in light of the \"Six Principles of Painting\" theory, we categorized the articles according to their research focus on artistic elements.","Second, we created a four-stage framework to illustrate the purposes of TCP applications.","Third, we summarized the popular computational techniques applied to TCPs.","The framework also provides insights into potential applications and future prospects, with professional opinion.","The list of surveyed publications and related information is available online at https://ca4tcp.com."],"url":"http://arxiv.org/abs/2307.14227v1"}
{"created":"2023-07-26 14:48:25","title":"Explore the possibility of advancing climate negotiations on the basis of regional trade organizations: A study based on RICE-N","abstract":"Climate issues have become more and more important now. Although global governments have made some progress, we are still facing the truth that the prospect of international cooperation is not clear at present. Due to the limitations of the Integrated assessment models (IAMs) model, it is difficult to simulate the dynamic negotiation process. Therefore, using deep learning to build a new agents based model (ABM) might can provide new theoretical support for climate negotiations. Building on the RICE-N model, this work proposed an approach to climate negotiations based on existing trade groups. Simulation results show that the scheme has a good prospect.","sentences":["Climate issues have become more and more important now.","Although global governments have made some progress, we are still facing the truth that the prospect of international cooperation is not clear at present.","Due to the limitations of the Integrated assessment models (IAMs) model, it is difficult to simulate the dynamic negotiation process.","Therefore, using deep learning to build a new agents based model (ABM) might can provide new theoretical support for climate negotiations.","Building on the RICE-N model, this work proposed an approach to climate negotiations based on existing trade groups.","Simulation results show that the scheme has a good prospect."],"url":"http://arxiv.org/abs/2307.14226v1"}
{"created":"2023-07-26 14:47:15","title":"Large Language Models are Competitive Near Cold-start Recommenders for Language- and Item-based Preferences","abstract":"Traditional recommender systems leverage users' item preference history to recommend novel content that users may like. However, modern dialog interfaces that allow users to express language-based preferences offer a fundamentally different modality for preference input. Inspired by recent successes of prompting paradigms for large language models (LLMs), we study their use for making recommendations from both item-based and language-based preferences in comparison to state-of-the-art item-based collaborative filtering (CF) methods. To support this investigation, we collect a new dataset consisting of both item-based and language-based preferences elicited from users along with their ratings on a variety of (biased) recommended items and (unbiased) random items. Among numerous experimental results, we find that LLMs provide competitive recommendation performance for pure language-based preferences (no item preferences) in the near cold-start case in comparison to item-based CF methods, despite having no supervised training for this specific task (zero-shot) or only a few labels (few-shot). This is particularly promising as language-based preference representations are more explainable and scrutable than item-based or vector-based representations.","sentences":["Traditional recommender systems leverage users' item preference history to recommend novel content that users may like.","However, modern dialog interfaces that allow users to express language-based preferences offer a fundamentally different modality for preference input.","Inspired by recent successes of prompting paradigms for large language models (LLMs), we study their use for making recommendations from both item-based and language-based preferences in comparison to state-of-the-art item-based collaborative filtering (CF) methods.","To support this investigation, we collect a new dataset consisting of both item-based and language-based preferences elicited from users along with their ratings on a variety of (biased) recommended items and (unbiased) random items.","Among numerous experimental results, we find that LLMs provide competitive recommendation performance for pure language-based preferences (no item preferences) in the near cold-start case in comparison to item-based CF methods, despite having no supervised training for this specific task (zero-shot) or only a few labels (few-shot).","This is particularly promising as language-based preference representations are more explainable and scrutable than item-based or vector-based representations."],"url":"http://arxiv.org/abs/2307.14225v1"}
{"created":"2023-07-26 14:40:21","title":"Rewriting and Completeness of Sum-Over-Paths in Dyadic Fragments of Quantum Computing","abstract":"The \"Sum-Over-Paths\" formalism is a way to symbolically manipulate linear maps that describe quantum systems, and is a tool that is used in formal verification of such systems. We give here a new set of rewrite rules for the formalism, and show that it is complete for \"Toffoli-Hadamard\", the simplest approximately universal fragment of quantum mechanics. We show that the rewriting is terminating, but not confluent (which is expected from the universality of the fragment). We do so using the connection between Sum-over-Paths and graphical language ZH-calculus, and also show how the axiomatisation translates into the latter. We provide generalisations of the presented rewrite rules, that can prove useful when trying to reduce terms in practice, and we show how to graphically make sense of these new rules. We show how to enrich the rewrite system to reach completeness for the dyadic fragments of quantum computation, used in particular in the Quantum Fourier Transform, and obtained by adding phase gates with dyadic multiples of $\\pi$ to the Toffoli-Hadamard gate-set. Finally, we show how to perform sums and concatenation of arbitrary terms, something which is not native in a system designed for analysing gate-based quantum computation, but necessary when considering Hamiltonian-based quantum computation.","sentences":["The \"Sum-Over-Paths\" formalism is a way to symbolically manipulate linear maps that describe quantum systems, and is a tool that is used in formal verification of such systems.","We give here a new set of rewrite rules for the formalism, and show that it is complete for \"Toffoli-Hadamard\", the simplest approximately universal fragment of quantum mechanics.","We show that the rewriting is terminating, but not confluent (which is expected from the universality of the fragment).","We do so using the connection between Sum-over-Paths and graphical language ZH-calculus, and also show how the axiomatisation translates into the latter.","We provide generalisations of the presented rewrite rules, that can prove useful when trying to reduce terms in practice, and we show how to graphically make sense of these new rules.","We show how to enrich the rewrite system to reach completeness for the dyadic fragments of quantum computation, used in particular in the Quantum Fourier Transform, and obtained by adding phase gates with dyadic multiples of $\\pi$ to the Toffoli-Hadamard gate-set.","Finally, we show how to perform sums and concatenation of arbitrary terms, something which is not native in a system designed for analysing gate-based quantum computation, but necessary when considering Hamiltonian-based quantum computation."],"url":"http://arxiv.org/abs/2307.14223v1"}
{"created":"2023-07-26 14:28:37","title":"Soft Air Pocket Force Sensors for Large Scale Flexible Robots","abstract":"Flexible robots have advantages over rigid robots in their ability to conform physically to their environment and to form a wide variety of shapes. Sensing the force applied by or to flexible robots is useful for both navigation and manipulation tasks, but it is challenging due to the need for the sensors to withstand the robots' shape change without encumbering their functionality. Also, for robots with long or large bodies, the number of sensors required to cover the entire surface area of the robot body can be prohibitive due to high cost and complexity. We present a novel soft air pocket force sensor that is highly flexible, lightweight, relatively inexpensive, and easily scalable to various sizes. Our sensor produces a change in internal pressure that is linear with the applied force. We present results of experimental testing of how uncontrollable factors (contact location and contact area) and controllable factors (initial internal pressure, thickness, size, and number of interior seals) affect the sensitivity. We demonstrate our sensor applied to a vine robot-a soft inflatable robot that \"grows\" from the tip via eversion-and we show that the robot can successfully grow and steer towards an object with which it senses contact.","sentences":["Flexible robots have advantages over rigid robots in their ability to conform physically to their environment and to form a wide variety of shapes.","Sensing the force applied by or to flexible robots is useful for both navigation and manipulation tasks, but it is challenging due to the need for the sensors to withstand the robots' shape change without encumbering their functionality.","Also, for robots with long or large bodies, the number of sensors required to cover the entire surface area of the robot body can be prohibitive due to high cost and complexity.","We present a novel soft air pocket force sensor that is highly flexible, lightweight, relatively inexpensive, and easily scalable to various sizes.","Our sensor produces a change in internal pressure that is linear with the applied force.","We present results of experimental testing of how uncontrollable factors (contact location and contact area) and controllable factors (initial internal pressure, thickness, size, and number of interior seals) affect the sensitivity.","We demonstrate our sensor applied to a vine robot-a soft inflatable robot that \"grows\" from the tip via eversion-and we show that the robot can successfully grow and steer towards an object with which it senses contact."],"url":"http://arxiv.org/abs/2307.14213v1"}
{"created":"2023-07-26 14:26:16","title":"Mining Reddit Data to Elicit Students' Requirements During COVID-19 Pandemic","abstract":"Data-driven requirements engineering leverages the abundance of openly accessible and crowdsourced information on the web. By incorporating user feedback provided about a software product, such as reviews in mobile app stores, these approaches facilitate the identification of issues, bug fixes, and implementation of change requests. However, relying solely on user feedback about a software product limits the possibility of eliciting all requirements, as users may not always have a clear understanding of their exact needs from the software, despite their wealth of experience with the problem, event, or challenges they encounter and use the software to assist them. In this study, we propose a shift in requirements elicitation, focusing on gathering feedback related to the problem itself rather than relying solely on feedback about the software product. We conducted a case study on student requirements during the COVID-19 pandemic in a higher education institution. We gathered their communications from Reddit during the pandemic and employed multiple machine-learning and natural language processing techniques to identify requirement sentences. We achieved the F-score of 0.79 using Naive Bayes with TF-IDF when benchmarking multiple techniques. The results lead us to believe that mining requirements from communication about a problem are feasible. While we present the preliminary results, we envision a future where these requirements complement conventionally elicited requirements and help to close the requirements gap.","sentences":["Data-driven requirements engineering leverages the abundance of openly accessible and crowdsourced information on the web.","By incorporating user feedback provided about a software product, such as reviews in mobile app stores, these approaches facilitate the identification of issues, bug fixes, and implementation of change requests.","However, relying solely on user feedback about a software product limits the possibility of eliciting all requirements, as users may not always have a clear understanding of their exact needs from the software, despite their wealth of experience with the problem, event, or challenges they encounter and use the software to assist them.","In this study, we propose a shift in requirements elicitation, focusing on gathering feedback related to the problem itself rather than relying solely on feedback about the software product.","We conducted a case study on student requirements during the COVID-19 pandemic in a higher education institution.","We gathered their communications from Reddit during the pandemic and employed multiple machine-learning and natural language processing techniques to identify requirement sentences.","We achieved the F-score of 0.79 using Naive Bayes with TF-IDF when benchmarking multiple techniques.","The results lead us to believe that mining requirements from communication about a problem are feasible.","While we present the preliminary results, we envision a future where these requirements complement conventionally elicited requirements and help to close the requirements gap."],"url":"http://arxiv.org/abs/2307.14212v1"}
{"created":"2023-07-26 14:14:38","title":"Online Modeling and Monitoring of Dependent Processes under Resource Constraints","abstract":"Monitoring a population of dependent processes under limited resources is critical for abnormal events detection. A novel online collaborative learning method is proposed to adaptively allocate the resources for exploitation of high-risk processes and exploration of dependent dynamics. Efficiency of the proposed method is proved through theoretical analysis and experiments.","sentences":["Monitoring a population of dependent processes under limited resources is critical for abnormal events detection.","A novel online collaborative learning method is proposed to adaptively allocate the resources for exploitation of high-risk processes and exploration of dependent dynamics.","Efficiency of the proposed method is proved through theoretical analysis and experiments."],"url":"http://arxiv.org/abs/2307.14208v1"}
{"created":"2023-07-26 14:12:16","title":"AI and Education: An Investigation into the Use of ChatGPT for Systems Thinking","abstract":"This exploratory study investigates the potential of the artificial intelligence tool, ChatGPT, to support systems thinking (ST) in various subjects. Using both general and subject specific prompts, the study assesses the accuracy, helpfulness, and reliability of ChatGPT's responses across different versions of the tool. The results indicate that ChatGPT can provide largely correct and very helpful responses in various subjects, demonstrating its potential as a tool for enhancing ST skills. However, occasional inaccuracies highlight the need for users to remain critical of ChatGPT's responses. Despite some limitations, this study suggests that with careful use and attention to its idiosyncrasies, ChatGPT can be a valuable tool for teaching and learning ST.","sentences":["This exploratory study investigates the potential of the artificial intelligence tool, ChatGPT, to support systems thinking (ST) in various subjects.","Using both general and subject specific prompts, the study assesses the accuracy, helpfulness, and reliability of ChatGPT's responses across different versions of the tool.","The results indicate that ChatGPT can provide largely correct and very helpful responses in various subjects, demonstrating its potential as a tool for enhancing ST skills.","However, occasional inaccuracies highlight the need for users to remain critical of ChatGPT's responses.","Despite some limitations, this study suggests that with careful use and attention to its idiosyncrasies, ChatGPT can be a valuable tool for teaching and learning ST."],"url":"http://arxiv.org/abs/2307.14206v1"}
{"created":"2023-07-26 13:57:31","title":"Heterogeneous Receptors - Based Molecule Harvesting in MC: Analysis for ISI Mitigation and Energy Efficiency","abstract":"This paper investigates a spherical transmitter (TX) with a membrane covered by heterogeneous receptors of varying sizes and arbitrary locations for molecular communication (MC), where molecules are encapsulated within vesicles and released from the TX through membrane fusion. Assuming continuous vesicle generation at the TX and a transparent receiver (RX), we calculate the molecule release rate, the fraction of absorbed molecules at the TX, and the received signal at the RX. All obtained analytical expressions are functions of all receptors locations and sizes, and are validated by particle-based simulations. Our numerical results indicate that evenly distributed receptors on the TX membrane can absorb more molecules than randomly distributed receptors or a single receptor. Furthermore, inspired by the autoreceptor functionality in synaptic communication, we incorporate a negative feedback mechanism (NFM) at the TX, such that molecule release stops after a certain period. We then derive the fraction of molecules that can be reused for the subsequent emissions when considering both NFM and molecule harvesting. Our numerical results demonstrate that incorporating NFM can reduce inter-symbol interference (ISI) while maintaining the same peak received signal as the case without NFM. Additionally, our results show that TXs incorporating both molecule harvesting and NFM can achieve a higher energy efficiency and lower error probability than TXs employing only molecule harvesting or neither functionality.","sentences":["This paper investigates a spherical transmitter (TX) with a membrane covered by heterogeneous receptors of varying sizes and arbitrary locations for molecular communication (MC), where molecules are encapsulated within vesicles and released from the TX through membrane fusion.","Assuming continuous vesicle generation at the TX and a transparent receiver (RX), we calculate the molecule release rate, the fraction of absorbed molecules at the TX, and the received signal at the RX.","All obtained analytical expressions are functions of all receptors locations and sizes, and are validated by particle-based simulations.","Our numerical results indicate that evenly distributed receptors on the TX membrane can absorb more molecules than randomly distributed receptors or a single receptor.","Furthermore, inspired by the autoreceptor functionality in synaptic communication, we incorporate a negative feedback mechanism (NFM) at the TX, such that molecule release stops after a certain period.","We then derive the fraction of molecules that can be reused for the subsequent emissions when considering both NFM and molecule harvesting.","Our numerical results demonstrate that incorporating NFM can reduce inter-symbol interference (ISI) while maintaining the same peak received signal as the case without NFM.","Additionally, our results show that TXs incorporating both molecule harvesting and NFM can achieve a higher energy efficiency and lower error probability than TXs employing only molecule harvesting or neither functionality."],"url":"http://arxiv.org/abs/2307.14202v1"}
{"created":"2023-07-26 13:52:53","title":"Application of Random Forest and Support Vector Machine for Investigation of Pressure Filtration Performance, a Zinc Plant Filter Cake Modeling","abstract":"The hydrometallurgical method of zinc production involves leaching zinc from ore and then separating the solid residue from the liquid solution by pressure filtration. This separation process is very important since the solid residue contains some moisture that can reduce the amount of zinc recovered. This study modeled the pressure filtration process through Random Forest (RF) and Support Vector Machine (SVM). The models take continuous variables (extracted features) from the lab samples as inputs. Thus, regression models namely Random Forest Regression (RFR) and Support Vector Regression (SVR) were chosen. A total dataset was obtained during the pressure filtration process in two conditions: 1) Polypropylene (S1) and 2) Polyester fabrics (S2). To predict the cake moisture, solids concentration (0.2 and 0.38), temperature (35 and 65 centigrade), pH (2, 3.5, and 5), pressure, cake thickness (14, 20, 26, and 34 mm), air-blow time (2, 10 and 15 min) and filtration time were applied as input variables. The models' predictive accuracy was evaluated by the coefficient of determination (R2) parameter. The results revealed that the RFR model is superior to the SVR model for cake moisture prediction.","sentences":["The hydrometallurgical method of zinc production involves leaching zinc from ore and then separating the solid residue from the liquid solution by pressure filtration.","This separation process is very important since the solid residue contains some moisture that can reduce the amount of zinc recovered.","This study modeled the pressure filtration process through Random Forest (RF) and Support Vector Machine (SVM).","The models take continuous variables (extracted features) from the lab samples as inputs.","Thus, regression models namely Random Forest Regression (RFR) and Support Vector Regression (SVR) were chosen.","A total dataset was obtained during the pressure filtration process in two conditions: 1) Polypropylene (S1) and 2) Polyester fabrics (S2).","To predict the cake moisture, solids concentration (0.2 and 0.38), temperature (35 and 65 centigrade), pH (2, 3.5, and 5), pressure, cake thickness (14, 20, 26, and 34 mm), air-blow time (2, 10 and 15 min) and filtration time were applied as input variables.","The models' predictive accuracy was evaluated by the coefficient of determination (R2) parameter.","The results revealed that the RFR model is superior to the SVR model for cake moisture prediction."],"url":"http://arxiv.org/abs/2307.14199v1"}
{"created":"2023-07-26 13:47:52","title":"Efficient Learning of Discrete-Continuous Computation Graphs","abstract":"Numerous models for supervised and reinforcement learning benefit from combinations of discrete and continuous model components. End-to-end learnable discrete-continuous models are compositional, tend to generalize better, and are more interpretable. A popular approach to building discrete-continuous computation graphs is that of integrating discrete probability distributions into neural networks using stochastic softmax tricks. Prior work has mainly focused on computation graphs with a single discrete component on each of the graph's execution paths. We analyze the behavior of more complex stochastic computations graphs with multiple sequential discrete components. We show that it is challenging to optimize the parameters of these models, mainly due to small gradients and local minima. We then propose two new strategies to overcome these challenges. First, we show that increasing the scale parameter of the Gumbel noise perturbations during training improves the learning behavior. Second, we propose dropout residual connections specifically tailored to stochastic, discrete-continuous computation graphs. With an extensive set of experiments, we show that we can train complex discrete-continuous models which one cannot train with standard stochastic softmax tricks. We also show that complex discrete-stochastic models generalize better than their continuous counterparts on several benchmark datasets.","sentences":["Numerous models for supervised and reinforcement learning benefit from combinations of discrete and continuous model components.","End-to-end learnable discrete-continuous models are compositional, tend to generalize better, and are more interpretable.","A popular approach to building discrete-continuous computation graphs is that of integrating discrete probability distributions into neural networks using stochastic softmax tricks.","Prior work has mainly focused on computation graphs with a single discrete component on each of the graph's execution paths.","We analyze the behavior of more complex stochastic computations graphs with multiple sequential discrete components.","We show that it is challenging to optimize the parameters of these models, mainly due to small gradients and local minima.","We then propose two new strategies to overcome these challenges.","First, we show that increasing the scale parameter of the Gumbel noise perturbations during training improves the learning behavior.","Second, we propose dropout residual connections specifically tailored to stochastic, discrete-continuous computation graphs.","With an extensive set of experiments, we show that we can train complex discrete-continuous models which one cannot train with standard stochastic softmax tricks.","We also show that complex discrete-stochastic models generalize better than their continuous counterparts on several benchmark datasets."],"url":"http://arxiv.org/abs/2307.14193v1"}
{"created":"2023-07-26 13:45:18","title":"Unveiling Security, Privacy, and Ethical Concerns of ChatGPT","abstract":"This paper delves into the realm of ChatGPT, an AI-powered chatbot that utilizes topic modeling and reinforcement learning to generate natural responses. Although ChatGPT holds immense promise across various industries, such as customer service, education, mental health treatment, personal productivity, and content creation, it is essential to address its security, privacy, and ethical implications. By exploring the upgrade path from GPT-1 to GPT-4, discussing the model's features, limitations, and potential applications, this study aims to shed light on the potential risks of integrating ChatGPT into our daily lives. Focusing on security, privacy, and ethics issues, we highlight the challenges these concerns pose for widespread adoption. Finally, we analyze the open problems in these areas, calling for concerted efforts to ensure the development of secure and ethically sound large language models.","sentences":["This paper delves into the realm of ChatGPT, an AI-powered chatbot that utilizes topic modeling and reinforcement learning to generate natural responses.","Although ChatGPT holds immense promise across various industries, such as customer service, education, mental health treatment, personal productivity, and content creation, it is essential to address its security, privacy, and ethical implications.","By exploring the upgrade path from GPT-1 to GPT-4, discussing the model's features, limitations, and potential applications, this study aims to shed light on the potential risks of integrating ChatGPT into our daily lives.","Focusing on security, privacy, and ethics issues, we highlight the challenges these concerns pose for widespread adoption.","Finally, we analyze the open problems in these areas, calling for concerted efforts to ensure the development of secure and ethically sound large language models."],"url":"http://arxiv.org/abs/2307.14192v1"}
{"created":"2023-07-26 13:41:51","title":"ADAPT: Efficient Multi-Agent Trajectory Prediction with Adaptation","abstract":"Forecasting future trajectories of agents in complex traffic scenes requires reliable and efficient predictions for all agents in the scene. However, existing methods for trajectory prediction are either inefficient or sacrifice accuracy. To address this challenge, we propose ADAPT, a novel approach for jointly predicting the trajectories of all agents in the scene with dynamic weight learning. Our approach outperforms state-of-the-art methods in both single-agent and multi-agent settings on the Argoverse and Interaction datasets, with a fraction of their computational overhead. We attribute the improvement in our performance: first, to the adaptive head augmenting the model capacity without increasing the model size; second, to our design choices in the endpoint-conditioned prediction, reinforced by gradient stopping. Our analyses show that ADAPT can focus on each agent with adaptive prediction, allowing for accurate predictions efficiently. https://KUIS-AI.github.io/adapt","sentences":["Forecasting future trajectories of agents in complex traffic scenes requires reliable and efficient predictions for all agents in the scene.","However, existing methods for trajectory prediction are either inefficient or sacrifice accuracy.","To address this challenge, we propose ADAPT, a novel approach for jointly predicting the trajectories of all agents in the scene with dynamic weight learning.","Our approach outperforms state-of-the-art methods in both single-agent and multi-agent settings on the Argoverse and Interaction datasets, with a fraction of their computational overhead.","We attribute the improvement in our performance: first, to the adaptive head augmenting the model capacity without increasing the model size; second, to our design choices in the endpoint-conditioned prediction, reinforced by gradient stopping.","Our analyses show that ADAPT can focus on each agent with adaptive prediction, allowing for accurate predictions efficiently.","https://KUIS-AI.github.io/adapt"],"url":"http://arxiv.org/abs/2307.14187v1"}
{"created":"2023-07-26 13:26:12","title":"Complexity results for the Pilot Assignment problem in Cell-Free Massive MIMO","abstract":"Wireless communication is enabling billions of people to connect to each other and the internet, transforming every sector of the economy, and building the foundations for powerful new technologies that hold great promise to improve lives at an unprecedented rate and scale. The rapid increase in the number of devices and the associated demands for higher data rates and broader network coverage fuels the need for more robust wireless technologies. The key technology identified to address this problem is referred to as Cell-Free Massive MIMO (CF-mMIMO). CF-mMIMO is accompanied by many challenges, one of which is efficiently allocating limited resources. In this paper, we focus on a major resource allocation problem in wireless networks, namely the Pilot Assignment problem (PA). We show that PA is strongly NP-hard and that it does not admit a polynomial-time constant-factor approximation algorithm. Further, we show that PA cannot be approximated in polynomial time within $\\mathcal{O}(K^2)$ (where $K$ is the number of users) when the system consists of at least three pilots. Finally, we present an approximation lower bound of $1.058$ (resp. $\\epsilon|K|^2$, for $\\epsilon >0$) in special cases where the system consists of exactly two (resp. three) pilots.","sentences":["Wireless communication is enabling billions of people to connect to each other and the internet, transforming every sector of the economy, and building the foundations for powerful new technologies that hold great promise to improve lives at an unprecedented rate and scale.","The rapid increase in the number of devices and the associated demands for higher data rates and broader network coverage fuels the need for more robust wireless technologies.","The key technology identified to address this problem is referred to as Cell-Free Massive MIMO (CF-mMIMO).","CF-mMIMO is accompanied by many challenges, one of which is efficiently allocating limited resources.","In this paper, we focus on a major resource allocation problem in wireless networks, namely the Pilot Assignment problem (PA).","We show that PA is strongly NP-hard and that it does not admit a polynomial-time constant-factor approximation algorithm.","Further, we show that PA cannot be approximated in polynomial time within $\\mathcal{O}(K^2)$ (where $K$ is the number of users) when the system consists of at least three pilots.","Finally, we present an approximation lower bound of $1.058$ (resp.","$\\epsilon|K|^2$, for $\\epsilon >0$) in special cases where the system consists of exactly two (resp.","three) pilots."],"url":"http://arxiv.org/abs/2307.14186v1"}
{"created":"2023-07-26 13:24:01","title":"A comparison of machine learning surrogate models of street-scale flooding in Norfolk, Virginia","abstract":"Low-lying coastal cities, exemplified by Norfolk, Virginia, face the challenge of street flooding caused by rainfall and tides, which strain transportation and sewer systems and can lead to property damage. While high-fidelity, physics-based simulations provide accurate predictions of urban pluvial flooding, their computational complexity renders them unsuitable for real-time applications. Using data from Norfolk rainfall events between 2016 and 2018, this study compares the performance of a previous surrogate model based on a random forest algorithm with two deep learning models: Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU). This investigation underscores the importance of using a model architecture that supports the communication of prediction uncertainty and the effective integration of relevant, multi-modal features.","sentences":["Low-lying coastal cities, exemplified by Norfolk, Virginia, face the challenge of street flooding caused by rainfall and tides, which strain transportation and sewer systems and can lead to property damage.","While high-fidelity, physics-based simulations provide accurate predictions of urban pluvial flooding, their computational complexity renders them unsuitable for real-time applications.","Using data from Norfolk rainfall events between 2016 and 2018, this study compares the performance of a previous surrogate model based on a random forest algorithm with two deep learning models: Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU).","This investigation underscores the importance of using a model architecture that supports the communication of prediction uncertainty and the effective integration of relevant, multi-modal features."],"url":"http://arxiv.org/abs/2307.14185v1"}
{"created":"2023-07-26 13:11:48","title":"Resolution-Aware Design of Atrous Rates for Semantic Segmentation Networks","abstract":"DeepLab is a widely used deep neural network for semantic segmentation, whose success is attributed to its parallel architecture called atrous spatial pyramid pooling (ASPP). ASPP uses multiple atrous convolutions with different atrous rates to extract both local and global information. However, fixed values of atrous rates are used for the ASPP module, which restricts the size of its field of view. In principle, atrous rate should be a hyperparameter to change the field of view size according to the target task or dataset. However, the manipulation of atrous rate is not governed by any guidelines. This study proposes practical guidelines for obtaining an optimal atrous rate. First, an effective receptive field for semantic segmentation is introduced to analyze the inner behavior of segmentation networks. We observed that the use of ASPP module yielded a specific pattern in the effective receptive field, which was traced to reveal the module's underlying mechanism. Accordingly, we derive practical guidelines for obtaining the optimal atrous rate, which should be controlled based on the size of input image. Compared to other values, using the optimal atrous rate consistently improved the segmentation results across multiple datasets, including the STARE, CHASE_DB1, HRF, Cityscapes, and iSAID datasets.","sentences":["DeepLab is a widely used deep neural network for semantic segmentation, whose success is attributed to its parallel architecture called atrous spatial pyramid pooling (ASPP).","ASPP uses multiple atrous convolutions with different atrous rates to extract both local and global information.","However, fixed values of atrous rates are used for the ASPP module, which restricts the size of its field of view.","In principle, atrous rate should be a hyperparameter to change the field of view size according to the target task or dataset.","However, the manipulation of atrous rate is not governed by any guidelines.","This study proposes practical guidelines for obtaining an optimal atrous rate.","First, an effective receptive field for semantic segmentation is introduced to analyze the inner behavior of segmentation networks.","We observed that the use of ASPP module yielded a specific pattern in the effective receptive field, which was traced to reveal the module's underlying mechanism.","Accordingly, we derive practical guidelines for obtaining the optimal atrous rate, which should be controlled based on the size of input image.","Compared to other values, using the optimal atrous rate consistently improved the segmentation results across multiple datasets, including the STARE, CHASE_DB1, HRF, Cityscapes, and iSAID datasets."],"url":"http://arxiv.org/abs/2307.14179v1"}
{"created":"2023-07-26 13:06:35","title":"High-definition event frame generation using SoC FPGA devices","abstract":"In this paper we have addressed the implementation of the accumulation and projection of high-resolution event data stream (HD -1280 x 720 pixels) onto the image plane in FPGA devices. The results confirm the feasibility of this approach, but there are a number of challenges, limitations and trade-offs to be considered. The required hardware resources of selected data representations, such as binary frame, event frame, exponentially decaying time surface and event frequency, were compared with those available on several popular platforms from AMD Xilinx. The resulting event frames can be used for typical vision algorithms, such as object classification and detection, using both classical and deep neural network methods.","sentences":["In this paper we have addressed the implementation of the accumulation and projection of high-resolution event data stream (HD -1280 x 720 pixels) onto the image plane in FPGA devices.","The results confirm the feasibility of this approach, but there are a number of challenges, limitations and trade-offs to be considered.","The required hardware resources of selected data representations, such as binary frame, event frame, exponentially decaying time surface and event frequency, were compared with those available on several popular platforms from AMD Xilinx.","The resulting event frames can be used for typical vision algorithms, such as object classification and detection, using both classical and deep neural network methods."],"url":"http://arxiv.org/abs/2307.14177v1"}
{"created":"2023-07-26 12:48:28","title":"$\\text{TT}^{\\Box}_{\\mathcal C}$: a Family of Extensional Type Theories with Effectful Realizers of Continuity","abstract":"$\\text{TT}^{\\Box}_{{\\mathcal C}}$ is a generic family of effectful, extensional type theories with a forcing interpretation parameterized by modalities. This paper identifies a subclass of $\\text{TT}^{\\Box}_{{\\mathcal C}}$ theories that internally realizes continuity principles through stateful computations, such as reference cells. The principle of continuity is a seminal property that holds for a number of intuitionistic theories such as System T. Roughly speaking, it states that functions on real numbers only need approximations of these numbers to compute. Generally, continuity principles have been justified using semantical arguments, but it is known that the modulus of continuity of functions can be computed using effectful computations such as exceptions or reference cells. In this paper, the modulus of continuity of the functionals on the Baire space is directly computed using the stateful computations enabled internally in the theory.","sentences":["$\\text{TT}^{\\Box}_{{\\mathcal C}}$ is a generic family of effectful, extensional type theories with a forcing interpretation parameterized by modalities.","This paper identifies a subclass of $\\text{TT}^{\\Box}_{{\\mathcal C}}$ theories that internally realizes continuity principles through stateful computations, such as reference cells.","The principle of continuity is a seminal property that holds for a number of intuitionistic theories such as System T. Roughly speaking, it states that functions on real numbers only need approximations of these numbers to compute.","Generally, continuity principles have been justified using semantical arguments, but it is known that the modulus of continuity of functions can be computed using effectful computations such as exceptions or reference cells.","In this paper, the modulus of continuity of the functionals on the Baire space is directly computed using the stateful computations enabled internally in the theory."],"url":"http://arxiv.org/abs/2307.14168v1"}
{"created":"2023-07-26 12:44:30","title":"Towards Continuous Time Finite Horizon LQR Control in SE(3)","abstract":"The control of free-floating robots requires dealing with several challenges. The motion of such robots evolves on a continuous manifold described by the Special Euclidean Group of dimension 3, known as SE(3). Methods from finite horizon Linear Quadratic Regulators (LQR) control have gained recent traction in the robotics community. However, such approaches are inherently solving an unconstrained optimization problem and hence are unable to respect the manifold constraints imposed by the group structure of SE(3). This may lead to small errors, singularity problems and double cover issues depending on the choice of coordinates to model the floating base motion. In this paper, we propose the use of canonical exponential coordinates of SE(3) and the associated Exponential map along with its differentials to embed this structure in the theory of finite horizon LQR controllers.","sentences":["The control of free-floating robots requires dealing with several challenges.","The motion of such robots evolves on a continuous manifold described by the Special Euclidean Group of dimension 3, known as SE(3).","Methods from finite horizon Linear Quadratic Regulators (LQR) control have gained recent traction in the robotics community.","However, such approaches are inherently solving an unconstrained optimization problem and hence are unable to respect the manifold constraints imposed by the group structure of SE(3).","This may lead to small errors, singularity problems and double cover issues depending on the choice of coordinates to model the floating base motion.","In this paper, we propose the use of canonical exponential coordinates of SE(3) and the associated Exponential map along with its differentials to embed this structure in the theory of finite horizon LQR controllers."],"url":"http://arxiv.org/abs/2307.14164v1"}
{"created":"2023-07-26 12:40:54","title":"ICCPS: Impact discovery using causal inference for cyber attacks in CPSs","abstract":"We propose a new method to quantify the impact of cyber attacks in Cyber Physical Systems (CPSs). In particular, our method allows to identify the Design Parameter (DPs) affected due to a cyber attack launched on a different set of DPs in the same CPS. To achieve this, we adopt causal graphs to causally link DPs with each other and quantify the impact of one DP on another. Using SWaT, a real world testbed of a water treatment system, we demonstrate that causal graphs can be build in two ways: i) using domain knowledge of the control logic and the physical connectivity structure of the DPs, we call these causal domain graphs and ii) learning from operational data logs, we call these causal learnt graphs. We then compare these graphs when a same set of DPs is used. Our analysis shows a common set of edges between the causal domain graphs and the causal learnt graphs exists, which helps validate the causal learnt graphs. Additionally, we show that the learnt graphs can discover new causal relations, not initially considered in the domain graphs, that help significantly characterising the impact of the attack. We use causal domain graphs to estimate the parameters of the graphs, and the causal learnt graphs for causal inference. To learn the structure of the causal learnt graphs in all the six-stages of SWaT, we experiment with three learning algorithms: Peter Clarke (PC), Hill Climb (HC) search and Chow-Lie (CH). Finally, we demonstrate how causal graphs can be used to analyse the impact of cyber attacks by analysing nine well known cyber attacks on the SWaT test bed. We find that by using causal learnt graphs the DPs impacted by the attacks are correctly discovered with a probability greater than 0.9.","sentences":["We propose a new method to quantify the impact of cyber attacks in Cyber Physical Systems (CPSs).","In particular, our method allows to identify the Design Parameter (DPs) affected due to a cyber attack launched on a different set of DPs in the same CPS.","To achieve this, we adopt causal graphs to causally link DPs with each other and quantify the impact of one DP on another.","Using SWaT, a real world testbed of a water treatment system, we demonstrate that causal graphs can be build in two ways: i) using domain knowledge of the control logic and the physical connectivity structure of the DPs, we call these causal domain graphs and ii) learning from operational data logs, we call these causal learnt graphs.","We then compare these graphs when a same set of DPs is used.","Our analysis shows a common set of edges between the causal domain graphs and the causal learnt graphs exists, which helps validate the causal learnt graphs.","Additionally, we show that the learnt graphs can discover new causal relations, not initially considered in the domain graphs, that help significantly characterising the impact of the attack.","We use causal domain graphs to estimate the parameters of the graphs, and the causal learnt graphs for causal inference.","To learn the structure of the causal learnt graphs in all the six-stages of SWaT, we experiment with three learning algorithms: Peter Clarke (PC), Hill Climb (HC) search and Chow-Lie (CH).","Finally, we demonstrate how causal graphs can be used to analyse the impact of cyber attacks by analysing nine well known cyber attacks on the SWaT test bed.","We find that by using causal learnt graphs the DPs impacted by the attacks are correctly discovered with a probability greater than 0.9."],"url":"http://arxiv.org/abs/2307.14161v1"}
{"created":"2023-07-26 12:31:39","title":"Investigating the Impact of Variables on Handover Performance in 5G Ultra-Dense Networks","abstract":"The advent of 5G New Radio (NR) technology has revolutionized the landscape of wireless communication, offering various enhancements such as elevated system capacity, improved spectrum efficiency, and higher data transmission rates. To achieve these benefits, 5G has implemented the Ultra-Dense Network (UDN) architecture, characterized by the deployment of numerous small general Node B (gNB) units. While this approach boosts system capacity and frequency reuse, it also raises concerns such as increased signal interference, longer handover times, and higher handover failure rates. To address these challenges, the critical factor of Time to Trigger (TTT) in handover management must be accurately determined. Furthermore, the density of gNBs has a significant impact on handover performance. This study provides a comprehensive analysis of 5G handover management. Through the development and utilization of a downlink system-level simulator, the effects of various TTT values and gNB densities on 5G handover were evaluated, taking into consideration the movement of Traffic Users (TUs) with varying velocities. Simulation results showed that the handover performance can be optimized by adjusting the TTT under different gNB densities, providing valuable insights into the proper selection of TTT, UDN, and TU velocity to enhance 5G handover performance.","sentences":["The advent of 5G New Radio (NR) technology has revolutionized the landscape of wireless communication, offering various enhancements such as elevated system capacity, improved spectrum efficiency, and higher data transmission rates.","To achieve these benefits, 5G has implemented the Ultra-Dense Network (UDN) architecture, characterized by the deployment of numerous small general Node B (gNB) units.","While this approach boosts system capacity and frequency reuse, it also raises concerns such as increased signal interference, longer handover times, and higher handover failure rates.","To address these challenges, the critical factor of Time to Trigger (TTT) in handover management must be accurately determined.","Furthermore, the density of gNBs has a significant impact on handover performance.","This study provides a comprehensive analysis of 5G handover management.","Through the development and utilization of a downlink system-level simulator, the effects of various TTT values and gNB densities on 5G handover were evaluated, taking into consideration the movement of Traffic Users (TUs) with varying velocities.","Simulation results showed that the handover performance can be optimized by adjusting the TTT under different gNB densities, providing valuable insights into the proper selection of TTT, UDN, and TU velocity to enhance 5G handover performance."],"url":"http://arxiv.org/abs/2307.14152v1"}
{"created":"2023-07-26 12:29:58","title":"Learning Disentangled Discrete Representations","abstract":"Recent successes in image generation, model-based reinforcement learning, and text-to-image generation have demonstrated the empirical advantages of discrete latent representations, although the reasons behind their benefits remain unclear. We explore the relationship between discrete latent spaces and disentangled representations by replacing the standard Gaussian variational autoencoder (VAE) with a tailored categorical variational autoencoder. We show that the underlying grid structure of categorical distributions mitigates the problem of rotational invariance associated with multivariate Gaussian distributions, acting as an efficient inductive prior for disentangled representations. We provide both analytical and empirical findings that demonstrate the advantages of discrete VAEs for learning disentangled representations. Furthermore, we introduce the first unsupervised model selection strategy that favors disentangled representations.","sentences":["Recent successes in image generation, model-based reinforcement learning, and text-to-image generation have demonstrated the empirical advantages of discrete latent representations, although the reasons behind their benefits remain unclear.","We explore the relationship between discrete latent spaces and disentangled representations by replacing the standard Gaussian variational autoencoder (VAE) with a tailored categorical variational autoencoder.","We show that the underlying grid structure of categorical distributions mitigates the problem of rotational invariance associated with multivariate Gaussian distributions, acting as an efficient inductive prior for disentangled representations.","We provide both analytical and empirical findings that demonstrate the advantages of discrete VAEs for learning disentangled representations.","Furthermore, we introduce the first unsupervised model selection strategy that favors disentangled representations."],"url":"http://arxiv.org/abs/2307.14151v1"}
{"created":"2023-07-26 12:27:06","title":"Old and New Benchmarks for Relative Termination of String Rewrite Systems","abstract":"We provide a critical assessment of the current set of benchmarks for relative SRS termination in the Termination Problems Database (TPDB): most of the benchmarks in Waldmann_19 and ICFP_10_relative are, in fact, strictly terminating (i. e., terminating when non-strict rules are considered strict), so these benchmarks should be removed, or relabelled.   To fill this gap, we enumerate small relative string rewrite systems. At present, we have complete enumerations for a 2-letter alphabet up to size 11, and for a 3-letter alphabet up to size 8.   For some selected benchmarks, old and new, we discuss how to prove termination, automated or not.","sentences":["We provide a critical assessment of the current set of benchmarks for relative SRS termination in the Termination Problems Database (TPDB): most of the benchmarks in Waldmann_19 and ICFP_10_relative are, in fact, strictly terminating (i. e., terminating when non-strict rules are considered strict), so these benchmarks should be removed, or relabelled.   ","To fill this gap, we enumerate small relative string rewrite systems.","At present, we have complete enumerations for a 2-letter alphabet up to size 11, and for a 3-letter alphabet up to size 8.   ","For some selected benchmarks, old and new, we discuss how to prove termination, automated or not."],"url":"http://arxiv.org/abs/2307.14149v1"}
{"created":"2023-07-26 12:22:23","title":"MorphoLander: Reinforcement Learning Based Landing of a Group of Drones on the Adaptive Morphogenetic UAV","abstract":"This paper focuses on a novel robotic system MorphoLander representing heterogeneous swarm of drones for exploring rough terrain environments. The morphogenetic leader drone is capable of landing on uneven terrain, traversing it, and maintaining horizontal position to deploy smaller drones for extensive area exploration. After completing their tasks, these drones return and land back on the landing pads of MorphoGear. The reinforcement learning algorithm was developed for a precise landing of drones on the leader robot that either remains static during their mission or relocates to the new position. Several experiments were conducted to evaluate the performance of the developed landing algorithm under both even and uneven terrain conditions. The experiments revealed that the proposed system results in high landing accuracy of 0.5 cm when landing on the leader drone under even terrain conditions and 2.35 cm under uneven terrain conditions. MorphoLander has the potential to significantly enhance the efficiency of the industrial inspections, seismic surveys, and rescue missions in highly cluttered and unstructured environments.","sentences":["This paper focuses on a novel robotic system MorphoLander representing heterogeneous swarm of drones for exploring rough terrain environments.","The morphogenetic leader drone is capable of landing on uneven terrain, traversing it, and maintaining horizontal position to deploy smaller drones for extensive area exploration.","After completing their tasks, these drones return and land back on the landing pads of MorphoGear.","The reinforcement learning algorithm was developed for a precise landing of drones on the leader robot that either remains static during their mission or relocates to the new position.","Several experiments were conducted to evaluate the performance of the developed landing algorithm under both even and uneven terrain conditions.","The experiments revealed that the proposed system results in high landing accuracy of 0.5 cm when landing on the leader drone under even terrain conditions and 2.35 cm under uneven terrain conditions.","MorphoLander has the potential to significantly enhance the efficiency of the industrial inspections, seismic surveys, and rescue missions in highly cluttered and unstructured environments."],"url":"http://arxiv.org/abs/2307.14147v1"}
{"created":"2023-07-26 12:13:00","title":"LOIS: Looking Out of Instance Semantics for Visual Question Answering","abstract":"Visual question answering (VQA) has been intensively studied as a multimodal task that requires effort in bridging vision and language to infer answers correctly. Recent attempts have developed various attention-based modules for solving VQA tasks. However, the performance of model inference is largely bottlenecked by visual processing for semantics understanding. Most existing detection methods rely on bounding boxes, remaining a serious challenge for VQA models to understand the causal nexus of object semantics in images and correctly infer contextual information. To this end, we propose a finer model framework without bounding boxes in this work, termed Looking Out of Instance Semantics (LOIS) to tackle this important issue. LOIS enables more fine-grained feature descriptions to produce visual facts. Furthermore, to overcome the label ambiguity caused by instance masks, two types of relation attention modules: 1) intra-modality and 2) inter-modality, are devised to infer the correct answers from the different multi-view features. Specifically, we implement a mutual relation attention module to model sophisticated and deeper visual semantic relations between instance objects and background information. In addition, our proposed attention model can further analyze salient image regions by focusing on important word-related questions. Experimental results on four benchmark VQA datasets prove that our proposed method has favorable performance in improving visual reasoning capability.","sentences":["Visual question answering (VQA) has been intensively studied as a multimodal task that requires effort in bridging vision and language to infer answers correctly.","Recent attempts have developed various attention-based modules for solving VQA tasks.","However, the performance of model inference is largely bottlenecked by visual processing for semantics understanding.","Most existing detection methods rely on bounding boxes, remaining a serious challenge for VQA models to understand the causal nexus of object semantics in images and correctly infer contextual information.","To this end, we propose a finer model framework without bounding boxes in this work, termed Looking Out of Instance Semantics (LOIS) to tackle this important issue.","LOIS enables more fine-grained feature descriptions to produce visual facts.","Furthermore, to overcome the label ambiguity caused by instance masks, two types of relation attention modules: 1) intra-modality and 2) inter-modality, are devised to infer the correct answers from the different multi-view features.","Specifically, we implement a mutual relation attention module to model sophisticated and deeper visual semantic relations between instance objects and background information.","In addition, our proposed attention model can further analyze salient image regions by focusing on important word-related questions.","Experimental results on four benchmark VQA datasets prove that our proposed method has favorable performance in improving visual reasoning capability."],"url":"http://arxiv.org/abs/2307.14142v1"}
{"created":"2023-07-26 12:06:13","title":"Piecewise-Stationary Combinatorial Semi-Bandit with Causally Related Rewards","abstract":"We study the piecewise stationary combinatorial semi-bandit problem with causally related rewards. In our nonstationary environment, variations in the base arms' distributions, causal relationships between rewards, or both, change the reward generation process. In such an environment, an optimal decision-maker must follow both sources of change and adapt accordingly. The problem becomes aggravated in the combinatorial semi-bandit setting, where the decision-maker only observes the outcome of the selected bundle of arms. The core of our proposed policy is the Upper Confidence Bound (UCB) algorithm. We assume the agent relies on an adaptive approach to overcome the challenge. More specifically, it employs a change-point detector based on the Generalized Likelihood Ratio (GLR) test. Besides, we introduce the notion of group restart as a new alternative restarting strategy in the decision making process in structured environments. Finally, our algorithm integrates a mechanism to trace the variations of the underlying graph structure, which captures the causal relationships between the rewards in the bandit setting. Theoretically, we establish a regret upper bound that reflects the effects of the number of structural- and distribution changes on the performance. The outcome of our numerical experiments in real-world scenarios exhibits applicability and superior performance of our proposal compared to the state-of-the-art benchmarks.","sentences":["We study the piecewise stationary combinatorial semi-bandit problem with causally related rewards.","In our nonstationary environment, variations in the base arms' distributions, causal relationships between rewards, or both, change the reward generation process.","In such an environment, an optimal decision-maker must follow both sources of change and adapt accordingly.","The problem becomes aggravated in the combinatorial semi-bandit setting, where the decision-maker only observes the outcome of the selected bundle of arms.","The core of our proposed policy is the Upper Confidence Bound (UCB) algorithm.","We assume the agent relies on an adaptive approach to overcome the challenge.","More specifically, it employs a change-point detector based on the Generalized Likelihood Ratio (GLR) test.","Besides, we introduce the notion of group restart as a new alternative restarting strategy in the decision making process in structured environments.","Finally, our algorithm integrates a mechanism to trace the variations of the underlying graph structure, which captures the causal relationships between the rewards in the bandit setting.","Theoretically, we establish a regret upper bound that reflects the effects of the number of structural- and distribution changes on the performance.","The outcome of our numerical experiments in real-world scenarios exhibits applicability and superior performance of our proposal compared to the state-of-the-art benchmarks."],"url":"http://arxiv.org/abs/2307.14138v1"}
{"created":"2023-07-26 12:02:30","title":"Developing and Evaluating Tiny to Medium-Sized Turkish BERT Models","abstract":"This study introduces and evaluates tiny, mini, small, and medium-sized uncased Turkish BERT models, aiming to bridge the research gap in less-resourced languages. We trained these models on a diverse dataset encompassing over 75GB of text from multiple sources and tested them on several tasks, including mask prediction, sentiment analysis, news classification, and, zero-shot classification. Despite their smaller size, our models exhibited robust performance, including zero-shot task, while ensuring computational efficiency and faster execution times. Our findings provide valuable insights into the development and application of smaller language models, especially in the context of the Turkish language.","sentences":["This study introduces and evaluates tiny, mini, small, and medium-sized uncased Turkish BERT models, aiming to bridge the research gap in less-resourced languages.","We trained these models on a diverse dataset encompassing over 75GB of text from multiple sources and tested them on several tasks, including mask prediction, sentiment analysis, news classification, and, zero-shot classification.","Despite their smaller size, our models exhibited robust performance, including zero-shot task, while ensuring computational efficiency and faster execution times.","Our findings provide valuable insights into the development and application of smaller language models, especially in the context of the Turkish language."],"url":"http://arxiv.org/abs/2307.14134v1"}
{"created":"2023-07-26 11:59:14","title":"Say Goodbye to RNN-T Loss: A Novel CIF-based Transducer Architecture for Automatic Speech Recognition","abstract":"RNN-T models are widely used in ASR, which rely on the RNN-T loss to achieve length alignment between input audio and target sequence. However, the implementation complexity and the alignment-based optimization target of RNN-T loss lead to computational redundancy and a reduced role for predictor network, respectively. In this paper, we propose a novel model named CIF-Transducer (CIF-T) which incorporates the Continuous Integrate-and-Fire (CIF) mechanism with the RNN-T model to achieve efficient alignment. In this way, the RNN-T loss is abandoned, thus bringing a computational reduction and allowing the predictor network a more significant role. We also introduce Funnel-CIF, Context Blocks, Unified Gating and Bilinear Pooling joint network, and auxiliary training strategy to further improve performance. Experiments on the 178-hour AISHELL-1 and 10000-hour WenetSpeech datasets show that CIF-T achieves state-of-the-art results with lower computational overhead compared to RNN-T models.","sentences":["RNN-T models are widely used in ASR, which rely on the RNN-T loss to achieve length alignment between input audio and target sequence.","However, the implementation complexity and the alignment-based optimization target of RNN-T loss lead to computational redundancy and a reduced role for predictor network, respectively.","In this paper, we propose a novel model named CIF-Transducer (CIF-T) which incorporates the Continuous Integrate-and-Fire (CIF) mechanism with the RNN-T model to achieve efficient alignment.","In this way, the RNN-T loss is abandoned, thus bringing a computational reduction and allowing the predictor network a more significant role.","We also introduce Funnel-CIF, Context Blocks, Unified Gating and Bilinear Pooling joint network, and auxiliary training strategy to further improve performance.","Experiments on the 178-hour AISHELL-1 and 10000-hour WenetSpeech datasets show that CIF-T achieves state-of-the-art results with lower computational overhead compared to RNN-T models."],"url":"http://arxiv.org/abs/2307.14132v1"}
{"created":"2023-07-26 11:47:44","title":"Creative Birds: Self-Supervised Single-View 3D Style Transfer","abstract":"In this paper, we propose a novel method for single-view 3D style transfer that generates a unique 3D object with both shape and texture transfer. Our focus lies primarily on birds, a popular subject in 3D reconstruction, for which no existing single-view 3D transfer methods have been developed.The method we propose seeks to generate a 3D mesh shape and texture of a bird from two single-view images. To achieve this, we introduce a novel shape transfer generator that comprises a dual residual gated network (DRGNet), and a multi-layer perceptron (MLP). DRGNet extracts the features of source and target images using a shared coordinate gate unit, while the MLP generates spatial coordinates for building a 3D mesh. We also introduce a semantic UV texture transfer module that implements textural style transfer using semantic UV segmentation, which ensures consistency in the semantic meaning of the transferred regions. This module can be widely adapted to many existing approaches. Finally, our method constructs a novel 3D bird using a differentiable renderer. Experimental results on the CUB dataset verify that our method achieves state-of-the-art performance on the single-view 3D style transfer task. Code is available in https://github.com/wrk226/2D-to-3D-Evolution-Transfer.","sentences":["In this paper, we propose a novel method for single-view 3D style transfer that generates a unique 3D object with both shape and texture transfer.","Our focus lies primarily on birds, a popular subject in 3D reconstruction, for which no existing single-view 3D transfer methods have been developed.","The method we propose seeks to generate a 3D mesh shape and texture of a bird from two single-view images.","To achieve this, we introduce a novel shape transfer generator that comprises a dual residual gated network (DRGNet), and a multi-layer perceptron (MLP).","DRGNet extracts the features of source and target images using a shared coordinate gate unit, while the MLP generates spatial coordinates for building a 3D mesh.","We also introduce a semantic UV texture transfer module that implements textural style transfer using semantic UV segmentation, which ensures consistency in the semantic meaning of the transferred regions.","This module can be widely adapted to many existing approaches.","Finally, our method constructs a novel 3D bird using a differentiable renderer.","Experimental results on the CUB dataset verify that our method achieves state-of-the-art performance on the single-view 3D style transfer task.","Code is available in https://github.com/wrk226/2D-to-3D-Evolution-Transfer."],"url":"http://arxiv.org/abs/2307.14127v1"}
{"created":"2023-07-26 11:45:39","title":"Multi-modal Learning with Missing Modality via Shared-Specific Feature Modelling","abstract":"The missing modality issue is critical but non-trivial to be solved by multi-modal models. Current methods aiming to handle the missing modality problem in multi-modal tasks, either deal with missing modalities only during evaluation or train separate models to handle specific missing modality settings. In addition, these models are designed for specific tasks, so for example, classification models are not easily adapted to segmentation tasks and vice versa. In this paper, we propose the Shared-Specific Feature Modelling (ShaSpec) method that is considerably simpler and more effective than competing approaches that address the issues above. ShaSpec is designed to take advantage of all available input modalities during training and evaluation by learning shared and specific features to better represent the input data. This is achieved from a strategy that relies on auxiliary tasks based on distribution alignment and domain classification, in addition to a residual feature fusion procedure. Also, the design simplicity of ShaSpec enables its easy adaptation to multiple tasks, such as classification and segmentation. Experiments are conducted on both medical image segmentation and computer vision classification, with results indicating that ShaSpec outperforms competing methods by a large margin. For instance, on BraTS2018, ShaSpec improves the SOTA by more than 3% for enhancing tumour, 5% for tumour core and 3% for whole tumour.","sentences":["The missing modality issue is critical but non-trivial to be solved by multi-modal models.","Current methods aiming to handle the missing modality problem in multi-modal tasks, either deal with missing modalities only during evaluation or train separate models to handle specific missing modality settings.","In addition, these models are designed for specific tasks, so for example, classification models are not easily adapted to segmentation tasks and vice versa.","In this paper, we propose the Shared-Specific Feature Modelling (ShaSpec) method that is considerably simpler and more effective than competing approaches that address the issues above.","ShaSpec is designed to take advantage of all available input modalities during training and evaluation by learning shared and specific features to better represent the input data.","This is achieved from a strategy that relies on auxiliary tasks based on distribution alignment and domain classification, in addition to a residual feature fusion procedure.","Also, the design simplicity of ShaSpec enables its easy adaptation to multiple tasks, such as classification and segmentation.","Experiments are conducted on both medical image segmentation and computer vision classification, with results indicating that ShaSpec outperforms competing methods by a large margin.","For instance, on BraTS2018, ShaSpec improves the SOTA by more than 3% for enhancing tumour, 5% for tumour core and 3% for whole tumour."],"url":"http://arxiv.org/abs/2307.14126v1"}
{"created":"2023-07-26 11:45:16","title":"Multi-IMU Proprioceptive State Estimator for Humanoid Robots","abstract":"Algorithms for state estimation of humanoid robots usually assume that the feet remain flat and in a constant position while in contact with the ground. However, this hypothesis is easily violated while walking, especially for human-like gaits with heel-toe motion. This reduces the time during which the contact assumption can be used, or requires higher variances to account for errors. In this paper, we present a novel state estimator based on the extended Kalman filter that can properly handle any contact configuration. We consider multiple inertial measurement units (IMUs) distributed throughout the robot's structure, including on both feet, which are used to track multiple bodies of the robot. This multi-IMU instrumentation setup also has the advantage of allowing the deformations in the robot's structure to be estimated, improving the kinematic model used in the filter. The proposed approach is validated experimentally on the exoskeleton Atalante and is shown to present low drift, performing better than similar single-IMU filters. The obtained trajectory estimates are accurate enough to construct elevation maps that have little distortion with respect to the ground truth.","sentences":["Algorithms for state estimation of humanoid robots usually assume that the feet remain flat and in a constant position while in contact with the ground.","However, this hypothesis is easily violated while walking, especially for human-like gaits with heel-toe motion.","This reduces the time during which the contact assumption can be used, or requires higher variances to account for errors.","In this paper, we present a novel state estimator based on the extended Kalman filter that can properly handle any contact configuration.","We consider multiple inertial measurement units (IMUs) distributed throughout the robot's structure, including on both feet, which are used to track multiple bodies of the robot.","This multi-IMU instrumentation setup also has the advantage of allowing the deformations in the robot's structure to be estimated, improving the kinematic model used in the filter.","The proposed approach is validated experimentally on the exoskeleton Atalante and is shown to present low drift, performing better than similar single-IMU filters.","The obtained trajectory estimates are accurate enough to construct elevation maps that have little distortion with respect to the ground truth."],"url":"http://arxiv.org/abs/2307.14125v1"}
{"created":"2023-07-26 11:44:44","title":"Memory-Efficient Graph Convolutional Networks for Object Classification and Detection with Event Cameras","abstract":"Recent advances in event camera research emphasize processing data in its original sparse form, which allows the use of its unique features such as high temporal resolution, high dynamic range, low latency, and resistance to image blur. One promising approach for analyzing event data is through graph convolutional networks (GCNs). However, current research in this domain primarily focuses on optimizing computational costs, neglecting the associated memory costs. In this paper, we consider both factors together in order to achieve satisfying results and relatively low model complexity. For this purpose, we performed a comparative analysis of different graph convolution operations, considering factors such as execution time, the number of trainable model parameters, data format requirements, and training outcomes. Our results show a 450-fold reduction in the number of parameters for the feature extraction module and a 4.5-fold reduction in the size of the data representation while maintaining a classification accuracy of 52.3%, which is 6.3% higher compared to the operation used in state-of-the-art approaches. To further evaluate performance, we implemented the object detection architecture and evaluated its performance on the N-Caltech101 dataset. The results showed an accuracy of 53.7 % mAP@0.5 and reached an execution rate of 82 graphs per second.","sentences":["Recent advances in event camera research emphasize processing data in its original sparse form, which allows the use of its unique features such as high temporal resolution, high dynamic range, low latency, and resistance to image blur.","One promising approach for analyzing event data is through graph convolutional networks (GCNs).","However, current research in this domain primarily focuses on optimizing computational costs, neglecting the associated memory costs.","In this paper, we consider both factors together in order to achieve satisfying results and relatively low model complexity.","For this purpose, we performed a comparative analysis of different graph convolution operations, considering factors such as execution time, the number of trainable model parameters, data format requirements, and training outcomes.","Our results show a 450-fold reduction in the number of parameters for the feature extraction module and a 4.5-fold reduction in the size of the data representation while maintaining a classification accuracy of 52.3%, which is 6.3% higher compared to the operation used in state-of-the-art approaches.","To further evaluate performance, we implemented the object detection architecture and evaluated its performance on the N-Caltech101 dataset.","The results showed an accuracy of 53.7 % mAP@0.5 and reached an execution rate of 82 graphs per second."],"url":"http://arxiv.org/abs/2307.14124v1"}
{"created":"2023-07-26 11:38:45","title":"A semantics-driven methodology for high-quality image annotation","abstract":"Recent work in Machine Learning and Computer Vision has highlighted the presence of various types of systematic flaws inside ground truth object recognition benchmark datasets. Our basic tenet is that these flaws are rooted in the many-to-many mappings which exist between the visual information encoded in images and the intended semantics of the labels annotating them. The net consequence is that the current annotation process is largely under-specified, thus leaving too much freedom to the subjective judgment of annotators. In this paper, we propose vTelos, an integrated Natural Language Processing, Knowledge Representation, and Computer Vision methodology whose main goal is to make explicit the (otherwise implicit) intended annotation semantics, thus minimizing the number and role of subjective choices. A key element of vTelos is the exploitation of the WordNet lexico-semantic hierarchy as the main means for providing the meaning of natural language labels and, as a consequence, for driving the annotation of images based on the objects and the visual properties they depict. The methodology is validated on images populating a subset of the ImageNet hierarchy.","sentences":["Recent work in Machine Learning and Computer Vision has highlighted the presence of various types of systematic flaws inside ground truth object recognition benchmark datasets.","Our basic tenet is that these flaws are rooted in the many-to-many mappings which exist between the visual information encoded in images and the intended semantics of the labels annotating them.","The net consequence is that the current annotation process is largely under-specified, thus leaving too much freedom to the subjective judgment of annotators.","In this paper, we propose vTelos, an integrated Natural Language Processing, Knowledge Representation, and Computer Vision methodology whose main goal is to make explicit the (otherwise implicit) intended annotation semantics, thus minimizing the number and role of subjective choices.","A key element of vTelos is the exploitation of the WordNet lexico-semantic hierarchy as the main means for providing the meaning of natural language labels and, as a consequence, for driving the annotation of images based on the objects and the visual properties they depict.","The methodology is validated on images populating a subset of the ImageNet hierarchy."],"url":"http://arxiv.org/abs/2307.14119v1"}
{"created":"2023-07-26 11:34:53","title":"Leveraging Implicit Feedback from Deployment Data in Dialogue","abstract":"We study improving social conversational agents by learning from natural dialogue between users and a deployed model, without extra annotations. To implicitly measure the quality of a machine-generated utterance, we leverage signals like user response length, sentiment and reaction of the future human utterances in the collected dialogue episodes. Our experiments use the publicly released deployment data from BlenderBot (Xu et al., 2023). Human evaluation indicates improvements in our new models over baseline responses; however, we find that some proxy signals can lead to more generations with undesirable properties as well. For example, optimizing for conversation length can lead to more controversial or unfriendly generations compared to the baseline, whereas optimizing for positive sentiment or reaction can decrease these behaviors.","sentences":["We study improving social conversational agents by learning from natural dialogue between users and a deployed model, without extra annotations.","To implicitly measure the quality of a machine-generated utterance, we leverage signals like user response length, sentiment and reaction of the future human utterances in the collected dialogue episodes.","Our experiments use the publicly released deployment data from BlenderBot (Xu et al., 2023).","Human evaluation indicates improvements in our new models over baseline responses; however, we find that some proxy signals can lead to more generations with undesirable properties as well.","For example, optimizing for conversation length can lead to more controversial or unfriendly generations compared to the baseline, whereas optimizing for positive sentiment or reaction can decrease these behaviors."],"url":"http://arxiv.org/abs/2307.14117v1"}
{"created":"2023-07-26 11:19:33","title":"Risk Assessment Graphs: Utilizing Attack Graphs for Risk Assessment","abstract":"Risk assessment plays a crucial role in ensuring the security and resilience of modern computer systems. Existing methods for conducting risk assessments often suffer from tedious and time-consuming processes, making it challenging to maintain a comprehensive overview of potential security issues. In this paper, we propose a novel approach that leverages attack graphs to enhance the efficiency and effectiveness of risk assessment. Attack graphs visually represent the various attack paths that adversaries can exploit within a system, enabling a systematic exploration of potential vulnerabilities. By extending attack graphs with capabilities to include countermeasures and consequences, they can be leveraged to constitute the complete risk assessment process. Our method offers a more streamlined and comprehensive analysis of system vulnerabilities, where system changes, or environment changes can easily be adapted and the issues exposing the highest risk can easily be identified. We demonstrate the effectiveness of our approach through a case study, as well as the applicability by combining existing risk assessment standards with our method. Our work aims to bridge the gap between risk assessment practices and evolving threat landscapes, offering an improved methodology for managing and mitigating risks in modern computer systems.","sentences":["Risk assessment plays a crucial role in ensuring the security and resilience of modern computer systems.","Existing methods for conducting risk assessments often suffer from tedious and time-consuming processes, making it challenging to maintain a comprehensive overview of potential security issues.","In this paper, we propose a novel approach that leverages attack graphs to enhance the efficiency and effectiveness of risk assessment.","Attack graphs visually represent the various attack paths that adversaries can exploit within a system, enabling a systematic exploration of potential vulnerabilities.","By extending attack graphs with capabilities to include countermeasures and consequences, they can be leveraged to constitute the complete risk assessment process.","Our method offers a more streamlined and comprehensive analysis of system vulnerabilities, where system changes, or environment changes can easily be adapted and the issues exposing the highest risk can easily be identified.","We demonstrate the effectiveness of our approach through a case study, as well as the applicability by combining existing risk assessment standards with our method.","Our work aims to bridge the gap between risk assessment practices and evolving threat landscapes, offering an improved methodology for managing and mitigating risks in modern computer systems."],"url":"http://arxiv.org/abs/2307.14114v1"}
{"created":"2023-07-26 11:14:36","title":"Periocular biometrics: databases, algorithms and directions","abstract":"Periocular biometrics has been established as an independent modality due to concerns on the performance of iris or face systems in uncontrolled conditions. Periocular refers to the facial region in the eye vicinity, including eyelids, lashes and eyebrows. It is available over a wide range of acquisition distances, representing a trade-off between the whole face (which can be occluded at close distances) and the iris texture (which do not have enough resolution at long distances). Since the periocular region appears in face or iris images, it can be used also in conjunction with these modalities. Features extracted from the periocular region have been also used successfully for gender classification and ethnicity classification, and to study the impact of gender transformation or plastic surgery in the recognition performance. This paper presents a review of the state of the art in periocular biometric research, providing an insight of the most relevant issues and giving a thorough coverage of the existing literature. Future research trends are also briefly discussed.","sentences":["Periocular biometrics has been established as an independent modality due to concerns on the performance of iris or face systems in uncontrolled conditions.","Periocular refers to the facial region in the eye vicinity, including eyelids, lashes and eyebrows.","It is available over a wide range of acquisition distances, representing a trade-off between the whole face (which can be occluded at close distances) and the iris texture (which do not have enough resolution at long distances).","Since the periocular region appears in face or iris images, it can be used also in conjunction with these modalities.","Features extracted from the periocular region have been also used successfully for gender classification and ethnicity classification, and to study the impact of gender transformation or plastic surgery in the recognition performance.","This paper presents a review of the state of the art in periocular biometric research, providing an insight of the most relevant issues and giving a thorough coverage of the existing literature.","Future research trends are also briefly discussed."],"url":"http://arxiv.org/abs/2307.14111v1"}
{"created":"2023-07-26 11:13:14","title":"Reinforced Potential Field for Multi-Robot Motion Planning in Cluttered Environments","abstract":"Motion planning is challenging for multiple robots in cluttered environments without communication, especially in view of real-time efficiency, motion safety, distributed computation, and trajectory optimality, etc. In this paper, a reinforced potential field method is developed for distributed multi-robot motion planning, which is a synthesized design of reinforcement learning and artificial potential fields. An observation embedding with a self-attention mechanism is presented to model the robot-robot and robot-environment interactions. A soft wall-following rule is developed to improve the trajectory smoothness. Our method belongs to reactive planning, but environment properties are implicitly encoded. The total amount of robots in our method can be scaled up to any number. The performance improvement over a vanilla APF and RL method has been demonstrated via numerical simulations. Experiments are also performed using quadrotors to further illustrate the competence of our method.","sentences":["Motion planning is challenging for multiple robots in cluttered environments without communication, especially in view of real-time efficiency, motion safety, distributed computation, and trajectory optimality, etc.","In this paper, a reinforced potential field method is developed for distributed multi-robot motion planning, which is a synthesized design of reinforcement learning and artificial potential fields.","An observation embedding with a self-attention mechanism is presented to model the robot-robot and robot-environment interactions.","A soft wall-following rule is developed to improve the trajectory smoothness.","Our method belongs to reactive planning, but environment properties are implicitly encoded.","The total amount of robots in our method can be scaled up to any number.","The performance improvement over a vanilla APF and RL method has been demonstrated via numerical simulations.","Experiments are also performed using quadrotors to further illustrate the competence of our method."],"url":"http://arxiv.org/abs/2307.14110v1"}
{"created":"2023-07-26 11:12:55","title":"GraphRNN Revisited: An Ablation Study and Extensions for Directed Acyclic Graphs","abstract":"GraphRNN is a deep learning-based architecture proposed by You et al. for learning generative models for graphs. We replicate the results of You et al. using a reproduced implementation of the GraphRNN architecture and evaluate this against baseline models using new metrics. Through an ablation study, we find that the BFS traversal suggested by You et al. to collapse representations of isomorphic graphs contributes significantly to model performance. Additionally, we extend GraphRNN to generate directed acyclic graphs by replacing the BFS traversal with a topological sort. We demonstrate that this method improves significantly over a directed-multiclass variant of GraphRNN on a real-world dataset.","sentences":["GraphRNN is a deep learning-based architecture proposed by You et al. for learning generative models for graphs.","We replicate the results of You et al.","using a reproduced implementation of the GraphRNN architecture and evaluate this against baseline models using new metrics.","Through an ablation study, we find that the BFS traversal suggested by You et al. to collapse representations of isomorphic graphs contributes significantly to model performance.","Additionally, we extend GraphRNN to generate directed acyclic graphs by replacing the BFS traversal with a topological sort.","We demonstrate that this method improves significantly over a directed-multiclass variant of GraphRNN on a real-world dataset."],"url":"http://arxiv.org/abs/2307.14109v1"}
{"created":"2023-07-26 11:10:04","title":"Decoding ChatGPT: A Taxonomy of Existing Research, Current Challenges, and Possible Future Directions","abstract":"Chat Generative Pre-trained Transformer (ChatGPT) has gained significant interest and attention since its launch in November 2022. It has shown impressive performance in various domains, including passing exams and creative writing. However, challenges and concerns related to biases and trust persist. In this work, we present a comprehensive review of over 100 Scopus-indexed publications on ChatGPT, aiming to provide a taxonomy of ChatGPT research and explore its applications. We critically analyze the existing literature, identifying common approaches employed in the studies. Additionally, we investigate diverse application areas where ChatGPT has found utility, such as healthcare, marketing and financial services, software engineering, academic and scientific writing, research and education, environmental science, and natural language processing. Through examining these applications, we gain valuable insights into the potential of ChatGPT in addressing real-world challenges. We also discuss crucial issues related to ChatGPT, including biases and trustworthiness, emphasizing the need for further research and development in these areas. Furthermore, we identify potential future directions for ChatGPT research, proposing solutions to current challenges and speculating on expected advancements. By fully leveraging the capabilities of ChatGPT, we can unlock its potential across various domains, leading to advancements in conversational AI and transformative impacts in society.","sentences":["Chat Generative Pre-trained Transformer (ChatGPT) has gained significant interest and attention since its launch in November 2022.","It has shown impressive performance in various domains, including passing exams and creative writing.","However, challenges and concerns related to biases and trust persist.","In this work, we present a comprehensive review of over 100 Scopus-indexed publications on ChatGPT, aiming to provide a taxonomy of ChatGPT research and explore its applications.","We critically analyze the existing literature, identifying common approaches employed in the studies.","Additionally, we investigate diverse application areas where ChatGPT has found utility, such as healthcare, marketing and financial services, software engineering, academic and scientific writing, research and education, environmental science, and natural language processing.","Through examining these applications, we gain valuable insights into the potential of ChatGPT in addressing real-world challenges.","We also discuss crucial issues related to ChatGPT, including biases and trustworthiness, emphasizing the need for further research and development in these areas.","Furthermore, we identify potential future directions for ChatGPT research, proposing solutions to current challenges and speculating on expected advancements.","By fully leveraging the capabilities of ChatGPT, we can unlock its potential across various domains, leading to advancements in conversational AI and transformative impacts in society."],"url":"http://arxiv.org/abs/2307.14107v1"}
{"created":"2023-07-26 11:06:43","title":"Active Robot Vision for Distant Object Change Detection: A Lightweight Training Simulator Inspired by Multi-Armed Bandits","abstract":"In ground-view object change detection, the recently emerging map-less navigation has great potential as a means of navigating a robot to distantly detected objects and identifying their changing states (appear/disappear/no-change) with high resolution imagery. However, the brute-force naive action strategy of navigating to every distant object requires huge sense/plan/action costs proportional to the number of objects. In this work, we study this new problem of ``Which distant objects should be prioritized for map-less navigation?\" and in order to speed up the R{\\&}D cycle, propose a highly-simplified approach that is easy to implement and easy to extend. In our approach, a new layer called map-based navigation is added on top of the map-less navigation, which constitutes a hierarchical planner. First, a dataset consisting of $N$ view sequences is acquired by a real robot via map-less navigation. Then, an environment simulator was built to simulate a simple action planning problem: ``Which view sequence should the robot select next?\". Then, a solver was built inspired by the analogy to the multi-armed bandit problem: ``Which arm should the player select next?\". Finally, the effectiveness of the proposed framework was verified using the semantically non-trivial scenario ``sofa as bookshelf\".","sentences":["In ground-view object change detection, the recently emerging map-less navigation has great potential as a means of navigating a robot to distantly detected objects and identifying their changing states (appear/disappear/no-change) with high resolution imagery.","However, the brute-force naive action strategy of navigating to every distant object requires huge sense/plan/action costs proportional to the number of objects.","In this work, we study this new problem of ``Which distant objects should be prioritized for map-less navigation?\" and in order to speed up the R{\\&}D cycle, propose a highly-simplified approach that is easy to implement and easy to extend.","In our approach, a new layer called map-based navigation is added on top of the map-less navigation, which constitutes a hierarchical planner.","First, a dataset consisting of $N$ view sequences is acquired by a real robot via map-less navigation.","Then, an environment simulator was built to simulate a simple action planning problem: ``Which view sequence should the robot select next?\".","Then, a solver was built inspired by the analogy to the multi-armed bandit problem: ``Which arm should the player select next?\".","Finally, the effectiveness of the proposed framework was verified using the semantically non-trivial scenario ``sofa as bookshelf\"."],"url":"http://arxiv.org/abs/2307.14105v1"}
{"created":"2023-07-26 10:42:35","title":"On Singleton Self-Loop Removal for Termination of LCTRSs with Bit-Vector Arithmetic","abstract":"As for term rewrite systems, the dependency pair (DP, for short) framework with several kinds of DP processors is useful for proving termination of logically constrained term rewrite systems (LCTRSs, for short). However, the polynomial interpretation processor is not so effective against LCTRSs with bit-vector arithmetic (BV-LCTRSs, for short). In this paper, we propose a novel DP processor for BV-LCTRSs to solve a singleton DP problem consisting of a dependency pair forming a self-loop. The processor is based on an acyclic directed graph such that the nodes are bit-vectors and any dependency chain of the problem is projected to a path of the graph. We show a sufficient condition for the existence of such an acyclic graph, and simplify it for a specific case.","sentences":["As for term rewrite systems, the dependency pair (DP, for short) framework with several kinds of DP processors is useful for proving termination of logically constrained term rewrite systems (LCTRSs, for short).","However, the polynomial interpretation processor is not so effective against LCTRSs with bit-vector arithmetic (BV-LCTRSs, for short).","In this paper, we propose a novel DP processor for BV-LCTRSs to solve a singleton DP problem consisting of a dependency pair forming a self-loop.","The processor is based on an acyclic directed graph such that the nodes are bit-vectors and any dependency chain of the problem is projected to a path of the graph.","We show a sufficient condition for the existence of such an acyclic graph, and simplify it for a specific case."],"url":"http://arxiv.org/abs/2307.14094v1"}
{"created":"2023-07-26 10:31:43","title":"Phase Transitions of Diversity in Stochastic Block Model Dynamics","abstract":"This paper proposes a stochastic block model with dynamics where the population grows using preferential attachment. Nodes with higher weighted degree are more likely to recruit new nodes, and nodes always recruit nodes from their own community. This model can capture how communities grow or shrink based on their collaborations with other nodes in the network, where an edge represents collaboration on a project.   Focusing on the case of two communities, we derive a deterministic approximation to the dynamics and characterize the phase transitions for diversity, i.e. the parameter regimes in which either one of the communities dies out or the two communities reach parity over time.   In particular, we find that the minority may vanish when the probability of cross-community edges is low, even when cross-community projects are more valuable than projects with collaborators from the same community.","sentences":["This paper proposes a stochastic block model with dynamics where the population grows using preferential attachment.","Nodes with higher weighted degree are more likely to recruit new nodes, and nodes always recruit nodes from their own community.","This model can capture how communities grow or shrink based on their collaborations with other nodes in the network, where an edge represents collaboration on a project.   ","Focusing on the case of two communities, we derive a deterministic approximation to the dynamics and characterize the phase transitions for diversity, i.e. the parameter regimes in which either one of the communities dies out or the two communities reach parity over time.   ","In particular, we find that the minority may vanish when the probability of cross-community edges is low, even when cross-community projects are more valuable than projects with collaborators from the same community."],"url":"http://arxiv.org/abs/2307.13713v1"}
{"created":"2023-07-26 10:24:17","title":"Actions Speak What You Want: Provably Sample-Efficient Reinforcement Learning of the Quantal Stackelberg Equilibrium from Strategic Feedbacks","abstract":"We study reinforcement learning (RL) for learning a Quantal Stackelberg Equilibrium (QSE) in an episodic Markov game with a leader-follower structure. In specific, at the outset of the game, the leader announces her policy to the follower and commits to it. The follower observes the leader's policy and, in turn, adopts a quantal response policy by solving an entropy-regularized policy optimization problem induced by leader's policy. The goal of the leader is to find her optimal policy, which yields the optimal expected total return, by interacting with the follower and learning from data. A key challenge of this problem is that the leader cannot observe the follower's reward, and needs to infer the follower's quantal response model from his actions against leader's policies. We propose sample-efficient algorithms for both the online and offline settings, in the context of function approximation. Our algorithms are based on (i) learning the quantal response model via maximum likelihood estimation and (ii) model-free or model-based RL for solving the leader's decision making problem, and we show that they achieve sublinear regret upper bounds. Moreover, we quantify the uncertainty of these estimators and leverage the uncertainty to implement optimistic and pessimistic algorithms for online and offline settings. Besides, when specialized to the linear and myopic setting, our algorithms are also computationally efficient. Our theoretical analysis features a novel performance-difference lemma which incorporates the error of quantal response model, which might be of independent interest.","sentences":["We study reinforcement learning (RL) for learning a Quantal Stackelberg Equilibrium (QSE) in an episodic Markov game with a leader-follower structure.","In specific, at the outset of the game, the leader announces her policy to the follower and commits to it.","The follower observes the leader's policy and, in turn, adopts a quantal response policy by solving an entropy-regularized policy optimization problem induced by leader's policy.","The goal of the leader is to find her optimal policy, which yields the optimal expected total return, by interacting with the follower and learning from data.","A key challenge of this problem is that the leader cannot observe the follower's reward, and needs to infer the follower's quantal response model from his actions against leader's policies.","We propose sample-efficient algorithms for both the online and offline settings, in the context of function approximation.","Our algorithms are based on (i) learning the quantal response model via maximum likelihood estimation and (ii) model-free or model-based RL for solving the leader's decision making problem, and we show that they achieve sublinear regret upper bounds.","Moreover, we quantify the uncertainty of these estimators and leverage the uncertainty to implement optimistic and pessimistic algorithms for online and offline settings.","Besides, when specialized to the linear and myopic setting, our algorithms are also computationally efficient.","Our theoretical analysis features a novel performance-difference lemma which incorporates the error of quantal response model, which might be of independent interest."],"url":"http://arxiv.org/abs/2307.14085v1"}
{"created":"2023-07-26 09:54:47","title":"Gleam: An RDMA-accelerated Multicast Protocol for Datacenter Networks","abstract":"RDMA has been widely adopted for high-speed datacenter networks. However, native RDMA merely supports one-to-one reliable connection, which mismatches various applications with group communication patterns (e.g., one-to-many). While there are some multicast enhancements to address it, they all fail to simultaneously achieve optimal multicast forwarding and fully unleash the distinguished RDMA capabilities.   In this paper, we present Gleam, an RDMA-accelerated multicast protocol that simultaneously supports optimal multicast forwarding, efficient utilization of the prominent RDMA capabilities, and compatibility with the commodity RNICs. At its core, Gleam re-purposes the existing RDMA RC logic with careful switch coordination as an efficient multicast transport. Gleam performs the one-to-many connection maintenance and many-to-one feedback aggregation, based on an extended multicast forwarding table structure, to achieve integration between standard RC logic and in-fabric multicast. We implement a fully functional Gleam prototype. With extensive testbed experiments and simulations, we demonstrate Gleam's significant improvement in accelerating multicast communication of realistic applications. For instance, Gleam achieves 2.9X lower communication time of an HPC benchmark application and 2.7X higher data replication throughput.","sentences":["RDMA has been widely adopted for high-speed datacenter networks.","However, native RDMA merely supports one-to-one reliable connection, which mismatches various applications with group communication patterns (e.g., one-to-many).","While there are some multicast enhancements to address it, they all fail to simultaneously achieve optimal multicast forwarding and fully unleash the distinguished RDMA capabilities.   ","In this paper, we present Gleam, an RDMA-accelerated multicast protocol that simultaneously supports optimal multicast forwarding, efficient utilization of the prominent RDMA capabilities, and compatibility with the commodity RNICs.","At its core, Gleam re-purposes the existing RDMA RC logic with careful switch coordination as an efficient multicast transport.","Gleam performs the one-to-many connection maintenance and many-to-one feedback aggregation, based on an extended multicast forwarding table structure, to achieve integration between standard RC logic and in-fabric multicast.","We implement a fully functional Gleam prototype.","With extensive testbed experiments and simulations, we demonstrate Gleam's significant improvement in accelerating multicast communication of realistic applications.","For instance, Gleam achieves 2.9X lower communication time of an HPC benchmark application and 2.7X higher data replication throughput."],"url":"http://arxiv.org/abs/2307.14074v1"}
{"created":"2023-07-26 09:50:44","title":"VideoControlNet: A Motion-Guided Video-to-Video Translation Framework by Using Diffusion Model with ControlNet","abstract":"Recently, diffusion models like StableDiffusion have achieved impressive image generation results. However, the generation process of such diffusion models is uncontrollable, which makes it hard to generate videos with continuous and consistent content. In this work, by using the diffusion model with ControlNet, we proposed a new motion-guided video-to-video translation framework called VideoControlNet to generate various videos based on the given prompts and the condition from the input video. Inspired by the video codecs that use motion information for reducing temporal redundancy, our framework uses motion information to prevent the regeneration of the redundant areas for content consistency. Specifically, we generate the first frame (i.e., the I-frame) by using the diffusion model with ControlNet. Then we generate other key frames (i.e., the P-frame) based on the previous I/P-frame by using our newly proposed motion-guided P-frame generation (MgPG) method, in which the P-frames are generated based on the motion information and the occlusion areas are inpainted by using the diffusion model. Finally, the rest frames (i.e., the B-frame) are generated by using our motion-guided B-frame interpolation (MgBI) module. Our experiments demonstrate that our proposed VideoControlNet inherits the generation capability of the pre-trained large diffusion model and extends the image diffusion model to the video diffusion model by using motion information. More results are provided at our project page.","sentences":["Recently, diffusion models like StableDiffusion have achieved impressive image generation results.","However, the generation process of such diffusion models is uncontrollable, which makes it hard to generate videos with continuous and consistent content.","In this work, by using the diffusion model with ControlNet, we proposed a new motion-guided video-to-video translation framework called VideoControlNet to generate various videos based on the given prompts and the condition from the input video.","Inspired by the video codecs that use motion information for reducing temporal redundancy, our framework uses motion information to prevent the regeneration of the redundant areas for content consistency.","Specifically, we generate the first frame (i.e., the I-frame) by using the diffusion model with ControlNet.","Then we generate other key frames (i.e., the P-frame) based on the previous I/P-frame by using our newly proposed motion-guided P-frame generation (MgPG) method, in which the P-frames are generated based on the motion information and the occlusion areas are inpainted by using the diffusion model.","Finally, the rest frames (i.e., the B-frame) are generated by using our motion-guided B-frame interpolation (MgBI) module.","Our experiments demonstrate that our proposed VideoControlNet inherits the generation capability of the pre-trained large diffusion model and extends the image diffusion model to the video diffusion model by using motion information.","More results are provided at our project page."],"url":"http://arxiv.org/abs/2307.14073v1"}
{"created":"2023-07-26 09:47:37","title":"Uncertainty Guided Adaptive Warping for Robust and Efficient Stereo Matching","abstract":"Correlation based stereo matching has achieved outstanding performance, which pursues cost volume between two feature maps. Unfortunately, current methods with a fixed model do not work uniformly well across various datasets, greatly limiting their real-world applicability. To tackle this issue, this paper proposes a new perspective to dynamically calculate correlation for robust stereo matching. A novel Uncertainty Guided Adaptive Correlation (UGAC) module is introduced to robustly adapt the same model for different scenarios. Specifically, a variance-based uncertainty estimation is employed to adaptively adjust the sampling area during warping operation. Additionally, we improve the traditional non-parametric warping with learnable parameters, such that the position-specific weights can be learned. We show that by empowering the recurrent network with the UGAC module, stereo matching can be exploited more robustly and effectively. Extensive experiments demonstrate that our method achieves state-of-the-art performance over the ETH3D, KITTI, and Middlebury datasets when employing the same fixed model over these datasets without any retraining procedure. To target real-time applications, we further design a lightweight model based on UGAC, which also outperforms other methods over KITTI benchmarks with only 0.6 M parameters.","sentences":["Correlation based stereo matching has achieved outstanding performance, which pursues cost volume between two feature maps.","Unfortunately, current methods with a fixed model do not work uniformly well across various datasets, greatly limiting their real-world applicability.","To tackle this issue, this paper proposes a new perspective to dynamically calculate correlation for robust stereo matching.","A novel Uncertainty Guided Adaptive Correlation (UGAC) module is introduced to robustly adapt the same model for different scenarios.","Specifically, a variance-based uncertainty estimation is employed to adaptively adjust the sampling area during warping operation.","Additionally, we improve the traditional non-parametric warping with learnable parameters, such that the position-specific weights can be learned.","We show that by empowering the recurrent network with the UGAC module, stereo matching can be exploited more robustly and effectively.","Extensive experiments demonstrate that our method achieves state-of-the-art performance over the ETH3D, KITTI, and Middlebury datasets when employing the same fixed model over these datasets without any retraining procedure.","To target real-time applications, we further design a lightweight model based on UGAC, which also outperforms other methods over KITTI benchmarks with only 0.6 M parameters."],"url":"http://arxiv.org/abs/2307.14071v1"}
{"created":"2023-07-26 09:45:17","title":"PNT-Edge: Towards Robust Edge Detection with Noisy Labels by Learning Pixel-level Noise Transitions","abstract":"Relying on large-scale training data with pixel-level labels, previous edge detection methods have achieved high performance. However, it is hard to manually label edges accurately, especially for large datasets, and thus the datasets inevitably contain noisy labels. This label-noise issue has been studied extensively for classification, while still remaining under-explored for edge detection. To address the label-noise issue for edge detection, this paper proposes to learn Pixel-level NoiseTransitions to model the label-corruption process. To achieve it, we develop a novel Pixel-wise Shift Learning (PSL) module to estimate the transition from clean to noisy labels as a displacement field. Exploiting the estimated noise transitions, our model, named PNT-Edge, is able to fit the prediction to clean labels. In addition, a local edge density regularization term is devised to exploit local structure information for better transition learning. This term encourages learning large shifts for the edges with complex local structures. Experiments on SBD and Cityscapes demonstrate the effectiveness of our method in relieving the impact of label noise. Codes will be available at github.","sentences":["Relying on large-scale training data with pixel-level labels, previous edge detection methods have achieved high performance.","However, it is hard to manually label edges accurately, especially for large datasets, and thus the datasets inevitably contain noisy labels.","This label-noise issue has been studied extensively for classification, while still remaining under-explored for edge detection.","To address the label-noise issue for edge detection, this paper proposes to learn Pixel-level NoiseTransitions to model the label-corruption process.","To achieve it, we develop a novel Pixel-wise Shift Learning (PSL) module to estimate the transition from clean to noisy labels as a displacement field.","Exploiting the estimated noise transitions, our model, named PNT-Edge, is able to fit the prediction to clean labels.","In addition, a local edge density regularization term is devised to exploit local structure information for better transition learning.","This term encourages learning large shifts for the edges with complex local structures.","Experiments on SBD and Cityscapes demonstrate the effectiveness of our method in relieving the impact of label noise.","Codes will be available at github."],"url":"http://arxiv.org/abs/2307.14070v1"}
{"created":"2023-07-26 09:40:19","title":"Dynamic Domain Discrepancy Adjustment for Active Multi-Domain Adaptation","abstract":"Multi-source unsupervised domain adaptation (MUDA) aims to transfer knowledge from related source domains to an unlabeled target domain. While recent MUDA methods have shown promising results, most focus on aligning the overall feature distributions across source domains, which can lead to negative effects due to redundant features within each domain. Moreover, there is a significant performance gap between MUDA and supervised methods. To address these challenges, we propose a novel approach called Dynamic Domain Discrepancy Adjustment for Active Multi-Domain Adaptation (D3AAMDA). Firstly, we establish a multi-source dynamic modulation mechanism during the training process based on the degree of distribution differences between source and target domains. This mechanism controls the alignment level of features between each source domain and the target domain, effectively leveraging the local advantageous feature information within the source domains. Additionally, we propose a Multi-source Active Boundary Sample Selection (MABS) strategy, which utilizes a guided dynamic boundary loss to design an efficient query function for selecting important samples. This strategy achieves improved generalization to the target domain with minimal sampling costs. We extensively evaluate our proposed method on commonly used domain adaptation datasets, comparing it against existing UDA and ADA methods. The experimental results unequivocally demonstrate the superiority of our approach.","sentences":["Multi-source unsupervised domain adaptation (MUDA) aims to transfer knowledge from related source domains to an unlabeled target domain.","While recent MUDA methods have shown promising results, most focus on aligning the overall feature distributions across source domains, which can lead to negative effects due to redundant features within each domain.","Moreover, there is a significant performance gap between MUDA and supervised methods.","To address these challenges, we propose a novel approach called Dynamic Domain Discrepancy Adjustment for Active Multi-Domain Adaptation (D3AAMDA).","Firstly, we establish a multi-source dynamic modulation mechanism during the training process based on the degree of distribution differences between source and target domains.","This mechanism controls the alignment level of features between each source domain and the target domain, effectively leveraging the local advantageous feature information within the source domains.","Additionally, we propose a Multi-source Active Boundary Sample Selection (MABS) strategy, which utilizes a guided dynamic boundary loss to design an efficient query function for selecting important samples.","This strategy achieves improved generalization to the target domain with minimal sampling costs.","We extensively evaluate our proposed method on commonly used domain adaptation datasets, comparing it against existing UDA and ADA methods.","The experimental results unequivocally demonstrate the superiority of our approach."],"url":"http://arxiv.org/abs/2307.14068v1"}
{"created":"2023-07-26 09:34:34","title":"Machine Learning Applications In Healthcare: The State Of Knowledge and Future Directions","abstract":"Detection of easily missed hidden patterns with fast processing power makes machine learning (ML) indispensable to today's healthcare system. Though many ML applications have already been discovered and many are still under investigation, only a few have been adopted by current healthcare systems. As a result, there exists an enormous opportunity in healthcare system for ML but distributed information, scarcity of properly arranged and easily explainable documentation in related sector are major impede which are making ML applications difficult to healthcare professionals. This study aimed to gather ML applications in different areas of healthcare concisely and more effectively so that necessary information can be accessed immediately with relevant references. We divided our study into five major groups: community level work, risk management/ preventive care, healthcare operation management, remote care, and early detection. Dividing these groups into subgroups, we provided relevant references with description in tabular form for quick access. Our objective is to inform people about ML applicability in healthcare industry, reduce the knowledge gap of clinicians about the ML applications and motivate healthcare professionals towards more machine learning based healthcare system.","sentences":["Detection of easily missed hidden patterns with fast processing power makes machine learning (ML) indispensable to today's healthcare system.","Though many ML applications have already been discovered and many are still under investigation, only a few have been adopted by current healthcare systems.","As a result, there exists an enormous opportunity in healthcare system for ML but distributed information, scarcity of properly arranged and easily explainable documentation in related sector are major impede which are making ML applications difficult to healthcare professionals.","This study aimed to gather ML applications in different areas of healthcare concisely and more effectively so that necessary information can be accessed immediately with relevant references.","We divided our study into five major groups: community level work, risk management/ preventive care, healthcare operation management, remote care, and early detection.","Dividing these groups into subgroups, we provided relevant references with description in tabular form for quick access.","Our objective is to inform people about ML applicability in healthcare industry, reduce the knowledge gap of clinicians about the ML applications and motivate healthcare professionals towards more machine learning based healthcare system."],"url":"http://arxiv.org/abs/2307.14067v1"}
{"created":"2023-07-26 09:33:24","title":"Pre-Training with Diffusion models for Dental Radiography segmentation","abstract":"Medical radiography segmentation, and specifically dental radiography, is highly limited by the cost of labeling which requires specific expertise and labor-intensive annotations. In this work, we propose a straightforward pre-training method for semantic segmentation leveraging Denoising Diffusion Probabilistic Models (DDPM), which have shown impressive results for generative modeling. Our straightforward approach achieves remarkable performance in terms of label efficiency and does not require architectural modifications between pre-training and downstream tasks. We propose to first pre-train a Unet by exploiting the DDPM training objective, and then fine-tune the resulting model on a segmentation task. Our experimental results on the segmentation of dental radiographs demonstrate that the proposed method is competitive with state-of-the-art pre-training methods.","sentences":["Medical radiography segmentation, and specifically dental radiography, is highly limited by the cost of labeling which requires specific expertise and labor-intensive annotations.","In this work, we propose a straightforward pre-training method for semantic segmentation leveraging Denoising Diffusion Probabilistic Models (DDPM), which have shown impressive results for generative modeling.","Our straightforward approach achieves remarkable performance in terms of label efficiency and does not require architectural modifications between pre-training and downstream tasks.","We propose to first pre-train a Unet by exploiting the DDPM training objective, and then fine-tune the resulting model on a segmentation task.","Our experimental results on the segmentation of dental radiographs demonstrate that the proposed method is competitive with state-of-the-art pre-training methods."],"url":"http://arxiv.org/abs/2307.14066v1"}
{"created":"2023-07-26 09:31:30","title":"Relay-Enabled Backscatter Communications: Linear Mapping and Resource Allocation","abstract":"Relay-enabled backscatter communication (BC) is an intriguing paradigm to alleviate energy shortage and improve throughput of Internet-of-Things (IoT) devices. Most of the existing works focus on the resource allocation that considered the unequal and continuous time allocation for both source-relay and relay-destination links. However, the continuous time allocation may be infeasible since in practice, the time allocation shall be carried out in integral multiple of the subframe duration unit. In this article, we study a discrete time scheme from the perspective of frame structure, where one transmission block is divided into two phases and the linear mapping is employed as a re-encoding method to determine the number of subframes for both phases and the power allocation for each subframe in a relay-enabled BC system. Based on this, we derive an accurate system-throughput expression and formulate a mixed-integral non-convex optimization problem to maximize the system throughput by jointly optimizing the power reflection coefficient (PRC) of the IoT node, the power allocation of the hybrid access point (HAP) and the linear mapping matrix, and solve it via a three-step approach. Accordingly, we propose a low complexity iterative algorithm to obtain the throughput maximization-based resource allocation solution. Numerical results analyze the performance of our proposed algorithm, verify the superiority of our proposed scheme, and evaluate the impacts of network parameters on the system throughput.","sentences":["Relay-enabled backscatter communication (BC) is an intriguing paradigm to alleviate energy shortage and improve throughput of Internet-of-Things (IoT) devices.","Most of the existing works focus on the resource allocation that considered the unequal and continuous time allocation for both source-relay and relay-destination links.","However, the continuous time allocation may be infeasible since in practice, the time allocation shall be carried out in integral multiple of the subframe duration unit.","In this article, we study a discrete time scheme from the perspective of frame structure, where one transmission block is divided into two phases and the linear mapping is employed as a re-encoding method to determine the number of subframes for both phases and the power allocation for each subframe in a relay-enabled BC system.","Based on this, we derive an accurate system-throughput expression and formulate a mixed-integral non-convex optimization problem to maximize the system throughput by jointly optimizing the power reflection coefficient (PRC) of the IoT node, the power allocation of the hybrid access point (HAP) and the linear mapping matrix, and solve it via a three-step approach.","Accordingly, we propose a low complexity iterative algorithm to obtain the throughput maximization-based resource allocation solution.","Numerical results analyze the performance of our proposed algorithm, verify the superiority of our proposed scheme, and evaluate the impacts of network parameters on the system throughput."],"url":"http://arxiv.org/abs/2307.14064v1"}
{"created":"2023-07-26 09:31:06","title":"ECO: Ensembling Context Optimization for Vision-Language Models","abstract":"Image recognition has recently witnessed a paradigm shift, where vision-language models are now used to perform few-shot classification based on textual prompts. Among these, the CLIP model has shown remarkable capabilities for zero-shot transfer by matching an image and a custom textual prompt in its latent space. This has paved the way for several works that focus on engineering or learning textual contexts for maximizing CLIP's classification capabilities. In this paper, we follow this trend by learning an ensemble of prompts for image classification. We show that learning diverse and possibly shorter contexts improves considerably and consistently the results rather than relying on a single trainable prompt. In particular, we report better few-shot capabilities with no additional cost at inference time. We demonstrate the capabilities of our approach on 11 different benchmarks.","sentences":["Image recognition has recently witnessed a paradigm shift, where vision-language models are now used to perform few-shot classification based on textual prompts.","Among these, the CLIP model has shown remarkable capabilities for zero-shot transfer by matching an image and a custom textual prompt in its latent space.","This has paved the way for several works that focus on engineering or learning textual contexts for maximizing CLIP's classification capabilities.","In this paper, we follow this trend by learning an ensemble of prompts for image classification.","We show that learning diverse and possibly shorter contexts improves considerably and consistently the results rather than relying on a single trainable prompt.","In particular, we report better few-shot capabilities with no additional cost at inference time.","We demonstrate the capabilities of our approach on 11 different benchmarks."],"url":"http://arxiv.org/abs/2307.14063v1"}
{"created":"2023-07-26 09:19:21","title":"Set-level Guidance Attack: Boosting Adversarial Transferability of Vision-Language Pre-training Models","abstract":"Vision-language pre-training (VLP) models have shown vulnerability to adversarial examples in multimodal tasks. Furthermore, malicious adversaries can be deliberately transferred to attack other black-box models. However, existing work has mainly focused on investigating white-box attacks. In this paper, we present the first study to investigate the adversarial transferability of recent VLP models. We observe that existing methods exhibit much lower transferability, compared to the strong attack performance in white-box settings. The transferability degradation is partly caused by the under-utilization of cross-modal interactions. Particularly, unlike unimodal learning, VLP models rely heavily on cross-modal interactions and the multimodal alignments are many-to-many, e.g., an image can be described in various natural languages. To this end, we propose a highly transferable Set-level Guidance Attack (SGA) that thoroughly leverages modality interactions and incorporates alignment-preserving augmentation with cross-modal guidance. Experimental results demonstrate that SGA could generate adversarial examples that can strongly transfer across different VLP models on multiple downstream vision-language tasks. On image-text retrieval, SGA significantly enhances the attack success rate for transfer attacks from ALBEF to TCL by a large margin (at least 9.78% and up to 30.21%), compared to the state-of-the-art.","sentences":["Vision-language pre-training (VLP) models have shown vulnerability to adversarial examples in multimodal tasks.","Furthermore, malicious adversaries can be deliberately transferred to attack other black-box models.","However, existing work has mainly focused on investigating white-box attacks.","In this paper, we present the first study to investigate the adversarial transferability of recent VLP models.","We observe that existing methods exhibit much lower transferability, compared to the strong attack performance in white-box settings.","The transferability degradation is partly caused by the under-utilization of cross-modal interactions.","Particularly, unlike unimodal learning, VLP models rely heavily on cross-modal interactions and the multimodal alignments are many-to-many, e.g., an image can be described in various natural languages.","To this end, we propose a highly transferable Set-level Guidance Attack (SGA) that thoroughly leverages modality interactions and incorporates alignment-preserving augmentation with cross-modal guidance.","Experimental results demonstrate that SGA could generate adversarial examples that can strongly transfer across different VLP models on multiple downstream vision-language tasks.","On image-text retrieval, SGA significantly enhances the attack success rate for transfer attacks from ALBEF to TCL by a large margin (at least 9.78% and up to 30.21%), compared to the state-of-the-art."],"url":"http://arxiv.org/abs/2307.14061v1"}
{"created":"2023-07-26 09:12:49","title":"A Probabilistic Position Bias Model for Short-Video Recommendation Feeds","abstract":"Modern web-based platforms show ranked lists of recommendations to users, attempting to maximise user satisfaction or business metrics. Typically, the goal of such systems boils down to maximising the exposure probability for items that are deemed \"reward-maximising\" according to a metric of interest. This general framing comprises streaming applications, as well as e-commerce or job recommendations, and even web search. Position bias or user models can be used to estimate exposure probabilities for each use-case, specifically tailored to how users interact with the presented rankings. A unifying factor in these diverse problem settings is that typically only one or several items will be engaged with (clicked, streamed,...) before a user leaves the ranked list. Short-video feeds on social media platforms diverge from this general framing in several ways, most notably that users do not tend to leave the feed after e.g. liking a post. Indeed, seemingly infinite feeds invite users to scroll further down the ranked list. For this reason, existing position bias or user models tend to fall short in such settings, as they do not accurately capture users' interaction modalities.   In this work, we propose a novel and probabilistically sound personalised position bias model for feed recommendations. We focus on a 1st-level feed in a hierarchical structure, where users may enter a 2nd-level feed via any given 1st-level item. We posit that users come to the platform with a scrolling budget drawn according to some distribution, and show how the survival function of said distribution can be used to obtain closed-form estimates for personalised exposure probabilities. Empirical insights from a large-scale social media platform show how our probabilistic position bias model more accurately captures empirical exposure than existing models, and paves the way for unbiased evaluation and learning-to-rank.","sentences":["Modern web-based platforms show ranked lists of recommendations to users, attempting to maximise user satisfaction or business metrics.","Typically, the goal of such systems boils down to maximising the exposure probability for items that are deemed \"reward-maximising\" according to a metric of interest.","This general framing comprises streaming applications, as well as e-commerce or job recommendations, and even web search.","Position bias or user models can be used to estimate exposure probabilities for each use-case, specifically tailored to how users interact with the presented rankings.","A unifying factor in these diverse problem settings is that typically only one or several items will be engaged with (clicked, streamed,...) before a user leaves the ranked list.","Short-video feeds on social media platforms diverge from this general framing in several ways, most notably that users do not tend to leave the feed after e.g. liking a post.","Indeed, seemingly infinite feeds invite users to scroll further down the ranked list.","For this reason, existing position bias or user models tend to fall short in such settings, as they do not accurately capture users' interaction modalities.   ","In this work, we propose a novel and probabilistically sound personalised position bias model for feed recommendations.","We focus on a 1st-level feed in a hierarchical structure, where users may enter a 2nd-level feed via any given 1st-level item.","We posit that users come to the platform with a scrolling budget drawn according to some distribution, and show how the survival function of said distribution can be used to obtain closed-form estimates for personalised exposure probabilities.","Empirical insights from a large-scale social media platform show how our probabilistic position bias model more accurately captures empirical exposure than existing models, and paves the way for unbiased evaluation and learning-to-rank."],"url":"http://arxiv.org/abs/2307.14059v1"}
{"created":"2023-07-26 09:12:05","title":"Towards Establishing Systematic Classification Requirements for Automated Driving","abstract":"Despite the presence of the classification task in many different benchmark datasets for perception in the automotive domain, few efforts have been undertaken to define consistent classification requirements. This work addresses the topic by proposing a structured method to generate a classification structure. First, legal categories are identified based on behavioral requirements for the vehicle. This structure is further substantiated by considering the two aspects of collision safety for objects as well as perceptual categories. A classification hierarchy is obtained by applying the method to an exemplary legal text. A comparison of the results with benchmark dataset categories shows limited agreement. This indicates the necessity for explicit consideration of legal requirements regarding perception.","sentences":["Despite the presence of the classification task in many different benchmark datasets for perception in the automotive domain, few efforts have been undertaken to define consistent classification requirements.","This work addresses the topic by proposing a structured method to generate a classification structure.","First, legal categories are identified based on behavioral requirements for the vehicle.","This structure is further substantiated by considering the two aspects of collision safety for objects as well as perceptual categories.","A classification hierarchy is obtained by applying the method to an exemplary legal text.","A comparison of the results with benchmark dataset categories shows limited agreement.","This indicates the necessity for explicit consideration of legal requirements regarding perception."],"url":"http://arxiv.org/abs/2307.14058v1"}
{"created":"2023-07-26 09:09:48","title":"Open Image Content Disarm And Reconstruction","abstract":"With the advance in malware technology, attackers create new ways to hide their malicious code from antivirus services. One way to obfuscate an attack is to use common files as cover to hide the malicious scripts, so the malware will look like a legitimate file. Although cutting-edge Artificial Intelligence and content signature exist, evasive malware successfully bypasses next-generation malware detection using advanced methods like steganography. Some of the files commonly used to hide malware are image files (e.g., JPEG). In addition, some malware use steganography to hide malicious scripts or sensitive data in images. Steganography in images is difficult to detect even with specialized tools. Image-based attacks try to attack the user's device using malicious payloads or utilize image steganography to hide sensitive data inside legitimate images and leak it outside the user's device. Therefore in this paper, we present a novel Image Content Disarm and Reconstruction (ICDR). Our ICDR system removes potential malware, with a zero trust approach, while maintaining high image quality and file usability. By extracting the image data, removing it from the rest of the file, and manipulating the image pixels, it is possible to disable or remove the hidden malware inside the file.","sentences":["With the advance in malware technology, attackers create new ways to hide their malicious code from antivirus services.","One way to obfuscate an attack is to use common files as cover to hide the malicious scripts, so the malware will look like a legitimate file.","Although cutting-edge Artificial Intelligence and content signature exist, evasive malware successfully bypasses next-generation malware detection using advanced methods like steganography.","Some of the files commonly used to hide malware are image files (e.g., JPEG).","In addition, some malware use steganography to hide malicious scripts or sensitive data in images.","Steganography in images is difficult to detect even with specialized tools.","Image-based attacks try to attack the user's device using malicious payloads or utilize image steganography to hide sensitive data inside legitimate images and leak it outside the user's device.","Therefore in this paper, we present a novel Image Content Disarm and Reconstruction (ICDR).","Our ICDR system removes potential malware, with a zero trust approach, while maintaining high image quality and file usability.","By extracting the image data, removing it from the rest of the file, and manipulating the image pixels, it is possible to disable or remove the hidden malware inside the file."],"url":"http://arxiv.org/abs/2307.14057v1"}
{"created":"2023-07-26 09:04:35","title":"Unite-Divide-Unite: Joint Boosting Trunk and Structure for High-accuracy Dichotomous Image Segmentation","abstract":"High-accuracy Dichotomous Image Segmentation (DIS) aims to pinpoint category-agnostic foreground objects from natural scenes. The main challenge for DIS involves identifying the highly accurate dominant area while rendering detailed object structure. However, directly using a general encoder-decoder architecture may result in an oversupply of high-level features and neglect the shallow spatial information necessary for partitioning meticulous structures. To fill this gap, we introduce a novel Unite-Divide-Unite Network (UDUN} that restructures and bipartitely arranges complementary features to simultaneously boost the effectiveness of trunk and structure identification. The proposed UDUN proceeds from several strengths. First, a dual-size input feeds into the shared backbone to produce more holistic and detailed features while keeping the model lightweight. Second, a simple Divide-and-Conquer Module (DCM) is proposed to decouple multiscale low- and high-level features into our structure decoder and trunk decoder to obtain structure and trunk information respectively. Moreover, we design a Trunk-Structure Aggregation module (TSA) in our union decoder that performs cascade integration for uniform high-accuracy segmentation. As a result, UDUN performs favorably against state-of-the-art competitors in all six evaluation metrics on overall DIS-TE, i.e., achieving 0.772 weighted F-measure and 977 HCE. Using 1024*1024 input, our model enables real-time inference at 65.3 fps with ResNet-18.","sentences":["High-accuracy Dichotomous Image Segmentation (DIS) aims to pinpoint category-agnostic foreground objects from natural scenes.","The main challenge for DIS involves identifying the highly accurate dominant area while rendering detailed object structure.","However, directly using a general encoder-decoder architecture may result in an oversupply of high-level features and neglect the shallow spatial information necessary for partitioning meticulous structures.","To fill this gap, we introduce a novel Unite-Divide-Unite Network (UDUN} that restructures and bipartitely arranges complementary features to simultaneously boost the effectiveness of trunk and structure identification.","The proposed UDUN proceeds from several strengths.","First, a dual-size input feeds into the shared backbone to produce more holistic and detailed features while keeping the model lightweight.","Second, a simple Divide-and-Conquer Module (DCM) is proposed to decouple multiscale low- and high-level features into our structure decoder and trunk decoder to obtain structure and trunk information respectively.","Moreover, we design a Trunk-Structure Aggregation module (TSA) in our union decoder that performs cascade integration for uniform high-accuracy segmentation.","As a result, UDUN performs favorably against state-of-the-art competitors in all six evaluation metrics on overall DIS-TE, i.e., achieving 0.772 weighted F-measure and 977 HCE.","Using 1024*1024 input, our model enables real-time inference at 65.3 fps with ResNet-18."],"url":"http://arxiv.org/abs/2307.14052v1"}
{"created":"2023-07-26 09:04:27","title":"3D Semantic Subspace Traverser: Empowering 3D Generative Model with Shape Editing Capability","abstract":"Shape generation is the practice of producing 3D shapes as various representations for 3D content creation. Previous studies on 3D shape generation have focused on shape quality and structure, without or less considering the importance of semantic information. Consequently, such generative models often fail to preserve the semantic consistency of shape structure or enable manipulation of the semantic attributes of shapes during generation. In this paper, we proposed a novel semantic generative model named 3D Semantic Subspace Traverser that utilizes semantic attributes for category-specific 3D shape generation and editing. Our method utilizes implicit functions as the 3D shape representation and combines a novel latent-space GAN with a linear subspace model to discover semantic dimensions in the local latent space of 3D shapes. Each dimension of the subspace corresponds to a particular semantic attribute, and we can edit the attributes of generated shapes by traversing the coefficients of those dimensions. Experimental results demonstrate that our method can produce plausible shapes with complex structures and enable the editing of semantic attributes. The code and trained models are available at https://github.com/TrepangCat/3D_Semantic_Subspace_Traverser","sentences":["Shape generation is the practice of producing 3D shapes as various representations for 3D content creation.","Previous studies on 3D shape generation have focused on shape quality and structure, without or less considering the importance of semantic information.","Consequently, such generative models often fail to preserve the semantic consistency of shape structure or enable manipulation of the semantic attributes of shapes during generation.","In this paper, we proposed a novel semantic generative model named 3D Semantic Subspace Traverser that utilizes semantic attributes for category-specific 3D shape generation and editing.","Our method utilizes implicit functions as the 3D shape representation and combines a novel latent-space GAN with a linear subspace model to discover semantic dimensions in the local latent space of 3D shapes.","Each dimension of the subspace corresponds to a particular semantic attribute, and we can edit the attributes of generated shapes by traversing the coefficients of those dimensions.","Experimental results demonstrate that our method can produce plausible shapes with complex structures and enable the editing of semantic attributes.","The code and trained models are available at https://github.com/TrepangCat/3D_Semantic_Subspace_Traverser"],"url":"http://arxiv.org/abs/2307.14051v1"}
{"created":"2023-07-26 09:03:08","title":"Is the Performance of NOMA-aided Integrated Sensing and Multicast-Unicast Communications Improved by IRS?","abstract":"In this paper, we consider intelligent reflecting surface (IRS) in a non-orthogonal multiple access (NOMA)-aided Integrated Sensing and Multicast-Unicast Communication (ISMUC) system, where the multicast signal is used for sensing and communications while the unicast signal is used only for communications. Our goal is to depict whether the IRS improves the performance of NOMA-ISMUC system or not under the imperfect/perfect successive interference cancellation (SIC) scenario. Towards this end, we formulate a non-convex problem to maximize the unicast rate while ensuring the minimum target illumination power and multicast rate. To settle this problem, we employ the Dinkelbach method to transform this original problem into an equivalent one, which is then solved via alternating optimization algorithm and semidefinite relaxation (SDR) with Sequential Rank-One Constraint Relaxation (SROCR). Based on this, an iterative algorithm is devised to obtain a near-optimal solution. Computer simulations verify the quick convergence of the devised iterative algorithm, and provide insightful results. Compared to NOMA-ISMUC without IRS, IRS-aided NOMA-ISMUC achieves a higher rate with perfect SIC but keeps the almost same rate in the case of imperfect SIC.","sentences":["In this paper, we consider intelligent reflecting surface (IRS) in a non-orthogonal multiple access (NOMA)-aided Integrated Sensing and Multicast-Unicast Communication (ISMUC) system, where the multicast signal is used for sensing and communications while the unicast signal is used only for communications.","Our goal is to depict whether the IRS improves the performance of NOMA-ISMUC system or not under the imperfect/perfect successive interference cancellation (SIC) scenario.","Towards this end, we formulate a non-convex problem to maximize the unicast rate while ensuring the minimum target illumination power and multicast rate.","To settle this problem, we employ the Dinkelbach method to transform this original problem into an equivalent one, which is then solved via alternating optimization algorithm and semidefinite relaxation (SDR) with Sequential Rank-One Constraint Relaxation (SROCR).","Based on this, an iterative algorithm is devised to obtain a near-optimal solution.","Computer simulations verify the quick convergence of the devised iterative algorithm, and provide insightful results.","Compared to NOMA-ISMUC without IRS, IRS-aided NOMA-ISMUC achieves a higher rate with perfect SIC but keeps the almost same rate in the case of imperfect SIC."],"url":"http://arxiv.org/abs/2307.14050v1"}
{"created":"2023-07-26 08:46:07","title":"GovernR: Provenance and Confidentiality Guarantees In Research Data Repositories","abstract":"We propose cryptographic protocols to incorporate time provenance guarantees while meeting confidentiality and controlled sharing needs for research data. We demonstrate the efficacy of these mechanisms by developing and benchmarking a practical tool, GovernR, which furthermore takes into usability issues and is compatible with a popular open-sourced research data storage platform, Dataverse. In doing so, we identify and provide a solution addressing an important gap (though applicable to only niche use cases) in practical research data management.","sentences":["We propose cryptographic protocols to incorporate time provenance guarantees while meeting confidentiality and controlled sharing needs for research data.","We demonstrate the efficacy of these mechanisms by developing and benchmarking a practical tool, GovernR, which furthermore takes into usability issues and is compatible with a popular open-sourced research data storage platform, Dataverse.","In doing so, we identify and provide a solution addressing an important gap (though applicable to only niche use cases) in practical research data management."],"url":"http://arxiv.org/abs/2307.14041v1"}
{"created":"2023-07-26 08:43:12","title":"Controllable Guide-Space for Generalizable Face Forgery Detection","abstract":"Recent studies on face forgery detection have shown satisfactory performance for methods involved in training datasets, but are not ideal enough for unknown domains. This motivates many works to improve the generalization, but forgery-irrelevant information, such as image background and identity, still exists in different domain features and causes unexpected clustering, limiting the generalization. In this paper, we propose a controllable guide-space (GS) method to enhance the discrimination of different forgery domains, so as to increase the forgery relevance of features and thereby improve the generalization. The well-designed guide-space can simultaneously achieve both the proper separation of forgery domains and the large distance between real-forgery domains in an explicit and controllable manner. Moreover, for better discrimination, we use a decoupling module to weaken the interference of forgery-irrelevant correlations between domains. Furthermore, we make adjustments to the decision boundary manifold according to the clustering degree of the same domain features within the neighborhood. Extensive experiments in multiple in-domain and cross-domain settings confirm that our method can achieve state-of-the-art generalization.","sentences":["Recent studies on face forgery detection have shown satisfactory performance for methods involved in training datasets, but are not ideal enough for unknown domains.","This motivates many works to improve the generalization, but forgery-irrelevant information, such as image background and identity, still exists in different domain features and causes unexpected clustering, limiting the generalization.","In this paper, we propose a controllable guide-space (GS) method to enhance the discrimination of different forgery domains, so as to increase the forgery relevance of features and thereby improve the generalization.","The well-designed guide-space can simultaneously achieve both the proper separation of forgery domains and the large distance between real-forgery domains in an explicit and controllable manner.","Moreover, for better discrimination, we use a decoupling module to weaken the interference of forgery-irrelevant correlations between domains.","Furthermore, we make adjustments to the decision boundary manifold according to the clustering degree of the same domain features within the neighborhood.","Extensive experiments in multiple in-domain and cross-domain settings confirm that our method can achieve state-of-the-art generalization."],"url":"http://arxiv.org/abs/2307.14039v1"}
{"created":"2023-07-26 08:41:22","title":"Research on Inertial Navigation Technology of Unmanned Aerial Vehicles with Integrated Reinforcement Learning Algorithm","abstract":"We first define appropriate state representation and action space, and then design an adjustment mechanism based on the actions selected by the intelligent agent. The adjustment mechanism outputs the next state and reward value of the agent. Additionally, the adjustment mechanism calculates the error between the adjusted state and the unadjusted state. Furthermore, the intelligent agent stores the acquired experience samples containing states and reward values in a buffer and replays the experiences during each iteration to learn the dynamic characteristics of the environment. We name the improved algorithm as the DQM algorithm. Experimental results demonstrate that the intelligent agent using our proposed algorithm effectively reduces the accumulated errors of inertial navigation in dynamic environments. Although our research provides a basis for achieving autonomous navigation of unmanned aerial vehicles, there is still room for significant optimization. Further research can include testing unmanned aerial vehicles in simulated environments, testing unmanned aerial vehicles in real-world environments, optimizing the design of reward functions, improving the algorithm workflow to enhance convergence speed and performance, and enhancing the algorithm's generalization ability.","sentences":["We first define appropriate state representation and action space, and then design an adjustment mechanism based on the actions selected by the intelligent agent.","The adjustment mechanism outputs the next state and reward value of the agent.","Additionally, the adjustment mechanism calculates the error between the adjusted state and the unadjusted state.","Furthermore, the intelligent agent stores the acquired experience samples containing states and reward values in a buffer and replays the experiences during each iteration to learn the dynamic characteristics of the environment.","We name the improved algorithm as the DQM algorithm.","Experimental results demonstrate that the intelligent agent using our proposed algorithm effectively reduces the accumulated errors of inertial navigation in dynamic environments.","Although our research provides a basis for achieving autonomous navigation of unmanned aerial vehicles, there is still room for significant optimization.","Further research can include testing unmanned aerial vehicles in simulated environments, testing unmanned aerial vehicles in real-world environments, optimizing the design of reward functions, improving the algorithm workflow to enhance convergence speed and performance, and enhancing the algorithm's generalization ability."],"url":"http://arxiv.org/abs/2307.14038v1"}
{"created":"2023-07-26 08:40:21","title":"Hydra Battles and AC Termination, Revisited","abstract":"We present a termination proof for the Battle of Hercules and Hydra represented as a rewrite system with AC symbols. Our proof employs type introduction in connection with many-sorted semantic labeling for AC rewriting and AC-RPO.","sentences":["We present a termination proof for the Battle of Hercules and Hydra represented as a rewrite system with AC symbols.","Our proof employs type introduction in connection with many-sorted semantic labeling for AC rewriting and AC-RPO."],"url":"http://arxiv.org/abs/2307.14036v1"}
{"created":"2023-07-26 08:29:42","title":"Multi3WOZ: A Multilingual, Multi-Domain, Multi-Parallel Dataset for Training and Evaluating Culturally Adapted Task-Oriented Dialog Systems","abstract":"Creating high-quality annotated data for task-oriented dialog (ToD) is known to be notoriously difficult, and the challenges are amplified when the goal is to create equitable, culturally adapted, and large-scale ToD datasets for multiple languages. Therefore, the current datasets are still very scarce and suffer from limitations such as translation-based non-native dialogs with translation artefacts, small scale, or lack of cultural adaptation, among others. In this work, we first take stock of the current landscape of multilingual ToD datasets, offering a systematic overview of their properties and limitations. Aiming to reduce all the detected limitations, we then introduce Multi3WOZ, a novel multilingual, multi-domain, multi-parallel ToD dataset. It is large-scale and offers culturally adapted dialogs in 4 languages to enable training and evaluation of multilingual and cross-lingual ToD systems. We describe a complex bottom-up data collection process that yielded the final dataset, and offer the first sets of baseline scores across different ToD-related tasks for future reference, also highlighting its challenging nature.","sentences":["Creating high-quality annotated data for task-oriented dialog (ToD) is known to be notoriously difficult, and the challenges are amplified when the goal is to create equitable, culturally adapted, and large-scale ToD datasets for multiple languages.","Therefore, the current datasets are still very scarce and suffer from limitations such as translation-based non-native dialogs with translation artefacts, small scale, or lack of cultural adaptation, among others.","In this work, we first take stock of the current landscape of multilingual ToD datasets, offering a systematic overview of their properties and limitations.","Aiming to reduce all the detected limitations, we then introduce Multi3WOZ, a novel multilingual, multi-domain, multi-parallel ToD dataset.","It is large-scale and offers culturally adapted dialogs in 4 languages to enable training and evaluation of multilingual and cross-lingual ToD systems.","We describe a complex bottom-up data collection process that yielded the final dataset, and offer the first sets of baseline scores across different ToD-related tasks for future reference, also highlighting its challenging nature."],"url":"http://arxiv.org/abs/2307.14031v1"}
{"created":"2023-07-26 08:25:46","title":"Consensus-Adaptive RANSAC","abstract":"RANSAC and its variants are widely used for robust estimation, however, they commonly follow a greedy approach to finding the highest scoring model while ignoring other model hypotheses. In contrast, Iteratively Reweighted Least Squares (IRLS) techniques gradually approach the model by iteratively updating the weight of each correspondence based on the residuals from previous iterations. Inspired by these methods, we propose a new RANSAC framework that learns to explore the parameter space by considering the residuals seen so far via a novel attention layer. The attention mechanism operates on a batch of point-to-model residuals, and updates a per-point estimation state to take into account the consensus found through a lightweight one-step transformer. This rich state then guides the minimal sampling between iterations as well as the model refinement. We evaluate the proposed approach on essential and fundamental matrix estimation on a number of indoor and outdoor datasets. It outperforms state-of-the-art estimators by a significant margin adding only a small runtime overhead. Moreover, we demonstrate good generalization properties of our trained model, indicating its effectiveness across different datasets and tasks. The proposed attention mechanism and one-step transformer provide an adaptive behavior that enhances the performance of RANSAC, making it a more effective tool for robust estimation. Code is available at https://github.com/cavalli1234/CA-RANSAC.","sentences":["RANSAC and its variants are widely used for robust estimation, however, they commonly follow a greedy approach to finding the highest scoring model while ignoring other model hypotheses.","In contrast, Iteratively Reweighted Least Squares (IRLS) techniques gradually approach the model by iteratively updating the weight of each correspondence based on the residuals from previous iterations.","Inspired by these methods, we propose a new RANSAC framework that learns to explore the parameter space by considering the residuals seen so far via a novel attention layer.","The attention mechanism operates on a batch of point-to-model residuals, and updates a per-point estimation state to take into account the consensus found through a lightweight one-step transformer.","This rich state then guides the minimal sampling between iterations as well as the model refinement.","We evaluate the proposed approach on essential and fundamental matrix estimation on a number of indoor and outdoor datasets.","It outperforms state-of-the-art estimators by a significant margin adding only a small runtime overhead.","Moreover, we demonstrate good generalization properties of our trained model, indicating its effectiveness across different datasets and tasks.","The proposed attention mechanism and one-step transformer provide an adaptive behavior that enhances the performance of RANSAC, making it a more effective tool for robust estimation.","Code is available at https://github.com/cavalli1234/CA-RANSAC."],"url":"http://arxiv.org/abs/2307.14030v1"}
{"created":"2023-07-26 08:14:18","title":"Topologically-Regularized Multiple Instance Learning for Red Blood Cell Disease Classification","abstract":"Diagnosing rare anemia disorders using microscopic images is challenging for skilled specialists and machine-learning methods alike. Due to thousands of disease-relevant cells in a single blood sample, this constitutes a complex multiple-instance learning (MIL) problem. While the spatial neighborhood of red blood cells is not meaningful per se, the topology, i.e., the geometry of blood samples as a whole, contains informative features to remedy typical MIL issues, such as vanishing gradients and overfitting when training on limited data. We thus develop a topology-based approach that extracts multi-scale topological features from bags of single red blood cell images. The topological features are used to regularize the model, enforcing the preservation of characteristic topological properties of the data. Applied to a dataset of 71 patients suffering from rare anemia disorders with 521 microscopic images of red blood cells, our experiments show that topological regularization is an effective method that leads to more than 3% performance improvements for the automated classification of rare anemia disorders based on single-cell images. This is the first approach that uses topological properties for regularizing the MIL process.","sentences":["Diagnosing rare anemia disorders using microscopic images is challenging for skilled specialists and machine-learning methods alike.","Due to thousands of disease-relevant cells in a single blood sample, this constitutes a complex multiple-instance learning (MIL) problem.","While the spatial neighborhood of red blood cells is not meaningful per se, the topology, i.e., the geometry of blood samples as a whole, contains informative features to remedy typical MIL issues, such as vanishing gradients and overfitting when training on limited data.","We thus develop a topology-based approach that extracts multi-scale topological features from bags of single red blood cell images.","The topological features are used to regularize the model, enforcing the preservation of characteristic topological properties of the data.","Applied to a dataset of 71 patients suffering from rare anemia disorders with 521 microscopic images of red blood cells, our experiments show that topological regularization is an effective method that leads to more than 3% performance improvements for the automated classification of rare anemia disorders based on single-cell images.","This is the first approach that uses topological properties for regularizing the MIL process."],"url":"http://arxiv.org/abs/2307.14025v1"}
{"created":"2023-07-26 08:08:05","title":"Multi-view Hypergraph Contrastive Policy Learning for Conversational Recommendation","abstract":"Conversational recommendation systems (CRS) aim to interactively acquire user preferences and accordingly recommend items to users. Accurately learning the dynamic user preferences is of crucial importance for CRS. Previous works learn the user preferences with pairwise relations from the interactive conversation and item knowledge, while largely ignoring the fact that factors for a relationship in CRS are multiplex. Specifically, the user likes/dislikes the items that satisfy some attributes (Like/Dislike view). Moreover social influence is another important factor that affects user preference towards the item (Social view), while is largely ignored by previous works in CRS. The user preferences from these three views are inherently different but also correlated as a whole. The user preferences from the same views should be more similar than that from different views. The user preferences from Like View should be similar to Social View while different from Dislike View. To this end, we propose a novel model, namely Multi-view Hypergraph Contrastive Policy Learning (MHCPL). Specifically, MHCPL timely chooses useful social information according to the interactive history and builds a dynamic hypergraph with three types of multiplex relations from different views. The multiplex relations in each view are successively connected according to their generation order.","sentences":["Conversational recommendation systems (CRS) aim to interactively acquire user preferences and accordingly recommend items to users.","Accurately learning the dynamic user preferences is of crucial importance for CRS.","Previous works learn the user preferences with pairwise relations from the interactive conversation and item knowledge, while largely ignoring the fact that factors for a relationship in CRS are multiplex.","Specifically, the user likes/dislikes the items that satisfy some attributes (Like/Dislike view).","Moreover social influence is another important factor that affects user preference towards the item (Social view), while is largely ignored by previous works in CRS.","The user preferences from these three views are inherently different but also correlated as a whole.","The user preferences from the same views should be more similar than that from different views.","The user preferences from Like View should be similar to Social View while different from Dislike View.","To this end, we propose a novel model, namely Multi-view Hypergraph Contrastive Policy Learning (MHCPL).","Specifically, MHCPL timely chooses useful social information according to the interactive history and builds a dynamic hypergraph with three types of multiplex relations from different views.","The multiplex relations in each view are successively connected according to their generation order."],"url":"http://arxiv.org/abs/2307.14024v1"}
{"created":"2023-07-26 08:07:37","title":"Are Transformers with One Layer Self-Attention Using Low-Rank Weight Matrices Universal Approximators?","abstract":"Existing analyses of the expressive capacity of Transformer models have required excessively deep layers for data memorization, leading to a discrepancy with the Transformers actually used in practice. This is primarily due to the interpretation of the softmax function as an approximation of the hardmax function. By clarifying the connection between the softmax function and the Boltzmann operator, we prove that a single layer of self-attention with low-rank weight matrices possesses the capability to perfectly capture the context of an entire input sequence. As a consequence, we show that single-layer Transformer has a memorization capacity for finite samples, and that Transformers consisting of one self-attention layer with two feed-forward neural networks are universal approximators for continuous functions on a compact domain.","sentences":["Existing analyses of the expressive capacity of Transformer models have required excessively deep layers for data memorization, leading to a discrepancy with the Transformers actually used in practice.","This is primarily due to the interpretation of the softmax function as an approximation of the hardmax function.","By clarifying the connection between the softmax function and the Boltzmann operator, we prove that a single layer of self-attention with low-rank weight matrices possesses the capability to perfectly capture the context of an entire input sequence.","As a consequence, we show that single-layer Transformer has a memorization capacity for finite samples, and that Transformers consisting of one self-attention layer with two feed-forward neural networks are universal approximators for continuous functions on a compact domain."],"url":"http://arxiv.org/abs/2307.14023v1"}
{"created":"2023-07-26 08:06:40","title":"Retinotopy Inspired Brain Encoding Model and the All-for-One Training Recipe","abstract":"Brain encoding models aim to predict brain voxel-wise responses to stimuli images, replicating brain signals captured by neuroimaging techniques. There is a large volume of publicly available data, but training a comprehensive brain encoding model is challenging. The main difficulties stem from a) diversity within individual brain, with functional heterogeneous brain regions; b) diversity of brains from different subjects, due to genetic and developmental differences; c) diversity of imaging modalities and processing pipelines. We use this diversity to our advantage by introducing the All-for-One training recipe, which divides the challenging one-big-model problem into multiple small models, with the small models aggregating the knowledge while preserving the distinction between the different functional regions. Agnostic of the training recipe, we use biological knowledge of the brain, specifically retinotopy, to introduce inductive bias to learn a 3D brain-to-image mapping that ensures a) each neuron knows which image regions and semantic levels to gather information, and b) no neurons are left behind in the model.   We pre-trained a brain encoding model using over one million data points from five public datasets spanning three imaging modalities. To the best of our knowledge, this is the most comprehensive brain encoding model to the date. We demonstrate the effectiveness of the pre-trained model as a drop-in replacement for commonly used vision backbone models. Furthermore, we demonstrate the application of the model to brain decoding. Code and the model checkpoint will be made available.","sentences":["Brain encoding models aim to predict brain voxel-wise responses to stimuli images, replicating brain signals captured by neuroimaging techniques.","There is a large volume of publicly available data, but training a comprehensive brain encoding model is challenging.","The main difficulties stem from a) diversity within individual brain, with functional heterogeneous brain regions; b) diversity of brains from different subjects, due to genetic and developmental differences; c) diversity of imaging modalities and processing pipelines.","We use this diversity to our advantage by introducing the All-for-One training recipe, which divides the challenging one-big-model problem into multiple small models, with the small models aggregating the knowledge while preserving the distinction between the different functional regions.","Agnostic of the training recipe, we use biological knowledge of the brain, specifically retinotopy, to introduce inductive bias to learn a 3D brain-to-image mapping that ensures a) each neuron knows which image regions and semantic levels to gather information, and b) no neurons are left behind in the model.   ","We pre-trained a brain encoding model using over one million data points from five public datasets spanning three imaging modalities.","To the best of our knowledge, this is the most comprehensive brain encoding model to the date.","We demonstrate the effectiveness of the pre-trained model as a drop-in replacement for commonly used vision backbone models.","Furthermore, we demonstrate the application of the model to brain decoding.","Code and the model checkpoint will be made available."],"url":"http://arxiv.org/abs/2307.14021v1"}
{"created":"2023-07-26 08:04:31","title":"Fabrication-Aware Strip-Decomposable Quadrilateral Meshes","abstract":"Strip-decomposable quadrilateral (SDQ) meshes, i.e., quad meshes that can be decomposed into two transversal strip networks, are vital in numerous fabrication processes; examples include woven structures, surfaces from sheets, custom rebar, or cable-net structures. However, their design is often challenging and includes tedious manual work, and there is a lack of methodologies for editing such meshes while preserving their strip decomposability. We present an interactive methodology to generate and edit SDQ meshes aligned to user-defined directions, while also incorporating desirable properties to the strips for fabrication. Our technique is based on the computation of two coupled transversal tangent direction fields, integrated into two overlapping networks of strips on the surface. As a case study, we consider the fabrication scenario of robotic non-planar 3D printing of freefrom shell surfaces and apply the presented methodology to design and fabricate non-planar print paths.","sentences":["Strip-decomposable quadrilateral (SDQ) meshes, i.e., quad meshes that can be decomposed into two transversal strip networks, are vital in numerous fabrication processes; examples include woven structures, surfaces from sheets, custom rebar, or cable-net structures.","However, their design is often challenging and includes tedious manual work, and there is a lack of methodologies for editing such meshes while preserving their strip decomposability.","We present an interactive methodology to generate and edit SDQ meshes aligned to user-defined directions, while also incorporating desirable properties to the strips for fabrication.","Our technique is based on the computation of two coupled transversal tangent direction fields, integrated into two overlapping networks of strips on the surface.","As a case study, we consider the fabrication scenario of robotic non-planar 3D printing of freefrom shell surfaces and apply the presented methodology to design and fabricate non-planar print paths."],"url":"http://arxiv.org/abs/2307.14020v1"}
{"created":"2023-07-26 08:04:01","title":"One-Nearest Neighborhood Guides Inlier Estimation for Unsupervised Point Cloud Registration","abstract":"The precision of unsupervised point cloud registration methods is typically limited by the lack of reliable inlier estimation and self-supervised signal, especially in partially overlapping scenarios. In this paper, we propose an effective inlier estimation method for unsupervised point cloud registration by capturing geometric structure consistency between the source point cloud and its corresponding reference point cloud copy. Specifically, to obtain a high quality reference point cloud copy, an One-Nearest Neighborhood (1-NN) point cloud is generated by input point cloud. This facilitates matching map construction and allows for integrating dual neighborhood matching scores of 1-NN point cloud and input point cloud to improve matching confidence. Benefiting from the high quality reference copy, we argue that the neighborhood graph formed by inlier and its neighborhood should have consistency between source point cloud and its corresponding reference copy. Based on this observation, we construct transformation-invariant geometric structure representations and capture geometric structure consistency to score the inlier confidence for estimated correspondences between source point cloud and its reference copy. This strategy can simultaneously provide the reliable self-supervised signal for model optimization. Finally, we further calculate transformation estimation by the weighted SVD algorithm with the estimated correspondences and corresponding inlier confidence. We train the proposed model in an unsupervised manner, and extensive experiments on synthetic and real-world datasets illustrate the effectiveness of the proposed method.","sentences":["The precision of unsupervised point cloud registration methods is typically limited by the lack of reliable inlier estimation and self-supervised signal, especially in partially overlapping scenarios.","In this paper, we propose an effective inlier estimation method for unsupervised point cloud registration by capturing geometric structure consistency between the source point cloud and its corresponding reference point cloud copy.","Specifically, to obtain a high quality reference point cloud copy, an One-Nearest Neighborhood (1-NN) point cloud is generated by input point cloud.","This facilitates matching map construction and allows for integrating dual neighborhood matching scores of 1-NN point cloud and input point cloud to improve matching confidence.","Benefiting from the high quality reference copy, we argue that the neighborhood graph formed by inlier and its neighborhood should have consistency between source point cloud and its corresponding reference copy.","Based on this observation, we construct transformation-invariant geometric structure representations and capture geometric structure consistency to score the inlier confidence for estimated correspondences between source point cloud and its reference copy.","This strategy can simultaneously provide the reliable self-supervised signal for model optimization.","Finally, we further calculate transformation estimation by the weighted SVD algorithm with the estimated correspondences and corresponding inlier confidence.","We train the proposed model in an unsupervised manner, and extensive experiments on synthetic and real-world datasets illustrate the effectiveness of the proposed method."],"url":"http://arxiv.org/abs/2307.14019v1"}
{"created":"2023-07-26 07:57:56","title":"RPG-Palm: Realistic Pseudo-data Generation for Palmprint Recognition","abstract":"Palmprint recently shows great potential in recognition applications as it is a privacy-friendly and stable biometric. However, the lack of large-scale public palmprint datasets limits further research and development of palmprint recognition. In this paper, we propose a novel realistic pseudo-palmprint generation (RPG) model to synthesize palmprints with massive identities. We first introduce a conditional modulation generator to improve the intra-class diversity. Then an identity-aware loss is proposed to ensure identity consistency against unpaired training. We further improve the B\\'ezier palm creases generation strategy to guarantee identity independence. Extensive experimental results demonstrate that synthetic pretraining significantly boosts the recognition model performance. For example, our model improves the state-of-the-art B\\'ezierPalm by more than $5\\%$ and $14\\%$ in terms of TAR@FAR=1e-6 under the $1:1$ and $1:3$ Open-set protocol. When accessing only $10\\%$ of the real training data, our method still outperforms ArcFace with $100\\%$ real training data, indicating that we are closer to real-data-free palmprint recognition.","sentences":["Palmprint recently shows great potential in recognition applications as it is a privacy-friendly and stable biometric.","However, the lack of large-scale public palmprint datasets limits further research and development of palmprint recognition.","In this paper, we propose a novel realistic pseudo-palmprint generation (RPG) model to synthesize palmprints with massive identities.","We first introduce a conditional modulation generator to improve the intra-class diversity.","Then an identity-aware loss is proposed to ensure identity consistency against unpaired training.","We further improve the B\\'ezier palm creases generation strategy to guarantee identity independence.","Extensive experimental results demonstrate that synthetic pretraining significantly boosts the recognition model performance.","For example, our model improves the state-of-the-art B\\'ezierPalm by more than $5\\%$ and $14\\%$ in terms of TAR@FAR=1e-6 under the $1:1$ and $1:3$ Open-set protocol.","When accessing only $10\\%$ of the real training data, our method still outperforms ArcFace with $100\\%$ real training data, indicating that we are closer to real-data-free palmprint recognition."],"url":"http://arxiv.org/abs/2307.14016v1"}
{"created":"2023-07-26 07:45:14","title":"ESSAformer: Efficient Transformer for Hyperspectral Image Super-resolution","abstract":"Single hyperspectral image super-resolution (single-HSI-SR) aims to restore a high-resolution hyperspectral image from a low-resolution observation. However, the prevailing CNN-based approaches have shown limitations in building long-range dependencies and capturing interaction information between spectral features. This results in inadequate utilization of spectral information and artifacts after upsampling. To address this issue, we propose ESSAformer, an ESSA attention-embedded Transformer network for single-HSI-SR with an iterative refining structure. Specifically, we first introduce a robust and spectral-friendly similarity metric, \\ie, the spectral correlation coefficient of the spectrum (SCC), to replace the original attention matrix and incorporates inductive biases into the model to facilitate training. Built upon it, we further utilize the kernelizable attention technique with theoretical support to form a novel efficient SCC-kernel-based self-attention (ESSA) and reduce attention computation to linear complexity. ESSA enlarges the receptive field for features after upsampling without bringing much computation and allows the model to effectively utilize spatial-spectral information from different scales, resulting in the generation of more natural high-resolution images. Without the need for pretraining on large-scale datasets, our experiments demonstrate ESSA's effectiveness in both visual quality and quantitative results.","sentences":["Single hyperspectral image super-resolution (single-HSI-SR) aims to restore a high-resolution hyperspectral image from a low-resolution observation.","However, the prevailing CNN-based approaches have shown limitations in building long-range dependencies and capturing interaction information between spectral features.","This results in inadequate utilization of spectral information and artifacts after upsampling.","To address this issue, we propose ESSAformer, an ESSA attention-embedded Transformer network for single-HSI-SR with an iterative refining structure.","Specifically, we first introduce a robust and spectral-friendly similarity metric, \\ie, the spectral correlation coefficient of the spectrum (SCC), to replace the original attention matrix and incorporates inductive biases into the model to facilitate training.","Built upon it, we further utilize the kernelizable attention technique with theoretical support to form a novel efficient SCC-kernel-based self-attention (ESSA) and reduce attention computation to linear complexity.","ESSA enlarges the receptive field for features after upsampling without bringing much computation and allows the model to effectively utilize spatial-spectral information from different scales, resulting in the generation of more natural high-resolution images.","Without the need for pretraining on large-scale datasets, our experiments demonstrate ESSA's effectiveness in both visual quality and quantitative results."],"url":"http://arxiv.org/abs/2307.14010v1"}
{"created":"2023-07-26 07:44:34","title":"Car-Studio: Learning Car Radiance Fields from Single-View and Endless In-the-wild Images","abstract":"Compositional neural scene graph studies have shown that radiance fields can be an efficient tool in an editable autonomous driving simulator. However, previous studies learned within a sequence of autonomous driving datasets, resulting in unsatisfactory blurring when rotating the car in the simulator. In this letter, we propose a pipeline for learning unconstrained images and building a dataset from processed images. To meet the requirements of the simulator, which demands that the vehicle maintain clarity when the perspective changes and that the contour remains sharp from the background to avoid artifacts when editing, we design a radiation field of the vehicle, a crucial part of the urban scene foreground. Through experiments, we demonstrate that our model achieves competitive performance compared to baselines. Using the datasets built from in-the-wild images, our method gradually presents a controllable appearance editing function. We will release the dataset and code on https://lty2226262.github.io/car-studio/ to facilitate further research in the field.","sentences":["Compositional neural scene graph studies have shown that radiance fields can be an efficient tool in an editable autonomous driving simulator.","However, previous studies learned within a sequence of autonomous driving datasets, resulting in unsatisfactory blurring when rotating the car in the simulator.","In this letter, we propose a pipeline for learning unconstrained images and building a dataset from processed images.","To meet the requirements of the simulator, which demands that the vehicle maintain clarity when the perspective changes and that the contour remains sharp from the background to avoid artifacts when editing, we design a radiation field of the vehicle, a crucial part of the urban scene foreground.","Through experiments, we demonstrate that our model achieves competitive performance compared to baselines.","Using the datasets built from in-the-wild images, our method gradually presents a controllable appearance editing function.","We will release the dataset and code on https://lty2226262.github.io/car-studio/ to facilitate further research in the field."],"url":"http://arxiv.org/abs/2307.14009v1"}
{"created":"2023-07-26 07:42:28","title":"Adaptive Frequency Filters As Efficient Global Token Mixers","abstract":"Recent vision transformers, large-kernel CNNs and MLPs have attained remarkable successes in broad vision tasks thanks to their effective information fusion in the global scope. However, their efficient deployments, especially on mobile devices, still suffer from noteworthy challenges due to the heavy computational costs of self-attention mechanisms, large kernels, or fully connected layers. In this work, we apply conventional convolution theorem to deep learning for addressing this and reveal that adaptive frequency filters can serve as efficient global token mixers. With this insight, we propose Adaptive Frequency Filtering (AFF) token mixer. This neural operator transfers a latent representation to the frequency domain via a Fourier transform and performs semantic-adaptive frequency filtering via an elementwise multiplication, which mathematically equals to a token mixing operation in the original latent space with a dynamic convolution kernel as large as the spatial resolution of this latent representation. We take AFF token mixers as primary neural operators to build a lightweight neural network, dubbed AFFNet. Extensive experiments demonstrate the effectiveness of our proposed AFF token mixer and show that AFFNet achieve superior accuracy and efficiency trade-offs compared to other lightweight network designs on broad visual tasks, including visual recognition and dense prediction tasks.","sentences":["Recent vision transformers, large-kernel CNNs and MLPs have attained remarkable successes in broad vision tasks thanks to their effective information fusion in the global scope.","However, their efficient deployments, especially on mobile devices, still suffer from noteworthy challenges due to the heavy computational costs of self-attention mechanisms, large kernels, or fully connected layers.","In this work, we apply conventional convolution theorem to deep learning for addressing this and reveal that adaptive frequency filters can serve as efficient global token mixers.","With this insight, we propose Adaptive Frequency Filtering (AFF) token mixer.","This neural operator transfers a latent representation to the frequency domain via a Fourier transform and performs semantic-adaptive frequency filtering via an elementwise multiplication, which mathematically equals to a token mixing operation in the original latent space with a dynamic convolution kernel as large as the spatial resolution of this latent representation.","We take AFF token mixers as primary neural operators to build a lightweight neural network, dubbed AFFNet.","Extensive experiments demonstrate the effectiveness of our proposed AFF token mixer and show that AFFNet achieve superior accuracy and efficiency trade-offs compared to other lightweight network designs on broad visual tasks, including visual recognition and dense prediction tasks."],"url":"http://arxiv.org/abs/2307.14008v1"}
{"created":"2023-07-26 07:36:38","title":"Learning Snippet-to-Motion Progression for Skeleton-based Human Motion Prediction","abstract":"Existing Graph Convolutional Networks to achieve human motion prediction largely adopt a one-step scheme, which output the prediction straight from history input, failing to exploit human motion patterns. We observe that human motions have transitional patterns and can be split into snippets representative of each transition. Each snippet can be reconstructed from its starting and ending poses referred to as the transitional poses. We propose a snippet-to-motion multi-stage framework that breaks motion prediction into sub-tasks easier to accomplish. Each sub-task integrates three modules: transitional pose prediction, snippet reconstruction, and snippet-to-motion prediction. Specifically, we propose to first predict only the transitional poses. Then we use them to reconstruct the corresponding snippets, obtaining a close approximation to the true motion sequence. Finally we refine them to produce the final prediction output. To implement the network, we propose a novel unified graph modeling, which allows for direct and effective feature propagation compared to existing approaches which rely on separate space-time modeling. Extensive experiments on Human 3.6M, CMU Mocap and 3DPW datasets verify the effectiveness of our method which achieves state-of-the-art performance.","sentences":["Existing Graph Convolutional Networks to achieve human motion prediction largely adopt a one-step scheme, which output the prediction straight from history input, failing to exploit human motion patterns.","We observe that human motions have transitional patterns and can be split into snippets representative of each transition.","Each snippet can be reconstructed from its starting and ending poses referred to as the transitional poses.","We propose a snippet-to-motion multi-stage framework that breaks motion prediction into sub-tasks easier to accomplish.","Each sub-task integrates three modules: transitional pose prediction, snippet reconstruction, and snippet-to-motion prediction.","Specifically, we propose to first predict only the transitional poses.","Then we use them to reconstruct the corresponding snippets, obtaining a close approximation to the true motion sequence.","Finally we refine them to produce the final prediction output.","To implement the network, we propose a novel unified graph modeling, which allows for direct and effective feature propagation compared to existing approaches which rely on separate space-time modeling.","Extensive experiments on Human 3.6M, CMU Mocap and 3DPW datasets verify the effectiveness of our method which achieves state-of-the-art performance."],"url":"http://arxiv.org/abs/2307.14006v1"}
{"created":"2023-07-26 07:36:25","title":"Unsupervised extraction of local and global keywords from a single text","abstract":"We propose an unsupervised, corpus-independent method to extract keywords from a single text. It is based on the spatial distribution of words and the response of this distribution to a random permutation of words. As compared to existing methods (such as e.g. YAKE) our method has three advantages. First, it is significantly more effective at extracting keywords from long texts. Second, it allows inference of two types of keywords: local and global. Third, it uncovers basic themes in texts. Additionally, our method is language-independent and applies to short texts. The results are obtained via human annotators with previous knowledge of texts from our database of classical literary works (the agreement between annotators is from moderate to substantial). Our results are supported via human-independent arguments based on the average length of extracted content words and on the average number of nouns in extracted words. We discuss relations of keywords with higher-order textual features and reveal a connection between keywords and chapter divisions.","sentences":["We propose an unsupervised, corpus-independent method to extract keywords from a single text.","It is based on the spatial distribution of words and the response of this distribution to a random permutation of words.","As compared to existing methods (such as e.g. YAKE)","our method has three advantages.","First, it is significantly more effective at extracting keywords from long texts.","Second, it allows inference of two types of keywords: local and global.","Third, it uncovers basic themes in texts.","Additionally, our method is language-independent and applies to short texts.","The results are obtained via human annotators with previous knowledge of texts from our database of classical literary works (the agreement between annotators is from moderate to substantial).","Our results are supported via human-independent arguments based on the average length of extracted content words and on the average number of nouns in extracted words.","We discuss relations of keywords with higher-order textual features and reveal a connection between keywords and chapter divisions."],"url":"http://arxiv.org/abs/2307.14005v1"}
{"created":"2023-07-26 07:34:19","title":"Affective Natural Language Generation of Event Descriptions through Fine-grained Appraisal Conditions","abstract":"Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions. This is appropriate when the goal is to create explicit emotion statements (\"The kid is happy.\"). Emotions are, however, commonly communicated implicitly. For instance, the emotional interpretation of an event (\"Their dog died.\") does often not require an explicit emotion statement. In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion. They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens. We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages. (1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has. This leads to text generation that better fulfills the condition. (2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category. Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1. Further, (2) the texts with appraisal variables are longer and contain more details. This exemplifies the greater control for users.","sentences":["Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions.","This is appropriate when the goal is to create explicit emotion statements (\"The kid is happy.\").","Emotions are, however, commonly communicated implicitly.","For instance, the emotional interpretation of an event (\"Their dog died.\") does often not require an explicit emotion statement.","In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion.","They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens.","We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages.","(1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has.","This leads to text generation that better fulfills the condition.","(2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category.","Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1.","Further, (2) the texts with appraisal variables are longer and contain more details.","This exemplifies the greater control for users."],"url":"http://arxiv.org/abs/2307.14004v1"}
{"created":"2023-07-26 07:08:03","title":"Fast algorithms for k-submodular maximization subject to a matroid constraint","abstract":"In this paper, we apply a Threshold-Decreasing Algorithm to maximize $k$-submodular functions under a matroid constraint, which reduces the query complexity of the algorithm compared to the greedy algorithm with little loss in approximation ratio. We give a $(\\frac{1}{2} - \\epsilon)$-approximation algorithm for monotone $k$-submodular function maximization, and a $(\\frac{1}{3} - \\epsilon)$-approximation algorithm for non-monotone case, with complexity $O(\\frac{n(k\\cdot EO + IO)}{\\epsilon} \\log \\frac{r}{\\epsilon})$, where $r$ denotes the rank of the matroid, and $IO, EO$ denote the number of oracles to evaluate whether a subset is an independent set and to compute the function value of $f$, respectively. Since the constraint of total size can be looked as a special matroid, called uniform matroid, then we present the fast algorithm for maximizing $k$-submodular functions subject to a total size constraint as corollaries. corollaries.","sentences":["In this paper, we apply a Threshold-Decreasing Algorithm to maximize $k$-submodular functions under a matroid constraint, which reduces the query complexity of the algorithm compared to the greedy algorithm with little loss in approximation ratio.","We give a $(\\frac{1}{2} - \\epsilon)$-approximation algorithm for monotone $k$-submodular function maximization, and a $(\\frac{1}{3} - \\epsilon)$-approximation algorithm for non-monotone case, with complexity $O(\\frac{n(k\\cdot EO + IO)}{\\epsilon} \\log \\frac{r}{\\epsilon})$, where $r$ denotes the rank of the matroid, and $IO, EO$ denote the number of oracles to evaluate whether a subset is an independent set and to compute the function value of $f$, respectively.","Since the constraint of total size can be looked as a special matroid, called uniform matroid, then we present the fast algorithm for maximizing $k$-submodular functions subject to a total size constraint as corollaries.","corollaries."],"url":"http://arxiv.org/abs/2307.13996v1"}
{"created":"2023-07-26 07:07:27","title":"Take Your Pick: Enabling Effective Personalized Federated Learning within Low-dimensional Feature Space","abstract":"Personalized federated learning (PFL) is a popular framework that allows clients to have different models to address application scenarios where clients' data are in different domains. The typical model of a client in PFL features a global encoder trained by all clients to extract universal features from the raw data and personalized layers (e.g., a classifier) trained using the client's local data. Nonetheless, due to the differences between the data distributions of different clients (aka, domain gaps), the universal features produced by the global encoder largely encompass numerous components irrelevant to a certain client's local task. Some recent PFL methods address the above problem by personalizing specific parameters within the encoder. However, these methods encounter substantial challenges attributed to the high dimensionality and non-linearity of neural network parameter space. In contrast, the feature space exhibits a lower dimensionality, providing greater intuitiveness and interpretability as compared to the parameter space. To this end, we propose a novel PFL framework named FedPick. FedPick achieves PFL in the low-dimensional feature space by selecting task-relevant features adaptively for each client from the features generated by the global encoder based on its local data distribution. It presents a more accessible and interpretable implementation of PFL compared to those methods working in the parameter space. Extensive experimental results show that FedPick could effectively select task-relevant features for each client and improve model performance in cross-domain FL.","sentences":["Personalized federated learning (PFL) is a popular framework that allows clients to have different models to address application scenarios where clients' data are in different domains.","The typical model of a client in PFL features a global encoder trained by all clients to extract universal features from the raw data and personalized layers (e.g., a classifier) trained using the client's local data.","Nonetheless, due to the differences between the data distributions of different clients (aka, domain gaps), the universal features produced by the global encoder largely encompass numerous components irrelevant to a certain client's local task.","Some recent PFL methods address the above problem by personalizing specific parameters within the encoder.","However, these methods encounter substantial challenges attributed to the high dimensionality and non-linearity of neural network parameter space.","In contrast, the feature space exhibits a lower dimensionality, providing greater intuitiveness and interpretability as compared to the parameter space.","To this end, we propose a novel PFL framework named FedPick.","FedPick achieves PFL in the low-dimensional feature space by selecting task-relevant features adaptively for each client from the features generated by the global encoder based on its local data distribution.","It presents a more accessible and interpretable implementation of PFL compared to those methods working in the parameter space.","Extensive experimental results show that FedPick could effectively select task-relevant features for each client and improve model performance in cross-domain FL."],"url":"http://arxiv.org/abs/2307.13995v1"}
{"created":"2023-07-26 07:07:03","title":"BovineTalk: Machine Learning for Vocalization Analysis of Dairy Cattle under Negative Affective States","abstract":"There is a critical need to develop and validate non-invasive animal-based indicators of affective states in livestock species, in order to integrate them into on-farm assessment protocols, potentially via the use of precision livestock farming (PLF) tools. One such promising approach is the use of vocal indicators. The acoustic structure of vocalizations and their functions were extensively studied in important livestock species, such as pigs, horses, poultry and goats, yet cattle remain understudied in this context to date. Cows were shown to produce two types vocalizations: low-frequency calls (LF), produced with the mouth closed, or partially closed, for close distance contacts and open mouth emitted high-frequency calls (HF), produced for long distance communication, with the latter considered to be largely associated with negative affective states. Moreover, cattle vocalizations were shown to contain information on individuality across a wide range of contexts, both negative and positive. Nowadays, dairy cows are facing a series of negative challenges and stressors in a typical production cycle, making vocalizations during negative affective states of special interest for research. One contribution of this study is providing the largest to date pre-processed (clean from noises) dataset of lactating adult multiparous dairy cows during negative affective states induced by visual isolation challenges. Here we present two computational frameworks - deep learning based and explainable machine learning based, to classify high and low-frequency cattle calls, and individual cow voice recognition. Our models in these two frameworks reached 87.2% and 89.4% accuracy for LF and HF classification, with 68.9% and 72.5% accuracy rates for the cow individual identification, respectively.","sentences":["There is a critical need to develop and validate non-invasive animal-based indicators of affective states in livestock species, in order to integrate them into on-farm assessment protocols, potentially via the use of precision livestock farming (PLF) tools.","One such promising approach is the use of vocal indicators.","The acoustic structure of vocalizations and their functions were extensively studied in important livestock species, such as pigs, horses, poultry and goats, yet cattle remain understudied in this context to date.","Cows were shown to produce two types vocalizations: low-frequency calls (LF), produced with the mouth closed, or partially closed, for close distance contacts and open mouth emitted high-frequency calls (HF), produced for long distance communication, with the latter considered to be largely associated with negative affective states.","Moreover, cattle vocalizations were shown to contain information on individuality across a wide range of contexts, both negative and positive.","Nowadays, dairy cows are facing a series of negative challenges and stressors in a typical production cycle, making vocalizations during negative affective states of special interest for research.","One contribution of this study is providing the largest to date pre-processed (clean from noises) dataset of lactating adult multiparous dairy cows during negative affective states induced by visual isolation challenges.","Here we present two computational frameworks - deep learning based and explainable machine learning based, to classify high and low-frequency cattle calls, and individual cow voice recognition.","Our models in these two frameworks reached 87.2% and 89.4% accuracy for LF and HF classification, with 68.9% and 72.5% accuracy rates for the cow individual identification, respectively."],"url":"http://arxiv.org/abs/2307.13994v1"}
{"created":"2023-07-26 07:01:57","title":"Causal reasoning in typical computer vision tasks","abstract":"Deep learning has revolutionized the field of artificial intelligence. Based on the statistical correlations uncovered by deep learning-based methods, computer vision technology has contributed to tremendous growth in areas such as autonomous driving and robotics. Despite being the basis of deep learning, such correlation is not stable and is susceptible to uncontrolled factors. In the absence of the guidance of prior knowledge, statistical correlations can easily turn into spurious correlations and cause confounders. As a result, researchers are beginning to refine deep learning-based methods with causal theory. Causal theory models the intrinsic causal structure unaffected by data bias and is effective in avoiding spurious correlations. This paper aims to comprehensively review the existing causal methods in typical vision and vision-language tasks such as semantic segmentation, object detection, and image captioning. The advantages of causality and the approaches for building causal paradigms will be summarized. Future roadmaps are also proposed, including facilitating the development of causal theory and its application in other complex scenes and systems.","sentences":["Deep learning has revolutionized the field of artificial intelligence.","Based on the statistical correlations uncovered by deep learning-based methods, computer vision technology has contributed to tremendous growth in areas such as autonomous driving and robotics.","Despite being the basis of deep learning, such correlation is not stable and is susceptible to uncontrolled factors.","In the absence of the guidance of prior knowledge, statistical correlations can easily turn into spurious correlations and cause confounders.","As a result, researchers are beginning to refine deep learning-based methods with causal theory.","Causal theory models the intrinsic causal structure unaffected by data bias and is effective in avoiding spurious correlations.","This paper aims to comprehensively review the existing causal methods in typical vision and vision-language tasks such as semantic segmentation, object detection, and image captioning.","The advantages of causality and the approaches for building causal paradigms will be summarized.","Future roadmaps are also proposed, including facilitating the development of causal theory and its application in other complex scenes and systems."],"url":"http://arxiv.org/abs/2307.13992v1"}
{"created":"2023-07-26 06:58:19","title":"METAVerse: Meta-Learning Traversability Cost Map for Off-Road Navigation","abstract":"Autonomous navigation in off-road conditions requires an accurate estimation of terrain traversability. However, traversability estimation in unstructured environments is subject to high uncertainty due to the variability of numerous factors that influence vehicle-terrain interaction. Consequently, it is challenging to obtain a generalizable model that can accurately predict traversability in a variety of environments. This paper presents METAVerse, a meta-learning framework for learning a global model that accurately and reliably predicts terrain traversability across diverse environments. We train the traversability prediction network to generate a dense and continuous-valued cost map from a sparse LiDAR point cloud, leveraging vehicle-terrain interaction feedback in a self-supervised manner. Meta-learning is utilized to train a global model with driving data collected from multiple environments, effectively minimizing estimation uncertainty. During deployment, online adaptation is performed to rapidly adapt the network to the local environment by exploiting recent interaction experiences. To conduct a comprehensive evaluation, we collect driving data from various terrains and demonstrate that our method can obtain a global model that minimizes uncertainty. Moreover, by integrating our model with a model predictive controller, we demonstrate that the reduced uncertainty results in safe and stable navigation in unstructured and unknown terrains.","sentences":["Autonomous navigation in off-road conditions requires an accurate estimation of terrain traversability.","However, traversability estimation in unstructured environments is subject to high uncertainty due to the variability of numerous factors that influence vehicle-terrain interaction.","Consequently, it is challenging to obtain a generalizable model that can accurately predict traversability in a variety of environments.","This paper presents METAVerse, a meta-learning framework for learning a global model that accurately and reliably predicts terrain traversability across diverse environments.","We train the traversability prediction network to generate a dense and continuous-valued cost map from a sparse LiDAR point cloud, leveraging vehicle-terrain interaction feedback in a self-supervised manner.","Meta-learning is utilized to train a global model with driving data collected from multiple environments, effectively minimizing estimation uncertainty.","During deployment, online adaptation is performed to rapidly adapt the network to the local environment by exploiting recent interaction experiences.","To conduct a comprehensive evaluation, we collect driving data from various terrains and demonstrate that our method can obtain a global model that minimizes uncertainty.","Moreover, by integrating our model with a model predictive controller, we demonstrate that the reduced uncertainty results in safe and stable navigation in unstructured and unknown terrains."],"url":"http://arxiv.org/abs/2307.13991v1"}
{"created":"2023-07-26 06:54:31","title":"This is not correct! Negation-aware Evaluation of Language Generation Systems","abstract":"Large language models underestimate the impact of negations on how much they change the meaning of a sentence. Therefore, learned evaluation metrics based on these models are insensitive to negations. In this paper, we propose NegBLEURT, a negation-aware version of the BLEURT evaluation metric. For that, we designed a rule-based sentence negation tool and used it to create the CANNOT negation evaluation dataset. Based on this dataset, we fine-tuned a sentence transformer and an evaluation metric to improve their negation sensitivity. Evaluating these models on existing benchmarks shows that our fine-tuned models outperform existing metrics on the negated sentences by far while preserving their base models' performances on other perturbations.","sentences":["Large language models underestimate the impact of negations on how much they change the meaning of a sentence.","Therefore, learned evaluation metrics based on these models are insensitive to negations.","In this paper, we propose NegBLEURT, a negation-aware version of the BLEURT evaluation metric.","For that, we designed a rule-based sentence negation tool and used it to create the CANNOT negation evaluation dataset.","Based on this dataset, we fine-tuned a sentence transformer and an evaluation metric to improve their negation sensitivity.","Evaluating these models on existing benchmarks shows that our fine-tuned models outperform existing metrics on the negated sentences by far while preserving their base models' performances on other perturbations."],"url":"http://arxiv.org/abs/2307.13989v1"}
{"created":"2023-07-26 06:52:53","title":"Distributed Computing of Functions of Structured Sources with Helper Side Information","abstract":"In this work, we consider the problem of distributed computing of functions of structured sources, focusing on the classical setting of two correlated sources and one user that seeks the outcome of the function while benefiting from low-rate side information provided by a helper node. Focusing on the case where the sources are jointly distributed according to a very general mixture model, we here provide an achievable coding scheme that manages to substantially reduce the communication cost of distributed computing by exploiting the nature of the joint distribution of the sources, the side information, as well as the symmetry enjoyed by the desired functions. Our scheme -- which can readily apply in a variety of real-life scenarios including learning, combinatorics, and graph neural network applications -- is here shown to provide substantial reductions in the communication costs, while simultaneously providing computational savings by reducing the exponential complexity of joint decoding techniques to a complexity that is merely linear.","sentences":["In this work, we consider the problem of distributed computing of functions of structured sources, focusing on the classical setting of two correlated sources and one user that seeks the outcome of the function while benefiting from low-rate side information provided by a helper node.","Focusing on the case where the sources are jointly distributed according to a very general mixture model, we here provide an achievable coding scheme that manages to substantially reduce the communication cost of distributed computing by exploiting the nature of the joint distribution of the sources, the side information, as well as the symmetry enjoyed by the desired functions.","Our scheme -- which can readily apply in a variety of real-life scenarios including learning, combinatorics, and graph neural network applications -- is here shown to provide substantial reductions in the communication costs, while simultaneously providing computational savings by reducing the exponential complexity of joint decoding techniques to a complexity that is merely linear."],"url":"http://arxiv.org/abs/2307.13987v1"}
{"created":"2023-07-26 06:50:58","title":"Enhanced Security against Adversarial Examples Using a Random Ensemble of Encrypted Vision Transformer Models","abstract":"Deep neural networks (DNNs) are well known to be vulnerable to adversarial examples (AEs). In addition, AEs have adversarial transferability, which means AEs generated for a source model can fool another black-box model (target model) with a non-trivial probability. In previous studies, it was confirmed that the vision transformer (ViT) is more robust against the property of adversarial transferability than convolutional neural network (CNN) models such as ConvMixer, and moreover encrypted ViT is more robust than ViT without any encryption. In this article, we propose a random ensemble of encrypted ViT models to achieve much more robust models. In experiments, the proposed scheme is verified to be more robust against not only black-box attacks but also white-box ones than convention methods.","sentences":["Deep neural networks (DNNs) are well known to be vulnerable to adversarial examples (AEs).","In addition, AEs have adversarial transferability, which means AEs generated for a source model can fool another black-box model (target model) with a non-trivial probability.","In previous studies, it was confirmed that the vision transformer (ViT) is more robust against the property of adversarial transferability than convolutional neural network (CNN) models such as ConvMixer, and moreover encrypted ViT is more robust than ViT without any encryption.","In this article, we propose a random ensemble of encrypted ViT models to achieve much more robust models.","In experiments, the proposed scheme is verified to be more robust against not only black-box attacks but also white-box ones than convention methods."],"url":"http://arxiv.org/abs/2307.13985v1"}
{"created":"2023-07-26 06:38:33","title":"Analysis of Video Quality Datasets via Design of Minimalistic Video Quality Models","abstract":"Blind video quality assessment (BVQA) plays an indispensable role in monitoring and improving the end-users' viewing experience in various real-world video-enabled media applications. As an experimental field, the improvements of BVQA models have been measured primarily on a few human-rated VQA datasets. Thus, it is crucial to gain a better understanding of existing VQA datasets in order to properly evaluate the current progress in BVQA. Towards this goal, we conduct a first-of-its-kind computational analysis of VQA datasets via designing minimalistic BVQA models. By minimalistic, we restrict our family of BVQA models to build only upon basic blocks: a video preprocessor (for aggressive spatiotemporal downsampling), a spatial quality analyzer, an optional temporal quality analyzer, and a quality regressor, all with the simplest possible instantiations. By comparing the quality prediction performance of different model variants on eight VQA datasets with realistic distortions, we find that nearly all datasets suffer from the easy dataset problem of varying severity, some of which even admit blind image quality assessment (BIQA) solutions. We additionally justify our claims by contrasting our model generalizability on these VQA datasets, and by ablating a dizzying set of BVQA design choices related to the basic building blocks. Our results cast doubt on the current progress in BVQA, and meanwhile shed light on good practices of constructing next-generation VQA datasets and models.","sentences":["Blind video quality assessment (BVQA) plays an indispensable role in monitoring and improving the end-users' viewing experience in various real-world video-enabled media applications.","As an experimental field, the improvements of BVQA models have been measured primarily on a few human-rated VQA datasets.","Thus, it is crucial to gain a better understanding of existing VQA datasets in order to properly evaluate the current progress in BVQA.","Towards this goal, we conduct a first-of-its-kind computational analysis of VQA datasets via designing minimalistic BVQA models.","By minimalistic, we restrict our family of BVQA models to build only upon basic blocks: a video preprocessor (for aggressive spatiotemporal downsampling), a spatial quality analyzer, an optional temporal quality analyzer, and a quality regressor, all with the simplest possible instantiations.","By comparing the quality prediction performance of different model variants on eight VQA datasets with realistic distortions, we find that nearly all datasets suffer from the easy dataset problem of varying severity, some of which even admit blind image quality assessment (BIQA) solutions.","We additionally justify our claims by contrasting our model generalizability on these VQA datasets, and by ablating a dizzying set of BVQA design choices related to the basic building blocks.","Our results cast doubt on the current progress in BVQA, and meanwhile shed light on good practices of constructing next-generation VQA datasets and models."],"url":"http://arxiv.org/abs/2307.13981v1"}
{"created":"2023-07-26 06:34:24","title":"Controlling the Latent Space of GANs through Reinforcement Learning: A Case Study on Task-based Image-to-Image Translation","abstract":"Generative Adversarial Networks (GAN) have emerged as a formidable AI tool to generate realistic outputs based on training datasets. However, the challenge of exerting control over the generation process of GANs remains a significant hurdle. In this paper, we propose a novel methodology to address this issue by integrating a reinforcement learning (RL) agent with a latent-space GAN (l-GAN), thereby facilitating the generation of desired outputs. More specifically, we have developed an actor-critic RL agent with a meticulously designed reward policy, enabling it to acquire proficiency in navigating the latent space of the l-GAN and generating outputs based on specified tasks. To substantiate the efficacy of our approach, we have conducted a series of experiments employing the MNIST dataset, including arithmetic addition as an illustrative task. The outcomes of these experiments serve to validate our methodology. Our pioneering integration of an RL agent with a GAN model represents a novel advancement, holding great potential for enhancing generative networks in the future.","sentences":["Generative Adversarial Networks (GAN) have emerged as a formidable AI tool to generate realistic outputs based on training datasets.","However, the challenge of exerting control over the generation process of GANs remains a significant hurdle.","In this paper, we propose a novel methodology to address this issue by integrating a reinforcement learning (RL) agent with a latent-space GAN (l-GAN), thereby facilitating the generation of desired outputs.","More specifically, we have developed an actor-critic RL agent with a meticulously designed reward policy, enabling it to acquire proficiency in navigating the latent space of the l-GAN and generating outputs based on specified tasks.","To substantiate the efficacy of our approach, we have conducted a series of experiments employing the MNIST dataset, including arithmetic addition as an illustrative task.","The outcomes of these experiments serve to validate our methodology.","Our pioneering integration of an RL agent with a GAN model represents a novel advancement, holding great potential for enhancing generative networks in the future."],"url":"http://arxiv.org/abs/2307.13978v1"}
{"created":"2023-07-26 06:29:57","title":"Formal Verification of Robotic Contact Tasks via Reachability Analysis","abstract":"Verifying the correct behavior of robots in contact tasks is challenging due to model uncertainties associated with contacts. Standard methods for testing often fall short since all (uncountable many) solutions cannot be obtained. Instead, we propose to formally and efficiently verify robot behaviors in contact tasks using reachability analysis, which enables checking all the reachable states against user-provided specifications. To this end, we extend the state of the art in reachability analysis for hybrid (mixed discrete and continuous) dynamics subject to discrete-time input trajectories. In particular, we present a novel and scalable guard intersection approach to reliably compute the complex behavior caused by contacts. We model robots subject to contacts as hybrid automata in which crucial time delays are included. The usefulness of our approach is demonstrated by verifying safe human-robot interaction in the presence of constrained collisions, which was out of reach for existing methods.","sentences":["Verifying the correct behavior of robots in contact tasks is challenging due to model uncertainties associated with contacts.","Standard methods for testing often fall short since all (uncountable many) solutions cannot be obtained.","Instead, we propose to formally and efficiently verify robot behaviors in contact tasks using reachability analysis, which enables checking all the reachable states against user-provided specifications.","To this end, we extend the state of the art in reachability analysis for hybrid (mixed discrete and continuous) dynamics subject to discrete-time input trajectories.","In particular, we present a novel and scalable guard intersection approach to reliably compute the complex behavior caused by contacts.","We model robots subject to contacts as hybrid automata in which crucial time delays are included.","The usefulness of our approach is demonstrated by verifying safe human-robot interaction in the presence of constrained collisions, which was out of reach for existing methods."],"url":"http://arxiv.org/abs/2307.13977v1"}
{"created":"2023-07-26 06:19:46","title":"Tracking Anything in High Quality","abstract":"Visual object tracking is a fundamental video task in computer vision. Recently, the notably increasing power of perception algorithms allows the unification of single/multiobject and box/mask-based tracking. Among them, the Segment Anything Model (SAM) attracts much attention. In this report, we propose HQTrack, a framework for High Quality Tracking anything in videos. HQTrack mainly consists of a video multi-object segmenter (VMOS) and a mask refiner (MR). Given the object to be tracked in the initial frame of a video, VMOS propagates the object masks to the current frame. The mask results at this stage are not accurate enough since VMOS is trained on several closeset video object segmentation (VOS) datasets, which has limited ability to generalize to complex and corner scenes. To further improve the quality of tracking masks, a pretrained MR model is employed to refine the tracking results. As a compelling testament to the effectiveness of our paradigm, without employing any tricks such as test-time data augmentations and model ensemble, HQTrack ranks the 2nd place in the Visual Object Tracking and Segmentation (VOTS2023) challenge. Code and models are available at https://github.com/jiawen-zhu/HQTrack.","sentences":["Visual object tracking is a fundamental video task in computer vision.","Recently, the notably increasing power of perception algorithms allows the unification of single/multiobject and box/mask-based tracking.","Among them, the Segment Anything Model (SAM) attracts much attention.","In this report, we propose HQTrack, a framework for High Quality Tracking anything in videos.","HQTrack mainly consists of a video multi-object segmenter (VMOS) and a mask refiner (MR).","Given the object to be tracked in the initial frame of a video, VMOS propagates the object masks to the current frame.","The mask results at this stage are not accurate enough since VMOS is trained on several closeset video object segmentation (VOS) datasets, which has limited ability to generalize to complex and corner scenes.","To further improve the quality of tracking masks, a pretrained MR model is employed to refine the tracking results.","As a compelling testament to the effectiveness of our paradigm, without employing any tricks such as test-time data augmentations and model ensemble, HQTrack ranks the 2nd place in the Visual Object Tracking and Segmentation (VOTS2023) challenge.","Code and models are available at https://github.com/jiawen-zhu/HQTrack."],"url":"http://arxiv.org/abs/2307.13974v1"}
{"created":"2023-07-26 05:29:29","title":"Understanding Deep Neural Networks via Linear Separability of Hidden Layers","abstract":"In this paper, we measure the linear separability of hidden layer outputs to study the characteristics of deep neural networks. In particular, we first propose Minkowski difference based linear separability measures (MD-LSMs) to evaluate the linear separability degree of two points sets. Then, we demonstrate that there is a synchronicity between the linear separability degree of hidden layer outputs and the network training performance, i.e., if the updated weights can enhance the linear separability degree of hidden layer outputs, the updated network will achieve a better training performance, and vice versa. Moreover, we study the effect of activation function and network size (including width and depth) on the linear separability of hidden layers. Finally, we conduct the numerical experiments to validate our findings on some popular deep networks including multilayer perceptron (MLP), convolutional neural network (CNN), deep belief network (DBN), ResNet, VGGNet, AlexNet, vision transformer (ViT) and GoogLeNet.","sentences":["In this paper, we measure the linear separability of hidden layer outputs to study the characteristics of deep neural networks.","In particular, we first propose Minkowski difference based linear separability measures (MD-LSMs) to evaluate the linear separability degree of two points sets.","Then, we demonstrate that there is a synchronicity between the linear separability degree of hidden layer outputs and the network training performance, i.e., if the updated weights can enhance the linear separability degree of hidden layer outputs, the updated network will achieve a better training performance, and vice versa.","Moreover, we study the effect of activation function and network size (including width and depth) on the linear separability of hidden layers.","Finally, we conduct the numerical experiments to validate our findings on some popular deep networks including multilayer perceptron (MLP), convolutional neural network (CNN), deep belief network (DBN), ResNet, VGGNet, AlexNet, vision transformer (ViT) and GoogLeNet."],"url":"http://arxiv.org/abs/2307.13962v1"}
{"created":"2023-07-26 05:06:41","title":"Visual Prompt Flexible-Modal Face Anti-Spoofing","abstract":"Recently, vision transformer based multimodal learning methods have been proposed to improve the robustness of face anti-spoofing (FAS) systems. However, multimodal face data collected from the real world is often imperfect due to missing modalities from various imaging sensors. Recently, flexible-modal FAS~\\cite{yu2023flexible} has attracted more attention, which aims to develop a unified multimodal FAS model using complete multimodal face data but is insensitive to test-time missing modalities. In this paper, we tackle one main challenge in flexible-modal FAS, i.e., when missing modality occurs either during training or testing in real-world situations. Inspired by the recent success of the prompt learning in language models, we propose \\textbf{V}isual \\textbf{P}rompt flexible-modal \\textbf{FAS} (VP-FAS), which learns the modal-relevant prompts to adapt the frozen pre-trained foundation model to downstream flexible-modal FAS task. Specifically, both vanilla visual prompts and residual contextual prompts are plugged into multimodal transformers to handle general missing-modality cases, while only requiring less than 4\\% learnable parameters compared to training the entire model. Furthermore, missing-modality regularization is proposed to force models to learn consistent multimodal feature embeddings when missing partial modalities. Extensive experiments conducted on two multimodal FAS benchmark datasets demonstrate the effectiveness of our VP-FAS framework that improves the performance under various missing-modality cases while alleviating the requirement of heavy model re-training.","sentences":["Recently, vision transformer based multimodal learning methods have been proposed to improve the robustness of face anti-spoofing (FAS) systems.","However, multimodal face data collected from the real world is often imperfect due to missing modalities from various imaging sensors.","Recently, flexible-modal FAS~\\cite{yu2023flexible} has attracted more attention, which aims to develop a unified multimodal FAS model using complete multimodal face data but is insensitive to test-time missing modalities.","In this paper, we tackle one main challenge in flexible-modal FAS, i.e., when missing modality occurs either during training or testing in real-world situations.","Inspired by the recent success of the prompt learning in language models, we propose \\textbf{V}isual \\textbf{P}rompt flexible-modal \\textbf{FAS} (VP-FAS), which learns the modal-relevant prompts to adapt the frozen pre-trained foundation model to downstream flexible-modal FAS task.","Specifically, both vanilla visual prompts and residual contextual prompts are plugged into multimodal transformers to handle general missing-modality cases, while only requiring less than 4\\% learnable parameters compared to training the entire model.","Furthermore, missing-modality regularization is proposed to force models to learn consistent multimodal feature embeddings when missing partial modalities.","Extensive experiments conducted on two multimodal FAS benchmark datasets demonstrate the effectiveness of our VP-FAS framework that improves the performance under various missing-modality cases while alleviating the requirement of heavy model re-training."],"url":"http://arxiv.org/abs/2307.13958v1"}
{"created":"2023-07-26 04:33:05","title":"Heterogeneous Embodied Multi-Agent Collaboration","abstract":"Multi-agent embodied tasks have recently been studied in complex indoor visual environments. Collaboration among multiple agents can improve work efficiency and has significant practical value. However, most of the existing research focuses on homogeneous multi-agent tasks. Compared with homogeneous agents, heterogeneous agents can leverage their different capabilities to allocate corresponding sub-tasks and cooperate to complete complex tasks. Heterogeneous multi-agent tasks are common in real-world scenarios, and the collaboration strategy among heterogeneous agents is a challenging and important problem to be solved. To study collaboration among heterogeneous agents, we propose the heterogeneous multi-agent tidying-up task, in which multiple heterogeneous agents with different capabilities collaborate with each other to detect misplaced objects and place them in reasonable locations. This is a demanding task since it requires agents to make the best use of their different capabilities to conduct reasonable task planning and complete the whole task. To solve this task, we build a heterogeneous multi-agent tidying-up benchmark dataset in a large number of houses with multiple rooms based on ProcTHOR-10K. We propose the hierarchical decision model based on misplaced object detection, reasonable receptacle prediction, as well as the handshake-based group communication mechanism. Extensive experiments are conducted to demonstrate the effectiveness of the proposed model. The project's website and videos of experiments can be found at https://hetercol.github.io/.","sentences":["Multi-agent embodied tasks have recently been studied in complex indoor visual environments.","Collaboration among multiple agents can improve work efficiency and has significant practical value.","However, most of the existing research focuses on homogeneous multi-agent tasks.","Compared with homogeneous agents, heterogeneous agents can leverage their different capabilities to allocate corresponding sub-tasks and cooperate to complete complex tasks.","Heterogeneous multi-agent tasks are common in real-world scenarios, and the collaboration strategy among heterogeneous agents is a challenging and important problem to be solved.","To study collaboration among heterogeneous agents, we propose the heterogeneous multi-agent tidying-up task, in which multiple heterogeneous agents with different capabilities collaborate with each other to detect misplaced objects and place them in reasonable locations.","This is a demanding task since it requires agents to make the best use of their different capabilities to conduct reasonable task planning and complete the whole task.","To solve this task, we build a heterogeneous multi-agent tidying-up benchmark dataset in a large number of houses with multiple rooms based on ProcTHOR-10K.","We propose the hierarchical decision model based on misplaced object detection, reasonable receptacle prediction, as well as the handshake-based group communication mechanism.","Extensive experiments are conducted to demonstrate the effectiveness of the proposed model.","The project's website and videos of experiments can be found at https://hetercol.github.io/."],"url":"http://arxiv.org/abs/2307.13957v1"}
{"created":"2023-07-26 04:08:12","title":"The Hidden Dance of Phonemes and Visage: Unveiling the Enigmatic Link between Phonemes and Facial Features","abstract":"This work unveils the enigmatic link between phonemes and facial features. Traditional studies on voice-face correlations typically involve using a long period of voice input, including generating face images from voices and reconstructing 3D face meshes from voices. However, in situations like voice-based crimes, the available voice evidence may be short and limited. Additionally, from a physiological perspective, each segment of speech -- phoneme -- corresponds to different types of airflow and movements in the face. Therefore, it is advantageous to discover the hidden link between phonemes and face attributes. In this paper, we propose an analysis pipeline to help us explore the voice-face relationship in a fine-grained manner, i.e., phonemes v.s. facial anthropometric measurements (AM). We build an estimator for each phoneme-AM pair and evaluate the correlation through hypothesis testing. Our results indicate that AMs are more predictable from vowels compared to consonants, particularly with plosives. Additionally, we observe that if a specific AM exhibits more movement during phoneme pronunciation, it is more predictable. Our findings support those in physiology regarding correlation and lay the groundwork for future research on speech-face multimodal learning.","sentences":["This work unveils the enigmatic link between phonemes and facial features.","Traditional studies on voice-face correlations typically involve using a long period of voice input, including generating face images from voices and reconstructing 3D face meshes from voices.","However, in situations like voice-based crimes, the available voice evidence may be short and limited.","Additionally, from a physiological perspective, each segment of speech -- phoneme -- corresponds to different types of airflow and movements in the face.","Therefore, it is advantageous to discover the hidden link between phonemes and face attributes.","In this paper, we propose an analysis pipeline to help us explore the voice-face relationship in a fine-grained manner, i.e., phonemes v.s. facial anthropometric measurements (AM).","We build an estimator for each phoneme-AM pair and evaluate the correlation through hypothesis testing.","Our results indicate that AMs are more predictable from vowels compared to consonants, particularly with plosives.","Additionally, we observe that if a specific AM exhibits more movement during phoneme pronunciation, it is more predictable.","Our findings support those in physiology regarding correlation and lay the groundwork for future research on speech-face multimodal learning."],"url":"http://arxiv.org/abs/2307.13953v1"}
{"created":"2023-07-26 04:06:55","title":"Security Weaknesses in IoT Management Platforms","abstract":"A diverse set of Internet of Things (IoT) devices are becoming an integrated part of daily lives, and playing an increasingly vital role in various industry, enterprise and agricultural settings. The current IoT ecosystem relies on several IoT management platforms to manage and operate a large number of IoT devices, their data, and their connectivity. Considering their key role, these platforms must be properly secured against cyber attacks. In this work, we first explore the core operations/features of leading platforms to design a framework to perform a systematic security evaluation of these platforms. Subsequently, we use our framework to analyze a representative set of 52 IoT management platforms, including 42 web-hosted and 10 locally-deployable platforms. We discover a number of high severity unauthorized access vulnerabilities in 9/52 evaluated IoT management platforms, which could be abused to perform attacks such as remote IoT SIM deactivation, IoT SIM overcharging and IoT device data forgery. More seriously, we also uncover instances of broken authentication in 13/52 platforms, including complete account takeover on 8/52 platforms along with remote code execution on 2/52 platforms. In effect, 17/52 platforms were affected by vulnerabilities that could lead to platform-wide attacks. Overall, vulnerabilities were uncovered in 33 platforms, out of which 28 platforms responded to our responsible disclosure. We were also assigned 11 CVEs and awarded bounty for our findings.","sentences":["A diverse set of Internet of Things (IoT) devices are becoming an integrated part of daily lives, and playing an increasingly vital role in various industry, enterprise and agricultural settings.","The current IoT ecosystem relies on several IoT management platforms to manage and operate a large number of IoT devices, their data, and their connectivity.","Considering their key role, these platforms must be properly secured against cyber attacks.","In this work, we first explore the core operations/features of leading platforms to design a framework to perform a systematic security evaluation of these platforms.","Subsequently, we use our framework to analyze a representative set of 52 IoT management platforms, including 42 web-hosted and 10 locally-deployable platforms.","We discover a number of high severity unauthorized access vulnerabilities in 9/52 evaluated IoT management platforms, which could be abused to perform attacks such as remote IoT SIM deactivation, IoT SIM overcharging and IoT device data forgery.","More seriously, we also uncover instances of broken authentication in 13/52 platforms, including complete account takeover on 8/52 platforms along with remote code execution on 2/52 platforms.","In effect, 17/52 platforms were affected by vulnerabilities that could lead to platform-wide attacks.","Overall, vulnerabilities were uncovered in 33 platforms, out of which 28 platforms responded to our responsible disclosure.","We were also assigned 11 CVEs and awarded bounty for our findings."],"url":"http://arxiv.org/abs/2307.13952v1"}
{"created":"2023-07-26 04:04:14","title":"Deep Robust Multi-Robot Re-localisation in Natural Environments","abstract":"The success of re-localisation has crucial implications for the practical deployment of robots operating within a prior map or relative to one another in real-world scenarios. Using single-modality, place recognition and localisation can be compromised in challenging environments such as forests. To address this, we propose a strategy to prevent lidar-based re-localisation failure using lidar-image cross-modality. Our solution relies on self-supervised 2D-3D feature matching to predict alignment and misalignment. Leveraging a deep network for lidar feature extraction and relative pose estimation between point clouds, we train a model to evaluate the estimated transformation. A model predicting the presence of misalignment is learned by analysing image-lidar similarity in the embedding space and the geometric constraints available within the region seen in both modalities in Euclidean space. Experimental results using real datasets (offline and online modes) demonstrate the effectiveness of the proposed pipeline for robust re-localisation in unstructured, natural environments.","sentences":["The success of re-localisation has crucial implications for the practical deployment of robots operating within a prior map or relative to one another in real-world scenarios.","Using single-modality, place recognition and localisation can be compromised in challenging environments such as forests.","To address this, we propose a strategy to prevent lidar-based re-localisation failure using lidar-image cross-modality.","Our solution relies on self-supervised 2D-3D feature matching to predict alignment and misalignment.","Leveraging a deep network for lidar feature extraction and relative pose estimation between point clouds, we train a model to evaluate the estimated transformation.","A model predicting the presence of misalignment is learned by analysing image-lidar similarity in the embedding space and the geometric constraints available within the region seen in both modalities in Euclidean space.","Experimental results using real datasets (offline and online modes) demonstrate the effectiveness of the proposed pipeline for robust re-localisation in unstructured, natural environments."],"url":"http://arxiv.org/abs/2307.13950v1"}
{"created":"2023-07-26 04:03:25","title":"How Does Diffusion Influence Pretrained Language Models on Out-of-Distribution Data?","abstract":"Transformer-based pretrained language models (PLMs) have achieved great success in modern NLP. An important advantage of PLMs is good out-of-distribution (OOD) robustness. Recently, diffusion models have attracted a lot of work to apply diffusion to PLMs. It remains under-explored how diffusion influences PLMs on OOD data. The core of diffusion models is a forward diffusion process which gradually applies Gaussian noise to inputs, and a reverse denoising process which removes noise. The noised input reconstruction is a fundamental ability of diffusion models. We directly analyze OOD robustness by measuring the reconstruction loss, including testing the abilities to reconstruct OOD data, and to detect OOD samples. Experiments are conducted by analyzing different training parameters and data statistical features on eight datasets. It shows that finetuning PLMs with diffusion degrades the reconstruction ability on OOD data. The comparison also shows that diffusion models can effectively detect OOD samples, achieving state-of-the-art performance in most of the datasets with an absolute accuracy improvement up to 18%. These results indicate that diffusion reduces OOD robustness of PLMs.","sentences":["Transformer-based pretrained language models (PLMs) have achieved great success in modern NLP.","An important advantage of PLMs is good out-of-distribution (OOD) robustness.","Recently, diffusion models have attracted a lot of work to apply diffusion to PLMs.","It remains under-explored how diffusion influences PLMs on OOD data.","The core of diffusion models is a forward diffusion process which gradually applies Gaussian noise to inputs, and a reverse denoising process which removes noise.","The noised input reconstruction is a fundamental ability of diffusion models.","We directly analyze OOD robustness by measuring the reconstruction loss, including testing the abilities to reconstruct OOD data, and to detect OOD samples.","Experiments are conducted by analyzing different training parameters and data statistical features on eight datasets.","It shows that finetuning PLMs with diffusion degrades the reconstruction ability on OOD data.","The comparison also shows that diffusion models can effectively detect OOD samples, achieving state-of-the-art performance in most of the datasets with an absolute accuracy improvement up to 18%.","These results indicate that diffusion reduces OOD robustness of PLMs."],"url":"http://arxiv.org/abs/2307.13949v1"}
{"created":"2023-07-26 04:03:10","title":"Rethinking Voice-Face Correlation: A Geometry View","abstract":"Previous works on voice-face matching and voice-guided face synthesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emotion. In this paper, we aim to investigate the capability of reconstructing the 3D facial shape from voice from a geometry perspective without any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face correlation and can serve as a good empirical study for anthropometry science.","sentences":["Previous works on voice-face matching and voice-guided face synthesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emotion.","In this paper, we aim to investigate the capability of reconstructing the 3D facial shape from voice from a geometry perspective without any semantic information.","We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction.","By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable.","Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium.","Our work offers a new perspective on voice-face correlation and can serve as a good empirical study for anthropometry science."],"url":"http://arxiv.org/abs/2307.13948v1"}
{"created":"2023-07-26 04:01:57","title":"Centroid-aware feature recalibration for cancer grading in pathology images","abstract":"Cancer grading is an essential task in pathology. The recent developments of artificial neural networks in computational pathology have shown that these methods hold great potential for improving the accuracy and quality of cancer diagnosis. However, the issues with the robustness and reliability of such methods have not been fully resolved yet. Herein, we propose a centroid-aware feature recalibration network that can conduct cancer grading in an accurate and robust manner. The proposed network maps an input pathology image into an embedding space and adjusts it by using centroids embedding vectors of different cancer grades via attention mechanism. Equipped with the recalibrated embedding vector, the proposed network classifiers the input pathology image into a pertinent class label, i.e., cancer grade. We evaluate the proposed network using colorectal cancer datasets that were collected under different environments. The experimental results confirm that the proposed network is able to conduct cancer grading in pathology images with high accuracy regardless of the environmental changes in the datasets.","sentences":["Cancer grading is an essential task in pathology.","The recent developments of artificial neural networks in computational pathology have shown that these methods hold great potential for improving the accuracy and quality of cancer diagnosis.","However, the issues with the robustness and reliability of such methods have not been fully resolved yet.","Herein, we propose a centroid-aware feature recalibration network that can conduct cancer grading in an accurate and robust manner.","The proposed network maps an input pathology image into an embedding space and adjusts it by using centroids embedding vectors of different cancer grades via attention mechanism.","Equipped with the recalibrated embedding vector, the proposed network classifiers the input pathology image into a pertinent class label, i.e., cancer grade.","We evaluate the proposed network using colorectal cancer datasets that were collected under different environments.","The experimental results confirm that the proposed network is able to conduct cancer grading in pathology images with high accuracy regardless of the environmental changes in the datasets."],"url":"http://arxiv.org/abs/2307.13947v1"}
{"created":"2023-07-26 03:55:08","title":"Entropy Neural Estimation for Graph Contrastive Learning","abstract":"Contrastive learning on graphs aims at extracting distinguishable high-level representations of nodes. In this paper, we theoretically illustrate that the entropy of a dataset can be approximated by maximizing the lower bound of the mutual information across different views of a graph, \\ie, entropy is estimated by a neural network. Based on this finding, we propose a simple yet effective subset sampling strategy to contrast pairwise representations between views of a dataset. In particular, we randomly sample nodes and edges from a given graph to build the input subset for a view. Two views are fed into a parameter-shared Siamese network to extract the high-dimensional embeddings and estimate the information entropy of the entire graph. For the learning process, we propose to optimize the network using two objectives, simultaneously. Concretely, the input of the contrastive loss function consists of positive and negative pairs. Our selection strategy of pairs is different from previous works and we present a novel strategy to enhance the representation ability of the graph encoder by selecting nodes based on cross-view similarities. We enrich the diversity of the positive and negative pairs by selecting highly similar samples and totally different data with the guidance of cross-view similarity scores, respectively. We also introduce a cross-view consistency constraint on the representations generated from the different views. This objective guarantees the learned representations are consistent across views from the perspective of the entire graph. We conduct extensive experiments on seven graph benchmarks, and the proposed approach achieves competitive performance compared to the current state-of-the-art methods. The source code will be publicly released once this paper is accepted.","sentences":["Contrastive learning on graphs aims at extracting distinguishable high-level representations of nodes.","In this paper, we theoretically illustrate that the entropy of a dataset can be approximated by maximizing the lower bound of the mutual information across different views of a graph, \\ie, entropy is estimated by a neural network.","Based on this finding, we propose a simple yet effective subset sampling strategy to contrast pairwise representations between views of a dataset.","In particular, we randomly sample nodes and edges from a given graph to build the input subset for a view.","Two views are fed into a parameter-shared Siamese network to extract the high-dimensional embeddings and estimate the information entropy of the entire graph.","For the learning process, we propose to optimize the network using two objectives, simultaneously.","Concretely, the input of the contrastive loss function consists of positive and negative pairs.","Our selection strategy of pairs is different from previous works and we present a novel strategy to enhance the representation ability of the graph encoder by selecting nodes based on cross-view similarities.","We enrich the diversity of the positive and negative pairs by selecting highly similar samples and totally different data with the guidance of cross-view similarity scores, respectively.","We also introduce a cross-view consistency constraint on the representations generated from the different views.","This objective guarantees the learned representations are consistent across views from the perspective of the entire graph.","We conduct extensive experiments on seven graph benchmarks, and the proposed approach achieves competitive performance compared to the current state-of-the-art methods.","The source code will be publicly released once this paper is accepted."],"url":"http://arxiv.org/abs/2307.13944v1"}
{"created":"2023-07-26 03:48:37","title":"Topology-aware Robust Optimization for Out-of-distribution Generalization","abstract":"Out-of-distribution (OOD) generalization is a challenging machine learning problem yet highly desirable in many high-stake applications. Existing methods suffer from overly pessimistic modeling with low generalization confidence. As generalizing to arbitrary test distributions is impossible, we hypothesize that further structure on the topology of distributions is crucial in developing strong OOD resilience. To this end, we propose topology-aware robust optimization (TRO) that seamlessly integrates distributional topology in a principled optimization framework. More specifically, TRO solves two optimization objectives: (1) Topology Learning which explores data manifold to uncover the distributional topology; (2) Learning on Topology which exploits the topology to constrain robust optimization for tightly-bounded generalization risks. We theoretically demonstrate the effectiveness of our approach and empirically show that it significantly outperforms the state of the arts in a wide range of tasks including classification, regression, and semantic segmentation. Moreover, we empirically find the data-driven distributional topology is consistent with domain knowledge, enhancing the explainability of our approach.","sentences":["Out-of-distribution (OOD) generalization is a challenging machine learning problem yet highly desirable in many high-stake applications.","Existing methods suffer from overly pessimistic modeling with low generalization confidence.","As generalizing to arbitrary test distributions is impossible, we hypothesize that further structure on the topology of distributions is crucial in developing strong OOD resilience.","To this end, we propose topology-aware robust optimization (TRO) that seamlessly integrates distributional topology in a principled optimization framework.","More specifically, TRO solves two optimization objectives: (1) Topology Learning which explores data manifold to uncover the distributional topology; (2) Learning on Topology which exploits the topology to constrain robust optimization for tightly-bounded generalization risks.","We theoretically demonstrate the effectiveness of our approach and empirically show that it significantly outperforms the state of the arts in a wide range of tasks including classification, regression, and semantic segmentation.","Moreover, we empirically find the data-driven distributional topology is consistent with domain knowledge, enhancing the explainability of our approach."],"url":"http://arxiv.org/abs/2307.13943v1"}
{"created":"2023-07-26 03:38:51","title":"The Weighted Euler Characteristic Transform for Image Shape Classification","abstract":"The weighted Euler characteristic transform (WECT) is a new tool for extracting shape information from data equipped with a weight function. Image data may benefit from the WECT where the intensity of the pixels are used to define the weight function. In this work, an empirical assessment of the WECT's ability to distinguish shapes on images with different pixel intensity distributions is considered, along with visualization techniques to improve the intuition and understanding of what is captured by the WECT. Additionally, the expected weighted Euler characteristic and the expected WECT are derived.","sentences":["The weighted Euler characteristic transform (WECT) is a new tool for extracting shape information from data equipped with a weight function.","Image data may benefit from the WECT where the intensity of the pixels are used to define the weight function.","In this work, an empirical assessment of the WECT's ability to distinguish shapes on images with different pixel intensity distributions is considered, along with visualization techniques to improve the intuition and understanding of what is captured by the WECT.","Additionally, the expected weighted Euler characteristic and the expected WECT are derived."],"url":"http://arxiv.org/abs/2307.13940v1"}
{"created":"2023-07-26 03:30:28","title":"Improving Semi-Supervised Semantic Segmentation with Dual-Level Siamese Structure Network","abstract":"Semi-supervised semantic segmentation (SSS) is an important task that utilizes both labeled and unlabeled data to reduce expenses on labeling training examples. However, the effectiveness of SSS algorithms is limited by the difficulty of fully exploiting the potential of unlabeled data. To address this, we propose a dual-level Siamese structure network (DSSN) for pixel-wise contrastive learning. By aligning positive pairs with a pixel-wise contrastive loss using strong augmented views in both low-level image space and high-level feature space, the proposed DSSN is designed to maximize the utilization of available unlabeled data. Additionally, we introduce a novel class-aware pseudo-label selection strategy for weak-to-strong supervision, which addresses the limitations of most existing methods that do not perform selection or apply a predefined threshold for all classes. Specifically, our strategy selects the top high-confidence prediction of the weak view for each class to generate pseudo labels that supervise the strong augmented views. This strategy is capable of taking into account the class imbalance and improving the performance of long-tailed classes. Our proposed method achieves state-of-the-art results on two datasets, PASCAL VOC 2012 and Cityscapes, outperforming other SSS algorithms by a significant margin.","sentences":["Semi-supervised semantic segmentation (SSS) is an important task that utilizes both labeled and unlabeled data to reduce expenses on labeling training examples.","However, the effectiveness of SSS algorithms is limited by the difficulty of fully exploiting the potential of unlabeled data.","To address this, we propose a dual-level Siamese structure network (DSSN) for pixel-wise contrastive learning.","By aligning positive pairs with a pixel-wise contrastive loss using strong augmented views in both low-level image space and high-level feature space, the proposed DSSN is designed to maximize the utilization of available unlabeled data.","Additionally, we introduce a novel class-aware pseudo-label selection strategy for weak-to-strong supervision, which addresses the limitations of most existing methods that do not perform selection or apply a predefined threshold for all classes.","Specifically, our strategy selects the top high-confidence prediction of the weak view for each class to generate pseudo labels that supervise the strong augmented views.","This strategy is capable of taking into account the class imbalance and improving the performance of long-tailed classes.","Our proposed method achieves state-of-the-art results on two datasets, PASCAL VOC 2012 and Cityscapes, outperforming other SSS algorithms by a significant margin."],"url":"http://arxiv.org/abs/2307.13938v1"}
{"created":"2023-07-26 03:22:32","title":"On Minimizing Generalized Makespan on Unrelated Machines","abstract":"We consider the Generalized Makespan Problem (GMP) on unrelated machines, where we are given $n$ jobs and $m$ machines and each job $j$ has arbitrary processing time $p_{ij}$ on machine $i$. Additionally, there is a general symmetric monotone norm $\\psi_i$ for each machine $i$, that determines the load on machine $i$ as a function of the sizes of jobs assigned to it. The goal is to assign the jobs to minimize the maximum machine load.   Recently, Deng, Li, and Rabani (SODA'22) gave a $3$ approximation for GMP when the $\\psi_i$ are top-$k$ norms, and they ask the question whether an $O(1)$ approximation exists for general norms $\\psi$? We answer this negatively and show that, under natural complexity assumptions, there is some fixed constant $\\delta>0$, such that GMP is $\\Omega(\\log^{\\delta} n)$ hard to approximate. We also give an $\\Omega(\\log^{1/2} n)$ integrality gap for the natural configuration LP.","sentences":["We consider the Generalized Makespan Problem (GMP) on unrelated machines, where we are given $n$ jobs and $m$ machines and each job $j$ has arbitrary processing time $p_{ij}$ on machine $i$. Additionally, there is a general symmetric monotone norm $\\psi_i$ for each machine $i$, that determines the load on machine $i$ as a function of the sizes of jobs assigned to it.","The goal is to assign the jobs to minimize the maximum machine load.   ","Recently, Deng, Li, and Rabani (SODA'22) gave a $3$ approximation for GMP when the $\\psi_i$ are top-$k$ norms, and they ask the question whether an $O(1)$ approximation exists for general norms $\\psi$?","We answer this negatively and show that, under natural complexity assumptions, there is some fixed constant $\\delta>0$, such that GMP is $\\Omega(\\log^{\\delta} n)$ hard to approximate.","We also give an $\\Omega(\\log^{1/2} n)$ integrality gap for the natural configuration LP."],"url":"http://arxiv.org/abs/2307.13937v1"}
{"created":"2023-07-26 03:12:05","title":"AIDE: A Vision-Driven Multi-View, Multi-Modal, Multi-Tasking Dataset for Assistive Driving Perception","abstract":"Driver distraction has become a significant cause of severe traffic accidents over the past decade. Despite the growing development of vision-driven driver monitoring systems, the lack of comprehensive perception datasets restricts road safety and traffic security. In this paper, we present an AssIstive Driving pErception dataset (AIDE) that considers context information both inside and outside the vehicle in naturalistic scenarios. AIDE facilitates holistic driver monitoring through three distinctive characteristics, including multi-view settings of driver and scene, multi-modal annotations of face, body, posture, and gesture, and four pragmatic task designs for driving understanding. To thoroughly explore AIDE, we provide experimental benchmarks on three kinds of baseline frameworks via extensive methods. Moreover, two fusion strategies are introduced to give new insights into learning effective multi-stream/modal representations. We also systematically investigate the importance and rationality of the key components in AIDE and benchmarks. The project link is https://github.com/ydk122024/AIDE.","sentences":["Driver distraction has become a significant cause of severe traffic accidents over the past decade.","Despite the growing development of vision-driven driver monitoring systems, the lack of comprehensive perception datasets restricts road safety and traffic security.","In this paper, we present an AssIstive Driving pErception dataset (AIDE) that considers context information both inside and outside the vehicle in naturalistic scenarios.","AIDE facilitates holistic driver monitoring through three distinctive characteristics, including multi-view settings of driver and scene, multi-modal annotations of face, body, posture, and gesture, and four pragmatic task designs for driving understanding.","To thoroughly explore AIDE, we provide experimental benchmarks on three kinds of baseline frameworks via extensive methods.","Moreover, two fusion strategies are introduced to give new insights into learning effective multi-stream/modal representations.","We also systematically investigate the importance and rationality of the key components in AIDE and benchmarks.","The project link is https://github.com/ydk122024/AIDE."],"url":"http://arxiv.org/abs/2307.13933v1"}
{"created":"2023-07-26 03:00:31","title":"Spatio-Temporal Domain Awareness for Multi-Agent Collaborative Perception","abstract":"Multi-agent collaborative perception as a potential application for vehicle-to-everything communication could significantly improve the perception performance of autonomous vehicles over single-agent perception. However, several challenges remain in achieving pragmatic information sharing in this emerging research. In this paper, we propose SCOPE, a novel collaborative perception framework that aggregates the spatio-temporal awareness characteristics across on-road agents in an end-to-end manner. Specifically, SCOPE has three distinct strengths: i) it considers effective semantic cues of the temporal context to enhance current representations of the target agent; ii) it aggregates perceptually critical spatial information from heterogeneous agents and overcomes localization errors via multi-scale feature interactions; iii) it integrates multi-source representations of the target agent based on their complementary contributions by an adaptive fusion paradigm. To thoroughly evaluate SCOPE, we consider both real-world and simulated scenarios of collaborative 3D object detection tasks on three datasets. Extensive experiments demonstrate the superiority of our approach and the necessity of the proposed components.","sentences":["Multi-agent collaborative perception as a potential application for vehicle-to-everything communication could significantly improve the perception performance of autonomous vehicles over single-agent perception.","However, several challenges remain in achieving pragmatic information sharing in this emerging research.","In this paper, we propose SCOPE, a novel collaborative perception framework that aggregates the spatio-temporal awareness characteristics across on-road agents in an end-to-end manner.","Specifically, SCOPE has three distinct strengths: i) it considers effective semantic cues of the temporal context to enhance current representations of the target agent; ii) it aggregates perceptually critical spatial information from heterogeneous agents and overcomes localization errors via multi-scale feature interactions; iii) it integrates multi-source representations of the target agent based on their complementary contributions by an adaptive fusion paradigm.","To thoroughly evaluate SCOPE, we consider both real-world and simulated scenarios of collaborative 3D object detection tasks on three datasets.","Extensive experiments demonstrate the superiority of our approach and the necessity of the proposed components."],"url":"http://arxiv.org/abs/2307.13929v1"}
{"created":"2023-07-26 02:55:33","title":"Beyond Strict Competition: Approximate Convergence of Multi Agent Q-Learning Dynamics","abstract":"The behaviour of multi-agent learning in competitive settings is often considered under the restrictive assumption of a zero-sum game. Only under this strict requirement is the behaviour of learning well understood; beyond this, learning dynamics can often display non-convergent behaviours which prevent fixed-point analysis. Nonetheless, many relevant competitive games do not satisfy the zero-sum assumption.   Motivated by this, we study a smooth variant of Q-Learning, a popular reinforcement learning dynamics which balances the agents' tendency to maximise their payoffs with their propensity to explore the state space. We examine this dynamic in games which are `close' to network zero-sum games and find that Q-Learning converges to a neighbourhood around a unique equilibrium. The size of the neighbourhood is determined by the `distance' to the zero-sum game, as well as the exploration rates of the agents. We complement these results by providing a method whereby, given an arbitrary network game, the `nearest' network zero-sum game can be found efficiently. As our experiments show, these guarantees are independent of whether the dynamics ultimately reach an equilibrium, or remain non-convergent.","sentences":["The behaviour of multi-agent learning in competitive settings is often considered under the restrictive assumption of a zero-sum game.","Only under this strict requirement is the behaviour of learning well understood; beyond this, learning dynamics can often display non-convergent behaviours which prevent fixed-point analysis.","Nonetheless, many relevant competitive games do not satisfy the zero-sum assumption.   ","Motivated by this, we study a smooth variant of Q-Learning, a popular reinforcement learning dynamics which balances the agents' tendency to maximise their payoffs with their propensity to explore the state space.","We examine this dynamic in games which are `close' to network zero-sum games and find that Q-Learning converges to a neighbourhood around a unique equilibrium.","The size of the neighbourhood is determined by the `distance' to the zero-sum game, as well as the exploration rates of the agents.","We complement these results by providing a method whereby, given an arbitrary network game, the `nearest' network zero-sum game can be found efficiently.","As our experiments show, these guarantees are independent of whether the dynamics ultimately reach an equilibrium, or remain non-convergent."],"url":"http://arxiv.org/abs/2307.13928v1"}
{"created":"2023-07-26 02:53:29","title":"DFR-Net: Density Feature Refinement Network for Image Dehazing Utilizing Haze Density Difference","abstract":"In image dehazing task, haze density is a key feature and affects the performance of dehazing methods. However, some of the existing methods lack a comparative image to measure densities, and others create intermediate results but lack the exploitation of their density differences, which can facilitate perception of density. To address these deficiencies, we propose a density-aware dehazing method named Density Feature Refinement Network (DFR-Net) that extracts haze density features from density differences and leverages density differences to refine density features. In DFR-Net, we first generate a proposal image that has lower overall density than the hazy input, bringing in global density differences. Additionally, the dehazing residual of the proposal image reflects the level of dehazing performance and provides local density differences that indicate localized hard dehazing or high density areas. Subsequently, we introduce a Global Branch (GB) and a Local Branch (LB) to achieve density-awareness. In GB, we use Siamese networks for feature extraction of hazy inputs and proposal images, and we propose a Global Density Feature Refinement (GDFR) module that can refine features by pushing features with different global densities further away. In LB, we explore local density features from the dehazing residuals between hazy inputs and proposal images and introduce an Intermediate Dehazing Residual Feedforward (IDRF) module to update local features and pull them closer to clear image features. Sufficient experiments demonstrate that the proposed method achieves results beyond the state-of-the-art methods on various datasets.","sentences":["In image dehazing task, haze density is a key feature and affects the performance of dehazing methods.","However, some of the existing methods lack a comparative image to measure densities, and others create intermediate results but lack the exploitation of their density differences, which can facilitate perception of density.","To address these deficiencies, we propose a density-aware dehazing method named Density Feature Refinement Network (DFR-Net) that extracts haze density features from density differences and leverages density differences to refine density features.","In DFR-Net, we first generate a proposal image that has lower overall density than the hazy input, bringing in global density differences.","Additionally, the dehazing residual of the proposal image reflects the level of dehazing performance and provides local density differences that indicate localized hard dehazing or high density areas.","Subsequently, we introduce a Global Branch (GB) and a Local Branch (LB) to achieve density-awareness.","In GB, we use Siamese networks for feature extraction of hazy inputs and proposal images, and we propose a Global Density Feature Refinement (GDFR) module that can refine features by pushing features with different global densities further away.","In LB, we explore local density features from the dehazing residuals between hazy inputs and proposal images and introduce an Intermediate Dehazing Residual Feedforward (IDRF) module to update local features and pull them closer to clear image features.","Sufficient experiments demonstrate that the proposed method achieves results beyond the state-of-the-art methods on various datasets."],"url":"http://arxiv.org/abs/2307.13927v1"}
{"created":"2023-07-26 02:47:15","title":"Fourier Growth of Communication Protocols for XOR Functions","abstract":"The level-$k$ $\\ell_1$-Fourier weight of a Boolean function refers to the sum of absolute values of its level-$k$ Fourier coefficients. Fourier growth refers to the growth of these weights as $k$ grows. It has been extensively studied for various computational models, and bounds on the Fourier growth, even for the first few levels, have proven useful in learning theory, circuit lower bounds, pseudorandomness, and quantum-classical separations.   We investigate the Fourier growth of certain functions that naturally arise from communication protocols for XOR functions (partial functions evaluated on the bitwise XOR of the inputs to Alice and Bob). If a protocol $\\mathcal C$ computes an XOR function, then $\\mathcal C(x,y)$ is a function of the parity $x\\oplus y$. This motivates us to analyze the XOR-fiber of $\\mathcal C$, defined as $h(z):=\\mathbb E_{x,y}[\\mathcal C(x,y)|x\\oplus y=z]$.   We present improved Fourier growth bounds for the XOR-fibers of protocols that communicate $d$ bits. For the first level, we show a tight $O(\\sqrt d)$ bound and obtain a new coin theorem, as well as an alternative proof for the tight randomized communication lower bound for Gap-Hamming. For the second level, we show an $d^{3/2}\\cdot\\mathrm{polylog}(n)$ bound, which improves the previous $O(d^2)$ bound by Girish, Raz, and Tal (ITCS 2021) and implies a polynomial improvement on the randomized communication lower bound for the XOR-lift of Forrelation, extending its quantum-classical gap.   Our analysis is based on a new way of adaptively partitioning a relatively large set in Gaussian space to control its moments in all directions. We achieve this via martingale arguments and allowing protocols to transmit real values. We also show a connection between Fourier growth and lifting theorems with constant-sized gadgets as a potential approach to prove optimal bounds for the second level and beyond.","sentences":["The level-$k$ $\\ell_1$-Fourier weight of a Boolean function refers to the sum of absolute values of its level-$k$ Fourier coefficients.","Fourier growth refers to the growth of these weights as $k$ grows.","It has been extensively studied for various computational models, and bounds on the Fourier growth, even for the first few levels, have proven useful in learning theory, circuit lower bounds, pseudorandomness, and quantum-classical separations.   ","We investigate the Fourier growth of certain functions that naturally arise from communication protocols for XOR functions (partial functions evaluated on the bitwise XOR of the inputs to Alice and Bob).","If a protocol $\\mathcal C$ computes an XOR function, then $\\mathcal C(x,y)$ is a function of the parity $x\\oplus y$.","This motivates us to analyze the XOR-fiber of $\\mathcal C$, defined as $h(z):=\\mathbb E_{x,y}[\\mathcal C(x,y)|x\\oplus y=z]$.   We present improved Fourier growth bounds for the XOR-fibers of protocols that communicate $d$ bits.","For the first level, we show a tight $O(\\sqrt d)$ bound and obtain a new coin theorem, as well as an alternative proof for the tight randomized communication lower bound for Gap-Hamming.","For the second level, we show an $d^{3/2}\\cdot\\mathrm{polylog}(n)$ bound, which improves the previous $O(d^2)$ bound by Girish, Raz, and Tal (ITCS 2021) and implies a polynomial improvement on the randomized communication lower bound for the XOR-lift of Forrelation, extending its quantum-classical gap.   ","Our analysis is based on a new way of adaptively partitioning a relatively large set in Gaussian space to control its moments in all directions.","We achieve this via martingale arguments and allowing protocols to transmit real values.","We also show a connection between Fourier growth and lifting theorems with constant-sized gadgets as a potential approach to prove optimal bounds for the second level and beyond."],"url":"http://arxiv.org/abs/2307.13926v1"}
{"created":"2023-07-26 02:46:50","title":"EasyNet: An Easy Network for 3D Industrial Anomaly Detection","abstract":"3D anomaly detection is an emerging and vital computer vision task in industrial manufacturing (IM). Recently many advanced algorithms have been published, but most of them cannot meet the needs of IM. There are several disadvantages: i) difficult to deploy on production lines since their algorithms heavily rely on large pre-trained models; ii) hugely increase storage overhead due to overuse of memory banks; iii) the inference speed cannot be achieved in real-time. To overcome these issues, we propose an easy and deployment-friendly network (called EasyNet) without using pre-trained models and memory banks: firstly, we design a multi-scale multi-modality feature encoder-decoder to accurately reconstruct the segmentation maps of anomalous regions and encourage the interaction between RGB images and depth images; secondly, we adopt a multi-modality anomaly segmentation network to achieve a precise anomaly map; thirdly, we propose an attention-based information entropy fusion module for feature fusion during inference, making it suitable for real-time deployment. Extensive experiments show that EasyNet achieves an anomaly detection AUROC of 92.6% without using pre-trained models and memory banks. In addition, EasyNet is faster than existing methods, with a high frame rate of 94.55 FPS on a Tesla V100 GPU.","sentences":["3D anomaly detection is an emerging and vital computer vision task in industrial manufacturing (IM).","Recently many advanced algorithms have been published, but most of them cannot meet the needs of IM.","There are several disadvantages: i) difficult to deploy on production lines since their algorithms heavily rely on large pre-trained models; ii) hugely increase storage overhead due to overuse of memory banks; iii) the inference speed cannot be achieved in real-time.","To overcome these issues, we propose an easy and deployment-friendly network (called EasyNet) without using pre-trained models and memory banks: firstly, we design a multi-scale multi-modality feature encoder-decoder to accurately reconstruct the segmentation maps of anomalous regions and encourage the interaction between RGB images and depth images; secondly, we adopt a multi-modality anomaly segmentation network to achieve a precise anomaly map; thirdly, we propose an attention-based information entropy fusion module for feature fusion during inference, making it suitable for real-time deployment.","Extensive experiments show that EasyNet achieves an anomaly detection AUROC of 92.6% without using pre-trained models and memory banks.","In addition, EasyNet is faster than existing methods, with a high frame rate of 94.55 FPS on a Tesla V100 GPU."],"url":"http://arxiv.org/abs/2307.13925v1"}
{"created":"2023-07-26 02:45:59","title":"trajdata: A Unified Interface to Multiple Human Trajectory Datasets","abstract":"The field of trajectory forecasting has grown significantly in recent years, partially owing to the release of numerous large-scale, real-world human trajectory datasets for autonomous vehicles (AVs) and pedestrian motion tracking. While such datasets have been a boon for the community, they each use custom and unique data formats and APIs, making it cumbersome for researchers to train and evaluate methods across multiple datasets. To remedy this, we present trajdata: a unified interface to multiple human trajectory datasets. At its core, trajdata provides a simple, uniform, and efficient representation and API for trajectory and map data. As a demonstration of its capabilities, in this work we conduct a comprehensive empirical evaluation of existing trajectory datasets, providing users with a rich understanding of the data underpinning much of current pedestrian and AV motion forecasting research, and proposing suggestions for future datasets from these insights. trajdata is permissively licensed (Apache 2.0) and can be accessed online at https://github.com/NVlabs/trajdata","sentences":["The field of trajectory forecasting has grown significantly in recent years, partially owing to the release of numerous large-scale, real-world human trajectory datasets for autonomous vehicles (AVs) and pedestrian motion tracking.","While such datasets have been a boon for the community, they each use custom and unique data formats and APIs, making it cumbersome for researchers to train and evaluate methods across multiple datasets.","To remedy this, we present trajdata: a unified interface to multiple human trajectory datasets.","At its core, trajdata provides a simple, uniform, and efficient representation and API for trajectory and map data.","As a demonstration of its capabilities, in this work we conduct a comprehensive empirical evaluation of existing trajectory datasets, providing users with a rich understanding of the data underpinning much of current pedestrian and AV motion forecasting research, and proposing suggestions for future datasets from these insights.","trajdata is permissively licensed (Apache 2.0) and can be accessed online at https://github.com/NVlabs/trajdata"],"url":"http://arxiv.org/abs/2307.13924v1"}
{"created":"2023-07-26 02:45:38","title":"GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning","abstract":"Grammatical error correction aims to correct ungrammatical sentences automatically. Recently, some work has demonstrated the excellent capabilities of closed-source Large Language Models (LLMs, e.g., ChatGPT) in grammatical error correction. However, the potential of open-source LLMs remains unexplored. In this paper, we introduced GrammarGPT, an open-source LLM, to preliminary explore its potential for native Chinese grammatical error correction. The core recipe of GrammarGPT is to leverage the hybrid dataset of ChatGPT-generated and human-annotated. For grammatical errors with clues, we proposed a heuristic method to guide ChatGPT to generate ungrammatical sentences by providing those clues. For grammatical errors without clues, we collected ungrammatical sentences from publicly available websites and manually corrected them. In addition, we employed an error-invariant augmentation method to enhance the ability of the model to correct native Chinese grammatical errors. We ultimately constructed about 1k parallel data and utilized these data to fine-tune open-source LLMs (e.g., Phoenix, released by The Chinese University of Hong Kong, Shenzhen) with instruction tuning. The experimental results show that GrammarGPT outperforms the existing SOTA system significantly. Although model parameters are 20x larger than the SOTA baseline, the required amount of data for instruction tuning is 1200x smaller, illustrating the potential of open-source LLMs on native CGEC. Our GrammarGPT ranks $3^{rd}$ on NLPCC2023 SharedTask1, demonstrating our approach's effectiveness. The code and data are available at \\url{https://github.com/FreedomIntelligence/GrammarGPT}.","sentences":["Grammatical error correction aims to correct ungrammatical sentences automatically.","Recently, some work has demonstrated the excellent capabilities of closed-source Large Language Models (LLMs, e.g., ChatGPT) in grammatical error correction.","However, the potential of open-source LLMs remains unexplored.","In this paper, we introduced GrammarGPT, an open-source LLM, to preliminary explore its potential for native Chinese grammatical error correction.","The core recipe of GrammarGPT is to leverage the hybrid dataset of ChatGPT-generated and human-annotated.","For grammatical errors with clues, we proposed a heuristic method to guide ChatGPT to generate ungrammatical sentences by providing those clues.","For grammatical errors without clues, we collected ungrammatical sentences from publicly available websites and manually corrected them.","In addition, we employed an error-invariant augmentation method to enhance the ability of the model to correct native Chinese grammatical errors.","We ultimately constructed about 1k parallel data and utilized these data to fine-tune open-source LLMs (e.g., Phoenix, released by The Chinese University of Hong Kong, Shenzhen) with instruction tuning.","The experimental results show that GrammarGPT outperforms the existing SOTA system significantly.","Although model parameters are 20x larger than the SOTA baseline, the required amount of data for instruction tuning is 1200x smaller, illustrating the potential of open-source LLMs on native CGEC.","Our GrammarGPT ranks $3^{rd}$ on NLPCC2023 SharedTask1, demonstrating our approach's effectiveness.","The code and data are available at \\url{https://github.com/FreedomIntelligence/GrammarGPT}."],"url":"http://arxiv.org/abs/2307.13923v1"}
{"created":"2023-07-26 02:45:02","title":"Stability of Multi-Agent Learning: Convergence in Network Games with Many Players","abstract":"The behaviour of multi-agent learning in many player games has been shown to display complex dynamics outside of restrictive examples such as network zero-sum games. In addition, it has been shown that convergent behaviour is less likely to occur as the number of players increase. To make progress in resolving this problem, we study Q-Learning dynamics and determine a sufficient condition for the dynamics to converge to a unique equilibrium in any network game. We find that this condition depends on the nature of pairwise interactions and on the network structure, but is explicitly independent of the total number of agents in the game. We evaluate this result on a number of representative network games and show that, under suitable network conditions, stable learning dynamics can be achieved with an arbitrary number of agents.","sentences":["The behaviour of multi-agent learning in many player games has been shown to display complex dynamics outside of restrictive examples such as network zero-sum games.","In addition, it has been shown that convergent behaviour is less likely to occur as the number of players increase.","To make progress in resolving this problem, we study Q-Learning dynamics and determine a sufficient condition for the dynamics to converge to a unique equilibrium in any network game.","We find that this condition depends on the nature of pairwise interactions and on the network structure, but is explicitly independent of the total number of agents in the game.","We evaluate this result on a number of representative network games and show that, under suitable network conditions, stable learning dynamics can be achieved with an arbitrary number of agents."],"url":"http://arxiv.org/abs/2307.13922v1"}
{"created":"2023-07-26 02:41:52","title":"On the hardness of finding balanced independent sets in random bipartite graphs","abstract":"We consider the algorithmic problem of finding large \\textit{balanced} independent sets in sparse random bipartite graphs, and more generally the problem of finding independent sets with specified proportions of vertices on each side of the bipartition. In a bipartite graph it is trivial to find an independent set of density at least half (take one of the partition classes). In contrast, in a random bipartite graph of average degree $d$, the largest balanced independent sets (containing equal number of vertices from each class) are typically of density $(2+o_d(1)) \\frac{\\log d}{d}$. Can we find such large balanced independent sets in these graphs efficiently? By utilizing the overlap gap property and the low-degree algorithmic framework, we prove that local and low-degree algorithms (even those that know the bipartition) cannot find balanced independent sets of density greater than $(1+\\epsilon) \\frac{\\log d}{d}$ for any $\\epsilon>0$ fixed and $d$ large but constant. This factor $2$ statistical--computational gap between what exists and what local algorithms can achieve is analogous to the gap for finding large independent sets in (non-bipartite) random graphs. Our results therefor suggest that this gap is pervasive in many models, and that hard computational problems can lurk inside otherwise tractable ones. A particularly striking aspect of the gap in bipartite graphs is that the algorithm achieving the lower bound is extremely simple and can be implemented as a $1$-local algorithm and a degree-$1$ polynomial (a linear function).","sentences":["We consider the algorithmic problem of finding large \\textit{balanced} independent sets in sparse random bipartite graphs, and more generally the problem of finding independent sets with specified proportions of vertices on each side of the bipartition.","In a bipartite graph it is trivial to find an independent set of density at least half (take one of the partition classes).","In contrast, in a random bipartite graph of average degree $d$, the largest balanced independent sets (containing equal number of vertices from each class) are typically of density $(2+o_d(1))","\\frac{\\log d}{d}$. Can we find such large balanced independent sets in these graphs efficiently?","By utilizing the overlap gap property and the low-degree algorithmic framework, we prove that local and low-degree algorithms (even those that know the bipartition) cannot find balanced independent sets of density greater than $(1+\\epsilon) \\frac{\\log d}{d}$ for any $\\epsilon>0$ fixed and $d$ large but constant.","This factor $2$ statistical--computational gap between what exists and what local algorithms can achieve is analogous to the gap for finding large independent sets in (non-bipartite) random graphs.","Our results therefor suggest that this gap is pervasive in many models, and that hard computational problems can lurk inside otherwise tractable ones.","A particularly striking aspect of the gap in bipartite graphs is that the algorithm achieving the lower bound is extremely simple and can be implemented as a $1$-local algorithm and a degree-$1$ polynomial (a linear function)."],"url":"http://arxiv.org/abs/2307.13921v1"}
{"created":"2023-07-26 02:34:13","title":"BayesDAG: Gradient-Based Posterior Sampling for Causal Discovery","abstract":"Bayesian causal discovery aims to infer the posterior distribution over causal models from observed data, quantifying epistemic uncertainty and benefiting downstream tasks. However, computational challenges arise due to joint inference over combinatorial space of Directed Acyclic Graphs (DAGs) and nonlinear functions. Despite recent progress towards efficient posterior inference over DAGs, existing methods are either limited to variational inference on node permutation matrices for linear causal models, leading to compromised inference accuracy, or continuous relaxation of adjacency matrices constrained by a DAG regularizer, which cannot ensure resulting graphs are DAGs. In this work, we introduce a scalable Bayesian causal discovery framework based on stochastic gradient Markov Chain Monte Carlo (SG-MCMC) that overcomes these limitations. Our approach directly samples DAGs from the posterior without requiring any DAG regularization, simultaneously draws function parameter samples and is applicable to both linear and nonlinear causal models. To enable our approach, we derive a novel equivalence to the permutation-based DAG learning, which opens up possibilities of using any relaxed gradient estimator defined over permutations. To our knowledge, this is the first framework applying gradient-based MCMC sampling for causal discovery. Empirical evaluations on synthetic and real-world datasets demonstrate our approach's effectiveness compared to state-of-the-art baselines.","sentences":["Bayesian causal discovery aims to infer the posterior distribution over causal models from observed data, quantifying epistemic uncertainty and benefiting downstream tasks.","However, computational challenges arise due to joint inference over combinatorial space of Directed Acyclic Graphs (DAGs) and nonlinear functions.","Despite recent progress towards efficient posterior inference over DAGs, existing methods are either limited to variational inference on node permutation matrices for linear causal models, leading to compromised inference accuracy, or continuous relaxation of adjacency matrices constrained by a DAG regularizer, which cannot ensure resulting graphs are DAGs.","In this work, we introduce a scalable Bayesian causal discovery framework based on stochastic gradient Markov Chain Monte Carlo (SG-MCMC) that overcomes these limitations.","Our approach directly samples DAGs from the posterior without requiring any DAG regularization, simultaneously draws function parameter samples and is applicable to both linear and nonlinear causal models.","To enable our approach, we derive a novel equivalence to the permutation-based DAG learning, which opens up possibilities of using any relaxed gradient estimator defined over permutations.","To our knowledge, this is the first framework applying gradient-based MCMC sampling for causal discovery.","Empirical evaluations on synthetic and real-world datasets demonstrate our approach's effectiveness compared to state-of-the-art baselines."],"url":"http://arxiv.org/abs/2307.13917v1"}
{"created":"2023-07-26 02:32:56","title":"Algoritmo Concurrente por Conjuntos de Pilas con Multiplicidad: SetStackLogic","abstract":"This article aims to describe and explain the theoretical foundations of concurrent and set concurrent algorithms, considering an asynchronous shared memory system where any number of processes can crash. Verification of concurrent algorithms is often described in terms of their progress condition, which guarantees that eventually something good will happen, also called the security of the algorithms, and correctness, which guarantees that nothing bad will happen, also called liveliness. of the algorithms. The meaning of correctness of a concurrent algorithm is explained in detail, focusing on linearizability, and a generalization is addressed, concurrency by sets; which is much more recent and less well known. The {\\it SetStackLogic} algorithm is shown, which is a set-concurrent algorithm and is also an implementation of a stack with multiplicity. The properties of the algorithm {\\it SetStackLogic} are demonstrated in a formal and detailed way, in order to present a rigorous scheme in the formalization of this type of algorithm; same that could be used for other algorithms. In addition, the operation of the algorithm is explained through scenario examples that illustrate its dynamics in some possible executions.","sentences":["This article aims to describe and explain the theoretical foundations of concurrent and set concurrent algorithms, considering an asynchronous shared memory system where any number of processes can crash.","Verification of concurrent algorithms is often described in terms of their progress condition, which guarantees that eventually something good will happen, also called the security of the algorithms, and correctness, which guarantees that nothing bad will happen, also called liveliness.","of the algorithms.","The meaning of correctness of a concurrent algorithm is explained in detail, focusing on linearizability, and a generalization is addressed, concurrency by sets; which is much more recent and less well known.","The {\\it SetStackLogic} algorithm is shown, which is a set-concurrent algorithm and is also an implementation of a stack with multiplicity.","The properties of the algorithm {\\it SetStackLogic} are demonstrated in a formal and detailed way, in order to present a rigorous scheme in the formalization of this type of algorithm; same that could be used for other algorithms.","In addition, the operation of the algorithm is explained through scenario examples that illustrate its dynamics in some possible executions."],"url":"http://arxiv.org/abs/2307.13915v1"}
{"created":"2023-07-26 02:27:24","title":"Embedding Democratic Values into Social Media AIs via Societal Objective Functions","abstract":"Can we design artificial intelligence (AI) systems that rank our social media feeds to consider democratic values such as mitigating partisan animosity as part of their objective functions? We introduce a method for translating established, vetted social scientific constructs into AI objective functions, which we term societal objective functions, and demonstrate the method with application to the political science construct of anti-democratic attitudes. Traditionally, we have lacked observable outcomes to use to train such models, however, the social sciences have developed survey instruments and qualitative codebooks for these constructs, and their precision facilitates translation into detailed prompts for large language models. We apply this method to create a democratic attitude model that estimates the extent to which a social media post promotes anti-democratic attitudes, and test this democratic attitude model across three studies. In Study 1, we first test the attitudinal and behavioral effectiveness of the intervention among US partisans (N=1,380) by manually annotating (alpha=.895) social media posts with anti-democratic attitude scores and testing several feed ranking conditions based on these scores. Removal (d=.20) and downranking feeds (d=.25) reduced participants' partisan animosity without compromising their experience and engagement. In Study 2, we scale up the manual labels by creating the democratic attitude model, finding strong agreement with manual labels (rho=.75). Finally, in Study 3, we replicate Study 1 using the democratic attitude model instead of manual labels to test its attitudinal and behavioral impact (N=558), and again find that the feed downranking using the societal objective function reduced partisan animosity (d=.25). This method presents a novel strategy to draw on social science theory and methods to mitigate societal harms in social media AIs.","sentences":["Can we design artificial intelligence (AI) systems that rank our social media feeds to consider democratic values such as mitigating partisan animosity as part of their objective functions?","We introduce a method for translating established, vetted social scientific constructs into AI objective functions, which we term societal objective functions, and demonstrate the method with application to the political science construct of anti-democratic attitudes.","Traditionally, we have lacked observable outcomes to use to train such models, however, the social sciences have developed survey instruments and qualitative codebooks for these constructs, and their precision facilitates translation into detailed prompts for large language models.","We apply this method to create a democratic attitude model that estimates the extent to which a social media post promotes anti-democratic attitudes, and test this democratic attitude model across three studies.","In Study 1, we first test the attitudinal and behavioral effectiveness of the intervention among US partisans (N=1,380) by manually annotating (alpha=.895) social media posts with anti-democratic attitude scores and testing several feed ranking conditions based on these scores.","Removal (d=.20) and downranking feeds (d=.25) reduced participants' partisan animosity without compromising their experience and engagement.","In Study 2, we scale up the manual labels by creating the democratic attitude model, finding strong agreement with manual labels (rho=.75).","Finally, in Study 3, we replicate Study 1 using the democratic attitude model instead of manual labels to test its attitudinal and behavioral impact (N=558), and again find that the feed downranking using the societal objective function reduced partisan animosity (d=.25).","This method presents a novel strategy to draw on social science theory and methods to mitigate societal harms in social media AIs."],"url":"http://arxiv.org/abs/2307.13912v1"}
{"created":"2023-07-26 02:24:23","title":"Domain Disentanglement with Interpolative Data Augmentation for Dual-Target Cross-Domain Recommendation","abstract":"The conventional single-target Cross-Domain Recommendation (CDR) aims to improve the recommendation performance on a sparser target domain by transferring the knowledge from a source domain that contains relatively richer information. By contrast, in recent years, dual-target CDR has been proposed to improve the recommendation performance on both domains simultaneously. However, to this end, there are two challenges in dual-target CDR: (1) how to generate both relevant and diverse augmented user representations, and (2) how to effectively decouple domain-independent information from domain-specific information, in addition to domain-shared information, to capture comprehensive user preferences. To address the above two challenges, we propose a Disentanglement-based framework with Interpolative Data Augmentation for dual-target Cross-Domain Recommendation, called DIDA-CDR. In DIDA-CDR, we first propose an interpolative data augmentation approach to generating both relevant and diverse augmented user representations to augment sparser domain and explore potential user preferences. We then propose a disentanglement module to effectively decouple domain-specific and domain-independent information to capture comprehensive user preferences. Both steps significantly contribute to capturing more comprehensive user preferences, thereby improving the recommendation performance on each domain. Extensive experiments conducted on five real-world datasets show the significant superiority of DIDA-CDR over the state-of-the-art methods.","sentences":["The conventional single-target Cross-Domain Recommendation (CDR) aims to improve the recommendation performance on a sparser target domain by transferring the knowledge from a source domain that contains relatively richer information.","By contrast, in recent years, dual-target CDR has been proposed to improve the recommendation performance on both domains simultaneously.","However, to this end, there are two challenges in dual-target CDR: (1) how to generate both relevant and diverse augmented user representations, and (2) how to effectively decouple domain-independent information from domain-specific information, in addition to domain-shared information, to capture comprehensive user preferences.","To address the above two challenges, we propose a Disentanglement-based framework with Interpolative Data Augmentation for dual-target Cross-Domain Recommendation, called DIDA-CDR.","In DIDA-CDR, we first propose an interpolative data augmentation approach to generating both relevant and diverse augmented user representations to augment sparser domain and explore potential user preferences.","We then propose a disentanglement module to effectively decouple domain-specific and domain-independent information to capture comprehensive user preferences.","Both steps significantly contribute to capturing more comprehensive user preferences, thereby improving the recommendation performance on each domain.","Extensive experiments conducted on five real-world datasets show the significant superiority of DIDA-CDR over the state-of-the-art methods."],"url":"http://arxiv.org/abs/2307.13910v1"}
{"created":"2023-07-26 02:18:04","title":"Graph Neural Networks-based Hybrid Framework For Predicting Particle Crushing Strength","abstract":"Graph Neural Networks have emerged as an effective machine learning tool for multi-disciplinary tasks such as pharmaceutical molecule classification and chemical reaction prediction, because they can model non-euclidean relationships between different entities. Particle crushing, as a significant field of civil engineering, describes the breakage of granular materials caused by the breakage of particle fragment bonds under the modeling of numerical simulations, which motivates us to characterize the mechanical behaviors of particle crushing through the connectivity of particle fragments with Graph Neural Networks (GNNs). However, there lacks an open-source large-scale particle crushing dataset for research due to the expensive costs of laboratory tests or numerical simulations. Therefore, we firstly generate a dataset with 45,000 numerical simulations and 900 particle types to facilitate the research progress of machine learning for particle crushing. Secondly, we devise a hybrid framework based on GNNs to predict particle crushing strength in a particle fragment view with the advances of state of the art GNNs. Finally, we compare our hybrid framework against traditional machine learning methods and the plain MLP to verify its effectiveness. The usefulness of different features is further discussed through the gradient attribution explanation w.r.t the predictions. Our data and code are released at https://github.com/doujiang-zheng/GNN-For-Particle-Crushing.","sentences":["Graph Neural Networks have emerged as an effective machine learning tool for multi-disciplinary tasks such as pharmaceutical molecule classification and chemical reaction prediction, because they can model non-euclidean relationships between different entities.","Particle crushing, as a significant field of civil engineering, describes the breakage of granular materials caused by the breakage of particle fragment bonds under the modeling of numerical simulations, which motivates us to characterize the mechanical behaviors of particle crushing through the connectivity of particle fragments with Graph Neural Networks (GNNs).","However, there lacks an open-source large-scale particle crushing dataset for research due to the expensive costs of laboratory tests or numerical simulations.","Therefore, we firstly generate a dataset with 45,000 numerical simulations and 900 particle types to facilitate the research progress of machine learning for particle crushing.","Secondly, we devise a hybrid framework based on GNNs to predict particle crushing strength in a particle fragment view with the advances of state of the art GNNs.","Finally, we compare our hybrid framework against traditional machine learning methods and the plain MLP to verify its effectiveness.","The usefulness of different features is further discussed through the gradient attribution explanation w.r.t the predictions.","Our data and code are released at https://github.com/doujiang-zheng/GNN-For-Particle-Crushing."],"url":"http://arxiv.org/abs/2307.13909v1"}
{"created":"2023-07-26 02:16:55","title":"Points-to-3D: Bridging the Gap between Sparse Points and Shape-Controllable Text-to-3D Generation","abstract":"Text-to-3D generation has recently garnered significant attention, fueled by 2D diffusion models trained on billions of image-text pairs. Existing methods primarily rely on score distillation to leverage the 2D diffusion priors to supervise the generation of 3D models, e.g., NeRF. However, score distillation is prone to suffer the view inconsistency problem, and implicit NeRF modeling can also lead to an arbitrary shape, thus leading to less realistic and uncontrollable 3D generation. In this work, we propose a flexible framework of Points-to-3D to bridge the gap between sparse yet freely available 3D points and realistic shape-controllable 3D generation by distilling the knowledge from both 2D and 3D diffusion models. The core idea of Points-to-3D is to introduce controllable sparse 3D points to guide the text-to-3D generation. Specifically, we use the sparse point cloud generated from the 3D diffusion model, Point-E, as the geometric prior, conditioned on a single reference image. To better utilize the sparse 3D points, we propose an efficient point cloud guidance loss to adaptively drive the NeRF's geometry to align with the shape of the sparse 3D points. In addition to controlling the geometry, we propose to optimize the NeRF for a more view-consistent appearance. To be specific, we perform score distillation to the publicly available 2D image diffusion model ControlNet, conditioned on text as well as depth map of the learned compact geometry. Qualitative and quantitative comparisons demonstrate that Points-to-3D improves view consistency and achieves good shape controllability for text-to-3D generation. Points-to-3D provides users with a new way to improve and control text-to-3D generation.","sentences":["Text-to-3D generation has recently garnered significant attention, fueled by 2D diffusion models trained on billions of image-text pairs.","Existing methods primarily rely on score distillation to leverage the 2D diffusion priors to supervise the generation of 3D models, e.g., NeRF.","However, score distillation is prone to suffer the view inconsistency problem, and implicit NeRF modeling can also lead to an arbitrary shape, thus leading to less realistic and uncontrollable 3D generation.","In this work, we propose a flexible framework of Points-to-3D to bridge the gap between sparse yet freely available 3D points and realistic shape-controllable 3D generation by distilling the knowledge from both 2D and 3D diffusion models.","The core idea of Points-to-3D is to introduce controllable sparse 3D points to guide the text-to-3D generation.","Specifically, we use the sparse point cloud generated from the 3D diffusion model, Point-E, as the geometric prior, conditioned on a single reference image.","To better utilize the sparse 3D points, we propose an efficient point cloud guidance loss to adaptively drive the NeRF's geometry to align with the shape of the sparse 3D points.","In addition to controlling the geometry, we propose to optimize the NeRF for a more view-consistent appearance.","To be specific, we perform score distillation to the publicly available 2D image diffusion model ControlNet, conditioned on text as well as depth map of the learned compact geometry.","Qualitative and quantitative comparisons demonstrate that Points-to-3D improves view consistency and achieves good shape controllability for text-to-3D generation.","Points-to-3D provides users with a new way to improve and control text-to-3D generation."],"url":"http://arxiv.org/abs/2307.13908v1"}
{"created":"2023-07-26 02:15:11","title":"Robustness Verification of Deep Neural Networks using Star-Based Reachability Analysis with Variable-Length Time Series Input","abstract":"Data-driven, neural network (NN) based anomaly detection and predictive maintenance are emerging research areas. NN-based analytics of time-series data offer valuable insights into past behaviors and estimates of critical parameters like remaining useful life (RUL) of equipment and state-of-charge (SOC) of batteries. However, input time series data can be exposed to intentional or unintentional noise when passing through sensors, necessitating robust validation and verification of these NNs. This paper presents a case study of the robustness verification approach for time series regression NNs (TSRegNN) using set-based formal methods. It focuses on utilizing variable-length input data to streamline input manipulation and enhance network architecture generalizability. The method is applied to two data sets in the Prognostics and Health Management (PHM) application areas: (1) SOC estimation of a Lithium-ion battery and (2) RUL estimation of a turbine engine. The NNs' robustness is checked using star-based reachability analysis, and several performance measures evaluate the effect of bounded perturbations in the input on network outputs, i.e., future outcomes. Overall, the paper offers a comprehensive case study for validating and verifying NN-based analytics of time-series data in real-world applications, emphasizing the importance of robustness testing for accurate and reliable predictions, especially considering the impact of noise on future outcomes.","sentences":["Data-driven, neural network (NN) based anomaly detection and predictive maintenance are emerging research areas.","NN-based analytics of time-series data offer valuable insights into past behaviors and estimates of critical parameters like remaining useful life (RUL) of equipment and state-of-charge (SOC) of batteries.","However, input time series data can be exposed to intentional or unintentional noise when passing through sensors, necessitating robust validation and verification of these NNs.","This paper presents a case study of the robustness verification approach for time series regression NNs (TSRegNN) using set-based formal methods.","It focuses on utilizing variable-length input data to streamline input manipulation and enhance network architecture generalizability.","The method is applied to two data sets in the Prognostics and Health Management (PHM) application areas: (1) SOC estimation of a Lithium-ion battery and (2) RUL estimation of a turbine engine.","The NNs' robustness is checked using star-based reachability analysis, and several performance measures evaluate the effect of bounded perturbations in the input on network outputs, i.e., future outcomes.","Overall, the paper offers a comprehensive case study for validating and verifying NN-based analytics of time-series data in real-world applications, emphasizing the importance of robustness testing for accurate and reliable predictions, especially considering the impact of noise on future outcomes."],"url":"http://arxiv.org/abs/2307.13907v1"}
{"created":"2023-07-26 02:05:34","title":"Reinforcement Learning for Sequential Decoding of Generalized LDPC Codes","abstract":"In this work, we propose reinforcement learning (RL) for sequential decoding of moderate length generalized low-density parity-check (GLDPC) codes. Here, sequential decoding refers to scheduling all the generalized constraint nodes (GCNs) and single parity-check nodes (SPCNs) of a GLDPC code serially in each iteration. A GLDPC decoding environment is modeled as a finite Markov decision process (MDP) in which the state-space comprises of all possible sequences of hard-decision values of the variables nodes (VNs) connected to the scheduled GCN or SPCN, and the action-space of the MDP consists of all possible actions (GCN and SPCN scheduling). The goal of RL is to determine an optimized scheduling policy, i.e., one that results in a decoded codeword by minimizing the complexity of the belief propagation (BP) decoder. For training, we consider the proportion of correct bits at the output of the GCN or SPCN as a reward once it is scheduled. The expected rewards for scheduling all the GCNs/SPCNs in the code's Tanner graph are earned via BP decoding during the RL phase. The proposed RL-based decoding scheme is shown to significantly outperform the standard BP flooding decoder, as well as a sequential decoder in which the GCNs/SPCNs are scheduled randomly.","sentences":["In this work, we propose reinforcement learning (RL) for sequential decoding of moderate length generalized low-density parity-check (GLDPC) codes.","Here, sequential decoding refers to scheduling all the generalized constraint nodes (GCNs) and single parity-check nodes (SPCNs) of a GLDPC code serially in each iteration.","A GLDPC decoding environment is modeled as a finite Markov decision process (MDP) in which the state-space comprises of all possible sequences of hard-decision values of the variables nodes (VNs) connected to the scheduled GCN or SPCN, and the action-space of the MDP consists of all possible actions (GCN and SPCN scheduling).","The goal of RL is to determine an optimized scheduling policy, i.e., one that results in a decoded codeword by minimizing the complexity of the belief propagation (BP) decoder.","For training, we consider the proportion of correct bits at the output of the GCN or SPCN as a reward once it is scheduled.","The expected rewards for scheduling all the GCNs/SPCNs in the code's Tanner graph are earned via BP decoding during the RL phase.","The proposed RL-based decoding scheme is shown to significantly outperform the standard BP flooding decoder, as well as a sequential decoder in which the GCNs/SPCNs are scheduled randomly."],"url":"http://arxiv.org/abs/2307.13905v1"}
{"created":"2023-07-26 02:02:19","title":"Corruption-Robust Lipschitz Contextual Search","abstract":"I study the problem of learning a Lipschitz function with corrupted binary signals. The learner tries to learn a Lipschitz function $f$ that the adversary chooses. In each round, the adversary selects a context vector $x_t$ in the input space, and the learner makes a guess to the true function value $f(x_t)$ and receives a binary signal indicating whether the guess was high or low. In a total of $C$ rounds, the signal may be corrupted, though the value of $C$ is unknown to the learner. The learner's goal is to incur a small cumulative loss. I present a natural yet powerful technique sanity check, which proves useful in designing corruption-robust algorithms. I design algorithms which (treating the Lipschitz parameter $L$ as constant): for the symmetric loss, the learner achieves regret $O(C\\log T)$ with $d = 1$ and $O_d(C\\log T + T^{(d-1)/d})$ with $d > 1$; for the pricing loss the learner achieves regret $\\widetilde{O} (T^{d/(d+1)} + C\\cdot T^{1/(d+1)})$.","sentences":["I study the problem of learning a Lipschitz function with corrupted binary signals.","The learner tries to learn a Lipschitz function $f$ that the adversary chooses.","In each round, the adversary selects a context vector $x_t$ in the input space, and the learner makes a guess to the true function value $f(x_t)$ and receives a binary signal indicating whether the guess was high or low.","In a total of $C$ rounds, the signal may be corrupted, though the value of $C$ is unknown to the learner.","The learner's goal is to incur a small cumulative loss.","I present a natural yet powerful technique sanity check, which proves useful in designing corruption-robust algorithms.","I design algorithms which (treating the Lipschitz parameter $L$ as constant): for the symmetric loss, the learner achieves regret $O(C\\log T)$ with $d = 1$ and $O_d(C\\log T + T^{(d-1)/d})$ with $d > 1$; for the pricing loss the learner achieves regret $\\widetilde{O} (T^{d/(d+1)} + C\\cdot T^{1/(d+1)})$."],"url":"http://arxiv.org/abs/2307.13903v1"}
{"created":"2023-07-26 01:51:10","title":"YOLOBench: Benchmarking Efficient Object Detectors on Embedded Systems","abstract":"We present YOLOBench, a benchmark comprised of 550+ YOLO-based object detection models on 4 different datasets and 4 different embedded hardware platforms (x86 CPU, ARM CPU, Nvidia GPU, NPU). We collect accuracy and latency numbers for a variety of YOLO-based one-stage detectors at different model scales by performing a fair, controlled comparison of these detectors with a fixed training environment (code and training hyperparameters). Pareto-optimality analysis of the collected data reveals that, if modern detection heads and training techniques are incorporated into the learning process, multiple architectures of the YOLO series achieve a good accuracy-latency trade-off, including older models like YOLOv3 and YOLOv4. We also evaluate training-free accuracy estimators used in neural architecture search on YOLOBench and demonstrate that, while most state-of-the-art zero-cost accuracy estimators are outperformed by a simple baseline like MAC count, some of them can be effectively used to predict Pareto-optimal detection models. We showcase that by using a zero-cost proxy to identify a YOLO architecture competitive against a state-of-the-art YOLOv8 model on a Raspberry Pi 4 CPU. The code and data are available at https://github.com/Deeplite/deeplite-torch-zoo","sentences":["We present YOLOBench, a benchmark comprised of 550+ YOLO-based object detection models on 4 different datasets and 4 different embedded hardware platforms (x86 CPU, ARM CPU, Nvidia GPU, NPU).","We collect accuracy and latency numbers for a variety of YOLO-based one-stage detectors at different model scales by performing a fair, controlled comparison of these detectors with a fixed training environment (code and training hyperparameters).","Pareto-optimality analysis of the collected data reveals that, if modern detection heads and training techniques are incorporated into the learning process, multiple architectures of the YOLO series achieve a good accuracy-latency trade-off, including older models like YOLOv3 and YOLOv4.","We also evaluate training-free accuracy estimators used in neural architecture search on YOLOBench and demonstrate that, while most state-of-the-art zero-cost accuracy estimators are outperformed by a simple baseline like MAC count, some of them can be effectively used to predict Pareto-optimal detection models.","We showcase that by using a zero-cost proxy to identify a YOLO architecture competitive against a state-of-the-art YOLOv8 model on a Raspberry Pi 4 CPU.","The code and data are available at https://github.com/Deeplite/deeplite-torch-zoo"],"url":"http://arxiv.org/abs/2307.13901v1"}
{"created":"2023-07-26 01:48:52","title":"FinTree: Financial Dataset Pretrain Transformer Encoder for Relation Extraction","abstract":"We present FinTree, Financial Dataset Pretrain Transformer Encoder for Relation Extraction. Utilizing an encoder language model, we further pretrain FinTree on the financial dataset, adapting the model in financial domain tasks. FinTree stands out with its novel structure that predicts a masked token instead of the conventional [CLS] token, inspired by the Pattern Exploiting Training methodology. This structure allows for more accurate relation predictions between two given entities. The model is trained with a unique input pattern to provide contextual and positional information about the entities of interest, and a post-processing step ensures accurate predictions in line with the entity types. Our experiments demonstrate that FinTree outperforms on the REFinD, a large-scale financial relation extraction dataset. The code and pretrained models are available at https://github.com/HJ-Ok/FinTree.","sentences":["We present FinTree, Financial Dataset Pretrain Transformer Encoder for Relation Extraction.","Utilizing an encoder language model, we further pretrain FinTree on the financial dataset, adapting the model in financial domain tasks.","FinTree stands out with its novel structure that predicts a masked token instead of the conventional [CLS] token, inspired by the Pattern Exploiting Training methodology.","This structure allows for more accurate relation predictions between two given entities.","The model is trained with a unique input pattern to provide contextual and positional information about the entities of interest, and a post-processing step ensures accurate predictions in line with the entity types.","Our experiments demonstrate that FinTree outperforms on the REFinD, a large-scale financial relation extraction dataset.","The code and pretrained models are available at https://github.com/HJ-Ok/FinTree."],"url":"http://arxiv.org/abs/2307.13900v1"}
{"created":"2023-07-26 01:47:49","title":"Regularizing Neural Networks with Meta-Learning Generative Models","abstract":"This paper investigates methods for improving generative data augmentation for deep learning. Generative data augmentation leverages the synthetic samples produced by generative models as an additional dataset for classification with small dataset settings. A key challenge of generative data augmentation is that the synthetic data contain uninformative samples that degrade accuracy. This is because the synthetic samples do not perfectly represent class categories in real data and uniform sampling does not necessarily provide useful samples for tasks. In this paper, we present a novel strategy for generative data augmentation called meta generative regularization (MGR). To avoid the degradation of generative data augmentation, MGR utilizes synthetic samples in the regularization term for feature extractors instead of in the loss function, e.g., cross-entropy. These synthetic samples are dynamically determined to minimize the validation losses through meta-learning. We observed that MGR can avoid the performance degradation of na\\\"ive generative data augmentation and boost the baselines. Experiments on six datasets showed that MGR is effective particularly when datasets are smaller and stably outperforms baselines.","sentences":["This paper investigates methods for improving generative data augmentation for deep learning.","Generative data augmentation leverages the synthetic samples produced by generative models as an additional dataset for classification with small dataset settings.","A key challenge of generative data augmentation is that the synthetic data contain uninformative samples that degrade accuracy.","This is because the synthetic samples do not perfectly represent class categories in real data and uniform sampling does not necessarily provide useful samples for tasks.","In this paper, we present a novel strategy for generative data augmentation called meta generative regularization (MGR).","To avoid the degradation of generative data augmentation, MGR utilizes synthetic samples in the regularization term for feature extractors instead of in the loss function, e.g., cross-entropy.","These synthetic samples are dynamically determined to minimize the validation losses through meta-learning.","We observed that MGR can avoid the performance degradation of na\\\"ive generative data augmentation and boost the baselines.","Experiments on six datasets showed that MGR is effective particularly when datasets are smaller and stably outperforms baselines."],"url":"http://arxiv.org/abs/2307.13899v1"}
{"created":"2023-07-26 01:44:31","title":"AViT: Adapting Vision Transformers for Small Skin Lesion Segmentation Datasets","abstract":"Skin lesion segmentation (SLS) plays an important role in skin lesion analysis. Vision transformers (ViTs) are considered an auspicious solution for SLS, but they require more training data compared to convolutional neural networks (CNNs) due to their inherent parameter-heavy structure and lack of some inductive biases. To alleviate this issue, current approaches fine-tune pre-trained ViT backbones on SLS datasets, aiming to leverage the knowledge learned from a larger set of natural images to lower the amount of skin training data needed. However, fully fine-tuning all parameters of large backbones is computationally expensive and memory intensive. In this paper, we propose AViT, a novel efficient strategy to mitigate ViTs' data-hunger by transferring any pre-trained ViTs to the SLS task. Specifically, we integrate lightweight modules (adapters) within the transformer layers, which modulate the feature representation of a ViT without updating its pre-trained weights. In addition, we employ a shallow CNN as a prompt generator to create a prompt embedding from the input image, which grasps fine-grained information and CNN's inductive biases to guide the segmentation task on small datasets. Our quantitative experiments on 4 skin lesion datasets demonstrate that AViT achieves competitive, and at times superior, performance to SOTA but with significantly fewer trainable parameters. Our code is available at https://github.com/siyi-wind/AViT.","sentences":["Skin lesion segmentation (SLS) plays an important role in skin lesion analysis.","Vision transformers (ViTs) are considered an auspicious solution for SLS, but they require more training data compared to convolutional neural networks (CNNs) due to their inherent parameter-heavy structure and lack of some inductive biases.","To alleviate this issue, current approaches fine-tune pre-trained ViT backbones on SLS datasets, aiming to leverage the knowledge learned from a larger set of natural images to lower the amount of skin training data needed.","However, fully fine-tuning all parameters of large backbones is computationally expensive and memory intensive.","In this paper, we propose AViT, a novel efficient strategy to mitigate ViTs' data-hunger by transferring any pre-trained ViTs to the SLS task.","Specifically, we integrate lightweight modules (adapters) within the transformer layers, which modulate the feature representation of a ViT without updating its pre-trained weights.","In addition, we employ a shallow CNN as a prompt generator to create a prompt embedding from the input image, which grasps fine-grained information and CNN's inductive biases to guide the segmentation task on small datasets.","Our quantitative experiments on 4 skin lesion datasets demonstrate that AViT achieves competitive, and at times superior, performance to SOTA but with significantly fewer trainable parameters.","Our code is available at https://github.com/siyi-wind/AViT."],"url":"http://arxiv.org/abs/2307.13897v1"}
{"created":"2023-07-26 01:44:02","title":"Low-Parameter Federated Learning with Large Language Models","abstract":"We study few-shot Natural Language Understanding (NLU) tasks with Large Language Models (LLMs) in federated learning (FL) scenarios. It is a challenging task due to limited labeled data and communication capacities in FL, especially with mobile devices. Recent studies show LLMs can be prompted to perform few-shot NLU tasks like sentiment analysis and arithmetic reasoning. However, the huge sizes of LLMs result in high computation and communication costs, making classical FL schemes impractical. To address these challenges, we propose Low-Parameter Federated Learning (LP-FL). LP-FL combines few-shot prompt learning from LLMs with efficient communication and federating techniques. Our approach enables federated clients to assign soft labels to unlabeled data using gradually learned knowledge from the global model. Through iterative soft-label assigning, we continually expand the labeled set during the FL process. Additionally, to reduce computation and communication costs, LP-FL utilizes the Low-Rank Adaptation (LoRA) technique for compact learnable parameter construction, efficient local model fine-tuning, and affordable global model federation. LP-FL consistently outperforms Full-Parameter Federated Learning (FP-FL) in sentiment analysis tasks across various FL settings. Its resistance to overfitting allows LP-FL to equal or surpass centralized training in few-shot scenarios.","sentences":["We study few-shot Natural Language Understanding (NLU) tasks with Large Language Models (LLMs) in federated learning (FL) scenarios.","It is a challenging task due to limited labeled data and communication capacities in FL, especially with mobile devices.","Recent studies show LLMs can be prompted to perform few-shot NLU tasks like sentiment analysis and arithmetic reasoning.","However, the huge sizes of LLMs result in high computation and communication costs, making classical FL schemes impractical.","To address these challenges, we propose Low-Parameter Federated Learning (LP-FL).","LP-FL combines few-shot prompt learning from LLMs with efficient communication and federating techniques.","Our approach enables federated clients to assign soft labels to unlabeled data using gradually learned knowledge from the global model.","Through iterative soft-label assigning, we continually expand the labeled set during the FL process.","Additionally, to reduce computation and communication costs, LP-FL utilizes the Low-Rank Adaptation (LoRA) technique for compact learnable parameter construction, efficient local model fine-tuning, and affordable global model federation.","LP-FL consistently outperforms Full-Parameter Federated Learning (FP-FL) in sentiment analysis tasks across various FL settings.","Its resistance to overfitting allows LP-FL to equal or surpass centralized training in few-shot scenarios."],"url":"http://arxiv.org/abs/2307.13896v1"}
{"created":"2023-07-26 01:39:36","title":"AI4GCC - Team: Below Sea Level: Critiques and Improvements","abstract":"We present a critical analysis of the simulation framework RICE-N, an integrated assessment model (IAM) for evaluating the impacts of climate change on the economy. We identify key issues with RICE-N, including action masking and irrelevant actions, and suggest improvements such as utilizing tariff revenue and penalizing overproduction. We also critically engage with features of IAMs in general, namely overly optimistic damage functions and unrealistic abatement cost functions. Our findings contribute to the ongoing efforts to further develop the RICE-N framework in an effort to improve the simulation, making it more useful as an inspiration for policymakers.","sentences":["We present a critical analysis of the simulation framework RICE-N, an integrated assessment model (IAM) for evaluating the impacts of climate change on the economy.","We identify key issues with RICE-N, including action masking and irrelevant actions, and suggest improvements such as utilizing tariff revenue and penalizing overproduction.","We also critically engage with features of IAMs in general, namely overly optimistic damage functions and unrealistic abatement cost functions.","Our findings contribute to the ongoing efforts to further develop the RICE-N framework in an effort to improve the simulation, making it more useful as an inspiration for policymakers."],"url":"http://arxiv.org/abs/2307.13894v1"}
{"created":"2023-07-26 01:34:43","title":"Dynamic Grouping for Climate Change Negotiation: Facilitating Cooperation and Balancing Interests through Effective Strategies","abstract":"In this paper, we propose a dynamic grouping negotiation model for climate mitigation based on real-world business and political negotiation protocols. Within the AI4GCC competition framework, we develop a three-stage process: group formation and updates, intra-group negotiation, and inter-group negotiation. Our model promotes efficient and effective cooperation between various stakeholders to achieve global climate change objectives. By implementing a group-forming method and group updating strategy, we address the complexities and imbalances in multi-region climate negotiations. Intra-group negotiations ensure that all members contribute to mitigation efforts, while inter-group negotiations use the proposal-evaluation framework to set mitigation and savings rates. We demonstrate our negotiation model within the RICE-N framework, illustrating a promising approach for facilitating international cooperation on climate change mitigation.","sentences":["In this paper, we propose a dynamic grouping negotiation model for climate mitigation based on real-world business and political negotiation protocols.","Within the AI4GCC competition framework, we develop a three-stage process: group formation and updates, intra-group negotiation, and inter-group negotiation.","Our model promotes efficient and effective cooperation between various stakeholders to achieve global climate change objectives.","By implementing a group-forming method and group updating strategy, we address the complexities and imbalances in multi-region climate negotiations.","Intra-group negotiations ensure that all members contribute to mitigation efforts, while inter-group negotiations use the proposal-evaluation framework to set mitigation and savings rates.","We demonstrate our negotiation model within the RICE-N framework, illustrating a promising approach for facilitating international cooperation on climate change mitigation."],"url":"http://arxiv.org/abs/2307.13893v1"}
{"created":"2023-07-26 01:32:19","title":"AI4GCC - Team: Below Sea Level: Score and Real World Relevance","abstract":"As our submission for track three of the AI for Global Climate Cooperation (AI4GCC) competition, we propose a negotiation protocol for use in the RICE-N climate-economic simulation. Our proposal seeks to address the challenges of carbon leakage through methods inspired by the Carbon Border Adjustment Mechanism (CBAM) and Climate Clubs (CC). We demonstrate the effectiveness of our approach by comparing simulated outcomes to representative concentration pathways (RCP) and shared socioeconomic pathways (SSP). Our protocol results in a temperature rise comparable to RCP 3.4/4.5 and SSP 2. Furthermore, we provide an analysis of our protocol's World Trade Organization compliance, administrative and political feasibility, and ethical concerns. We recognize that our proposal risks hurting the least developing countries, and we suggest specific corrective measures to avoid exacerbating existing inequalities, such as technology sharing and wealth redistribution. Future research should improve the RICE-N tariff mechanism and implement actions allowing for the aforementioned corrective measures.","sentences":["As our submission for track three of the AI for Global Climate Cooperation (AI4GCC) competition, we propose a negotiation protocol for use in the RICE-N climate-economic simulation.","Our proposal seeks to address the challenges of carbon leakage through methods inspired by the Carbon Border Adjustment Mechanism (CBAM) and Climate Clubs (CC).","We demonstrate the effectiveness of our approach by comparing simulated outcomes to representative concentration pathways (RCP) and shared socioeconomic pathways (SSP).","Our protocol results in a temperature rise comparable to RCP 3.4/4.5 and SSP 2.","Furthermore, we provide an analysis of our protocol's World Trade Organization compliance, administrative and political feasibility, and ethical concerns.","We recognize that our proposal risks hurting the least developing countries, and we suggest specific corrective measures to avoid exacerbating existing inequalities, such as technology sharing and wealth redistribution.","Future research should improve the RICE-N tariff mechanism and implement actions allowing for the aforementioned corrective measures."],"url":"http://arxiv.org/abs/2307.13892v1"}
{"created":"2023-07-26 01:12:44","title":"Dynamic Grouping for Climate Change Negotiation: Facilitating Cooperation and Balancing Interests through Effective Strategies","abstract":"The current framework for climate change negotiation models presents several limitations that warrant further research and development. In this track, we discuss mainly two key areas for improvement, focusing on the geographical impacts and utility framework. In the aspects of geographical impacts, We explore five critical aspects: (1) the shift from local to global impact, (2) variability in climate change effects across regions, (3) heterogeneity in geographical location and political structures, and (4) collaborations between adjacent nations, (5) the importance of including historical and cultural factors influencing climate negotiations. Furthermore, we emphasize the need to refine the utility and rewards framework to reduce the homogeneity and the level of overestimating the climate mitigation by integrating the positive effects of saving rates into the reward function and heterogeneity among all regions. By addressing these limitations, we hope to enhance the accuracy and effectiveness of climate change negotiation models, enabling policymakers and stakeholders to devise targeted and appropriate strategies to tackle climate change at both regional and global levels.","sentences":["The current framework for climate change negotiation models presents several limitations that warrant further research and development.","In this track, we discuss mainly two key areas for improvement, focusing on the geographical impacts and utility framework.","In the aspects of geographical impacts, We explore five critical aspects: (1) the shift from local to global impact, (2) variability in climate change effects across regions, (3) heterogeneity in geographical location and political structures, and (4) collaborations between adjacent nations, (5) the importance of including historical and cultural factors influencing climate negotiations.","Furthermore, we emphasize the need to refine the utility and rewards framework to reduce the homogeneity and the level of overestimating the climate mitigation by integrating the positive effects of saving rates into the reward function and heterogeneity among all regions.","By addressing these limitations, we hope to enhance the accuracy and effectiveness of climate change negotiation models, enabling policymakers and stakeholders to devise targeted and appropriate strategies to tackle climate change at both regional and global levels."],"url":"http://arxiv.org/abs/2307.13886v1"}
{"created":"2023-07-26 01:10:29","title":"Efficient Estimation of the Local Robustness of Machine Learning Models","abstract":"Machine learning models often need to be robust to noisy input data. The effect of real-world noise (which is often random) on model predictions is captured by a model's local robustness, i.e., the consistency of model predictions in a local region around an input. However, the na\\\"ive approach to computing local robustness based on Monte-Carlo sampling is statistically inefficient, leading to prohibitive computational costs for large-scale applications. In this work, we develop the first analytical estimators to efficiently compute local robustness of multi-class discriminative models using local linear function approximation and the multivariate Normal CDF. Through the derivation of these estimators, we show how local robustness is connected to concepts such as randomized smoothing and softmax probability. We also confirm empirically that these estimators accurately and efficiently compute the local robustness of standard deep learning models. In addition, we demonstrate these estimators' usefulness for various tasks involving local robustness, such as measuring robustness bias and identifying examples that are vulnerable to noise perturbation in a dataset. By developing these analytical estimators, this work not only advances conceptual understanding of local robustness, but also makes its computation practical, enabling the use of local robustness in critical downstream applications.","sentences":["Machine learning models often need to be robust to noisy input data.","The effect of real-world noise (which is often random) on model predictions is captured by a model's local robustness, i.e., the consistency of model predictions in a local region around an input.","However, the na\\\"ive approach to computing local robustness based on Monte-Carlo sampling is statistically inefficient, leading to prohibitive computational costs for large-scale applications.","In this work, we develop the first analytical estimators to efficiently compute local robustness of multi-class discriminative models using local linear function approximation and the multivariate Normal CDF.","Through the derivation of these estimators, we show how local robustness is connected to concepts such as randomized smoothing and softmax probability.","We also confirm empirically that these estimators accurately and efficiently compute the local robustness of standard deep learning models.","In addition, we demonstrate these estimators' usefulness for various tasks involving local robustness, such as measuring robustness bias and identifying examples that are vulnerable to noise perturbation in a dataset.","By developing these analytical estimators, this work not only advances conceptual understanding of local robustness, but also makes its computation practical, enabling the use of local robustness in critical downstream applications."],"url":"http://arxiv.org/abs/2307.13885v1"}
{"created":"2023-07-26 01:07:52","title":"ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis","abstract":"When writing programs, people have the ability to tackle a new complex task by decomposing it into smaller and more familiar subtasks. While it is difficult to measure whether neural program synthesis methods have similar capabilities, we can measure whether they compositionally generalize, that is, whether a model that has been trained on the simpler subtasks is subsequently able to solve more complex tasks. In this paper, we characterize several different forms of compositional generalization that are desirable in program synthesis, forming a meta-benchmark which we use to create generalization tasks for two popular datasets, RobustFill and DeepCoder. We then propose ExeDec, a novel decomposition-based synthesis strategy that predicts execution subgoals to solve problems step-by-step informed by program execution at each step. ExeDec has better synthesis performance and greatly improved compositional generalization ability compared to baselines.","sentences":["When writing programs, people have the ability to tackle a new complex task by decomposing it into smaller and more familiar subtasks.","While it is difficult to measure whether neural program synthesis methods have similar capabilities, we can measure whether they compositionally generalize, that is, whether a model that has been trained on the simpler subtasks is subsequently able to solve more complex tasks.","In this paper, we characterize several different forms of compositional generalization that are desirable in program synthesis, forming a meta-benchmark which we use to create generalization tasks for two popular datasets, RobustFill and DeepCoder.","We then propose ExeDec, a novel decomposition-based synthesis strategy that predicts execution subgoals to solve problems step-by-step informed by program execution at each step.","ExeDec has better synthesis performance and greatly improved compositional generalization ability compared to baselines."],"url":"http://arxiv.org/abs/2307.13883v1"}
{"created":"2023-07-26 01:07:24","title":"Human Culture: A History Irrelevant and Predictable Experience","abstract":"Human culture research has witnessed an opportunity of revolution thanks to the big data and social network revolution. Websites such as Douban.com, Goodreads.com, Pandora and IMDB become the new gold mine for cultural researchers. In 2021 and 2022, the author of this paper invented 2 data-free recommender systems for AI cold-start problem. The algorithms can recommend cultural and commercial products to users without reference to users' past preferences. The social implications of the new inventions are human cultural tastes can be predicted very precisely without any information related to human individuals. In this paper, we analyze the AI technologies and its cultural implications together with other AI algorithms. We show that human culture is (mostly) a history irrelevant and predictable experience.","sentences":["Human culture research has witnessed an opportunity of revolution thanks to the big data and social network revolution.","Websites such as Douban.com, Goodreads.com, Pandora and IMDB become the new gold mine for cultural researchers.","In 2021 and 2022, the author of this paper invented 2 data-free recommender systems for AI cold-start problem.","The algorithms can recommend cultural and commercial products to users without reference to users' past preferences.","The social implications of the new inventions are human cultural tastes can be predicted very precisely without any information related to human individuals.","In this paper, we analyze the AI technologies and its cultural implications together with other AI algorithms.","We show that human culture is (mostly) a history irrelevant and predictable experience."],"url":"http://arxiv.org/abs/2307.13882v1"}
{"created":"2023-07-26 00:01:21","title":"Good Lattice Training: Physics-Informed Neural Networks Accelerated by Number Theory","abstract":"Physics-informed neural networks (PINNs) offer a novel and efficient approach to solving partial differential equations (PDEs). Their success lies in the physics-informed loss, which trains a neural network to satisfy a given PDE at specific points and to approximate the solution. However, the solutions to PDEs are inherently infinite-dimensional, and the distance between the output and the solution is defined by an integral over the domain. Therefore, the physics-informed loss only provides a finite approximation, and selecting appropriate collocation points becomes crucial to suppress the discretization errors, although this aspect has often been overlooked. In this paper, we propose a new technique called good lattice training (GLT) for PINNs, inspired by number theoretic methods for numerical analysis. GLT offers a set of collocation points that are effective even with a small number of points and for multi-dimensional spaces. Our experiments demonstrate that GLT requires 2--20 times fewer collocation points (resulting in lower computational cost) than uniformly random sampling or Latin hypercube sampling, while achieving competitive performance.","sentences":["Physics-informed neural networks (PINNs) offer a novel and efficient approach to solving partial differential equations (PDEs).","Their success lies in the physics-informed loss, which trains a neural network to satisfy a given PDE at specific points and to approximate the solution.","However, the solutions to PDEs are inherently infinite-dimensional, and the distance between the output and the solution is defined by an integral over the domain.","Therefore, the physics-informed loss only provides a finite approximation, and selecting appropriate collocation points becomes crucial to suppress the discretization errors, although this aspect has often been overlooked.","In this paper, we propose a new technique called good lattice training (GLT) for PINNs, inspired by number theoretic methods for numerical analysis.","GLT offers a set of collocation points that are effective even with a small number of points and for multi-dimensional spaces.","Our experiments demonstrate that GLT requires 2--20 times fewer collocation points (resulting in lower computational cost) than uniformly random sampling or Latin hypercube sampling, while achieving competitive performance."],"url":"http://arxiv.org/abs/2307.13869v1"}
{"created":"2023-07-25 23:46:48","title":"Pretrained Deep 2.5D Models for Efficient Predictive Modeling from Retinal OCT","abstract":"In the field of medical imaging, 3D deep learning models play a crucial role in building powerful predictive models of disease progression. However, the size of these models presents significant challenges, both in terms of computational resources and data requirements. Moreover, achieving high-quality pretraining of 3D models proves to be even more challenging. To address these issues, hybrid 2.5D approaches provide an effective solution for utilizing 3D volumetric data efficiently using 2D models. Combining 2D and 3D techniques offers a promising avenue for optimizing performance while minimizing memory requirements. In this paper, we explore 2.5D architectures based on a combination of convolutional neural networks (CNNs), long short-term memory (LSTM), and Transformers. In addition, leveraging the benefits of recent non-contrastive pretraining approaches in 2D, we enhanced the performance and data efficiency of 2.5D techniques even further. We demonstrate the effectiveness of architectures and associated pretraining on a task of predicting progression to wet age-related macular degeneration (AMD) within a six-month period on two large longitudinal OCT datasets.","sentences":["In the field of medical imaging, 3D deep learning models play a crucial role in building powerful predictive models of disease progression.","However, the size of these models presents significant challenges, both in terms of computational resources and data requirements.","Moreover, achieving high-quality pretraining of 3D models proves to be even more challenging.","To address these issues, hybrid 2.5D approaches provide an effective solution for utilizing 3D volumetric data efficiently using 2D models.","Combining 2D and 3D techniques offers a promising avenue for optimizing performance while minimizing memory requirements.","In this paper, we explore 2.5D architectures based on a combination of convolutional neural networks (CNNs), long short-term memory (LSTM), and Transformers.","In addition, leveraging the benefits of recent non-contrastive pretraining approaches in 2D, we enhanced the performance and data efficiency of 2.5D techniques even further.","We demonstrate the effectiveness of architectures and associated pretraining on a task of predicting progression to wet age-related macular degeneration (AMD) within a six-month period on two large longitudinal OCT datasets."],"url":"http://arxiv.org/abs/2307.13865v1"}
{"created":"2023-07-25 23:25:05","title":"Learning to Design Analog Circuits to Meet Threshold Specifications","abstract":"Automated design of analog and radio-frequency circuits using supervised or reinforcement learning from simulation data has recently been studied as an alternative to manual expert design. It is straightforward for a design agent to learn an inverse function from desired performance metrics to circuit parameters. However, it is more common for a user to have threshold performance criteria rather than an exact target vector of feasible performance measures. In this work, we propose a method for generating from simulation data a dataset on which a system can be trained via supervised learning to design circuits to meet threshold specifications. We moreover perform the to-date most extensive evaluation of automated analog circuit design, including experimenting in a significantly more diverse set of circuits than in prior work, covering linear, nonlinear, and autonomous circuit configurations, and show that our method consistently reaches success rate better than 90% at 5% error margin, while also improving data efficiency by upward of an order of magnitude. A demo of this system is available at circuits.streamlit.app","sentences":["Automated design of analog and radio-frequency circuits using supervised or reinforcement learning from simulation data has recently been studied as an alternative to manual expert design.","It is straightforward for a design agent to learn an inverse function from desired performance metrics to circuit parameters.","However, it is more common for a user to have threshold performance criteria rather than an exact target vector of feasible performance measures.","In this work, we propose a method for generating from simulation data a dataset on which a system can be trained via supervised learning to design circuits to meet threshold specifications.","We moreover perform the to-date most extensive evaluation of automated analog circuit design, including experimenting in a significantly more diverse set of circuits than in prior work, covering linear, nonlinear, and autonomous circuit configurations, and show that our method consistently reaches success rate better than 90% at 5% error margin, while also improving data efficiency by upward of an order of magnitude.","A demo of this system is available at circuits.streamlit.app"],"url":"http://arxiv.org/abs/2307.13861v1"}
{"created":"2023-07-25 23:13:21","title":"Random (Un)rounding : Vulnerabilities in Discrete Attribute Disclosure in the 2021 Canadian Census","abstract":"The 2021 Canadian census is notable for using a unique form of privacy, random rounding, which independently and probabilistically rounds discrete numerical attribute values. In this work, we explore how hierarchical summative correlation between discrete variables allows for both probabilistic and exact solutions to attribute values in the 2021 Canadian Census disclosure. We demonstrate that, in some cases, it is possible to \"unround\" and extract the original private values before rounding, both in the presence and absence of provided population invariants. Using these methods, we expose the exact value of 624 previously private attributes in the 2021 Canadian census disclosure. We also infer the potential values of more than 1000 private attributes with a high probability of correctness. Finally, we propose how a simple solution based on unbounded discrete noise can effectively negate exact unrounding while maintaining high utility in the final product.","sentences":["The 2021 Canadian census is notable for using a unique form of privacy, random rounding, which independently and probabilistically rounds discrete numerical attribute values.","In this work, we explore how hierarchical summative correlation between discrete variables allows for both probabilistic and exact solutions to attribute values in the 2021 Canadian Census disclosure.","We demonstrate that, in some cases, it is possible to \"unround\" and extract the original private values before rounding, both in the presence and absence of provided population invariants.","Using these methods, we expose the exact value of 624 previously private attributes in the 2021 Canadian census disclosure.","We also infer the potential values of more than 1000 private attributes with a high probability of correctness.","Finally, we propose how a simple solution based on unbounded discrete noise can effectively negate exact unrounding while maintaining high utility in the final product."],"url":"http://arxiv.org/abs/2307.13859v1"}
{"created":"2023-07-25 23:12:27","title":"EmphasisChecker: A Tool for Guiding Chart and Caption Emphasis","abstract":"Recent work has shown that when both the chart and caption emphasize the same aspects of the data, readers tend to remember the doubly-emphasized features as takeaways; when there is a mismatch, readers rely on the chart to form takeaways and can miss information in the caption text. Through a survey of 280 chart-caption pairs in real-world sources (e.g., news media, poll reports, government reports, academic articles, and Tableau Public), we find that captions often do not emphasize the same information in practice, which could limit how effectively readers take away the authors' intended messages. Motivated by the survey findings, we present EmphasisChecker, an interactive tool that highlights visually prominent chart features as well as the features emphasized by the caption text along with any mismatches in the emphasis. The tool implements a time-series prominent feature detector based on the Ramer-Douglas-Peucker algorithm and a text reference extractor that identifies time references and data descriptions in the caption and matches them with chart data. This information enables authors to compare features emphasized by these two modalities, quickly see mismatches, and make necessary revisions. A user study confirms that our tool is both useful and easy to use when authoring charts and captions.","sentences":["Recent work has shown that when both the chart and caption emphasize the same aspects of the data, readers tend to remember the doubly-emphasized features as takeaways; when there is a mismatch, readers rely on the chart to form takeaways and can miss information in the caption text.","Through a survey of 280 chart-caption pairs in real-world sources (e.g., news media, poll reports, government reports, academic articles, and Tableau Public), we find that captions often do not emphasize the same information in practice, which could limit how effectively readers take away the authors' intended messages.","Motivated by the survey findings, we present EmphasisChecker, an interactive tool that highlights visually prominent chart features as well as the features emphasized by the caption text along with any mismatches in the emphasis.","The tool implements a time-series prominent feature detector based on the Ramer-Douglas-Peucker algorithm and a text reference extractor that identifies time references and data descriptions in the caption and matches them with chart data.","This information enables authors to compare features emphasized by these two modalities, quickly see mismatches, and make necessary revisions.","A user study confirms that our tool is both useful and easy to use when authoring charts and captions."],"url":"http://arxiv.org/abs/2307.13858v1"}
{"created":"2023-07-25 23:09:05","title":"On the unreasonable vulnerability of transformers for image restoration -- and an easy fix","abstract":"Following their success in visual recognition tasks, Vision Transformers(ViTs) are being increasingly employed for image restoration. As a few recent works claim that ViTs for image classification also have better robustness properties, we investigate whether the improved adversarial robustness of ViTs extends to image restoration. We consider the recently proposed Restormer model, as well as NAFNet and the \"Baseline network\" which are both simplified versions of a Restormer. We use Projected Gradient Descent (PGD) and CosPGD, a recently proposed adversarial attack tailored to pixel-wise prediction tasks for our robustness evaluation. Our experiments are performed on real-world images from the GoPro dataset for image deblurring. Our analysis indicates that contrary to as advocated by ViTs in image classification works, these models are highly susceptible to adversarial attacks. We attempt to improve their robustness through adversarial training. While this yields a significant increase in robustness for Restormer, results on other networks are less promising. Interestingly, the design choices in NAFNet and Baselines, which were based on iid performance, and not on robust generalization, seem to be at odds with the model robustness. Thus, we investigate this further and find a fix.","sentences":["Following their success in visual recognition tasks, Vision Transformers(ViTs) are being increasingly employed for image restoration.","As a few recent works claim that ViTs for image classification also have better robustness properties, we investigate whether the improved adversarial robustness of ViTs extends to image restoration.","We consider the recently proposed Restormer model, as well as NAFNet and the \"Baseline network\" which are both simplified versions of a Restormer.","We use Projected Gradient Descent (PGD) and CosPGD, a recently proposed adversarial attack tailored to pixel-wise prediction tasks for our robustness evaluation.","Our experiments are performed on real-world images from the GoPro dataset for image deblurring.","Our analysis indicates that contrary to as advocated by ViTs in image classification works, these models are highly susceptible to adversarial attacks.","We attempt to improve their robustness through adversarial training.","While this yields a significant increase in robustness for Restormer, results on other networks are less promising.","Interestingly, the design choices in NAFNet and Baselines, which were based on iid performance, and not on robust generalization, seem to be at odds with the model robustness.","Thus, we investigate this further and find a fix."],"url":"http://arxiv.org/abs/2307.13856v1"}
{"created":"2023-07-25 23:02:35","title":"Exploring the Sharpened Cosine Similarity","abstract":"Convolutional layers have long served as the primary workhorse for image classification. Recently, an alternative to convolution was proposed using the Sharpened Cosine Similarity (SCS), which in theory may serve as a better feature detector. While multiple sources report promising results, there has not been to date a full-scale empirical analysis of neural network performance using these new layers. In our work, we explore SCS's parameter behavior and potential as a drop-in replacement for convolutions in multiple CNN architectures benchmarked on CIFAR-10. We find that while SCS may not yield significant increases in accuracy, it may learn more interpretable representations. We also find that, in some circumstances, SCS may confer a slight increase in adversarial robustness.","sentences":["Convolutional layers have long served as the primary workhorse for image classification.","Recently, an alternative to convolution was proposed using the Sharpened Cosine Similarity (SCS), which in theory may serve as a better feature detector.","While multiple sources report promising results, there has not been to date a full-scale empirical analysis of neural network performance using these new layers.","In our work, we explore SCS's parameter behavior and potential as a drop-in replacement for convolutions in multiple CNN architectures benchmarked on CIFAR-10.","We find that while SCS may not yield significant increases in accuracy, it may learn more interpretable representations.","We also find that, in some circumstances, SCS may confer a slight increase in adversarial robustness."],"url":"http://arxiv.org/abs/2307.13855v1"}
{"created":"2023-07-25 22:59:32","title":"WebArena: A Realistic Web Environment for Building Autonomous Agents","abstract":"With generative AI advances, the exciting potential for autonomous agents to manage daily tasks via natural language commands has emerged. However, cur rent agents are primarily created and tested in simplified synthetic environments, substantially limiting real-world scenario representation. In this paper, we build an environment for agent command and control that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on websites, and we create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and are designed to emulate tasks that humans routinely perform on the internet. We design and implement several autonomous agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 10.59%. These results highlight the need for further development of robust agents, that current state-of-the-art LMs are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress. Our code, data, environment reproduction resources, and video demonstrations are publicly available at https://webarena.dev/.","sentences":["With generative AI advances, the exciting potential for autonomous agents to manage daily tasks via natural language commands has emerged.","However, cur rent agents are primarily created and tested in simplified synthetic environments, substantially limiting real-world scenario representation.","In this paper, we build an environment for agent command and control that is highly realistic and reproducible.","Specifically, we focus on agents that perform tasks on websites, and we create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.","Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving.","Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions.","The tasks in our benchmark are diverse, long-horizon, and are designed to emulate tasks that humans routinely perform on the internet.","We design and implement several autonomous agents, integrating recent techniques such as reasoning before acting.","The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 10.59%.","These results highlight the need for further development of robust agents, that current state-of-the-art LMs are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.","Our code, data, environment reproduction resources, and video demonstrations are publicly available at https://webarena.dev/."],"url":"http://arxiv.org/abs/2307.13854v1"}
{"created":"2023-07-25 22:54:47","title":"SplitFed resilience to packet loss: Where to split, that is the question","abstract":"Decentralized machine learning has broadened its scope recently with the invention of Federated Learning (FL), Split Learning (SL), and their hybrids like Split Federated Learning (SplitFed or SFL). The goal of SFL is to reduce the computational power required by each client in FL and parallelize SL while maintaining privacy. This paper investigates the robustness of SFL against packet loss on communication links. The performance of various SFL aggregation strategies is examined by splitting the model at two points -- shallow split and deep split -- and testing whether the split point makes a statistically significant difference to the accuracy of the final model. Experiments are carried out on a segmentation model for human embryo images and indicate the statistically significant advantage of a deeper split point.","sentences":["Decentralized machine learning has broadened its scope recently with the invention of Federated Learning (FL), Split Learning (SL), and their hybrids like Split Federated Learning (SplitFed or SFL).","The goal of SFL is to reduce the computational power required by each client in FL and parallelize SL while maintaining privacy.","This paper investigates the robustness of SFL against packet loss on communication links.","The performance of various SFL aggregation strategies is examined by splitting the model at two points -- shallow split and deep split -- and testing whether the split point makes a statistically significant difference to the accuracy of the final model.","Experiments are carried out on a segmentation model for human embryo images and indicate the statistically significant advantage of a deeper split point."],"url":"http://arxiv.org/abs/2307.13851v1"}
{"created":"2023-07-25 22:51:36","title":"MAEA: Multimodal Attribution for Embodied AI","abstract":"Understanding multimodal perception for embodied AI is an open question because such inputs may contain highly complementary as well as redundant information for the task. A relevant direction for multimodal policies is understanding the global trends of each modality at the fusion layer. To this end, we disentangle the attributions for visual, language, and previous action inputs across different policies trained on the ALFRED dataset. Attribution analysis can be utilized to rank and group the failure scenarios, investigate modeling and dataset biases, and critically analyze multimodal EAI policies for robustness and user trust before deployment. We present MAEA, a framework to compute global attributions per modality of any differentiable policy. In addition, we show how attributions enable lower-level behavior analysis in EAI policies for language and visual attributions.","sentences":["Understanding multimodal perception for embodied AI is an open question because such inputs may contain highly complementary as well as redundant information for the task.","A relevant direction for multimodal policies is understanding the global trends of each modality at the fusion layer.","To this end, we disentangle the attributions for visual, language, and previous action inputs across different policies trained on the ALFRED dataset.","Attribution analysis can be utilized to rank and group the failure scenarios, investigate modeling and dataset biases, and critically analyze multimodal EAI policies for robustness and user trust before deployment.","We present MAEA, a framework to compute global attributions per modality of any differentiable policy.","In addition, we show how attributions enable lower-level behavior analysis in EAI policies for language and visual attributions."],"url":"http://arxiv.org/abs/2307.13850v1"}
{"created":"2023-07-25 22:46:42","title":"TeleBTC: Trustless Wrapped Bitcoin","abstract":"This paper introduces TeleBTC, a fully decentralized protocol designed to wrap Bitcoin (BTC) on programmable blockchains. The creation of a decentralized wrapped BTC presents challenges due to the non-programmable nature of Bitcoin, making it difficult to custody BTCs in a decentralized way. Existing solutions have addressed this challenge by introducing an external layer of validators who take custody of users' BTCs. However, the security and decentralization of this layer are inferior to the underlying blockchains on which wrapped BTC is built. Moreover, the process of joining or leaving for a validator has become overly complex and expensive. To overcome these limitations, we propose a novel approach that eliminates the need for such an external layer by leveraging the light client bridge protocol. Additionally, we employ economic mechanisms such as incentivization and slashing, resulting in a secure and trust-minimized wrapped BTC solution. With TeleBTC, users can seamlessly transfer their BTC to other blockchains and utilize it within decentralized applications. Furthermore, they can unwrap their TeleBTC and reclaim the native BTC. To address the high costs associated with light client bridges, we present an optimistic approach that minimizes the cost. This approach significantly reduces the operational expenses of running the protocol.","sentences":["This paper introduces TeleBTC, a fully decentralized protocol designed to wrap Bitcoin (BTC) on programmable blockchains.","The creation of a decentralized wrapped BTC presents challenges due to the non-programmable nature of Bitcoin, making it difficult to custody BTCs in a decentralized way.","Existing solutions have addressed this challenge by introducing an external layer of validators who take custody of users' BTCs.","However, the security and decentralization of this layer are inferior to the underlying blockchains on which wrapped BTC is built.","Moreover, the process of joining or leaving for a validator has become overly complex and expensive.","To overcome these limitations, we propose a novel approach that eliminates the need for such an external layer by leveraging the light client bridge protocol.","Additionally, we employ economic mechanisms such as incentivization and slashing, resulting in a secure and trust-minimized wrapped BTC solution.","With TeleBTC, users can seamlessly transfer their BTC to other blockchains and utilize it within decentralized applications.","Furthermore, they can unwrap their TeleBTC and reclaim the native BTC.","To address the high costs associated with light client bridges, we present an optimistic approach that minimizes the cost.","This approach significantly reduces the operational expenses of running the protocol."],"url":"http://arxiv.org/abs/2307.13848v1"}
{"created":"2023-07-25 22:40:17","title":"Polymorphic Reachability Types: Tracking Freshness, Aliasing, and Separation in Higher-Order Generic Programs","abstract":"Reachability types are a recent proposal that has shown promise in scaling to higher-order but monomorphic settings, tracking aliasing and separation on top of a substrate inspired by separation logic. The prior $\\lambda^*$ reachability type system qualifies types with sets of reachable variables and guarantees separation if two terms have disjoint qualifiers. However, naive extensions with type polymorphism and/or precise reachability polymorphism are unsound, making $\\lambda^*$ unsuitable for adoption in real languages. Combining reachability and type polymorphism that is precise, sound, and parametric remains an open challenge.   This paper presents a rethinking of the design of reachability tracking and proposes a solution to the key challenge of reachability polymorphism. Instead of always tracking the transitive closure of reachable variables as in the original design, we only track variables reachable in a single step and compute transitive closures only when necessary, thus preserving chains of reachability over known variables that can be refined using substitution. To enable this property, we introduce a new freshness qualifier, which indicates variables whose reachability sets may grow during evaluation steps. These ideas yield the simply-typed $\\lambda^\\diamond$-calculus with precise lightweight, i.e., quantifier-free, reachability polymorphism, and the $\\mathsf{F}_{<:}^\\diamond$-calculus with bounded parametric polymorphism over types and reachability qualifiers. We prove type soundness and a preservation of separation property in Coq.","sentences":["Reachability types are a recent proposal that has shown promise in scaling to higher-order but monomorphic settings, tracking aliasing and separation on top of a substrate inspired by separation logic.","The prior $\\lambda^*$ reachability type system qualifies types with sets of reachable variables and guarantees separation if two terms have disjoint qualifiers.","However, naive extensions with type polymorphism and/or precise reachability polymorphism are unsound, making $\\lambda^*$ unsuitable for adoption in real languages.","Combining reachability and type polymorphism that is precise, sound, and parametric remains an open challenge.   ","This paper presents a rethinking of the design of reachability tracking and proposes a solution to the key challenge of reachability polymorphism.","Instead of always tracking the transitive closure of reachable variables as in the original design, we only track variables reachable in a single step and compute transitive closures only when necessary, thus preserving chains of reachability over known variables that can be refined using substitution.","To enable this property, we introduce a new freshness qualifier, which indicates variables whose reachability sets may grow during evaluation steps.","These ideas yield the simply-typed $\\lambda^\\diamond$-calculus with precise lightweight, i.e., quantifier-free, reachability polymorphism, and the $\\mathsf{F}_{<:}^\\diamond$-calculus with bounded parametric polymorphism over types and reachability qualifiers.","We prove type soundness and a preservation of separation property in Coq."],"url":"http://arxiv.org/abs/2307.13844v1"}
{"created":"2023-07-25 22:37:10","title":"CosSIF: Cosine similarity-based image filtering to overcome low inter-class variation in synthetic medical image datasets","abstract":"Crafting effective deep learning models for medical image analysis is a complex task, particularly in cases where the medical image dataset lacks significant inter-class variation. This challenge is further aggravated when employing such datasets to generate synthetic images using generative adversarial networks (GANs), as the output of GANs heavily relies on the input data. In this research, we propose a novel filtering algorithm called Cosine Similarity-based Image Filtering (CosSIF). We leverage CosSIF to develop two distinct filtering methods: Filtering Before GAN Training (FBGT) and Filtering After GAN Training (FAGT). FBGT involves the removal of real images that exhibit similarities to images of other classes before utilizing them as the training dataset for a GAN. On the other hand, FAGT focuses on eliminating synthetic images with less discriminative features compared to real images used for training the GAN. Experimental results reveal that employing either the FAGT or FBGT method with modern transformer and convolutional-based networks leads to substantial performance gains in various evaluation metrics. FAGT implementation on the ISIC-2016 dataset surpasses the baseline method in terms of sensitivity by 1.59\\% and AUC by 1.88\\%. Furthermore, for the HAM10000 dataset, applying FABT outperforms the baseline approach in terms of recall by 13.75\\%, and with the sole implementation of FAGT, achieves a maximum accuracy of 94.44\\%.","sentences":["Crafting effective deep learning models for medical image analysis is a complex task, particularly in cases where the medical image dataset lacks significant inter-class variation.","This challenge is further aggravated when employing such datasets to generate synthetic images using generative adversarial networks (GANs), as the output of GANs heavily relies on the input data.","In this research, we propose a novel filtering algorithm called Cosine Similarity-based Image Filtering (CosSIF).","We leverage CosSIF to develop two distinct filtering methods: Filtering Before GAN Training (FBGT) and Filtering After GAN Training (FAGT).","FBGT involves the removal of real images that exhibit similarities to images of other classes before utilizing them as the training dataset for a GAN.","On the other hand, FAGT focuses on eliminating synthetic images with less discriminative features compared to real images used for training the GAN.","Experimental results reveal that employing either the FAGT or FBGT method with modern transformer and convolutional-based networks leads to substantial performance gains in various evaluation metrics.","FAGT implementation on the ISIC-2016 dataset surpasses the baseline method in terms of sensitivity by 1.59\\% and AUC by 1.88\\%.","Furthermore, for the HAM10000 dataset, applying FABT outperforms the baseline approach in terms of recall by 13.75\\%, and with the sole implementation of FAGT, achieves a maximum accuracy of 94.44\\%."],"url":"http://arxiv.org/abs/2307.13842v1"}
{"created":"2023-07-25 22:21:07","title":"Scaling Integer Arithmetic in Probabilistic Programs","abstract":"Distributions on integers are ubiquitous in probabilistic modeling but remain challenging for many of today's probabilistic programming languages (PPLs). The core challenge comes from discrete structure: many of today's PPL inference strategies rely on enumeration, sampling, or differentiation in order to scale, which fail for high-dimensional complex discrete distributions involving integers. Our insight is that there is structure in arithmetic that these approaches are not using. We present a binary encoding strategy for discrete distributions that exploits the rich logical structure of integer operations like summation and comparison. We leverage this structured encoding with knowledge compilation to perform exact probabilistic inference, and show that this approach scales to much larger integer distributions with arithmetic.","sentences":["Distributions on integers are ubiquitous in probabilistic modeling but remain challenging for many of today's probabilistic programming languages (PPLs).","The core challenge comes from discrete structure: many of today's PPL inference strategies rely on enumeration, sampling, or differentiation in order to scale, which fail for high-dimensional complex discrete distributions involving integers.","Our insight is that there is structure in arithmetic that these approaches are not using.","We present a binary encoding strategy for discrete distributions that exploits the rich logical structure of integer operations like summation and comparison.","We leverage this structured encoding with knowledge compilation to perform exact probabilistic inference, and show that this approach scales to much larger integer distributions with arithmetic."],"url":"http://arxiv.org/abs/2307.13837v1"}
{"created":"2023-07-25 22:07:41","title":"Determining the Optimal Frequencies for a Duplicated Randomized Clock SCA Countermeasure","abstract":"Side-channel attacks pose significant challenges to the security of embedded systems, often allowing attackers to circumvent encryption algorithms in minutes compared to the trillions of years required for brute-force attacks. To mitigate these vulnerabilities, various countermeasures have been developed. This study focuses on two specific countermeasures: randomization of the encryption algorithm's clock and the incorporation of a dummy core to disguise power traces.   The objective of this research is to identify the optimal frequencies that yield the highest level of randomness when these two countermeasures are combined. By investigating the interplay between clock randomization and the presence of dummy cores, we aim to enhance the overall security of embedded systems. The insights gained from this study will contribute to the development of more robust countermeasures against side-channel attacks, bolstering the protection of sensitive information and systems.   To achieve this, we conduct simulations and perform side-channel attacks on an FPGA to establish the relationship between frequencies and the resulting protection. We break the encryption on a non-duplicated circuit and note the least amount of measured power traces necessary and the timing overhead. We do this for all sets of frequencies considered which gives a good indication of which sets of frequencies give good protection. By comparing the frequencies generated with those from the duplicated circuit we use similar conclusions to prove whether a frequency set is secure or not.   Based on our results we argue that having one frequency lower than half of the base frequency and the other frequencies being close but not higher than the base gives the highest security compared to the timing overhead measured.","sentences":["Side-channel attacks pose significant challenges to the security of embedded systems, often allowing attackers to circumvent encryption algorithms in minutes compared to the trillions of years required for brute-force attacks.","To mitigate these vulnerabilities, various countermeasures have been developed.","This study focuses on two specific countermeasures: randomization of the encryption algorithm's clock and the incorporation of a dummy core to disguise power traces.   ","The objective of this research is to identify the optimal frequencies that yield the highest level of randomness when these two countermeasures are combined.","By investigating the interplay between clock randomization and the presence of dummy cores, we aim to enhance the overall security of embedded systems.","The insights gained from this study will contribute to the development of more robust countermeasures against side-channel attacks, bolstering the protection of sensitive information and systems.   ","To achieve this, we conduct simulations and perform side-channel attacks on an FPGA to establish the relationship between frequencies and the resulting protection.","We break the encryption on a non-duplicated circuit and note the least amount of measured power traces necessary and the timing overhead.","We do this for all sets of frequencies considered which gives a good indication of which sets of frequencies give good protection.","By comparing the frequencies generated with those from the duplicated circuit we use similar conclusions to prove whether a frequency set is secure or not.   ","Based on our results we argue that having one frequency lower than half of the base frequency and the other frequencies being close but not higher than the base gives the highest security compared to the timing overhead measured."],"url":"http://arxiv.org/abs/2307.13834v1"}
