{"created":"2023-05-24","title":"Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For Large Language Models","abstract":"The performance on Large Language Models (LLMs) on existing reasoning benchmarks has shot up considerably over the past years. In response, we present JEEBench, a considerably more challenging benchmark dataset for evaluating the problem solving abilities of LLMs. We curate 450 challenging pre-engineering mathematics, physics and chemistry problems from the IIT JEE-Advanced exam. Long-horizon reasoning on top of deep in-domain knowledge is essential for solving problems in this benchmark. Our evaluation on the GPT series of models reveals that although performance improves with newer models, the best being GPT-4, the highest performance, even after using techniques like Self-Consistency and Chain-of-Thought prompting is less than 40 percent. Our analysis demonstrates that errors in algebraic manipulation and failure in retrieving relevant domain specific concepts are primary contributors to GPT4's low performance. Given the challenging nature of the benchmark, we hope that it can guide future research in problem solving using LLMs. Our code and dataset is available here.","sentences":["The performance on Large Language Models (LLMs) on existing reasoning benchmarks has shot up considerably over the past years.","In response, we present JEEBench, a considerably more challenging benchmark dataset for evaluating the problem solving abilities of LLMs.","We curate 450 challenging pre-engineering mathematics, physics and chemistry problems from the IIT JEE-Advanced exam.","Long-horizon reasoning on top of deep in-domain knowledge is essential for solving problems in this benchmark.","Our evaluation on the GPT series of models reveals that although performance improves with newer models, the best being GPT-4, the highest performance, even after using techniques like Self-Consistency and Chain-of-Thought prompting is less than 40 percent.","Our analysis demonstrates that errors in algebraic manipulation and failure in retrieving relevant domain specific concepts are primary contributors to GPT4's low performance.","Given the challenging nature of the benchmark, we hope that it can guide future research in problem solving using LLMs.","Our code and dataset is available here."],"url":"http://arxiv.org/abs/2305.15074v1"}
{"created":"2023-05-24","title":"A New Era in Software Security: Towards Self-Healing Software via Large Language Models and Formal Verification","abstract":"In this paper we present a novel solution that combines the capabilities of Large Language Models (LLMs) with Formal Verification strategies to verify and automatically repair software vulnerabilities. Initially, we employ Bounded Model Checking (BMC) to locate the software vulnerability and derive a counterexample. The counterexample provides evidence that the system behaves incorrectly or contains a vulnerability. The counterexample that has been detected, along with the source code, are provided to the LLM engine. Our approach involves establishing a specialized prompt language for conducting code debugging and generation to understand the vulnerability's root cause and repair the code. Finally, we use BMC to verify the corrected version of the code generated by the LLM. As a proof of concept, we create ESBMC-AI based on the Efficient SMT-based Context-Bounded Model Checker (ESBMC) and a pre-trained Transformer model, specifically gpt-3.5-turbo, to detect and fix errors in C programs. Our experimentation involved generating a dataset comprising 1000 C code samples, each consisting of 20 to 50 lines of code. Notably, our proposed method achieved an impressive success rate of up to 80% in repairing vulnerable code encompassing buffer overflow and pointer dereference failures. We assert that this automated approach can effectively incorporate into the software development lifecycle's continuous integration and deployment (CI/CD) process.","sentences":["In this paper we present a novel solution that combines the capabilities of Large Language Models (LLMs) with Formal Verification strategies to verify and automatically repair software vulnerabilities.","Initially, we employ Bounded Model Checking (BMC) to locate the software vulnerability and derive a counterexample.","The counterexample provides evidence that the system behaves incorrectly or contains a vulnerability.","The counterexample that has been detected, along with the source code, are provided to the LLM engine.","Our approach involves establishing a specialized prompt language for conducting code debugging and generation to understand the vulnerability's root cause and repair the code.","Finally, we use BMC to verify the corrected version of the code generated by the LLM.","As a proof of concept, we create ESBMC-AI based on the Efficient SMT-based Context-Bounded Model Checker (ESBMC) and a pre-trained Transformer model, specifically gpt-3.5-turbo, to detect and fix errors in C programs.","Our experimentation involved generating a dataset comprising 1000 C code samples, each consisting of 20 to 50 lines of code.","Notably, our proposed method achieved an impressive success rate of up to 80% in repairing vulnerable code encompassing buffer overflow and pointer dereference failures.","We assert that this automated approach can effectively incorporate into the software development lifecycle's continuous integration and deployment (CI/CD) process."],"url":"http://arxiv.org/abs/2305.14752v1"}
{"created":"2023-05-24","title":"Enabling Large Language Models to Generate Text with Citations","abstract":"Large language models (LLMs) have emerged as a widely-used tool for information seeking, but their generated outputs are prone to hallucination. In this work, we aim to enable LLMs to generate text with citations, improving their factual correctness and verifiability. Existing work mainly relies on commercial search engines and human evaluation, making it challenging to reproduce and compare with different modeling approaches. We propose ALCE, the first benchmark for Automatic LLMs' Citation Evaluation. ALCE collects a diverse set of questions and retrieval corpora and requires building end-to-end systems to retrieve supporting evidence and generate answers with citations. We build automatic metrics along three dimensions -- fluency, correctness, and citation quality -- and demonstrate their strong correlation with human judgements. Our experiments with state-of-the-art LLMs and novel prompting strategies show that current systems have considerable room for improvements -- for example, on the ELI5 dataset, even the best model has 49% of its generations lacking complete citation support. Our extensive analyses further highlight promising future directions, including developing better retrievers, advancing long-context LLMs, and improving the ability to synthesize information from multiple sources.","sentences":["Large language models (LLMs) have emerged as a widely-used tool for information seeking, but their generated outputs are prone to hallucination.","In this work, we aim to enable LLMs to generate text with citations, improving their factual correctness and verifiability.","Existing work mainly relies on commercial search engines and human evaluation, making it challenging to reproduce and compare with different modeling approaches.","We propose ALCE, the first benchmark for Automatic LLMs' Citation Evaluation.","ALCE collects a diverse set of questions and retrieval corpora and requires building end-to-end systems to retrieve supporting evidence and generate answers with citations.","We build automatic metrics along three dimensions -- fluency, correctness, and citation quality -- and demonstrate their strong correlation with human judgements.","Our experiments with state-of-the-art LLMs and novel prompting strategies show that current systems have considerable room for improvements -- for example, on the ELI5 dataset, even the best model has 49% of its generations lacking complete citation support.","Our extensive analyses further highlight promising future directions, including developing better retrievers, advancing long-context LLMs, and improving the ability to synthesize information from multiple sources."],"url":"http://arxiv.org/abs/2305.14627v1"}
{"created":"2023-05-24","title":"ALGO: Synthesizing Algorithmic Programs with Generated Oracle Verifiers","abstract":"Large language models (LLMs) excel at implementing code from functionality descriptions, but struggle with algorithmic problems that require not only implementation but also identification of the suitable algorithm. Moreover, LLM-generated programs lack guaranteed correctness and require human verification. To address these challenges, we propose ALGO, a framework that synthesizes Algorithmic programs with LLM-Generated Oracles to guide the creation and verify their correctness. ALGO first generates a probably correct but possibly slow reference oracle by prompting an LLM to exhaustively enumerate all the combinations of relevant variables. This oracle is then utilized to guide an arbitrary search strategy in exploring the algorithm space and to verify the algorithms synthesized. Our study shows that the LLM-generated oracles are correct for 88% of the cases. With the oracles as verifiers, ALGO can be integrated with any existing code generation model in a model-agnostic manner to enhance its performance. Experiments show that when equipped with ALGO, we achieve an 8x better one-submission pass rate over the Codex model and a 2.6x better one-submission pass rate over CodeT, the current state-of-the-art model on CodeContests. We can also get 1.3x better pass rate over the ChatGPT Code Interpreter on unseen problems.","sentences":["Large language models (LLMs) excel at implementing code from functionality descriptions, but struggle with algorithmic problems that require not only implementation but also identification of the suitable algorithm.","Moreover, LLM-generated programs lack guaranteed correctness and require human verification.","To address these challenges, we propose ALGO, a framework that synthesizes Algorithmic programs with LLM-Generated Oracles to guide the creation and verify their correctness.","ALGO first generates a probably correct but possibly slow reference oracle by prompting an LLM to exhaustively enumerate all the combinations of relevant variables.","This oracle is then utilized to guide an arbitrary search strategy in exploring the algorithm space and to verify the algorithms synthesized.","Our study shows that the LLM-generated oracles are correct for 88% of the cases.","With the oracles as verifiers, ALGO can be integrated with any existing code generation model in a model-agnostic manner to enhance its performance.","Experiments show that when equipped with ALGO, we achieve an 8x better one-submission pass rate over the Codex model and a 2.6x better one-submission pass rate over CodeT, the current state-of-the-art model on CodeContests.","We can also get 1.3x better pass rate over the ChatGPT Code Interpreter on unseen problems."],"url":"http://arxiv.org/abs/2305.14591v1"}
{"created":"2023-05-24","title":"From Text to MITRE Techniques: Exploring the Malicious Use of Large Language Models for Generating Cyber Attack Payloads","abstract":"This research article critically examines the potential risks and implications arising from the malicious utilization of large language models(LLM), focusing specifically on ChatGPT and Google's Bard. Although these large language models have numerous beneficial applications, the misuse of this technology by cybercriminals for creating offensive payloads and tools is a significant concern. In this study, we systematically generated implementable code for the top-10 MITRE Techniques prevalent in 2022, utilizing ChatGPT, and conduct a comparative analysis of its performance with Google's Bard. Our experimentation reveals that ChatGPT has the potential to enable attackers to accelerate the operation of more targeted and sophisticated attacks. Additionally, the technology provides amateur attackers with more capabilities to perform a wide range of attacks and empowers script kiddies to develop customized tools that contribute to the acceleration of cybercrime. Furthermore, LLMs significantly benefits malware authors, particularly ransomware gangs, in generating sophisticated variants of wiper and ransomware attacks with ease. On a positive note, our study also highlights how offensive security researchers and pentesters can make use of LLMs to simulate realistic attack scenarios, identify potential vulnerabilities, and better protect organizations. Overall, we conclude by emphasizing the need for increased vigilance in mitigating the risks associated with LLMs. This includes implementing robust security measures, increasing awareness and education around the potential risks of this technology, and collaborating with security experts to stay ahead of emerging threats.","sentences":["This research article critically examines the potential risks and implications arising from the malicious utilization of large language models(LLM), focusing specifically on ChatGPT and Google's Bard.","Although these large language models have numerous beneficial applications, the misuse of this technology by cybercriminals for creating offensive payloads and tools is a significant concern.","In this study, we systematically generated implementable code for the top-10 MITRE Techniques prevalent in 2022, utilizing ChatGPT, and conduct a comparative analysis of its performance with Google's Bard.","Our experimentation reveals that ChatGPT has the potential to enable attackers to accelerate the operation of more targeted and sophisticated attacks.","Additionally, the technology provides amateur attackers with more capabilities to perform a wide range of attacks and empowers script kiddies to develop customized tools that contribute to the acceleration of cybercrime.","Furthermore, LLMs significantly benefits malware authors, particularly ransomware gangs, in generating sophisticated variants of wiper and ransomware attacks with ease.","On a positive note, our study also highlights how offensive security researchers and pentesters can make use of LLMs to simulate realistic attack scenarios, identify potential vulnerabilities, and better protect organizations.","Overall, we conclude by emphasizing the need for increased vigilance in mitigating the risks associated with LLMs.","This includes implementing robust security measures, increasing awareness and education around the potential risks of this technology, and collaborating with security experts to stay ahead of emerging threats."],"url":"http://arxiv.org/abs/2305.15336v1"}
{"created":"2023-05-24","title":"Science in the Era of ChatGPT, Large Language Models and AI: Challenges for Research Ethics Review and How to Respond","abstract":"Large language models of artificial intelligence (AI) such as ChatGPT find remarkable but controversial applicability in science and research. This paper reviews epistemological challenges, ethical and integrity risks in science conduct. This is with the aim to lay new timely foundations for a high-quality research ethics review in the era of AI. The role of AI language models as a research instrument and subject is scrutinized along with ethical implications for scientists, participants and reviewers. Ten recommendations shape a response for a more responsible research conduct with AI language models.","sentences":["Large language models of artificial intelligence (AI) such as ChatGPT find remarkable but controversial applicability in science and research.","This paper reviews epistemological challenges, ethical and integrity risks in science conduct.","This is with the aim to lay new timely foundations for a high-quality research ethics review in the era of AI.","The role of AI language models as a research instrument and subject is scrutinized along with ethical implications for scientists, participants and reviewers.","Ten recommendations shape a response for a more responsible research conduct with AI language models."],"url":"http://arxiv.org/abs/2305.15299v1"}
{"created":"2023-05-24","title":"Machine Unlearning: its nature, scope, and importance for a \"delete culture\"","abstract":"The article explores the cultural shift from recording to deleting information in the digital age and its implications on privacy, intellectual property (IP), and Large Language Models like ChatGPT. It begins by defining a delete culture where information, in principle legal, is made unavailable or inaccessible because unacceptable or undesirable, especially but not only due to its potential to infringe on privacy or IP. Then it focuses on two strategies in this context: deleting, to make information unavailable; and blocking, to make it inaccessible. The article argues that both strategies have significant implications, particularly for machine learning (ML) models where information is not easily made unavailable. However, the emerging research area of Machine Unlearning (MU) is highlighted as a potential solution. MU, still in its infancy, seeks to remove specific data points from ML models, effectively making them 'forget' completely specific information. If successful, MU could provide a feasible means to manage the overabundance of information and ensure a better protection of privacy and IP. However, potential ethical risks, such as misuse, overuse, and underuse of MU, should be systematically studied to devise appropriate policies.","sentences":["The article explores the cultural shift from recording to deleting information in the digital age and its implications on privacy, intellectual property (IP), and Large Language Models like ChatGPT.","It begins by defining a delete culture where information, in principle legal, is made unavailable or inaccessible because unacceptable or undesirable, especially but not only due to its potential to infringe on privacy or IP.","Then it focuses on two strategies in this context: deleting, to make information unavailable; and blocking, to make it inaccessible.","The article argues that both strategies have significant implications, particularly for machine learning (ML) models where information is not easily made unavailable.","However, the emerging research area of Machine Unlearning (MU) is highlighted as a potential solution.","MU, still in its infancy, seeks to remove specific data points from ML models, effectively making them 'forget' completely specific information.","If successful, MU could provide a feasible means to manage the overabundance of information and ensure a better protection of privacy and IP.","However, potential ethical risks, such as misuse, overuse, and underuse of MU, should be systematically studied to devise appropriate policies."],"url":"http://arxiv.org/abs/2305.15242v1"}
{"created":"2023-05-24","title":"Eliciting the Translation Ability of Large Language Models via Multilingual Finetuning with Translation Instructions","abstract":"Large-scale Pretrained Language Models~(LLMs), such as ChatGPT and GPT4, have shown strong abilities in multilingual translations, without being explicitly trained on parallel corpora. It is interesting how the LLMs obtain their ability to carry out translation instructions for different languages. In this paper, we present a detailed analysis by finetuning a multilingual pretrained language model, XGLM-7B, to perform multilingual translation following given instructions. Firstly, we show that the multilingual LLMs have stronger translation abilities than previously demonstrated. For a certain language pair, the performance depends on both the language families and the amount of data used in the pretraining phase. Secondly, we find that LLMs' ability to carry out translation instructions relies on the understanding of translation instruction and the alignment among different languages. With proper enhancement, LLMs could perform the translation task well even for those language pairs unseen during the instruction tuning phase.","sentences":["Large-scale Pretrained Language Models~(LLMs), such as ChatGPT and GPT4, have shown strong abilities in multilingual translations, without being explicitly trained on parallel corpora.","It is interesting how the LLMs obtain their ability to carry out translation instructions for different languages.","In this paper, we present a detailed analysis by finetuning a multilingual pretrained language model, XGLM-7B, to perform multilingual translation following given instructions.","Firstly, we show that the multilingual LLMs have stronger translation abilities than previously demonstrated.","For a certain language pair, the performance depends on both the language families and the amount of data used in the pretraining phase.","Secondly, we find that LLMs' ability to carry out translation instructions relies on the understanding of translation instruction and the alignment among different languages.","With proper enhancement, LLMs could perform the translation task well even for those language pairs unseen during the instruction tuning phase."],"url":"http://arxiv.org/abs/2305.15083v1"}
{"created":"2023-05-24","title":"HuatuoGPT, towards Taming Language Model to Be a Doctor","abstract":"In this paper, we present HuatuoGPT, a large language model (LLM) for medical consultation. The core recipe of HuatuoGPT is to leverage both \\textit{distilled data from ChatGPT} and \\textit{real-world data from doctors} in the supervised fine-tuned stage. The responses of ChatGPT are usually detailed, well-presented and informative while it cannot perform like a doctor in many aspects, e.g. for integrative diagnosis. We argue that real-world data from doctors would be complementary to distilled data in the sense the former could tame a distilled language model to perform like doctors. To better leverage the strengths of both data, we train a reward model to align the language model with the merits that both data bring, following an RLAIF (reinforced learning from AI feedback) fashion. To evaluate and benchmark the models, we propose a comprehensive evaluation scheme (including automatic and manual metrics). Experimental results demonstrate that HuatuoGPT achieves state-of-the-art results in performing medical consultation among open-source LLMs in GPT-4 evaluation, human evaluation, and medical benchmark datasets. It is worth noting that by using additional real-world data and RLAIF, the distilled language model (i.e., HuatuoGPT) outperforms its teacher model ChatGPT in most cases. Our code, data, and models are publicly available at \\url{https://github.com/FreedomIntelligence/HuatuoGPT}. The online demo is available at \\url{https://www.HuatuoGPT.cn/}.","sentences":["In this paper, we present HuatuoGPT, a large language model (LLM) for medical consultation.","The core recipe of HuatuoGPT is to leverage both \\textit{distilled data from ChatGPT} and \\textit{real-world data from doctors} in the supervised fine-tuned stage.","The responses of ChatGPT are usually detailed, well-presented and informative while it cannot perform like a doctor in many aspects, e.g. for integrative diagnosis.","We argue that real-world data from doctors would be complementary to distilled data in the sense the former could tame a distilled language model to perform like doctors.","To better leverage the strengths of both data, we train a reward model to align the language model with the merits that both data bring, following an RLAIF (reinforced learning from AI feedback) fashion.","To evaluate and benchmark the models, we propose a comprehensive evaluation scheme (including automatic and manual metrics).","Experimental results demonstrate that HuatuoGPT achieves state-of-the-art results in performing medical consultation among open-source LLMs in GPT-4 evaluation, human evaluation, and medical benchmark datasets.","It is worth noting that by using additional real-world data and RLAIF, the distilled language model (i.e., HuatuoGPT) outperforms its teacher model ChatGPT in most cases.","Our code, data, and models are publicly available at \\url{https://github.com/FreedomIntelligence/HuatuoGPT}.","The online demo is available at \\url{https://www.HuatuoGPT.cn/}."],"url":"http://arxiv.org/abs/2305.15075v1"}
{"created":"2023-05-24","title":"PathAsst: Redefining Pathology through Generative Foundation AI Assistant for Pathology","abstract":"As advances in large language models (LLMs) and multimodal techniques continue to mature, the development of general-purpose multimodal large language models (MLLMs) has surged, with significant applications in natural image interpretation. However, the field of pathology has largely remained untapped in this regard, despite the growing need for accurate, timely, and personalized diagnostics. To bridge the gap in pathology MLLMs, we present the PathAsst in this study, which is a generative foundation AI assistant to revolutionize diagnostic and predictive analytics in pathology. To develop PathAsst, we collect over 142K high-quality pathology image-text pairs from a variety of reliable sources, including PubMed, comprehensive pathology textbooks, reputable pathology websites, and private data annotated by pathologists. Leveraging the advanced capabilities of ChatGPT/GPT-4, we generate over 180K instruction-following samples. Furthermore, we devise additional instruction-following data, specifically tailored for the invocation of the pathology-specific models, allowing the PathAsst to effectively interact with these models based on the input image and user intent, consequently enhancing the model's diagnostic capabilities. Subsequently, our PathAsst is trained based on Vicuna-13B language model in coordination with the CLIP vision encoder. The results of PathAsst show the potential of harnessing the AI-powered generative foundation model to improve pathology diagnosis and treatment processes. We are committed to open-sourcing our meticulously curated dataset, as well as a comprehensive toolkit designed to aid researchers in the extensive collection and preprocessing of their own datasets. Resources can be obtained at https://github.com/superjamessyx/Generative-Foundation-AI-Assistant-for-Pathology.","sentences":["As advances in large language models (LLMs) and multimodal techniques continue to mature, the development of general-purpose multimodal large language models (MLLMs) has surged, with significant applications in natural image interpretation.","However, the field of pathology has largely remained untapped in this regard, despite the growing need for accurate, timely, and personalized diagnostics.","To bridge the gap in pathology MLLMs, we present the PathAsst in this study, which is a generative foundation AI assistant to revolutionize diagnostic and predictive analytics in pathology.","To develop PathAsst, we collect over 142K high-quality pathology image-text pairs from a variety of reliable sources, including PubMed, comprehensive pathology textbooks, reputable pathology websites, and private data annotated by pathologists.","Leveraging the advanced capabilities of ChatGPT/GPT-4, we generate over 180K instruction-following samples.","Furthermore, we devise additional instruction-following data, specifically tailored for the invocation of the pathology-specific models, allowing the PathAsst to effectively interact with these models based on the input image and user intent, consequently enhancing the model's diagnostic capabilities.","Subsequently, our PathAsst is trained based on Vicuna-13B language model in coordination with the CLIP vision encoder.","The results of PathAsst show the potential of harnessing the AI-powered generative foundation model to improve pathology diagnosis and treatment processes.","We are committed to open-sourcing our meticulously curated dataset, as well as a comprehensive toolkit designed to aid researchers in the extensive collection and preprocessing of their own datasets.","Resources can be obtained at https://github.com/superjamessyx/Generative-Foundation-AI-Assistant-for-Pathology."],"url":"http://arxiv.org/abs/2305.15072v1"}
{"created":"2023-05-24","title":"GPT4Graph: Can Large Language Models Understand Graph Structured Data ? An Empirical Evaluation and Benchmarking","abstract":"Large language models~(LLM) like ChatGPT have become indispensable to artificial general intelligence~(AGI), demonstrating excellent performance in various natural language processing tasks. In the real world, graph data is ubiquitous and an essential part of AGI and prevails in domains like social network analysis, bioinformatics and recommender systems. The training corpus of large language models often includes some algorithmic components, which allows them to achieve certain effects on some graph data-related problems. However, there is still little research on their performance on a broader range of graph-structured data. In this study, we conduct an extensive investigation to assess the proficiency of LLMs in comprehending graph data, employing a diverse range of structural and semantic-related tasks. Our analysis encompasses 10 distinct tasks that evaluate the LLMs' capabilities in graph understanding. Through our study, we not only uncover the current limitations of language models in comprehending graph structures and performing associated reasoning tasks but also emphasize the necessity for further advancements and novel approaches to enhance their graph processing capabilities. Our findings contribute valuable insights towards bridging the gap between language models and graph understanding, paving the way for more effective graph mining and knowledge extraction.","sentences":["Large language models~(LLM) like ChatGPT have become indispensable to artificial general intelligence~(AGI), demonstrating excellent performance in various natural language processing tasks.","In the real world, graph data is ubiquitous and an essential part of AGI and prevails in domains like social network analysis, bioinformatics and recommender systems.","The training corpus of large language models often includes some algorithmic components, which allows them to achieve certain effects on some graph data-related problems.","However, there is still little research on their performance on a broader range of graph-structured data.","In this study, we conduct an extensive investigation to assess the proficiency of LLMs in comprehending graph data, employing a diverse range of structural and semantic-related tasks.","Our analysis encompasses 10 distinct tasks that evaluate the LLMs' capabilities in graph understanding.","Through our study, we not only uncover the current limitations of language models in comprehending graph structures and performing associated reasoning tasks but also emphasize the necessity for further advancements and novel approaches to enhance their graph processing capabilities.","Our findings contribute valuable insights towards bridging the gap between language models and graph understanding, paving the way for more effective graph mining and knowledge extraction."],"url":"http://arxiv.org/abs/2305.15066v1"}
{"created":"2023-05-24","title":"ChatAgri: Exploring Potentials of ChatGPT on Cross-linguistic Agricultural Text Classification","abstract":"In the era of sustainable smart agriculture, a massive amount of agricultural news text is being posted on the Internet, in which massive agricultural knowledge has been accumulated. In this context, it is urgent to explore effective text classification techniques for users to access the required agricultural knowledge with high efficiency. Mainstream deep learning approaches employing fine-tuning strategies on pre-trained language models (PLMs), have demonstrated remarkable performance gains over the past few years. Nonetheless, these methods still face many drawbacks that are complex to solve, including: 1. Limited agricultural training data due to the expensive-cost and labour-intensive annotation; 2. Poor domain transferability, especially of cross-linguistic ability; 3. Complex and expensive large models deployment.Inspired by the extraordinary success brought by the recent ChatGPT (e.g. GPT-3.5, GPT-4), in this work, we systematically investigate and explore the capability and utilization of ChatGPT applying to the agricultural informatization field. ....(shown in article).... Code has been released on Github https://github.com/albert-jin/agricultural_textual_classification_ChatGPT.","sentences":["In the era of sustainable smart agriculture, a massive amount of agricultural news text is being posted on the Internet, in which massive agricultural knowledge has been accumulated.","In this context, it is urgent to explore effective text classification techniques for users to access the required agricultural knowledge with high efficiency.","Mainstream deep learning approaches employing fine-tuning strategies on pre-trained language models (PLMs), have demonstrated remarkable performance gains over the past few years.","Nonetheless, these methods still face many drawbacks that are complex to solve, including: 1. Limited agricultural training data due to the expensive-cost and labour-intensive annotation; 2. Poor domain transferability, especially of cross-linguistic ability; 3. Complex and expensive large models deployment.","Inspired by the extraordinary success brought by the recent ChatGPT (e.g. GPT-3.5, GPT-4), in this work, we systematically investigate and explore the capability and utilization of ChatGPT applying to the agricultural informatization field.","....(shown in article)....","Code has been released on Github https://github.com/albert-jin/agricultural_textual_classification_ChatGPT."],"url":"http://arxiv.org/abs/2305.15024v1"}
{"created":"2023-05-24","title":"Are Chatbots Ready for Privacy-Sensitive Applications? An Investigation into Input Regurgitation and Prompt-Induced Sanitization","abstract":"LLM-powered chatbots are becoming widely adopted in applications such as healthcare, personal assistants, industry hiring decisions, etc. In many of these cases, chatbots are fed sensitive, personal information in their prompts, as samples for in-context learning, retrieved records from a database, or as part of the conversation. The information provided in the prompt could directly appear in the output, which might have privacy ramifications if there is sensitive information there. As such, in this paper, we aim to understand the input copying and regurgitation capabilities of these models during inference and how they can be directly instructed to limit this copying by complying with regulations such as HIPAA and GDPR, based on their internal knowledge of them. More specifically, we find that when ChatGPT is prompted to summarize cover letters of a 100 candidates, it would retain personally identifiable information (PII) verbatim in 57.4% of cases, and we find this retention to be non-uniform between different subgroups of people, based on attributes such as gender identity. We then probe ChatGPT's perception of privacy-related policies and privatization mechanisms by directly instructing it to provide compliant outputs and observe a significant omission of PII from output.","sentences":["LLM-powered chatbots are becoming widely adopted in applications such as healthcare, personal assistants, industry hiring decisions, etc.","In many of these cases, chatbots are fed sensitive, personal information in their prompts, as samples for in-context learning, retrieved records from a database, or as part of the conversation.","The information provided in the prompt could directly appear in the output, which might have privacy ramifications if there is sensitive information there.","As such, in this paper, we aim to understand the input copying and regurgitation capabilities of these models during inference and how they can be directly instructed to limit this copying by complying with regulations such as HIPAA and GDPR, based on their internal knowledge of them.","More specifically, we find that when ChatGPT is prompted to summarize cover letters of a 100 candidates, it would retain personally identifiable information (PII) verbatim in 57.4% of cases, and we find this retention to be non-uniform between different subgroups of people, based on attributes such as gender identity.","We then probe ChatGPT's perception of privacy-related policies and privatization mechanisms by directly instructing it to provide compliant outputs and observe a significant omission of PII from output."],"url":"http://arxiv.org/abs/2305.15008v1"}
{"created":"2023-05-24","title":"Sentiment Analysis in the Era of Large Language Models: A Reality Check","abstract":"Sentiment analysis (SA) has been a long-standing research area in natural language processing. It can offer rich insights into human sentiments and opinions and has thus seen considerable interest from both academia and industry. With the advent of large language models (LLMs) such as ChatGPT, there is a great potential for their employment on SA problems. However, the extent to which existing LLMs can be leveraged for different sentiment analysis tasks remains unclear. This paper aims to provide a comprehensive investigation into the capabilities of LLMs in performing various sentiment analysis tasks, from conventional sentiment classification to aspect-based sentiment analysis and multifaceted analysis of subjective texts. We evaluate performance across 13 tasks on 26 datasets and compare the results against small language models (SLMs) trained on domain-specific datasets. Our study reveals that while LLMs demonstrate satisfactory performance in simpler tasks, they lag behind in more complex tasks requiring deeper understanding or structured sentiment information. However, LLMs significantly outperform SLMs in few-shot learning settings, suggesting their potential when annotation resources are limited. We also highlight the limitations of current evaluation practices in assessing LLMs' SA abilities and propose a novel benchmark, \\textsc{SentiEval}, for a more comprehensive and realistic evaluation. Data and code during our investigations are available at \\url{https://github.com/DAMO-NLP-SG/LLM-Sentiment}.","sentences":["Sentiment analysis (SA) has been a long-standing research area in natural language processing.","It can offer rich insights into human sentiments and opinions and has thus seen considerable interest from both academia and industry.","With the advent of large language models (LLMs) such as ChatGPT, there is a great potential for their employment on SA problems.","However, the extent to which existing LLMs can be leveraged for different sentiment analysis tasks remains unclear.","This paper aims to provide a comprehensive investigation into the capabilities of LLMs in performing various sentiment analysis tasks, from conventional sentiment classification to aspect-based sentiment analysis and multifaceted analysis of subjective texts.","We evaluate performance across 13 tasks on 26 datasets and compare the results against small language models (SLMs) trained on domain-specific datasets.","Our study reveals that while LLMs demonstrate satisfactory performance in simpler tasks, they lag behind in more complex tasks requiring deeper understanding or structured sentiment information.","However, LLMs significantly outperform SLMs in few-shot learning settings, suggesting their potential when annotation resources are limited.","We also highlight the limitations of current evaluation practices in assessing LLMs' SA abilities and propose a novel benchmark, \\textsc{SentiEval}, for a more comprehensive and realistic evaluation.","Data and code during our investigations are available at \\url{https://github.com/DAMO-NLP-SG/LLM-Sentiment}."],"url":"http://arxiv.org/abs/2305.15005v1"}
{"created":"2023-05-24","title":"Balancing the Picture: Debiasing Vision-Language Datasets with Synthetic Contrast Sets","abstract":"Vision-language models are growing in popularity and public visibility to generate, edit, and caption images at scale; but their outputs can perpetuate and amplify societal biases learned during pre-training on uncurated image-text pairs from the internet. Although debiasing methods have been proposed, we argue that these measurements of model bias lack validity due to dataset bias. We demonstrate there are spurious correlations in COCO Captions, the most commonly used dataset for evaluating bias, between background context and the gender of people in-situ. This is problematic because commonly-used bias metrics (such as Bias@K) rely on per-gender base rates. To address this issue, we propose a novel dataset debiasing pipeline to augment the COCO dataset with synthetic, gender-balanced contrast sets, where only the gender of the subject is edited and the background is fixed. However, existing image editing methods have limitations and sometimes produce low-quality images; so, we introduce a method to automatically filter the generated images based on their similarity to real images. Using our balanced synthetic contrast sets, we benchmark bias in multiple CLIP-based models, demonstrating how metrics are skewed by imbalance in the original COCO images. Our results indicate that the proposed approach improves the validity of the evaluation, ultimately contributing to more realistic understanding of bias in vision-language models.","sentences":["Vision-language models are growing in popularity and public visibility to generate, edit, and caption images at scale; but their outputs can perpetuate and amplify societal biases learned during pre-training on uncurated image-text pairs from the internet.","Although debiasing methods have been proposed, we argue that these measurements of model bias lack validity due to dataset bias.","We demonstrate there are spurious correlations in COCO Captions, the most commonly used dataset for evaluating bias, between background context and the gender of people in-situ.","This is problematic because commonly-used bias metrics (such as Bias@K) rely on per-gender base rates.","To address this issue, we propose a novel dataset debiasing pipeline to augment the COCO dataset with synthetic, gender-balanced contrast sets, where only the gender of the subject is edited and the background is fixed.","However, existing image editing methods have limitations and sometimes produce low-quality images; so, we introduce a method to automatically filter the generated images based on their similarity to real images.","Using our balanced synthetic contrast sets, we benchmark bias in multiple CLIP-based models, demonstrating how metrics are skewed by imbalance in the original COCO images.","Our results indicate that the proposed approach improves the validity of the evaluation, ultimately contributing to more realistic understanding of bias in vision-language models."],"url":"http://arxiv.org/abs/2305.15407v1"}
{"created":"2023-05-24","title":"AV-TranSpeech: Audio-Visual Robust Speech-to-Speech Translation","abstract":"Direct speech-to-speech translation (S2ST) aims to convert speech from one language into another, and has demonstrated significant progress to date. Despite the recent success, current S2ST models still suffer from distinct degradation in noisy environments and fail to translate visual speech (i.e., the movement of lips and teeth). In this work, we present AV-TranSpeech, the first audio-visual speech-to-speech (AV-S2ST) translation model without relying on intermediate text. AV-TranSpeech complements the audio stream with visual information to promote system robustness and opens up a host of practical applications: dictation or dubbing archival films. To mitigate the data scarcity with limited parallel AV-S2ST data, we 1) explore self-supervised pre-training with unlabeled audio-visual data to learn contextual representation, and 2) introduce cross-modal distillation with S2ST models trained on the audio-only corpus to further reduce the requirements of visual data. Experimental results on two language pairs demonstrate that AV-TranSpeech outperforms audio-only models under all settings regardless of the type of noise. With low-resource audio-visual data (10h, 30h), cross-modal distillation yields an improvement of 7.6 BLEU on average compared with baselines. Audio samples are available at https://AV-TranSpeech.github.io","sentences":["Direct speech-to-speech translation (S2ST) aims to convert speech from one language into another, and has demonstrated significant progress to date.","Despite the recent success, current S2ST models still suffer from distinct degradation in noisy environments and fail to translate visual speech (i.e., the movement of lips and teeth).","In this work, we present AV-TranSpeech, the first audio-visual speech-to-speech (AV-S2ST) translation model without relying on intermediate text.","AV-TranSpeech complements the audio stream with visual information to promote system robustness and opens up a host of practical applications: dictation or dubbing archival films.","To mitigate the data scarcity with limited parallel AV-S2ST data, we 1) explore self-supervised pre-training with unlabeled audio-visual data to learn contextual representation, and 2) introduce cross-modal distillation with S2ST models trained on the audio-only corpus to further reduce the requirements of visual data.","Experimental results on two language pairs demonstrate that AV-TranSpeech outperforms audio-only models under all settings regardless of the type of noise.","With low-resource audio-visual data (10h, 30h), cross-modal distillation yields an improvement of 7.6 BLEU on average compared with baselines.","Audio samples are available at https://AV-TranSpeech.github.io"],"url":"http://arxiv.org/abs/2305.15403v1"}
{"created":"2023-05-24","title":"Machine Learning Prediction of Critical Cooling Rate for Metallic Glasses From Expanded Datasets and Elemental Features","abstract":"We use a random forest model to predict the critical cooling rate (RC) for glass formation of various alloys from features of their constituent elements. The random forest model was trained on a database that integrates multiple sources of direct and indirect RC data for metallic glasses to expand the directly measured RC database of less than 100 values to a training set of over 2,000 values. The model error on 5-fold cross validation is 0.66 orders of magnitude in K/s. The error on leave out one group cross validation on alloy system groups is 0.59 log units in K/s when the target alloy constituents appear more than 500 times in training data. Using this model, we make predictions for the set of compositions with melt-spun glasses in the database, and for the full set of quaternary alloys that have constituents which appear more than 500 times in training data. These predictions identify a number of potential new bulk metallic glass (BMG) systems for future study, but the model is most useful for identification of alloy systems likely to contain good glass formers, rather than detailed discovery of bulk glass composition regions within known glassy systems.","sentences":["We use a random forest model to predict the critical cooling rate (RC) for glass formation of various alloys from features of their constituent elements.","The random forest model was trained on a database that integrates multiple sources of direct and indirect RC data for metallic glasses to expand the directly measured RC database of less than 100 values to a training set of over 2,000 values.","The model error on 5-fold cross validation is 0.66 orders of magnitude in K/s. The error on leave out one group cross validation on alloy system groups is 0.59 log units in K/s when the target alloy constituents appear more than 500 times in training data.","Using this model, we make predictions for the set of compositions with melt-spun glasses in the database, and for the full set of quaternary alloys that have constituents which appear more than 500 times in training data.","These predictions identify a number of potential new bulk metallic glass (BMG) systems for future study, but the model is most useful for identification of alloy systems likely to contain good glass formers, rather than detailed discovery of bulk glass composition regions within known glassy systems."],"url":"http://arxiv.org/abs/2305.15390v1"}
{"created":"2023-05-24","title":"Vistaar: Diverse Benchmarks and Training Sets for Indian Language ASR","abstract":"Improving ASR systems is necessary to make new LLM-based use-cases accessible to people across the globe. In this paper, we focus on Indian languages, and make the case that diverse benchmarks are required to evaluate and improve ASR systems for Indian languages. To address this, we collate Vistaar as a set of 59 benchmarks across various language and domain combinations, on which we evaluate 3 publicly available ASR systems and 2 commercial systems. We also train IndicWhisper models by fine-tuning the Whisper models on publicly available training datasets across 12 Indian languages totalling to 10.7K hours. We show that IndicWhisper significantly improves on considered ASR systems on the Vistaar benchmark. Indeed, IndicWhisper has the lowest WER in 39 out of the 59 benchmarks, with an average reduction of 4.1 WER. We open-source all datasets, code and models.","sentences":["Improving ASR systems is necessary to make new LLM-based use-cases accessible to people across the globe.","In this paper, we focus on Indian languages, and make the case that diverse benchmarks are required to evaluate and improve ASR systems for Indian languages.","To address this, we collate Vistaar as a set of 59 benchmarks across various language and domain combinations, on which we evaluate 3 publicly available ASR systems and 2 commercial systems.","We also train IndicWhisper models by fine-tuning the Whisper models on publicly available training datasets across 12 Indian languages totalling to 10.7K hours.","We show that IndicWhisper significantly improves on considered ASR systems on the Vistaar benchmark.","Indeed, IndicWhisper has the lowest WER in 39 out of the 59 benchmarks, with an average reduction of 4.1 WER.","We open-source all datasets, code and models."],"url":"http://arxiv.org/abs/2305.15386v1"}
{"created":"2023-05-24","title":"Sentiment Analysis Using Aligned Word Embeddings for Uralic Languages","abstract":"In this paper, we present an approach for translating word embeddings from a majority language into 4 minority languages: Erzya, Moksha, Udmurt and Komi-Zyrian. Furthermore, we align these word embeddings and present a novel neural network model that is trained on English data to conduct sentiment analysis and then applied on endangered language data through the aligned word embeddings. To test our model, we annotated a small sentiment analysis corpus for the 4 endangered languages and Finnish. Our method reached at least 56\\% accuracy for each endangered language. The models and the sentiment corpus will be released together with this paper. Our research shows that state-of-the-art neural models can be used with endangered languages with the only requirement being a dictionary between the endangered language and a majority language.","sentences":["In this paper, we present an approach for translating word embeddings from a majority language into 4 minority languages: Erzya, Moksha, Udmurt and Komi-Zyrian.","Furthermore, we align these word embeddings and present a novel neural network model that is trained on English data to conduct sentiment analysis and then applied on endangered language data through the aligned word embeddings.","To test our model, we annotated a small sentiment analysis corpus for the 4 endangered languages and Finnish.","Our method reached at least 56\\% accuracy for each endangered language.","The models and the sentiment corpus will be released together with this paper.","Our research shows that state-of-the-art neural models can be used with endangered languages with the only requirement being a dictionary between the endangered language and a majority language."],"url":"http://arxiv.org/abs/2305.15380v1"}
{"created":"2023-05-24","title":"Uncovering and Quantifying Social Biases in Code Generation","abstract":"With the popularity of automatic code generation tools, such as Copilot, the study of the potential hazards of these tools is gaining importance. In this work, we explore the social bias problem in pre-trained code generation models. We propose a new paradigm to construct code prompts and successfully uncover social biases in code generation models. To quantify the severity of social biases in generated code, we develop a dataset along with three metrics to evaluate the overall social bias and fine-grained unfairness across different demographics. Experimental results on three pre-trained code generation models (Codex, InCoder, and CodeGen) with varying sizes, reveal severe social biases. Moreover, we conduct analysis to provide useful insights for further choice of code generation models with low social bias. (This work contains examples that potentially implicate stereotypes, associations, and other harms that could be offensive to individuals in certain social groups.)","sentences":["With the popularity of automatic code generation tools, such as Copilot, the study of the potential hazards of these tools is gaining importance.","In this work, we explore the social bias problem in pre-trained code generation models.","We propose a new paradigm to construct code prompts and successfully uncover social biases in code generation models.","To quantify the severity of social biases in generated code, we develop a dataset along with three metrics to evaluate the overall social bias and fine-grained unfairness across different demographics.","Experimental results on three pre-trained code generation models (Codex, InCoder, and CodeGen) with varying sizes, reveal severe social biases.","Moreover, we conduct analysis to provide useful insights for further choice of code generation models with low social bias.","(This work contains examples that potentially implicate stereotypes, associations, and other harms that could be offensive to individuals in certain social groups.)"],"url":"http://arxiv.org/abs/2305.15377v1"}
{"created":"2023-05-24","title":"ASPER: Answer Set Programming Enhanced Neural Network Models for Joint Entity-Relation Extraction","abstract":"A plethora of approaches have been proposed for joint entity-relation (ER) extraction. Most of these methods largely depend on a large amount of manually annotated training data. However, manual data annotation is time consuming, labor intensive, and error prone. Human beings learn using both data (through induction) and knowledge (through deduction). Answer Set Programming (ASP) has been a widely utilized approach for knowledge representation and reasoning that is elaboration tolerant and adept at reasoning with incomplete information. This paper proposes a new approach, ASP-enhanced Entity-Relation extraction (ASPER), to jointly recognize entities and relations by learning from both data and domain knowledge. In particular, ASPER takes advantage of the factual knowledge (represented as facts in ASP) and derived knowledge (represented as rules in ASP) in the learning process of neural network models. We have conducted experiments on two real datasets and compare our method with three baselines. The results show that our ASPER model consistently outperforms the baselines.","sentences":["A plethora of approaches have been proposed for joint entity-relation (ER) extraction.","Most of these methods largely depend on a large amount of manually annotated training data.","However, manual data annotation is time consuming, labor intensive, and error prone.","Human beings learn using both data (through induction) and knowledge (through deduction).","Answer Set Programming (ASP) has been a widely utilized approach for knowledge representation and reasoning that is elaboration tolerant and adept at reasoning with incomplete information.","This paper proposes a new approach, ASP-enhanced Entity-Relation extraction (ASPER), to jointly recognize entities and relations by learning from both data and domain knowledge.","In particular, ASPER takes advantage of the factual knowledge (represented as facts in ASP) and derived knowledge (represented as rules in ASP) in the learning process of neural network models.","We have conducted experiments on two real datasets and compare our method with three baselines.","The results show that our ASPER model consistently outperforms the baselines."],"url":"http://arxiv.org/abs/2305.15374v1"}
{"created":"2023-05-24","title":"Stochastic Unrolled Federated Learning","abstract":"Algorithm unrolling has emerged as a learning-based optimization paradigm that unfolds truncated iterative algorithms in trainable neural-network optimizers. We introduce Stochastic UnRolled Federated learning (SURF), a method that expands algorithm unrolling to a federated learning scenario. Our proposed method tackles two challenges of this expansion, namely the need to feed whole datasets to the unrolled optimizers to find a descent direction and the decentralized nature of federated learning. We circumvent the former challenge by feeding stochastic mini-batches to each unrolled layer and imposing descent constraints to mitigate the randomness induced by using mini-batches. We address the latter challenge by unfolding the distributed gradient descent (DGD) algorithm in a graph neural network (GNN)-based unrolled architecture, which preserves the decentralized nature of training in federated learning. We theoretically prove that our proposed unrolled optimizer converges to a near-optimal region infinitely often. Through extensive numerical experiments, we also demonstrate the effectiveness of the proposed framework in collaborative training of image classifiers.","sentences":["Algorithm unrolling has emerged as a learning-based optimization paradigm that unfolds truncated iterative algorithms in trainable neural-network optimizers.","We introduce Stochastic UnRolled Federated learning (SURF), a method that expands algorithm unrolling to a federated learning scenario.","Our proposed method tackles two challenges of this expansion, namely the need to feed whole datasets to the unrolled optimizers to find a descent direction and the decentralized nature of federated learning.","We circumvent the former challenge by feeding stochastic mini-batches to each unrolled layer and imposing descent constraints to mitigate the randomness induced by using mini-batches.","We address the latter challenge by unfolding the distributed gradient descent (DGD) algorithm in a graph neural network (GNN)-based unrolled architecture, which preserves the decentralized nature of training in federated learning.","We theoretically prove that our proposed unrolled optimizer converges to a near-optimal region infinitely often.","Through extensive numerical experiments, we also demonstrate the effectiveness of the proposed framework in collaborative training of image classifiers."],"url":"http://arxiv.org/abs/2305.15371v1"}
{"created":"2023-05-24","title":"Boundary Attention Mapping (BAM): Fine-grained saliency maps for segmentation of Burn Injuries","abstract":"Burn injuries can result from mechanisms such as thermal, chemical, and electrical insults. A prompt and accurate assessment of burns is essential for deciding definitive clinical treatments. Currently, the primary approach for burn assessments, via visual and tactile observations, is approximately 60%-80% accurate. The gold standard is biopsy and a close second would be non-invasive methods like Laser Doppler Imaging (LDI) assessments, which have up to 97% accuracy in predicting burn severity and the required healing time. In this paper, we introduce a machine learning pipeline for assessing burn severities and segmenting the regions of skin that are affected by burn. Segmenting 2D colour images of burns allows for the injured versus non-injured skin to be delineated, clearly marking the extent and boundaries of the localized burn/region-of-interest, even during remote monitoring of a burn patient. We trained a convolutional neural network (CNN) to classify four severities of burns. We built a saliency mapping method, Boundary Attention Mapping (BAM), that utilises this trained CNN for the purpose of accurately localizing and segmenting the burn regions from skin burn images. We demonstrated the effectiveness of our proposed pipeline through extensive experiments and evaluations using two datasets; 1) A larger skin burn image dataset consisting of 1684 skin burn images of four burn severities, 2) An LDI dataset that consists of a total of 184 skin burn images with their associated LDI scans. The CNN trained using the first dataset achieved an average F1-Score of 78% and micro/macro- average ROC of 85% in classifying the four burn severities. Moreover, a comparison between the BAM results and LDI results for measuring injury boundary showed that the segmentations generated by our method achieved 91.60% accuracy, 78.17% sensitivity, and 93.37% specificity.","sentences":["Burn injuries can result from mechanisms such as thermal, chemical, and electrical insults.","A prompt and accurate assessment of burns is essential for deciding definitive clinical treatments.","Currently, the primary approach for burn assessments, via visual and tactile observations, is approximately 60%-80% accurate.","The gold standard is biopsy and a close second would be non-invasive methods like Laser Doppler Imaging (LDI) assessments, which have up to 97% accuracy in predicting burn severity and the required healing time.","In this paper, we introduce a machine learning pipeline for assessing burn severities and segmenting the regions of skin that are affected by burn.","Segmenting 2D colour images of burns allows for the injured versus non-injured skin to be delineated, clearly marking the extent and boundaries of the localized burn/region-of-interest, even during remote monitoring of a burn patient.","We trained a convolutional neural network (CNN) to classify four severities of burns.","We built a saliency mapping method, Boundary Attention Mapping (BAM), that utilises this trained CNN for the purpose of accurately localizing and segmenting the burn regions from skin burn images.","We demonstrated the effectiveness of our proposed pipeline through extensive experiments and evaluations using two datasets; 1) A larger skin burn image dataset consisting of 1684 skin burn images of four burn severities, 2) An LDI dataset that consists of a total of 184 skin burn images with their associated LDI scans.","The CNN trained using the first dataset achieved an average F1-Score of 78% and micro/macro- average ROC of 85% in classifying the four burn severities.","Moreover, a comparison between the BAM results and LDI results for measuring injury boundary showed that the segmentations generated by our method achieved 91.60% accuracy, 78.17% sensitivity, and 93.37% specificity."],"url":"http://arxiv.org/abs/2305.15365v1"}
{"created":"2023-05-24","title":"Private and Collaborative Kaplan-Meier Estimators","abstract":"Kaplan-Meier estimators capture the survival behavior of a cohort. They are one of the key statistics in survival analysis. As with any estimator, they become more accurate in presence of larger datasets. This motivates multiple data holders to share their data in order to calculate a more accurate Kaplan-Meier estimator. However, these survival datasets often contain sensitive information of individuals and it is the responsibility of the data holders to protect their data, thus a naive sharing of data is often not viable.   In this work, we propose two novel differentially private schemes that are facilitated by our novel synthetic dataset generation method. Based on these scheme we propose various paths that allow a joint estimation of the Kaplan-Meier curves with strict privacy guarantees.   Our contribution includes a taxonomy of methods for this task and an extensive experimental exploration and evaluation based on this structure. We show that we can construct a joint, global Kaplan-Meier estimator which satisfies very tight privacy guarantees and with no statistically-significant utility loss compared to the non-private centralized setting.","sentences":["Kaplan-Meier estimators capture the survival behavior of a cohort.","They are one of the key statistics in survival analysis.","As with any estimator, they become more accurate in presence of larger datasets.","This motivates multiple data holders to share their data in order to calculate a more accurate Kaplan-Meier estimator.","However, these survival datasets often contain sensitive information of individuals and it is the responsibility of the data holders to protect their data, thus a naive sharing of data is often not viable.   ","In this work, we propose two novel differentially private schemes that are facilitated by our novel synthetic dataset generation method.","Based on these scheme we propose various paths that allow a joint estimation of the Kaplan-Meier curves with strict privacy guarantees.   ","Our contribution includes a taxonomy of methods for this task and an extensive experimental exploration and evaluation based on this structure.","We show that we can construct a joint, global Kaplan-Meier estimator which satisfies very tight privacy guarantees and with no statistically-significant utility loss compared to the non-private centralized setting."],"url":"http://arxiv.org/abs/2305.15359v1"}
{"created":"2023-05-24","title":"Another Dead End for Morphological Tags? Perturbed Inputs and Parsing","abstract":"The usefulness of part-of-speech tags for parsing has been heavily questioned due to the success of word-contextualized parsers. Yet, most studies are limited to coarse-grained tags and high quality written content; while we know little about their influence when it comes to models in production that face lexical errors. We expand these setups and design an adversarial attack to verify if the use of morphological information by parsers: (i) contributes to error propagation or (ii) if on the other hand it can play a role to correct mistakes that word-only neural parsers make. The results on 14 diverse UD treebanks show that under such attacks, for transition- and graph-based models their use contributes to degrade the performance even faster, while for the (lower-performing) sequence labeling parsers they are helpful. We also show that if morphological tags were utopically robust against lexical perturbations, they would be able to correct parsing mistakes.","sentences":["The usefulness of part-of-speech tags for parsing has been heavily questioned due to the success of word-contextualized parsers.","Yet, most studies are limited to coarse-grained tags and high quality written content; while we know little about their influence when it comes to models in production that face lexical errors.","We expand these setups and design an adversarial attack to verify if the use of morphological information by parsers: (i) contributes to error propagation or (ii) if on the other hand it can play a role to correct mistakes that word-only neural parsers make.","The results on 14 diverse UD treebanks show that under such attacks, for transition- and graph-based models their use contributes to degrade the performance even faster, while for the (lower-performing) sequence labeling parsers they are helpful.","We also show that if morphological tags were utopically robust against lexical perturbations, they would be able to correct parsing mistakes."],"url":"http://arxiv.org/abs/2305.15119v1"}
{"created":"2023-05-24","title":"Reconstructive Neuron Pruning for Backdoor Defense","abstract":"Deep neural networks (DNNs) have been found to be vulnerable to backdoor attacks, raising security concerns about their deployment in mission-critical applications. While existing defense methods have demonstrated promising results, it is still not clear how to effectively remove backdoor-associated neurons in backdoored DNNs. In this paper, we propose a novel defense called \\emph{Reconstructive Neuron Pruning} (RNP) to expose and prune backdoor neurons via an unlearning and then recovering process. Specifically, RNP first unlearns the neurons by maximizing the model's error on a small subset of clean samples and then recovers the neurons by minimizing the model's error on the same data. In RNP, unlearning is operated at the neuron level while recovering is operated at the filter level, forming an asymmetric reconstructive learning procedure. We show that such an asymmetric process on only a few clean samples can effectively expose and prune the backdoor neurons implanted by a wide range of attacks, achieving a new state-of-the-art defense performance. Moreover, the unlearned model at the intermediate step of our RNP can be directly used to improve other backdoor defense tasks including backdoor removal, trigger recovery, backdoor label detection, and backdoor sample detection. Code is available at \\url{https://github.com/bboylyg/RNP}.","sentences":["Deep neural networks (DNNs) have been found to be vulnerable to backdoor attacks, raising security concerns about their deployment in mission-critical applications.","While existing defense methods have demonstrated promising results, it is still not clear how to effectively remove backdoor-associated neurons in backdoored DNNs.","In this paper, we propose a novel defense called \\emph{Reconstructive Neuron Pruning} (RNP) to expose and prune backdoor neurons via an unlearning and then recovering process.","Specifically, RNP first unlearns the neurons by maximizing the model's error on a small subset of clean samples and then recovers the neurons by minimizing the model's error on the same data.","In RNP, unlearning is operated at the neuron level while recovering is operated at the filter level, forming an asymmetric reconstructive learning procedure.","We show that such an asymmetric process on only a few clean samples can effectively expose and prune the backdoor neurons implanted by a wide range of attacks, achieving a new state-of-the-art defense performance.","Moreover, the unlearned model at the intermediate step of our RNP can be directly used to improve other backdoor defense tasks including backdoor removal, trigger recovery, backdoor label detection, and backdoor sample detection.","Code is available at \\url{https://github.com/bboylyg/RNP}."],"url":"http://arxiv.org/abs/2305.14876v1"}
{"created":"2023-05-24","title":"Robust 3D-aware Object Classification via Discriminative Render-and-Compare","abstract":"In real-world applications, it is essential to jointly estimate the 3D object pose and class label of objects, i.e., to perform 3D-aware classification.While current approaches for either image classification or pose estimation can be extended to 3D-aware classification, we observe that they are inherently limited: 1) Their performance is much lower compared to the respective single-task models, and 2) they are not robust in out-of-distribution (OOD) scenarios. Our main contribution is a novel architecture for 3D-aware classification, which builds upon a recent work and performs comparably to single-task models while being highly robust. In our method, an object category is represented as a 3D cuboid mesh composed of feature vectors at each mesh vertex. Using differentiable rendering, we estimate the 3D object pose by minimizing the reconstruction error between the mesh and the feature representation of the target image. Object classification is then performed by comparing the reconstruction losses across object categories. Notably, the neural texture of the mesh is trained in a discriminative manner to enhance the classification performance while also avoiding local optima in the reconstruction loss. Furthermore, we show how our method and feed-forward neural networks can be combined to scale the render-and-compare approach to larger numbers of categories. Our experiments on PASCAL3D+, occluded-PASCAL3D+, and OOD-CV show that our method outperforms all baselines at 3D-aware classification by a wide margin in terms of performance and robustness.","sentences":["In real-world applications, it is essential to jointly estimate the 3D object pose and class label of objects, i.e., to perform 3D-aware classification.","While current approaches for either image classification or pose estimation can be extended to 3D-aware classification, we observe that they are inherently limited:","1) Their performance is much lower compared to the respective single-task models, and 2) they are not robust in out-of-distribution (OOD) scenarios.","Our main contribution is a novel architecture for 3D-aware classification, which builds upon a recent work and performs comparably to single-task models while being highly robust.","In our method, an object category is represented as a 3D cuboid mesh composed of feature vectors at each mesh vertex.","Using differentiable rendering, we estimate the 3D object pose by minimizing the reconstruction error between the mesh and the feature representation of the target image.","Object classification is then performed by comparing the reconstruction losses across object categories.","Notably, the neural texture of the mesh is trained in a discriminative manner to enhance the classification performance while also avoiding local optima in the reconstruction loss.","Furthermore, we show how our method and feed-forward neural networks can be combined to scale the render-and-compare approach to larger numbers of categories.","Our experiments on PASCAL3D+, occluded-PASCAL3D+, and OOD-CV show that our method outperforms all baselines at 3D-aware classification by a wide margin in terms of performance and robustness."],"url":"http://arxiv.org/abs/2305.14668v1"}
{"created":"2023-05-24","title":"Measuring and Mitigating Constraint Violations of In-Context Learning for Utterance-to-API Semantic Parsing","abstract":"In executable task-oriented semantic parsing, the system aims to translate users' utterances in natural language to machine-interpretable programs (API calls) that can be executed according to pre-defined API specifications. With the popularity of Large Language Models (LLMs), in-context learning offers a strong baseline for such scenarios, especially in data-limited regimes. However, LLMs are known to hallucinate and therefore pose a formidable challenge in constraining generated content. Thus, it remains uncertain if LLMs can effectively perform task-oriented utterance-to-API generation where respecting API's structural and task-specific constraints is crucial.   In this work, we seek to measure, analyze and mitigate such constraints violations. First, we identify the categories of various constraints in obtaining API-semantics from task-oriented utterances, and define fine-grained metrics that complement traditional ones. Second, we leverage these metrics to conduct a detailed error analysis of constraints violations seen in state-of-the-art LLMs, which motivates us to investigate two mitigation strategies: Semantic-Retrieval of Demonstrations (SRD) and API-aware Constrained Decoding (API-CD). Our experiments show that these strategies are effective at reducing constraints violations and improving the quality of the generated API calls, but require careful consideration given their implementation complexity and latency.","sentences":["In executable task-oriented semantic parsing, the system aims to translate users' utterances in natural language to machine-interpretable programs (API calls) that can be executed according to pre-defined API specifications.","With the popularity of Large Language Models (LLMs), in-context learning offers a strong baseline for such scenarios, especially in data-limited regimes.","However, LLMs are known to hallucinate and therefore pose a formidable challenge in constraining generated content.","Thus, it remains uncertain if LLMs can effectively perform task-oriented utterance-to-API generation where respecting API's structural and task-specific constraints is crucial.   ","In this work, we seek to measure, analyze and mitigate such constraints violations.","First, we identify the categories of various constraints in obtaining API-semantics from task-oriented utterances, and define fine-grained metrics that complement traditional ones.","Second, we leverage these metrics to conduct a detailed error analysis of constraints violations seen in state-of-the-art LLMs, which motivates us to investigate two mitigation strategies: Semantic-Retrieval of Demonstrations (SRD) and API-aware Constrained Decoding (API-CD).","Our experiments show that these strategies are effective at reducing constraints violations and improving the quality of the generated API calls, but require careful consideration given their implementation complexity and latency."],"url":"http://arxiv.org/abs/2305.15338v1"}
{"created":"2023-05-24","title":"Breaking the Curse of Quality Saturation with User-Centric Ranking","abstract":"A key puzzle in search, ads, and recommendation is that the ranking model can only utilize a small portion of the vastly available user interaction data. As a result, increasing data volume, model size, or computation FLOPs will quickly suffer from diminishing returns. We examined this problem and found that one of the root causes may lie in the so-called ``item-centric'' formulation, which has an unbounded vocabulary and thus uncontrolled model complexity. To mitigate quality saturation, we introduce an alternative formulation named ``user-centric ranking'', which is based on a transposed view of the dyadic user-item interaction data. We show that this formulation has a promising scaling property, enabling us to train better-converged models on substantially larger data sets.","sentences":["A key puzzle in search, ads, and recommendation is that the ranking model can only utilize a small portion of the vastly available user interaction data.","As a result, increasing data volume, model size, or computation FLOPs will quickly suffer from diminishing returns.","We examined this problem and found that one of the root causes may lie in the so-called ``item-centric'' formulation, which has an unbounded vocabulary and thus uncontrolled model complexity.","To mitigate quality saturation, we introduce an alternative formulation named ``user-centric ranking'', which is based on a transposed view of the dyadic user-item interaction data.","We show that this formulation has a promising scaling property, enabling us to train better-converged models on substantially larger data sets."],"url":"http://arxiv.org/abs/2305.15333v1"}
{"created":"2023-05-24","title":"Training on Thin Air: Improve Image Classification with Generated Data","abstract":"Acquiring high-quality data for training discriminative models is a crucial yet challenging aspect of building effective predictive systems. In this paper, we present Diffusion Inversion, a simple yet effective method that leverages the pre-trained generative model, Stable Diffusion, to generate diverse, high-quality training data for image classification. Our approach captures the original data distribution and ensures data coverage by inverting images to the latent space of Stable Diffusion, and generates diverse novel training images by conditioning the generative model on noisy versions of these vectors. We identify three key components that allow our generated images to successfully supplant the original dataset, leading to a 2-3x enhancement in sample complexity and a 6.5x decrease in sampling time. Moreover, our approach consistently outperforms generic prompt-based steering methods and KNN retrieval baseline across a wide range of datasets. Additionally, we demonstrate the compatibility of our approach with widely-used data augmentation techniques, as well as the reliability of the generated data in supporting various neural architectures and enhancing few-shot learning.","sentences":["Acquiring high-quality data for training discriminative models is a crucial yet challenging aspect of building effective predictive systems.","In this paper, we present Diffusion Inversion, a simple yet effective method that leverages the pre-trained generative model, Stable Diffusion, to generate diverse, high-quality training data for image classification.","Our approach captures the original data distribution and ensures data coverage by inverting images to the latent space of Stable Diffusion, and generates diverse novel training images by conditioning the generative model on noisy versions of these vectors.","We identify three key components that allow our generated images to successfully supplant the original dataset, leading to a 2-3x enhancement in sample complexity and a 6.5x decrease in sampling time.","Moreover, our approach consistently outperforms generic prompt-based steering methods and KNN retrieval baseline across a wide range of datasets.","Additionally, we demonstrate the compatibility of our approach with widely-used data augmentation techniques, as well as the reliability of the generated data in supporting various neural architectures and enhancing few-shot learning."],"url":"http://arxiv.org/abs/2305.15316v1"}
{"created":"2023-05-24","title":"A Scintillator Beam Monitor for Real-Time FLASH Radiotherapy","abstract":"FLASH Radiotherapy (RT) is a potentially new cancer radiotherapy technique where an entire therapeutic dose is delivered in about 0.1 s and at ~1000 times higher dose rate than in conventional RT. For clinical trials to be conducted safely, precise and fast beam monitoring that can generate an out-of-tolerance beam interrupt is required. A FLASH Beam Scintillator Monitor (FBSM) is being developed based in part on two novel proprietary scintillator materials: an organic polymeric material (PM) and inorganic hybrid (HM). The FBSM provides large area coverage, low mass profile, linear response over a broad dynamic range, radiation tolerance, and real-time analysis IEC-compliant fast beam-interrupt signal. This paper includes the design concept and test results from prototype devices in radiation beams that include heavy ions, low energy protons at nA currents, FLASH level dose per pulse electron beams, and in a hospital radiotherapy clinic with electron beams. Results include image quality, response linearity, radiation hardness, spatial resolution, and real-time data processing. PM and HM scintillator exhibited no measurable drop in signal after a cumulative dose of 9 kGy and 20 kGy respectively. HM showed a small -0.02%/kGy signal decrease after a 212 kGy cumulative dose resulting from continuous exposure for 15 minutes at a high FLASH dose rate of 234 Gy/s. These tests established the linear response of the FBSM with respect to beam currents, dose per pulse, and material thickness. Comparison with commercial Gafchromic film indicates that the FBSM produces a high resolution 2D beam image and can reproduce a nearly identical beam profile, including primary beam tails. At 20 kfps or 50 microsec/frame, the real-time FPGA based computation and analysis of beam position, beam shape, and beam dose takes < 1 microsec.","sentences":["FLASH Radiotherapy (RT) is a potentially new cancer radiotherapy technique where an entire therapeutic dose is delivered in about 0.1 s and at ~1000 times higher dose rate than in conventional RT.","For clinical trials to be conducted safely, precise and fast beam monitoring that can generate an out-of-tolerance beam interrupt is required.","A FLASH Beam Scintillator Monitor (FBSM) is being developed based in part on two novel proprietary scintillator materials: an organic polymeric material (PM) and inorganic hybrid (HM).","The FBSM provides large area coverage, low mass profile, linear response over a broad dynamic range, radiation tolerance, and real-time analysis IEC-compliant fast beam-interrupt signal.","This paper includes the design concept and test results from prototype devices in radiation beams that include heavy ions, low energy protons at nA currents, FLASH level dose per pulse electron beams, and in a hospital radiotherapy clinic with electron beams.","Results include image quality, response linearity, radiation hardness, spatial resolution, and real-time data processing.","PM and HM scintillator exhibited no measurable drop in signal after a cumulative dose of 9 kGy and 20 kGy respectively.","HM showed a small -0.02%/kGy signal decrease after a 212 kGy cumulative dose resulting from continuous exposure for 15 minutes at a high FLASH dose rate of 234 Gy/s. These tests established the linear response of the FBSM with respect to beam currents, dose per pulse, and material thickness.","Comparison with commercial Gafchromic film indicates that the FBSM produces a high resolution 2D beam image and can reproduce a nearly identical beam profile, including primary beam tails.","At 20 kfps or 50 microsec/frame, the real-time FPGA based computation and analysis of beam position, beam shape, and beam dose takes < 1 microsec."],"url":"http://arxiv.org/abs/2305.15306v1"}
{"created":"2023-05-24","title":"Neural Summarization of Electronic Health Records","abstract":"Hospital discharge documentation is among the most essential, yet time-consuming documents written by medical practitioners. The objective of this study was to automatically generate hospital discharge summaries using neural network summarization models. We studied various data preparation and neural network training techniques that generate discharge summaries. Using nursing notes and discharge summaries from the MIMIC-III dataset, we studied the viability of the automatic generation of various sections of a discharge summary using four state-of-the-art neural network summarization models (BART, T5, Longformer and FLAN-T5). Our experiments indicated that training environments including nursing notes as the source, and discrete sections of the discharge summary as the target output (e.g. \"History of Present Illness\") improve language model efficiency and text quality. According to our findings, the fine-tuned BART model improved its ROUGE F1 score by 43.6% against its standard off-the-shelf version. We also found that fine-tuning the baseline BART model with other setups caused different degrees of improvement (up to 80% relative improvement). We also observed that a fine-tuned T5 generally achieves higher ROUGE F1 scores than other fine-tuned models and a fine-tuned FLAN-T5 achieves the highest ROUGE score overall, i.e., 45.6. For majority of the fine-tuned language models, summarizing discharge summary report sections separately outperformed the summarization the entire report quantitatively. On the other hand, fine-tuning language models that were previously instruction fine-tuned showed better performance in summarizing entire reports. This study concludes that a focused dataset designed for the automatic generation of discharge summaries by a language model can produce coherent Discharge Summary sections.","sentences":["Hospital discharge documentation is among the most essential, yet time-consuming documents written by medical practitioners.","The objective of this study was to automatically generate hospital discharge summaries using neural network summarization models.","We studied various data preparation and neural network training techniques that generate discharge summaries.","Using nursing notes and discharge summaries from the MIMIC-III dataset, we studied the viability of the automatic generation of various sections of a discharge summary using four state-of-the-art neural network summarization models (BART, T5, Longformer and FLAN-T5).","Our experiments indicated that training environments including nursing notes as the source, and discrete sections of the discharge summary as the target output (e.g. \"History of Present Illness\") improve language model efficiency and text quality.","According to our findings, the fine-tuned BART model improved its ROUGE F1 score by 43.6% against its standard off-the-shelf version.","We also found that fine-tuning the baseline BART model with other setups caused different degrees of improvement (up to 80% relative improvement).","We also observed that a fine-tuned T5 generally achieves higher ROUGE F1 scores than other fine-tuned models and a fine-tuned FLAN-T5 achieves the highest ROUGE score overall, i.e., 45.6.","For majority of the fine-tuned language models, summarizing discharge summary report sections separately outperformed the summarization the entire report quantitatively.","On the other hand, fine-tuning language models that were previously instruction fine-tuned showed better performance in summarizing entire reports.","This study concludes that a focused dataset designed for the automatic generation of discharge summaries by a language model can produce coherent Discharge Summary sections."],"url":"http://arxiv.org/abs/2305.15222v1"}
{"created":"2023-05-24","title":"Generalized Bayesian Inference for Scientific Simulators via Amortized Cost Estimation","abstract":"Simulation-based inference (SBI) enables amortized Bayesian inference for simulators with implicit likelihoods. But when we are primarily interested in the quality of predictive simulations, or when the model cannot exactly reproduce the observed data (i.e., is misspecified), targeting the Bayesian posterior may be overly restrictive. Generalized Bayesian Inference (GBI) aims to robustify inference for (misspecified) simulator models, replacing the likelihood-function with a cost function that evaluates the goodness of parameters relative to data. However, GBI methods generally require running multiple simulations to estimate the cost function at each parameter value during inference, making the approach computationally infeasible for even moderately complex simulators. Here, we propose amortized cost estimation (ACE) for GBI to address this challenge: We train a neural network to approximate the cost function, which we define as the expected distance between simulations produced by a parameter and observed data. The trained network can then be used with MCMC to infer GBI posteriors for any observation without running additional simulations. We show that, on several benchmark tasks, ACE accurately predicts cost and provides predictive simulations that are closer to synthetic observations than other SBI methods, especially for misspecified simulators. Finally, we apply ACE to infer parameters of the Hodgkin-Huxley model given real intracellular recordings from the Allen Cell Types Database. ACE identifies better data-matching parameters while being an order of magnitude more simulation-efficient than a standard SBI method. In summary, ACE combines the strengths of SBI methods and GBI to perform robust and simulation-amortized inference for scientific simulators.","sentences":["Simulation-based inference (SBI) enables amortized Bayesian inference for simulators with implicit likelihoods.","But when we are primarily interested in the quality of predictive simulations, or when the model cannot exactly reproduce the observed data (i.e., is misspecified), targeting the Bayesian posterior may be overly restrictive.","Generalized Bayesian Inference (GBI) aims to robustify inference for (misspecified) simulator models, replacing the likelihood-function with a cost function that evaluates the goodness of parameters relative to data.","However, GBI methods generally require running multiple simulations to estimate the cost function at each parameter value during inference, making the approach computationally infeasible for even moderately complex simulators.","Here, we propose amortized cost estimation (ACE) for GBI to address this challenge: We train a neural network to approximate the cost function, which we define as the expected distance between simulations produced by a parameter and observed data.","The trained network can then be used with MCMC to infer GBI posteriors for any observation without running additional simulations.","We show that, on several benchmark tasks, ACE accurately predicts cost and provides predictive simulations that are closer to synthetic observations than other SBI methods, especially for misspecified simulators.","Finally, we apply ACE to infer parameters of the Hodgkin-Huxley model given real intracellular recordings from the Allen Cell Types Database.","ACE identifies better data-matching parameters while being an order of magnitude more simulation-efficient than a standard SBI method.","In summary, ACE combines the strengths of SBI methods and GBI to perform robust and simulation-amortized inference for scientific simulators."],"url":"http://arxiv.org/abs/2305.15208v1"}
{"created":"2023-05-24","title":"6G Enabled Advanced Transportation Systems","abstract":"The 6th generation (6G) wireless communication network is envisaged to be able to change our lives drastically, including transportation. In this paper, two ways of interactions between 6G communication networks and transportation are introduced. With the new usage scenarios and capabilities 6G is going to support, passengers on all sorts of transportation systems will be able to get data more easily, even in the most remote areas on the planet. The quality of communication will also be improved significantly, thanks to the advanced capabilities of 6G. On top of providing seamless and ubiquitous connectivity to all forms of transportation, 6G will also transform the transportation systems to make them more intelligent, more efficient, and safer. Based on the latest research and standardization progresses, technical analysis on how 6G can empower advanced transportation systems are provided, as well as challenges and insights for a possible road ahead.","sentences":["The 6th generation (6G) wireless communication network is envisaged to be able to change our lives drastically, including transportation.","In this paper, two ways of interactions between 6G communication networks and transportation are introduced.","With the new usage scenarios and capabilities 6G is going to support, passengers on all sorts of transportation systems will be able to get data more easily, even in the most remote areas on the planet.","The quality of communication will also be improved significantly, thanks to the advanced capabilities of 6G. On top of providing seamless and ubiquitous connectivity to all forms of transportation, 6G will also transform the transportation systems to make them more intelligent, more efficient, and safer.","Based on the latest research and standardization progresses, technical analysis on how 6G can empower advanced transportation systems are provided, as well as challenges and insights for a possible road ahead."],"url":"http://arxiv.org/abs/2305.15184v1"}
{"created":"2023-05-24","title":"Using Scalarizations for the Approximation of Multiobjective Optimization Problems: Towards a General Theory","abstract":"We study the approximation of general multiobjective optimization problems with the help of scalarizations. Existing results state that multiobjective minimization problems can be approximated well by norm-based scalarizations. However, for multiobjective maximization problems, only impossibility results are known so far. Countering this, we show that all multiobjective optimization problems can, in principle, be approximated equally well by scalarizations. In this context, we introduce a transformation theory for scalarizations that establishes the following: Suppose there exists a scalarization that yields an approximation of a certain quality for arbitrary instances of multiobjective optimization problems with a given decomposition specifying which objective functions are to be minimized / maximized. Then, for each other decomposition, our transformation yields another scalarization that yields the same approximation quality for arbitrary instances of problems with this other decomposition. In this sense, the existing results about the approximation via scalarizations for minimization problems carry over to any other objective decomposition -- in particular, to maximization problems -- when suitably adapting the employed scalarization.   We further provide necessary and sufficient conditions on a scalarization such that its optimal solutions achieve a constant approximation quality. We give an upper bound on the best achievable approximation quality that applies to general scalarizations and is tight for the majority of norm-based scalarizations applied in the context of multiobjective optimization. As a consequence, none of these norm-based scalarizations can induce approximation sets for optimization problems with maximization objectives, which unifies and generalizes the existing impossibility results concerning the approximation of maximization problems.","sentences":["We study the approximation of general multiobjective optimization problems with the help of scalarizations.","Existing results state that multiobjective minimization problems can be approximated well by norm-based scalarizations.","However, for multiobjective maximization problems, only impossibility results are known so far.","Countering this, we show that all multiobjective optimization problems can, in principle, be approximated equally well by scalarizations.","In this context, we introduce a transformation theory for scalarizations that establishes the following: Suppose there exists a scalarization that yields an approximation of a certain quality for arbitrary instances of multiobjective optimization problems with a given decomposition specifying which objective functions are to be minimized / maximized.","Then, for each other decomposition, our transformation yields another scalarization that yields the same approximation quality for arbitrary instances of problems with this other decomposition.","In this sense, the existing results about the approximation via scalarizations for minimization problems carry over to any other objective decomposition -- in particular, to maximization problems -- when suitably adapting the employed scalarization.   ","We further provide necessary and sufficient conditions on a scalarization such that its optimal solutions achieve a constant approximation quality.","We give an upper bound on the best achievable approximation quality that applies to general scalarizations and is tight for the majority of norm-based scalarizations applied in the context of multiobjective optimization.","As a consequence, none of these norm-based scalarizations can induce approximation sets for optimization problems with maximization objectives, which unifies and generalizes the existing impossibility results concerning the approximation of maximization problems."],"url":"http://arxiv.org/abs/2305.15173v1"}
{"created":"2023-05-24","title":"Reliability Scores from Saliency Map Clusters for Improved Image-based Harvest-Readiness Prediction in Cauliflower","abstract":"Cauliflower is a hand-harvested crop that must fulfill high-quality standards in sales making the timing of harvest important. However, accurately determining harvest-readiness can be challenging due to the cauliflower head being covered by its canopy. While deep learning enables automated harvest-readiness estimation, errors can occur due to field-variability and limited training data. In this paper, we analyze the reliability of a harvest-readiness classifier with interpretable machine learning. By identifying clusters of saliency maps, we derive reliability scores for each classification result using knowledge about the domain and the image properties. For unseen data, the reliability can be used to (i) inform farmers to improve their decision-making and (ii) increase the model prediction accuracy. Using RGB images of single cauliflower plants at different developmental stages from the GrowliFlower dataset, we investigate various saliency mapping approaches and find that they result in different quality of reliability scores. With the most suitable interpretation tool, we adjust the classification result and achieve a 15.72% improvement of the overall accuracy to 88.14% and a 15.44% improvement of the average class accuracy to 88.52% for the GrowliFlower dataset.","sentences":["Cauliflower is a hand-harvested crop that must fulfill high-quality standards in sales making the timing of harvest important.","However, accurately determining harvest-readiness can be challenging due to the cauliflower head being covered by its canopy.","While deep learning enables automated harvest-readiness estimation, errors can occur due to field-variability and limited training data.","In this paper, we analyze the reliability of a harvest-readiness classifier with interpretable machine learning.","By identifying clusters of saliency maps, we derive reliability scores for each classification result using knowledge about the domain and the image properties.","For unseen data, the reliability can be used to (i) inform farmers to improve their decision-making and (ii) increase the model prediction accuracy.","Using RGB images of single cauliflower plants at different developmental stages from the GrowliFlower dataset, we investigate various saliency mapping approaches and find that they result in different quality of reliability scores.","With the most suitable interpretation tool, we adjust the classification result and achieve a 15.72% improvement of the overall accuracy to 88.14% and a 15.44% improvement of the average class accuracy to 88.52% for the GrowliFlower dataset."],"url":"http://arxiv.org/abs/2305.15149v1"}
{"created":"2023-05-24","title":"PLCMOS -- a data-driven non-intrusive metric for the evaluation of packet loss concealment algorithms","abstract":"Speech quality assessment is a problem for every researcher working on models that produce or process speech. Human subjective ratings, the gold standard in speech quality assessment, are expensive and time-consuming to acquire in a quantity that is sufficient to get reliable data, while automated objective metrics show a low correlation with gold standard ratings. This paper presents PLCMOS, a non-intrusive data-driven tool for generating a robust, accurate estimate of the mean opinion score a human rater would assign an audio file that has been processed by being transmitted over a degraded packet-switched network with missing packets being healed by a packet loss concealment algorithm. Our new model shows a model-wise Pearson's correlation of ~0.97 and rank correlation of ~0.95 with human ratings, substantially above all other available intrusive and non-intrusive metrics. The model is released as an ONNX model for other researchers to use when building PLC systems.","sentences":["Speech quality assessment is a problem for every researcher working on models that produce or process speech.","Human subjective ratings, the gold standard in speech quality assessment, are expensive and time-consuming to acquire in a quantity that is sufficient to get reliable data, while automated objective metrics show a low correlation with gold standard ratings.","This paper presents PLCMOS, a non-intrusive data-driven tool for generating a robust, accurate estimate of the mean opinion score a human rater would assign an audio file that has been processed by being transmitted over a degraded packet-switched network with missing packets being healed by a packet loss concealment algorithm.","Our new model shows a model-wise Pearson's correlation of ~0.97 and rank correlation of ~0.95 with human ratings, substantially above all other available intrusive and non-intrusive metrics.","The model is released as an ONNX model for other researchers to use when building PLC systems."],"url":"http://arxiv.org/abs/2305.15127v1"}
{"created":"2023-05-24","title":"Rethinking the Evaluation Protocol of Domain Generalization","abstract":"Domain generalization aims to solve the challenge of Out-of-Distribution (OOD) generalization by leveraging common knowledge learned from multiple training domains to generalize to unseen test domains. To accurately evaluate the OOD generalization ability, it is necessary to ensure that test data information is unavailable. However, the current domain generalization protocol may still have potential test data information leakage. This paper examines the potential risks of test data information leakage in two aspects of the current protocol: pretraining on ImageNet and oracle model selection. We propose that training from scratch and using multiple test domains would result in a more precise evaluation of OOD generalization ability. We also rerun the algorithms with the modified protocol and introduce a new leaderboard to encourage future research in domain generalization with a fairer comparison.","sentences":["Domain generalization aims to solve the challenge of Out-of-Distribution (OOD) generalization by leveraging common knowledge learned from multiple training domains to generalize to unseen test domains.","To accurately evaluate the OOD generalization ability, it is necessary to ensure that test data information is unavailable.","However, the current domain generalization protocol may still have potential test data information leakage.","This paper examines the potential risks of test data information leakage in two aspects of the current protocol: pretraining on ImageNet and oracle model selection.","We propose that training from scratch and using multiple test domains would result in a more precise evaluation of OOD generalization ability.","We also rerun the algorithms with the modified protocol and introduce a new leaderboard to encourage future research in domain generalization with a fairer comparison."],"url":"http://arxiv.org/abs/2305.15253v1"}
