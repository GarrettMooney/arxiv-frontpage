{"created":"2023-11-07 18:59:58","title":"OtterHD: A High-Resolution Multi-modality Model","abstract":"In this paper, we present OtterHD-8B, an innovative multimodal model evolved from Fuyu-8B, specifically engineered to interpret high-resolution visual inputs with granular precision. Unlike conventional models that are constrained by fixed-size vision encoders, OtterHD-8B boasts the ability to handle flexible input dimensions, ensuring its versatility across various inference requirements. Alongside this model, we introduce MagnifierBench, an evaluation framework designed to scrutinize models' ability to discern minute details and spatial relationships of small objects. Our comparative analysis reveals that while current leading models falter on this benchmark, OtterHD-8B, particularly when directly processing high-resolution inputs, outperforms its counterparts by a substantial margin. The findings illuminate the structural variances in visual information processing among different models and the influence that the vision encoders' pre-training resolution disparities have on model effectiveness within such benchmarks. Our study highlights the critical role of flexibility and high-resolution input capabilities in large multimodal models and also exemplifies the potential inherent in the Fuyu architecture's simplicity for handling complex visual data.","sentences":["In this paper, we present OtterHD-8B, an innovative multimodal model evolved from Fuyu-8B, specifically engineered to interpret high-resolution visual inputs with granular precision.","Unlike conventional models that are constrained by fixed-size vision encoders, OtterHD-8B boasts the ability to handle flexible input dimensions, ensuring its versatility across various inference requirements.","Alongside this model, we introduce MagnifierBench, an evaluation framework designed to scrutinize models' ability to discern minute details and spatial relationships of small objects.","Our comparative analysis reveals that while current leading models falter on this benchmark, OtterHD-8B, particularly when directly processing high-resolution inputs, outperforms its counterparts by a substantial margin.","The findings illuminate the structural variances in visual information processing among different models and the influence that the vision encoders' pre-training resolution disparities have on model effectiveness within such benchmarks.","Our study highlights the critical role of flexibility and high-resolution input capabilities in large multimodal models and also exemplifies the potential inherent in the Fuyu architecture's simplicity for handling complex visual data."],"url":"http://arxiv.org/abs/2311.04219v1"}
{"created":"2023-11-07 18:59:51","title":"Towards Garment Sewing Pattern Reconstruction from a Single Image","abstract":"Garment sewing pattern represents the intrinsic rest shape of a garment, and is the core for many applications like fashion design, virtual try-on, and digital avatars. In this work, we explore the challenging problem of recovering garment sewing patterns from daily photos for augmenting these applications. To solve the problem, we first synthesize a versatile dataset, named SewFactory, which consists of around 1M images and ground-truth sewing patterns for model training and quantitative evaluation. SewFactory covers a wide range of human poses, body shapes, and sewing patterns, and possesses realistic appearances thanks to the proposed human texture synthesis network. Then, we propose a two-level Transformer network called Sewformer, which significantly improves the sewing pattern prediction performance. Extensive experiments demonstrate that the proposed framework is effective in recovering sewing patterns and well generalizes to casually-taken human photos. Code, dataset, and pre-trained models are available at: https://sewformer.github.io.","sentences":["Garment sewing pattern represents the intrinsic rest shape of a garment, and is the core for many applications like fashion design, virtual try-on, and digital avatars.","In this work, we explore the challenging problem of recovering garment sewing patterns from daily photos for augmenting these applications.","To solve the problem, we first synthesize a versatile dataset, named SewFactory, which consists of around 1M images and ground-truth sewing patterns for model training and quantitative evaluation.","SewFactory covers a wide range of human poses, body shapes, and sewing patterns, and possesses realistic appearances thanks to the proposed human texture synthesis network.","Then, we propose a two-level Transformer network called Sewformer, which significantly improves the sewing pattern prediction performance.","Extensive experiments demonstrate that the proposed framework is effective in recovering sewing patterns and well generalizes to casually-taken human photos.","Code, dataset, and pre-trained models are available at: https://sewformer.github.io."],"url":"http://arxiv.org/abs/2311.04218v1"}
{"created":"2023-11-07 18:59:14","title":"Wearable data from subjects playing Super Mario, sitting university exams, or performing physical exercise help detect acute mood episodes via self-supervised learning","abstract":"Personal sensing, leveraging data passively and near-continuously collected with wearables from patients in their ecological environment, is a promising paradigm to monitor mood disorders (MDs), a major determinant of worldwide disease burden. However, collecting and annotating wearable data is very resource-intensive. Studies of this kind can thus typically afford to recruit only a couple dozens of patients. This constitutes one of the major obstacles to applying modern supervised machine learning techniques to MDs detection. In this paper, we overcome this data bottleneck and advance the detection of MDs acute episode vs stable state from wearables data on the back of recent advances in self-supervised learning (SSL). This leverages unlabelled data to learn representations during pre-training, subsequently exploited for a supervised task. First, we collected open-access datasets recording with an Empatica E4 spanning different, unrelated to MD monitoring, personal sensing tasks -- from emotion recognition in Super Mario players to stress detection in undergraduates -- and devised a pre-processing pipeline performing on-/off-body detection, sleep-wake detection, segmentation, and (optionally) feature extraction. With 161 E4-recorded subjects, we introduce E4SelfLearning, the largest to date open access collection, and its pre-processing pipeline. Second, we show that SSL confidently outperforms fully-supervised pipelines using either our novel E4-tailored Transformer architecture (E4mer) or classical baseline XGBoost: 81.23% against 75.35% (E4mer) and 72.02% (XGBoost) correctly classified recording segments from 64 (half acute, half stable) patients. Lastly, we illustrate that SSL performance is strongly associated with the specific surrogate task employed for pre-training as well as with unlabelled data availability.","sentences":["Personal sensing, leveraging data passively and near-continuously collected with wearables from patients in their ecological environment, is a promising paradigm to monitor mood disorders (MDs), a major determinant of worldwide disease burden.","However, collecting and annotating wearable data is very resource-intensive.","Studies of this kind can thus typically afford to recruit only a couple dozens of patients.","This constitutes one of the major obstacles to applying modern supervised machine learning techniques to MDs detection.","In this paper, we overcome this data bottleneck and advance the detection of MDs acute episode vs stable state from wearables data on the back of recent advances in self-supervised learning (SSL).","This leverages unlabelled data to learn representations during pre-training, subsequently exploited for a supervised task.","First, we collected open-access datasets recording with an Empatica E4 spanning different, unrelated to MD monitoring, personal sensing tasks -- from emotion recognition in Super Mario players to stress detection in undergraduates -- and devised a pre-processing pipeline performing on-/off-body detection, sleep-wake detection, segmentation, and (optionally) feature extraction.","With 161 E4-recorded subjects, we introduce E4SelfLearning, the largest to date open access collection, and its pre-processing pipeline.","Second, we show that SSL confidently outperforms fully-supervised pipelines using either our novel E4-tailored Transformer architecture (E4mer) or classical baseline XGBoost: 81.23% against 75.35% (E4mer) and 72.02% (XGBoost) correctly classified recording segments from 64 (half acute, half stable) patients.","Lastly, we illustrate that SSL performance is strongly associated with the specific surrogate task employed for pre-training as well as with unlabelled data availability."],"url":"http://arxiv.org/abs/2311.04215v1"}
{"created":"2023-11-07 18:57:12","title":"Video Instance Matting","abstract":"Conventional video matting outputs one alpha matte for all instances appearing in a video frame so that individual instances are not distinguished. While video instance segmentation provides time-consistent instance masks, results are unsatisfactory for matting applications, especially due to applied binarization. To remedy this deficiency, we propose Video Instance Matting~(VIM), that is, estimating alpha mattes of each instance at each frame of a video sequence. To tackle this challenging problem, we present MSG-VIM, a Mask Sequence Guided Video Instance Matting neural network, as a novel baseline model for VIM. MSG-VIM leverages a mixture of mask augmentations to make predictions robust to inaccurate and inconsistent mask guidance. It incorporates temporal mask and temporal feature guidance to improve the temporal consistency of alpha matte predictions. Furthermore, we build a new benchmark for VIM, called VIM50, which comprises 50 video clips with multiple human instances as foreground objects. To evaluate performances on the VIM task, we introduce a suitable metric called Video Instance-aware Matting Quality~(VIMQ). Our proposed model MSG-VIM sets a strong baseline on the VIM50 benchmark and outperforms existing methods by a large margin. The project is open-sourced at https://github.com/SHI-Labs/VIM.","sentences":["Conventional video matting outputs one alpha matte for all instances appearing in a video frame so that individual instances are not distinguished.","While video instance segmentation provides time-consistent instance masks, results are unsatisfactory for matting applications, especially due to applied binarization.","To remedy this deficiency, we propose Video Instance Matting~(VIM), that is, estimating alpha mattes of each instance at each frame of a video sequence.","To tackle this challenging problem, we present MSG-VIM, a Mask Sequence Guided Video Instance Matting neural network, as a novel baseline model for VIM.","MSG-VIM leverages a mixture of mask augmentations to make predictions robust to inaccurate and inconsistent mask guidance.","It incorporates temporal mask and temporal feature guidance to improve the temporal consistency of alpha matte predictions.","Furthermore, we build a new benchmark for VIM, called VIM50, which comprises 50 video clips with multiple human instances as foreground objects.","To evaluate performances on the VIM task, we introduce a suitable metric called Video Instance-aware Matting Quality~(VIMQ).","Our proposed model MSG-VIM sets a strong baseline on the VIM50 benchmark and outperforms existing methods by a large margin.","The project is open-sourced at https://github.com/SHI-Labs/VIM."],"url":"http://arxiv.org/abs/2311.04212v1"}
{"created":"2023-11-07 18:47:28","title":"Deep Hashing via Householder Quantization","abstract":"Hashing is at the heart of large-scale image similarity search, and recent methods have been substantially improved through deep learning techniques. Such algorithms typically learn continuous embeddings of the data. To avoid a subsequent costly binarization step, a common solution is to employ loss functions that combine a similarity learning term (to ensure similar images are grouped to nearby embeddings) and a quantization penalty term (to ensure that the embedding entries are close to binarized entries, e.g., -1 or 1). Still, the interaction between these two terms can make learning harder and the embeddings worse. We propose an alternative quantization strategy that decomposes the learning problem in two stages: first, perform similarity learning over the embedding space with no quantization; second, find an optimal orthogonal transformation of the embeddings so each coordinate of the embedding is close to its sign, and then quantize the transformed embedding through the sign function. In the second step, we parametrize orthogonal transformations using Householder matrices to efficiently leverage stochastic gradient descent. Since similarity measures are usually invariant under orthogonal transformations, this quantization strategy comes at no cost in terms of performance. The resulting algorithm is unsupervised, fast, hyperparameter-free and can be run on top of any existing deep hashing or metric learning algorithm. We provide extensive experimental results showing that this approach leads to state-of-the-art performance on widely used image datasets, and, unlike other quantization strategies, brings consistent improvements in performance to existing deep hashing algorithms.","sentences":["Hashing is at the heart of large-scale image similarity search, and recent methods have been substantially improved through deep learning techniques.","Such algorithms typically learn continuous embeddings of the data.","To avoid a subsequent costly binarization step, a common solution is to employ loss functions that combine a similarity learning term (to ensure similar images are grouped to nearby embeddings) and a quantization penalty term (to ensure that the embedding entries are close to binarized entries, e.g., -1 or 1).","Still, the interaction between these two terms can make learning harder and the embeddings worse.","We propose an alternative quantization strategy that decomposes the learning problem in two stages: first, perform similarity learning over the embedding space with no quantization; second, find an optimal orthogonal transformation of the embeddings so each coordinate of the embedding is close to its sign, and then quantize the transformed embedding through the sign function.","In the second step, we parametrize orthogonal transformations using Householder matrices to efficiently leverage stochastic gradient descent.","Since similarity measures are usually invariant under orthogonal transformations, this quantization strategy comes at no cost in terms of performance.","The resulting algorithm is unsupervised, fast, hyperparameter-free and can be run on top of any existing deep hashing or metric learning algorithm.","We provide extensive experimental results showing that this approach leads to state-of-the-art performance on widely used image datasets, and, unlike other quantization strategies, brings consistent improvements in performance to existing deep hashing algorithms."],"url":"http://arxiv.org/abs/2311.04207v1"}
{"created":"2023-11-07 18:43:34","title":"Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves","abstract":"Misunderstandings arise not only in interpersonal communication but also between humans and Large Language Models (LLMs). Such discrepancies can make LLMs interpret seemingly unambiguous questions in unexpected ways, yielding incorrect responses. While it is widely acknowledged that the quality of a prompt, such as a question, significantly impacts the quality of the response provided by LLMs, a systematic method for crafting questions that LLMs can better comprehend is still underdeveloped. In this paper, we present a method named `Rephrase and Respond' (RaR), which allows LLMs to rephrase and expand questions posed by humans and provide responses in a single prompt. This approach serves as a simple yet effective prompting method for improving performance. We also introduce a two-step variant of RaR, where a rephrasing LLM first rephrases the question and then passes the original and rephrased questions together to a different responding LLM. This facilitates the effective utilization of rephrased questions generated by one LLM with another. Our experiments demonstrate that our methods significantly improve the performance of different models across a wide range to tasks. We further provide a comprehensive comparison between RaR and the popular Chain-of-Thought (CoT) methods, both theoretically and empirically. We show that RaR is complementary to CoT and can be combined with CoT to achieve even better performance. Our work not only contributes to enhancing LLM performance efficiently and effectively but also sheds light on a fair evaluation of LLM capabilities. Data and codes are available at https://github.com/uclaml/Rephrase-and-Respond.","sentences":["Misunderstandings arise not only in interpersonal communication but also between humans and Large Language Models (LLMs).","Such discrepancies can make LLMs interpret seemingly unambiguous questions in unexpected ways, yielding incorrect responses.","While it is widely acknowledged that the quality of a prompt, such as a question, significantly impacts the quality of the response provided by LLMs, a systematic method for crafting questions that LLMs can better comprehend is still underdeveloped.","In this paper, we present a method named `Rephrase and Respond' (RaR), which allows LLMs to rephrase and expand questions posed by humans and provide responses in a single prompt.","This approach serves as a simple yet effective prompting method for improving performance.","We also introduce a two-step variant of RaR, where a rephrasing LLM first rephrases the question and then passes the original and rephrased questions together to a different responding LLM.","This facilitates the effective utilization of rephrased questions generated by one LLM with another.","Our experiments demonstrate that our methods significantly improve the performance of different models across a wide range to tasks.","We further provide a comprehensive comparison between RaR and the popular Chain-of-Thought (CoT) methods, both theoretically and empirically.","We show that RaR is complementary to CoT and can be combined with CoT to achieve even better performance.","Our work not only contributes to enhancing LLM performance efficiently and effectively but also sheds light on a fair evaluation of LLM capabilities.","Data and codes are available at https://github.com/uclaml/Rephrase-and-Respond."],"url":"http://arxiv.org/abs/2311.04205v1"}
{"created":"2023-11-07 18:43:27","title":"Sharp Thresholds Imply Circuit Lower Bounds: from random 2-SAT to Planted Clique","abstract":"We show that sharp thresholds for Boolean functions directly imply average-case circuit lower bounds. More formally we show that any Boolean function exhibiting a sharp enough threshold at \\emph{arbitrary} critical density cannot be computed by Boolean circuits of bounded depth and polynomial size.   Our general result implies new average-case bounded depth circuit lower bounds in a variety of settings.   (a) ($k$-cliques) For $k=\\Theta(n)$, we prove that any circuit of depth $d$ deciding the presence of a size $k$ clique in a random graph requires exponential-in-$n^{\\Theta(1/d)}$ size. To the best of our knowledge, this is the first exponential size lower bound for bounded depth (not necessarily monotone) circuits solving the fundamental $k$-clique problem (for any $k=k_n$), even for worst-case input graphs.   (b)(random 2-SAT) We prove that any circuit of depth $d$ deciding the satisfiability of a random 2-SAT formula requires exponential-in-$n^{\\Theta(1/d)}$ size. To the best of our knowledge, this is the first bounded depth circuit lower bound for random $k$-SAT for any value of $k \\geq 2.$ Our results also provide the first rigorous lower bound in agreement with a conjectured ``computational hardness'' of random $k$-SAT around its satisfiability threshold.   (c)(Statistical estimation -- planted $k$-clique) Over the recent years, multiple statistical estimation problems have also been proven to exhibit a ``statistical'' sharp threshold, called the All-or-Nothing (AoN) phenomenon. We show that AoN also implies circuit lower bounds for statistical problems. As a simple corollary of that, we prove that any circuit of depth $d$ that solves to information-theoretic optimality a ``dense'' variant of the celebrated planted $k$-clique problem requires exponential-in-$n^{\\Theta(1/d)}$ size.","sentences":["We show that sharp thresholds for Boolean functions directly imply average-case circuit lower bounds.","More formally we show that any Boolean function exhibiting a sharp enough threshold at \\emph{arbitrary} critical density cannot be computed by Boolean circuits of bounded depth and polynomial size.   ","Our general result implies new average-case bounded depth circuit lower bounds in a variety of settings.   ","(a) ($k$-cliques)","For $k=\\Theta(n)$, we prove that any circuit of depth $d$ deciding the presence of a size $k$ clique in a random graph requires exponential-in-$n^{\\Theta(1/d)}$ size.","To the best of our knowledge, this is the first exponential size lower bound for bounded depth (not necessarily monotone) circuits solving the fundamental $k$-clique problem (for any $k=k_n$), even for worst-case input graphs.   ","(b)(random 2-SAT) We prove that any circuit of depth $d$ deciding the satisfiability of a random 2-SAT formula requires exponential-in-$n^{\\Theta(1/d)}$ size.","To the best of our knowledge, this is the first bounded depth circuit lower bound for random $k$-SAT for any value of $k \\geq 2.$","Our results also provide the first rigorous lower bound in agreement with a conjectured ``computational hardness'' of random $k$-SAT around its satisfiability threshold.   ","(c)(Statistical estimation -- planted $k$-clique)","Over the recent years, multiple statistical estimation problems have also been proven to exhibit a ``statistical'' sharp threshold, called the All-or-Nothing (AoN) phenomenon.","We show that AoN also implies circuit lower bounds for statistical problems.","As a simple corollary of that, we prove that any circuit of depth $d$ that solves to information-theoretic optimality a ``dense'' variant of the celebrated planted $k$-clique problem requires exponential-in-$n^{\\Theta(1/d)}$ size."],"url":"http://arxiv.org/abs/2311.04204v1"}
{"created":"2023-11-07 18:39:10","title":"Exploring Recommendation Capabilities of GPT-4V(ision): A Preliminary Case Study","abstract":"Large Multimodal Models (LMMs) have demonstrated impressive performance across various vision and language tasks, yet their potential applications in recommendation tasks with visual assistance remain unexplored. To bridge this gap, we present a preliminary case study investigating the recommendation capabilities of GPT-4V(ison), a recently released LMM by OpenAI. We construct a series of qualitative test samples spanning multiple domains and employ these samples to assess the quality of GPT-4V's responses within recommendation scenarios. Evaluation results on these test samples prove that GPT-4V has remarkable zero-shot recommendation abilities across diverse domains, thanks to its robust visual-text comprehension capabilities and extensive general knowledge. However, we have also identified some limitations in using GPT-4V for recommendations, including a tendency to provide similar responses when given similar inputs. This report concludes with an in-depth discussion of the challenges and research opportunities associated with utilizing GPT-4V in recommendation scenarios. Our objective is to explore the potential of extending LMMs from vision and language tasks to recommendation tasks. We hope to inspire further research into next-generation multimodal generative recommendation models, which can enhance user experiences by offering greater diversity and interactivity. All images and prompts used in this report will be accessible at https://github.com/PALIN2018/Evaluate_GPT-4V_Rec.","sentences":["Large Multimodal Models (LMMs) have demonstrated impressive performance across various vision and language tasks, yet their potential applications in recommendation tasks with visual assistance remain unexplored.","To bridge this gap, we present a preliminary case study investigating the recommendation capabilities of GPT-4V(ison), a recently released LMM by OpenAI.","We construct a series of qualitative test samples spanning multiple domains and employ these samples to assess the quality of GPT-4V's responses within recommendation scenarios.","Evaluation results on these test samples prove that GPT-4V has remarkable zero-shot recommendation abilities across diverse domains, thanks to its robust visual-text comprehension capabilities and extensive general knowledge.","However, we have also identified some limitations in using GPT-4V for recommendations, including a tendency to provide similar responses when given similar inputs.","This report concludes with an in-depth discussion of the challenges and research opportunities associated with utilizing GPT-4V in recommendation scenarios.","Our objective is to explore the potential of extending LMMs from vision and language tasks to recommendation tasks.","We hope to inspire further research into next-generation multimodal generative recommendation models, which can enhance user experiences by offering greater diversity and interactivity.","All images and prompts used in this report will be accessible at https://github.com/PALIN2018/Evaluate_GPT-4V_Rec."],"url":"http://arxiv.org/abs/2311.04199v1"}
{"created":"2023-11-07 18:36:16","title":"JPAVE: A Generation and Classification-based Model for Joint Product Attribute Prediction and Value Extraction","abstract":"Product attribute value extraction is an important task in e-Commerce which can help several downstream applications such as product search and recommendation. Most previous models handle this task using sequence labeling or question answering method which rely on the sequential position information of values in the product text and are vulnerable to data discrepancy between training and testing. This limits their generalization ability to real-world scenario in which each product can have multiple descriptions across various shopping platforms with different composition of text and style. They also have limited zero-shot ability to new values. In this paper, we propose a multi-task learning model with value generation/classification and attribute prediction called JPAVE to predict values without the necessity of position information of values in the text. Furthermore, the copy mechanism in value generator and the value attention module in value classifier help our model address the data discrepancy issue by only focusing on the relevant part of input text and ignoring other information which causes the discrepancy issue such as sentence structure in the text. Besides, two variants of our model are designed for open-world and closed-world scenarios. In addition, copy mechanism introduced in the first variant based on value generation can improve its zero-shot ability for identifying unseen values. Experimental results on a public dataset demonstrate the superiority of our model compared with strong baselines and its generalization ability of predicting new values.","sentences":["Product attribute value extraction is an important task in e-Commerce which can help several downstream applications such as product search and recommendation.","Most previous models handle this task using sequence labeling or question answering method which rely on the sequential position information of values in the product text and are vulnerable to data discrepancy between training and testing.","This limits their generalization ability to real-world scenario in which each product can have multiple descriptions across various shopping platforms with different composition of text and style.","They also have limited zero-shot ability to new values.","In this paper, we propose a multi-task learning model with value generation/classification and attribute prediction called JPAVE to predict values without the necessity of position information of values in the text.","Furthermore, the copy mechanism in value generator and the value attention module in value classifier help our model address the data discrepancy issue by only focusing on the relevant part of input text and ignoring other information which causes the discrepancy issue such as sentence structure in the text.","Besides, two variants of our model are designed for open-world and closed-world scenarios.","In addition, copy mechanism introduced in the first variant based on value generation can improve its zero-shot ability for identifying unseen values.","Experimental results on a public dataset demonstrate the superiority of our model compared with strong baselines and its generalization ability of predicting new values."],"url":"http://arxiv.org/abs/2311.04196v1"}
{"created":"2023-11-07 18:35:29","title":"Quantization-aware Neural Architectural Search for Intrusion Detection","abstract":"Deploying machine learning-based intrusion detection systems (IDSs) on hardware devices is challenging due to their limited computational resources, power consumption, and network connectivity. Hence, there is a significant need for robust, deep learning models specifically designed with such constraints in mind. In this paper, we present a design methodology that automatically trains and evolves quantized neural network (NN) models that are a thousand times smaller than state-of-the-art NNs but can efficiently analyze network data for intrusion at high accuracy. In this regard, the number of LUTs utilized by this network when deployed to an FPGA is between 2.3x and 8.5x smaller with performance comparable to prior work.","sentences":["Deploying machine learning-based intrusion detection systems (IDSs) on hardware devices is challenging due to their limited computational resources, power consumption, and network connectivity.","Hence, there is a significant need for robust, deep learning models specifically designed with such constraints in mind.","In this paper, we present a design methodology that automatically trains and evolves quantized neural network (NN) models that are a thousand times smaller than state-of-the-art NNs but can efficiently analyze network data for intrusion at high accuracy.","In this regard, the number of LUTs utilized by this network when deployed to an FPGA is between 2.3x and 8.5x smaller with performance comparable to prior work."],"url":"http://arxiv.org/abs/2311.04194v1"}
{"created":"2023-11-07 18:34:02","title":"Selective Visual Representations Improve Convergence and Generalization for Embodied AI","abstract":"Embodied AI models often employ off the shelf vision backbones like CLIP to encode their visual observations. Although such general purpose representations encode rich syntactic and semantic information about the scene, much of this information is often irrelevant to the specific task at hand. This introduces noise within the learning process and distracts the agent's focus from task-relevant visual cues. Inspired by selective attention in humans-the process through which people filter their perception based on their experiences, knowledge, and the task at hand-we introduce a parameter-efficient approach to filter visual stimuli for embodied AI. Our approach induces a task-conditioned bottleneck using a small learnable codebook module. This codebook is trained jointly to optimize task reward and acts as a task-conditioned selective filter over the visual observation. Our experiments showcase state-of-the-art performance for object goal navigation and object displacement across 5 benchmarks, ProcTHOR, ArchitecTHOR, RoboTHOR, AI2-iTHOR, and ManipulaTHOR. The filtered representations produced by the codebook are also able generalize better and converge faster when adapted to other simulation environments such as Habitat. Our qualitative analyses show that agents explore their environments more effectively and their representations retain task-relevant information like target object recognition while ignoring superfluous information about other objects. Code and pretrained models are available at our project website: https://embodied-codebook.github.io.","sentences":["Embodied AI models often employ off the shelf vision backbones like CLIP to encode their visual observations.","Although such general purpose representations encode rich syntactic and semantic information about the scene, much of this information is often irrelevant to the specific task at hand.","This introduces noise within the learning process and distracts the agent's focus from task-relevant visual cues.","Inspired by selective attention in humans-the process through which people filter their perception based on their experiences, knowledge, and the task at hand-we introduce a parameter-efficient approach to filter visual stimuli for embodied AI.","Our approach induces a task-conditioned bottleneck using a small learnable codebook module.","This codebook is trained jointly to optimize task reward and acts as a task-conditioned selective filter over the visual observation.","Our experiments showcase state-of-the-art performance for object goal navigation and object displacement across 5 benchmarks, ProcTHOR, ArchitecTHOR, RoboTHOR, AI2-iTHOR, and ManipulaTHOR.","The filtered representations produced by the codebook are also able generalize better and converge faster when adapted to other simulation environments such as Habitat.","Our qualitative analyses show that agents explore their environments more effectively and their representations retain task-relevant information like target object recognition while ignoring superfluous information about other objects.","Code and pretrained models are available at our project website: https://embodied-codebook.github.io."],"url":"http://arxiv.org/abs/2311.04193v1"}
{"created":"2023-11-07 18:33:34","title":"JaSPICE: Automatic Evaluation Metric Using Predicate-Argument Structures for Image Captioning Models","abstract":"Image captioning studies heavily rely on automatic evaluation metrics such as BLEU and METEOR. However, such n-gram-based metrics have been shown to correlate poorly with human evaluation, leading to the proposal of alternative metrics such as SPICE for English; however, no equivalent metrics have been established for other languages. Therefore, in this study, we propose an automatic evaluation metric called JaSPICE, which evaluates Japanese captions based on scene graphs. The proposed method generates a scene graph from dependencies and the predicate-argument structure, and extends the graph using synonyms. We conducted experiments employing 10 image captioning models trained on STAIR Captions and PFN-PIC and constructed the Shichimi dataset, which contains 103,170 human evaluations. The results showed that our metric outperformed the baseline metrics for the correlation coefficient with the human evaluation.","sentences":["Image captioning studies heavily rely on automatic evaluation metrics such as BLEU and METEOR.","However, such n-gram-based metrics have been shown to correlate poorly with human evaluation, leading to the proposal of alternative metrics such as SPICE for English; however, no equivalent metrics have been established for other languages.","Therefore, in this study, we propose an automatic evaluation metric called JaSPICE, which evaluates Japanese captions based on scene graphs.","The proposed method generates a scene graph from dependencies and the predicate-argument structure, and extends the graph using synonyms.","We conducted experiments employing 10 image captioning models trained on STAIR Captions and PFN-PIC and constructed the Shichimi dataset, which contains 103,170 human evaluations.","The results showed that our metric outperformed the baseline metrics for the correlation coefficient with the human evaluation."],"url":"http://arxiv.org/abs/2311.04192v1"}
{"created":"2023-11-07 18:33:08","title":"Spatio-Temporal Anomaly Detection with Graph Networks for Data Quality Monitoring of the Hadron Calorimeter","abstract":"The compact muon solenoid (CMS) experiment is a general-purpose detector for high-energy collision at the large hadron collider (LHC) at CERN. It employs an online data quality monitoring (DQM) system to promptly spot and diagnose particle data acquisition problems to avoid data quality loss. In this study, we present semi-supervised spatio-temporal anomaly detection (AD) monitoring for the physics particle reading channels of the hadronic calorimeter (HCAL) of the CMS using three-dimensional digi-occupancy map data of the DQM. We propose the GraphSTAD system, which employs convolutional and graph neural networks to learn local spatial characteristics induced by particles traversing the detector, and global behavior owing to shared backend circuit connections and housing boxes of the channels, respectively. Recurrent neural networks capture the temporal evolution of the extracted spatial features. We have validated the accuracy of the proposed AD system in capturing diverse channel fault types using the LHC Run-2 collision data sets. The GraphSTAD system has achieved production-level accuracy and is being integrated into the CMS core production system--for real-time monitoring of the HCAL. We have also provided a quantitative performance comparison with alternative benchmark models to demonstrate the promising leverage of the presented system.","sentences":["The compact muon solenoid (CMS) experiment is a general-purpose detector for high-energy collision at the large hadron collider (LHC) at CERN.","It employs an online data quality monitoring (DQM) system to promptly spot and diagnose particle data acquisition problems to avoid data quality loss.","In this study, we present semi-supervised spatio-temporal anomaly detection (AD) monitoring for the physics particle reading channels of the hadronic calorimeter (HCAL) of the CMS using three-dimensional digi-occupancy map data of the DQM.","We propose the GraphSTAD system, which employs convolutional and graph neural networks to learn local spatial characteristics induced by particles traversing the detector, and global behavior owing to shared backend circuit connections and housing boxes of the channels, respectively.","Recurrent neural networks capture the temporal evolution of the extracted spatial features.","We have validated the accuracy of the proposed AD system in capturing diverse channel fault types using the LHC Run-2 collision data sets.","The GraphSTAD system has achieved production-level accuracy and is being integrated into the CMS core production system--for real-time monitoring of the HCAL.","We have also provided a quantitative performance comparison with alternative benchmark models to demonstrate the promising leverage of the presented system."],"url":"http://arxiv.org/abs/2311.04190v1"}
{"created":"2023-11-07 18:32:34","title":"SpaDeLeF: A Dataset for Hierarchical Classification of Lexical Functions for Collocations in Spanish","abstract":"In natural language processing (NLP), lexical function is a concept to unambiguously represent semantic and syntactic features of words and phrases in text first crafted in the Meaning-Text Theory. Hierarchical classification of lexical functions involves organizing these features into a tree-like hierarchy of categories or labels. This is a challenging task as it requires a good understanding of the context and the relationships among words and phrases in text. It also needs large amounts of labeled data to train language models effectively. In this paper, we present a dataset of most frequent Spanish verb-noun collocations and sentences where they occur, each collocation is assigned to one of 37 lexical functions defined as classes for a hierarchical classification task. Each class represents a relation between the noun and the verb in a collocation involving their semantic and syntactic features. We combine the classes in a tree-based structure, and introduce classification objectives for each level of the structure. The dataset was created by dependency tree parsing and matching of the phrases in Spanish news. We provide baselines and data splits for each objective.","sentences":["In natural language processing (NLP), lexical function is a concept to unambiguously represent semantic and syntactic features of words and phrases in text first crafted in the Meaning-Text Theory.","Hierarchical classification of lexical functions involves organizing these features into a tree-like hierarchy of categories or labels.","This is a challenging task as it requires a good understanding of the context and the relationships among words and phrases in text.","It also needs large amounts of labeled data to train language models effectively.","In this paper, we present a dataset of most frequent Spanish verb-noun collocations and sentences where they occur, each collocation is assigned to one of 37 lexical functions defined as classes for a hierarchical classification task.","Each class represents a relation between the noun and the verb in a collocation involving their semantic and syntactic features.","We combine the classes in a tree-based structure, and introduce classification objectives for each level of the structure.","The dataset was created by dependency tree parsing and matching of the phrases in Spanish news.","We provide baselines and data splits for each objective."],"url":"http://arxiv.org/abs/2311.04189v1"}
{"created":"2023-11-07 18:13:47","title":"A First Look At NAT64 Deployment In-The-Wild","abstract":"IPv6 is a fundamentally different Internet Protocol than IPv4, and IPv6-only networks cannot, by default, communicate with the IPv4 Internet. This lack of interoperability necessitates complex mechanisms for incremental deployment and bridging networks so that non-dual-stack systems can interact with the whole Internet. NAT64 is one such bridging mechanism by which a network allows IPv6-only clients to connect to the entire Internet, leveraging DNS to identify IPv4-only networks, inject IPv6 response addresses pointing to an internal gateway, and seamlessly translate connections. To date, our understanding of NAT64 deployments is limited; what little information exists is largely qualitative, taken from mailing lists and informal discussions.   In this work, we present a first look at the active measurement of NAT64 deployment on the Internet focused on deployment prevalence, configuration, and security. We seek to measure NAT64 via two distinct large-scale measurements: 1) open resolvers on the Internet, and 2) client measurements from RIPE Atlas. For both datasets, we broadly find that despite substantial anecdotal reports of NAT64 deployment, measurable deployments are exceedingly sparse. While our measurements do not preclude the large-scale deployment of NAT64, they do point to substantial challenges in measuring deployments with our existing best-known methods. Finally, we also identify problems in NAT64 deployments, with gateways not following the RFC specification and also posing potential security risks.","sentences":["IPv6 is a fundamentally different Internet Protocol than IPv4, and IPv6-only networks cannot, by default, communicate with the IPv4 Internet.","This lack of interoperability necessitates complex mechanisms for incremental deployment and bridging networks so that non-dual-stack systems can interact with the whole Internet.","NAT64 is one such bridging mechanism by which a network allows IPv6-only clients to connect to the entire Internet, leveraging DNS to identify IPv4-only networks, inject IPv6 response addresses pointing to an internal gateway, and seamlessly translate connections.","To date, our understanding of NAT64 deployments is limited; what little information exists is largely qualitative, taken from mailing lists and informal discussions.   ","In this work, we present a first look at the active measurement of NAT64 deployment on the Internet focused on deployment prevalence, configuration, and security.","We seek to measure NAT64 via two distinct large-scale measurements: 1) open resolvers on the Internet, and 2) client measurements from RIPE Atlas.","For both datasets, we broadly find that despite substantial anecdotal reports of NAT64 deployment, measurable deployments are exceedingly sparse.","While our measurements do not preclude the large-scale deployment of NAT64, they do point to substantial challenges in measuring deployments with our existing best-known methods.","Finally, we also identify problems in NAT64 deployments, with gateways not following the RFC specification and also posing potential security risks."],"url":"http://arxiv.org/abs/2311.04181v1"}
{"created":"2023-11-07 18:10:37","title":"Polyregular functions on unordered trees of bounded height","abstract":"We consider injective first-order interpretations that input and output trees of bounded height. The corresponding functions have polynomial output size, since a first-order interpretation can use a k-tuple of input nodes to represent a single output node. We prove that the equivalence problem for such functions is decidable, i.e. given two such interpretations, one can decide whether, for every input tree, the two output trees are isomorphic.   We also give a calculus of typed functions and combinators which derives exactly injective first-order interpretations for unordered trees of bounded height. The calculus is based on a type system, where the type constructors are products, coproducts and a monad of multisets. Thanks to our results about tree-to-tree interpretations, the equivalence problem is decidable for this calculus.   As an application, we show that the equivalence problem is decidable for first-order interpretations between classes of graphs that have bounded tree-depth. In all cases studied in this paper, first-order logic and MSO have the same expressive power, and hence all results apply also to MSO interpretations.","sentences":["We consider injective first-order interpretations that input and output trees of bounded height.","The corresponding functions have polynomial output size, since a first-order interpretation can use a k-tuple of input nodes to represent a single output node.","We prove that the equivalence problem for such functions is decidable, i.e. given two such interpretations, one can decide whether, for every input tree, the two output trees are isomorphic.   ","We also give a calculus of typed functions and combinators which derives exactly injective first-order interpretations for unordered trees of bounded height.","The calculus is based on a type system, where the type constructors are products, coproducts and a monad of multisets.","Thanks to our results about tree-to-tree interpretations, the equivalence problem is decidable for this calculus.   ","As an application, we show that the equivalence problem is decidable for first-order interpretations between classes of graphs that have bounded tree-depth.","In all cases studied in this paper, first-order logic and MSO have the same expressive power, and hence all results apply also to MSO interpretations."],"url":"http://arxiv.org/abs/2311.04180v1"}
{"created":"2023-11-07 18:06:29","title":"On Leakage in Machine Learning Pipelines","abstract":"Machine learning (ML) provides powerful tools for predictive modeling. ML's popularity stems from the promise of sample-level prediction with applications across a variety of fields from physics and marketing to healthcare. However, if not properly implemented and evaluated, ML pipelines may contain leakage typically resulting in overoptimistic performance estimates and failure to generalize to new data. This can have severe negative financial and societal implications. Our aim is to expand understanding associated with causes leading to leakage when designing, implementing, and evaluating ML pipelines. Illustrated by concrete examples, we provide a comprehensive overview and discussion of various types of leakage that may arise in ML pipelines.","sentences":["Machine learning (ML) provides powerful tools for predictive modeling.","ML's popularity stems from the promise of sample-level prediction with applications across a variety of fields from physics and marketing to healthcare.","However, if not properly implemented and evaluated, ML pipelines may contain leakage typically resulting in overoptimistic performance estimates and failure to generalize to new data.","This can have severe negative financial and societal implications.","Our aim is to expand understanding associated with causes leading to leakage when designing, implementing, and evaluating ML pipelines.","Illustrated by concrete examples, we provide a comprehensive overview and discussion of various types of leakage that may arise in ML pipelines."],"url":"http://arxiv.org/abs/2311.04179v1"}
{"created":"2023-11-07 18:03:23","title":"Enhancing LLM Intelligence with ARM-RAG: Auxiliary Rationale Memory for Retrieval Augmented Generation","abstract":"Large Language Models (LLMs) are smart but forgetful. Recent studies, (e.g., (Bubeck et al., 2023)) on modern LLMs have shown that they are capable of performing amazing tasks typically necessitating human-level intelligence. However, unlike humans, frozen LLMs do not improve over time; they neither acquire new knowledge nor learn from their successes or failures. Some approaches to improving the intelligence of LLMs include fine-tuning models based on problem-solving performance (Zelikman et al., 2022), and building bigger and more sophisticated models (Bubeck et al., 2023). However, these methods have the drawback of requiring substantial data and computational resources to retrain existing models. In this paper, we explore the use of Retrieval Augmented Generation, also known as RAG (Lewis et al., 2021) to improve problem-solving performance. We propose ARM-RAG (Auxiliary Rationale Memory for Retrieval Augmented Generation), a system that learns from its successes without incurring high training costs. We demonstrate that the storage and subsequent retrieval of reasoning chains have a positive influence on performance in grade-school math problems.","sentences":["Large Language Models (LLMs) are smart but forgetful.","Recent studies, (e.g., (Bubeck et al., 2023)) on modern LLMs have shown that they are capable of performing amazing tasks typically necessitating human-level intelligence.","However, unlike humans, frozen LLMs do not improve over time; they neither acquire new knowledge nor learn from their successes or failures.","Some approaches to improving the intelligence of LLMs include fine-tuning models based on problem-solving performance (Zelikman et al., 2022), and building bigger and more sophisticated models (Bubeck et al., 2023).","However, these methods have the drawback of requiring substantial data and computational resources to retrain existing models.","In this paper, we explore the use of Retrieval Augmented Generation, also known as RAG (Lewis et al., 2021) to improve problem-solving performance.","We propose ARM-RAG (Auxiliary Rationale Memory for Retrieval Augmented Generation), a system that learns from its successes without incurring high training costs.","We demonstrate that the storage and subsequent retrieval of reasoning chains have a positive influence on performance in grade-school math problems."],"url":"http://arxiv.org/abs/2311.04177v1"}
{"created":"2023-11-07 17:54:04","title":"HADES: Fast Singularity Detection with Local Measure Comparison","abstract":"We introduce Hades, an unsupervised algorithm to detect singularities in data. This algorithm employs a kernel goodness-of-fit test, and as a consequence it is much faster and far more scaleable than the existing topology-based alternatives. Using tools from differential geometry and optimal transport theory, we prove that Hades correctly detects singularities with high probability when the data sample lives on a transverse intersection of equidimensional manifolds. In computational experiments, Hades recovers singularities in synthetically generated data, branching points in road network data, intersection rings in molecular conformation space, and anomalies in image data.","sentences":["We introduce Hades, an unsupervised algorithm to detect singularities in data.","This algorithm employs a kernel goodness-of-fit test, and as a consequence it is much faster and far more scaleable than the existing topology-based alternatives.","Using tools from differential geometry and optimal transport theory, we prove that Hades correctly detects singularities with high probability when the data sample lives on a transverse intersection of equidimensional manifolds.","In computational experiments, Hades recovers singularities in synthetically generated data, branching points in road network data, intersection rings in molecular conformation space, and anomalies in image data."],"url":"http://arxiv.org/abs/2311.04171v1"}
{"created":"2023-11-07 17:48:35","title":"Perturbed examples reveal invariances shared by language models","abstract":"An explosion of work in language is leading to ever-increasing numbers of available natural language processing models, with little understanding of how new models compare to better-understood models. One major reason for this difficulty is saturating benchmark datasets, which may not reflect well differences in model performance in the wild. In this work, we propose a novel framework for comparing two natural language processing models by revealing their shared invariance to interpretable input perturbations that are designed to target a specific linguistic capability (e.g., Synonym-Invariance, Typo-Invariance). Via experiments on models from within the same and across different architecture families, this framework offers a number of insights about how changes in models (e.g., distillation, increase in size, amount of pre-training) affect multiple well-defined linguistic capabilities. Furthermore, we also demonstrate how our framework can enable evaluation of the invariances shared between models that are available as commercial black-box APIs (e.g., InstructGPT family) and models that are relatively better understood (e.g., GPT-2). Across several experiments, we observe that large language models share many of the invariances encoded by models of various sizes, whereas the invariances encoded by large language models are only shared by other large models. Possessing a wide variety of invariances may be a key reason for the recent successes of large language models, and our framework can shed light on the types of invariances that are retained by or emerge in new models.","sentences":["An explosion of work in language is leading to ever-increasing numbers of available natural language processing models, with little understanding of how new models compare to better-understood models.","One major reason for this difficulty is saturating benchmark datasets, which may not reflect well differences in model performance in the wild.","In this work, we propose a novel framework for comparing two natural language processing models by revealing their shared invariance to interpretable input perturbations that are designed to target a specific linguistic capability (e.g., Synonym-Invariance, Typo-Invariance).","Via experiments on models from within the same and across different architecture families, this framework offers a number of insights about how changes in models (e.g., distillation, increase in size, amount of pre-training) affect multiple well-defined linguistic capabilities.","Furthermore, we also demonstrate how our framework can enable evaluation of the invariances shared between models that are available as commercial black-box APIs (e.g., InstructGPT family) and models that are relatively better understood (e.g., GPT-2).","Across several experiments, we observe that large language models share many of the invariances encoded by models of various sizes, whereas the invariances encoded by large language models are only shared by other large models.","Possessing a wide variety of invariances may be a key reason for the recent successes of large language models, and our framework can shed light on the types of invariances that are retained by or emerge in new models."],"url":"http://arxiv.org/abs/2311.04166v1"}
{"created":"2023-11-07 17:47:20","title":"Models towards Risk Behavior Prediction and Analysis: A Netherlands Case study","abstract":"In many countries financial service providers have to elicit their customers risk preferences, when offering products and services. For instance, in the Netherlands pension funds will be legally obliged to factor in their clients risk preferences when devising their investment strategies. Therefore, assessing and measuring the risk preferences of individuals is critical for the analysis of individuals' behavior and policy prescriptions. In the psychology and economics, a number of methods to elicit risk preferences have been developed using hypothetical scenarios and economic experiments. These methods of eliciting individual risk preferences are usually applied to small samples because they are expensive and the implementation can be complex and not suitable when large cohorts need to be measured. A large number of supervised learning models ranging from linear regression to support vector machines are used to predict risk preference measures using socio-economic register data such as age, gender, migration background and other demographic variables in combination with data on income, wealth, pension fund contributions, and other financial data. The employed machine learning models cover a range of assumptions and properties as well as a diverse set of regression metrics. The optimum model is selected using the metrics and interpretability of the model. The optimal models are lasso regression and gradient boosting machines with mean average percentage error of about 30%. This is important as it helps to estimate risk attitudes without actually measuring them. It should be noted that with the current accuracy the tested models are not ready for deployment for applications that require high accuracy. However, the results do indicate which models should be used in situations that do not require the most accurate predictions such as augmentation data for pensions' recommendation.","sentences":["In many countries financial service providers have to elicit their customers risk preferences, when offering products and services.","For instance, in the Netherlands pension funds will be legally obliged to factor in their clients risk preferences when devising their investment strategies.","Therefore, assessing and measuring the risk preferences of individuals is critical for the analysis of individuals' behavior and policy prescriptions.","In the psychology and economics, a number of methods to elicit risk preferences have been developed using hypothetical scenarios and economic experiments.","These methods of eliciting individual risk preferences are usually applied to small samples because they are expensive and the implementation can be complex and not suitable when large cohorts need to be measured.","A large number of supervised learning models ranging from linear regression to support vector machines are used to predict risk preference measures using socio-economic register data such as age, gender, migration background and other demographic variables in combination with data on income, wealth, pension fund contributions, and other financial data.","The employed machine learning models cover a range of assumptions and properties as well as a diverse set of regression metrics.","The optimum model is selected using the metrics and interpretability of the model.","The optimal models are lasso regression and gradient boosting machines with mean average percentage error of about 30%.","This is important as it helps to estimate risk attitudes without actually measuring them.","It should be noted that with the current accuracy the tested models are not ready for deployment for applications that require high accuracy.","However, the results do indicate which models should be used in situations that do not require the most accurate predictions such as augmentation data for pensions' recommendation."],"url":"http://arxiv.org/abs/2311.04164v1"}
{"created":"2023-11-07 17:43:50","title":"Outliers with Opposing Signals Have an Outsized Effect on Neural Network Optimization","abstract":"We identify a new phenomenon in neural network optimization which arises from the interaction of depth and a particular heavy-tailed structure in natural data. Our result offers intuitive explanations for several previously reported observations about network training dynamics. In particular, it implies a conceptually new cause for progressive sharpening and the edge of stability; we also highlight connections to other concepts in optimization and generalization including grokking, simplicity bias, and Sharpness-Aware Minimization.   Experimentally, we demonstrate the significant influence of paired groups of outliers in the training data with strong opposing signals: consistent, large magnitude features which dominate the network output throughout training and provide gradients which point in opposite directions. Due to these outliers, early optimization enters a narrow valley which carefully balances the opposing groups; subsequent sharpening causes their loss to rise rapidly, oscillating between high on one group and then the other, until the overall loss spikes. We describe how to identify these groups, explore what sets them apart, and carefully study their effect on the network's optimization and behavior. We complement these experiments with a mechanistic explanation on a toy example of opposing signals and a theoretical analysis of a two-layer linear network on a simple model. Our finding enables new qualitative predictions of training behavior which we confirm experimentally. It also provides a new lens through which to study and improve modern training practices for stochastic optimization, which we highlight via a case study of Adam versus SGD.","sentences":["We identify a new phenomenon in neural network optimization which arises from the interaction of depth and a particular heavy-tailed structure in natural data.","Our result offers intuitive explanations for several previously reported observations about network training dynamics.","In particular, it implies a conceptually new cause for progressive sharpening and the edge of stability; we also highlight connections to other concepts in optimization and generalization including grokking, simplicity bias, and Sharpness-Aware Minimization.   ","Experimentally, we demonstrate the significant influence of paired groups of outliers in the training data with strong opposing signals: consistent, large magnitude features which dominate the network output throughout training and provide gradients which point in opposite directions.","Due to these outliers, early optimization enters a narrow valley which carefully balances the opposing groups; subsequent sharpening causes their loss to rise rapidly, oscillating between high on one group and then the other, until the overall loss spikes.","We describe how to identify these groups, explore what sets them apart, and carefully study their effect on the network's optimization and behavior.","We complement these experiments with a mechanistic explanation on a toy example of opposing signals and a theoretical analysis of a two-layer linear network on a simple model.","Our finding enables new qualitative predictions of training behavior which we confirm experimentally.","It also provides a new lens through which to study and improve modern training practices for stochastic optimization, which we highlight via a case study of Adam versus SGD."],"url":"http://arxiv.org/abs/2311.04163v1"}
{"created":"2023-11-07 17:38:35","title":"\"Tell me about that church\": Exploring the Design and User Experience of In-Vehicle Multi-modal Intuitive Interface in the Context of Driving Scenario","abstract":"Intuitive interaction has long been seen as a highly user-friendly method. There are attempts to implement intuitive interfaces in vehicles in both research and industrial, such as voice commands. However, there is a lack of exploration in the in-vehicle multi-modal intuitive interaction, especially under a dynamic driving scenario. In this research, we conducted a design workshop (N=6) to understand user's needs and designers' considerations on the in-vehicle multi-modal intuitive interface, based on which we implemented our design on both a simulator and a real autonomous vehicle using Wizard-of-Oz. We conducted a user experiment (N=12) on the simulator to explore determinants of users' acceptance, experience, and behavior. We figured that acceptance was significantly influenced by six determinants. Drivers' behavior has an obvious pattern of change. Drivers have been proven to have less workload but distractions were also reported. Our findings offered empirical evidence which could give insights into future vehicle design.","sentences":["Intuitive interaction has long been seen as a highly user-friendly method.","There are attempts to implement intuitive interfaces in vehicles in both research and industrial, such as voice commands.","However, there is a lack of exploration in the in-vehicle multi-modal intuitive interaction, especially under a dynamic driving scenario.","In this research, we conducted a design workshop (N=6) to understand user's needs and designers' considerations on the in-vehicle multi-modal intuitive interface, based on which we implemented our design on both a simulator and a real autonomous vehicle using Wizard-of-Oz.","We conducted a user experiment (N=12) on the simulator to explore determinants of users' acceptance, experience, and behavior.","We figured that acceptance was significantly influenced by six determinants.","Drivers' behavior has an obvious pattern of change.","Drivers have been proven to have less workload but distractions were also reported.","Our findings offered empirical evidence which could give insights into future vehicle design."],"url":"http://arxiv.org/abs/2311.04160v1"}
{"created":"2023-11-07 17:34:56","title":"Computing Approximate $\\ell_p$ Sensitivities","abstract":"Recent works in dimensionality reduction for regression tasks have introduced the notion of sensitivity, an estimate of the importance of a specific datapoint in a dataset, offering provable guarantees on the quality of the approximation after removing low-sensitivity datapoints via subsampling. However, fast algorithms for approximating $\\ell_p$ sensitivities, which we show is equivalent to approximate $\\ell_p$ regression, are known for only the $\\ell_2$ setting, in which they are termed leverage scores.   In this work, we provide efficient algorithms for approximating $\\ell_p$ sensitivities and related summary statistics of a given matrix. In particular, for a given $n \\times d$ matrix, we compute $\\alpha$-approximation to its $\\ell_1$ sensitivities at the cost of $O(n/\\alpha)$ sensitivity computations. For estimating the total $\\ell_p$ sensitivity (i.e. the sum of $\\ell_p$ sensitivities), we provide an algorithm based on importance sampling of $\\ell_p$ Lewis weights, which computes a constant factor approximation to the total sensitivity at the cost of roughly $O(\\sqrt{d})$ sensitivity computations. Furthermore, we estimate the maximum $\\ell_1$ sensitivity, up to a $\\sqrt{d}$ factor, using $O(d)$ sensitivity computations. We generalize all these results to $\\ell_p$ norms for $p > 1$. Lastly, we experimentally show that for a wide class of matrices in real-world datasets, the total sensitivity can be quickly approximated and is significantly smaller than the theoretical prediction, demonstrating that real-world datasets have low intrinsic effective dimensionality.","sentences":["Recent works in dimensionality reduction for regression tasks have introduced the notion of sensitivity, an estimate of the importance of a specific datapoint in a dataset, offering provable guarantees on the quality of the approximation after removing low-sensitivity datapoints via subsampling.","However, fast algorithms for approximating $\\ell_p$ sensitivities, which we show is equivalent to approximate $\\ell_p$ regression, are known for only the $\\ell_2$ setting, in which they are termed leverage scores.   ","In this work, we provide efficient algorithms for approximating $\\ell_p$ sensitivities and related summary statistics of a given matrix.","In particular, for a given $n \\times d$ matrix, we compute $\\alpha$-approximation to its $\\ell_1$ sensitivities at the cost of $O(n/\\alpha)$ sensitivity computations.","For estimating the total $\\ell_p$ sensitivity (i.e. the sum of $\\ell_p$ sensitivities), we provide an algorithm based on importance sampling of $\\ell_p$ Lewis weights, which computes a constant factor approximation to the total sensitivity at the cost of roughly $O(\\sqrt{d})$ sensitivity computations.","Furthermore, we estimate the maximum $\\ell_1$ sensitivity, up to a $\\sqrt{d}$ factor, using $O(d)$ sensitivity computations.","We generalize all these results to $\\ell_p$ norms for $p > 1$.","Lastly, we experimentally show that for a wide class of matrices in real-world datasets, the total sensitivity can be quickly approximated and is significantly smaller than the theoretical prediction, demonstrating that real-world datasets have low intrinsic effective dimensionality."],"url":"http://arxiv.org/abs/2311.04158v1"}
{"created":"2023-11-07 17:32:55","title":"A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis","abstract":"We present a novel usage of Transformers to make image classification interpretable. Unlike mainstream classifiers that wait until the last fully-connected layer to incorporate class information to make predictions, we investigate a proactive approach, asking each class to search for itself in an image. We realize this idea via a Transformer encoder-decoder inspired by DEtection TRansformer (DETR). We learn ``class-specific'' queries (one for each class) as input to the decoder, enabling each class to localize its patterns in an image via cross-attention. We name our approach INterpretable TRansformer (INTR), which is fairly easy to implement and exhibits several compelling properties. We show that INTR intrinsically encourages each class to attend distinctively; the cross-attention weights thus provide a faithful interpretation of the prediction. Interestingly, via ``multi-head'' cross-attention, INTR could identify different ``attributes'' of a class, making it particularly suitable for fine-grained classification and analysis, which we demonstrate on eight datasets. Our code and pre-trained model are publicly accessible at https://github.com/Imageomics/INTR.","sentences":["We present a novel usage of Transformers to make image classification interpretable.","Unlike mainstream classifiers that wait until the last fully-connected layer to incorporate class information to make predictions, we investigate a proactive approach, asking each class to search for itself in an image.","We realize this idea via a Transformer encoder-decoder inspired by DEtection TRansformer (DETR).","We learn ``class-specific'' queries (one for each class) as input to the decoder, enabling each class to localize its patterns in an image via cross-attention.","We name our approach INterpretable TRansformer (INTR), which is fairly easy to implement and exhibits several compelling properties.","We show that INTR intrinsically encourages each class to attend distinctively; the cross-attention weights thus provide a faithful interpretation of the prediction.","Interestingly, via ``multi-head'' cross-attention, INTR could identify different ``attributes'' of a class, making it particularly suitable for fine-grained classification and analysis, which we demonstrate on eight datasets.","Our code and pre-trained model are publicly accessible at https://github.com/Imageomics/INTR."],"url":"http://arxiv.org/abs/2311.04157v1"}
{"created":"2023-11-07 17:31:50","title":"Black-Box Prompt Optimization: Aligning Large Language Models without Model Training","abstract":"Large language models (LLMs) have shown impressive success in various applications. However, these models are often not well aligned with human intents, which calls for additional treatments on them, that is, the alignment problem. To make LLMs better follow user instructions, existing alignment methods mostly focus on further training them. However, the extra training of LLMs are usually expensive in terms of GPU compute; worse still, LLMs of interest are oftentimes not accessible for user-demanded training, such as GPTs. In this work, we take a different perspective -- Black-Box Prompt Optimization (BPO) -- to perform alignments. The idea is to optimize user prompts to suit LLMs' input understanding, so as to best realize users' intents without updating LLMs' parameters. BPO is model-agnostic and the empirical results demonstrate that the BPO-aligned ChatGPT yields a 22\\% increase in the win rate against its original version, and 10\\% for GPT-4. Importantly, the \\model-aligned LLMs can outperform the same models aligned by PPO and DPO, and it also brings additional performance gains when combining \\model with PPO or DPO. Code and datasets are released at https://github.com/thu-coai/BPO.","sentences":["Large language models (LLMs) have shown impressive success in various applications.","However, these models are often not well aligned with human intents, which calls for additional treatments on them, that is, the alignment problem.","To make LLMs better follow user instructions, existing alignment methods mostly focus on further training them.","However, the extra training of LLMs are usually expensive in terms of GPU compute; worse still, LLMs of interest are oftentimes not accessible for user-demanded training, such as GPTs.","In this work, we take a different perspective -- Black-Box Prompt Optimization (BPO) -- to perform alignments.","The idea is to optimize user prompts to suit LLMs' input understanding, so as to best realize users' intents without updating LLMs' parameters.","BPO is model-agnostic and the empirical results demonstrate that the BPO-aligned ChatGPT yields a 22\\% increase in the win rate against its original version, and 10\\% for GPT-4.","Importantly, the \\model-aligned LLMs can outperform the same models aligned by PPO and DPO, and it also brings additional performance gains when combining \\model with PPO or DPO.","Code and datasets are released at https://github.com/thu-coai/BPO."],"url":"http://arxiv.org/abs/2311.04155v1"}
{"created":"2023-11-07 17:31:27","title":"High-fidelity 3D Reconstruction of Plants using Neural Radiance Field","abstract":"Accurate reconstruction of plant phenotypes plays a key role in optimising sustainable farming practices in the field of Precision Agriculture (PA). Currently, optical sensor-based approaches dominate the field, but the need for high-fidelity 3D reconstruction of crops and plants in unstructured agricultural environments remains challenging. Recently, a promising development has emerged in the form of Neural Radiance Field (NeRF), a novel method that utilises neural density fields. This technique has shown impressive performance in various novel vision synthesis tasks, but has remained relatively unexplored in the agricultural context. In our study, we focus on two fundamental tasks within plant phenotyping: (1) the synthesis of 2D novel-view images and (2) the 3D reconstruction of crop and plant models. We explore the world of neural radiance fields, in particular two SOTA methods: Instant-NGP, which excels in generating high-quality images with impressive training and inference speed, and Instant-NSR, which improves the reconstructed geometry by incorporating the Signed Distance Function (SDF) during training. In particular, we present a novel plant phenotype dataset comprising real plant images from production environments. This dataset is a first-of-its-kind initiative aimed at comprehensively exploring the advantages and limitations of NeRF in agricultural contexts. Our experimental results show that NeRF demonstrates commendable performance in the synthesis of novel-view images and is able to achieve reconstruction results that are competitive with Reality Capture, a leading commercial software for 3D Multi-View Stereo (MVS)-based reconstruction. However, our study also highlights certain drawbacks of NeRF, including relatively slow training speeds, performance limitations in cases of insufficient sampling, and challenges in obtaining geometry quality in complex setups.","sentences":["Accurate reconstruction of plant phenotypes plays a key role in optimising sustainable farming practices in the field of Precision Agriculture (PA).","Currently, optical sensor-based approaches dominate the field, but the need for high-fidelity 3D reconstruction of crops and plants in unstructured agricultural environments remains challenging.","Recently, a promising development has emerged in the form of Neural Radiance Field (NeRF), a novel method that utilises neural density fields.","This technique has shown impressive performance in various novel vision synthesis tasks, but has remained relatively unexplored in the agricultural context.","In our study, we focus on two fundamental tasks within plant phenotyping: (1) the synthesis of 2D novel-view images and (2) the 3D reconstruction of crop and plant models.","We explore the world of neural radiance fields, in particular two SOTA methods: Instant-NGP, which excels in generating high-quality images with impressive training and inference speed, and Instant-NSR, which improves the reconstructed geometry by incorporating the Signed Distance Function (SDF) during training.","In particular, we present a novel plant phenotype dataset comprising real plant images from production environments.","This dataset is a first-of-its-kind initiative aimed at comprehensively exploring the advantages and limitations of NeRF in agricultural contexts.","Our experimental results show that NeRF demonstrates commendable performance in the synthesis of novel-view images and is able to achieve reconstruction results that are competitive with Reality Capture, a leading commercial software for 3D Multi-View Stereo (MVS)-based reconstruction.","However, our study also highlights certain drawbacks of NeRF, including relatively slow training speeds, performance limitations in cases of insufficient sampling, and challenges in obtaining geometry quality in complex setups."],"url":"http://arxiv.org/abs/2311.04154v1"}
{"created":"2023-11-07 17:26:51","title":"What Makes a Fantastic Passenger-Car Driver in Urban Contexts?","abstract":"The accurate evaluation of the quality of driving behavior is crucial for optimizing and implementing autonomous driving technology in practice. However, there is no comprehensive understanding of good driving behaviors currently. In this paper, we sought to understand driving behaviors from the perspectives of both drivers and passengers. We invited 10 expert drivers and 14 novice drivers to complete a 5.7-kilometer urban road driving task. After the experiments, we conducted semi-structured interviews with 24 drivers and 48 of their passengers (two passengers per driver). Through the analysis of interview data, we found passengers' assessing logic of driving behaviors, divers' considerations and efforts to achieve good driving, and gaps between these perspectives. Our research provided insights into a systematic evaluation of autonomous driving and the design implications for future autonomous vehicles.","sentences":["The accurate evaluation of the quality of driving behavior is crucial for optimizing and implementing autonomous driving technology in practice.","However, there is no comprehensive understanding of good driving behaviors currently.","In this paper, we sought to understand driving behaviors from the perspectives of both drivers and passengers.","We invited 10 expert drivers and 14 novice drivers to complete a 5.7-kilometer urban road driving task.","After the experiments, we conducted semi-structured interviews with 24 drivers and 48 of their passengers (two passengers per driver).","Through the analysis of interview data, we found passengers' assessing logic of driving behaviors, divers' considerations and efforts to achieve good driving, and gaps between these perspectives.","Our research provided insights into a systematic evaluation of autonomous driving and the design implications for future autonomous vehicles."],"url":"http://arxiv.org/abs/2311.04150v1"}
{"created":"2023-11-07 17:26:31","title":"HyperS2V: A Framework for Structural Representation of Nodes in Hyper Networks","abstract":"In contrast to regular (simple) networks, hyper networks possess the ability to depict more complex relationships among nodes and store extensive information. Such networks are commonly found in real-world applications, such as in social interactions. Learning embedded representations for nodes involves a process that translates network structures into more simplified spaces, thereby enabling the application of machine learning approaches designed for vector data to be extended to network data. Nevertheless, there remains a need to delve into methods for learning embedded representations that prioritize structural aspects. This research introduces HyperS2V, a node embedding approach that centers on the structural similarity within hyper networks. Initially, we establish the concept of hyper-degrees to capture the structural properties of nodes within hyper networks. Subsequently, a novel function is formulated to measure the structural similarity between different hyper-degree values. Lastly, we generate structural embeddings utilizing a multi-scale random walk framework. Moreover, a series of experiments, both intrinsic and extrinsic, are performed on both toy and real networks. The results underscore the superior performance of HyperS2V in terms of both interpretability and applicability to downstream tasks.","sentences":["In contrast to regular (simple) networks, hyper networks possess the ability to depict more complex relationships among nodes and store extensive information.","Such networks are commonly found in real-world applications, such as in social interactions.","Learning embedded representations for nodes involves a process that translates network structures into more simplified spaces, thereby enabling the application of machine learning approaches designed for vector data to be extended to network data.","Nevertheless, there remains a need to delve into methods for learning embedded representations that prioritize structural aspects.","This research introduces HyperS2V, a node embedding approach that centers on the structural similarity within hyper networks.","Initially, we establish the concept of hyper-degrees to capture the structural properties of nodes within hyper networks.","Subsequently, a novel function is formulated to measure the structural similarity between different hyper-degree values.","Lastly, we generate structural embeddings utilizing a multi-scale random walk framework.","Moreover, a series of experiments, both intrinsic and extrinsic, are performed on both toy and real networks.","The results underscore the superior performance of HyperS2V in terms of both interpretability and applicability to downstream tasks."],"url":"http://arxiv.org/abs/2311.04149v1"}
{"created":"2023-11-07 17:19:59","title":"Contactless Fingerprint Biometric Anti-Spoofing: An Unsupervised Deep Learning Approach","abstract":"Contactless fingerprint recognition offers a higher level of user comfort and addresses hygiene concerns more effectively. However, it is also more vulnerable to presentation attacks such as photo paper, paper-printout, and various display attacks, which makes it more challenging to implement in biometric systems compared to contact-based modalities. Limited research has been conducted on presentation attacks in contactless fingerprint systems, and these studies have encountered challenges in terms of generalization and scalability since both bonafide samples and presentation attacks are utilized during training model. Although this approach appears promising, it lacks the ability to handle unseen attacks, which is a crucial factor for developing PAD methods that can generalize effectively. We introduced an innovative anti-spoofing approach that combines an unsupervised autoencoder with a convolutional block attention module to address the limitations of existing methods. Our model is exclusively trained on bonafide images without exposure to any spoofed samples during the training phase. It is then evaluated against various types of presentation attack images in the testing phase. The scheme we proposed has achieved an average BPCER of 0.96\\% with an APCER of 1.6\\% for presentation attacks involving various types of spoofed samples.","sentences":["Contactless fingerprint recognition offers a higher level of user comfort and addresses hygiene concerns more effectively.","However, it is also more vulnerable to presentation attacks such as photo paper, paper-printout, and various display attacks, which makes it more challenging to implement in biometric systems compared to contact-based modalities.","Limited research has been conducted on presentation attacks in contactless fingerprint systems, and these studies have encountered challenges in terms of generalization and scalability since both bonafide samples and presentation attacks are utilized during training model.","Although this approach appears promising, it lacks the ability to handle unseen attacks, which is a crucial factor for developing PAD methods that can generalize effectively.","We introduced an innovative anti-spoofing approach that combines an unsupervised autoencoder with a convolutional block attention module to address the limitations of existing methods.","Our model is exclusively trained on bonafide images without exposure to any spoofed samples during the training phase.","It is then evaluated against various types of presentation attack images in the testing phase.","The scheme we proposed has achieved an average BPCER of 0.96\\% with an APCER of 1.6\\% for presentation attacks involving various types of spoofed samples."],"url":"http://arxiv.org/abs/2311.04148v1"}
{"created":"2023-11-07 17:18:52","title":"Multi-resolution Time-Series Transformer for Long-term Forecasting","abstract":"The performance of transformers for time-series forecasting has improved significantly. Recent architectures learn complex temporal patterns by segmenting a time-series into patches and using the patches as tokens. The patch size controls the ability of transformers to learn the temporal patterns at different frequencies: shorter patches are effective for learning localized, high-frequency patterns, whereas mining long-term seasonalities and trends requires longer patches. Inspired by this observation, we propose a novel framework, Multi-resolution Time-Series Transformer (MTST), which consists of a multi-branch architecture for simultaneous modeling of diverse temporal patterns at different resolutions. In contrast to many existing time-series transformers, we employ relative positional encoding, which is better suited for extracting periodic components at different scales. Extensive experiments on several real-world datasets demonstrate the effectiveness of MTST in comparison to state-of-the-art forecasting techniques.","sentences":["The performance of transformers for time-series forecasting has improved significantly.","Recent architectures learn complex temporal patterns by segmenting a time-series into patches and using the patches as tokens.","The patch size controls the ability of transformers to learn the temporal patterns at different frequencies: shorter patches are effective for learning localized, high-frequency patterns, whereas mining long-term seasonalities and trends requires longer patches.","Inspired by this observation, we propose a novel framework, Multi-resolution Time-Series Transformer (MTST), which consists of a multi-branch architecture for simultaneous modeling of diverse temporal patterns at different resolutions.","In contrast to many existing time-series transformers, we employ relative positional encoding, which is better suited for extracting periodic components at different scales.","Extensive experiments on several real-world datasets demonstrate the effectiveness of MTST in comparison to state-of-the-art forecasting techniques."],"url":"http://arxiv.org/abs/2311.04147v1"}
{"created":"2023-11-07 17:16:06","title":"I2VGen-XL: High-Quality Image-to-Video Synthesis via Cascaded Diffusion Models","abstract":"Video synthesis has recently made remarkable strides benefiting from the rapid development of diffusion models. However, it still encounters challenges in terms of semantic accuracy, clarity and spatio-temporal continuity. They primarily arise from the scarcity of well-aligned text-video data and the complex inherent structure of videos, making it difficult for the model to simultaneously ensure semantic and qualitative excellence. In this report, we propose a cascaded I2VGen-XL approach that enhances model performance by decoupling these two factors and ensures the alignment of the input data by utilizing static images as a form of crucial guidance. I2VGen-XL consists of two stages: i) the base stage guarantees coherent semantics and preserves content from input images by using two hierarchical encoders, and ii) the refinement stage enhances the video's details by incorporating an additional brief text and improves the resolution to 1280$\\times$720. To improve the diversity, we collect around 35 million single-shot text-video pairs and 6 billion text-image pairs to optimize the model. By this means, I2VGen-XL can simultaneously enhance the semantic accuracy, continuity of details and clarity of generated videos. Through extensive experiments, we have investigated the underlying principles of I2VGen-XL and compared it with current top methods, which can demonstrate its effectiveness on diverse data. The source code and models will be publicly available at \\url{https://i2vgen-xl.github.io}.","sentences":["Video synthesis has recently made remarkable strides benefiting from the rapid development of diffusion models.","However, it still encounters challenges in terms of semantic accuracy, clarity and spatio-temporal continuity.","They primarily arise from the scarcity of well-aligned text-video data and the complex inherent structure of videos, making it difficult for the model to simultaneously ensure semantic and qualitative excellence.","In this report, we propose a cascaded I2VGen-XL approach that enhances model performance by decoupling these two factors and ensures the alignment of the input data by utilizing static images as a form of crucial guidance.","I2VGen-XL consists of two stages: i) the base stage guarantees coherent semantics and preserves content from input images by using two hierarchical encoders, and ii) the refinement stage enhances the video's details by incorporating an additional brief text and improves the resolution to 1280$\\times$720.","To improve the diversity, we collect around 35 million single-shot text-video pairs and 6 billion text-image pairs to optimize the model.","By this means, I2VGen-XL can simultaneously enhance the semantic accuracy, continuity of details and clarity of generated videos.","Through extensive experiments, we have investigated the underlying principles of I2VGen-XL and compared it with current top methods, which can demonstrate its effectiveness on diverse data.","The source code and models will be publicly available at \\url{https://i2vgen-xl.github.io}."],"url":"http://arxiv.org/abs/2311.04145v1"}
{"created":"2023-11-07 17:13:40","title":"What is Lost in Knowledge Distillation?","abstract":"Deep neural networks (DNNs) have improved NLP tasks significantly, but training and maintaining such networks could be costly. Model compression techniques, such as, knowledge distillation (KD), have been proposed to address the issue; however, the compression process could be lossy. Motivated by this, our work investigates how a distilled student model differs from its teacher, if the distillation process causes any information losses, and if the loss follows a specific pattern. Our experiments aim to shed light on the type of tasks might be less or more sensitive to KD by reporting data points on the contribution of different factors, such as the number of layers or attention heads. Results such as ours could be utilized when determining effective and efficient configurations to achieve optimal information transfers between larger (teacher) and smaller (student) models.","sentences":["Deep neural networks (DNNs) have improved NLP tasks significantly, but training and maintaining such networks could be costly.","Model compression techniques, such as, knowledge distillation (KD), have been proposed to address the issue; however, the compression process could be lossy.","Motivated by this, our work investigates how a distilled student model differs from its teacher, if the distillation process causes any information losses, and if the loss follows a specific pattern.","Our experiments aim to shed light on the type of tasks might be less or more sensitive to KD by reporting data points on the contribution of different factors, such as the number of layers or attention heads.","Results such as ours could be utilized when determining effective and efficient configurations to achieve optimal information transfers between larger (teacher) and smaller (student) models."],"url":"http://arxiv.org/abs/2311.04142v1"}
{"created":"2023-11-07 17:12:58","title":"A Nearly Linear-Time Distributed Algorithm for Exact Maximum Matching","abstract":"In this paper, we propose a randomized $\\tilde{O}(\\Mmax)$-round algorithm for the maximum cardinality matching problem in the CONGEST model, where $\\Mmax$ means the maximum size of a matching of the input graph $G$. The proposed algorithm substantially improves the current best worst-case running time. The key technical ingredient is a new randomized algorithm of finding an augmenting path of length $\\ell$ with high probability within $\\tilde{O}(\\ell)$ rounds, which positively settles an open problem left in the prior work by Ahmadi and Kuhn [DISC'20].   The idea of our augmenting path algorithm is based on a recent result by Kitamura and Izumi [IEICE Trans.'22], which efficiently identifies a sparse substructure of the input graph containing an augmenting path, following a new concept called \\emph{alternating base trees}. Their algorithm, however, resorts to a centralized approach of collecting the entire information of the substructure into a single vertex for constructing an augmenting path. The technical highlight of this paper is to provide a fully-decentralized counterpart of such a centralized method. To develop the algorithm, we prove several new structural properties of alternating base trees, which are of independent interest.","sentences":["In this paper, we propose a randomized $\\tilde{O}(\\Mmax)$-round algorithm for the maximum cardinality matching problem in the CONGEST model, where $\\Mmax$ means the maximum size of a matching of the input graph $G$.","The proposed algorithm substantially improves the current best worst-case running time.","The key technical ingredient is a new randomized algorithm of finding an augmenting path of length $\\ell$ with high probability within $\\tilde{O}(\\ell)$ rounds, which positively settles an open problem left in the prior work by Ahmadi and Kuhn [DISC'20].   ","The idea of our augmenting path algorithm is based on a recent result by Kitamura and Izumi","[IEICE Trans.'22], which efficiently identifies a sparse substructure of the input graph containing an augmenting path, following a new concept called \\emph{alternating base trees}.","Their algorithm, however, resorts to a centralized approach of collecting the entire information of the substructure into a single vertex for constructing an augmenting path.","The technical highlight of this paper is to provide a fully-decentralized counterpart of such a centralized method.","To develop the algorithm, we prove several new structural properties of alternating base trees, which are of independent interest."],"url":"http://arxiv.org/abs/2311.04140v1"}
{"created":"2023-11-07 17:12:39","title":"Modelling Sentiment Analysis: LLMs and data augmentation techniques","abstract":"This paper provides different approaches for a binary sentiment classification on a small training dataset. LLMs that provided state-of-the-art results in sentiment analysis and similar domains are being used, such as BERT, RoBERTa and XLNet.","sentences":["This paper provides different approaches for a binary sentiment classification on a small training dataset.","LLMs that provided state-of-the-art results in sentiment analysis and similar domains are being used, such as BERT, RoBERTa and XLNet."],"url":"http://arxiv.org/abs/2311.04139v1"}
{"created":"2023-11-07 17:00:33","title":"Simple Bundles of Complex Networks","abstract":"Complex networks can be used to represent and model an ample diversity of abstract and real-world systems and structures. A good deal of the research on these structures has focused on specific topological properties, including node degree, shortest paths, and modularity. In the present work, we develop an approach aimed at identifying and characterizing simple bundles of interconnections between pairs of nodes (source and destination) in complex networks. More specifically, simple bundles can be understood as corresponding to the bundle of paths obtained while traveling through successive neighborhoods after departing from a given source node. Because no node appears more than once along a given bundle, these structures have been said to be simple, in analogy to the concept of a simple path. In addition to describing simple bundles and providing a possible methodology for their identification, we also consider how their respective effective width can be estimated in terms of diffusion flow and exponential entropy of transition probabilities. The potential of the concepts and methods described in this work is then illustrated respectively to the characterization and analysis of model-theoretic networks, with several interesting results.","sentences":["Complex networks can be used to represent and model an ample diversity of abstract and real-world systems and structures.","A good deal of the research on these structures has focused on specific topological properties, including node degree, shortest paths, and modularity.","In the present work, we develop an approach aimed at identifying and characterizing simple bundles of interconnections between pairs of nodes (source and destination) in complex networks.","More specifically, simple bundles can be understood as corresponding to the bundle of paths obtained while traveling through successive neighborhoods after departing from a given source node.","Because no node appears more than once along a given bundle, these structures have been said to be simple, in analogy to the concept of a simple path.","In addition to describing simple bundles and providing a possible methodology for their identification, we also consider how their respective effective width can be estimated in terms of diffusion flow and exponential entropy of transition probabilities.","The potential of the concepts and methods described in this work is then illustrated respectively to the characterization and analysis of model-theoretic networks, with several interesting results."],"url":"http://arxiv.org/abs/2311.04133v1"}
{"created":"2023-11-07 16:58:51","title":"Locating Cross-Task Sequence Continuation Circuits in Transformers","abstract":"While transformer models exhibit strong capabilities on linguistic tasks, their complex architectures make them difficult to interpret. Recent work has aimed to reverse engineer transformer models into human-readable representations called circuits that implement algorithmic functions. We extend this research by analyzing and comparing circuits for similar sequence continuation tasks, which include increasing sequences of digits, number words, and months. Through the application of circuit analysis techniques, we identify key sub-circuits responsible for detecting sequence members and for predicting the next member in a sequence. Our analysis reveals that semantically related sequences rely on shared circuit subgraphs with analogous roles. Overall, documenting shared computational structures enables better prediction of model behaviors, identification of errors, and safer editing procedures. This mechanistic understanding of transformers is a critical step towards building more robust, aligned, and interpretable language models.","sentences":["While transformer models exhibit strong capabilities on linguistic tasks, their complex architectures make them difficult to interpret.","Recent work has aimed to reverse engineer transformer models into human-readable representations called circuits that implement algorithmic functions.","We extend this research by analyzing and comparing circuits for similar sequence continuation tasks, which include increasing sequences of digits, number words, and months.","Through the application of circuit analysis techniques, we identify key sub-circuits responsible for detecting sequence members and for predicting the next member in a sequence.","Our analysis reveals that semantically related sequences rely on shared circuit subgraphs with analogous roles.","Overall, documenting shared computational structures enables better prediction of model behaviors, identification of errors, and safer editing procedures.","This mechanistic understanding of transformers is a critical step towards building more robust, aligned, and interpretable language models."],"url":"http://arxiv.org/abs/2311.04131v1"}
{"created":"2023-11-07 16:53:56","title":"Generative learning for nonlinear dynamics","abstract":"Modern generative machine learning models demonstrate surprising ability to create realistic outputs far beyond their training data, such as photorealistic artwork, accurate protein structures, or conversational text. These successes suggest that generative models learn to effectively parametrize and sample arbitrarily complex distributions. Beginning half a century ago, foundational works in nonlinear dynamics used tools from information theory to infer properties of chaotic attractors from time series, motivating the development of algorithms for parametrizing chaos in real datasets. In this perspective, we aim to connect these classical works to emerging themes in large-scale generative statistical learning. We first consider classical attractor reconstruction, which mirrors constraints on latent representations learned by state space models of time series. We next revisit early efforts to use symbolic approximations to compare minimal discrete generators underlying complex processes, a problem relevant to modern efforts to distill and interpret black-box statistical models. Emerging interdisciplinary works bridge nonlinear dynamics and learning theory, such as operator-theoretic methods for complex fluid flows, or detection of broken detailed balance in biological datasets. We anticipate that future machine learning techniques may revisit other classical concepts from nonlinear dynamics, such as transinformation decay and complexity-entropy tradeoffs.","sentences":["Modern generative machine learning models demonstrate surprising ability to create realistic outputs far beyond their training data, such as photorealistic artwork, accurate protein structures, or conversational text.","These successes suggest that generative models learn to effectively parametrize and sample arbitrarily complex distributions.","Beginning half a century ago, foundational works in nonlinear dynamics used tools from information theory to infer properties of chaotic attractors from time series, motivating the development of algorithms for parametrizing chaos in real datasets.","In this perspective, we aim to connect these classical works to emerging themes in large-scale generative statistical learning.","We first consider classical attractor reconstruction, which mirrors constraints on latent representations learned by state space models of time series.","We next revisit early efforts to use symbolic approximations to compare minimal discrete generators underlying complex processes, a problem relevant to modern efforts to distill and interpret black-box statistical models.","Emerging interdisciplinary works bridge nonlinear dynamics and learning theory, such as operator-theoretic methods for complex fluid flows, or detection of broken detailed balance in biological datasets.","We anticipate that future machine learning techniques may revisit other classical concepts from nonlinear dynamics, such as transinformation decay and complexity-entropy tradeoffs."],"url":"http://arxiv.org/abs/2311.04128v1"}
{"created":"2023-11-07 16:53:34","title":"From Diagram to Deployment: Translating BPMN Collaborations into X-Klaim for Efficient Multi-Robot System Programming","abstract":"This paper introduces a novel method for translating Business Process Model and Notation (BPMN) diagrams into executable X-Klaim code for Multi-Robot Systems (MRSs). Merging the clarity of BPMN with the operational strength of X-Klaim, we enable the design and execution of complex robotic interactions without requiring in-depth knowledge of the underlying programming language from the users. Our approach maintains the BPMN model's core design principles and logic in the translation to X-Klaim, thus enhancing the readability and maintainability of MRS applications. We offer a series of translated examples, address optimization strategies, and introduce the B2XKLAIM tool, which automates the conversion process. This method aims to streamline MRS programming and improve collaboration between roboticists and domain experts throughout the design and implementation stages.","sentences":["This paper introduces a novel method for translating Business Process Model and Notation (BPMN) diagrams into executable X-Klaim code for Multi-Robot Systems (MRSs).","Merging the clarity of BPMN with the operational strength of X-Klaim, we enable the design and execution of complex robotic interactions without requiring in-depth knowledge of the underlying programming language from the users.","Our approach maintains the BPMN model's core design principles and logic in the translation to X-Klaim, thus enhancing the readability and maintainability of MRS applications.","We offer a series of translated examples, address optimization strategies, and introduce the B2XKLAIM tool, which automates the conversion process.","This method aims to streamline MRS programming and improve collaboration between roboticists and domain experts throughout the design and implementation stages."],"url":"http://arxiv.org/abs/2311.04126v1"}
{"created":"2023-11-07 16:50:33","title":"Unveiling Safety Vulnerabilities of Large Language Models","abstract":"As large language models become more prevalent, their possible harmful or inappropriate responses are a cause for concern. This paper introduces a unique dataset containing adversarial examples in the form of questions, which we call AttaQ, designed to provoke such harmful or inappropriate responses. We assess the efficacy of our dataset by analyzing the vulnerabilities of various models when subjected to it. Additionally, we introduce a novel automatic approach for identifying and naming vulnerable semantic regions - input semantic areas for which the model is likely to produce harmful outputs. This is achieved through the application of specialized clustering techniques that consider both the semantic similarity of the input attacks and the harmfulness of the model's responses. Automatically identifying vulnerable semantic regions enhances the evaluation of model weaknesses, facilitating targeted improvements to its safety mechanisms and overall reliability.","sentences":["As large language models become more prevalent, their possible harmful or inappropriate responses are a cause for concern.","This paper introduces a unique dataset containing adversarial examples in the form of questions, which we call AttaQ, designed to provoke such harmful or inappropriate responses.","We assess the efficacy of our dataset by analyzing the vulnerabilities of various models when subjected to it.","Additionally, we introduce a novel automatic approach for identifying and naming vulnerable semantic regions - input semantic areas for which the model is likely to produce harmful outputs.","This is achieved through the application of specialized clustering techniques that consider both the semantic similarity of the input attacks and the harmfulness of the model's responses.","Automatically identifying vulnerable semantic regions enhances the evaluation of model weaknesses, facilitating targeted improvements to its safety mechanisms and overall reliability."],"url":"http://arxiv.org/abs/2311.04124v1"}
{"created":"2023-11-07 16:31:56","title":"Do Language Models Learn Semantics of Code? A Case Study in Vulnerability Detection","abstract":"Recently, pretrained language models have shown state-of-the-art performance on the vulnerability detection task. These models are pretrained on a large corpus of source code, then fine-tuned on a smaller supervised vulnerability dataset. Due to the different training objectives and the performance of the models, it is interesting to consider whether the models have learned the semantics of code relevant to vulnerability detection, namely bug semantics, and if so, how the alignment to bug semantics relates to model performance. In this paper, we analyze the models using three distinct methods: interpretability tools, attention analysis, and interaction matrix analysis. We compare the models' influential feature sets with the bug semantic features which define the causes of bugs, including buggy paths and Potentially Vulnerable Statements (PVS). We find that (1) better-performing models also aligned better with PVS, (2) the models failed to align strongly to PVS, and (3) the models failed to align at all to buggy paths. Based on our analysis, we developed two annotation methods which highlight the bug semantics inside the model's inputs. We evaluated our approach on four distinct transformer models and four vulnerability datasets and found that our annotations improved the models' performance in the majority of settings - 11 out of 16, with up to 9.57 points improvement in F1 score compared to conventional fine-tuning. We further found that with our annotations, the models aligned up to 232% better to potentially vulnerable statements. Our findings indicate that it is helpful to provide the model with information of the bug semantics, that the model can attend to it, and motivate future work in learning more complex path-based bug semantics. Our code and data are available at https://figshare.com/s/4a16a528d6874aad51a0.","sentences":["Recently, pretrained language models have shown state-of-the-art performance on the vulnerability detection task.","These models are pretrained on a large corpus of source code, then fine-tuned on a smaller supervised vulnerability dataset.","Due to the different training objectives and the performance of the models, it is interesting to consider whether the models have learned the semantics of code relevant to vulnerability detection, namely bug semantics, and if so, how the alignment to bug semantics relates to model performance.","In this paper, we analyze the models using three distinct methods: interpretability tools, attention analysis, and interaction matrix analysis.","We compare the models' influential feature sets with the bug semantic features which define the causes of bugs, including buggy paths and Potentially Vulnerable Statements (PVS).","We find that (1) better-performing models also aligned better with PVS, (2) the models failed to align strongly to PVS, and (3) the models failed to align at all to buggy paths.","Based on our analysis, we developed two annotation methods which highlight the bug semantics inside the model's inputs.","We evaluated our approach on four distinct transformer models and four vulnerability datasets and found that our annotations improved the models' performance in the majority of settings - 11 out of 16, with up to 9.57 points improvement in F1 score compared to conventional fine-tuning.","We further found that with our annotations, the models aligned up to 232% better to potentially vulnerable statements.","Our findings indicate that it is helpful to provide the model with information of the bug semantics, that the model can attend to it, and motivate future work in learning more complex path-based bug semantics.","Our code and data are available at https://figshare.com/s/4a16a528d6874aad51a0."],"url":"http://arxiv.org/abs/2311.04109v1"}
{"created":"2023-11-07 16:30:38","title":"The Early Microbenchmark Catches the Bug -- Studying Performance Issues Using Micro- and Application Benchmarks","abstract":"An application's performance regressions can be detected by both application or microbenchmarks. While application benchmarks stress the system under test by sending synthetic but realistic requests which, e.g., simulate real user traffic, microbenchmarks evaluate the performance on a subroutine level by calling the function under test repeatedly.   In this paper, we use a testbed microservice application which includes three performance issues to study the detection capabilities of both approaches. In extensive benchmarking experiments, we increase the severity of each performance issue stepwise, run both an application benchmark and the microbenchmark suite, and check at which point each benchmark detects the performance issue. Our results show that microbenchmarks detect all three issues earlier, some even at the lowest severity level. Application benchmarks, however, raised false positive alarms, wrongly detected performance improvements, and detected the performance issues later.","sentences":["An application's performance regressions can be detected by both application or microbenchmarks.","While application benchmarks stress the system under test by sending synthetic but realistic requests which, e.g., simulate real user traffic, microbenchmarks evaluate the performance on a subroutine level by calling the function under test repeatedly.   ","In this paper, we use a testbed microservice application which includes three performance issues to study the detection capabilities of both approaches.","In extensive benchmarking experiments, we increase the severity of each performance issue stepwise, run both an application benchmark and the microbenchmark suite, and check at which point each benchmark detects the performance issue.","Our results show that microbenchmarks detect all three issues earlier, some even at the lowest severity level.","Application benchmarks, however, raised false positive alarms, wrongly detected performance improvements, and detected the performance issues later."],"url":"http://arxiv.org/abs/2311.04108v1"}
{"created":"2023-11-07 16:30:12","title":"Interactive Semantic Map Representation for Skill-based Visual Object Navigation","abstract":"Visual object navigation using learning methods is one of the key tasks in mobile robotics. This paper introduces a new representation of a scene semantic map formed during the embodied agent interaction with the indoor environment. It is based on a neural network method that adjusts the weights of the segmentation model with backpropagation of the predicted fusion loss values during inference on a regular (backward) or delayed (forward) image sequence. We have implemented this representation into a full-fledged navigation approach called SkillTron, which can select robot skills from end-to-end policies based on reinforcement learning and classic map-based planning methods. The proposed approach makes it possible to form both intermediate goals for robot exploration and the final goal for object navigation. We conducted intensive experiments with the proposed approach in the Habitat environment, which showed a significant superiority in navigation quality metrics compared to state-of-the-art approaches. The developed code and used custom datasets are publicly available at github.com/AIRI-Institute/skill-fusion.","sentences":["Visual object navigation using learning methods is one of the key tasks in mobile robotics.","This paper introduces a new representation of a scene semantic map formed during the embodied agent interaction with the indoor environment.","It is based on a neural network method that adjusts the weights of the segmentation model with backpropagation of the predicted fusion loss values during inference on a regular (backward) or delayed (forward) image sequence.","We have implemented this representation into a full-fledged navigation approach called SkillTron, which can select robot skills from end-to-end policies based on reinforcement learning and classic map-based planning methods.","The proposed approach makes it possible to form both intermediate goals for robot exploration and the final goal for object navigation.","We conducted intensive experiments with the proposed approach in the Habitat environment, which showed a significant superiority in navigation quality metrics compared to state-of-the-art approaches.","The developed code and used custom datasets are publicly available at github.com/AIRI-Institute/skill-fusion."],"url":"http://arxiv.org/abs/2311.04107v1"}
{"created":"2023-11-07 16:14:38","title":"DeepPatent2: A Large-Scale Benchmarking Corpus for Technical Drawing Understanding","abstract":"Recent advances in computer vision (CV) and natural language processing have been driven by exploiting big data on practical applications. However, these research fields are still limited by the sheer volume, versatility, and diversity of the available datasets. CV tasks, such as image captioning, which has primarily been carried out on natural images, still struggle to produce accurate and meaningful captions on sketched images often included in scientific and technical documents. The advancement of other tasks such as 3D reconstruction from 2D images requires larger datasets with multiple viewpoints. We introduce DeepPatent2, a large-scale dataset, providing more than 2.7 million technical drawings with 132,890 object names and 22,394 viewpoints extracted from 14 years of US design patent documents. We demonstrate the usefulness of DeepPatent2 with conceptual captioning. We further provide the potential usefulness of our dataset to facilitate other research areas such as 3D image reconstruction and image retrieval.","sentences":["Recent advances in computer vision (CV) and natural language processing have been driven by exploiting big data on practical applications.","However, these research fields are still limited by the sheer volume, versatility, and diversity of the available datasets.","CV tasks, such as image captioning, which has primarily been carried out on natural images, still struggle to produce accurate and meaningful captions on sketched images often included in scientific and technical documents.","The advancement of other tasks such as 3D reconstruction from 2D images requires larger datasets with multiple viewpoints.","We introduce DeepPatent2, a large-scale dataset, providing more than 2.7 million technical drawings with 132,890 object names and 22,394 viewpoints extracted from 14 years of US design patent documents.","We demonstrate the usefulness of DeepPatent2 with conceptual captioning.","We further provide the potential usefulness of our dataset to facilitate other research areas such as 3D image reconstruction and image retrieval."],"url":"http://arxiv.org/abs/2311.04098v1"}
{"created":"2023-11-07 16:06:05","title":"Imitation learning for sim-to-real transfer of robotic cutting policies based on residual Gaussian process disturbance force model","abstract":"Robotic cutting, or milling, plays a significant role in applications such as disassembly, decommissioning, and demolition. Planning and control of cutting in real-world scenarios in uncertain environments is a complex task, with the potential to benefit from simulated training environments. This letter focuses on sim-to-real transfer for robotic cutting policies, addressing the need for effective policy transfer from simulation to practical implementation. We extend our previous domain generalisation approach to learning cutting tasks based on a mechanistic model-based simulation framework, by proposing a hybrid approach for sim-to-real transfer based on a milling process force model and residual Gaussian process (GP) force model, learned from either single or multiple real-world cutting force examples. We demonstrate successful sim-to-real transfer of a robotic cutting policy without the need for fine-tuning on the real robot setup. The proposed approach autonomously adapts to materials with differing structural and mechanical properties. Furthermore, we demonstrate the proposed method outperforms fine-tuning or re-training alone.","sentences":["Robotic cutting, or milling, plays a significant role in applications such as disassembly, decommissioning, and demolition.","Planning and control of cutting in real-world scenarios in uncertain environments is a complex task, with the potential to benefit from simulated training environments.","This letter focuses on sim-to-real transfer for robotic cutting policies, addressing the need for effective policy transfer from simulation to practical implementation.","We extend our previous domain generalisation approach to learning cutting tasks based on a mechanistic model-based simulation framework, by proposing a hybrid approach for sim-to-real transfer based on a milling process force model and residual Gaussian process (GP) force model, learned from either single or multiple real-world cutting force examples.","We demonstrate successful sim-to-real transfer of a robotic cutting policy without the need for fine-tuning on the real robot setup.","The proposed approach autonomously adapts to materials with differing structural and mechanical properties.","Furthermore, we demonstrate the proposed method outperforms fine-tuning or re-training alone."],"url":"http://arxiv.org/abs/2311.04096v1"}
{"created":"2023-11-07 16:05:27","title":"Image-Pointcloud Fusion based Anomaly Detection using PD-REAL Dataset","abstract":"We present PD-REAL, a novel large-scale dataset for unsupervised anomaly detection (AD) in the 3D domain. It is motivated by the fact that 2D-only representations in the AD task may fail to capture the geometric structures of anomalies due to uncertainty in lighting conditions or shooting angles. PD-REAL consists entirely of Play-Doh models for 15 object categories and focuses on the analysis of potential benefits from 3D information in a controlled environment. Specifically, objects are first created with six types of anomalies, such as dent, crack, or perforation, and then photographed under different lighting conditions to mimic real-world inspection scenarios. To demonstrate the usefulness of 3D information, we use a commercially available RealSense camera to capture RGB and depth images. Compared to the existing 3D dataset for AD tasks, the data acquisition of PD-REAL is significantly cheaper, easily scalable and easier to control variables. Extensive evaluations with state-of-the-art AD algorithms on our dataset demonstrate the benefits as well as challenges of using 3D information. Our dataset can be downloaded from https://github.com/Andy-cs008/PD-REAL","sentences":["We present PD-REAL, a novel large-scale dataset for unsupervised anomaly detection (AD) in the 3D domain.","It is motivated by the fact that 2D-only representations in the AD task may fail to capture the geometric structures of anomalies due to uncertainty in lighting conditions or shooting angles.","PD-REAL consists entirely of Play-Doh models for 15 object categories and focuses on the analysis of potential benefits from 3D information in a controlled environment.","Specifically, objects are first created with six types of anomalies, such as dent, crack, or perforation, and then photographed under different lighting conditions to mimic real-world inspection scenarios.","To demonstrate the usefulness of 3D information, we use a commercially available RealSense camera to capture RGB and depth images.","Compared to the existing 3D dataset for AD tasks, the data acquisition of PD-REAL is significantly cheaper, easily scalable and easier to control variables.","Extensive evaluations with state-of-the-art AD algorithms on our dataset demonstrate the benefits as well as challenges of using 3D information.","Our dataset can be downloaded from https://github.com/Andy-cs008/PD-REAL"],"url":"http://arxiv.org/abs/2311.04095v1"}
{"created":"2023-11-07 16:02:33","title":"Solvable Polynomial Ideals: The Ideal Reflection for Program Analysis","abstract":"This paper presents a program analysis method that generates program summaries involving polynomial arithmetic. Our approach builds on prior techniques that use solvable polynomial maps for summarizing loops. These techniques are able to generate all polynomial invariants for a restricted class of programs, but cannot be applied to programs outside of this class -- for instance, programs with nested loops, conditional branching, unstructured control flow, etc. There currently lacks approaches to apply these prior methods to the case of general programs. This paper bridges that gap. Instead of restricting the kinds of programs we can handle, our method abstracts every loop into a model that can be solved with prior techniques, bringing to bear prior work on solvable polynomial maps to general programs. While no method can generate all polynomial invariants for arbitrary programs, our method establishes its merit through a monotonicty result. We have implemented our techniques, and tested them on a suite of benchmarks from the literature. Our experiments indicate our techniques show promise on challenging verification tasks requiring non-linear reasoning.","sentences":["This paper presents a program analysis method that generates program summaries involving polynomial arithmetic.","Our approach builds on prior techniques that use solvable polynomial maps for summarizing loops.","These techniques are able to generate all polynomial invariants for a restricted class of programs, but cannot be applied to programs outside of this class -- for instance, programs with nested loops, conditional branching, unstructured control flow, etc.","There currently lacks approaches to apply these prior methods to the case of general programs.","This paper bridges that gap.","Instead of restricting the kinds of programs we can handle, our method abstracts every loop into a model that can be solved with prior techniques, bringing to bear prior work on solvable polynomial maps to general programs.","While no method can generate all polynomial invariants for arbitrary programs, our method establishes its merit through a monotonicty result.","We have implemented our techniques, and tested them on a suite of benchmarks from the literature.","Our experiments indicate our techniques show promise on challenging verification tasks requiring non-linear reasoning."],"url":"http://arxiv.org/abs/2311.04092v1"}
{"created":"2023-11-07 16:00:42","title":"Proceedings of the 5th International Workshop on Reading Music Systems","abstract":"The International Workshop on Reading Music Systems (WoRMS) is a workshop that tries to connect researchers who develop systems for reading music, such as in the field of Optical Music Recognition, with other researchers and practitioners that could benefit from such systems, like librarians or musicologists. The relevant topics of interest for the workshop include, but are not limited to: Music reading systems; Optical music recognition; Datasets and performance evaluation; Image processing on music scores; Writer identification; Authoring, editing, storing and presentation systems for music scores; Multi-modal systems; Novel input-methods for music to produce written music; Web-based Music Information Retrieval services; Applications and projects; Use-cases related to written music.   These are the proceedings of the 5th International Workshop on Reading Music Systems, held in Milan, Italy on Nov. 4th 2023.","sentences":["The International Workshop on Reading Music Systems (WoRMS) is a workshop that tries to connect researchers who develop systems for reading music, such as in the field of Optical Music Recognition, with other researchers and practitioners that could benefit from such systems, like librarians or musicologists.","The relevant topics of interest for the workshop include, but are not limited to: Music reading systems; Optical music recognition;","Datasets and performance evaluation; Image processing on music scores; Writer identification; Authoring, editing, storing and presentation systems for music scores; Multi-modal systems; Novel input-methods for music to produce written music; Web-based Music Information Retrieval services; Applications and projects; Use-cases related to written music.   ","These are the proceedings of the 5th International Workshop on Reading Music Systems, held in Milan, Italy on Nov. 4th 2023."],"url":"http://arxiv.org/abs/2311.04091v1"}
{"created":"2023-11-07 15:56:19","title":"Personality Style Recognition via Machine Learning: Identifying Anaclitic and Introjective Personality Styles from Patients' Speech","abstract":"In disentangling the heterogeneity observed in psychopathology, personality of the patients is considered crucial. While it has been demonstrated that personality traits are reflected in the language used by a patient, we hypothesize that this enables automatic inference of the personality type directly from speech utterances, potentially more accurately than through a traditional questionnaire-based approach explicitly designed for personality classification. To validate this hypothesis, we adopt natural language processing (NLP) and standard machine learning tools for classification. We test this on a dataset of recorded clinical diagnostic interviews (CDI) on a sample of 79 patients diagnosed with major depressive disorder (MDD) -- a condition for which differentiated treatment based on personality styles has been advocated -- and classified into anaclitic and introjective personality styles. We start by analyzing the interviews to see which linguistic features are associated with each style, in order to gain a better understanding of the styles. Then, we develop automatic classifiers based on (a) standardized questionnaire responses; (b) basic text features, i.e., TF-IDF scores of words and word sequences; (c) more advanced text features, using LIWC (linguistic inquiry and word count) and context-aware features using BERT (bidirectional encoder representations from transformers); (d) audio features. We find that automated classification with language-derived features (i.e., based on LIWC) significantly outperforms questionnaire-based classification models. Furthermore, the best performance is achieved by combining LIWC with the questionnaire features. This suggests that more work should be put into developing linguistically based automated techniques for characterizing personality, however questionnaires still to some extent complement such methods.","sentences":["In disentangling the heterogeneity observed in psychopathology, personality of the patients is considered crucial.","While it has been demonstrated that personality traits are reflected in the language used by a patient, we hypothesize that this enables automatic inference of the personality type directly from speech utterances, potentially more accurately than through a traditional questionnaire-based approach explicitly designed for personality classification.","To validate this hypothesis, we adopt natural language processing (NLP) and standard machine learning tools for classification.","We test this on a dataset of recorded clinical diagnostic interviews (CDI) on a sample of 79 patients diagnosed with major depressive disorder (MDD) -- a condition for which differentiated treatment based on personality styles has been advocated -- and classified into anaclitic and introjective personality styles.","We start by analyzing the interviews to see which linguistic features are associated with each style, in order to gain a better understanding of the styles.","Then, we develop automatic classifiers based on (a) standardized questionnaire responses; (b) basic text features, i.e., TF-IDF scores of words and word sequences; (c) more advanced text features, using LIWC (linguistic inquiry and word count) and context-aware features using BERT (bidirectional encoder representations from transformers); (d) audio features.","We find that automated classification with language-derived features (i.e., based on LIWC) significantly outperforms questionnaire-based classification models.","Furthermore, the best performance is achieved by combining LIWC with the questionnaire features.","This suggests that more work should be put into developing linguistically based automated techniques for characterizing personality, however questionnaires still to some extent complement such methods."],"url":"http://arxiv.org/abs/2311.04088v1"}
{"created":"2023-11-07 15:51:56","title":"A Categorical Model for Retrosynthetic Reaction Analysis","abstract":"We introduce a mathematical framework for retrosynthetic analysis, an important research method in synthetic chemistry. Our approach represents molecules and their interaction using string diagrams in layered props - a recently introduced categorical model for partial explanations in scientific reasoning. Such principled approach allows one to model features currently not available in automated retrosynthesis tools, such as chirality, reaction environment and protection-deprotection steps.","sentences":["We introduce a mathematical framework for retrosynthetic analysis, an important research method in synthetic chemistry.","Our approach represents molecules and their interaction using string diagrams in layered props - a recently introduced categorical model for partial explanations in scientific reasoning.","Such principled approach allows one to model features currently not available in automated retrosynthesis tools, such as chirality, reaction environment and protection-deprotection steps."],"url":"http://arxiv.org/abs/2311.04085v1"}
{"created":"2023-11-07 15:48:07","title":"Time-Efficient Reinforcement Learning with Stochastic Stateful Policies","abstract":"Stateful policies play an important role in reinforcement learning, such as handling partially observable environments, enhancing robustness, or imposing an inductive bias directly into the policy structure. The conventional method for training stateful policies is Backpropagation Through Time (BPTT), which comes with significant drawbacks, such as slow training due to sequential gradient propagation and the occurrence of vanishing or exploding gradients. The gradient is often truncated to address these issues, resulting in a biased policy update. We present a novel approach for training stateful policies by decomposing the latter into a stochastic internal state kernel and a stateless policy, jointly optimized by following the stateful policy gradient. We introduce different versions of the stateful policy gradient theorem, enabling us to easily instantiate stateful variants of popular reinforcement learning and imitation learning algorithms. Furthermore, we provide a theoretical analysis of our new gradient estimator and compare it with BPTT. We evaluate our approach on complex continuous control tasks, e.g., humanoid locomotion, and demonstrate that our gradient estimator scales effectively with task complexity while offering a faster and simpler alternative to BPTT.","sentences":["Stateful policies play an important role in reinforcement learning, such as handling partially observable environments, enhancing robustness, or imposing an inductive bias directly into the policy structure.","The conventional method for training stateful policies is Backpropagation Through Time (BPTT), which comes with significant drawbacks, such as slow training due to sequential gradient propagation and the occurrence of vanishing or exploding gradients.","The gradient is often truncated to address these issues, resulting in a biased policy update.","We present a novel approach for training stateful policies by decomposing the latter into a stochastic internal state kernel and a stateless policy, jointly optimized by following the stateful policy gradient.","We introduce different versions of the stateful policy gradient theorem, enabling us to easily instantiate stateful variants of popular reinforcement learning and imitation learning algorithms.","Furthermore, we provide a theoretical analysis of our new gradient estimator and compare it with BPTT.","We evaluate our approach on complex continuous control tasks, e.g., humanoid locomotion, and demonstrate that our gradient estimator scales effectively with task complexity while offering a faster and simpler alternative to BPTT."],"url":"http://arxiv.org/abs/2311.04082v1"}
{"created":"2023-11-07 15:42:22","title":"Augmenting Lane Perception and Topology Understanding with Standard Definition Navigation Maps","abstract":"Autonomous driving has traditionally relied heavily on costly and labor-intensive High Definition (HD) maps, hindering scalability. In contrast, Standard Definition (SD) maps are more affordable and have worldwide coverage, offering a scalable alternative. In this work, we systematically explore the effect of SD maps for real-time lane-topology understanding. We propose a novel framework to integrate SD maps into online map prediction and propose a Transformer-based encoder, SD Map Encoder Representations from transFormers, to leverage priors in SD maps for the lane-topology prediction task. This enhancement consistently and significantly boosts (by up to 60%) lane detection and topology prediction on current state-of-the-art online map prediction methods without bells and whistles and can be immediately incorporated into any Transformer-based lane-topology method. Code is available at https://github.com/NVlabs/SMERF.","sentences":["Autonomous driving has traditionally relied heavily on costly and labor-intensive High Definition (HD) maps, hindering scalability.","In contrast, Standard Definition (SD) maps are more affordable and have worldwide coverage, offering a scalable alternative.","In this work, we systematically explore the effect of SD maps for real-time lane-topology understanding.","We propose a novel framework to integrate SD maps into online map prediction and propose a Transformer-based encoder, SD Map Encoder Representations from transFormers, to leverage priors in SD maps for the lane-topology prediction task.","This enhancement consistently and significantly boosts (by up to 60%) lane detection and topology prediction on current state-of-the-art online map prediction methods without bells and whistles and can be immediately incorporated into any Transformer-based lane-topology method.","Code is available at https://github.com/NVlabs/SMERF."],"url":"http://arxiv.org/abs/2311.04079v1"}
{"created":"2023-11-07 15:42:14","title":"A Lightweight and Secure PUF-Based Authentication and Key-exchange Protocol for IoT Devices","abstract":"The Internet of Things (IoT) has improved people's lives by seamlessly integrating into many facets of modern life and facilitating information sharing across platforms. Device Authentication and Key exchange are major challenges for the IoT. High computational resource requirements for cryptographic primitives and message transmission during Authentication make the existing methods like PKI and IBE not suitable for these resource constrained devices. PUF appears to offer a practical and economical security mechanism in place of typically sophisticated cryptosystems like PKI and IBE. PUF provides an unclonable and tamper sensitive unique signature based on the PUF chip by using manufacturing process variability. Therefore, in this study, we use lightweight bitwise XOR, hash function, and PUF to Authenticate IoT devices. Despite several studies employing the PUF to authenticate communication between IoT devices, to the authors' knowledge, existing solutions require intermediary gateway and internet capabilities by the IoT device to directly interact with a Server for Authentication and hence, are not scalable when the IoT device works on different technologies like BLE, Zigbee, etc. To address the aforementioned issue, we present a system in which the IoT device does not require a continuous active internet connection to communicate with the server in order to Authenticate itself. The results of a thorough security study are validated against adversarial attacks and PUF modeling attacks. For formal security validation, the AVISPA verification tool is also used. Performance study recommends this protocol's lightweight characteristics. The proposed protocol's acceptability and defenses against adversarial assaults are supported by a prototype developed with ESP32.","sentences":["The Internet of Things (IoT) has improved people's lives by seamlessly integrating into many facets of modern life and facilitating information sharing across platforms.","Device Authentication and Key exchange are major challenges for the IoT. High computational resource requirements for cryptographic primitives and message transmission during Authentication make the existing methods like PKI and IBE not suitable for these resource constrained devices.","PUF appears to offer a practical and economical security mechanism in place of typically sophisticated cryptosystems like PKI and IBE.","PUF provides an unclonable and tamper sensitive unique signature based on the PUF chip by using manufacturing process variability.","Therefore, in this study, we use lightweight bitwise XOR, hash function, and PUF to Authenticate IoT devices.","Despite several studies employing the PUF to authenticate communication between IoT devices, to the authors' knowledge, existing solutions require intermediary gateway and internet capabilities by the IoT device to directly interact with a Server for Authentication and hence, are not scalable when the IoT device works on different technologies like BLE, Zigbee, etc.","To address the aforementioned issue, we present a system in which the IoT device does not require a continuous active internet connection to communicate with the server in order to Authenticate itself.","The results of a thorough security study are validated against adversarial attacks and PUF modeling attacks.","For formal security validation, the AVISPA verification tool is also used.","Performance study recommends this protocol's lightweight characteristics.","The proposed protocol's acceptability and defenses against adversarial assaults are supported by a prototype developed with ESP32."],"url":"http://arxiv.org/abs/2311.04078v1"}
{"created":"2023-11-07 15:40:43","title":"Do LLMs exhibit human-like response biases? A case study in survey design","abstract":"As large language models (LLMs) become more capable, there is growing excitement about the possibility of using LLMs as proxies for humans in real-world tasks where subjective labels are desired, such as in surveys and opinion polling. One widely-cited barrier to the adoption of LLMs is their sensitivity to prompt wording -- but interestingly, humans also display sensitivities to instruction changes in the form of response biases. As such, we argue that if LLMs are going to be used to approximate human opinions, it is necessary to investigate the extent to which LLMs also reflect human response biases, if at all. In this work, we use survey design as a case study, where human response biases caused by permutations in wordings of ``prompts'' have been extensively studied. Drawing from prior work in social psychology, we design a dataset and propose a framework to evaluate whether LLMs exhibit human-like response biases in survey questionnaires. Our comprehensive evaluation of nine models shows that popular open and commercial LLMs generally fail to reflect human-like behavior. These inconsistencies tend to be more prominent in models that have been instruction fine-tuned. Furthermore, even if a model shows a significant change in the same direction as humans, we find that perturbations that are not meant to elicit significant changes in humans may also result in a similar change, suggesting that such a result could be partially due to other spurious correlations. These results highlight the potential pitfalls of using LLMs to substitute humans in parts of the annotation pipeline, and further underscore the importance of finer-grained characterizations of model behavior. Our code, dataset, and collected samples are available at https://github.com/lindiatjuatja/BiasMonkey","sentences":["As large language models (LLMs) become more capable, there is growing excitement about the possibility of using LLMs as proxies for humans in real-world tasks where subjective labels are desired, such as in surveys and opinion polling.","One widely-cited barrier to the adoption of LLMs is their sensitivity to prompt wording -- but interestingly, humans also display sensitivities to instruction changes in the form of response biases.","As such, we argue that if LLMs are going to be used to approximate human opinions, it is necessary to investigate the extent to which LLMs also reflect human response biases, if at all.","In this work, we use survey design as a case study, where human response biases caused by permutations in wordings of ``prompts'' have been extensively studied.","Drawing from prior work in social psychology, we design a dataset and propose a framework to evaluate whether LLMs exhibit human-like response biases in survey questionnaires.","Our comprehensive evaluation of nine models shows that popular open and commercial LLMs generally fail to reflect human-like behavior.","These inconsistencies tend to be more prominent in models that have been instruction fine-tuned.","Furthermore, even if a model shows a significant change in the same direction as humans, we find that perturbations that are not meant to elicit significant changes in humans may also result in a similar change, suggesting that such a result could be partially due to other spurious correlations.","These results highlight the potential pitfalls of using LLMs to substitute humans in parts of the annotation pipeline, and further underscore the importance of finer-grained characterizations of model behavior.","Our code, dataset, and collected samples are available at https://github.com/lindiatjuatja/BiasMonkey"],"url":"http://arxiv.org/abs/2311.04076v1"}
{"created":"2023-11-07 15:36:40","title":"Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment","abstract":"Alignment with human preference is a desired property of large language models (LLMs). Currently, the main alignment approach is based on reinforcement learning from human feedback (RLHF). Despite the effectiveness of RLHF, it is intricate to implement and train, thus recent studies explore how to develop alternative alignment approaches based on supervised fine-tuning (SFT). A major limitation of SFT is that it essentially does imitation learning, which cannot fully understand what are the expected behaviors. To address this issue, we propose an improved alignment approach named FIGA. Different from prior methods, we incorporate fine-grained (i.e., token or phrase level) quality signals that are derived by contrasting good and bad responses. Our approach has made two major contributions. Firstly, we curate a refined alignment dataset that pairs initial responses and the corresponding revised ones. Secondly, we devise a new loss function can leverage fine-grained quality signals to instruct the learning of LLMs for alignment. Extensive experiments have demonstrated the effectiveness of our approaches by comparing a number of competitive baselines.","sentences":["Alignment with human preference is a desired property of large language models (LLMs).","Currently, the main alignment approach is based on reinforcement learning from human feedback (RLHF).","Despite the effectiveness of RLHF, it is intricate to implement and train, thus recent studies explore how to develop alternative alignment approaches based on supervised fine-tuning (SFT).","A major limitation of SFT is that it essentially does imitation learning, which cannot fully understand what are the expected behaviors.","To address this issue, we propose an improved alignment approach named FIGA.","Different from prior methods, we incorporate fine-grained (i.e., token or phrase level) quality signals that are derived by contrasting good and bad responses.","Our approach has made two major contributions.","Firstly, we curate a refined alignment dataset that pairs initial responses and the corresponding revised ones.","Secondly, we devise a new loss function can leverage fine-grained quality signals to instruct the learning of LLMs for alignment.","Extensive experiments have demonstrated the effectiveness of our approaches by comparing a number of competitive baselines."],"url":"http://arxiv.org/abs/2311.04072v1"}
{"created":"2023-11-07 15:35:56","title":"Energy-based Calibrated VAE with Test Time Free Lunch","abstract":"In this paper, we propose a novel Energy-Calibrated Generative Model that utilizes a Conditional EBM for enhancing Variational Autoencoders (VAEs). VAEs are sampling efficient but often suffer from blurry generation results due to the lack of training in the generative direction. On the other hand, Energy-Based Models (EBMs) can generate high-quality samples but require expensive Markov Chain Monte Carlo (MCMC) sampling. To address these issues, we introduce a Conditional EBM for calibrating the generative direction during training, without requiring it for test time sampling. Our approach enables the generative model to be trained upon data and calibrated samples with adaptive weight, thereby enhancing efficiency and effectiveness without necessitating MCMC sampling in the inference phase. We also show that the proposed approach can be extended to calibrate normalizing flows and variational posterior. Moreover, we propose to apply the proposed method to zero-shot image restoration via neural transport prior and range-null theory. We demonstrate the effectiveness of the proposed method through extensive experiments in various applications, including image generation and zero-shot image restoration. Our method shows state-of-the-art performance over single-step non-adversarial generation.","sentences":["In this paper, we propose a novel Energy-Calibrated Generative Model that utilizes a Conditional EBM for enhancing Variational Autoencoders (VAEs).","VAEs are sampling efficient but often suffer from blurry generation results due to the lack of training in the generative direction.","On the other hand, Energy-Based Models (EBMs) can generate high-quality samples but require expensive Markov Chain Monte Carlo (MCMC) sampling.","To address these issues, we introduce a Conditional EBM for calibrating the generative direction during training, without requiring it for test time sampling.","Our approach enables the generative model to be trained upon data and calibrated samples with adaptive weight, thereby enhancing efficiency and effectiveness without necessitating MCMC sampling in the inference phase.","We also show that the proposed approach can be extended to calibrate normalizing flows and variational posterior.","Moreover, we propose to apply the proposed method to zero-shot image restoration via neural transport prior and range-null theory.","We demonstrate the effectiveness of the proposed method through extensive experiments in various applications, including image generation and zero-shot image restoration.","Our method shows state-of-the-art performance over single-step non-adversarial generation."],"url":"http://arxiv.org/abs/2311.04071v1"}
{"created":"2023-11-07 15:35:17","title":"LISBET: a self-supervised Transformer model for the automatic segmentation of social behavior motifs","abstract":"Social behavior, defined as the process by which individuals act and react in response to others, is crucial for the function of societies and holds profound implications for mental health. To fully grasp the intricacies of social behavior and identify potential therapeutic targets for addressing social deficits, it is essential to understand its core principles. Although machine learning algorithms have made it easier to study specific aspects of complex behavior, current methodologies tend to focus primarily on single-animal behavior. In this study, we introduce LISBET (seLf-supervIsed Social BEhavioral Transformer), a model designed to detect and segment social interactions. Our model eliminates the need for feature selection and extensive human annotation by using self-supervised learning to detect and quantify social behaviors from dynamic body parts tracking data. LISBET can be used in hypothesis-driven mode to automate behavior classification using supervised finetuning, and in discovery-driven mode to segment social behavior motifs using unsupervised learning. We found that motifs recognized using the discovery-driven approach not only closely match the human annotations but also correlate with the electrophysiological activity of dopaminergic neurons in the Ventral Tegmental Area (VTA). We hope LISBET will help the community improve our understanding of social behaviors and their neural underpinnings.","sentences":["Social behavior, defined as the process by which individuals act and react in response to others, is crucial for the function of societies and holds profound implications for mental health.","To fully grasp the intricacies of social behavior and identify potential therapeutic targets for addressing social deficits, it is essential to understand its core principles.","Although machine learning algorithms have made it easier to study specific aspects of complex behavior, current methodologies tend to focus primarily on single-animal behavior.","In this study, we introduce LISBET (seLf-supervIsed Social BEhavioral Transformer), a model designed to detect and segment social interactions.","Our model eliminates the need for feature selection and extensive human annotation by using self-supervised learning to detect and quantify social behaviors from dynamic body parts tracking data.","LISBET can be used in hypothesis-driven mode to automate behavior classification using supervised finetuning, and in discovery-driven mode to segment social behavior motifs using unsupervised learning.","We found that motifs recognized using the discovery-driven approach not only closely match the human annotations but also correlate with the electrophysiological activity of dopaminergic neurons in the Ventral Tegmental Area (VTA).","We hope LISBET will help the community improve our understanding of social behaviors and their neural underpinnings."],"url":"http://arxiv.org/abs/2311.04069v1"}
{"created":"2023-11-07 15:27:52","title":"Multitask Multimodal Prompted Training for Interactive Embodied Task Completion","abstract":"Interactive and embodied tasks pose at least two fundamental challenges to existing Vision & Language (VL) models, including 1) grounding language in trajectories of actions and observations, and 2) referential disambiguation. To tackle these challenges, we propose an Embodied MultiModal Agent (EMMA): a unified encoder-decoder model that reasons over images and trajectories, and casts action prediction as multimodal text generation. By unifying all tasks as text generation, EMMA learns a language of actions which facilitates transfer across tasks. Different to previous modular approaches with independently trained components, we use a single multitask model where each task contributes to goal completion. EMMA performs on par with similar models on several VL benchmarks and sets a new state-of-the-art performance (36.81% success rate) on the Dialog-guided Task Completion (DTC), a benchmark to evaluate dialog-guided agents in the Alexa Arena","sentences":["Interactive and embodied tasks pose at least two fundamental challenges to existing Vision & Language (VL) models, including 1) grounding language in trajectories of actions and observations, and 2) referential disambiguation.","To tackle these challenges, we propose an Embodied MultiModal Agent (EMMA): a unified encoder-decoder model that reasons over images and trajectories, and casts action prediction as multimodal text generation.","By unifying all tasks as text generation, EMMA learns a language of actions which facilitates transfer across tasks.","Different to previous modular approaches with independently trained components, we use a single multitask model where each task contributes to goal completion.","EMMA performs on par with similar models on several VL benchmarks and sets a new state-of-the-art performance (36.81% success rate) on the Dialog-guided Task Completion (DTC), a benchmark to evaluate dialog-guided agents in the Alexa Arena"],"url":"http://arxiv.org/abs/2311.04067v1"}
{"created":"2023-11-07 15:26:57","title":"Can CLIP Help Sound Source Localization?","abstract":"Large-scale pre-trained image-text models demonstrate remarkable versatility across diverse tasks, benefiting from their robust representational capabilities and effective multimodal alignment. We extend the application of these models, specifically CLIP, to the domain of sound source localization. Unlike conventional approaches, we employ the pre-trained CLIP model without explicit text input, relying solely on the audio-visual correspondence. To this end, we introduce a framework that translates audio signals into tokens compatible with CLIP's text encoder, yielding audio-driven embeddings. By directly using these embeddings, our method generates audio-grounded masks for the provided audio, extracts audio-grounded image features from the highlighted regions, and aligns them with the audio-driven embeddings using the audio-visual correspondence objective. Our findings suggest that utilizing pre-trained image-text models enable our model to generate more complete and compact localization maps for the sounding objects. Extensive experiments show that our method outperforms state-of-the-art approaches by a significant margin.","sentences":["Large-scale pre-trained image-text models demonstrate remarkable versatility across diverse tasks, benefiting from their robust representational capabilities and effective multimodal alignment.","We extend the application of these models, specifically CLIP, to the domain of sound source localization.","Unlike conventional approaches, we employ the pre-trained CLIP model without explicit text input, relying solely on the audio-visual correspondence.","To this end, we introduce a framework that translates audio signals into tokens compatible with CLIP's text encoder, yielding audio-driven embeddings.","By directly using these embeddings, our method generates audio-grounded masks for the provided audio, extracts audio-grounded image features from the highlighted regions, and aligns them with the audio-driven embeddings using the audio-visual correspondence objective.","Our findings suggest that utilizing pre-trained image-text models enable our model to generate more complete and compact localization maps for the sounding objects.","Extensive experiments show that our method outperforms state-of-the-art approaches by a significant margin."],"url":"http://arxiv.org/abs/2311.04066v1"}
{"created":"2023-11-07 15:25:52","title":"Implementation and Comparison of Methods to Extract Reliability KPIs out of Textual Wind Turbine Maintenance Work Orders","abstract":"Maintenance work orders are commonly used to document information about wind turbine operation and maintenance. This includes details about proactive and reactive wind turbine downtimes, such as preventative and corrective maintenance. However, the information contained in maintenance work orders is often unstructured and difficult to analyze, making it challenging for decision-makers to use this information for optimizing operation and maintenance. To address this issue, this work presents three different approaches to calculate reliability key performance indicators from maintenance work orders. The first approach involves manual labeling of the maintenance work orders by domain experts, using the schema defined in an industrial guideline to assign the label accordingly. The second approach involves the development of a model that automatically labels the maintenance work orders using text classification methods. The third technique uses an AI-assisted tagging tool to tag and structure the raw maintenance information contained in the maintenance work orders. The resulting calculated reliability key performance indicator of the first approach are used as a benchmark for comparison with the results of the second and third approaches. The quality and time spent are considered as criteria for evaluation. Overall, these three methods make extracting maintenance information from maintenance work orders more efficient, enable the assessment of reliability key performance indicators and therefore support the optimization of wind turbine operation and maintenance.","sentences":["Maintenance work orders are commonly used to document information about wind turbine operation and maintenance.","This includes details about proactive and reactive wind turbine downtimes, such as preventative and corrective maintenance.","However, the information contained in maintenance work orders is often unstructured and difficult to analyze, making it challenging for decision-makers to use this information for optimizing operation and maintenance.","To address this issue, this work presents three different approaches to calculate reliability key performance indicators from maintenance work orders.","The first approach involves manual labeling of the maintenance work orders by domain experts, using the schema defined in an industrial guideline to assign the label accordingly.","The second approach involves the development of a model that automatically labels the maintenance work orders using text classification methods.","The third technique uses an AI-assisted tagging tool to tag and structure the raw maintenance information contained in the maintenance work orders.","The resulting calculated reliability key performance indicator of the first approach are used as a benchmark for comparison with the results of the second and third approaches.","The quality and time spent are considered as criteria for evaluation.","Overall, these three methods make extracting maintenance information from maintenance work orders more efficient, enable the assessment of reliability key performance indicators and therefore support the optimization of wind turbine operation and maintenance."],"url":"http://arxiv.org/abs/2311.04064v1"}
{"created":"2023-11-07 15:20:42","title":"Neural Yarn-Level Appearance Model for Cloth Rendering","abstract":"The realistic rendering of woven and knitted fabrics has posed significant challenges throughout many years. Previously, fiber-based micro-appearance models have achieved considerable success in attaining high levels of realism. However, rendering such models remains complex due to the intricate internal scatterings of hundreds or thousands of fibers within a yarn, requiring vast amounts of memory and time to render. In this paper, we introduce a novel framework to capture yarn-level appearance by tracing and aggregating many light paths through the underlying fiber geometry. We then employ lightweight neural networks to accurately model the aggregated BSDF, which allows for the precise modeling of a diverse array of materials while offering substantial improvements in speed and reductions in memory. Furthermore, we introduce a novel importance sampling scheme to further speed up the rate of convergence. We validate the efficacy and versatility of our framework through comparisons with preceding fiber-based shading models and by replicating various real-world fabrics. Our proposed model's enhanced performance and adaptability make it especially beneficial for film and video game production applications.","sentences":["The realistic rendering of woven and knitted fabrics has posed significant challenges throughout many years.","Previously, fiber-based micro-appearance models have achieved considerable success in attaining high levels of realism.","However, rendering such models remains complex due to the intricate internal scatterings of hundreds or thousands of fibers within a yarn, requiring vast amounts of memory and time to render.","In this paper, we introduce a novel framework to capture yarn-level appearance by tracing and aggregating many light paths through the underlying fiber geometry.","We then employ lightweight neural networks to accurately model the aggregated BSDF, which allows for the precise modeling of a diverse array of materials while offering substantial improvements in speed and reductions in memory.","Furthermore, we introduce a novel importance sampling scheme to further speed up the rate of convergence.","We validate the efficacy and versatility of our framework through comparisons with preceding fiber-based shading models and by replicating various real-world fabrics.","Our proposed model's enhanced performance and adaptability make it especially beneficial for film and video game production applications."],"url":"http://arxiv.org/abs/2311.04061v1"}
{"created":"2023-11-07 15:19:50","title":"Estimator-Coupled Reinforcement Learning for Robust Purely Tactile In-Hand Manipulation","abstract":"This paper identifies and addresses the problems with naively combining (reinforcement) learning-based controllers and state estimators for robotic in-hand manipulation. Specifically, we tackle the challenging task of purely tactile, goal-conditioned, dextrous in-hand reorientation with the hand pointing downwards. Due to the limited sensing available, many control strategies that are feasible in simulation when having full knowledge of the object's state do not allow for accurate state estimation. Hence, separately training the controller and the estimator and combining the two at test time leads to poor performance. We solve this problem by coupling the control policy to the state estimator already during training in simulation. This approach leads to more robust state estimation and overall higher performance on the task while maintaining an interpretability advantage over end-to-end policy learning. With our GPU-accelerated implementation, learning from scratch takes a median training time of only 6.5 hours on a single, low-cost GPU. In simulation experiments with the DLR-Hand II and for four significantly different object shapes, we provide an in-depth analysis of the performance of our approach. We demonstrate the successful sim2real transfer by rotating the four objects to all 24 orientations in the $\\pi/2$ discretization of SO(3), which has never been achieved for such a diverse set of shapes. Finally, our method can reorient a cube consecutively to nine goals (median), which was beyond the reach of previous methods in this challenging setting.","sentences":["This paper identifies and addresses the problems with naively combining (reinforcement) learning-based controllers and state estimators for robotic in-hand manipulation.","Specifically, we tackle the challenging task of purely tactile, goal-conditioned, dextrous in-hand reorientation with the hand pointing downwards.","Due to the limited sensing available, many control strategies that are feasible in simulation when having full knowledge of the object's state do not allow for accurate state estimation.","Hence, separately training the controller and the estimator and combining the two at test time leads to poor performance.","We solve this problem by coupling the control policy to the state estimator already during training in simulation.","This approach leads to more robust state estimation and overall higher performance on the task while maintaining an interpretability advantage over end-to-end policy learning.","With our GPU-accelerated implementation, learning from scratch takes a median training time of only 6.5 hours on a single, low-cost GPU.","In simulation experiments with the DLR-Hand II and for four significantly different object shapes, we provide an in-depth analysis of the performance of our approach.","We demonstrate the successful sim2real transfer by rotating the four objects to all 24 orientations in the $\\pi/2$ discretization of SO(3), which has never been achieved for such a diverse set of shapes.","Finally, our method can reorient a cube consecutively to nine goals (median), which was beyond the reach of previous methods in this challenging setting."],"url":"http://arxiv.org/abs/2311.04060v1"}
{"created":"2023-11-07 15:14:35","title":"Over-the-Air Computation Empowered Federated Learning: A Joint Uplink-Downlink Design","abstract":"In this paper, we investigate the communication designs of over-the-air computation (AirComp) empowered federated learning (FL) systems considering uplink model aggregation and downlink model dissemination jointly. We first derive an upper bound on the expected difference between the training loss and the optimal loss, which reveals that optimizing the FL performance is equivalent to minimizing the distortion in the received global gradient vector at each edge node. As such, we jointly optimize each edge node transmit and receive equalization coefficients along with the edge server forwarding matrix to minimize the maximum gradient distortion across all edge nodes. We further utilize the MNIST dataset to evaluate the performance of the considered FL system in the context of the handwritten digit recognition task. Experiment results show that deploying multiple antennas at the edge server significantly reduces the distortion in the received global gradient vector, leading to a notable improvement in recognition accuracy compared to the single antenna case.","sentences":["In this paper, we investigate the communication designs of over-the-air computation (AirComp) empowered federated learning (FL) systems considering uplink model aggregation and downlink model dissemination jointly.","We first derive an upper bound on the expected difference between the training loss and the optimal loss, which reveals that optimizing the FL performance is equivalent to minimizing the distortion in the received global gradient vector at each edge node.","As such, we jointly optimize each edge node transmit and receive equalization coefficients along with the edge server forwarding matrix to minimize the maximum gradient distortion across all edge nodes.","We further utilize the MNIST dataset to evaluate the performance of the considered FL system in the context of the handwritten digit recognition task.","Experiment results show that deploying multiple antennas at the edge server significantly reduces the distortion in the received global gradient vector, leading to a notable improvement in recognition accuracy compared to the single antenna case."],"url":"http://arxiv.org/abs/2311.04059v1"}
{"created":"2023-11-07 15:11:27","title":"mmFUSION: Multimodal Fusion for 3D Objects Detection","abstract":"Multi-sensor fusion is essential for accurate 3D object detection in self-driving systems. Camera and LiDAR are the most commonly used sensors, and usually, their fusion happens at the early or late stages of 3D detectors with the help of regions of interest (RoIs). On the other hand, fusion at the intermediate level is more adaptive because it does not need RoIs from modalities but is complex as the features of both modalities are presented from different points of view. In this paper, we propose a new intermediate-level multi-modal fusion (mmFUSION) approach to overcome these challenges. First, the mmFUSION uses separate encoders for each modality to compute features at a desired lower space volume. Second, these features are fused through cross-modality and multi-modality attention mechanisms proposed in mmFUSION. The mmFUSION framework preserves multi-modal information and learns to complement modalities' deficiencies through attention weights. The strong multi-modal features from the mmFUSION framework are fed to a simple 3D detection head for 3D predictions. We evaluate mmFUSION on the KITTI and NuScenes dataset where it performs better than available early, intermediate, late, and even two-stage based fusion schemes. The code with the mmdetection3D project plugin will be publicly available soon.","sentences":["Multi-sensor fusion is essential for accurate 3D object detection in self-driving systems.","Camera and LiDAR are the most commonly used sensors, and usually, their fusion happens at the early or late stages of 3D detectors with the help of regions of interest (RoIs).","On the other hand, fusion at the intermediate level is more adaptive because it does not need RoIs from modalities but is complex as the features of both modalities are presented from different points of view.","In this paper, we propose a new intermediate-level multi-modal fusion (mmFUSION) approach to overcome these challenges.","First, the mmFUSION uses separate encoders for each modality to compute features at a desired lower space volume.","Second, these features are fused through cross-modality and multi-modality attention mechanisms proposed in mmFUSION.","The mmFUSION framework preserves multi-modal information and learns to complement modalities' deficiencies through attention weights.","The strong multi-modal features from the mmFUSION framework are fed to a simple 3D detection head for 3D predictions.","We evaluate mmFUSION on the KITTI and NuScenes dataset where it performs better than available early, intermediate, late, and even two-stage based fusion schemes.","The code with the mmdetection3D project plugin will be publicly available soon."],"url":"http://arxiv.org/abs/2311.04058v1"}
{"created":"2023-11-07 15:07:08","title":"Multi-View Causal Representation Learning with Partial Observability","abstract":"We present a unified framework for studying the identifiability of representations learned from simultaneously observed views, such as different data modalities. We allow a partially observed setting in which each view constitutes a nonlinear mixture of a subset of underlying latent variables, which can be causally related. We prove that the information shared across all subsets of any number of views can be learned up to a smooth bijection using contrastive learning and a single encoder per view. We also provide graphical criteria indicating which latent variables can be identified through a simple set of rules, which we refer to as identifiability algebra. Our general framework and theoretical results unify and extend several previous works on multi-view nonlinear ICA, disentanglement, and causal representation learning. We experimentally validate our claims on numerical, image, and multi-modal data sets. Further, we demonstrate that the performance of prior methods is recovered in different special cases of our setup. Overall, we find that access to multiple partial views enables us to identify a more fine-grained representation, under the generally milder assumption of partial observability.","sentences":["We present a unified framework for studying the identifiability of representations learned from simultaneously observed views, such as different data modalities.","We allow a partially observed setting in which each view constitutes a nonlinear mixture of a subset of underlying latent variables, which can be causally related.","We prove that the information shared across all subsets of any number of views can be learned up to a smooth bijection using contrastive learning and a single encoder per view.","We also provide graphical criteria indicating which latent variables can be identified through a simple set of rules, which we refer to as identifiability algebra.","Our general framework and theoretical results unify and extend several previous works on multi-view nonlinear ICA, disentanglement, and causal representation learning.","We experimentally validate our claims on numerical, image, and multi-modal data sets.","Further, we demonstrate that the performance of prior methods is recovered in different special cases of our setup.","Overall, we find that access to multiple partial views enables us to identify a more fine-grained representation, under the generally milder assumption of partial observability."],"url":"http://arxiv.org/abs/2311.04056v1"}
{"created":"2023-11-07 15:07:02","title":"Feature Space Renormalization for Semi-supervised Learning","abstract":"Semi-supervised learning (SSL) has been proven to be a powerful method for leveraging unlabelled data to alleviate models' dependence on large labelled datasets. The common framework among recent approaches is to train the model on a large amount of unlabelled data with consistency regularization to constrain the model predictions to be invariant to input perturbation. However, the existing SSL frameworks still have room for improvement in the consistency regularization method. Instead of regularizing category predictions in the label space as in existing frameworks, this paper proposes a feature space renormalization (FSR) mechanism for SSL. First, we propose a feature space renormalization mechanism to substitute for the commonly used consistency regularization mechanism to learn better discriminative features. To apply this mechanism, we start by building a basic model and an empirical model and then introduce our mechanism to renormalize the feature learning of the basic model with the guidance of the empirical model. Second, we combine the proposed mechanism with pseudo-labelling to obtain a novel effective SSL model named FreMatch. The experimental results show that our method can achieve better performance on a variety of standard SSL benchmark datasets, and the proposed feature space renormalization mechanism can also enhance the performance of other SSL approaches.","sentences":["Semi-supervised learning (SSL) has been proven to be a powerful method for leveraging unlabelled data to alleviate models' dependence on large labelled datasets.","The common framework among recent approaches is to train the model on a large amount of unlabelled data with consistency regularization to constrain the model predictions to be invariant to input perturbation.","However, the existing SSL frameworks still have room for improvement in the consistency regularization method.","Instead of regularizing category predictions in the label space as in existing frameworks, this paper proposes a feature space renormalization (FSR) mechanism for SSL.","First, we propose a feature space renormalization mechanism to substitute for the commonly used consistency regularization mechanism to learn better discriminative features.","To apply this mechanism, we start by building a basic model and an empirical model and then introduce our mechanism to renormalize the feature learning of the basic model with the guidance of the empirical model.","Second, we combine the proposed mechanism with pseudo-labelling to obtain a novel effective SSL model named FreMatch.","The experimental results show that our method can achieve better performance on a variety of standard SSL benchmark datasets, and the proposed feature space renormalization mechanism can also enhance the performance of other SSL approaches."],"url":"http://arxiv.org/abs/2311.04055v1"}
{"created":"2023-11-07 15:05:19","title":"Generative Structural Design Integrating BIM and Diffusion Model","abstract":"Intelligent structural design using AI can effectively reduce time overhead and increase efficiency. It has potential to become the new design paradigm in the future to assist and even replace engineers, and so it has become a research hotspot in the academic community. However, current methods have some limitations to be addressed, whether in terms of application scope, visual quality of generated results, or evaluation metrics of results. This study proposes a comprehensive solution. Firstly, we introduce building information modeling (BIM) into intelligent structural design and establishes a structural design pipeline integrating BIM and generative AI, which is a powerful supplement to the previous frameworks that only considered CAD drawings. In order to improve the perceptual quality and details of generations, this study makes 3 contributions. Firstly, in terms of generation framework, inspired by the process of human drawing, a novel 2-stage generation framework is proposed to replace the traditional end-to-end framework to reduce the generation difficulty for AI models. Secondly, in terms of generative AI tools adopted, diffusion models (DMs) are introduced to replace widely used generative adversarial network (GAN)-based models, and a novel physics-based conditional diffusion model (PCDM) is proposed to consider different design prerequisites. Thirdly, in terms of neural networks, an attention block (AB) consisting of a self-attention block (SAB) and a parallel cross-attention block (PCAB) is designed to facilitate cross-domain data fusion. The quantitative and qualitative results demonstrate the powerful generation and representation capabilities of PCDM. Necessary ablation studies are conducted to examine the validity of the methods. This study also shows that DMs have the potential to replace GANs and become the new benchmark for generative problems in civil engineering.","sentences":["Intelligent structural design using AI can effectively reduce time overhead and increase efficiency.","It has potential to become the new design paradigm in the future to assist and even replace engineers, and so it has become a research hotspot in the academic community.","However, current methods have some limitations to be addressed, whether in terms of application scope, visual quality of generated results, or evaluation metrics of results.","This study proposes a comprehensive solution.","Firstly, we introduce building information modeling (BIM) into intelligent structural design and establishes a structural design pipeline integrating BIM and generative AI, which is a powerful supplement to the previous frameworks that only considered CAD drawings.","In order to improve the perceptual quality and details of generations, this study makes 3 contributions.","Firstly, in terms of generation framework, inspired by the process of human drawing, a novel 2-stage generation framework is proposed to replace the traditional end-to-end framework to reduce the generation difficulty for AI models.","Secondly, in terms of generative AI tools adopted, diffusion models (DMs) are introduced to replace widely used generative adversarial network (GAN)-based models, and a novel physics-based conditional diffusion model (PCDM) is proposed to consider different design prerequisites.","Thirdly, in terms of neural networks, an attention block (AB) consisting of a self-attention block (SAB) and a parallel cross-attention block (PCAB) is designed to facilitate cross-domain data fusion.","The quantitative and qualitative results demonstrate the powerful generation and representation capabilities of PCDM.","Necessary ablation studies are conducted to examine the validity of the methods.","This study also shows that DMs have the potential to replace GANs and become the new benchmark for generative problems in civil engineering."],"url":"http://arxiv.org/abs/2311.04052v1"}
{"created":"2023-11-07 15:00:39","title":"Reinforcement Learning Fine-tuning of Language Models is Biased Towards More Extractable Features","abstract":"Many capable large language models (LLMs) are developed via self-supervised pre-training followed by a reinforcement-learning fine-tuning phase, often based on human or AI feedback. During this stage, models may be guided by their inductive biases to rely on simpler features which may be easier to extract, at a cost to robustness and generalisation. We investigate whether principles governing inductive biases in the supervised fine-tuning of LLMs also apply when the fine-tuning process uses reinforcement learning. Following Lovering et al (2021), we test two hypotheses: that features more $\\textit{extractable}$ after pre-training are more likely to be utilised by the final policy, and that the evidence for/against a feature predicts whether it will be utilised. Through controlled experiments on synthetic and natural language tasks, we find statistically significant correlations which constitute strong evidence for these hypotheses.","sentences":["Many capable large language models (LLMs) are developed via self-supervised pre-training followed by a reinforcement-learning fine-tuning phase, often based on human or AI feedback.","During this stage, models may be guided by their inductive biases to rely on simpler features which may be easier to extract, at a cost to robustness and generalisation.","We investigate whether principles governing inductive biases in the supervised fine-tuning of LLMs also apply when the fine-tuning process uses reinforcement learning.","Following Lovering et al (2021), we test two hypotheses: that features more $\\textit{extractable}$ after pre-training are more likely to be utilised by the final policy, and that the evidence for/against a feature predicts whether it will be utilised.","Through controlled experiments on synthetic and natural language tasks, we find statistically significant correlations which constitute strong evidence for these hypotheses."],"url":"http://arxiv.org/abs/2311.04046v1"}
{"created":"2023-11-07 14:55:52","title":"P-Bench: A Multi-level Privacy Evaluation Benchmark for Language Models","abstract":"The rapid development of language models (LMs) brings unprecedented accessibility and usage for both models and users. On the one hand, powerful LMs, trained with massive textual data, achieve state-of-the-art performance over numerous downstream NLP tasks. On the other hand, more and more attention is paid to unrestricted model accesses that may bring malicious privacy risks of data leakage. To address these issues, many recent works propose privacy-preserving language models (PPLMs) with differential privacy (DP). Unfortunately, different DP implementations make it challenging for a fair comparison among existing PPLMs. In this paper, we present P-Bench, a multi-perspective privacy evaluation benchmark to empirically and intuitively quantify the privacy leakage of LMs. Instead of only protecting and measuring the privacy of protected data with DP parameters, P-Bench sheds light on the neglected inference data privacy during actual usage. P-Bench first clearly defines multi-faceted privacy objectives during private fine-tuning. Then, P-Bench constructs a unified pipeline to perform private fine-tuning. Lastly, P-Bench performs existing privacy attacks on LMs with pre-defined privacy objectives as the empirical evaluation results. The empirical attack results are used to fairly and intuitively evaluate the privacy leakage of various PPLMs. We conduct extensive experiments on three datasets of GLUE for mainstream LMs.","sentences":["The rapid development of language models (LMs) brings unprecedented accessibility and usage for both models and users.","On the one hand, powerful LMs, trained with massive textual data, achieve state-of-the-art performance over numerous downstream NLP tasks.","On the other hand, more and more attention is paid to unrestricted model accesses that may bring malicious privacy risks of data leakage.","To address these issues, many recent works propose privacy-preserving language models (PPLMs) with differential privacy (DP).","Unfortunately, different DP implementations make it challenging for a fair comparison among existing PPLMs.","In this paper, we present P-Bench, a multi-perspective privacy evaluation benchmark to empirically and intuitively quantify the privacy leakage of LMs.","Instead of only protecting and measuring the privacy of protected data with DP parameters, P-Bench sheds light on the neglected inference data privacy during actual usage.","P-Bench first clearly defines multi-faceted privacy objectives during private fine-tuning.","Then, P-Bench constructs a unified pipeline to perform private fine-tuning.","Lastly, P-Bench performs existing privacy attacks on LMs with pre-defined privacy objectives as the empirical evaluation results.","The empirical attack results are used to fairly and intuitively evaluate the privacy leakage of various PPLMs.","We conduct extensive experiments on three datasets of GLUE for mainstream LMs."],"url":"http://arxiv.org/abs/2311.04044v1"}
{"created":"2023-11-07 14:54:46","title":"Analyzing Near-Infrared Hyperspectral Imaging for Protein Content Regression and Grain Variety Classification Using Bulk References and Varying Grain-to-Background Ratios","abstract":"Based on previous work, we assess the use of NIR-HSI images for calibrating models on two datasets, focusing on protein content regression and grain variety classification. Limited reference data for protein content is expanded by subsampling and associating it with the bulk sample. However, this method introduces significant biases due to skewed leptokurtic prediction distributions, affecting both PLS-R and deep CNN models. We propose adjustments to mitigate these biases, improving mean protein reference predictions. Additionally, we investigate the impact of grain-to-background ratios on both tasks. Higher ratios yield more accurate predictions, but including lower-ratio images in calibration enhances model robustness for such scenarios.","sentences":["Based on previous work, we assess the use of NIR-HSI images for calibrating models on two datasets, focusing on protein content regression and grain variety classification.","Limited reference data for protein content is expanded by subsampling and associating it with the bulk sample.","However, this method introduces significant biases due to skewed leptokurtic prediction distributions, affecting both PLS-R and deep CNN models.","We propose adjustments to mitigate these biases, improving mean protein reference predictions.","Additionally, we investigate the impact of grain-to-background ratios on both tasks.","Higher ratios yield more accurate predictions, but including lower-ratio images in calibration enhances model robustness for such scenarios."],"url":"http://arxiv.org/abs/2311.04042v1"}
{"created":"2023-11-07 14:49:54","title":"Data exploitation: multi-task learning of object detection and semantic segmentation on partially annotated data","abstract":"Multi-task partially annotated data where each data point is annotated for only a single task are potentially helpful for data scarcity if a network can leverage the inter-task relationship. In this paper, we study the joint learning of object detection and semantic segmentation, the two most popular vision problems, from multi-task data with partial annotations. Extensive experiments are performed to evaluate each task performance and explore their complementarity when a multi-task network cannot optimize both tasks simultaneously. We propose employing knowledge distillation to leverage joint-task optimization. The experimental results show favorable results for multi-task learning and knowledge distillation over single-task learning and even full supervision scenario. All code and data splits are available at https://github.com/lhoangan/multas","sentences":["Multi-task partially annotated data where each data point is annotated for only a single task are potentially helpful for data scarcity if a network can leverage the inter-task relationship.","In this paper, we study the joint learning of object detection and semantic segmentation, the two most popular vision problems, from multi-task data with partial annotations.","Extensive experiments are performed to evaluate each task performance and explore their complementarity when a multi-task network cannot optimize both tasks simultaneously.","We propose employing knowledge distillation to leverage joint-task optimization.","The experimental results show favorable results for multi-task learning and knowledge distillation over single-task learning and even full supervision scenario.","All code and data splits are available at https://github.com/lhoangan/multas"],"url":"http://arxiv.org/abs/2311.04040v1"}
{"created":"2023-11-07 14:44:27","title":"Causal Discovery Under Local Privacy","abstract":"Differential privacy is a widely adopted framework designed to safeguard the sensitive information of data providers within a data set. It is based on the application of controlled noise at the interface between the server that stores and processes the data, and the data consumers. Local differential privacy is a variant that allows data providers to apply the privatization mechanism themselves on their data individually. Therefore it provides protection also in contexts in which the server, or even the data collector, cannot be trusted. The introduction of noise, however, inevitably affects the utility of the data, particularly by distorting the correlations between individual data components. This distortion can prove detrimental to tasks such as causal discovery. In this paper, we consider various well-known locally differentially private mechanisms and compare the trade-off between the privacy they provide, and the accuracy of the causal structure produced by algorithms for causal learning when applied to data obfuscated by these mechanisms. Our analysis yields valuable insights for selecting appropriate local differentially private protocols for causal discovery tasks. We foresee that our findings will aid researchers and practitioners in conducting locally private causal discovery.","sentences":["Differential privacy is a widely adopted framework designed to safeguard the sensitive information of data providers within a data set.","It is based on the application of controlled noise at the interface between the server that stores and processes the data, and the data consumers.","Local differential privacy is a variant that allows data providers to apply the privatization mechanism themselves on their data individually.","Therefore it provides protection also in contexts in which the server, or even the data collector, cannot be trusted.","The introduction of noise, however, inevitably affects the utility of the data, particularly by distorting the correlations between individual data components.","This distortion can prove detrimental to tasks such as causal discovery.","In this paper, we consider various well-known locally differentially private mechanisms and compare the trade-off between the privacy they provide, and the accuracy of the causal structure produced by algorithms for causal learning when applied to data obfuscated by these mechanisms.","Our analysis yields valuable insights for selecting appropriate local differentially private protocols for causal discovery tasks.","We foresee that our findings will aid researchers and practitioners in conducting locally private causal discovery."],"url":"http://arxiv.org/abs/2311.04037v1"}
{"created":"2023-11-07 14:38:18","title":"Impact of HPO on AutoML Forecasting Ensembles","abstract":"A forecasting ensemble consisting of a diverse range of estimators for both local and global univariate forecasting, in particular MQ-CNN,DeepAR, Prophet, NPTS, ARIMA and ETS, can be used to make forecasts for a variety of problems. This paper delves into the aspect of adding different hyperparameter optimization strategies to the deep learning models in such a setup (DeepAR and MQ-CNN), exploring the trade-off between added training cost and the increase in accuracy for different configurations. It shows that in such a setup, adding hyperparameter optimization can lead to performance improvements, with the final setup having a 9.9 % percent accuracy improvement with respect to the avg-wQL over the baseline ensemble without HPO, accompanied by a 65.8 % increase in end-to-end ensemble latency. This improvement is based on an empirical analysis of combining the ensemble pipeline with different tuning strategies, namely Bayesian Optimisation and Hyperband and different configurations of those strategies. In the final configuration, the proposed combination of ensemble learning and HPO outperforms the state of the art commercial AutoML forecasting solution, Amazon Forecast, with a 3.5 % lower error and 16.0 % lower end-to-end ensemble latency.","sentences":["A forecasting ensemble consisting of a diverse range of estimators for both local and global univariate forecasting, in particular MQ-CNN,DeepAR, Prophet, NPTS, ARIMA and ETS, can be used to make forecasts for a variety of problems.","This paper delves into the aspect of adding different hyperparameter optimization strategies to the deep learning models in such a setup (DeepAR and MQ-CNN), exploring the trade-off between added training cost and the increase in accuracy for different configurations.","It shows that in such a setup, adding hyperparameter optimization can lead to performance improvements, with the final setup having a 9.9 % percent accuracy improvement with respect to the avg-wQL over the baseline ensemble without HPO, accompanied by a 65.8 % increase in end-to-end ensemble latency.","This improvement is based on an empirical analysis of combining the ensemble pipeline with different tuning strategies, namely Bayesian Optimisation and Hyperband and different configurations of those strategies.","In the final configuration, the proposed combination of ensemble learning and HPO outperforms the state of the art commercial AutoML forecasting solution, Amazon Forecast, with a 3.5 % lower error and 16.0 % lower end-to-end ensemble latency."],"url":"http://arxiv.org/abs/2311.04034v1"}
{"created":"2023-11-07 14:33:29","title":"Ramsey Quantifiers in Linear Arithmetics","abstract":"We study Satisfiability Modulo Theories (SMT) enriched with the so-called Ramsey quantifiers, which assert the existence of cliques (complete graphs) in the graph induced by some formulas. The extended framework is known to have applications in proving program termination (in particular, whether a transitive binary predicate is well-founded), and monadic decomposability of SMT formulas. Our main result is a new algorithm for eliminating Ramsey quantifiers from three common SMT theories: Linear Integer Arithmetic (LIA), Linear Real Arithmetic (LRA), and Linear Integer Real Arithmetic (LIRA). In particular, if we work only with existentially quantified formulas, then our algorithm runs in polynomial time and produces a formula of linear size. One immediate consequence is that checking well-foundedness of a given formula in the aforementioned theory defining a transitive predicate can be straightforwardly handled by highly optimized SMT-solvers. We show also how this provides a uniform semi-algorithm for verifying termination and liveness with completeness guarantee (in fact, with an optimal computational complexity) for several well-known classes of infinite-state systems, which include succinct timed systems, one-counter systems, and monotonic counter systems. Another immediate consequence is a solution to an open problem on checking monadic decomposability of a given relation in quantifier-free fragments of LRA and LIRA, which is an important problem in automated reasoning and constraint databases. Our result immediately implies decidability of this problem with an optimal complexity (coNP-complete) and enables exploitation of SMT-solvers. It also provides a termination guarantee for the generic monadic decomposition algorithm of Veanes et al. for LIA, LRA, and LIRA. We report encouraging experimental results on a prototype implementation of our algorithms on micro-benchmarks.","sentences":["We study Satisfiability Modulo Theories (SMT) enriched with the so-called Ramsey quantifiers, which assert the existence of cliques (complete graphs) in the graph induced by some formulas.","The extended framework is known to have applications in proving program termination (in particular, whether a transitive binary predicate is well-founded), and monadic decomposability of SMT formulas.","Our main result is a new algorithm for eliminating Ramsey quantifiers from three common SMT theories: Linear Integer Arithmetic (LIA), Linear Real Arithmetic (LRA), and Linear Integer Real Arithmetic (LIRA).","In particular, if we work only with existentially quantified formulas, then our algorithm runs in polynomial time and produces a formula of linear size.","One immediate consequence is that checking well-foundedness of a given formula in the aforementioned theory defining a transitive predicate can be straightforwardly handled by highly optimized SMT-solvers.","We show also how this provides a uniform semi-algorithm for verifying termination and liveness with completeness guarantee (in fact, with an optimal computational complexity) for several well-known classes of infinite-state systems, which include succinct timed systems, one-counter systems, and monotonic counter systems.","Another immediate consequence is a solution to an open problem on checking monadic decomposability of a given relation in quantifier-free fragments of LRA and LIRA, which is an important problem in automated reasoning and constraint databases.","Our result immediately implies decidability of this problem with an optimal complexity (coNP-complete) and enables exploitation of SMT-solvers.","It also provides a termination guarantee for the generic monadic decomposition algorithm of Veanes et al.","for LIA, LRA, and LIRA.","We report encouraging experimental results on a prototype implementation of our algorithms on micro-benchmarks."],"url":"http://arxiv.org/abs/2311.04031v1"}
{"created":"2023-11-07 14:18:03","title":"Analyzing Film Adaptation through Narrative Alignment","abstract":"Novels are often adapted into feature films, but the differences between the two media usually require dropping sections of the source text from the movie script. Here we study this screen adaptation process by constructing narrative alignments using the Smith-Waterman local alignment algorithm coupled with SBERT embedding distance to quantify text similarity between scenes and book units. We use these alignments to perform an automated analysis of 40 adaptations, revealing insights into the screenwriting process concerning (i) faithfulness of adaptation, (ii) importance of dialog, (iii) preservation of narrative order, and (iv) gender representation issues reflective of the Bechdel test.","sentences":["Novels are often adapted into feature films, but the differences between the two media usually require dropping sections of the source text from the movie script.","Here we study this screen adaptation process by constructing narrative alignments using the Smith-Waterman local alignment algorithm coupled with SBERT embedding distance to quantify text similarity between scenes and book units.","We use these alignments to perform an automated analysis of 40 adaptations, revealing insights into the screenwriting process concerning (i) faithfulness of adaptation, (ii) importance of dialog, (iii) preservation of narrative order, and (iv) gender representation issues reflective of the Bechdel test."],"url":"http://arxiv.org/abs/2311.04020v1"}
{"created":"2023-11-07 14:14:32","title":"Exploring Dataset-Scale Indicators of Data Quality","abstract":"Modern computer vision foundation models are trained on massive amounts of data, incurring large economic and environmental costs. Recent research has suggested that improving data quality can significantly reduce the need for data quantity. But what constitutes data quality in computer vision? We posit that the quality of a given dataset can be decomposed into distinct sample-level and dataset-level constituents, and that the former have been more extensively studied than the latter. We ablate the effects of two important dataset-level constituents: label set design, and class balance. By monitoring these constituents using key indicators we provide, researchers and practitioners can better anticipate model performance, measured in terms of its accuracy and robustness to distribution shifts.","sentences":["Modern computer vision foundation models are trained on massive amounts of data, incurring large economic and environmental costs.","Recent research has suggested that improving data quality can significantly reduce the need for data quantity.","But what constitutes data quality in computer vision?","We posit that the quality of a given dataset can be decomposed into distinct sample-level and dataset-level constituents, and that the former have been more extensively studied than the latter.","We ablate the effects of two important dataset-level constituents: label set design, and class balance.","By monitoring these constituents using key indicators we provide, researchers and practitioners can better anticipate model performance, measured in terms of its accuracy and robustness to distribution shifts."],"url":"http://arxiv.org/abs/2311.04016v1"}
{"created":"2023-11-07 14:14:15","title":"Expressivity of ReLU-Networks under Convex Relaxations","abstract":"Convex relaxations are a key component of training and certifying provably safe neural networks. However, despite substantial progress, a wide and poorly understood accuracy gap to standard networks remains, raising the question of whether this is due to fundamental limitations of convex relaxations. Initial work investigating this question focused on the simple and widely used IBP relaxation. It revealed that some univariate, convex, continuous piecewise linear (CPWL) functions cannot be encoded by any ReLU network such that its IBP-analysis is precise. To explore whether this limitation is shared by more advanced convex relaxations, we conduct the first in-depth study on the expressive power of ReLU networks across all commonly used convex relaxations. We show that: (i) more advanced relaxations allow a larger class of univariate functions to be expressed as precisely analyzable ReLU networks, (ii) more precise relaxations can allow exponentially larger solution spaces of ReLU networks encoding the same functions, and (iii) even using the most precise single-neuron relaxations, it is impossible to construct precisely analyzable ReLU networks that express multivariate, convex, monotone CPWL functions.","sentences":["Convex relaxations are a key component of training and certifying provably safe neural networks.","However, despite substantial progress, a wide and poorly understood accuracy gap to standard networks remains, raising the question of whether this is due to fundamental limitations of convex relaxations.","Initial work investigating this question focused on the simple and widely used IBP relaxation.","It revealed that some univariate, convex, continuous piecewise linear (CPWL) functions cannot be encoded by any ReLU network such that its IBP-analysis is precise.","To explore whether this limitation is shared by more advanced convex relaxations, we conduct the first in-depth study on the expressive power of ReLU networks across all commonly used convex relaxations.","We show that: (i) more advanced relaxations allow a larger class of univariate functions to be expressed as precisely analyzable ReLU networks, (ii) more precise relaxations can allow exponentially larger solution spaces of ReLU networks encoding the same functions, and (iii) even using the most precise single-neuron relaxations, it is impossible to construct precisely analyzable ReLU networks that express multivariate, convex, monotone CPWL functions."],"url":"http://arxiv.org/abs/2311.04015v1"}
