{"created":"2023-11-13 18:59:47","title":"SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for Multi-modal Large Language Models","abstract":"We present SPHINX, a versatile multi-modal large language model (MLLM) with a joint mixing of model weights, tuning tasks, and visual embeddings. First, for stronger vision-language alignment, we unfreeze the large language model (LLM) during pre-training, and introduce a weight mix strategy between LLMs trained by real-world and synthetic data. By directly integrating the weights from two domains, the mixed LLM can efficiently incorporate diverse semantics with favorable robustness. Then, to enable multi-purpose capabilities, we mix a variety of tasks for joint visual instruction tuning, and design task-specific instructions to avoid inter-task conflict. In addition to the basic visual question answering, we include more challenging tasks such as region-level understanding, caption grounding, document layout detection, and human pose estimation, contributing to mutual enhancement over different scenarios. Additionally, we propose to extract comprehensive visual embeddings from various network architectures, pre-training paradigms, and information granularity, providing language models with more robust image representations. Based on our proposed joint mixing, SPHINX exhibits superior multi-modal understanding capabilities on a wide range of applications. On top of this, we further propose an efficient strategy aiming to better capture fine-grained appearances of high-resolution images. With a mixing of different scales and high-resolution sub-images, SPHINX attains exceptional visual parsing and reasoning performance on existing evaluation benchmarks. We hope our work may cast a light on the exploration of joint mixing in future MLLM research. Code is released at https://github.com/Alpha-VLLM/LLaMA2-Accessory.","sentences":["We present SPHINX, a versatile multi-modal large language model (MLLM) with a joint mixing of model weights, tuning tasks, and visual embeddings.","First, for stronger vision-language alignment, we unfreeze the large language model (LLM) during pre-training, and introduce a weight mix strategy between LLMs trained by real-world and synthetic data.","By directly integrating the weights from two domains, the mixed LLM can efficiently incorporate diverse semantics with favorable robustness.","Then, to enable multi-purpose capabilities, we mix a variety of tasks for joint visual instruction tuning, and design task-specific instructions to avoid inter-task conflict.","In addition to the basic visual question answering, we include more challenging tasks such as region-level understanding, caption grounding, document layout detection, and human pose estimation, contributing to mutual enhancement over different scenarios.","Additionally, we propose to extract comprehensive visual embeddings from various network architectures, pre-training paradigms, and information granularity, providing language models with more robust image representations.","Based on our proposed joint mixing, SPHINX exhibits superior multi-modal understanding capabilities on a wide range of applications.","On top of this, we further propose an efficient strategy aiming to better capture fine-grained appearances of high-resolution images.","With a mixing of different scales and high-resolution sub-images, SPHINX attains exceptional visual parsing and reasoning performance on existing evaluation benchmarks.","We hope our work may cast a light on the exploration of joint mixing in future MLLM research.","Code is released at https://github.com/Alpha-VLLM/LLaMA2-Accessory."],"url":"http://arxiv.org/abs/2311.07575v1"}
{"created":"2023-11-13 18:59:31","title":"To See is to Believe: Prompting GPT-4V for Better Visual Instruction Tuning","abstract":"Existing visual instruction tuning methods typically prompt large language models with textual descriptions to generate instruction-following data. Despite the promising performance achieved, these descriptions are derived from image annotations, which are oftentimes coarse-grained. Furthermore, the instructions might even contradict the visual content without observing the entire visual context. To address this challenge, we introduce a fine-grained visual instruction dataset, LVIS-Instruct4V, which contains 220K visually aligned and context-aware instructions produced by prompting the powerful GPT-4V with images from LVIS. Through experimental validation and case studies, we demonstrate that high-quality visual instructional data could improve the performance of LLaVA-1.5, a state-of-the-art large multimodal model, across a wide spectrum of benchmarks by clear margins. Notably, by simply replacing the LLaVA-Instruct with our LVIS-Instruct4V, we achieve better results than LLaVA on most challenging LMM benchmarks, e.g., LLaVA$^w$ (76.7 vs. 70.7) and MM-Vet (40.2 vs. 35.4). We release our data and model at https://github.com/X2FD/LVIS-INSTRUCT4V.","sentences":["Existing visual instruction tuning methods typically prompt large language models with textual descriptions to generate instruction-following data.","Despite the promising performance achieved, these descriptions are derived from image annotations, which are oftentimes coarse-grained.","Furthermore, the instructions might even contradict the visual content without observing the entire visual context.","To address this challenge, we introduce a fine-grained visual instruction dataset, LVIS-Instruct4V, which contains 220K visually aligned and context-aware instructions produced by prompting the powerful GPT-4V with images from LVIS.","Through experimental validation and case studies, we demonstrate that high-quality visual instructional data could improve the performance of LLaVA-1.5, a state-of-the-art large multimodal model, across a wide spectrum of benchmarks by clear margins.","Notably, by simply replacing the LLaVA-Instruct with our LVIS-Instruct4V, we achieve better results than LLaVA on most challenging LMM benchmarks, e.g., LLaVA$^w$ (76.7 vs. 70.7) and MM-Vet (40.2 vs. 35.4).","We release our data and model at https://github.com/X2FD/LVIS-INSTRUCT4V."],"url":"http://arxiv.org/abs/2311.07574v1"}
{"created":"2023-11-13 18:59:07","title":"Realizability of Free Spaces of Curves","abstract":"The free space diagram is a popular tool to compute the well-known Fr\\'echet distance. As the Fr\\'echet distance is used in many different fields, many variants have been established to cover the specific needs of these applications. Often, the question arises whether a certain pattern in the free space diagram is \"realizable\", i.e., whether there exists a pair of polygonal chains whose free space diagram corresponds to it. The answer to this question may help in deciding the computational complexity of these distance measures, as well as allowing to design more efficient algorithms for restricted input classes that avoid certain free space patterns. Therefore, we study the inverse problem: Given a potential free space diagram, do there exist curves that generate this diagram?   Our problem of interest is closely tied to the classic Distance Geometry problem. We settle the complexity of Distance Geometry in $\\mathbb{R}^{> 2}$, showing $\\exists\\mathbb{R}$-hardness. We use this to show that for curves in $\\mathbb{R}^{\\ge 2}$, the realizability problem is $\\exists\\mathbb{R}$-complete, both for continuous and for discrete Fr\\'echet distance. We prove that the continuous case in $\\mathbb{R}^1$ is only weakly NP-hard, and we provide a pseudo-polynomial time algorithm and show that it is fixed-parameter tractable. Interestingly, for the discrete case in $\\mathbb{R}^1$, we show that the problem becomes solvable in polynomial time.","sentences":["The free space diagram is a popular tool to compute the well-known Fr\\'echet distance.","As the Fr\\'echet distance is used in many different fields, many variants have been established to cover the specific needs of these applications.","Often, the question arises whether a certain pattern in the free space diagram is \"realizable\", i.e., whether there exists a pair of polygonal chains whose free space diagram corresponds to it.","The answer to this question may help in deciding the computational complexity of these distance measures, as well as allowing to design more efficient algorithms for restricted input classes that avoid certain free space patterns.","Therefore, we study the inverse problem: Given a potential free space diagram, do there exist curves that generate this diagram?   ","Our problem of interest is closely tied to the classic Distance Geometry problem.","We settle the complexity of Distance Geometry in $\\mathbb{R}^{> 2}$, showing $\\exists\\mathbb{R}$-hardness.","We use this to show that for curves in $\\mathbb{R}^{\\ge 2}$, the realizability problem is $\\exists\\mathbb{R}$-complete, both for continuous and for discrete Fr\\'echet distance.","We prove that the continuous case in $\\mathbb{R}^1$ is only weakly NP-hard, and we provide a pseudo-polynomial time algorithm and show that it is fixed-parameter tractable.","Interestingly, for the discrete case in $\\mathbb{R}^1$, we show that the problem becomes solvable in polynomial time."],"url":"http://arxiv.org/abs/2311.07573v1"}
{"created":"2023-11-13 18:56:33","title":"Feature emergence via margin maximization: case studies in algebraic tasks","abstract":"Understanding the internal representations learned by neural networks is a cornerstone challenge in the science of machine learning. While there have been significant recent strides in some cases towards understanding how neural networks implement specific target functions, this paper explores a complementary question -- why do networks arrive at particular computational strategies? Our inquiry focuses on the algebraic learning tasks of modular addition, sparse parities, and finite group operations. Our primary theoretical findings analytically characterize the features learned by stylized neural networks for these algebraic tasks. Notably, our main technique demonstrates how the principle of margin maximization alone can be used to fully specify the features learned by the network. Specifically, we prove that the trained networks utilize Fourier features to perform modular addition and employ features corresponding to irreducible group-theoretic representations to perform compositions in general groups, aligning closely with the empirical observations of Nanda et al. and Chughtai et al. More generally, we hope our techniques can help to foster a deeper understanding of why neural networks adopt specific computational strategies.","sentences":["Understanding the internal representations learned by neural networks is a cornerstone challenge in the science of machine learning.","While there have been significant recent strides in some cases towards understanding how neural networks implement specific target functions, this paper explores a complementary question -- why do networks arrive at particular computational strategies?","Our inquiry focuses on the algebraic learning tasks of modular addition, sparse parities, and finite group operations.","Our primary theoretical findings analytically characterize the features learned by stylized neural networks for these algebraic tasks.","Notably, our main technique demonstrates how the principle of margin maximization alone can be used to fully specify the features learned by the network.","Specifically, we prove that the trained networks utilize Fourier features to perform modular addition and employ features corresponding to irreducible group-theoretic representations to perform compositions in general groups, aligning closely with the empirical observations of Nanda et al. and Chughtai et al.","More generally, we hope our techniques can help to foster a deeper understanding of why neural networks adopt specific computational strategies."],"url":"http://arxiv.org/abs/2311.07568v1"}
{"created":"2023-11-13 18:54:43","title":"Exploration via linearly perturbed loss minimisation","abstract":"We introduce exploration via linear loss perturbations (EVILL), a randomised exploration method for structured stochastic bandit problems that works by solving for the minimiser of a linearly perturbed regularised negative log-likelihood function. We show that, for the case of generalised linear bandits, EVILL reduces to perturbed history exploration (PHE), a method where exploration is done by training on randomly perturbed rewards. In doing so, we provide a simple and clean explanation of when and why random reward perturbations give rise to good bandit algorithms. With the data-dependent perturbations we propose, not present in previous PHE-type methods, EVILL is shown to match the performance of Thompson-sampling-style parameter-perturbation methods, both in theory and in practice. Moreover, we show an example outside of generalised linear bandits where PHE leads to inconsistent estimates, and thus linear regret, while EVILL remains performant. Like PHE, EVILL can be implemented in just a few lines of code.","sentences":["We introduce exploration via linear loss perturbations (EVILL), a randomised exploration method for structured stochastic bandit problems that works by solving for the minimiser of a linearly perturbed regularised negative log-likelihood function.","We show that, for the case of generalised linear bandits, EVILL reduces to perturbed history exploration (PHE), a method where exploration is done by training on randomly perturbed rewards.","In doing so, we provide a simple and clean explanation of when and why random reward perturbations give rise to good bandit algorithms.","With the data-dependent perturbations we propose, not present in previous PHE-type methods, EVILL is shown to match the performance of Thompson-sampling-style parameter-perturbation methods, both in theory and in practice.","Moreover, we show an example outside of generalised linear bandits where PHE leads to inconsistent estimates, and thus linear regret, while EVILL remains performant.","Like PHE, EVILL can be implemented in just a few lines of code."],"url":"http://arxiv.org/abs/2311.07565v1"}
{"created":"2023-11-13 18:54:17","title":"Can Authorship Attribution Models Distinguish Speakers in Speech Transcripts?","abstract":"Authorship verification is the problem of determining if two distinct writing samples share the same author and is typically concerned with the attribution of written text. In this paper, we explore the attribution of transcribed speech, which poses novel challenges. The main challenge is that many stylistic features, such as punctuation and capitalization, are not available or reliable. Therefore, we expect a priori that transcribed speech is a more challenging domain for attribution. On the other hand, other stylistic features, such as speech disfluencies, may enable more successful attribution but, being specific to speech, require special purpose models. To better understand the challenges of this setting, we contribute the first systematic study of speaker attribution based solely on transcribed speech. Specifically, we propose a new benchmark for speaker attribution focused on conversational speech transcripts. To control for spurious associations of speakers with topic, we employ both conversation prompts and speakers' participating in the same conversation to construct challenging verification trials of varying difficulties. We establish the state of the art on this new benchmark by comparing a suite of neural and non-neural baselines, finding that although written text attribution models achieve surprisingly good performance in certain settings, they struggle in the hardest settings we consider.","sentences":["Authorship verification is the problem of determining if two distinct writing samples share the same author and is typically concerned with the attribution of written text.","In this paper, we explore the attribution of transcribed speech, which poses novel challenges.","The main challenge is that many stylistic features, such as punctuation and capitalization, are not available or reliable.","Therefore, we expect a priori that transcribed speech is a more challenging domain for attribution.","On the other hand, other stylistic features, such as speech disfluencies, may enable more successful attribution but, being specific to speech, require special purpose models.","To better understand the challenges of this setting, we contribute the first systematic study of speaker attribution based solely on transcribed speech.","Specifically, we propose a new benchmark for speaker attribution focused on conversational speech transcripts.","To control for spurious associations of speakers with topic, we employ both conversation prompts and speakers' participating in the same conversation to construct challenging verification trials of varying difficulties.","We establish the state of the art on this new benchmark by comparing a suite of neural and non-neural baselines, finding that although written text attribution models achieve surprisingly good performance in certain settings, they struggle in the hardest settings we consider."],"url":"http://arxiv.org/abs/2311.07564v1"}
{"created":"2023-11-13 18:53:37","title":"GPT-4V in Wonderland: Large Multimodal Models for Zero-Shot Smartphone GUI Navigation","abstract":"We present MM-Navigator, a GPT-4V-based agent for the smartphone graphical user interface (GUI) navigation task. MM-Navigator can interact with a smartphone screen as human users, and determine subsequent actions to fulfill given instructions. Our findings demonstrate that large multimodal models (LMMs), specifically GPT-4V, excel in zero-shot GUI navigation through its advanced screen interpretation, action reasoning, and precise action localization capabilities. We first benchmark MM-Navigator on our collected iOS screen dataset. According to human assessments, the system exhibited a 91\\% accuracy rate in generating reasonable action descriptions and a 75\\% accuracy rate in executing the correct actions for single-step instructions on iOS. Additionally, we evaluate the model on a subset of an Android screen navigation dataset, where the model outperforms previous GUI navigators in a zero-shot fashion. Our benchmark and detailed analyses aim to lay a robust groundwork for future research into the GUI navigation task. The project page is at https://github.com/zzxslp/MM-Navigator.","sentences":["We present MM-Navigator, a GPT-4V-based agent for the smartphone graphical user interface (GUI) navigation task.","MM-Navigator can interact with a smartphone screen as human users, and determine subsequent actions to fulfill given instructions.","Our findings demonstrate that large multimodal models (LMMs), specifically GPT-4V, excel in zero-shot GUI navigation through its advanced screen interpretation, action reasoning, and precise action localization capabilities.","We first benchmark MM-Navigator on our collected iOS screen dataset.","According to human assessments, the system exhibited a 91\\% accuracy rate in generating reasonable action descriptions and a 75\\% accuracy rate in executing the correct actions for single-step instructions on iOS.","Additionally, we evaluate the model on a subset of an Android screen navigation dataset, where the model outperforms previous GUI navigators in a zero-shot fashion.","Our benchmark and detailed analyses aim to lay a robust groundwork for future research into the GUI navigation task.","The project page is at https://github.com/zzxslp/MM-Navigator."],"url":"http://arxiv.org/abs/2311.07562v1"}
{"created":"2023-11-13 18:53:30","title":"Fast Normalized Cross-Correlation for Template Matching with Rotations","abstract":"Normalized cross-correlation is the reference approach to carry out template matching on images. When it is computed in Fourier space, it can handle efficiently template translations but it cannot do so with template rotations. Including rotations requires sampling the whole space of rotations, repeating the computation of the correlation each time.   This article develops an alternative mathematical theory to handle efficiently, at the same time, rotations and translations. Our proposal has a reduced computational complexity because it does not require to repeatedly sample the space of rotations. To do so, we integrate the information relative to all rotated versions of the template into a unique symmetric tensor template -which is computed only once per template-. Afterward, we demonstrate that the correlation between the image to be processed with the independent tensor components of the tensorial template contains enough information to recover template instance positions and rotations.   Our proposed method has the potential to speed up conventional template matching computations by a factor of several magnitude orders for the case of 3D images.","sentences":["Normalized cross-correlation is the reference approach to carry out template matching on images.","When it is computed in Fourier space, it can handle efficiently template translations but it cannot do so with template rotations.","Including rotations requires sampling the whole space of rotations, repeating the computation of the correlation each time.   ","This article develops an alternative mathematical theory to handle efficiently, at the same time, rotations and translations.","Our proposal has a reduced computational complexity because it does not require to repeatedly sample the space of rotations.","To do so, we integrate the information relative to all rotated versions of the template into a unique symmetric tensor template -which is computed only once per template-.","Afterward, we demonstrate that the correlation between the image to be processed with the independent tensor components of the tensorial template contains enough information to recover template instance positions and rotations.   ","Our proposed method has the potential to speed up conventional template matching computations by a factor of several magnitude orders for the case of 3D images."],"url":"http://arxiv.org/abs/2311.07561v1"}
{"created":"2023-11-13 18:52:27","title":"Sound Gradual Verification with Symbolic Execution","abstract":"Gradual verification, which supports explicitly partial specifications and verifies them with a combination of static and dynamic checks, makes verification more incremental and provides earlier feedback to developers. While an abstract, weakest precondition-based approach to gradual verification was previously proven sound, the approach did not provide sufficient guidance for implementation and optimization of the required run-time checks. More recently, gradual verification was implemented using symbolic execution techniques, but the soundness of the approach (as with related static checkers based on implicit dynamic frames) was an open question. This paper puts practical gradual verification on a sound footing with a formalization of symbolic execution, optimized run-time check generation, and run time execution. We prove our approach is sound; our proof also covers a core subset of the Viper tool, for which we are aware of no previous soundness result. Our formalization enabled us to find a soundness bug in an implemented gradual verification tool and describe the fix necessary to make it sound.","sentences":["Gradual verification, which supports explicitly partial specifications and verifies them with a combination of static and dynamic checks, makes verification more incremental and provides earlier feedback to developers.","While an abstract, weakest precondition-based approach to gradual verification was previously proven sound, the approach did not provide sufficient guidance for implementation and optimization of the required run-time checks.","More recently, gradual verification was implemented using symbolic execution techniques, but the soundness of the approach (as with related static checkers based on implicit dynamic frames) was an open question.","This paper puts practical gradual verification on a sound footing with a formalization of symbolic execution, optimized run-time check generation, and run time execution.","We prove our approach is sound; our proof also covers a core subset of the Viper tool, for which we are aware of no previous soundness result.","Our formalization enabled us to find a soundness bug in an implemented gradual verification tool and describe the fix necessary to make it sound."],"url":"http://arxiv.org/abs/2311.07559v1"}
{"created":"2023-11-13 18:51:57","title":"Data-Efficient Task Generalization via Probabilistic Model-based Meta Reinforcement Learning","abstract":"We introduce PACOH-RL, a novel model-based Meta-Reinforcement Learning (Meta-RL) algorithm designed to efficiently adapt control policies to changing dynamics. PACOH-RL meta-learns priors for the dynamics model, allowing swift adaptation to new dynamics with minimal interaction data. Existing Meta-RL methods require abundant meta-learning data, limiting their applicability in settings such as robotics, where data is costly to obtain. To address this, PACOH-RL incorporates regularization and epistemic uncertainty quantification in both the meta-learning and task adaptation stages. When facing new dynamics, we use these uncertainty estimates to effectively guide exploration and data collection. Overall, this enables positive transfer, even when access to data from prior tasks or dynamic settings is severely limited. Our experiment results demonstrate that PACOH-RL outperforms model-based RL and model-based Meta-RL baselines in adapting to new dynamic conditions. Finally, on a real robotic car, we showcase the potential for efficient RL policy adaptation in diverse, data-scarce conditions.","sentences":["We introduce PACOH-RL, a novel model-based Meta-Reinforcement Learning (Meta-RL) algorithm designed to efficiently adapt control policies to changing dynamics.","PACOH-RL meta-learns priors for the dynamics model, allowing swift adaptation to new dynamics with minimal interaction data.","Existing Meta-RL methods require abundant meta-learning data, limiting their applicability in settings such as robotics, where data is costly to obtain.","To address this, PACOH-RL incorporates regularization and epistemic uncertainty quantification in both the meta-learning and task adaptation stages.","When facing new dynamics, we use these uncertainty estimates to effectively guide exploration and data collection.","Overall, this enables positive transfer, even when access to data from prior tasks or dynamic settings is severely limited.","Our experiment results demonstrate that PACOH-RL outperforms model-based RL and model-based Meta-RL baselines in adapting to new dynamic conditions.","Finally, on a real robotic car, we showcase the potential for efficient RL policy adaptation in diverse, data-scarce conditions."],"url":"http://arxiv.org/abs/2311.07558v1"}
{"created":"2023-11-13 18:49:13","title":"Using Natural Language Explanations to Improve Robustness of In-context Learning for Natural Language Inference","abstract":"Recent studies have demonstrated that large language models (LLMs) excel in diverse tasks through in-context learning (ICL) facilitated by task-specific prompts and examples. However, the existing literature shows that ICL encounters performance deterioration when exposed to adversarial inputs. Enhanced performance has been observed when ICL is augmented with natural language explanations (NLEs) (we refer to it as X-ICL). Thus, this work investigates whether X-ICL can improve the robustness of LLMs on a suite of seven adversarial and challenging natural language inference datasets. Moreover, we introduce a new approach to X-ICL by prompting an LLM (ChatGPT in our case) with few human-generated NLEs to produce further NLEs (we call it ChatGPT few-shot), which we show superior to both ChatGPT zero-shot and human-generated NLEs alone. We evaluate five popular LLMs (GPT3.5-turbo, LLaMa2, Vicuna, Zephyr, Mistral) and show that X-ICL with ChatGPT few-shot yields over 6% improvement over ICL. Furthermore, while prompt selection strategies were previously shown to significantly improve ICL on in-distribution test sets, we show that these strategies do not match the efficacy of the X-ICL paradigm in robustness-oriented evaluations.","sentences":["Recent studies have demonstrated that large language models (LLMs) excel in diverse tasks through in-context learning (ICL) facilitated by task-specific prompts and examples.","However, the existing literature shows that ICL encounters performance deterioration when exposed to adversarial inputs.","Enhanced performance has been observed when ICL is augmented with natural language explanations (NLEs) (we refer to it as X-ICL).","Thus, this work investigates whether X-ICL can improve the robustness of LLMs on a suite of seven adversarial and challenging natural language inference datasets.","Moreover, we introduce a new approach to X-ICL by prompting an LLM (ChatGPT in our case) with few human-generated NLEs to produce further NLEs (we call it ChatGPT few-shot), which we show superior to both ChatGPT zero-shot and human-generated NLEs alone.","We evaluate five popular LLMs (GPT3.5-turbo, LLaMa2, Vicuna, Zephyr, Mistral) and show that X-ICL with ChatGPT few-shot yields over 6% improvement over ICL.","Furthermore, while prompt selection strategies were previously shown to significantly improve ICL on in-distribution test sets, we show that these strategies do not match the efficacy of the X-ICL paradigm in robustness-oriented evaluations."],"url":"http://arxiv.org/abs/2311.07556v1"}
{"created":"2023-11-13 18:48:57","title":"Fast and Space-Efficient Parallel Algorithms for Influence Maximization","abstract":"Influence Maximization (IM) is a crucial problem in data science. The goal is to find a fixed-size set of highly-influential seed vertices on a network to maximize the influence spread along the edges. While IM is NP-hard on commonly-used diffusion models, a greedy algorithm can achieve $(1-1/e)$-approximation, repeatedly selecting the vertex with the highest marginal gain in influence as the seed. Due to theoretical guarantees, rich literature focuses on improving the performance of the greedy algorithm. To estimate the marginal gain, existing work either runs Monte Carlo (MC) simulations of influence spread or pre-stores hundreds of sketches (usually per-vertex information). However, these approaches can be inefficient in time (MC simulation) or space (storing sketches), preventing the ideas from scaling to today's large-scale graphs.   This paper significantly improves the scalability of IM using two key techniques. The first is a sketch-compression technique for the independent cascading model on undirected graphs. It allows combining the simulation and sketching approaches to achieve a time-space tradeoff. The second technique includes new data structures for parallel seed selection. Using our new approaches, we implemented PaC-IM: Parallel and Compressed IM.   We compare PaC-IM with state-of-the-art parallel IM systems on a 96-core machine with 1.5TB memory. PaC-IM can process large-scale graphs with up to 900M vertices and 74B edges in about 2 hours. On average across all tested graphs, our uncompressed version is 5--18$\\times$ faster and about 1.4$\\times$ more space-efficient than existing parallel IM systems. Using compression further saves 3.8$\\times$ space with only 70% overhead in time on average.","sentences":["Influence Maximization (IM) is a crucial problem in data science.","The goal is to find a fixed-size set of highly-influential seed vertices on a network to maximize the influence spread along the edges.","While IM is NP-hard on commonly-used diffusion models, a greedy algorithm can achieve $(1-1/e)$-approximation, repeatedly selecting the vertex with the highest marginal gain in influence as the seed.","Due to theoretical guarantees, rich literature focuses on improving the performance of the greedy algorithm.","To estimate the marginal gain, existing work either runs Monte Carlo (MC) simulations of influence spread or pre-stores hundreds of sketches (usually per-vertex information).","However, these approaches can be inefficient in time (MC simulation) or space (storing sketches), preventing the ideas from scaling to today's large-scale graphs.   ","This paper significantly improves the scalability of IM using two key techniques.","The first is a sketch-compression technique for the independent cascading model on undirected graphs.","It allows combining the simulation and sketching approaches to achieve a time-space tradeoff.","The second technique includes new data structures for parallel seed selection.","Using our new approaches, we implemented PaC-IM: Parallel and Compressed IM.   ","We compare PaC-IM with state-of-the-art parallel IM systems on a 96-core machine with 1.5TB memory.","PaC-IM can process large-scale graphs with up to 900M vertices and 74B edges in about 2 hours.","On average across all tested graphs, our uncompressed version is 5--18$\\times$ faster and about 1.4$\\times$ more space-efficient than existing parallel IM systems.","Using compression further saves 3.8$\\times$ space with only 70% overhead in time on average."],"url":"http://arxiv.org/abs/2311.07554v1"}
{"created":"2023-11-13 18:48:54","title":"An Extensive Study on Adversarial Attack against Pre-trained Models of Code","abstract":"Transformer-based pre-trained models of code (PTMC) have been widely utilized and have achieved state-of-the-art performance in many mission-critical applications. However, they can be vulnerable to adversarial attacks through identifier substitution or coding style transformation, which can significantly degrade accuracy and may further incur security concerns. Although several approaches have been proposed to generate adversarial examples for PTMC, the effectiveness and efficiency of such approaches, especially on different code intelligence tasks, has not been well understood. To bridge this gap, this study systematically analyzes five state-of-the-art adversarial attack approaches from three perspectives: effectiveness, efficiency, and the quality of generated examples. The results show that none of the five approaches balances all these perspectives. Particularly, approaches with a high attack success rate tend to be time-consuming; the adversarial code they generate often lack naturalness, and vice versa. To address this limitation, we explore the impact of perturbing identifiers under different contexts and find that identifier substitution within for and if statements is the most effective. Based on these findings, we propose a new approach that prioritizes different types of statements for various tasks and further utilizes beam search to generate adversarial examples. Evaluation results show that it outperforms the state-of-the-art ALERT in terms of both effectiveness and efficiency while preserving the naturalness of the generated adversarial examples.","sentences":["Transformer-based pre-trained models of code (PTMC) have been widely utilized and have achieved state-of-the-art performance in many mission-critical applications.","However, they can be vulnerable to adversarial attacks through identifier substitution or coding style transformation, which can significantly degrade accuracy and may further incur security concerns.","Although several approaches have been proposed to generate adversarial examples for PTMC, the effectiveness and efficiency of such approaches, especially on different code intelligence tasks, has not been well understood.","To bridge this gap, this study systematically analyzes five state-of-the-art adversarial attack approaches from three perspectives: effectiveness, efficiency, and the quality of generated examples.","The results show that none of the five approaches balances all these perspectives.","Particularly, approaches with a high attack success rate tend to be time-consuming; the adversarial code they generate often lack naturalness, and vice versa.","To address this limitation, we explore the impact of perturbing identifiers under different contexts and find that identifier substitution within for and if statements is the most effective.","Based on these findings, we propose a new approach that prioritizes different types of statements for various tasks and further utilizes beam search to generate adversarial examples.","Evaluation results show that it outperforms the state-of-the-art ALERT in terms of both effectiveness and efficiency while preserving the naturalness of the generated adversarial examples."],"url":"http://arxiv.org/abs/2311.07553v1"}
{"created":"2023-11-13 18:39:44","title":"Tabdoor: Backdoor Vulnerabilities in Transformer-based Neural Networks for Tabular Data","abstract":"Deep neural networks (DNNs) have shown great promise in various domains. Alongside these developments, vulnerabilities associated with DNN training, such as backdoor attacks, are a significant concern. These attacks involve the subtle insertion of triggers during model training, allowing for manipulated predictions. More recently, DNNs for tabular data have gained increasing attention due to the rise of transformer models.   Our research presents a comprehensive analysis of backdoor attacks on tabular data using DNNs, particularly focusing on transformer-based networks. Given the inherent complexities of tabular data, we explore the challenges of embedding backdoors. Through systematic experimentation across benchmark datasets, we uncover that transformer-based DNNs for tabular data are highly susceptible to backdoor attacks, even with minimal feature value alterations. Our results indicate nearly perfect attack success rates (approx100%) by introducing novel backdoor attack strategies to tabular data. Furthermore, we evaluate several defenses against these attacks, identifying Spectral Signatures as the most effective one. Our findings highlight the urgency to address such vulnerabilities and provide insights into potential countermeasures for securing DNN models against backdoors on tabular data.","sentences":["Deep neural networks (DNNs) have shown great promise in various domains.","Alongside these developments, vulnerabilities associated with DNN training, such as backdoor attacks, are a significant concern.","These attacks involve the subtle insertion of triggers during model training, allowing for manipulated predictions.","More recently, DNNs for tabular data have gained increasing attention due to the rise of transformer models.   ","Our research presents a comprehensive analysis of backdoor attacks on tabular data using DNNs, particularly focusing on transformer-based networks.","Given the inherent complexities of tabular data, we explore the challenges of embedding backdoors.","Through systematic experimentation across benchmark datasets, we uncover that transformer-based DNNs for tabular data are highly susceptible to backdoor attacks, even with minimal feature value alterations.","Our results indicate nearly perfect attack success rates (approx100%) by introducing novel backdoor attack strategies to tabular data.","Furthermore, we evaluate several defenses against these attacks, identifying Spectral Signatures as the most effective one.","Our findings highlight the urgency to address such vulnerabilities and provide insights into potential countermeasures for securing DNN models against backdoors on tabular data."],"url":"http://arxiv.org/abs/2311.07550v1"}
{"created":"2023-11-13 18:37:07","title":"Interpretable Fine-Tuning for Graph Neural Network Surrogate Models","abstract":"Data-based surrogate modeling has surged in capability in recent years with the emergence of graph neural networks (GNNs), which can operate directly on mesh-based representations of data. The goal of this work is to introduce an interpretable fine-tuning strategy for GNNs, with application to unstructured mesh-based fluid dynamics modeling. The end result is a fine-tuned GNN that adds interpretability to a pre-trained baseline GNN through an adaptive sub-graph sampling strategy that isolates regions in physical space intrinsically linked to the forecasting task, while retaining the predictive capability of the baseline. The structures identified by the fine-tuned GNNs, which are adaptively produced in the forward pass as explicit functions of the input, serve as an accessible link between the baseline model architecture, the optimization goal, and known problem-specific physics. Additionally, through a regularization procedure, the fine-tuned GNNs can also be used to identify, during inference, graph nodes that correspond to a majority of the anticipated forecasting error, adding a novel interpretable error-tagging capability to baseline models. Demonstrations are performed using unstructured flow data sourced from flow over a backward-facing step at high Reynolds numbers.","sentences":["Data-based surrogate modeling has surged in capability in recent years with the emergence of graph neural networks (GNNs), which can operate directly on mesh-based representations of data.","The goal of this work is to introduce an interpretable fine-tuning strategy for GNNs, with application to unstructured mesh-based fluid dynamics modeling.","The end result is a fine-tuned GNN that adds interpretability to a pre-trained baseline GNN through an adaptive sub-graph sampling strategy that isolates regions in physical space intrinsically linked to the forecasting task, while retaining the predictive capability of the baseline.","The structures identified by the fine-tuned GNNs, which are adaptively produced in the forward pass as explicit functions of the input, serve as an accessible link between the baseline model architecture, the optimization goal, and known problem-specific physics.","Additionally, through a regularization procedure, the fine-tuned GNNs can also be used to identify, during inference, graph nodes that correspond to a majority of the anticipated forecasting error, adding a novel interpretable error-tagging capability to baseline models.","Demonstrations are performed using unstructured flow data sourced from flow over a backward-facing step at high Reynolds numbers."],"url":"http://arxiv.org/abs/2311.07548v1"}
{"created":"2023-11-13 18:36:50","title":"GPT-4V(ision) as A Social Media Analysis Engine","abstract":"Recent research has offered insights into the extraordinary capabilities of Large Multimodal Models (LMMs) in various general vision and language tasks. There is growing interest in how LMMs perform in more specialized domains. Social media content, inherently multimodal, blends text, images, videos, and sometimes audio. Understanding social multimedia content remains a challenging problem for contemporary machine learning frameworks. In this paper, we explore GPT-4V(ision)'s capabilities for social multimedia analysis. We select five representative tasks, including sentiment analysis, hate speech detection, fake news identification, demographic inference, and political ideology detection, to evaluate GPT-4V. Our investigation begins with a preliminary quantitative analysis for each task using existing benchmark datasets, followed by a careful review of the results and a selection of qualitative samples that illustrate GPT-4V's potential in understanding multimodal social media content. GPT-4V demonstrates remarkable efficacy in these tasks, showcasing strengths such as joint understanding of image-text pairs, contextual and cultural awareness, and extensive commonsense knowledge. Despite the overall impressive capacity of GPT-4V in the social media domain, there remain notable challenges. GPT-4V struggles with tasks involving multilingual social multimedia comprehension and has difficulties in generalizing to the latest trends in social media. Additionally, it exhibits a tendency to generate erroneous information in the context of evolving celebrity and politician knowledge, reflecting the known hallucination problem. The insights gleaned from our findings underscore a promising future for LMMs in enhancing our comprehension of social media content and its users through the analysis of multimodal information.","sentences":["Recent research has offered insights into the extraordinary capabilities of Large Multimodal Models (LMMs) in various general vision and language tasks.","There is growing interest in how LMMs perform in more specialized domains.","Social media content, inherently multimodal, blends text, images, videos, and sometimes audio.","Understanding social multimedia content remains a challenging problem for contemporary machine learning frameworks.","In this paper, we explore GPT-4V(ision)'s capabilities for social multimedia analysis.","We select five representative tasks, including sentiment analysis, hate speech detection, fake news identification, demographic inference, and political ideology detection, to evaluate GPT-4V. Our investigation begins with a preliminary quantitative analysis for each task using existing benchmark datasets, followed by a careful review of the results and a selection of qualitative samples that illustrate GPT-4V's potential in understanding multimodal social media content.","GPT-4V demonstrates remarkable efficacy in these tasks, showcasing strengths such as joint understanding of image-text pairs, contextual and cultural awareness, and extensive commonsense knowledge.","Despite the overall impressive capacity of GPT-4V in the social media domain, there remain notable challenges.","GPT-4V struggles with tasks involving multilingual social multimedia comprehension and has difficulties in generalizing to the latest trends in social media.","Additionally, it exhibits a tendency to generate erroneous information in the context of evolving celebrity and politician knowledge, reflecting the known hallucination problem.","The insights gleaned from our findings underscore a promising future for LMMs in enhancing our comprehension of social media content and its users through the analysis of multimodal information."],"url":"http://arxiv.org/abs/2311.07547v1"}
{"created":"2023-11-13 18:31:48","title":"mlscorecheck: Testing the consistency of reported performance scores and experiments in machine learning","abstract":"Addressing the reproducibility crisis in artificial intelligence through the validation of reported experimental results is a challenging task. It necessitates either the reimplementation of techniques or a meticulous assessment of papers for deviations from the scientific method and best statistical practices. To facilitate the validation of reported results, we have developed numerical techniques capable of identifying inconsistencies between reported performance scores and various experimental setups in machine learning problems, including binary/multiclass classification and regression. These consistency tests are integrated into the open-source package mlscorecheck, which also provides specific test bundles designed to detect systematically recurring flaws in various fields, such as retina image processing and synthetic minority oversampling.","sentences":["Addressing the reproducibility crisis in artificial intelligence through the validation of reported experimental results is a challenging task.","It necessitates either the reimplementation of techniques or a meticulous assessment of papers for deviations from the scientific method and best statistical practices.","To facilitate the validation of reported results, we have developed numerical techniques capable of identifying inconsistencies between reported performance scores and various experimental setups in machine learning problems, including binary/multiclass classification and regression.","These consistency tests are integrated into the open-source package mlscorecheck, which also provides specific test bundles designed to detect systematically recurring flaws in various fields, such as retina image processing and synthetic minority oversampling."],"url":"http://arxiv.org/abs/2311.07541v1"}
{"created":"2023-11-13 18:31:42","title":"Finding planted cliques using Markov chain Monte Carlo","abstract":"The planted clique problem is a paradigmatic model of statistical-to-computational gaps: the planted clique is information-theoretically detectable if its size $k\\ge 2\\log_2 n$ but polynomial-time algorithms only exist for the recovery task when $k= \\Omega(\\sqrt{n})$. By now, there are many simple and fast algorithms that succeed as soon as $k = \\Omega(\\sqrt{n})$. Glaringly, however, no MCMC approach to the problem had been shown to work, including the Metropolis process on cliques studied by Jerrum since 1992. In fact, Chen, Mossel, and Zadik recently showed that any Metropolis process whose state space is the set of cliques fails to find any sub-linear sized planted clique in polynomial time if initialized naturally from the empty set. Here, we redeem MCMC performance for the planted clique problem by relaxing the state space to all vertex subsets and adding a corresponding energy penalty for missing edges. With that, we prove that energy-minimizing Markov chains (gradient descent and a low-temperature relaxation of it) succeed at recovering planted cliques of size $k = \\Omega(\\sqrt{n})$ if initialized from the full graph. Importantly, initialized from the empty set, the relaxation still does not help the gradient descent find sub-linear planted cliques. We also demonstrate robustness of these Markov chain approaches under a natural contamination model.","sentences":["The planted clique problem is a paradigmatic model of statistical-to-computational gaps: the planted clique is information-theoretically detectable if its size $k\\ge 2\\log_2 n$ but polynomial-time algorithms only exist for the recovery task when $k= \\Omega(\\sqrt{n})$. By now, there are many simple and fast algorithms that succeed as soon as $k = \\Omega(\\sqrt{n})$. Glaringly, however, no MCMC approach to the problem had been shown to work, including the Metropolis process on cliques studied by Jerrum since 1992.","In fact, Chen, Mossel, and Zadik recently showed that any Metropolis process whose state space is the set of cliques fails to find any sub-linear sized planted clique in polynomial time if initialized naturally from the empty set.","Here, we redeem MCMC performance for the planted clique problem by relaxing the state space to all vertex subsets and adding a corresponding energy penalty for missing edges.","With that, we prove that energy-minimizing Markov chains (gradient descent and a low-temperature relaxation of it) succeed at recovering planted cliques of size $k = \\Omega(\\sqrt{n})$ if initialized from the full graph.","Importantly, initialized from the empty set, the relaxation still does not help the gradient descent find sub-linear planted cliques.","We also demonstrate robustness of these Markov chain approaches under a natural contamination model."],"url":"http://arxiv.org/abs/2311.07540v1"}
{"created":"2023-11-13 18:28:25","title":"Leveraging Multiple Teachers for Test-Time Adaptation of Language-Guided Classifiers","abstract":"Recent approaches have explored language-guided classifiers capable of classifying examples from novel tasks when provided with task-specific natural language explanations, instructions or prompts (Sanh et al., 2022; R. Menon et al., 2022). While these classifiers can generalize in zero-shot settings, their task performance often varies substantially between different language explanations in unpredictable ways (Lu et al., 2022; Gonen et al., 2022). Also, current approaches fail to leverage unlabeled examples that may be available in many scenarios. Here, we introduce TALC, a framework that uses data programming to adapt a language-guided classifier for a new task during inference when provided with explanations from multiple teachers and unlabeled test examples. Our results show that TALC consistently outperforms a competitive baseline from prior work by an impressive 9.3% (relative improvement). Further, we demonstrate the robustness of TALC to variations in the quality and quantity of provided explanations, highlighting its potential in scenarios where learning from multiple teachers or a crowd is involved. Our code is available at: https://github.com/WeiKangda/TALC.git.","sentences":["Recent approaches have explored language-guided classifiers capable of classifying examples from novel tasks when provided with task-specific natural language explanations, instructions or prompts (Sanh et al., 2022; R. Menon et al., 2022).","While these classifiers can generalize in zero-shot settings, their task performance often varies substantially between different language explanations in unpredictable ways (Lu et al., 2022; Gonen et al., 2022).","Also, current approaches fail to leverage unlabeled examples that may be available in many scenarios.","Here, we introduce TALC, a framework that uses data programming to adapt a language-guided classifier for a new task during inference when provided with explanations from multiple teachers and unlabeled test examples.","Our results show that TALC consistently outperforms a competitive baseline from prior work by an impressive 9.3% (relative improvement).","Further, we demonstrate the robustness of TALC to variations in the quality and quantity of provided explanations, highlighting its potential in scenarios where learning from multiple teachers or a crowd is involved.","Our code is available at: https://github.com/WeiKangda/TALC.git."],"url":"http://arxiv.org/abs/2311.07538v1"}
{"created":"2023-11-13 18:22:32","title":"A Comprehensive Evaluation of GPT-4V on Knowledge-Intensive Visual Question Answering","abstract":"The emergence of multimodal large models (MLMs) has significantly advanced the field of visual understanding, offering remarkable capabilities in the realm of visual question answering (VQA). Yet, the true challenge lies in the domain of knowledge-intensive VQA tasks, which necessitate not just recognition of visual elements, but also a deep comprehension of the visual information in conjunction with a vast repository of learned knowledge. To uncover such capabilities of MLMs, particularly the newly introduced GPT-4V, we provide an in-depth evaluation from three perspectives: 1) Commonsense Knowledge, which assesses how well models can understand visual cues and connect to general knowledge; 2) Fine-grained World Knowledge, which tests the model's skill in reasoning out specific knowledge from images, showcasing their proficiency across various specialized fields; 3) Comprehensive Knowledge with Decision-making Rationales, which examines model's capability to provide logical explanations for its inference, facilitating a deeper analysis from the interpretability perspective. Extensive experiments indicate that GPT-4V achieves SOTA performance on above three tasks. Interestingly, we find that: a) GPT-4V demonstrates enhanced reasoning and explanation when using composite images as few-shot; b) GPT-4V produces severe hallucinations when dealing with world knowledge, highlighting the future need for advancements in this research direction.","sentences":["The emergence of multimodal large models (MLMs) has significantly advanced the field of visual understanding, offering remarkable capabilities in the realm of visual question answering (VQA).","Yet, the true challenge lies in the domain of knowledge-intensive VQA tasks, which necessitate not just recognition of visual elements, but also a deep comprehension of the visual information in conjunction with a vast repository of learned knowledge.","To uncover such capabilities of MLMs, particularly the newly introduced GPT-4V, we provide an in-depth evaluation from three perspectives: 1) Commonsense Knowledge, which assesses how well models can understand visual cues and connect to general knowledge; 2) Fine-grained World Knowledge, which tests the model's skill in reasoning out specific knowledge from images, showcasing their proficiency across various specialized fields; 3) Comprehensive Knowledge with Decision-making Rationales, which examines model's capability to provide logical explanations for its inference, facilitating a deeper analysis from the interpretability perspective.","Extensive experiments indicate that GPT-4V achieves SOTA performance on above three tasks.","Interestingly, we find that: a) GPT-4V demonstrates enhanced reasoning and explanation when using composite images as few-shot; b) GPT-4V produces severe hallucinations when dealing with world knowledge, highlighting the future need for advancements in this research direction."],"url":"http://arxiv.org/abs/2311.07536v1"}
{"created":"2023-11-13 18:22:16","title":"Causality Diagrams using Hybrid Vector Clocks","abstract":"Causality in distributed systems is a concept that has long been explored and numerous approaches have been made to use causality as a way to trace distributed system execution. Traditional approaches usually used system profiling and newer approaches profiled clocks of systems to detect failures and construct timelines that caused those failures. Since the advent of logical clocks, these profiles have become more and more accurate with ways to characterize concurrency and distributions, with accurate diagrams for message passing. Vector clocks addressed the shortcomings of using traditional logical clocks, by storing information about other processes in the system as well. Hybrid vector clocks are a novel approach to this concept where clocks need not store all the process information. Rather, we store information of processes within an acceptable skew of the focused process. This gives us an efficient way of profiling with substantially reduced costs to the system. Building on this idea, we propose the idea of building causal traces using information generated from the hybrid vector clock. The hybrid vector clock would provide us with a strong sense of concurrency and distribution, and we theorize that all the information generated from the clock is sufficient to develop a causal trace for debugging. We post-process and parse the clocks generated from an execution trace to develop a swimlane on a web interface, that traces the points of failure of a distributed system. We also provide an API to reuse this concept for any generic distributed system framework.","sentences":["Causality in distributed systems is a concept that has long been explored and numerous approaches have been made to use causality as a way to trace distributed system execution.","Traditional approaches usually used system profiling and newer approaches profiled clocks of systems to detect failures and construct timelines that caused those failures.","Since the advent of logical clocks, these profiles have become more and more accurate with ways to characterize concurrency and distributions, with accurate diagrams for message passing.","Vector clocks addressed the shortcomings of using traditional logical clocks, by storing information about other processes in the system as well.","Hybrid vector clocks are a novel approach to this concept where clocks need not store all the process information.","Rather, we store information of processes within an acceptable skew of the focused process.","This gives us an efficient way of profiling with substantially reduced costs to the system.","Building on this idea, we propose the idea of building causal traces using information generated from the hybrid vector clock.","The hybrid vector clock would provide us with a strong sense of concurrency and distribution, and we theorize that all the information generated from the clock is sufficient to develop a causal trace for debugging.","We post-process and parse the clocks generated from an execution trace to develop a swimlane on a web interface, that traces the points of failure of a distributed system.","We also provide an API to reuse this concept for any generic distributed system framework."],"url":"http://arxiv.org/abs/2311.07535v1"}
{"created":"2023-11-13 18:21:33","title":"Unsupervised Musical Object Discovery from Audio","abstract":"Current object-centric learning models such as the popular SlotAttention architecture allow for unsupervised visual scene decomposition. Our novel MusicSlots method adapts SlotAttention to the audio domain, to achieve unsupervised music decomposition. Since concepts of opacity and occlusion in vision have no auditory analogues, the softmax normalization of alpha masks in the decoders of visual object-centric models is not well-suited for decomposing audio objects. MusicSlots overcomes this problem. We introduce a spectrogram-based multi-object music dataset tailored to evaluate object-centric learning on western tonal music. MusicSlots achieves good performance on unsupervised note discovery and outperforms several established baselines on supervised note property prediction tasks.","sentences":["Current object-centric learning models such as the popular SlotAttention architecture allow for unsupervised visual scene decomposition.","Our novel MusicSlots method adapts SlotAttention to the audio domain, to achieve unsupervised music decomposition.","Since concepts of opacity and occlusion in vision have no auditory analogues, the softmax normalization of alpha masks in the decoders of visual object-centric models is not well-suited for decomposing audio objects.","MusicSlots overcomes this problem.","We introduce a spectrogram-based multi-object music dataset tailored to evaluate object-centric learning on western tonal music.","MusicSlots achieves good performance on unsupervised note discovery and outperforms several established baselines on supervised note property prediction tasks."],"url":"http://arxiv.org/abs/2311.07534v1"}
{"created":"2023-11-13 18:18:22","title":"It's Not Easy Being Wrong: Evaluating Process of Elimination Reasoning in Large Language Models","abstract":"Chain-of-thought (COT) prompting can help large language models (LLMs) reason toward correct answers, but its efficacy in reasoning toward incorrect answers is unexplored. This strategy of process of elimination (PoE), when used with COT, has the potential to enhance interpretability in tasks like medical diagnoses of exclusion. Thus, we propose PoE with COT, a new task where LLMs must reason toward incorrect options on multiple-choice questions. We evaluate the ability of GPT-3.5, LLaMA-2, and Falcon to perform PoE with COT on 2-choice commonsense and scientific reasoning datasets. We show that PoE consistently underperforms directly choosing the correct answer. The agreement of these strategies is also lower than the self-consistency of each strategy. To study these issues further, we conduct an error analysis and give suggestions for future work.","sentences":["Chain-of-thought (COT) prompting can help large language models (LLMs) reason toward correct answers, but its efficacy in reasoning toward incorrect answers is unexplored.","This strategy of process of elimination (PoE), when used with COT, has the potential to enhance interpretability in tasks like medical diagnoses of exclusion.","Thus, we propose PoE with COT, a new task where LLMs must reason toward incorrect options on multiple-choice questions.","We evaluate the ability of GPT-3.5, LLaMA-2, and Falcon to perform PoE with COT on 2-choice commonsense and scientific reasoning datasets.","We show that PoE consistently underperforms directly choosing the correct answer.","The agreement of these strategies is also lower than the self-consistency of each strategy.","To study these issues further, we conduct an error analysis and give suggestions for future work."],"url":"http://arxiv.org/abs/2311.07532v1"}
{"created":"2023-11-13 17:56:54","title":"VGSG: Vision-Guided Semantic-Group Network for Text-based Person Search","abstract":"Text-based Person Search (TBPS) aims to retrieve images of target pedestrian indicated by textual descriptions. It is essential for TBPS to extract fine-grained local features and align them crossing modality. Existing methods utilize external tools or heavy cross-modal interaction to achieve explicit alignment of cross-modal fine-grained features, which is inefficient and time-consuming. In this work, we propose a Vision-Guided Semantic-Group Network (VGSG) for text-based person search to extract well-aligned fine-grained visual and textual features. In the proposed VGSG, we develop a Semantic-Group Textual Learning (SGTL) module and a Vision-guided Knowledge Transfer (VGKT) module to extract textual local features under the guidance of visual local clues. In SGTL, in order to obtain the local textual representation, we group textual features from the channel dimension based on the semantic cues of language expression, which encourages similar semantic patterns to be grouped implicitly without external tools. In VGKT, a vision-guided attention is employed to extract visual-related textual features, which are inherently aligned with visual cues and termed vision-guided textual features. Furthermore, we design a relational knowledge transfer, including a vision-language similarity transfer and a class probability transfer, to adaptively propagate information of the vision-guided textual features to semantic-group textual features. With the help of relational knowledge transfer, VGKT is capable of aligning semantic-group textual features with corresponding visual features without external tools and complex pairwise interaction. Experimental results on two challenging benchmarks demonstrate its superiority over state-of-the-art methods.","sentences":["Text-based Person Search (TBPS) aims to retrieve images of target pedestrian indicated by textual descriptions.","It is essential for TBPS to extract fine-grained local features and align them crossing modality.","Existing methods utilize external tools or heavy cross-modal interaction to achieve explicit alignment of cross-modal fine-grained features, which is inefficient and time-consuming.","In this work, we propose a Vision-Guided Semantic-Group Network (VGSG) for text-based person search to extract well-aligned fine-grained visual and textual features.","In the proposed VGSG, we develop a Semantic-Group Textual Learning (SGTL) module and a Vision-guided Knowledge Transfer (VGKT) module to extract textual local features under the guidance of visual local clues.","In SGTL, in order to obtain the local textual representation, we group textual features from the channel dimension based on the semantic cues of language expression, which encourages similar semantic patterns to be grouped implicitly without external tools.","In VGKT, a vision-guided attention is employed to extract visual-related textual features, which are inherently aligned with visual cues and termed vision-guided textual features.","Furthermore, we design a relational knowledge transfer, including a vision-language similarity transfer and a class probability transfer, to adaptively propagate information of the vision-guided textual features to semantic-group textual features.","With the help of relational knowledge transfer, VGKT is capable of aligning semantic-group textual features with corresponding visual features without external tools and complex pairwise interaction.","Experimental results on two challenging benchmarks demonstrate its superiority over state-of-the-art methods."],"url":"http://arxiv.org/abs/2311.07514v1"}
{"created":"2023-11-13 17:55:07","title":"Explicit Foundation Model Optimization with Self-Attentive Feed-Forward Neural Units","abstract":"Iterative approximation methods using backpropagation enable the optimization of neural networks, but they remain computationally expensive, especially when used at scale. This paper presents an efficient alternative for optimizing neural networks that reduces the costs of scaling neural networks and provides high-efficiency optimizations for low-resource applications. We will discuss a general result about feed-forward neural networks and then extend this solution to compositional (mult-layer) networks, which are applied to a simplified transformer block containing feed-forward and self-attention layers. These models are used to train highly-specified and complex multi-layer neural architectures that we refer to as self-attentive feed-forward unit (SAFFU) layers, which we use to develop a transformer that appears to generalize well over small, cognitively-feasible, volumes of data. Testing demonstrates explicit solutions outperform models optimized by backpropagation alone. Moreover, further application of backpropagation after explicit solutions leads to better optima from smaller scales of data, training effective models from much less data is enabled by explicit solution warm starts. We then carry out ablation experiments training a roadmap of about 250 transformer models over 1-million tokens to determine ideal settings. We find that multiple different architectural variants produce highly-performant models, and discover from this ablation that some of the best are not the most parameterized. This appears to indicate well-generalized models could be reached using less data by using explicit solutions, and that architectural exploration using explicit solutions pays dividends in guiding the search for efficient variants with fewer parameters, and which could be incorporated into low-resource hardware where AI might be embodied.","sentences":["Iterative approximation methods using backpropagation enable the optimization of neural networks, but they remain computationally expensive, especially when used at scale.","This paper presents an efficient alternative for optimizing neural networks that reduces the costs of scaling neural networks and provides high-efficiency optimizations for low-resource applications.","We will discuss a general result about feed-forward neural networks and then extend this solution to compositional (mult-layer) networks, which are applied to a simplified transformer block containing feed-forward and self-attention layers.","These models are used to train highly-specified and complex multi-layer neural architectures that we refer to as self-attentive feed-forward unit (SAFFU) layers, which we use to develop a transformer that appears to generalize well over small, cognitively-feasible, volumes of data.","Testing demonstrates explicit solutions outperform models optimized by backpropagation alone.","Moreover, further application of backpropagation after explicit solutions leads to better optima from smaller scales of data, training effective models from much less data is enabled by explicit solution warm starts.","We then carry out ablation experiments training a roadmap of about 250 transformer models over 1-million tokens to determine ideal settings.","We find that multiple different architectural variants produce highly-performant models, and discover from this ablation that some of the best are not the most parameterized.","This appears to indicate well-generalized models could be reached using less data by using explicit solutions, and that architectural exploration using explicit solutions pays dividends in guiding the search for efficient variants with fewer parameters, and which could be incorporated into low-resource hardware where AI might be embodied."],"url":"http://arxiv.org/abs/2311.07510v1"}
{"created":"2023-11-13 17:54:50","title":"A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model's Accuracy for Question Answering on Enterprise SQL Databases","abstract":"Enterprise applications of Large Language Models (LLMs) hold promise for question answering on enterprise SQL databases. However, the extent to which LLMs can accurately respond to enterprise questions in such databases remains unclear, given the absence of suitable Text-to-SQL benchmarks tailored to enterprise settings. Additionally, the potential of Knowledge Graphs (KGs) to enhance LLM-based question answering by providing business context is not well understood. This study aims to evaluate the accuracy of LLM-powered question answering systems in the context of enterprise questions and SQL databases, while also exploring the role of knowledge graphs in improving accuracy. To achieve this, we introduce a benchmark comprising an enterprise SQL schema in the insurance domain, a range of enterprise queries encompassing reporting to metrics, and a contextual layer incorporating an ontology and mappings that define a knowledge graph. Our primary finding reveals that question answering using GPT-4, with zero-shot prompts directly on SQL databases, achieves an accuracy of 16%. Notably, this accuracy increases to 54% when questions are posed over a Knowledge Graph representation of the enterprise SQL database. Therefore, investing in Knowledge Graph provides higher accuracy for LLM powered question answering systems.","sentences":["Enterprise applications of Large Language Models (LLMs) hold promise for question answering on enterprise SQL databases.","However, the extent to which LLMs can accurately respond to enterprise questions in such databases remains unclear, given the absence of suitable Text-to-SQL benchmarks tailored to enterprise settings.","Additionally, the potential of Knowledge Graphs (KGs) to enhance LLM-based question answering by providing business context is not well understood.","This study aims to evaluate the accuracy of LLM-powered question answering systems in the context of enterprise questions and SQL databases, while also exploring the role of knowledge graphs in improving accuracy.","To achieve this, we introduce a benchmark comprising an enterprise SQL schema in the insurance domain, a range of enterprise queries encompassing reporting to metrics, and a contextual layer incorporating an ontology and mappings that define a knowledge graph.","Our primary finding reveals that question answering using GPT-4, with zero-shot prompts directly on SQL databases, achieves an accuracy of 16%.","Notably, this accuracy increases to 54% when questions are posed over a Knowledge Graph representation of the enterprise SQL database.","Therefore, investing in Knowledge Graph provides higher accuracy for LLM powered question answering systems."],"url":"http://arxiv.org/abs/2311.07509v1"}
{"created":"2023-11-13 17:45:28","title":"STEM Rebalance: A Novel Approach for Tackling Imbalanced Datasets using SMOTE, Edited Nearest Neighbour, and Mixup","abstract":"Imbalanced datasets in medical imaging are characterized by skewed class proportions and scarcity of abnormal cases. When trained using such data, models tend to assign higher probabilities to normal cases, leading to biased performance. Common oversampling techniques such as SMOTE rely on local information and can introduce marginalization issues. This paper investigates the potential of using Mixup augmentation that combines two training examples along with their corresponding labels to generate new data points as a generic vicinal distribution. To this end, we propose STEM, which combines SMOTE-ENN and Mixup at the instance level. This integration enables us to effectively leverage the entire distribution of minority classes, thereby mitigating both between-class and within-class imbalances. We focus on the breast cancer problem, where imbalanced datasets are prevalent. The results demonstrate the effectiveness of STEM, which achieves AUC values of 0.96 and 0.99 in the Digital Database for Screening Mammography and Wisconsin Breast Cancer (Diagnostics) datasets, respectively. Moreover, this method shows promising potential when applied with an ensemble of machine learning (ML) classifiers.","sentences":["Imbalanced datasets in medical imaging are characterized by skewed class proportions and scarcity of abnormal cases.","When trained using such data, models tend to assign higher probabilities to normal cases, leading to biased performance.","Common oversampling techniques such as SMOTE rely on local information and can introduce marginalization issues.","This paper investigates the potential of using Mixup augmentation that combines two training examples along with their corresponding labels to generate new data points as a generic vicinal distribution.","To this end, we propose STEM, which combines SMOTE-ENN and Mixup at the instance level.","This integration enables us to effectively leverage the entire distribution of minority classes, thereby mitigating both between-class and within-class imbalances.","We focus on the breast cancer problem, where imbalanced datasets are prevalent.","The results demonstrate the effectiveness of STEM, which achieves AUC values of 0.96 and 0.99 in the Digital Database for Screening Mammography and Wisconsin Breast Cancer (Diagnostics) datasets, respectively.","Moreover, this method shows promising potential when applied with an ensemble of machine learning (ML) classifiers."],"url":"http://arxiv.org/abs/2311.07504v1"}
{"created":"2023-11-13 17:44:24","title":"ARWalker: A Virtual Walking Companion Application","abstract":"Extended Reality (XR) technologies, including Augmented Reality (AR), have attracted significant attention over the past few years and have been utilized in several fields, including education, healthcare, and manufacturing. In this paper, we aim to explore the use of AR in the field of biomechanics and human movement through the development of ARWalker, which is an AR application that features virtual walking companions (avatars). Research participants walk in close synchrony with the virtual companions, whose gait exhibits properties found in the gait of young and healthy adults. As a result, research participants can train their gait to the gait of the avatar, thus regaining the healthy properties of their gait and reducing the risk of falls. ARWalker can especially help older adults and individuals with diseases, who exhibit pathological gait thus being more prone to falls. We implement a prototype of ARWalker and evaluate its systems performance while running on a Microsoft Hololens 2 headset.","sentences":["Extended Reality (XR) technologies, including Augmented Reality (AR), have attracted significant attention over the past few years and have been utilized in several fields, including education, healthcare, and manufacturing.","In this paper, we aim to explore the use of AR in the field of biomechanics and human movement through the development of ARWalker, which is an AR application that features virtual walking companions (avatars).","Research participants walk in close synchrony with the virtual companions, whose gait exhibits properties found in the gait of young and healthy adults.","As a result, research participants can train their gait to the gait of the avatar, thus regaining the healthy properties of their gait and reducing the risk of falls.","ARWalker can especially help older adults and individuals with diseases, who exhibit pathological gait thus being more prone to falls.","We implement a prototype of ARWalker and evaluate its systems performance while running on a Microsoft Hololens 2 headset."],"url":"http://arxiv.org/abs/2311.07502v1"}
{"created":"2023-11-13 17:40:34","title":"Bridging the Sim-to-Real Gap with Dynamic Compliance Tuning for Industrial Insertion","abstract":"Contact-rich manipulation tasks often exhibit a large sim-to-real gap. For instance, industrial assembly tasks frequently involve tight insertions where the clearance is less than \\(0.1\\) mm and can even be negative when dealing with a deformable receptacle. This narrow clearance leads to complex contact dynamics that are difficult to model accurately in simulation, making it challenging to transfer simulation-learned policies to real-world robots. In this paper, we propose a novel framework for robustly learning manipulation skills for real-world tasks using only the simulated data. Our framework consists of two main components: the ``Force Planner'' and the ``Gain Tuner''. The Force Planner is responsible for planning both the robot motion and desired contact forces, while the Gain Tuner dynamically adjusts the compliance control gains to accurately track the desired contact forces during task execution. The key insight of this work is that by adaptively adjusting the robot's compliance control gains during task execution, we can modulate contact forces in the new environment, thereby generating trajectories similar to those trained in simulation and narrows the sim-to-real gap. Experimental results show that our method, trained in simulation on a generic square peg-and-hole task, can generalize to a variety of real-world insertion tasks involving narrow or even negative clearances, all without requiring any fine-tuning.","sentences":["Contact-rich manipulation tasks often exhibit a large sim-to-real gap.","For instance, industrial assembly tasks frequently involve tight insertions where the clearance is less than \\(0.1\\) mm and can even be negative when dealing with a deformable receptacle.","This narrow clearance leads to complex contact dynamics that are difficult to model accurately in simulation, making it challenging to transfer simulation-learned policies to real-world robots.","In this paper, we propose a novel framework for robustly learning manipulation skills for real-world tasks using only the simulated data.","Our framework consists of two main components: the ``Force Planner'' and the ``Gain Tuner''.","The Force Planner is responsible for planning both the robot motion and desired contact forces, while the Gain Tuner dynamically adjusts the compliance control gains to accurately track the desired contact forces during task execution.","The key insight of this work is that by adaptively adjusting the robot's compliance control gains during task execution, we can modulate contact forces in the new environment, thereby generating trajectories similar to those trained in simulation and narrows the sim-to-real gap.","Experimental results show that our method, trained in simulation on a generic square peg-and-hole task, can generalize to a variety of real-world insertion tasks involving narrow or even negative clearances, all without requiring any fine-tuning."],"url":"http://arxiv.org/abs/2311.07499v1"}
{"created":"2023-11-13 17:38:07","title":"Reducing the Need for Backpropagation and Discovering Better Optima With Explicit Optimizations of Neural Networks","abstract":"Iterative differential approximation methods that rely upon backpropagation have enabled the optimization of neural networks; however, at present, they remain computationally expensive, especially when training models at scale. In this paper, we propose a computationally efficient alternative for optimizing neural networks that can both reduce the costs of scaling neural networks and provide high-efficiency optimizations for low-resource applications. We derive an explicit solution to a simple feed-forward language model (LM) by mathematically analyzing its gradients. This solution generalizes from single-layer LMs to the class of all single-layer feed-forward softmax-activated neural models trained on positive-valued features, as is demonstrated by our extension of this solution application to MNIST digit classification. For both LM and digit classifiers, we find computationally that explicit solutions perform near-optimality in experiments showing that 1) iterative optimization only marginally improves the explicit solution parameters and 2) randomly initialized parameters iteratively optimize towards the explicit solution. We also preliminarily apply the explicit solution locally by layer in multi-layer networks and discuss how the solution's computational savings increase with model complexity -- for both single- and mult-layer applications of the explicit solution, we emphasize that the optima achieved cannot be reached by backpropagation alone, i.e., better optima appear discoverable only after explicit solutions are applied. Finally, we discuss the solution's computational savings alongside its impact on model interpretability and suggest future directions for the derivation of explicit solutions to complex- and multi-layer architectures.","sentences":["Iterative differential approximation methods that rely upon backpropagation have enabled the optimization of neural networks; however, at present, they remain computationally expensive, especially when training models at scale.","In this paper, we propose a computationally efficient alternative for optimizing neural networks that can both reduce the costs of scaling neural networks and provide high-efficiency optimizations for low-resource applications.","We derive an explicit solution to a simple feed-forward language model (LM) by mathematically analyzing its gradients.","This solution generalizes from single-layer LMs to the class of all single-layer feed-forward softmax-activated neural models trained on positive-valued features, as is demonstrated by our extension of this solution application to MNIST digit classification.","For both LM and digit classifiers, we find computationally that explicit solutions perform near-optimality in experiments showing that 1) iterative optimization only marginally improves the explicit solution parameters and 2) randomly initialized parameters iteratively optimize towards the explicit solution.","We also preliminarily apply the explicit solution locally by layer in multi-layer networks and discuss how the solution's computational savings increase with model complexity -- for both single- and mult-layer applications of the explicit solution, we emphasize that the optima achieved cannot be reached by backpropagation alone, i.e., better optima appear discoverable only after explicit solutions are applied.","Finally, we discuss the solution's computational savings alongside its impact on model interpretability and suggest future directions for the derivation of explicit solutions to complex- and multi-layer architectures."],"url":"http://arxiv.org/abs/2311.07498v1"}
{"created":"2023-11-13 17:36:58","title":"Multilingual Nonce Dependency Treebanks: Understanding how LLMs represent and process syntactic structure","abstract":"We introduce SPUD (Semantically Perturbed Universal Dependencies), a framework for creating nonce treebanks for the multilingual Universal Dependencies (UD) corpora. SPUD data satisfies syntactic argument structure, provides syntactic annotations, and ensures grammaticality via language-specific rules. We create nonce data in Arabic, English, French, German, and Russian, and demonstrate two use cases of SPUD treebanks. First, we investigate the effect of nonce data on word co-occurrence statistics, as measured by perplexity scores of autoregressive (ALM) and masked language models (MLM). We find that ALM scores are significantly more affected by nonce data than MLM scores. Second, we show how nonce data affects the performance of syntactic dependency probes. We replicate the findings of M\\\"uller-Eberstein et al. (2022) on nonce test data and show that the performance declines on both MLMs and ALMs wrt. original test data. However, a majority of the performance is kept, suggesting that the probe indeed learns syntax independently from semantics.","sentences":["We introduce SPUD (Semantically Perturbed Universal Dependencies), a framework for creating nonce treebanks for the multilingual Universal Dependencies (UD) corpora.","SPUD data satisfies syntactic argument structure, provides syntactic annotations, and ensures grammaticality via language-specific rules.","We create nonce data in Arabic, English, French, German, and Russian, and demonstrate two use cases of SPUD treebanks.","First, we investigate the effect of nonce data on word co-occurrence statistics, as measured by perplexity scores of autoregressive (ALM) and masked language models (MLM).","We find that ALM scores are significantly more affected by nonce data than MLM scores.","Second, we show how nonce data affects the performance of syntactic dependency probes.","We replicate the findings of M\\\"uller-Eberstein et al. (2022) on nonce test data and show that the performance declines on both MLMs and ALMs wrt. original test data.","However, a majority of the performance is kept, suggesting that the probe indeed learns syntax independently from semantics."],"url":"http://arxiv.org/abs/2311.07497v1"}
{"created":"2023-11-13 17:34:23","title":"The Last Decade in Review: Tracing the Evolution of Safety Assurance Cases through a Comprehensive Bibliometric Analysis","abstract":"Safety assurance is of paramount importance across various domains, including automotive, aerospace, and nuclear energy, where the reliability and acceptability of mission-critical systems are imperative. This assurance is effectively realized through the utilization of Safety Assurance Cases. The use of safety assurance cases allows for verifying the correctness of the created systems capabilities, preventing system failure. The latter may result in loss of life, severe injuries, large-scale environmental damage, property destruction, and major economic loss. Still, the emergence of complex technologies such as cyber-physical systems (CPSs), characterized by their heterogeneity, autonomy, machine learning capabilities, and the uncertainty of their operational environments poses significant challenges for safety assurance activities. Several papers have tried to propose solutions to tackle these challenges, but to the best of our knowledge, no secondary study investigates the trends, patterns, and relationships characterizing the safety case scientific literature. This makes it difficult to have a holistic view of the safety case landscape and to identify the most promising future research directions. In this paper, we, therefore, rely on state-of-the-art bibliometric tools(e.g., VosViewer) to conduct a bibliometric analysis that allows us to generate valuable insights, identify key authors and venues, and gain a birds eye view of the current state of research in the safety assurance area. By revealing knowledge gaps and highlighting potential avenues for future research, our analysis provides an essential foundation for researchers, corporate safety analysts, and regulators seeking to embrace or enhance safety practices that align with their specific needs and objectives.","sentences":["Safety assurance is of paramount importance across various domains, including automotive, aerospace, and nuclear energy, where the reliability and acceptability of mission-critical systems are imperative.","This assurance is effectively realized through the utilization of Safety Assurance Cases.","The use of safety assurance cases allows for verifying the correctness of the created systems capabilities, preventing system failure.","The latter may result in loss of life, severe injuries, large-scale environmental damage, property destruction, and major economic loss.","Still, the emergence of complex technologies such as cyber-physical systems (CPSs), characterized by their heterogeneity, autonomy, machine learning capabilities, and the uncertainty of their operational environments poses significant challenges for safety assurance activities.","Several papers have tried to propose solutions to tackle these challenges, but to the best of our knowledge, no secondary study investigates the trends, patterns, and relationships characterizing the safety case scientific literature.","This makes it difficult to have a holistic view of the safety case landscape and to identify the most promising future research directions.","In this paper, we, therefore, rely on state-of-the-art bibliometric tools(e.g., VosViewer) to conduct a bibliometric analysis that allows us to generate valuable insights, identify key authors and venues, and gain a birds eye view of the current state of research in the safety assurance area.","By revealing knowledge gaps and highlighting potential avenues for future research, our analysis provides an essential foundation for researchers, corporate safety analysts, and regulators seeking to embrace or enhance safety practices that align with their specific needs and objectives."],"url":"http://arxiv.org/abs/2311.07495v1"}
{"created":"2023-11-13 17:29:07","title":"Ara2: Exploring Single- and Multi-Core Vector Processing with an Efficient RVV1.0 Compliant Open-Source Processor","abstract":"Vector processing is highly effective in boosting processor performance and efficiency for data-parallel workloads. In this paper, we present Ara2, the first fully open-source vector processor to support the RISC-V V 1.0 frozen ISA. We evaluate Ara2's performance on a diverse set of data-parallel kernels for various problem sizes and vector-unit configurations, achieving an average functional-unit utilization of 95% on the most computationally intensive kernels. We pinpoint performance boosters and bottlenecks, including the scalar core, memories, and vector architecture, providing insights into the main vector architecture's performance drivers. Leveraging the openness of the design, we implement Ara2 in a 22nm technology, characterize its PPA metrics on various configurations (2-16 lanes), and analyze its microarchitecture and implementation bottlenecks. Ara2 achieves a state-of-the-art energy efficiency of 37.8 DP-GFLOPS/W (0.8V) and 1.35GHz of clock frequency (critical path: ~40 FO4 gates). Finally, we explore the performance and energy-efficiency trade-offs of multi-core vector processors: we find that multiple vector cores help overcome the scalar core issue-rate bound that limits short-vector performance. For example, a cluster of eight 2-lane Ara2 (16 FPUs) achieves more than 3x better performance than a 16-lane single-core Ara2 (16 FPUs) when executing a 32x32x32 matrix multiplication, with 1.5x improved energy efficiency.","sentences":["Vector processing is highly effective in boosting processor performance and efficiency for data-parallel workloads.","In this paper, we present Ara2, the first fully open-source vector processor to support the RISC-V V 1.0 frozen ISA.","We evaluate Ara2's performance on a diverse set of data-parallel kernels for various problem sizes and vector-unit configurations, achieving an average functional-unit utilization of 95% on the most computationally intensive kernels.","We pinpoint performance boosters and bottlenecks, including the scalar core, memories, and vector architecture, providing insights into the main vector architecture's performance drivers.","Leveraging the openness of the design, we implement Ara2 in a 22nm technology, characterize its PPA metrics on various configurations (2-16 lanes), and analyze its microarchitecture and implementation bottlenecks.","Ara2 achieves a state-of-the-art energy efficiency of 37.8 DP-GFLOPS/W (0.8V) and 1.35GHz of clock frequency (critical path: ~40","FO4 gates).","Finally, we explore the performance and energy-efficiency trade-offs of multi-core vector processors: we find that multiple vector cores help overcome the scalar core issue-rate bound that limits short-vector performance.","For example, a cluster of eight 2-lane Ara2 (16 FPUs) achieves more than 3x better performance than a 16-lane single-core Ara2 (16 FPUs) when executing a 32x32x32 matrix multiplication, with 1.5x improved energy efficiency."],"url":"http://arxiv.org/abs/2311.07493v1"}
{"created":"2023-11-13 17:28:57","title":"How Physicality Enables Trust: A New Era of Trust-Centered Cyberphysical Systems","abstract":"Multi-agent cyberphysical systems enable new capabilities in efficiency, resilience, and security. The unique characteristics of these systems prompt a reevaluation of their security concepts, including their vulnerabilities, and mechanisms to mitigate these vulnerabilities. This survey paper examines how advancement in wireless networking, coupled with the sensing and computing in cyberphysical systems, can foster novel security capabilities. This study delves into three main themes related to securing multi-agent cyberphysical systems. First, we discuss the threats that are particularly relevant to multi-agent cyberphysical systems given the potential lack of trust between agents. Second, we present prospects for sensing, contextual awareness, and authentication, enabling the inference and measurement of ``inter-agent trust\" for these systems. Third, we elaborate on the application of quantifiable trust notions to enable ``resilient coordination,\" where ``resilient\" signifies sustained functionality amid attacks on multiagent cyberphysical systems. We refer to the capability of cyberphysical systems to self-organize, and coordinate to achieve a task as autonomy. This survey unveils the cyberphysical character of future interconnected systems as a pivotal catalyst for realizing robust, trust-centered autonomy in tomorrow's world.","sentences":["Multi-agent cyberphysical systems enable new capabilities in efficiency, resilience, and security.","The unique characteristics of these systems prompt a reevaluation of their security concepts, including their vulnerabilities, and mechanisms to mitigate these vulnerabilities.","This survey paper examines how advancement in wireless networking, coupled with the sensing and computing in cyberphysical systems, can foster novel security capabilities.","This study delves into three main themes related to securing multi-agent cyberphysical systems.","First, we discuss the threats that are particularly relevant to multi-agent cyberphysical systems given the potential lack of trust between agents.","Second, we present prospects for sensing, contextual awareness, and authentication, enabling the inference and measurement of ``inter-agent trust\" for these systems.","Third, we elaborate on the application of quantifiable trust notions to enable ``resilient coordination,\" where ``resilient\" signifies sustained functionality amid attacks on multiagent cyberphysical systems.","We refer to the capability of cyberphysical systems to self-organize, and coordinate to achieve a task as autonomy.","This survey unveils the cyberphysical character of future interconnected systems as a pivotal catalyst for realizing robust, trust-centered autonomy in tomorrow's world."],"url":"http://arxiv.org/abs/2311.07492v1"}
{"created":"2023-11-13 17:28:03","title":"A Step Closer to Comprehensive Answers: Constrained Multi-Stage Question Decomposition with Large Language Models","abstract":"While large language models exhibit remarkable performance in the Question Answering task, they are susceptible to hallucinations. Challenges arise when these models grapple with understanding multi-hop relations in complex questions or lack the necessary knowledge for a comprehensive response. To address this issue, we introduce the \"Decompose-and-Query\" framework (D&Q). This framework guides the model to think and utilize external knowledge similar to ReAct, while also restricting its thinking to reliable information, effectively mitigating the risk of hallucinations. Experiments confirm the effectiveness of D&Q: On our ChitChatQA dataset, D&Q does not lose to ChatGPT in 67% of cases; on the HotPotQA question-only setting, D&Q achieved an F1 score of 59.6%. Our code is available at https://github.com/alkaidpku/DQ-ToolQA.","sentences":["While large language models exhibit remarkable performance in the Question Answering task, they are susceptible to hallucinations.","Challenges arise when these models grapple with understanding multi-hop relations in complex questions or lack the necessary knowledge for a comprehensive response.","To address this issue, we introduce the \"Decompose-and-Query\" framework (D&Q).","This framework guides the model to think and utilize external knowledge similar to ReAct, while also restricting its thinking to reliable information, effectively mitigating the risk of hallucinations.","Experiments confirm the effectiveness of D&Q: On our ChitChatQA dataset, D&Q does not lose to ChatGPT in 67% of cases; on the HotPotQA question-only setting, D&Q achieved an F1 score of 59.6%.","Our code is available at https://github.com/alkaidpku/DQ-ToolQA."],"url":"http://arxiv.org/abs/2311.07491v1"}
{"created":"2023-11-13 17:28:01","title":"A Guide to Evaluating the Experience of Media and Arts Technology","abstract":"Evaluation is essential to understanding the value that digital creativity brings to people's experience, for example in terms of their enjoyment, creativity, and engagement. There is a substantial body of research on how to design and evaluate interactive arts and digital creativity applications. There is also extensive Human-Computer Interaction (HCI) literature on how to evaluate user interfaces and user experiences. However, it can be difficult for artists, practitioners, and researchers to navigate such a broad and disparate collection of materials when considering how to evaluate technology they create that is at the intersection of art and interaction. This chapter provides a guide to designing robust user studies of creative applications at the intersection of art, technology and interaction, which we refer to as Media and Arts Technology (MAT). We break MAT studies down into two main kinds: proof-of-concept and comparative studies. As MAT studies are exploratory in nature, their evaluation requires the collection and analysis of both qualitative data such as free text questionnaire responses, interviews, and observations, and also quantitative data such as questionnaires, number of interactions, and length of time spent interacting. This chapter draws on over 15 years of experience of designing and evaluating novel interactive systems to provide a concrete template on how to structure a study to evaluate MATs that is both rigorous and repeatable, and how to report study results that are publishable and accessible to a wide readership in art and science communities alike.","sentences":["Evaluation is essential to understanding the value that digital creativity brings to people's experience, for example in terms of their enjoyment, creativity, and engagement.","There is a substantial body of research on how to design and evaluate interactive arts and digital creativity applications.","There is also extensive Human-Computer Interaction (HCI) literature on how to evaluate user interfaces and user experiences.","However, it can be difficult for artists, practitioners, and researchers to navigate such a broad and disparate collection of materials when considering how to evaluate technology they create that is at the intersection of art and interaction.","This chapter provides a guide to designing robust user studies of creative applications at the intersection of art, technology and interaction, which we refer to as Media and Arts Technology (MAT).","We break MAT studies down into two main kinds: proof-of-concept and comparative studies.","As MAT studies are exploratory in nature, their evaluation requires the collection and analysis of both qualitative data such as free text questionnaire responses, interviews, and observations, and also quantitative data such as questionnaires, number of interactions, and length of time spent interacting.","This chapter draws on over 15 years of experience of designing and evaluating novel interactive systems to provide a concrete template on how to structure a study to evaluate MATs that is both rigorous and repeatable, and how to report study results that are publishable and accessible to a wide readership in art and science communities alike."],"url":"http://arxiv.org/abs/2311.07490v1"}
{"created":"2023-11-13 17:25:06","title":"EvoFed: Leveraging Evolutionary Strategies for Communication-Efficient Federated Learning","abstract":"Federated Learning (FL) is a decentralized machine learning paradigm that enables collaborative model training across dispersed nodes without having to force individual nodes to share data. However, its broad adoption is hindered by the high communication costs of transmitting a large number of model parameters. This paper presents EvoFed, a novel approach that integrates Evolutionary Strategies (ES) with FL to address these challenges. EvoFed employs a concept of 'fitness-based information sharing', deviating significantly from the conventional model-based FL. Rather than exchanging the actual updated model parameters, each node transmits a distance-based similarity measure between the locally updated model and each member of the noise-perturbed model population. Each node, as well as the server, generates an identical population set of perturbed models in a completely synchronized fashion using the same random seeds. With properly chosen noise variance and population size, perturbed models can be combined to closely reflect the actual model updated using the local dataset, allowing the transmitted similarity measures (or fitness values) to carry nearly the complete information about the model parameters. As the population size is typically much smaller than the number of model parameters, the savings in communication load is large. The server aggregates these fitness values and is able to update the global model. This global fitness vector is then disseminated back to the nodes, each of which applies the same update to be synchronized to the global model. Our analysis shows that EvoFed converges, and our experimental results validate that at the cost of increased local processing loads, EvoFed achieves performance comparable to FedAvg while reducing overall communication requirements drastically in various practical settings.","sentences":["Federated Learning (FL) is a decentralized machine learning paradigm that enables collaborative model training across dispersed nodes without having to force individual nodes to share data.","However, its broad adoption is hindered by the high communication costs of transmitting a large number of model parameters.","This paper presents EvoFed, a novel approach that integrates Evolutionary Strategies (ES) with FL to address these challenges.","EvoFed employs a concept of 'fitness-based information sharing', deviating significantly from the conventional model-based FL.","Rather than exchanging the actual updated model parameters, each node transmits a distance-based similarity measure between the locally updated model and each member of the noise-perturbed model population.","Each node, as well as the server, generates an identical population set of perturbed models in a completely synchronized fashion using the same random seeds.","With properly chosen noise variance and population size, perturbed models can be combined to closely reflect the actual model updated using the local dataset, allowing the transmitted similarity measures (or fitness values) to carry nearly the complete information about the model parameters.","As the population size is typically much smaller than the number of model parameters, the savings in communication load is large.","The server aggregates these fitness values and is able to update the global model.","This global fitness vector is then disseminated back to the nodes, each of which applies the same update to be synchronized to the global model.","Our analysis shows that EvoFed converges, and our experimental results validate that at the cost of increased local processing loads, EvoFed achieves performance comparable to FedAvg while reducing overall communication requirements drastically in various practical settings."],"url":"http://arxiv.org/abs/2311.07485v1"}
{"created":"2023-11-13 17:19:14","title":"Psychometric Predictive Power of Large Language Models","abstract":"Next-word probabilities from language models have been shown to successfully simulate human reading behavior. Building on this, we show that, interestingly, instruction-tuned large language models (LLMs) yield worse psychometric predictive power (PPP) for human reading behavior than base LLMs with equivalent perplexities. In other words, instruction tuning, which helps LLMs provide human-preferred responses, does not always make them human-like from the computational psycholinguistics perspective. In addition, we explore prompting methodologies in simulating human reading behavior with LLMs, showing that prompts reflecting a particular linguistic hypothesis lead LLMs to exhibit better PPP but are still worse than base LLMs. These highlight that recent instruction tuning and prompting do not offer better estimates than direct probability measurements from base LLMs in cognitive modeling.","sentences":["Next-word probabilities from language models have been shown to successfully simulate human reading behavior.","Building on this, we show that, interestingly, instruction-tuned large language models (LLMs) yield worse psychometric predictive power (PPP) for human reading behavior than base LLMs with equivalent perplexities.","In other words, instruction tuning, which helps LLMs provide human-preferred responses, does not always make them human-like from the computational psycholinguistics perspective.","In addition, we explore prompting methodologies in simulating human reading behavior with LLMs, showing that prompts reflecting a particular linguistic hypothesis lead LLMs to exhibit better PPP but are still worse than base LLMs.","These highlight that recent instruction tuning and prompting do not offer better estimates than direct probability measurements from base LLMs in cognitive modeling."],"url":"http://arxiv.org/abs/2311.07484v1"}
{"created":"2023-11-13 17:16:25","title":"Quieting the Static: A Study of Static Analysis Alert Suppressions","abstract":"Static analysis tools are commonly used to detect defects before the code is released. Previous research has focused on their overall effectiveness and their ability to detect defects. However, little is known about the usage patterns of warning suppressions: the configurations developers set up in order to prevent the appearance of specific warnings. We address this gap by analyzing how often are warning suppression features used, which warning suppression features are used and for what purpose, and also how could the use of warning suppression annotations be avoided. To answer these questions we examine 1\\,425 open-source Java-based projects that utilize Findbugs or Spotbugs for warning-suppressing configurations and source code annotations. We find that although most warnings are suppressed, only a small portion of them get frequently suppressed. Contrary to expectations, false positives account for a minor proportion of suppressions. A significant number of suppressions introduce technical debt, suggesting potential disregard for code quality or a lack of appropriate guidance from the tool. Misleading suggestions and incorrect assumptions also lead to suppressions. Findings underscore the need for better communication and education related to the use of static analysis tools, improved bug pattern definitions, and better code annotation. Future research can extend these findings to other static analysis tools, and apply them to improve the effectiveness of static analysis.","sentences":["Static analysis tools are commonly used to detect defects before the code is released.","Previous research has focused on their overall effectiveness and their ability to detect defects.","However, little is known about the usage patterns of warning suppressions: the configurations developers set up in order to prevent the appearance of specific warnings.","We address this gap by analyzing how often are warning suppression features used, which warning suppression features are used and for what purpose, and also how could the use of warning suppression annotations be avoided.","To answer these questions we examine 1\\,425 open-source Java-based projects that utilize Findbugs or Spotbugs for warning-suppressing configurations and source code annotations.","We find that although most warnings are suppressed, only a small portion of them get frequently suppressed.","Contrary to expectations, false positives account for a minor proportion of suppressions.","A significant number of suppressions introduce technical debt, suggesting potential disregard for code quality or a lack of appropriate guidance from the tool.","Misleading suggestions and incorrect assumptions also lead to suppressions.","Findings underscore the need for better communication and education related to the use of static analysis tools, improved bug pattern definitions, and better code annotation.","Future research can extend these findings to other static analysis tools, and apply them to improve the effectiveness of static analysis."],"url":"http://arxiv.org/abs/2311.07482v1"}
{"created":"2023-11-13 17:13:34","title":"Qualifying System F-sub","abstract":"Type qualifiers offer a lightweight mechanism for enriching existing type systems to enforce additional, desirable, program invariants. They do so by offering a restricted but effective form of subtyping. While the theory of type qualifiers is well understood and present in many programming languages today, polymorphism over type qualifiers is an area that is less examined. We explore how such a polymorphic system could arise by constructing a calculus System F<:Q which combines the higher-rank bounded polymorphism of System F<: with the theory of type qualifiers. We explore how the ideas used to construct System F<:Q can be reused in situations where type qualifiers naturally arise -- in reference immutability, function colouring, and capture checking. Finally, we re-examine other qualifier systems in the literature in light of the observations presented while developing System F<:Q.","sentences":["Type qualifiers offer a lightweight mechanism for enriching existing type systems to enforce additional, desirable, program invariants.","They do so by offering a restricted but effective form of subtyping.","While the theory of type qualifiers is well understood and present in many programming languages today, polymorphism over type qualifiers is an area that is less examined.","We explore how such a polymorphic system could arise by constructing a calculus System F<:Q which combines the higher-rank bounded polymorphism of System F<: with the theory of type qualifiers.","We explore how the ideas used to construct System F<:Q can be reused in situations where type qualifiers naturally arise -- in reference immutability, function colouring, and capture checking.","Finally, we re-examine other qualifier systems in the literature in light of the observations presented while developing System F<:Q."],"url":"http://arxiv.org/abs/2311.07480v1"}
{"created":"2023-11-13 17:13:13","title":"Towards Robotic Tree Manipulation: Leveraging Graph Representations","abstract":"There is growing interest in automating agricultural tasks that require intricate and precise interaction with specialty crops, such as trees and vines. However, developing robotic solutions for crop manipulation remains a difficult challenge due to complexities involved in modeling their deformable behavior. In this study, we present a framework for learning the deformation behavior of tree-like crops under contact interaction. Our proposed method involves encoding the state of a spring-damper modeled tree crop as a graph. This representation allows us to employ graph networks to learn both a forward model for predicting resulting deformations, and a contact policy for inferring actions to manipulate tree crops. We conduct a comprehensive set of experiments in a simulated environment and demonstrate generalizability of our method on previously unseen trees. Videos can be found on the project website: https://kantor-lab.github.io/tree_gnn","sentences":["There is growing interest in automating agricultural tasks that require intricate and precise interaction with specialty crops, such as trees and vines.","However, developing robotic solutions for crop manipulation remains a difficult challenge due to complexities involved in modeling their deformable behavior.","In this study, we present a framework for learning the deformation behavior of tree-like crops under contact interaction.","Our proposed method involves encoding the state of a spring-damper modeled tree crop as a graph.","This representation allows us to employ graph networks to learn both a forward model for predicting resulting deformations, and a contact policy for inferring actions to manipulate tree crops.","We conduct a comprehensive set of experiments in a simulated environment and demonstrate generalizability of our method on previously unseen trees.","Videos can be found on the project website: https://kantor-lab.github.io/tree_gnn"],"url":"http://arxiv.org/abs/2311.07479v1"}
{"created":"2023-11-13 17:11:35","title":"Temporal Performance Prediction for Deep Convolutional Long Short-Term Memory Networks","abstract":"Quantifying predictive uncertainty of deep semantic segmentation networks is essential in safety-critical tasks. In applications like autonomous driving, where video data is available, convolutional long short-term memory networks are capable of not only providing semantic segmentations but also predicting the segmentations of the next timesteps. These models use cell states to broadcast information from previous data by taking a time series of inputs to predict one or even further steps into the future. We present a temporal postprocessing method which estimates the prediction performance of convolutional long short-term memory networks by either predicting the intersection over union of predicted and ground truth segments or classifying between intersection over union being equal to zero or greater than zero. To this end, we create temporal cell state-based input metrics per segment and investigate different models for the estimation of the predictive quality based on these metrics. We further study the influence of the number of considered cell states for the proposed metrics.","sentences":["Quantifying predictive uncertainty of deep semantic segmentation networks is essential in safety-critical tasks.","In applications like autonomous driving, where video data is available, convolutional long short-term memory networks are capable of not only providing semantic segmentations but also predicting the segmentations of the next timesteps.","These models use cell states to broadcast information from previous data by taking a time series of inputs to predict one or even further steps into the future.","We present a temporal postprocessing method which estimates the prediction performance of convolutional long short-term memory networks by either predicting the intersection over union of predicted and ground truth segments or classifying between intersection over union being equal to zero or greater than zero.","To this end, we create temporal cell state-based input metrics per segment and investigate different models for the estimation of the predictive quality based on these metrics.","We further study the influence of the number of considered cell states for the proposed metrics."],"url":"http://arxiv.org/abs/2311.07477v1"}
{"created":"2023-11-13 17:09:57","title":"Masked Face Dataset Generation and Masked Face Recognition","abstract":"In the post-pandemic era, wearing face masks has posed great challenge to the ordinary face recognition. In the previous study, researchers has applied pretrained VGG16, and ResNet50 to extract features on the elaborate curated existing masked face recognition (MFR) datasets, RMFRD and SMFRD. To make the model more adaptable to the real world situation where the sample size is smaller and the camera environment has greater changes, we created a more challenging masked face dataset ourselves, by selecting 50 identities with 1702 images from Labelled Faces in the Wild (LFW) Dataset, and simulated face masks through key point detection. The another part of our study is to solve the masked face recognition problem, and we chose models by referring to the former state of the art results, instead of directly using pretrained models, we fine tuned the model on our new dataset and use the last linear layer to do the classification directly. Furthermore, we proposed using data augmentation strategy to further increase the test accuracy, and fine tuned a new networks beyond the former study, one of the most SOTA networks, Inception ResNet v1. The best test accuracy on 50 identity MFR has achieved 95%.","sentences":["In the post-pandemic era, wearing face masks has posed great challenge to the ordinary face recognition.","In the previous study, researchers has applied pretrained VGG16, and ResNet50 to extract features on the elaborate curated existing masked face recognition (MFR) datasets, RMFRD and SMFRD.","To make the model more adaptable to the real world situation where the sample size is smaller and the camera environment has greater changes, we created a more challenging masked face dataset ourselves, by selecting 50 identities with 1702 images from Labelled Faces in the Wild (LFW) Dataset, and simulated face masks through key point detection.","The another part of our study is to solve the masked face recognition problem, and we chose models by referring to the former state of the art results, instead of directly using pretrained models, we fine tuned the model on our new dataset and use the last linear layer to do the classification directly.","Furthermore, we proposed using data augmentation strategy to further increase the test accuracy, and fine tuned a new networks beyond the former study, one of the most SOTA networks, Inception ResNet v1.","The best test accuracy on 50 identity MFR has achieved 95%."],"url":"http://arxiv.org/abs/2311.07475v1"}
{"created":"2023-11-13 17:03:02","title":"Finding and Editing Multi-Modal Neurons in Pre-Trained Transformer","abstract":"Multi-modal large language models (LLM) have achieved powerful capabilities for visual semantic understanding in recent years. However, little is known about how LLMs comprehend visual information and interpret different modalities of features. In this paper, we propose a new method for identifying multi-modal neurons in transformer-based multi-modal LLMs. Through a series of experiments, We highlight three critical properties of multi-modal neurons by four well-designed quantitative evaluation metrics. Furthermore, we introduce a knowledge editing method based on the identified multi-modal neurons, for modifying a specific token to another designative token. We hope our findings can inspire further explanatory researches on understanding mechanisms of multi-modal LLMs.","sentences":["Multi-modal large language models (LLM) have achieved powerful capabilities for visual semantic understanding in recent years.","However, little is known about how LLMs comprehend visual information and interpret different modalities of features.","In this paper, we propose a new method for identifying multi-modal neurons in transformer-based multi-modal LLMs.","Through a series of experiments, We highlight three critical properties of multi-modal neurons by four well-designed quantitative evaluation metrics.","Furthermore, we introduce a knowledge editing method based on the identified multi-modal neurons, for modifying a specific token to another designative token.","We hope our findings can inspire further explanatory researches on understanding mechanisms of multi-modal LLMs."],"url":"http://arxiv.org/abs/2311.07470v1"}
{"created":"2023-11-13 17:02:06","title":"InCA: Rethinking In-Car Conversational System Assessment Leveraging Large Language Models","abstract":"The assessment of advanced generative large language models (LLMs) poses a significant challenge, given their heightened complexity in recent developments. Furthermore, evaluating the performance of LLM-based applications in various industries, as indicated by Key Performance Indicators (KPIs), is a complex undertaking. This task necessitates a profound understanding of industry use cases and the anticipated system behavior. Within the context of the automotive industry, existing evaluation metrics prove inadequate for assessing in-car conversational question answering (ConvQA) systems. The unique demands of these systems, where answers may relate to driver or car safety and are confined within the car domain, highlight the limitations of current metrics. To address these challenges, this paper introduces a set of KPIs tailored for evaluating the performance of in-car ConvQA systems, along with datasets specifically designed for these KPIs. A preliminary and comprehensive empirical evaluation substantiates the efficacy of our proposed approach. Furthermore, we investigate the impact of employing varied personas in prompts and found that it enhances the model's capacity to simulate diverse viewpoints in assessments, mirroring how individuals with different backgrounds perceive a topic.","sentences":["The assessment of advanced generative large language models (LLMs) poses a significant challenge, given their heightened complexity in recent developments.","Furthermore, evaluating the performance of LLM-based applications in various industries, as indicated by Key Performance Indicators (KPIs), is a complex undertaking.","This task necessitates a profound understanding of industry use cases and the anticipated system behavior.","Within the context of the automotive industry, existing evaluation metrics prove inadequate for assessing in-car conversational question answering (ConvQA) systems.","The unique demands of these systems, where answers may relate to driver or car safety and are confined within the car domain, highlight the limitations of current metrics.","To address these challenges, this paper introduces a set of KPIs tailored for evaluating the performance of in-car ConvQA systems, along with datasets specifically designed for these KPIs.","A preliminary and comprehensive empirical evaluation substantiates the efficacy of our proposed approach.","Furthermore, we investigate the impact of employing varied personas in prompts and found that it enhances the model's capacity to simulate diverse viewpoints in assessments, mirroring how individuals with different backgrounds perceive a topic."],"url":"http://arxiv.org/abs/2311.07469v1"}
{"created":"2023-11-13 17:01:12","title":"Are We Falling in a Middle-Intelligence Trap? An Analysis and Mitigation of the Reversal Curse","abstract":"Recent studies have highlighted a phenomenon in large language models (LLMs) known as \"the reversal curse,\" in which the order of knowledge entities in the training data biases the models' comprehension. For example, if a model is trained on sentences where entity A consistently appears before entity B, it can respond to queries about A by providing B. However, it may encounter confusion when presented with questions concerning B. We contend that the reversal curse is partially a result of specific model training objectives, particularly evident in the prevalent use of the next-token prediction within most causal language models. For the next-token prediction, models solely focus on a token's preceding context, resulting in a restricted comprehension of the input. In contrast, we illustrate that the GLM, trained using the autoregressive blank infilling objective where tokens to be predicted have access to the entire context, exhibits better resilience against the reversal curse. We propose a novel training method, BIdirectional Casual language modeling Optimization (BICO), designed to mitigate the reversal curse when fine-tuning pretrained causal language models on new data. BICO modifies the causal attention mechanism to function bidirectionally and employs a mask denoising optimization. In the task designed to assess the reversal curse, our approach improves Llama's accuracy from the original 0% to around 70%. We hope that more attention can be focused on exploring and addressing these inherent weaknesses of the current LLMs, in order to achieve a higher level of intelligence.","sentences":["Recent studies have highlighted a phenomenon in large language models (LLMs) known as \"the reversal curse,\" in which the order of knowledge entities in the training data biases the models' comprehension.","For example, if a model is trained on sentences where entity A consistently appears before entity B, it can respond to queries about A by providing B. However, it may encounter confusion when presented with questions concerning B.","We contend that the reversal curse is partially a result of specific model training objectives, particularly evident in the prevalent use of the next-token prediction within most causal language models.","For the next-token prediction, models solely focus on a token's preceding context, resulting in a restricted comprehension of the input.","In contrast, we illustrate that the GLM, trained using the autoregressive blank infilling objective where tokens to be predicted have access to the entire context, exhibits better resilience against the reversal curse.","We propose a novel training method, BIdirectional Casual language modeling Optimization (BICO), designed to mitigate the reversal curse when fine-tuning pretrained causal language models on new data.","BICO modifies the causal attention mechanism to function bidirectionally and employs a mask denoising optimization.","In the task designed to assess the reversal curse, our approach improves Llama's accuracy from the original 0% to around 70%.","We hope that more attention can be focused on exploring and addressing these inherent weaknesses of the current LLMs, in order to achieve a higher level of intelligence."],"url":"http://arxiv.org/abs/2311.07468v1"}
{"created":"2023-11-13 16:53:51","title":"On Measuring Faithfulness of Natural Language Explanations","abstract":"Large language models (LLMs) can explain their own predictions, through post-hoc or Chain-of-Thought (CoT) explanations. However the LLM could make up reasonably sounding explanations that are unfaithful to its underlying reasoning. Recent work has designed tests that aim to judge the faithfulness of either post-hoc or CoT explanations. In this paper we argue that existing faithfulness tests are not actually measuring faithfulness in terms of the models' inner workings, but only evaluate their self-consistency on the output level. The aims of our work are two-fold. i) We aim to clarify the status of existing faithfulness tests in terms of model explainability, characterising them as self-consistency tests instead. This assessment we underline by constructing a Comparative Consistency Bank for self-consistency tests that for the first time compares existing tests on a common suite of 11 open-source LLMs and 5 datasets -- including ii) our own proposed self-consistency measure CC-SHAP. CC-SHAP is a new fine-grained measure (not test) of LLM self-consistency that compares a model's input contributions to answer prediction and generated explanation. With CC-SHAP, we aim to take a step further towards measuring faithfulness with a more interpretable and fine-grained method. Code available at \\url{https://github.com/Heidelberg-NLP/CC-SHAP}","sentences":["Large language models (LLMs) can explain their own predictions, through post-hoc or Chain-of-Thought (CoT) explanations.","However the LLM could make up reasonably sounding explanations that are unfaithful to its underlying reasoning.","Recent work has designed tests that aim to judge the faithfulness of either post-hoc or CoT explanations.","In this paper we argue that existing faithfulness tests are not actually measuring faithfulness in terms of the models' inner workings, but only evaluate their self-consistency on the output level.","The aims of our work are two-fold.","i)","We aim to clarify the status of existing faithfulness tests in terms of model explainability, characterising them as self-consistency tests instead.","This assessment we underline by constructing a Comparative Consistency Bank for self-consistency tests that for the first time compares existing tests on a common suite of 11 open-source LLMs and 5 datasets -- including ii) our own proposed self-consistency measure CC-SHAP.","CC-SHAP is a new fine-grained measure (not test) of LLM self-consistency that compares a model's input contributions to answer prediction and generated explanation.","With CC-SHAP, we aim to take a step further towards measuring faithfulness with a more interpretable and fine-grained method.","Code available at \\url{https://github.com/Heidelberg-NLP/CC-SHAP}"],"url":"http://arxiv.org/abs/2311.07466v1"}
{"created":"2023-11-13 16:45:37","title":"MEGAVERSE: Benchmarking Large Language Models Across Languages, Modalities, Models and Tasks","abstract":"Recently, there has been a rapid advancement in research on Large Language Models (LLMs), resulting in significant progress in several Natural Language Processing (NLP) tasks. Consequently, there has been a surge in LLM evaluation research to comprehend the models' capabilities and limitations. However, much of this research has been confined to the English language, leaving LLM building and evaluation for non-English languages relatively unexplored. There has been an introduction of several new LLMs, necessitating their evaluation on non-English languages. This study aims to expand our MEGA benchmarking suite by including six new datasets to form the MEGAVERSE benchmark. The benchmark comprises 22 datasets covering 81 languages, including low-resource African languages. We evaluate several state-of-the-art LLMs like GPT-3.5-Turbo, GPT4, PaLM2, and Llama2 on the MEGAVERSE datasets. Additionally, we include two multimodal datasets in the benchmark and assess the performance of the LLaVa-v1.5 model. Our experiments suggest that GPT4 and PaLM2 outperform the Llama models on various tasks, notably on low-resource languages, with GPT4 outperforming PaLM2 on more datasets than vice versa. However, issues such as data contamination must be addressed to obtain an accurate assessment of LLM performance on non-English languages.","sentences":["Recently, there has been a rapid advancement in research on Large Language Models (LLMs), resulting in significant progress in several Natural Language Processing (NLP) tasks.","Consequently, there has been a surge in LLM evaluation research to comprehend the models' capabilities and limitations.","However, much of this research has been confined to the English language, leaving LLM building and evaluation for non-English languages relatively unexplored.","There has been an introduction of several new LLMs, necessitating their evaluation on non-English languages.","This study aims to expand our MEGA benchmarking suite by including six new datasets to form the MEGAVERSE benchmark.","The benchmark comprises 22 datasets covering 81 languages, including low-resource African languages.","We evaluate several state-of-the-art LLMs like GPT-3.5-Turbo, GPT4, PaLM2, and Llama2 on the MEGAVERSE datasets.","Additionally, we include two multimodal datasets in the benchmark and assess the performance of the LLaVa-v1.5 model.","Our experiments suggest that GPT4 and PaLM2 outperform the Llama models on various tasks, notably on low-resource languages, with GPT4 outperforming PaLM2 on more datasets than vice versa.","However, issues such as data contamination must be addressed to obtain an accurate assessment of LLM performance on non-English languages."],"url":"http://arxiv.org/abs/2311.07463v1"}
{"created":"2023-11-13 16:43:34","title":"KnowSafe: Combined Knowledge and Data Driven Hazard Mitigation in Artificial Pancreas Systems","abstract":"Significant progress has been made in anomaly detection and run-time monitoring to improve the safety and security of cyber-physical systems (CPS). However, less attention has been paid to hazard mitigation. This paper proposes a combined knowledge and data driven approach, KnowSafe, for the design of safety engines that can predict and mitigate safety hazards resulting from safety-critical malicious attacks or accidental faults targeting a CPS controller. We integrate domain-specific knowledge of safety constraints and context-specific mitigation actions with machine learning (ML) techniques to estimate system trajectories in the far and near future, infer potential hazards, and generate optimal corrective actions to keep the system safe. Experimental evaluation on two realistic closed-loop testbeds for artificial pancreas systems (APS) and a real-world clinical trial dataset for diabetes treatment demonstrates that KnowSafe outperforms the state-of-the-art by achieving higher accuracy in predicting system state trajectories and potential hazards, a low false positive rate, and no false negatives. It also maintains the safe operation of the simulated APS despite faults or attacks without introducing any new hazards, with a hazard mitigation success rate of 92.8%, which is at least 76% higher than solely rule-based (50.9%) and data-driven (52.7%) methods.","sentences":["Significant progress has been made in anomaly detection and run-time monitoring to improve the safety and security of cyber-physical systems (CPS).","However, less attention has been paid to hazard mitigation.","This paper proposes a combined knowledge and data driven approach, KnowSafe, for the design of safety engines that can predict and mitigate safety hazards resulting from safety-critical malicious attacks or accidental faults targeting a CPS controller.","We integrate domain-specific knowledge of safety constraints and context-specific mitigation actions with machine learning (ML) techniques to estimate system trajectories in the far and near future, infer potential hazards, and generate optimal corrective actions to keep the system safe.","Experimental evaluation on two realistic closed-loop testbeds for artificial pancreas systems (APS) and a real-world clinical trial dataset for diabetes treatment demonstrates that KnowSafe outperforms the state-of-the-art by achieving higher accuracy in predicting system state trajectories and potential hazards, a low false positive rate, and no false negatives.","It also maintains the safe operation of the simulated APS despite faults or attacks without introducing any new hazards, with a hazard mitigation success rate of 92.8%, which is at least 76% higher than solely rule-based (50.9%) and data-driven (52.7%) methods."],"url":"http://arxiv.org/abs/2311.07460v1"}
{"created":"2023-11-13 16:42:21","title":"Trust in Queer Human-Robot Interaction","abstract":"Human-robot interaction (HRI) systems need to build trust with people of diverse identities. This position paper argues that queer (LGBTQIA+) people must be included in the design and evaluation of HRI systems to ensure their trust in and acceptance of robots. Queer people have faced discrimination and harm from artificial intelligence and robotic systems. Despite calls for increased diversity and inclusion, HRI has not systemically addressed queer issues. This paper suggests three approaches to address trust in queer HRI: diversifying human-subject pools, centering queer people in HRI studies, and contextualizing measures of trust.","sentences":["Human-robot interaction (HRI) systems need to build trust with people of diverse identities.","This position paper argues that queer (LGBTQIA+) people must be included in the design and evaluation of HRI systems to ensure their trust in and acceptance of robots.","Queer people have faced discrimination and harm from artificial intelligence and robotic systems.","Despite calls for increased diversity and inclusion, HRI has not systemically addressed queer issues.","This paper suggests three approaches to address trust in queer HRI: diversifying human-subject pools, centering queer people in HRI studies, and contextualizing measures of trust."],"url":"http://arxiv.org/abs/2311.07458v1"}
{"created":"2023-11-13 16:35:34","title":"Causal Discovery under Latent Class Confounding","abstract":"Directed acyclic graphs are used to model the causal structure of a system. ``Causal discovery'' describes the problem of learning this structure from data. When data is an aggregate from multiple sources (populations or environments), global confounding obscures conditional independence properties that drive many causal discovery algorithms. For this reason, existing causal discovery algorithms are not suitable for the multiple-source setting. We demonstrate that, if the confounding is of bounded cardinality (i.e. the data comes from a limited number of sources), causal discovery can still be achieved. The feasibility of this problem is governed by a trade-off between the cardinality of the global confounder, the cardinalities of the observed variables, and the sparsity of the causal structure.","sentences":["Directed acyclic graphs are used to model the causal structure of a system.","``Causal discovery'' describes the problem of learning this structure from data.","When data is an aggregate from multiple sources (populations or environments), global confounding obscures conditional independence properties that drive many causal discovery algorithms.","For this reason, existing causal discovery algorithms are not suitable for the multiple-source setting.","We demonstrate that, if the confounding is of bounded cardinality (i.e. the data comes from a limited number of sources), causal discovery can still be achieved.","The feasibility of this problem is governed by a trade-off between the cardinality of the global confounder, the cardinalities of the observed variables, and the sparsity of the causal structure."],"url":"http://arxiv.org/abs/2311.07454v1"}
{"created":"2023-11-13 16:35:29","title":"ChartCheck: An Evidence-Based Fact-Checking Dataset over Real-World Chart Images","abstract":"Data visualizations are common in the real-world. We often use them in data sources such as scientific documents, news articles, textbooks, and social media to summarize key information in a visual form. Charts can also mislead its audience by communicating false information or biasing them towards a specific agenda. Verifying claims against charts is not a straightforward process. It requires analyzing both the text and visual components of the chart, considering characteristics such as colors, positions, and orientations. Moreover, to determine if a claim is supported by the chart content often requires different types of reasoning. To address this challenge, we introduce ChartCheck, a novel dataset for fact-checking against chart images. ChartCheck is the first large-scale dataset with 1.7k real-world charts and 10.5k human-written claims and explanations. We evaluated the dataset on state-of-the-art models and achieved an accuracy of 73.9 in the finetuned setting. Additionally, we identified chart characteristics and reasoning types that challenge the models.","sentences":["Data visualizations are common in the real-world.","We often use them in data sources such as scientific documents, news articles, textbooks, and social media to summarize key information in a visual form.","Charts can also mislead its audience by communicating false information or biasing them towards a specific agenda.","Verifying claims against charts is not a straightforward process.","It requires analyzing both the text and visual components of the chart, considering characteristics such as colors, positions, and orientations.","Moreover, to determine if a claim is supported by the chart content often requires different types of reasoning.","To address this challenge, we introduce ChartCheck, a novel dataset for fact-checking against chart images.","ChartCheck is the first large-scale dataset with 1.7k real-world charts and 10.5k human-written claims and explanations.","We evaluated the dataset on state-of-the-art models and achieved an accuracy of 73.9 in the finetuned setting.","Additionally, we identified chart characteristics and reasoning types that challenge the models."],"url":"http://arxiv.org/abs/2311.07453v1"}
{"created":"2023-11-13 16:30:49","title":"Language Grounded QFormer for Efficient Vision Language Understanding","abstract":"Large-scale pretraining and instruction tuning have been successful for training general-purpose language models with broad competencies. However, extending to general-purpose vision-language models is challenging due to the distributional diversity in visual inputs. A recent line of work explores vision-language instruction tuning, taking inspiration from the Query Transformer (QFormer) approach proposed in BLIP-2 models for bridging frozen modalities. However, these approaches rely heavily on large-scale multi-modal pretraining for representation learning before eventual finetuning, incurring a huge computational overhead, poor scaling, and limited accessibility. To that end, we propose a more efficient method for QFormer-based vision-language alignment and demonstrate the effectiveness of our strategy compared to existing baselines in improving the efficiency of vision-language pretraining.","sentences":["Large-scale pretraining and instruction tuning have been successful for training general-purpose language models with broad competencies.","However, extending to general-purpose vision-language models is challenging due to the distributional diversity in visual inputs.","A recent line of work explores vision-language instruction tuning, taking inspiration from the Query Transformer (QFormer) approach proposed in BLIP-2 models for bridging frozen modalities.","However, these approaches rely heavily on large-scale multi-modal pretraining for representation learning before eventual finetuning, incurring a huge computational overhead, poor scaling, and limited accessibility.","To that end, we propose a more efficient method for QFormer-based vision-language alignment and demonstrate the effectiveness of our strategy compared to existing baselines in improving the efficiency of vision-language pretraining."],"url":"http://arxiv.org/abs/2311.07449v1"}
{"created":"2023-11-13 16:22:38","title":"Story-to-Motion: Synthesizing Infinite and Controllable Character Animation from Long Text","abstract":"Generating natural human motion from a story has the potential to transform the landscape of animation, gaming, and film industries. A new and challenging task, Story-to-Motion, arises when characters are required to move to various locations and perform specific motions based on a long text description. This task demands a fusion of low-level control (trajectories) and high-level control (motion semantics). Previous works in character control and text-to-motion have addressed related aspects, yet a comprehensive solution remains elusive: character control methods do not handle text description, whereas text-to-motion methods lack position constraints and often produce unstable motions. In light of these limitations, we propose a novel system that generates controllable, infinitely long motions and trajectories aligned with the input text. (1) We leverage contemporary Large Language Models to act as a text-driven motion scheduler to extract a series of (text, position, duration) pairs from long text. (2) We develop a text-driven motion retrieval scheme that incorporates motion matching with motion semantic and trajectory constraints. (3) We design a progressive mask transformer that addresses common artifacts in the transition motion such as unnatural pose and foot sliding. Beyond its pioneering role as the first comprehensive solution for Story-to-Motion, our system undergoes evaluation across three distinct sub-tasks: trajectory following, temporal action composition, and motion blending, where it outperforms previous state-of-the-art motion synthesis methods across the board. Homepage: https://story2motion.github.io/.","sentences":["Generating natural human motion from a story has the potential to transform the landscape of animation, gaming, and film industries.","A new and challenging task, Story-to-Motion, arises when characters are required to move to various locations and perform specific motions based on a long text description.","This task demands a fusion of low-level control (trajectories) and high-level control (motion semantics).","Previous works in character control and text-to-motion have addressed related aspects, yet a comprehensive solution remains elusive: character control methods do not handle text description, whereas text-to-motion methods lack position constraints and often produce unstable motions.","In light of these limitations, we propose a novel system that generates controllable, infinitely long motions and trajectories aligned with the input text.","(1) We leverage contemporary Large Language Models to act as a text-driven motion scheduler to extract a series of (text, position, duration) pairs from long text.","(2) We develop a text-driven motion retrieval scheme that incorporates motion matching with motion semantic and trajectory constraints.","(3) We design a progressive mask transformer that addresses common artifacts in the transition motion such as unnatural pose and foot sliding.","Beyond its pioneering role as the first comprehensive solution for Story-to-Motion, our system undergoes evaluation across three distinct sub-tasks: trajectory following, temporal action composition, and motion blending, where it outperforms previous state-of-the-art motion synthesis methods across the board.","Homepage: https://story2motion.github.io/."],"url":"http://arxiv.org/abs/2311.07446v1"}
{"created":"2023-11-13 16:19:42","title":"Think Before You Speak: Cultivating Communication Skills of Large Language Models via Inner Monologue","abstract":"The emergence of large language models (LLMs) further improves the capabilities of open-domain dialogue systems and can generate fluent, coherent, and diverse responses. However, LLMs still lack an important ability: communication skills, which makes them more like information seeking tools than anthropomorphic chatbots. To make LLMs more anthropomorphic and proactive during the conversation, we add five communication skills to the response generation process: topic transition, proactively asking questions, concept guidance, empathy, and summarising often. The addition of communication skills increases the interest of users in the conversation and attracts them to chat for longer. To enable LLMs better understand and use communication skills, we design and add the inner monologue to LLMs. The complete process is achieved through prompt engineering and in-context learning. To evaluate communication skills, we construct a benchmark named Cskills for evaluating various communication skills, which can also more comprehensively evaluate the dialogue generation ability of the model. Experimental results show that the proposed CSIM strategy improves the backbone models and outperforms the baselines in both automatic and human evaluations.","sentences":["The emergence of large language models (LLMs) further improves the capabilities of open-domain dialogue systems and can generate fluent, coherent, and diverse responses.","However, LLMs still lack an important ability: communication skills, which makes them more like information seeking tools than anthropomorphic chatbots.","To make LLMs more anthropomorphic and proactive during the conversation, we add five communication skills to the response generation process: topic transition, proactively asking questions, concept guidance, empathy, and summarising often.","The addition of communication skills increases the interest of users in the conversation and attracts them to chat for longer.","To enable LLMs better understand and use communication skills, we design and add the inner monologue to LLMs.","The complete process is achieved through prompt engineering and in-context learning.","To evaluate communication skills, we construct a benchmark named Cskills for evaluating various communication skills, which can also more comprehensively evaluate the dialogue generation ability of the model.","Experimental results show that the proposed CSIM strategy improves the backbone models and outperforms the baselines in both automatic and human evaluations."],"url":"http://arxiv.org/abs/2311.07445v1"}
{"created":"2023-11-13 16:18:58","title":"On the Robustness of Neural Collapse and the Neural Collapse of Robustness","abstract":"Neural Collapse refers to the curious phenomenon in the end of training of a neural network, where feature vectors and classification weights converge to a very simple geometrical arrangement (a simplex). While it has been observed empirically in various cases and has been theoretically motivated, its connection with crucial properties of neural networks, like their generalization and robustness, remains unclear. In this work, we study the stability properties of these simplices. We find that the simplex structure disappears under small adversarial attacks, and that perturbed examples \"leap\" between simplex vertices. We further analyze the geometry of networks that are optimized to be robust against adversarial perturbations of the input, and find that Neural Collapse is a pervasive phenomenon in these cases as well, with clean and perturbed representations forming aligned simplices, and giving rise to a robust simple nearest-neighbor classifier. By studying the propagation of the amount of collapse inside the network, we identify novel properties of both robust and non-robust machine learning models, and show that earlier, unlike later layers maintain reliable simplices on perturbed data.","sentences":["Neural Collapse refers to the curious phenomenon in the end of training of a neural network, where feature vectors and classification weights converge to a very simple geometrical arrangement (a simplex).","While it has been observed empirically in various cases and has been theoretically motivated, its connection with crucial properties of neural networks, like their generalization and robustness, remains unclear.","In this work, we study the stability properties of these simplices.","We find that the simplex structure disappears under small adversarial attacks, and that perturbed examples \"leap\" between simplex vertices.","We further analyze the geometry of networks that are optimized to be robust against adversarial perturbations of the input, and find that Neural Collapse is a pervasive phenomenon in these cases as well, with clean and perturbed representations forming aligned simplices, and giving rise to a robust simple nearest-neighbor classifier.","By studying the propagation of the amount of collapse inside the network, we identify novel properties of both robust and non-robust machine learning models, and show that earlier, unlike later layers maintain reliable simplices on perturbed data."],"url":"http://arxiv.org/abs/2311.07444v1"}
{"created":"2023-11-13 16:15:20","title":"Investigating Multi-Pivot Ensembling with Massively Multilingual Machine Translation Models","abstract":"Massively multilingual machine translation models allow for the translation of a large number of languages with a single model, but have limited performance on low- and very-low-resource translation directions. Pivoting via high-resource languages remains a strong strategy for low-resource directions, and in this paper we revisit ways of pivoting through multiple languages. Previous work has used a simple averaging of probability distributions from multiple paths, but we find that this performs worse than using a single pivot, and exacerbates the hallucination problem because the same hallucinations can be probable across different paths. As an alternative, we propose MaxEns, a combination strategy that is biased towards the most confident predictions, hypothesising that confident predictions are less prone to be hallucinations. We evaluate different strategies on the FLORES benchmark for 20 low-resource language directions, demonstrating that MaxEns improves translation quality for low-resource languages while reducing hallucination in translations, compared to both direct translation and an averaging approach. On average, multi-pivot strategies still lag behind using English as a single pivot language, raising the question of how to identify the best pivoting strategy for a given translation direction.","sentences":["Massively multilingual machine translation models allow for the translation of a large number of languages with a single model, but have limited performance on low- and very-low-resource translation directions.","Pivoting via high-resource languages remains a strong strategy for low-resource directions, and in this paper we revisit ways of pivoting through multiple languages.","Previous work has used a simple averaging of probability distributions from multiple paths, but we find that this performs worse than using a single pivot, and exacerbates the hallucination problem because the same hallucinations can be probable across different paths.","As an alternative, we propose MaxEns, a combination strategy that is biased towards the most confident predictions, hypothesising that confident predictions are less prone to be hallucinations.","We evaluate different strategies on the FLORES benchmark for 20 low-resource language directions, demonstrating that MaxEns improves translation quality for low-resource languages while reducing hallucination in translations, compared to both direct translation and an averaging approach.","On average, multi-pivot strategies still lag behind using English as a single pivot language, raising the question of how to identify the best pivoting strategy for a given translation direction."],"url":"http://arxiv.org/abs/2311.07439v1"}
{"created":"2023-11-13 16:13:30","title":"Hardest Monotone Functions for Evolutionary Algorithms","abstract":"The study of hardest and easiest fitness landscapes is an active area of research. Recently, Kaufmann, Larcher, Lengler and Zou conjectured that for the self-adjusting $(1,\\lambda)$-EA, Adversarial Dynamic BinVal (ADBV) is the hardest dynamic monotone function to optimize. We introduce the function Switching Dynamic BinVal (SDBV) which coincides with ADBV whenever the number of remaining zeros in the search point is strictly less than $n/2$, where $n$ denotes the dimension of the search space. We show, using a combinatorial argument, that for the $(1+1)$-EA with any mutation rate $p \\in [0,1]$, SDBV is drift-minimizing among the class of dynamic monotone functions. Our construction provides the first explicit example of an instance of the partially-ordered evolutionary algorithm (PO-EA) model with parameterized pessimism introduced by Colin, Doerr and F\\'erey, building on work of Jansen. We further show that the $(1+1)$-EA optimizes SDBV in $\\Theta(n^{3/2})$ generations. Our simulations demonstrate matching runtimes for both static and self-adjusting $(1,\\lambda)$ and $(1+\\lambda)$-EA. We further show, using an example of fixed dimension, that drift-minimization does not equal maximal runtime.","sentences":["The study of hardest and easiest fitness landscapes is an active area of research.","Recently, Kaufmann, Larcher, Lengler and Zou conjectured that for the self-adjusting $(1,\\lambda)$-EA, Adversarial Dynamic BinVal (ADBV) is the hardest dynamic monotone function to optimize.","We introduce the function Switching Dynamic BinVal (SDBV) which coincides with ADBV whenever the number of remaining zeros in the search point is strictly less than $n/2$, where $n$ denotes the dimension of the search space.","We show, using a combinatorial argument, that for the $(1+1)$-EA with any mutation rate $p \\in","[0,1]$, SDBV is drift-minimizing among the class of dynamic monotone functions.","Our construction provides the first explicit example of an instance of the partially-ordered evolutionary algorithm (PO-EA) model with parameterized pessimism introduced by Colin, Doerr and F\\'erey, building on work of Jansen.","We further show that the $(1+1)$-EA optimizes SDBV in $\\Theta(n^{3/2})$ generations.","Our simulations demonstrate matching runtimes for both static and self-adjusting $(1,\\lambda)$ and $(1+\\lambda)$-EA.","We further show, using an example of fixed dimension, that drift-minimization does not equal maximal runtime."],"url":"http://arxiv.org/abs/2311.07438v1"}
{"created":"2023-11-13 16:08:16","title":"Understanding Users' Dissatisfaction with ChatGPT Responses: Types, Resolving Tactics, and the Effect of Knowledge Level","abstract":"Large language models (LLMs) with chat-based capabilities, such as ChatGPT, are widely used in various workflows. However, due to a limited understanding of these large-scale models, users struggle to use this technology and experience different kinds of dissatisfaction. Researchers have introduced several methods such as prompt engineering to improve model responses. However, they focus on crafting one prompt, and little has been investigated on how to deal with the dissatisfaction the user encountered during the conversation. Therefore, with ChatGPT as the case study, we examine end users' dissatisfaction along with their strategies to address the dissatisfaction. After organizing users' dissatisfaction with LLM into seven categories based on a literature review, we collected 511 instances of dissatisfactory ChatGPT responses from 107 users and their detailed recollections of dissatisfied experiences, which we release as a publicly accessible dataset. Our analysis reveals that users most frequently experience dissatisfaction when ChatGPT fails to grasp their intentions, while they rate the severity of dissatisfaction the highest with dissatisfaction related to accuracy. We also identified four tactics users employ to address their dissatisfaction and their effectiveness. We found that users often do not use any tactics to address their dissatisfaction, and even when using tactics, 72% of dissatisfaction remained unresolved. Moreover, we found that users with low knowledge regarding LLMs tend to face more dissatisfaction on accuracy while they often put minimal effort in addressing dissatisfaction. Based on these findings, we propose design implications for minimizing user dissatisfaction and enhancing the usability of chat-based LLM services.","sentences":["Large language models (LLMs) with chat-based capabilities, such as ChatGPT, are widely used in various workflows.","However, due to a limited understanding of these large-scale models, users struggle to use this technology and experience different kinds of dissatisfaction.","Researchers have introduced several methods such as prompt engineering to improve model responses.","However, they focus on crafting one prompt, and little has been investigated on how to deal with the dissatisfaction the user encountered during the conversation.","Therefore, with ChatGPT as the case study, we examine end users' dissatisfaction along with their strategies to address the dissatisfaction.","After organizing users' dissatisfaction with LLM into seven categories based on a literature review, we collected 511 instances of dissatisfactory ChatGPT responses from 107 users and their detailed recollections of dissatisfied experiences, which we release as a publicly accessible dataset.","Our analysis reveals that users most frequently experience dissatisfaction when ChatGPT fails to grasp their intentions, while they rate the severity of dissatisfaction the highest with dissatisfaction related to accuracy.","We also identified four tactics users employ to address their dissatisfaction and their effectiveness.","We found that users often do not use any tactics to address their dissatisfaction, and even when using tactics, 72% of dissatisfaction remained unresolved.","Moreover, we found that users with low knowledge regarding LLMs tend to face more dissatisfaction on accuracy while they often put minimal effort in addressing dissatisfaction.","Based on these findings, we propose design implications for minimizing user dissatisfaction and enhancing the usability of chat-based LLM services."],"url":"http://arxiv.org/abs/2311.07434v1"}
{"created":"2023-11-13 16:04:41","title":"Supersampling of Data from Structured-light Scanner with Deep Learning","abstract":"This paper focuses on increasing the resolution of depth maps obtained from 3D cameras using structured light technology. Two deep learning models FDSR and DKN are modified to work with high-resolution data, and data pre-processing techniques are implemented for stable training. The models are trained on our custom dataset of 1200 3D scans. The resulting high-resolution depth maps are evaluated using qualitative and quantitative metrics. The approach for depth map upsampling offers benefits such as reducing the processing time of a pipeline by first downsampling a high-resolution depth map, performing various processing steps at the lower resolution and upsampling the resulting depth map or increasing the resolution of a point cloud captured in lower resolution by a cheaper device. The experiments demonstrate that the FDSR model excels in terms of faster processing time, making it a suitable choice for applications where speed is crucial. On the other hand, the DKN model provides results with higher precision, making it more suitable for applications that prioritize accuracy.","sentences":["This paper focuses on increasing the resolution of depth maps obtained from 3D cameras using structured light technology.","Two deep learning models FDSR and DKN are modified to work with high-resolution data, and data pre-processing techniques are implemented for stable training.","The models are trained on our custom dataset of 1200 3D scans.","The resulting high-resolution depth maps are evaluated using qualitative and quantitative metrics.","The approach for depth map upsampling offers benefits such as reducing the processing time of a pipeline by first downsampling a high-resolution depth map, performing various processing steps at the lower resolution and upsampling the resulting depth map or increasing the resolution of a point cloud captured in lower resolution by a cheaper device.","The experiments demonstrate that the FDSR model excels in terms of faster processing time, making it a suitable choice for applications where speed is crucial.","On the other hand, the DKN model provides results with higher precision, making it more suitable for applications that prioritize accuracy."],"url":"http://arxiv.org/abs/2311.07432v1"}
{"created":"2023-11-13 16:03:23","title":"Controlled Text Generation for Black-box Language Models via Score-based Progressive Editor","abstract":"Despite recent progress in language models, generating constrained text for specific domains remains a challenge, particularly when utilizing black-box models that lack domain-specific knowledge. In this paper, we introduce ScoPE (Score-based Progressive Editor) generation, a novel approach for controlled text generation for black-box language models. We employ ScoPE to facilitate text generation in the target domain by integrating it with language models through a cascading approach. Trained to enhance the target domain score of the edited text, ScoPE progressively edits intermediate output discrete tokens to align with the target attributes throughout the auto-regressive generation process of the language model. This iterative process guides subsequent steps to produce desired output texts for the target domain. Our experimental results on diverse controlled generations demonstrate that ScoPE effectively facilitates controlled text generation for black-box language models in both in-domain and out-of-domain conditions, which is challenging for existing methods.","sentences":["Despite recent progress in language models, generating constrained text for specific domains remains a challenge, particularly when utilizing black-box models that lack domain-specific knowledge.","In this paper, we introduce ScoPE (Score-based Progressive Editor) generation, a novel approach for controlled text generation for black-box language models.","We employ ScoPE to facilitate text generation in the target domain by integrating it with language models through a cascading approach.","Trained to enhance the target domain score of the edited text, ScoPE progressively edits intermediate output discrete tokens to align with the target attributes throughout the auto-regressive generation process of the language model.","This iterative process guides subsequent steps to produce desired output texts for the target domain.","Our experimental results on diverse controlled generations demonstrate that ScoPE effectively facilitates controlled text generation for black-box language models in both in-domain and out-of-domain conditions, which is challenging for existing methods."],"url":"http://arxiv.org/abs/2311.07430v1"}
{"created":"2023-11-13 16:01:43","title":"Boolean Variation and Boolean Logic BackPropagation","abstract":"The notion of variation is introduced for the Boolean set and based on which Boolean logic backpropagation principle is developed. Using this concept, deep models can be built with weights and activations being Boolean numbers and operated with Boolean logic instead of real arithmetic. In particular, Boolean deep models can be trained directly in the Boolean domain without latent weights. No gradient but logic is synthesized and backpropagated through layers.","sentences":["The notion of variation is introduced for the Boolean set and based on which Boolean logic backpropagation principle is developed.","Using this concept, deep models can be built with weights and activations being Boolean numbers and operated with Boolean logic instead of real arithmetic.","In particular, Boolean deep models can be trained directly in the Boolean domain without latent weights.","No gradient but logic is synthesized and backpropagated through layers."],"url":"http://arxiv.org/abs/2311.07427v1"}
{"created":"2023-11-13 16:00:16","title":"Optimising Human-AI Collaboration by Learning Convincing Explanations","abstract":"Machine learning models are being increasingly deployed to take, or assist in taking, complicated and high-impact decisions, from quasi-autonomous vehicles to clinical decision support systems. This poses challenges, particularly when models have hard-to-detect failure modes and are able to take actions without oversight. In order to handle this challenge, we propose a method for a collaborative system that remains safe by having a human ultimately making decisions, while giving the model the best opportunity to convince and debate them with interpretable explanations. However, the most helpful explanation varies among individuals and may be inconsistent across stated preferences. To this end we develop an algorithm, Ardent, to efficiently learn a ranking through interaction and best assist humans complete a task. By utilising a collaborative approach, we can ensure safety and improve performance while addressing transparency and accountability concerns. Ardent enables efficient and effective decision-making by adapting to individual preferences for explanations, which we validate through extensive simulations alongside a user study involving a challenging image classification task, demonstrating consistent improvement over competing systems.","sentences":["Machine learning models are being increasingly deployed to take, or assist in taking, complicated and high-impact decisions, from quasi-autonomous vehicles to clinical decision support systems.","This poses challenges, particularly when models have hard-to-detect failure modes and are able to take actions without oversight.","In order to handle this challenge, we propose a method for a collaborative system that remains safe by having a human ultimately making decisions, while giving the model the best opportunity to convince and debate them with interpretable explanations.","However, the most helpful explanation varies among individuals and may be inconsistent across stated preferences.","To this end we develop an algorithm, Ardent, to efficiently learn a ranking through interaction and best assist humans complete a task.","By utilising a collaborative approach, we can ensure safety and improve performance while addressing transparency and accountability concerns.","Ardent enables efficient and effective decision-making by adapting to individual preferences for explanations, which we validate through extensive simulations alongside a user study involving a challenging image classification task, demonstrating consistent improvement over competing systems."],"url":"http://arxiv.org/abs/2311.07426v1"}
{"created":"2023-11-13 15:58:18","title":"Hallucination Augmented Recitations for Language Models","abstract":"Attribution is a key concept in large language models (LLMs) as it enables control over information sources and enhances the factuality of LLMs. While existing approaches utilize open book question answering to improve attribution, factual datasets may reward language models to recall facts that they already know from their pretraining data, not attribution. In contrast, counterfactual open book QA datasets would further improve attribution because the answer could only be grounded in the given text. We propose Hallucination Augmented Recitations (HAR) for creating counterfactual datasets by utilizing hallucination in LLMs to improve attribution. For open book QA as a case study, we demonstrate that models finetuned with our counterfactual datasets improve text grounding, leading to better open book QA performance, with up to an 8.0% increase in F1 score. Our counterfactual dataset leads to significantly better performance than using humanannotated factual datasets, even with 4x smaller datasets and 4x smaller models. We observe that improvements are consistent across various model sizes and datasets, including multi-hop, biomedical, and adversarial QA datasets.","sentences":["Attribution is a key concept in large language models (LLMs) as it enables control over information sources and enhances the factuality of LLMs.","While existing approaches utilize open book question answering to improve attribution, factual datasets may reward language models to recall facts that they already know from their pretraining data, not attribution.","In contrast, counterfactual open book QA datasets would further improve attribution because the answer could only be grounded in the given text.","We propose Hallucination Augmented Recitations (HAR) for creating counterfactual datasets by utilizing hallucination in LLMs to improve attribution.","For open book QA as a case study, we demonstrate that models finetuned with our counterfactual datasets improve text grounding, leading to better open book QA performance, with up to an 8.0% increase in F1 score.","Our counterfactual dataset leads to significantly better performance than using humanannotated factual datasets, even with 4x smaller datasets and 4x smaller models.","We observe that improvements are consistent across various model sizes and datasets, including multi-hop, biomedical, and adversarial QA datasets."],"url":"http://arxiv.org/abs/2311.07424v1"}
{"created":"2023-11-13 15:57:45","title":"Sidekick compilation with xDSL","abstract":"Traditionally, compiler researchers either conduct experiments within an existing production compiler or develop their own prototype compiler; both options come with trade-offs. On one hand, prototyping in a production compiler can be cumbersome, as they are often optimized for program compilation speed at the expense of software simplicity and development speed. On the other hand, the transition from a prototype compiler to production requires significant engineering work. To bridge this gap, we introduce the concept of sidekick compiler frameworks, an approach that uses multiple frameworks that interoperate with each other by leveraging textual interchange formats and declarative descriptions of abstractions. Each such compiler framework is specialized for specific use cases, such as performance or prototyping. Abstractions are by design shared across frameworks, simplifying the transition from prototyping to production. We demonstrate this idea with xDSL, a sidekick for MLIR focused on prototyping and teaching. xDSL interoperates with MLIR through a shared textual IR and the exchange of IRs through an IR Definition Language. The benefits of sidekick compiler frameworks are evaluated by showing on three use cases how xDSL impacts their development: teaching, DSL compilation, and rewrite system prototyping. We also investigate the trade-offs that xDSL offers, and demonstrate how we simplify the transition between frameworks using the IRDL dialect. With sidekick compilation, we envision a future in which engineers minimize the cost of development by choosing a framework built for their immediate needs, and later transitioning to production with minimal overhead.","sentences":["Traditionally, compiler researchers either conduct experiments within an existing production compiler or develop their own prototype compiler; both options come with trade-offs.","On one hand, prototyping in a production compiler can be cumbersome, as they are often optimized for program compilation speed at the expense of software simplicity and development speed.","On the other hand, the transition from a prototype compiler to production requires significant engineering work.","To bridge this gap, we introduce the concept of sidekick compiler frameworks, an approach that uses multiple frameworks that interoperate with each other by leveraging textual interchange formats and declarative descriptions of abstractions.","Each such compiler framework is specialized for specific use cases, such as performance or prototyping.","Abstractions are by design shared across frameworks, simplifying the transition from prototyping to production.","We demonstrate this idea with xDSL, a sidekick for MLIR focused on prototyping and teaching.","xDSL","interoperates with MLIR through a shared textual IR and the exchange of IRs through an IR Definition Language.","The benefits of sidekick compiler frameworks are evaluated by showing on three use cases how xDSL impacts their development: teaching, DSL compilation, and rewrite system prototyping.","We also investigate the trade-offs that xDSL offers, and demonstrate how we simplify the transition between frameworks using the IRDL dialect.","With sidekick compilation, we envision a future in which engineers minimize the cost of development by choosing a framework built for their immediate needs, and later transitioning to production with minimal overhead."],"url":"http://arxiv.org/abs/2311.07422v1"}
{"created":"2023-11-13 15:57:17","title":"Robust semi-supervised segmentation with timestep ensembling diffusion models","abstract":"Medical image segmentation is a challenging task, made more difficult by many datasets' limited size and annotations. Denoising diffusion probabilistic models (DDPM) have recently shown promise in modelling the distribution of natural images and were successfully applied to various medical imaging tasks. This work focuses on semi-supervised image segmentation using diffusion models, particularly addressing domain generalisation. Firstly, we demonstrate that smaller diffusion steps generate latent representations that are more robust for downstream tasks than larger steps. Secondly, we use this insight to propose an improved esembling scheme that leverages information-dense small steps and the regularising effect of larger steps to generate predictions. Our model shows significantly better performance in domain-shifted settings while retaining competitive performance in-domain. Overall, this work highlights the potential of DDPMs for semi-supervised medical image segmentation and provides insights into optimising their performance under domain shift.","sentences":["Medical image segmentation is a challenging task, made more difficult by many datasets' limited size and annotations.","Denoising diffusion probabilistic models (DDPM) have recently shown promise in modelling the distribution of natural images and were successfully applied to various medical imaging tasks.","This work focuses on semi-supervised image segmentation using diffusion models, particularly addressing domain generalisation.","Firstly, we demonstrate that smaller diffusion steps generate latent representations that are more robust for downstream tasks than larger steps.","Secondly, we use this insight to propose an improved esembling scheme that leverages information-dense small steps and the regularising effect of larger steps to generate predictions.","Our model shows significantly better performance in domain-shifted settings while retaining competitive performance in-domain.","Overall, this work highlights the potential of DDPMs for semi-supervised medical image segmentation and provides insights into optimising their performance under domain shift."],"url":"http://arxiv.org/abs/2311.07421v1"}
{"created":"2023-11-13 15:54:30","title":"Speech-based Slot Filling using Large Language Models","abstract":"Recently, advancements in large language models (LLMs) have shown an unprecedented ability across various language tasks. This paper investigates the potential application of LLMs to slot filling with noisy ASR transcriptions, via both in-context learning and task-specific fine-tuning. Dedicated prompt designs and fine-tuning approaches are proposed to improve the robustness of LLMs for slot filling with noisy ASR transcriptions. Moreover, a linearised knowledge injection (LKI) scheme is also proposed to integrate dynamic external knowledge into LLMs. Experiments were performed on SLURP to quantify the performance of LLMs, including GPT-3.5-turbo, GPT-4, LLaMA-13B and Vicuna-13B (v1.1 and v1.5) with different ASR error rates. The use of the proposed fine-tuning together with the LKI scheme for LLaMA-13B achieved an 8.3% absolute SLU-F1 improvement compared to the strong Flan-T5-base baseline system on a limited data setup.","sentences":["Recently, advancements in large language models (LLMs) have shown an unprecedented ability across various language tasks.","This paper investigates the potential application of LLMs to slot filling with noisy ASR transcriptions, via both in-context learning and task-specific fine-tuning.","Dedicated prompt designs and fine-tuning approaches are proposed to improve the robustness of LLMs for slot filling with noisy ASR transcriptions.","Moreover, a linearised knowledge injection (LKI) scheme is also proposed to integrate dynamic external knowledge into LLMs.","Experiments were performed on SLURP to quantify the performance of LLMs, including GPT-3.5-turbo, GPT-4, LLaMA-13B and Vicuna-13B (v1.1 and v1.5) with different ASR error rates.","The use of the proposed fine-tuning together with the LKI scheme for LLaMA-13B achieved an 8.3% absolute SLU-F1 improvement compared to the strong Flan-T5-base baseline system on a limited data setup."],"url":"http://arxiv.org/abs/2311.07418v1"}
{"created":"2023-11-13 15:54:27","title":"Mitigating Backdoors within Deep Neural Networks in Data-limited Configuration","abstract":"As the capacity of deep neural networks (DNNs) increases, their need for huge amounts of data significantly grows. A common practice is to outsource the training process or collect more data over the Internet, which introduces the risks of a backdoored DNN. A backdoored DNN shows normal behavior on clean data while behaving maliciously once a trigger is injected into a sample at the test time. In such cases, the defender faces multiple difficulties. First, the available clean dataset may not be sufficient for fine-tuning and recovering the backdoored DNN. Second, it is impossible to recover the trigger in many real-world applications without information about it. In this paper, we formulate some characteristics of poisoned neurons. This backdoor suspiciousness score can rank network neurons according to their activation values, weights, and their relationship with other neurons in the same layer. Our experiments indicate the proposed method decreases the chance of attacks being successful by more than 50% with a tiny clean dataset, i.e., ten clean samples for the CIFAR-10 dataset, without significantly deteriorating the model's performance. Moreover, the proposed method runs three times as fast as baselines.","sentences":["As the capacity of deep neural networks (DNNs) increases, their need for huge amounts of data significantly grows.","A common practice is to outsource the training process or collect more data over the Internet, which introduces the risks of a backdoored DNN.","A backdoored DNN shows normal behavior on clean data while behaving maliciously once a trigger is injected into a sample at the test time.","In such cases, the defender faces multiple difficulties.","First, the available clean dataset may not be sufficient for fine-tuning and recovering the backdoored DNN.","Second, it is impossible to recover the trigger in many real-world applications without information about it.","In this paper, we formulate some characteristics of poisoned neurons.","This backdoor suspiciousness score can rank network neurons according to their activation values, weights, and their relationship with other neurons in the same layer.","Our experiments indicate the proposed method decreases the chance of attacks being successful by more than 50% with a tiny clean dataset, i.e., ten clean samples for the CIFAR-10 dataset, without significantly deteriorating the model's performance.","Moreover, the proposed method runs three times as fast as baselines."],"url":"http://arxiv.org/abs/2311.07417v1"}
{"created":"2023-11-13 15:53:45","title":"Differentially Private Approximate Pattern Matching","abstract":"In this paper, we consider the $k$-approximate pattern matching problem under differential privacy, where the goal is to report or count all substrings of a given string $S$ which have a Hamming distance at most $k$ to a pattern $P$, or decide whether such a substring exists. In our definition of privacy, individual positions of the string $S$ are protected. To be able to answer queries under differential privacy, we allow some slack on $k$, i.e. we allow reporting or counting substrings of $S$ with a distance at most $(1+\\gamma)k+\\alpha$ to $P$, for a multiplicative error $\\gamma$ and an additive error $\\alpha$. We analyze which values of $\\alpha$ and $\\gamma$ are necessary or sufficient to solve the $k$-approximate pattern matching problem while satisfying $\\epsilon$-differential privacy. Let $n$ denote the length of $S$. We give 1) an $\\epsilon$-differentially private algorithm with an additive error of $O(\\epsilon^{-1}\\log n)$ and no multiplicative error for the existence variant; 2) an $\\epsilon$-differentially private algorithm with an additive error $O(\\epsilon^{-1}\\max(k,\\log n)\\cdot\\log n)$ for the counting variant; 3) an $\\epsilon$-differentially private algorithm with an additive error of $O(\\epsilon^{-1}\\log n)$ and multiplicative error $O(1)$ for the reporting variant for a special class of patterns. The error bounds hold with high probability. All of these algorithms return a witness, that is, if there exists a substring of $S$ with distance at most $k$ to $P$, then the algorithm returns a substring of $S$ with distance at most $(1+\\gamma)k+\\alpha$ to $P$. Further, we complement these results by a lower bound, showing that any algorithm for the existence variant which also returns a witness must have an additive error of $\\Omega(\\epsilon^{-1}\\log n)$ with constant probability.","sentences":["In this paper, we consider the $k$-approximate pattern matching problem under differential privacy, where the goal is to report or count all substrings of a given string $S$ which have a Hamming distance at most $k$ to a pattern $P$, or decide whether such a substring exists.","In our definition of privacy, individual positions of the string $S$ are protected.","To be able to answer queries under differential privacy, we allow some slack on $k$, i.e. we allow reporting or counting substrings of $S$ with a distance at most $(1+\\gamma)k+\\alpha$ to $P$, for a multiplicative error $\\gamma$ and an additive error $\\alpha$. We analyze which values of $\\alpha$ and $\\gamma$ are necessary or sufficient to solve the $k$-approximate pattern matching problem while satisfying $\\epsilon$-differential privacy.","Let $n$ denote the length of $S$. We give 1) an $\\epsilon$-differentially private algorithm with an additive error of $O(\\epsilon^{-1}\\log n)$ and no multiplicative error for the existence variant; 2) an $\\epsilon$-differentially private algorithm with an additive error $O(\\epsilon^{-1}\\max(k,\\log n)\\cdot\\log n)$ for the counting variant; 3) an $\\epsilon$-differentially private algorithm with an additive error of $O(\\epsilon^{-1}\\log n)$ and multiplicative error $O(1)$ for the reporting variant for a special class of patterns.","The error bounds hold with high probability.","All of these algorithms return a witness, that is, if there exists a substring of $S$ with distance at most $k$ to $P$, then the algorithm returns a substring of $S$ with distance at most $(1+\\gamma)k+\\alpha$ to $P$. Further, we complement these results by a lower bound, showing that any algorithm for the existence variant which also returns a witness must have an additive error of $\\Omega(\\epsilon^{-1}\\log n)$ with constant probability."],"url":"http://arxiv.org/abs/2311.07415v1"}
{"created":"2023-11-13 15:50:25","title":"FIRST: A Million-Entry Dataset for Text-Driven Fashion Synthesis and Design","abstract":"Text-driven fashion synthesis and design is an extremely valuable part of artificial intelligence generative content(AIGC), which has the potential to propel a tremendous revolution in the traditional fashion industry. To advance the research on text-driven fashion synthesis and design, we introduce a new dataset comprising a million high-resolution fashion images with rich structured textual(FIRST) descriptions. In the FIRST, there is a wide range of attire categories and each image-paired textual description is organized at multiple hierarchical levels. Experiments on prevalent generative models trained over FISRT show the necessity of FIRST. We invite the community to further develop more intelligent fashion synthesis and design systems that make fashion design more creative and imaginative based on our dataset. The dataset will be released soon.","sentences":["Text-driven fashion synthesis and design is an extremely valuable part of artificial intelligence generative content(AIGC), which has the potential to propel a tremendous revolution in the traditional fashion industry.","To advance the research on text-driven fashion synthesis and design, we introduce a new dataset comprising a million high-resolution fashion images with rich structured textual(FIRST) descriptions.","In the FIRST, there is a wide range of attire categories and each image-paired textual description is organized at multiple hierarchical levels.","Experiments on prevalent generative models trained over FISRT show the necessity of FIRST.","We invite the community to further develop more intelligent fashion synthesis and design systems that make fashion design more creative and imaginative based on our dataset.","The dataset will be released soon."],"url":"http://arxiv.org/abs/2311.07414v1"}
{"created":"2023-11-13 15:44:07","title":"Toward Optimal Psychological Functioning in AI-driven Software Engineering Tasks: The SEWELL-CARE Assessment Framework","abstract":"In the field of software engineering, there has been a shift towards utilizing various artificial intelligence techniques to address challenges and create innovative tools. These solutions are aimed at enhancing efficiency, automating tasks, and providing valuable support to developers. While the technical aspects are crucial, the well-being and psychology of the individuals performing these tasks are often overlooked. This paper argues that a holistic approach is essential, one that considers the technical, psychological, and social aspects of software engineering tasks. To address this gap, we introduce SEWELL-CARE, a conceptual framework designed to assess AI-driven software engineering tasks from multiple perspectives, with the goal of customizing the tools to improve the efficiency, well-being, and psychological functioning of developers. By emphasizing both technical and human dimensions, our framework provides a nuanced evaluation that goes beyond traditional technical metrics.","sentences":["In the field of software engineering, there has been a shift towards utilizing various artificial intelligence techniques to address challenges and create innovative tools.","These solutions are aimed at enhancing efficiency, automating tasks, and providing valuable support to developers.","While the technical aspects are crucial, the well-being and psychology of the individuals performing these tasks are often overlooked.","This paper argues that a holistic approach is essential, one that considers the technical, psychological, and social aspects of software engineering tasks.","To address this gap, we introduce SEWELL-CARE, a conceptual framework designed to assess AI-driven software engineering tasks from multiple perspectives, with the goal of customizing the tools to improve the efficiency, well-being, and psychological functioning of developers.","By emphasizing both technical and human dimensions, our framework provides a nuanced evaluation that goes beyond traditional technical metrics."],"url":"http://arxiv.org/abs/2311.07410v1"}
{"created":"2023-11-13 15:41:25","title":"Towards Automatic Honey Bee Flower-Patch Assays with Paint Marking Re-Identification","abstract":"In this paper, we show that paint markings are a feasible approach to automatize the analysis of behavioral assays involving honey bees in the field where marking has to be as lightweight as possible. We contribute a novel dataset for bees re-identification with paint-markings with 4392 images and 27 identities. Contrastive learning with a ResNet backbone and triplet loss led to identity representation features with almost perfect recognition in closed setting where identities are known in advance. Diverse experiments evaluate the capability to generalize to separate IDs, and show the impact of using different body parts for identification, such as using the unmarked abdomen only. In addition, we show the potential to fully automate the visit detection and provide preliminary results of compute time for future real-time deployment in the field on an edge device.","sentences":["In this paper, we show that paint markings are a feasible approach to automatize the analysis of behavioral assays involving honey bees in the field where marking has to be as lightweight as possible.","We contribute a novel dataset for bees re-identification with paint-markings with 4392 images and 27 identities.","Contrastive learning with a ResNet backbone and triplet loss led to identity representation features with almost perfect recognition in closed setting where identities are known in advance.","Diverse experiments evaluate the capability to generalize to separate IDs, and show the impact of using different body parts for identification, such as using the unmarked abdomen only.","In addition, we show the potential to fully automate the visit detection and provide preliminary results of compute time for future real-time deployment in the field on an edge device."],"url":"http://arxiv.org/abs/2311.07407v1"}
{"created":"2023-11-13 15:27:23","title":"Context-Aware Adaptive Prefetching for DASH Streaming over 5G Networks","abstract":"The increasing consumption of video streams and the demand for higher-quality content drive the evolution of telecommunication networks and the development of new network accelerators to boost media delivery while optimizing network usage. Multi-access Edge Computing (MEC) enables the possibility to enforce media delivery by deploying caching instances at the network edge, close to the Radio Access Network (RAN). Thus, the content can be prefetched and served from the MEC host, reducing network traffic and increasing the Quality of Service (QoS) and the Quality of Experience (QoE). This paper proposes a novel mechanism to prefetch Dynamic Adaptive Streaming over HTTP (DASH) streams at the MEC, employing a Machine Learning (ML) classification model to select the media segments to prefetch. The model is trained with media session metrics to improve the forecasts with application layer information. The proposal is tested with Mobile Network Operators (MNOs)' 5G MEC and RAN and compared with other strategies by assessing cache and player's performance metrics.","sentences":["The increasing consumption of video streams and the demand for higher-quality content drive the evolution of telecommunication networks and the development of new network accelerators to boost media delivery while optimizing network usage.","Multi-access Edge Computing (MEC) enables the possibility to enforce media delivery by deploying caching instances at the network edge, close to the Radio Access Network (RAN).","Thus, the content can be prefetched and served from the MEC host, reducing network traffic and increasing the Quality of Service (QoS) and the Quality of Experience (QoE).","This paper proposes a novel mechanism to prefetch Dynamic Adaptive Streaming over HTTP (DASH) streams at the MEC, employing a Machine Learning (ML) classification model to select the media segments to prefetch.","The model is trained with media session metrics to improve the forecasts with application layer information.","The proposal is tested with Mobile Network Operators (MNOs)' 5G MEC and RAN and compared with other strategies by assessing cache and player's performance metrics."],"url":"http://arxiv.org/abs/2311.07399v1"}
{"created":"2023-11-13 15:25:55","title":"Processing and Segmentation of Human Teeth from 2D Images using Weakly Supervised Learning","abstract":"Teeth segmentation is an essential task in dental image analysis for accurate diagnosis and treatment planning. While supervised deep learning methods can be utilized for teeth segmentation, they often require extensive manual annotation of segmentation masks, which is time-consuming and costly. In this research, we propose a weakly supervised approach for teeth segmentation that reduces the need for manual annotation. Our method utilizes the output heatmaps and intermediate feature maps from a keypoint detection network to guide the segmentation process. We introduce the TriDental dataset, consisting of 3000 oral cavity images annotated with teeth keypoints, to train a teeth keypoint detection network. We combine feature maps from different layers of the keypoint detection network, enabling accurate teeth segmentation without explicit segmentation annotations. The detected keypoints are also used for further refinement of the segmentation masks. Experimental results on the TriDental dataset demonstrate the superiority of our approach in terms of accuracy and robustness compared to state-of-the-art segmentation methods. Our method offers a cost-effective and efficient solution for teeth segmentation in real-world dental applications, eliminating the need for extensive manual annotation efforts.","sentences":["Teeth segmentation is an essential task in dental image analysis for accurate diagnosis and treatment planning.","While supervised deep learning methods can be utilized for teeth segmentation, they often require extensive manual annotation of segmentation masks, which is time-consuming and costly.","In this research, we propose a weakly supervised approach for teeth segmentation that reduces the need for manual annotation.","Our method utilizes the output heatmaps and intermediate feature maps from a keypoint detection network to guide the segmentation process.","We introduce the TriDental dataset, consisting of 3000 oral cavity images annotated with teeth keypoints, to train a teeth keypoint detection network.","We combine feature maps from different layers of the keypoint detection network, enabling accurate teeth segmentation without explicit segmentation annotations.","The detected keypoints are also used for further refinement of the segmentation masks.","Experimental results on the TriDental dataset demonstrate the superiority of our approach in terms of accuracy and robustness compared to state-of-the-art segmentation methods.","Our method offers a cost-effective and efficient solution for teeth segmentation in real-world dental applications, eliminating the need for extensive manual annotation efforts."],"url":"http://arxiv.org/abs/2311.07398v1"}
{"created":"2023-11-13 15:25:42","title":"An LLM-free Multi-dimensional Benchmark for MLLMs Hallucination Evaluation","abstract":"Despite making significant progress in multi-modal tasks, current Multi-modal Large Language Models (MLLMs) encounter the significant challenge of hallucination, which may lead to harmful consequences. Therefore, evaluating MLLMs' hallucinations is becoming increasingly important in model improvement and practical application deployment. Previous works are limited in high evaluation costs (e.g., relying on humans or advanced LLMs) and insufficient evaluation dimensions (e.g., types of hallucination and task). In this paper, we propose an LLM-free multi-dimensional benchmark AMBER, which can be used to evaluate both generative task and discriminative task including object existence, object attribute and object relation hallucination. Based on AMBER, we design a low-cost and efficient evaluation pipeline. Additionally, we conduct a comprehensive evaluation and detailed analysis of mainstream MLLMs including GPT-4V(ision), and also give guideline suggestions for mitigating hallucinations. The data and code of AMBER are available at https://github.com/junyangwang0410/AMBER.","sentences":["Despite making significant progress in multi-modal tasks, current Multi-modal Large Language Models (MLLMs) encounter the significant challenge of hallucination, which may lead to harmful consequences.","Therefore, evaluating MLLMs' hallucinations is becoming increasingly important in model improvement and practical application deployment.","Previous works are limited in high evaluation costs (e.g., relying on humans or advanced LLMs) and insufficient evaluation dimensions (e.g., types of hallucination and task).","In this paper, we propose an LLM-free multi-dimensional benchmark AMBER, which can be used to evaluate both generative task and discriminative task including object existence, object attribute and object relation hallucination.","Based on AMBER, we design a low-cost and efficient evaluation pipeline.","Additionally, we conduct a comprehensive evaluation and detailed analysis of mainstream MLLMs including GPT-4V(ision), and also give guideline suggestions for mitigating hallucinations.","The data and code of AMBER are available at https://github.com/junyangwang0410/AMBER."],"url":"http://arxiv.org/abs/2311.07397v1"}
{"created":"2023-11-13 15:24:55","title":"Exploring Values in Museum Artifacts in the SPICE project: a Preliminary Study","abstract":"This document describes the rationale, the implementation and a preliminary evaluation of a semantic reasoning tool developed in the EU H2020 SPICE project to enhance the diversity of perspectives experienced by museum visitors. The tool, called DEGARI 2.0 for values, relies on the commonsense reasoning framework TCL, and exploits an ontological model formalizingthe Haidt's theory of moral values to associate museum items with combined values and emotions. Within a museum exhibition, this tool can suggest cultural items that are associated not only with the values of already experienced or preferred objects, but also with novel items with different value stances, opening the visit experience to more inclusive interpretations of cultural content. The system has been preliminarily tested, in the context of the SPICE project, on the collection of the Hecht Museum of Haifa.","sentences":["This document describes the rationale, the implementation and a preliminary evaluation of a semantic reasoning tool developed in the EU H2020 SPICE project to enhance the diversity of perspectives experienced by museum visitors.","The tool, called DEGARI 2.0 for values, relies on the commonsense reasoning framework TCL, and exploits an ontological model formalizingthe Haidt's theory of moral values to associate museum items with combined values and emotions.","Within a museum exhibition, this tool can suggest cultural items that are associated not only with the values of already experienced or preferred objects, but also with novel items with different value stances, opening the visit experience to more inclusive interpretations of cultural content.","The system has been preliminarily tested, in the context of the SPICE project, on the collection of the Hecht Museum of Haifa."],"url":"http://arxiv.org/abs/2311.07396v1"}
{"created":"2023-11-13 15:23:26","title":"Predicting Continuous Locomotion Modes via Multidimensional Feature Learning from sEMG","abstract":"Walking-assistive devices require adaptive control methods to ensure smooth transitions between various modes of locomotion. For this purpose, detecting human locomotion modes (e.g., level walking or stair ascent) in advance is crucial for improving the intelligence and transparency of such robotic systems. This study proposes Deep-STF, a unified end-to-end deep learning model designed for integrated feature extraction in spatial, temporal, and frequency dimensions from surface electromyography (sEMG) signals. Our model enables accurate and robust continuous prediction of nine locomotion modes and 15 transitions at varying prediction time intervals, ranging from 100 to 500 ms. In addition, we introduced the concept of 'stable prediction time' as a distinct metric to quantify prediction efficiency. This term refers to the duration during which consistent and accurate predictions of mode transitions are made, measured from the time of the fifth correct prediction to the occurrence of the critical event leading to the task transition. This distinction between stable prediction time and prediction time is vital as it underscores our focus on the precision and reliability of mode transition predictions. Experimental results showcased Deep-STP's cutting-edge prediction performance across diverse locomotion modes and transitions, relying solely on sEMG data. When forecasting 100 ms ahead, Deep-STF surpassed CNN and other machine learning techniques, achieving an outstanding average prediction accuracy of 96.48%. Even with an extended 500 ms prediction horizon, accuracy only marginally decreased to 93.00%. The averaged stable prediction times for detecting next upcoming transitions spanned from 28.15 to 372.21 ms across the 100-500 ms time advances.","sentences":["Walking-assistive devices require adaptive control methods to ensure smooth transitions between various modes of locomotion.","For this purpose, detecting human locomotion modes (e.g., level walking or stair ascent) in advance is crucial for improving the intelligence and transparency of such robotic systems.","This study proposes Deep-STF, a unified end-to-end deep learning model designed for integrated feature extraction in spatial, temporal, and frequency dimensions from surface electromyography (sEMG) signals.","Our model enables accurate and robust continuous prediction of nine locomotion modes and 15 transitions at varying prediction time intervals, ranging from 100 to 500 ms.","In addition, we introduced the concept of 'stable prediction time' as a distinct metric to quantify prediction efficiency.","This term refers to the duration during which consistent and accurate predictions of mode transitions are made, measured from the time of the fifth correct prediction to the occurrence of the critical event leading to the task transition.","This distinction between stable prediction time and prediction time is vital as it underscores our focus on the precision and reliability of mode transition predictions.","Experimental results showcased Deep-STP's cutting-edge prediction performance across diverse locomotion modes and transitions, relying solely on sEMG data.","When forecasting 100 ms ahead, Deep-STF surpassed CNN and other machine learning techniques, achieving an outstanding average prediction accuracy of 96.48%.","Even with an extended 500 ms prediction horizon, accuracy only marginally decreased to 93.00%.","The averaged stable prediction times for detecting next upcoming transitions spanned from 28.15 to 372.21 ms across the 100-500 ms time advances."],"url":"http://arxiv.org/abs/2311.07395v1"}
{"created":"2023-11-13 15:15:05","title":"Multi-Layer Monitoring at the Edge for Vehicular Video Streaming: Field Trials","abstract":"In an increasingly connected world, wireless networks' monitoring and characterization are of vital importance. Service and application providers need to have a detailed understanding of network performance to offer new solutions tailored to the needs of today's society. In the context of mobility, in-vehicle infotainment services are expected to stand out among other popular connected vehicle services, so it is essential that communication networks are able to satisfy the Quality of Service (QoS) and Quality of Experience (QoE) requirements needed for these type of services. This paper investigates a multi-layer network performance monitoring architecture at the edge providing QoS, QoE, and localization information for vehicular video streaming applications in real-time over 5G networks. In order to conduct field trials and show test results, Mobile Network Operators (MNOs)' 5G Standalone (SA) network and Multi-access Edge Computing (MEC) infrastructure are used to provide connectivity and edge computing resources to a vehicle equipped with a 5G modem.","sentences":["In an increasingly connected world, wireless networks' monitoring and characterization are of vital importance.","Service and application providers need to have a detailed understanding of network performance to offer new solutions tailored to the needs of today's society.","In the context of mobility, in-vehicle infotainment services are expected to stand out among other popular connected vehicle services, so it is essential that communication networks are able to satisfy the Quality of Service (QoS) and Quality of Experience (QoE) requirements needed for these type of services.","This paper investigates a multi-layer network performance monitoring architecture at the edge providing QoS, QoE, and localization information for vehicular video streaming applications in real-time over 5G networks.","In order to conduct field trials and show test results, Mobile Network Operators (MNOs)' 5G Standalone (SA) network and Multi-access Edge Computing (MEC) infrastructure are used to provide connectivity and edge computing resources to a vehicle equipped with a 5G modem."],"url":"http://arxiv.org/abs/2311.07391v1"}
{"created":"2023-11-13 15:14:53","title":"Evaluating the Significance of Outdoor Advertising from Driver's Perspective Using Computer Vision","abstract":"Outdoor advertising, such as roadside billboards, plays a significant role in marketing campaigns but can also be a distraction for drivers, potentially leading to accidents. In this study, we propose a pipeline for evaluating the significance of roadside billboards in videos captured from a driver's perspective. We have collected and annotated a new BillboardLamac dataset, comprising eight videos captured by drivers driving through a predefined path wearing eye-tracking devices. The dataset includes annotations of billboards, including 154 unique IDs and 155 thousand bounding boxes, as well as eye fixation data. We evaluate various object tracking methods in combination with a YOLOv8 detector to identify billboard advertisements with the best approach achieving 38.5 HOTA on BillboardLamac. Additionally, we train a random forest classifier to classify billboards into three classes based on the length of driver fixations achieving 75.8% test accuracy. An analysis of the trained classifier reveals that the duration of billboard visibility, its saliency, and size are the most influential features when assessing billboard significance.","sentences":["Outdoor advertising, such as roadside billboards, plays a significant role in marketing campaigns but can also be a distraction for drivers, potentially leading to accidents.","In this study, we propose a pipeline for evaluating the significance of roadside billboards in videos captured from a driver's perspective.","We have collected and annotated a new BillboardLamac dataset, comprising eight videos captured by drivers driving through a predefined path wearing eye-tracking devices.","The dataset includes annotations of billboards, including 154 unique IDs and 155 thousand bounding boxes, as well as eye fixation data.","We evaluate various object tracking methods in combination with a YOLOv8 detector to identify billboard advertisements with the best approach achieving 38.5 HOTA on BillboardLamac.","Additionally, we train a random forest classifier to classify billboards into three classes based on the length of driver fixations achieving 75.8% test accuracy.","An analysis of the trained classifier reveals that the duration of billboard visibility, its saliency, and size are the most influential features when assessing billboard significance."],"url":"http://arxiv.org/abs/2311.07390v1"}
{"created":"2023-11-13 15:14:50","title":"Transpose Attack: Stealing Datasets with Bidirectional Training","abstract":"Deep neural networks are normally executed in the forward direction. However, in this work, we identify a vulnerability that enables models to be trained in both directions and on different tasks. Adversaries can exploit this capability to hide rogue models within seemingly legitimate models. In addition, in this work we show that neural networks can be taught to systematically memorize and retrieve specific samples from datasets. Together, these findings expose a novel method in which adversaries can exfiltrate datasets from protected learning environments under the guise of legitimate models. We focus on the data exfiltration attack and show that modern architectures can be used to secretly exfiltrate tens of thousands of samples with high fidelity, high enough to compromise data privacy and even train new models. Moreover, to mitigate this threat we propose a novel approach for detecting infected models.","sentences":["Deep neural networks are normally executed in the forward direction.","However, in this work, we identify a vulnerability that enables models to be trained in both directions and on different tasks.","Adversaries can exploit this capability to hide rogue models within seemingly legitimate models.","In addition, in this work we show that neural networks can be taught to systematically memorize and retrieve specific samples from datasets.","Together, these findings expose a novel method in which adversaries can exfiltrate datasets from protected learning environments under the guise of legitimate models.","We focus on the data exfiltration attack and show that modern architectures can be used to secretly exfiltrate tens of thousands of samples with high fidelity, high enough to compromise data privacy and even train new models.","Moreover, to mitigate this threat we propose a novel approach for detecting infected models."],"url":"http://arxiv.org/abs/2311.07389v1"}
{"created":"2023-11-13 15:11:26","title":"Assessing Logical Puzzle Solving in Large Language Models: Insights from a Minesweeper Case Study","abstract":"Large Language Models (LLMs) have shown remarkable proficiency in language understanding and have been successfully applied to a variety of real-world tasks through task-specific fine-tuning or prompt engineering. Despite these advancements, it remains an open question whether LLMs are fundamentally capable of reasoning and planning, or if they primarily rely on recalling and synthesizing information from their training data. In our research, we introduce a novel task -- Minesweeper -- specifically designed in a format unfamiliar to LLMs and absent from their training datasets. This task challenges LLMs to identify the locations of mines based on numerical clues provided by adjacent opened cells. Successfully completing this task requires an understanding of each cell's state, discerning spatial relationships between the clues and mines, and strategizing actions based on logical deductions drawn from the arrangement of the cells. Our experiments, including trials with the advanced GPT-4 model, indicate that while LLMs possess the foundational abilities required for this task, they struggle to integrate these into a coherent, multi-step logical reasoning process needed to solve Minesweeper. These findings highlight the need for further research to understand and nature of reasoning capabilities in LLMs under similar circumstances, and to explore pathways towards more sophisticated AI reasoning and planning models.","sentences":["Large Language Models (LLMs) have shown remarkable proficiency in language understanding and have been successfully applied to a variety of real-world tasks through task-specific fine-tuning or prompt engineering.","Despite these advancements, it remains an open question whether LLMs are fundamentally capable of reasoning and planning, or if they primarily rely on recalling and synthesizing information from their training data.","In our research, we introduce a novel task -- Minesweeper -- specifically designed in a format unfamiliar to LLMs and absent from their training datasets.","This task challenges LLMs to identify the locations of mines based on numerical clues provided by adjacent opened cells.","Successfully completing this task requires an understanding of each cell's state, discerning spatial relationships between the clues and mines, and strategizing actions based on logical deductions drawn from the arrangement of the cells.","Our experiments, including trials with the advanced GPT-4 model, indicate that while LLMs possess the foundational abilities required for this task, they struggle to integrate these into a coherent, multi-step logical reasoning process needed to solve Minesweeper.","These findings highlight the need for further research to understand and nature of reasoning capabilities in LLMs under similar circumstances, and to explore pathways towards more sophisticated AI reasoning and planning models."],"url":"http://arxiv.org/abs/2311.07387v1"}
{"created":"2023-11-13 15:09:54","title":"P4-PSFP: P4-Based Per-Stream Filtering and Policing for Time-Sensitive Networking","abstract":"Time-Sensitive Networking (TSN) extends Ethernet to enable real-time communication, including the Credit-Based Shaper (CBS) for prioritized scheduling and the Time-Aware Shaper (TAS) for scheduled traffic. Generally, TSN requires streams to be explicitly admitted before being transmitted. To ensure that admitted traffic conforms with the traffic descriptors indicated for admission control, Per-Stream Filtering and Policing (PSFP) has been defined. For credit-based metering, well-known token bucket policers are applied. However, time-based metering requires time-dependent switch behavior and time synchronization with sub-microsecond precision. While TSN-capable switches support various TSN traffic shaping mechanisms, a full implementation of PSFP is still not available. To bridge this gap, we present a P4-based implementation of PSFP on a 100 Gb/s per port hardware switch. We explain the most interesting aspects of the PSFP implementation whose code is available on GitHub. We demonstrate credit-based and time-based policing and synchronization capabilities to validate the functionality and effectiveness of P4-PSFP. The implementation scales up to 35840 streams depending on the stream identification method. P4-PSFP can be used in practice as long as appropriate TSN switches lack this function. Moreover, its implementation may be helpful for other P4-based hardware implementations that require time synchronization.","sentences":["Time-Sensitive Networking (TSN) extends Ethernet to enable real-time communication, including the Credit-Based Shaper (CBS) for prioritized scheduling and the Time-Aware Shaper (TAS) for scheduled traffic.","Generally, TSN requires streams to be explicitly admitted before being transmitted.","To ensure that admitted traffic conforms with the traffic descriptors indicated for admission control, Per-Stream Filtering and Policing (PSFP) has been defined.","For credit-based metering, well-known token bucket policers are applied.","However, time-based metering requires time-dependent switch behavior and time synchronization with sub-microsecond precision.","While TSN-capable switches support various TSN traffic shaping mechanisms, a full implementation of PSFP is still not available.","To bridge this gap, we present a P4-based implementation of PSFP on a 100 Gb/s per port hardware switch.","We explain the most interesting aspects of the PSFP implementation whose code is available on GitHub.","We demonstrate credit-based and time-based policing and synchronization capabilities to validate the functionality and effectiveness of P4-PSFP.","The implementation scales up to 35840 streams depending on the stream identification method.","P4-PSFP can be used in practice as long as appropriate TSN switches lack this function.","Moreover, its implementation may be helpful for other P4-based hardware implementations that require time synchronization."],"url":"http://arxiv.org/abs/2311.07385v1"}
{"created":"2023-11-13 15:08:59","title":"LM-Polygraph: Uncertainty Estimation for Language Models","abstract":"Recent advancements in the capabilities of large language models (LLMs) have paved the way for a myriad of groundbreaking applications in various fields. However, a significant challenge arises as these models often \"hallucinate\", i.e., fabricate facts without providing users an apparent means to discern the veracity of their statements. Uncertainty estimation (UE) methods are one path to safer, more responsible, and more effective use of LLMs. However, to date, research on UE methods for LLMs has been focused primarily on theoretical rather than engineering contributions. In this work, we tackle this issue by introducing LM-Polygraph, a framework with implementations of a battery of state-of-the-art UE methods for LLMs in text generation tasks, with unified program interfaces in Python. Additionally, it introduces an extendable benchmark for consistent evaluation of UE techniques by researchers, and a demo web application that enriches the standard chat dialog with confidence scores, empowering end-users to discern unreliable responses. LM-Polygraph is compatible with the most recent LLMs, including BLOOMz, LLaMA-2, ChatGPT, and GPT-4, and is designed to support future releases of similarly-styled LMs.","sentences":["Recent advancements in the capabilities of large language models (LLMs) have paved the way for a myriad of groundbreaking applications in various fields.","However, a significant challenge arises as these models often \"hallucinate\", i.e., fabricate facts without providing users an apparent means to discern the veracity of their statements.","Uncertainty estimation (UE) methods are one path to safer, more responsible, and more effective use of LLMs.","However, to date, research on UE methods for LLMs has been focused primarily on theoretical rather than engineering contributions.","In this work, we tackle this issue by introducing LM-Polygraph, a framework with implementations of a battery of state-of-the-art UE methods for LLMs in text generation tasks, with unified program interfaces in Python.","Additionally, it introduces an extendable benchmark for consistent evaluation of UE techniques by researchers, and a demo web application that enriches the standard chat dialog with confidence scores, empowering end-users to discern unreliable responses.","LM-Polygraph is compatible with the most recent LLMs, including BLOOMz, LLaMA-2, ChatGPT, and GPT-4, and is designed to support future releases of similarly-styled LMs."],"url":"http://arxiv.org/abs/2311.07383v1"}
{"created":"2023-11-13 14:56:14","title":"Testing learning-enabled cyber-physical systems with Large-Language Models: A Formal Approach","abstract":"The integration of machine learning (ML) into cyber-physical systems (CPS) offers significant benefits, including enhanced efficiency, predictive capabilities, real-time responsiveness, and the enabling of autonomous operations. This convergence has accelerated the development and deployment of a range of real-world applications, such as autonomous vehicles, delivery drones, service robots, and telemedicine procedures. However, the software development life cycle (SDLC) for AI-infused CPS diverges significantly from traditional approaches, featuring data and learning as two critical components. Existing verification and validation techniques are often inadequate for these new paradigms. In this study, we pinpoint the main challenges in ensuring formal safety for learningenabled CPS.We begin by examining testing as the most pragmatic method for verification and validation, summarizing the current state-of-the-art methodologies. Recognizing the limitations in current testing approaches to provide formal safety guarantees, we propose a roadmap to transition from foundational probabilistic testing to a more rigorous approach capable of delivering formal assurance.","sentences":["The integration of machine learning (ML) into cyber-physical systems (CPS) offers significant benefits, including enhanced efficiency, predictive capabilities, real-time responsiveness, and the enabling of autonomous operations.","This convergence has accelerated the development and deployment of a range of real-world applications, such as autonomous vehicles, delivery drones, service robots, and telemedicine procedures.","However, the software development life cycle (SDLC) for AI-infused CPS diverges significantly from traditional approaches, featuring data and learning as two critical components.","Existing verification and validation techniques are often inadequate for these new paradigms.","In this study, we pinpoint the main challenges in ensuring formal safety for learningenabled CPS.We begin by examining testing as the most pragmatic method for verification and validation, summarizing the current state-of-the-art methodologies.","Recognizing the limitations in current testing approaches to provide formal safety guarantees, we propose a roadmap to transition from foundational probabilistic testing to a more rigorous approach capable of delivering formal assurance."],"url":"http://arxiv.org/abs/2311.07377v1"}
{"created":"2023-11-13 14:36:29","title":"Classification of developmental and brain disorders via graph convolutional aggregation","abstract":"While graph convolution based methods have become the de-facto standard for graph representation learning, their applications to disease prediction tasks remain quite limited, particularly in the classification of neurodevelopmental and neurodegenerative brain disorders. In this paper, we introduce an aggregator normalization graph convolutional network by leveraging aggregation in graph sampling, as well as skip connections and identity mapping. The proposed model learns discriminative graph node representations by incorporating both imaging and non-imaging features into the graph nodes and edges, respectively, with the aim of augmenting predictive capabilities and providing a holistic perspective on the underlying mechanisms of brain disorders. Skip connections enable the direct flow of information from the input features to later layers of the network, while identity mapping helps maintain the structural information of the graph during feature learning. We benchmark our model against several recent baseline methods on two large datasets, Autism Brain Imaging Data Exchange (ABIDE) and Alzheimer's Disease Neuroimaging Initiative (ADNI), for the prediction of autism spectrum disorder and Alzheimer's disease, respectively. Experimental results demonstrate the competitive performance of our approach in comparison with recent baselines in terms of several evaluation metrics, achieving relative improvements of 50% and 13.56% in classification accuracy over graph convolutional networks on ABIDE and ADNI, respectively.","sentences":["While graph convolution based methods have become the de-facto standard for graph representation learning, their applications to disease prediction tasks remain quite limited, particularly in the classification of neurodevelopmental and neurodegenerative brain disorders.","In this paper, we introduce an aggregator normalization graph convolutional network by leveraging aggregation in graph sampling, as well as skip connections and identity mapping.","The proposed model learns discriminative graph node representations by incorporating both imaging and non-imaging features into the graph nodes and edges, respectively, with the aim of augmenting predictive capabilities and providing a holistic perspective on the underlying mechanisms of brain disorders.","Skip connections enable the direct flow of information from the input features to later layers of the network, while identity mapping helps maintain the structural information of the graph during feature learning.","We benchmark our model against several recent baseline methods on two large datasets, Autism Brain Imaging Data Exchange (ABIDE) and Alzheimer's Disease Neuroimaging Initiative (ADNI), for the prediction of autism spectrum disorder and Alzheimer's disease, respectively.","Experimental results demonstrate the competitive performance of our approach in comparison with recent baselines in terms of several evaluation metrics, achieving relative improvements of 50% and 13.56% in classification accuracy over graph convolutional networks on ABIDE and ADNI, respectively."],"url":"http://arxiv.org/abs/2311.07370v1"}
{"created":"2023-11-13 14:34:00","title":"Unboxed data constructors -- or, how cpp decides a halting problem","abstract":"We propose a new language feature for ML-family languages, the ability to selectively *unbox* certain data constructors, so that their runtime representation gets compiled away to just the identity on their argument.   Unboxing must be statically rejected when it could introduce *confusions*, that is, distinct values with the same representation.   We discuss the use-case of big numbers, where unboxing allows to write code that is both efficient and safe, replacing either a safe but slow version or a fast but unsafe version.   We explain the static analysis necessary to reject incorrect unboxing requests.   We present our prototype implementation of this feature for the OCaml programming language, discuss several design choices and the interaction with advanced features such as Guarded Algebraic Datatypes.   Our static analysis requires expanding type definitions in type expressions, which is not necessarily normalizing in presence of recursive type definitions. In other words, we must decide normalization of terms in the first-order lambda-calculus with recursion. We provide an algorithm to detect non-termination on-the-fly during reduction, with proofs of correctness and completeness.   Our termination-monitoring algorithm turns out to be closely related to the normalization strategy for macro expansion in the `cpp` preprocessor.","sentences":["We propose a new language feature for ML-family languages, the ability to selectively *unbox* certain data constructors, so that their runtime representation gets compiled away to just the identity on their argument.   ","Unboxing must be statically rejected when it could introduce *confusions*, that is, distinct values with the same representation.   ","We discuss the use-case of big numbers, where unboxing allows to write code that is both efficient and safe, replacing either a safe but slow version or a fast but unsafe version.   ","We explain the static analysis necessary to reject incorrect unboxing requests.   ","We present our prototype implementation of this feature for the OCaml programming language, discuss several design choices and the interaction with advanced features such as Guarded Algebraic Datatypes.   ","Our static analysis requires expanding type definitions in type expressions, which is not necessarily normalizing in presence of recursive type definitions.","In other words, we must decide normalization of terms in the first-order lambda-calculus with recursion.","We provide an algorithm to detect non-termination on-the-fly during reduction, with proofs of correctness and completeness.   ","Our termination-monitoring algorithm turns out to be closely related to the normalization strategy for macro expansion in the `cpp` preprocessor."],"url":"http://arxiv.org/abs/2311.07369v1"}
