{"created":"2023-10-03 17:59:58","title":"DREAM: Visual Decoding from Reversing Human Visual System","abstract":"In this work we present DREAM, an fMRI-to-image method for reconstructing viewed images from brain activities, grounded on fundamental knowledge of the human visual system. We craft reverse pathways that emulate the hierarchical and parallel nature of how humans perceive the visual world. These tailored pathways are specialized to decipher semantics, color, and depth cues from fMRI data, mirroring the forward pathways from visual stimuli to fMRI recordings. To do so, two components mimic the inverse processes within the human visual system: the Reverse Visual Association Cortex (R-VAC) which reverses pathways of this brain region, extracting semantics from fMRI data; the Reverse Parallel PKM (R-PKM) component simultaneously predicting color and depth from fMRI signals. The experiments indicate that our method outperforms the current state-of-the-art models in terms of the consistency of appearance, structure, and semantics. Code will be made publicly available to facilitate further research in this field.","sentences":["In this work we present DREAM, an fMRI-to-image method for reconstructing viewed images from brain activities, grounded on fundamental knowledge of the human visual system.","We craft reverse pathways that emulate the hierarchical and parallel nature of how humans perceive the visual world.","These tailored pathways are specialized to decipher semantics, color, and depth cues from fMRI data, mirroring the forward pathways from visual stimuli to fMRI recordings.","To do so, two components mimic the inverse processes within the human visual system: the Reverse Visual Association Cortex (R-VAC) which reverses pathways of this brain region, extracting semantics from fMRI data; the Reverse Parallel PKM (R-PKM) component simultaneously predicting color and depth from fMRI signals.","The experiments indicate that our method outperforms the current state-of-the-art models in terms of the consistency of appearance, structure, and semantics.","Code will be made publicly available to facilitate further research in this field."],"url":"http://arxiv.org/abs/2310.02265v1"}
{"created":"2023-10-03 17:59:46","title":"Contrastive Post-training Large Language Models on Data Curriculum","abstract":"Alignment serves as an important step to steer large language models (LLMs) towards human preferences. In this paper, we explore contrastive post-training techniques for alignment by automatically constructing preference pairs from multiple models of varying strengths (e.g., InstructGPT, ChatGPT and GPT-4). We carefully compare the contrastive techniques of SLiC and DPO to SFT baselines and find that DPO provides a step-function improvement even after continueing SFT saturates. We also explore a data curriculum learning scheme for contrastive post-training, which starts by learning from \"easier\" pairs and transitioning to \"harder\" ones, which further improves alignment. Finally, we scale up our experiments to train with more data and larger models like Orca. Remarkably, contrastive post-training further improves the performance of Orca, already a state-of-the-art instruction learning model tuned with GPT-4 outputs, to exceed that of ChatGPT.","sentences":["Alignment serves as an important step to steer large language models (LLMs) towards human preferences.","In this paper, we explore contrastive post-training techniques for alignment by automatically constructing preference pairs from multiple models of varying strengths (e.g., InstructGPT, ChatGPT and GPT-4).","We carefully compare the contrastive techniques of SLiC and DPO to SFT baselines and find that DPO provides a step-function improvement even after continueing SFT saturates.","We also explore a data curriculum learning scheme for contrastive post-training, which starts by learning from \"easier\" pairs and transitioning to \"harder\" ones, which further improves alignment.","Finally, we scale up our experiments to train with more data and larger models like Orca.","Remarkably, contrastive post-training further improves the performance of Orca, already a state-of-the-art instruction learning model tuned with GPT-4 outputs, to exceed that of ChatGPT."],"url":"http://arxiv.org/abs/2310.02263v1"}
{"created":"2023-10-03 17:59:46","title":"Generalizable Long-Horizon Manipulations with Large Language Models","abstract":"This work introduces a framework harnessing the capabilities of Large Language Models (LLMs) to generate primitive task conditions for generalizable long-horizon manipulations with novel objects and unseen tasks. These task conditions serve as guides for the generation and adjustment of Dynamic Movement Primitives (DMP) trajectories for long-horizon task execution. We further create a challenging robotic manipulation task suite based on Pybullet for long-horizon task evaluation. Extensive experiments in both simulated and real-world environments demonstrate the effectiveness of our framework on both familiar tasks involving new objects and novel but related tasks, highlighting the potential of LLMs in enhancing robotic system versatility and adaptability. Project website: https://object814.github.io/Task-Condition-With-LLM/","sentences":["This work introduces a framework harnessing the capabilities of Large Language Models (LLMs) to generate primitive task conditions for generalizable long-horizon manipulations with novel objects and unseen tasks.","These task conditions serve as guides for the generation and adjustment of Dynamic Movement Primitives (DMP) trajectories for long-horizon task execution.","We further create a challenging robotic manipulation task suite based on Pybullet for long-horizon task evaluation.","Extensive experiments in both simulated and real-world environments demonstrate the effectiveness of our framework on both familiar tasks involving new objects and novel but related tasks, highlighting the potential of LLMs in enhancing robotic system versatility and adaptability.","Project website: https://object814.github.io/Task-Condition-With-LLM/"],"url":"http://arxiv.org/abs/2310.02264v1"}
{"created":"2023-10-03 17:59:32","title":"RSRD: A Road Surface Reconstruction Dataset and Benchmark for Safe and Comfortable Autonomous Driving","abstract":"This paper addresses the growing demands for safety and comfort in intelligent robot systems, particularly autonomous vehicles, where road conditions play a pivotal role in overall driving performance. For example, reconstructing road surfaces helps to enhance the analysis and prediction of vehicle responses for motion planning and control systems. We introduce the Road Surface Reconstruction Dataset (RSRD), a real-world, high-resolution, and high-precision dataset collected with a specialized platform in diverse driving conditions. It covers common road types containing approximately 16,000 pairs of stereo images, original point clouds, and ground-truth depth/disparity maps, with accurate post-processing pipelines to ensure its quality. Based on RSRD, we further build a comprehensive benchmark for recovering road profiles through depth estimation and stereo matching. Preliminary evaluations with various state-of-the-art methods reveal the effectiveness of our dataset and the challenge of the task, underscoring substantial opportunities of RSRD as a valuable resource for advancing techniques, e.g., multi-view stereo towards safe autonomous driving. The dataset and demo videos are available at https://thu-rsxd.com/rsrd/","sentences":["This paper addresses the growing demands for safety and comfort in intelligent robot systems, particularly autonomous vehicles, where road conditions play a pivotal role in overall driving performance.","For example, reconstructing road surfaces helps to enhance the analysis and prediction of vehicle responses for motion planning and control systems.","We introduce the Road Surface Reconstruction Dataset (RSRD), a real-world, high-resolution, and high-precision dataset collected with a specialized platform in diverse driving conditions.","It covers common road types containing approximately 16,000 pairs of stereo images, original point clouds, and ground-truth depth/disparity maps, with accurate post-processing pipelines to ensure its quality.","Based on RSRD, we further build a comprehensive benchmark for recovering road profiles through depth estimation and stereo matching.","Preliminary evaluations with various state-of-the-art methods reveal the effectiveness of our dataset and the challenge of the task, underscoring substantial opportunities of RSRD as a valuable resource for advancing techniques, e.g., multi-view stereo towards safe autonomous driving.","The dataset and demo videos are available at https://thu-rsxd.com/rsrd/"],"url":"http://arxiv.org/abs/2310.02262v1"}
{"created":"2023-10-03 17:59:05","title":"TransRadar: Adaptive-Directional Transformer for Real-Time Multi-View Radar Semantic Segmentation","abstract":"Scene understanding plays an essential role in enabling autonomous driving and maintaining high standards of performance and safety. To address this task, cameras and laser scanners (LiDARs) have been the most commonly used sensors, with radars being less popular. Despite that, radars remain low-cost, information-dense, and fast-sensing techniques that are resistant to adverse weather conditions. While multiple works have been previously presented for radar-based scene semantic segmentation, the nature of the radar data still poses a challenge due to the inherent noise and sparsity, as well as the disproportionate foreground and background. In this work, we propose a novel approach to the semantic segmentation of radar scenes using a multi-input fusion of radar data through a novel architecture and loss functions that are tailored to tackle the drawbacks of radar perception. Our novel architecture includes an efficient attention block that adaptively captures important feature information. Our method, TransRadar, outperforms state-of-the-art methods on the CARRADA and RADIal datasets while having smaller model sizes. https://github.com/YahiDar/TransRadar","sentences":["Scene understanding plays an essential role in enabling autonomous driving and maintaining high standards of performance and safety.","To address this task, cameras and laser scanners (LiDARs) have been the most commonly used sensors, with radars being less popular.","Despite that, radars remain low-cost, information-dense, and fast-sensing techniques that are resistant to adverse weather conditions.","While multiple works have been previously presented for radar-based scene semantic segmentation, the nature of the radar data still poses a challenge due to the inherent noise and sparsity, as well as the disproportionate foreground and background.","In this work, we propose a novel approach to the semantic segmentation of radar scenes using a multi-input fusion of radar data through a novel architecture and loss functions that are tailored to tackle the drawbacks of radar perception.","Our novel architecture includes an efficient attention block that adaptively captures important feature information.","Our method, TransRadar, outperforms state-of-the-art methods on the CARRADA and RADIal datasets while having smaller model sizes.","https://github.com/YahiDar/TransRadar"],"url":"http://arxiv.org/abs/2310.02260v1"}
{"created":"2023-10-03 17:58:33","title":"A Neural Scaling Law from Lottery Ticket Ensembling","abstract":"Neural scaling laws (NSL) refer to the phenomenon where model performance improves with scale. Sharma & Kaplan analyzed NSL using approximation theory and predict that MSE losses decay as $N^{-\\alpha}$, $\\alpha=4/d$, where $N$ is the number of model parameters, and $d$ is the intrinsic input dimension. Although their theory works well for some cases (e.g., ReLU networks), we surprisingly find that a simple 1D problem $y=x^2$ manifests a different scaling law ($\\alpha=1$) from their predictions ($\\alpha=4$). We opened the neural networks and found that the new scaling law originates from lottery ticket ensembling: a wider network on average has more \"lottery tickets\", which are ensembled to reduce the variance of outputs. We support the ensembling mechanism by mechanistically interpreting single neural networks, as well as studying them statistically. We attribute the $N^{-1}$ scaling law to the \"central limit theorem\" of lottery tickets. Finally, we discuss its potential implications for large language models and statistical physics-type theories of learning.","sentences":["Neural scaling laws (NSL) refer to the phenomenon where model performance improves with scale.","Sharma & Kaplan analyzed NSL using approximation theory and predict that MSE losses decay as $N^{-\\alpha}$, $\\alpha=4/d$, where $N$ is the number of model parameters, and $d$ is the intrinsic input dimension.","Although their theory works well for some cases (e.g., ReLU networks), we surprisingly find that a simple 1D problem $y=x^2$ manifests a different scaling law ($\\alpha=1$) from their predictions ($\\alpha=4$).","We opened the neural networks and found that the new scaling law originates from lottery ticket ensembling: a wider network on average has more \"lottery tickets\", which are ensembled to reduce the variance of outputs.","We support the ensembling mechanism by mechanistically interpreting single neural networks, as well as studying them statistically.","We attribute the $N^{-1}$ scaling law to the \"central limit theorem\" of lottery tickets.","Finally, we discuss its potential implications for large language models and statistical physics-type theories of learning."],"url":"http://arxiv.org/abs/2310.02258v1"}
{"created":"2023-10-03 17:57:24","title":"MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts","abstract":"Although Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit impressive skills in various domains, their ability for mathematical reasoning within visual contexts has not been formally examined. Equipping LLMs and LMMs with this capability is vital for general-purpose AI assistants and showcases promising potential in education, data analysis, and scientific discovery. To bridge this gap, we present MathVista, a benchmark designed to amalgamate challenges from diverse mathematical and visual tasks. We first taxonomize the key task types, reasoning skills, and visual contexts from the literature to guide our selection from 28 existing math-focused and visual question answering datasets. Then, we construct three new datasets, IQTest, FunctionQA, and PaperQA, to accommodate for missing types of visual contexts. The problems featured often require deep visual understanding beyond OCR or image captioning, and compositional reasoning with rich domain-specific tools, thus posing a notable challenge to existing models. We conduct a comprehensive evaluation of 11 prominent open-source and proprietary foundation models (LLMs, LLMs augmented with tools, and LMMs), and early experiments with GPT-4V. The best-performing model, Multimodal Bard, achieves only 58% of human performance (34.8% vs 60.3%), indicating ample room for further improvement. Given this significant gap, MathVista fuels future research in the development of general-purpose AI agents capable of tackling mathematically intensive and visually rich real-world tasks. Preliminary tests show that MathVista also presents challenges to GPT-4V, underscoring the benchmark's importance. The project is available at https://mathvista.github.io/.","sentences":["Although Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit impressive skills in various domains, their ability for mathematical reasoning within visual contexts has not been formally examined.","Equipping LLMs and LMMs with this capability is vital for general-purpose AI assistants and showcases promising potential in education, data analysis, and scientific discovery.","To bridge this gap, we present MathVista, a benchmark designed to amalgamate challenges from diverse mathematical and visual tasks.","We first taxonomize the key task types, reasoning skills, and visual contexts from the literature to guide our selection from 28 existing math-focused and visual question answering datasets.","Then, we construct three new datasets, IQTest, FunctionQA, and PaperQA, to accommodate for missing types of visual contexts.","The problems featured often require deep visual understanding beyond OCR or image captioning, and compositional reasoning with rich domain-specific tools, thus posing a notable challenge to existing models.","We conduct a comprehensive evaluation of 11 prominent open-source and proprietary foundation models (LLMs, LLMs augmented with tools, and LMMs), and early experiments with GPT-4V. The best-performing model, Multimodal Bard, achieves only 58% of human performance (34.8% vs 60.3%), indicating ample room for further improvement.","Given this significant gap, MathVista fuels future research in the development of general-purpose AI agents capable of tackling mathematically intensive and visually rich real-world tasks.","Preliminary tests show that MathVista also presents challenges to GPT-4V, underscoring the benchmark's importance.","The project is available at https://mathvista.github.io/."],"url":"http://arxiv.org/abs/2310.02255v1"}
{"created":"2023-10-03 17:53:51","title":"Talk2BEV: Language-enhanced Bird's-eye View Maps for Autonomous Driving","abstract":"Talk2BEV is a large vision-language model (LVLM) interface for bird's-eye view (BEV) maps in autonomous driving contexts. While existing perception systems for autonomous driving scenarios have largely focused on a pre-defined (closed) set of object categories and driving scenarios, Talk2BEV blends recent advances in general-purpose language and vision models with BEV-structured map representations, eliminating the need for task-specific models. This enables a single system to cater to a variety of autonomous driving tasks encompassing visual and spatial reasoning, predicting the intents of traffic actors, and decision-making based on visual cues. We extensively evaluate Talk2BEV on a large number of scene understanding tasks that rely on both the ability to interpret free-form natural language queries, and in grounding these queries to the visual context embedded into the language-enhanced BEV map. To enable further research in LVLMs for autonomous driving scenarios, we develop and release Talk2BEV-Bench, a benchmark encompassing 1000 human-annotated BEV scenarios, with more than 20,000 questions and ground-truth responses from the NuScenes dataset.","sentences":["Talk2BEV is a large vision-language model (LVLM) interface for bird's-eye view (BEV) maps in autonomous driving contexts.","While existing perception systems for autonomous driving scenarios have largely focused on a pre-defined (closed) set of object categories and driving scenarios, Talk2BEV blends recent advances in general-purpose language and vision models with BEV-structured map representations, eliminating the need for task-specific models.","This enables a single system to cater to a variety of autonomous driving tasks encompassing visual and spatial reasoning, predicting the intents of traffic actors, and decision-making based on visual cues.","We extensively evaluate Talk2BEV on a large number of scene understanding tasks that rely on both the ability to interpret free-form natural language queries, and in grounding these queries to the visual context embedded into the language-enhanced BEV map.","To enable further research in LVLMs for autonomous driving scenarios, we develop and release Talk2BEV-Bench, a benchmark encompassing 1000 human-annotated BEV scenarios, with more than 20,000 questions and ground-truth responses from the NuScenes dataset."],"url":"http://arxiv.org/abs/2310.02251v1"}
{"created":"2023-10-03 17:53:43","title":"Why do autoencoders work?","abstract":"Deep neural network autoencoders are routinely used computationally for model reduction. They allow recognizing the intrinsic dimension of data that lie in a $k$-dimensional subset $K$ of an input Euclidean space $\\R^n$. The underlying idea is to obtain both an encoding layer that maps $\\R^n$ into $\\R^k$ (called the bottleneck layer or the space of latent variables) and a decoding layer that maps $\\R^k$ back into $\\R^n$, in such a way that the input data from the set $K$ is recovered when composing the two maps. This is achieved by adjusting parameters (weights) in the network to minimize the discrepancy between the input and the reconstructed output. Since neural networks (with continuous activation functions) compute continuous maps, the existence of a network that achieves perfect reconstruction would imply that $K$ is homeomorphic to a $k$-dimensional subset of $\\R^k$, so clearly there are topological obstructions to finding such a network. On the other hand, in practice the technique is found to ``work'' well, which leads one to ask if there is a way to explain this effectiveness. We show that, up to small errors, indeed the method is guaranteed to work. This is done by appealing to certain facts from differential geometry. A computational example is also included to illustrate the ideas.","sentences":["Deep neural network autoencoders are routinely used computationally for model reduction.","They allow recognizing the intrinsic dimension of data that lie in a $k$-dimensional subset $K$ of an input Euclidean space $\\R^n$. The underlying idea is to obtain both an encoding layer that maps $\\R^n$ into $\\R^k$ (called the bottleneck layer or the space of latent variables) and a decoding layer that maps $\\R^k$ back into $\\R^n$, in such a way that the input data from the set $K$ is recovered when composing the two maps.","This is achieved by adjusting parameters (weights) in the network to minimize the discrepancy between the input and the reconstructed output.","Since neural networks (with continuous activation functions) compute continuous maps, the existence of a network that achieves perfect reconstruction would imply that $K$ is homeomorphic to a $k$-dimensional subset of $\\R^k$, so clearly there are topological obstructions to finding such a network.","On the other hand, in practice the technique is found to ``work'' well, which leads one to ask if there is a way to explain this effectiveness.","We show that, up to small errors, indeed the method is guaranteed to work.","This is done by appealing to certain facts from differential geometry.","A computational example is also included to illustrate the ideas."],"url":"http://arxiv.org/abs/2310.02250v1"}
{"created":"2023-10-03 17:53:09","title":"Harnessing Pre-Trained Sentence Transformers for Offensive Language Detection in Indian Languages","abstract":"In our increasingly interconnected digital world, social media platforms have emerged as powerful channels for the dissemination of hate speech and offensive content. This work delves into the domain of hate speech detection, placing specific emphasis on three low-resource Indian languages: Bengali, Assamese, and Gujarati. The challenge is framed as a text classification task, aimed at discerning whether a tweet contains offensive or non-offensive content. Leveraging the HASOC 2023 datasets, we fine-tuned pre-trained BERT and SBERT models to evaluate their effectiveness in identifying hate speech. Our findings underscore the superiority of monolingual sentence-BERT models, particularly in the Bengali language, where we achieved the highest ranking. However, the performance in Assamese and Gujarati languages signifies ongoing opportunities for enhancement. Our goal is to foster inclusive online spaces by countering hate speech proliferation.","sentences":["In our increasingly interconnected digital world, social media platforms have emerged as powerful channels for the dissemination of hate speech and offensive content.","This work delves into the domain of hate speech detection, placing specific emphasis on three low-resource Indian languages: Bengali, Assamese, and Gujarati.","The challenge is framed as a text classification task, aimed at discerning whether a tweet contains offensive or non-offensive content.","Leveraging the HASOC 2023 datasets, we fine-tuned pre-trained BERT and SBERT models to evaluate their effectiveness in identifying hate speech.","Our findings underscore the superiority of monolingual sentence-BERT models, particularly in the Bengali language, where we achieved the highest ranking.","However, the performance in Assamese and Gujarati languages signifies ongoing opportunities for enhancement.","Our goal is to foster inclusive online spaces by countering hate speech proliferation."],"url":"http://arxiv.org/abs/2310.02249v1"}
{"created":"2023-10-03 17:51:55","title":"Efficient Enumeration of Drawings and Combinatorial Structures for Maximal Planar Graphs","abstract":"We propose efficient algorithms for enumerating the notorious combinatorial structures of maximal planar graphs, called canonical orderings and Schnyder woods, and the related classical graph drawings by de Fraysseix, Pach, and Pollack [Combinatorica, 1990] and by Schnyder [SODA, 1990], called canonical drawings and Schnyder drawings, respectively. To this aim (i) we devise an algorithm for enumerating special $e$-bipolar orientations of maximal planar graphs, called canonical orientations; (ii) we establish bijections between canonical orientations and canonical drawings, and between canonical orientations and Schnyder drawings; and (iii) we exploit the known correspondence between canonical orientations and canonical orderings, and the known bijection between canonical orientations and Schnyder woods. All our enumeration algorithms have $O(n)$ setup time, space usage, and delay between any two consecutively listed outputs, for an $n$-vertex maximal planar graph.","sentences":["We propose efficient algorithms for enumerating the notorious combinatorial structures of maximal planar graphs, called canonical orderings and Schnyder woods, and the related classical graph drawings by de Fraysseix, Pach, and Pollack [Combinatorica, 1990] and by Schnyder [SODA, 1990], called canonical drawings and Schnyder drawings, respectively.","To this aim (i) we devise an algorithm for enumerating special $e$-bipolar orientations of maximal planar graphs, called canonical orientations; (ii) we establish bijections between canonical orientations and canonical drawings, and between canonical orientations and Schnyder drawings; and (iii) we exploit the known correspondence between canonical orientations and canonical orderings, and the known bijection between canonical orientations and Schnyder woods.","All our enumeration algorithms have $O(n)$ setup time, space usage, and delay between any two consecutively listed outputs, for an $n$-vertex maximal planar graph."],"url":"http://arxiv.org/abs/2310.02247v1"}
{"created":"2023-10-03 17:51:42","title":"Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances","abstract":"Solving a linear system $Ax=b$ is a fundamental scientific computing primitive for which numerous solvers and preconditioners have been developed. These come with parameters whose optimal values depend on the system being solved and are often impossible or too expensive to identify; thus in practice sub-optimal heuristics are used. We consider the common setting in which many related linear systems need to be solved, e.g. during a single numerical simulation. In this scenario, can we sequentially choose parameters that attain a near-optimal overall number of iterations, without extra matrix computations? We answer in the affirmative for Successive Over-Relaxation (SOR), a standard solver whose parameter $\\omega$ has a strong impact on its runtime. For this method, we prove that a bandit online learning algorithm -- using only the number of iterations as feedback -- can select parameters for a sequence of instances such that the overall cost approaches that of the best fixed $\\omega$ as the sequence length increases. Furthermore, when given additional structural information, we show that a contextual bandit method asymptotically achieves the performance of the instance-optimal policy, which selects the best $\\omega$ for each instance. Our work provides the first learning-theoretic treatment of high-precision linear system solvers and the first end-to-end guarantees for data-driven scientific computing, demonstrating theoretically the potential to speed up numerical methods using well-understood learning algorithms.","sentences":["Solving a linear system $Ax=b$ is a fundamental scientific computing primitive for which numerous solvers and preconditioners have been developed.","These come with parameters whose optimal values depend on the system being solved and are often impossible or too expensive to identify; thus in practice sub-optimal heuristics are used.","We consider the common setting in which many related linear systems need to be solved, e.g. during a single numerical simulation.","In this scenario, can we sequentially choose parameters that attain a near-optimal overall number of iterations, without extra matrix computations?","We answer in the affirmative for Successive Over-Relaxation (SOR), a standard solver whose parameter $\\omega$ has a strong impact on its runtime.","For this method, we prove that a bandit online learning algorithm -- using only the number of iterations as feedback -- can select parameters for a sequence of instances such that the overall cost approaches that of the best fixed $\\omega$ as the sequence length increases.","Furthermore, when given additional structural information, we show that a contextual bandit method asymptotically achieves the performance of the instance-optimal policy, which selects the best $\\omega$ for each instance.","Our work provides the first learning-theoretic treatment of high-precision linear system solvers and the first end-to-end guarantees for data-driven scientific computing, demonstrating theoretically the potential to speed up numerical methods using well-understood learning algorithms."],"url":"http://arxiv.org/abs/2310.02246v1"}
{"created":"2023-10-03 17:50:40","title":"Tensor Programs VI: Feature Learning in Infinite-Depth Neural Networks","abstract":"By classifying infinite-width neural networks and identifying the *optimal* limit, Tensor Programs IV and V demonstrated a universal way, called $\\mu$P, for *widthwise hyperparameter transfer*, i.e., predicting optimal hyperparameters of wide neural networks from narrow ones. Here we investigate the analogous classification for *depthwise parametrizations* of deep residual networks (resnets). We classify depthwise parametrizations of block multiplier and learning rate by their infinite-width-then-depth limits. In resnets where each block has only one layer, we identify a unique optimal parametrization, called Depth-$\\mu$P that extends $\\mu$P and show empirically it admits depthwise hyperparameter transfer. We identify *feature diversity* as a crucial factor in deep networks, and Depth-$\\mu$P can be characterized as maximizing both feature learning and feature diversity. Exploiting this, we find that absolute value, among all homogeneous nonlinearities, maximizes feature diversity and indeed empirically leads to significant better performance. However, if each block is deeper (such as modern transformers), then we find fundamental limitations in all possible infinite-depth limits of such parametrizations, which we illustrate both theoretically and empirically on simple networks as well as Megatron transformer trained on Common Crawl.","sentences":["By classifying infinite-width neural networks and identifying the *optimal* limit, Tensor Programs IV and V demonstrated a universal way, called $\\mu$P, for *widthwise hyperparameter transfer*, i.e., predicting optimal hyperparameters of wide neural networks from narrow ones.","Here we investigate the analogous classification for *depthwise parametrizations* of deep residual networks (resnets).","We classify depthwise parametrizations of block multiplier and learning rate by their infinite-width-then-depth limits.","In resnets where each block has only one layer, we identify a unique optimal parametrization, called Depth-$\\mu$P that extends $\\mu$P and show empirically it admits depthwise hyperparameter transfer.","We identify *feature diversity* as a crucial factor in deep networks, and Depth-$\\mu$P can be characterized as maximizing both feature learning and feature diversity.","Exploiting this, we find that absolute value, among all homogeneous nonlinearities, maximizes feature diversity and indeed empirically leads to significant better performance.","However, if each block is deeper (such as modern transformers), then we find fundamental limitations in all possible infinite-depth limits of such parametrizations, which we illustrate both theoretically and empirically on simple networks as well as Megatron transformer trained on Common Crawl."],"url":"http://arxiv.org/abs/2310.02244v1"}
{"created":"2023-10-03 17:50:23","title":"Hierarchical Generation of Human-Object Interactions with Diffusion Probabilistic Models","abstract":"This paper presents a novel approach to generating the 3D motion of a human interacting with a target object, with a focus on solving the challenge of synthesizing long-range and diverse motions, which could not be fulfilled by existing auto-regressive models or path planning-based methods. We propose a hierarchical generation framework to solve this challenge. Specifically, our framework first generates a set of milestones and then synthesizes the motion along them. Therefore, the long-range motion generation could be reduced to synthesizing several short motion sequences guided by milestones. The experiments on the NSM, COUCH, and SAMP datasets show that our approach outperforms previous methods by a large margin in both quality and diversity. The source code is available on our project page https://zju3dv.github.io/hghoi.","sentences":["This paper presents a novel approach to generating the 3D motion of a human interacting with a target object, with a focus on solving the challenge of synthesizing long-range and diverse motions, which could not be fulfilled by existing auto-regressive models or path planning-based methods.","We propose a hierarchical generation framework to solve this challenge.","Specifically, our framework first generates a set of milestones and then synthesizes the motion along them.","Therefore, the long-range motion generation could be reduced to synthesizing several short motion sequences guided by milestones.","The experiments on the NSM, COUCH, and SAMP datasets show that our approach outperforms previous methods by a large margin in both quality and diversity.","The source code is available on our project page https://zju3dv.github.io/hghoi."],"url":"http://arxiv.org/abs/2310.02242v1"}
{"created":"2023-10-03 17:49:21","title":"Spherical Rolling Robots Design, Modeling, and Control: A Systematic Literature Review","abstract":"Spherical robots have garnered increasing interest for their applications in exploration, tunnel inspection, and extraterrestrial missions. Diverse designs have emerged, including barycentric configurations, pendulum-based mechanisms, etc. In addition, a wide spectrum of control strategies has been proposed, ranging from traditional PID approaches to cutting-edge neural networks. Our systematic review aims to comprehensively identify and categorize locomotion systems and control schemes employed by spherical robots, spanning the years 1996 to 2023. A meticulous search across five databases yielded a dataset of 3189 records. As a result of our exhaustive analysis, we identified a collection of novel designs and control strategies. Leveraging the insights garnered, we provide valuable recommendations for optimizing the design and control aspects of spherical robots, supporting both novel design endeavors and the advancement of field deployments. Furthermore, we illuminate key research directions that hold the potential to unlock the full capabilities of spherical robots","sentences":["Spherical robots have garnered increasing interest for their applications in exploration, tunnel inspection, and extraterrestrial missions.","Diverse designs have emerged, including barycentric configurations, pendulum-based mechanisms, etc.","In addition, a wide spectrum of control strategies has been proposed, ranging from traditional PID approaches to cutting-edge neural networks.","Our systematic review aims to comprehensively identify and categorize locomotion systems and control schemes employed by spherical robots, spanning the years 1996 to 2023.","A meticulous search across five databases yielded a dataset of 3189 records.","As a result of our exhaustive analysis, we identified a collection of novel designs and control strategies.","Leveraging the insights garnered, we provide valuable recommendations for optimizing the design and control aspects of spherical robots, supporting both novel design endeavors and the advancement of field deployments.","Furthermore, we illuminate key research directions that hold the potential to unlock the full capabilities of spherical robots"],"url":"http://arxiv.org/abs/2310.02240v1"}
{"created":"2023-10-03 17:49:04","title":"MiniGPT-5: Interleaved Vision-and-Language Generation via Generative Vokens","abstract":"Large Language Models (LLMs) have garnered significant attention for their advancements in natural language processing, demonstrating unparalleled prowess in text comprehension and generation. Yet, the simultaneous generation of images with coherent textual narratives remains an evolving frontier. In response, we introduce an innovative interleaved vision-and-language generation technique anchored by the concept of \"generative vokens,\" acting as the bridge for harmonized image-text outputs. Our approach is characterized by a distinctive two-staged training strategy focusing on description-free multimodal generation, where the training requires no comprehensive descriptions of images. To bolster model integrity, classifier-free guidance is incorporated, enhancing the effectiveness of vokens on image generation. Our model, MiniGPT-5, exhibits substantial improvement over the baseline Divter model on the MMDialog dataset and consistently delivers superior or comparable multimodal outputs in human evaluations on the VIST dataset, highlighting its efficacy across diverse benchmarks.","sentences":["Large Language Models (LLMs) have garnered significant attention for their advancements in natural language processing, demonstrating unparalleled prowess in text comprehension and generation.","Yet, the simultaneous generation of images with coherent textual narratives remains an evolving frontier.","In response, we introduce an innovative interleaved vision-and-language generation technique anchored by the concept of \"generative vokens,\" acting as the bridge for harmonized image-text outputs.","Our approach is characterized by a distinctive two-staged training strategy focusing on description-free multimodal generation, where the training requires no comprehensive descriptions of images.","To bolster model integrity, classifier-free guidance is incorporated, enhancing the effectiveness of vokens on image generation.","Our model, MiniGPT-5, exhibits substantial improvement over the baseline Divter model on the MMDialog dataset and consistently delivers superior or comparable multimodal outputs in human evaluations on the VIST dataset, highlighting its efficacy across diverse benchmarks."],"url":"http://arxiv.org/abs/2310.02239v1"}
{"created":"2023-10-03 17:48:14","title":"Who's Harry Potter? Approximate Unlearning in LLMs","abstract":"Large language models (LLMs) are trained on massive internet corpora that often contain copyrighted content. This poses legal and ethical challenges for the developers and users of these models, as well as the original authors and publishers. In this paper, we propose a novel technique for unlearning a subset of the training data from a LLM, without having to retrain it from scratch.   We evaluate our technique on the task of unlearning the Harry Potter books from the Llama2-7b model (a generative language model recently open-sourced by Meta). While the model took over 184K GPU-hours to pretrain, we show that in about 1 GPU hour of finetuning, we effectively erase the model's ability to generate or recall Harry Potter-related content, while its performance on common benchmarks (such as Winogrande, Hellaswag, arc, boolq and piqa) remains almost unaffected. We make our fine-tuned model publicly available on HuggingFace for community evaluation. To the best of our knowledge, this is the first paper to present an effective technique for unlearning in generative language models.   Our technique consists of three main components: First, we use a reinforced model that is further trained on the target data to identify the tokens that are most related to the unlearning target, by comparing its logits with those of a baseline model. Second, we replace idiosyncratic expressions in the target data with generic counterparts, and leverage the model's own predictions to generate alternative labels for every token. These labels aim to approximate the next-token predictions of a model that has not been trained on the target data. Third, we finetune the model on these alternative labels, which effectively erases the original text from the model's memory whenever it is prompted with its context.","sentences":["Large language models (LLMs) are trained on massive internet corpora that often contain copyrighted content.","This poses legal and ethical challenges for the developers and users of these models, as well as the original authors and publishers.","In this paper, we propose a novel technique for unlearning a subset of the training data from a LLM, without having to retrain it from scratch.   ","We evaluate our technique on the task of unlearning the Harry Potter books from the Llama2-7b model (a generative language model recently open-sourced by Meta).","While the model took over 184K GPU-hours to pretrain, we show that in about 1 GPU hour of finetuning, we effectively erase the model's ability to generate or recall Harry Potter-related content, while its performance on common benchmarks (such as Winogrande, Hellaswag, arc, boolq and piqa) remains almost unaffected.","We make our fine-tuned model publicly available on HuggingFace for community evaluation.","To the best of our knowledge, this is the first paper to present an effective technique for unlearning in generative language models.   ","Our technique consists of three main components:","First, we use a reinforced model that is further trained on the target data to identify the tokens that are most related to the unlearning target, by comparing its logits with those of a baseline model.","Second, we replace idiosyncratic expressions in the target data with generic counterparts, and leverage the model's own predictions to generate alternative labels for every token.","These labels aim to approximate the next-token predictions of a model that has not been trained on the target data.","Third, we finetune the model on these alternative labels, which effectively erases the original text from the model's memory whenever it is prompted with its context."],"url":"http://arxiv.org/abs/2310.02238v1"}
{"created":"2023-10-03 17:47:25","title":"Exploring Model Learning Heterogeneity for Boosting Ensemble Robustness","abstract":"Deep neural network ensembles hold the potential of improving generalization performance for complex learning tasks. This paper presents formal analysis and empirical evaluation to show that heterogeneous deep ensembles with high ensemble diversity can effectively leverage model learning heterogeneity to boost ensemble robustness. We first show that heterogeneous DNN models trained for solving the same learning problem, e.g., object detection, can significantly strengthen the mean average precision (mAP) through our weighted bounding box ensemble consensus method. Second, we further compose ensembles of heterogeneous models for solving different learning problems, e.g., object detection and semantic segmentation, by introducing the connected component labeling (CCL) based alignment. We show that this two-tier heterogeneity driven ensemble construction method can compose an ensemble team that promotes high ensemble diversity and low negative correlation among member models of the ensemble, strengthening ensemble robustness against both negative examples and adversarial attacks. Third, we provide a formal analysis of the ensemble robustness in terms of negative correlation. Extensive experiments validate the enhanced robustness of heterogeneous ensembles in both benign and adversarial settings. The source codes are available on GitHub at https://github.com/git-disl/HeteRobust.","sentences":["Deep neural network ensembles hold the potential of improving generalization performance for complex learning tasks.","This paper presents formal analysis and empirical evaluation to show that heterogeneous deep ensembles with high ensemble diversity can effectively leverage model learning heterogeneity to boost ensemble robustness.","We first show that heterogeneous DNN models trained for solving the same learning problem, e.g., object detection, can significantly strengthen the mean average precision (mAP) through our weighted bounding box ensemble consensus method.","Second, we further compose ensembles of heterogeneous models for solving different learning problems, e.g., object detection and semantic segmentation, by introducing the connected component labeling (CCL) based alignment.","We show that this two-tier heterogeneity driven ensemble construction method can compose an ensemble team that promotes high ensemble diversity and low negative correlation among member models of the ensemble, strengthening ensemble robustness against both negative examples and adversarial attacks.","Third, we provide a formal analysis of the ensemble robustness in terms of negative correlation.","Extensive experiments validate the enhanced robustness of heterogeneous ensembles in both benign and adversarial settings.","The source codes are available on GitHub at https://github.com/git-disl/HeteRobust."],"url":"http://arxiv.org/abs/2310.02237v1"}
{"created":"2023-10-03 17:45:39","title":"Automatic Quality Assessment of Wikipedia Articles -- A Systematic Literature Review","abstract":"Wikipedia is the world's largest online encyclopedia, but maintaining article quality through collaboration is challenging. Wikipedia designed a quality scale, but with such a manual assessment process, many articles remain unassessed. We review existing methods for automatically measuring the quality of Wikipedia articles, identifying and comparing machine learning algorithms, article features, quality metrics, and used datasets, examining 149 distinct studies, and exploring commonalities and gaps in them. The literature is extensive, and the approaches follow past technological trends. However, machine learning is still not widely used by Wikipedia, and we hope that our analysis helps future researchers change that reality.","sentences":["Wikipedia is the world's largest online encyclopedia, but maintaining article quality through collaboration is challenging.","Wikipedia designed a quality scale, but with such a manual assessment process, many articles remain unassessed.","We review existing methods for automatically measuring the quality of Wikipedia articles, identifying and comparing machine learning algorithms, article features, quality metrics, and used datasets, examining 149 distinct studies, and exploring commonalities and gaps in them.","The literature is extensive, and the approaches follow past technological trends.","However, machine learning is still not widely used by Wikipedia, and we hope that our analysis helps future researchers change that reality."],"url":"http://arxiv.org/abs/2310.02235v1"}
{"created":"2023-10-03 17:43:24","title":"MIS-AVioDD: Modality Invariant and Specific Representation for Audio-Visual Deepfake Detection","abstract":"Deepfakes are synthetic media generated using deep generative algorithms and have posed a severe societal and political threat. Apart from facial manipulation and synthetic voice, recently, a novel kind of deepfakes has emerged with either audio or visual modalities manipulated. In this regard, a new generation of multimodal audio-visual deepfake detectors is being investigated to collectively focus on audio and visual data for multimodal manipulation detection. Existing multimodal (audio-visual) deepfake detectors are often based on the fusion of the audio and visual streams from the video. Existing studies suggest that these multimodal detectors often obtain equivalent performances with unimodal audio and visual deepfake detectors. We conjecture that the heterogeneous nature of the audio and visual signals creates distributional modality gaps and poses a significant challenge to effective fusion and efficient performance. In this paper, we tackle the problem at the representation level to aid the fusion of audio and visual streams for multimodal deepfake detection. Specifically, we propose the joint use of modality (audio and visual) invariant and specific representations. This ensures that the common patterns and patterns specific to each modality representing pristine or fake content are preserved and fused for multimodal deepfake manipulation detection. Our experimental results on FakeAVCeleb and KoDF audio-visual deepfake datasets suggest the enhanced accuracy of our proposed method over SOTA unimodal and multimodal audio-visual deepfake detectors by $17.8$% and $18.4$%, respectively. Thus, obtaining state-of-the-art performance.","sentences":["Deepfakes are synthetic media generated using deep generative algorithms and have posed a severe societal and political threat.","Apart from facial manipulation and synthetic voice, recently, a novel kind of deepfakes has emerged with either audio or visual modalities manipulated.","In this regard, a new generation of multimodal audio-visual deepfake detectors is being investigated to collectively focus on audio and visual data for multimodal manipulation detection.","Existing multimodal (audio-visual) deepfake detectors are often based on the fusion of the audio and visual streams from the video.","Existing studies suggest that these multimodal detectors often obtain equivalent performances with unimodal audio and visual deepfake detectors.","We conjecture that the heterogeneous nature of the audio and visual signals creates distributional modality gaps and poses a significant challenge to effective fusion and efficient performance.","In this paper, we tackle the problem at the representation level to aid the fusion of audio and visual streams for multimodal deepfake detection.","Specifically, we propose the joint use of modality (audio and visual) invariant and specific representations.","This ensures that the common patterns and patterns specific to each modality representing pristine or fake content are preserved and fused for multimodal deepfake manipulation detection.","Our experimental results on FakeAVCeleb and KoDF audio-visual deepfake datasets suggest the enhanced accuracy of our proposed method over SOTA unimodal and multimodal audio-visual deepfake detectors by $17.8$% and $18.4$%, respectively.","Thus, obtaining state-of-the-art performance."],"url":"http://arxiv.org/abs/2310.02234v1"}
{"created":"2023-10-03 17:42:09","title":"HoloNets: Spectral Convolutions do extend to Directed Graphs","abstract":"Within the graph learning community, conventional wisdom dictates that spectral convolutional networks may only be deployed on undirected graphs: Only there could the existence of a well-defined graph Fourier transform be guaranteed, so that information may be translated between spatial- and spectral domains. Here we show this traditional reliance on the graph Fourier transform to be superfluous and -- making use of certain advanced tools from complex analysis and spectral theory -- extend spectral convolutions to directed graphs. We provide a frequency-response interpretation of newly developed filters, investigate the influence of the basis used to express filters and discuss the interplay with characteristic operators on which networks are based. In order to thoroughly test the developed theory, we conduct experiments in real world settings, showcasing that directed spectral convolutional networks provide new state of the art results for heterophilic node classification on many datasets and -- as opposed to baselines -- may be rendered stable to resolution-scale varying topological perturbations.","sentences":["Within the graph learning community, conventional wisdom dictates that spectral convolutional networks may only be deployed on undirected graphs: Only there could the existence of a well-defined graph Fourier transform be guaranteed, so that information may be translated between spatial- and spectral domains.","Here we show this traditional reliance on the graph Fourier transform to be superfluous and -- making use of certain advanced tools from complex analysis and spectral theory -- extend spectral convolutions to directed graphs.","We provide a frequency-response interpretation of newly developed filters, investigate the influence of the basis used to express filters and discuss the interplay with characteristic operators on which networks are based.","In order to thoroughly test the developed theory, we conduct experiments in real world settings, showcasing that directed spectral convolutional networks provide new state of the art results for heterophilic node classification on many datasets and -- as opposed to baselines -- may be rendered stable to resolution-scale varying topological perturbations."],"url":"http://arxiv.org/abs/2310.02232v1"}
{"created":"2023-10-03 17:37:52","title":"Leveraging Diffusion Disentangled Representations to Mitigate Shortcuts in Underspecified Visual Tasks","abstract":"Spurious correlations in the data, where multiple cues are predictive of the target labels, often lead to shortcut learning phenomena, where a model may rely on erroneous, easy-to-learn, cues while ignoring reliable ones. In this work, we propose an ensemble diversification framework exploiting the generation of synthetic counterfactuals using Diffusion Probabilistic Models (DPMs). We discover that DPMs have the inherent capability to represent multiple visual cues independently, even when they are largely correlated in the training data. We leverage this characteristic to encourage model diversity and empirically show the efficacy of the approach with respect to several diversification objectives. We show that diffusion-guided diversification can lead models to avert attention from shortcut cues, achieving ensemble diversity performance comparable to previous methods requiring additional data collection.","sentences":["Spurious correlations in the data, where multiple cues are predictive of the target labels, often lead to shortcut learning phenomena, where a model may rely on erroneous, easy-to-learn, cues while ignoring reliable ones.","In this work, we propose an ensemble diversification framework exploiting the generation of synthetic counterfactuals using Diffusion Probabilistic Models (DPMs).","We discover that DPMs have the inherent capability to represent multiple visual cues independently, even when they are largely correlated in the training data.","We leverage this characteristic to encourage model diversity and empirically show the efficacy of the approach with respect to several diversification objectives.","We show that diffusion-guided diversification can lead models to avert attention from shortcut cues, achieving ensemble diversity performance comparable to previous methods requiring additional data collection."],"url":"http://arxiv.org/abs/2310.02230v1"}
{"created":"2023-10-03 17:37:22","title":"Extraction of Medication and Temporal Relation from Clinical Text by Harnessing Different Deep Learning Models","abstract":"Clinical texts, represented in electronic medical records (EMRs), contain rich medical information and are essential for disease prediction, personalised information recommendation, clinical decision support, and medication pattern mining and measurement. Relation extractions between medication mentions and temporal information can further help clinicians better understand the patients' treatment history. To evaluate the performances of deep learning (DL) and large language models (LLMs) in medication extraction and temporal relations classification, we carry out an empirical investigation of \\textbf{MedTem} project using several advanced learning structures including BiLSTM-CRF and CNN-BiLSTM for a clinical domain named entity recognition (NER), and BERT-CNN for temporal relation extraction (RE), in addition to the exploration of different word embedding techniques. Furthermore, we also designed a set of post-processing roles to generate structured output on medications and the temporal relation. Our experiments show that CNN-BiLSTM slightly wins the BiLSTM-CRF model on the i2b2-2009 clinical NER task yielding 75.67, 77.83, and 78.17 for precision, recall, and F1 scores using Macro Average. BERT-CNN model also produced reasonable evaluation scores 64.48, 67.17, and 65.03 for P/R/F1 using Macro Avg on the temporal relation extraction test set from i2b2-2012 challenges. Code and Tools from MedTem will be hosted at \\url{https://github.com/HECTA-UoM/MedTem}","sentences":["Clinical texts, represented in electronic medical records (EMRs), contain rich medical information and are essential for disease prediction, personalised information recommendation, clinical decision support, and medication pattern mining and measurement.","Relation extractions between medication mentions and temporal information can further help clinicians better understand the patients' treatment history.","To evaluate the performances of deep learning (DL) and large language models (LLMs) in medication extraction and temporal relations classification, we carry out an empirical investigation of \\textbf{MedTem} project using several advanced learning structures including BiLSTM-CRF and CNN-BiLSTM for a clinical domain named entity recognition (NER), and BERT-CNN for temporal relation extraction (RE), in addition to the exploration of different word embedding techniques.","Furthermore, we also designed a set of post-processing roles to generate structured output on medications and the temporal relation.","Our experiments show that CNN-BiLSTM slightly wins the BiLSTM-CRF model on the i2b2-2009 clinical NER task yielding 75.67, 77.83, and 78.17 for precision, recall, and F1 scores using Macro Average.","BERT-CNN model also produced reasonable evaluation scores 64.48, 67.17, and 65.03 for P/R/F1 using Macro Avg on the temporal relation extraction test set from i2b2-2012 challenges.","Code and Tools from MedTem will be hosted at \\url{https://github.com/HECTA-UoM/MedTem}"],"url":"http://arxiv.org/abs/2310.02229v1"}
{"created":"2023-10-03 17:32:44","title":"SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training","abstract":"In an era where symbolic mathematical equations are indispensable for modeling complex natural phenomena, scientific inquiry often involves collecting observations and translating them into mathematical expressions. Recently, deep learning has emerged as a powerful tool for extracting insights from data. However, existing models typically specialize in either numeric or symbolic domains, and are usually trained in a supervised manner tailored to specific tasks. This approach neglects the substantial benefits that could arise from a task-agnostic unified understanding between symbolic equations and their numeric counterparts. To bridge the gap, we introduce SNIP, a Symbolic-Numeric Integrated Pre-training, which employs joint contrastive learning between symbolic and numeric domains, enhancing their mutual similarities in the pre-trained embeddings. By performing latent space analysis, we observe that SNIP provides cross-domain insights into the representations, revealing that symbolic supervision enhances the embeddings of numeric data and vice versa. We evaluate SNIP across diverse tasks, including symbolic-to-numeric mathematical property prediction and numeric-to-symbolic equation discovery, commonly known as symbolic regression. Results show that SNIP effectively transfers to various tasks, consistently outperforming fully supervised baselines and competing strongly with established task-specific methods, especially in few-shot learning scenarios where available data is limited.","sentences":["In an era where symbolic mathematical equations are indispensable for modeling complex natural phenomena, scientific inquiry often involves collecting observations and translating them into mathematical expressions.","Recently, deep learning has emerged as a powerful tool for extracting insights from data.","However, existing models typically specialize in either numeric or symbolic domains, and are usually trained in a supervised manner tailored to specific tasks.","This approach neglects the substantial benefits that could arise from a task-agnostic unified understanding between symbolic equations and their numeric counterparts.","To bridge the gap, we introduce SNIP, a Symbolic-Numeric Integrated Pre-training, which employs joint contrastive learning between symbolic and numeric domains, enhancing their mutual similarities in the pre-trained embeddings.","By performing latent space analysis, we observe that SNIP provides cross-domain insights into the representations, revealing that symbolic supervision enhances the embeddings of numeric data and vice versa.","We evaluate SNIP across diverse tasks, including symbolic-to-numeric mathematical property prediction and numeric-to-symbolic equation discovery, commonly known as symbolic regression.","Results show that SNIP effectively transfers to various tasks, consistently outperforming fully supervised baselines and competing strongly with established task-specific methods, especially in few-shot learning scenarios where available data is limited."],"url":"http://arxiv.org/abs/2310.02227v1"}
{"created":"2023-10-03 17:32:41","title":"Think before you speak: Training Language Models With Pause Tokens","abstract":"Language models generate responses by producing a series of tokens in immediate succession: the $(K+1)^{th}$ token is an outcome of manipulating $K$ hidden vectors per layer, one vector per preceding token. What if instead we were to let the model manipulate say, $K+10$ hidden vectors, before it outputs the $(K+1)^{th}$ token? We operationalize this idea by performing training and inference on language models with a (learnable) $\\textit{pause}$ token, a sequence of which is appended to the input prefix. We then delay extracting the model's outputs until the last pause token is seen, thereby allowing the model to process extra computation before committing to an answer. We empirically evaluate $\\textit{pause-training}$ on decoder-only models of 1B and 130M parameters with causal pretraining on C4, and on downstream tasks covering reasoning, question-answering, general understanding and fact recall. Our main finding is that inference-time delays show gains when the model is both pre-trained and finetuned with delays. For the 1B model, we witness gains on 8 of 9 tasks, most prominently, a gain of $18\\%$ EM score on the QA task of SQuAD, $8\\%$ on CommonSenseQA and $1\\%$ accuracy on the reasoning task of GSM8k. Our work raises a range of conceptual and practical future research questions on making delayed next-token prediction a widely applicable new paradigm.","sentences":["Language models generate responses by producing a series of tokens in immediate succession: the $(K+1)^{th}$ token is an outcome of manipulating $K$ hidden vectors per layer, one vector per preceding token.","What if instead we were to let the model manipulate say, $K+10$ hidden vectors, before it outputs the $(K+1)^{th}$ token?","We operationalize this idea by performing training and inference on language models with a (learnable) $\\textit{pause}$ token, a sequence of which is appended to the input prefix.","We then delay extracting the model's outputs until the last pause token is seen, thereby allowing the model to process extra computation before committing to an answer.","We empirically evaluate $\\textit{pause-training}$ on decoder-only models of 1B and 130M parameters with causal pretraining on C4, and on downstream tasks covering reasoning, question-answering, general understanding and fact recall.","Our main finding is that inference-time delays show gains when the model is both pre-trained and finetuned with delays.","For the 1B model, we witness gains on 8 of 9 tasks, most prominently, a gain of $18\\%$ EM score on the QA task of SQuAD, $8\\%$ on CommonSenseQA and $1\\%$ accuracy on the reasoning task of GSM8k.","Our work raises a range of conceptual and practical future research questions on making delayed next-token prediction a widely applicable new paradigm."],"url":"http://arxiv.org/abs/2310.02226v1"}
{"created":"2023-10-03 17:30:33","title":"Can Language Models be Instructed to Protect Personal Information?","abstract":"Large multimodal language models have proven transformative in numerous applications. However, these models have been shown to memorize and leak pre-training data, raising serious user privacy and information security concerns. While data leaks should be prevented, it is also crucial to examine the trade-off between the privacy protection and model utility of proposed approaches. In this paper, we introduce PrivQA -- a multimodal benchmark to assess this privacy/utility trade-off when a model is instructed to protect specific categories of personal information in a simulated scenario. We also propose a technique to iteratively self-moderate responses, which significantly improves privacy. However, through a series of red-teaming experiments, we find that adversaries can also easily circumvent these protections with simple jailbreaking methods through textual and/or image inputs. We believe PrivQA has the potential to support the development of new models with improved privacy protections, as well as the adversarial robustness of these protections. We release the entire PrivQA dataset at https://llm-access-control.github.io/.","sentences":["Large multimodal language models have proven transformative in numerous applications.","However, these models have been shown to memorize and leak pre-training data, raising serious user privacy and information security concerns.","While data leaks should be prevented, it is also crucial to examine the trade-off between the privacy protection and model utility of proposed approaches.","In this paper, we introduce PrivQA -- a multimodal benchmark to assess this privacy/utility trade-off when a model is instructed to protect specific categories of personal information in a simulated scenario.","We also propose a technique to iteratively self-moderate responses, which significantly improves privacy.","However, through a series of red-teaming experiments, we find that adversaries can also easily circumvent these protections with simple jailbreaking methods through textual and/or image inputs.","We believe PrivQA has the potential to support the development of new models with improved privacy protections, as well as the adversarial robustness of these protections.","We release the entire PrivQA dataset at https://llm-access-control.github.io/."],"url":"http://arxiv.org/abs/2310.02224v1"}
{"created":"2023-10-03 17:30:28","title":"Optimum Monitoring of Heterogeneous Continuous Time Markov Chains","abstract":"We study a remote monitoring system in which a collection of ergodic, aperiodic, mutually independent, and heterogeneous continuous time Markov chain (CTMC) based information sources is considered. In this system, a common remote monitor samples the states of the individual CTMCs according to a Poisson process with possibly different per-source sampling rates, in order to maintain remote estimates of the states of each of the sources. Three information freshness models are considered to quantify the accuracy of the remote estimates: fresh when equal (FWE), fresh when sampled (FWS) and fresh when close (FWC). For each of these freshness models, closed-form expressions are derived for mean information freshness for a given source. Using these expressions, optimum sampling rates for all sources are obtained so as to maximize the weighted sum freshness of the monitoring system under an overall sampling rate constraint. This optimization problem possesses a water-filling solution with quadratic worst case computational complexity in the number of information sources. Numerical examples are provided to validate the effectiveness of the optimum sampler in comparison to several baseline sampling policies.","sentences":["We study a remote monitoring system in which a collection of ergodic, aperiodic, mutually independent, and heterogeneous continuous time Markov chain (CTMC) based information sources is considered.","In this system, a common remote monitor samples the states of the individual CTMCs according to a Poisson process with possibly different per-source sampling rates, in order to maintain remote estimates of the states of each of the sources.","Three information freshness models are considered to quantify the accuracy of the remote estimates: fresh when equal (FWE), fresh when sampled (FWS) and fresh when close (FWC).","For each of these freshness models, closed-form expressions are derived for mean information freshness for a given source.","Using these expressions, optimum sampling rates for all sources are obtained so as to maximize the weighted sum freshness of the monitoring system under an overall sampling rate constraint.","This optimization problem possesses a water-filling solution with quadratic worst case computational complexity in the number of information sources.","Numerical examples are provided to validate the effectiveness of the optimum sampler in comparison to several baseline sampling policies."],"url":"http://arxiv.org/abs/2310.02223v1"}
{"created":"2023-10-03 17:27:10","title":"What do we learn from a large-scale study of pre-trained visual representations in sim and real environments?","abstract":"We present a large empirical investigation on the use of pre-trained visual representations (PVRs) for training downstream policies that execute real-world tasks. Our study spans five different PVRs, two different policy-learning paradigms (imitation and reinforcement learning), and three different robots for 5 distinct manipulation and indoor navigation tasks. From this effort, we can arrive at three insights: 1) the performance trends of PVRs in the simulation are generally indicative of their trends in the real world, 2) the use of PVRs enables a first-of-its-kind result with indoor ImageNav (zero-shot transfer to a held-out scene in the real world), and 3) the benefits from variations in PVRs, primarily data-augmentation and fine-tuning, also transfer to the real-world performance. See project website for additional details and visuals.","sentences":["We present a large empirical investigation on the use of pre-trained visual representations (PVRs) for training downstream policies that execute real-world tasks.","Our study spans five different PVRs, two different policy-learning paradigms (imitation and reinforcement learning), and three different robots for 5 distinct manipulation and indoor navigation tasks.","From this effort, we can arrive at three insights: 1) the performance trends of PVRs in the simulation are generally indicative of their trends in the real world, 2) the use of PVRs enables a first-of-its-kind result with indoor ImageNav (zero-shot transfer to a held-out scene in the real world), and 3) the benefits from variations in PVRs, primarily data-augmentation and fine-tuning, also transfer to the real-world performance.","See project website for additional details and visuals."],"url":"http://arxiv.org/abs/2310.02219v1"}
{"created":"2023-10-03 17:08:45","title":"Fast Localization and Tracking in City-Scale UWB Networks","abstract":"Localization of networked nodes is an essential problem in emerging applications, including first-responder navigation, automated manufacturing lines, vehicular and drone navigation, asset navigation and tracking, Internet of Things and 5G communication networks. In this paper, we present Locate3D, a novel system for peer-to-peer node localization and orientation estimation in large networks. Unlike traditional range-only methods, Locate3D introduces angle-of-arrival (AoA) data as an added network topology constraint. The system solves three key challenges: it uses angles to reduce the number of measurements required by 4x and jointly use range and angle data for location estimation. We develop a spanning-tree approach for fast location updates, and to ensure the output graphs are rigid and uniquely realizable, even in occluded or weakly connected areas. Locate3D cuts down latency by up to 75% without compromising accuracy, surpassing standard range-only solutions. It has a 10.2 meters median localization error for large-scale networks (30,000 nodes, 15 anchors spread across 14km square) and 0.5 meters for small-scale networks (10 nodes).","sentences":["Localization of networked nodes is an essential problem in emerging applications, including first-responder navigation, automated manufacturing lines, vehicular and drone navigation, asset navigation and tracking, Internet of Things and 5G communication networks.","In this paper, we present Locate3D, a novel system for peer-to-peer node localization and orientation estimation in large networks.","Unlike traditional range-only methods, Locate3D introduces angle-of-arrival (AoA) data as an added network topology constraint.","The system solves three key challenges: it uses angles to reduce the number of measurements required by 4x and jointly use range and angle data for location estimation.","We develop a spanning-tree approach for fast location updates, and to ensure the output graphs are rigid and uniquely realizable, even in occluded or weakly connected areas.","Locate3D cuts down latency by up to 75% without compromising accuracy, surpassing standard range-only solutions.","It has a 10.2 meters median localization error for large-scale networks (30,000 nodes, 15 anchors spread across 14km square) and 0.5 meters for small-scale networks (10 nodes)."],"url":"http://arxiv.org/abs/2310.02211v1"}
{"created":"2023-10-03 17:06:52","title":"Language Models Represent Space and Time","abstract":"The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a coherent model of the data generating process -- a world model. We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. We discover that LLMs learn linear representations of space and time across multiple scales. These representations are robust to prompting variations and unified across different entity types (e.g. cities and landmarks). In addition, we identify individual ``space neurons'' and ``time neurons'' that reliably encode spatial and temporal coordinates. Our analysis demonstrates that modern LLMs acquire structured knowledge about fundamental dimensions such as space and time, supporting the view that they learn not merely superficial statistics, but literal world models.","sentences":["The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a coherent model of the data generating process -- a world model.","We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models.","We discover that LLMs learn linear representations of space and time across multiple scales.","These representations are robust to prompting variations and unified across different entity types (e.g. cities and landmarks).","In addition, we identify individual ``space neurons'' and ``time neurons'' that reliably encode spatial and temporal coordinates.","Our analysis demonstrates that modern LLMs acquire structured knowledge about fundamental dimensions such as space and time, supporting the view that they learn not merely superficial statistics, but literal world models."],"url":"http://arxiv.org/abs/2310.02207v1"}
{"created":"2023-10-03 17:04:33","title":"Chunking: Forgetting Matters in Continual Learning even without Changing Tasks","abstract":"Work on continual learning (CL) has largely focused on the problems arising from the dynamically-changing data distribution. However, CL can be decomposed into two sub-problems: (a) shifts in the data distribution, and (b) dealing with the fact that the data is split into chunks and so only a part of the data is available to be trained on at any point in time. In this work, we look at the latter sub-problem -- the chunking of data -- and note that previous analysis of chunking in the CL literature is sparse. We show that chunking is an important part of CL, accounting for around half of the performance drop from offline learning in our experiments. Furthermore, our results reveal that current CL algorithms do not address the chunking sub-problem, only performing as well as plain SGD training when there is no shift in the data distribution. We analyse why performance drops when learning occurs on chunks of data, and find that forgetting, which is often seen to be a problem due to distribution shift, still arises and is a significant problem. Motivated by an analysis of the linear case, we show that per-chunk weight averaging improves performance in the chunking setting and that this performance transfers to the full CL setting. Hence, we argue that work on chunking can help advance CL in general.","sentences":["Work on continual learning (CL) has largely focused on the problems arising from the dynamically-changing data distribution.","However, CL can be decomposed into two sub-problems: (a) shifts in the data distribution, and (b) dealing with the fact that the data is split into chunks and so only a part of the data is available to be trained on at any point in time.","In this work, we look at the latter sub-problem -- the chunking of data -- and note that previous analysis of chunking in the CL literature is sparse.","We show that chunking is an important part of CL, accounting for around half of the performance drop from offline learning in our experiments.","Furthermore, our results reveal that current CL algorithms do not address the chunking sub-problem, only performing as well as plain SGD training when there is no shift in the data distribution.","We analyse why performance drops when learning occurs on chunks of data, and find that forgetting, which is often seen to be a problem due to distribution shift, still arises and is a significant problem.","Motivated by an analysis of the linear case, we show that per-chunk weight averaging improves performance in the chunking setting and that this performance transfers to the full CL setting.","Hence, we argue that work on chunking can help advance CL in general."],"url":"http://arxiv.org/abs/2310.02206v1"}
{"created":"2023-10-03 17:00:19","title":"Determinisation and Unambiguisation of Polynomially-Ambiguous Rational Weighted Automata","abstract":"We study the determinisation and unambiguisation problems of weighted automata over the rational field: Given a weighted automaton, can we determine whether there exists an equivalent deterministic, respectively unambiguous, weighted automaton? Recent results by Bell and Smertnig show that the problem is decidable, however they do not provide any complexity bounds. We show that both problems are in PSPACE for polynomially-ambiguous weighted automata.","sentences":["We study the determinisation and unambiguisation problems of weighted automata over the rational field: Given a weighted automaton, can we determine whether there exists an equivalent deterministic, respectively unambiguous, weighted automaton?","Recent results by Bell and Smertnig show that the problem is decidable, however they do not provide any complexity bounds.","We show that both problems are in PSPACE for polynomially-ambiguous weighted automata."],"url":"http://arxiv.org/abs/2310.02204v1"}
{"created":"2023-10-03 16:57:05","title":"Learnable Data Augmentation for One-Shot Unsupervised Domain Adaptation","abstract":"This paper presents a classification framework based on learnable data augmentation to tackle the One-Shot Unsupervised Domain Adaptation (OS-UDA) problem. OS-UDA is the most challenging setting in Domain Adaptation, as only one single unlabeled target sample is assumed to be available for model adaptation. Driven by such single sample, our method LearnAug-UDA learns how to augment source data, making it perceptually similar to the target. As a result, a classifier trained on such augmented data will generalize well for the target domain. To achieve this, we designed an encoder-decoder architecture that exploits a perceptual loss and style transfer strategies to augment the source data. Our method achieves state-of-the-art performance on two well-known Domain Adaptation benchmarks, DomainNet and VisDA. The project code is available at https://github.com/IIT-PAVIS/LearnAug-UDA","sentences":["This paper presents a classification framework based on learnable data augmentation to tackle the One-Shot Unsupervised Domain Adaptation (OS-UDA) problem.","OS-UDA is the most challenging setting in Domain Adaptation, as only one single unlabeled target sample is assumed to be available for model adaptation.","Driven by such single sample, our method LearnAug-UDA learns how to augment source data, making it perceptually similar to the target.","As a result, a classifier trained on such augmented data will generalize well for the target domain.","To achieve this, we designed an encoder-decoder architecture that exploits a perceptual loss and style transfer strategies to augment the source data.","Our method achieves state-of-the-art performance on two well-known Domain Adaptation benchmarks, DomainNet and VisDA.","The project code is available at https://github.com/IIT-PAVIS/LearnAug-UDA"],"url":"http://arxiv.org/abs/2310.02201v1"}
{"created":"2023-10-03 16:47:35","title":"Strong Faithfulness for ELH Ontology Embeddings","abstract":"Ontology embedding methods are powerful approaches to represent and reason over structured knowledge in various domains. One advantage of ontology embeddings over knowledge graph embeddings is their ability to capture and impose an underlying schema to which the model must conform. Despite advances, most current approaches do not guarantee that the resulting embedding respects the axioms the ontology entails. In this work, we formally prove that normalized ${\\cal ELH}$ has the strong faithfulness property on convex geometric models, which means that there is an embedding that precisely captures the original ontology. We present a region-based geometric model for embedding normalized ${\\cal ELH}$ ontologies into a continuous vector space. To prove strong faithfulness, our construction takes advantage of the fact that normalized ${\\cal ELH}$ has a finite canonical model. We first prove the statement assuming (possibly) non-convex regions, allowing us to keep the required dimensions low. Then, we impose convexity on the regions and show the property still holds. Finally, we consider reasoning tasks on geometric models and analyze the complexity in the class of convex geometric models used for proving strong faithfulness.","sentences":["Ontology embedding methods are powerful approaches to represent and reason over structured knowledge in various domains.","One advantage of ontology embeddings over knowledge graph embeddings is their ability to capture and impose an underlying schema to which the model must conform.","Despite advances, most current approaches do not guarantee that the resulting embedding respects the axioms the ontology entails.","In this work, we formally prove that normalized ${\\cal ELH}$ has the strong faithfulness property on convex geometric models, which means that there is an embedding that precisely captures the original ontology.","We present a region-based geometric model for embedding normalized ${\\cal ELH}$ ontologies into a continuous vector space.","To prove strong faithfulness, our construction takes advantage of the fact that normalized ${\\cal ELH}$ has a finite canonical model.","We first prove the statement assuming (possibly) non-convex regions, allowing us to keep the required dimensions low.","Then, we impose convexity on the regions and show the property still holds.","Finally, we consider reasoning tasks on geometric models and analyze the complexity in the class of convex geometric models used for proving strong faithfulness."],"url":"http://arxiv.org/abs/2310.02198v1"}
{"created":"2023-10-03 16:41:46","title":"Efficient Online Scheduling and Routing for Automated Guided Vehicles: Comparing a Novel Loop-Based Algorithm Against Existing Methods","abstract":"Automated guided vehicles (AGVs) are widely used in various industries, and scheduling and routing them in a conflict-free manner is crucial to their efficient operation. We propose a loop-based algorithm that solves the online, conflict-free scheduling and routing problem for AGVs. The proposed algorithm is compared against an exact method, a greedy heuristic and a metaheuristic. We experimentally show that this algorithm either outperforms the other algorithms or gets an equally good solution in less computing time.","sentences":["Automated guided vehicles (AGVs) are widely used in various industries, and scheduling and routing them in a conflict-free manner is crucial to their efficient operation.","We propose a loop-based algorithm that solves the online, conflict-free scheduling and routing problem for AGVs.","The proposed algorithm is compared against an exact method, a greedy heuristic and a metaheuristic.","We experimentally show that this algorithm either outperforms the other algorithms or gets an equally good solution in less computing time."],"url":"http://arxiv.org/abs/2310.02195v1"}
{"created":"2023-10-03 16:39:21","title":"Uncertainty Quantification in Inverse Models in Hydrology","abstract":"In hydrology, modeling streamflow remains a challenging task due to the limited availability of basin characteristics information such as soil geology and geomorphology. These characteristics may be noisy due to measurement errors or may be missing altogether. To overcome this challenge, we propose a knowledge-guided, probabilistic inverse modeling method for recovering physical characteristics from streamflow and weather data, which are more readily available. We compare our framework with state-of-the-art inverse models for estimating river basin characteristics. We also show that these estimates offer improvement in streamflow modeling as opposed to using the original basin characteristic values. Our inverse model offers 3\\% improvement in R$^2$ for the inverse model (basin characteristic estimation) and 6\\% for the forward model (streamflow prediction). Our framework also offers improved explainability since it can quantify uncertainty in both the inverse and the forward model. Uncertainty quantification plays a pivotal role in improving the explainability of machine learning models by providing additional insights into the reliability and limitations of model predictions. In our analysis, we assess the quality of the uncertainty estimates. Compared to baseline uncertainty quantification methods, our framework offers 10\\% improvement in the dispersion of epistemic uncertainty and 13\\% improvement in coverage rate. This information can help stakeholders understand the level of uncertainty associated with the predictions and provide a more comprehensive view of the potential outcomes.","sentences":["In hydrology, modeling streamflow remains a challenging task due to the limited availability of basin characteristics information such as soil geology and geomorphology.","These characteristics may be noisy due to measurement errors or may be missing altogether.","To overcome this challenge, we propose a knowledge-guided, probabilistic inverse modeling method for recovering physical characteristics from streamflow and weather data, which are more readily available.","We compare our framework with state-of-the-art inverse models for estimating river basin characteristics.","We also show that these estimates offer improvement in streamflow modeling as opposed to using the original basin characteristic values.","Our inverse model offers 3\\% improvement in R$^2$ for the inverse model (basin characteristic estimation) and 6\\% for the forward model (streamflow prediction).","Our framework also offers improved explainability since it can quantify uncertainty in both the inverse and the forward model.","Uncertainty quantification plays a pivotal role in improving the explainability of machine learning models by providing additional insights into the reliability and limitations of model predictions.","In our analysis, we assess the quality of the uncertainty estimates.","Compared to baseline uncertainty quantification methods, our framework offers 10\\% improvement in the dispersion of epistemic uncertainty and 13\\% improvement in coverage rate.","This information can help stakeholders understand the level of uncertainty associated with the predictions and provide a more comprehensive view of the potential outcomes."],"url":"http://arxiv.org/abs/2310.02193v1"}
{"created":"2023-10-03 16:37:36","title":"Sneaked references: Cooked reference metadata inflate citation counts","abstract":"We report evidence of an undocumented method to manipulate citation counts involving 'sneaked' references. Sneaked references are registered as metadata for scientific articles in which they do not appear. This manipulation exploits trusted relationships between various actors: publishers, the Crossref metadata registration agency, digital libraries, and bibliometric platforms. By collecting metadata from various sources, we show that extra undue references are actually sneaked in at Digital Object Identifier (DOI) registration time, resulting in artificially inflated citation counts. As a case study, focusing on three journals from a given publisher, we identified at least 9% sneaked references (5,978/65,836) mainly benefiting two authors. Despite not existing in the articles, these sneaked references exist in metadata registries and inappropriately propagate to bibliometric dashboards. Furthermore, we discovered 'lost' references: the studied bibliometric platform failed to index at least 56% (36,939/65,836) of the references listed in the HTML version of the publications. The extent of the sneaked and lost references in the global literature remains unknown and requires further investigations. Bibliometric platforms producing citation counts should identify, quantify, and correct these flaws to provide accurate data to their patrons and prevent further citation gaming.","sentences":["We report evidence of an undocumented method to manipulate citation counts involving 'sneaked' references.","Sneaked references are registered as metadata for scientific articles in which they do not appear.","This manipulation exploits trusted relationships between various actors: publishers, the Crossref metadata registration agency, digital libraries, and bibliometric platforms.","By collecting metadata from various sources, we show that extra undue references are actually sneaked in at Digital Object Identifier (DOI) registration time, resulting in artificially inflated citation counts.","As a case study, focusing on three journals from a given publisher, we identified at least 9% sneaked references (5,978/65,836) mainly benefiting two authors.","Despite not existing in the articles, these sneaked references exist in metadata registries and inappropriately propagate to bibliometric dashboards.","Furthermore, we discovered 'lost' references: the studied bibliometric platform failed to index at least 56% (36,939/65,836) of the references listed in the HTML version of the publications.","The extent of the sneaked and lost references in the global literature remains unknown and requires further investigations.","Bibliometric platforms producing citation counts should identify, quantify, and correct these flaws to provide accurate data to their patrons and prevent further citation gaming."],"url":"http://arxiv.org/abs/2310.02192v1"}
{"created":"2023-10-03 16:25:47","title":"Puddles: Application-Independent Recovery and Location-Independent Data for Persistent Memory","abstract":"In this paper, we argue that current work has failed to provide a comprehensive and maintainable in-memory representation for persistent memory.   PM data should be easily mappable into a process address space, shareable across processes, shippable between machines, consistent after a crash, and accessible to legacy code with fast, efficient pointers as first-class abstractions.   While existing systems have provided niceties like mmap()-based load/store access, they have not been able to support all these necessary properties due to conflicting requirements.   We propose Puddles, a new persistent memory abstraction, to solve these problems. Puddles provide application-independent recovery after a power outage; they make recovery from a system failure a system-level property of the stored data rather than the responsibility of the programs that access it. Puddles use native pointers, so they are compatible with existing code. Finally, Puddles implement support for sharing and shipping of PM data between processes and systems without expensive serialization and deserialization.   Compared to existing systems, Puddles are at least as fast as and up to 1.34$\\times$ faster than PMDK while being competitive with other PM libraries across YCSB workloads. Moreover, to demonstrate Puddles' ability to relocate data, we showcase a sensor network data-aggregation workload that results in a 4.7$\\times$ speedup over PMDK.","sentences":["In this paper, we argue that current work has failed to provide a comprehensive and maintainable in-memory representation for persistent memory.   ","PM data should be easily mappable into a process address space, shareable across processes, shippable between machines, consistent after a crash, and accessible to legacy code with fast, efficient pointers as first-class abstractions.   ","While existing systems have provided niceties like mmap()-based load/store access, they have not been able to support all these necessary properties due to conflicting requirements.   ","We propose Puddles, a new persistent memory abstraction, to solve these problems.","Puddles provide application-independent recovery after a power outage; they make recovery from a system failure a system-level property of the stored data rather than the responsibility of the programs that access it.","Puddles use native pointers, so they are compatible with existing code.","Finally, Puddles implement support for sharing and shipping of PM data between processes and systems without expensive serialization and deserialization.   ","Compared to existing systems, Puddles are at least as fast as and up to 1.34$\\times$ faster than PMDK while being competitive with other PM libraries across YCSB workloads.","Moreover, to demonstrate Puddles' ability to relocate data, we showcase a sensor network data-aggregation workload that results in a 4.7$\\times$ speedup over PMDK."],"url":"http://arxiv.org/abs/2310.02183v1"}
{"created":"2023-10-03 16:08:41","title":"Ask Again, Then Fail: Large Language Models' Vacillations in Judgement","abstract":"With the emergence of generative conversational large language models (LLMs) like ChatGPT, serving as virtual assistants in various fields, the stability and reliability of their responses have become crucial. However, during usage, it has been observed that these models tend to waver in their judgements when confronted with follow-up questions from users expressing skepticism or disagreement. In this work, we draw inspiration from questioning strategies in education and propose a \\textsc{Follow-up Questioning Mechanism} along with two evaluation metrics to assess the judgement consistency of LLMs before and after exposure to disturbances. We evaluate the judgement consistency of ChatGPT, PaLM2-Bison, and Vicuna-13B under this mechanism across eight reasoning benchmarks. Empirical results show that even when the initial answers are correct, judgement consistency sharply decreases when LLMs face disturbances such as questioning, negation, or misleading. Additionally, we study these models' judgement consistency under various settings (sampling temperature and prompts) to validate this issue further, observing the impact of prompt tone and conducting an in-depth error analysis for deeper behavioral insights. Furthermore, we also explore several prompting methods to mitigate this issue and demonstrate their effectiveness\\footnote{\\url{https://github.com/NUSTM/LLMs-Waver-In-Judgements}}.","sentences":["With the emergence of generative conversational large language models (LLMs) like ChatGPT, serving as virtual assistants in various fields, the stability and reliability of their responses have become crucial.","However, during usage, it has been observed that these models tend to waver in their judgements when confronted with follow-up questions from users expressing skepticism or disagreement.","In this work, we draw inspiration from questioning strategies in education and propose a \\textsc{Follow-up Questioning Mechanism} along with two evaluation metrics to assess the judgement consistency of LLMs before and after exposure to disturbances.","We evaluate the judgement consistency of ChatGPT, PaLM2-Bison, and Vicuna-13B under this mechanism across eight reasoning benchmarks.","Empirical results show that even when the initial answers are correct, judgement consistency sharply decreases when LLMs face disturbances such as questioning, negation, or misleading.","Additionally, we study these models' judgement consistency under various settings (sampling temperature and prompts) to validate this issue further, observing the impact of prompt tone and conducting an in-depth error analysis for deeper behavioral insights.","Furthermore, we also explore several prompting methods to mitigate this issue and demonstrate their effectiveness\\footnote{\\url{https://github.com/NUSTM/LLMs-Waver-In-Judgements}}."],"url":"http://arxiv.org/abs/2310.02174v1"}
{"created":"2023-10-03 16:06:30","title":"Lyfe Agents: Generative agents for low-cost real-time social interactions","abstract":"Highly autonomous generative agents powered by large language models promise to simulate intricate social behaviors in virtual societies. However, achieving real-time interactions with humans at a low computational cost remains challenging. Here, we introduce Lyfe Agents. They combine low-cost with real-time responsiveness, all while remaining intelligent and goal-oriented. Key innovations include: (1) an option-action framework, reducing the cost of high-level decisions; (2) asynchronous self-monitoring for better self-consistency; and (3) a Summarize-and-Forget memory mechanism, prioritizing critical memory items at a low cost. We evaluate Lyfe Agents' self-motivation and sociability across several multi-agent scenarios in our custom LyfeGame 3D virtual environment platform. When equipped with our brain-inspired techniques, Lyfe Agents can exhibit human-like self-motivated social reasoning. For example, the agents can solve a crime (a murder mystery) through autonomous collaboration and information exchange. Meanwhile, our techniques enabled Lyfe Agents to operate at a computational cost 10-100 times lower than existing alternatives. Our findings underscore the transformative potential of autonomous generative agents to enrich human social experiences in virtual worlds.","sentences":["Highly autonomous generative agents powered by large language models promise to simulate intricate social behaviors in virtual societies.","However, achieving real-time interactions with humans at a low computational cost remains challenging.","Here, we introduce Lyfe Agents.","They combine low-cost with real-time responsiveness, all while remaining intelligent and goal-oriented.","Key innovations include: (1) an option-action framework, reducing the cost of high-level decisions; (2) asynchronous self-monitoring for better self-consistency; and (3) a Summarize-and-Forget memory mechanism, prioritizing critical memory items at a low cost.","We evaluate Lyfe Agents' self-motivation and sociability across several multi-agent scenarios in our custom LyfeGame 3D virtual environment platform.","When equipped with our brain-inspired techniques, Lyfe Agents can exhibit human-like self-motivated social reasoning.","For example, the agents can solve a crime (a murder mystery) through autonomous collaboration and information exchange.","Meanwhile, our techniques enabled Lyfe Agents to operate at a computational cost 10-100 times lower than existing alternatives.","Our findings underscore the transformative potential of autonomous generative agents to enrich human social experiences in virtual worlds."],"url":"http://arxiv.org/abs/2310.02172v1"}
{"created":"2023-10-03 16:05:48","title":"Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with Agent Team Optimization","abstract":"Large language model (LLM) agents have been shown effective on a wide range of tasks, and by ensembling multiple LLM agents, their performances could be further improved. Existing approaches employ a fixed set of agents to interact with each other in a static architecture, which limits their generalizability to various tasks and requires strong human prior in designing these agents. In this work, we propose to construct a strategic team of agents communicating in a dynamic interaction architecture based on the task query. Specifically, we build a framework named Dynamic LLM-Agent Network ($\\textbf{DyLAN}$) for LLM-agent collaboration on complicated tasks like reasoning and code generation. DyLAN enables agents to interact for multiple rounds in a dynamic architecture with inference-time agent selection and an early-stopping mechanism to improve performance and efficiency. We further design an automatic agent team optimization algorithm based on an unsupervised metric termed $\\textit{Agent Importance Score}$, enabling the selection of best agents based on the contribution each agent makes. Empirically, we demonstrate that DyLAN performs well in both reasoning and code generation tasks with reasonable computational cost. DyLAN achieves 13.0% and 13.3% improvement on MATH and HumanEval, respectively, compared to a single execution on GPT-35-turbo. On specific subjects of MMLU, agent team optimization in DyLAN increases accuracy by up to 25.0%.","sentences":["Large language model (LLM) agents have been shown effective on a wide range of tasks, and by ensembling multiple LLM agents, their performances could be further improved.","Existing approaches employ a fixed set of agents to interact with each other in a static architecture, which limits their generalizability to various tasks and requires strong human prior in designing these agents.","In this work, we propose to construct a strategic team of agents communicating in a dynamic interaction architecture based on the task query.","Specifically, we build a framework named Dynamic LLM-Agent Network ($\\textbf{DyLAN}$) for LLM-agent collaboration on complicated tasks like reasoning and code generation.","DyLAN enables agents to interact for multiple rounds in a dynamic architecture with inference-time agent selection and an early-stopping mechanism to improve performance and efficiency.","We further design an automatic agent team optimization algorithm based on an unsupervised metric termed $\\textit{Agent Importance Score}$, enabling the selection of best agents based on the contribution each agent makes.","Empirically, we demonstrate that DyLAN performs well in both reasoning and code generation tasks with reasonable computational cost.","DyLAN achieves 13.0% and 13.3% improvement on MATH and HumanEval, respectively, compared to a single execution on GPT-35-turbo.","On specific subjects of MMLU, agent team optimization in DyLAN increases accuracy by up to 25.0%."],"url":"http://arxiv.org/abs/2310.02170v1"}
{"created":"2023-10-03 16:02:36","title":"Editing Personality for LLMs","abstract":"This paper introduces an innovative task focused on editing the personality traits of Large Language Models (LLMs). This task seeks to adjust the models' responses to opinion-related questions on specified topics since an individual's personality often manifests in the form of their expressed opinions, thereby showcasing different personality traits. Specifically, we construct a new benchmark dataset PersonalityEdit to address this task. Drawing on the theory in Social Psychology, we isolate three representative traits, namely Neuroticism, Extraversion, and Agreeableness, as the foundation for our benchmark. We then gather data using GPT-4, generating responses that not only align with a specified topic but also embody the targeted personality trait. We conduct comprehensive experiments involving various baselines and discuss the representation of personality behavior in LLMs. Our intriguing findings uncover potential challenges of the proposed task, illustrating several remaining issues. We anticipate that our work can provide the NLP community with insights. Code and datasets will be released at https://github.com/zjunlp/EasyEdit.","sentences":["This paper introduces an innovative task focused on editing the personality traits of Large Language Models (LLMs).","This task seeks to adjust the models' responses to opinion-related questions on specified topics since an individual's personality often manifests in the form of their expressed opinions, thereby showcasing different personality traits.","Specifically, we construct a new benchmark dataset PersonalityEdit to address this task.","Drawing on the theory in Social Psychology, we isolate three representative traits, namely Neuroticism, Extraversion, and Agreeableness, as the foundation for our benchmark.","We then gather data using GPT-4, generating responses that not only align with a specified topic but also embody the targeted personality trait.","We conduct comprehensive experiments involving various baselines and discuss the representation of personality behavior in LLMs.","Our intriguing findings uncover potential challenges of the proposed task, illustrating several remaining issues.","We anticipate that our work can provide the NLP community with insights.","Code and datasets will be released at https://github.com/zjunlp/EasyEdit."],"url":"http://arxiv.org/abs/2310.02168v1"}
{"created":"2023-10-03 16:01:06","title":"Towards a Unified Framework for Sequential Decision Making","abstract":"In recent years, the integration of Automated Planning (AP) and Reinforcement Learning (RL) has seen a surge of interest. To perform this integration, a general framework for Sequential Decision Making (SDM) would prove immensely useful, as it would help us understand how AP and RL fit together. In this preliminary work, we attempt to provide such a framework, suitable for any method ranging from Classical Planning to Deep RL, by drawing on concepts from Probability Theory and Bayesian inference. We formulate an SDM task as a set of training and test Markov Decision Processes (MDPs), to account for generalization. We provide a general algorithm for SDM which we hypothesize every SDM method is based on. According to it, every SDM algorithm can be seen as a procedure that iteratively improves its solution estimate by leveraging the task knowledge available. Finally, we derive a set of formulas and algorithms for calculating interesting properties of SDM tasks and methods, which make possible their empirical evaluation and comparison.","sentences":["In recent years, the integration of Automated Planning (AP) and Reinforcement Learning (RL) has seen a surge of interest.","To perform this integration, a general framework for Sequential Decision Making (SDM) would prove immensely useful, as it would help us understand how AP and RL fit together.","In this preliminary work, we attempt to provide such a framework, suitable for any method ranging from Classical Planning to Deep RL, by drawing on concepts from Probability Theory and Bayesian inference.","We formulate an SDM task as a set of training and test Markov Decision Processes (MDPs), to account for generalization.","We provide a general algorithm for SDM which we hypothesize every SDM method is based on.","According to it, every SDM algorithm can be seen as a procedure that iteratively improves its solution estimate by leveraging the task knowledge available.","Finally, we derive a set of formulas and algorithms for calculating interesting properties of SDM tasks and methods, which make possible their empirical evaluation and comparison."],"url":"http://arxiv.org/abs/2310.02167v1"}
{"created":"2023-10-03 15:57:00","title":"Large Language Models Meet Knowledge Graphs to Answer Factoid Questions","abstract":"Recently, it has been shown that the incorporation of structured knowledge into Large Language Models significantly improves the results for a variety of NLP tasks. In this paper, we propose a method for exploring pre-trained Text-to-Text Language Models enriched with additional information from Knowledge Graphs for answering factoid questions. More specifically, we propose an algorithm for subgraphs extraction from a Knowledge Graph based on question entities and answer candidates. Then, we procure easily interpreted information with Transformer-based models through the linearization of the extracted subgraphs. Final re-ranking of the answer candidates with the extracted information boosts Hits@1 scores of the pre-trained text-to-text language models by 4-6%.","sentences":["Recently, it has been shown that the incorporation of structured knowledge into Large Language Models significantly improves the results for a variety of NLP tasks.","In this paper, we propose a method for exploring pre-trained Text-to-Text Language Models enriched with additional information from Knowledge Graphs for answering factoid questions.","More specifically, we propose an algorithm for subgraphs extraction from a Knowledge Graph based on question entities and answer candidates.","Then, we procure easily interpreted information with Transformer-based models through the linearization of the extracted subgraphs.","Final re-ranking of the answer candidates with the extracted information boosts Hits@1 scores of the pre-trained text-to-text language models by 4-6%."],"url":"http://arxiv.org/abs/2310.02166v1"}
{"created":"2023-10-03 15:49:03","title":"TreeScope: An Agricultural Robotics Dataset for LiDAR-Based Mapping of Trees in Forests and Orchards","abstract":"Data collection for forestry, timber, and agriculture currently relies on manual techniques which are labor-intensive and time-consuming. We seek to demonstrate that robotics offers improvements over these techniques and accelerate agricultural research, beginning with semantic segmentation and diameter estimation of trees in forests and orchards. We present TreeScope v1.0, the first robotics dataset for precision agriculture and forestry addressing the counting and mapping of trees in forestry and orchards. TreeScope provides LiDAR data from agricultural environments collected with robotics platforms, such as UAV and mobile robot platforms carried by vehicles and human operators. In the first release of this dataset, we provide ground-truth data with over 1,800 manually annotated semantic labels for tree stems and field-measured tree diameters. We share benchmark scripts for these tasks that researchers may use to evaluate the accuracy of their algorithms. Finally, we run our open-source diameter estimation and off-the-shelf semantic segmentation algorithms and share our baseline results.","sentences":["Data collection for forestry, timber, and agriculture currently relies on manual techniques which are labor-intensive and time-consuming.","We seek to demonstrate that robotics offers improvements over these techniques and accelerate agricultural research, beginning with semantic segmentation and diameter estimation of trees in forests and orchards.","We present TreeScope v1.0, the first robotics dataset for precision agriculture and forestry addressing the counting and mapping of trees in forestry and orchards.","TreeScope provides LiDAR data from agricultural environments collected with robotics platforms, such as UAV and mobile robot platforms carried by vehicles and human operators.","In the first release of this dataset, we provide ground-truth data with over 1,800 manually annotated semantic labels for tree stems and field-measured tree diameters.","We share benchmark scripts for these tasks that researchers may use to evaluate the accuracy of their algorithms.","Finally, we run our open-source diameter estimation and off-the-shelf semantic segmentation algorithms and share our baseline results."],"url":"http://arxiv.org/abs/2310.02162v1"}
{"created":"2023-10-03 15:48:22","title":"Selenite: Scaffolding Decision Making with Comprehensive Overviews Elicited from Large Language Models","abstract":"Decision-making in unfamiliar domains can be challenging, demanding considerable user effort to compare different options with respect to various criteria. Prior research and our formative study found that people would benefit from seeing an overview of the information space upfront, such as the criteria that others have previously found useful. However, existing sensemaking tools struggle with the \"cold-start\" problem -- it not only requires significant input from previous users to generate and share these overviews, but such overviews may also be biased and incomplete. In this work, we introduce a novel system, Selenite, which leverages LLMs as reasoning machines and knowledge retrievers to automatically produce a comprehensive overview of options and criteria to jumpstart users' sensemaking processes. Subsequently, Selenite also adapts as people use it, helping users find, read, and navigate unfamiliar information in a systematic yet personalized manner. Through three studies, we found that Selenite produced accurate and high-quality overviews reliably, significantly accelerated users' information processing, and effectively improved their overall comprehension and sensemaking experience.","sentences":["Decision-making in unfamiliar domains can be challenging, demanding considerable user effort to compare different options with respect to various criteria.","Prior research and our formative study found that people would benefit from seeing an overview of the information space upfront, such as the criteria that others have previously found useful.","However, existing sensemaking tools struggle with the \"cold-start\" problem -- it not only requires significant input from previous users to generate and share these overviews, but such overviews may also be biased and incomplete.","In this work, we introduce a novel system, Selenite, which leverages LLMs as reasoning machines and knowledge retrievers to automatically produce a comprehensive overview of options and criteria to jumpstart users' sensemaking processes.","Subsequently, Selenite also adapts as people use it, helping users find, read, and navigate unfamiliar information in a systematic yet personalized manner.","Through three studies, we found that Selenite produced accurate and high-quality overviews reliably, significantly accelerated users' information processing, and effectively improved their overall comprehension and sensemaking experience."],"url":"http://arxiv.org/abs/2310.02161v1"}
{"created":"2023-10-03 15:43:59","title":"Probabilistically Rewired Message-Passing Neural Networks","abstract":"Message-passing graph neural networks (MPNNs) emerged as powerful tools for processing graph-structured input. However, they operate on a fixed input graph structure, ignoring potential noise and missing information. Furthermore, their local aggregation mechanism can lead to problems such as over-squashing and limited expressive power in capturing relevant graph structures. Existing solutions to these challenges have primarily relied on heuristic methods, often disregarding the underlying data distribution. Hence, devising principled approaches for learning to infer graph structures relevant to the given prediction task remains an open challenge. In this work, leveraging recent progress in exact and differentiable $k$-subset sampling, we devise probabilistically rewired MPNNs (PR-MPNNs), which learn to add relevant edges while omitting less beneficial ones. For the first time, our theoretical analysis explores how PR-MPNNs enhance expressive power, and we identify precise conditions under which they outperform purely randomized approaches. Empirically, we demonstrate that our approach effectively mitigates issues like over-squashing and under-reaching. In addition, on established real-world datasets, our method exhibits competitive or superior predictive performance compared to traditional MPNN models and recent graph transformer architectures.","sentences":["Message-passing graph neural networks (MPNNs) emerged as powerful tools for processing graph-structured input.","However, they operate on a fixed input graph structure, ignoring potential noise and missing information.","Furthermore, their local aggregation mechanism can lead to problems such as over-squashing and limited expressive power in capturing relevant graph structures.","Existing solutions to these challenges have primarily relied on heuristic methods, often disregarding the underlying data distribution.","Hence, devising principled approaches for learning to infer graph structures relevant to the given prediction task remains an open challenge.","In this work, leveraging recent progress in exact and differentiable $k$-subset sampling, we devise probabilistically rewired MPNNs (PR-MPNNs), which learn to add relevant edges while omitting less beneficial ones.","For the first time, our theoretical analysis explores how PR-MPNNs enhance expressive power, and we identify precise conditions under which they outperform purely randomized approaches.","Empirically, we demonstrate that our approach effectively mitigates issues like over-squashing and under-reaching.","In addition, on established real-world datasets, our method exhibits competitive or superior predictive performance compared to traditional MPNN models and recent graph transformer architectures."],"url":"http://arxiv.org/abs/2310.02156v1"}
{"created":"2023-10-03 15:40:19","title":"Program Structure Aware Precondition Generation","abstract":"We introduce a novel approach for inferring natural preconditions from code. Our technique produces preconditions of high quality in terms of both correctness (modulo a test generator) and naturalness. Prior works generate preconditions from scratch through combinations of boolean predicates, but fall short in readability and ease of comprehension. Our innovation lies in, instead, leveraging the structure of a target method as a seed to infer a precondition through program transformations. Our evaluation shows that humans can more easily reason over preconditions inferred using our approach. Lastly, we instantiate our technique into a framework which can be applied at scale. We present a dataset of ~18k Java (method, precondition) pairs obtained by applying our framework to 87 real-world projects. We use this dataset to both evaluate our approach and draw useful insights for future research in precondition inference.","sentences":["We introduce a novel approach for inferring natural preconditions from code.","Our technique produces preconditions of high quality in terms of both correctness (modulo a test generator) and naturalness.","Prior works generate preconditions from scratch through combinations of boolean predicates, but fall short in readability and ease of comprehension.","Our innovation lies in, instead, leveraging the structure of a target method as a seed to infer a precondition through program transformations.","Our evaluation shows that humans can more easily reason over preconditions inferred using our approach.","Lastly, we instantiate our technique into a framework which can be applied at scale.","We present a dataset of ~18k Java (method, precondition) pairs obtained by applying our framework to 87 real-world projects.","We use this dataset to both evaluate our approach and draw useful insights for future research in precondition inference."],"url":"http://arxiv.org/abs/2310.02154v1"}
{"created":"2023-10-03 15:34:21","title":"Finite-Time Analysis of Whittle Index based Q-Learning for Restless Multi-Armed Bandits with Neural Network Function Approximation","abstract":"Whittle index policy is a heuristic to the intractable restless multi-armed bandits (RMAB) problem. Although it is provably asymptotically optimal, finding Whittle indices remains difficult. In this paper, we present Neural-Q-Whittle, a Whittle index based Q-learning algorithm for RMAB with neural network function approximation, which is an example of nonlinear two-timescale stochastic approximation with Q-function values updated on a faster timescale and Whittle indices on a slower timescale. Despite the empirical success of deep Q-learning, the non-asymptotic convergence rate of Neural-Q-Whittle, which couples neural networks with two-timescale Q-learning largely remains unclear. This paper provides a finite-time analysis of Neural-Q-Whittle, where data are generated from a Markov chain, and Q-function is approximated by a ReLU neural network. Our analysis leverages a Lyapunov drift approach to capture the evolution of two coupled parameters, and the nonlinearity in value function approximation further requires us to characterize the approximation error. Combing these provide Neural-Q-Whittle with $\\mathcal{O}(1/k^{2/3})$ convergence rate, where $k$ is the number of iterations.","sentences":["Whittle index policy is a heuristic to the intractable restless multi-armed bandits (RMAB) problem.","Although it is provably asymptotically optimal, finding Whittle indices remains difficult.","In this paper, we present Neural-Q-Whittle, a Whittle index based Q-learning algorithm for RMAB with neural network function approximation, which is an example of nonlinear two-timescale stochastic approximation with Q-function values updated on a faster timescale and Whittle indices on a slower timescale.","Despite the empirical success of deep Q-learning, the non-asymptotic convergence rate of Neural-Q-Whittle, which couples neural networks with two-timescale Q-learning largely remains unclear.","This paper provides a finite-time analysis of Neural-Q-Whittle, where data are generated from a Markov chain, and Q-function is approximated by a ReLU neural network.","Our analysis leverages a Lyapunov drift approach to capture the evolution of two coupled parameters, and the nonlinearity in value function approximation further requires us to characterize the approximation error.","Combing these provide Neural-Q-Whittle with $\\mathcal{O}(1/k^{2/3})$ convergence rate, where $k$ is the number of iterations."],"url":"http://arxiv.org/abs/2310.02147v1"}
{"created":"2023-10-03 15:29:37","title":"CORec-Cri: How collaborative and social technologies can help to contextualize crises?","abstract":"Crisis situations can present complex and multifaceted challenges, often requiring the involvement of multiple organizations and stakeholders with varying areas of expertise, responsibilities, and resources. Acquiring accurate and timely information about impacted areas is crucial to effectively respond to these crises. In this paper, we investigate how collaborative and social technologies help to contextualize crises, including identifying impacted areas and real-time needs. To this end, we define CORec-Cri (Contextulized Ontology-based Recommender system for crisis management) based on existing work. Our motivation for this approach is two-fold: first, effective collaboration among stakeholders is essential for efficient and coordinated crisis response; second, social computing facilitates interaction, information flow, and collaboration among stakeholders. We detail the key components of our system design, highlighting its potential to support decision-making, resource allocation, and communication among stakeholders. Finally, we provide examples of how our system can be applied to contextualize crises to improve crisis management.","sentences":["Crisis situations can present complex and multifaceted challenges, often requiring the involvement of multiple organizations and stakeholders with varying areas of expertise, responsibilities, and resources.","Acquiring accurate and timely information about impacted areas is crucial to effectively respond to these crises.","In this paper, we investigate how collaborative and social technologies help to contextualize crises, including identifying impacted areas and real-time needs.","To this end, we define CORec-Cri (Contextulized Ontology-based Recommender system for crisis management) based on existing work.","Our motivation for this approach is two-fold: first, effective collaboration among stakeholders is essential for efficient and coordinated crisis response; second, social computing facilitates interaction, information flow, and collaboration among stakeholders.","We detail the key components of our system design, highlighting its potential to support decision-making, resource allocation, and communication among stakeholders.","Finally, we provide examples of how our system can be applied to contextualize crises to improve crisis management."],"url":"http://arxiv.org/abs/2310.02143v1"}
{"created":"2023-10-03 15:26:41","title":"Arena-independent Memory Bounds for Nash Equilibria in Reachability Games","abstract":"We study the memory requirements of Nash equilibria in turn-based multiplayer games on possibly infinite graphs with reachability, shortest path and B\\\"uchi objectives.   We present constructions for finite-memory Nash equilibria in these games that apply to arbitrary game graphs, bypassing the finite-arena requirement that is central in existing approaches. We show that, for these three types of games, from any Nash equilibrium, we can derive another Nash equilibrium where all strategies are finite-memory such that the same players accomplish their objective, without increasing their cost for shortest path games.   Furthermore, we provide memory bounds that are independent of the size of the game graph for reachability and shortest path games. These bounds depend only on the number of players.   To the best of our knowledge, we provide the first results pertaining to finite-memory constrained Nash equilibria in infinite arenas and the first arena-independent memory bounds for Nash equilibria.","sentences":["We study the memory requirements of Nash equilibria in turn-based multiplayer games on possibly infinite graphs with reachability, shortest path and B\\\"uchi objectives.   ","We present constructions for finite-memory Nash equilibria in these games that apply to arbitrary game graphs, bypassing the finite-arena requirement that is central in existing approaches.","We show that, for these three types of games, from any Nash equilibrium, we can derive another Nash equilibrium where all strategies are finite-memory such that the same players accomplish their objective, without increasing their cost for shortest path games.   ","Furthermore, we provide memory bounds that are independent of the size of the game graph for reachability and shortest path games.","These bounds depend only on the number of players.   ","To the best of our knowledge, we provide the first results pertaining to finite-memory constrained Nash equilibria in infinite arenas and the first arena-independent memory bounds for Nash equilibria."],"url":"http://arxiv.org/abs/2310.02142v1"}
{"created":"2023-10-03 15:25:57","title":"Adaptive Gait Modeling and Optimization for Principally Kinematic Systems","abstract":"Robotic adaptation to unanticipated operating conditions is crucial to achieving persistence and robustness in complex real world settings. For a wide range of cutting-edge robotic systems, such as micro- and nano-scale robots, soft robots, medical robots, and bio-hybrid robots, it is infeasible to anticipate the operating environment a priori due to complexities that arise from numerous factors including imprecision in manufacturing, chemo-mechanical forces, and poorly understood contact mechanics. Drawing inspiration from data-driven modeling, geometric mechanics (or gauge theory), and adaptive control, we employ an adaptive system identification framework and demonstrate its efficacy in enhancing the performance of principally kinematic locomotors (those governed by Rayleigh dissipation or zero momentum conservation). We showcase the capability of the adaptive model to efficiently accommodate varying terrains and iteratively modified behaviors within a behavior optimization framework. This provides both the ability to improve fundamental behaviors and perform motion tracking to precision. Notably, we are capable of optimizing the gaits of the Purcell swimmer using approximately 10 cycles per link, which for the nine-link Purcell swimmer provides a factor of ten improvement in optimization speed over the state of the art. Beyond simply a computational speed up, this ten-fold improvement may enable this method to be successfully deployed for in-situ behavior refinement, injury recovery, and terrain adaptation, particularly in domains where simulations provide poor guides for the real world.","sentences":["Robotic adaptation to unanticipated operating conditions is crucial to achieving persistence and robustness in complex real world settings.","For a wide range of cutting-edge robotic systems, such as micro- and nano-scale robots, soft robots, medical robots, and bio-hybrid robots, it is infeasible to anticipate the operating environment a priori due to complexities that arise from numerous factors including imprecision in manufacturing, chemo-mechanical forces, and poorly understood contact mechanics.","Drawing inspiration from data-driven modeling, geometric mechanics (or gauge theory), and adaptive control, we employ an adaptive system identification framework and demonstrate its efficacy in enhancing the performance of principally kinematic locomotors (those governed by Rayleigh dissipation or zero momentum conservation).","We showcase the capability of the adaptive model to efficiently accommodate varying terrains and iteratively modified behaviors within a behavior optimization framework.","This provides both the ability to improve fundamental behaviors and perform motion tracking to precision.","Notably, we are capable of optimizing the gaits of the Purcell swimmer using approximately 10 cycles per link, which for the nine-link Purcell swimmer provides a factor of ten improvement in optimization speed over the state of the art.","Beyond simply a computational speed up, this ten-fold improvement may enable this method to be successfully deployed for in-situ behavior refinement, injury recovery, and terrain adaptation, particularly in domains where simulations provide poor guides for the real world."],"url":"http://arxiv.org/abs/2310.02141v1"}
{"created":"2023-10-03 15:24:15","title":"PAD-Phys: Exploiting Physiology for Presentation Attack Detection in Face Biometrics","abstract":"Presentation Attack Detection (PAD) is a crucial stage in facial recognition systems to avoid leakage of personal information or spoofing of identity to entities. Recently, pulse detection based on remote photoplethysmography (rPPG) has been shown to be effective in face presentation attack detection.   This work presents three different approaches to the presentation attack detection based on rPPG: (i) The physiological domain, a domain using rPPG-based models, (ii) the Deepfakes domain, a domain where models were retrained from the physiological domain to specific Deepfakes detection tasks; and (iii) a new Presentation Attack domain was trained by applying transfer learning from the two previous domains to improve the capability to differentiate between bona-fides and attacks.   The results show the efficiency of the rPPG-based models for presentation attack detection, evidencing a 21.70% decrease in average classification error rate (ACER) (from 41.03% to 19.32%) when the presentation attack domain is compared to the physiological and Deepfakes domains. Our experiments highlight the efficiency of transfer learning in rPPG-based models and perform well in presentation attack detection in instruments that do not allow copying of this physiological feature.","sentences":["Presentation Attack Detection (PAD) is a crucial stage in facial recognition systems to avoid leakage of personal information or spoofing of identity to entities.","Recently, pulse detection based on remote photoplethysmography (rPPG) has been shown to be effective in face presentation attack detection.   ","This work presents three different approaches to the presentation attack detection based on rPPG: (i) The physiological domain, a domain using rPPG-based models, (ii) the Deepfakes domain, a domain where models were retrained from the physiological domain to specific Deepfakes detection tasks; and (iii) a new Presentation Attack domain was trained by applying transfer learning from the two previous domains to improve the capability to differentiate between bona-fides and attacks.   ","The results show the efficiency of the rPPG-based models for presentation attack detection, evidencing a 21.70% decrease in average classification error rate (ACER) (from 41.03% to 19.32%) when the presentation attack domain is compared to the physiological and Deepfakes domains.","Our experiments highlight the efficiency of transfer learning in rPPG-based models and perform well in presentation attack detection in instruments that do not allow copying of this physiological feature."],"url":"http://arxiv.org/abs/2310.02140v1"}
{"created":"2023-10-03 15:14:28","title":"Learning Reliable Logical Rules with SATNet","abstract":"Bridging logical reasoning and deep learning is crucial for advanced AI systems. In this work, we present a new framework that addresses this goal by generating interpretable and verifiable logical rules through differentiable learning, without relying on pre-specified logical structures. Our approach builds upon SATNet, a differentiable MaxSAT solver that learns the underlying rules from input-output examples. Despite its efficacy, the learned weights in SATNet are not straightforwardly interpretable, failing to produce human-readable rules. To address this, we propose a novel specification method called \"maximum equality\", which enables the interchangeability between the learned weights of SATNet and a set of propositional logical rules in weighted MaxSAT form. With the decoded weighted MaxSAT formula, we further introduce several effective verification techniques to validate it against the ground truth rules. Experiments on stream transformations and Sudoku problems show that our decoded rules are highly reliable: using exact solvers on them could achieve 100% accuracy, whereas the original SATNet fails to give correct solutions in many cases. Furthermore, we formally verify that our decoded logical rules are functionally equivalent to the ground truth ones.","sentences":["Bridging logical reasoning and deep learning is crucial for advanced AI systems.","In this work, we present a new framework that addresses this goal by generating interpretable and verifiable logical rules through differentiable learning, without relying on pre-specified logical structures.","Our approach builds upon SATNet, a differentiable MaxSAT solver that learns the underlying rules from input-output examples.","Despite its efficacy, the learned weights in SATNet are not straightforwardly interpretable, failing to produce human-readable rules.","To address this, we propose a novel specification method called \"maximum equality\", which enables the interchangeability between the learned weights of SATNet and a set of propositional logical rules in weighted MaxSAT form.","With the decoded weighted MaxSAT formula, we further introduce several effective verification techniques to validate it against the ground truth rules.","Experiments on stream transformations and Sudoku problems show that our decoded rules are highly reliable: using exact solvers on them could achieve 100% accuracy, whereas the original SATNet fails to give correct solutions in many cases.","Furthermore, we formally verify that our decoded logical rules are functionally equivalent to the ground truth ones."],"url":"http://arxiv.org/abs/2310.02133v1"}
{"created":"2023-10-03 15:12:47","title":"Clustering Graphs of Bounded Treewidth to Minimize the Sum of Radius-Dependent Costs","abstract":"We consider the following natural problem that generalizes min-sum-radii clustering: Given is $k\\in\\mathbb{N}$ as well as some metric space $(V,d)$ where $V=F\\cup C$ for facilities $F$ and clients $C$. The goal is to find a clustering given by $k$ facility-radius pairs $(f_1,r_1),\\dots,(f_k,r_k)\\in F\\times\\mathbb{R}_{\\geq 0}$ such that $C\\subseteq B(f_1,r_1)\\cup\\dots\\cup B(f_k,r_k)$ and $\\sum_{i=1,\\dots,k} g(r_i)$ is minimized for some increasing function $g:\\mathbb{R}_{\\geq 0}\\rightarrow\\mathbb{R}_{\\geq 0}$. Here, $B(x,r)$ is the radius-$r$ ball centered at $x$. For the case that $(V,d)$ is the shortest-path metric of some edge-weighted graph of bounded treewidth, we present a dynamic program that is tailored to this class of problems and achieves a polynomial running time, establishing that the problem is in $\\mathsf{XP}$ with parameter treewidth.","sentences":["We consider the following natural problem that generalizes min-sum-radii clustering: Given is $k\\in\\mathbb{N}$ as well as some metric space $(V,d)$ where $V=F\\cup C$ for facilities $F$ and clients $C$.","The goal is to find a clustering given by $k$ facility-radius pairs $(f_1,r_1),\\dots,(f_k,r_k)\\in F\\times\\mathbb{R}_{\\geq 0}$ such that $C\\subseteq B(f_1,r_1)\\cup\\dots\\cup B(f_k,r_k)$ and $\\sum_{i=1,\\dots,k} g(r_i)$ is minimized for some increasing function $g:\\mathbb{R}_{\\geq 0}\\rightarrow\\mathbb{R}_{\\geq 0}$.","Here, $B(x,r)$ is the radius-$r$ ball centered at $x$.","For the case that $(V,d)$ is the shortest-path metric of some edge-weighted graph of bounded treewidth, we present a dynamic program that is tailored to this class of problems and achieves a polynomial running time, establishing that the problem is in $\\mathsf{XP}$ with parameter treewidth."],"url":"http://arxiv.org/abs/2310.02130v1"}
{"created":"2023-10-03 15:10:46","title":"Unveiling the Pitfalls of Knowledge Editing for Large Language Models","abstract":"As the cost associated with fine-tuning Large Language Models (LLMs) continues to rise, recent research efforts have pivoted towards developing methodologies to edit implicit knowledge embedded within LLMs. Yet, there's still a dark cloud lingering overhead -- will knowledge editing trigger butterfly effect? since it is still unclear whether knowledge editing might introduce side effects that pose potential risks or not. This paper pioneers the investigation into the potential pitfalls associated with knowledge editing for LLMs. To achieve this, we introduce new benchmark datasets and propose innovative evaluation metrics. Our results underline two pivotal concerns: (1) Knowledge Conflict: Editing groups of facts that logically clash can magnify the inherent inconsistencies in LLMs-a facet neglected by previous methods. (2) Knowledge Distortion: Altering parameters with the aim of editing factual knowledge can irrevocably warp the innate knowledge structure of LLMs. Experimental results vividly demonstrate that knowledge editing might inadvertently cast a shadow of unintended consequences on LLMs, which warrant attention and efforts for future works. Code will be released at https://github.com/zjunlp/PitfallsKnowledgeEditing.","sentences":["As the cost associated with fine-tuning Large Language Models (LLMs) continues to rise, recent research efforts have pivoted towards developing methodologies to edit implicit knowledge embedded within LLMs.","Yet, there's still a dark cloud lingering overhead -- will knowledge editing trigger butterfly effect?","since it is still unclear whether knowledge editing might introduce side effects that pose potential risks or not.","This paper pioneers the investigation into the potential pitfalls associated with knowledge editing for LLMs.","To achieve this, we introduce new benchmark datasets and propose innovative evaluation metrics.","Our results underline two pivotal concerns: (1) Knowledge Conflict:","Editing groups of facts that logically clash can magnify the inherent inconsistencies in LLMs-a facet neglected by previous methods.","(2) Knowledge Distortion: Altering parameters with the aim of editing factual knowledge can irrevocably warp the innate knowledge structure of LLMs.","Experimental results vividly demonstrate that knowledge editing might inadvertently cast a shadow of unintended consequences on LLMs, which warrant attention and efforts for future works.","Code will be released at https://github.com/zjunlp/PitfallsKnowledgeEditing."],"url":"http://arxiv.org/abs/2310.02129v1"}
{"created":"2023-10-03 15:09:49","title":"Semantic Code Graph -- an information model to facilitate software comprehension","abstract":"Software comprehension can be extremely time-consuming due to the ever-growing size of codebases. Consequently, there is an increasing need to accelerate the code comprehension process to facilitate maintenance and reduce associated costs. A crucial aspect of this process is understanding and preserving the high quality of the code dependency structure. While a variety of code structure models already exist, there is a surprising lack of models that closely represent the source code and focus on software comprehension. As a result, there are no readily available and easy-to-use tools to assist with dependency comprehension, refactoring, and quality monitoring of code. To address this gap, we propose the Semantic Code Graph (SCG), an information model that offers a detailed abstract representation of code dependencies with a close relationship to the source code. To validate the SCG model's usefulness in software comprehension, we compare it to nine other source code representation models. Additionally, we select 11 well-known and widely-used open-source projects developed in Java and Scala and perform a range of software comprehension activities on them using three different code representation models: the proposed SCG, the Call Graph (CG), and the Class Collaboration Network (CCN). We then qualitatively analyze the results to compare the performance of these models in terms of software comprehension capabilities. These activities encompass project structure comprehension, identifying critical project entities, interactive visualization of code dependencies, and uncovering code similarities through software mining. Our findings demonstrate that the SCG enhances software comprehension capabilities compared to the prevailing CCN and CG models. We believe that the work described is a step towards the next generation of tools that streamline code dependency comprehension and management.","sentences":["Software comprehension can be extremely time-consuming due to the ever-growing size of codebases.","Consequently, there is an increasing need to accelerate the code comprehension process to facilitate maintenance and reduce associated costs.","A crucial aspect of this process is understanding and preserving the high quality of the code dependency structure.","While a variety of code structure models already exist, there is a surprising lack of models that closely represent the source code and focus on software comprehension.","As a result, there are no readily available and easy-to-use tools to assist with dependency comprehension, refactoring, and quality monitoring of code.","To address this gap, we propose the Semantic Code Graph (SCG), an information model that offers a detailed abstract representation of code dependencies with a close relationship to the source code.","To validate the SCG model's usefulness in software comprehension, we compare it to nine other source code representation models.","Additionally, we select 11 well-known and widely-used open-source projects developed in Java and Scala and perform a range of software comprehension activities on them using three different code representation models: the proposed SCG, the Call Graph (CG), and the Class Collaboration Network (CCN).","We then qualitatively analyze the results to compare the performance of these models in terms of software comprehension capabilities.","These activities encompass project structure comprehension, identifying critical project entities, interactive visualization of code dependencies, and uncovering code similarities through software mining.","Our findings demonstrate that the SCG enhances software comprehension capabilities compared to the prevailing CCN and CG models.","We believe that the work described is a step towards the next generation of tools that streamline code dependency comprehension and management."],"url":"http://arxiv.org/abs/2310.02128v1"}
{"created":"2023-10-03 15:05:52","title":"Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology View","abstract":"As Natural Language Processing (NLP) systems are increasingly employed in intricate social environments, a pressing query emerges: Can these NLP systems mirror human-esque collaborative intelligence, in a multi-agent society consisting of multiple large language models (LLMs)? This paper probes the collaboration mechanisms among contemporary NLP systems by melding practical experiments with theoretical insights. We fabricate four unique `societies' comprised of LLM agents, where each agent is characterized by a specific `trait' (easy-going or overconfident) and engages in collaboration with a distinct `thinking pattern' (debate or reflection). Evaluating these multi-agent societies on three benchmark datasets, we discern that LLM agents navigate tasks by leveraging diverse social behaviors, from active debates to introspective reflections. Notably, certain collaborative strategies only optimize efficiency (using fewer API tokens), but also outshine previous top-tier approaches. Moreover, our results further illustrate that LLM agents manifest human-like social behaviors, such as conformity or majority rule, mirroring foundational Social Psychology theories. In conclusion, we integrate insights from Social Psychology to contextualize the collaboration of LLM agents, inspiring further investigations into the collaboration mechanism for LLMs. We commit to sharing our code and datasets (already submitted in supplementary materials), hoping to catalyze further research in this promising avenue (All code and data are available at \\url{https://github.com/zjunlp/MachineSoM}.).","sentences":["As Natural Language Processing (NLP) systems are increasingly employed in intricate social environments, a pressing query emerges: Can these NLP systems mirror human-esque collaborative intelligence, in a multi-agent society consisting of multiple large language models (LLMs)?","This paper probes the collaboration mechanisms among contemporary NLP systems by melding practical experiments with theoretical insights.","We fabricate four unique `societies' comprised of LLM agents, where each agent is characterized by a specific `trait' (easy-going or overconfident) and engages in collaboration with a distinct `thinking pattern' (debate or reflection).","Evaluating these multi-agent societies on three benchmark datasets, we discern that LLM agents navigate tasks by leveraging diverse social behaviors, from active debates to introspective reflections.","Notably, certain collaborative strategies only optimize efficiency (using fewer API tokens), but also outshine previous top-tier approaches.","Moreover, our results further illustrate that LLM agents manifest human-like social behaviors, such as conformity or majority rule, mirroring foundational Social Psychology theories.","In conclusion, we integrate insights from Social Psychology to contextualize the collaboration of LLM agents, inspiring further investigations into the collaboration mechanism for LLMs.","We commit to sharing our code and datasets (already submitted in supplementary materials), hoping to catalyze further research in this promising avenue (All code and data are available at \\url{https://github.com/zjunlp/MachineSoM}.)."],"url":"http://arxiv.org/abs/2310.02124v1"}
{"created":"2023-10-03 15:03:43","title":"Fast algorithm for centralized multi-agent maze exploration","abstract":"Recent advancements in robotics have paved the way for robots to replace humans in perilous situations, such as searching for victims in blazing buildings, earthquake-damaged structures, uncharted caves, traversing minefields, or patrolling crime-ridden streets. These challenges can be generalized as problems where agents need to explore unknown mazes. Although various algorithms for single-agent maze exploration exist, extending them to multi-agent systems poses complexities.   We propose a solution: a cooperative multi-agent system of automated mobile agents for exploring unknown mazes and locating stationary targets. Our algorithm employs a potential field governing maze exploration, integrating cooperative agent behaviors like collision avoidance, coverage coordination, and path planning.   This approach builds upon the Heat Equation Driven Area Coverage (HEDAC) method by Ivi\\'c, Crnkovi\\'c, and Mezi\\'c. Unlike previous continuous domain applications, we adapt HEDAC for discrete domains, specifically mazes divided into nodes. Our algorithm is versatile, easily modified for anti-collision requirements, and adaptable to expanding mazes and numerical meshes over time.   Comparative evaluations against alternative maze-solving methods illustrate our algorithm's superiority. The results highlight significant enhancements, showcasing its applicability across diverse mazes. Numerical simulations affirm its robustness, adaptability, scalability, and simplicity, enabling centralized parallel computation in autonomous systems of basic agents/robots.","sentences":["Recent advancements in robotics have paved the way for robots to replace humans in perilous situations, such as searching for victims in blazing buildings, earthquake-damaged structures, uncharted caves, traversing minefields, or patrolling crime-ridden streets.","These challenges can be generalized as problems where agents need to explore unknown mazes.","Although various algorithms for single-agent maze exploration exist, extending them to multi-agent systems poses complexities.   ","We propose a solution: a cooperative multi-agent system of automated mobile agents for exploring unknown mazes and locating stationary targets.","Our algorithm employs a potential field governing maze exploration, integrating cooperative agent behaviors like collision avoidance, coverage coordination, and path planning.   ","This approach builds upon the Heat Equation Driven Area Coverage (HEDAC) method by Ivi\\'c, Crnkovi\\'c, and Mezi\\'c.","Unlike previous continuous domain applications, we adapt HEDAC for discrete domains, specifically mazes divided into nodes.","Our algorithm is versatile, easily modified for anti-collision requirements, and adaptable to expanding mazes and numerical meshes over time.   ","Comparative evaluations against alternative maze-solving methods illustrate our algorithm's superiority.","The results highlight significant enhancements, showcasing its applicability across diverse mazes.","Numerical simulations affirm its robustness, adaptability, scalability, and simplicity, enabling centralized parallel computation in autonomous systems of basic agents/robots."],"url":"http://arxiv.org/abs/2310.02121v1"}
{"created":"2023-10-03 15:03:10","title":"HPCClusterScape: Increasing Transparency and Efficiency of Shared High-Performance Computing Clusters for Large-scale AI Models","abstract":"The emergence of large-scale AI models, like GPT-4, has significantly impacted academia and industry, driving the demand for high-performance computing (HPC) to accelerate workloads. To address this, we present HPCClusterScape, a visualization system that enhances the efficiency and transparency of shared HPC clusters for large-scale AI models. HPCClusterScape provides a comprehensive overview of system-level (e.g., partitions, hosts, and workload status) and application-level (e.g., identification of experiments and researchers) information, allowing HPC operators and machine learning researchers to monitor resource utilization and identify issues through customizable violation rules. The system includes diagnostic tools to investigate workload imbalances and synchronization bottlenecks in large-scale distributed deep learning experiments. Deployed in industrial-scale HPC clusters, HPCClusterScape incorporates user feedback and meets specific requirements. This paper outlines the challenges and prerequisites for efficient HPC operation, introduces the interactive visualization system, and highlights its contributions in addressing pain points and optimizing resource utilization in shared HPC clusters.","sentences":["The emergence of large-scale AI models, like GPT-4, has significantly impacted academia and industry, driving the demand for high-performance computing (HPC) to accelerate workloads.","To address this, we present HPCClusterScape, a visualization system that enhances the efficiency and transparency of shared HPC clusters for large-scale AI models.","HPCClusterScape provides a comprehensive overview of system-level (e.g., partitions, hosts, and workload status) and application-level (e.g., identification of experiments and researchers) information, allowing HPC operators and machine learning researchers to monitor resource utilization and identify issues through customizable violation rules.","The system includes diagnostic tools to investigate workload imbalances and synchronization bottlenecks in large-scale distributed deep learning experiments.","Deployed in industrial-scale HPC clusters, HPCClusterScape incorporates user feedback and meets specific requirements.","This paper outlines the challenges and prerequisites for efficient HPC operation, introduces the interactive visualization system, and highlights its contributions in addressing pain points and optimizing resource utilization in shared HPC clusters."],"url":"http://arxiv.org/abs/2310.02120v1"}
{"created":"2023-10-03 14:59:35","title":"TWIZ: The Wizard of Multimodal Conversational-Stimulus","abstract":"In this report, we describe the vision, challenges, and scientific contributions of the Task Wizard team, TWIZ, in the Alexa Prize TaskBot Challenge 2022. Our vision, is to build TWIZ bot as an helpful, multimodal, knowledgeable, and engaging assistant that can guide users towards the successful completion of complex manual tasks. To achieve this, we focus our efforts on three main research questions: (1) Humanly-Shaped Conversations, by providing information in a knowledgeable way; (2) Multimodal Stimulus, making use of various modalities including voice, images, and videos; and (3) Zero-shot Conversational Flows, to improve the robustness of the interaction to unseen scenarios. TWIZ is an assistant capable of supporting a wide range of tasks, with several innovative features such as creative cooking, video navigation through voice, and the robust TWIZ-LLM, a Large Language Model trained for dialoguing about complex manual tasks. Given ratings and feedback provided by users, we observed that TWIZ bot is an effective and robust system, capable of guiding users through tasks while providing several multimodal stimuli.","sentences":["In this report, we describe the vision, challenges, and scientific contributions of the Task Wizard team, TWIZ, in the Alexa Prize TaskBot Challenge 2022.","Our vision, is to build TWIZ bot as an helpful, multimodal, knowledgeable, and engaging assistant that can guide users towards the successful completion of complex manual tasks.","To achieve this, we focus our efforts on three main research questions: (1) Humanly-Shaped Conversations, by providing information in a knowledgeable way; (2) Multimodal Stimulus, making use of various modalities including voice, images, and videos; and (3) Zero-shot Conversational Flows, to improve the robustness of the interaction to unseen scenarios.","TWIZ is an assistant capable of supporting a wide range of tasks, with several innovative features such as creative cooking, video navigation through voice, and the robust TWIZ-LLM, a Large Language Model trained for dialoguing about complex manual tasks.","Given ratings and feedback provided by users, we observed that TWIZ bot is an effective and robust system, capable of guiding users through tasks while providing several multimodal stimuli."],"url":"http://arxiv.org/abs/2310.02118v1"}
{"created":"2023-10-03 14:59:00","title":"Symmetric Single Index Learning","abstract":"Few neural architectures lend themselves to provable learning with gradient based methods. One popular model is the single-index model, in which labels are produced by composing an unknown linear projection with a possibly unknown scalar link function. Learning this model with SGD is relatively well-understood, whereby the so-called information exponent of the link function governs a polynomial sample complexity rate. However, extending this analysis to deeper or more complicated architectures remains challenging.   In this work, we consider single index learning in the setting of symmetric neural networks. Under analytic assumptions on the activation and maximum degree assumptions on the link function, we prove that gradient flow recovers the hidden planted direction, represented as a finitely supported vector in the feature space of power sum polynomials. We characterize a notion of information exponent adapted to our setting that controls the efficiency of learning.","sentences":["Few neural architectures lend themselves to provable learning with gradient based methods.","One popular model is the single-index model, in which labels are produced by composing an unknown linear projection with a possibly unknown scalar link function.","Learning this model with SGD is relatively well-understood, whereby the so-called information exponent of the link function governs a polynomial sample complexity rate.","However, extending this analysis to deeper or more complicated architectures remains challenging.   ","In this work, we consider single index learning in the setting of symmetric neural networks.","Under analytic assumptions on the activation and maximum degree assumptions on the link function, we prove that gradient flow recovers the hidden planted direction, represented as a finitely supported vector in the feature space of power sum polynomials.","We characterize a notion of information exponent adapted to our setting that controls the efficiency of learning."],"url":"http://arxiv.org/abs/2310.02117v1"}
{"created":"2023-10-03 14:57:31","title":"Hierarchical Concept Discovery Models: A Concept Pyramid Scheme","abstract":"Deep Learning algorithms have recently gained significant attention due to their impressive performance. However, their high complexity and un-interpretable mode of operation hinders their confident deployment in real-world safety-critical tasks. This work targets ante hoc interpretability, and specifically Concept Bottleneck Models (CBMs). Our goal is to design a framework that admits a highly interpretable decision making process with respect to human understandable concepts, on multiple levels of granularity. To this end, we propose a novel hierarchical concept discovery formulation leveraging: (i) recent advances in image-text models, and (ii) an innovative formulation for multi-level concept selection via data-driven and sparsity inducing Bayesian arguments. Within this framework, concept information does not solely rely on the similarity between the whole image and general unstructured concepts; instead, we introduce the notion of concept hierarchy to uncover and exploit more granular concept information residing in patch-specific regions of the image scene. As we experimentally show, the proposed construction not only outperforms recent CBM approaches, but also yields a principled framework towards interpetability.","sentences":["Deep Learning algorithms have recently gained significant attention due to their impressive performance.","However, their high complexity and un-interpretable mode of operation hinders their confident deployment in real-world safety-critical tasks.","This work targets ante hoc interpretability, and specifically Concept Bottleneck Models (CBMs).","Our goal is to design a framework that admits a highly interpretable decision making process with respect to human understandable concepts, on multiple levels of granularity.","To this end, we propose a novel hierarchical concept discovery formulation leveraging: (i) recent advances in image-text models, and (ii) an innovative formulation for multi-level concept selection via data-driven and sparsity inducing Bayesian arguments.","Within this framework, concept information does not solely rely on the similarity between the whole image and general unstructured concepts; instead, we introduce the notion of concept hierarchy to uncover and exploit more granular concept information residing in patch-specific regions of the image scene.","As we experimentally show, the proposed construction not only outperforms recent CBM approaches, but also yields a principled framework towards interpetability."],"url":"http://arxiv.org/abs/2310.02116v1"}
{"created":"2023-10-03 14:55:30","title":"FLEDGE: Ledger-based Federated Learning Resilient to Inference and Backdoor Attacks","abstract":"Federated learning (FL) is a distributed learning process that uses a trusted aggregation server to allow multiple parties (or clients) to collaboratively train a machine learning model without having them share their private data. Recent research, however, has demonstrated the effectiveness of inference and poisoning attacks on FL. Mitigating both attacks simultaneously is very challenging. State-of-the-art solutions have proposed the use of poisoning defenses with Secure Multi-Party Computation (SMPC) and/or Differential Privacy (DP). However, these techniques are not efficient and fail to address the malicious intent behind the attacks, i.e., adversaries (curious servers and/or compromised clients) seek to exploit a system for monetization purposes. To overcome these limitations, we present a ledger-based FL framework known as FLEDGE that allows making parties accountable for their behavior and achieve reasonable efficiency for mitigating inference and poisoning attacks. Our solution leverages crypto-currency to increase party accountability by penalizing malicious behavior and rewarding benign conduct. We conduct an extensive evaluation on four public datasets: Reddit, MNIST, Fashion-MNIST, and CIFAR-10. Our experimental results demonstrate that (1) FLEDGE provides strong privacy guarantees for model updates without sacrificing model utility; (2) FLEDGE can successfully mitigate different poisoning attacks without degrading the performance of the global model; and (3) FLEDGE offers unique reward mechanisms to promote benign behavior during model training and/or model aggregation.","sentences":["Federated learning (FL) is a distributed learning process that uses a trusted aggregation server to allow multiple parties (or clients) to collaboratively train a machine learning model without having them share their private data.","Recent research, however, has demonstrated the effectiveness of inference and poisoning attacks on FL.","Mitigating both attacks simultaneously is very challenging.","State-of-the-art solutions have proposed the use of poisoning defenses with Secure Multi-Party Computation (SMPC) and/or Differential Privacy (DP).","However, these techniques are not efficient and fail to address the malicious intent behind the attacks, i.e., adversaries (curious servers and/or compromised clients) seek to exploit a system for monetization purposes.","To overcome these limitations, we present a ledger-based FL framework known as FLEDGE that allows making parties accountable for their behavior and achieve reasonable efficiency for mitigating inference and poisoning attacks.","Our solution leverages crypto-currency to increase party accountability by penalizing malicious behavior and rewarding benign conduct.","We conduct an extensive evaluation on four public datasets: Reddit, MNIST, Fashion-MNIST, and CIFAR-10.","Our experimental results demonstrate that (1) FLEDGE provides strong privacy guarantees for model updates without sacrificing model utility; (2) FLEDGE can successfully mitigate different poisoning attacks without degrading the performance of the global model; and (3) FLEDGE offers unique reward mechanisms to promote benign behavior during model training and/or model aggregation."],"url":"http://arxiv.org/abs/2310.02113v1"}
{"created":"2023-10-03 14:53:53","title":"SIEVE: Multimodal Dataset Pruning Using Image Captioning Models","abstract":"Vision-Language Models (VLMs) are pretrained on large, diverse, and noisy web-crawled datasets. This underscores the critical need for dataset pruning, as the quality of these datasets is strongly correlated with the performance of VLMs on downstream tasks. Using CLIPScore from a pretrained model to only train models using highly-aligned samples is one of the most successful methods for pruning.We argue that this approach suffers from multiple limitations including: 1) false positives due to spurious correlations captured by the pretrained CLIP model, 2) false negatives due to poor discrimination between hard and bad samples, and 3) biased ranking towards samples similar to the pretrained CLIP dataset. We propose a pruning method, SIEVE, that employs synthetic captions generated by image-captioning models pretrained on small, diverse, and well-aligned image-text pairs to evaluate the alignment of noisy image-text pairs. To bridge the gap between the limited diversity of generated captions and the high diversity of alternative text (alt-text), we estimate the semantic textual similarity in the embedding space of a language model pretrained on billions of sentences. Using DataComp, a multimodal dataset filtering benchmark, we achieve state-of-the-art performance on the large scale pool, and competitive results on the medium scale pool, surpassing CLIPScore-based filtering by 1.7% and 2.6% on average, on 38 downstream tasks.","sentences":["Vision-Language Models (VLMs) are pretrained on large, diverse, and noisy web-crawled datasets.","This underscores the critical need for dataset pruning, as the quality of these datasets is strongly correlated with the performance of VLMs on downstream tasks.","Using CLIPScore from a pretrained model to only train models using highly-aligned samples is one of the most successful methods for pruning.","We argue that this approach suffers from multiple limitations including: 1) false positives due to spurious correlations captured by the pretrained CLIP model, 2) false negatives due to poor discrimination between hard and bad samples, and 3) biased ranking towards samples similar to the pretrained CLIP dataset.","We propose a pruning method, SIEVE, that employs synthetic captions generated by image-captioning models pretrained on small, diverse, and well-aligned image-text pairs to evaluate the alignment of noisy image-text pairs.","To bridge the gap between the limited diversity of generated captions and the high diversity of alternative text (alt-text), we estimate the semantic textual similarity in the embedding space of a language model pretrained on billions of sentences.","Using DataComp, a multimodal dataset filtering benchmark, we achieve state-of-the-art performance on the large scale pool, and competitive results on the medium scale pool, surpassing CLIPScore-based filtering by 1.7% and 2.6% on average, on 38 downstream tasks."],"url":"http://arxiv.org/abs/2310.02110v1"}
{"created":"2023-10-03 14:51:53","title":"Towards Effective Human-AI Decision-Making: The Role of Human Learning in Appropriate Reliance on AI Advice","abstract":"The true potential of human-AI collaboration lies in exploiting the complementary capabilities of humans and AI to achieve a joint performance superior to that of the individual AI or human, i.e., to achieve complementary team performance (CTP). To realize this complementarity potential, humans need to exercise discretion in following AI 's advice, i.e., appropriately relying on the AI's advice. While previous work has focused on building a mental model of the AI to assess AI recommendations, recent research has shown that the mental model alone cannot explain appropriate reliance. We hypothesize that, in addition to the mental model, human learning is a key mediator of appropriate reliance and, thus, CTP. In this study, we demonstrate the relationship between learning and appropriate reliance in an experiment with 100 participants. This work provides fundamental concepts for analyzing reliance and derives implications for the effective design of human-AI decision-making.","sentences":["The true potential of human-AI collaboration lies in exploiting the complementary capabilities of humans and AI to achieve a joint performance superior to that of the individual AI or human, i.e., to achieve complementary team performance (CTP).","To realize this complementarity potential, humans need to exercise discretion in following AI 's advice, i.e., appropriately relying on the AI's advice.","While previous work has focused on building a mental model of the AI to assess AI recommendations, recent research has shown that the mental model alone cannot explain appropriate reliance.","We hypothesize that, in addition to the mental model, human learning is a key mediator of appropriate reliance and, thus, CTP.","In this study, we demonstrate the relationship between learning and appropriate reliance in an experiment with 100 participants.","This work provides fundamental concepts for analyzing reliance and derives implications for the effective design of human-AI decision-making."],"url":"http://arxiv.org/abs/2310.02108v1"}
{"created":"2023-10-03 14:51:34","title":"Instance Needs More Care: Rewriting Prompts for Instances Yields Better Zero-Shot Performance","abstract":"Enabling large language models (LLMs) to perform tasks in zero-shot has been an appealing goal owing to its labor-saving (i.e., requiring no task-specific annotations); as such, zero-shot prompting approaches also enjoy better task generalizability. To improve LLMs' zero-shot performance, prior work has focused on devising more effective task instructions (e.g., ``let's think step by step'' ). However, we argue that, in order for an LLM to solve them correctly in zero-shot, individual test instances need more carefully designed and customized instructions. To this end, we propose PRoMPTd, an approach that rewrites the task prompt for each individual test input to be more specific, unambiguous, and complete, so as to provide better guidance to the task LLM. We evaluated PRoMPTd on eight datasets covering tasks including arithmetics, logical reasoning, and code generation, using GPT-4 as the task LLM. Notably, \\algoname achieves an absolute improvement of around 10\\% on the complex MATH dataset and 5\\% on the code generation task on HumanEval, outperforming conventional zero-shot methods. In addition, we also showed that the rewritten prompt can provide better interpretability of how the LLM resolves each test instance, which can potentially be leveraged as a defense mechanism against adversarial prompting. The source code and dataset can be obtained from https://github.com/salokr/PRoMPTd","sentences":["Enabling large language models (LLMs) to perform tasks in zero-shot has been an appealing goal owing to its labor-saving (i.e., requiring no task-specific annotations); as such, zero-shot prompting approaches also enjoy better task generalizability.","To improve LLMs' zero-shot performance, prior work has focused on devising more effective task instructions (e.g., ``let's think step by step'' ).","However, we argue that, in order for an LLM to solve them correctly in zero-shot, individual test instances need more carefully designed and customized instructions.","To this end, we propose PRoMPTd, an approach that rewrites the task prompt for each individual test input to be more specific, unambiguous, and complete, so as to provide better guidance to the task LLM.","We evaluated PRoMPTd on eight datasets covering tasks including arithmetics, logical reasoning, and code generation, using GPT-4 as the task LLM.","Notably, \\algoname achieves an absolute improvement of around 10\\% on the complex MATH dataset and 5\\% on the code generation task on HumanEval, outperforming conventional zero-shot methods.","In addition, we also showed that the rewritten prompt can provide better interpretability of how the LLM resolves each test instance, which can potentially be leveraged as a defense mechanism against adversarial prompting.","The source code and dataset can be obtained from https://github.com/salokr/PRoMPTd"],"url":"http://arxiv.org/abs/2310.02107v1"}
{"created":"2023-10-03 14:48:32","title":"An empirical study of ChatGPT-3.5 on question answering and code maintenance","abstract":"Ever since the launch of ChatGPT in 2022, a rising concern is whether ChatGPT will replace programmers and kill jobs. Motivated by this widespread concern, we conducted an empirical study to systematically compare ChatGPT against programmers in question-answering and software-maintaining. We reused a dataset introduced by prior work, which includes 130 StackOverflow (SO) discussion threads referred to by the Java developers of 357 GitHub projects. We mainly investigated three research questions (RQs). First, how does ChatGPT compare with programmers when answering technical questions? Second, how do developers perceive the differences between ChatGPT's answers and SO answers? Third, how does ChatGPT compare with humans when revising code for maintenance requests?   For RQ1, we provided the 130 SO questions to ChatGPT, and manually compared ChatGPT answers with the accepted/most popular SO answers in terms of relevance, readability, informativeness, comprehensiveness, and reusability. For RQ2, we conducted a user study with 30 developers, asking each developer to assess and compare 10 pairs of answers, without knowing the information source (i.e., ChatGPT or SO). For RQ3, we distilled 48 software maintenance tasks from 48 GitHub projects citing the studied SO threads. We queried ChatGPT to revise a given Java file, and to incorporate the code implementation for any prescribed maintenance requirement. Our study reveals interesting phenomena: For the majority of SO questions (97/130), ChatGPT provided better answers; in 203 of 300 ratings, developers preferred ChatGPT answers to SO answers; ChatGPT revised code correctly for 22 of the 48 tasks. Our research will expand people's knowledge of ChatGPT capabilities, and shed light on future adoption of ChatGPT by the software industry.","sentences":["Ever since the launch of ChatGPT in 2022, a rising concern is whether ChatGPT will replace programmers and kill jobs.","Motivated by this widespread concern, we conducted an empirical study to systematically compare ChatGPT against programmers in question-answering and software-maintaining.","We reused a dataset introduced by prior work, which includes 130 StackOverflow (SO) discussion threads referred to by the Java developers of 357 GitHub projects.","We mainly investigated three research questions (RQs).","First, how does ChatGPT compare with programmers when answering technical questions?","Second, how do developers perceive the differences between ChatGPT's answers and SO answers?","Third, how does ChatGPT compare with humans when revising code for maintenance requests?   ","For RQ1, we provided the 130 SO questions to ChatGPT, and manually compared ChatGPT answers with the accepted/most popular SO answers in terms of relevance, readability, informativeness, comprehensiveness, and reusability.","For RQ2, we conducted a user study with 30 developers, asking each developer to assess and compare 10 pairs of answers, without knowing the information source (i.e., ChatGPT or SO).","For RQ3, we distilled 48 software maintenance tasks from 48 GitHub projects citing the studied SO threads.","We queried ChatGPT to revise a given Java file, and to incorporate the code implementation for any prescribed maintenance requirement.","Our study reveals interesting phenomena: For the majority of SO questions (97/130), ChatGPT provided better answers; in 203 of 300 ratings, developers preferred ChatGPT answers to SO answers; ChatGPT revised code correctly for 22 of the 48 tasks.","Our research will expand people's knowledge of ChatGPT capabilities, and shed light on future adoption of ChatGPT by the software industry."],"url":"http://arxiv.org/abs/2310.02104v1"}
{"created":"2023-10-03 14:46:33","title":"dFlow: A Domain Specific Language for the Rapid Development of open-source Virtual Assistants","abstract":"An increasing number of models and frameworks for Virtual Assistant (VA) development exist nowadays, following the progress in the Natural Language Processing (NLP) and Natural Language Understanding (NLU) fields. Regardless of their performance, popularity, and ease of use, these frameworks require at least basic expertise in NLP and software engineering, even for simple and repetitive processes, limiting their use only to the domain and programming experts. However, since the current state of practice of VA development is a straightforward process, Model-Driven Engineering approaches can be utilized to achieve automation and rapid development in a more convenient manner. To this end, we present \\textit{dFlow}, a textual Domain-Specific Language (DSL) that offers a simplified, reusable, and framework-agnostic language for creating task-specific VAs in a low-code manner. We describe a system-agnostic VA meta-model, the developed grammar, and all essential processes for developing and deploying smart VAs. For further convenience, we create a cloud-native architecture and expose it through the Discord platform. We conducted a large-scale empirical evaluation with more than 200 junior software developers and collected positive feedback, indicating that dFlow can accelerate the entire VA development process, while also enabling citizen and software developers with minimum experience to participate.","sentences":["An increasing number of models and frameworks for Virtual Assistant (VA) development exist nowadays, following the progress in the Natural Language Processing (NLP) and Natural Language Understanding (NLU) fields.","Regardless of their performance, popularity, and ease of use, these frameworks require at least basic expertise in NLP and software engineering, even for simple and repetitive processes, limiting their use only to the domain and programming experts.","However, since the current state of practice of VA development is a straightforward process, Model-Driven Engineering approaches can be utilized to achieve automation and rapid development in a more convenient manner.","To this end, we present \\textit{dFlow}, a textual Domain-Specific Language (DSL) that offers a simplified, reusable, and framework-agnostic language for creating task-specific VAs in a low-code manner.","We describe a system-agnostic VA meta-model, the developed grammar, and all essential processes for developing and deploying smart VAs.","For further convenience, we create a cloud-native architecture and expose it through the Discord platform.","We conducted a large-scale empirical evaluation with more than 200 junior software developers and collected positive feedback, indicating that dFlow can accelerate the entire VA development process, while also enabling citizen and software developers with minimum experience to participate."],"url":"http://arxiv.org/abs/2310.02102v1"}
{"created":"2023-10-03 14:41:30","title":"Leveraging Classic Deconvolution and Feature Extraction in Zero-Shot Image Restoration","abstract":"Non-blind deconvolution aims to restore a sharp image from its blurred counterpart given an obtained kernel. Existing deep neural architectures are often built based on large datasets of sharp ground truth images and trained with supervision. Sharp, high quality ground truth images, however, are not always available, especially for biomedical applications. This severely hampers the applicability of current approaches in practice. In this paper, we propose a novel non-blind deconvolution method that leverages the power of deep learning and classic iterative deconvolution algorithms. Our approach combines a pre-trained network to extract deep features from the input image with iterative Richardson-Lucy deconvolution steps. Subsequently, a zero-shot optimisation process is employed to integrate the deconvolved features, resulting in a high-quality reconstructed image. By performing the preliminary reconstruction with the classic iterative deconvolution method, we can effectively utilise a smaller network to produce the final image, thus accelerating the reconstruction whilst reducing the demand for valuable computational resources. Our method demonstrates significant improvements in various real-world applications non-blind deconvolution tasks.","sentences":["Non-blind deconvolution aims to restore a sharp image from its blurred counterpart given an obtained kernel.","Existing deep neural architectures are often built based on large datasets of sharp ground truth images and trained with supervision.","Sharp, high quality ground truth images, however, are not always available, especially for biomedical applications.","This severely hampers the applicability of current approaches in practice.","In this paper, we propose a novel non-blind deconvolution method that leverages the power of deep learning and classic iterative deconvolution algorithms.","Our approach combines a pre-trained network to extract deep features from the input image with iterative Richardson-Lucy deconvolution steps.","Subsequently, a zero-shot optimisation process is employed to integrate the deconvolved features, resulting in a high-quality reconstructed image.","By performing the preliminary reconstruction with the classic iterative deconvolution method, we can effectively utilise a smaller network to produce the final image, thus accelerating the reconstruction whilst reducing the demand for valuable computational resources.","Our method demonstrates significant improvements in various real-world applications non-blind deconvolution tasks."],"url":"http://arxiv.org/abs/2310.02097v1"}
{"created":"2023-10-03 14:39:13","title":"A Survey on the Role of Crowds in Combating Online Misinformation: Annotators, Evaluators, and Creators","abstract":"Online misinformation poses a global risk with significant real-world consequences. To combat misinformation, current research relies on professionals like journalists and fact-checkers for annotating and debunking misinformation, and develops automated machine learning methods for detecting misinformation. Complementary to these approaches, recent research has increasingly concentrated on utilizing the power of ordinary social media users, a.k.a. \"crowd\", who act as eyes-on-the-ground proactively questioning and countering misinformation. Notably, recent studies show that 96% of counter-misinformation responses originate from them. Acknowledging their prominent role, we present the first systematic and comprehensive survey of research papers that actively leverage the crowds to combat misinformation.   We first identify 88 papers related to crowd-based efforts, following a meticulous annotation process adhering to the PRISMA framework. We then present key statistics related to misinformation, counter-misinformation, and crowd input in different formats and topics. Upon holistic analysis of the papers, we introduce a novel taxonomy of the roles played by the crowds: (i)annotators who actively identify misinformation; (ii)evaluators who assess counter-misinformation effectiveness; (iii)creators who create counter-misinformation. This taxonomy explores the crowd's capabilities in misinformation detection, identifies prerequisites for effective counter-misinformation, and analyzes crowd-generated counter-misinformation. Then, we delve into (i)distinguishing individual, collaborative, and machine-assisted labeling for annotators; (ii)analyzing the effectiveness of counter-misinformation through surveys, interviews, and in-lab experiments for evaluators; and (iii)characterizing creation patterns and creator profiles for creators. Finally, we outline potential future research in this field.","sentences":["Online misinformation poses a global risk with significant real-world consequences.","To combat misinformation, current research relies on professionals like journalists and fact-checkers for annotating and debunking misinformation, and develops automated machine learning methods for detecting misinformation.","Complementary to these approaches, recent research has increasingly concentrated on utilizing the power of ordinary social media users, a.k.a. \"crowd\", who act as eyes-on-the-ground proactively questioning and countering misinformation.","Notably, recent studies show that 96% of counter-misinformation responses originate from them.","Acknowledging their prominent role, we present the first systematic and comprehensive survey of research papers that actively leverage the crowds to combat misinformation.   ","We first identify 88 papers related to crowd-based efforts, following a meticulous annotation process adhering to the PRISMA framework.","We then present key statistics related to misinformation, counter-misinformation, and crowd input in different formats and topics.","Upon holistic analysis of the papers, we introduce a novel taxonomy of the roles played by the crowds: (i)annotators who actively identify misinformation; (ii)evaluators who assess counter-misinformation effectiveness; (iii)creators who create counter-misinformation.","This taxonomy explores the crowd's capabilities in misinformation detection, identifies prerequisites for effective counter-misinformation, and analyzes crowd-generated counter-misinformation.","Then, we delve into (i)distinguishing individual, collaborative, and machine-assisted labeling for annotators; (ii)analyzing the effectiveness of counter-misinformation through surveys, interviews, and in-lab experiments for evaluators; and (iii)characterizing creation patterns and creator profiles for creators.","Finally, we outline potential future research in this field."],"url":"http://arxiv.org/abs/2310.02095v1"}
{"created":"2023-10-03 14:38:12","title":"CoNO: Complex Neural Operator for Continuous Dynamical Systems","abstract":"Neural operators extend data-driven models to map between infinite-dimensional functional spaces. These models have successfully solved continuous dynamical systems represented by differential equations, viz weather forecasting, fluid flow, or solid mechanics. However, the existing operators still rely on real space, thereby losing rich representations potentially captured in the complex space by functional transforms. In this paper, we introduce a Complex Neural Operator (CoNO), that parameterizes the integral kernel in the complex fractional Fourier domain. Additionally, the model employing a complex-valued neural network along with aliasing-free activation functions preserves the complex values and complex algebraic properties, thereby enabling improved representation, robustness to noise, and generalization. We show that the model effectively captures the underlying partial differential equation with a single complex fractional Fourier transform. We perform an extensive empirical evaluation of CoNO on several datasets and additional tasks such as zero-shot super-resolution, evaluation of out-of-distribution data, data efficiency, and robustness to noise. CoNO exhibits comparable or superior performance to all the state-of-the-art models in these tasks. Altogether, CoNO presents a robust and superior model for modeling continuous dynamical systems, providing a fillip to scientific machine learning.","sentences":["Neural operators extend data-driven models to map between infinite-dimensional functional spaces.","These models have successfully solved continuous dynamical systems represented by differential equations, viz weather forecasting, fluid flow, or solid mechanics.","However, the existing operators still rely on real space, thereby losing rich representations potentially captured in the complex space by functional transforms.","In this paper, we introduce a Complex Neural Operator (CoNO), that parameterizes the integral kernel in the complex fractional Fourier domain.","Additionally, the model employing a complex-valued neural network along with aliasing-free activation functions preserves the complex values and complex algebraic properties, thereby enabling improved representation, robustness to noise, and generalization.","We show that the model effectively captures the underlying partial differential equation with a single complex fractional Fourier transform.","We perform an extensive empirical evaluation of CoNO on several datasets and additional tasks such as zero-shot super-resolution, evaluation of out-of-distribution data, data efficiency, and robustness to noise.","CoNO exhibits comparable or superior performance to all the state-of-the-art models in these tasks.","Altogether, CoNO presents a robust and superior model for modeling continuous dynamical systems, providing a fillip to scientific machine learning."],"url":"http://arxiv.org/abs/2310.02094v1"}
{"created":"2023-10-03 14:36:05","title":"Stochastic Gradient Descent with Preconditioned Polyak Step-size","abstract":"Stochastic Gradient Descent (SGD) is one of the many iterative optimization methods that are widely used in solving machine learning problems. These methods display valuable properties and attract researchers and industrial machine learning engineers with their simplicity. However, one of the weaknesses of this type of methods is the necessity to tune learning rate (step-size) for every loss function and dataset combination to solve an optimization problem and get an efficient performance in a given time budget. Stochastic Gradient Descent with Polyak Step-size (SPS) is a method that offers an update rule that alleviates the need of fine-tuning the learning rate of an optimizer. In this paper, we propose an extension of SPS that employs preconditioning techniques, such as Hutchinson's method, Adam, and AdaGrad, to improve its performance on badly scaled and/or ill-conditioned datasets.","sentences":["Stochastic Gradient Descent (SGD) is one of the many iterative optimization methods that are widely used in solving machine learning problems.","These methods display valuable properties and attract researchers and industrial machine learning engineers with their simplicity.","However, one of the weaknesses of this type of methods is the necessity to tune learning rate (step-size) for every loss function and dataset combination to solve an optimization problem and get an efficient performance in a given time budget.","Stochastic Gradient Descent with Polyak Step-size (SPS) is a method that offers an update rule that alleviates the need of fine-tuning the learning rate of an optimizer.","In this paper, we propose an extension of SPS that employs preconditioning techniques, such as Hutchinson's method, Adam, and AdaGrad, to improve its performance on badly scaled and/or ill-conditioned datasets."],"url":"http://arxiv.org/abs/2310.02093v1"}
{"created":"2023-10-03 14:33:34","title":"1D-CapsNet-LSTM: A Deep Learning-Based Model for Multi-Step Stock Index Forecasting","abstract":"Multi-step forecasting of stock market index prices is a crucial task in the financial sector, playing a pivotal role in decision-making across various financial activities. However, forecasting results are often unsatisfactory owing to the stochastic and volatile nature of the data. Researchers have made various attempts, and this process is ongoing. Inspired by convolutional neural network long short-term memory (CNN-LSTM) networks that utilize a 1D CNN for feature extraction to boost model performance, this study explores the use of a capsule network (CapsNet) as an advanced feature extractor in an LSTM-based forecasting model to enhance multi-step predictions. To this end, a novel neural architecture called 1D-CapsNet-LSTM was introduced, which combines a 1D CapsNet to extract high-level features from 1D sequential data and an LSTM layer to capture the temporal dependencies between the previously extracted features and uses a multi-input multi-output (MIMO) strategy to maintain the stochastic dependencies between the predicted values at different time steps. The proposed model was evaluated based on several real-world stock market indices, including Standard & Poor's 500 (S&P 500), Dow Jones Industrial Average (DJIA), Nasdaq Composite Index (IXIC), and New York Stock Exchange (NYSE), and was compared with baseline models such as LSTM, recurrent neural network (RNN), and CNN-LSTM in terms of various evaluation metrics. The comparison results suggest that the 1D-CapsNet-LSTM model outperforms the baseline models and has immense potential for the effective handling of complex prediction tasks.","sentences":["Multi-step forecasting of stock market index prices is a crucial task in the financial sector, playing a pivotal role in decision-making across various financial activities.","However, forecasting results are often unsatisfactory owing to the stochastic and volatile nature of the data.","Researchers have made various attempts, and this process is ongoing.","Inspired by convolutional neural network long short-term memory (CNN-LSTM) networks that utilize a 1D CNN for feature extraction to boost model performance, this study explores the use of a capsule network (CapsNet) as an advanced feature extractor in an LSTM-based forecasting model to enhance multi-step predictions.","To this end, a novel neural architecture called 1D-CapsNet-LSTM was introduced, which combines a 1D CapsNet to extract high-level features from 1D sequential data and an LSTM layer to capture the temporal dependencies between the previously extracted features and uses a multi-input multi-output (MIMO) strategy to maintain the stochastic dependencies between the predicted values at different time steps.","The proposed model was evaluated based on several real-world stock market indices, including Standard & Poor's 500 (S&P 500), Dow Jones Industrial Average (DJIA), Nasdaq Composite Index (IXIC), and New York Stock Exchange (NYSE), and was compared with baseline models such as LSTM, recurrent neural network (RNN), and CNN-LSTM in terms of various evaluation metrics.","The comparison results suggest that the 1D-CapsNet-LSTM model outperforms the baseline models and has immense potential for the effective handling of complex prediction tasks."],"url":"http://arxiv.org/abs/2310.02090v1"}
{"created":"2023-10-03 14:26:56","title":"Point Neighborhood Embeddings","abstract":"Point convolution operations rely on different embedding mechanisms to encode the neighborhood information of each point in order to detect patterns in 3D space. However, as convolutions are usually evaluated as a whole, not much work has been done to investigate which is the ideal mechanism to encode such neighborhood information. In this paper, we provide the first extensive study that analyzes such Point Neighborhood Embeddings (PNE) alone in a controlled experimental setup. From our experiments, we derive a set of recommendations for PNE that can help to improve future designs of neural network architectures for point clouds. Our most surprising finding shows that the most commonly used embedding based on a Multi-layer Perceptron (MLP) with ReLU activation functions provides the lowest performance among all embeddings, even being surpassed on some tasks by a simple linear combination of the point coordinates. Additionally, we show that a neural network architecture using simple convolutions based on such embeddings is able to achieve state-of-the-art results on several tasks, outperforming recent and more complex operations. Lastly, we show that these findings extrapolate to other more complex convolution operations, where we show how following our recommendations we are able to improve recent state-of-the-art architectures.","sentences":["Point convolution operations rely on different embedding mechanisms to encode the neighborhood information of each point in order to detect patterns in 3D space.","However, as convolutions are usually evaluated as a whole, not much work has been done to investigate which is the ideal mechanism to encode such neighborhood information.","In this paper, we provide the first extensive study that analyzes such Point Neighborhood Embeddings (PNE) alone in a controlled experimental setup.","From our experiments, we derive a set of recommendations for PNE that can help to improve future designs of neural network architectures for point clouds.","Our most surprising finding shows that the most commonly used embedding based on a Multi-layer Perceptron (MLP) with ReLU activation functions provides the lowest performance among all embeddings, even being surpassed on some tasks by a simple linear combination of the point coordinates.","Additionally, we show that a neural network architecture using simple convolutions based on such embeddings is able to achieve state-of-the-art results on several tasks, outperforming recent and more complex operations.","Lastly, we show that these findings extrapolate to other more complex convolution operations, where we show how following our recommendations we are able to improve recent state-of-the-art architectures."],"url":"http://arxiv.org/abs/2310.02083v1"}
{"created":"2023-10-03 14:16:25","title":"What Does the Chart Say? Grouping Cues Guide Viewer Comparisons and Conclusions in Bar Charts","abstract":"Reading a visualization is like reading a paragraph. Each sentence is a comparison: the mean of these is higher than those; this difference is smaller than that. What determines which comparisons are made first? The viewer's goals and expertise matter, but the way that values are visually grouped together within the chart also impacts those comparisons. Research from psychology suggests that comparisons involve multiple steps. First, the viewer divides the visualization into a set of units. This might include a single bar or a grouped set of bars. Then the viewer selects and compares two of these units, perhaps noting that one pair of bars is longer than another. Viewers might take an additional third step and perform a second-order comparison, perhaps determining that the difference between one pair of bars is greater than the difference between another pair. We create a visual comparison taxonomy that allows us to develop and test a sequence of hypotheses about which comparisons people are more likely to make when reading a visualization. We find that people tend to compare two groups before comparing two individual bars and that second-order comparisons are rare. Visual cues like spatial proximity and color can influence which elements are grouped together and selected for comparison, with spatial proximity being a stronger grouping cue. Interestingly, once the viewer grouped together and compared a set of bars, regardless of whether the group is formed by spatial proximity or color similarity, they no longer consider other possible groupings in their comparisons.","sentences":["Reading a visualization is like reading a paragraph.","Each sentence is a comparison: the mean of these is higher than those; this difference is smaller than that.","What determines which comparisons are made first?","The viewer's goals and expertise matter, but the way that values are visually grouped together within the chart also impacts those comparisons.","Research from psychology suggests that comparisons involve multiple steps.","First, the viewer divides the visualization into a set of units.","This might include a single bar or a grouped set of bars.","Then the viewer selects and compares two of these units, perhaps noting that one pair of bars is longer than another.","Viewers might take an additional third step and perform a second-order comparison, perhaps determining that the difference between one pair of bars is greater than the difference between another pair.","We create a visual comparison taxonomy that allows us to develop and test a sequence of hypotheses about which comparisons people are more likely to make when reading a visualization.","We find that people tend to compare two groups before comparing two individual bars and that second-order comparisons are rare.","Visual cues like spatial proximity and color can influence which elements are grouped together and selected for comparison, with spatial proximity being a stronger grouping cue.","Interestingly, once the viewer grouped together and compared a set of bars, regardless of whether the group is formed by spatial proximity or color similarity, they no longer consider other possible groupings in their comparisons."],"url":"http://arxiv.org/abs/2310.02076v1"}
{"created":"2023-10-03 14:13:36","title":"Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model: Explorations with GPT4-Vision and Beyond","abstract":"In this study, we explore the potential of Multimodal Large Language Models (MLLMs) in improving embodied decision-making processes for agents. While Large Language Models (LLMs) have been widely used due to their advanced reasoning skills and vast world knowledge, MLLMs like GPT4-Vision offer enhanced visual understanding and reasoning capabilities. We investigate whether state-of-the-art MLLMs can handle embodied decision-making in an end-to-end manner and whether collaborations between LLMs and MLLMs can enhance decision-making. To address these questions, we introduce a new benchmark called PCA-EVAL, which evaluates embodied decision-making from the perspectives of Perception, Cognition, and Action. Additionally, we propose HOLMES, a multi-agent cooperation framework that allows LLMs to leverage MLLMs and APIs to gather multimodal information for informed decision-making. We compare end-to-end embodied decision-making and HOLMES on our benchmark and find that the GPT4-Vision model demonstrates strong end-to-end embodied decision-making abilities, outperforming GPT4-HOLMES in terms of average decision accuracy (+3%). However, this performance is exclusive to the latest GPT4-Vision model, surpassing the open-source state-of-the-art MLLM by 26%. Our results indicate that powerful MLLMs like GPT4-Vision hold promise for decision-making in embodied agents, offering new avenues for MLLM research.","sentences":["In this study, we explore the potential of Multimodal Large Language Models (MLLMs) in improving embodied decision-making processes for agents.","While Large Language Models (LLMs) have been widely used due to their advanced reasoning skills and vast world knowledge, MLLMs like GPT4-Vision offer enhanced visual understanding and reasoning capabilities.","We investigate whether state-of-the-art MLLMs can handle embodied decision-making in an end-to-end manner and whether collaborations between LLMs and MLLMs can enhance decision-making.","To address these questions, we introduce a new benchmark called PCA-EVAL, which evaluates embodied decision-making from the perspectives of Perception, Cognition, and Action.","Additionally, we propose HOLMES, a multi-agent cooperation framework that allows LLMs to leverage MLLMs and APIs to gather multimodal information for informed decision-making.","We compare end-to-end embodied decision-making and HOLMES on our benchmark and find that the GPT4-Vision model demonstrates strong end-to-end embodied decision-making abilities, outperforming GPT4-HOLMES in terms of average decision accuracy (+3%).","However, this performance is exclusive to the latest GPT4-Vision model, surpassing the open-source state-of-the-art MLLM by 26%.","Our results indicate that powerful MLLMs like GPT4-Vision hold promise for decision-making in embodied agents, offering new avenues for MLLM research."],"url":"http://arxiv.org/abs/2310.02071v1"}
{"created":"2023-10-03 14:12:36","title":"TOaCNN: Adaptive Convolutional Neural Network for Multidisciplinary Topology Optimization","abstract":"This paper presents an adaptive convolutional neural network (CNN) architecture that can automate diverse topology optimization (TO) problems having different underlying physics. The architecture uses the encoder-decoder networks with dense layers in the middle which includes an additional adaptive layer to capture complex geometrical features. The network is trained using the dataset obtained from the three open-source TO codes involving different physics. The robustness and success of the presented adaptive CNN are demonstrated on compliance minimization problems with constant and design-dependent loads and material bulk modulus optimization. The architecture takes the user's input of the volume fraction. It instantly generates optimized designs resembling their counterparts obtained via open-source TO codes with negligible performance and volume fraction error.","sentences":["This paper presents an adaptive convolutional neural network (CNN) architecture that can automate diverse topology optimization (TO) problems having different underlying physics.","The architecture uses the encoder-decoder networks with dense layers in the middle which includes an additional adaptive layer to capture complex geometrical features.","The network is trained using the dataset obtained from the three open-source TO codes involving different physics.","The robustness and success of the presented adaptive CNN are demonstrated on compliance minimization problems with constant and design-dependent loads and material bulk modulus optimization.","The architecture takes the user's input of the volume fraction.","It instantly generates optimized designs resembling their counterparts obtained via open-source TO codes with negligible performance and volume fraction error."],"url":"http://arxiv.org/abs/2310.02069v1"}
{"created":"2023-10-03 14:09:27","title":"Content Bias in Deep Learning Age Approximation: A new Approach Towards more Explainability","abstract":"In the context of temporal image forensics, it is not evident that a neural network, trained on images from different time-slots (classes), exploit solely age related features. Usually, images taken in close temporal proximity (e.g., belonging to the same age class) share some common content properties. Such content bias can be exploited by a neural network. In this work, a novel approach that evaluates the influence of image content is proposed. This approach is verified using synthetic images (where content bias can be ruled out) with an age signal embedded. Based on the proposed approach, it is shown that a `standard' neural network trained in the context of age classification is strongly dependent on image content. As a potential countermeasure, two different techniques are applied to mitigate the influence of the image content during training, and they are also evaluated by the proposed method.","sentences":["In the context of temporal image forensics, it is not evident that a neural network, trained on images from different time-slots (classes), exploit solely age related features.","Usually, images taken in close temporal proximity (e.g., belonging to the same age class) share some common content properties.","Such content bias can be exploited by a neural network.","In this work, a novel approach that evaluates the influence of image content is proposed.","This approach is verified using synthetic images (where content bias can be ruled out) with an age signal embedded.","Based on the proposed approach, it is shown that a `standard' neural network trained in the context of age classification is strongly dependent on image content.","As a potential countermeasure, two different techniques are applied to mitigate the influence of the image content during training, and they are also evaluated by the proposed method."],"url":"http://arxiv.org/abs/2310.02067v1"}
{"created":"2023-10-03 14:09:15","title":"De Novo Drug Design with Joint Transformers","abstract":"De novo drug design requires simultaneously generating novel molecules outside of training data and predicting their target properties, making it a hard task for generative models. To address this, we propose Joint Transformer that combines a Transformer decoder, a Transformer encoder, and a predictor in a joint generative model with shared weights. We show that training the model with a penalized log-likelihood objective results in state-of-the-art performance in molecule generation, while decreasing the prediction error on newly sampled molecules, as compared to a fine-tuned decoder-only Transformer, by 42%. Finally, we propose a probabilistic black-box optimization algorithm that employs Joint Transformer to generate novel molecules with improved target properties, as compared to the training data, outperforming other SMILES-based optimization methods in de novo drug design.","sentences":["De novo drug design requires simultaneously generating novel molecules outside of training data and predicting their target properties, making it a hard task for generative models.","To address this, we propose Joint Transformer that combines a Transformer decoder, a Transformer encoder, and a predictor in a joint generative model with shared weights.","We show that training the model with a penalized log-likelihood objective results in state-of-the-art performance in molecule generation, while decreasing the prediction error on newly sampled molecules, as compared to a fine-tuned decoder-only Transformer, by 42%.","Finally, we propose a probabilistic black-box optimization algorithm that employs Joint Transformer to generate novel molecules with improved target properties, as compared to the training data, outperforming other SMILES-based optimization methods in de novo drug design."],"url":"http://arxiv.org/abs/2310.02066v1"}
{"created":"2023-10-03 14:08:26","title":"VENOM: A Vectorized N:M Format for Unleashing the Power of Sparse Tensor Cores","abstract":"The increasing success and scaling of Deep Learning models demands higher computational efficiency and power. Sparsification can lead to both smaller models as well as higher compute efficiency, and accelerated hardware is becoming available. However, exploiting it efficiently requires kernel implementations, pruning algorithms, and storage formats, to utilize hardware support of specialized sparse vector units. An example of those are the NVIDIA's Sparse Tensor Cores (SPTCs), which promise a 2x speedup. However, SPTCs only support the 2:4 format, limiting achievable sparsity ratios to 50%. We present the V:N:M format, which enables the execution of arbitrary N:M ratios on SPTCs. To efficiently exploit the resulting format, we propose Spatha, a high-performance sparse-library for DL routines. We show that Spatha achieves up to 37x speedup over cuBLAS. We also demonstrate a second-order pruning technique that enables sparsification to high sparsity ratios with V:N:M and little to no loss in accuracy in modern transformers.","sentences":["The increasing success and scaling of Deep Learning models demands higher computational efficiency and power.","Sparsification can lead to both smaller models as well as higher compute efficiency, and accelerated hardware is becoming available.","However, exploiting it efficiently requires kernel implementations, pruning algorithms, and storage formats, to utilize hardware support of specialized sparse vector units.","An example of those are the NVIDIA's Sparse Tensor Cores (SPTCs), which promise a 2x speedup.","However, SPTCs only support the 2:4 format, limiting achievable sparsity ratios to 50%.","We present the V:N:M format, which enables the execution of arbitrary N:M ratios on SPTCs.","To efficiently exploit the resulting format, we propose Spatha, a high-performance sparse-library for DL routines.","We show that Spatha achieves up to 37x speedup over cuBLAS.","We also demonstrate a second-order pruning technique that enables sparsification to high sparsity ratios with V:N:M and little to no loss in accuracy in modern transformers."],"url":"http://arxiv.org/abs/2310.02065v1"}
{"created":"2023-10-03 14:06:43","title":"Auction Design for Bidders with Ex Post ROI Constraints","abstract":"Motivated by practical constraints in online advertising, we investigate single-parameter auction design for bidders with constraints on their Return On Investment (ROI) -- a targeted minimum ratio between the obtained value and the payment. We focus on ex post ROI constraints, which require the ROI condition to be satisfied for every realized value profile. With ROI-constrained bidders, we first provide a full characterization of the allocation and payment rules of dominant-strategy incentive compatible (DSIC) auctions. In particular, we show that given any monotone allocation rule, the corresponding DSIC payment should be the Myerson payment with a rebate for each bidder to meet their ROI constraints. Furthermore, we also determine the optimal auction structure when the item is sold to a single bidder under a mild regularity condition. This structure entails a randomized allocation scheme and a first-price payment rule, which differs from the deterministic Myerson auction and previous works on ex ante ROI constraints.","sentences":["Motivated by practical constraints in online advertising, we investigate single-parameter auction design for bidders with constraints on their Return On Investment (ROI) -- a targeted minimum ratio between the obtained value and the payment.","We focus on ex post ROI constraints, which require the ROI condition to be satisfied for every realized value profile.","With ROI-constrained bidders, we first provide a full characterization of the allocation and payment rules of dominant-strategy incentive compatible (DSIC) auctions.","In particular, we show that given any monotone allocation rule, the corresponding DSIC payment should be the Myerson payment with a rebate for each bidder to meet their ROI constraints.","Furthermore, we also determine the optimal auction structure when the item is sold to a single bidder under a mild regularity condition.","This structure entails a randomized allocation scheme and a first-price payment rule, which differs from the deterministic Myerson auction and previous works on ex ante ROI constraints."],"url":"http://arxiv.org/abs/2310.02064v1"}
{"created":"2023-10-03 14:04:45","title":"Lessons Learned from EXMOS User Studies: A Technical Report Summarizing Key Takeaways from User Studies Conducted to Evaluate The EXMOS Platform","abstract":"In the realm of interactive machine-learning systems, the provision of explanations serves as a vital aid in the processes of debugging and enhancing prediction models. However, the extent to which various global model-centric and data-centric explanations can effectively assist domain experts in detecting and resolving potential data-related issues for the purpose of model improvement has remained largely unexplored. In this technical report, we summarise the key findings of our two user studies. Our research involved a comprehensive examination of the impact of global explanations rooted in both data-centric and model-centric perspectives within systems designed to support healthcare experts in optimising machine learning models through both automated and manual data configurations. To empirically investigate these dynamics, we conducted two user studies, comprising quantitative analysis involving a sample size of 70 healthcare experts and qualitative assessments involving 30 healthcare experts. These studies were aimed at illuminating the influence of different explanation types on three key dimensions: trust, understandability, and model improvement. Results show that global model-centric explanations alone are insufficient for effectively guiding users during the intricate process of data configuration. In contrast, data-centric explanations exhibited their potential by enhancing the understanding of system changes that occur post-configuration. However, a combination of both showed the highest level of efficacy for fostering trust, improving understandability, and facilitating model enhancement among healthcare experts. We also present essential implications for developing interactive machine-learning systems driven by explanations. These insights can guide the creation of more effective systems that empower domain experts to harness the full potential of machine learning","sentences":["In the realm of interactive machine-learning systems, the provision of explanations serves as a vital aid in the processes of debugging and enhancing prediction models.","However, the extent to which various global model-centric and data-centric explanations can effectively assist domain experts in detecting and resolving potential data-related issues for the purpose of model improvement has remained largely unexplored.","In this technical report, we summarise the key findings of our two user studies.","Our research involved a comprehensive examination of the impact of global explanations rooted in both data-centric and model-centric perspectives within systems designed to support healthcare experts in optimising machine learning models through both automated and manual data configurations.","To empirically investigate these dynamics, we conducted two user studies, comprising quantitative analysis involving a sample size of 70 healthcare experts and qualitative assessments involving 30 healthcare experts.","These studies were aimed at illuminating the influence of different explanation types on three key dimensions: trust, understandability, and model improvement.","Results show that global model-centric explanations alone are insufficient for effectively guiding users during the intricate process of data configuration.","In contrast, data-centric explanations exhibited their potential by enhancing the understanding of system changes that occur post-configuration.","However, a combination of both showed the highest level of efficacy for fostering trust, improving understandability, and facilitating model enhancement among healthcare experts.","We also present essential implications for developing interactive machine-learning systems driven by explanations.","These insights can guide the creation of more effective systems that empower domain experts to harness the full potential of machine learning"],"url":"http://arxiv.org/abs/2310.02063v1"}
{"created":"2023-10-03 14:04:40","title":"Gotta Catch 'em All: Aggregating CVSS Scores","abstract":"Security metrics are not standardized, but inter-national proposals such as the Common Vulnerability ScoringSystem (CVSS) for quantifying the severity of known vulnerabil-ities are widely used. Many CVSS aggregation mechanisms havebeen proposed in the literature. Nevertheless, factors related tothe context of the System Under Test (SUT) are not taken intoaccount in the aggregation process; vulnerabilities that in theoryaffect the SUT, but are not exploitable in reality. We propose aCVSS aggregation algorithm that integrates information aboutthe functionality disruption of the SUT, exploitation difficulty,existence of exploits, and the context where the SUT operates.The aggregation algorithm was applied to OpenPLC V3, showingthat it is capable of filtering out vulnerabilities that cannot beexploited in the real conditions of deployment of the particularsystem. Finally, because of the nature of the proposed algorithm,the result can be interpreted in the same way as a normal CVSS.","sentences":["Security metrics are not standardized, but inter-national proposals such as the Common Vulnerability ScoringSystem (CVSS) for quantifying the severity of known vulnerabil-ities are widely used.","Many CVSS aggregation mechanisms havebeen proposed in the literature.","Nevertheless, factors related tothe context of the System Under Test (SUT) are not taken intoaccount in the aggregation process; vulnerabilities that in theoryaffect the SUT, but are not exploitable in reality.","We propose aCVSS aggregation algorithm that integrates information aboutthe functionality disruption of the SUT, exploitation difficulty,existence of exploits, and the context where the SUT operates.","The aggregation algorithm was applied to OpenPLC V3, showingthat it is capable of filtering out vulnerabilities that cannot beexploited in the real conditions of deployment of the particularsystem.","Finally, because of the nature of the proposed algorithm,the result can be interpreted in the same way as a normal CVSS."],"url":"http://arxiv.org/abs/2310.02062v1"}
{"created":"2023-10-03 14:03:20","title":"Global Attractor for a Reaction-Diffusion Model Arising in Biological Dynamic in 3D Soil Structure","abstract":"Partial Differential Equations (PDEs) play a crucial role as tools for modeling and comprehending intricate natural processes, notably within the domain of biology. This research explores the domain of microbial activity within the complex matrix of 3D soil structures, providing valuable understanding into both the existence and uniqueness of solutions and the asymptotic behavior of the corresponding PDE model. Our investigation results in the discovery of a global attractor, a fundamental feature with significant implications for long-term system behavior. To enhance the clarity of our findings, numerical simulations are employed to visually illustrate the attributes of this global attractor.","sentences":["Partial Differential Equations (PDEs) play a crucial role as tools for modeling and comprehending intricate natural processes, notably within the domain of biology.","This research explores the domain of microbial activity within the complex matrix of 3D soil structures, providing valuable understanding into both the existence and uniqueness of solutions and the asymptotic behavior of the corresponding PDE model.","Our investigation results in the discovery of a global attractor, a fundamental feature with significant implications for long-term system behavior.","To enhance the clarity of our findings, numerical simulations are employed to visually illustrate the attributes of this global attractor."],"url":"http://arxiv.org/abs/2310.02060v1"}
{"created":"2023-10-03 14:01:28","title":"Security Weaknesses of Copilot Generated Code in GitHub","abstract":"Modern code generation tools use AI models, particularly Large Language Models (LLMs), to generate functional and complete code. While such tools are becoming popular and widely available for developers, using these tools is often accompanied by security challenges. Therefore, it is important to assess the quality of the generated code, especially in terms of its security. Researchers have recently explored various aspects of code generation tools, including security. However, many open questions about the security of the generated code require further investigation, especially the security issues of automatically generated code in the wild. To this end, we conducted an empirical study by analyzing the security weaknesses in code snippets generated by GitHub Copilot that are found as part of publicly available projects hosted on GitHub. The goal is to investigate the types of security issues and their scale in real-world scenarios (rather than crafted scenarios). To this end, we identified 435 code snippets generated by Copilot from publicly available projects. We then conducted extensive security analysis to identify Common Weakness Enumeration (CWE) instances in these code snippets. The results show that (1) 35.8% of Copilot generated code snippets contain CWEs, and those issues are spread across multiple languages, (2) the security weaknesses are diverse and related to 42 different CWEs, in which CWE-78: OS Command Injection, CWE-330: Use of Insufficiently Random Values, and CWE-703: Improper Check or Handling of Exceptional Conditions occurred the most frequently, and (3) among the 42 CWEs identified, 11 of those belong to the currently recognized 2022 CWE Top-25. Our findings confirm that developers should be careful when adding code generated by Copilot (and similar AI code generation tools) and should also run appropriate security checks as they accept the suggested code.","sentences":["Modern code generation tools use AI models, particularly Large Language Models (LLMs), to generate functional and complete code.","While such tools are becoming popular and widely available for developers, using these tools is often accompanied by security challenges.","Therefore, it is important to assess the quality of the generated code, especially in terms of its security.","Researchers have recently explored various aspects of code generation tools, including security.","However, many open questions about the security of the generated code require further investigation, especially the security issues of automatically generated code in the wild.","To this end, we conducted an empirical study by analyzing the security weaknesses in code snippets generated by GitHub Copilot that are found as part of publicly available projects hosted on GitHub.","The goal is to investigate the types of security issues and their scale in real-world scenarios (rather than crafted scenarios).","To this end, we identified 435 code snippets generated by Copilot from publicly available projects.","We then conducted extensive security analysis to identify Common Weakness Enumeration (CWE) instances in these code snippets.","The results show that (1) 35.8% of Copilot generated code snippets contain CWEs, and those issues are spread across multiple languages, (2) the security weaknesses are diverse and related to 42 different CWEs, in which CWE-78: OS Command Injection, CWE-330: Use of Insufficiently Random Values, and CWE-703: Improper Check or Handling of Exceptional Conditions occurred the most frequently, and (3) among the 42 CWEs identified, 11 of those belong to the currently recognized 2022 CWE Top-25.","Our findings confirm that developers should be careful when adding code generated by Copilot (and similar AI code generation tools) and should also run appropriate security checks as they accept the suggested code."],"url":"http://arxiv.org/abs/2310.02059v1"}
