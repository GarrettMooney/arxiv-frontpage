{"created":"2023-10-18 17:59:45","title":"Probabilistic Sampling of Balanced K-Means using Adiabatic Quantum Computing","abstract":"Adiabatic quantum computing (AQC) is a promising quantum computing approach for discrete and often NP-hard optimization problems. Current AQCs allow to implement problems of research interest, which has sparked the development of quantum representations for many machine learning and computer vision tasks. Despite requiring multiple measurements from the noisy AQC, current approaches only utilize the best measurement, discarding information contained in the remaining ones. In this work, we explore the potential of using this information for probabilistic balanced k-means clustering. Instead of discarding non-optimal solutions, we propose to use them to compute calibrated posterior probabilities with little additional compute cost. This allows us to identify ambiguous solutions and data points, which we demonstrate on a D-Wave AQC on synthetic and real data.","sentences":["Adiabatic quantum computing (AQC) is a promising quantum computing approach for discrete and often NP-hard optimization problems.","Current AQCs allow to implement problems of research interest, which has sparked the development of quantum representations for many machine learning and computer vision tasks.","Despite requiring multiple measurements from the noisy AQC, current approaches only utilize the best measurement, discarding information contained in the remaining ones.","In this work, we explore the potential of using this information for probabilistic balanced k-means clustering.","Instead of discarding non-optimal solutions, we propose to use them to compute calibrated posterior probabilities with little additional compute cost.","This allows us to identify ambiguous solutions and data points, which we demonstrate on a D-Wave AQC on synthetic and real data."],"url":"http://arxiv.org/abs/2310.12153v1"}
{"created":"2023-10-18 17:59:41","title":"Learning from Rich Semantics and Coarse Locations for Long-tailed Object Detection","abstract":"Long-tailed object detection (LTOD) aims to handle the extreme data imbalance in real-world datasets, where many tail classes have scarce instances. One popular strategy is to explore extra data with image-level labels, yet it produces limited results due to (1) semantic ambiguity -- an image-level label only captures a salient part of the image, ignoring the remaining rich semantics within the image; and (2) location sensitivity -- the label highly depends on the locations and crops of the original image, which may change after data transformations like random cropping. To remedy this, we propose RichSem, a simple but effective method, which is robust to learn rich semantics from coarse locations without the need of accurate bounding boxes. RichSem leverages rich semantics from images, which are then served as additional soft supervision for training detectors. Specifically, we add a semantic branch to our detector to learn these soft semantics and enhance feature representations for long-tailed object detection. The semantic branch is only used for training and is removed during inference. RichSem achieves consistent improvements on both overall and rare-category of LVIS under different backbones and detectors. Our method achieves state-of-the-art performance without requiring complex training and testing procedures. Moreover, we show the effectiveness of our method on other long-tailed datasets with additional experiments. Code is available at \\url{https://github.com/MengLcool/RichSem}.","sentences":["Long-tailed object detection (LTOD) aims to handle the extreme data imbalance in real-world datasets, where many tail classes have scarce instances.","One popular strategy is to explore extra data with image-level labels, yet it produces limited results due to (1) semantic ambiguity -- an image-level label only captures a salient part of the image, ignoring the remaining rich semantics within the image; and (2) location sensitivity -- the label highly depends on the locations and crops of the original image, which may change after data transformations like random cropping.","To remedy this, we propose RichSem, a simple but effective method, which is robust to learn rich semantics from coarse locations without the need of accurate bounding boxes.","RichSem leverages rich semantics from images, which are then served as additional soft supervision for training detectors.","Specifically, we add a semantic branch to our detector to learn these soft semantics and enhance feature representations for long-tailed object detection.","The semantic branch is only used for training and is removed during inference.","RichSem achieves consistent improvements on both overall and rare-category of LVIS under different backbones and detectors.","Our method achieves state-of-the-art performance without requiring complex training and testing procedures.","Moreover, we show the effectiveness of our method on other long-tailed datasets with additional experiments.","Code is available at \\url{https://github.com/MengLcool/RichSem}."],"url":"http://arxiv.org/abs/2310.12152v1"}
{"created":"2023-10-18 17:59:10","title":"Understanding Retrieval Augmentation for Long-Form Question Answering","abstract":"We present a study of retrieval-augmented language models (LMs) on long-form question answering. We analyze how retrieval augmentation impacts different LMs, by comparing answers generated from models while using the same evidence documents, and how differing quality of retrieval document set impacts the answers generated from the same LM. We study various attributes of generated answers (e.g., fluency, length, variance) with an emphasis on the attribution of generated long-form answers to in-context evidence documents. We collect human annotations of answer attribution and evaluate methods for automatically judging attribution. Our study provides new insights on how retrieval augmentation impacts long, knowledge-rich text generation of LMs. We further identify attribution patterns for long text generation and analyze the main culprits of attribution errors. Together, our analysis reveals how retrieval augmentation impacts long knowledge-rich text generation and provide directions for future work.","sentences":["We present a study of retrieval-augmented language models (LMs) on long-form question answering.","We analyze how retrieval augmentation impacts different LMs, by comparing answers generated from models while using the same evidence documents, and how differing quality of retrieval document set impacts the answers generated from the same LM.","We study various attributes of generated answers (e.g., fluency, length, variance) with an emphasis on the attribution of generated long-form answers to in-context evidence documents.","We collect human annotations of answer attribution and evaluate methods for automatically judging attribution.","Our study provides new insights on how retrieval augmentation impacts long, knowledge-rich text generation of LMs.","We further identify attribution patterns for long text generation and analyze the main culprits of attribution errors.","Together, our analysis reveals how retrieval augmentation impacts long knowledge-rich text generation and provide directions for future work."],"url":"http://arxiv.org/abs/2310.12150v1"}
{"created":"2023-10-18 17:59:02","title":"Object-aware Inversion and Reassembly for Image Editing","abstract":"By comparing the original and target prompts in editing task, we can obtain numerous editing pairs, each comprising an object and its corresponding editing target. To allow editability while maintaining fidelity to the input image, existing editing methods typically involve a fixed number of inversion steps that project the whole input image to its noisier latent representation, followed by a denoising process guided by the target prompt. However, we find that the optimal number of inversion steps for achieving ideal editing results varies significantly among different editing pairs, owing to varying editing difficulties. Therefore, the current literature, which relies on a fixed number of inversion steps, produces sub-optimal generation quality, especially when handling multiple editing pairs in a natural image. To this end, we propose a new image editing paradigm, dubbed Object-aware Inversion and Reassembly (OIR), to enable object-level fine-grained editing. Specifically, we design a new search metric, which determines the optimal inversion steps for each editing pair, by jointly considering the editability of the target and the fidelity of the non-editing region. We use our search metric to find the optimal inversion step for each editing pair when editing an image. We then edit these editing pairs separately to avoid concept mismatch. Subsequently, we propose an additional reassembly step to seamlessly integrate the respective editing results and the non-editing region to obtain the final edited image. To systematically evaluate the effectiveness of our method, we collect two datasets for benchmarking single- and multi-object editing, respectively. Experiments demonstrate that our method achieves superior performance in editing object shapes, colors, materials, categories, etc., especially in multi-object editing scenarios.","sentences":["By comparing the original and target prompts in editing task, we can obtain numerous editing pairs, each comprising an object and its corresponding editing target.","To allow editability while maintaining fidelity to the input image, existing editing methods typically involve a fixed number of inversion steps that project the whole input image to its noisier latent representation, followed by a denoising process guided by the target prompt.","However, we find that the optimal number of inversion steps for achieving ideal editing results varies significantly among different editing pairs, owing to varying editing difficulties.","Therefore, the current literature, which relies on a fixed number of inversion steps, produces sub-optimal generation quality, especially when handling multiple editing pairs in a natural image.","To this end, we propose a new image editing paradigm, dubbed Object-aware Inversion and Reassembly (OIR), to enable object-level fine-grained editing.","Specifically, we design a new search metric, which determines the optimal inversion steps for each editing pair, by jointly considering the editability of the target and the fidelity of the non-editing region.","We use our search metric to find the optimal inversion step for each editing pair when editing an image.","We then edit these editing pairs separately to avoid concept mismatch.","Subsequently, we propose an additional reassembly step to seamlessly integrate the respective editing results and the non-editing region to obtain the final edited image.","To systematically evaluate the effectiveness of our method, we collect two datasets for benchmarking single- and multi-object editing, respectively.","Experiments demonstrate that our method achieves superior performance in editing object shapes, colors, materials, categories, etc., especially in multi-object editing scenarios."],"url":"http://arxiv.org/abs/2310.12149v1"}
{"created":"2023-10-18 17:57:05","title":"InViG: Benchmarking Interactive Visual Grounding with 500K Human-Robot Interactions","abstract":"Ambiguity is ubiquitous in human communication. Previous approaches in Human-Robot Interaction (HRI) have often relied on predefined interaction templates, leading to reduced performance in realistic and open-ended scenarios. To address these issues, we present a large-scale dataset, \\invig, for interactive visual grounding under language ambiguity. Our dataset comprises over 520K images accompanied by open-ended goal-oriented disambiguation dialogues, encompassing millions of object instances and corresponding question-answer pairs. Leveraging the \\invig dataset, we conduct extensive studies and propose a set of baseline solutions for end-to-end interactive visual disambiguation and grounding, achieving a 45.6\\% success rate during validation. To the best of our knowledge, the \\invig dataset is the first large-scale dataset for resolving open-ended interactive visual grounding, presenting a practical yet highly challenging benchmark for ambiguity-aware HRI. Codes and datasets are available at: \\href{https://openivg.github.io}{https://openivg.github.io}.","sentences":["Ambiguity is ubiquitous in human communication.","Previous approaches in Human-Robot Interaction (HRI) have often relied on predefined interaction templates, leading to reduced performance in realistic and open-ended scenarios.","To address these issues, we present a large-scale dataset, \\invig, for interactive visual grounding under language ambiguity.","Our dataset comprises over 520K images accompanied by open-ended goal-oriented disambiguation dialogues, encompassing millions of object instances and corresponding question-answer pairs.","Leveraging the \\invig dataset, we conduct extensive studies and propose a set of baseline solutions for end-to-end interactive visual disambiguation and grounding, achieving a 45.6\\% success rate during validation.","To the best of our knowledge, the \\invig dataset is the first large-scale dataset for resolving open-ended interactive visual grounding, presenting a practical yet highly challenging benchmark for ambiguity-aware HRI.","Codes and datasets are available at: \\href{https://openivg.github.io}{https://openivg.github.io}."],"url":"http://arxiv.org/abs/2310.12147v1"}
{"created":"2023-10-18 17:56:24","title":"Fairer and More Accurate Tabular Models Through NAS","abstract":"Making models algorithmically fairer in tabular data has been long studied, with techniques typically oriented towards fixes which usually take a neural model with an undesirable outcome and make changes to how the data are ingested, what the model weights are, or how outputs are processed. We employ an emergent and different strategy where we consider updating the model's architecture and training hyperparameters to find an entirely new model with better outcomes from the beginning of the debiasing procedure. In this work, we propose using multi-objective Neural Architecture Search (NAS) and Hyperparameter Optimization (HPO) in the first application to the very challenging domain of tabular data. We conduct extensive exploration of architectural and hyperparameter spaces (MLP, ResNet, and FT-Transformer) across diverse datasets, demonstrating the dependence of accuracy and fairness metrics of model predictions on hyperparameter combinations. We show that models optimized solely for accuracy with NAS often fail to inherently address fairness concerns. We propose a novel approach that jointly optimizes architectural and training hyperparameters in a multi-objective constraint of both accuracy and fairness. We produce architectures that consistently Pareto dominate state-of-the-art bias mitigation methods either in fairness, accuracy or both, all of this while being Pareto-optimal over hyperparameters achieved through single-objective (accuracy) optimization runs. This research underscores the promise of automating fairness and accuracy optimization in deep learning models.","sentences":["Making models algorithmically fairer in tabular data has been long studied, with techniques typically oriented towards fixes which usually take a neural model with an undesirable outcome and make changes to how the data are ingested, what the model weights are, or how outputs are processed.","We employ an emergent and different strategy where we consider updating the model's architecture and training hyperparameters to find an entirely new model with better outcomes from the beginning of the debiasing procedure.","In this work, we propose using multi-objective Neural Architecture Search (NAS) and Hyperparameter Optimization (HPO) in the first application to the very challenging domain of tabular data.","We conduct extensive exploration of architectural and hyperparameter spaces (MLP, ResNet, and FT-Transformer) across diverse datasets, demonstrating the dependence of accuracy and fairness metrics of model predictions on hyperparameter combinations.","We show that models optimized solely for accuracy with NAS often fail to inherently address fairness concerns.","We propose a novel approach that jointly optimizes architectural and training hyperparameters in a multi-objective constraint of both accuracy and fairness.","We produce architectures that consistently Pareto dominate state-of-the-art bias mitigation methods either in fairness, accuracy or both, all of this while being Pareto-optimal over hyperparameters achieved through single-objective (accuracy) optimization runs.","This research underscores the promise of automating fairness and accuracy optimization in deep learning models."],"url":"http://arxiv.org/abs/2310.12145v1"}
{"created":"2023-10-18 17:54:29","title":"Simple Mechanisms for Representing, Indexing and Manipulating Concepts","abstract":"Deep networks typically learn concepts via classifiers, which involves setting up a model and training it via gradient descent to fit the concept-labeled data. We will argue instead that learning a concept could be done by looking at its moment statistics matrix to generate a concrete representation or signature of that concept. These signatures can be used to discover structure across the set of concepts and could recursively produce higher-level concepts by learning this structure from those signatures. When the concepts are `intersected', signatures of the concepts can be used to find a common theme across a number of related `intersected' concepts. This process could be used to keep a dictionary of concepts so that inputs could correctly identify and be routed to the set of concepts involved in the (latent) generation of the input.","sentences":["Deep networks typically learn concepts via classifiers, which involves setting up a model and training it via gradient descent to fit the concept-labeled data.","We will argue instead that learning a concept could be done by looking at its moment statistics matrix to generate a concrete representation or signature of that concept.","These signatures can be used to discover structure across the set of concepts and could recursively produce higher-level concepts by learning this structure from those signatures.","When the concepts are `intersected', signatures of the concepts can be used to find a common theme across a number of related `intersected' concepts.","This process could be used to keep a dictionary of concepts so that inputs could correctly identify and be routed to the set of concepts involved in the (latent) generation of the input."],"url":"http://arxiv.org/abs/2310.12143v1"}
{"created":"2023-10-18 17:48:05","title":"Pseudointelligence: A Unifying Framework for Language Model Evaluation","abstract":"With large language models surpassing human performance on an increasing number of benchmarks, we must take a principled approach for targeted evaluation of model capabilities. Inspired by pseudorandomness, we propose pseudointelligence, which captures the maxim that \"(perceived) intelligence lies in the eye of the beholder\". That is, that claims of intelligence are meaningful only when their evaluator is taken into account. Concretely, we propose a complexity-theoretic framework of model evaluation cast as a dynamic interaction between a model and a learned evaluator. We demonstrate that this framework can be used to reason about two case studies in language model evaluation, as well as analyze existing evaluation methods.","sentences":["With large language models surpassing human performance on an increasing number of benchmarks, we must take a principled approach for targeted evaluation of model capabilities.","Inspired by pseudorandomness, we propose pseudointelligence, which captures the maxim that \"(perceived) intelligence lies in the eye of the beholder\".","That is, that claims of intelligence are meaningful only when their evaluator is taken into account.","Concretely, we propose a complexity-theoretic framework of model evaluation cast as a dynamic interaction between a model and a learned evaluator.","We demonstrate that this framework can be used to reason about two case studies in language model evaluation, as well as analyze existing evaluation methods."],"url":"http://arxiv.org/abs/2310.12135v1"}
{"created":"2023-10-18 17:43:54","title":"A comprehensible analysis of the efficacy of Ensemble Models for Bug Prediction","abstract":"The correctness of software systems is vital for their effective operation. It makes discovering and fixing software bugs an important development task. The increasing use of Artificial Intelligence (AI) techniques in Software Engineering led to the development of a number of techniques that can assist software developers in identifying potential bugs in code. In this paper, we present a comprehensible comparison and analysis of the efficacy of two AI-based approaches, namely single AI models and ensemble AI models, for predicting the probability of a Java class being buggy. We used two open-source Apache Commons Project's Java components for training and evaluating the models. Our experimental findings indicate that the ensemble of AI models can outperform the results of applying individual AI models. We also offer insight into the factors that contribute to the enhanced performance of the ensemble AI model. The presented results demonstrate the potential of using ensemble AI models to enhance bug prediction results, which could ultimately result in more reliable software systems.","sentences":["The correctness of software systems is vital for their effective operation.","It makes discovering and fixing software bugs an important development task.","The increasing use of Artificial Intelligence (AI) techniques in Software Engineering led to the development of a number of techniques that can assist software developers in identifying potential bugs in code.","In this paper, we present a comprehensible comparison and analysis of the efficacy of two AI-based approaches, namely single AI models and ensemble AI models, for predicting the probability of a Java class being buggy.","We used two open-source Apache Commons Project's Java components for training and evaluating the models.","Our experimental findings indicate that the ensemble of AI models can outperform the results of applying individual AI models.","We also offer insight into the factors that contribute to the enhanced performance of the ensemble AI model.","The presented results demonstrate the potential of using ensemble AI models to enhance bug prediction results, which could ultimately result in more reliable software systems."],"url":"http://arxiv.org/abs/2310.12133v1"}
{"created":"2023-10-18 17:42:58","title":"The Effects of Computational Resources on Flaky Tests","abstract":"Flaky tests are tests that nondeterministically pass and fail in unchanged code. These tests can be detrimental to developers' productivity. Particularly when tests run in continuous integration environments, the tests may be competing for access to limited computational resources (CPUs, memory etc.), and we hypothesize that resource (in)availability may be a significant factor in the failure rate of flaky tests. We present the first assessment of the impact that computational resources have on flaky tests, including a total of 52 projects written in Java, JavaScript and Python, and 27 different resource configurations. Using a rigorous statistical methodology, we determine which tests are RAFT (Resource-Affected Flaky Tests). We find that 46.5% of the flaky tests in our dataset are RAFT, indicating that a substantial proportion of flaky-test failures can be avoided by adjusting the resources available when running tests. We report RAFTs and configurations to avoid them to developers, and received interest to either fix the RAFTs or to improve the specifications of the projects so that tests would be run only in configurations that are unlikely to encounter RAFT failures. Our results also have implications for researchers attempting to detect flaky tests, e.g., reducing the resources available when running tests is a cost-effective approach to detect more flaky failures.","sentences":["Flaky tests are tests that nondeterministically pass and fail in unchanged code.","These tests can be detrimental to developers' productivity.","Particularly when tests run in continuous integration environments, the tests may be competing for access to limited computational resources (CPUs, memory etc.), and we hypothesize that resource (in)availability may be a significant factor in the failure rate of flaky tests.","We present the first assessment of the impact that computational resources have on flaky tests, including a total of 52 projects written in Java, JavaScript and Python, and 27 different resource configurations.","Using a rigorous statistical methodology, we determine which tests are RAFT (Resource-Affected Flaky Tests).","We find that 46.5% of the flaky tests in our dataset are RAFT, indicating that a substantial proportion of flaky-test failures can be avoided by adjusting the resources available when running tests.","We report RAFTs and configurations to avoid them to developers, and received interest to either fix the RAFTs or to improve the specifications of the projects so that tests would be run only in configurations that are unlikely to encounter RAFT failures.","Our results also have implications for researchers attempting to detect flaky tests, e.g., reducing the resources available when running tests is a cost-effective approach to detect more flaky failures."],"url":"http://arxiv.org/abs/2310.12132v1"}
{"created":"2023-10-18 17:41:28","title":"Automated Attribute Extraction from Legal Proceedings","abstract":"The escalating number of pending cases is a growing concern world-wide. Recent advancements in digitization have opened up possibilities for leveraging artificial intelligence (AI) tools in the processing of legal documents. Adopting a structured representation for legal documents, as opposed to a mere bag-of-words flat text representation, can significantly enhance processing capabilities. With the aim of achieving this objective, we put forward a set of diverse attributes for criminal case proceedings. We use a state-of-the-art sequence labeling framework to automatically extract attributes from the legal documents. Moreover, we demonstrate the efficacy of the extracted attributes in a downstream task, namely legal judgment prediction.","sentences":["The escalating number of pending cases is a growing concern world-wide.","Recent advancements in digitization have opened up possibilities for leveraging artificial intelligence (AI) tools in the processing of legal documents.","Adopting a structured representation for legal documents, as opposed to a mere bag-of-words flat text representation, can significantly enhance processing capabilities.","With the aim of achieving this objective, we put forward a set of diverse attributes for criminal case proceedings.","We use a state-of-the-art sequence labeling framework to automatically extract attributes from the legal documents.","Moreover, we demonstrate the efficacy of the extracted attributes in a downstream task, namely legal judgment prediction."],"url":"http://arxiv.org/abs/2310.12131v1"}
{"created":"2023-10-18 17:37:10","title":"DiagrammerGPT: Generating Open-Domain, Open-Platform Diagrams via LLM Planning","abstract":"Text-to-image (T2I) generation has seen significant growth over the past few years. Despite this, there has been little work on generating diagrams with T2I models. A diagram is a symbolic/schematic representation that explains information using structurally rich and spatially complex visualizations (e.g., a dense combination of related objects, text labels, directional arrows, connection lines, etc.). Existing state-of-the-art T2I models often fail at diagram generation because they lack fine-grained object layout control when many objects are densely connected via complex relations such as arrows/lines and also often fail to render comprehensible text labels. To address this gap, we present DiagrammerGPT, a novel two-stage text-to-diagram generation framework that leverages the layout guidance capabilities of LLMs (e.g., GPT-4) to generate more accurate open-domain, open-platform diagrams. In the first stage, we use LLMs to generate and iteratively refine 'diagram plans' (in a planner-auditor feedback loop) which describe all the entities (objects and text labels), their relationships (arrows or lines), and their bounding box layouts. In the second stage, we use a diagram generator, DiagramGLIGEN, and a text label rendering module to generate diagrams following the diagram plans. To benchmark the text-to-diagram generation task, we introduce AI2D-Caption, a densely annotated diagram dataset built on top of the AI2D dataset. We show quantitatively and qualitatively that our DiagrammerGPT framework produces more accurate diagrams, outperforming existing T2I models. We also provide comprehensive analysis including open-domain diagram generation, vector graphic diagram generation in different platforms, human-in-the-loop diagram plan editing, and multimodal planner/auditor LLMs (e.g., GPT-4Vision). We hope our work can inspire further research on diagram generation via T2I models and LLMs.","sentences":["Text-to-image (T2I) generation has seen significant growth over the past few years.","Despite this, there has been little work on generating diagrams with T2I models.","A diagram is a symbolic/schematic representation that explains information using structurally rich and spatially complex visualizations (e.g., a dense combination of related objects, text labels, directional arrows, connection lines, etc.).","Existing state-of-the-art T2I models often fail at diagram generation because they lack fine-grained object layout control when many objects are densely connected via complex relations such as arrows/lines and also often fail to render comprehensible text labels.","To address this gap, we present DiagrammerGPT, a novel two-stage text-to-diagram generation framework that leverages the layout guidance capabilities of LLMs (e.g., GPT-4) to generate more accurate open-domain, open-platform diagrams.","In the first stage, we use LLMs to generate and iteratively refine 'diagram plans' (in a planner-auditor feedback loop) which describe all the entities (objects and text labels), their relationships (arrows or lines), and their bounding box layouts.","In the second stage, we use a diagram generator, DiagramGLIGEN, and a text label rendering module to generate diagrams following the diagram plans.","To benchmark the text-to-diagram generation task, we introduce AI2D-Caption, a densely annotated diagram dataset built on top of the AI2D dataset.","We show quantitatively and qualitatively that our DiagrammerGPT framework produces more accurate diagrams, outperforming existing T2I models.","We also provide comprehensive analysis including open-domain diagram generation, vector graphic diagram generation in different platforms, human-in-the-loop diagram plan editing, and multimodal planner/auditor LLMs (e.g., GPT-4Vision).","We hope our work can inspire further research on diagram generation via T2I models and LLMs."],"url":"http://arxiv.org/abs/2310.12128v1"}
{"created":"2023-10-18 17:36:55","title":"A Tale of Pronouns: Interpretability Informs Gender Bias Mitigation for Fairer Instruction-Tuned Machine Translation","abstract":"Recent instruction fine-tuned models can solve multiple NLP tasks when prompted to do so, with machine translation (MT) being a prominent use case. However, current research often focuses on standard performance benchmarks, leaving compelling fairness and ethical considerations behind. In MT, this might lead to misgendered translations, resulting, among other harms, in the perpetuation of stereotypes and prejudices. In this work, we address this gap by investigating whether and to what extent such models exhibit gender bias in machine translation and how we can mitigate it. Concretely, we compute established gender bias metrics on the WinoMT corpus from English to German and Spanish. We discover that IFT models default to male-inflected translations, even disregarding female occupational stereotypes. Next, using interpretability methods, we unveil that models systematically overlook the pronoun indicating the gender of a target occupation in misgendered translations. Finally, based on this finding, we propose an easy-to-implement and effective bias mitigation solution based on few-shot learning that leads to significantly fairer translations.","sentences":["Recent instruction fine-tuned models can solve multiple NLP tasks when prompted to do so, with machine translation (MT) being a prominent use case.","However, current research often focuses on standard performance benchmarks, leaving compelling fairness and ethical considerations behind.","In MT, this might lead to misgendered translations, resulting, among other harms, in the perpetuation of stereotypes and prejudices.","In this work, we address this gap by investigating whether and to what extent such models exhibit gender bias in machine translation and how we can mitigate it.","Concretely, we compute established gender bias metrics on the WinoMT corpus from English to German and Spanish.","We discover that IFT models default to male-inflected translations, even disregarding female occupational stereotypes.","Next, using interpretability methods, we unveil that models systematically overlook the pronoun indicating the gender of a target occupation in misgendered translations.","Finally, based on this finding, we propose an easy-to-implement and effective bias mitigation solution based on few-shot learning that leads to significantly fairer translations."],"url":"http://arxiv.org/abs/2310.12127v1"}
{"created":"2023-10-18 17:35:15","title":"SHARCS: Efficient Transformers through Routing with Dynamic Width Sub-networks","abstract":"We introduce SHARCS for adaptive inference that takes into account the hardness of input samples. SHARCS can train a router on any transformer network, enabling the model to direct different samples to sub-networks with varying widths. Our experiments demonstrate that: (1) SHARCS outperforms or complements existing per-sample adaptive inference methods across various classification tasks in terms of accuracy vs. FLOPs; (2) SHARCS generalizes across different architectures and can be even applied to compressed and efficient transformer encoders to further improve their efficiency; (3) SHARCS can provide a 2 times inference speed up at an insignificant drop in accuracy.","sentences":["We introduce SHARCS for adaptive inference that takes into account the hardness of input samples.","SHARCS can train a router on any transformer network, enabling the model to direct different samples to sub-networks with varying widths.","Our experiments demonstrate that: (1) SHARCS outperforms or complements existing per-sample adaptive inference methods across various classification tasks in terms of accuracy vs. FLOPs; (2) SHARCS generalizes across different architectures and can be even applied to compressed and efficient transformer encoders to further improve their efficiency; (3) SHARCS can provide a 2 times inference speed up at an insignificant drop in accuracy."],"url":"http://arxiv.org/abs/2310.12126v1"}
{"created":"2023-10-18 17:21:01","title":"Automatic prediction of mortality in patients with mental illness using electronic health records","abstract":"Mental disorders impact the lives of millions of people globally, not only impeding their day-to-day lives but also markedly reducing life expectancy. This paper addresses the persistent challenge of predicting mortality in patients with mental diagnoses using predictive machine-learning models with electronic health records (EHR). Data from patients with mental disease diagnoses were extracted from the well-known clinical MIMIC-III data set utilizing demographic, prescription, and procedural information. Four machine learning algorithms (Logistic Regression, Random Forest, Support Vector Machine, and K-Nearest Neighbors) were used, with results indicating that Random Forest and Support Vector Machine models outperformed others, with AUC scores of 0.911. Feature importance analysis revealed that drug prescriptions, particularly Morphine Sulfate, play a pivotal role in prediction. We applied a variety of machine learning algorithms to predict 30-day mortality followed by feature importance analysis. This study can be used to assist hospital workers in identifying at-risk patients to reduce excess mortality.","sentences":["Mental disorders impact the lives of millions of people globally, not only impeding their day-to-day lives but also markedly reducing life expectancy.","This paper addresses the persistent challenge of predicting mortality in patients with mental diagnoses using predictive machine-learning models with electronic health records (EHR).","Data from patients with mental disease diagnoses were extracted from the well-known clinical MIMIC-III data set utilizing demographic, prescription, and procedural information.","Four machine learning algorithms (Logistic Regression, Random Forest, Support Vector Machine, and K-Nearest Neighbors) were used, with results indicating that Random Forest and Support Vector Machine models outperformed others, with AUC scores of 0.911.","Feature importance analysis revealed that drug prescriptions, particularly Morphine Sulfate, play a pivotal role in prediction.","We applied a variety of machine learning algorithms to predict 30-day mortality followed by feature importance analysis.","This study can be used to assist hospital workers in identifying at-risk patients to reduce excess mortality."],"url":"http://arxiv.org/abs/2310.12121v1"}
{"created":"2023-10-18 17:14:41","title":"Harnessing Dataset Cartography for Improved Compositional Generalization in Transformers","abstract":"Neural networks have revolutionized language modeling and excelled in various downstream tasks. However, the extent to which these models achieve compositional generalization comparable to human cognitive abilities remains a topic of debate. While existing approaches in the field have mainly focused on novel architectures and alternative learning paradigms, we introduce a pioneering method harnessing the power of dataset cartography (Swayamdipta et al., 2020). By strategically identifying a subset of compositional generalization data using this approach, we achieve a remarkable improvement in model accuracy, yielding enhancements of up to 10% on CFQ and COGS datasets. Notably, our technique incorporates dataset cartography as a curriculum learning criterion, eliminating the need for hyperparameter tuning while consistently achieving superior performance. Our findings highlight the untapped potential of dataset cartography in unleashing the full capabilities of compositional generalization within Transformer models. Our code is available at https://github.com/cyberiada/cartography-for-compositionality.","sentences":["Neural networks have revolutionized language modeling and excelled in various downstream tasks.","However, the extent to which these models achieve compositional generalization comparable to human cognitive abilities remains a topic of debate.","While existing approaches in the field have mainly focused on novel architectures and alternative learning paradigms, we introduce a pioneering method harnessing the power of dataset cartography (Swayamdipta et al., 2020).","By strategically identifying a subset of compositional generalization data using this approach, we achieve a remarkable improvement in model accuracy, yielding enhancements of up to 10% on CFQ and COGS datasets.","Notably, our technique incorporates dataset cartography as a curriculum learning criterion, eliminating the need for hyperparameter tuning while consistently achieving superior performance.","Our findings highlight the untapped potential of dataset cartography in unleashing the full capabilities of compositional generalization within Transformer models.","Our code is available at https://github.com/cyberiada/cartography-for-compositionality."],"url":"http://arxiv.org/abs/2310.12118v1"}
{"created":"2023-10-18 17:13:12","title":"Distributed Indexing Schemes for k-Dominant Skyline Analytics on Uncertain Edge-IoT Data","abstract":"Skyline queries typically search a Pareto-optimal set from a given data set to solve the corresponding multiobjective optimization problem. As the number of criteria increases, the skyline presumes excessive data items, which yield a meaningless result. To address this curse of dimensionality, we proposed a k-dominant skyline in which the number of skyline members was reduced by relaxing the restriction on the number of dimensions, considering the uncertainty of data. Specifically, each data item was associated with a probability of appearance, which represented the probability of becoming a member of the k-dominant skyline. As data items appear continuously in data streams, the corresponding k-dominant skyline may vary with time. Therefore, an effective and rapid mechanism of updating the k-dominant skyline becomes crucial. Herein, we proposed two time-efficient schemes, Middle Indexing (MI) and All Indexing (AI), for k-dominant skyline in distributed edge-computing environments, where irrelevant data items can be effectively excluded from the compute to reduce the processing duration. Furthermore, the proposed schemes were validated with extensive experimental simulations. The experimental results demonstrated that the proposed MI and AI schemes reduced the computation time by approximately 13% and 56%, respectively, compared with the existing method.","sentences":["Skyline queries typically search a Pareto-optimal set from a given data set to solve the corresponding multiobjective optimization problem.","As the number of criteria increases, the skyline presumes excessive data items, which yield a meaningless result.","To address this curse of dimensionality, we proposed a k-dominant skyline in which the number of skyline members was reduced by relaxing the restriction on the number of dimensions, considering the uncertainty of data.","Specifically, each data item was associated with a probability of appearance, which represented the probability of becoming a member of the k-dominant skyline.","As data items appear continuously in data streams, the corresponding k-dominant skyline may vary with time.","Therefore, an effective and rapid mechanism of updating the k-dominant skyline becomes crucial.","Herein, we proposed two time-efficient schemes, Middle Indexing (MI) and All Indexing (AI), for k-dominant skyline in distributed edge-computing environments, where irrelevant data items can be effectively excluded from the compute to reduce the processing duration.","Furthermore, the proposed schemes were validated with extensive experimental simulations.","The experimental results demonstrated that the proposed MI and AI schemes reduced the computation time by approximately 13% and 56%, respectively, compared with the existing method."],"url":"http://arxiv.org/abs/2310.12116v1"}
{"created":"2023-10-18 17:07:37","title":"CAPGrasp: An $\\mathbb{R}^3\\times \\text{SO(2)-equivariant}$ Continuous Approach-Constrained Generative Grasp Sampler","abstract":"We propose CAPGrasp, an $\\mathbb{R}^3\\times \\text{SO(2)-equivariant}$ 6-DoF continuous approach-constrained generative grasp sampler. It includes a novel learning strategy for training CAPGrasp that eliminates the need to curate massive conditionally labeled datasets and a constrained grasp refinement technique that improves grasp poses while respecting the grasp approach directional constraints. The experimental results demonstrate that CAPGrasp is more than three times as sample efficient as unconstrained grasp samplers while achieving up to 38% grasp success rate improvement. CAPGrasp also achieves 4-10% higher grasp success rates than constrained but noncontinuous grasp samplers. Overall, CAPGrasp is a sample-efficient solution when grasps must originate from specific directions, such as grasping in confined spaces.","sentences":["We propose CAPGrasp, an $\\mathbb{R}^3\\times \\text{SO(2)-equivariant}$ 6-DoF continuous approach-constrained generative grasp sampler.","It includes a novel learning strategy for training CAPGrasp that eliminates the need to curate massive conditionally labeled datasets and a constrained grasp refinement technique that improves grasp poses while respecting the grasp approach directional constraints.","The experimental results demonstrate that CAPGrasp is more than three times as sample efficient as unconstrained grasp samplers while achieving up to 38% grasp success rate improvement.","CAPGrasp also achieves 4-10% higher grasp success rates than constrained but noncontinuous grasp samplers.","Overall, CAPGrasp is a sample-efficient solution when grasps must originate from specific directions, such as grasping in confined spaces."],"url":"http://arxiv.org/abs/2310.12113v1"}
{"created":"2023-10-18 17:07:07","title":"A Cautionary Tale: On the Role of Reference Data in Empirical Privacy Defenses","abstract":"Within the realm of privacy-preserving machine learning, empirical privacy defenses have been proposed as a solution to achieve satisfactory levels of training data privacy without a significant drop in model utility. Most existing defenses against membership inference attacks assume access to reference data, defined as an additional dataset coming from the same (or a similar) underlying distribution as training data. Despite the common use of reference data, previous works are notably reticent about defining and evaluating reference data privacy. As gains in model utility and/or training data privacy may come at the expense of reference data privacy, it is essential that all three aspects are duly considered. In this paper, we first examine the availability of reference data and its privacy treatment in previous works and demonstrate its necessity for fairly comparing defenses. Second, we propose a baseline defense that enables the utility-privacy tradeoff with respect to both training and reference data to be easily understood. Our method is formulated as an empirical risk minimization with a constraint on the generalization error, which, in practice, can be evaluated as a weighted empirical risk minimization (WERM) over the training and reference datasets. Although we conceived of WERM as a simple baseline, our experiments show that, surprisingly, it outperforms the most well-studied and current state-of-the-art empirical privacy defenses using reference data for nearly all relative privacy levels of reference and training data. Our investigation also reveals that these existing methods are unable to effectively trade off reference data privacy for model utility and/or training data privacy. Overall, our work highlights the need for a proper evaluation of the triad model utility / training data privacy / reference data privacy when comparing privacy defenses.","sentences":["Within the realm of privacy-preserving machine learning, empirical privacy defenses have been proposed as a solution to achieve satisfactory levels of training data privacy without a significant drop in model utility.","Most existing defenses against membership inference attacks assume access to reference data, defined as an additional dataset coming from the same (or a similar) underlying distribution as training data.","Despite the common use of reference data, previous works are notably reticent about defining and evaluating reference data privacy.","As gains in model utility and/or training data privacy may come at the expense of reference data privacy, it is essential that all three aspects are duly considered.","In this paper, we first examine the availability of reference data and its privacy treatment in previous works and demonstrate its necessity for fairly comparing defenses.","Second, we propose a baseline defense that enables the utility-privacy tradeoff with respect to both training and reference data to be easily understood.","Our method is formulated as an empirical risk minimization with a constraint on the generalization error, which, in practice, can be evaluated as a weighted empirical risk minimization (WERM) over the training and reference datasets.","Although we conceived of WERM as a simple baseline, our experiments show that, surprisingly, it outperforms the most well-studied and current state-of-the-art empirical privacy defenses using reference data for nearly all relative privacy levels of reference and training data.","Our investigation also reveals that these existing methods are unable to effectively trade off reference data privacy for model utility and/or training data privacy.","Overall, our work highlights the need for a proper evaluation of the triad model utility / training data privacy / reference data privacy when comparing privacy defenses."],"url":"http://arxiv.org/abs/2310.12112v1"}
{"created":"2023-10-18 17:06:22","title":"Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture","abstract":"Machine learning models are increasingly being scaled in both sequence length and model dimension to reach longer contexts and better performance. However, existing architectures such as Transformers scale quadratically along both these axes. We ask: are there performant architectures that can scale sub-quadratically along sequence length and model dimension? We introduce Monarch Mixer (M2), a new architecture that uses the same sub-quadratic primitive along both sequence length and model dimension: Monarch matrices, a simple class of expressive structured matrices that captures many linear transforms, achieves high hardware efficiency on GPUs, and scales sub-quadratically. As a proof of concept, we explore the performance of M2 in three domains: non-causal BERT-style language modeling, ViT-style image classification, and causal GPT-style language modeling. For non-causal BERT-style modeling, M2 matches BERT-base and BERT-large in downstream GLUE quality with up to 27% fewer parameters, and achieves up to 9.1$\\times$ higher throughput at sequence length 4K. On ImageNet, M2 outperforms ViT-b by 1% in accuracy, with only half the parameters. Causal GPT-style models introduce a technical challenge: enforcing causality via masking introduces a quadratic bottleneck. To alleviate this bottleneck, we develop a novel theoretical view of Monarch matrices based on multivariate polynomial evaluation and interpolation, which lets us parameterize M2 to be causal while remaining sub-quadratic. Using this parameterization, M2 matches GPT-style Transformers at 360M parameters in pretraining perplexity on The PILE--showing for the first time that it may be possible to match Transformer quality without attention or MLPs.","sentences":["Machine learning models are increasingly being scaled in both sequence length and model dimension to reach longer contexts and better performance.","However, existing architectures such as Transformers scale quadratically along both these axes.","We ask: are there performant architectures that can scale sub-quadratically along sequence length and model dimension?","We introduce Monarch Mixer (M2), a new architecture that uses the same sub-quadratic primitive along both sequence length and model dimension:","Monarch matrices, a simple class of expressive structured matrices that captures many linear transforms, achieves high hardware efficiency on GPUs, and scales sub-quadratically.","As a proof of concept, we explore the performance of M2 in three domains: non-causal BERT-style language modeling, ViT-style image classification, and causal GPT-style language modeling.","For non-causal BERT-style modeling, M2 matches BERT-base and BERT-large in downstream GLUE quality with up to 27% fewer parameters, and achieves up to 9.1$\\times$ higher throughput at sequence length 4K. On ImageNet, M2 outperforms ViT-b by 1% in accuracy, with only half the parameters.","Causal GPT-style models introduce a technical challenge: enforcing causality via masking introduces a quadratic bottleneck.","To alleviate this bottleneck, we develop a novel theoretical view of Monarch matrices based on multivariate polynomial evaluation and interpolation, which lets us parameterize M2 to be causal while remaining sub-quadratic.","Using this parameterization, M2 matches GPT-style Transformers at 360M parameters in pretraining perplexity on The PILE--showing for the first time that it may be possible to match Transformer quality without attention or MLPs."],"url":"http://arxiv.org/abs/2310.12109v1"}
{"created":"2023-10-18 17:01:32","title":"An Online Learning Theory of Brokerage","abstract":"We investigate brokerage between traders from an online learning perspective. At any round $t$, two traders arrive with their private valuations, and the broker proposes a trading price. Unlike other bilateral trade problems already studied in the online learning literature, we focus on the case where there are no designated buyer and seller roles: each trader will attempt to either buy or sell depending on the current price of the good.   We assume the agents' valuations are drawn i.i.d. from a fixed but unknown distribution. If the distribution admits a density bounded by some constant $M$, then, for any time horizon $T$:   $\\bullet$ If the agents' valuations are revealed after each interaction, we provide an algorithm achieving regret $M \\log T$ and show this rate is optimal, up to constant factors.   $\\bullet$ If only their willingness to sell or buy at the proposed price is revealed after each interaction, we provide an algorithm achieving regret $\\sqrt{M T}$ and show this rate is optimal, up to constant factors.   Finally, if we drop the bounded density assumption, we show that the optimal rate degrades to $\\sqrt{T}$ in the first case, and the problem becomes unlearnable in the second.","sentences":["We investigate brokerage between traders from an online learning perspective.","At any round $t$, two traders arrive with their private valuations, and the broker proposes a trading price.","Unlike other bilateral trade problems already studied in the online learning literature, we focus on the case where there are no designated buyer and seller roles: each trader will attempt to either buy or sell depending on the current price of the good.   ","We assume the agents' valuations are drawn i.i.d.","from a fixed but unknown distribution.","If the distribution admits a density bounded by some constant $M$, then, for any time horizon $T$:   $\\bullet$ If the agents' valuations are revealed after each interaction, we provide an algorithm achieving regret $M \\log T$ and show this rate is optimal, up to constant factors.   ","$\\bullet$ If only their willingness to sell or buy at the proposed price is revealed after each interaction, we provide an algorithm achieving regret $\\sqrt{M T}$ and show this rate is optimal, up to constant factors.   ","Finally, if we drop the bounded density assumption, we show that the optimal rate degrades to $\\sqrt{T}$ in the first case, and the problem becomes unlearnable in the second."],"url":"http://arxiv.org/abs/2310.12107v1"}
{"created":"2023-10-18 16:46:16","title":"Quality Diversity through Human Feedback","abstract":"Reinforcement learning from human feedback (RLHF) has exhibited the potential to enhance the performance of foundation models for qualitative tasks. Despite its promise, its efficacy is often restricted when conceptualized merely as a mechanism to maximize learned reward models of averaged human preferences, especially in areas such as image generation which demand diverse model responses. Meanwhile, quality diversity (QD) algorithms, dedicated to seeking diverse, high-quality solutions, are often constrained by the dependency on manually defined diversity metrics. Interestingly, such limitations of RLHF and QD can be overcome by blending insights from both. This paper introduces Quality Diversity through Human Feedback (QDHF), which employs human feedback for inferring diversity metrics, expanding the applicability of QD algorithms. Empirical results reveal that QDHF outperforms existing QD methods regarding automatic diversity discovery, and matches the search capabilities of QD with human-constructed metrics. Notably, when deployed for a latent space illumination task, QDHF markedly enhances the diversity of images generated by a Diffusion model. The study concludes with an in-depth analysis of QDHF's sample efficiency and the quality of its derived diversity metrics, emphasizing its promise for enhancing exploration and diversity in optimization for complex, open-ended tasks.","sentences":["Reinforcement learning from human feedback (RLHF) has exhibited the potential to enhance the performance of foundation models for qualitative tasks.","Despite its promise, its efficacy is often restricted when conceptualized merely as a mechanism to maximize learned reward models of averaged human preferences, especially in areas such as image generation which demand diverse model responses.","Meanwhile, quality diversity (QD) algorithms, dedicated to seeking diverse, high-quality solutions, are often constrained by the dependency on manually defined diversity metrics.","Interestingly, such limitations of RLHF and QD can be overcome by blending insights from both.","This paper introduces Quality Diversity through Human Feedback (QDHF), which employs human feedback for inferring diversity metrics, expanding the applicability of QD algorithms.","Empirical results reveal that QDHF outperforms existing QD methods regarding automatic diversity discovery, and matches the search capabilities of QD with human-constructed metrics.","Notably, when deployed for a latent space illumination task, QDHF markedly enhances the diversity of images generated by a Diffusion model.","The study concludes with an in-depth analysis of QDHF's sample efficiency and the quality of its derived diversity metrics, emphasizing its promise for enhancing exploration and diversity in optimization for complex, open-ended tasks."],"url":"http://arxiv.org/abs/2310.12103v1"}
{"created":"2023-10-18 16:43:08","title":"Non-Intrusive Adaptation: Input-Centric Parameter-efficient Fine-Tuning for Versatile Multimodal Modeling","abstract":"Large language models (LLMs) and vision language models (VLMs) demonstrate excellent performance on a wide range of tasks by scaling up parameter counts from O(10^9) to O(10^{12}) levels and further beyond. These large scales make it impossible to adapt and deploy fully specialized models given a task of interest. Parameter-efficient fine-tuning (PEFT) emerges as a promising direction to tackle the adaptation and serving challenges for such large models. We categorize PEFT techniques into two types: intrusive and non-intrusive. Intrusive PEFT techniques directly change a model's internal architecture. Though more flexible, they introduce significant complexities for training and serving. Non-intrusive PEFT techniques leave the internal architecture unchanged and only adapt model-external parameters, such as embeddings for input. In this work, we describe AdaLink as a non-intrusive PEFT technique that achieves competitive performance compared to SoTA intrusive PEFT (LoRA) and full model fine-tuning (FT) on various tasks. We evaluate using both text-only and multimodal tasks, with experiments that account for both parameter-count scaling and training regime (with and without instruction tuning).","sentences":["Large language models (LLMs) and vision language models (VLMs) demonstrate excellent performance on a wide range of tasks by scaling up parameter counts from O(10^9) to O(10^{12}) levels and further beyond.","These large scales make it impossible to adapt and deploy fully specialized models given a task of interest.","Parameter-efficient fine-tuning (PEFT) emerges as a promising direction to tackle the adaptation and serving challenges for such large models.","We categorize PEFT techniques into two types: intrusive and non-intrusive.","Intrusive PEFT techniques directly change a model's internal architecture.","Though more flexible, they introduce significant complexities for training and serving.","Non-intrusive PEFT techniques leave the internal architecture unchanged and only adapt model-external parameters, such as embeddings for input.","In this work, we describe AdaLink as a non-intrusive PEFT technique that achieves competitive performance compared to SoTA intrusive PEFT (LoRA) and full model fine-tuning (FT) on various tasks.","We evaluate using both text-only and multimodal tasks, with experiments that account for both parameter-count scaling and training regime (with and without instruction tuning)."],"url":"http://arxiv.org/abs/2310.12100v1"}
{"created":"2023-10-18 16:38:24","title":"Vital Edges for (s,t)-mincut: Efficient Algorithms, Compact Structures, and Optimal Sensitivity Oracle","abstract":"Let G be a directed weighted graph (DiGraph) on n vertices and m edges with source s and sink t. An edge in G is vital if its removal reduces the capacity of (s,t)-mincut. Since the seminal work of Ford and Fulkerson, a long line of work has been done on computing the most vital edge and all vital edges of G. Unfortunately, after 60 years, the existing results are for undirected or unweighted graphs. We present the following result for DiGraph, which solves an open problem stated by Ausiello et al.   1. There is an algorithm that computes all vital edges as well as the most vital edge of G using O(n) maxflow computations.   Vital edges play a crucial role in the design of Sensitivity Oracle (SO) for (s,t)-mincut. For directed graphs, the only existing SO is for unweighted graphs by Picard and Queyranne. We present the first and optimal SO for DiGraph.   2. (a) There is an O(n) space SO that can report in O(1) time the capacity of (s,t)-mincut and (b) an O($n^2$) space SO that can report an (s,t)-mincut in O(n) time after failure/insertion of an edge.   For unweighted graphs, Picard and Queyranne designed an O(m) space DAG that stores and characterizes all mincuts for all vital edges. Conversely, there is a set containing at most n-1 (s,t)-cuts such that at least one mincut for every vital edge belongs to the set. We generalize these results for DiGraph.   3. (a) There is a set containing at most n-1 (s,t)-cuts such that at least one mincut for every vital edge is present in the set. (b) We design two compact structures for storing and characterizing all mincuts for all vital edges, (i) O(m) space DAG for partial characterization and (ii) O(mn) space structure for complete characterization.   To arrive at our results, we develop new techniques, especially a generalization of maxflow-mincut theorem by Ford and Fulkerson, which might be of independent interest.","sentences":["Let G be a directed weighted graph (DiGraph) on n vertices and m edges with source s and sink t. An edge in G is vital if its removal reduces the capacity of (s,t)-mincut.","Since the seminal work of Ford and Fulkerson, a long line of work has been done on computing the most vital edge and all vital edges of G. Unfortunately, after 60 years, the existing results are for undirected or unweighted graphs.","We present the following result for DiGraph, which solves an open problem stated by Ausiello et al.   1.","There is an algorithm that computes all vital edges as well as the most vital edge of G using O(n) maxflow computations.   ","Vital edges play a crucial role in the design of Sensitivity Oracle (SO) for (s,t)-mincut.","For directed graphs, the only existing SO is for unweighted graphs by Picard and Queyranne.","We present the first and optimal SO for DiGraph.   2.","(a) There is an O(n) space SO that can report in O(1) time the capacity of (s,t)-mincut and (b) an O($n^2$) space SO that can report an (s,t)-mincut in O(n) time after failure/insertion of an edge.   ","For unweighted graphs, Picard and Queyranne designed an O(m) space DAG that stores and characterizes all mincuts for all vital edges.","Conversely, there is a set containing at most n-1 (s,t)-cuts such that at least one mincut for every vital edge belongs to the set.","We generalize these results for DiGraph.   3.","(a) There is a set containing at most n-1 (s,t)-cuts such that at least one mincut for every vital edge is present in the set.","(b) We design two compact structures for storing and characterizing all mincuts for all vital edges, (i) O(m) space DAG for partial characterization and (ii) O(mn) space structure for complete characterization.   ","To arrive at our results, we develop new techniques, especially a generalization of maxflow-mincut theorem by Ford and Fulkerson, which might be of independent interest."],"url":"http://arxiv.org/abs/2310.12096v1"}
{"created":"2023-10-18 16:38:23","title":"On the latent dimension of deep autoencoders for reduced order modeling of PDEs parametrized by random fields","abstract":"Deep Learning is having a remarkable impact on the design of Reduced Order Models (ROMs) for Partial Differential Equations (PDEs), where it is exploited as a powerful tool for tackling complex problems for which classical methods might fail. In this respect, deep autoencoders play a fundamental role, as they provide an extremely flexible tool for reducing the dimensionality of a given problem by leveraging on the nonlinear capabilities of neural networks. Indeed, starting from this paradigm, several successful approaches have already been developed, which are here referred to as Deep Learning-based ROMs (DL-ROMs). Nevertheless, when it comes to stochastic problems parameterized by random fields, the current understanding of DL-ROMs is mostly based on empirical evidence: in fact, their theoretical analysis is currently limited to the case of PDEs depending on a finite number of (deterministic) parameters. The purpose of this work is to extend the existing literature by providing some theoretical insights about the use of DL-ROMs in the presence of stochasticity generated by random fields. In particular, we derive explicit error bounds that can guide domain practitioners when choosing the latent dimension of deep autoencoders. We evaluate the practical usefulness of our theory by means of numerical experiments, showing how our analysis can significantly impact the performance of DL-ROMs.","sentences":["Deep Learning is having a remarkable impact on the design of Reduced Order Models (ROMs) for Partial Differential Equations (PDEs), where it is exploited as a powerful tool for tackling complex problems for which classical methods might fail.","In this respect, deep autoencoders play a fundamental role, as they provide an extremely flexible tool for reducing the dimensionality of a given problem by leveraging on the nonlinear capabilities of neural networks.","Indeed, starting from this paradigm, several successful approaches have already been developed, which are here referred to as Deep Learning-based ROMs (DL-ROMs).","Nevertheless, when it comes to stochastic problems parameterized by random fields, the current understanding of DL-ROMs is mostly based on empirical evidence: in fact, their theoretical analysis is currently limited to the case of PDEs depending on a finite number of (deterministic) parameters.","The purpose of this work is to extend the existing literature by providing some theoretical insights about the use of DL-ROMs in the presence of stochasticity generated by random fields.","In particular, we derive explicit error bounds that can guide domain practitioners when choosing the latent dimension of deep autoencoders.","We evaluate the practical usefulness of our theory by means of numerical experiments, showing how our analysis can significantly impact the performance of DL-ROMs."],"url":"http://arxiv.org/abs/2310.12095v1"}
{"created":"2023-10-18 16:37:01","title":"HSTR-Net: Reference Based Video Super-resolution for Aerial Surveillance with Dual Cameras","abstract":"Aerial surveillance requires high spatio-temporal resolution (HSTR) video for more accurate detection and tracking of objects. This is especially true for wide-area surveillance (WAS), where the surveyed region is large and the objects of interest are small. This paper proposes a dual camera system for the generation of HSTR video using reference-based super-resolution (RefSR). One camera captures high spatial resolution low frame rate (HSLF) video while the other captures low spatial resolution high frame rate (LSHF) video simultaneously for the same scene. A novel deep learning architecture is proposed to fuse HSLF and LSHF video feeds and synthesize HSTR video frames at the output. The proposed model combines optical flow estimation and (channel-wise and spatial) attention mechanisms to capture the fine motion and intricate dependencies between frames of the two video feeds. Simulations show that the proposed model provides significant improvement over existing reference-based SR techniques in terms of PSNR and SSIM metrics. The method also exhibits sufficient frames per second (FPS) for WAS when deployed on a power-constrained drone equipped with dual cameras.","sentences":["Aerial surveillance requires high spatio-temporal resolution (HSTR) video for more accurate detection and tracking of objects.","This is especially true for wide-area surveillance (WAS), where the surveyed region is large and the objects of interest are small.","This paper proposes a dual camera system for the generation of HSTR video using reference-based super-resolution (RefSR).","One camera captures high spatial resolution low frame rate (HSLF) video while the other captures low spatial resolution high frame rate (LSHF) video simultaneously for the same scene.","A novel deep learning architecture is proposed to fuse HSLF and LSHF video feeds and synthesize HSTR video frames at the output.","The proposed model combines optical flow estimation and (channel-wise and spatial) attention mechanisms to capture the fine motion and intricate dependencies between frames of the two video feeds.","Simulations show that the proposed model provides significant improvement over existing reference-based SR techniques in terms of PSNR and SSIM metrics.","The method also exhibits sufficient frames per second (FPS) for WAS when deployed on a power-constrained drone equipped with dual cameras."],"url":"http://arxiv.org/abs/2310.12092v1"}
{"created":"2023-10-18 16:27:49","title":"Unveiling the Siren's Song: Towards Reliable Fact-Conflicting Hallucination Detection","abstract":"Large Language Models (LLMs), such as ChatGPT/GPT-4, have garnered widespread attention owing to their myriad of practical applications, yet their adoption has been constrained by issues of fact-conflicting hallucinations across web platforms. The assessment of factuality in text, produced by LLMs, remains inadequately explored, extending not only to the judgment of vanilla facts but also encompassing the evaluation of factual errors emerging in complex inferential tasks like multi-hop, and etc. In response, we introduce FactCHD, a fact-conflicting hallucination detection benchmark meticulously designed for LLMs. Functioning as a pivotal tool in evaluating factuality within \"Query-Respons\" contexts, our benchmark assimilates a large-scale dataset, encapsulating a broad spectrum of factuality patterns, such as vanilla, multi-hops, comparison, and set-operation patterns. A distinctive feature of our benchmark is its incorporation of fact-based chains of evidence, thereby facilitating comprehensive and conducive factual reasoning throughout the assessment process. We evaluate multiple LLMs, demonstrating the effectiveness of the benchmark and current methods fall short of faithfully detecting factual errors. Furthermore, we present TRUTH-TRIANGULATOR that synthesizes reflective considerations by tool-enhanced ChatGPT and LoRA-tuning based on Llama2, aiming to yield more credible detection through the amalgamation of predictive results and evidence. The benchmark dataset and source code will be made available in https://github.com/zjunlp/FactCHD.","sentences":["Large Language Models (LLMs), such as ChatGPT/GPT-4, have garnered widespread attention owing to their myriad of practical applications, yet their adoption has been constrained by issues of fact-conflicting hallucinations across web platforms.","The assessment of factuality in text, produced by LLMs, remains inadequately explored, extending not only to the judgment of vanilla facts but also encompassing the evaluation of factual errors emerging in complex inferential tasks like multi-hop, and etc.","In response, we introduce FactCHD, a fact-conflicting hallucination detection benchmark meticulously designed for LLMs.","Functioning as a pivotal tool in evaluating factuality within \"Query-Respons\" contexts, our benchmark assimilates a large-scale dataset, encapsulating a broad spectrum of factuality patterns, such as vanilla, multi-hops, comparison, and set-operation patterns.","A distinctive feature of our benchmark is its incorporation of fact-based chains of evidence, thereby facilitating comprehensive and conducive factual reasoning throughout the assessment process.","We evaluate multiple LLMs, demonstrating the effectiveness of the benchmark and current methods fall short of faithfully detecting factual errors.","Furthermore, we present TRUTH-TRIANGULATOR that synthesizes reflective considerations by tool-enhanced ChatGPT and LoRA-tuning based on Llama2, aiming to yield more credible detection through the amalgamation of predictive results and evidence.","The benchmark dataset and source code will be made available in https://github.com/zjunlp/FactCHD."],"url":"http://arxiv.org/abs/2310.12086v1"}
{"created":"2023-10-18 16:27:06","title":"On the Benefit of Generative Foundation Models for Human Activity Recognition","abstract":"In human activity recognition (HAR), the limited availability of annotated data presents a significant challenge. Drawing inspiration from the latest advancements in generative AI, including Large Language Models (LLMs) and motion synthesis models, we believe that generative AI can address this data scarcity by autonomously generating virtual IMU data from text descriptions. Beyond this, we spotlight several promising research pathways that could benefit from generative AI for the community, including the generating benchmark datasets, the development of foundational models specific to HAR, the exploration of hierarchical structures within HAR, breaking down complex activities, and applications in health sensing and activity summarization.","sentences":["In human activity recognition (HAR), the limited availability of annotated data presents a significant challenge.","Drawing inspiration from the latest advancements in generative AI, including Large Language Models (LLMs) and motion synthesis models, we believe that generative AI can address this data scarcity by autonomously generating virtual IMU data from text descriptions.","Beyond this, we spotlight several promising research pathways that could benefit from generative AI for the community, including the generating benchmark datasets, the development of foundational models specific to HAR, the exploration of hierarchical structures within HAR, breaking down complex activities, and applications in health sensing and activity summarization."],"url":"http://arxiv.org/abs/2310.12085v1"}
{"created":"2023-10-18 16:24:23","title":"Contributing Components of Metabolic Energy Models to Metabolic Cost Estimations in Gait","abstract":"Objective: As metabolic cost is a primary factor influencing humans' gait, we want to deepen our understanding of metabolic energy expenditure models. Therefore, this paper identifies the parameters and input variables, such as muscle or joint states, that contribute to accurate metabolic cost estimations. Methods: We explored the parameters of four metabolic energy expenditure models in a Monte Carlo sensitivity analysis. Then, we analysed the model parameters by their calculated sensitivity indices, physiological context, and the resulting metabolic rates during the gait cycle. The parameter combination with the highest accuracy in the Monte Carlo simulations represented a quasi-optimized model. In the second step, we investigated the importance of input parameters and variables by analysing the accuracy of neural networks trained with different input features. Results: Power-related parameters were most influential in the sensitivity analysis and the neural network-based feature selection. We observed that the quasi-optimized models produced negative metabolic rates, contradicting muscle physiology. Neural network-based models showed promising abilities but have been unable to match the accuracy of traditional metabolic energy expenditure models. Conclusion: We showed that power-related metabolic energy expenditure model parameters and inputs are most influential during gait. Furthermore, our results suggest that neural network-based metabolic energy expenditure models are viable. However, bigger datasets are required to achieve better accuracy. Significance: As there is a need for more accurate metabolic energy expenditure models, we explored which musculoskeletal parameters are essential when developing a model to estimate metabolic energy.","sentences":["Objective: As metabolic cost is a primary factor influencing humans' gait, we want to deepen our understanding of metabolic energy expenditure models.","Therefore, this paper identifies the parameters and input variables, such as muscle or joint states, that contribute to accurate metabolic cost estimations.","Methods: We explored the parameters of four metabolic energy expenditure models in a Monte Carlo sensitivity analysis.","Then, we analysed the model parameters by their calculated sensitivity indices, physiological context, and the resulting metabolic rates during the gait cycle.","The parameter combination with the highest accuracy in the Monte Carlo simulations represented a quasi-optimized model.","In the second step, we investigated the importance of input parameters and variables by analysing the accuracy of neural networks trained with different input features.","Results: Power-related parameters were most influential in the sensitivity analysis and the neural network-based feature selection.","We observed that the quasi-optimized models produced negative metabolic rates, contradicting muscle physiology.","Neural network-based models showed promising abilities but have been unable to match the accuracy of traditional metabolic energy expenditure models.","Conclusion: We showed that power-related metabolic energy expenditure model parameters and inputs are most influential during gait.","Furthermore, our results suggest that neural network-based metabolic energy expenditure models are viable.","However, bigger datasets are required to achieve better accuracy.","Significance:","As there is a need for more accurate metabolic energy expenditure models, we explored which musculoskeletal parameters are essential when developing a model to estimate metabolic energy."],"url":"http://arxiv.org/abs/2310.12083v1"}
{"created":"2023-10-18 16:16:53","title":"DHOT-GM: Robust Graph Matching Using A Differentiable Hierarchical Optimal Transport Framework","abstract":"Graph matching is one of the most significant graph analytic tasks in practice, which aims to find the node correspondence across different graphs. Most existing approaches rely on adjacency matrices or node embeddings when matching graphs, whose performances are often sub-optimal because of not fully leveraging the multi-modal information hidden in graphs, such as node attributes, subgraph structures, etc. In this study, we propose a novel and effective graph matching method based on a differentiable hierarchical optimal transport (HOT) framework, called DHOT-GM. Essentially, our method represents each graph as a set of relational matrices corresponding to the information of different modalities. Given two graphs, we enumerate all relational matrix pairs and obtain their matching results, and accordingly, infer the node correspondence by the weighted averaging of the matching results. This method can be implemented as computing the HOT distance between the two graphs -- each matching result is an optimal transport plan associated with the Gromov-Wasserstein (GW) distance between two relational matrices, and the weights of all matching results are the elements of an upper-level optimal transport plan defined on the matrix sets. We propose a bi-level optimization algorithm to compute the HOT distance in a differentiable way, making the significance of the relational matrices adjustable. Experiments on various graph matching tasks demonstrate the superiority and robustness of our method compared to state-of-the-art approaches.","sentences":["Graph matching is one of the most significant graph analytic tasks in practice, which aims to find the node correspondence across different graphs.","Most existing approaches rely on adjacency matrices or node embeddings when matching graphs, whose performances are often sub-optimal because of not fully leveraging the multi-modal information hidden in graphs, such as node attributes, subgraph structures, etc.","In this study, we propose a novel and effective graph matching method based on a differentiable hierarchical optimal transport (HOT) framework, called DHOT-GM.","Essentially, our method represents each graph as a set of relational matrices corresponding to the information of different modalities.","Given two graphs, we enumerate all relational matrix pairs and obtain their matching results, and accordingly, infer the node correspondence by the weighted averaging of the matching results.","This method can be implemented as computing the HOT distance between the two graphs -- each matching result is an optimal transport plan associated with the Gromov-Wasserstein (GW) distance between two relational matrices, and the weights of all matching results are the elements of an upper-level optimal transport plan defined on the matrix sets.","We propose a bi-level optimization algorithm to compute the HOT distance in a differentiable way, making the significance of the relational matrices adjustable.","Experiments on various graph matching tasks demonstrate the superiority and robustness of our method compared to state-of-the-art approaches."],"url":"http://arxiv.org/abs/2310.12081v1"}
{"created":"2023-10-18 16:13:35","title":"One-Shot Imitation Learning: A Pose Estimation Perspective","abstract":"In this paper, we study imitation learning under the challenging setting of: (1) only a single demonstration, (2) no further data collection, and (3) no prior task or object knowledge. We show how, with these constraints, imitation learning can be formulated as a combination of trajectory transfer and unseen object pose estimation. To explore this idea, we provide an in-depth study on how state-of-the-art unseen object pose estimators perform for one-shot imitation learning on ten real-world tasks, and we take a deep dive into the effects that camera calibration, pose estimation error, and spatial generalisation have on task success rates. For videos, please visit https://www.robot-learning.uk/pose-estimation-perspective.","sentences":["In this paper, we study imitation learning under the challenging setting of: (1) only a single demonstration, (2) no further data collection, and (3) no prior task or object knowledge.","We show how, with these constraints, imitation learning can be formulated as a combination of trajectory transfer and unseen object pose estimation.","To explore this idea, we provide an in-depth study on how state-of-the-art unseen object pose estimators perform for one-shot imitation learning on ten real-world tasks, and we take a deep dive into the effects that camera calibration, pose estimation error, and spatial generalisation have on task success rates.","For videos, please visit https://www.robot-learning.uk/pose-estimation-perspective."],"url":"http://arxiv.org/abs/2310.12077v1"}
{"created":"2023-10-18 16:13:22","title":"Exploring Fairness in Pre-trained Visual Transformer based Natural and GAN Generated Image Detection Systems and Understanding the Impact of Image Compression in Fairness","abstract":"It is not only sufficient to construct computational models that can accurately classify or detect fake images from real images taken from a camera, but it is also important to ensure whether these computational models are fair enough or produce biased outcomes that can eventually harm certain social groups or cause serious security threats. Exploring fairness in forensic algorithms is an initial step towards correcting these biases. Since visual transformers are recently being widely used in most image classification based tasks due to their capability to produce high accuracies, this study tries to explore bias in the transformer based image forensic algorithms that classify natural and GAN generated images. By procuring a bias evaluation corpora, this study analyzes bias in gender, racial, affective, and intersectional domains using a wide set of individual and pairwise bias evaluation measures. As the generalizability of the algorithms against image compression is an important factor to be considered in forensic tasks, this study also analyzes the role of image compression on model bias. Hence to study the impact of image compression on model bias, a two phase evaluation setting is followed, where a set of experiments is carried out in the uncompressed evaluation setting and the other in the compressed evaluation setting.","sentences":["It is not only sufficient to construct computational models that can accurately classify or detect fake images from real images taken from a camera, but it is also important to ensure whether these computational models are fair enough or produce biased outcomes that can eventually harm certain social groups or cause serious security threats.","Exploring fairness in forensic algorithms is an initial step towards correcting these biases.","Since visual transformers are recently being widely used in most image classification based tasks due to their capability to produce high accuracies, this study tries to explore bias in the transformer based image forensic algorithms that classify natural and GAN generated images.","By procuring a bias evaluation corpora, this study analyzes bias in gender, racial, affective, and intersectional domains using a wide set of individual and pairwise bias evaluation measures.","As the generalizability of the algorithms against image compression is an important factor to be considered in forensic tasks, this study also analyzes the role of image compression on model bias.","Hence to study the impact of image compression on model bias, a two phase evaluation setting is followed, where a set of experiments is carried out in the uncompressed evaluation setting and the other in the compressed evaluation setting."],"url":"http://arxiv.org/abs/2310.12076v1"}
{"created":"2023-10-18 16:10:23","title":"Monte-Carlo Tree Search for Behavior Planning in Autonomous Driving","abstract":"The integration of autonomous vehicles into urban and highway environments necessitates the development of robust and adaptable behavior planning systems. This study presents an innovative approach to address this challenge by utilizing a Monte-Carlo Tree Search (MCTS) based algorithm for autonomous driving behavior planning. The core objective is to leverage the balance between exploration and exploitation inherent in MCTS to facilitate intelligent driving decisions in complex scenarios.   We introduce an MCTS-based algorithm tailored to the specific demands of autonomous driving. This involves the integration of carefully crafted cost functions, encompassing safety, comfort, and passability metrics, into the MCTS framework. The effectiveness of our approach is demonstrated by enabling autonomous vehicles to navigate intricate scenarios, such as intersections, unprotected left turns, cut-ins, and ramps, even under traffic congestion, in real-time.   Qualitative instances illustrate the integration of diverse driving decisions, such as lane changes, acceleration, and deceleration, into the MCTS framework. Moreover, quantitative results, derived from examining the impact of iteration time and look-ahead steps on decision quality and real-time applicability, substantiate the robustness of our approach. This robustness is further underscored by the high success rate of the MCTS algorithm across various scenarios.","sentences":["The integration of autonomous vehicles into urban and highway environments necessitates the development of robust and adaptable behavior planning systems.","This study presents an innovative approach to address this challenge by utilizing a Monte-Carlo Tree Search (MCTS) based algorithm for autonomous driving behavior planning.","The core objective is to leverage the balance between exploration and exploitation inherent in MCTS to facilitate intelligent driving decisions in complex scenarios.   ","We introduce an MCTS-based algorithm tailored to the specific demands of autonomous driving.","This involves the integration of carefully crafted cost functions, encompassing safety, comfort, and passability metrics, into the MCTS framework.","The effectiveness of our approach is demonstrated by enabling autonomous vehicles to navigate intricate scenarios, such as intersections, unprotected left turns, cut-ins, and ramps, even under traffic congestion, in real-time.   ","Qualitative instances illustrate the integration of diverse driving decisions, such as lane changes, acceleration, and deceleration, into the MCTS framework.","Moreover, quantitative results, derived from examining the impact of iteration time and look-ahead steps on decision quality and real-time applicability, substantiate the robustness of our approach.","This robustness is further underscored by the high success rate of the MCTS algorithm across various scenarios."],"url":"http://arxiv.org/abs/2310.12075v1"}
{"created":"2023-10-18 16:07:13","title":"Towards Safer Operations: An Expert-involved Dataset of High-Pressure Gas Incidents for Preventing Future Failures","abstract":"This paper introduces a new IncidentAI dataset for safety prevention. Different from prior corpora that usually contain a single task, our dataset comprises three tasks: named entity recognition, cause-effect extraction, and information retrieval. The dataset is annotated by domain experts who have at least six years of practical experience as high-pressure gas conservation managers. We validate the contribution of the dataset in the scenario of safety prevention. Preliminary results on the three tasks show that NLP techniques are beneficial for analyzing incident reports to prevent future failures. The dataset facilitates future research in NLP and incident management communities. The access to the dataset is also provided (the IncidentAI dataset is available at: https://github.com/Cinnamon/incident-ai-dataset).","sentences":["This paper introduces a new IncidentAI dataset for safety prevention.","Different from prior corpora that usually contain a single task, our dataset comprises three tasks: named entity recognition, cause-effect extraction, and information retrieval.","The dataset is annotated by domain experts who have at least six years of practical experience as high-pressure gas conservation managers.","We validate the contribution of the dataset in the scenario of safety prevention.","Preliminary results on the three tasks show that NLP techniques are beneficial for analyzing incident reports to prevent future failures.","The dataset facilitates future research in NLP and incident management communities.","The access to the dataset is also provided (the IncidentAI dataset is available at: https://github.com/Cinnamon/incident-ai-dataset)."],"url":"http://arxiv.org/abs/2310.12074v1"}
{"created":"2023-10-18 16:07:01","title":"SPEED: Speculative Pipelined Execution for Efficient Decoding","abstract":"Generative Large Language Models (LLMs) based on the Transformer architecture have recently emerged as a dominant foundation model for a wide range of Natural Language Processing tasks. Nevertheless, their application in real-time scenarios has been highly restricted due to the significant inference latency associated with these models. This is particularly pronounced due to the autoregressive nature of generative LLM inference, where tokens are generated sequentially since each token depends on all previous output tokens. It is therefore challenging to achieve any token-level parallelism, making inference extremely memory-bound. In this work, we propose SPEED, which improves inference efficiency by speculatively executing multiple future tokens in parallel with the current token using predicted values based on early-layer hidden states. For Transformer decoders that employ parameter sharing, the memory operations for the tokens executing in parallel can be amortized, which allows us to accelerate generative LLM inference. We demonstrate the efficiency of our method in terms of latency reduction relative to model accuracy and demonstrate how speculation allows for training deeper decoders with parameter sharing with minimal runtime overhead.","sentences":["Generative Large Language Models (LLMs) based on the Transformer architecture have recently emerged as a dominant foundation model for a wide range of Natural Language Processing tasks.","Nevertheless, their application in real-time scenarios has been highly restricted due to the significant inference latency associated with these models.","This is particularly pronounced due to the autoregressive nature of generative LLM inference, where tokens are generated sequentially since each token depends on all previous output tokens.","It is therefore challenging to achieve any token-level parallelism, making inference extremely memory-bound.","In this work, we propose SPEED, which improves inference efficiency by speculatively executing multiple future tokens in parallel with the current token using predicted values based on early-layer hidden states.","For Transformer decoders that employ parameter sharing, the memory operations for the tokens executing in parallel can be amortized, which allows us to accelerate generative LLM inference.","We demonstrate the efficiency of our method in terms of latency reduction relative to model accuracy and demonstrate how speculation allows for training deeper decoders with parameter sharing with minimal runtime overhead."],"url":"http://arxiv.org/abs/2310.12072v1"}
{"created":"2023-10-18 15:57:36","title":"A Persuasive Approach to Combating Misinformation","abstract":"We propose using Bayesian Persuasion as a tool for social media platforms to combat the spread of online misinformation. As platforms can predict the popularity and misinformation features of to-be-shared posts, and users are motivated to only share popular content, platforms can strategically reveal this informational advantage to persuade users to not share misinformed content. Our work mathematically characterizes the optimal information design scheme and the resulting utility when observations are not perfectly observed but arise from an imperfect classifier. Framing the optimization problem as a linear program, we give sufficient and necessary conditions on the classifier accuracy to ensure platform utility under optimal signaling is monotonically increasing and continuous. We next consider this interaction under a performative model, wherein platform intervention through signaling affects the content distribution in the future. We fully characterize the convergence and stability of optimal signaling under this performative process. Lastly, the broader scope of using information design to combat misinformation is discussed throughout.","sentences":["We propose using Bayesian Persuasion as a tool for social media platforms to combat the spread of online misinformation.","As platforms can predict the popularity and misinformation features of to-be-shared posts, and users are motivated to only share popular content, platforms can strategically reveal this informational advantage to persuade users to not share misinformed content.","Our work mathematically characterizes the optimal information design scheme and the resulting utility when observations are not perfectly observed but arise from an imperfect classifier.","Framing the optimization problem as a linear program, we give sufficient and necessary conditions on the classifier accuracy to ensure platform utility under optimal signaling is monotonically increasing and continuous.","We next consider this interaction under a performative model, wherein platform intervention through signaling affects the content distribution in the future.","We fully characterize the convergence and stability of optimal signaling under this performative process.","Lastly, the broader scope of using information design to combat misinformation is discussed throughout."],"url":"http://arxiv.org/abs/2310.12065v1"}
{"created":"2023-10-18 15:53:45","title":"Code Book for the Annotation of Diverse Cross-Document Coreference of Entities in News Articles","abstract":"This paper presents a scheme for annotating coreference across news articles, extending beyond traditional identity relations by also considering near-identity and bridging relations. It includes a precise description of how to set up Inception, a respective annotation tool, how to annotate entities in news articles, connect them with diverse coreferential relations, and link them across documents to Wikidata's global knowledge graph. This multi-layered annotation approach is discussed in the context of the problem of media bias. Our main contribution lies in providing a methodology for creating a diverse cross-document coreference corpus which can be applied to the analysis of media bias by word-choice and labelling.","sentences":["This paper presents a scheme for annotating coreference across news articles, extending beyond traditional identity relations by also considering near-identity and bridging relations.","It includes a precise description of how to set up Inception, a respective annotation tool, how to annotate entities in news articles, connect them with diverse coreferential relations, and link them across documents to Wikidata's global knowledge graph.","This multi-layered annotation approach is discussed in the context of the problem of media bias.","Our main contribution lies in providing a methodology for creating a diverse cross-document coreference corpus which can be applied to the analysis of media bias by word-choice and labelling."],"url":"http://arxiv.org/abs/2310.12064v1"}
{"created":"2023-10-18 15:53:20","title":"Black-Box Training Data Identification in GANs via Detector Networks","abstract":"Since their inception Generative Adversarial Networks (GANs) have been popular generative models across images, audio, video, and tabular data. In this paper we study whether given access to a trained GAN, as well as fresh samples from the underlying distribution, if it is possible for an attacker to efficiently identify if a given point is a member of the GAN's training data. This is of interest for both reasons related to copyright, where a user may want to determine if their copyrighted data has been used to train a GAN, and in the study of data privacy, where the ability to detect training set membership is known as a membership inference attack. Unlike the majority of prior work this paper investigates the privacy implications of using GANs in black-box settings, where the attack only has access to samples from the generator, rather than access to the discriminator as well. We introduce a suite of membership inference attacks against GANs in the black-box setting and evaluate our attacks on image GANs trained on the CIFAR10 dataset and tabular GANs trained on genomic data. Our most successful attack, called The Detector, involve training a second network to score samples based on their likelihood of being generated by the GAN, as opposed to a fresh sample from the distribution. We prove under a simple model of the generator that the detector is an approximately optimal membership inference attack. Across a wide range of tabular and image datasets, attacks, and GAN architectures, we find that adversaries can orchestrate non-trivial privacy attacks when provided with access to samples from the generator. At the same time, the attack success achievable against GANs still appears to be lower compared to other generative and discriminative models; this leaves the intriguing open question of whether GANs are in fact more private, or if it is a matter of developing stronger attacks.","sentences":["Since their inception Generative Adversarial Networks (GANs) have been popular generative models across images, audio, video, and tabular data.","In this paper we study whether given access to a trained GAN, as well as fresh samples from the underlying distribution, if it is possible for an attacker to efficiently identify if a given point is a member of the GAN's training data.","This is of interest for both reasons related to copyright, where a user may want to determine if their copyrighted data has been used to train a GAN, and in the study of data privacy, where the ability to detect training set membership is known as a membership inference attack.","Unlike the majority of prior work this paper investigates the privacy implications of using GANs in black-box settings, where the attack only has access to samples from the generator, rather than access to the discriminator as well.","We introduce a suite of membership inference attacks against GANs in the black-box setting and evaluate our attacks on image GANs trained on the CIFAR10 dataset and tabular GANs trained on genomic data.","Our most successful attack, called The Detector, involve training a second network to score samples based on their likelihood of being generated by the GAN, as opposed to a fresh sample from the distribution.","We prove under a simple model of the generator that the detector is an approximately optimal membership inference attack.","Across a wide range of tabular and image datasets, attacks, and GAN architectures, we find that adversaries can orchestrate non-trivial privacy attacks when provided with access to samples from the generator.","At the same time, the attack success achievable against GANs still appears to be lower compared to other generative and discriminative models; this leaves the intriguing open question of whether GANs are in fact more private, or if it is a matter of developing stronger attacks."],"url":"http://arxiv.org/abs/2310.12063v1"}
{"created":"2023-10-18 15:50:48","title":"On the use of Vision-Language models for Visual Sentiment Analysis: a study on CLIP","abstract":"This work presents a study on how to exploit the CLIP embedding space to perform Visual Sentiment Analysis. We experiment with two architectures built on top of the CLIP embedding space, which we denote by CLIP-E. We train the CLIP-E models with WEBEmo, the largest publicly available and manually labeled benchmark for Visual Sentiment Analysis, and perform two sets of experiments. First, we test on WEBEmo and compare the CLIP-E architectures with state-of-the-art (SOTA) models and with CLIP Zero-Shot. Second, we perform cross dataset evaluation, and test the CLIP-E architectures trained with WEBEmo on other Visual Sentiment Analysis benchmarks. Our results show that the CLIP-E approaches outperform SOTA models in WEBEmo fine grained categorization, and they also generalize better when tested on datasets that have not been seen during training. Interestingly, we observed that for the FI dataset, CLIP Zero-Shot produces better accuracies than SOTA models and CLIP-E trained on WEBEmo. These results motivate several questions that we discuss in this paper, such as how we should design new benchmarks and evaluate Visual Sentiment Analysis, and whether we should keep designing tailored Deep Learning models for Visual Sentiment Analysis or focus our efforts on better using the knowledge encoded in large vision-language models such as CLIP for this task.","sentences":["This work presents a study on how to exploit the CLIP embedding space to perform Visual Sentiment Analysis.","We experiment with two architectures built on top of the CLIP embedding space, which we denote by CLIP-E. We train the CLIP-E models with WEBEmo, the largest publicly available and manually labeled benchmark for Visual Sentiment Analysis, and perform two sets of experiments.","First, we test on WEBEmo and compare the CLIP-E architectures with state-of-the-art (SOTA) models and with CLIP Zero-Shot.","Second, we perform cross dataset evaluation, and test the CLIP-E architectures trained with WEBEmo on other Visual Sentiment Analysis benchmarks.","Our results show that the CLIP-E approaches outperform SOTA models in WEBEmo fine grained categorization, and they also generalize better when tested on datasets that have not been seen during training.","Interestingly, we observed that for the FI dataset, CLIP Zero-Shot produces better accuracies than SOTA models and CLIP-E trained on WEBEmo.","These results motivate several questions that we discuss in this paper, such as how we should design new benchmarks and evaluate Visual Sentiment Analysis, and whether we should keep designing tailored Deep Learning models for Visual Sentiment Analysis or focus our efforts on better using the knowledge encoded in large vision-language models such as CLIP for this task."],"url":"http://arxiv.org/abs/2310.12062v1"}
{"created":"2023-10-18 15:49:46","title":"Robust Class-Conditional Distribution Alignment for Partial Domain Adaptation","abstract":"Unwanted samples from private source categories in the learning objective of a partial domain adaptation setup can lead to negative transfer and reduce classification performance. Existing methods, such as re-weighting or aggregating target predictions, are vulnerable to this issue, especially during initial training stages, and do not adequately address overlapping categorical distributions. We propose a solution to overcome these limitations by exploring beyond the first-order moments for robust alignment of categorical distributions. We employ objectives that optimize the intra and inter-class distributions in a domain-invariant fashion and design a robust pseudo-labeling for efficient target supervision. Our approach incorporates a complement entropy objective module to reduce classification uncertainty and flatten incorrect category predictions. The experimental findings and ablation analysis of the proposed modules demonstrate the superior performance of our proposed model compared to benchmarks.","sentences":["Unwanted samples from private source categories in the learning objective of a partial domain adaptation setup can lead to negative transfer and reduce classification performance.","Existing methods, such as re-weighting or aggregating target predictions, are vulnerable to this issue, especially during initial training stages, and do not adequately address overlapping categorical distributions.","We propose a solution to overcome these limitations by exploring beyond the first-order moments for robust alignment of categorical distributions.","We employ objectives that optimize the intra and inter-class distributions in a domain-invariant fashion and design a robust pseudo-labeling for efficient target supervision.","Our approach incorporates a complement entropy objective module to reduce classification uncertainty and flatten incorrect category predictions.","The experimental findings and ablation analysis of the proposed modules demonstrate the superior performance of our proposed model compared to benchmarks."],"url":"http://arxiv.org/abs/2310.12060v1"}
{"created":"2023-10-18 15:48:07","title":"Evaluating the Symbol Binding Ability of Large Language Models for Multiple-Choice Questions in Vietnamese General Education","abstract":"In this paper, we evaluate the ability of large language models (LLMs) to perform multiple choice symbol binding (MCSB) for multiple choice question answering (MCQA) tasks in zero-shot, one-shot, and few-shot settings. We focus on Vietnamese, with fewer challenging MCQA datasets than in English. The two existing datasets, ViMMRC 1.0 and ViMMRC 2.0, focus on literature. Recent research in Vietnamese natural language processing (NLP) has focused on the Vietnamese National High School Graduation Examination (VNHSGE) from 2019 to 2023 to evaluate ChatGPT. However, these studies have mainly focused on how ChatGPT solves the VNHSGE step by step. We aim to create a novel and high-quality dataset by providing structured guidelines for typing LaTeX formulas for mathematics, physics, chemistry, and biology. This dataset can be used to evaluate the MCSB ability of LLMs and smaller language models (LMs) because it is typed in a strict LaTeX style. We focus on predicting the character (A, B, C, or D) that is the most likely answer to a question, given the context of the question. Our evaluation of six well-known LLMs, namely BLOOMZ-7.1B-MT, LLaMA-2-7B, LLaMA-2-70B, GPT-3, GPT-3.5, and GPT-4.0, on the ViMMRC 1.0 and ViMMRC 2.0 benchmarks and our proposed dataset shows promising results on the MCSB ability of LLMs for Vietnamese. The dataset is available for research purposes only.","sentences":["In this paper, we evaluate the ability of large language models (LLMs) to perform multiple choice symbol binding (MCSB) for multiple choice question answering (MCQA) tasks in zero-shot, one-shot, and few-shot settings.","We focus on Vietnamese, with fewer challenging MCQA datasets than in English.","The two existing datasets, ViMMRC 1.0 and ViMMRC 2.0, focus on literature.","Recent research in Vietnamese natural language processing (NLP) has focused on the Vietnamese National High School Graduation Examination (VNHSGE) from 2019 to 2023 to evaluate ChatGPT.","However, these studies have mainly focused on how ChatGPT solves the VNHSGE step by step.","We aim to create a novel and high-quality dataset by providing structured guidelines for typing LaTeX formulas for mathematics, physics, chemistry, and biology.","This dataset can be used to evaluate the MCSB ability of LLMs and smaller language models (LMs) because it is typed in a strict LaTeX style.","We focus on predicting the character (A, B, C, or D) that is the most likely answer to a question, given the context of the question.","Our evaluation of six well-known LLMs, namely BLOOMZ-7.1B-MT, LLaMA-2-7B, LLaMA-2-70B, GPT-3, GPT-3.5, and GPT-4.0, on the ViMMRC 1.0 and ViMMRC 2.0 benchmarks and our proposed dataset shows promising results on the MCSB ability of LLMs for Vietnamese.","The dataset is available for research purposes only."],"url":"http://arxiv.org/abs/2310.12059v1"}
{"created":"2023-10-18 15:46:12","title":"HIFuzz: Human Interaction Fuzzing for small Unmanned Aerial Vehicles","abstract":"Small Unmanned Aerial Systems (sUAS) must meet rigorous safety standards when deployed in high-stress emergency response scenarios. However, tests that execute perfectly in simulation can fail dramatically in real-world environments. Fuzz testing can be used to increase system robustness by providing malformed input data aimed at triggering failure cases. In this paper, we apply fuzzing to support human interaction testing. Initial tests are run in simulation to provide broad coverage of the input space in a safe environment; however, they lack the fidelity of real-world tests. Field tests provide higher fidelity but can result in costly or dangerous crashes. We, therefore, propose and demonstrate HiFuzz, which executes large numbers of fuzz tests in simulation and then down-selects tests for deployment in human-in-the-loop simulations and safety-aware physical field tests. We apply \\hf to a multi-sUAS system and show that each test level serves a unique purpose in identifying known and unknown failures associated with human interactions.","sentences":["Small Unmanned Aerial Systems (sUAS) must meet rigorous safety standards when deployed in high-stress emergency response scenarios.","However, tests that execute perfectly in simulation can fail dramatically in real-world environments.","Fuzz testing can be used to increase system robustness by providing malformed input data aimed at triggering failure cases.","In this paper, we apply fuzzing to support human interaction testing.","Initial tests are run in simulation to provide broad coverage of the input space in a safe environment; however, they lack the fidelity of real-world tests.","Field tests provide higher fidelity but can result in costly or dangerous crashes.","We, therefore, propose and demonstrate HiFuzz, which executes large numbers of fuzz tests in simulation and then down-selects tests for deployment in human-in-the-loop simulations and safety-aware physical field tests.","We apply \\hf to a multi-sUAS system and show that each test level serves a unique purpose in identifying known and unknown failures associated with human interactions."],"url":"http://arxiv.org/abs/2310.12058v1"}
{"created":"2023-10-18 15:42:53","title":"Understanding Reward Ambiguity Through Optimal Transport Theory in Inverse Reinforcement Learning","abstract":"In inverse reinforcement learning (IRL), the central objective is to infer underlying reward functions from observed expert behaviors in a way that not only explains the given data but also generalizes to unseen scenarios. This ensures robustness against reward ambiguity where multiple reward functions can equally explain the same expert behaviors. While significant efforts have been made in addressing this issue, current methods often face challenges with high-dimensional problems and lack a geometric foundation. This paper harnesses the optimal transport (OT) theory to provide a fresh perspective on these challenges. By utilizing the Wasserstein distance from OT, we establish a geometric framework that allows for quantifying reward ambiguity and identifying a central representation or centroid of reward functions. These insights pave the way for robust IRL methodologies anchored in geometric interpretations, offering a structured approach to tackle reward ambiguity in high-dimensional settings.","sentences":["In inverse reinforcement learning (IRL), the central objective is to infer underlying reward functions from observed expert behaviors in a way that not only explains the given data but also generalizes to unseen scenarios.","This ensures robustness against reward ambiguity where multiple reward functions can equally explain the same expert behaviors.","While significant efforts have been made in addressing this issue, current methods often face challenges with high-dimensional problems and lack a geometric foundation.","This paper harnesses the optimal transport (OT) theory to provide a fresh perspective on these challenges.","By utilizing the Wasserstein distance from OT, we establish a geometric framework that allows for quantifying reward ambiguity and identifying a central representation or centroid of reward functions.","These insights pave the way for robust IRL methodologies anchored in geometric interpretations, offering a structured approach to tackle reward ambiguity in high-dimensional settings."],"url":"http://arxiv.org/abs/2310.12055v1"}
{"created":"2023-10-18 15:40:57","title":"Simultaneous Learning of Contact and Continuous Dynamics","abstract":"Robotic manipulation can greatly benefit from the data efficiency, robustness, and predictability of model-based methods if robots can quickly generate models of novel objects they encounter. This is especially difficult when effects like complex joint friction lack clear first-principles models and are usually ignored by physics simulators. Further, numerically-stiff contact dynamics can make common model-building approaches struggle. We propose a method to simultaneously learn contact and continuous dynamics of a novel, possibly multi-link object by observing its motion through contact-rich trajectories. We formulate a system identification process with a loss that infers unmeasured contact forces, penalizing their violation of physical constraints and laws of motion given current model parameters. Our loss is unlike prediction-based losses used in differentiable simulation. Using a new dataset of real articulated object trajectories and an existing cube toss dataset, our method outperforms differentiable simulation and end-to-end alternatives with more data efficiency. See our project page for code, datasets, and media: https://sites.google.com/view/continuous-contact-nets/home","sentences":["Robotic manipulation can greatly benefit from the data efficiency, robustness, and predictability of model-based methods if robots can quickly generate models of novel objects they encounter.","This is especially difficult when effects like complex joint friction lack clear first-principles models and are usually ignored by physics simulators.","Further, numerically-stiff contact dynamics can make common model-building approaches struggle.","We propose a method to simultaneously learn contact and continuous dynamics of a novel, possibly multi-link object by observing its motion through contact-rich trajectories.","We formulate a system identification process with a loss that infers unmeasured contact forces, penalizing their violation of physical constraints and laws of motion given current model parameters.","Our loss is unlike prediction-based losses used in differentiable simulation.","Using a new dataset of real articulated object trajectories and an existing cube toss dataset, our method outperforms differentiable simulation and end-to-end alternatives with more data efficiency.","See our project page for code, datasets, and media: https://sites.google.com/view/continuous-contact-nets/home"],"url":"http://arxiv.org/abs/2310.12054v1"}
{"created":"2023-10-18 15:37:19","title":"Machine Learning-based Nutrient Application's Timeline Recommendation for Smart Agriculture: A Large-Scale Data Mining Approach","abstract":"This study addresses the vital role of data analytics in monitoring fertiliser applications in crop cultivation. Inaccurate fertiliser application decisions can lead to costly consequences, hinder food production, and cause environmental harm. We propose a solution to predict nutrient application by determining required fertiliser quantities for an entire season. The proposed solution recommends adjusting fertiliser amounts based on weather conditions and soil characteristics to promote cost-effective and environmentally friendly agriculture. The collected dataset is high-dimensional and heterogeneous. Our research examines large-scale heterogeneous datasets in the context of the decision-making process, encompassing data collection and analysis. We also study the impact of fertiliser applications combined with weather data on crop yield, using the winter wheat crop as a case study. By understanding local contextual and geographic factors, we aspire to stabilise or even reduce the demand for agricultural nutrients while enhancing crop development. The proposed approach is proven to be efficient and scalable, as it is validated using a real-world and large dataset.","sentences":["This study addresses the vital role of data analytics in monitoring fertiliser applications in crop cultivation.","Inaccurate fertiliser application decisions can lead to costly consequences, hinder food production, and cause environmental harm.","We propose a solution to predict nutrient application by determining required fertiliser quantities for an entire season.","The proposed solution recommends adjusting fertiliser amounts based on weather conditions and soil characteristics to promote cost-effective and environmentally friendly agriculture.","The collected dataset is high-dimensional and heterogeneous.","Our research examines large-scale heterogeneous datasets in the context of the decision-making process, encompassing data collection and analysis.","We also study the impact of fertiliser applications combined with weather data on crop yield, using the winter wheat crop as a case study.","By understanding local contextual and geographic factors, we aspire to stabilise or even reduce the demand for agricultural nutrients while enhancing crop development.","The proposed approach is proven to be efficient and scalable, as it is validated using a real-world and large dataset."],"url":"http://arxiv.org/abs/2310.12052v1"}
{"created":"2023-10-18 15:36:20","title":"Simpler and Higher Lower Bounds for Shortcut Sets","abstract":"We provide a variety of lower bounds for the well-known shortcut set problem: how much can one decrease the diameter of a directed graph on $n$ vertices and $m$ edges by adding $O(n)$ or $O(m)$ of shortcuts from the transitive closure of the graph. Our results are based on a vast simplification of the recent construction of Bodwin and Hoppenworth [FOCS 2023] which was used to show an $\\widetilde{\\Omega}(n^{1/4})$ lower bound for the $O(n)$-sized shortcut set problem. We highlight that our simplification completely removes the use of the convex sets by B\\'ar\\'any and Larman [Math. Ann. 1998] used in all previous lower bound constructions. Our simplification also removes the need for randomness and further removes some log factors. This allows us to generalize the construction to higher dimensions, which in turn can be used to show the following results. For $O(m)$-sized shortcut sets, we show an $\\Omega(n^{1/5})$ lower bound, improving on the previous best $\\Omega(n^{1/8})$ lower bound. For all $\\varepsilon > 0$, we show that there exists a $\\delta > 0$ such that there are $n$-vertex $O(n)$-edge graphs $G$ where adding any shortcut set of size $O(n^{2-\\varepsilon})$ keeps the diameter of $G$ at $\\Omega(n^\\delta)$. This improves the sparsity of the constructed graph compared to a known similar result by Hesse [SODA 2003].   We also consider the sourcewise setting for shortcut sets: given a graph $G=(V,E)$, a set $S\\subseteq V$, how much can we decrease the sourcewise diameter of $G$, $\\max_{(s, v) \\in S \\times V, \\text{dist}(s, v) < \\infty} \\text{dist}(s,v)$ by adding a set of edges $H$ from the transitive closure of $G$? We show that for any integer $d \\ge 2$, there exists a graph $G=(V, E)$ on $n$ vertices and $S \\subseteq V$ with $|S| = \\widetilde{\\Theta}(n^{3/(d+3)})$, such that when adding $O(n)$ or $O(m)$ shortcuts, the sourcewise diameter is $\\widetilde{\\Omega}(|S|^{1/3})$.","sentences":["We provide a variety of lower bounds for the well-known shortcut set problem: how much can one decrease the diameter of a directed graph on $n$ vertices and $m$ edges by adding $O(n)$ or $O(m)$ of shortcuts from the transitive closure of the graph.","Our results are based on a vast simplification of the recent construction of Bodwin and Hoppenworth [FOCS 2023] which was used to show an $\\widetilde{\\Omega}(n^{1/4})$ lower bound for the $O(n)$-sized shortcut set problem.","We highlight that our simplification completely removes the use of the convex sets by B\\'ar\\'any and Larman [Math.","Ann. 1998] used in all previous lower bound constructions.","Our simplification also removes the need for randomness and further removes some log factors.","This allows us to generalize the construction to higher dimensions, which in turn can be used to show the following results.","For $O(m)$-sized shortcut sets, we show an $\\Omega(n^{1/5})$ lower bound, improving on the previous best $\\Omega(n^{1/8})$ lower bound.","For all $\\varepsilon > 0$, we show that there exists a $\\delta > 0$ such that there are $n$-vertex $O(n)$-edge graphs $G$ where adding any shortcut set of size $O(n^{2-\\varepsilon})$ keeps the diameter of $G$ at $\\Omega(n^\\delta)$. This improves the sparsity of the constructed graph compared to a known similar result by Hesse","[SODA 2003].   ","We also consider the sourcewise setting for shortcut sets: given a graph $G=(V,E)$, a set $S\\subseteq V$, how much can we decrease the sourcewise diameter of $G$, $\\max_{(s, v) \\in S \\times V, \\text{dist}(s, v) <","\\infty} \\text{dist}(s,v)$ by adding a set of edges $H$ from the transitive closure of $G$?","We show that for any integer $d \\ge 2$, there exists a graph $G=(V, E)$ on $n$ vertices and $S \\subseteq V$ with $|S| = \\widetilde{\\Theta}(n^{3/(d+3)})$, such that when adding $O(n)$ or $O(m)$ shortcuts, the sourcewise diameter is $\\widetilde{\\Omega}(|S|^{1/3})$."],"url":"http://arxiv.org/abs/2310.12051v1"}
{"created":"2023-10-18 15:34:37","title":"Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models","abstract":"Existing text scaling methods often require a large corpus, struggle with short texts, or require labeled data. We develop a text scaling method that leverages the pattern recognition capabilities of generative large language models (LLMs). Specifically, we propose concept-guided chain-of-thought (CGCoT), which uses prompts designed to summarize ideas and identify target parties in texts to generate concept-specific breakdowns, in many ways similar to guidance for human coder content analysis. CGCoT effectively shifts pairwise text comparisons from a reasoning problem to a pattern recognition problem. We then pairwise compare concept-specific breakdowns using an LLM. We use the results of these pairwise comparisons to estimate a scale using the Bradley-Terry model. We use this approach to scale affective speech on Twitter. Our measures correlate more strongly with human judgments than alternative approaches like Wordfish. Besides a small set of pilot data to develop the CGCoT prompts, our measures require no additional labeled data and produce binary predictions comparable to a RoBERTa-Large model fine-tuned on thousands of human-labeled tweets. We demonstrate how combining substantive knowledge with LLMs can create state-of-the-art measures of abstract concepts.","sentences":["Existing text scaling methods often require a large corpus, struggle with short texts, or require labeled data.","We develop a text scaling method that leverages the pattern recognition capabilities of generative large language models (LLMs).","Specifically, we propose concept-guided chain-of-thought (CGCoT), which uses prompts designed to summarize ideas and identify target parties in texts to generate concept-specific breakdowns, in many ways similar to guidance for human coder content analysis.","CGCoT effectively shifts pairwise text comparisons from a reasoning problem to a pattern recognition problem.","We then pairwise compare concept-specific breakdowns using an LLM.","We use the results of these pairwise comparisons to estimate a scale using the Bradley-Terry model.","We use this approach to scale affective speech on Twitter.","Our measures correlate more strongly with human judgments than alternative approaches like Wordfish.","Besides a small set of pilot data to develop the CGCoT prompts, our measures require no additional labeled data and produce binary predictions comparable to a RoBERTa-Large model fine-tuned on thousands of human-labeled tweets.","We demonstrate how combining substantive knowledge with LLMs can create state-of-the-art measures of abstract concepts."],"url":"http://arxiv.org/abs/2310.12049v1"}
{"created":"2023-10-18 15:29:14","title":"TeslaCharge: Smart Robotic Charger Driven by Impedance Control and Human Haptic Patterns","abstract":"The growing demand for electric vehicles requires the development of automated car charging methods. At the moment, the process of charging an electric car is completely manual, and that requires physical effort to accomplish the task, which is not suitable for people with disabilities. Typically, the effort in the research is focused on detecting the position and orientation of the socket, which resulted in a relatively high accuracy, $\\pm 5 \\: mm $ and $\\pm 10^o$. However, this accuracy is not enough to complete the charging process. In this work, we focus on designing a novel methodology for robust robotic plug-in and plug-out based on human haptics, to overcome the error in the position and orientation of the socket. Participants were invited to perform the charging task, and their cognitive capabilities were recognized by measuring the applied forces along with the movement of the charger. Three controllers were designed based on impedance control to mimic the human patterns of charging an electric car. The recorded data from humans were used to calibrate the parameters of the impedance controllers: inertia $M_d$, damping $D_d$, and stiffness $K_d$. A robotic validation was performed, where the designed controllers were applied to the robot UR10. Using the proposed controllers and the human kinesthetic data, it was possible to successfully automate the operation of charging an electric car.","sentences":["The growing demand for electric vehicles requires the development of automated car charging methods.","At the moment, the process of charging an electric car is completely manual, and that requires physical effort to accomplish the task, which is not suitable for people with disabilities.","Typically, the effort in the research is focused on detecting the position and orientation of the socket, which resulted in a relatively high accuracy, $\\pm 5 \\: mm $ and $\\pm 10^o$. However, this accuracy is not enough to complete the charging process.","In this work, we focus on designing a novel methodology for robust robotic plug-in and plug-out based on human haptics, to overcome the error in the position and orientation of the socket.","Participants were invited to perform the charging task, and their cognitive capabilities were recognized by measuring the applied forces along with the movement of the charger.","Three controllers were designed based on impedance control to mimic the human patterns of charging an electric car.","The recorded data from humans were used to calibrate the parameters of the impedance controllers: inertia $M_d$, damping $D_d$, and stiffness $K_d$. A robotic validation was performed, where the designed controllers were applied to the robot UR10.","Using the proposed controllers and the human kinesthetic data, it was possible to successfully automate the operation of charging an electric car."],"url":"http://arxiv.org/abs/2310.12044v1"}
{"created":"2023-10-18 15:24:37","title":"Ordered Reliability Direct Error Pattern Testing Decoding Algorithm","abstract":"We introduce a novel universal soft-decision decoding algorithm for binary block codes called ordered reliability direct error pattern testing (ORDEPT). Our results, obtained for a variety of popular short high-rate codes, demonstrate that ORDEPT outperforms state-of-the-art decoding algorithms of comparable complexity such as ordered reliability bits guessing random additive noise decoding (ORBGRAND) in terms of the decoding error probability and latency. The improvements carry on to the iterative decoding of product codes and convolutional product-like codes, where we present a new adaptive decoding algorithm and demonstrate the ability of ORDEPT to efficiently find multiple candidate codewords to produce soft output.","sentences":["We introduce a novel universal soft-decision decoding algorithm for binary block codes called ordered reliability direct error pattern testing (ORDEPT).","Our results, obtained for a variety of popular short high-rate codes, demonstrate that ORDEPT outperforms state-of-the-art decoding algorithms of comparable complexity such as ordered reliability bits guessing random additive noise decoding (ORBGRAND) in terms of the decoding error probability and latency.","The improvements carry on to the iterative decoding of product codes and convolutional product-like codes, where we present a new adaptive decoding algorithm and demonstrate the ability of ORDEPT to efficiently find multiple candidate codewords to produce soft output."],"url":"http://arxiv.org/abs/2310.12039v1"}
{"created":"2023-10-18 15:21:41","title":"Envisioning the Future of Cyber Security in Post-Quantum Era: A Survey on PQ Standardization, Applications, Challenges and Opportunities","abstract":"The rise of quantum computers exposes vulnerabilities in current public key cryptographic protocols, necessitating the development of secure post-quantum (PQ) schemes. Hence, we conduct a comprehensive study on various PQ approaches, covering the constructional design, structural vulnerabilities, and offer security assessments, implementation evaluations, and a particular focus on side-channel attacks. We analyze global standardization processes, evaluate their metrics in relation to real-world applications, and primarily focus on standardized PQ schemes, selected additional signature competition candidates, and PQ-secure cutting-edge schemes beyond standardization. Finally, we present visions and potential future directions for a seamless transition to the PQ era.","sentences":["The rise of quantum computers exposes vulnerabilities in current public key cryptographic protocols, necessitating the development of secure post-quantum (PQ) schemes.","Hence, we conduct a comprehensive study on various PQ approaches, covering the constructional design, structural vulnerabilities, and offer security assessments, implementation evaluations, and a particular focus on side-channel attacks.","We analyze global standardization processes, evaluate their metrics in relation to real-world applications, and primarily focus on standardized PQ schemes, selected additional signature competition candidates, and PQ-secure cutting-edge schemes beyond standardization.","Finally, we present visions and potential future directions for a seamless transition to the PQ era."],"url":"http://arxiv.org/abs/2310.12037v1"}
{"created":"2023-10-18 15:21:28","title":"A General Theoretical Paradigm to Understand Learning from Human Preferences","abstract":"The prevalent deployment of learning from human preferences through reinforcement learning (RLHF) relies on two important approximations: the first assumes that pairwise preferences can be substituted with pointwise rewards. The second assumes that a reward model trained on these pointwise rewards can generalize from collected data to out-of-distribution data sampled by the policy. Recently, Direct Preference Optimisation (DPO) has been proposed as an approach that bypasses the second approximation and learn directly a policy from collected data without the reward modelling stage. However, this method still heavily relies on the first approximation.   In this paper we try to gain a deeper theoretical understanding of these practical algorithms. In particular we derive a new general objective called $\\Psi$PO for learning from human preferences that is expressed in terms of pairwise preferences and therefore bypasses both approximations. This new general objective allows us to perform an in-depth analysis of the behavior of RLHF and DPO (as special cases of $\\Psi$PO) and to identify their potential pitfalls. We then consider another special case for $\\Psi$PO by setting $\\Psi$ simply to Identity, for which we can derive an efficient optimisation procedure, prove performance guarantees and demonstrate its empirical superiority to DPO on some illustrative examples.","sentences":["The prevalent deployment of learning from human preferences through reinforcement learning (RLHF) relies on two important approximations: the first assumes that pairwise preferences can be substituted with pointwise rewards.","The second assumes that a reward model trained on these pointwise rewards can generalize from collected data to out-of-distribution data sampled by the policy.","Recently, Direct Preference Optimisation (DPO) has been proposed as an approach that bypasses the second approximation and learn directly a policy from collected data without the reward modelling stage.","However, this method still heavily relies on the first approximation.   ","In this paper we try to gain a deeper theoretical understanding of these practical algorithms.","In particular we derive a new general objective called $\\Psi$PO for learning from human preferences that is expressed in terms of pairwise preferences and therefore bypasses both approximations.","This new general objective allows us to perform an in-depth analysis of the behavior of RLHF and DPO (as special cases of $\\Psi$PO) and to identify their potential pitfalls.","We then consider another special case for $\\Psi$PO by setting $\\Psi$ simply to Identity, for which we can derive an efficient optimisation procedure, prove performance guarantees and demonstrate its empirical superiority to DPO on some illustrative examples."],"url":"http://arxiv.org/abs/2310.12036v1"}
{"created":"2023-10-18 15:17:46","title":"Tracking flow: Decoding dynamic flow experience on a sub-minute timescale through performance in fine fingertip force control task","abstract":"Flow, an optimal mental state merging action and awareness, significantly impacts performance, emotion and wellbeing in real-world contexts. However, capturing its fluctuations on a sub-minute timescale is challenging due to the sparsity of the existing flow measuring tools. Here we present a virtual reality fine fingertip force control (F3C) task to induce flow, wherein the task challenge is set at a compatible level with personal skill, and to track the flow fluctuations from the synchronous force control performance. We extract eight performance metrics from the fingertip force sequence and reveal their significant differences under distinct flow states. Further, we built a flow decoder and demonstrated that the flow variations can be decoded using selected metrics. The predicted values reach significant correlation with the self-reported flow intensity (r=0.81). This study showcases the feasibility of tracking intrinsic flow variations with high temporal resolution using task performance measures.","sentences":["Flow, an optimal mental state merging action and awareness, significantly impacts performance, emotion and wellbeing in real-world contexts.","However, capturing its fluctuations on a sub-minute timescale is challenging due to the sparsity of the existing flow measuring tools.","Here we present a virtual reality fine fingertip force control (F3C) task to induce flow, wherein the task challenge is set at a compatible level with personal skill, and to track the flow fluctuations from the synchronous force control performance.","We extract eight performance metrics from the fingertip force sequence and reveal their significant differences under distinct flow states.","Further, we built a flow decoder and demonstrated that the flow variations can be decoded using selected metrics.","The predicted values reach significant correlation with the self-reported flow intensity (r=0.81).","This study showcases the feasibility of tracking intrinsic flow variations with high temporal resolution using task performance measures."],"url":"http://arxiv.org/abs/2310.12035v1"}
{"created":"2023-10-18 15:17:10","title":"Conformal Drug Property Prediction with Density Estimation under Covariate Shift","abstract":"In drug discovery, it is vital to confirm the predictions of pharmaceutical properties from computational models using costly wet-lab experiments. Hence, obtaining reliable uncertainty estimates is crucial for prioritizing drug molecules for subsequent experimental validation. Conformal Prediction (CP) is a promising tool for creating such prediction sets for molecular properties with a coverage guarantee. However, the exchangeability assumption of CP is often challenged with covariate shift in drug discovery tasks: Most datasets contain limited labeled data, which may not be representative of the vast chemical space from which molecules are drawn. To address this limitation, we propose a method called CoDrug that employs an energy-based model leveraging both training data and unlabelled data, and Kernel Density Estimation (KDE) to assess the densities of a molecule set. The estimated densities are then used to weigh the molecule samples while building prediction sets and rectifying for distribution shift. In extensive experiments involving realistic distribution drifts in various small-molecule drug discovery tasks, we demonstrate the ability of CoDrug to provide valid prediction sets and its utility in addressing the distribution shift arising from de novo drug design models. On average, using CoDrug can reduce the coverage gap by over 35% when compared to conformal prediction sets not adjusted for covariate shift.","sentences":["In drug discovery, it is vital to confirm the predictions of pharmaceutical properties from computational models using costly wet-lab experiments.","Hence, obtaining reliable uncertainty estimates is crucial for prioritizing drug molecules for subsequent experimental validation.","Conformal Prediction (CP) is a promising tool for creating such prediction sets for molecular properties with a coverage guarantee.","However, the exchangeability assumption of CP is often challenged with covariate shift in drug discovery tasks: Most datasets contain limited labeled data, which may not be representative of the vast chemical space from which molecules are drawn.","To address this limitation, we propose a method called CoDrug that employs an energy-based model leveraging both training data and unlabelled data, and Kernel Density Estimation (KDE) to assess the densities of a molecule set.","The estimated densities are then used to weigh the molecule samples while building prediction sets and rectifying for distribution shift.","In extensive experiments involving realistic distribution drifts in various small-molecule drug discovery tasks, we demonstrate the ability of CoDrug to provide valid prediction sets and its utility in addressing the distribution shift arising from de novo drug design models.","On average, using CoDrug can reduce the coverage gap by over 35% when compared to conformal prediction sets not adjusted for covariate shift."],"url":"http://arxiv.org/abs/2310.12033v1"}
{"created":"2023-10-18 15:16:24","title":"Exact and efficient solutions of the LMC Multitask Gaussian Process model","abstract":"The Linear Model of Co-regionalization (LMC) is a very general model of multitask gaussian process for regression or classification. While its expressivity and conceptual simplicity are appealing, naive implementations have cubic complexity in the number of datapoints and number of tasks, making approximations mandatory for most applications. However, recent work has shown that under some conditions the latent processes of the model can be decoupled, leading to a complexity that is only linear in the number of said processes. We here extend these results, showing from the most general assumptions that the only condition necessary to an efficient exact computation of the LMC is a mild hypothesis on the noise model. We introduce a full parametrization of the resulting \\emph{projected LMC} model, and an expression of the marginal likelihood enabling efficient optimization. We perform a parametric study on synthetic data to show the excellent performance of our approach, compared to an unrestricted exact LMC and approximations of the latter. Overall, the projected LMC appears as a credible and simpler alternative to state-of-the art models, which greatly facilitates some computations such as leave-one-out cross-validation and fantasization.","sentences":["The Linear Model of Co-regionalization (LMC) is a very general model of multitask gaussian process for regression or classification.","While its expressivity and conceptual simplicity are appealing, naive implementations have cubic complexity in the number of datapoints and number of tasks, making approximations mandatory for most applications.","However, recent work has shown that under some conditions the latent processes of the model can be decoupled, leading to a complexity that is only linear in the number of said processes.","We here extend these results, showing from the most general assumptions that the only condition necessary to an efficient exact computation of the LMC is a mild hypothesis on the noise model.","We introduce a full parametrization of the resulting \\emph{projected LMC} model, and an expression of the marginal likelihood enabling efficient optimization.","We perform a parametric study on synthetic data to show the excellent performance of our approach, compared to an unrestricted exact LMC and approximations of the latter.","Overall, the projected LMC appears as a credible and simpler alternative to state-of-the art models, which greatly facilitates some computations such as leave-one-out cross-validation and fantasization."],"url":"http://arxiv.org/abs/2310.12032v1"}
{"created":"2023-10-18 15:15:13","title":"SegmATRon: Embodied Adaptive Semantic Segmentation for Indoor Environment","abstract":"This paper presents an adaptive transformer model named SegmATRon for embodied image semantic segmentation. Its distinctive feature is the adaptation of model weights during inference on several images using a hybrid multicomponent loss function. We studied this model on datasets collected in the photorealistic Habitat and the synthetic AI2-THOR Simulators. We showed that obtaining additional images using the agent's actions in an indoor environment can improve the quality of semantic segmentation. The code of the proposed approach and datasets are publicly available at https://github.com/wingrune/SegmATRon.","sentences":["This paper presents an adaptive transformer model named SegmATRon for embodied image semantic segmentation.","Its distinctive feature is the adaptation of model weights during inference on several images using a hybrid multicomponent loss function.","We studied this model on datasets collected in the photorealistic Habitat and the synthetic AI2-THOR Simulators.","We showed that obtaining additional images using the agent's actions in an indoor environment can improve the quality of semantic segmentation.","The code of the proposed approach and datasets are publicly available at https://github.com/wingrune/SegmATRon."],"url":"http://arxiv.org/abs/2310.12031v1"}
{"created":"2023-10-18 14:58:13","title":"CORE: A Few-Shot Company Relation Classification Dataset for Robust Domain Adaptation","abstract":"We introduce CORE, a dataset for few-shot relation classification (RC) focused on company relations and business entities. CORE includes 4,708 instances of 12 relation types with corresponding textual evidence extracted from company Wikipedia pages. Company names and business entities pose a challenge for few-shot RC models due to the rich and diverse information associated with them. For example, a company name may represent the legal entity, products, people, or business divisions depending on the context. Therefore, deriving the relation type between entities is highly dependent on textual context. To evaluate the performance of state-of-the-art RC models on the CORE dataset, we conduct experiments in the few-shot domain adaptation setting. Our results reveal substantial performance gaps, confirming that models trained on different domains struggle to adapt to CORE. Interestingly, we find that models trained on CORE showcase improved out-of-domain performance, which highlights the importance of high-quality data for robust domain adaptation. Specifically, the information richness embedded in business entities allows models to focus on contextual nuances, reducing their reliance on superficial clues such as relation-specific verbs. In addition to the dataset, we provide relevant code snippets to facilitate reproducibility and encourage further research in the field.","sentences":["We introduce CORE, a dataset for few-shot relation classification (RC) focused on company relations and business entities.","CORE includes 4,708 instances of 12 relation types with corresponding textual evidence extracted from company Wikipedia pages.","Company names and business entities pose a challenge for few-shot RC models due to the rich and diverse information associated with them.","For example, a company name may represent the legal entity, products, people, or business divisions depending on the context.","Therefore, deriving the relation type between entities is highly dependent on textual context.","To evaluate the performance of state-of-the-art RC models on the CORE dataset, we conduct experiments in the few-shot domain adaptation setting.","Our results reveal substantial performance gaps, confirming that models trained on different domains struggle to adapt to CORE.","Interestingly, we find that models trained on CORE showcase improved out-of-domain performance, which highlights the importance of high-quality data for robust domain adaptation.","Specifically, the information richness embedded in business entities allows models to focus on contextual nuances, reducing their reliance on superficial clues such as relation-specific verbs.","In addition to the dataset, we provide relevant code snippets to facilitate reproducibility and encourage further research in the field."],"url":"http://arxiv.org/abs/2310.12024v1"}
{"created":"2023-10-18 14:53:14","title":"LoHoRavens: A Long-Horizon Language-Conditioned Benchmark for Robotic Tabletop Manipulation","abstract":"The convergence of embodied agents and large language models (LLMs) has brought significant advancements to embodied instruction following. Particularly, the strong reasoning capabilities of LLMs make it possible for robots to perform long-horizon tasks without expensive annotated demonstrations. However, public benchmarks for testing the long-horizon reasoning capabilities of language-conditioned robots in various scenarios are still missing. To fill this gap, this work focuses on the tabletop manipulation task and releases a simulation benchmark, \\textit{LoHoRavens}, which covers various long-horizon reasoning aspects spanning color, size, space, arithmetics and reference. Furthermore, there is a key modality bridging problem for long-horizon manipulation tasks with LLMs: how to incorporate the observation feedback during robot execution for the LLM's closed-loop planning, which is however less studied by prior work. We investigate two methods of bridging the modality gap: caption generation and learnable interface for incorporating explicit and implicit observation feedback to the LLM, respectively. These methods serve as the two baselines for our proposed benchmark. Experiments show that both methods struggle to solve some tasks, indicating long-horizon manipulation tasks are still challenging for current popular models. We expect the proposed public benchmark and baselines can help the community develop better models for long-horizon tabletop manipulation tasks.","sentences":["The convergence of embodied agents and large language models (LLMs) has brought significant advancements to embodied instruction following.","Particularly, the strong reasoning capabilities of LLMs make it possible for robots to perform long-horizon tasks without expensive annotated demonstrations.","However, public benchmarks for testing the long-horizon reasoning capabilities of language-conditioned robots in various scenarios are still missing.","To fill this gap, this work focuses on the tabletop manipulation task and releases a simulation benchmark, \\textit{LoHoRavens}, which covers various long-horizon reasoning aspects spanning color, size, space, arithmetics and reference.","Furthermore, there is a key modality bridging problem for long-horizon manipulation tasks with LLMs: how to incorporate the observation feedback during robot execution for the LLM's closed-loop planning, which is however less studied by prior work.","We investigate two methods of bridging the modality gap: caption generation and learnable interface for incorporating explicit and implicit observation feedback to the LLM, respectively.","These methods serve as the two baselines for our proposed benchmark.","Experiments show that both methods struggle to solve some tasks, indicating long-horizon manipulation tasks are still challenging for current popular models.","We expect the proposed public benchmark and baselines can help the community develop better models for long-horizon tabletop manipulation tasks."],"url":"http://arxiv.org/abs/2310.12020v1"}
{"created":"2023-10-18 14:52:44","title":"DesignQuizzer: A Community-Powered Conversational Agent for Learning Visual Design","abstract":"Online design communities, where members exchange free-form views on others' designs, offer a space for beginners to learn visual design. However, the content of these communities is often unorganized for learners, containing many redundancies and irrelevant comments. In this paper, we propose a computational approach for leveraging online design communities to run a conversational agent that assists informal learning of visual elements (e.g., color and space). Our method extracts critiques, suggestions, and rationales on visual elements from comments. We present DesignQuizzer, which asks questions about visual design in UI examples and provides structured comment summaries. Two user studies demonstrate the engagement and usefulness of DesignQuizzer compared with the baseline (reading reddit.com/r/UI_design). We also showcase how effectively novices can apply what they learn with DesignQuizzer in a design critique task and a visual design task. We discuss how to use our approach with other communities and offer design considerations for community-powered learning support tools.","sentences":["Online design communities, where members exchange free-form views on others' designs, offer a space for beginners to learn visual design.","However, the content of these communities is often unorganized for learners, containing many redundancies and irrelevant comments.","In this paper, we propose a computational approach for leveraging online design communities to run a conversational agent that assists informal learning of visual elements (e.g., color and space).","Our method extracts critiques, suggestions, and rationales on visual elements from comments.","We present DesignQuizzer, which asks questions about visual design in UI examples and provides structured comment summaries.","Two user studies demonstrate the engagement and usefulness of DesignQuizzer compared with the baseline (reading reddit.com/r/UI_design).","We also showcase how effectively novices can apply what they learn with DesignQuizzer in a design critique task and a visual design task.","We discuss how to use our approach with other communities and offer design considerations for community-powered learning support tools."],"url":"http://arxiv.org/abs/2310.12019v1"}
{"created":"2023-10-18 14:49:54","title":"Exploring Decision-based Black-box Attacks on Face Forgery Detection","abstract":"Face forgery generation technologies generate vivid faces, which have raised public concerns about security and privacy. Many intelligent systems, such as electronic payment and identity verification, rely on face forgery detection. Although face forgery detection has successfully distinguished fake faces, recent studies have demonstrated that face forgery detectors are very vulnerable to adversarial examples. Meanwhile, existing attacks rely on network architectures or training datasets instead of the predicted labels, which leads to a gap in attacking deployed applications. To narrow this gap, we first explore the decision-based attacks on face forgery detection. However, applying existing decision-based attacks directly suffers from perturbation initialization failure and low image quality. First, we propose cross-task perturbation to handle initialization failures by utilizing the high correlation of face features on different tasks. Then, inspired by using frequency cues by face forgery detection, we propose the frequency decision-based attack. We add perturbations in the frequency domain and then constrain the visual quality in the spatial domain. Finally, extensive experiments demonstrate that our method achieves state-of-the-art attack performance on FaceForensics++, CelebDF, and industrial APIs, with high query efficiency and guaranteed image quality. Further, the fake faces by our method can pass face forgery detection and face recognition, which exposes the security problems of face forgery detectors.","sentences":["Face forgery generation technologies generate vivid faces, which have raised public concerns about security and privacy.","Many intelligent systems, such as electronic payment and identity verification, rely on face forgery detection.","Although face forgery detection has successfully distinguished fake faces, recent studies have demonstrated that face forgery detectors are very vulnerable to adversarial examples.","Meanwhile, existing attacks rely on network architectures or training datasets instead of the predicted labels, which leads to a gap in attacking deployed applications.","To narrow this gap, we first explore the decision-based attacks on face forgery detection.","However, applying existing decision-based attacks directly suffers from perturbation initialization failure and low image quality.","First, we propose cross-task perturbation to handle initialization failures by utilizing the high correlation of face features on different tasks.","Then, inspired by using frequency cues by face forgery detection, we propose the frequency decision-based attack.","We add perturbations in the frequency domain and then constrain the visual quality in the spatial domain.","Finally, extensive experiments demonstrate that our method achieves state-of-the-art attack performance on FaceForensics++, CelebDF, and industrial APIs, with high query efficiency and guaranteed image quality.","Further, the fake faces by our method can pass face forgery detection and face recognition, which exposes the security problems of face forgery detectors."],"url":"http://arxiv.org/abs/2310.12017v1"}
{"created":"2023-10-18 14:43:07","title":"Gold: A Global and Local-aware Denoising Framework for Commonsense Knowledge Graph Noise Detection","abstract":"Commonsense Knowledge Graphs (CSKGs) are crucial for commonsense reasoning, yet constructing them through human annotations can be costly. As a result, various automatic methods have been proposed to construct CSKG with larger semantic coverage. However, these unsupervised approaches introduce spurious noise that can lower the quality of the resulting CSKG, which cannot be tackled easily by existing denoising algorithms due to the unique characteristics of nodes and structures in CSKGs. To address this issue, we propose Gold (Global and Local-aware Denoising), a denoising framework for CSKGs that incorporates entity semantic information, global rules, and local structural information from the CSKG. Experiment results demonstrate that Gold outperforms all baseline methods in noise detection tasks on synthetic noisy CSKG benchmarks. Furthermore, we show that denoising a real-world CSKG is effective and even benefits the downstream zero-shot commonsense question-answering task.","sentences":["Commonsense Knowledge Graphs (CSKGs) are crucial for commonsense reasoning, yet constructing them through human annotations can be costly.","As a result, various automatic methods have been proposed to construct CSKG with larger semantic coverage.","However, these unsupervised approaches introduce spurious noise that can lower the quality of the resulting CSKG, which cannot be tackled easily by existing denoising algorithms due to the unique characteristics of nodes and structures in CSKGs.","To address this issue, we propose Gold (Global and Local-aware Denoising), a denoising framework for CSKGs that incorporates entity semantic information, global rules, and local structural information from the CSKG.","Experiment results demonstrate that Gold outperforms all baseline methods in noise detection tasks on synthetic noisy CSKG benchmarks.","Furthermore, we show that denoising a real-world CSKG is effective and even benefits the downstream zero-shot commonsense question-answering task."],"url":"http://arxiv.org/abs/2310.12011v1"}
{"created":"2023-10-18 14:41:09","title":"Multi-view Contrastive Learning for Entity Typing over Knowledge Graphs","abstract":"Knowledge graph entity typing (KGET) aims at inferring plausible types of entities in knowledge graphs. Existing approaches to KGET focus on how to better encode the knowledge provided by the neighbors and types of an entity into its representation. However, they ignore the semantic knowledge provided by the way in which types can be clustered together. In this paper, we propose a novel method called Multi-view Contrastive Learning for knowledge graph Entity Typing (MCLET), which effectively encodes the coarse-grained knowledge provided by clusters into entity and type embeddings. MCLET is composed of three modules: i) Multi-view Generation and Encoder module, which encodes structured information from entity-type, entity-cluster and cluster-type views; ii) Cross-view Contrastive Learning module, which encourages different views to collaboratively improve view-specific representations of entities and types; iii) Entity Typing Prediction module, which integrates multi-head attention and a Mixture-of-Experts strategy to infer missing entity types. Extensive experiments show the strong performance of MCLET compared to the state-of-the-art","sentences":["Knowledge graph entity typing (KGET) aims at inferring plausible types of entities in knowledge graphs.","Existing approaches to KGET focus on how to better encode the knowledge provided by the neighbors and types of an entity into its representation.","However, they ignore the semantic knowledge provided by the way in which types can be clustered together.","In this paper, we propose a novel method called Multi-view Contrastive Learning for knowledge graph Entity Typing (MCLET), which effectively encodes the coarse-grained knowledge provided by clusters into entity and type embeddings.","MCLET is composed of three modules: i) Multi-view Generation and Encoder module, which encodes structured information from entity-type, entity-cluster and cluster-type views; ii) Cross-view Contrastive Learning module, which encourages different views to collaboratively improve view-specific representations of entities and types; iii) Entity Typing Prediction module, which integrates multi-head attention and a Mixture-of-Experts strategy to infer missing entity types.","Extensive experiments show the strong performance of MCLET compared to the state-of-the-art"],"url":"http://arxiv.org/abs/2310.12008v1"}
{"created":"2023-10-18 14:40:52","title":"KI-PMF: Knowledge Integrated Plausible Motion Forecasting","abstract":"Accurately forecasting the motion of traffic actors is crucial for the deployment of autonomous vehicles at a large scale. Current trajectory forecasting approaches primarily concentrate on optimizing a loss function with a specific metric, which can result in predictions that do not adhere to physical laws or violate external constraints. Our objective is to incorporate explicit knowledge priors that allow a network to forecast future trajectories in compliance with both the kinematic constraints of a vehicle and the geometry of the driving environment. To achieve this, we introduce a non-parametric pruning layer and attention layers to integrate the defined knowledge priors. Our proposed method is designed to ensure reachability guarantees for traffic actors in both complex and dynamic situations. By conditioning the network to follow physical laws, we can obtain accurate and safe predictions, essential for maintaining autonomous vehicles' safety and efficiency in real-world settings.In summary, this paper presents concepts that prevent off-road predictions for safe and reliable motion forecasting by incorporating knowledge priors into the training process.","sentences":["Accurately forecasting the motion of traffic actors is crucial for the deployment of autonomous vehicles at a large scale.","Current trajectory forecasting approaches primarily concentrate on optimizing a loss function with a specific metric, which can result in predictions that do not adhere to physical laws or violate external constraints.","Our objective is to incorporate explicit knowledge priors that allow a network to forecast future trajectories in compliance with both the kinematic constraints of a vehicle and the geometry of the driving environment.","To achieve this, we introduce a non-parametric pruning layer and attention layers to integrate the defined knowledge priors.","Our proposed method is designed to ensure reachability guarantees for traffic actors in both complex and dynamic situations.","By conditioning the network to follow physical laws, we can obtain accurate and safe predictions, essential for maintaining autonomous vehicles' safety and efficiency in real-world settings.","In summary, this paper presents concepts that prevent off-road predictions for safe and reliable motion forecasting by incorporating knowledge priors into the training process."],"url":"http://arxiv.org/abs/2310.12007v1"}
{"created":"2023-10-18 14:40:45","title":"Guaranteed, Predictable, Polynomial AGV Time-Pathing","abstract":"In this paper we present a framework of key algorithms and data-structures for efficiently generating timetables for any number of AGVs from any given positioning on any given graph to accomplish any given demands as long as a few easily satisfiable assumptions are met. Our proposed algorithms provide guaranteed solutions in predictable polynomial running-times, which is fundamental to any real-time application. We also develop an improved geographic reservation algorithm that provides a substantial run-time improvement of the previously best-known algorithm from $O(nm)$ to $O(n)$.","sentences":["In this paper we present a framework of key algorithms and data-structures for efficiently generating timetables for any number of AGVs from any given positioning on any given graph to accomplish any given demands as long as a few easily satisfiable assumptions are met.","Our proposed algorithms provide guaranteed solutions in predictable polynomial running-times, which is fundamental to any real-time application.","We also develop an improved geographic reservation algorithm that provides a substantial run-time improvement of the previously best-known algorithm from $O(nm)$ to $O(n)$."],"url":"http://arxiv.org/abs/2310.12006v1"}
{"created":"2023-10-18 14:39:25","title":"Image Super-resolution Via Latent Diffusion: A Sampling-space Mixture Of Experts And Frequency-augmented Decoder Approach","abstract":"The recent use of diffusion prior, enhanced by pre-trained text-image models, has markedly elevated the performance of image super-resolution (SR). To alleviate the huge computational cost required by pixel-based diffusion SR, latent-based methods utilize a feature encoder to transform the image and then implement the SR image generation in a compact latent space. Nevertheless, there are two major issues that limit the performance of latent-based diffusion. First, the compression of latent space usually causes reconstruction distortion. Second, huge computational cost constrains the parameter scale of the diffusion model. To counteract these issues, we first propose a frequency compensation module that enhances the frequency components from latent space to pixel space. The reconstruction distortion (especially for high-frequency information) can be significantly decreased. Then, we propose to use Sample-Space Mixture of Experts (SS-MoE) to achieve more powerful latent-based SR, which steadily improves the capacity of the model without a significant increase in inference costs. These carefully crafted designs contribute to performance improvements in largely explored 4x blind super-resolution benchmarks and extend to large magnification factors, i.e., 8x image SR benchmarks. The code is available at https://github.com/amandaluof/moe_sr.","sentences":["The recent use of diffusion prior, enhanced by pre-trained text-image models, has markedly elevated the performance of image super-resolution (SR).","To alleviate the huge computational cost required by pixel-based diffusion SR, latent-based methods utilize a feature encoder to transform the image and then implement the SR image generation in a compact latent space.","Nevertheless, there are two major issues that limit the performance of latent-based diffusion.","First, the compression of latent space usually causes reconstruction distortion.","Second, huge computational cost constrains the parameter scale of the diffusion model.","To counteract these issues, we first propose a frequency compensation module that enhances the frequency components from latent space to pixel space.","The reconstruction distortion (especially for high-frequency information) can be significantly decreased.","Then, we propose to use Sample-Space Mixture of Experts (SS-MoE) to achieve more powerful latent-based SR, which steadily improves the capacity of the model without a significant increase in inference costs.","These carefully crafted designs contribute to performance improvements in largely explored 4x blind super-resolution benchmarks and extend to large magnification factors, i.e., 8x image SR benchmarks.","The code is available at https://github.com/amandaluof/moe_sr."],"url":"http://arxiv.org/abs/2310.12004v1"}
{"created":"2023-10-18 14:32:20","title":"Bayesian Flow Networks in Continual Learning","abstract":"Bayesian Flow Networks (BFNs) has been recently proposed as one of the most promising direction to universal generative modelling, having ability to learn any of the data type. Their power comes from the expressiveness of neural networks and Bayesian inference which make them suitable in the context of continual learning. We delve into the mechanics behind BFNs and conduct the experiments to empirically verify the generative capabilities on non-stationary data.","sentences":["Bayesian Flow Networks (BFNs) has been recently proposed as one of the most promising direction to universal generative modelling, having ability to learn any of the data type.","Their power comes from the expressiveness of neural networks and Bayesian inference which make them suitable in the context of continual learning.","We delve into the mechanics behind BFNs and conduct the experiments to empirically verify the generative capabilities on non-stationary data."],"url":"http://arxiv.org/abs/2310.12001v1"}
{"created":"2023-10-18 14:26:51","title":"Parallel Log Spectra index (PaLOSi): a quality metric in large scale resting EEG preprocessing","abstract":"Toward large scale electrophysiology data analysis, many preprocessing pipelines are developed to reject artifacts as the prerequisite step before the downstream analysis. A mainstay of these pipelines is based on the data driven approach -- Independent Component Analysis (ICA). Nevertheless, there is little effort put to the preprocessing quality control. In this paper, attentions to this issue were carefully paid by our observation that after running ICA based preprocessing pipeline: some subjects showed approximately Parallel multichannel Log power Spectra (PaLOS), namely, multichannel power spectra are proportional to each other. Firstly, the presence of PaLOS and its implications to connectivity analysis were described by real instance and simulation; secondly, we built its mathematical model and proposed the PaLOS index (PaLOSi) based on the common principal component analysis to detect its presence; thirdly, the performance of PaLOSi was tested on 30094 cases of EEG from 5 databases. The results showed that 1) the PaLOS implies a sole source which is physiologically implausible. 2) PaLOSi can detect the excessive elimination of brain components and is robust in terms of channel number, electrode layout, reference, and the other factors. 3) PaLOSi can output the channel and frequency wise index to help for in-depth check. This paper presented the PaLOS issue in the quality control step after running the preprocessing pipeline and the proposed PaLOSi may serve as a novel data quality metric in the large-scale automatic preprocessing.","sentences":["Toward large scale electrophysiology data analysis, many preprocessing pipelines are developed to reject artifacts as the prerequisite step before the downstream analysis.","A mainstay of these pipelines is based on the data driven approach -- Independent Component Analysis (ICA).","Nevertheless, there is little effort put to the preprocessing quality control.","In this paper, attentions to this issue were carefully paid by our observation that after running ICA based preprocessing pipeline: some subjects showed approximately Parallel multichannel Log power Spectra (PaLOS), namely, multichannel power spectra are proportional to each other.","Firstly, the presence of PaLOS and its implications to connectivity analysis were described by real instance and simulation; secondly, we built its mathematical model and proposed the PaLOS index (PaLOSi) based on the common principal component analysis to detect its presence; thirdly, the performance of PaLOSi was tested on 30094 cases of EEG from 5 databases.","The results showed that 1) the PaLOS implies a sole source which is physiologically implausible.","2) PaLOSi can detect the excessive elimination of brain components and is robust in terms of channel number, electrode layout, reference, and the other factors.","3) PaLOSi can output the channel and frequency wise index to help for in-depth check.","This paper presented the PaLOS issue in the quality control step after running the preprocessing pipeline and the proposed PaLOSi may serve as a novel data quality metric in the large-scale automatic preprocessing."],"url":"http://arxiv.org/abs/2310.11994v1"}
{"created":"2023-10-18 14:22:36","title":"Removing Spurious Concepts from Neural Network Representations via Joint Subspace Estimation","abstract":"Out-of-distribution generalization in neural networks is often hampered by spurious correlations. A common strategy is to mitigate this by removing spurious concepts from the neural network representation of the data. Existing concept-removal methods tend to be overzealous by inadvertently eliminating features associated with the main task of the model, thereby harming model performance. We propose an iterative algorithm that separates spurious from main-task concepts by jointly identifying two low-dimensional orthogonal subspaces in the neural network representation. We evaluate the algorithm on benchmark datasets for computer vision (Waterbirds, CelebA) and natural language processing (MultiNLI), and show that it outperforms existing concept removal methods","sentences":["Out-of-distribution generalization in neural networks is often hampered by spurious correlations.","A common strategy is to mitigate this by removing spurious concepts from the neural network representation of the data.","Existing concept-removal methods tend to be overzealous by inadvertently eliminating features associated with the main task of the model, thereby harming model performance.","We propose an iterative algorithm that separates spurious from main-task concepts by jointly identifying two low-dimensional orthogonal subspaces in the neural network representation.","We evaluate the algorithm on benchmark datasets for computer vision (Waterbirds, CelebA) and natural language processing (MultiNLI), and show that it outperforms existing concept removal methods"],"url":"http://arxiv.org/abs/2310.11991v1"}
{"created":"2023-10-18 14:20:55","title":"Image Clustering with External Guidance","abstract":"The core of clustering is incorporating prior knowledge to construct supervision signals. From classic k-means based on data compactness to recent contrastive clustering guided by self-supervision, the evolution of clustering methods intrinsically corresponds to the progression of supervision signals. At present, substantial efforts have been devoted to mining internal supervision signals from data. Nevertheless, the abundant external knowledge such as semantic descriptions, which naturally conduces to clustering, is regrettably overlooked. In this work, we propose leveraging external knowledge as a new supervision signal to guide clustering, even though it seems irrelevant to the given data. To implement and validate our idea, we design an externally guided clustering method (Text-Aided Clustering, TAC), which leverages the textual semantics of WordNet to facilitate image clustering. Specifically, TAC first selects and retrieves WordNet nouns that best distinguish images to enhance the feature discriminability. Then, to improve image clustering performance, TAC collaborates text and image modalities by mutually distilling cross-modal neighborhood information. Experiments demonstrate that TAC achieves state-of-the-art performance on five widely used and three more challenging image clustering benchmarks, including the full ImageNet-1K dataset.","sentences":["The core of clustering is incorporating prior knowledge to construct supervision signals.","From classic k-means based on data compactness to recent contrastive clustering guided by self-supervision, the evolution of clustering methods intrinsically corresponds to the progression of supervision signals.","At present, substantial efforts have been devoted to mining internal supervision signals from data.","Nevertheless, the abundant external knowledge such as semantic descriptions, which naturally conduces to clustering, is regrettably overlooked.","In this work, we propose leveraging external knowledge as a new supervision signal to guide clustering, even though it seems irrelevant to the given data.","To implement and validate our idea, we design an externally guided clustering method (Text-Aided Clustering, TAC), which leverages the textual semantics of WordNet to facilitate image clustering.","Specifically, TAC first selects and retrieves WordNet nouns that best distinguish images to enhance the feature discriminability.","Then, to improve image clustering performance, TAC collaborates text and image modalities by mutually distilling cross-modal neighborhood information.","Experiments demonstrate that TAC achieves state-of-the-art performance on five widely used and three more challenging image clustering benchmarks, including the full ImageNet-1K dataset."],"url":"http://arxiv.org/abs/2310.11989v1"}
{"created":"2023-10-18 14:13:58","title":"Sociotechnical Safety Evaluation of Generative AI Systems","abstract":"Generative AI systems produce a range of risks. To ensure the safety of generative AI systems, these risks must be evaluated. In this paper, we make two main contributions toward establishing such evaluations. First, we propose a three-layered framework that takes a structured, sociotechnical approach to evaluating these risks. This framework encompasses capability evaluations, which are the main current approach to safety evaluation. It then reaches further by building on system safety principles, particularly the insight that context determines whether a given capability may cause harm. To account for relevant context, our framework adds human interaction and systemic impacts as additional layers of evaluation. Second, we survey the current state of safety evaluation of generative AI systems and create a repository of existing evaluations. Three salient evaluation gaps emerge from this analysis. We propose ways forward to closing these gaps, outlining practical steps as well as roles and responsibilities for different actors. Sociotechnical safety evaluation is a tractable approach to the robust and comprehensive safety evaluation of generative AI systems.","sentences":["Generative AI systems produce a range of risks.","To ensure the safety of generative AI systems, these risks must be evaluated.","In this paper, we make two main contributions toward establishing such evaluations.","First, we propose a three-layered framework that takes a structured, sociotechnical approach to evaluating these risks.","This framework encompasses capability evaluations, which are the main current approach to safety evaluation.","It then reaches further by building on system safety principles, particularly the insight that context determines whether a given capability may cause harm.","To account for relevant context, our framework adds human interaction and systemic impacts as additional layers of evaluation.","Second, we survey the current state of safety evaluation of generative AI systems and create a repository of existing evaluations.","Three salient evaluation gaps emerge from this analysis.","We propose ways forward to closing these gaps, outlining practical steps as well as roles and responsibilities for different actors.","Sociotechnical safety evaluation is a tractable approach to the robust and comprehensive safety evaluation of generative AI systems."],"url":"http://arxiv.org/abs/2310.11986v1"}
{"created":"2023-10-18 14:11:41","title":"A Finite-Horizon Approach to Active Level Set Estimation","abstract":"We consider the problem of active learning in the context of spatial sampling for level set estimation (LSE), where the goal is to localize all regions where a function of interest lies above/below a given threshold as quickly as possible. We present a finite-horizon search procedure to perform LSE in one dimension while optimally balancing both the final estimation error and the distance traveled for a fixed number of samples. A tuning parameter is used to trade off between the estimation accuracy and distance traveled. We show that the resulting optimization problem can be solved in closed form and that the resulting policy generalizes existing approaches to this problem. We then show how this approach can be used to perform level set estimation in higher dimensions under the popular Gaussian process model. Empirical results on synthetic data indicate that as the cost of travel increases, our method's ability to treat distance nonmyopically allows it to significantly improve on the state of the art. On real air quality data, our approach achieves roughly one fifth the estimation error at less than half the cost of competing algorithms.","sentences":["We consider the problem of active learning in the context of spatial sampling for level set estimation (LSE), where the goal is to localize all regions where a function of interest lies above/below a given threshold as quickly as possible.","We present a finite-horizon search procedure to perform LSE in one dimension while optimally balancing both the final estimation error and the distance traveled for a fixed number of samples.","A tuning parameter is used to trade off between the estimation accuracy and distance traveled.","We show that the resulting optimization problem can be solved in closed form and that the resulting policy generalizes existing approaches to this problem.","We then show how this approach can be used to perform level set estimation in higher dimensions under the popular Gaussian process model.","Empirical results on synthetic data indicate that as the cost of travel increases, our method's ability to treat distance nonmyopically allows it to significantly improve on the state of the art.","On real air quality data, our approach achieves roughly one fifth the estimation error at less than half the cost of competing algorithms."],"url":"http://arxiv.org/abs/2310.11985v1"}
{"created":"2023-10-18 14:10:47","title":"From Interpolation to Extrapolation: Complete Length Generalization for Arithmetic Transformers","abstract":"Since its introduction, the transformer model has demonstrated outstanding performance across various tasks. However, there are still unresolved issues regarding length generalization, particularly in algorithmic tasks. In this paper, we investigate the inherent capabilities of transformer models in learning arithmetic algorithms, such as addition and multiplication. Through experiments and attention analysis, we identify a number of crucial factors for achieving optimal length generalization. We show that transformer models are able to generalize to long lengths with the help of targeted attention biasing. We then introduce Attention Bias Calibration (ABC), a calibration stage that enables the model to automatically learn the proper attention biases, which we link to mechanisms in relative position encoding. We demonstrate that using ABC, the transformer model can achieve unprecedented perfect length generalization on certain arithmetic tasks.","sentences":["Since its introduction, the transformer model has demonstrated outstanding performance across various tasks.","However, there are still unresolved issues regarding length generalization, particularly in algorithmic tasks.","In this paper, we investigate the inherent capabilities of transformer models in learning arithmetic algorithms, such as addition and multiplication.","Through experiments and attention analysis, we identify a number of crucial factors for achieving optimal length generalization.","We show that transformer models are able to generalize to long lengths with the help of targeted attention biasing.","We then introduce Attention Bias Calibration (ABC), a calibration stage that enables the model to automatically learn the proper attention biases, which we link to mechanisms in relative position encoding.","We demonstrate that using ABC, the transformer model can achieve unprecedented perfect length generalization on certain arithmetic tasks."],"url":"http://arxiv.org/abs/2310.11984v1"}
{"created":"2023-10-18 14:01:39","title":"InfoDiffusion: Information Entropy Aware Diffusion Process for Non-Autoregressive Text Generation","abstract":"Diffusion models have garnered considerable interest in the field of text generation. Several studies have explored text diffusion models with different structures and applied them to various tasks, including named entity recognition and summarization. However, there exists a notable disparity between the \"easy-first\" text generation process of current diffusion models and the \"keyword-first\" natural text generation process of humans, which has received limited attention. To bridge this gap, we propose InfoDiffusion, a non-autoregressive text diffusion model. Our approach introduces a \"keyinfo-first\" generation strategy and incorporates a noise schedule based on the amount of text information. In addition, InfoDiffusion combines self-conditioning with a newly proposed partially noising model structure. Experimental results show that InfoDiffusion outperforms the baseline model in terms of generation quality and diversity, as well as exhibiting higher sampling efficiency.","sentences":["Diffusion models have garnered considerable interest in the field of text generation.","Several studies have explored text diffusion models with different structures and applied them to various tasks, including named entity recognition and summarization.","However, there exists a notable disparity between the \"easy-first\" text generation process of current diffusion models and the \"keyword-first\" natural text generation process of humans, which has received limited attention.","To bridge this gap, we propose InfoDiffusion, a non-autoregressive text diffusion model.","Our approach introduces a \"keyinfo-first\" generation strategy and incorporates a noise schedule based on the amount of text information.","In addition, InfoDiffusion combines self-conditioning with a newly proposed partially noising model structure.","Experimental results show that InfoDiffusion outperforms the baseline model in terms of generation quality and diversity, as well as exhibiting higher sampling efficiency."],"url":"http://arxiv.org/abs/2310.11976v1"}
{"created":"2023-10-18 13:54:15","title":"Improving Generalization of Alignment with Human Preferences through Group Invariant Learning","abstract":"The success of AI assistants based on language models (LLMs) hinges crucially on Reinforcement Learning from Human Feedback (RLHF), which enables the generation of responses more aligned with human preferences. As universal AI assistants, there's a growing expectation for them to perform consistently across various domains. However, previous work shows that Reinforcement Learning (RL) often exploits shortcuts to attain high rewards and overlooks challenging samples. This focus on quick reward gains undermines both the stability in training and the model's ability to generalize to new, unseen data. In this work, we propose a novel approach that can learn a consistent policy via RL across various data groups or domains. Given the challenges associated with acquiring group annotations, our method automatically classifies data into different groups, deliberately maximizing performance variance. Then, we optimize the policy to perform well on challenging groups. Lastly, leveraging the established groups, our approach adaptively adjusts the exploration space, allocating more learning capacity to more challenging data and preventing the model from over-optimizing on simpler data. Experimental results indicate that our approach significantly enhances training stability and model generalization.","sentences":["The success of AI assistants based on language models (LLMs) hinges crucially on Reinforcement Learning from Human Feedback (RLHF), which enables the generation of responses more aligned with human preferences.","As universal AI assistants, there's a growing expectation for them to perform consistently across various domains.","However, previous work shows that Reinforcement Learning (RL) often exploits shortcuts to attain high rewards and overlooks challenging samples.","This focus on quick reward gains undermines both the stability in training and the model's ability to generalize to new, unseen data.","In this work, we propose a novel approach that can learn a consistent policy via RL across various data groups or domains.","Given the challenges associated with acquiring group annotations, our method automatically classifies data into different groups, deliberately maximizing performance variance.","Then, we optimize the policy to perform well on challenging groups.","Lastly, leveraging the established groups, our approach adaptively adjusts the exploration space, allocating more learning capacity to more challenging data and preventing the model from over-optimizing on simpler data.","Experimental results indicate that our approach significantly enhances training stability and model generalization."],"url":"http://arxiv.org/abs/2310.11971v1"}
{"created":"2023-10-18 13:51:27","title":"Quantifying Privacy Risks of Prompts in Visual Prompt Learning","abstract":"Large-scale pre-trained models are increasingly adapted to downstream tasks through a new paradigm called prompt learning. In contrast to fine-tuning, prompt learning does not update the pre-trained model's parameters. Instead, it only learns an input perturbation, namely prompt, to be added to the downstream task data for predictions. Given the fast development of prompt learning, a well-generalized prompt inevitably becomes a valuable asset as significant effort and proprietary data are used to create it. This naturally raises the question of whether a prompt may leak the proprietary information of its training data. In this paper, we perform the first comprehensive privacy assessment of prompts learned by visual prompt learning through the lens of property inference and membership inference attacks. Our empirical evaluation shows that the prompts are vulnerable to both attacks. We also demonstrate that the adversary can mount a successful property inference attack with limited cost. Moreover, we show that membership inference attacks against prompts can be successful with relaxed adversarial assumptions. We further make some initial investigations on the defenses and observe that our method can mitigate the membership inference attacks with a decent utility-defense trade-off but fails to defend against property inference attacks. We hope our results can shed light on the privacy risks of the popular prompt learning paradigm. To facilitate the research in this direction, we will share our code and models with the community.","sentences":["Large-scale pre-trained models are increasingly adapted to downstream tasks through a new paradigm called prompt learning.","In contrast to fine-tuning, prompt learning does not update the pre-trained model's parameters.","Instead, it only learns an input perturbation, namely prompt, to be added to the downstream task data for predictions.","Given the fast development of prompt learning, a well-generalized prompt inevitably becomes a valuable asset as significant effort and proprietary data are used to create it.","This naturally raises the question of whether a prompt may leak the proprietary information of its training data.","In this paper, we perform the first comprehensive privacy assessment of prompts learned by visual prompt learning through the lens of property inference and membership inference attacks.","Our empirical evaluation shows that the prompts are vulnerable to both attacks.","We also demonstrate that the adversary can mount a successful property inference attack with limited cost.","Moreover, we show that membership inference attacks against prompts can be successful with relaxed adversarial assumptions.","We further make some initial investigations on the defenses and observe that our method can mitigate the membership inference attacks with a decent utility-defense trade-off but fails to defend against property inference attacks.","We hope our results can shed light on the privacy risks of the popular prompt learning paradigm.","To facilitate the research in this direction, we will share our code and models with the community."],"url":"http://arxiv.org/abs/2310.11970v1"}
{"created":"2023-10-18 13:45:47","title":"Take the aTrain. Introducing an Interface for the Accessible Transcription of Interviews","abstract":"aTrain is an open-source and offline tool for transcribing audio data in multiple languages with CPU and NVIDIA GPU support. It is specifically designed for researchers using qualitative data generated from various forms of speech interactions with research participants. aTrain requires no programming skills, runs on most computers, does not require an internet connection, and was verified not to upload data to any server. aTrain combines OpenAI's Whisper model with speaker recognition to provide output that integrates with the popular qualitative data analysis software tools MAXQDA and ATLAS.ti. It has an easy-to-use graphical interface and is provided as a Windows-App through the Microsoft Store allowing for simple installation by researchers. The source code is freely available on GitHub. Having developed aTrain with a focus on speed on local computers, we show that the transcription time on current mobile CPUs is around 2 to 3 times the duration of the audio file using the highest-accuracy transcription models. If an entry-level graphics card is available, the transcription speed increases to 20% of the audio duration.","sentences":["aTrain is an open-source and offline tool for transcribing audio data in multiple languages with CPU and NVIDIA GPU support.","It is specifically designed for researchers using qualitative data generated from various forms of speech interactions with research participants.","aTrain requires no programming skills, runs on most computers, does not require an internet connection, and was verified not to upload data to any server.","aTrain combines OpenAI's Whisper model with speaker recognition to provide output that integrates with the popular qualitative data analysis software tools MAXQDA and ATLAS.ti.","It has an easy-to-use graphical interface and is provided as a Windows-App through the Microsoft Store allowing for simple installation by researchers.","The source code is freely available on GitHub.","Having developed aTrain with a focus on speed on local computers, we show that the transcription time on current mobile CPUs is around 2 to 3 times the duration of the audio file using the highest-accuracy transcription models.","If an entry-level graphics card is available, the transcription speed increases to 20% of the audio duration."],"url":"http://arxiv.org/abs/2310.11967v1"}
{"created":"2023-10-18 13:45:17","title":"Flexible Payload Configuration for Satellites using Machine Learning","abstract":"Satellite communications, essential for modern connectivity, extend access to maritime, aeronautical, and remote areas where terrestrial networks are unfeasible. Current GEO systems distribute power and bandwidth uniformly across beams using multi-beam footprints with fractional frequency reuse. However, recent research reveals the limitations of this approach in heterogeneous traffic scenarios, leading to inefficiencies. To address this, this paper presents a machine learning (ML)-based approach to Radio Resource Management (RRM).   We treat the RRM task as a regression ML problem, integrating RRM objectives and constraints into the loss function that the ML algorithm aims at minimizing. Moreover, we introduce a context-aware ML metric that evaluates the ML model's performance but also considers the impact of its resource allocation decisions on the overall performance of the communication system.","sentences":["Satellite communications, essential for modern connectivity, extend access to maritime, aeronautical, and remote areas where terrestrial networks are unfeasible.","Current GEO systems distribute power and bandwidth uniformly across beams using multi-beam footprints with fractional frequency reuse.","However, recent research reveals the limitations of this approach in heterogeneous traffic scenarios, leading to inefficiencies.","To address this, this paper presents a machine learning (ML)-based approach to Radio Resource Management (RRM).   ","We treat the RRM task as a regression ML problem, integrating RRM objectives and constraints into the loss function that the ML algorithm aims at minimizing.","Moreover, we introduce a context-aware ML metric that evaluates the ML model's performance but also considers the impact of its resource allocation decisions on the overall performance of the communication system."],"url":"http://arxiv.org/abs/2310.11966v1"}
{"created":"2023-10-18 13:44:58","title":"Filling in the Gaps: Efficient Event Coreference Resolution using Graph Autoencoder Networks","abstract":"We introduce a novel and efficient method for Event Coreference Resolution (ECR) applied to a lower-resourced language domain. By framing ECR as a graph reconstruction task, we are able to combine deep semantic embeddings with structural coreference chain knowledge to create a parameter-efficient family of Graph Autoencoder models (GAE). Our method significantly outperforms classical mention-pair methods on a large Dutch event coreference corpus in terms of overall score, efficiency and training speed. Additionally, we show that our models are consistently able to classify more difficult coreference links and are far more robust in low-data settings when compared to transformer-based mention-pair coreference algorithms.","sentences":["We introduce a novel and efficient method for Event Coreference Resolution (ECR) applied to a lower-resourced language domain.","By framing ECR as a graph reconstruction task, we are able to combine deep semantic embeddings with structural coreference chain knowledge to create a parameter-efficient family of Graph Autoencoder models (GAE).","Our method significantly outperforms classical mention-pair methods on a large Dutch event coreference corpus in terms of overall score, efficiency and training speed.","Additionally, we show that our models are consistently able to classify more difficult coreference links and are far more robust in low-data settings when compared to transformer-based mention-pair coreference algorithms."],"url":"http://arxiv.org/abs/2310.11965v1"}
{"created":"2023-10-18 13:44:26","title":"AMR Parsing with Causal Hierarchical Attention and Pointers","abstract":"Translation-based AMR parsers have recently gained popularity due to their simplicity and effectiveness. They predict linearized graphs as free texts, avoiding explicit structure modeling. However, this simplicity neglects structural locality in AMR graphs and introduces unnecessary tokens to represent coreferences. In this paper, we introduce new target forms of AMR parsing and a novel model, CHAP, which is equipped with causal hierarchical attention and the pointer mechanism, enabling the integration of structures into the Transformer decoder. We empirically explore various alternative modeling options. Experiments show that our model outperforms baseline models on four out of five benchmarks in the setting of no additional data.","sentences":["Translation-based AMR parsers have recently gained popularity due to their simplicity and effectiveness.","They predict linearized graphs as free texts, avoiding explicit structure modeling.","However, this simplicity neglects structural locality in AMR graphs and introduces unnecessary tokens to represent coreferences.","In this paper, we introduce new target forms of AMR parsing and a novel model, CHAP, which is equipped with causal hierarchical attention and the pointer mechanism, enabling the integration of structures into the Transformer decoder.","We empirically explore various alternative modeling options.","Experiments show that our model outperforms baseline models on four out of five benchmarks in the setting of no additional data."],"url":"http://arxiv.org/abs/2310.11964v1"}
{"created":"2023-10-18 13:40:41","title":"Fast Multipole Attention: A Divide-and-Conquer Attention Mechanism for Long Sequences","abstract":"Transformer-based models have achieved state-of-the-art performance in many areas. However, the quadratic complexity of self-attention with respect to the input length hinders the applicability of Transformer-based models to long sequences. To address this, we present Fast Multipole Attention, a new attention mechanism that uses a divide-and-conquer strategy to reduce the time and memory complexity of attention for sequences of length $n$ from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(n \\log n)$ or $O(n)$, while retaining a global receptive field. The hierarchical approach groups queries, keys, and values into $\\mathcal{O}( \\log n)$ levels of resolution, where groups at greater distances are increasingly larger in size and the weights to compute group quantities are learned. As such, the interaction between tokens far from each other is considered in lower resolution in an efficient hierarchical manner. The overall complexity of Fast Multipole Attention is $\\mathcal{O}(n)$ or $\\mathcal{O}(n \\log n)$, depending on whether the queries are down-sampled or not. This multi-level divide-and-conquer strategy is inspired by fast summation methods from $n$-body physics and the Fast Multipole Method. We perform evaluation on autoregressive and bidirectional language modeling tasks and compare our Fast Multipole Attention model with other efficient attention variants on medium-size datasets. We find empirically that the Fast Multipole Transformer performs much better than other efficient transformers in terms of memory size and accuracy. The Fast Multipole Attention mechanism has the potential to empower large language models with much greater sequence lengths, taking the full context into account in an efficient, naturally hierarchical manner during training and when generating long sequences.","sentences":["Transformer-based models have achieved state-of-the-art performance in many areas.","However, the quadratic complexity of self-attention with respect to the input length hinders the applicability of Transformer-based models to long sequences.","To address this, we present Fast Multipole Attention, a new attention mechanism that uses a divide-and-conquer strategy to reduce the time and memory complexity of attention for sequences of length $n$ from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(n \\log n)$ or $O(n)$, while retaining a global receptive field.","The hierarchical approach groups queries, keys, and values into $\\mathcal{O}( \\log n)$ levels of resolution, where groups at greater distances are increasingly larger in size and the weights to compute group quantities are learned.","As such, the interaction between tokens far from each other is considered in lower resolution in an efficient hierarchical manner.","The overall complexity of Fast Multipole Attention is $\\mathcal{O}(n)$ or $\\mathcal{O}(n \\log n)$, depending on whether the queries are down-sampled or not.","This multi-level divide-and-conquer strategy is inspired by fast summation methods from $n$-body physics and the Fast Multipole Method.","We perform evaluation on autoregressive and bidirectional language modeling tasks and compare our Fast Multipole Attention model with other efficient attention variants on medium-size datasets.","We find empirically that the Fast Multipole Transformer performs much better than other efficient transformers in terms of memory size and accuracy.","The Fast Multipole Attention mechanism has the potential to empower large language models with much greater sequence lengths, taking the full context into account in an efficient, naturally hierarchical manner during training and when generating long sequences."],"url":"http://arxiv.org/abs/2310.11960v1"}
{"created":"2023-10-18 13:39:07","title":"A Multi-Scale Decomposition MLP-Mixer for Time Series Analysis","abstract":"Time series data, often characterized by unique composition and complex multi-scale temporal variations, requires special consideration of decomposition and multi-scale modeling in its analysis. Existing deep learning methods on this best fit to only univariate time series, and have not sufficiently accounted for sub-series level modeling and decomposition completeness. To address this, we propose MSD-Mixer, a Multi-Scale Decomposition MLP-Mixer which learns to explicitly decompose the input time series into different components, and represents the components in different layers. To handle multi-scale temporal patterns and inter-channel dependencies, we propose a novel temporal patching approach to model the time series as multi-scale sub-series, i.e., patches, and employ MLPs to mix intra- and inter-patch variations and channel-wise correlations. In addition, we propose a loss function to constrain both the magnitude and autocorrelation of the decomposition residual for decomposition completeness. Through extensive experiments on various real-world datasets for five common time series analysis tasks (long- and short-term forecasting, imputation, anomaly detection, and classification), we demonstrate that MSD-Mixer consistently achieves significantly better performance in comparison with other state-of-the-art task-general and task-specific approaches.","sentences":["Time series data, often characterized by unique composition and complex multi-scale temporal variations, requires special consideration of decomposition and multi-scale modeling in its analysis.","Existing deep learning methods on this best fit to only univariate time series, and have not sufficiently accounted for sub-series level modeling and decomposition completeness.","To address this, we propose MSD-Mixer, a Multi-Scale Decomposition MLP-Mixer which learns to explicitly decompose the input time series into different components, and represents the components in different layers.","To handle multi-scale temporal patterns and inter-channel dependencies, we propose a novel temporal patching approach to model the time series as multi-scale sub-series, i.e., patches, and employ MLPs to mix intra- and inter-patch variations and channel-wise correlations.","In addition, we propose a loss function to constrain both the magnitude and autocorrelation of the decomposition residual for decomposition completeness.","Through extensive experiments on various real-world datasets for five common time series analysis tasks (long- and short-term forecasting, imputation, anomaly detection, and classification), we demonstrate that MSD-Mixer consistently achieves significantly better performance in comparison with other state-of-the-art task-general and task-specific approaches."],"url":"http://arxiv.org/abs/2310.11959v1"}
{"created":"2023-10-18 13:38:03","title":"Emptying the Ocean with a Spoon: Should We Edit Models?","abstract":"We call into question the recently popularized method of direct model editing as a means of correcting factual errors in LLM generations. We contrast model editing with three similar but distinct approaches that pursue better defined objectives: (1) retrieval-based architectures, which decouple factual memory from inference and linguistic capabilities embodied in LLMs; (2) concept erasure methods, which aim at preventing systemic bias in generated text; and (3) attribution methods, which aim at grounding generations into identified textual sources. We argue that direct model editing cannot be trusted as a systematic remedy for the disadvantages inherent to LLMs, and while it has proven potential in improving model explainability, it opens risks by reinforcing the notion that models can be trusted for factuality. We call for cautious promotion and application of model editing as part of the LLM deployment process, and for responsibly limiting the use cases of LLMs to those not relying on editing as a critical component.","sentences":["We call into question the recently popularized method of direct model editing as a means of correcting factual errors in LLM generations.","We contrast model editing with three similar but distinct approaches that pursue better defined objectives: (1) retrieval-based architectures, which decouple factual memory from inference and linguistic capabilities embodied in LLMs; (2) concept erasure methods, which aim at preventing systemic bias in generated text; and (3) attribution methods, which aim at grounding generations into identified textual sources.","We argue that direct model editing cannot be trusted as a systematic remedy for the disadvantages inherent to LLMs, and while it has proven potential in improving model explainability, it opens risks by reinforcing the notion that models can be trusted for factuality.","We call for cautious promotion and application of model editing as part of the LLM deployment process, and for responsibly limiting the use cases of LLMs to those not relying on editing as a critical component."],"url":"http://arxiv.org/abs/2310.11958v1"}
{"created":"2023-10-18 13:37:07","title":"Supporting UAVs with Edge Computing: A Review of Opportunities and Challenges","abstract":"Over the last years, Unmanned Aerial Vehicles (UAVs) have seen significant advancements in sensor capabilities and computational abilities, allowing for efficient autonomous navigation and visual tracking applications. However, the demand for computationally complex tasks has increased faster than advances in battery technology. This opens up possibilities for improvements using edge computing. In edge computing, edge servers can achieve lower latency responses compared to traditional cloud servers through strategic geographic deployments. Furthermore, these servers can maintain superior computational performance compared to UAVs, as they are not limited by battery constraints. Combining these technologies by aiding UAVs with edge servers, research finds measurable improvements in task completion speed, energy efficiency, and reliability across multiple applications and industries. This systematic literature review aims to analyze the current state of research and collect, select, and extract the key areas where UAV activities can be supported and improved through edge computing.","sentences":["Over the last years, Unmanned Aerial Vehicles (UAVs) have seen significant advancements in sensor capabilities and computational abilities, allowing for efficient autonomous navigation and visual tracking applications.","However, the demand for computationally complex tasks has increased faster than advances in battery technology.","This opens up possibilities for improvements using edge computing.","In edge computing, edge servers can achieve lower latency responses compared to traditional cloud servers through strategic geographic deployments.","Furthermore, these servers can maintain superior computational performance compared to UAVs, as they are not limited by battery constraints.","Combining these technologies by aiding UAVs with edge servers, research finds measurable improvements in task completion speed, energy efficiency, and reliability across multiple applications and industries.","This systematic literature review aims to analyze the current state of research and collect, select, and extract the key areas where UAV activities can be supported and improved through edge computing."],"url":"http://arxiv.org/abs/2310.11957v1"}
{"created":"2023-10-18 13:31:10","title":"MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models","abstract":"AI-empowered music processing is a diverse field that encompasses dozens of tasks, ranging from generation tasks (e.g., timbre synthesis) to comprehension tasks (e.g., music classification). For developers and amateurs, it is very difficult to grasp all of these task to satisfy their requirements in music processing, especially considering the huge differences in the representations of music data and the model applicability across platforms among various tasks. Consequently, it is necessary to build a system to organize and integrate these tasks, and thus help practitioners to automatically analyze their demand and call suitable tools as solutions to fulfill their requirements. Inspired by the recent success of large language models (LLMs) in task automation, we develop a system, named MusicAgent, which integrates numerous music-related tools and an autonomous workflow to address user requirements. More specifically, we build 1) toolset that collects tools from diverse sources, including Hugging Face, GitHub, and Web API, etc. 2) an autonomous workflow empowered by LLMs (e.g., ChatGPT) to organize these tools and automatically decompose user requests into multiple sub-tasks and invoke corresponding music tools. The primary goal of this system is to free users from the intricacies of AI-music tools, enabling them to concentrate on the creative aspect. By granting users the freedom to effortlessly combine tools, the system offers a seamless and enriching music experience.","sentences":["AI-empowered music processing is a diverse field that encompasses dozens of tasks, ranging from generation tasks (e.g., timbre synthesis) to comprehension tasks (e.g., music classification).","For developers and amateurs, it is very difficult to grasp all of these task to satisfy their requirements in music processing, especially considering the huge differences in the representations of music data and the model applicability across platforms among various tasks.","Consequently, it is necessary to build a system to organize and integrate these tasks, and thus help practitioners to automatically analyze their demand and call suitable tools as solutions to fulfill their requirements.","Inspired by the recent success of large language models (LLMs) in task automation, we develop a system, named MusicAgent, which integrates numerous music-related tools and an autonomous workflow to address user requirements.","More specifically, we build 1) toolset that collects tools from diverse sources, including Hugging Face, GitHub, and Web API, etc. 2) an autonomous workflow empowered by LLMs (e.g., ChatGPT) to organize these tools and automatically decompose user requests into multiple sub-tasks and invoke corresponding music tools.","The primary goal of this system is to free users from the intricacies of AI-music tools, enabling them to concentrate on the creative aspect.","By granting users the freedom to effortlessly combine tools, the system offers a seamless and enriching music experience."],"url":"http://arxiv.org/abs/2310.11954v1"}
