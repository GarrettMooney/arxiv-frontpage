{"created":"2023-07-25 17:59:59","title":"Benchmarking and Analyzing Generative Data for Visual Recognition","abstract":"Advancements in large pre-trained generative models have expanded their potential as effective data generators in visual recognition. This work delves into the impact of generative images, primarily comparing paradigms that harness external data (\\ie generative \\vs retrieval \\vs original).   Our key contributions are: \\textbf{1) GenBench Construction:} We devise \\textbf{GenBench}, a broad benchmark comprising 22 datasets with 2548 categories, to appraise generative data across various visual recognition tasks. \\textbf{2) CLER Score:} To address the insufficient correlation of existing metrics (\\eg, FID, CLIP score) with downstream recognition performance, we propose \\textbf{CLER}, a training-free metric indicating generative data's efficiency for recognition tasks prior to training. \\textbf{3) New Baselines:} Comparisons of generative data with retrieved data from the same external pool help to elucidate the unique traits of generative data. \\textbf{4) External Knowledge Injection:} By fine-tuning special token embeddings for each category via Textual Inversion, performance improves across 17 datasets, except when dealing with low-resolution reference images.   Our exhaustive benchmark and analysis spotlight generative data's promise in visual recognition, while identifying key challenges for future investigation.","sentences":["Advancements in large pre-trained generative models have expanded their potential as effective data generators in visual recognition.","This work delves into the impact of generative images, primarily comparing paradigms that harness external data (\\ie generative \\vs retrieval \\vs original).   ","Our key contributions are: \\textbf{1) GenBench Construction:}","We devise \\textbf{GenBench}, a broad benchmark comprising 22 datasets with 2548 categories, to appraise generative data across various visual recognition tasks.","\\textbf{2) CLER Score:} To address the insufficient correlation of existing metrics (\\eg, FID, CLIP score) with downstream recognition performance, we propose \\textbf{CLER}, a training-free metric indicating generative data's efficiency for recognition tasks prior to training.","\\textbf{3) New Baselines:} Comparisons of generative data with retrieved data from the same external pool help to elucidate the unique traits of generative data.","\\textbf{4)","External Knowledge Injection:} By fine-tuning special token embeddings for each category via Textual Inversion, performance improves across 17 datasets, except when dealing with low-resolution reference images.   ","Our exhaustive benchmark and analysis spotlight generative data's promise in visual recognition, while identifying key challenges for future investigation."],"url":"http://arxiv.org/abs/2307.13697v1"}
{"created":"2023-07-25 17:58:38","title":"A Compact DAG for Storing and Searching Maximal Common Subsequences","abstract":"Maximal Common Subsequences (MCSs) between two strings X and Y are subsequences of both X and Y that are maximal under inclusion. MCSs relax and generalize the well known and widely used concept of Longest Common Subsequences (LCSs), which can be seen as MCSs of maximum length. While the number both LCSs and MCSs can be exponential in the length of the strings, LCSs have been long exploited for string and text analysis, as simple compact representations of all LCSs between two strings, built via dynamic programming or automata, have been known since the '70s. MCSs appear to have a more challenging structure: even listing them efficiently was an open problem open until recently, thus narrowing the complexity difference between the two problems, but the gap remained significant. In this paper we close the complexity gap: we show how to build DAG of polynomial size-in polynomial time-which allows for efficient operations on the set of all MCSs such as enumeration in Constant Amortized Time per solution (CAT), counting, and random access to the i-th element (i.e., rank and select operations). Other than improving known algorithmic results, this work paves the way for new sequence analysis methods based on MCSs.","sentences":["Maximal Common Subsequences (MCSs) between two strings X and Y are subsequences of both X and Y that are maximal under inclusion.","MCSs relax and generalize the well known and widely used concept of Longest Common Subsequences (LCSs), which can be seen as MCSs of maximum length.","While the number both LCSs and MCSs can be exponential in the length of the strings, LCSs have been long exploited for string and text analysis, as simple compact representations of all LCSs between two strings, built via dynamic programming or automata, have been known since the '70s.","MCSs appear to have a more challenging structure: even listing them efficiently was an open problem open until recently, thus narrowing the complexity difference between the two problems, but the gap remained significant.","In this paper we close the complexity gap: we show how to build DAG of polynomial size-in polynomial time-which allows for efficient operations on the set of all MCSs such as enumeration in Constant Amortized Time per solution (CAT), counting, and random access to the i-th element (i.e., rank and select operations).","Other than improving known algorithmic results, this work paves the way for new sequence analysis methods based on MCSs."],"url":"http://arxiv.org/abs/2307.13695v1"}
{"created":"2023-07-25 17:57:18","title":"Evaluating Large Language Models for Radiology Natural Language Processing","abstract":"The rise of large language models (LLMs) has marked a pivotal shift in the field of natural language processing (NLP). LLMs have revolutionized a multitude of domains, and they have made a significant impact in the medical field. Large language models are now more abundant than ever, and many of these models exhibit bilingual capabilities, proficient in both English and Chinese. However, a comprehensive evaluation of these models remains to be conducted. This lack of assessment is especially apparent within the context of radiology NLP. This study seeks to bridge this gap by critically evaluating thirty two LLMs in interpreting radiology reports, a crucial component of radiology NLP. Specifically, the ability to derive impressions from radiologic findings is assessed. The outcomes of this evaluation provide key insights into the performance, strengths, and weaknesses of these LLMs, informing their practical applications within the medical domain.","sentences":["The rise of large language models (LLMs) has marked a pivotal shift in the field of natural language processing (NLP).","LLMs have revolutionized a multitude of domains, and they have made a significant impact in the medical field.","Large language models are now more abundant than ever, and many of these models exhibit bilingual capabilities, proficient in both English and Chinese.","However, a comprehensive evaluation of these models remains to be conducted.","This lack of assessment is especially apparent within the context of radiology NLP.","This study seeks to bridge this gap by critically evaluating thirty two LLMs in interpreting radiology reports, a crucial component of radiology NLP.","Specifically, the ability to derive impressions from radiologic findings is assessed.","The outcomes of this evaluation provide key insights into the performance, strengths, and weaknesses of these LLMs, informing their practical applications within the medical domain."],"url":"http://arxiv.org/abs/2307.13693v1"}
{"created":"2023-07-25 17:55:19","title":"ARB: Advanced Reasoning Benchmark for Large Language Models","abstract":"Large Language Models (LLMs) have demonstrated remarkable performance on various quantitative reasoning and knowledge benchmarks. However, many of these benchmarks are losing utility as LLMs get increasingly high scores, despite not yet reaching expert performance in these domains. We introduce ARB, a novel benchmark composed of advanced reasoning problems in multiple fields. ARB presents a more challenging test than prior benchmarks, featuring problems in mathematics, physics, biology, chemistry, and law. As a subset of ARB, we introduce a challenging set of math and physics problems which require advanced symbolic reasoning and domain knowledge. We evaluate recent models such as GPT-4 and Claude on ARB and demonstrate that current models score well below 50% on more demanding tasks. In order to improve both automatic and assisted evaluation capabilities, we introduce a rubric-based evaluation approach, allowing GPT-4 to score its own intermediate reasoning steps. Further, we conduct a human evaluation of the symbolic subset of ARB, finding promising agreement between annotators and GPT-4 rubric evaluation scores.","sentences":["Large Language Models (LLMs) have demonstrated remarkable performance on various quantitative reasoning and knowledge benchmarks.","However, many of these benchmarks are losing utility as LLMs get increasingly high scores, despite not yet reaching expert performance in these domains.","We introduce ARB, a novel benchmark composed of advanced reasoning problems in multiple fields.","ARB presents a more challenging test than prior benchmarks, featuring problems in mathematics, physics, biology, chemistry, and law.","As a subset of ARB, we introduce a challenging set of math and physics problems which require advanced symbolic reasoning and domain knowledge.","We evaluate recent models such as GPT-4 and Claude on ARB and demonstrate that current models score well below 50% on more demanding tasks.","In order to improve both automatic and assisted evaluation capabilities, we introduce a rubric-based evaluation approach, allowing GPT-4 to score its own intermediate reasoning steps.","Further, we conduct a human evaluation of the symbolic subset of ARB, finding promising agreement between annotators and GPT-4 rubric evaluation scores."],"url":"http://arxiv.org/abs/2307.13692v1"}
{"created":"2023-07-25 17:55:17","title":"A Comprehensive Review of Recent Research Trends on UAVs","abstract":"The growing interest in unmanned aerial vehicles (UAVs) from both scientific and industrial sectors has attracted a wave of new researchers and substantial investments in this expansive field. However, due to the wide range of topics and subdomains within UAV research, newcomers may find themselves overwhelmed by the numerous options available. It is therefore crucial for those involved in UAV research to recognize its interdisciplinary nature and its connections with other disciplines. This paper presents a comprehensive overview of the UAV field, highlighting recent trends and advancements. Drawing on recent literature reviews and surveys, the review begins by classifying UAVs based on their flight characteristics. It then provides an overview of current research trends in UAVs, utilizing data from the Scopus database to quantify the number of scientific documents associated with each research direction and their interconnections. The paper also explores potential areas for further development in UAVs, including communication, artificial intelligence, remote sensing, miniaturization, swarming and cooperative control, and transformability. Additionally, it discusses the development of aircraft control, commonly used control techniques, and appropriate control algorithms in UAV research. Furthermore, the paper addresses the general hardware and software architecture of UAVs, their applications, and the key issues associated with them. It also provides an overview of current open-source software and hardware projects in the UAV field. By presenting a comprehensive view of the UAV field, this paper aims to enhance understanding of this rapidly evolving and highly interdisciplinary area of research.","sentences":["The growing interest in unmanned aerial vehicles (UAVs) from both scientific and industrial sectors has attracted a wave of new researchers and substantial investments in this expansive field.","However, due to the wide range of topics and subdomains within UAV research, newcomers may find themselves overwhelmed by the numerous options available.","It is therefore crucial for those involved in UAV research to recognize its interdisciplinary nature and its connections with other disciplines.","This paper presents a comprehensive overview of the UAV field, highlighting recent trends and advancements.","Drawing on recent literature reviews and surveys, the review begins by classifying UAVs based on their flight characteristics.","It then provides an overview of current research trends in UAVs, utilizing data from the Scopus database to quantify the number of scientific documents associated with each research direction and their interconnections.","The paper also explores potential areas for further development in UAVs, including communication, artificial intelligence, remote sensing, miniaturization, swarming and cooperative control, and transformability.","Additionally, it discusses the development of aircraft control, commonly used control techniques, and appropriate control algorithms in UAV research.","Furthermore, the paper addresses the general hardware and software architecture of UAVs, their applications, and the key issues associated with them.","It also provides an overview of current open-source software and hardware projects in the UAV field.","By presenting a comprehensive view of the UAV field, this paper aims to enhance understanding of this rapidly evolving and highly interdisciplinary area of research."],"url":"http://arxiv.org/abs/2307.13691v1"}
{"created":"2023-07-25 17:45:41","title":"Noisy k-means++ Revisited","abstract":"The $k$-means++ algorithm by Arthur and Vassilvitskii [SODA 2007] is a classical and time-tested algorithm for the $k$-means problem. While being very practical, the algorithm also has good theoretical guarantees: its solution is $O(\\log k)$-approximate, in expectation.   In a recent work, Bhattacharya, Eube, Roglin, and Schmidt [ESA 2020] considered the following question: does the algorithm retain its guarantees if we allow for a slight adversarial noise in the sampling probability distributions used by the algorithm? This is motivated e.g. by the fact that computations with real numbers in $k$-means++ implementations are inexact.   Surprisingly, the analysis under this scenario gets substantially more difficult and the authors were able to prove only a weaker approximation guarantee of $O(\\log^2 k)$. In this paper, we close the gap by providing a tight, $O(\\log k)$-approximate guarantee for the $k$-means++ algorithm with noise.","sentences":["The $k$-means++ algorithm by Arthur and Vassilvitskii [SODA 2007] is a classical and time-tested algorithm for the $k$-means problem.","While being very practical, the algorithm also has good theoretical guarantees: its solution is $O(\\log k)$-approximate, in expectation.   ","In a recent work, Bhattacharya, Eube, Roglin, and Schmidt [ESA 2020] considered the following question: does the algorithm retain its guarantees if we allow for a slight adversarial noise in the sampling probability distributions used by the algorithm?","This is motivated e.g. by the fact that computations with real numbers in $k$-means++ implementations are inexact.   ","Surprisingly, the analysis under this scenario gets substantially more difficult and the authors were able to prove only a weaker approximation guarantee of $O(\\log^2 k)$.","In this paper, we close the gap by providing a tight, $O(\\log k)$-approximate guarantee for the $k$-means++ algorithm with noise."],"url":"http://arxiv.org/abs/2307.13685v1"}
{"created":"2023-07-25 17:39:39","title":"The Visual Language of Fabrics","abstract":"We introduce text2fabric, a novel dataset that links free-text descriptions to various fabric materials. The dataset comprises 15,000 natural language descriptions associated to 3,000 corresponding images of fabric materials. Traditionally, material descriptions come in the form of tags/keywords, which limits their expressivity, induces pre-existing knowledge of the appropriate vocabulary, and ultimately leads to a chopped description system. Therefore, we study the use of free-text as a more appropriate way to describe material appearance, taking the use case of fabrics as a common item that non-experts may often deal with. Based on the analysis of the dataset, we identify a compact lexicon, set of attributes and key structure that emerge from the descriptions. This allows us to accurately understand how people describe fabrics and draw directions for generalization to other types of materials. We also show that our dataset enables specializing large vision-language models such as CLIP, creating a meaningful latent space for fabric appearance, and significantly improving applications such as fine-grained material retrieval and automatic captioning.","sentences":["We introduce text2fabric, a novel dataset that links free-text descriptions to various fabric materials.","The dataset comprises 15,000 natural language descriptions associated to 3,000 corresponding images of fabric materials.","Traditionally, material descriptions come in the form of tags/keywords, which limits their expressivity, induces pre-existing knowledge of the appropriate vocabulary, and ultimately leads to a chopped description system.","Therefore, we study the use of free-text as a more appropriate way to describe material appearance, taking the use case of fabrics as a common item that non-experts may often deal with.","Based on the analysis of the dataset, we identify a compact lexicon, set of attributes and key structure that emerge from the descriptions.","This allows us to accurately understand how people describe fabrics and draw directions for generalization to other types of materials.","We also show that our dataset enables specializing large vision-language models such as CLIP, creating a meaningful latent space for fabric appearance, and significantly improving applications such as fine-grained material retrieval and automatic captioning."],"url":"http://arxiv.org/abs/2307.13681v1"}
{"created":"2023-07-25 17:36:56","title":"High Probability Analysis for Non-Convex Stochastic Optimization with Clipping","abstract":"Gradient clipping is a commonly used technique to stabilize the training process of neural networks. A growing body of studies has shown that gradient clipping is a promising technique for dealing with the heavy-tailed behavior that emerged in stochastic optimization as well. While gradient clipping is significant, its theoretical guarantees are scarce. Most theoretical guarantees only provide an in-expectation analysis and only focus on optimization performance. In this paper, we provide high probability analysis in the non-convex setting and derive the optimization bound and the generalization bound simultaneously for popular stochastic optimization algorithms with gradient clipping, including stochastic gradient descent and its variants of momentum and adaptive stepsizes. With the gradient clipping, we study a heavy-tailed assumption that the gradients only have bounded $\\alpha$-th moments for some $\\alpha \\in (1, 2]$, which is much weaker than the standard bounded second-moment assumption. Overall, our study provides a relatively complete picture for the theoretical guarantee of stochastic optimization algorithms with clipping.","sentences":["Gradient clipping is a commonly used technique to stabilize the training process of neural networks.","A growing body of studies has shown that gradient clipping is a promising technique for dealing with the heavy-tailed behavior that emerged in stochastic optimization as well.","While gradient clipping is significant, its theoretical guarantees are scarce.","Most theoretical guarantees only provide an in-expectation analysis and only focus on optimization performance.","In this paper, we provide high probability analysis in the non-convex setting and derive the optimization bound and the generalization bound simultaneously for popular stochastic optimization algorithms with gradient clipping, including stochastic gradient descent and its variants of momentum and adaptive stepsizes.","With the gradient clipping, we study a heavy-tailed assumption that the gradients only have bounded $\\alpha$-th moments for some $\\alpha \\in (1, 2]$, which is much weaker than the standard bounded second-moment assumption.","Overall, our study provides a relatively complete picture for the theoretical guarantee of stochastic optimization algorithms with clipping."],"url":"http://arxiv.org/abs/2307.13680v1"}
{"created":"2023-07-25 17:36:34","title":"RED CoMETS: An ensemble classifier for symbolically represented multivariate time series","abstract":"Multivariate time series classification is a rapidly growing research field with practical applications in finance, healthcare, engineering, and more. The complexity of classifying multivariate time series data arises from its high dimensionality, temporal dependencies, and varying lengths. This paper introduces a novel ensemble classifier called RED CoMETS (Random Enhanced Co-eye for Multivariate Time Series), which addresses these challenges. RED CoMETS builds upon the success of Co-eye, an ensemble classifier specifically designed for symbolically represented univariate time series, and extends its capabilities to handle multivariate data. The performance of RED CoMETS is evaluated on benchmark datasets from the UCR archive, where it demonstrates competitive accuracy when compared to state-of-the-art techniques in multivariate settings. Notably, it achieves the highest reported accuracy in the literature for the 'HandMovementDirection' dataset. Moreover, the proposed method significantly reduces computation time compared to Co-eye, making it an efficient and effective choice for multivariate time series classification.","sentences":["Multivariate time series classification is a rapidly growing research field with practical applications in finance, healthcare, engineering, and more.","The complexity of classifying multivariate time series data arises from its high dimensionality, temporal dependencies, and varying lengths.","This paper introduces a novel ensemble classifier called RED CoMETS (Random Enhanced Co-eye for Multivariate Time Series), which addresses these challenges.","RED CoMETS builds upon the success of Co-eye, an ensemble classifier specifically designed for symbolically represented univariate time series, and extends its capabilities to handle multivariate data.","The performance of RED CoMETS is evaluated on benchmark datasets from the UCR archive, where it demonstrates competitive accuracy when compared to state-of-the-art techniques in multivariate settings.","Notably, it achieves the highest reported accuracy in the literature for the 'HandMovementDirection' dataset.","Moreover, the proposed method significantly reduces computation time compared to Co-eye, making it an efficient and effective choice for multivariate time series classification."],"url":"http://arxiv.org/abs/2307.13679v1"}
{"created":"2023-07-25 17:36:06","title":"Smartpick: Workload Prediction for Serverless-enabled Scalable Data Analytics Systems","abstract":"Many data analytic systems have adopted a newly emerging compute resource, serverless (SL), to handle data analytics queries in a timely and cost-efficient manner, i.e., serverless data analytics. While these systems can start processing queries quickly thanks to the agility and scalability of SL, they may encounter performance- and cost-bottlenecks based on workloads due to SL's worse performance and more expensive cost than traditional compute resources, e.g., virtual machine (VM). In this project, we introduce Smartpick, a SL-enabled scalable data analytics system that exploits SL and VM together to realize composite benefits, i.e., agility from SL and better performance with reduced cost from VM. Smartpick uses a machine learning prediction scheme, decision-tree based Random Forest with Bayesian Optimizer, to determine SL and VM configurations, i.e., how many SL and VM instances for queries, that meet cost-performance goals. Smartpick offers a knob for applications to allow them to explore a richer cost-performance tradeoff space opened by exploiting SL and VM together. To maximize the benefits of SL, Smartpick supports a simple but strong mechanism, called relay-instances. Smartpick also supports event-driven prediction model retraining to deal with workload dynamics. A Smartpick prototype was implemented on Spark and deployed on live test-beds, Amazon AWS and Google Cloud Platform. Evaluation results indicate 97.05% and 83.49% prediction accuracies respectively with up to 50% cost reduction as opposed to the baselines. The results also confirm that Smartpick allows data analytics applications to navigate the richer cost-performance tradeoff space efficiently and to handle workload dynamics effectively and automatically.","sentences":["Many data analytic systems have adopted a newly emerging compute resource, serverless (SL), to handle data analytics queries in a timely and cost-efficient manner, i.e., serverless data analytics.","While these systems can start processing queries quickly thanks to the agility and scalability of SL, they may encounter performance-","and cost-bottlenecks based on workloads due to SL's worse performance and more expensive cost than traditional compute resources, e.g., virtual machine (VM).","In this project, we introduce Smartpick, a SL-enabled scalable data analytics system that exploits SL and VM together to realize composite benefits, i.e., agility from SL and better performance with reduced cost from VM.","Smartpick uses a machine learning prediction scheme, decision-tree based Random Forest with Bayesian Optimizer, to determine SL and VM configurations, i.e., how many SL and VM instances for queries, that meet cost-performance goals.","Smartpick offers a knob for applications to allow them to explore a richer cost-performance tradeoff space opened by exploiting SL and VM together.","To maximize the benefits of SL, Smartpick supports a simple but strong mechanism, called relay-instances.","Smartpick also supports event-driven prediction model retraining to deal with workload dynamics.","A Smartpick prototype was implemented on Spark and deployed on live test-beds, Amazon AWS and Google Cloud Platform.","Evaluation results indicate 97.05% and 83.49% prediction accuracies respectively with up to 50% cost reduction as opposed to the baselines.","The results also confirm that Smartpick allows data analytics applications to navigate the richer cost-performance tradeoff space efficiently and to handle workload dynamics effectively and automatically."],"url":"http://arxiv.org/abs/2307.13677v1"}
{"created":"2023-07-25 17:14:49","title":"Parametric Subtyping for Structural Parametric Polymorphism","abstract":"We study the interaction of structural subtyping with parametric polymorphism and recursively defined type constructors. Although structural subtyping is undecidable in this setting, we describe a notion of parametricity for type constructors and then exploit it to define parametric subtyping, a conceptually simple, decidable, and expressive fragment of structural subtyping that strictly generalizes nominal subtyping. We present and prove correct an effective saturation-based decision procedure for parametric subtyping, demonstrating its applicability using a variety of examples. An implementation of this decision procedure is available in an online repository.","sentences":["We study the interaction of structural subtyping with parametric polymorphism and recursively defined type constructors.","Although structural subtyping is undecidable in this setting, we describe a notion of parametricity for type constructors and then exploit it to define parametric subtyping, a conceptually simple, decidable, and expressive fragment of structural subtyping that strictly generalizes nominal subtyping.","We present and prove correct an effective saturation-based decision procedure for parametric subtyping, demonstrating its applicability using a variety of examples.","An implementation of this decision procedure is available in an online repository."],"url":"http://arxiv.org/abs/2307.13661v1"}
{"created":"2023-07-25 17:13:11","title":"Computing the Gromov--Hausdorff distance using first-order methods","abstract":"The Gromov--Hausdorff distance measures the difference in shape between compact metric spaces and poses a notoriously difficult problem in combinatorial optimization. We introduce its quadratic relaxation over a convex polytope whose solutions provably deliver the Gromov--Hausdorff distance. The optimality guarantee is enabled by the fact that the search space of our approach is not constrained to a generalization of bijections, unlike in other relaxations such as the Gromov--Wasserstein distance.   We suggest the Frank--Wolfe algorithm with $O(n^3)$-time iterations for solving the relaxation and numerically demonstrate its performance on metric spaces of hundreds of points. In particular, we obtain a new upper bound of the Gromov--Hausdorff distance between the unit circle and the unit hemisphere equipped with Euclidean metric. Our approach is implemented as a Python package dGH.","sentences":["The Gromov--Hausdorff distance measures the difference in shape between compact metric spaces and poses a notoriously difficult problem in combinatorial optimization.","We introduce its quadratic relaxation over a convex polytope whose solutions provably deliver the Gromov--Hausdorff distance.","The optimality guarantee is enabled by the fact that the search space of our approach is not constrained to a generalization of bijections, unlike in other relaxations such as the Gromov--Wasserstein distance.   ","We suggest the Frank--Wolfe algorithm with $O(n^3)$-time iterations for solving the relaxation and numerically demonstrate its performance on metric spaces of hundreds of points.","In particular, we obtain a new upper bound of the Gromov--Hausdorff distance between the unit circle and the unit hemisphere equipped with Euclidean metric.","Our approach is implemented as a Python package dGH."],"url":"http://arxiv.org/abs/2307.13660v1"}
{"created":"2023-07-25 17:09:28","title":"Towards an AI Accountability Policy","abstract":"This white paper is a response to the \"AI Accountability Policy Request for Comments\" by the National Telecommunications and Information Administration of the United States. The question numbers for which comments were requested are provided in superscripts at the end of key sentences answering the respective questions. The white paper offers a set of interconnected recommendations for an AI accountability policy.","sentences":["This white paper is a response to the \"AI Accountability Policy Request for Comments\" by the National Telecommunications and Information Administration of the United States.","The question numbers for which comments were requested are provided in superscripts at the end of key sentences answering the respective questions.","The white paper offers a set of interconnected recommendations for an AI accountability policy."],"url":"http://arxiv.org/abs/2307.13658v1"}
{"created":"2023-07-25 17:08:21","title":"A Soft Robotic Gripper with Active Palm for In-Hand Object Reorientation","abstract":"The human hand has an inherent ability to manipulate and re-orientate objects without external assistance. As a consequence, we are able to operate tools and perform an array of actions using just one hand, without having to continuously re-grasp objects. Emulating this functionality in robotic end-effectors remains a key area of study with efforts being made to create advanced control systems that could be used to operate complex manipulators. In this paper, a three fingered soft gripper with an active rotary palm is presented as a simpler, alternative method of performing in-hand rotations. The gripper, complete with its pneumatic suction cup to prevent object slippage, was tested and found to be able to effectively grasp and rotate a variety of objects both quickly and precisely.","sentences":["The human hand has an inherent ability to manipulate and re-orientate objects without external assistance.","As a consequence, we are able to operate tools and perform an array of actions using just one hand, without having to continuously re-grasp objects.","Emulating this functionality in robotic end-effectors remains a key area of study with efforts being made to create advanced control systems that could be used to operate complex manipulators.","In this paper, a three fingered soft gripper with an active rotary palm is presented as a simpler, alternative method of performing in-hand rotations.","The gripper, complete with its pneumatic suction cup to prevent object slippage, was tested and found to be able to effectively grasp and rotate a variety of objects both quickly and precisely."],"url":"http://arxiv.org/abs/2307.13657v1"}
{"created":"2023-07-25 17:02:38","title":"A Comprehensive Evaluation and Analysis Study for Chinese Spelling Check","abstract":"With the development of pre-trained models and the incorporation of phonetic and graphic information, neural models have achieved high scores in Chinese Spelling Check (CSC). However, it does not provide a comprehensive reflection of the models' capability due to the limited test sets. In this study, we abstract the representative model paradigm, implement it with nine structures and experiment them on comprehensive test sets we constructed with different purposes. We perform a detailed analysis of the results and find that: 1) Fusing phonetic and graphic information reasonably is effective for CSC. 2) Models are sensitive to the error distribution of the test set, which reflects the shortcomings of models and reveals the direction we should work on. 3) Whether or not the errors and contexts have been seen has a significant impact on models. 4) The commonly used benchmark, SIGHAN, can not reliably evaluate models' performance.","sentences":["With the development of pre-trained models and the incorporation of phonetic and graphic information, neural models have achieved high scores in Chinese Spelling Check (CSC).","However, it does not provide a comprehensive reflection of the models' capability due to the limited test sets.","In this study, we abstract the representative model paradigm, implement it with nine structures and experiment them on comprehensive test sets we constructed with different purposes.","We perform a detailed analysis of the results and find that: 1) Fusing phonetic and graphic information reasonably is effective for CSC.","2) Models are sensitive to the error distribution of the test set, which reflects the shortcomings of models and reveals the direction we should work on.","3) Whether or not the errors and contexts have been seen has a significant impact on models.","4) The commonly used benchmark, SIGHAN, can not reliably evaluate models' performance."],"url":"http://arxiv.org/abs/2307.13655v1"}
{"created":"2023-07-25 17:01:10","title":"Personal Protective Equipment Detection in Extreme Construction Conditions","abstract":"Object detection has been widely applied for construction safety management, especially personal protective equipment (PPE) detection. Though the existing PPE detection models trained on conventional datasets have achieved excellent results, their performance dramatically declines in extreme construction conditions. A robust detection model NST-YOLOv5 is developed by combining the neural style transfer (NST) and YOLOv5 technologies. Five extreme conditions are considered and simulated via the NST module to endow the detection model with excellent robustness, including low light, intense light, sand dust, fog, and rain. Experiments show that the NST has great potential as a tool for extreme data synthesis since it is better at simulating extreme conditions than other traditional image processing algorithms and helps the NST-YOLOv5 achieve 0.141 and 0.083 mAP_(05:95) improvements in synthesized and real-world extreme data. This study provides a new feasible way to obtain a more robust detection model for extreme construction conditions.","sentences":["Object detection has been widely applied for construction safety management, especially personal protective equipment (PPE) detection.","Though the existing PPE detection models trained on conventional datasets have achieved excellent results, their performance dramatically declines in extreme construction conditions.","A robust detection model NST-YOLOv5 is developed by combining the neural style transfer (NST) and YOLOv5 technologies.","Five extreme conditions are considered and simulated via the NST module to endow the detection model with excellent robustness, including low light, intense light, sand dust, fog, and rain.","Experiments show that the NST has great potential as a tool for extreme data synthesis since it is better at simulating extreme conditions than other traditional image processing algorithms and helps the NST-YOLOv5 achieve 0.141 and 0.083 mAP_(05:95) improvements in synthesized and real-world extreme data.","This study provides a new feasible way to obtain a more robust detection model for extreme construction conditions."],"url":"http://arxiv.org/abs/2307.13654v1"}
{"created":"2023-07-25 16:55:13","title":"QuickQual: Lightweight, convenient retinal image quality scoring with off-the-shelf pretrained models","abstract":"Image quality remains a key problem for both traditional and deep learning (DL)-based approaches to retinal image analysis, but identifying poor quality images can be time consuming and subjective. Thus, automated methods for retinal image quality scoring (RIQS) are needed. The current state-of-the-art is MCFNet, composed of three Densenet121 backbones each operating in a different colour space. MCFNet, and the EyeQ dataset released by the same authors, was a huge step forward for RIQS. We present QuickQual, a simple approach to RIQS, consisting of a single off-the-shelf ImageNet-pretrained Densenet121 backbone plus a Support Vector Machine (SVM). QuickQual performs very well, setting a new state-of-the-art for EyeQ (Accuracy: 88.50% vs 88.00% for MCFNet; AUC: 0.9687 vs 0.9588). This suggests that RIQS can be solved with generic perceptual features learned on natural images, as opposed to requiring DL models trained on large amounts of fundus images. Additionally, we propose a Fixed Prior linearisation scheme, that converts EyeQ from a 3-way classification to a continuous logistic regression task. For this task, we present a second model, QuickQual MEga Minified Estimator (QuickQual-MEME), that consists of only 10 parameters on top of an off-the-shelf Densenet121 and can distinguish between gradable and ungradable images with an accuracy of 89.18% (AUC: 0.9537). Code and model are available on GitHub: https://github.com/justinengelmann/QuickQual . QuickQual is so lightweight, that the entire inference code (and even the parameters for QuickQual-MEME) is already contained in this paper.","sentences":["Image quality remains a key problem for both traditional and deep learning (DL)-based approaches to retinal image analysis, but identifying poor quality images can be time consuming and subjective.","Thus, automated methods for retinal image quality scoring (RIQS) are needed.","The current state-of-the-art is MCFNet, composed of three Densenet121 backbones each operating in a different colour space.","MCFNet, and the EyeQ dataset released by the same authors, was a huge step forward for RIQS.","We present QuickQual, a simple approach to RIQS, consisting of a single off-the-shelf ImageNet-pretrained Densenet121 backbone plus a Support Vector Machine (SVM).","QuickQual performs very well, setting a new state-of-the-art for EyeQ (Accuracy: 88.50% vs 88.00% for MCFNet; AUC: 0.9687 vs 0.9588).","This suggests that RIQS can be solved with generic perceptual features learned on natural images, as opposed to requiring DL models trained on large amounts of fundus images.","Additionally, we propose a Fixed Prior linearisation scheme, that converts EyeQ from a 3-way classification to a continuous logistic regression task.","For this task, we present a second model, QuickQual MEga Minified Estimator (QuickQual-MEME), that consists of only 10 parameters on top of an off-the-shelf Densenet121 and can distinguish between gradable and ungradable images with an accuracy of 89.18% (AUC: 0.9537).","Code and model are available on GitHub: https://github.com/justinengelmann/QuickQual .","QuickQual is so lightweight, that the entire inference code (and even the parameters for QuickQual-MEME) is already contained in this paper."],"url":"http://arxiv.org/abs/2307.13646v1"}
{"created":"2023-07-25 16:54:48","title":"Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation","abstract":"Obtaining labelled data in medical image segmentation is challenging due to the need for pixel-level annotations by experts. Recent works have shown that augmenting the object of interest with deformable transformations can help mitigate this challenge. However, these transformations have been learned globally for the image, limiting their transferability across datasets or applicability in problems where image alignment is difficult. While object-centric augmentations provide a great opportunity to overcome these issues, existing works are only focused on position and random transformations without considering shape variations of the objects. To this end, we propose a novel object-centric data augmentation model that is able to learn the shape variations for the objects of interest and augment the object in place without modifying the rest of the image. We demonstrated its effectiveness in improving kidney tumour segmentation when leveraging shape variations learned both from within the same dataset and transferred from external datasets.","sentences":["Obtaining labelled data in medical image segmentation is challenging due to the need for pixel-level annotations by experts.","Recent works have shown that augmenting the object of interest with deformable transformations can help mitigate this challenge.","However, these transformations have been learned globally for the image, limiting their transferability across datasets or applicability in problems where image alignment is difficult.","While object-centric augmentations provide a great opportunity to overcome these issues, existing works are only focused on position and random transformations without considering shape variations of the objects.","To this end, we propose a novel object-centric data augmentation model that is able to learn the shape variations for the objects of interest and augment the object in place without modifying the rest of the image.","We demonstrated its effectiveness in improving kidney tumour segmentation when leveraging shape variations learned both from within the same dataset and transferred from external datasets."],"url":"http://arxiv.org/abs/2307.13645v1"}
{"created":"2023-07-25 16:49:54","title":"Safety Margins for Reinforcement Learning","abstract":"Any autonomous controller will be unsafe in some situations. The ability to quantitatively identify when these unsafe situations are about to occur is crucial for drawing timely human oversight in, e.g., freight transportation applications. In this work, we demonstrate that the true criticality of an agent's situation can be robustly defined as the mean reduction in reward given some number of random actions. Proxy criticality metrics that are computable in real-time (i.e., without actually simulating the effects of random actions) can be compared to the true criticality, and we show how to leverage these proxy metrics to generate safety margins, which directly tie the consequences of potentially incorrect actions to an anticipated loss in overall performance. We evaluate our approach on learned policies from APE-X and A3C within an Atari environment, and demonstrate how safety margins decrease as agents approach failure states. The integration of safety margins into programs for monitoring deployed agents allows for the real-time identification of potentially catastrophic situations.","sentences":["Any autonomous controller will be unsafe in some situations.","The ability to quantitatively identify when these unsafe situations are about to occur is crucial for drawing timely human oversight in, e.g., freight transportation applications.","In this work, we demonstrate that the true criticality of an agent's situation can be robustly defined as the mean reduction in reward given some number of random actions.","Proxy criticality metrics that are computable in real-time (i.e., without actually simulating the effects of random actions) can be compared to the true criticality, and we show how to leverage these proxy metrics to generate safety margins, which directly tie the consequences of potentially incorrect actions to an anticipated loss in overall performance.","We evaluate our approach on learned policies from APE-X and A3C within an Atari environment, and demonstrate how safety margins decrease as agents approach failure states.","The integration of safety margins into programs for monitoring deployed agents allows for the real-time identification of potentially catastrophic situations."],"url":"http://arxiv.org/abs/2307.13642v1"}
{"created":"2023-07-25 16:45:35","title":"Optical Flow boosts Unsupervised Localization and Segmentation","abstract":"Unsupervised localization and segmentation are long-standing robot vision challenges that describe the critical ability for an autonomous robot to learn to decompose images into individual objects without labeled data. These tasks are important because of the limited availability of dense image manual annotation and the promising vision of adapting to an evolving set of object categories in lifelong learning. Most recent methods focus on using visual appearance continuity as object cues by spatially clustering features obtained from self-supervised vision transformers (ViT). In this work, we leverage motion cues, inspired by the common fate principle that pixels that share similar movements tend to belong to the same object. We propose a new loss term formulation that uses optical flow in unlabeled videos to encourage self-supervised ViT features to become closer to each other if their corresponding spatial locations share similar movements, and vice versa. We use the proposed loss function to finetune vision transformers that were originally trained on static images. Our fine-tuning procedure outperforms state-of-the-art techniques for unsupervised semantic segmentation through linear probing, without the use of any labeled data. This procedure also demonstrates increased performance over original ViT networks across unsupervised object localization and semantic segmentation benchmarks.","sentences":["Unsupervised localization and segmentation are long-standing robot vision challenges that describe the critical ability for an autonomous robot to learn to decompose images into individual objects without labeled data.","These tasks are important because of the limited availability of dense image manual annotation and the promising vision of adapting to an evolving set of object categories in lifelong learning.","Most recent methods focus on using visual appearance continuity as object cues by spatially clustering features obtained from self-supervised vision transformers (ViT).","In this work, we leverage motion cues, inspired by the common fate principle that pixels that share similar movements tend to belong to the same object.","We propose a new loss term formulation that uses optical flow in unlabeled videos to encourage self-supervised ViT features to become closer to each other if their corresponding spatial locations share similar movements, and vice versa.","We use the proposed loss function to finetune vision transformers that were originally trained on static images.","Our fine-tuning procedure outperforms state-of-the-art techniques for unsupervised semantic segmentation through linear probing, without the use of any labeled data.","This procedure also demonstrates increased performance over original ViT networks across unsupervised object localization and semantic segmentation benchmarks."],"url":"http://arxiv.org/abs/2307.13640v1"}
{"created":"2023-07-25 16:42:06","title":"Fake It Without Making It: Conditioned Face Generation for Accurate 3D Face Shape Estimation","abstract":"Accurate 3D face shape estimation is an enabling technology with applications in healthcare, security, and creative industries, yet current state-of-the-art methods either rely on self-supervised training with 2D image data or supervised training with very limited 3D data. To bridge this gap, we present a novel approach which uses a conditioned stable diffusion model for face image generation, leveraging the abundance of 2D facial information to inform 3D space. By conditioning stable diffusion on depth maps sampled from a 3D Morphable Model (3DMM) of the human face, we generate diverse and shape-consistent images, forming the basis of SynthFace. We introduce this large-scale synthesised dataset of 250K photorealistic images and corresponding 3DMM parameters. We further propose ControlFace, a deep neural network, trained on SynthFace, which achieves competitive performance on the NoW benchmark, without requiring 3D supervision or manual 3D asset creation.","sentences":["Accurate 3D face shape estimation is an enabling technology with applications in healthcare, security, and creative industries, yet current state-of-the-art methods either rely on self-supervised training with 2D image data or supervised training with very limited 3D data.","To bridge this gap, we present a novel approach which uses a conditioned stable diffusion model for face image generation, leveraging the abundance of 2D facial information to inform 3D space.","By conditioning stable diffusion on depth maps sampled from a 3D Morphable Model (3DMM) of the human face, we generate diverse and shape-consistent images, forming the basis of SynthFace.","We introduce this large-scale synthesised dataset of 250K photorealistic images and corresponding 3DMM parameters.","We further propose ControlFace, a deep neural network, trained on SynthFace, which achieves competitive performance on the NoW benchmark, without requiring 3D supervision or manual 3D asset creation."],"url":"http://arxiv.org/abs/2307.13639v1"}
{"created":"2023-07-25 16:39:35","title":"Insights into Cognitive Engagement: Comparing the Effectiveness of Game-Based and Video-Based Learning","abstract":"The analysis of brain signals holds considerable importance in enhancing our comprehension of diverse learning techniques and cognitive mechanisms. Game-based learning is increasingly being recognized for its interactive and engaging educational approach. A pilot study of twelve participants divided into experimental and control groups was conducted to understand its effects on cognitive processes. Both groups were provided with the same contents regarding the basic structure of the graph. The participants in the experimental group engaged in a quiz-based game, while those in the control group watched a pre-recorded video. Functional Near-Infrared Spectroscopy (fNIRS) was employed to acquire cerebral signals, and a series of pre and post-tests were administered. The findings of our study indicate that the group engaged in the game activity displayed elevated levels of oxygenated hemoglobin compared to the group involved in watching videos. Conversely, the deoxygenated hemoglobin levels remained relatively consistent across both groups throughout the learning process. The aforementioned findings suggest that the use of game-based learning has a substantial influence on cognitive processes. Furthermore, it is evident that both the game and video groups exhibited higher neural activity in the Lateral Prefrontal cortex (PFC). The oxygenated hemoglobin ratio demonstrates that the game group had 2.33 times more neural processing in the Lateral PFC than the video group. This data is further supported by the knowledge gain analysis, which indicates that the game-based approach resulted in a 47.74% higher knowledge gain than the video group, as calculated from the difference in pre-and post-test scores.","sentences":["The analysis of brain signals holds considerable importance in enhancing our comprehension of diverse learning techniques and cognitive mechanisms.","Game-based learning is increasingly being recognized for its interactive and engaging educational approach.","A pilot study of twelve participants divided into experimental and control groups was conducted to understand its effects on cognitive processes.","Both groups were provided with the same contents regarding the basic structure of the graph.","The participants in the experimental group engaged in a quiz-based game, while those in the control group watched a pre-recorded video.","Functional Near-Infrared Spectroscopy (fNIRS) was employed to acquire cerebral signals, and a series of pre and post-tests were administered.","The findings of our study indicate that the group engaged in the game activity displayed elevated levels of oxygenated hemoglobin compared to the group involved in watching videos.","Conversely, the deoxygenated hemoglobin levels remained relatively consistent across both groups throughout the learning process.","The aforementioned findings suggest that the use of game-based learning has a substantial influence on cognitive processes.","Furthermore, it is evident that both the game and video groups exhibited higher neural activity in the Lateral Prefrontal cortex (PFC).","The oxygenated hemoglobin ratio demonstrates that the game group had 2.33 times more neural processing in the Lateral PFC than the video group.","This data is further supported by the knowledge gain analysis, which indicates that the game-based approach resulted in a 47.74% higher knowledge gain than the video group, as calculated from the difference in pre-and post-test scores."],"url":"http://arxiv.org/abs/2307.13637v1"}
{"created":"2023-07-25 16:31:59","title":"Mitigating Mainstream Bias in Recommendation via Cost-sensitive Learning","abstract":"Mainstream bias, where some users receive poor recommendations because their preferences are uncommon or simply because they are less active, is an important aspect to consider regarding fairness in recommender systems. Existing methods to mitigate mainstream bias do not explicitly model the importance of these non-mainstream users or, when they do, it is in a way that is not necessarily compatible with the data and recommendation model at hand. In contrast, we use the recommendation utility as a more generic and implicit proxy to quantify mainstreamness, and propose a simple user-weighting approach to incorporate it into the training process while taking the cost of potential recommendation errors into account. We provide extensive experimental results showing that quantifying mainstreamness via utility is better able at identifying non-mainstream users, and that they are indeed better served when training the model in a cost-sensitive way. This is achieved with negligible or no loss in overall recommendation accuracy, meaning that the models learn a better balance across users. In addition, we show that research of this kind, which evaluates recommendation quality at the individual user level, may not be reliable if not using enough interactions when assessing model performance.","sentences":["Mainstream bias, where some users receive poor recommendations because their preferences are uncommon or simply because they are less active, is an important aspect to consider regarding fairness in recommender systems.","Existing methods to mitigate mainstream bias do not explicitly model the importance of these non-mainstream users or, when they do, it is in a way that is not necessarily compatible with the data and recommendation model at hand.","In contrast, we use the recommendation utility as a more generic and implicit proxy to quantify mainstreamness, and propose a simple user-weighting approach to incorporate it into the training process while taking the cost of potential recommendation errors into account.","We provide extensive experimental results showing that quantifying mainstreamness via utility is better able at identifying non-mainstream users, and that they are indeed better served when training the model in a cost-sensitive way.","This is achieved with negligible or no loss in overall recommendation accuracy, meaning that the models learn a better balance across users.","In addition, we show that research of this kind, which evaluates recommendation quality at the individual user level, may not be reliable if not using enough interactions when assessing model performance."],"url":"http://arxiv.org/abs/2307.13632v1"}
{"created":"2023-07-25 16:31:20","title":"Contributions to the Improvement of Question Answering Systems in the Biomedical Domain","abstract":"This thesis work falls within the framework of question answering (QA) in the biomedical domain where several specific challenges are addressed, such as specialized lexicons and terminologies, the types of treated questions, and the characteristics of targeted documents. We are particularly interested in studying and improving methods that aim at finding accurate and short answers to biomedical natural language questions from a large scale of biomedical textual documents in English. QA aims at providing inquirers with direct, short and precise answers to their natural language questions. In this Ph.D. thesis, we propose four contributions to improve the performance of QA in the biomedical domain. In our first contribution, we propose a machine learning-based method for question type classification to determine the types of given questions which enable to a biomedical QA system to use the appropriate answer extraction method. We also propose an another machine learning-based method to assign one or more topics (e.g., pharmacological, test, treatment, etc.) to given questions in order to determine the semantic types of the expected answers which are very useful in generating specific answer retrieval strategies. In the second contribution, we first propose a document retrieval method to retrieve a set of relevant documents that are likely to contain the answers to biomedical questions from the MEDLINE database. We then present a passage retrieval method to retrieve a set of relevant passages to questions. In the third contribution, we propose specific answer extraction methods to generate both exact and ideal answers. Finally, in the fourth contribution, we develop a fully automated semantic biomedical QA system called SemBioNLQA which is able to deal with a variety of natural language questions and to generate appropriate answers by providing both exact and ideal answers.","sentences":["This thesis work falls within the framework of question answering (QA) in the biomedical domain where several specific challenges are addressed, such as specialized lexicons and terminologies, the types of treated questions, and the characteristics of targeted documents.","We are particularly interested in studying and improving methods that aim at finding accurate and short answers to biomedical natural language questions from a large scale of biomedical textual documents in English.","QA aims at providing inquirers with direct, short and precise answers to their natural language questions.","In this Ph.D. thesis, we propose four contributions to improve the performance of QA in the biomedical domain.","In our first contribution, we propose a machine learning-based method for question type classification to determine the types of given questions which enable to a biomedical QA system to use the appropriate answer extraction method.","We also propose an another machine learning-based method to assign one or more topics (e.g., pharmacological, test, treatment, etc.) to given questions in order to determine the semantic types of the expected answers which are very useful in generating specific answer retrieval strategies.","In the second contribution, we first propose a document retrieval method to retrieve a set of relevant documents that are likely to contain the answers to biomedical questions from the MEDLINE database.","We then present a passage retrieval method to retrieve a set of relevant passages to questions.","In the third contribution, we propose specific answer extraction methods to generate both exact and ideal answers.","Finally, in the fourth contribution, we develop a fully automated semantic biomedical QA system called SemBioNLQA which is able to deal with a variety of natural language questions and to generate appropriate answers by providing both exact and ideal answers."],"url":"http://arxiv.org/abs/2307.13631v1"}
{"created":"2023-07-25 16:23:32","title":"Scaling machine learning-based chemical plant simulation: A method for fine-tuning a model to induce stable fixed points","abstract":"Idealized first-principles models of chemical plants can be inaccurate. An alternative is to fit a Machine Learning (ML) model directly to plant sensor data. We use a structured approach: Each unit within the plant gets represented by one ML model. After fitting the models to the data, the models are connected into a flowsheet-like directed graph. We find that for smaller plants, this approach works well, but for larger plants, the complex dynamics arising from large and nested cycles in the flowsheet lead to instabilities in the cycle solver. We analyze this problem in depth and show that it is not merely a specialized concern but rather a more pervasive challenge that will likely occur whenever ML is applied to larger plants. To address this problem, we present a way to fine-tune ML models such that solving cycles with the usual methods becomes robust again.","sentences":["Idealized first-principles models of chemical plants can be inaccurate.","An alternative is to fit a Machine Learning (ML) model directly to plant sensor data.","We use a structured approach: Each unit within the plant gets represented by one ML model.","After fitting the models to the data, the models are connected into a flowsheet-like directed graph.","We find that for smaller plants, this approach works well, but for larger plants, the complex dynamics arising from large and nested cycles in the flowsheet lead to instabilities in the cycle solver.","We analyze this problem in depth and show that it is not merely a specialized concern but rather a more pervasive challenge that will likely occur whenever ML is applied to larger plants.","To address this problem, we present a way to fine-tune ML models such that solving cycles with the usual methods becomes robust again."],"url":"http://arxiv.org/abs/2307.13621v1"}
{"created":"2023-07-25 16:22:58","title":"RecursiveDet: End-to-End Region-based Recursive Object Detection","abstract":"End-to-end region-based object detectors like Sparse R-CNN usually have multiple cascade bounding box decoding stages, which refine the current predictions according to their previous results. Model parameters within each stage are independent, evolving a huge cost. In this paper, we find the general setting of decoding stages is actually redundant. By simply sharing parameters and making a recursive decoder, the detector already obtains a significant improvement. The recursive decoder can be further enhanced by positional encoding (PE) of the proposal box, which makes it aware of the exact locations and sizes of input bounding boxes, thus becoming adaptive to proposals from different stages during the recursion. Moreover, we also design centerness-based PE to distinguish the RoI feature element and dynamic convolution kernels at different positions within the bounding box. To validate the effectiveness of the proposed method, we conduct intensive ablations and build the full model on three recent mainstream region-based detectors. The RecusiveDet is able to achieve obvious performance boosts with even fewer model parameters and slightly increased computation cost. Codes are available at https://github.com/bravezzzzzz/RecursiveDet.","sentences":["End-to-end region-based object detectors like Sparse R-CNN usually have multiple cascade bounding box decoding stages, which refine the current predictions according to their previous results.","Model parameters within each stage are independent, evolving a huge cost.","In this paper, we find the general setting of decoding stages is actually redundant.","By simply sharing parameters and making a recursive decoder, the detector already obtains a significant improvement.","The recursive decoder can be further enhanced by positional encoding (PE) of the proposal box, which makes it aware of the exact locations and sizes of input bounding boxes, thus becoming adaptive to proposals from different stages during the recursion.","Moreover, we also design centerness-based PE to distinguish the RoI feature element and dynamic convolution kernels at different positions within the bounding box.","To validate the effectiveness of the proposed method, we conduct intensive ablations and build the full model on three recent mainstream region-based detectors.","The RecusiveDet is able to achieve obvious performance boosts with even fewer model parameters and slightly increased computation cost.","Codes are available at https://github.com/bravezzzzzz/RecursiveDet."],"url":"http://arxiv.org/abs/2307.13619v1"}
{"created":"2023-07-25 16:21:07","title":"GPT-3 Models are Few-Shot Financial Reasoners","abstract":"Financial analysis is an important tool for evaluating company performance. Practitioners work to answer financial questions to make profitable investment decisions, and use advanced quantitative analyses to do so. As a result, Financial Question Answering (QA) is a question answering task that requires deep reasoning about numbers. Furthermore, it is unknown how well pre-trained language models can reason in the financial domain. The current state-of-the-art requires a retriever to collect relevant facts about the financial question from the text and a generator to produce a valid financial program and a final answer. However, recently large language models like GPT-3 have achieved state-of-the-art performance on wide variety of tasks with just a few shot examples. We run several experiments with GPT-3 and find that a separate retrieval model and logic engine continue to be essential components to achieving SOTA performance in this task, particularly due to the precise nature of financial questions and the complex information stored in financial documents. With this understanding, our refined prompt-engineering approach on GPT-3 achieves near SOTA accuracy without any fine-tuning.","sentences":["Financial analysis is an important tool for evaluating company performance.","Practitioners work to answer financial questions to make profitable investment decisions, and use advanced quantitative analyses to do so.","As a result, Financial Question Answering (QA) is a question answering task that requires deep reasoning about numbers.","Furthermore, it is unknown how well pre-trained language models can reason in the financial domain.","The current state-of-the-art requires a retriever to collect relevant facts about the financial question from the text and a generator to produce a valid financial program and a final answer.","However, recently large language models like GPT-3 have achieved state-of-the-art performance on wide variety of tasks with just a few shot examples.","We run several experiments with GPT-3 and find that a separate retrieval model and logic engine continue to be essential components to achieving SOTA performance in this task, particularly due to the precise nature of financial questions and the complex information stored in financial documents.","With this understanding, our refined prompt-engineering approach on GPT-3 achieves near SOTA accuracy without any fine-tuning."],"url":"http://arxiv.org/abs/2307.13617v1"}
{"created":"2023-07-25 16:15:29","title":"Object-based Probabilistic Similarity Evidence of Sparse Latent Features from Fully Convolutional Networks","abstract":"Similarity analysis using neural networks has emerged as a powerful technique for understanding and categorizing complex patterns in various domains. By leveraging the latent representations learned by neural networks, data objects such as images can be compared effectively. This research explores the utilization of latent information generated by fully convolutional networks (FCNs) in similarity analysis, notably to estimate the visual resemblance of objects segmented in 2D pictures. To do this, the analytical scheme comprises two steps: (1) extracting and transforming feature patterns per 2D object from a trained FCN, and (2) identifying the most similar patterns through fuzzy inference. The step (2) can be further enhanced by incorporating a weighting scheme that considers the significance of latent variables in the analysis. The results provide valuable insights into the benefits and challenges of employing neural network-based similarity analysis for discerning data patterns effectively.","sentences":["Similarity analysis using neural networks has emerged as a powerful technique for understanding and categorizing complex patterns in various domains.","By leveraging the latent representations learned by neural networks, data objects such as images can be compared effectively.","This research explores the utilization of latent information generated by fully convolutional networks (FCNs) in similarity analysis, notably to estimate the visual resemblance of objects segmented in 2D pictures.","To do this, the analytical scheme comprises two steps: (1) extracting and transforming feature patterns per 2D object from a trained FCN, and (2) identifying the most similar patterns through fuzzy inference.","The step (2) can be further enhanced by incorporating a weighting scheme that considers the significance of latent variables in the analysis.","The results provide valuable insights into the benefits and challenges of employing neural network-based similarity analysis for discerning data patterns effectively."],"url":"http://arxiv.org/abs/2307.13606v1"}
{"created":"2023-07-25 16:06:21","title":"The Importance of Distrust in AI","abstract":"In recent years the use of Artificial Intelligence (AI) has become increasingly prevalent in a growing number of fields. As AI systems are being adopted in more high-stakes areas such as medicine and finance, ensuring that they are trustworthy is of increasing importance. A concern that is prominently addressed by the development and application of explainability methods, which are purported to increase trust from its users and wider society. While an increase in trust may be desirable, an analysis of literature from different research fields shows that an exclusive focus on increasing trust may not be warranted. Something which is well exemplified by the recent development in AI chatbots, which while highly coherent tend to make up facts. In this contribution, we investigate the concepts of trust, trustworthiness, and user reliance.   In order to foster appropriate reliance on AI we need to prevent both disuse of these systems as well as overtrust. From our analysis of research on interpersonal trust, trust in automation, and trust in (X)AI, we identify the potential merit of the distinction between trust and distrust (in AI). We propose that alongside trust a healthy amount of distrust is of additional value for mitigating disuse and overtrust. We argue that by considering and evaluating both trust and distrust, we can ensure that users can rely appropriately on trustworthy AI, which can both be useful as well as fallible.","sentences":["In recent years the use of Artificial Intelligence (AI) has become increasingly prevalent in a growing number of fields.","As AI systems are being adopted in more high-stakes areas such as medicine and finance, ensuring that they are trustworthy is of increasing importance.","A concern that is prominently addressed by the development and application of explainability methods, which are purported to increase trust from its users and wider society.","While an increase in trust may be desirable, an analysis of literature from different research fields shows that an exclusive focus on increasing trust may not be warranted.","Something which is well exemplified by the recent development in AI chatbots, which while highly coherent tend to make up facts.","In this contribution, we investigate the concepts of trust, trustworthiness, and user reliance.   ","In order to foster appropriate reliance on AI we need to prevent both disuse of these systems as well as overtrust.","From our analysis of research on interpersonal trust, trust in automation, and trust in (X)AI, we identify the potential merit of the distinction between trust and distrust (in AI).","We propose that alongside trust a healthy amount of distrust is of additional value for mitigating disuse and overtrust.","We argue that by considering and evaluating both trust and distrust, we can ensure that users can rely appropriately on trustworthy AI, which can both be useful as well as fallible."],"url":"http://arxiv.org/abs/2307.13601v1"}
{"created":"2023-07-25 16:03:47","title":"Decisive Data using Multi-Modality Optical Sensors for Advanced Vehicular Systems","abstract":"Optical sensors have played a pivotal role in acquiring real world data for critical applications. This data, when integrated with advanced machine learning algorithms provides meaningful information thus enhancing human vision. This paper focuses on various optical technologies for design and development of state-of-the-art out-cabin forward vision systems and in-cabin driver monitoring systems. The focused optical sensors include Longwave Thermal Imaging (LWIR) cameras, Near Infrared (NIR), Neuromorphic/ event cameras, Visible CMOS cameras and Depth cameras. Further the paper discusses different potential applications which can be employed using the unique strengths of each these optical modalities in real time environment.","sentences":["Optical sensors have played a pivotal role in acquiring real world data for critical applications.","This data, when integrated with advanced machine learning algorithms provides meaningful information thus enhancing human vision.","This paper focuses on various optical technologies for design and development of state-of-the-art out-cabin forward vision systems and in-cabin driver monitoring systems.","The focused optical sensors include Longwave Thermal Imaging (LWIR) cameras, Near Infrared (NIR), Neuromorphic/ event cameras, Visible CMOS cameras and Depth cameras.","Further the paper discusses different potential applications which can be employed using the unique strengths of each these optical modalities in real time environment."],"url":"http://arxiv.org/abs/2307.13600v1"}
{"created":"2023-07-25 15:49:25","title":"Multi-GPU Approach for Training of Graph ML Models on large CFD Meshes","abstract":"Mesh-based numerical solvers are an important part in many design tool chains. However, accurate simulations like computational fluid dynamics are time and resource consuming which is why surrogate models are employed to speed-up the solution process. Machine Learning based surrogate models on the other hand are fast in predicting approximate solutions but often lack accuracy. Thus, the development of the predictor in a predictor-corrector approach is the focus here, where the surrogate model predicts a flow field and the numerical solver corrects it. This paper scales a state-of-the-art surrogate model from the domain of graph-based machine learning to industry-relevant mesh sizes of a numerical flow simulation. The approach partitions and distributes the flow domain to multiple GPUs and provides halo exchange between these partitions during training. The utilized graph neural network operates directly on the numerical mesh and is able to preserve complex geometries as well as all other properties of the mesh. The proposed surrogate model is evaluated with an application on a three dimensional turbomachinery setup and compared to a traditionally trained distributed model. The results show that the traditional approach produces superior predictions and outperforms the proposed surrogate model. Possible explanations, improvements and future directions are outlined.","sentences":["Mesh-based numerical solvers are an important part in many design tool chains.","However, accurate simulations like computational fluid dynamics are time and resource consuming which is why surrogate models are employed to speed-up the solution process.","Machine Learning based surrogate models on the other hand are fast in predicting approximate solutions but often lack accuracy.","Thus, the development of the predictor in a predictor-corrector approach is the focus here, where the surrogate model predicts a flow field and the numerical solver corrects it.","This paper scales a state-of-the-art surrogate model from the domain of graph-based machine learning to industry-relevant mesh sizes of a numerical flow simulation.","The approach partitions and distributes the flow domain to multiple GPUs and provides halo exchange between these partitions during training.","The utilized graph neural network operates directly on the numerical mesh and is able to preserve complex geometries as well as all other properties of the mesh.","The proposed surrogate model is evaluated with an application on a three dimensional turbomachinery setup and compared to a traditionally trained distributed model.","The results show that the traditional approach produces superior predictions and outperforms the proposed surrogate model.","Possible explanations, improvements and future directions are outlined."],"url":"http://arxiv.org/abs/2307.13592v1"}
{"created":"2023-07-25 15:42:11","title":"Settling the Sample Complexity of Online Reinforcement Learning","abstract":"A central issue lying at the heart of online reinforcement learning (RL) is data efficiency. While a number of recent works achieved asymptotically minimal regret in online RL, the optimality of these results is only guaranteed in a ``large-sample'' regime, imposing enormous burn-in cost in order for their algorithms to operate optimally. How to achieve minimax-optimal regret without incurring any burn-in cost has been an open problem in RL theory.   We settle this problem for the context of finite-horizon inhomogeneous Markov decision processes. Specifically, we prove that a modified version of Monotonic Value Propagation (MVP), a model-based algorithm proposed by \\cite{zhang2020reinforcement}, achieves a regret on the order of (modulo log factors) \\begin{equation*}   \\min\\big\\{ \\sqrt{SAH^3K}, \\,HK \\big\\}, \\end{equation*} where $S$ is the number of states, $A$ is the number of actions, $H$ is the planning horizon, and $K$ is the total number of episodes. This regret matches the minimax lower bound for the entire range of sample size $K\\geq 1$, essentially eliminating any burn-in requirement. It also translates to a PAC sample complexity (i.e., the number of episodes needed to yield $\\varepsilon$-accuracy) of $\\frac{SAH^3}{\\varepsilon^2}$ up to log factor, which is minimax-optimal for the full $\\varepsilon$-range.   Further, we extend our theory to unveil the influences of problem-dependent quantities like the optimal value/cost and certain variances. The key technical innovation lies in the development of a new regret decomposition strategy and a novel analysis paradigm to decouple complicated statistical dependency -- a long-standing challenge facing the analysis of online RL in the sample-hungry regime.","sentences":["A central issue lying at the heart of online reinforcement learning (RL) is data efficiency.","While a number of recent works achieved asymptotically minimal regret in online RL, the optimality of these results is only guaranteed in a ``large-sample'' regime, imposing enormous burn-in cost in order for their algorithms to operate optimally.","How to achieve minimax-optimal regret without incurring any burn-in cost has been an open problem in RL theory.   ","We settle this problem for the context of finite-horizon inhomogeneous Markov decision processes.","Specifically, we prove that a modified version of Monotonic Value Propagation (MVP), a model-based algorithm proposed by \\cite{zhang2020reinforcement}, achieves a regret on the order of (modulo log factors)","\\begin{equation*}   \\min\\big\\{ \\sqrt{SAH^3K}, \\,HK \\big\\}, \\end{equation*} where $S$ is the number of states, $A$ is the number of actions, $H$ is the planning horizon, and $K$ is the total number of episodes.","This regret matches the minimax lower bound for the entire range of sample size $K\\geq 1$, essentially eliminating any burn-in requirement.","It also translates to a PAC sample complexity (i.e., the number of episodes needed to yield $\\varepsilon$-accuracy) of $\\frac{SAH^3}{\\varepsilon^2}$ up to log factor, which is minimax-optimal for the full $\\varepsilon$-range.   ","Further, we extend our theory to unveil the influences of problem-dependent quantities like the optimal value/cost and certain variances.","The key technical innovation lies in the development of a new regret decomposition strategy and a novel analysis paradigm to decouple complicated statistical dependency -- a long-standing challenge facing the analysis of online RL in the sample-hungry regime."],"url":"http://arxiv.org/abs/2307.13586v1"}
{"created":"2023-07-25 15:36:33","title":"Argument Attribution Explanations in Quantitative Bipolar Argumentation Frameworks","abstract":"Argumentative explainable AI has been advocated by several in recent years, with an increasing interest on explaining the reasoning outcomes of Argumentation Frameworks (AFs). While there is a considerable body of research on qualitatively explaining the reasoning outcomes of AFs with debates/disputes/dialogues in the spirit of \\emph{extension-based semantics}, explaining the quantitative reasoning outcomes of AFs under \\emph{gradual semantics} has not received much attention, despite widespread use in applications. In this paper, we contribute to filling this gap by proposing a novel theory of \\emph{Argument Attribution Explanations (AAEs)} by incorporating the spirit of feature attribution from machine learning in the context of Quantitative Bipolar Argumentation Frameworks (QBAFs): whereas feature attribution is used to determine the influence of features towards outputs of machine learning models, AAEs are used to determine the influence of arguments towards \\emph{topic argument}s of interest. We study desirable properties of AAEs, including some new ones and some partially adapted from the literature to our setting. To demonstrate the applicability of our AAEs in practice, we conclude by carrying out two case studies in the scenarios of fake news detection and movie recommender systems.","sentences":["Argumentative explainable AI has been advocated by several in recent years, with an increasing interest on explaining the reasoning outcomes of Argumentation Frameworks (AFs).","While there is a considerable body of research on qualitatively explaining the reasoning outcomes of AFs with debates/disputes/dialogues in the spirit of \\emph{extension-based semantics}, explaining the quantitative reasoning outcomes of AFs under \\emph{gradual semantics} has not received much attention, despite widespread use in applications.","In this paper, we contribute to filling this gap by proposing a novel theory of \\emph{Argument Attribution Explanations (AAEs)} by incorporating the spirit of feature attribution from machine learning in the context of Quantitative Bipolar Argumentation Frameworks (QBAFs): whereas feature attribution is used to determine the influence of features towards outputs of machine learning models, AAEs are used to determine the influence of arguments towards \\emph{topic argument}s of interest.","We study desirable properties of AAEs, including some new ones and some partially adapted from the literature to our setting.","To demonstrate the applicability of our AAEs in practice, we conclude by carrying out two case studies in the scenarios of fake news detection and movie recommender systems."],"url":"http://arxiv.org/abs/2307.13582v1"}
{"created":"2023-07-25 15:33:38","title":"Reinterpreting survival analysis in the universal approximator age","abstract":"Survival analysis is an integral part of the statistical toolbox. However, while most domains of classical statistics have embraced deep learning, survival analysis only recently gained some minor attention from the deep learning community. This recent development is likely in part motivated by the COVID-19 pandemic. We aim to provide the tools needed to fully harness the potential of survival analysis in deep learning. On the one hand, we discuss how survival analysis connects to classification and regression. On the other hand, we provide technical tools. We provide a new loss function, evaluation metrics, and the first universal approximating network that provably produces survival curves without numeric integration. We show that the loss function and model outperform other approaches using a large numerical study.","sentences":["Survival analysis is an integral part of the statistical toolbox.","However, while most domains of classical statistics have embraced deep learning, survival analysis only recently gained some minor attention from the deep learning community.","This recent development is likely in part motivated by the COVID-19 pandemic.","We aim to provide the tools needed to fully harness the potential of survival analysis in deep learning.","On the one hand, we discuss how survival analysis connects to classification and regression.","On the other hand, we provide technical tools.","We provide a new loss function, evaluation metrics, and the first universal approximating network that provably produces survival curves without numeric integration.","We show that the loss function and model outperform other approaches using a large numerical study."],"url":"http://arxiv.org/abs/2307.13579v1"}
{"created":"2023-07-25 15:23:15","title":"PT$\\mathrm{L}^{p}$: Partial Transport $\\mathrm{L}^{p}$ Distances","abstract":"Optimal transport and its related problems, including optimal partial transport, have proven to be valuable tools in machine learning for computing meaningful distances between probability or positive measures. This success has led to a growing interest in defining transport-based distances that allow for comparing signed measures and, more generally, multi-channeled signals. Transport $\\mathrm{L}^{p}$ distances are notable extensions of the optimal transport framework to signed and possibly multi-channeled signals. In this paper, we introduce partial transport $\\mathrm{L}^{p}$ distances as a new family of metrics for comparing generic signals, benefiting from the robustness of partial transport distances. We provide theoretical background such as the existence of optimal plans and the behavior of the distance in various limits. Furthermore, we introduce the sliced variation of these distances, which allows for rapid comparison of generic signals. Finally, we demonstrate the application of the proposed distances in signal class separability and nearest neighbor classification.","sentences":["Optimal transport and its related problems, including optimal partial transport, have proven to be valuable tools in machine learning for computing meaningful distances between probability or positive measures.","This success has led to a growing interest in defining transport-based distances that allow for comparing signed measures and, more generally, multi-channeled signals.","Transport $\\mathrm{L}^{p}$ distances are notable extensions of the optimal transport framework to signed and possibly multi-channeled signals.","In this paper, we introduce partial transport $\\mathrm{L}^{p}$ distances as a new family of metrics for comparing generic signals, benefiting from the robustness of partial transport distances.","We provide theoretical background such as the existence of optimal plans and the behavior of the distance in various limits.","Furthermore, we introduce the sliced variation of these distances, which allows for rapid comparison of generic signals.","Finally, we demonstrate the application of the proposed distances in signal class separability and nearest neighbor classification."],"url":"http://arxiv.org/abs/2307.13571v1"}
{"created":"2023-07-25 15:23:02","title":"On the Error-Reducing Properties of Superposition Codes","abstract":"Next-generation wireless communication systems impose much stricter requirements for transmission rate, latency, and reliability. The peak data rate of 6G networks should be no less than 1 Tb/s, which is comparable to existing long-haul optical transport networks. It is believed that using long error-correcting codes (ECC) with soft-decision decoding (SDD) is not feasible in this case due to the resulting high power consumption. On the other hand, ECC with hard-decision decoding (HDD) suffers from significant performance degradation. In this paper, we consider a concatenated solution consisting of an outer long HDD code and an inner short SDD code. The latter code is a crucial component of the system and the focus of our research. Due to its short length, the code cannot correct all errors, but it is designed to minimize the number of errors. Such codes are known as error-reducing codes. We investigate the error-reducing properties of superposition codes. Initially, we explore sparse regression codes (SPARCs) with Gaussian signals. This approach outperforms error-reducing binary LDPC codes optimized by Barakatain, et al. (2018) in terms of performance but faces limitations in practical applicability due to high implementation complexity. Subsequently, we propose an LDPC-based superposition code scheme with low-complexity soft successive interference cancellation (SIC) decoding. This scheme demonstrates comparable performance to SPARCs while maintaining manageable complexity. Numerical results were obtained for inner codes with an overhead (OH) of 8.24% within a concatenated scheme (15% OH) with an outer hard-decision decoded staircase code (6.25% OH).","sentences":["Next-generation wireless communication systems impose much stricter requirements for transmission rate, latency, and reliability.","The peak data rate of 6G networks should be no less than 1 Tb/s, which is comparable to existing long-haul optical transport networks.","It is believed that using long error-correcting codes (ECC) with soft-decision decoding (SDD) is not feasible in this case due to the resulting high power consumption.","On the other hand, ECC with hard-decision decoding (HDD) suffers from significant performance degradation.","In this paper, we consider a concatenated solution consisting of an outer long HDD code and an inner short SDD code.","The latter code is a crucial component of the system and the focus of our research.","Due to its short length, the code cannot correct all errors, but it is designed to minimize the number of errors.","Such codes are known as error-reducing codes.","We investigate the error-reducing properties of superposition codes.","Initially, we explore sparse regression codes (SPARCs) with Gaussian signals.","This approach outperforms error-reducing binary LDPC codes optimized by Barakatain, et al.","(2018) in terms of performance","but faces limitations in practical applicability due to high implementation complexity.","Subsequently, we propose an LDPC-based superposition code scheme with low-complexity soft successive interference cancellation (SIC) decoding.","This scheme demonstrates comparable performance to SPARCs while maintaining manageable complexity.","Numerical results were obtained for inner codes with an overhead (OH) of 8.24% within a concatenated scheme (15% OH) with an outer hard-decision decoded staircase code (6.25% OH)."],"url":"http://arxiv.org/abs/2307.13570v1"}
{"created":"2023-07-25 15:20:19","title":"Mystique: Deconstructing SVG Charts for Layout Reuse","abstract":"To facilitate the reuse of existing charts, previous research has examined how to obtain a semantic understanding of a chart by deconstructing its visual representation into reusable components, such as encodings. However, existing deconstruction approaches primarily focus on chart styles, handling only basic layouts. In this paper, we investigate how to deconstruct chart layouts, focusing on rectangle-based ones as they cover not only 17 chart types but also advanced layouts (e.g., small multiples, nested layouts). We develop an interactive tool, called Mystique, adopting a mixed-initiative approach to extract the axes and legend, and deconstruct a chart's layout into four semantic components: mark groups, spatial relationships, data encodings, and graphical constraints. Mystique employs a wizard interface that guides chart authors through a series of steps to specify how the deconstructed components map to their own data. On 150 rectangle-based SVG charts, Mystique achieves above 85% accuracy for axis and legend extraction and 96% accuracy for layout deconstruction. In a chart reproduction study, participants could easily reuse existing charts on new datasets. We discuss the current limitations of Mystique and future research directions.","sentences":["To facilitate the reuse of existing charts, previous research has examined how to obtain a semantic understanding of a chart by deconstructing its visual representation into reusable components, such as encodings.","However, existing deconstruction approaches primarily focus on chart styles, handling only basic layouts.","In this paper, we investigate how to deconstruct chart layouts, focusing on rectangle-based ones as they cover not only 17 chart types but also advanced layouts (e.g., small multiples, nested layouts).","We develop an interactive tool, called Mystique, adopting a mixed-initiative approach to extract the axes and legend, and deconstruct a chart's layout into four semantic components: mark groups, spatial relationships, data encodings, and graphical constraints.","Mystique employs a wizard interface that guides chart authors through a series of steps to specify how the deconstructed components map to their own data.","On 150 rectangle-based SVG charts, Mystique achieves above 85% accuracy for axis and legend extraction and 96% accuracy for layout deconstruction.","In a chart reproduction study, participants could easily reuse existing charts on new datasets.","We discuss the current limitations of Mystique and future research directions."],"url":"http://arxiv.org/abs/2307.13567v1"}
{"created":"2023-07-25 15:19:36","title":"The Impact of Imperfect XAI on Human-AI Decision-Making","abstract":"Explainability techniques are rapidly being developed to improve human-AI decision-making across various cooperative work settings. Consequently, previous research has evaluated how decision-makers collaborate with imperfect AI by investigating appropriate reliance and task performance with the aim of designing more human-centered computer-supported collaborative tools. Several human-centered explainable AI (XAI) techniques have been proposed in hopes of improving decision-makers' collaboration with AI; however, these techniques are grounded in findings from previous studies that primarily focus on the impact of incorrect AI advice. Few studies acknowledge the possibility for the explanations to be incorrect even if the AI advice is correct. Thus, it is crucial to understand how imperfect XAI affects human-AI decision-making. In this work, we contribute a robust, mixed-methods user study with 136 participants to evaluate how incorrect explanations influence humans' decision-making behavior in a bird species identification task taking into account their level of expertise and an explanation's level of assertiveness. Our findings reveal the influence of imperfect XAI and humans' level of expertise on their reliance on AI and human-AI team performance. We also discuss how explanations can deceive decision-makers during human-AI collaboration. Hence, we shed light on the impacts of imperfect XAI in the field of computer-supported cooperative work and provide guidelines for designers of human-AI collaboration systems.","sentences":["Explainability techniques are rapidly being developed to improve human-AI decision-making across various cooperative work settings.","Consequently, previous research has evaluated how decision-makers collaborate with imperfect AI by investigating appropriate reliance and task performance with the aim of designing more human-centered computer-supported collaborative tools.","Several human-centered explainable AI (XAI) techniques have been proposed in hopes of improving decision-makers' collaboration with AI; however, these techniques are grounded in findings from previous studies that primarily focus on the impact of incorrect AI advice.","Few studies acknowledge the possibility for the explanations to be incorrect even if the AI advice is correct.","Thus, it is crucial to understand how imperfect XAI affects human-AI decision-making.","In this work, we contribute a robust, mixed-methods user study with 136 participants to evaluate how incorrect explanations influence humans' decision-making behavior in a bird species identification task taking into account their level of expertise and an explanation's level of assertiveness.","Our findings reveal the influence of imperfect XAI and humans' level of expertise on their reliance on AI and human-AI team performance.","We also discuss how explanations can deceive decision-makers during human-AI collaboration.","Hence, we shed light on the impacts of imperfect XAI in the field of computer-supported cooperative work and provide guidelines for designers of human-AI collaboration systems."],"url":"http://arxiv.org/abs/2307.13566v1"}
{"created":"2023-07-25 15:17:31","title":"Decision-Focused Learning: Foundations, State of the Art, Benchmark and Future Opportunities","abstract":"Decision-focused learning (DFL) is an emerging paradigm in machine learning which trains a model to optimize decisions, integrating prediction and optimization in an end-to-end system. This paradigm holds the promise to revolutionize decision-making in many real-world applications which operate under uncertainty, where the estimation of unknown parameters within these decision models often becomes a substantial roadblock. This paper presents a comprehensive review of DFL. It provides an in-depth analysis of the various techniques devised to integrate machine learning and optimization models introduces a taxonomy of DFL methods distinguished by their unique characteristics, and conducts an extensive empirical evaluation of these methods proposing suitable benchmark dataset and tasks for DFL. Finally, the study provides valuable insights into current and potential future avenues in DFL research.","sentences":["Decision-focused learning (DFL) is an emerging paradigm in machine learning which trains a model to optimize decisions, integrating prediction and optimization in an end-to-end system.","This paradigm holds the promise to revolutionize decision-making in many real-world applications which operate under uncertainty, where the estimation of unknown parameters within these decision models often becomes a substantial roadblock.","This paper presents a comprehensive review of DFL.","It provides an in-depth analysis of the various techniques devised to integrate machine learning and optimization models introduces a taxonomy of DFL methods distinguished by their unique characteristics, and conducts an extensive empirical evaluation of these methods proposing suitable benchmark dataset and tasks for DFL.","Finally, the study provides valuable insights into current and potential future avenues in DFL research."],"url":"http://arxiv.org/abs/2307.13565v1"}
{"created":"2023-07-25 15:08:34","title":"XDLM: Cross-lingual Diffusion Language Model for Machine Translation","abstract":"Recently, diffusion models have excelled in image generation tasks and have also been applied to neural language processing (NLP) for controllable text generation. However, the application of diffusion models in a cross-lingual setting is less unexplored. Additionally, while pretraining with diffusion models has been studied within a single language, the potential of cross-lingual pretraining remains understudied. To address these gaps, we propose XDLM, a novel Cross-lingual diffusion model for machine translation, consisting of pretraining and fine-tuning stages. In the pretraining stage, we propose TLDM, a new training objective for mastering the mapping between different languages; in the fine-tuning stage, we build up the translation system based on the pretrained model. We evaluate the result on several machine translation benchmarks and outperformed both diffusion and Transformer baselines.","sentences":["Recently, diffusion models have excelled in image generation tasks and have also been applied to neural language processing (NLP) for controllable text generation.","However, the application of diffusion models in a cross-lingual setting is less unexplored.","Additionally, while pretraining with diffusion models has been studied within a single language, the potential of cross-lingual pretraining remains understudied.","To address these gaps, we propose XDLM, a novel Cross-lingual diffusion model for machine translation, consisting of pretraining and fine-tuning stages.","In the pretraining stage, we propose TLDM, a new training objective for mastering the mapping between different languages; in the fine-tuning stage, we build up the translation system based on the pretrained model.","We evaluate the result on several machine translation benchmarks and outperformed both diffusion and Transformer baselines."],"url":"http://arxiv.org/abs/2307.13560v1"}
{"created":"2023-07-25 14:52:23","title":"On Solving the Rubik's Cube with Domain-Independent Planners Using Standard Representations","abstract":"Rubik's Cube (RC) is a well-known and computationally challenging puzzle that has motivated AI researchers to explore efficient alternative representations and problem-solving methods. The ideal situation for planning here is that a problem be solved optimally and efficiently represented in a standard notation using a general-purpose solver and heuristics. The fastest solver today for RC is DeepCubeA with a custom representation, and another approach is with Scorpion planner with State-Action-Space+ (SAS+) representation. In this paper, we present the first RC representation in the popular PDDL language so that the domain becomes more accessible to PDDL planners, competitions, and knowledge engineering tools, and is more human-readable. We then bridge across existing approaches and compare performance. We find that in one comparable experiment, DeepCubeA solves all problems with varying complexities, albeit only 18\\% are optimal plans. For the same problem set, Scorpion with SAS+ representation and pattern database heuristics solves 61.50\\% problems, while FastDownward with PDDL representation and FF heuristic solves 56.50\\% problems, out of which all the plans generated were optimal. Our study provides valuable insights into the trade-offs between representational choice and plan optimality that can help researchers design future strategies for challenging domains combining general-purpose solving methods (planning, reinforcement learning), heuristics, and representations (standard or custom).","sentences":["Rubik's Cube (RC) is a well-known and computationally challenging puzzle that has motivated AI researchers to explore efficient alternative representations and problem-solving methods.","The ideal situation for planning here is that a problem be solved optimally and efficiently represented in a standard notation using a general-purpose solver and heuristics.","The fastest solver today for RC is DeepCubeA with a custom representation, and another approach is with Scorpion planner with State-Action-Space+ (SAS+) representation.","In this paper, we present the first RC representation in the popular PDDL language so that the domain becomes more accessible to PDDL planners, competitions, and knowledge engineering tools, and is more human-readable.","We then bridge across existing approaches and compare performance.","We find that in one comparable experiment, DeepCubeA solves all problems with varying complexities, albeit only 18\\% are optimal plans.","For the same problem set, Scorpion with SAS+ representation and pattern database heuristics solves 61.50\\% problems, while FastDownward with PDDL representation and FF heuristic solves 56.50\\% problems, out of which all the plans generated were optimal.","Our study provides valuable insights into the trade-offs between representational choice and plan optimality that can help researchers design future strategies for challenging domains combining general-purpose solving methods (planning, reinforcement learning), heuristics, and representations (standard or custom)."],"url":"http://arxiv.org/abs/2307.13552v1"}
{"created":"2023-07-25 14:51:07","title":"A Planning Ontology to Represent and Exploit Planning Knowledge for Performance Efficiency","abstract":"Ontologies are known for their ability to organize rich metadata, support the identification of novel insights via semantic queries, and promote reuse. In this paper, we consider the problem of automated planning, where the objective is to find a sequence of actions that will move an agent from an initial state of the world to a desired goal state. We hypothesize that given a large number of available planners and diverse planning domains; they carry essential information that can be leveraged to identify suitable planners and improve their performance for a domain. We use data on planning domains and planners from the International Planning Competition (IPC) to construct a planning ontology and demonstrate via experiments in two use cases that the ontology can lead to the selection of promising planners and improving their performance using macros - a form of action ordering constraints extracted from planning ontology. We also make the planning ontology and associated resources available to the community to promote further research.","sentences":["Ontologies are known for their ability to organize rich metadata, support the identification of novel insights via semantic queries, and promote reuse.","In this paper, we consider the problem of automated planning, where the objective is to find a sequence of actions that will move an agent from an initial state of the world to a desired goal state.","We hypothesize that given a large number of available planners and diverse planning domains; they carry essential information that can be leveraged to identify suitable planners and improve their performance for a domain.","We use data on planning domains and planners from the International Planning Competition (IPC) to construct a planning ontology and demonstrate via experiments in two use cases that the ontology can lead to the selection of promising planners and improving their performance using macros - a form of action ordering constraints extracted from planning ontology.","We also make the planning ontology and associated resources available to the community to promote further research."],"url":"http://arxiv.org/abs/2307.13549v1"}
{"created":"2023-07-25 14:51:01","title":"Node Injection Link Stealing Attack","abstract":"In this paper, we present a stealthy and effective attack that exposes privacy vulnerabilities in Graph Neural Networks (GNNs) by inferring private links within graph-structured data. Focusing on the inductive setting where new nodes join the graph and an API is used to query predictions, we investigate the potential leakage of private edge information. We also propose methods to preserve privacy while maintaining model utility. Our attack demonstrates superior performance in inferring the links compared to the state of the art. Furthermore, we examine the application of differential privacy (DP) mechanisms to mitigate the impact of our proposed attack, we analyze the trade-off between privacy preservation and model utility. Our work highlights the privacy vulnerabilities inherent in GNNs, underscoring the importance of developing robust privacy-preserving mechanisms for their application.","sentences":["In this paper, we present a stealthy and effective attack that exposes privacy vulnerabilities in Graph Neural Networks (GNNs) by inferring private links within graph-structured data.","Focusing on the inductive setting where new nodes join the graph and an API is used to query predictions, we investigate the potential leakage of private edge information.","We also propose methods to preserve privacy while maintaining model utility.","Our attack demonstrates superior performance in inferring the links compared to the state of the art.","Furthermore, we examine the application of differential privacy (DP) mechanisms to mitigate the impact of our proposed attack, we analyze the trade-off between privacy preservation and model utility.","Our work highlights the privacy vulnerabilities inherent in GNNs, underscoring the importance of developing robust privacy-preserving mechanisms for their application."],"url":"http://arxiv.org/abs/2307.13548v1"}
{"created":"2023-07-25 14:44:41","title":"Group Activity Recognition in Computer Vision: A Comprehensive Review, Challenges, and Future Perspectives","abstract":"Group activity recognition is a hot topic in computer vision. Recognizing activities through group relationships plays a vital role in group activity recognition. It holds practical implications in various scenarios, such as video analysis, surveillance, automatic driving, and understanding social activities. The model's key capabilities encompass efficiently modeling hierarchical relationships within a scene and accurately extracting distinctive spatiotemporal features from groups. Given this technology's extensive applicability, identifying group activities has garnered significant research attention. This work examines the current progress in technology for recognizing group activities, with a specific focus on global interactivity and activities. Firstly, we comprehensively review the pertinent literature and various group activity recognition approaches, from traditional methodologies to the latest methods based on spatial structure, descriptors, non-deep learning, hierarchical recurrent neural networks (HRNN), relationship models, and attention mechanisms. Subsequently, we present the relational network and relational architectures for each module. Thirdly, we investigate methods for recognizing group activity and compare their performance with state-of-the-art technologies. We summarize the existing challenges and provide comprehensive guidance for newcomers to understand group activity recognition. Furthermore, we review emerging perspectives in group activity recognition to explore new directions and possibilities.","sentences":["Group activity recognition is a hot topic in computer vision.","Recognizing activities through group relationships plays a vital role in group activity recognition.","It holds practical implications in various scenarios, such as video analysis, surveillance, automatic driving, and understanding social activities.","The model's key capabilities encompass efficiently modeling hierarchical relationships within a scene and accurately extracting distinctive spatiotemporal features from groups.","Given this technology's extensive applicability, identifying group activities has garnered significant research attention.","This work examines the current progress in technology for recognizing group activities, with a specific focus on global interactivity and activities.","Firstly, we comprehensively review the pertinent literature and various group activity recognition approaches, from traditional methodologies to the latest methods based on spatial structure, descriptors, non-deep learning, hierarchical recurrent neural networks (HRNN), relationship models, and attention mechanisms.","Subsequently, we present the relational network and relational architectures for each module.","Thirdly, we investigate methods for recognizing group activity and compare their performance with state-of-the-art technologies.","We summarize the existing challenges and provide comprehensive guidance for newcomers to understand group activity recognition.","Furthermore, we review emerging perspectives in group activity recognition to explore new directions and possibilities."],"url":"http://arxiv.org/abs/2307.13541v1"}
{"created":"2023-07-25 14:40:11","title":"Model Calibration in Dense Classification with Adaptive Label Perturbation","abstract":"For safety-related applications, it is crucial to produce trustworthy deep neural networks whose prediction is associated with confidence that can represent the likelihood of correctness for subsequent decision-making. Existing dense binary classification models are prone to being over-confident. To improve model calibration, we propose Adaptive Stochastic Label Perturbation (ASLP) which learns a unique label perturbation level for each training image. ASLP employs our proposed Self-Calibrating Binary Cross Entropy (SC-BCE) loss, which unifies label perturbation processes including stochastic approaches (like DisturbLabel), and label smoothing, to correct calibration while maintaining classification rates. ASLP follows Maximum Entropy Inference of classic statistical mechanics to maximise prediction entropy with respect to missing information. It performs this while: (1) preserving classification accuracy on known data as a conservative solution, or (2) specifically improves model calibration degree by minimising the gap between the prediction accuracy and expected confidence of the target training label. Extensive results demonstrate that ASLP can significantly improve calibration degrees of dense binary classification models on both in-distribution and out-of-distribution data. The code is available on https://github.com/Carlisle-Liu/ASLP.","sentences":["For safety-related applications, it is crucial to produce trustworthy deep neural networks whose prediction is associated with confidence that can represent the likelihood of correctness for subsequent decision-making.","Existing dense binary classification models are prone to being over-confident.","To improve model calibration, we propose Adaptive Stochastic Label Perturbation (ASLP) which learns a unique label perturbation level for each training image.","ASLP employs our proposed Self-Calibrating Binary Cross Entropy (SC-BCE) loss, which unifies label perturbation processes including stochastic approaches (like DisturbLabel), and label smoothing, to correct calibration while maintaining classification rates.","ASLP follows Maximum Entropy Inference of classic statistical mechanics to maximise prediction entropy with respect to missing information.","It performs this while: (1) preserving classification accuracy on known data as a conservative solution, or (2) specifically improves model calibration degree by minimising the gap between the prediction accuracy and expected confidence of the target training label.","Extensive results demonstrate that ASLP can significantly improve calibration degrees of dense binary classification models on both in-distribution and out-of-distribution data.","The code is available on https://github.com/Carlisle-Liu/ASLP."],"url":"http://arxiv.org/abs/2307.13539v1"}
{"created":"2023-07-25 14:35:55","title":"INFINITY: Neural Field Modeling for Reynolds-Averaged Navier-Stokes Equations","abstract":"For numerical design, the development of efficient and accurate surrogate models is paramount. They allow us to approximate complex physical phenomena, thereby reducing the computational burden of direct numerical simulations. We propose INFINITY, a deep learning model that utilizes implicit neural representations (INRs) to address this challenge. Our framework encodes geometric information and physical fields into compact representations and learns a mapping between them to infer the physical fields. We use an airfoil design optimization problem as an example task and we evaluate our approach on the challenging AirfRANS dataset, which closely resembles real-world industrial use-cases. The experimental results demonstrate that our framework achieves state-of-the-art performance by accurately inferring physical fields throughout the volume and surface. Additionally we demonstrate its applicability in contexts such as design exploration and shape optimization: our model can correctly predict drag and lift coefficients while adhering to the equations.","sentences":["For numerical design, the development of efficient and accurate surrogate models is paramount.","They allow us to approximate complex physical phenomena, thereby reducing the computational burden of direct numerical simulations.","We propose INFINITY, a deep learning model that utilizes implicit neural representations (INRs) to address this challenge.","Our framework encodes geometric information and physical fields into compact representations and learns a mapping between them to infer the physical fields.","We use an airfoil design optimization problem as an example task and we evaluate our approach on the challenging AirfRANS dataset, which closely resembles real-world industrial use-cases.","The experimental results demonstrate that our framework achieves state-of-the-art performance by accurately inferring physical fields throughout the volume and surface.","Additionally we demonstrate its applicability in contexts such as design exploration and shape optimization: our model can correctly predict drag and lift coefficients while adhering to the equations."],"url":"http://arxiv.org/abs/2307.13538v1"}
{"created":"2023-07-25 14:35:25","title":"Spectrum-guided Multi-granularity Referring Video Object Segmentation","abstract":"Current referring video object segmentation (R-VOS) techniques extract conditional kernels from encoded (low-resolution) vision-language features to segment the decoded high-resolution features. We discovered that this causes significant feature drift, which the segmentation kernels struggle to perceive during the forward computation. This negatively affects the ability of segmentation kernels. To address the drift problem, we propose a Spectrum-guided Multi-granularity (SgMg) approach, which performs direct segmentation on the encoded features and employs visual details to further optimize the masks. In addition, we propose Spectrum-guided Cross-modal Fusion (SCF) to perform intra-frame global interactions in the spectral domain for effective multimodal representation. Finally, we extend SgMg to perform multi-object R-VOS, a new paradigm that enables simultaneous segmentation of multiple referred objects in a video. This not only makes R-VOS faster, but also more practical. Extensive experiments show that SgMg achieves state-of-the-art performance on four video benchmark datasets, outperforming the nearest competitor by 2.8% points on Ref-YouTube-VOS. Our extended SgMg enables multi-object R-VOS, runs about 3 times faster while maintaining satisfactory performance. Code is available at https://github.com/bo-miao/SgMg.","sentences":["Current referring video object segmentation (R-VOS) techniques extract conditional kernels from encoded (low-resolution) vision-language features to segment the decoded high-resolution features.","We discovered that this causes significant feature drift, which the segmentation kernels struggle to perceive during the forward computation.","This negatively affects the ability of segmentation kernels.","To address the drift problem, we propose a Spectrum-guided Multi-granularity (SgMg) approach, which performs direct segmentation on the encoded features and employs visual details to further optimize the masks.","In addition, we propose Spectrum-guided Cross-modal Fusion (SCF) to perform intra-frame global interactions in the spectral domain for effective multimodal representation.","Finally, we extend SgMg to perform multi-object R-VOS, a new paradigm that enables simultaneous segmentation of multiple referred objects in a video.","This not only makes R-VOS faster, but also more practical.","Extensive experiments show that SgMg achieves state-of-the-art performance on four video benchmark datasets, outperforming the nearest competitor by 2.8% points on Ref-YouTube-VOS.","Our extended SgMg enables multi-object R-VOS, runs about 3 times faster while maintaining satisfactory performance.","Code is available at https://github.com/bo-miao/SgMg."],"url":"http://arxiv.org/abs/2307.13537v1"}
{"created":"2023-07-25 14:20:52","title":"Re-mine, Learn and Reason: Exploring the Cross-modal Semantic Correlations for Language-guided HOI detection","abstract":"Human-Object Interaction (HOI) detection is a challenging computer vision task that requires visual models to address the complex interactive relationship between humans and objects and predict HOI triplets. Despite the challenges posed by the numerous interaction combinations, they also offer opportunities for multimodal learning of visual texts. In this paper, we present a systematic and unified framework (RmLR) that enhances HOI detection by incorporating structured text knowledge. Firstly, we qualitatively and quantitatively analyze the loss of interaction information in the two-stage HOI detector and propose a re-mining strategy to generate more comprehensive visual representation.Secondly, we design more fine-grained sentence- and word-level alignment and knowledge transfer strategies to effectively address the many-to-many matching problem between multiple interactions and multiple texts.These strategies alleviate the matching confusion problem that arises when multiple interactions occur simultaneously, thereby improving the effectiveness of the alignment process. Finally, HOI reasoning by visual features augmented with textual knowledge substantially improves the understanding of interactions. Experimental results illustrate the effectiveness of our approach, where state-of-the-art performance is achieved on public benchmarks. We further analyze the effects of different components of our approach to provide insights into its efficacy.","sentences":["Human-Object Interaction (HOI) detection is a challenging computer vision task that requires visual models to address the complex interactive relationship between humans and objects and predict HOI triplets.","Despite the challenges posed by the numerous interaction combinations, they also offer opportunities for multimodal learning of visual texts.","In this paper, we present a systematic and unified framework (RmLR) that enhances HOI detection by incorporating structured text knowledge.","Firstly, we qualitatively and quantitatively analyze the loss of interaction information in the two-stage HOI detector and propose a re-mining strategy to generate more comprehensive visual representation.","Secondly, we design more fine-grained sentence-","and word-level alignment and knowledge transfer strategies to effectively address the many-to-many matching problem between multiple interactions and multiple texts.","These strategies alleviate the matching confusion problem that arises when multiple interactions occur simultaneously, thereby improving the effectiveness of the alignment process.","Finally, HOI reasoning by visual features augmented with textual knowledge substantially improves the understanding of interactions.","Experimental results illustrate the effectiveness of our approach, where state-of-the-art performance is achieved on public benchmarks.","We further analyze the effects of different components of our approach to provide insights into its efficacy."],"url":"http://arxiv.org/abs/2307.13529v1"}
{"created":"2023-07-25 14:20:51","title":"FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios","abstract":"The emergence of generative pre-trained models has facilitated the synthesis of high-quality text, but it has also posed challenges in identifying factual errors in the generated text. In particular: (1) A wider range of tasks now face an increasing risk of containing factual errors when handled by generative models. (2) Generated texts tend to be lengthy and lack a clearly defined granularity for individual facts. (3) There is a scarcity of explicit evidence available during the process of fact checking. With the above challenges in mind, in this paper, we propose FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT). Experiments on four different tasks (knowledge-based QA, code generation, mathematical reasoning, and scientific literature review) show the efficacy of the proposed method.","sentences":["The emergence of generative pre-trained models has facilitated the synthesis of high-quality text, but it has also posed challenges in identifying factual errors in the generated text.","In particular: (1) A wider range of tasks now face an increasing risk of containing factual errors when handled by generative models.","(2) Generated texts tend to be lengthy and lack a clearly defined granularity for individual facts.","(3) There is a scarcity of explicit evidence available during the process of fact checking.","With the above challenges in mind, in this paper, we propose FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT).","Experiments on four different tasks (knowledge-based QA, code generation, mathematical reasoning, and scientific literature review) show the efficacy of the proposed method."],"url":"http://arxiv.org/abs/2307.13528v1"}
{"created":"2023-07-25 14:18:58","title":"Not with my name! Inferring artists' names of input strings employed by Diffusion Models","abstract":"Diffusion Models (DM) are highly effective at generating realistic, high-quality images. However, these models lack creativity and merely compose outputs based on their training data, guided by a textual input provided at creation time. Is it acceptable to generate images reminiscent of an artist, employing his name as input? This imply that if the DM is able to replicate an artist's work then it was trained on some or all of his artworks thus violating copyright. In this paper, a preliminary study to infer the probability of use of an artist's name in the input string of a generated image is presented. To this aim we focused only on images generated by the famous DALL-E 2 and collected images (both original and generated) of five renowned artists. Finally, a dedicated Siamese Neural Network was employed to have a first kind of probability. Experimental results demonstrate that our approach is an optimal starting point and can be employed as a prior for predicting a complete input string of an investigated image. Dataset and code are available at: https://github.com/ictlab-unict/not-with-my-name .","sentences":["Diffusion Models (DM) are highly effective at generating realistic, high-quality images.","However, these models lack creativity and merely compose outputs based on their training data, guided by a textual input provided at creation time.","Is it acceptable to generate images reminiscent of an artist, employing his name as input?","This imply that if the DM is able to replicate an artist's work then it was trained on some or all of his artworks thus violating copyright.","In this paper, a preliminary study to infer the probability of use of an artist's name in the input string of a generated image is presented.","To this aim we focused only on images generated by the famous DALL-E 2 and collected images (both original and generated) of five renowned artists.","Finally, a dedicated Siamese Neural Network was employed to have a first kind of probability.","Experimental results demonstrate that our approach is an optimal starting point and can be employed as a prior for predicting a complete input string of an investigated image.","Dataset and code are available at: https://github.com/ictlab-unict/not-with-my-name ."],"url":"http://arxiv.org/abs/2307.13527v1"}
{"created":"2023-07-25 14:12:44","title":"Higher-Order LCTRSs and Their Termination","abstract":"Logically constrained term rewriting systems (LCTRSs) are a program analyzing formalism with native support for data types which are not (co)inductively defined. As a first-order formalism, LCTRSs have accommodated only analysis of imperative programs so far. In this paper, we present a higher-order variant of the LCTRS formalism, which can be used to analyze functional programs. Then we study the termination problem and define a higher-order recursive path ordering (HORPO) for this new formalism.","sentences":["Logically constrained term rewriting systems (LCTRSs) are a program analyzing formalism with native support for data types which are not (co)inductively defined.","As a first-order formalism, LCTRSs have accommodated only analysis of imperative programs so far.","In this paper, we present a higher-order variant of the LCTRS formalism, which can be used to analyze functional programs.","Then we study the termination problem and define a higher-order recursive path ordering (HORPO) for this new formalism."],"url":"http://arxiv.org/abs/2307.13519v1"}
{"created":"2023-07-25 14:05:59","title":"Preliminary Design of the Dragonfly Navigation Filter","abstract":"Dragonfly is scheduled to begin exploring Titan by 2034 using a series of multi-kilometer surface flights. This paper outlines the preliminary design of the navigation filter for the Dragonfly Mobility subsystem. The software architecture and filter formulation for lidar, visual odometry, pressure sensors, and redundant IMUs are described in detail. Special discussion is given to developments to achieve multi-kilometer surface flights, including optimizing sequential image baselines, modeling correlating image processing errors, and an efficient approximation to the Simultaneous Localization and Mapping (SLAM) problem.","sentences":["Dragonfly is scheduled to begin exploring Titan by 2034 using a series of multi-kilometer surface flights.","This paper outlines the preliminary design of the navigation filter for the Dragonfly Mobility subsystem.","The software architecture and filter formulation for lidar, visual odometry, pressure sensors, and redundant IMUs are described in detail.","Special discussion is given to developments to achieve multi-kilometer surface flights, including optimizing sequential image baselines, modeling correlating image processing errors, and an efficient approximation to the Simultaneous Localization and Mapping (SLAM) problem."],"url":"http://arxiv.org/abs/2307.13513v1"}
{"created":"2023-07-25 14:02:02","title":"HeightFormer: Explicit Height Modeling without Extra Data for Camera-only 3D Object Detection in Bird's Eye View","abstract":"Vision-based Bird's Eye View (BEV) representation is an emerging perception formulation for autonomous driving. The core challenge is to construct BEV space with multi-camera features, which is a one-to-many ill-posed problem. Diving into all previous BEV representation generation methods, we found that most of them fall into two types: modeling depths in image views or modeling heights in the BEV space, mostly in an implicit way. In this work, we propose to explicitly model heights in the BEV space, which needs no extra data like LiDAR and can fit arbitrary camera rigs and types compared to modeling depths. Theoretically, we give proof of the equivalence between height-based methods and depth-based methods. Considering the equivalence and some advantages of modeling heights, we propose HeightFormer, which models heights and uncertainties in a self-recursive way. Without any extra data, the proposed HeightFormer could estimate heights in BEV accurately. Benchmark results show that the performance of HeightFormer achieves SOTA compared with those camera-only methods.","sentences":["Vision-based Bird's Eye View (BEV) representation is an emerging perception formulation for autonomous driving.","The core challenge is to construct BEV space with multi-camera features, which is a one-to-many ill-posed problem.","Diving into all previous BEV representation generation methods, we found that most of them fall into two types: modeling depths in image views or modeling heights in the BEV space, mostly in an implicit way.","In this work, we propose to explicitly model heights in the BEV space, which needs no extra data like LiDAR and can fit arbitrary camera rigs and types compared to modeling depths.","Theoretically, we give proof of the equivalence between height-based methods and depth-based methods.","Considering the equivalence and some advantages of modeling heights, we propose HeightFormer, which models heights and uncertainties in a self-recursive way.","Without any extra data, the proposed HeightFormer could estimate heights in BEV accurately.","Benchmark results show that the performance of HeightFormer achieves SOTA compared with those camera-only methods."],"url":"http://arxiv.org/abs/2307.13510v1"}
{"created":"2023-07-25 13:59:03","title":"Good codes from twisted group algebras","abstract":"In this paper, we shall give an explicit proof that constacyclic codes over finite commutative rings can be realized as ideals in some twisted group rings. Also, we shall study isometries between those codes and, finally, we shall study k-Galois LCD constacyclic codes over finite fields. In particular, we shall characterize constacyclic LCD codes with respect to Euclidean inner product in terms of its idempotent generators and the classical involution using the twisted group algebras structures and find some good LCD codes.","sentences":["In this paper, we shall give an explicit proof that constacyclic codes over finite commutative rings can be realized as ideals in some twisted group rings.","Also, we shall study isometries between those codes and, finally, we shall study k-Galois LCD constacyclic codes over finite fields.","In particular, we shall characterize constacyclic LCD codes with respect to Euclidean inner product in terms of its idempotent generators and the classical involution using the twisted group algebras structures and find some good LCD codes."],"url":"http://arxiv.org/abs/2307.13507v1"}
{"created":"2023-07-25 13:58:28","title":"Register Minimization of Cost Register Automata over a Field","abstract":"Weighted automata (WA) are an extension of finite automata that defines functions from words to values in a given semi-ring. An alternative model that is deterministic, called Cost Register Automata (CRA), was introduced by Alur et al. It enriches deterministic finite automata with a finite number of registers, which store values, are updated at each transition using the operations of the semi-ring, and are combined to produce the output. The expressiveness of a CRA depends on the number of its registers and the type of register updates allowed for each of its transitions. In particular, the class of functions computable by a CRA with register updates defined by linear (or affine) maps correspond exactly with rational functions (functions computable by a WA). A natural problem for CRA is the register minimization problem: given a function defined by a CRA, what is the minimal number of registers needed to realize this function?   In this paper, we solve the register minimization problem for CRA over a field with linear (or affine) register updates, using an algebraic invariant of a WA introduced recently by Bell and Smertnig, the so-called the linear hull of the automaton. This invariant being computable, we are able to explicitly compute a CRA with linear (or affine) updates, using the minimal number of registers.   Using these techniques, we are also able to solve the more general CRA minimisation problem: given a CRA and integers $k,d$, is there an equivalent linear (resp.~affine) CRA using at most $k$ states and $d$ registers?","sentences":["Weighted automata (WA) are an extension of finite automata that defines functions from words to values in a given semi-ring.","An alternative model that is deterministic, called Cost Register Automata (CRA), was introduced by Alur et al.","It enriches deterministic finite automata with a finite number of registers, which store values, are updated at each transition using the operations of the semi-ring, and are combined to produce the output.","The expressiveness of a CRA depends on the number of its registers and the type of register updates allowed for each of its transitions.","In particular, the class of functions computable by a CRA with register updates defined by linear (or affine) maps correspond exactly with rational functions (functions computable by a WA).","A natural problem for CRA is the register minimization problem: given a function defined by a CRA, what is the minimal number of registers needed to realize this function?   ","In this paper, we solve the register minimization problem for CRA over a field with linear (or affine) register updates, using an algebraic invariant of a WA introduced recently by Bell and Smertnig, the so-called the linear hull of the automaton.","This invariant being computable, we are able to explicitly compute a CRA with linear (or affine) updates, using the minimal number of registers.   ","Using these techniques, we are also able to solve the more general CRA minimisation problem: given a CRA and integers $k,d$, is there an equivalent linear (resp.~affine) CRA using at most $k$ states and $d$ registers?"],"url":"http://arxiv.org/abs/2307.13505v1"}
{"created":"2023-07-25 13:54:00","title":"Continuous Time Evidential Distributions for Irregular Time Series","abstract":"Prevalent in many real-world settings such as healthcare, irregular time series are challenging to formulate predictions from. It is difficult to infer the value of a feature at any given time when observations are sporadic, as it could take on a range of values depending on when it was last observed. To characterize this uncertainty we present EDICT, a strategy that learns an evidential distribution over irregular time series in continuous time. This distribution enables well-calibrated and flexible inference of partially observed features at any time of interest, while expanding uncertainty temporally for sparse, irregular observations. We demonstrate that EDICT attains competitive performance on challenging time series classification tasks and enabling uncertainty-guided inference when encountering noisy data.","sentences":["Prevalent in many real-world settings such as healthcare, irregular time series are challenging to formulate predictions from.","It is difficult to infer the value of a feature at any given time when observations are sporadic, as it could take on a range of values depending on when it was last observed.","To characterize this uncertainty we present EDICT, a strategy that learns an evidential distribution over irregular time series in continuous time.","This distribution enables well-calibrated and flexible inference of partially observed features at any time of interest, while expanding uncertainty temporally for sparse, irregular observations.","We demonstrate that EDICT attains competitive performance on challenging time series classification tasks and enabling uncertainty-guided inference when encountering noisy data."],"url":"http://arxiv.org/abs/2307.13503v1"}
{"created":"2023-07-25 13:49:15","title":"Finding Money Launderers Using Heterogeneous Graph Neural Networks","abstract":"Current anti-money laundering (AML) systems, predominantly rule-based, exhibit notable shortcomings in efficiently and precisely detecting instances of money laundering. As a result, there has been a recent surge toward exploring alternative approaches, particularly those utilizing machine learning. Since criminals often collaborate in their money laundering endeavors, accounting for diverse types of customer relations and links becomes crucial. In line with this, the present paper introduces a graph neural network (GNN) approach to identify money laundering activities within a large heterogeneous network constructed from real-world bank transactions and business role data belonging to DNB, Norway's largest bank. Specifically, we extend the homogeneous GNN method known as the Message Passing Neural Network (MPNN) to operate effectively on a heterogeneous graph. As part of this procedure, we propose a novel method for aggregating messages across different edges of the graph. Our findings highlight the importance of using an appropriate GNN architecture when combining information in heterogeneous graphs. The performance results of our model demonstrate great potential in enhancing the quality of electronic surveillance systems employed by banks to detect instances of money laundering. To the best of our knowledge, this is the first published work applying GNN on a large real-world heterogeneous network for anti-money laundering purposes.","sentences":["Current anti-money laundering (AML) systems, predominantly rule-based, exhibit notable shortcomings in efficiently and precisely detecting instances of money laundering.","As a result, there has been a recent surge toward exploring alternative approaches, particularly those utilizing machine learning.","Since criminals often collaborate in their money laundering endeavors, accounting for diverse types of customer relations and links becomes crucial.","In line with this, the present paper introduces a graph neural network (GNN) approach to identify money laundering activities within a large heterogeneous network constructed from real-world bank transactions and business role data belonging to DNB, Norway's largest bank.","Specifically, we extend the homogeneous GNN method known as the Message Passing Neural Network (MPNN) to operate effectively on a heterogeneous graph.","As part of this procedure, we propose a novel method for aggregating messages across different edges of the graph.","Our findings highlight the importance of using an appropriate GNN architecture when combining information in heterogeneous graphs.","The performance results of our model demonstrate great potential in enhancing the quality of electronic surveillance systems employed by banks to detect instances of money laundering.","To the best of our knowledge, this is the first published work applying GNN on a large real-world heterogeneous network for anti-money laundering purposes."],"url":"http://arxiv.org/abs/2307.13499v1"}
{"created":"2023-07-25 13:46:36","title":"Zshot: An Open-source Framework for Zero-Shot Named Entity Recognition and Relation Extraction","abstract":"The Zero-Shot Learning (ZSL) task pertains to the identification of entities or relations in texts that were not seen during training. ZSL has emerged as a critical research area due to the scarcity of labeled data in specific domains, and its applications have grown significantly in recent years. With the advent of large pretrained language models, several novel methods have been proposed, resulting in substantial improvements in ZSL performance. There is a growing demand, both in the research community and industry, for a comprehensive ZSL framework that facilitates the development and accessibility of the latest methods and pretrained models.In this study, we propose a novel ZSL framework called Zshot that aims to address the aforementioned challenges. Our primary objective is to provide a platform that allows researchers to compare different state-of-the-art ZSL methods with standard benchmark datasets. Additionally, we have designed our framework to support the industry with readily available APIs for production under the standard SpaCy NLP pipeline. Our API is extendible and evaluable, moreover, we include numerous enhancements such as boosting the accuracy with pipeline ensembling and visualization utilities available as a SpaCy extension.","sentences":["The Zero-Shot Learning (ZSL) task pertains to the identification of entities or relations in texts that were not seen during training.","ZSL has emerged as a critical research area due to the scarcity of labeled data in specific domains, and its applications have grown significantly in recent years.","With the advent of large pretrained language models, several novel methods have been proposed, resulting in substantial improvements in ZSL performance.","There is a growing demand, both in the research community and industry, for a comprehensive ZSL framework that facilitates the development and accessibility of the latest methods and pretrained models.","In this study, we propose a novel ZSL framework called Zshot that aims to address the aforementioned challenges.","Our primary objective is to provide a platform that allows researchers to compare different state-of-the-art ZSL methods with standard benchmark datasets.","Additionally, we have designed our framework to support the industry with readily available APIs for production under the standard SpaCy NLP pipeline.","Our API is extendible and evaluable, moreover, we include numerous enhancements such as boosting the accuracy with pipeline ensembling and visualization utilities available as a SpaCy extension."],"url":"http://arxiv.org/abs/2307.13497v1"}
{"created":"2023-07-25 13:42:22","title":"Duet: efficient and scalable hybriD neUral rElation undersTanding","abstract":"Cardinality estimation methods based on probability distribution estimation have achieved high-precision estimation results compared to traditional methods. However, the most advanced methods suffer from high estimation costs due to the sampling method they use when dealing with range queries. Also, such a sampling method makes them difficult to differentiate, so the supervision signal from the query workload is difficult to train the model to improve the accuracy of cardinality estimation. In this paper, we propose a new hybrid and deterministic modeling approach (Duet) for the cardinality estimation problem which has better efficiency and scalability compared to previous approaches. Duet allows for direct cardinality estimation of range queries with significantly lower time and memory costs, as well as in a differentiable form. As the prediction process of this approach is differentiable, we can incorporate queries with larger model estimation errors into the training process to address the long-tail distribution problem of model estimation errors on high dimensional tables. We evaluate Duet on classical datasets and benchmarks, and the results prove the effectiveness of Duet.","sentences":["Cardinality estimation methods based on probability distribution estimation have achieved high-precision estimation results compared to traditional methods.","However, the most advanced methods suffer from high estimation costs due to the sampling method they use when dealing with range queries.","Also, such a sampling method makes them difficult to differentiate, so the supervision signal from the query workload is difficult to train the model to improve the accuracy of cardinality estimation.","In this paper, we propose a new hybrid and deterministic modeling approach (Duet) for the cardinality estimation problem which has better efficiency and scalability compared to previous approaches.","Duet allows for direct cardinality estimation of range queries with significantly lower time and memory costs, as well as in a differentiable form.","As the prediction process of this approach is differentiable, we can incorporate queries with larger model estimation errors into the training process to address the long-tail distribution problem of model estimation errors on high dimensional tables.","We evaluate Duet on classical datasets and benchmarks, and the results prove the effectiveness of Duet."],"url":"http://arxiv.org/abs/2307.13494v1"}
{"created":"2023-07-25 13:35:45","title":"NormAUG: Normalization-guided Augmentation for Domain Generalization","abstract":"Deep learning has made significant advancements in supervised learning. However, models trained in this setting often face challenges due to domain shift between training and test sets, resulting in a significant drop in performance during testing. To address this issue, several domain generalization methods have been developed to learn robust and domain-invariant features from multiple training domains that can generalize well to unseen test domains. Data augmentation plays a crucial role in achieving this goal by enhancing the diversity of the training data. In this paper, inspired by the observation that normalizing an image with different statistics generated by different batches with various domains can perturb its feature, we propose a simple yet effective method called NormAUG (Normalization-guided Augmentation). Our method includes two paths: the main path and the auxiliary (augmented) path. During training, the auxiliary path includes multiple sub-paths, each corresponding to batch normalization for a single domain or a random combination of multiple domains. This introduces diverse information at the feature level and improves the generalization of the main path. Moreover, our NormAUG method effectively reduces the existing upper boundary for generalization based on theoretical perspectives. During the test stage, we leverage an ensemble strategy to combine the predictions from the auxiliary path of our model, further boosting performance. Extensive experiments are conducted on multiple benchmark datasets to validate the effectiveness of our proposed method.","sentences":["Deep learning has made significant advancements in supervised learning.","However, models trained in this setting often face challenges due to domain shift between training and test sets, resulting in a significant drop in performance during testing.","To address this issue, several domain generalization methods have been developed to learn robust and domain-invariant features from multiple training domains that can generalize well to unseen test domains.","Data augmentation plays a crucial role in achieving this goal by enhancing the diversity of the training data.","In this paper, inspired by the observation that normalizing an image with different statistics generated by different batches with various domains can perturb its feature, we propose a simple yet effective method called NormAUG (Normalization-guided Augmentation).","Our method includes two paths: the main path and the auxiliary (augmented) path.","During training, the auxiliary path includes multiple sub-paths, each corresponding to batch normalization for a single domain or a random combination of multiple domains.","This introduces diverse information at the feature level and improves the generalization of the main path.","Moreover, our NormAUG method effectively reduces the existing upper boundary for generalization based on theoretical perspectives.","During the test stage, we leverage an ensemble strategy to combine the predictions from the auxiliary path of our model, further boosting performance.","Extensive experiments are conducted on multiple benchmark datasets to validate the effectiveness of our proposed method."],"url":"http://arxiv.org/abs/2307.13492v1"}
{"created":"2023-07-25 13:22:24","title":"Cos R-CNN for Online Few-shot Object Detection","abstract":"We propose Cos R-CNN, a simple exemplar-based R-CNN formulation that is designed for online few-shot object detection. That is, it is able to localise and classify novel object categories in images with few examples without fine-tuning. Cos R-CNN frames detection as a learning-to-compare task: unseen classes are represented as exemplar images, and objects are detected based on their similarity to these exemplars. The cosine-based classification head allows for dynamic adaptation of classification parameters to the exemplar embedding, and encourages the clustering of similar classes in embedding space without the need for manual tuning of distance-metric hyperparameters. This simple formulation achieves best results on the recently proposed 5-way ImageNet few-shot detection benchmark, beating the online 1/5/10-shot scenarios by more than 8/3/1%, as well as performing up to 20% better in online 20-way few-shot VOC across all shots on novel classes.","sentences":["We propose Cos R-CNN, a simple exemplar-based R-CNN formulation that is designed for online few-shot object detection.","That is, it is able to localise and classify novel object categories in images with few examples without fine-tuning.","Cos R-CNN frames detection as a learning-to-compare task: unseen classes are represented as exemplar images, and objects are detected based on their similarity to these exemplars.","The cosine-based classification head allows for dynamic adaptation of classification parameters to the exemplar embedding, and encourages the clustering of similar classes in embedding space without the need for manual tuning of distance-metric hyperparameters.","This simple formulation achieves best results on the recently proposed 5-way ImageNet few-shot detection benchmark, beating the online 1/5/10-shot scenarios by more than 8/3/1%, as well as performing up to 20% better in online 20-way few-shot VOC across all shots on novel classes."],"url":"http://arxiv.org/abs/2307.13485v1"}
{"created":"2023-07-25 13:21:07","title":"Rational kernel-based interpolation for complex-valued frequency response functions","abstract":"This work is concerned with the kernel-based approximation of a complex-valued function from data, where the frequency response function of a partial differential equation in the frequency domain is of particular interest. In this setting, kernel methods are employed more and more frequently, however, standard kernels do not perform well. Moreover, the role and mathematical implications of the underlying pair of kernels, which arises naturally in the complex-valued case, remain to be addressed. We introduce new reproducing kernel Hilbert spaces of complex-valued functions, and formulate the problem of complex-valued interpolation with a kernel pair as minimum norm interpolation in these spaces. Moreover, we combine the interpolant with a low-order rational function, where the order is adaptively selected based on a new model selection criterion. Numerical results on examples from different fields, including electromagnetics and acoustic examples, illustrate the performance of the method, also in comparison to available rational approximation methods.","sentences":["This work is concerned with the kernel-based approximation of a complex-valued function from data, where the frequency response function of a partial differential equation in the frequency domain is of particular interest.","In this setting, kernel methods are employed more and more frequently, however, standard kernels do not perform well.","Moreover, the role and mathematical implications of the underlying pair of kernels, which arises naturally in the complex-valued case, remain to be addressed.","We introduce new reproducing kernel Hilbert spaces of complex-valued functions, and formulate the problem of complex-valued interpolation with a kernel pair as minimum norm interpolation in these spaces.","Moreover, we combine the interpolant with a low-order rational function, where the order is adaptively selected based on a new model selection criterion.","Numerical results on examples from different fields, including electromagnetics and acoustic examples, illustrate the performance of the method, also in comparison to available rational approximation methods."],"url":"http://arxiv.org/abs/2307.13484v1"}
{"created":"2023-07-25 13:08:19","title":"Secure Aggregation with an Oblivious Server","abstract":"Secure aggregation usually aims at securely computing the sum of the inputs from $K$ users at a server. Noticing that the sum might inevitably reveal information about the inputs (when the inputs are non-uniform) and typically the users (not the server) desire the sum (in applications such as federated learning), we consider a variant of secure aggregation where the server is oblivious, i.e., the server only serves as a communication facilitator/helper to enable the users to securely compute the sum and learns nothing in the process. Our communication protocol involves one round of messages from the users to the server and one round of messages from the server to each user such that in the end each user only learns the sum of all $K$ inputs and the server learns no information about the inputs. For this secure aggregation with an oblivious server problem, we show that to compute $1$ bit of the sum securely, each user needs to send at least $1$ bit to the server, the server needs to send at least $1$ bit to each user, each user needs to hold a key of at least $2$ bits, and all users need to collectively hold at least $K$ key bits. In addition, when user dropouts are allowed, the optimal performance remains the same, except that the minimum size of the key held by each user increases to $K$ bits, per sum bit.","sentences":["Secure aggregation usually aims at securely computing the sum of the inputs from $K$ users at a server.","Noticing that the sum might inevitably reveal information about the inputs (when the inputs are non-uniform) and typically the users (not the server) desire the sum (in applications such as federated learning), we consider a variant of secure aggregation where the server is oblivious, i.e., the server only serves as a communication facilitator/helper to enable the users to securely compute the sum and learns nothing in the process.","Our communication protocol involves one round of messages from the users to the server and one round of messages from the server to each user such that in the end each user only learns the sum of all $K$ inputs and the server learns no information about the inputs.","For this secure aggregation with an oblivious server problem, we show that to compute $1$ bit of the sum securely, each user needs to send at least $1$ bit to the server, the server needs to send at least $1$ bit to each user, each user needs to hold a key of at least $2$ bits, and all users need to collectively hold at least $K$ key bits.","In addition, when user dropouts are allowed, the optimal performance remains the same, except that the minimum size of the key held by each user increases to $K$ bits, per sum bit."],"url":"http://arxiv.org/abs/2307.13474v1"}
{"created":"2023-07-25 13:01:25","title":"Combinatorial Auctions and Graph Neural Networks for Local Energy Flexibility Markets","abstract":"This paper proposes a new combinatorial auction framework for local energy flexibility markets, which addresses the issue of prosumers' inability to bundle multiple flexibility time intervals. To solve the underlying NP-complete winner determination problems, we present a simple yet powerful heterogeneous tri-partite graph representation and design graph neural network-based models. Our models achieve an average optimal value deviation of less than 5\\% from an off-the-shelf optimization tool and show linear inference time complexity compared to the exponential complexity of the commercial solver. Contributions and results demonstrate the potential of using machine learning to efficiently allocate energy flexibility resources in local markets and solving optimization problems in general.","sentences":["This paper proposes a new combinatorial auction framework for local energy flexibility markets, which addresses the issue of prosumers' inability to bundle multiple flexibility time intervals.","To solve the underlying NP-complete winner determination problems, we present a simple yet powerful heterogeneous tri-partite graph representation and design graph neural network-based models.","Our models achieve an average optimal value deviation of less than 5\\% from an off-the-shelf optimization tool and show linear inference time complexity compared to the exponential complexity of the commercial solver.","Contributions and results demonstrate the potential of using machine learning to efficiently allocate energy flexibility resources in local markets and solving optimization problems in general."],"url":"http://arxiv.org/abs/2307.13470v1"}
{"created":"2023-07-25 12:56:41","title":"Gaussian Graph with Prototypical Contrastive Learning in E-Commerce Bundle Recommendation","abstract":"Bundle recommendation aims to provide a bundle of items to satisfy the user preference on e-commerce platform. Existing successful solutions are based on the contrastive graph learning paradigm where graph neural networks (GNNs) are employed to learn representations from user-level and bundle-level graph views with a contrastive learning module to enhance the cooperative association between different views. Nevertheless, they ignore the uncertainty issue which has a significant impact in real bundle recommendation scenarios due to the lack of discriminative information caused by highly sparsity or diversity. We further suggest that their instancewise contrastive learning fails to distinguish the semantically similar negatives (i.e., sampling bias issue), resulting in performance degradation. In this paper, we propose a novel Gaussian Graph with Prototypical Contrastive Learning (GPCL) framework to overcome these challenges. In particular, GPCL embeds each user/bundle/item as a Gaussian distribution rather than a fixed vector. We further design a prototypical contrastive learning module to capture the contextual information and mitigate the sampling bias issue. Extensive experiments demonstrate that benefiting from the proposed components, we achieve new state-of-the-art performance compared to previous methods on several public datasets. Moreover, GPCL has been deployed on real-world e-commerce platform and achieved substantial improvements.","sentences":["Bundle recommendation aims to provide a bundle of items to satisfy the user preference on e-commerce platform.","Existing successful solutions are based on the contrastive graph learning paradigm where graph neural networks (GNNs) are employed to learn representations from user-level and bundle-level graph views with a contrastive learning module to enhance the cooperative association between different views.","Nevertheless, they ignore the uncertainty issue which has a significant impact in real bundle recommendation scenarios due to the lack of discriminative information caused by highly sparsity or diversity.","We further suggest that their instancewise contrastive learning fails to distinguish the semantically similar negatives (i.e., sampling bias issue), resulting in performance degradation.","In this paper, we propose a novel Gaussian Graph with Prototypical Contrastive Learning (GPCL) framework to overcome these challenges.","In particular, GPCL embeds each user/bundle/item as a Gaussian distribution rather than a fixed vector.","We further design a prototypical contrastive learning module to capture the contextual information and mitigate the sampling bias issue.","Extensive experiments demonstrate that benefiting from the proposed components, we achieve new state-of-the-art performance compared to previous methods on several public datasets.","Moreover, GPCL has been deployed on real-world e-commerce platform and achieved substantial improvements."],"url":"http://arxiv.org/abs/2307.13468v1"}
{"created":"2023-07-25 12:55:55","title":"Holographic MIMO Communications: What is the benefit of closely spaced antennas?","abstract":"Holographic MIMO refers to an array (possibly large) with a massive number of antennas that are individually controlled and densely deployed. The aim of this paper is to provide further insights into the advantages (if any) of having closely spaced antennas in the uplink and downlink of a multi-user Holographic MIMO system. To this end, we make use of the multiport communication theory, which ensures physically consistent uplink and downlink models. We first consider a simple uplink scenario with two side-by-side half-wavelength dipoles, two users and single path line-of-sight propagation, and show both analytically and numerically that the channel gain and average spectral efficiency depend strongly on the directions from which the signals are received and on the array matching network used. Numerical results are then used to extend the analysis to more practical scenarios with a larger number of dipoles and users. The case in which the antennas are densely packed in a space-constrained factor form is also considered. It turns out that the spectral efficiency increases as the antenna distance reduces thanks to the larger number of antennas that allow to collect more energy, not because of the mutual coupling.","sentences":["Holographic MIMO refers to an array (possibly large) with a massive number of antennas that are individually controlled and densely deployed.","The aim of this paper is to provide further insights into the advantages (if any) of having closely spaced antennas in the uplink and downlink of a multi-user Holographic MIMO system.","To this end, we make use of the multiport communication theory, which ensures physically consistent uplink and downlink models.","We first consider a simple uplink scenario with two side-by-side half-wavelength dipoles, two users and single path line-of-sight propagation, and show both analytically and numerically that the channel gain and average spectral efficiency depend strongly on the directions from which the signals are received and on the array matching network used.","Numerical results are then used to extend the analysis to more practical scenarios with a larger number of dipoles and users.","The case in which the antennas are densely packed in a space-constrained factor form is also considered.","It turns out that the spectral efficiency increases as the antenna distance reduces thanks to the larger number of antennas that allow to collect more energy, not because of the mutual coupling."],"url":"http://arxiv.org/abs/2307.13467v1"}
{"created":"2023-07-25 12:51:25","title":"Integrating processed-based models and machine learning for crop yield prediction","abstract":"Crop yield prediction typically involves the utilization of either theory-driven process-based crop growth models, which have proven to be difficult to calibrate for local conditions, or data-driven machine learning methods, which are known to require large datasets. In this work we investigate potato yield prediction using a hybrid meta-modeling approach. A crop growth model is employed to generate synthetic data for (pre)training a convolutional neural net, which is then fine-tuned with observational data. When applied in silico, our meta-modeling approach yields better predictions than a baseline comprising a purely data-driven approach. When tested on real-world data from field trials (n=303) and commercial fields (n=77), the meta-modeling approach yields competitive results with respect to the crop growth model. In the latter set, however, both models perform worse than a simple linear regression with a hand-picked feature set and dedicated preprocessing designed by domain experts. Our findings indicate the potential of meta-modeling for accurate crop yield prediction; however, further advancements and validation using extensive real-world datasets is recommended to solidify its practical effectiveness.","sentences":["Crop yield prediction typically involves the utilization of either theory-driven process-based crop growth models, which have proven to be difficult to calibrate for local conditions, or data-driven machine learning methods, which are known to require large datasets.","In this work we investigate potato yield prediction using a hybrid meta-modeling approach.","A crop growth model is employed to generate synthetic data for (pre)training a convolutional neural net, which is then fine-tuned with observational data.","When applied in silico, our meta-modeling approach yields better predictions than a baseline comprising a purely data-driven approach.","When tested on real-world data from field trials (n=303) and commercial fields (n=77), the meta-modeling approach yields competitive results with respect to the crop growth model.","In the latter set, however, both models perform worse than a simple linear regression with a hand-picked feature set and dedicated preprocessing designed by domain experts.","Our findings indicate the potential of meta-modeling for accurate crop yield prediction; however, further advancements and validation using extensive real-world datasets is recommended to solidify its practical effectiveness."],"url":"http://arxiv.org/abs/2307.13466v1"}
{"created":"2023-07-25 12:47:21","title":"Unlocking the Emotional World of Visual Media: An Overview of the Science, Research, and Impact of Understanding Emotion","abstract":"The emergence of artificial emotional intelligence technology is revolutionizing the fields of computers and robotics, allowing for a new level of communication and understanding of human behavior that was once thought impossible. While recent advancements in deep learning have transformed the field of computer vision, automated understanding of evoked or expressed emotions in visual media remains in its infancy. This foundering stems from the absence of a universally accepted definition of \"emotion\", coupled with the inherently subjective nature of emotions and their intricate nuances. In this article, we provide a comprehensive, multidisciplinary overview of the field of emotion analysis in visual media, drawing on insights from psychology, engineering, and the arts. We begin by exploring the psychological foundations of emotion and the computational principles that underpin the understanding of emotions from images and videos. We then review the latest research and systems within the field, accentuating the most promising approaches. We also discuss the current technological challenges and limitations of emotion analysis, underscoring the necessity for continued investigation and innovation. We contend that this represents a \"Holy Grail\" research problem in computing and delineate pivotal directions for future inquiry. Finally, we examine the ethical ramifications of emotion-understanding technologies and contemplate their potential societal impacts. Overall, this article endeavors to equip readers with a deeper understanding of the domain of emotion analysis in visual media and to inspire further research and development in this captivating and rapidly evolving field.","sentences":["The emergence of artificial emotional intelligence technology is revolutionizing the fields of computers and robotics, allowing for a new level of communication and understanding of human behavior that was once thought impossible.","While recent advancements in deep learning have transformed the field of computer vision, automated understanding of evoked or expressed emotions in visual media remains in its infancy.","This foundering stems from the absence of a universally accepted definition of \"emotion\", coupled with the inherently subjective nature of emotions and their intricate nuances.","In this article, we provide a comprehensive, multidisciplinary overview of the field of emotion analysis in visual media, drawing on insights from psychology, engineering, and the arts.","We begin by exploring the psychological foundations of emotion and the computational principles that underpin the understanding of emotions from images and videos.","We then review the latest research and systems within the field, accentuating the most promising approaches.","We also discuss the current technological challenges and limitations of emotion analysis, underscoring the necessity for continued investigation and innovation.","We contend that this represents a \"Holy Grail\" research problem in computing and delineate pivotal directions for future inquiry.","Finally, we examine the ethical ramifications of emotion-understanding technologies and contemplate their potential societal impacts.","Overall, this article endeavors to equip readers with a deeper understanding of the domain of emotion analysis in visual media and to inspire further research and development in this captivating and rapidly evolving field."],"url":"http://arxiv.org/abs/2307.13463v1"}
{"created":"2023-07-25 12:40:24","title":"Weakly-supervised 3D Pose Transfer with Keypoints","abstract":"The main challenges of 3D pose transfer are: 1) Lack of paired training data with different characters performing the same pose; 2) Disentangling pose and shape information from the target mesh; 3) Difficulty in applying to meshes with different topologies. We thus propose a novel weakly-supervised keypoint-based framework to overcome these difficulties. Specifically, we use a topology-agnostic keypoint detector with inverse kinematics to compute transformations between the source and target meshes. Our method only requires supervision on the keypoints, can be applied to meshes with different topologies and is shape-invariant for the target which allows extraction of pose-only information from the target meshes without transferring shape information. We further design a cycle reconstruction to perform self-supervised pose transfer without the need for ground truth deformed mesh with the same pose and shape as the target and source, respectively. We evaluate our approach on benchmark human and animal datasets, where we achieve superior performance compared to the state-of-the-art unsupervised approaches and even comparable performance with the fully supervised approaches. We test on the more challenging Mixamo dataset to verify our approach's ability in handling meshes with different topologies and complex clothes. Cross-dataset evaluation further shows the strong generalization ability of our approach.","sentences":["The main challenges of 3D pose transfer are: 1) Lack of paired training data with different characters performing the same pose; 2) Disentangling pose and shape information from the target mesh; 3) Difficulty in applying to meshes with different topologies.","We thus propose a novel weakly-supervised keypoint-based framework to overcome these difficulties.","Specifically, we use a topology-agnostic keypoint detector with inverse kinematics to compute transformations between the source and target meshes.","Our method only requires supervision on the keypoints, can be applied to meshes with different topologies and is shape-invariant for the target which allows extraction of pose-only information from the target meshes without transferring shape information.","We further design a cycle reconstruction to perform self-supervised pose transfer without the need for ground truth deformed mesh with the same pose and shape as the target and source, respectively.","We evaluate our approach on benchmark human and animal datasets, where we achieve superior performance compared to the state-of-the-art unsupervised approaches and even comparable performance with the fully supervised approaches.","We test on the more challenging Mixamo dataset to verify our approach's ability in handling meshes with different topologies and complex clothes.","Cross-dataset evaluation further shows the strong generalization ability of our approach."],"url":"http://arxiv.org/abs/2307.13459v1"}
{"created":"2023-07-25 12:33:53","title":"Monte-Carlo Tree Search for Multi-Agent Pathfinding: Preliminary Results","abstract":"In this work we study a well-known and challenging problem of Multi-agent Pathfinding, when a set of agents is confined to a graph, each agent is assigned a unique start and goal vertices and the task is to find a set of collision-free paths (one for each agent) such that each agent reaches its respective goal. We investigate how to utilize Monte-Carlo Tree Search (MCTS) to solve the problem. Although MCTS was shown to demonstrate superior performance in a wide range of problems like playing antagonistic games (e.g. Go, Chess etc.), discovering faster matrix multiplication algorithms etc., its application to the problem at hand was not well studied before. To this end we introduce an original variant of MCTS, tailored to multi-agent pathfinding. The crux of our approach is how the reward, that guides MCTS, is computed. Specifically, we use individual paths to assist the agents with the the goal-reaching behavior, while leaving them freedom to get off the track if it is needed to avoid collisions. We also use a dedicated decomposition technique to reduce the branching factor of the tree search procedure. Empirically we show that the suggested method outperforms the baseline planning algorithm that invokes heuristic search, e.g. A*, at each re-planning step.","sentences":["In this work we study a well-known and challenging problem of Multi-agent Pathfinding, when a set of agents is confined to a graph, each agent is assigned a unique start and goal vertices and the task is to find a set of collision-free paths (one for each agent) such that each agent reaches its respective goal.","We investigate how to utilize Monte-Carlo Tree Search (MCTS) to solve the problem.","Although MCTS was shown to demonstrate superior performance in a wide range of problems like playing antagonistic games (e.g. Go, Chess etc.), discovering faster matrix multiplication algorithms etc., its application to the problem at hand was not well studied before.","To this end we introduce an original variant of MCTS, tailored to multi-agent pathfinding.","The crux of our approach is how the reward, that guides MCTS, is computed.","Specifically, we use individual paths to assist the agents with the the goal-reaching behavior, while leaving them freedom to get off the track if it is needed to avoid collisions.","We also use a dedicated decomposition technique to reduce the branching factor of the tree search procedure.","Empirically we show that the suggested method outperforms the baseline planning algorithm that invokes heuristic search, e.g. A*, at each re-planning step."],"url":"http://arxiv.org/abs/2307.13453v1"}
{"created":"2023-07-25 12:19:35","title":"A behavioural transformer for effective collaboration between a robot and a non-stationary human","abstract":"A key challenge in human-robot collaboration is the non-stationarity created by humans due to changes in their behaviour. This alters environmental transitions and hinders human-robot collaboration. We propose a principled meta-learning framework to explore how robots could better predict human behaviour, and thereby deal with issues of non-stationarity. On the basis of this framework, we developed Behaviour-Transform (BeTrans). BeTrans is a conditional transformer that enables a robot agent to adapt quickly to new human agents with non-stationary behaviours, due to its notable performance with sequential data. We trained BeTrans on simulated human agents with different systematic biases in collaborative settings. We used an original customisable environment to show that BeTrans effectively collaborates with simulated human agents and adapts faster to non-stationary simulated human agents than SOTA techniques.","sentences":["A key challenge in human-robot collaboration is the non-stationarity created by humans due to changes in their behaviour.","This alters environmental transitions and hinders human-robot collaboration.","We propose a principled meta-learning framework to explore how robots could better predict human behaviour, and thereby deal with issues of non-stationarity.","On the basis of this framework, we developed Behaviour-Transform (BeTrans).","BeTrans is a conditional transformer that enables a robot agent to adapt quickly to new human agents with non-stationary behaviours, due to its notable performance with sequential data.","We trained BeTrans on simulated human agents with different systematic biases in collaborative settings.","We used an original customisable environment to show that BeTrans effectively collaborates with simulated human agents and adapts faster to non-stationary simulated human agents than SOTA techniques."],"url":"http://arxiv.org/abs/2307.13447v1"}
{"created":"2023-07-25 12:13:33","title":"On viewing SpaceX Starlink through the Social Media Lens","abstract":"Multiple low-Earth orbit satellite constellations, aimed at beaming broadband connectivity from space, are currently under active deployment. While such space-based Internet is set to augment, globally, today's terrestrial connectivity, and has managed to generate significant hype, it has been largely difficult for the community to measure, quantify, or understand the nuances of these offerings in the absence of a global measurement infrastructure -- the research community has mostly resorted to simulators, emulators, and limited measurements till now. In this paper, we identify an opportunity to use the social media `lens' to complement such measurements and mine user-centric insights on the evolving ecosystem at scale.","sentences":["Multiple low-Earth orbit satellite constellations, aimed at beaming broadband connectivity from space, are currently under active deployment.","While such space-based Internet is set to augment, globally, today's terrestrial connectivity, and has managed to generate significant hype, it has been largely difficult for the community to measure, quantify, or understand the nuances of these offerings in the absence of a global measurement infrastructure -- the research community has mostly resorted to simulators, emulators, and limited measurements till now.","In this paper, we identify an opportunity to use the social media `lens' to complement such measurements and mine user-centric insights on the evolving ecosystem at scale."],"url":"http://arxiv.org/abs/2307.13441v1"}
{"created":"2023-07-25 12:00:48","title":"Network Traffic Classification based on Single Flow Time Series Analysis","abstract":"Network traffic monitoring using IP flows is used to handle the current challenge of analyzing encrypted network communication. Nevertheless, the packet aggregation into flow records naturally causes information loss; therefore, this paper proposes a novel flow extension for traffic features based on the time series analysis of the Single Flow Time series, i.e., a time series created by the number of bytes in each packet and its timestamp. We propose 69 universal features based on the statistical analysis of data points, time domain analysis, packet distribution within the flow timespan, time series behavior, and frequency domain analysis. We have demonstrated the usability and universality of the proposed feature vector for various network traffic classification tasks using 15 well-known publicly available datasets. Our evaluation shows that the novel feature vector achieves classification performance similar or better than related works on both binary and multiclass classification tasks. In more than half of the evaluated tasks, the classification performance increased by up to 5\\%.","sentences":["Network traffic monitoring using IP flows is used to handle the current challenge of analyzing encrypted network communication.","Nevertheless, the packet aggregation into flow records naturally causes information loss; therefore, this paper proposes a novel flow extension for traffic features based on the time series analysis of the Single Flow Time series, i.e., a time series created by the number of bytes in each packet and its timestamp.","We propose 69 universal features based on the statistical analysis of data points, time domain analysis, packet distribution within the flow timespan, time series behavior, and frequency domain analysis.","We have demonstrated the usability and universality of the proposed feature vector for various network traffic classification tasks using 15 well-known publicly available datasets.","Our evaluation shows that the novel feature vector achieves classification performance similar or better than related works on both binary and multiclass classification tasks.","In more than half of the evaluated tasks, the classification performance increased by up to 5\\%."],"url":"http://arxiv.org/abs/2307.13434v1"}
{"created":"2023-07-25 11:51:19","title":"Multi-Objective Optimisation of URLLC-Based Metaverse Services","abstract":"Metaverse aims for building a fully immersive virtual shared space, where the users are able to engage in various activities. To successfully deploy the service for each user, the Metaverse service provider and network service provider generally localise the user first and then support the communication between the base station (BS) and the user. A reconfigurable intelligent surface (RIS) is capable of creating a reflected link between the BS and the user to enhance line-of-sight. Furthermore, the new key performance indicators (KPIs) in Metaverse, such as its energy-consumption-dependent total service cost and transmission latency, are often overlooked in ultra-reliable low latency communication (URLLC) designs, which have to be carefully considered in next-generation URLLC (xURLLC) regimes. In this paper, our design objective is to jointly optimise the transmit power, the RIS phase shifts, and the decoding error probability to simultaneously minimise the total service cost and transmission latency and approach the Pareto Front (PF). We conceive a twin-stage central controller, which aims for localising the users first and then supports the communication between the BS and users. In the first stage, we localise the Metaverse users, where the stochastic gradient descent (SGD) algorithm is invoked for accurate user localisation. In the second stage, a meta-learning-based position-dependent multi-objective soft actor and critic (MO-SAC) algorithm is proposed to approach the PF between the total service cost and transmission latency and to further optimise the latency-dependent reliability. Our numerical results demonstrate that ...","sentences":["Metaverse aims for building a fully immersive virtual shared space, where the users are able to engage in various activities.","To successfully deploy the service for each user, the Metaverse service provider and network service provider generally localise the user first and then support the communication between the base station (BS) and the user.","A reconfigurable intelligent surface (RIS) is capable of creating a reflected link between the BS and the user to enhance line-of-sight.","Furthermore, the new key performance indicators (KPIs) in Metaverse, such as its energy-consumption-dependent total service cost and transmission latency, are often overlooked in ultra-reliable low latency communication (URLLC) designs, which have to be carefully considered in next-generation URLLC (xURLLC) regimes.","In this paper, our design objective is to jointly optimise the transmit power, the RIS phase shifts, and the decoding error probability to simultaneously minimise the total service cost and transmission latency and approach the Pareto Front (PF).","We conceive a twin-stage central controller, which aims for localising the users first and then supports the communication between the BS and users.","In the first stage, we localise the Metaverse users, where the stochastic gradient descent (SGD) algorithm is invoked for accurate user localisation.","In the second stage, a meta-learning-based position-dependent multi-objective soft actor and critic (MO-SAC) algorithm is proposed to approach the PF between the total service cost and transmission latency and to further optimise the latency-dependent reliability.","Our numerical results demonstrate that ..."],"url":"http://arxiv.org/abs/2307.13429v1"}
{"created":"2023-07-25 11:51:14","title":"An Explainable Model-Agnostic Algorithm for CNN-based Biometrics Verification","abstract":"This paper describes an adaptation of the Local Interpretable Model-Agnostic Explanations (LIME) AI method to operate under a biometric verification setting. LIME was initially proposed for networks with the same output classes used for training, and it employs the softmax probability to determine which regions of the image contribute the most to classification. However, in a verification setting, the classes to be recognized have not been seen during training. In addition, instead of using the softmax output, face descriptors are usually obtained from a layer before the classification layer. The model is adapted to achieve explainability via cosine similarity between feature vectors of perturbated versions of the input image. The method is showcased for face biometrics with two CNN models based on MobileNetv2 and ResNet50.","sentences":["This paper describes an adaptation of the Local Interpretable Model-Agnostic Explanations (LIME) AI method to operate under a biometric verification setting.","LIME was initially proposed for networks with the same output classes used for training, and it employs the softmax probability to determine which regions of the image contribute the most to classification.","However, in a verification setting, the classes to be recognized have not been seen during training.","In addition, instead of using the softmax output, face descriptors are usually obtained from a layer before the classification layer.","The model is adapted to achieve explainability via cosine similarity between feature vectors of perturbated versions of the input image.","The method is showcased for face biometrics with two CNN models based on MobileNetv2 and ResNet50."],"url":"http://arxiv.org/abs/2307.13428v1"}
{"created":"2023-07-25 11:49:25","title":"Comprehensive Review on Semantic Information Retrieval and Ontology Engineering","abstract":"Situation awareness is a crucial cognitive skill that enables individuals to perceive, comprehend, and project the current state of their environment accurately. It involves being conscious of relevant information, understanding its meaning, and using that understanding to make well-informed decisions. Awareness systems often need to integrate new knowledge and adapt to changing environments. Ontology reasoning facilitates knowledge integration and evolution, allowing for seamless updates and expansions of the ontology. With the consideration of above, we are providing a quick review on semantic information retrieval and ontology engineering to understand the emerging challenges and future research. In the review we have found that the ontology reasoning addresses the limitations of traditional systems by providing a formal, flexible, and scalable framework for knowledge representation, reasoning, and inference.","sentences":["Situation awareness is a crucial cognitive skill that enables individuals to perceive, comprehend, and project the current state of their environment accurately.","It involves being conscious of relevant information, understanding its meaning, and using that understanding to make well-informed decisions.","Awareness systems often need to integrate new knowledge and adapt to changing environments.","Ontology reasoning facilitates knowledge integration and evolution, allowing for seamless updates and expansions of the ontology.","With the consideration of above, we are providing a quick review on semantic information retrieval and ontology engineering to understand the emerging challenges and future research.","In the review we have found that the ontology reasoning addresses the limitations of traditional systems by providing a formal, flexible, and scalable framework for knowledge representation, reasoning, and inference."],"url":"http://arxiv.org/abs/2307.13427v1"}
{"created":"2023-07-25 11:47:42","title":"Complexity Analysis for Call-by-Value Higher-Order Rewriting","abstract":"In this short paper, we consider a form of higher-order rewriting with a call-by-value evaluation strategy so as to model call-by-value programs. We briefly present a cost-size semantics to call-by-value rewriting: a class of algebraic interpretations that map terms to tuples that bound both the reductions' cost and the size of normal forms.","sentences":["In this short paper, we consider a form of higher-order rewriting with a call-by-value evaluation strategy so as to model call-by-value programs.","We briefly present a cost-size semantics to call-by-value rewriting: a class of algebraic interpretations that map terms to tuples that bound both the reductions' cost and the size of normal forms."],"url":"http://arxiv.org/abs/2307.13426v1"}
{"created":"2023-07-25 11:45:28","title":"A signal processing interpretation of noise-reduction convolutional neural networks","abstract":"Encoding-decoding CNNs play a central role in data-driven noise reduction and can be found within numerous deep-learning algorithms. However, the development of these CNN architectures is often done in ad-hoc fashion and theoretical underpinnings for important design choices is generally lacking. Up to this moment there are different existing relevant works that strive to explain the internal operation of these CNNs. Still, these ideas are either scattered and/or may require significant expertise to be accessible for a bigger audience. In order to open up this exciting field, this article builds intuition on the theory of deep convolutional framelets and explains diverse ED CNN architectures in a unified theoretical framework. By connecting basic principles from signal processing to the field of deep learning, this self-contained material offers significant guidance for designing robust and efficient novel CNN architectures.","sentences":["Encoding-decoding CNNs play a central role in data-driven noise reduction and can be found within numerous deep-learning algorithms.","However, the development of these CNN architectures is often done in ad-hoc fashion and theoretical underpinnings for important design choices is generally lacking.","Up to this moment there are different existing relevant works that strive to explain the internal operation of these CNNs.","Still, these ideas are either scattered and/or may require significant expertise to be accessible for a bigger audience.","In order to open up this exciting field, this article builds intuition on the theory of deep convolutional framelets and explains diverse ED CNN architectures in a unified theoretical framework.","By connecting basic principles from signal processing to the field of deep learning, this self-contained material offers significant guidance for designing robust and efficient novel CNN architectures."],"url":"http://arxiv.org/abs/2307.13425v1"}
{"created":"2023-07-25 11:44:28","title":"Holistic Exploration on Universal Decompositional Semantic Parsing: Architecture, Data Augmentation, and LLM Paradigm","abstract":"In this paper, we conduct a holistic exploration of the Universal Decompositional Semantic (UDS) Parsing. We first introduce a cascade model for UDS parsing that decomposes the complex parsing task into semantically appropriate subtasks. Our approach outperforms the prior models, while significantly reducing inference time. We also incorporate syntactic information and further optimized the architecture. Besides, different ways for data augmentation are explored, which further improve the UDS Parsing. Lastly, we conduct experiments to investigate the efficacy of ChatGPT in handling the UDS task, revealing that it excels in attribute parsing but struggles in relation parsing, and using ChatGPT for data augmentation yields suboptimal results. Our code is available at https://github.com/hexuandeng/HExp4UDS.","sentences":["In this paper, we conduct a holistic exploration of the Universal Decompositional Semantic (UDS) Parsing.","We first introduce a cascade model for UDS parsing that decomposes the complex parsing task into semantically appropriate subtasks.","Our approach outperforms the prior models, while significantly reducing inference time.","We also incorporate syntactic information and further optimized the architecture.","Besides, different ways for data augmentation are explored, which further improve the UDS Parsing.","Lastly, we conduct experiments to investigate the efficacy of ChatGPT in handling the UDS task, revealing that it excels in attribute parsing but struggles in relation parsing, and using ChatGPT for data augmentation yields suboptimal results.","Our code is available at https://github.com/hexuandeng/HExp4UDS."],"url":"http://arxiv.org/abs/2307.13424v1"}
{"created":"2023-07-25 11:42:52","title":"Non Intrusive Intelligibility Predictor for Hearing Impaired Individuals using Self Supervised Speech Representations","abstract":"Self-supervised speech representations (SSSRs) have been successfully applied to a number of speech-processing tasks, e.g. as feature extractor for speech quality (SQ) prediction, which is, in turn, relevant for assessment and training speech enhancement systems for users with normal or impaired hearing. However, exact knowledge of why and how quality-related information is encoded well in such representations remains poorly understood. In this work, techniques for non-intrusive prediction of SQ ratings are extended to the prediction of intelligibility for hearing-impaired users. It is found that self-supervised representations are useful as input features to non-intrusive prediction models, achieving competitive performance to more complex systems. A detailed analysis of the performance depending on Clarity Prediction Challenge 1 listeners and enhancement systems indicates that more data might be needed to allow generalisation to unknown systems and (hearing-impaired) individuals","sentences":["Self-supervised speech representations (SSSRs) have been successfully applied to a number of speech-processing tasks, e.g. as feature extractor for speech quality (SQ) prediction, which is, in turn, relevant for assessment and training speech enhancement systems for users with normal or impaired hearing.","However, exact knowledge of why and how quality-related information is encoded well in such representations remains poorly understood.","In this work, techniques for non-intrusive prediction of SQ ratings are extended to the prediction of intelligibility for hearing-impaired users.","It is found that self-supervised representations are useful as input features to non-intrusive prediction models, achieving competitive performance to more complex systems.","A detailed analysis of the performance depending on Clarity Prediction Challenge 1 listeners and enhancement systems indicates that more data might be needed to allow generalisation to unknown systems and","(hearing-impaired) individuals"],"url":"http://arxiv.org/abs/2307.13423v1"}
{"created":"2023-07-25 11:40:47","title":"On the learning Dynamics of Attention Networks","abstract":"Attention models are typically learned by optimizing one of three standard loss functions that are variously called -- soft attention, hard attention, and latent variable marginal likelihood (LVML) attention. All three paradigms are motivated by the same goal of finding two models -- a `focus' model that `selects' the right \\textit{segment} of the input and a `classification' model that processes the selected segment into the target label. However, they differ significantly in the way the selected segments are aggregated, resulting in distinct dynamics and final results. We observe a unique signature of models learned using these paradigms and explain this as a consequence of the evolution of the classification model under gradient descent when the focus model is fixed. We also analyze these paradigms in a simple setting and derive closed-form expressions for the parameter trajectory under gradient flow. With the soft attention loss, the focus model improves quickly at initialization and splutters later on. On the other hand, hard attention loss behaves in the opposite fashion. Based on our observations, we propose a simple hybrid approach that combines the advantages of the different loss functions and demonstrates it on a collection of semi-synthetic and real-world datasets","sentences":["Attention models are typically learned by optimizing one of three standard loss functions that are variously called -- soft attention, hard attention, and latent variable marginal likelihood (LVML) attention.","All three paradigms are motivated by the same goal of finding two models -- a `focus' model that `selects' the right \\textit{segment} of the input and a `classification' model that processes the selected segment into the target label.","However, they differ significantly in the way the selected segments are aggregated, resulting in distinct dynamics and final results.","We observe a unique signature of models learned using these paradigms and explain this as a consequence of the evolution of the classification model under gradient descent when the focus model is fixed.","We also analyze these paradigms in a simple setting and derive closed-form expressions for the parameter trajectory under gradient flow.","With the soft attention loss, the focus model improves quickly at initialization and splutters later on.","On the other hand, hard attention loss behaves in the opposite fashion.","Based on our observations, we propose a simple hybrid approach that combines the advantages of the different loss functions and demonstrates it on a collection of semi-synthetic and real-world datasets"],"url":"http://arxiv.org/abs/2307.13421v1"}
{"created":"2023-07-25 11:38:40","title":"Co-Design of Out-of-Distribution Detectors for Autonomous Emergency Braking Systems","abstract":"Learning enabled components (LECs), while critical for decision making in autonomous vehicles (AVs), are likely to make incorrect decisions when presented with samples outside of their training distributions. Out-of-distribution (OOD) detectors have been proposed to detect such samples, thereby acting as a safety monitor, however, both OOD detectors and LECs require heavy utilization of embedded hardware typically found in AVs. For both components, there is a tradeoff between non-functional and functional performance, and both impact a vehicle's safety. For instance, giving an OOD detector a longer response time can increase its accuracy at the expense of the LEC. We consider an LEC with binary output like an autonomous emergency braking system (AEBS) and use risk, the combination of severity and occurrence of a failure, to model the effect of both components' design parameters on each other's functional and non-functional performance, as well as their impact on system safety. We formulate a co-design methodology that uses this risk model to find the design parameters for an OOD detector and LEC that decrease risk below that of the baseline system and demonstrate it on a vision based AEBS. Using our methodology, we achieve a 42.3% risk reduction while maintaining equivalent resource utilization.","sentences":["Learning enabled components (LECs), while critical for decision making in autonomous vehicles (AVs), are likely to make incorrect decisions when presented with samples outside of their training distributions.","Out-of-distribution (OOD) detectors have been proposed to detect such samples, thereby acting as a safety monitor, however, both OOD detectors and LECs require heavy utilization of embedded hardware typically found in AVs.","For both components, there is a tradeoff between non-functional and functional performance, and both impact a vehicle's safety.","For instance, giving an OOD detector a longer response time can increase its accuracy at the expense of the LEC.","We consider an LEC with binary output like an autonomous emergency braking system (AEBS) and use risk, the combination of severity and occurrence of a failure, to model the effect of both components' design parameters on each other's functional and non-functional performance, as well as their impact on system safety.","We formulate a co-design methodology that uses this risk model to find the design parameters for an OOD detector and LEC that decrease risk below that of the baseline system and demonstrate it on a vision based AEBS.","Using our methodology, we achieve a 42.3% risk reduction while maintaining equivalent resource utilization."],"url":"http://arxiv.org/abs/2307.13419v1"}
{"created":"2023-07-25 11:29:55","title":"Towards Resolving Word Ambiguity with Word Embeddings","abstract":"Ambiguity is ubiquitous in natural language. Resolving ambiguous meanings is especially important in information retrieval tasks. While word embeddings carry semantic information, they fail to handle ambiguity well. Transformer models have been shown to handle word ambiguity for complex queries, but they cannot be used to identify ambiguous words, e.g. for a 1-word query. Furthermore, training these models is costly in terms of time, hardware resources, and training data, prohibiting their use in specialized environments with sensitive data. Word embeddings can be trained using moderate hardware resources. This paper shows that applying DBSCAN clustering to the latent space can identify ambiguous words and evaluate their level of ambiguity. An automatic DBSCAN parameter selection leads to high-quality clusters, which are semantically coherent and correspond well to the perceived meanings of a given word.","sentences":["Ambiguity is ubiquitous in natural language.","Resolving ambiguous meanings is especially important in information retrieval tasks.","While word embeddings carry semantic information, they fail to handle ambiguity well.","Transformer models have been shown to handle word ambiguity for complex queries, but they cannot be used to identify ambiguous words, e.g. for a 1-word query.","Furthermore, training these models is costly in terms of time, hardware resources, and training data, prohibiting their use in specialized environments with sensitive data.","Word embeddings can be trained using moderate hardware resources.","This paper shows that applying DBSCAN clustering to the latent space can identify ambiguous words and evaluate their level of ambiguity.","An automatic DBSCAN parameter selection leads to high-quality clusters, which are semantically coherent and correspond well to the perceived meanings of a given word."],"url":"http://arxiv.org/abs/2307.13417v1"}
{"created":"2023-07-25 11:19:21","title":"Mitigating Memory Wall Effects in CNN Engines with On-the-Fly Weights Generation","abstract":"The unprecedented accuracy of convolutional neural networks (CNNs) across a broad range of AI tasks has led to their widespread deployment in mobile and embedded settings. In a pursuit for high-performance and energy-efficient inference, significant research effort has been invested in the design of FPGA-based CNN accelerators. In this context, single computation engines constitute a popular approach to support diverse CNN modes without the overhead of fabric reconfiguration. Nevertheless, this flexibility often comes with significantly degraded performance on memory-bound layers and resource underutilisation due to the suboptimal mapping of certain layers on the engine's fixed configuration. In this work, we investigate the implications in terms of CNN engine design for a class of models that introduce a pre-convolution stage to decompress the weights at run time. We refer to these approaches as on-the-fly. This paper presents unzipFPGA, a novel CNN inference system that counteracts the limitations of existing CNN engines. The proposed framework comprises a novel CNN hardware architecture that introduces a weights generator module that enables the on-chip on-the-fly generation of weights, alleviating the negative impact of limited bandwidth on memory-bound layers. We further enhance unzipFPGA with an automated hardware-aware methodology that tailors the weights generation mechanism to the target CNN-device pair, leading to an improved accuracy-performance balance. Finally, we introduce an input selective processing element (PE) design that balances the load between PEs in suboptimally mapped layers. The proposed framework yields hardware designs that achieve an average of 2.57x performance efficiency gain over highly optimised GPU designs for the same power constraints and up to 3.94x higher performance density over a diverse range of state-of-the-art FPGA-based CNN accelerators.","sentences":["The unprecedented accuracy of convolutional neural networks (CNNs) across a broad range of AI tasks has led to their widespread deployment in mobile and embedded settings.","In a pursuit for high-performance and energy-efficient inference, significant research effort has been invested in the design of FPGA-based CNN accelerators.","In this context, single computation engines constitute a popular approach to support diverse CNN modes without the overhead of fabric reconfiguration.","Nevertheless, this flexibility often comes with significantly degraded performance on memory-bound layers and resource underutilisation due to the suboptimal mapping of certain layers on the engine's fixed configuration.","In this work, we investigate the implications in terms of CNN engine design for a class of models that introduce a pre-convolution stage to decompress the weights at run time.","We refer to these approaches as on-the-fly.","This paper presents unzipFPGA, a novel CNN inference system that counteracts the limitations of existing CNN engines.","The proposed framework comprises a novel CNN hardware architecture that introduces a weights generator module that enables the on-chip on-the-fly generation of weights, alleviating the negative impact of limited bandwidth on memory-bound layers.","We further enhance unzipFPGA with an automated hardware-aware methodology that tailors the weights generation mechanism to the target CNN-device pair, leading to an improved accuracy-performance balance.","Finally, we introduce an input selective processing element (PE) design that balances the load between PEs in suboptimally mapped layers.","The proposed framework yields hardware designs that achieve an average of 2.57x performance efficiency gain over highly optimised GPU designs for the same power constraints and up to 3.94x higher performance density over a diverse range of state-of-the-art FPGA-based CNN accelerators."],"url":"http://arxiv.org/abs/2307.13412v1"}
{"created":"2023-07-25 11:07:43","title":"The Double-Edged Sword of Big Data and Information Technology for the Disadvantaged: A Cautionary Tale from Open Banking","abstract":"This research article analyses and demonstrates the hidden implications for fairness of seemingly neutral data coupled with powerful technology, such as machine learning (ML), using Open Banking as an example. Open Banking has ignited a revolution in financial services, opening new opportunities for customer acquisition, management, retention, and risk assessment. However, the granularity of transaction data holds potential for harm where unnoticed proxies for sensitive and prohibited characteristics may lead to indirect discrimination. Against this backdrop, we investigate the dimensions of financial vulnerability (FV), a global concern resulting from COVID-19 and rising inflation. Specifically, we look to understand the behavioral elements leading up to FV and its impact on at-risk, disadvantaged groups through the lens of fair interpretation. Using a unique dataset from a UK FinTech lender, we demonstrate the power of fine-grained transaction data while simultaneously cautioning its safe usage. Three ML classifiers are compared in predicting the likelihood of FV, and groups exhibiting different magnitudes and forms of FV are identified via clustering to highlight the effects of feature combination. Our results indicate that engineered features of financial behavior can be predictive of omitted personal information, particularly sensitive or protected characteristics, shedding light on the hidden dangers of Open Banking data. We discuss the implications and conclude fairness via unawareness is ineffective in this new technological environment.","sentences":["This research article analyses and demonstrates the hidden implications for fairness of seemingly neutral data coupled with powerful technology, such as machine learning (ML), using Open Banking as an example.","Open Banking has ignited a revolution in financial services, opening new opportunities for customer acquisition, management, retention, and risk assessment.","However, the granularity of transaction data holds potential for harm where unnoticed proxies for sensitive and prohibited characteristics may lead to indirect discrimination.","Against this backdrop, we investigate the dimensions of financial vulnerability (FV), a global concern resulting from COVID-19 and rising inflation.","Specifically, we look to understand the behavioral elements leading up to FV and its impact on at-risk, disadvantaged groups through the lens of fair interpretation.","Using a unique dataset from a UK FinTech lender, we demonstrate the power of fine-grained transaction data while simultaneously cautioning its safe usage.","Three ML classifiers are compared in predicting the likelihood of FV, and groups exhibiting different magnitudes and forms of FV are identified via clustering to highlight the effects of feature combination.","Our results indicate that engineered features of financial behavior can be predictive of omitted personal information, particularly sensitive or protected characteristics, shedding light on the hidden dangers of Open Banking data.","We discuss the implications and conclude fairness via unawareness is ineffective in this new technological environment."],"url":"http://arxiv.org/abs/2307.13408v1"}
{"created":"2023-07-25 10:53:20","title":"Towards Bridging the Digital Language Divide","abstract":"It is a well-known fact that current AI-based language technology -- language models, machine translation systems, multilingual dictionaries and corpora -- focuses on the world's 2-3% most widely spoken languages. Recent research efforts have attempted to expand the coverage of AI technology to `under-resourced languages.' The goal of our paper is to bring attention to a phenomenon that we call linguistic bias: multilingual language processing systems often exhibit a hardwired, yet usually involuntary and hidden representational preference towards certain languages. Linguistic bias is manifested in uneven per-language performance even in the case of similar test conditions. We show that biased technology is often the result of research and development methodologies that do not do justice to the complexity of the languages being represented, and that can even become ethically problematic as they disregard valuable aspects of diversity as well as the needs of the language communities themselves. As our attempt at building diversity-aware language resources, we present a new initiative that aims at reducing linguistic bias through both technological design and methodology, based on an eye-level collaboration with local communities.","sentences":["It is a well-known fact that current AI-based language technology -- language models, machine translation systems, multilingual dictionaries and corpora -- focuses on the world's 2-3% most widely spoken languages.","Recent research efforts have attempted to expand the coverage of AI technology to `under-resourced languages.'","The goal of our paper is to bring attention to a phenomenon that we call linguistic bias: multilingual language processing systems often exhibit a hardwired, yet usually involuntary and hidden representational preference towards certain languages.","Linguistic bias is manifested in uneven per-language performance even in the case of similar test conditions.","We show that biased technology is often the result of research and development methodologies that do not do justice to the complexity of the languages being represented, and that can even become ethically problematic as they disregard valuable aspects of diversity as well as the needs of the language communities themselves.","As our attempt at building diversity-aware language resources, we present a new initiative that aims at reducing linguistic bias through both technological design and methodology, based on an eye-level collaboration with local communities."],"url":"http://arxiv.org/abs/2307.13405v1"}
{"created":"2023-07-25 10:48:00","title":"Longer Is Shorter: Making Long Paths to Improve the Worst-Case Response Time of DAG Tasks","abstract":"DAG (directed acyclic graph) tasks are widely used to model parallel real-time workload. The real-time performance of a DAG task not only depends on its total workload, but also its graph structure. Intuitively, with the same total workload, a DAG task with looser precedence constraints tends to have better real-time performance in terms of worst-case response time. However, this paper shows that actually we can shorten the worst-case response time of a DAG task by carefully adding new edges and constructing longer paths. We develop techniques based on the state-of-the-art DAG response time analysis techniques to properly add new edges so that the worst-case response time bound guaranteed by formal analysis can be significantly reduced. Experiments under different parameter settings demonstrate the effectiveness of the proposed techniques.","sentences":["DAG (directed acyclic graph) tasks are widely used to model parallel real-time workload.","The real-time performance of a DAG task not only depends on its total workload, but also its graph structure.","Intuitively, with the same total workload, a DAG task with looser precedence constraints tends to have better real-time performance in terms of worst-case response time.","However, this paper shows that actually we can shorten the worst-case response time of a DAG task by carefully adding new edges and constructing longer paths.","We develop techniques based on the state-of-the-art DAG response time analysis techniques to properly add new edges so that the worst-case response time bound guaranteed by formal analysis can be significantly reduced.","Experiments under different parameter settings demonstrate the effectiveness of the proposed techniques."],"url":"http://arxiv.org/abs/2307.13401v1"}
{"created":"2023-07-25 10:31:45","title":"Scoring Cycling Environments Perceived Safety using Pairwise Image Comparisons","abstract":"Today, many cities seek to transition to more sustainable transportation systems. Cycling is critical in this transition for shorter trips, including first-and-last-mile links to transit. Yet, if individuals perceive cycling as unsafe, they will not cycle and choose other transportation modes. This study presents a novel approach to identifying how the perception of cycling safety can be analyzed and understood and the impact of the built environment and cycling contexts on such perceptions. We base our work on other perception studies and pairwise comparisons, using real-world images to survey respondents. We repeatedly show respondents two road environments and ask them to select the one they perceive as safer for cycling. We compare several methods capable of rating cycling environments from pairwise comparisons and classify cycling environments perceived as safe or unsafe. Urban planning can use this score to improve interventions' effectiveness and improve cycling promotion campaigns. Furthermore, this approach facilitates the continuous assessment of changing cycling environments, allows for a short-term evaluation of measures, and is efficiently deployed in different locations or contexts.","sentences":["Today, many cities seek to transition to more sustainable transportation systems.","Cycling is critical in this transition for shorter trips, including first-and-last-mile links to transit.","Yet, if individuals perceive cycling as unsafe, they will not cycle and choose other transportation modes.","This study presents a novel approach to identifying how the perception of cycling safety can be analyzed and understood and the impact of the built environment and cycling contexts on such perceptions.","We base our work on other perception studies and pairwise comparisons, using real-world images to survey respondents.","We repeatedly show respondents two road environments and ask them to select the one they perceive as safer for cycling.","We compare several methods capable of rating cycling environments from pairwise comparisons and classify cycling environments perceived as safe or unsafe.","Urban planning can use this score to improve interventions' effectiveness and improve cycling promotion campaigns.","Furthermore, this approach facilitates the continuous assessment of changing cycling environments, allows for a short-term evaluation of measures, and is efficiently deployed in different locations or contexts."],"url":"http://arxiv.org/abs/2307.13397v1"}
{"created":"2023-07-25 10:31:36","title":"Solving Odd-Fair Parity Games","abstract":"This paper discusses the problem of efficiently solving parity games where player Odd has to obey an additional 'strong transition fairness constraint' on its vertices -- given that a player Odd vertex $v$ is visited infinitely often, a particular subset of the outgoing edges (called live edges) of $v$ has to be taken infinitely often. Such games, which we call 'Odd-fair parity games', naturally arise from abstractions of cyber-physical systems for planning and control.   In this paper, we present a new Zielonka-type algorithm for solving Odd-fair parity games. This algorithm not only shares 'the same worst-case time complexity' as Zielonka's algorithm for (normal) parity games but also preserves the algorithmic advantage Zielonka's algorithm possesses over other parity solvers with exponential time complexity.   We additionally introduce a formalization of Odd player winning strategies in such games, which were unexplored previous to this work. This formalization serves dual purposes: firstly, it enables us to prove our Zielonka-type algorithm; secondly, it stands as a noteworthy contribution in its own right, augmenting our understanding of additional fairness assumptions in two-player games.","sentences":["This paper discusses the problem of efficiently solving parity games where player Odd has to obey an additional 'strong transition fairness constraint' on its vertices -- given that a player Odd vertex $v$ is visited infinitely often, a particular subset of the outgoing edges (called live edges) of $v$ has to be taken infinitely often.","Such games, which we call 'Odd-fair parity games', naturally arise from abstractions of cyber-physical systems for planning and control.   ","In this paper, we present a new Zielonka-type algorithm for solving Odd-fair parity games.","This algorithm not only shares 'the same worst-case time complexity' as Zielonka's algorithm for (normal) parity games but also preserves the algorithmic advantage Zielonka's algorithm possesses over other parity solvers with exponential time complexity.   ","We additionally introduce a formalization of Odd player winning strategies in such games, which were unexplored previous to this work.","This formalization serves dual purposes: firstly, it enables us to prove our Zielonka-type algorithm; secondly, it stands as a noteworthy contribution in its own right, augmenting our understanding of additional fairness assumptions in two-player games."],"url":"http://arxiv.org/abs/2307.13396v1"}
{"created":"2023-07-25 10:27:00","title":"An End-to-End Workflow using Topic Segmentation and Text Summarisation Methods for Improved Podcast Comprehension","abstract":"The consumption of podcast media has been increasing rapidly. Due to the lengthy nature of podcast episodes, users often carefully select which ones to listen to. Although episode descriptions aid users by providing a summary of the entire podcast, they do not provide a topic-by-topic breakdown. This study explores the combined application of topic segmentation and text summarisation methods to investigate how podcast episode comprehension can be improved. We have sampled 10 episodes from Spotify's English-Language Podcast Dataset and employed TextTiling and TextSplit to segment them. Moreover, three text summarisation models, namely T5, BART, and Pegasus, were applied to provide a very short title for each segment. The segmentation part was evaluated using our annotated sample with the $P_k$ and WindowDiff ($WD$) metrics. A survey was also rolled out ($N=25$) to assess the quality of the generated summaries. The TextSplit algorithm achieved the lowest mean for both evaluation metrics ($\\bar{P_k}=0.41$ and $\\bar{WD}=0.41$), while the T5 model produced the best summaries, achieving a relevancy score only $8\\%$ less to the one achieved by the human-written titles.","sentences":["The consumption of podcast media has been increasing rapidly.","Due to the lengthy nature of podcast episodes, users often carefully select which ones to listen to.","Although episode descriptions aid users by providing a summary of the entire podcast, they do not provide a topic-by-topic breakdown.","This study explores the combined application of topic segmentation and text summarisation methods to investigate how podcast episode comprehension can be improved.","We have sampled 10 episodes from Spotify's English-Language Podcast Dataset and employed TextTiling and TextSplit to segment them.","Moreover, three text summarisation models, namely T5, BART, and Pegasus, were applied to provide a very short title for each segment.","The segmentation part was evaluated using our annotated sample with the $P_k$ and WindowDiff ($WD$) metrics.","A survey was also rolled out ($N=25$) to assess the quality of the generated summaries.","The TextSplit algorithm achieved the lowest mean for both evaluation metrics ($\\bar{P_k}=0.41$ and $\\bar{WD}=0.41$), while the T5 model produced the best summaries, achieving a relevancy score only $8\\%$ less to the one achieved by the human-written titles."],"url":"http://arxiv.org/abs/2307.13394v1"}
{"created":"2023-07-25 10:21:26","title":"Counterfactual Explanation via Search in Gaussian Mixture Distributed Latent Space","abstract":"Counterfactual Explanations (CEs) are an important tool in Algorithmic Recourse for addressing two questions: 1. What are the crucial factors that led to an automated prediction/decision? 2. How can these factors be changed to achieve a more favorable outcome from a user's perspective? Thus, guiding the user's interaction with AI systems by proposing easy-to-understand explanations and easy-to-attain feasible changes is essential for the trustworthy adoption and long-term acceptance of AI systems. In the literature, various methods have been proposed to generate CEs, and different quality measures have been suggested to evaluate these methods. However, the generation of CEs is usually computationally expensive, and the resulting suggestions are unrealistic and thus non-actionable. In this paper, we introduce a new method to generate CEs for a pre-trained binary classifier by first shaping the latent space of an autoencoder to be a mixture of Gaussian distributions. CEs are then generated in latent space by linear interpolation between the query sample and the centroid of the target class. We show that our method maintains the characteristics of the input sample during the counterfactual search. In various experiments, we show that the proposed method is competitive based on different quality measures on image and tabular datasets -- efficiently returns results that are closer to the original data manifold compared to three state-of-the-art methods, which are essential for realistic high-dimensional machine learning applications.","sentences":["Counterfactual Explanations (CEs) are an important tool in Algorithmic Recourse for addressing two questions:","1.","What are the crucial factors that led to an automated prediction/decision?","2. How can these factors be changed to achieve a more favorable outcome from a user's perspective?","Thus, guiding the user's interaction with AI systems by proposing easy-to-understand explanations and easy-to-attain feasible changes is essential for the trustworthy adoption and long-term acceptance of AI systems.","In the literature, various methods have been proposed to generate CEs, and different quality measures have been suggested to evaluate these methods.","However, the generation of CEs is usually computationally expensive, and the resulting suggestions are unrealistic and thus non-actionable.","In this paper, we introduce a new method to generate CEs for a pre-trained binary classifier by first shaping the latent space of an autoencoder to be a mixture of Gaussian distributions.","CEs are then generated in latent space by linear interpolation between the query sample and the centroid of the target class.","We show that our method maintains the characteristics of the input sample during the counterfactual search.","In various experiments, we show that the proposed method is competitive based on different quality measures on image and tabular datasets -- efficiently returns results that are closer to the original data manifold compared to three state-of-the-art methods, which are essential for realistic high-dimensional machine learning applications."],"url":"http://arxiv.org/abs/2307.13390v1"}
{"created":"2023-07-25 10:15:38","title":"BotHawk: An Approach for Bots Detection in Open Source Software Projects","abstract":"Social coding platforms have revolutionized collaboration in software development, leading to using software bots for streamlining operations. However, The presence of open-source software (OSS) bots gives rise to problems including impersonation, spamming, bias, and security risks. Identifying bot accounts and behavior is a challenging task in the OSS project. This research aims to investigate bots' behavior in open-source software projects and identify bot accounts with maximum possible accuracy. Our team gathered a dataset of 19,779 accounts that meet standardized criteria to enable future research on bots in open-source projects. We follow a rigorous workflow to ensure that the data we collect is accurate, generalizable, scalable, and up-to-date. We've identified four types of bot accounts in open-source software projects by analyzing their behavior across 17 features in 5 dimensions. Our team created BotHawk, a highly effective model for detecting bots in open-source software projects. It outperforms other models, achieving an AUC of 0.947 and an F1-score of 0.89. BotHawk can detect a wider variety of bots, including CI/CD and scanning bots. Furthermore, we find that the number of followers, number of repositories, and tags contain the most relevant features to identify the account type.","sentences":["Social coding platforms have revolutionized collaboration in software development, leading to using software bots for streamlining operations.","However, The presence of open-source software (OSS) bots gives rise to problems including impersonation, spamming, bias, and security risks.","Identifying bot accounts and behavior is a challenging task in the OSS project.","This research aims to investigate bots' behavior in open-source software projects and identify bot accounts with maximum possible accuracy.","Our team gathered a dataset of 19,779 accounts that meet standardized criteria to enable future research on bots in open-source projects.","We follow a rigorous workflow to ensure that the data we collect is accurate, generalizable, scalable, and up-to-date.","We've identified four types of bot accounts in open-source software projects by analyzing their behavior across 17 features in 5 dimensions.","Our team created BotHawk, a highly effective model for detecting bots in open-source software projects.","It outperforms other models, achieving an AUC of 0.947 and an F1-score of 0.89.","BotHawk can detect a wider variety of bots, including CI/CD and scanning bots.","Furthermore, we find that the number of followers, number of repositories, and tags contain the most relevant features to identify the account type."],"url":"http://arxiv.org/abs/2307.13386v1"}
{"created":"2023-07-25 10:07:02","title":"Predicting Code Coverage without Execution","abstract":"Code coverage is a widely used metric for quantifying the extent to which program elements, such as statements or branches, are executed during testing. Calculating code coverage is resource-intensive, requiring code building and execution with additional overhead for the instrumentation. Furthermore, computing coverage of any snippet of code requires the whole program context. Using Machine Learning to amortize this expensive process could lower the cost of code coverage by requiring only the source code context, and the task of code coverage prediction can be a novel benchmark for judging the ability of models to understand code. We propose a novel benchmark task called Code Coverage Prediction for Large Language Models (LLMs). We formalize this task to evaluate the capability of LLMs in understanding code execution by determining which lines of a method are executed by a given test case and inputs. We curate and release a dataset we call COVERAGEEVAL by executing tests and code from the HumanEval dataset and collecting code coverage information. We report the performance of four state-of-the-art LLMs used for code-related tasks, including OpenAI's GPT-4 and GPT-3.5-Turbo, Google's BARD, and Anthropic's Claude, on the Code Coverage Prediction task. Finally, we argue that code coverage as a metric and pre-training data source are valuable for overall LLM performance on software engineering tasks.","sentences":["Code coverage is a widely used metric for quantifying the extent to which program elements, such as statements or branches, are executed during testing.","Calculating code coverage is resource-intensive, requiring code building and execution with additional overhead for the instrumentation.","Furthermore, computing coverage of any snippet of code requires the whole program context.","Using Machine Learning to amortize this expensive process could lower the cost of code coverage by requiring only the source code context, and the task of code coverage prediction can be a novel benchmark for judging the ability of models to understand code.","We propose a novel benchmark task called Code Coverage Prediction for Large Language Models (LLMs).","We formalize this task to evaluate the capability of LLMs in understanding code execution by determining which lines of a method are executed by a given test case and inputs.","We curate and release a dataset we call COVERAGEEVAL by executing tests and code from the HumanEval dataset and collecting code coverage information.","We report the performance of four state-of-the-art LLMs used for code-related tasks, including OpenAI's GPT-4 and GPT-3.5-Turbo, Google's BARD, and Anthropic's Claude, on the Code Coverage Prediction task.","Finally, we argue that code coverage as a metric and pre-training data source are valuable for overall LLM performance on software engineering tasks."],"url":"http://arxiv.org/abs/2307.13383v1"}
{"created":"2023-07-25 10:04:33","title":"Scaff-PD: Communication Efficient Fair and Robust Federated Learning","abstract":"We present Scaff-PD, a fast and communication-efficient algorithm for distributionally robust federated learning. Our approach improves fairness by optimizing a family of distributionally robust objectives tailored to heterogeneous clients. We leverage the special structure of these objectives, and design an accelerated primal dual (APD) algorithm which uses bias corrected local steps (as in Scaffold) to achieve significant gains in communication efficiency and convergence speed. We evaluate Scaff-PD on several benchmark datasets and demonstrate its effectiveness in improving fairness and robustness while maintaining competitive accuracy. Our results suggest that Scaff-PD is a promising approach for federated learning in resource-constrained and heterogeneous settings.","sentences":["We present Scaff-PD, a fast and communication-efficient algorithm for distributionally robust federated learning.","Our approach improves fairness by optimizing a family of distributionally robust objectives tailored to heterogeneous clients.","We leverage the special structure of these objectives, and design an accelerated primal dual (APD) algorithm which uses bias corrected local steps (as in Scaffold) to achieve significant gains in communication efficiency and convergence speed.","We evaluate Scaff-PD on several benchmark datasets and demonstrate its effectiveness in improving fairness and robustness while maintaining competitive accuracy.","Our results suggest that Scaff-PD is a promising approach for federated learning in resource-constrained and heterogeneous settings."],"url":"http://arxiv.org/abs/2307.13381v1"}
{"created":"2023-07-25 09:51:17","title":"Embedding Models for Supervised Automatic Extraction and Classification of Named Entities in Scientific Acknowledgements","abstract":"Acknowledgments in scientific papers may give an insight into aspects of the scientific community, such as reward systems, collaboration patterns, and hidden research trends. The aim of the paper is to evaluate the performance of different embedding models for the task of automatic extraction and classification of acknowledged entities from the acknowledgment text in scientific papers. We trained and implemented a named entity recognition (NER) task using the Flair NLP framework. The training was conducted using three default Flair NER models with four differently-sized corpora and different versions of the Flair NLP framework. The Flair Embeddings model trained on the medium corpus with the latest FLAIR version showed the best accuracy of 0.79. Expanding the size of a training corpus from very small to medium size massively increased the accuracy of all training algorithms, but further expansion of the training corpus did not bring further improvement. Moreover, the performance of the model slightly deteriorated. Our model is able to recognize six entity types: funding agency, grant number, individuals, university, corporation, and miscellaneous. The model works more precisely for some entity types than for others; thus, individuals and grant numbers showed a very good F1-Score over 0.9. Most of the previous works on acknowledgment analysis were limited by the manual evaluation of data and therefore by the amount of processed data. This model can be applied for the comprehensive analysis of acknowledgment texts and may potentially make a great contribution to the field of automated acknowledgment analysis.","sentences":["Acknowledgments in scientific papers may give an insight into aspects of the scientific community, such as reward systems, collaboration patterns, and hidden research trends.","The aim of the paper is to evaluate the performance of different embedding models for the task of automatic extraction and classification of acknowledged entities from the acknowledgment text in scientific papers.","We trained and implemented a named entity recognition (NER) task using the Flair NLP framework.","The training was conducted using three default Flair NER models with four differently-sized corpora and different versions of the Flair NLP framework.","The Flair Embeddings model trained on the medium corpus with the latest FLAIR version showed the best accuracy of 0.79.","Expanding the size of a training corpus from very small to medium size massively increased the accuracy of all training algorithms, but further expansion of the training corpus did not bring further improvement.","Moreover, the performance of the model slightly deteriorated.","Our model is able to recognize six entity types: funding agency, grant number, individuals, university, corporation, and miscellaneous.","The model works more precisely for some entity types than for others; thus, individuals and grant numbers showed a very good F1-Score over 0.9.","Most of the previous works on acknowledgment analysis were limited by the manual evaluation of data and therefore by the amount of processed data.","This model can be applied for the comprehensive analysis of acknowledgment texts and may potentially make a great contribution to the field of automated acknowledgment analysis."],"url":"http://arxiv.org/abs/2307.13377v1"}
{"created":"2023-07-25 09:46:02","title":"Submodular Reinforcement Learning","abstract":"In reinforcement learning (RL), rewards of states are typically considered additive, and following the Markov assumption, they are $\\textit{independent}$ of states visited previously. In many important applications, such as coverage control, experiment design and informative path planning, rewards naturally have diminishing returns, i.e., their value decreases in light of similar states visited previously. To tackle this, we propose $\\textit{submodular RL}$ (SubRL), a paradigm which seeks to optimize more general, non-additive (and history-dependent) rewards modelled via submodular set functions which capture diminishing returns. Unfortunately, in general, even in tabular settings, we show that the resulting optimization problem is hard to approximate. On the other hand, motivated by the success of greedy algorithms in classical submodular optimization, we propose SubPO, a simple policy gradient-based algorithm for SubRL that handles non-additive rewards by greedily maximizing marginal gains. Indeed, under some assumptions on the underlying Markov Decision Process (MDP), SubPO recovers optimal constant factor approximations of submodular bandits. Moreover, we derive a natural policy gradient approach for locally optimizing SubRL instances even in large state- and action- spaces. We showcase the versatility of our approach by applying SubPO to several applications, such as biodiversity monitoring, Bayesian experiment design, informative path planning, and coverage maximization. Our results demonstrate sample efficiency, as well as scalability to high-dimensional state-action spaces.","sentences":["In reinforcement learning (RL), rewards of states are typically considered additive, and following the Markov assumption, they are $\\textit{independent}$ of states visited previously.","In many important applications, such as coverage control, experiment design and informative path planning, rewards naturally have diminishing returns, i.e., their value decreases in light of similar states visited previously.","To tackle this, we propose $\\textit{submodular RL}$ (SubRL), a paradigm which seeks to optimize more general, non-additive (and history-dependent) rewards modelled via submodular set functions which capture diminishing returns.","Unfortunately, in general, even in tabular settings, we show that the resulting optimization problem is hard to approximate.","On the other hand, motivated by the success of greedy algorithms in classical submodular optimization, we propose SubPO, a simple policy gradient-based algorithm for SubRL that handles non-additive rewards by greedily maximizing marginal gains.","Indeed, under some assumptions on the underlying Markov Decision Process (MDP), SubPO recovers optimal constant factor approximations of submodular bandits.","Moreover, we derive a natural policy gradient approach for locally optimizing SubRL instances even in large state- and action- spaces.","We showcase the versatility of our approach by applying SubPO to several applications, such as biodiversity monitoring, Bayesian experiment design, informative path planning, and coverage maximization.","Our results demonstrate sample efficiency, as well as scalability to high-dimensional state-action spaces."],"url":"http://arxiv.org/abs/2307.13372v1"}
{"created":"2023-07-25 09:45:47","title":"Learning Regions of Interest for Bayesian Optimization with Adaptive Level-Set Estimation","abstract":"We study Bayesian optimization (BO) in high-dimensional and non-stationary scenarios. Existing algorithms for such scenarios typically require extensive hyperparameter tuning, which limits their practical effectiveness. We propose a framework, called BALLET, which adaptively filters for a high-confidence region of interest (ROI) as a superlevel-set of a nonparametric probabilistic model such as a Gaussian process (GP). Our approach is easy to tune, and is able to focus on local region of the optimization space that can be tackled by existing BO methods. The key idea is to use two probabilistic models: a coarse GP to identify the ROI, and a localized GP for optimization within the ROI. We show theoretically that BALLET can efficiently shrink the search space, and can exhibit a tighter regret bound than standard BO without ROI filtering. We demonstrate empirically the effectiveness of BALLET on both synthetic and real-world optimization tasks.","sentences":["We study Bayesian optimization (BO) in high-dimensional and non-stationary scenarios.","Existing algorithms for such scenarios typically require extensive hyperparameter tuning, which limits their practical effectiveness.","We propose a framework, called BALLET, which adaptively filters for a high-confidence region of interest (ROI) as a superlevel-set of a nonparametric probabilistic model such as a Gaussian process (GP).","Our approach is easy to tune, and is able to focus on local region of the optimization space that can be tackled by existing BO methods.","The key idea is to use two probabilistic models: a coarse GP to identify the ROI, and a localized GP for optimization within the ROI.","We show theoretically that BALLET can efficiently shrink the search space, and can exhibit a tighter regret bound than standard BO without ROI filtering.","We demonstrate empirically the effectiveness of BALLET on both synthetic and real-world optimization tasks."],"url":"http://arxiv.org/abs/2307.13371v1"}
{"created":"2023-07-25 09:39:59","title":"Kefa: A Knowledge Enhanced and Fine-grained Aligned Speaker for Navigation Instruction Generation","abstract":"We introduce a novel speaker model \\textsc{Kefa} for navigation instruction generation. The existing speaker models in Vision-and-Language Navigation suffer from the large domain gap of vision features between different environments and insufficient temporal grounding capability. To address the challenges, we propose a Knowledge Refinement Module to enhance the feature representation with external knowledge facts, and an Adaptive Temporal Alignment method to enforce fine-grained alignment between the generated instructions and the observation sequences. Moreover, we propose a new metric SPICE-D for navigation instruction evaluation, which is aware of the correctness of direction phrases. The experimental results on R2R and UrbanWalk datasets show that the proposed KEFA speaker achieves state-of-the-art instruction generation performance for both indoor and outdoor scenes.","sentences":["We introduce a novel speaker model \\textsc{Kefa} for navigation instruction generation.","The existing speaker models in Vision-and-Language Navigation suffer from the large domain gap of vision features between different environments and insufficient temporal grounding capability.","To address the challenges, we propose a Knowledge Refinement Module to enhance the feature representation with external knowledge facts, and an Adaptive Temporal Alignment method to enforce fine-grained alignment between the generated instructions and the observation sequences.","Moreover, we propose a new metric SPICE-D for navigation instruction evaluation, which is aware of the correctness of direction phrases.","The experimental results on R2R and UrbanWalk datasets show that the proposed KEFA speaker achieves state-of-the-art instruction generation performance for both indoor and outdoor scenes."],"url":"http://arxiv.org/abs/2307.13368v1"}
{"created":"2023-07-25 09:34:42","title":"Empower Your Model with Longer and Better Context Comprehension","abstract":"Recently, with the emergence of numerous Large Language Models (LLMs), the implementation of AI has entered a new era. Irrespective of these models' own capacity and structure, there is a growing demand for LLMs to possess enhanced comprehension of longer and more complex contexts with relatively smaller sizes. Models often encounter an upper limit when processing sequences of sentences that extend beyond their comprehension capacity and result in off-topic or even chaotic responses. While several recent works attempt to address this issue in various ways, they rarely focus on \"why models are unable to compensate or strengthen their capabilities on their own\". In this paper, we thoroughly investigate the nature of information transfer within LLMs and propose a novel technique called Attention Transition. This technique empowers models to achieve longer and better context comprehension with minimal additional training or impact on generation fluency. Our experiments are conducted in XSum and achieve substantial improvement compared with the original generation results.","sentences":["Recently, with the emergence of numerous Large Language Models (LLMs), the implementation of AI has entered a new era.","Irrespective of these models' own capacity and structure, there is a growing demand for LLMs to possess enhanced comprehension of longer and more complex contexts with relatively smaller sizes.","Models often encounter an upper limit when processing sequences of sentences that extend beyond their comprehension capacity and result in off-topic or even chaotic responses.","While several recent works attempt to address this issue in various ways, they rarely focus on \"why models are unable to compensate or strengthen their capabilities on their own\".","In this paper, we thoroughly investigate the nature of information transfer within LLMs and propose a novel technique called Attention Transition.","This technique empowers models to achieve longer and better context comprehension with minimal additional training or impact on generation fluency.","Our experiments are conducted in XSum and achieve substantial improvement compared with the original generation results."],"url":"http://arxiv.org/abs/2307.13365v1"}
{"created":"2023-07-25 09:33:25","title":"3DRP-Net: 3D Relative Position-aware Network for 3D Visual Grounding","abstract":"3D visual grounding aims to localize the target object in a 3D point cloud by a free-form language description. Typically, the sentences describing the target object tend to provide information about its relative relation between other objects and its position within the whole scene. In this work, we propose a relation-aware one-stage framework, named 3D Relative Position-aware Network (3DRP-Net), which can effectively capture the relative spatial relationships between objects and enhance object attributes. Specifically, 1) we propose a 3D Relative Position Multi-head Attention (3DRP-MA) module to analyze relative relations from different directions in the context of object pairs, which helps the model to focus on the specific object relations mentioned in the sentence. 2) We designed a soft-labeling strategy to alleviate the spatial ambiguity caused by redundant points, which further stabilizes and enhances the learning process through a constant and discriminative distribution. Extensive experiments conducted on three benchmarks (i.e., ScanRefer and Nr3D/Sr3D) demonstrate that our method outperforms all the state-of-the-art methods in general. The source code will be released on GitHub.","sentences":["3D visual grounding aims to localize the target object in a 3D point cloud by a free-form language description.","Typically, the sentences describing the target object tend to provide information about its relative relation between other objects and its position within the whole scene.","In this work, we propose a relation-aware one-stage framework, named 3D Relative Position-aware Network (3DRP-Net), which can effectively capture the relative spatial relationships between objects and enhance object attributes.","Specifically, 1) we propose a 3D Relative Position Multi-head Attention (3DRP-MA) module to analyze relative relations from different directions in the context of object pairs, which helps the model to focus on the specific object relations mentioned in the sentence.","2) We designed a soft-labeling strategy to alleviate the spatial ambiguity caused by redundant points, which further stabilizes and enhances the learning process through a constant and discriminative distribution.","Extensive experiments conducted on three benchmarks (i.e., ScanRefer and Nr3D/Sr3D) demonstrate that our method outperforms all the state-of-the-art methods in general.","The source code will be released on GitHub."],"url":"http://arxiv.org/abs/2307.13363v1"}
{"created":"2023-07-25 09:31:55","title":"Of Mice and Pose: 2D Mouse Pose Estimation from Unlabelled Data and Synthetic Prior","abstract":"Numerous fields, such as ecology, biology, and neuroscience, use animal recordings to track and measure animal behaviour. Over time, a significant volume of such data has been produced, but some computer vision techniques cannot explore it due to the lack of annotations. To address this, we propose an approach for estimating 2D mouse body pose from unlabelled images using a synthetically generated empirical pose prior. Our proposal is based on a recent self-supervised method for estimating 2D human pose that uses single images and a set of unpaired typical 2D poses within a GAN framework. We adapt this method to the limb structure of the mouse and generate the empirical prior of 2D poses from a synthetic 3D mouse model, thereby avoiding manual annotation. In experiments on a new mouse video dataset, we evaluate the performance of the approach by comparing pose predictions to a manually obtained ground truth. We also compare predictions with those from a supervised state-of-the-art method for animal pose estimation. The latter evaluation indicates promising results despite the lack of paired training data. Finally, qualitative results using a dataset of horse images show the potential of the setting to adapt to other animal species.","sentences":["Numerous fields, such as ecology, biology, and neuroscience, use animal recordings to track and measure animal behaviour.","Over time, a significant volume of such data has been produced, but some computer vision techniques cannot explore it due to the lack of annotations.","To address this, we propose an approach for estimating 2D mouse body pose from unlabelled images using a synthetically generated empirical pose prior.","Our proposal is based on a recent self-supervised method for estimating 2D human pose that uses single images and a set of unpaired typical 2D poses within a GAN framework.","We adapt this method to the limb structure of the mouse and generate the empirical prior of 2D poses from a synthetic 3D mouse model, thereby avoiding manual annotation.","In experiments on a new mouse video dataset, we evaluate the performance of the approach by comparing pose predictions to a manually obtained ground truth.","We also compare predictions with those from a supervised state-of-the-art method for animal pose estimation.","The latter evaluation indicates promising results despite the lack of paired training data.","Finally, qualitative results using a dataset of horse images show the potential of the setting to adapt to other animal species."],"url":"http://arxiv.org/abs/2307.13361v1"}
{"created":"2023-07-25 09:30:21","title":"An Axiomatic Theory for Reversible Computation","abstract":"Undoing computations of a concurrent system is beneficial in many situations, e.g., in reversible debugging of multi-threaded programs and in recovery from errors due to optimistic execution in parallel discrete event simulation. A number of approaches have been proposed for how to reverse formal models of concurrent computation including process calculi such as CCS, languages like Erlang, prime event structures and occurrence nets. However it has not been settled what properties a reversible system should enjoy, nor how the various properties that have been suggested, such as the parabolic lemma and the causal-consistency property, are related. We contribute to a solution to these issues by using a generic labelled transition system equipped with a relation capturing whether transitions are independent to explore the implications between these properties. In particular, we show how they are derivable from a set of axioms. Our intention is that when establishing properties of some formalism it will be easier to verify the axioms rather than proving properties such as the parabolic lemma directly. We also introduce two new notions related to causal consistent reversibility, namely causal liveness and causal safety, stating, respectively, that an action can be undone if and only if it is independent from all the following ones. We show that both causal liveness and causal safety are derivable from our axioms.","sentences":["Undoing computations of a concurrent system is beneficial in many situations, e.g., in reversible debugging of multi-threaded programs and in recovery from errors due to optimistic execution in parallel discrete event simulation.","A number of approaches have been proposed for how to reverse formal models of concurrent computation including process calculi such as CCS, languages like Erlang, prime event structures and occurrence nets.","However it has not been settled what properties a reversible system should enjoy, nor how the various properties that have been suggested, such as the parabolic lemma and the causal-consistency property, are related.","We contribute to a solution to these issues by using a generic labelled transition system equipped with a relation capturing whether transitions are independent to explore the implications between these properties.","In particular, we show how they are derivable from a set of axioms.","Our intention is that when establishing properties of some formalism it will be easier to verify the axioms rather than proving properties such as the parabolic lemma directly.","We also introduce two new notions related to causal consistent reversibility, namely causal liveness and causal safety, stating, respectively, that an action can be undone if and only if it is independent from all the following ones.","We show that both causal liveness and causal safety are derivable from our axioms."],"url":"http://arxiv.org/abs/2307.13360v1"}
{"created":"2023-07-25 09:04:24","title":"Federated Heavy Hitter Recovery under Linear Sketching","abstract":"Motivated by real-life deployments of multi-round federated analytics with secure aggregation, we investigate the fundamental communication-accuracy tradeoffs of the heavy hitter discovery and approximate (open-domain) histogram problems under a linear sketching constraint. We propose efficient algorithms based on local subsampling and invertible bloom look-up tables (IBLTs). We also show that our algorithms are information-theoretically optimal for a broad class of interactive schemes. The results show that the linear sketching constraint does increase the communication cost for both tasks by introducing an extra linear dependence on the number of users in a round. Moreover, our results also establish a separation between the communication cost for heavy hitter discovery and approximate histogram in the multi-round setting. The dependence on the number of rounds $R$ is at most logarithmic for heavy hitter discovery whereas that of approximate histogram is $\\Theta(\\sqrt{R})$. We also empirically demonstrate our findings.","sentences":["Motivated by real-life deployments of multi-round federated analytics with secure aggregation, we investigate the fundamental communication-accuracy tradeoffs of the heavy hitter discovery and approximate (open-domain) histogram problems under a linear sketching constraint.","We propose efficient algorithms based on local subsampling and invertible bloom look-up tables (IBLTs).","We also show that our algorithms are information-theoretically optimal for a broad class of interactive schemes.","The results show that the linear sketching constraint does increase the communication cost for both tasks by introducing an extra linear dependence on the number of users in a round.","Moreover, our results also establish a separation between the communication cost for heavy hitter discovery and approximate histogram in the multi-round setting.","The dependence on the number of rounds $R$ is at most logarithmic for heavy hitter discovery whereas that of approximate histogram is $\\Theta(\\sqrt{R})$. We also empirically demonstrate our findings."],"url":"http://arxiv.org/abs/2307.13347v1"}
{"created":"2023-07-25 09:03:27","title":"A Snoring Sound Dataset for Body Position Recognition: Collection, Annotation, and Analysis","abstract":"Obstructive Sleep Apnea-Hypopnea Syndrome (OSAHS) is a chronic breathing disorder caused by a blockage in the upper airways. Snoring is a prominent symptom of OSAHS, and previous studies have attempted to identify the obstruction site of the upper airways by snoring sounds. Despite some progress, the classification of the obstruction site remains challenging in real-world clinical settings due to the influence of sleep body position on upper airways. To address this challenge, this paper proposes a snore-based sleep body position recognition dataset (SSBPR) consisting of 7570 snoring recordings, which comprises six distinct labels for sleep body position: supine, supine but left lateral head, supine but right lateral head, left-side lying, right-side lying and prone. Experimental results show that snoring sounds exhibit certain acoustic features that enable their effective utilization for identifying body posture during sleep in real-world scenarios.","sentences":["Obstructive Sleep Apnea-Hypopnea Syndrome (OSAHS) is a chronic breathing disorder caused by a blockage in the upper airways.","Snoring is a prominent symptom of OSAHS, and previous studies have attempted to identify the obstruction site of the upper airways by snoring sounds.","Despite some progress, the classification of the obstruction site remains challenging in real-world clinical settings due to the influence of sleep body position on upper airways.","To address this challenge, this paper proposes a snore-based sleep body position recognition dataset (SSBPR) consisting of 7570 snoring recordings, which comprises six distinct labels for sleep body position: supine, supine but left lateral head, supine but right lateral head, left-side lying, right-side lying and prone.","Experimental results show that snoring sounds exhibit certain acoustic features that enable their effective utilization for identifying body posture during sleep in real-world scenarios."],"url":"http://arxiv.org/abs/2307.13346v1"}
{"created":"2023-07-25 09:02:29","title":"Do humans and Convolutional Neural Networks attend to similar areas during scene classification: Effects of task and image type","abstract":"Deep Learning models like Convolutional Neural Networks (CNN) are powerful image classifiers, but what factors determine whether they attend to similar image areas as humans do? While previous studies have focused on technological factors, little is known about the role of factors that affect human attention. In the present study, we investigated how the tasks used to elicit human attention maps interact with image characteristics in modulating the similarity between humans and CNN. We varied the intentionality of human tasks, ranging from spontaneous gaze during categorization over intentional gaze-pointing up to manual area selection. Moreover, we varied the type of image to be categorized, using either singular, salient objects, indoor scenes consisting of object arrangements, or landscapes without distinct objects defining the category. The human attention maps generated in this way were compared to the CNN attention maps revealed by explainable artificial intelligence (Grad-CAM). The influence of human tasks strongly depended on image type: For objects, human manual selection produced maps that were most similar to CNN, while the specific eye movement task has little impact. For indoor scenes, spontaneous gaze produced the least similarity, while for landscapes, similarity was equally low across all human tasks. To better understand these results, we also compared the different human attention maps to each other. Our results highlight the importance of taking human factors into account when comparing the attention of humans and CNN.","sentences":["Deep Learning models like Convolutional Neural Networks (CNN) are powerful image classifiers, but what factors determine whether they attend to similar image areas as humans do?","While previous studies have focused on technological factors, little is known about the role of factors that affect human attention.","In the present study, we investigated how the tasks used to elicit human attention maps interact with image characteristics in modulating the similarity between humans and CNN.","We varied the intentionality of human tasks, ranging from spontaneous gaze during categorization over intentional gaze-pointing up to manual area selection.","Moreover, we varied the type of image to be categorized, using either singular, salient objects, indoor scenes consisting of object arrangements, or landscapes without distinct objects defining the category.","The human attention maps generated in this way were compared to the CNN attention maps revealed by explainable artificial intelligence (Grad-CAM).","The influence of human tasks strongly depended on image type:","For objects, human manual selection produced maps that were most similar to CNN, while the specific eye movement task has little impact.","For indoor scenes, spontaneous gaze produced the least similarity, while for landscapes, similarity was equally low across all human tasks.","To better understand these results, we also compared the different human attention maps to each other.","Our results highlight the importance of taking human factors into account when comparing the attention of humans and CNN."],"url":"http://arxiv.org/abs/2307.13345v1"}
{"created":"2023-07-25 08:58:26","title":"Prior Based Online Lane Graph Extraction from Single Onboard Camera Image","abstract":"The local road network information is essential for autonomous navigation. This information is commonly obtained from offline HD-Maps in terms of lane graphs. However, the local road network at a given moment can be drastically different than the one given in the offline maps; due to construction works, accidents etc. Moreover, the autonomous vehicle might be at a location not covered in the offline HD-Map. Thus, online estimation of the lane graph is crucial for widespread and reliable autonomous navigation. In this work, we tackle online Bird's-Eye-View lane graph extraction from a single onboard camera image. We propose to use prior information to increase quality of the estimations. The prior is extracted from the dataset through a transformer based Wasserstein Autoencoder. The autoencoder is then used to enhance the initial lane graph estimates. This is done through optimization of the latent space vector. The optimization encourages the lane graph estimation to be logical by discouraging it to diverge from the prior distribution. We test the method on two benchmark datasets, NuScenes and Argoverse. The results show that the proposed method significantly improves the performance compared to state-of-the-art methods.","sentences":["The local road network information is essential for autonomous navigation.","This information is commonly obtained from offline HD-Maps in terms of lane graphs.","However, the local road network at a given moment can be drastically different than the one given in the offline maps; due to construction works, accidents etc.","Moreover, the autonomous vehicle might be at a location not covered in the offline HD-Map.","Thus, online estimation of the lane graph is crucial for widespread and reliable autonomous navigation.","In this work, we tackle online Bird's-Eye-View lane graph extraction from a single onboard camera image.","We propose to use prior information to increase quality of the estimations.","The prior is extracted from the dataset through a transformer based Wasserstein Autoencoder.","The autoencoder is then used to enhance the initial lane graph estimates.","This is done through optimization of the latent space vector.","The optimization encourages the lane graph estimation to be logical by discouraging it to diverge from the prior distribution.","We test the method on two benchmark datasets, NuScenes and Argoverse.","The results show that the proposed method significantly improves the performance compared to state-of-the-art methods."],"url":"http://arxiv.org/abs/2307.13344v1"}
{"created":"2023-07-25 08:51:30","title":"Analyzing Chain-of-Thought Prompting in Large Language Models via Gradient-based Feature Attributions","abstract":"Chain-of-thought (CoT) prompting has been shown to empirically improve the accuracy of large language models (LLMs) on various question answering tasks. While understanding why CoT prompting is effective is crucial to ensuring that this phenomenon is a consequence of desired model behavior, little work has addressed this; nonetheless, such an understanding is a critical prerequisite for responsible model deployment. We address this question by leveraging gradient-based feature attribution methods which produce saliency scores that capture the influence of input tokens on model output. Specifically, we probe several open-source LLMs to investigate whether CoT prompting affects the relative importances they assign to particular input tokens. Our results indicate that while CoT prompting does not increase the magnitude of saliency scores attributed to semantically relevant tokens in the prompt compared to standard few-shot prompting, it increases the robustness of saliency scores to question perturbations and variations in model output.","sentences":["Chain-of-thought (CoT) prompting has been shown to empirically improve the accuracy of large language models (LLMs) on various question answering tasks.","While understanding why CoT prompting is effective is crucial to ensuring that this phenomenon is a consequence of desired model behavior, little work has addressed this; nonetheless, such an understanding is a critical prerequisite for responsible model deployment.","We address this question by leveraging gradient-based feature attribution methods which produce saliency scores that capture the influence of input tokens on model output.","Specifically, we probe several open-source LLMs to investigate whether CoT prompting affects the relative importances they assign to particular input tokens.","Our results indicate that while CoT prompting does not increase the magnitude of saliency scores attributed to semantically relevant tokens in the prompt compared to standard few-shot prompting, it increases the robustness of saliency scores to question perturbations and variations in model output."],"url":"http://arxiv.org/abs/2307.13339v1"}
{"created":"2023-07-25 08:50:01","title":"Overcoming Distribution Mismatch in Quantizing Image Super-Resolution Networks","abstract":"Quantization is a promising approach to reduce the high computational complexity of image super-resolution (SR) networks. However, compared to high-level tasks like image classification, low-bit quantization leads to severe accuracy loss in SR networks. This is because feature distributions of SR networks are significantly divergent for each channel or input image, and is thus difficult to determine a quantization range. Existing SR quantization works approach this distribution mismatch problem by dynamically adapting quantization ranges to the variant distributions during test time. However, such dynamic adaptation incurs additional computational costs that limit the benefits of quantization. Instead, we propose a new quantization-aware training framework that effectively Overcomes the Distribution Mismatch problem in SR networks without the need for dynamic adaptation. Intuitively, the mismatch can be reduced by directly regularizing the variance in features during training. However, we observe that variance regularization can collide with the reconstruction loss during training and adversely impact SR accuracy. Thus, we avoid the conflict between two losses by regularizing the variance only when the gradients of variance regularization are cooperative with that of reconstruction. Additionally, to further reduce the distribution mismatch, we introduce distribution offsets to layers with a significant mismatch, which either scales or shifts channel-wise features. Our proposed algorithm, called ODM, effectively reduces the mismatch in distributions with minimal computational overhead. Experimental results show that ODM effectively outperforms existing SR quantization approaches with similar or fewer computations, demonstrating the importance of reducing the distribution mismatch problem. Our code is available at https://github.com/Cheeun/ODM.","sentences":["Quantization is a promising approach to reduce the high computational complexity of image super-resolution (SR) networks.","However, compared to high-level tasks like image classification, low-bit quantization leads to severe accuracy loss in SR networks.","This is because feature distributions of SR networks are significantly divergent for each channel or input image, and is thus difficult to determine a quantization range.","Existing SR quantization works approach this distribution mismatch problem by dynamically adapting quantization ranges to the variant distributions during test time.","However, such dynamic adaptation incurs additional computational costs that limit the benefits of quantization.","Instead, we propose a new quantization-aware training framework that effectively Overcomes the Distribution Mismatch problem in SR networks without the need for dynamic adaptation.","Intuitively, the mismatch can be reduced by directly regularizing the variance in features during training.","However, we observe that variance regularization can collide with the reconstruction loss during training and adversely impact SR accuracy.","Thus, we avoid the conflict between two losses by regularizing the variance only when the gradients of variance regularization are cooperative with that of reconstruction.","Additionally, to further reduce the distribution mismatch, we introduce distribution offsets to layers with a significant mismatch, which either scales or shifts channel-wise features.","Our proposed algorithm, called ODM, effectively reduces the mismatch in distributions with minimal computational overhead.","Experimental results show that ODM effectively outperforms existing SR quantization approaches with similar or fewer computations, demonstrating the importance of reducing the distribution mismatch problem.","Our code is available at https://github.com/Cheeun/ODM."],"url":"http://arxiv.org/abs/2307.13337v1"}
{"created":"2023-07-25 08:45:41","title":"Feature Importance Measurement based on Decision Tree Sampling","abstract":"Random forest is effective for prediction tasks but the randomness of tree generation hinders interpretability in feature importance analysis. To address this, we proposed DT-Sampler, a SAT-based method for measuring feature importance in tree-based model. Our method has fewer parameters than random forest and provides higher interpretability and stability for the analysis in real-world problems. An implementation of DT-Sampler is available at https://github.com/tsudalab/DT-sampler.","sentences":["Random forest is effective for prediction tasks but the randomness of tree generation hinders interpretability in feature importance analysis.","To address this, we proposed DT-Sampler, a SAT-based method for measuring feature importance in tree-based model.","Our method has fewer parameters than random forest and provides higher interpretability and stability for the analysis in real-world problems.","An implementation of DT-Sampler is available at https://github.com/tsudalab/DT-sampler."],"url":"http://arxiv.org/abs/2307.13333v1"}
{"created":"2023-07-25 08:44:58","title":"The Optimal Approximation Factors in Misspecified Off-Policy Value Function Estimation","abstract":"Theoretical guarantees in reinforcement learning (RL) are known to suffer multiplicative blow-up factors with respect to the misspecification error of function approximation. Yet, the nature of such \\emph{approximation factors} -- especially their optimal form in a given learning problem -- is poorly understood. In this paper we study this question in linear off-policy value function estimation, where many open questions remain. We study the approximation factor in a broad spectrum of settings, such as with the weighted $L_2$-norm (where the weighting is the offline state distribution), the $L_\\infty$ norm, the presence vs. absence of state aliasing, and full vs. partial coverage of the state space. We establish the optimal asymptotic approximation factors (up to constants) for all of these settings. In particular, our bounds identify two instance-dependent factors for the $L_2(\\mu)$ norm and only one for the $L_\\infty$ norm, which are shown to dictate the hardness of off-policy evaluation under misspecification.","sentences":["Theoretical guarantees in reinforcement learning (RL) are known to suffer multiplicative blow-up factors with respect to the misspecification error of function approximation.","Yet, the nature of such \\emph{approximation factors} -- especially their optimal form in a given learning problem -- is poorly understood.","In this paper we study this question in linear off-policy value function estimation, where many open questions remain.","We study the approximation factor in a broad spectrum of settings, such as with the weighted $L_2$-norm (where the weighting is the offline state distribution), the $L_\\infty$ norm, the presence vs. absence of state aliasing, and full vs. partial coverage of the state space.","We establish the optimal asymptotic approximation factors (up to constants) for all of these settings.","In particular, our bounds identify two instance-dependent factors for the $L_2(\\mu)$ norm and only one for the $L_\\infty$ norm, which are shown to dictate the hardness of off-policy evaluation under misspecification."],"url":"http://arxiv.org/abs/2307.13332v1"}
{"created":"2023-07-25 08:32:36","title":"Learning Autonomous Ultrasound via Latent Task Representation and Robotic Skills Adaptation","abstract":"As medical ultrasound is becoming a prevailing examination approach nowadays, robotic ultrasound systems can facilitate the scanning process and prevent professional sonographers from repetitive and tedious work. Despite the recent progress, it is still a challenge to enable robots to autonomously accomplish the ultrasound examination, which is largely due to the lack of a proper task representation method, and also an adaptation approach to generalize learned skills across different patients. To solve these problems, we propose the latent task representation and the robotic skills adaptation for autonomous ultrasound in this paper. During the offline stage, the multimodal ultrasound skills are merged and encapsulated into a low-dimensional probability model through a fully self-supervised framework, which takes clinically demonstrated ultrasound images, probe orientations, and contact forces into account. During the online stage, the probability model will select and evaluate the optimal prediction. For unstable singularities, the adaptive optimizer fine-tunes them to near and stable predictions in high-confidence regions. Experimental results show that the proposed approach can generate complex ultrasound strategies for diverse populations and achieve significantly better quantitative results than our previous method.","sentences":["As medical ultrasound is becoming a prevailing examination approach nowadays, robotic ultrasound systems can facilitate the scanning process and prevent professional sonographers from repetitive and tedious work.","Despite the recent progress, it is still a challenge to enable robots to autonomously accomplish the ultrasound examination, which is largely due to the lack of a proper task representation method, and also an adaptation approach to generalize learned skills across different patients.","To solve these problems, we propose the latent task representation and the robotic skills adaptation for autonomous ultrasound in this paper.","During the offline stage, the multimodal ultrasound skills are merged and encapsulated into a low-dimensional probability model through a fully self-supervised framework, which takes clinically demonstrated ultrasound images, probe orientations, and contact forces into account.","During the online stage, the probability model will select and evaluate the optimal prediction.","For unstable singularities, the adaptive optimizer fine-tunes them to near and stable predictions in high-confidence regions.","Experimental results show that the proposed approach can generate complex ultrasound strategies for diverse populations and achieve significantly better quantitative results than our previous method."],"url":"http://arxiv.org/abs/2307.13323v1"}
{"created":"2023-07-25 08:32:03","title":"The Method of Types for the AWGN Channel","abstract":"For the discrete-time AWGN channel with a power constraint, we give an alternative derivation of Shannon's sphere-packing upper bound on the optimal block error exponent and prove for the first time an analogous lower bound on the optimal correct-decoding exponent. The derivations use the method of types with finite alphabets of sizes depending on the block length n and with the number of types sub-exponential in n.","sentences":["For the discrete-time AWGN channel with a power constraint, we give an alternative derivation of Shannon's sphere-packing upper bound on the optimal block error exponent and prove for the first time an analogous lower bound on the optimal correct-decoding exponent.","The derivations use the method of types with finite alphabets of sizes depending on the block length n and with the number of types sub-exponential in n."],"url":"http://arxiv.org/abs/2307.13322v1"}
{"created":"2023-07-25 08:26:05","title":"Affine Disjunctive Invariant Generation with Farkas' Lemma","abstract":"Invariant generation is the classical problem that aims at automated generation of assertions that over-approximates the set of reachable program states in a program. We consider the problem of generating affine invariants over affine while loops (i.e., loops with affine loop guards, conditional branches and assignment statements), and explore the automated generation of disjunctive affine invariants. Disjunctive invariants are an important class of invariants that capture disjunctive features in programs such as multiple phases, transitions between different modes, etc., and are typically more precise than conjunctive invariants over programs with these features. To generate tight affine invariants, existing constraint-solving approaches have investigated the application of Farkas' Lemma to conjunctive affine invariant generation, but none of them considers disjunctive affine invariants.","sentences":["Invariant generation is the classical problem that aims at automated generation of assertions that over-approximates the set of reachable program states in a program.","We consider the problem of generating affine invariants over affine while loops (i.e., loops with affine loop guards, conditional branches and assignment statements), and explore the automated generation of disjunctive affine invariants.","Disjunctive invariants are an important class of invariants that capture disjunctive features in programs such as multiple phases, transitions between different modes, etc., and are typically more precise than conjunctive invariants over programs with these features.","To generate tight affine invariants, existing constraint-solving approaches have investigated the application of Farkas' Lemma to conjunctive affine invariant generation, but none of them considers disjunctive affine invariants."],"url":"http://arxiv.org/abs/2307.13318v1"}
{"created":"2023-07-25 08:23:10","title":"Unmasking Anomalies in Road-Scene Segmentation","abstract":"Anomaly segmentation is a critical task for driving applications, and it is approached traditionally as a per-pixel classification problem. However, reasoning individually about each pixel without considering their contextual semantics results in high uncertainty around the objects' boundaries and numerous false positives. We propose a paradigm change by shifting from a per-pixel classification to a mask classification. Our mask-based method, Mask2Anomaly, demonstrates the feasibility of integrating an anomaly detection method in a mask-classification architecture. Mask2Anomaly includes several technical novelties that are designed to improve the detection of anomalies in masks: i) a global masked attention module to focus individually on the foreground and background regions; ii) a mask contrastive learning that maximizes the margin between an anomaly and known classes; and iii) a mask refinement solution to reduce false positives. Mask2Anomaly achieves new state-of-the-art results across a range of benchmarks, both in the per-pixel and component-level evaluations. In particular, Mask2Anomaly reduces the average false positives rate by 60% wrt the previous state-of-the-art. Github page: https://github.com/shyam671/Mask2Anomaly-Unmasking-Anomalies-in-Road-Scene-Segmentation.","sentences":["Anomaly segmentation is a critical task for driving applications, and it is approached traditionally as a per-pixel classification problem.","However, reasoning individually about each pixel without considering their contextual semantics results in high uncertainty around the objects' boundaries and numerous false positives.","We propose a paradigm change by shifting from a per-pixel classification to a mask classification.","Our mask-based method, Mask2Anomaly, demonstrates the feasibility of integrating an anomaly detection method in a mask-classification architecture.","Mask2Anomaly includes several technical novelties that are designed to improve the detection of anomalies in masks: i) a global masked attention module to focus individually on the foreground and background regions; ii) a mask contrastive learning that maximizes the margin between an anomaly and known classes; and iii) a mask refinement solution to reduce false positives.","Mask2Anomaly achieves new state-of-the-art results across a range of benchmarks, both in the per-pixel and component-level evaluations.","In particular, Mask2Anomaly reduces the average false positives rate by 60% wrt","the previous state-of-the-art.","Github page: https://github.com/shyam671/Mask2Anomaly-Unmasking-Anomalies-in-Road-Scene-Segmentation."],"url":"http://arxiv.org/abs/2307.13316v1"}
{"created":"2023-07-25 08:15:55","title":"Mitigating Cross-client GANs-based Attack in Federated Learning","abstract":"Machine learning makes multimedia data (e.g., images) more attractive, however, multimedia data is usually distributed and privacy sensitive. Multiple distributed multimedia clients can resort to federated learning (FL) to jointly learn a global shared model without requiring to share their private samples with any third-party entities. In this paper, we show that FL suffers from the cross-client generative adversarial networks (GANs)-based (C-GANs) attack, in which a malicious client (i.e., adversary) can reconstruct samples with the same distribution as the training samples from other clients (i.e., victims). Since a benign client's data can be leaked to the adversary, this attack brings the risk of local data leakage for clients in many security-critical FL applications. Thus, we propose Fed-EDKD (i.e., Federated Ensemble Data-free Knowledge Distillation) technique to improve the current popular FL schemes to resist C-GANs attack. In Fed-EDKD, each client submits a local model to the server for obtaining an ensemble global model. Then, to avoid model expansion, Fed-EDKD adopts data-free knowledge distillation techniques to transfer knowledge from the ensemble global model to a compressed model. By this way, Fed-EDKD reduces the adversary's control capability over the global model, so Fed-EDKD can effectively mitigate C-GANs attack. Finally, the experimental results demonstrate that Fed-EDKD significantly mitigates C-GANs attack while only incurring a slight accuracy degradation of FL.","sentences":["Machine learning makes multimedia data (e.g., images) more attractive, however, multimedia data is usually distributed and privacy sensitive.","Multiple distributed multimedia clients can resort to federated learning (FL) to jointly learn a global shared model without requiring to share their private samples with any third-party entities.","In this paper, we show that FL suffers from the cross-client generative adversarial networks (GANs)-based (C-GANs) attack, in which a malicious client (i.e., adversary) can reconstruct samples with the same distribution as the training samples from other clients (i.e., victims).","Since a benign client's data can be leaked to the adversary, this attack brings the risk of local data leakage for clients in many security-critical FL applications.","Thus, we propose Fed-EDKD (i.e., Federated Ensemble Data-free Knowledge Distillation) technique to improve the current popular FL schemes to resist C-GANs attack.","In Fed-EDKD, each client submits a local model to the server for obtaining an ensemble global model.","Then, to avoid model expansion, Fed-EDKD adopts data-free knowledge distillation techniques to transfer knowledge from the ensemble global model to a compressed model.","By this way, Fed-EDKD reduces the adversary's control capability over the global model, so Fed-EDKD can effectively mitigate C-GANs attack.","Finally, the experimental results demonstrate that Fed-EDKD significantly mitigates C-GANs attack while only incurring a slight accuracy degradation of FL."],"url":"http://arxiv.org/abs/2307.13314v1"}
{"created":"2023-07-25 08:00:40","title":"CT-Net: Arbitrary-Shaped Text Detection via Contour Transformer","abstract":"Contour based scene text detection methods have rapidly developed recently, but still suffer from inaccurate frontend contour initialization, multi-stage error accumulation, or deficient local information aggregation. To tackle these limitations, we propose a novel arbitrary-shaped scene text detection framework named CT-Net by progressive contour regression with contour transformers. Specifically, we first employ a contour initialization module that generates coarse text contours without any post-processing. Then, we adopt contour refinement modules to adaptively refine text contours in an iterative manner, which are beneficial for context information capturing and progressive global contour deformation. Besides, we propose an adaptive training strategy to enable the contour transformers to learn more potential deformation paths, and introduce a re-score mechanism that can effectively suppress false positives. Extensive experiments are conducted on four challenging datasets, which demonstrate the accuracy and efficiency of our CT-Net over state-of-the-art methods. Particularly, CT-Net achieves F-measure of 86.1 at 11.2 frames per second (FPS) and F-measure of 87.8 at 10.1 FPS for CTW1500 and Total-Text datasets, respectively.","sentences":["Contour based scene text detection methods have rapidly developed recently, but still suffer from inaccurate frontend contour initialization, multi-stage error accumulation, or deficient local information aggregation.","To tackle these limitations, we propose a novel arbitrary-shaped scene text detection framework named CT-Net by progressive contour regression with contour transformers.","Specifically, we first employ a contour initialization module that generates coarse text contours without any post-processing.","Then, we adopt contour refinement modules to adaptively refine text contours in an iterative manner, which are beneficial for context information capturing and progressive global contour deformation.","Besides, we propose an adaptive training strategy to enable the contour transformers to learn more potential deformation paths, and introduce a re-score mechanism that can effectively suppress false positives.","Extensive experiments are conducted on four challenging datasets, which demonstrate the accuracy and efficiency of our CT-Net over state-of-the-art methods.","Particularly, CT-Net achieves F-measure of 86.1 at 11.2 frames per second (FPS) and F-measure of 87.8 at 10.1 FPS for CTW1500 and Total-Text datasets, respectively."],"url":"http://arxiv.org/abs/2307.13310v1"}
{"created":"2023-07-25 07:44:06","title":"QuIP: 2-Bit Quantization of Large Language Models With Guarantees","abstract":"This work studies post-training parameter quantization in large language models (LLMs). We introduce quantization with incoherence processing (QuIP), a new method based on the insight that quantization benefits from incoherent weight and Hessian matrices, i.e., from the weights and the directions in which it is important to round them accurately being unaligned with the coordinate axes. QuIP consists of two steps: (1) an adaptive rounding procedure minimizing a quadratic proxy objective; (2) efficient pre- and post-processing that ensures weight and Hessian incoherence via multiplication by random orthogonal matrices. We complement QuIP with the first theoretical analysis for an LLM-scale quantization algorithm, and show that our theory also applies to an existing method, OPTQ. Empirically, we find that our incoherence preprocessing improves several existing quantization algorithms and yields the first LLM quantization methods that produce viable results using only two bits per weight. Our code can be found at https://github.com/jerry-chee/QuIP .","sentences":["This work studies post-training parameter quantization in large language models (LLMs).","We introduce quantization with incoherence processing (QuIP), a new method based on the insight that quantization benefits from incoherent weight and Hessian matrices, i.e., from the weights and the directions in which it is important to round them accurately being unaligned with the coordinate axes.","QuIP consists of two steps: (1) an adaptive rounding procedure minimizing a quadratic proxy objective; (2) efficient pre- and post-processing that ensures weight and Hessian incoherence via multiplication by random orthogonal matrices.","We complement QuIP with the first theoretical analysis for an LLM-scale quantization algorithm, and show that our theory also applies to an existing method, OPTQ.","Empirically, we find that our incoherence preprocessing improves several existing quantization algorithms and yields the first LLM quantization methods that produce viable results using only two bits per weight.","Our code can be found at https://github.com/jerry-chee/QuIP ."],"url":"http://arxiv.org/abs/2307.13304v1"}
{"created":"2023-07-25 07:30:28","title":"Mini-PointNetPlus: a local feature descriptor in deep learning model for 3d environment perception","abstract":"Common deep learning models for 3D environment perception often use pillarization/voxelization methods to convert point cloud data into pillars/voxels and then process it with a 2D/3D convolutional neural network (CNN). The pioneer work PointNet has been widely applied as a local feature descriptor, a fundamental component in deep learning models for 3D perception, to extract features of a point cloud. This is achieved by using a symmetric max-pooling operator which provides unique pillar/voxel features. However, by ignoring most of the points, the max-pooling operator causes an information loss, which reduces the model performance. To address this issue, we propose a novel local feature descriptor, mini-PointNetPlus, as an alternative for plug-and-play to PointNet. Our basic idea is to separately project the data points to the individual features considered, each leading to a permutation invariant. Thus, the proposed descriptor transforms an unordered point cloud to a stable order. The vanilla PointNet is proved to be a special case of our mini-PointNetPlus. Due to fully utilizing the features by the proposed descriptor, we demonstrate in experiment a considerable performance improvement for 3D perception.","sentences":["Common deep learning models for 3D environment perception often use pillarization/voxelization methods to convert point cloud data into pillars/voxels and then process it with a 2D/3D convolutional neural network (CNN).","The pioneer work PointNet has been widely applied as a local feature descriptor, a fundamental component in deep learning models for 3D perception, to extract features of a point cloud.","This is achieved by using a symmetric max-pooling operator which provides unique pillar/voxel features.","However, by ignoring most of the points, the max-pooling operator causes an information loss, which reduces the model performance.","To address this issue, we propose a novel local feature descriptor, mini-PointNetPlus, as an alternative for plug-and-play to PointNet.","Our basic idea is to separately project the data points to the individual features considered, each leading to a permutation invariant.","Thus, the proposed descriptor transforms an unordered point cloud to a stable order.","The vanilla PointNet is proved to be a special case of our mini-PointNetPlus.","Due to fully utilizing the features by the proposed descriptor, we demonstrate in experiment a considerable performance improvement for 3D perception."],"url":"http://arxiv.org/abs/2307.13300v1"}
{"created":"2023-07-25 07:27:32","title":"An Intent Taxonomy of Legal Case Retrieval","abstract":"Legal case retrieval is a special Information Retrieval~(IR) task focusing on legal case documents. Depending on the downstream tasks of the retrieved case documents, users' information needs in legal case retrieval could be significantly different from those in Web search and traditional ad-hoc retrieval tasks. While there are several studies that retrieve legal cases based on text similarity, the underlying search intents of legal retrieval users, as shown in this paper, are more complicated than that yet mostly unexplored. To this end, we present a novel hierarchical intent taxonomy of legal case retrieval. It consists of five intent types categorized by three criteria, i.e., search for Particular Case(s), Characterization, Penalty, Procedure, and Interest. The taxonomy was constructed transparently and evaluated extensively through interviews, editorial user studies, and query log analysis. Through a laboratory user study, we reveal significant differences in user behavior and satisfaction under different search intents in legal case retrieval. Furthermore, we apply the proposed taxonomy to various downstream legal retrieval tasks, e.g., result ranking and satisfaction prediction, and demonstrate its effectiveness. Our work provides important insights into the understanding of user intents in legal case retrieval and potentially leads to better retrieval techniques in the legal domain, such as intent-aware ranking strategies and evaluation methodologies.","sentences":["Legal case retrieval is a special Information Retrieval~(IR) task focusing on legal case documents.","Depending on the downstream tasks of the retrieved case documents, users' information needs in legal case retrieval could be significantly different from those in Web search and traditional ad-hoc retrieval tasks.","While there are several studies that retrieve legal cases based on text similarity, the underlying search intents of legal retrieval users, as shown in this paper, are more complicated than that yet mostly unexplored.","To this end, we present a novel hierarchical intent taxonomy of legal case retrieval.","It consists of five intent types categorized by three criteria, i.e., search for Particular Case(s), Characterization, Penalty, Procedure, and Interest.","The taxonomy was constructed transparently and evaluated extensively through interviews, editorial user studies, and query log analysis.","Through a laboratory user study, we reveal significant differences in user behavior and satisfaction under different search intents in legal case retrieval.","Furthermore, we apply the proposed taxonomy to various downstream legal retrieval tasks, e.g., result ranking and satisfaction prediction, and demonstrate its effectiveness.","Our work provides important insights into the understanding of user intents in legal case retrieval and potentially leads to better retrieval techniques in the legal domain, such as intent-aware ranking strategies and evaluation methodologies."],"url":"http://arxiv.org/abs/2307.13298v1"}
{"created":"2023-07-25 07:21:27","title":"CQNV: A combination of coarsely quantized bitstream and neural vocoder for low rate speech coding","abstract":"Recently, speech codecs based on neural networks have proven to perform better than traditional methods. However, redundancy in traditional parameter quantization is visible within the codec architecture of combining the traditional codec with the neural vocoder. In this paper, we propose a novel framework named CQNV, which combines the coarsely quantized parameters of a traditional parametric codec to reduce the bitrate with a neural vocoder to improve the quality of the decoded speech. Furthermore, we introduce a parameters processing module into the neural vocoder to enhance the application of the bitstream of traditional speech coding parameters to the neural vocoder, further improving the reconstructed speech's quality. In the experiments, both subjective and objective evaluations demonstrate the effectiveness of the proposed CQNV framework. Specifically, our proposed method can achieve higher quality reconstructed speech at 1.1 kbps than Lyra and Encodec at 3 kbps.","sentences":["Recently, speech codecs based on neural networks have proven to perform better than traditional methods.","However, redundancy in traditional parameter quantization is visible within the codec architecture of combining the traditional codec with the neural vocoder.","In this paper, we propose a novel framework named CQNV, which combines the coarsely quantized parameters of a traditional parametric codec to reduce the bitrate with a neural vocoder to improve the quality of the decoded speech.","Furthermore, we introduce a parameters processing module into the neural vocoder to enhance the application of the bitstream of traditional speech coding parameters to the neural vocoder, further improving the reconstructed speech's quality.","In the experiments, both subjective and objective evaluations demonstrate the effectiveness of the proposed CQNV framework.","Specifically, our proposed method can achieve higher quality reconstructed speech at 1.1 kbps than Lyra and Encodec at 3 kbps."],"url":"http://arxiv.org/abs/2307.13295v1"}
{"created":"2023-07-25 07:20:21","title":"Imperceptible Physical Attack against Face Recognition Systems via LED Illumination Modulation","abstract":"Although face recognition starts to play an important role in our daily life, we need to pay attention that data-driven face recognition vision systems are vulnerable to adversarial attacks. However, the current two categories of adversarial attacks, namely digital attacks and physical attacks both have drawbacks, with the former ones impractical and the latter one conspicuous, high-computational and inexecutable. To address the issues, we propose a practical, executable, inconspicuous and low computational adversarial attack based on LED illumination modulation. To fool the systems, the proposed attack generates imperceptible luminance changes to human eyes through fast intensity modulation of scene LED illumination and uses the rolling shutter effect of CMOS image sensors in face recognition systems to implant luminance information perturbation to the captured face images. In summary,we present a denial-of-service (DoS) attack for face detection and a dodging attack for face verification. We also evaluate their effectiveness against well-known face detection models, Dlib, MTCNN and RetinaFace , and face verification models, Dlib, FaceNet,and ArcFace.The extensive experiments show that the success rates of DoS attacks against face detection models reach 97.67%, 100%, and 100%, respectively, and the success rates of dodging attacks against all face verification models reach 100%.","sentences":["Although face recognition starts to play an important role in our daily life, we need to pay attention that data-driven face recognition vision systems are vulnerable to adversarial attacks.","However, the current two categories of adversarial attacks, namely digital attacks and physical attacks both have drawbacks, with the former ones impractical and the latter one conspicuous, high-computational and inexecutable.","To address the issues, we propose a practical, executable, inconspicuous and low computational adversarial attack based on LED illumination modulation.","To fool the systems, the proposed attack generates imperceptible luminance changes to human eyes through fast intensity modulation of scene LED illumination and uses the rolling shutter effect of CMOS image sensors in face recognition systems to implant luminance information perturbation to the captured face images.","In summary,we present a denial-of-service (DoS) attack for face detection and a dodging attack for face verification.","We also evaluate their effectiveness against well-known face detection models, Dlib, MTCNN and RetinaFace , and face verification models, Dlib, FaceNet,and ArcFace.","The extensive experiments show that the success rates of DoS attacks against face detection models reach 97.67%, 100%, and 100%, respectively, and the success rates of dodging attacks against all face verification models reach 100%."],"url":"http://arxiv.org/abs/2307.13294v1"}
{"created":"2023-07-25 07:17:03","title":"Nonlinear Probabilistic Constellation Shaping with Sequence Selection","abstract":"Probabilistic shaping is a pragmatic approach to improve the performance of coherent optical fiber communication systems. In the nonlinear regime, the advantages offered by probabilistic shaping might increase thanks to the opportunity to obtain an additional nonlinear shaping gain. Unfortunately, the optimization of conventional shaping techniques, such as probabilistic amplitude shaping (PAS), yields a relevant nonlinear shaping gain only in scenarios of limited practical interest. In this manuscript we use sequence selection to investigate the potential, opportunities, and challenges offered by nonlinear probabilistic shaping. First, we show that ideal sequence selection is able to provide up to 0.13 bit/s/Hz gain with respect to PAS with an optimized blocklength. However, this additional gain is obtained only if the selection metric accounts for the signs of the symbols: they must be known to compute the selection metric, but there is no need to shape them. Furthermore, we show that the selection depends in a non-critical way on the symbol rate and link length: the sequences selected for a certain scenario still provide a relevant gain if these are modified. Then, we analyze and compare several practical implementations of sequence selection by taking into account interaction with forward error correction (FEC) and complexity. Overall, the single block and the multi block FEC-independent bit scrambling are the best options, with a gain up to 0.08 bit/s/Hz. The main challenge and limitation to their practical implementation remains the evaluation of the metric, whose complexity is currently too high. Finally, we show that the nonlinear shaping gain provided by sequence selection persists when carrier phase recovery is included.","sentences":["Probabilistic shaping is a pragmatic approach to improve the performance of coherent optical fiber communication systems.","In the nonlinear regime, the advantages offered by probabilistic shaping might increase thanks to the opportunity to obtain an additional nonlinear shaping gain.","Unfortunately, the optimization of conventional shaping techniques, such as probabilistic amplitude shaping (PAS), yields a relevant nonlinear shaping gain only in scenarios of limited practical interest.","In this manuscript we use sequence selection to investigate the potential, opportunities, and challenges offered by nonlinear probabilistic shaping.","First, we show that ideal sequence selection is able to provide up to 0.13 bit/s/Hz gain with respect to PAS with an optimized blocklength.","However, this additional gain is obtained only if the selection metric accounts for the signs of the symbols: they must be known to compute the selection metric, but there is no need to shape them.","Furthermore, we show that the selection depends in a non-critical way on the symbol rate and link length: the sequences selected for a certain scenario still provide a relevant gain if these are modified.","Then, we analyze and compare several practical implementations of sequence selection by taking into account interaction with forward error correction (FEC) and complexity.","Overall, the single block and the multi block FEC-independent bit scrambling are the best options, with a gain up to 0.08 bit/s/Hz.","The main challenge and limitation to their practical implementation remains the evaluation of the metric, whose complexity is currently too high.","Finally, we show that the nonlinear shaping gain provided by sequence selection persists when carrier phase recovery is included."],"url":"http://arxiv.org/abs/2307.13292v1"}
{"created":"2023-07-25 06:50:23","title":"A Generic Framework for Hidden Markov Models on Biomedical Data","abstract":"Background: Biomedical data are usually collections of longitudinal data assessed at certain points in time. Clinical observations assess the presences and severity of symptoms, which are the basis for description and modeling of disease progression. Deciphering potential underlying unknowns solely from the distinct observation would substantially improve the understanding of pathological cascades. Hidden Markov Models (HMMs) have been successfully applied to the processing of possibly noisy continuous signals. The aim was to improve the application HMMs to multivariate time-series of categorically distributed data. Here, we used HHMs to study prediction of the loss of free walking ability as one major clinical deterioration in the most common autosomal dominantly inherited ataxia disorder worldwide. We used HHMs to investigate the prediction of loss of the ability to walk freely, representing a major clinical deterioration in the most common autosomal-dominant inherited ataxia disorder worldwide.   Results: We present a prediction pipeline which processes data paired with a configuration file, enabling to construct, validate and query a fully parameterized HMM-based model. In particular, we provide a theoretical and practical framework for multivariate time-series inference based on HMMs that includes constructing multiple HMMs, each to predict a particular observable variable. Our analysis is done on random data, but also on biomedical data based on Spinocerebellar ataxia type 3 disease.   Conclusions: HHMs are a promising approach to study biomedical data that naturally are represented as multivariate time-series. Our implementation of a HHMs framework is publicly available and can easily be adapted for further applications.","sentences":["Background: Biomedical data are usually collections of longitudinal data assessed at certain points in time.","Clinical observations assess the presences and severity of symptoms, which are the basis for description and modeling of disease progression.","Deciphering potential underlying unknowns solely from the distinct observation would substantially improve the understanding of pathological cascades.","Hidden Markov Models (HMMs) have been successfully applied to the processing of possibly noisy continuous signals.","The aim was to improve the application HMMs to multivariate time-series of categorically distributed data.","Here, we used HHMs to study prediction of the loss of free walking ability as one major clinical deterioration in the most common autosomal dominantly inherited ataxia disorder worldwide.","We used HHMs to investigate the prediction of loss of the ability to walk freely, representing a major clinical deterioration in the most common autosomal-dominant inherited ataxia disorder worldwide.   ","Results: We present a prediction pipeline which processes data paired with a configuration file, enabling to construct, validate and query a fully parameterized HMM-based model.","In particular, we provide a theoretical and practical framework for multivariate time-series inference based on HMMs that includes constructing multiple HMMs, each to predict a particular observable variable.","Our analysis is done on random data, but also on biomedical data based on Spinocerebellar ataxia type 3 disease.   ","Conclusions: HHMs are a promising approach to study biomedical data that naturally are represented as multivariate time-series.","Our implementation of a HHMs framework is publicly available and can easily be adapted for further applications."],"url":"http://arxiv.org/abs/2307.13288v1"}
{"created":"2023-07-25 06:48:14","title":"NetClone: Fast, Scalable, and Dynamic Request Cloning for Microsecond-Scale RPCs","abstract":"Spawning duplicate requests, called cloning, is a powerful technique to reduce tail latency by masking service-time variability. However, traditional client-based cloning is static and harmful to performance under high load, while a recent coordinator-based approach is slow and not scalable. Both approaches are insufficient to serve modern microsecond-scale Remote Procedure Calls (RPCs). To this end, we present NetClone, a request cloning system that performs cloning decisions dynamically within nanoseconds at scale. Rather than the client or the coordinator, NetClone performs request cloning in the network switch by leveraging the capability of programmable switch ASICs. Specifically, NetClone replicates requests based on server states and blocks redundant responses using request fingerprints in the switch data plane. To realize the idea while satisfying the strict hardware constraints, we address several technical challenges when designing a custom switch data plane. NetClone can be integrated with emerging in-network request schedulers like RackSched. We implement a NetClone prototype with an Intel Tofino switch and a cluster of commodity servers. Our experimental results show that NetClone can improve the tail latency of microsecond-scale RPCs for synthetic and real-world application workloads and is robust to various system conditions.","sentences":["Spawning duplicate requests, called cloning, is a powerful technique to reduce tail latency by masking service-time variability.","However, traditional client-based cloning is static and harmful to performance under high load, while a recent coordinator-based approach is slow and not scalable.","Both approaches are insufficient to serve modern microsecond-scale Remote Procedure Calls (RPCs).","To this end, we present NetClone, a request cloning system that performs cloning decisions dynamically within nanoseconds at scale.","Rather than the client or the coordinator, NetClone performs request cloning in the network switch by leveraging the capability of programmable switch ASICs.","Specifically, NetClone replicates requests based on server states and blocks redundant responses using request fingerprints in the switch data plane.","To realize the idea while satisfying the strict hardware constraints, we address several technical challenges when designing a custom switch data plane.","NetClone can be integrated with emerging in-network request schedulers like RackSched.","We implement a NetClone prototype with an Intel Tofino switch and a cluster of commodity servers.","Our experimental results show that NetClone can improve the tail latency of microsecond-scale RPCs for synthetic and real-world application workloads and is robust to various system conditions."],"url":"http://arxiv.org/abs/2307.13285v1"}
{"created":"2023-07-25 06:37:50","title":"High-Resolution Volumetric Reconstruction for Clothed Humans","abstract":"We present a novel method for reconstructing clothed humans from a sparse set of, e.g., 1 to 6 RGB images. Despite impressive results from recent works employing deep implicit representation, we revisit the volumetric approach and demonstrate that better performance can be achieved with proper system design. The volumetric representation offers significant advantages in leveraging 3D spatial context through 3D convolutions, and the notorious quantization error is largely negligible with a reasonably large yet affordable volume resolution, e.g., 512. To handle memory and computation costs, we propose a sophisticated coarse-to-fine strategy with voxel culling and subspace sparse convolution. Our method starts with a discretized visual hull to compute a coarse shape and then focuses on a narrow band nearby the coarse shape for refinement. Once the shape is reconstructed, we adopt an image-based rendering approach, which computes the colors of surface points by blending input images with learned weights. Extensive experimental results show that our method significantly reduces the mean point-to-surface (P2S) precision of state-of-the-art methods by more than 50% to achieve approximately 2mm accuracy with a 512 volume resolution. Additionally, images rendered from our textured model achieve a higher peak signal-to-noise ratio (PSNR) compared to state-of-the-art methods.","sentences":["We present a novel method for reconstructing clothed humans from a sparse set of, e.g., 1 to 6 RGB images.","Despite impressive results from recent works employing deep implicit representation, we revisit the volumetric approach and demonstrate that better performance can be achieved with proper system design.","The volumetric representation offers significant advantages in leveraging 3D spatial context through 3D convolutions, and the notorious quantization error is largely negligible with a reasonably large yet affordable volume resolution, e.g., 512.","To handle memory and computation costs, we propose a sophisticated coarse-to-fine strategy with voxel culling and subspace sparse convolution.","Our method starts with a discretized visual hull to compute a coarse shape and then focuses on a narrow band nearby the coarse shape for refinement.","Once the shape is reconstructed, we adopt an image-based rendering approach, which computes the colors of surface points by blending input images with learned weights.","Extensive experimental results show that our method significantly reduces the mean point-to-surface (P2S) precision of state-of-the-art methods by more than 50% to achieve approximately 2mm accuracy with a 512 volume resolution.","Additionally, images rendered from our textured model achieve a higher peak signal-to-noise ratio (PSNR) compared to state-of-the-art methods."],"url":"http://arxiv.org/abs/2307.13282v1"}
{"created":"2023-07-25 06:13:01","title":"Curvature-based Transformer for Molecular Property Prediction","abstract":"The prediction of molecular properties is one of the most important and challenging tasks in the field of artificial intelligence-based drug design. Among the current mainstream methods, the most commonly used feature representation for training DNN models is based on SMILES and molecular graphs, although these methods are concise and effective, they also limit the ability to capture spatial information. In this work, we propose Curvature-based Transformer to improve the ability of Graph Transformer neural network models to extract structural information on molecular graph data by introducing Discretization of Ricci Curvature. To embed the curvature in the model, we add the curvature information of the graph as positional Encoding to the node features during the attention-score calculation. This method can introduce curvature information from graph data without changing the original network architecture, and it has the potential to be extended to other models. We performed experiments on chemical molecular datasets including PCQM4M-LST, MoleculeNet and compared with models such as Uni-Mol, Graphormer, and the results show that this method can achieve the state-of-the-art results. It is proved that the discretized Ricci curvature also reflects the structural and functional relationship while describing the local geometry of the graph molecular data.","sentences":["The prediction of molecular properties is one of the most important and challenging tasks in the field of artificial intelligence-based drug design.","Among the current mainstream methods, the most commonly used feature representation for training DNN models is based on SMILES and molecular graphs, although these methods are concise and effective, they also limit the ability to capture spatial information.","In this work, we propose Curvature-based Transformer to improve the ability of Graph Transformer neural network models to extract structural information on molecular graph data by introducing Discretization of Ricci Curvature.","To embed the curvature in the model, we add the curvature information of the graph as positional Encoding to the node features during the attention-score calculation.","This method can introduce curvature information from graph data without changing the original network architecture, and it has the potential to be extended to other models.","We performed experiments on chemical molecular datasets including PCQM4M-LST, MoleculeNet and compared with models such as Uni-Mol, Graphormer, and the results show that this method can achieve the state-of-the-art results.","It is proved that the discretized Ricci curvature also reflects the structural and functional relationship while describing the local geometry of the graph molecular data."],"url":"http://arxiv.org/abs/2307.13275v1"}
{"created":"2023-07-25 05:55:12","title":"Towards Sim2Real Transfer of Autonomy Algorithms using AutoDRIVE Ecosystem","abstract":"The engineering community currently encounters significant challenges in the development of intelligent transportation algorithms that can be transferred from simulation to reality with minimal effort. This can be achieved by robustifying the algorithms using domain adaptation methods and/or by adopting cutting-edge tools that help support this objective seamlessly. This work presents AutoDRIVE, an openly accessible digital twin ecosystem designed to facilitate synergistic development, simulation and deployment of cyber-physical solutions pertaining to autonomous driving technology; and focuses on bridging the autonomy-oriented simulation-to-reality (sim2real) gap using the proposed ecosystem. In this paper, we extensively explore the modeling and simulation aspects of the ecosystem and substantiate its efficacy by demonstrating the successful transition of two candidate autonomy algorithms from simulation to reality to help support our claims: (i) autonomous parking using probabilistic robotics approach; (ii) behavioral cloning using deep imitation learning. The outcomes of these case studies further strengthen the credibility of AutoDRIVE as an invaluable tool for advancing the state-of-the-art in autonomous driving technology.","sentences":["The engineering community currently encounters significant challenges in the development of intelligent transportation algorithms that can be transferred from simulation to reality with minimal effort.","This can be achieved by robustifying the algorithms using domain adaptation methods and/or by adopting cutting-edge tools that help support this objective seamlessly.","This work presents AutoDRIVE, an openly accessible digital twin ecosystem designed to facilitate synergistic development, simulation and deployment of cyber-physical solutions pertaining to autonomous driving technology; and focuses on bridging the autonomy-oriented simulation-to-reality (sim2real) gap using the proposed ecosystem.","In this paper, we extensively explore the modeling and simulation aspects of the ecosystem and substantiate its efficacy by demonstrating the successful transition of two candidate autonomy algorithms from simulation to reality to help support our claims: (i) autonomous parking using probabilistic robotics approach; (ii) behavioral cloning using deep imitation learning.","The outcomes of these case studies further strengthen the credibility of AutoDRIVE as an invaluable tool for advancing the state-of-the-art in autonomous driving technology."],"url":"http://arxiv.org/abs/2307.13272v1"}
{"created":"2023-07-25 05:45:52","title":"Unbiased Weight Maximization","abstract":"A biologically plausible method for training an Artificial Neural Network (ANN) involves treating each unit as a stochastic Reinforcement Learning (RL) agent, thereby considering the network as a team of agents. Consequently, all units can learn via REINFORCE, a local learning rule modulated by a global reward signal, which aligns more closely with biologically observed forms of synaptic plasticity. Nevertheless, this learning method is often slow and scales poorly with network size due to inefficient structural credit assignment, since a single reward signal is broadcast to all units without considering individual contributions. Weight Maximization, a proposed solution, replaces a unit's reward signal with the norm of its outgoing weight, thereby allowing each hidden unit to maximize the norm of the outgoing weight instead of the global reward signal. In this research report, we analyze the theoretical properties of Weight Maximization and propose a variant, Unbiased Weight Maximization. This new approach provides an unbiased learning rule that increases learning speed and improves asymptotic performance. Notably, to our knowledge, this is the first learning rule for a network of Bernoulli-logistic units that is unbiased and scales well with the number of network's units in terms of learning speed.","sentences":["A biologically plausible method for training an Artificial Neural Network (ANN) involves treating each unit as a stochastic Reinforcement Learning (RL) agent, thereby considering the network as a team of agents.","Consequently, all units can learn via REINFORCE, a local learning rule modulated by a global reward signal, which aligns more closely with biologically observed forms of synaptic plasticity.","Nevertheless, this learning method is often slow and scales poorly with network size due to inefficient structural credit assignment, since a single reward signal is broadcast to all units without considering individual contributions.","Weight Maximization, a proposed solution, replaces a unit's reward signal with the norm of its outgoing weight, thereby allowing each hidden unit to maximize the norm of the outgoing weight instead of the global reward signal.","In this research report, we analyze the theoretical properties of Weight Maximization and propose a variant, Unbiased Weight Maximization.","This new approach provides an unbiased learning rule that increases learning speed and improves asymptotic performance.","Notably, to our knowledge, this is the first learning rule for a network of Bernoulli-logistic units that is unbiased and scales well with the number of network's units in terms of learning speed."],"url":"http://arxiv.org/abs/2307.13270v1"}
{"created":"2023-07-25 05:39:21","title":"LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition","abstract":"Low-rank adaptations (LoRA) are often employed to fine-tune large language models (LLMs) for new tasks. This paper investigates LoRA composability for cross-task generalization and introduces LoraHub, a strategic framework devised for the purposive assembly of LoRA modules trained on diverse given tasks, with the objective of achieving adaptable performance on unseen tasks. With just a few examples from a novel task, LoraHub enables the fluid combination of multiple LoRA modules, eradicating the need for human expertise. Notably, the composition requires neither additional model parameters nor gradients. Our empirical results, derived from the Big-Bench Hard (BBH) benchmark, suggest that LoraHub can effectively mimic the performance of in-context learning in few-shot scenarios, excluding the necessity of in-context examples alongside each inference input. A significant contribution of our research is the fostering of a community for LoRA, where users can share their trained LoRA modules, thereby facilitating their application to new tasks. We anticipate this resource will widen access to and spur advancements in general intelligence as well as LLMs in production. Code will be available at https://github.com/sail-sg/lorahub.","sentences":["Low-rank adaptations (LoRA) are often employed to fine-tune large language models (LLMs) for new tasks.","This paper investigates LoRA composability for cross-task generalization and introduces LoraHub, a strategic framework devised for the purposive assembly of LoRA modules trained on diverse given tasks, with the objective of achieving adaptable performance on unseen tasks.","With just a few examples from a novel task, LoraHub enables the fluid combination of multiple LoRA modules, eradicating the need for human expertise.","Notably, the composition requires neither additional model parameters nor gradients.","Our empirical results, derived from the Big-Bench Hard (BBH) benchmark, suggest that LoraHub can effectively mimic the performance of in-context learning in few-shot scenarios, excluding the necessity of in-context examples alongside each inference input.","A significant contribution of our research is the fostering of a community for LoRA, where users can share their trained LoRA modules, thereby facilitating their application to new tasks.","We anticipate this resource will widen access to and spur advancements in general intelligence as well as LLMs in production.","Code will be available at https://github.com/sail-sg/lorahub."],"url":"http://arxiv.org/abs/2307.13269v1"}
{"created":"2023-07-25 05:33:06","title":"Federated Split Learning with Only Positive Labels for resource-constrained IoT environment","abstract":"Distributed collaborative machine learning (DCML) is a promising method in the Internet of Things (IoT) domain for training deep learning models, as data is distributed across multiple devices. A key advantage of this approach is that it improves data privacy by removing the necessity for the centralized aggregation of raw data but also empowers IoT devices with low computational power. Among various techniques in a DCML framework, federated split learning, known as splitfed learning (SFL), is the most suitable for efficient training and testing when devices have limited computational capabilities. Nevertheless, when resource-constrained IoT devices have only positive labeled data, multiclass classification deep learning models in SFL fail to converge or provide suboptimal results. To overcome these challenges, we propose splitfed learning with positive labels (SFPL). SFPL applies a random shuffling function to the smashed data received from clients before supplying it to the server for model training. Additionally, SFPL incorporates the local batch normalization for the client-side model portion during the inference phase. Our results demonstrate that SFPL outperforms SFL: (i) by factors of 51.54 and 32.57 for ResNet-56 and ResNet-32, respectively, with the CIFAR-100 dataset, and (ii) by factors of 9.23 and 8.52 for ResNet-32 and ResNet-8, respectively, with CIFAR-10 dataset. Overall, this investigation underscores the efficacy of the proposed SFPL framework in DCML.","sentences":["Distributed collaborative machine learning (DCML) is a promising method in the Internet of Things (IoT) domain for training deep learning models, as data is distributed across multiple devices.","A key advantage of this approach is that it improves data privacy by removing the necessity for the centralized aggregation of raw data but also empowers IoT devices with low computational power.","Among various techniques in a DCML framework, federated split learning, known as splitfed learning (SFL), is the most suitable for efficient training and testing when devices have limited computational capabilities.","Nevertheless, when resource-constrained IoT devices have only positive labeled data, multiclass classification deep learning models in SFL fail to converge or provide suboptimal results.","To overcome these challenges, we propose splitfed learning with positive labels (SFPL).","SFPL applies a random shuffling function to the smashed data received from clients before supplying it to the server for model training.","Additionally, SFPL incorporates the local batch normalization for the client-side model portion during the inference phase.","Our results demonstrate that SFPL outperforms SFL: (i) by factors of 51.54 and 32.57 for ResNet-56 and ResNet-32, respectively, with the CIFAR-100 dataset, and (ii) by factors of 9.23 and 8.52 for ResNet-32 and ResNet-8, respectively, with CIFAR-10 dataset.","Overall, this investigation underscores the efficacy of the proposed SFPL framework in DCML."],"url":"http://arxiv.org/abs/2307.13266v1"}
{"created":"2023-07-25 05:10:39","title":"Online Maximum Independent Set of Hyperrectangles","abstract":"The maximum independent set problem is a classical NP-hard problem in theoretical computer science. In this work, we study a special case where the family of graphs considered is restricted to intersection graphs of sets of axis-aligned hyperrectangles and the input is provided in an online fashion. We prove bounds on the competitive ratio of an optimal online algorithm under the adaptive offline, adaptive online, and oblivious adversary models, for several classes of hyperrectangles and restrictions on the order of the input.   We are the first to present results on this problem under the oblivious adversary model. We prove bounds on the competitive ratio for unit hypercubes, $\\sigma$-bounded hypercubes, unit-volume hypercubes, arbitrary hypercubes, and arbitrary hyperrectangles, in both arbitrary and non-dominated order. We are also the first to present results under the adaptive offline and adaptive online adversary models with input in non-dominated order, proving bounds on the competitive ratio for the same classes of hyperrectangles; for input in arbitrary order, we present the first results on $\\sigma$-bounded hypercubes, unit-volume hyperrectangles, arbitrary hypercubes, and arbitrary hyperrectangles. For input in dominating order, we show that the performance of the naive greedy algorithm matches the performance of an optimal offline algorithm in all cases. We also give lower bounds on the competitive ratio of a probabilistic greedy algorithm under the oblivious adversary model. We conclude by discussing several promising directions for future work.","sentences":["The maximum independent set problem is a classical NP-hard problem in theoretical computer science.","In this work, we study a special case where the family of graphs considered is restricted to intersection graphs of sets of axis-aligned hyperrectangles and the input is provided in an online fashion.","We prove bounds on the competitive ratio of an optimal online algorithm under the adaptive offline, adaptive online, and oblivious adversary models, for several classes of hyperrectangles and restrictions on the order of the input.   ","We are the first to present results on this problem under the oblivious adversary model.","We prove bounds on the competitive ratio for unit hypercubes, $\\sigma$-bounded hypercubes, unit-volume hypercubes, arbitrary hypercubes, and arbitrary hyperrectangles, in both arbitrary and non-dominated order.","We are also the first to present results under the adaptive offline and adaptive online adversary models with input in non-dominated order, proving bounds on the competitive ratio for the same classes of hyperrectangles; for input in arbitrary order, we present the first results on $\\sigma$-bounded hypercubes, unit-volume hyperrectangles, arbitrary hypercubes, and arbitrary hyperrectangles.","For input in dominating order, we show that the performance of the naive greedy algorithm matches the performance of an optimal offline algorithm in all cases.","We also give lower bounds on the competitive ratio of a probabilistic greedy algorithm under the oblivious adversary model.","We conclude by discussing several promising directions for future work."],"url":"http://arxiv.org/abs/2307.13261v1"}
{"created":"2023-07-25 05:05:07","title":"GaitFormer: Revisiting Intrinsic Periodicity for Gait Recognition","abstract":"Gait recognition aims to distinguish different walking patterns by analyzing video-level human silhouettes, rather than relying on appearance information. Previous research on gait recognition has primarily focused on extracting local or global spatial-temporal representations, while overlooking the intrinsic periodic features of gait sequences, which, when fully utilized, can significantly enhance performance. In this work, we propose a plug-and-play strategy, called Temporal Periodic Alignment (TPA), which leverages the periodic nature and fine-grained temporal dependencies of gait patterns. The TPA strategy comprises two key components. The first component is Adaptive Fourier-transform Position Encoding (AFPE), which adaptively converts features and discrete-time signals into embeddings that are sensitive to periodic walking patterns. The second component is the Temporal Aggregation Module (TAM), which separates embeddings into trend and seasonal components, and extracts meaningful temporal correlations to identify primary components, while filtering out random noise. We present a simple and effective baseline method for gait recognition, based on the TPA strategy. Extensive experiments conducted on three popular public datasets (CASIA-B, OU-MVLP, and GREW) demonstrate that our proposed method achieves state-of-the-art performance on multiple benchmark tests.","sentences":["Gait recognition aims to distinguish different walking patterns by analyzing video-level human silhouettes, rather than relying on appearance information.","Previous research on gait recognition has primarily focused on extracting local or global spatial-temporal representations, while overlooking the intrinsic periodic features of gait sequences, which, when fully utilized, can significantly enhance performance.","In this work, we propose a plug-and-play strategy, called Temporal Periodic Alignment (TPA), which leverages the periodic nature and fine-grained temporal dependencies of gait patterns.","The TPA strategy comprises two key components.","The first component is Adaptive Fourier-transform Position Encoding (AFPE), which adaptively converts features and discrete-time signals into embeddings that are sensitive to periodic walking patterns.","The second component is the Temporal Aggregation Module (TAM), which separates embeddings into trend and seasonal components, and extracts meaningful temporal correlations to identify primary components, while filtering out random noise.","We present a simple and effective baseline method for gait recognition, based on the TPA strategy.","Extensive experiments conducted on three popular public datasets (CASIA-B, OU-MVLP, and GREW) demonstrate that our proposed method achieves state-of-the-art performance on multiple benchmark tests."],"url":"http://arxiv.org/abs/2307.13259v1"}
{"created":"2023-07-25 04:55:45","title":"Structural Credit Assignment with Coordinated Exploration","abstract":"A biologically plausible method for training an Artificial Neural Network (ANN) involves treating each unit as a stochastic Reinforcement Learning (RL) agent, thereby considering the network as a team of agents. Consequently, all units can learn via REINFORCE, a local learning rule modulated by a global reward signal, which aligns more closely with biologically observed forms of synaptic plasticity. However, this learning method tends to be slow and does not scale well with the size of the network. This inefficiency arises from two factors impeding effective structural credit assignment: (i) all units independently explore the network, and (ii) a single reward is used to evaluate the actions of all units. Accordingly, methods aimed at improving structural credit assignment can generally be classified into two categories. The first category includes algorithms that enable coordinated exploration among units, such as MAP propagation. The second category encompasses algorithms that compute a more specific reward signal for each unit within the network, like Weight Maximization and its variants. In this research report, our focus is on the first category. We propose the use of Boltzmann machines or a recurrent network for coordinated exploration. We show that the negative phase, which is typically necessary to train Boltzmann machines, can be removed. The resulting learning rules are similar to the reward-modulated Hebbian learning rule. Experimental results demonstrate that coordinated exploration significantly exceeds independent exploration in training speed for multiple stochastic and discrete units based on REINFORCE, even surpassing straight-through estimator (STE) backpropagation.","sentences":["A biologically plausible method for training an Artificial Neural Network (ANN) involves treating each unit as a stochastic Reinforcement Learning (RL) agent, thereby considering the network as a team of agents.","Consequently, all units can learn via REINFORCE, a local learning rule modulated by a global reward signal, which aligns more closely with biologically observed forms of synaptic plasticity.","However, this learning method tends to be slow and does not scale well with the size of the network.","This inefficiency arises from two factors impeding effective structural credit assignment: (i) all units independently explore the network, and (ii) a single reward is used to evaluate the actions of all units.","Accordingly, methods aimed at improving structural credit assignment can generally be classified into two categories.","The first category includes algorithms that enable coordinated exploration among units, such as MAP propagation.","The second category encompasses algorithms that compute a more specific reward signal for each unit within the network, like Weight Maximization and its variants.","In this research report, our focus is on the first category.","We propose the use of Boltzmann machines or a recurrent network for coordinated exploration.","We show that the negative phase, which is typically necessary to train Boltzmann machines, can be removed.","The resulting learning rules are similar to the reward-modulated Hebbian learning rule.","Experimental results demonstrate that coordinated exploration significantly exceeds independent exploration in training speed for multiple stochastic and discrete units based on REINFORCE, even surpassing straight-through estimator (STE) backpropagation."],"url":"http://arxiv.org/abs/2307.13256v1"}
{"created":"2023-07-25 04:48:03","title":"Conditional Cross Attention Network for Multi-Space Embedding without Entanglement in Only a SINGLE Network","abstract":"Many studies in vision tasks have aimed to create effective embedding spaces for single-label object prediction within an image. However, in reality, most objects possess multiple specific attributes, such as shape, color, and length, with each attribute composed of various classes. To apply models in real-world scenarios, it is essential to be able to distinguish between the granular components of an object. Conventional approaches to embedding multiple specific attributes into a single network often result in entanglement, where fine-grained features of each attribute cannot be identified separately. To address this problem, we propose a Conditional Cross-Attention Network that induces disentangled multi-space embeddings for various specific attributes with only a single backbone. Firstly, we employ a cross-attention mechanism to fuse and switch the information of conditions (specific attributes), and we demonstrate its effectiveness through a diverse visualization example. Secondly, we leverage the vision transformer for the first time to a fine-grained image retrieval task and present a simple yet effective framework compared to existing methods. Unlike previous studies where performance varied depending on the benchmark dataset, our proposed method achieved consistent state-of-the-art performance on the FashionAI, DARN, DeepFashion, and Zappos50K benchmark datasets.","sentences":["Many studies in vision tasks have aimed to create effective embedding spaces for single-label object prediction within an image.","However, in reality, most objects possess multiple specific attributes, such as shape, color, and length, with each attribute composed of various classes.","To apply models in real-world scenarios, it is essential to be able to distinguish between the granular components of an object.","Conventional approaches to embedding multiple specific attributes into a single network often result in entanglement, where fine-grained features of each attribute cannot be identified separately.","To address this problem, we propose a Conditional Cross-Attention Network that induces disentangled multi-space embeddings for various specific attributes with only a single backbone.","Firstly, we employ a cross-attention mechanism to fuse and switch the information of conditions (specific attributes), and we demonstrate its effectiveness through a diverse visualization example.","Secondly, we leverage the vision transformer for the first time to a fine-grained image retrieval task and present a simple yet effective framework compared to existing methods.","Unlike previous studies where performance varied depending on the benchmark dataset, our proposed method achieved consistent state-of-the-art performance on the FashionAI, DARN, DeepFashion, and Zappos50K benchmark datasets."],"url":"http://arxiv.org/abs/2307.13254v1"}
{"created":"2023-07-25 04:43:22","title":"GaPro: Box-Supervised 3D Point Cloud Instance Segmentation Using Gaussian Processes as Pseudo Labelers","abstract":"Instance segmentation on 3D point clouds (3DIS) is a longstanding challenge in computer vision, where state-of-the-art methods are mainly based on full supervision. As annotating ground truth dense instance masks is tedious and expensive, solving 3DIS with weak supervision has become more practical. In this paper, we propose GaPro, a new instance segmentation for 3D point clouds using axis-aligned 3D bounding box supervision. Our two-step approach involves generating pseudo labels from box annotations and training a 3DIS network with the resulting labels. Additionally, we employ the self-training strategy to improve the performance of our method further. We devise an effective Gaussian Process to generate pseudo instance masks from the bounding boxes and resolve ambiguities when they overlap, resulting in pseudo instance masks with their uncertainty values. Our experiments show that GaPro outperforms previous weakly supervised 3D instance segmentation methods and has competitive performance compared to state-of-the-art fully supervised ones. Furthermore, we demonstrate the robustness of our approach, where we can adapt various state-of-the-art fully supervised methods to the weak supervision task by using our pseudo labels for training. The source code and trained models are available at https://github.com/VinAIResearch/GaPro.","sentences":["Instance segmentation on 3D point clouds (3DIS) is a longstanding challenge in computer vision, where state-of-the-art methods are mainly based on full supervision.","As annotating ground truth dense instance masks is tedious and expensive, solving 3DIS with weak supervision has become more practical.","In this paper, we propose GaPro, a new instance segmentation for 3D point clouds using axis-aligned 3D bounding box supervision.","Our two-step approach involves generating pseudo labels from box annotations and training a 3DIS network with the resulting labels.","Additionally, we employ the self-training strategy to improve the performance of our method further.","We devise an effective Gaussian Process to generate pseudo instance masks from the bounding boxes and resolve ambiguities when they overlap, resulting in pseudo instance masks with their uncertainty values.","Our experiments show that GaPro outperforms previous weakly supervised 3D instance segmentation methods and has competitive performance compared to state-of-the-art fully supervised ones.","Furthermore, we demonstrate the robustness of our approach, where we can adapt various state-of-the-art fully supervised methods to the weak supervision task by using our pseudo labels for training.","The source code and trained models are available at https://github.com/VinAIResearch/GaPro."],"url":"http://arxiv.org/abs/2307.13251v1"}
{"created":"2023-07-25 04:41:32","title":"Keyword-Aware Relative Spatio-Temporal Graph Networks for Video Question Answering","abstract":"The main challenge in video question answering (VideoQA) is to capture and understand the complex spatial and temporal relations between objects based on given questions. Existing graph-based methods for VideoQA usually ignore keywords in questions and employ a simple graph to aggregate features without considering relative relations between objects, which may lead to inferior performance. In this paper, we propose a Keyword-aware Relative Spatio-Temporal (KRST) graph network for VideoQA. First, to make question features aware of keywords, we employ an attention mechanism to assign high weights to keywords during question encoding. The keyword-aware question features are then used to guide video graph construction. Second, because relations are relative, we integrate the relative relation modeling to better capture the spatio-temporal dynamics among object nodes. Moreover, we disentangle the spatio-temporal reasoning into an object-level spatial graph and a frame-level temporal graph, which reduces the impact of spatial and temporal relation reasoning on each other. Extensive experiments on the TGIF-QA, MSVD-QA and MSRVTT-QA datasets demonstrate the superiority of our KRST over multiple state-of-the-art methods.","sentences":["The main challenge in video question answering (VideoQA) is to capture and understand the complex spatial and temporal relations between objects based on given questions.","Existing graph-based methods for VideoQA usually ignore keywords in questions and employ a simple graph to aggregate features without considering relative relations between objects, which may lead to inferior performance.","In this paper, we propose a Keyword-aware Relative Spatio-Temporal (KRST) graph network for VideoQA.","First, to make question features aware of keywords, we employ an attention mechanism to assign high weights to keywords during question encoding.","The keyword-aware question features are then used to guide video graph construction.","Second, because relations are relative, we integrate the relative relation modeling to better capture the spatio-temporal dynamics among object nodes.","Moreover, we disentangle the spatio-temporal reasoning into an object-level spatial graph and a frame-level temporal graph, which reduces the impact of spatial and temporal relation reasoning on each other.","Extensive experiments on the TGIF-QA, MSVD-QA and MSRVTT-QA datasets demonstrate the superiority of our KRST over multiple state-of-the-art methods."],"url":"http://arxiv.org/abs/2307.13250v1"}
{"created":"2023-07-25 04:29:22","title":"Bayesian Rationality in Satisfaction Games","abstract":"We introduce a new paradigm for game theory -- Bayesian satisfaction. This novel approach is a synthesis of the idea of Bayesian rationality introduced by Aumann, and satisfaction games. The concept of Bayesian rationality for which, in part, Robert Aumann was awarded the Nobel Prize in 2005, is concerned with players in a game acting in their own best interest given a subjective knowledge of the other players' behaviours as represented by a probability distribution. Satisfaction games have emerged in the engineering literature as a way of modelling competitive interactions in resource allocation problems where players seek to attain a specified level of utility, rather than trying to maximise utility. In this paper, we explore the relationship between optimality in Aumann's sense (correlated equilibria), and satisfaction in games. We show that correlated equilibria in a satisfaction game represent stable outcomes in which no player can increase their probability of satisfaction by unilateral deviation from the specified behaviour. Thus, we propose a whole new class of equilibrium outcomes in satisfaction games which include existing notions of equilibria in such games. Iterative algorithms for computing such equilibria based on the existing ideas of regret matching are presented and interpreted within the satisfaction framework. Numerical examples of resource allocation are presented to illustrate the behaviour of these algorithms. A notable feature of these algorithms is that they almost always find equilibrium outcomes whereas existing approaches in satisfaction games may not.","sentences":["We introduce a new paradigm for game theory -- Bayesian satisfaction.","This novel approach is a synthesis of the idea of Bayesian rationality introduced by Aumann, and satisfaction games.","The concept of Bayesian rationality for which, in part, Robert Aumann was awarded the Nobel Prize in 2005, is concerned with players in a game acting in their own best interest given a subjective knowledge of the other players' behaviours as represented by a probability distribution.","Satisfaction games have emerged in the engineering literature as a way of modelling competitive interactions in resource allocation problems where players seek to attain a specified level of utility, rather than trying to maximise utility.","In this paper, we explore the relationship between optimality in Aumann's sense (correlated equilibria), and satisfaction in games.","We show that correlated equilibria in a satisfaction game represent stable outcomes in which no player can increase their probability of satisfaction by unilateral deviation from the specified behaviour.","Thus, we propose a whole new class of equilibrium outcomes in satisfaction games which include existing notions of equilibria in such games.","Iterative algorithms for computing such equilibria based on the existing ideas of regret matching are presented and interpreted within the satisfaction framework.","Numerical examples of resource allocation are presented to illustrate the behaviour of these algorithms.","A notable feature of these algorithms is that they almost always find equilibrium outcomes whereas existing approaches in satisfaction games may not."],"url":"http://arxiv.org/abs/2307.13247v1"}
{"created":"2023-07-25 04:12:50","title":"Multi-Granularity Prediction with Learnable Fusion for Scene Text Recognition","abstract":"Due to the enormous technical challenges and wide range of applications, scene text recognition (STR) has been an active research topic in computer vision for years. To tackle this tough problem, numerous innovative methods have been successively proposed, and incorporating linguistic knowledge into STR models has recently become a prominent trend. In this work, we first draw inspiration from the recent progress in Vision Transformer (ViT) to construct a conceptually simple yet functionally powerful vision STR model, which is built upon ViT and a tailored Adaptive Addressing and Aggregation (A$^3$) module. It already outperforms most previous state-of-the-art models for scene text recognition, including both pure vision models and language-augmented methods. To integrate linguistic knowledge, we further propose a Multi-Granularity Prediction strategy to inject information from the language modality into the model in an implicit way, \\ie, subword representations (BPE and WordPiece) widely used in NLP are introduced into the output space, in addition to the conventional character level representation, while no independent language model (LM) is adopted. To produce the final recognition results, two strategies for effectively fusing the multi-granularity predictions are devised. The resultant algorithm (termed MGP-STR) is able to push the performance envelope of STR to an even higher level. Specifically, MGP-STR achieves an average recognition accuracy of $94\\%$ on standard benchmarks for scene text recognition. Moreover, it also achieves state-of-the-art results on widely-used handwritten benchmarks as well as more challenging scene text datasets, demonstrating the generality of the proposed MGP-STR algorithm. The source code and models will be available at: \\url{https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/MGP-STR}.","sentences":["Due to the enormous technical challenges and wide range of applications, scene text recognition (STR) has been an active research topic in computer vision for years.","To tackle this tough problem, numerous innovative methods have been successively proposed, and incorporating linguistic knowledge into STR models has recently become a prominent trend.","In this work, we first draw inspiration from the recent progress in Vision Transformer (ViT) to construct a conceptually simple yet functionally powerful vision STR model, which is built upon ViT and a tailored Adaptive Addressing and Aggregation (A$^3$) module.","It already outperforms most previous state-of-the-art models for scene text recognition, including both pure vision models and language-augmented methods.","To integrate linguistic knowledge, we further propose a Multi-Granularity Prediction strategy to inject information from the language modality into the model in an implicit way, \\ie, subword representations (BPE and WordPiece) widely used in NLP are introduced into the output space, in addition to the conventional character level representation, while no independent language model (LM) is adopted.","To produce the final recognition results, two strategies for effectively fusing the multi-granularity predictions are devised.","The resultant algorithm (termed MGP-STR) is able to push the performance envelope of STR to an even higher level.","Specifically, MGP-STR achieves an average recognition accuracy of $94\\%$ on standard benchmarks for scene text recognition.","Moreover, it also achieves state-of-the-art results on widely-used handwritten benchmarks as well as more challenging scene text datasets, demonstrating the generality of the proposed MGP-STR algorithm.","The source code and models will be available at: \\url{https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/MGP-STR}."],"url":"http://arxiv.org/abs/2307.13244v1"}
{"created":"2023-07-25 04:11:47","title":"A Model Predictive Capture Point Control Framework for Robust Humanoid Balancing via Ankle, Hip, and Stepping Strategies","abstract":"The robust balancing capability of humanoid robots against disturbances has been considered as one of the crucial requirements for their practical mobility in real-world environments. In particular, many studies have been devoted to the efficient implementation of the three balance strategies, inspired by human balance strategies involving ankle, hip, and stepping strategies, to endow humanoid robots with human-level balancing capability. In this paper, a robust balance control framework for humanoid robots is proposed. Firstly, a novel Model Predictive Control (MPC) framework is proposed for Capture Point (CP) tracking control, enabling the integration of ankle, hip, and stepping strategies within a single framework. Additionally, a variable weighting method is introduced that adjusts the weighting parameters of the Centroidal Angular Momentum (CAM) damping control over the time horizon of MPC to improve the balancing performance. Secondly, a hierarchical structure of the MPC and a stepping controller was proposed, allowing for the step time optimization. The robust balancing performance of the proposed method is validated through extensive simulations and real robot experiments. Furthermore, a superior balancing performance is demonstrated, particularly in the presence of disturbances, compared to a state-of-the-art Quadratic Programming (QP)-based CP controller that employs the ankle, hip, and stepping strategies. The supplementary video is available at https://youtu.be/CrD75UbYzdc","sentences":["The robust balancing capability of humanoid robots against disturbances has been considered as one of the crucial requirements for their practical mobility in real-world environments.","In particular, many studies have been devoted to the efficient implementation of the three balance strategies, inspired by human balance strategies involving ankle, hip, and stepping strategies, to endow humanoid robots with human-level balancing capability.","In this paper, a robust balance control framework for humanoid robots is proposed.","Firstly, a novel Model Predictive Control (MPC) framework is proposed for Capture Point (CP) tracking control, enabling the integration of ankle, hip, and stepping strategies within a single framework.","Additionally, a variable weighting method is introduced that adjusts the weighting parameters of the Centroidal Angular Momentum (CAM) damping control over the time horizon of MPC to improve the balancing performance.","Secondly, a hierarchical structure of the MPC and a stepping controller was proposed, allowing for the step time optimization.","The robust balancing performance of the proposed method is validated through extensive simulations and real robot experiments.","Furthermore, a superior balancing performance is demonstrated, particularly in the presence of disturbances, compared to a state-of-the-art Quadratic Programming (QP)-based CP controller that employs the ankle, hip, and stepping strategies.","The supplementary video is available at https://youtu.be/CrD75UbYzdc"],"url":"http://arxiv.org/abs/2307.13243v1"}
{"created":"2023-07-25 04:11:22","title":"Social Optimum Equilibrium Selection for Distributed Multi-Agent Optimization","abstract":"We study the open question of how players learn to play a social optimum pure-strategy Nash equilibrium (PSNE) through repeated interactions in general-sum coordination games. A social optimum of a game is the stable Pareto-optimal state that provides a maximum return in the sum of all players' payoffs (social welfare) and always exists. We consider finite repeated games where each player only has access to its own utility (or payoff) function but is able to exchange information with other players. We develop a novel regret matching (RM) based algorithm for computing an efficient PSNE solution that could approach a desired Pareto-optimal outcome yielding the highest social welfare among all the attainable equilibria in the long run. Our proposed learning procedure follows the regret minimization framework but extends it in three major ways: (1) agents use global, instead of local, utility for calculating regrets, (2) each agent maintains a small and diminishing exploration probability in order to explore various PSNEs, and (3) agents stay with the actions that achieve the best global utility thus far, regardless of regrets. We prove that these three extensions enable the algorithm to select the stable social optimum equilibrium instead of converging to an arbitrary or cyclic equilibrium as in the conventional RM approach. We demonstrate the effectiveness of our approach through a set of applications in multi-agent distributed control, including a large-scale resource allocation game and a hard combinatorial task assignment problem for which no efficient (polynomial) solution exists.","sentences":["We study the open question of how players learn to play a social optimum pure-strategy Nash equilibrium (PSNE) through repeated interactions in general-sum coordination games.","A social optimum of a game is the stable Pareto-optimal state that provides a maximum return in the sum of all players' payoffs (social welfare) and always exists.","We consider finite repeated games where each player only has access to its own utility (or payoff) function but is able to exchange information with other players.","We develop a novel regret matching (RM) based algorithm for computing an efficient PSNE solution that could approach a desired Pareto-optimal outcome yielding the highest social welfare among all the attainable equilibria in the long run.","Our proposed learning procedure follows the regret minimization framework but extends it in three major ways: (1) agents use global, instead of local, utility for calculating regrets, (2) each agent maintains a small and diminishing exploration probability in order to explore various PSNEs, and (3) agents stay with the actions that achieve the best global utility thus far, regardless of regrets.","We prove that these three extensions enable the algorithm to select the stable social optimum equilibrium instead of converging to an arbitrary or cyclic equilibrium as in the conventional RM approach.","We demonstrate the effectiveness of our approach through a set of applications in multi-agent distributed control, including a large-scale resource allocation game and a hard combinatorial task assignment problem for which no efficient (polynomial) solution exists."],"url":"http://arxiv.org/abs/2307.13242v1"}
{"created":"2023-07-25 04:06:25","title":"Fashion Matrix: Editing Photos by Just Talking","abstract":"The utilization of Large Language Models (LLMs) for the construction of AI systems has garnered significant attention across diverse fields. The extension of LLMs to the domain of fashion holds substantial commercial potential but also inherent challenges due to the intricate semantic interactions in fashion-related generation. To address this issue, we developed a hierarchical AI system called Fashion Matrix dedicated to editing photos by just talking. This system facilitates diverse prompt-driven tasks, encompassing garment or accessory replacement, recoloring, addition, and removal. Specifically, Fashion Matrix employs LLM as its foundational support and engages in iterative interactions with users. It employs a range of Semantic Segmentation Models (e.g., Grounded-SAM, MattingAnything, etc.) to delineate the specific editing masks based on user instructions. Subsequently, Visual Foundation Models (e.g., Stable Diffusion, ControlNet, etc.) are leveraged to generate edited images from text prompts and masks, thereby facilitating the automation of fashion editing processes. Experiments demonstrate the outstanding ability of Fashion Matrix to explores the collaborative potential of functionally diverse pre-trained models in the domain of fashion editing.","sentences":["The utilization of Large Language Models (LLMs) for the construction of AI systems has garnered significant attention across diverse fields.","The extension of LLMs to the domain of fashion holds substantial commercial potential but also inherent challenges due to the intricate semantic interactions in fashion-related generation.","To address this issue, we developed a hierarchical AI system called Fashion Matrix dedicated to editing photos by just talking.","This system facilitates diverse prompt-driven tasks, encompassing garment or accessory replacement, recoloring, addition, and removal.","Specifically, Fashion Matrix employs LLM as its foundational support and engages in iterative interactions with users.","It employs a range of Semantic Segmentation Models (e.g., Grounded-SAM, MattingAnything, etc.) to delineate the specific editing masks based on user instructions.","Subsequently, Visual Foundation Models (e.g., Stable Diffusion, ControlNet, etc.) are leveraged to generate edited images from text prompts and masks, thereby facilitating the automation of fashion editing processes.","Experiments demonstrate the outstanding ability of Fashion Matrix to explores the collaborative potential of functionally diverse pre-trained models in the domain of fashion editing."],"url":"http://arxiv.org/abs/2307.13240v1"}
{"created":"2023-07-25 04:04:49","title":"RoSAS: Deep Semi-Supervised Anomaly Detection with Contamination-Resilient Continuous Supervision","abstract":"Semi-supervised anomaly detection methods leverage a few anomaly examples to yield drastically improved performance compared to unsupervised models. However, they still suffer from two limitations: 1) unlabeled anomalies (i.e., anomaly contamination) may mislead the learning process when all the unlabeled data are employed as inliers for model training; 2) only discrete supervision information (such as binary or ordinal data labels) is exploited, which leads to suboptimal learning of anomaly scores that essentially take on a continuous distribution. Therefore, this paper proposes a novel semi-supervised anomaly detection method, which devises \\textit{contamination-resilient continuous supervisory signals}. Specifically, we propose a mass interpolation method to diffuse the abnormality of labeled anomalies, thereby creating new data samples labeled with continuous abnormal degrees. Meanwhile, the contaminated area can be covered by new data samples generated via combinations of data with correct labels. A feature learning-based objective is added to serve as an optimization constraint to regularize the network and further enhance the robustness w.r.t. anomaly contamination. Extensive experiments on 11 real-world datasets show that our approach significantly outperforms state-of-the-art competitors by 20%-30% in AUC-PR and obtains more robust and superior performance in settings with different anomaly contamination levels and varying numbers of labeled anomalies. The source code is available at https://github.com/xuhongzuo/rosas/.","sentences":["Semi-supervised anomaly detection methods leverage a few anomaly examples to yield drastically improved performance compared to unsupervised models.","However, they still suffer from two limitations: 1) unlabeled anomalies (i.e., anomaly contamination) may mislead the learning process when all the unlabeled data are employed as inliers for model training; 2) only discrete supervision information (such as binary or ordinal data labels) is exploited, which leads to suboptimal learning of anomaly scores that essentially take on a continuous distribution.","Therefore, this paper proposes a novel semi-supervised anomaly detection method, which devises \\textit{contamination-resilient continuous supervisory signals}.","Specifically, we propose a mass interpolation method to diffuse the abnormality of labeled anomalies, thereby creating new data samples labeled with continuous abnormal degrees.","Meanwhile, the contaminated area can be covered by new data samples generated via combinations of data with correct labels.","A feature learning-based objective is added to serve as an optimization constraint to regularize the network and further enhance the robustness w.r.t.","anomaly contamination.","Extensive experiments on 11 real-world datasets show that our approach significantly outperforms state-of-the-art competitors by 20%-30% in AUC-PR and obtains more robust and superior performance in settings with different anomaly contamination levels and varying numbers of labeled anomalies.","The source code is available at https://github.com/xuhongzuo/rosas/."],"url":"http://arxiv.org/abs/2307.13239v1"}
{"created":"2023-07-25 04:02:32","title":"Rank Optimization for MIMO systems with RIS: Simulation and Measurement","abstract":"Reconfigurable intelligent surface (RIS) is a promising technology that can reshape the electromagnetic environment in wireless networks, offering various possibilities for enhancing wireless channels. Motivated by this, we investigate the channel optimization for multiple-input multiple-output (MIMO) systems assisted by RIS. In this paper, an efficient RIS optimization method is proposed to enhance the effective rank of the MIMO channel for achievable rate improvement. Numerical results are presented to verify the effectiveness of RIS in improving MIMO channels. Additionally, we construct a 2$\\times$2 RIS-assisted MIMO prototype to perform experimental measurements and validate the performance of our proposed algorithm. The results reveal a significant increase in effective rank and achievable rate for the RIS-assisted MIMO channel compared to the MIMO channel without RIS.","sentences":["Reconfigurable intelligent surface (RIS) is a promising technology that can reshape the electromagnetic environment in wireless networks, offering various possibilities for enhancing wireless channels.","Motivated by this, we investigate the channel optimization for multiple-input multiple-output (MIMO) systems assisted by RIS.","In this paper, an efficient RIS optimization method is proposed to enhance the effective rank of the MIMO channel for achievable rate improvement.","Numerical results are presented to verify the effectiveness of RIS in improving MIMO channels.","Additionally, we construct a 2$\\times$2 RIS-assisted MIMO prototype to perform experimental measurements and validate the performance of our proposed algorithm.","The results reveal a significant increase in effective rank and achievable rate for the RIS-assisted MIMO channel compared to the MIMO channel without RIS."],"url":"http://arxiv.org/abs/2307.13237v1"}
{"created":"2023-07-25 03:59:04","title":"Audio-aware Query-enhanced Transformer for Audio-Visual Segmentation","abstract":"The goal of the audio-visual segmentation (AVS) task is to segment the sounding objects in the video frames using audio cues. However, current fusion-based methods have the performance limitations due to the small receptive field of convolution and inadequate fusion of audio-visual features. To overcome these issues, we propose a novel \\textbf{Au}dio-aware query-enhanced \\textbf{TR}ansformer (AuTR) to tackle the task. Unlike existing methods, our approach introduces a multimodal transformer architecture that enables deep fusion and aggregation of audio-visual features. Furthermore, we devise an audio-aware query-enhanced transformer decoder that explicitly helps the model focus on the segmentation of the pinpointed sounding objects based on audio signals, while disregarding silent yet salient objects. Experimental results show that our method outperforms previous methods and demonstrates better generalization ability in multi-sound and open-set scenarios.","sentences":["The goal of the audio-visual segmentation (AVS) task is to segment the sounding objects in the video frames using audio cues.","However, current fusion-based methods have the performance limitations due to the small receptive field of convolution and inadequate fusion of audio-visual features.","To overcome these issues, we propose a novel \\textbf{Au}dio-aware query-enhanced \\textbf{TR}ansformer (AuTR) to tackle the task.","Unlike existing methods, our approach introduces a multimodal transformer architecture that enables deep fusion and aggregation of audio-visual features.","Furthermore, we devise an audio-aware query-enhanced transformer decoder that explicitly helps the model focus on the segmentation of the pinpointed sounding objects based on audio signals, while disregarding silent yet salient objects.","Experimental results show that our method outperforms previous methods and demonstrates better generalization ability in multi-sound and open-set scenarios."],"url":"http://arxiv.org/abs/2307.13236v1"}
{"created":"2023-07-25 03:45:56","title":"Spectral-DP: Differentially Private Deep Learning through Spectral Perturbation and Filtering","abstract":"Differential privacy is a widely accepted measure of privacy in the context of deep learning algorithms, and achieving it relies on a noisy training approach known as differentially private stochastic gradient descent (DP-SGD). DP-SGD requires direct noise addition to every gradient in a dense neural network, the privacy is achieved at a significant utility cost. In this work, we present Spectral-DP, a new differentially private learning approach which combines gradient perturbation in the spectral domain with spectral filtering to achieve a desired privacy guarantee with a lower noise scale and thus better utility. We develop differentially private deep learning methods based on Spectral-DP for architectures that contain both convolution and fully connected layers. In particular, for fully connected layers, we combine a block-circulant based spatial restructuring with Spectral-DP to achieve better utility. Through comprehensive experiments, we study and provide guidelines to implement Spectral-DP deep learning on benchmark datasets. In comparison with state-of-the-art DP-SGD based approaches, Spectral-DP is shown to have uniformly better utility performance in both training from scratch and transfer learning settings.","sentences":["Differential privacy is a widely accepted measure of privacy in the context of deep learning algorithms, and achieving it relies on a noisy training approach known as differentially private stochastic gradient descent (DP-SGD).","DP-SGD requires direct noise addition to every gradient in a dense neural network, the privacy is achieved at a significant utility cost.","In this work, we present Spectral-DP, a new differentially private learning approach which combines gradient perturbation in the spectral domain with spectral filtering to achieve a desired privacy guarantee with a lower noise scale and thus better utility.","We develop differentially private deep learning methods based on Spectral-DP for architectures that contain both convolution and fully connected layers.","In particular, for fully connected layers, we combine a block-circulant based spatial restructuring with Spectral-DP to achieve better utility.","Through comprehensive experiments, we study and provide guidelines to implement Spectral-DP deep learning on benchmark datasets.","In comparison with state-of-the-art DP-SGD based approaches, Spectral-DP is shown to have uniformly better utility performance in both training from scratch and transfer learning settings."],"url":"http://arxiv.org/abs/2307.13231v1"}
{"created":"2023-07-25 03:30:09","title":"Strivec: Sparse Tri-Vector Radiance Fields","abstract":"We propose Strivec, a novel neural representation that models a 3D scene as a radiance field with sparsely distributed and compactly factorized local tensor feature grids. Our approach leverages tensor decomposition, following the recent work TensoRF, to model the tensor grids. In contrast to TensoRF which uses a global tensor and focuses on their vector-matrix decomposition, we propose to utilize a cloud of local tensors and apply the classic CANDECOMP/PARAFAC (CP) decomposition to factorize each tensor into triple vectors that express local feature distributions along spatial axes and compactly encode a local neural field. We also apply multi-scale tensor grids to discover the geometry and appearance commonalities and exploit spatial coherence with the tri-vector factorization at multiple local scales. The final radiance field properties are regressed by aggregating neural features from multiple local tensors across all scales. Our tri-vector tensors are sparsely distributed around the actual scene surface, discovered by a fast coarse reconstruction, leveraging the sparsity of a 3D scene. We demonstrate that our model can achieve better rendering quality while using significantly fewer parameters than previous methods, including TensoRF and Instant-NGP.","sentences":["We propose Strivec, a novel neural representation that models a 3D scene as a radiance field with sparsely distributed and compactly factorized local tensor feature grids.","Our approach leverages tensor decomposition, following the recent work TensoRF, to model the tensor grids.","In contrast to TensoRF which uses a global tensor and focuses on their vector-matrix decomposition, we propose to utilize a cloud of local tensors and apply the classic CANDECOMP/PARAFAC (CP) decomposition to factorize each tensor into triple vectors that express local feature distributions along spatial axes and compactly encode a local neural field.","We also apply multi-scale tensor grids to discover the geometry and appearance commonalities and exploit spatial coherence with the tri-vector factorization at multiple local scales.","The final radiance field properties are regressed by aggregating neural features from multiple local tensors across all scales.","Our tri-vector tensors are sparsely distributed around the actual scene surface, discovered by a fast coarse reconstruction, leveraging the sparsity of a 3D scene.","We demonstrate that our model can achieve better rendering quality while using significantly fewer parameters than previous methods, including TensoRF and Instant-NGP."],"url":"http://arxiv.org/abs/2307.13226v1"}
{"created":"2023-07-25 03:25:56","title":"A Pairwise Dataset for GUI Conversion and Retrieval between Android Phones and Tablets","abstract":"With the popularity of smartphones and tablets, users have become accustomed to using different devices for different tasks, such as using their phones to play games and tablets to watch movies. To conquer the market, one app is often available on both smartphones and tablets. However, although one app has similar graphic user interfaces (GUIs) and functionalities on phone and tablet, current app developers typically start from scratch when developing a tablet-compatible version of their app, which drives up development costs and wastes existing design resources. Researchers are attempting to employ deep learning in automated GUIs development to enhance developers' productivity. Deep learning models rely heavily on high-quality datasets. There are currently several publicly accessible GUI page datasets for phones, but none for pairwise GUIs between phones and tablets. This poses a significant barrier to the employment of deep learning in automated GUI development. In this paper, we collect and make public the Papt dataset, which is a pairwise dataset for GUI conversion and retrieval between Android phones and tablets. The dataset contains 10,035 phone-tablet GUI page pairs from 5,593 phone-tablet app pairs. We illustrate the approaches of collecting pairwise data and statistical analysis of this dataset. We also illustrate the advantages of our dataset compared to other current datasets. Through preliminary experiments on this dataset, we analyse the present challenges of utilising deep learning in automated GUI development and find that our dataset can assist the application of some deep learning models to tasks involving automatic GUI development.","sentences":["With the popularity of smartphones and tablets, users have become accustomed to using different devices for different tasks, such as using their phones to play games and tablets to watch movies.","To conquer the market, one app is often available on both smartphones and tablets.","However, although one app has similar graphic user interfaces (GUIs) and functionalities on phone and tablet, current app developers typically start from scratch when developing a tablet-compatible version of their app, which drives up development costs and wastes existing design resources.","Researchers are attempting to employ deep learning in automated GUIs development to enhance developers' productivity.","Deep learning models rely heavily on high-quality datasets.","There are currently several publicly accessible GUI page datasets for phones, but none for pairwise GUIs between phones and tablets.","This poses a significant barrier to the employment of deep learning in automated GUI development.","In this paper, we collect and make public the Papt dataset, which is a pairwise dataset for GUI conversion and retrieval between Android phones and tablets.","The dataset contains 10,035 phone-tablet GUI page pairs from 5,593 phone-tablet app pairs.","We illustrate the approaches of collecting pairwise data and statistical analysis of this dataset.","We also illustrate the advantages of our dataset compared to other current datasets.","Through preliminary experiments on this dataset, we analyse the present challenges of utilising deep learning in automated GUI development and find that our dataset can assist the application of some deep learning models to tasks involving automatic GUI development."],"url":"http://arxiv.org/abs/2307.13225v1"}
{"created":"2023-07-25 03:18:04","title":"Multilevel Large Language Models for Everyone","abstract":"Large language models have made significant progress in the past few years. However, they are either generic {\\it or} field specific, splitting the community into different groups. In this paper, we unify these large language models into a larger map, where the generic {\\it and} specific models are linked together and can improve each other, based on the user personal input and information from the internet. The idea of linking several large language models together is inspired by the functionality of human brain. The specific regions on the brain cortex are specific for certain low level functionality. And these regions can jointly work together to achieve more complex high level functionality. Such behavior on human brain cortex sheds the light to design the multilevel large language models that contain global level, field level and user level models. The user level models run on local machines to achieve efficient response and protect the user's privacy. Such multilevel models reduce some redundancy and perform better than the single level models. The proposed multilevel idea can be applied in various applications, such as natural language processing, computer vision tasks, professional assistant, business and healthcare.","sentences":["Large language models have made significant progress in the past few years.","However, they are either generic {\\it or} field specific, splitting the community into different groups.","In this paper, we unify these large language models into a larger map, where the generic {\\it and} specific models are linked together and can improve each other, based on the user personal input and information from the internet.","The idea of linking several large language models together is inspired by the functionality of human brain.","The specific regions on the brain cortex are specific for certain low level functionality.","And these regions can jointly work together to achieve more complex high level functionality.","Such behavior on human brain cortex sheds the light to design the multilevel large language models that contain global level, field level and user level models.","The user level models run on local machines to achieve efficient response and protect the user's privacy.","Such multilevel models reduce some redundancy and perform better than the single level models.","The proposed multilevel idea can be applied in various applications, such as natural language processing, computer vision tasks, professional assistant, business and healthcare."],"url":"http://arxiv.org/abs/2307.13221v1"}
{"created":"2023-07-25 03:11:18","title":"A Primer on the Data Cleaning Pipeline","abstract":"The availability of both structured and unstructured databases, such as electronic health data, social media data, patent data, and surveys that are often updated in real time, among others, has grown rapidly over the past decade. With this expansion, the statistical and methodological questions around data integration, or rather merging multiple data sources, has also grown. Specifically, the science of the ``data cleaning pipeline'' contains four stages that allow an analyst to perform downstream tasks, predictive analyses, or statistical analyses on ``cleaned data.'' This article provides a review of this emerging field, introducing technical terminology and commonly used methods.","sentences":["The availability of both structured and unstructured databases, such as electronic health data, social media data, patent data, and surveys that are often updated in real time, among others, has grown rapidly over the past decade.","With this expansion, the statistical and methodological questions around data integration, or rather merging multiple data sources, has also grown.","Specifically, the science of the ``data cleaning pipeline'' contains four stages that allow an analyst to perform downstream tasks, predictive analyses, or statistical analyses on ``cleaned data.''","This article provides a review of this emerging field, introducing technical terminology and commonly used methods."],"url":"http://arxiv.org/abs/2307.13219v1"}
{"created":"2023-07-25 02:56:20","title":"Image Segmentation Keras : Implementation of Segnet, FCN, UNet, PSPNet and other models in Keras","abstract":"Semantic segmentation plays a vital role in computer vision tasks, enabling precise pixel-level understanding of images. In this paper, we present a comprehensive library for semantic segmentation, which contains implementations of popular segmentation models like SegNet, FCN, UNet, and PSPNet. We also evaluate and compare these models on several datasets, offering researchers and practitioners a powerful toolset for tackling diverse segmentation challenges.","sentences":["Semantic segmentation plays a vital role in computer vision tasks, enabling precise pixel-level understanding of images.","In this paper, we present a comprehensive library for semantic segmentation, which contains implementations of popular segmentation models like SegNet, FCN, UNet, and PSPNet.","We also evaluate and compare these models on several datasets, offering researchers and practitioners a powerful toolset for tackling diverse segmentation challenges."],"url":"http://arxiv.org/abs/2307.13215v1"}
{"created":"2023-07-25 02:55:33","title":"FedMEKT: Distillation-based Embedding Knowledge Transfer for Multimodal Federated Learning","abstract":"Federated learning (FL) enables a decentralized machine learning paradigm for multiple clients to collaboratively train a generalized global model without sharing their private data. Most existing works simply propose typical FL systems for single-modal data, thus limiting its potential on exploiting valuable multimodal data for future personalized applications. Furthermore, the majority of FL approaches still rely on the labeled data at the client side, which is limited in real-world applications due to the inability of self-annotation from users. In light of these limitations, we propose a novel multimodal FL framework that employs a semi-supervised learning approach to leverage the representations from different modalities. Bringing this concept into a system, we develop a distillation-based multimodal embedding knowledge transfer mechanism, namely FedMEKT, which allows the server and clients to exchange the joint knowledge of their learning models extracted from a small multimodal proxy dataset. Our FedMEKT iteratively updates the generalized global encoders with the joint embedding knowledge from the participating clients. Thereby, to address the modality discrepancy and labeled data constraint in existing FL systems, our proposed FedMEKT comprises local multimodal autoencoder learning, generalized multimodal autoencoder construction, and generalized classifier learning. Through extensive experiments on three multimodal human activity recognition datasets, we demonstrate that FedMEKT achieves superior global encoder performance on linear evaluation and guarantees user privacy for personal data and model parameters while demanding less communication cost than other baselines.","sentences":["Federated learning (FL) enables a decentralized machine learning paradigm for multiple clients to collaboratively train a generalized global model without sharing their private data.","Most existing works simply propose typical FL systems for single-modal data, thus limiting its potential on exploiting valuable multimodal data for future personalized applications.","Furthermore, the majority of FL approaches still rely on the labeled data at the client side, which is limited in real-world applications due to the inability of self-annotation from users.","In light of these limitations, we propose a novel multimodal FL framework that employs a semi-supervised learning approach to leverage the representations from different modalities.","Bringing this concept into a system, we develop a distillation-based multimodal embedding knowledge transfer mechanism, namely FedMEKT, which allows the server and clients to exchange the joint knowledge of their learning models extracted from a small multimodal proxy dataset.","Our FedMEKT iteratively updates the generalized global encoders with the joint embedding knowledge from the participating clients.","Thereby, to address the modality discrepancy and labeled data constraint in existing FL systems, our proposed FedMEKT comprises local multimodal autoencoder learning, generalized multimodal autoencoder construction, and generalized classifier learning.","Through extensive experiments on three multimodal human activity recognition datasets, we demonstrate that FedMEKT achieves superior global encoder performance on linear evaluation and guarantees user privacy for personal data and model parameters while demanding less communication cost than other baselines."],"url":"http://arxiv.org/abs/2307.13214v1"}
{"created":"2023-07-25 02:23:58","title":"Gait Cycle-Inspired Learning Strategy for Continuous Prediction of Knee Joint Trajectory from sEMG","abstract":"Predicting lower limb motion intent is vital for controlling exoskeleton robots and prosthetic limbs. Surface electromyography (sEMG) attracts increasing attention in recent years as it enables ahead-of-time prediction of motion intentions before actual movement. However, the estimation performance of human joint trajectory remains a challenging problem due to the inter- and intra-subject variations. The former is related to physiological differences (such as height and weight) and preferred walking patterns of individuals, while the latter is mainly caused by irregular and gait-irrelevant muscle activity. This paper proposes a model integrating two gait cycle-inspired learning strategies to mitigate the challenge for predicting human knee joint trajectory. The first strategy is to decouple knee joint angles into motion patterns and amplitudes former exhibit low variability while latter show high variability among individuals. By learning through separate network entities, the model manages to capture both the common and personalized gait features. In the second, muscle principal activation masks are extracted from gait cycles in a prolonged walk. These masks are used to filter out components unrelated to walking from raw sEMG and provide auxiliary guidance to capture more gait-related features. Experimental results indicate that our model could predict knee angles with the average root mean square error (RMSE) of 3.03(0.49) degrees and 50ms ahead of time. To our knowledge this is the best performance in relevant literatures that has been reported, with reduced RMSE by at least 9.5%.","sentences":["Predicting lower limb motion intent is vital for controlling exoskeleton robots and prosthetic limbs.","Surface electromyography (sEMG) attracts increasing attention in recent years as it enables ahead-of-time prediction of motion intentions before actual movement.","However, the estimation performance of human joint trajectory remains a challenging problem due to the inter- and intra-subject variations.","The former is related to physiological differences (such as height and weight) and preferred walking patterns of individuals, while the latter is mainly caused by irregular and gait-irrelevant muscle activity.","This paper proposes a model integrating two gait cycle-inspired learning strategies to mitigate the challenge for predicting human knee joint trajectory.","The first strategy is to decouple knee joint angles into motion patterns and amplitudes former exhibit low variability while latter show high variability among individuals.","By learning through separate network entities, the model manages to capture both the common and personalized gait features.","In the second, muscle principal activation masks are extracted from gait cycles in a prolonged walk.","These masks are used to filter out components unrelated to walking from raw sEMG and provide auxiliary guidance to capture more gait-related features.","Experimental results indicate that our model could predict knee angles with the average root mean square error (RMSE) of 3.03(0.49) degrees and 50ms ahead of time.","To our knowledge this is the best performance in relevant literatures that has been reported, with reduced RMSE by at least 9.5%."],"url":"http://arxiv.org/abs/2307.13209v1"}
{"created":"2023-07-25 02:11:41","title":"Transferability of Graph Neural Networks using Graphon and Sampling Theories","abstract":"Graph neural networks (GNNs) have become powerful tools for processing graph-based information in various domains. A desirable property of GNNs is transferability, where a trained network can swap in information from a different graph without retraining and retain its accuracy. A recent method of capturing transferability of GNNs is through the use of graphons, which are symmetric, measurable functions representing the limit of large dense graphs. In this work, we contribute to the application of graphons to GNNs by presenting an explicit two-layer graphon neural network (WNN) architecture. We prove its ability to approximate bandlimited signals within a specified error tolerance using a minimal number of network weights. We then leverage this result, to establish the transferability of an explicit two-layer GNN over all sufficiently large graphs in a sequence converging to a graphon. Our work addresses transferability between both deterministic weighted graphs and simple random graphs and overcomes issues related to the curse of dimensionality that arise in other GNN results. The proposed WNN and GNN architectures offer practical solutions for handling graph data of varying sizes while maintaining performance guarantees without extensive retraining.","sentences":["Graph neural networks (GNNs) have become powerful tools for processing graph-based information in various domains.","A desirable property of GNNs is transferability, where a trained network can swap in information from a different graph without retraining and retain its accuracy.","A recent method of capturing transferability of GNNs is through the use of graphons, which are symmetric, measurable functions representing the limit of large dense graphs.","In this work, we contribute to the application of graphons to GNNs by presenting an explicit two-layer graphon neural network (WNN) architecture.","We prove its ability to approximate bandlimited signals within a specified error tolerance using a minimal number of network weights.","We then leverage this result, to establish the transferability of an explicit two-layer GNN over all sufficiently large graphs in a sequence converging to a graphon.","Our work addresses transferability between both deterministic weighted graphs and simple random graphs and overcomes issues related to the curse of dimensionality that arise in other GNN results.","The proposed WNN and GNN architectures offer practical solutions for handling graph data of varying sizes while maintaining performance guarantees without extensive retraining."],"url":"http://arxiv.org/abs/2307.13206v1"}
{"created":"2023-07-25 02:08:28","title":"Text-oriented Modality Reinforcement Network for Multimodal Sentiment Analysis from Unaligned Multimodal Sequences","abstract":"Multimodal Sentiment Analysis (MSA) aims to mine sentiment information from text, visual, and acoustic modalities. Previous works have focused on representation learning and feature fusion strategies. However, most of these efforts ignored the disparity in the semantic richness of different modalities and treated each modality in the same manner. That may lead to strong modalities being neglected and weak modalities being overvalued. Motivated by these observations, we propose a Text-oriented Modality Reinforcement Network (TMRN), which focuses on the dominance of the text modality in MSA. More specifically, we design a Text-Centered Cross-modal Attention (TCCA) module to make full interaction for text/acoustic and text/visual pairs, and a Text-Gated Self-Attention (TGSA) module to guide the self-reinforcement of the other two modalities. Furthermore, we present an adaptive fusion mechanism to decide the proportion of different modalities involved in the fusion process. Finally, we combine the feature matrices into vectors to get the final representation for the downstream tasks. Experimental results show that our TMRN outperforms the state-of-the-art methods on two MSA benchmarks.","sentences":["Multimodal Sentiment Analysis (MSA) aims to mine sentiment information from text, visual, and acoustic modalities.","Previous works have focused on representation learning and feature fusion strategies.","However, most of these efforts ignored the disparity in the semantic richness of different modalities and treated each modality in the same manner.","That may lead to strong modalities being neglected and weak modalities being overvalued.","Motivated by these observations, we propose a Text-oriented Modality Reinforcement Network (TMRN), which focuses on the dominance of the text modality in MSA.","More specifically, we design a Text-Centered Cross-modal Attention (TCCA) module to make full interaction for text/acoustic and text/visual pairs, and a Text-Gated Self-Attention (TGSA) module to guide the self-reinforcement of the other two modalities.","Furthermore, we present an adaptive fusion mechanism to decide the proportion of different modalities involved in the fusion process.","Finally, we combine the feature matrices into vectors to get the final representation for the downstream tasks.","Experimental results show that our TMRN outperforms the state-of-the-art methods on two MSA benchmarks."],"url":"http://arxiv.org/abs/2307.13205v1"}
{"created":"2023-07-25 02:01:12","title":"GraspGPT: Leveraging Semantic Knowledge from a Large Language Model for Task-Oriented Grasping","abstract":"Task-oriented grasping (TOG) refers to the problem of predicting grasps on an object that enable subsequent manipulation tasks. To model the complex relationships between objects, tasks, and grasps, existing methods incorporate semantic knowledge as priors into TOG pipelines. However, the existing semantic knowledge is typically constructed based on closed-world concept sets, restraining the generalization to novel concepts out of the pre-defined sets. To address this issue, we propose GraspGPT, a large language model (LLM) based TOG framework that leverages the open-end semantic knowledge from an LLM to achieve zero-shot generalization to novel concepts. We conduct experiments on Language Augmented TaskGrasp (LA-TaskGrasp) dataset and demonstrate that GraspGPT outperforms existing TOG methods on different held-out settings when generalizing to novel concepts out of the training set. The effectiveness of GraspGPT is further validated in real-robot experiments. Our code, data, appendix, and video are publicly available at https://sites.google.com/view/graspgpt/.","sentences":["Task-oriented grasping (TOG) refers to the problem of predicting grasps on an object that enable subsequent manipulation tasks.","To model the complex relationships between objects, tasks, and grasps, existing methods incorporate semantic knowledge as priors into TOG pipelines.","However, the existing semantic knowledge is typically constructed based on closed-world concept sets, restraining the generalization to novel concepts out of the pre-defined sets.","To address this issue, we propose GraspGPT, a large language model (LLM) based TOG framework that leverages the open-end semantic knowledge from an LLM to achieve zero-shot generalization to novel concepts.","We conduct experiments on Language Augmented TaskGrasp (LA-TaskGrasp) dataset and demonstrate that GraspGPT outperforms existing TOG methods on different held-out settings when generalizing to novel concepts out of the training set.","The effectiveness of GraspGPT is further validated in real-robot experiments.","Our code, data, appendix, and video are publicly available at https://sites.google.com/view/graspgpt/."],"url":"http://arxiv.org/abs/2307.13204v1"}
{"created":"2023-07-25 02:00:07","title":"Sensor selection for fine-grained behavior verification that respects privacy","abstract":"A useful capability is that of classifying some agent's behavior using data from a sequence, or trace, of sensor measurements. The sensor selection problem involves choosing a subset of available sensors to ensure that, when generated, observation traces will contain enough information to determine whether the agent's activities match some pattern. In generalizing prior work, this paper studies a formulation in which multiple behavioral itineraries may be supplied, with sensors selected to distinguish between behaviors. This allows one to pose fine grained questions, e.g., to position the agent's activity on a spectrum. In addition, with multiple itineraries, one can also ask about choices of sensors where some behavior is always plausibly concealed by (or mistaken for, or conflated with) another. Using sensor ambiguity to limit the acquisition of knowledge is a strong privacy guarantee, and one which some earlier work has examined. By concretely formulating privacy requirements for sensor selection, this paper connects both lines of work: privacy -- where there is a bound from above, and behavior verification -- where sensors are bounded from below. We examine the worst case computational complexity that results from both types of bounds, proving that upper bounds are more challenging under standard computational complexity assumptions. The problem is intractable in general, but we give a novel approach to solving this problem that can exploit interrelationships between constraints, and we see opportunities for a few optimizations. Case studies are presented to demonstrate the usefulness and scalability of our proposed solution, and to assess the impact of the optimizations.","sentences":["A useful capability is that of classifying some agent's behavior using data from a sequence, or trace, of sensor measurements.","The sensor selection problem involves choosing a subset of available sensors to ensure that, when generated, observation traces will contain enough information to determine whether the agent's activities match some pattern.","In generalizing prior work, this paper studies a formulation in which multiple behavioral itineraries may be supplied, with sensors selected to distinguish between behaviors.","This allows one to pose fine grained questions, e.g., to position the agent's activity on a spectrum.","In addition, with multiple itineraries, one can also ask about choices of sensors where some behavior is always plausibly concealed by (or mistaken for, or conflated with) another.","Using sensor ambiguity to limit the acquisition of knowledge is a strong privacy guarantee, and one which some earlier work has examined.","By concretely formulating privacy requirements for sensor selection, this paper connects both lines of work: privacy -- where there is a bound from above, and behavior verification -- where sensors are bounded from below.","We examine the worst case computational complexity that results from both types of bounds, proving that upper bounds are more challenging under standard computational complexity assumptions.","The problem is intractable in general, but we give a novel approach to solving this problem that can exploit interrelationships between constraints, and we see opportunities for a few optimizations.","Case studies are presented to demonstrate the usefulness and scalability of our proposed solution, and to assess the impact of the optimizations."],"url":"http://arxiv.org/abs/2307.13203v1"}
{"created":"2023-07-25 01:14:56","title":"Counterfactual Explanation Policies in RL","abstract":"As Reinforcement Learning (RL) agents are increasingly employed in diverse decision-making problems using reward preferences, it becomes important to ensure that policies learned by these frameworks in mapping observations to a probability distribution of the possible actions are explainable. However, there is little to no work in the systematic understanding of these complex policies in a contrastive manner, i.e., what minimal changes to the policy would improve/worsen its performance to a desired level. In this work, we present COUNTERPOL, the first framework to analyze RL policies using counterfactual explanations in the form of minimal changes to the policy that lead to the desired outcome. We do so by incorporating counterfactuals in supervised learning in RL with the target outcome regulated using desired return. We establish a theoretical connection between Counterpol and widely used trust region-based policy optimization methods in RL. Extensive empirical analysis shows the efficacy of COUNTERPOL in generating explanations for (un)learning skills while keeping close to the original policy. Our results on five different RL environments with diverse state and action spaces demonstrate the utility of counterfactual explanations, paving the way for new frontiers in designing and developing counterfactual policies.","sentences":["As Reinforcement Learning (RL) agents are increasingly employed in diverse decision-making problems using reward preferences, it becomes important to ensure that policies learned by these frameworks in mapping observations to a probability distribution of the possible actions are explainable.","However, there is little to no work in the systematic understanding of these complex policies in a contrastive manner, i.e., what minimal changes to the policy would improve/worsen its performance to a desired level.","In this work, we present COUNTERPOL, the first framework to analyze RL policies using counterfactual explanations in the form of minimal changes to the policy that lead to the desired outcome.","We do so by incorporating counterfactuals in supervised learning in RL with the target outcome regulated using desired return.","We establish a theoretical connection between Counterpol and widely used trust region-based policy optimization methods in RL.","Extensive empirical analysis shows the efficacy of COUNTERPOL in generating explanations for (un)learning skills while keeping close to the original policy.","Our results on five different RL environments with diverse state and action spaces demonstrate the utility of counterfactual explanations, paving the way for new frontiers in designing and developing counterfactual policies."],"url":"http://arxiv.org/abs/2307.13192v1"}
{"created":"2023-07-25 00:45:41","title":"Digital Emotion Regulation on Social Media","abstract":"Emotion regulation is the process of consciously altering one's affective state, that is the underlying emotional state such as happiness, confidence, guilt, anger etc. The ability to effectively regulate emotions is necessary for functioning efficiently in everyday life. Today, the pervasiveness of digital technology is being purposefully employed to modify our affective states, a process known as digital emotion regulation. Understanding digital emotion regulation can help support the rise of ethical technology design, development, and deployment. This article presents an overview of digital emotion regulation in social media applications, as well as a synthesis of recent research on emotion regulation interventions for social media. We share our findings from analysing state-of-the-art literature on how different social media applications are utilised at different stages in the process of emotion regulation.","sentences":["Emotion regulation is the process of consciously altering one's affective state, that is the underlying emotional state such as happiness, confidence, guilt, anger etc.","The ability to effectively regulate emotions is necessary for functioning efficiently in everyday life.","Today, the pervasiveness of digital technology is being purposefully employed to modify our affective states, a process known as digital emotion regulation.","Understanding digital emotion regulation can help support the rise of ethical technology design, development, and deployment.","This article presents an overview of digital emotion regulation in social media applications, as well as a synthesis of recent research on emotion regulation interventions for social media.","We share our findings from analysing state-of-the-art literature on how different social media applications are utilised at different stages in the process of emotion regulation."],"url":"http://arxiv.org/abs/2307.13187v1"}
{"created":"2023-07-25 00:42:34","title":"The BET project: Behavior-enabled IoT","abstract":"IoT is changing the way Internet is used due to the availability of a large amount of data timely collected from every-day life objects. Designing applications in this new scenario poses new challenges. This extended abstract discusses them and presents the objective of the BeT project whose main aim is to introduce a reference architecture, a conceptual framework, and related techniques to design behavior-enabled IoT systems and applications.","sentences":["IoT is changing the way Internet is used due to the availability of a large amount of data timely collected from every-day life objects.","Designing applications in this new scenario poses new challenges.","This extended abstract discusses them and presents the objective of the BeT project whose main aim is to introduce a reference architecture, a conceptual framework, and related techniques to design behavior-enabled IoT systems and applications."],"url":"http://arxiv.org/abs/2307.13186v1"}
{"created":"2023-07-25 00:25:15","title":"Curve-lifted codes for local recovery using lines","abstract":"In this paper, we introduce curve-lifted codes over fields of arbitrary characteristic, inspired by Hermitian-lifted codes over $\\mathbb{F}_{2^r}$. These codes are designed for locality and availability, and their particular parameters depend on the choice of curve and its properties. Due to the construction, the numbers of rational points of intersection between curves and lines play a key role. To demonstrate that and generate new families of locally recoverable codes (LRCs) with high availabilty, we focus on norm-trace-lifted codes. In some cases, they are easier to define than their Hermitian counterparts and consequently have a better asymptotic bound on the code rate.","sentences":["In this paper, we introduce curve-lifted codes over fields of arbitrary characteristic, inspired by Hermitian-lifted codes over $\\mathbb{F}_{2^r}$. These codes are designed for locality and availability, and their particular parameters depend on the choice of curve and its properties.","Due to the construction, the numbers of rational points of intersection between curves and lines play a key role.","To demonstrate that and generate new families of locally recoverable codes (LRCs) with high availabilty, we focus on norm-trace-lifted codes.","In some cases, they are easier to define than their Hermitian counterparts and consequently have a better asymptotic bound on the code rate."],"url":"http://arxiv.org/abs/2307.13183v1"}
{"created":"2023-07-25 00:01:10","title":"Neural Memory Decoding with EEG Data and Representation Learning","abstract":"We describe a method for the neural decoding of memory from EEG data. Using this method, a concept being recalled can be identified from an EEG trace with an average top-1 accuracy of about 78.4% (chance 4%). The method employs deep representation learning with supervised contrastive loss to map an EEG recording of brain activity to a low-dimensional space. Because representation learning is used, concepts can be identified even if they do not appear in the training data set. However, reference EEG data must exist for each such concept. We also show an application of the method to the problem of information retrieval. In neural information retrieval, EEG data is captured while a user recalls the contents of a document, and a list of links to predicted documents is produced.","sentences":["We describe a method for the neural decoding of memory from EEG data.","Using this method, a concept being recalled can be identified from an EEG trace with an average top-1 accuracy of about 78.4% (chance 4%).","The method employs deep representation learning with supervised contrastive loss to map an EEG recording of brain activity to a low-dimensional space.","Because representation learning is used, concepts can be identified even if they do not appear in the training data set.","However, reference EEG data must exist for each such concept.","We also show an application of the method to the problem of information retrieval.","In neural information retrieval, EEG data is captured while a user recalls the contents of a document, and a list of links to predicted documents is produced."],"url":"http://arxiv.org/abs/2307.13181v1"}
{"created":"2023-07-24 23:59:10","title":"Navigating the Web of Misinformation: A Framework for Misinformation Domain Detection Using Browser Traffic","abstract":"The proliferation of misinformation and propaganda is a global challenge, with profound effects during major crises such as the COVID-19 pandemic and the Russian invasion of Ukraine. Understanding the spread of misinformation and its social impacts requires identifying the news sources spreading false information. While machine learning (ML) techniques have been proposed to address this issue, ML models have failed to provide an efficient implementation scenario that yields useful results. In prior research, the precision of deployment in real traffic deteriorates significantly, experiencing a decrement up to ten times compared to the results derived from benchmark data sets. Our research addresses this gap by proposing a graph-based approach to capture navigational patterns and generate traffic-based features which are used to train a classification model. These navigational and traffic-based features result in classifiers that present outstanding performance when evaluated against real traffic. Moreover, we also propose graph-based filtering techniques to filter out models to be classified by our framework. These filtering techniques increase the signal-to-noise ratio of the models to be classified, greatly reducing false positives and the computational cost of deploying the model. Our proposed framework for the detection of misinformation domains achieves a precision of 0.78 when evaluated in real traffic. This outcome represents an improvement factor of over ten times over those achieved in previous studies.","sentences":["The proliferation of misinformation and propaganda is a global challenge, with profound effects during major crises such as the COVID-19 pandemic and the Russian invasion of Ukraine.","Understanding the spread of misinformation and its social impacts requires identifying the news sources spreading false information.","While machine learning (ML) techniques have been proposed to address this issue, ML models have failed to provide an efficient implementation scenario that yields useful results.","In prior research, the precision of deployment in real traffic deteriorates significantly, experiencing a decrement up to ten times compared to the results derived from benchmark data sets.","Our research addresses this gap by proposing a graph-based approach to capture navigational patterns and generate traffic-based features which are used to train a classification model.","These navigational and traffic-based features result in classifiers that present outstanding performance when evaluated against real traffic.","Moreover, we also propose graph-based filtering techniques to filter out models to be classified by our framework.","These filtering techniques increase the signal-to-noise ratio of the models to be classified, greatly reducing false positives and the computational cost of deploying the model.","Our proposed framework for the detection of misinformation domains achieves a precision of 0.78 when evaluated in real traffic.","This outcome represents an improvement factor of over ten times over those achieved in previous studies."],"url":"http://arxiv.org/abs/2307.13180v1"}
{"created":"2023-07-24 23:59:06","title":"A Comprehensive Bibliometric Analysis on Social Network Anonymization: Current Approaches and Future Directions","abstract":"In recent decades, social network anonymization has become a crucial research field due to its pivotal role in preserving users' privacy. However, the high diversity of approaches introduced in relevant studies poses a challenge to gaining a profound understanding of the field. In response to this, the current study presents an exhaustive and well-structured bibliometric analysis of the social network anonymization field. To begin our research, related studies from the period of 2007-2022 were collected from the Scopus Database then pre-processed. Following this, the VOSviewer was used to visualize the network of authors' keywords. Subsequently, extensive statistical and network analyses were performed to identify the most prominent keywords and trending topics. Additionally, the application of co-word analysis through SciMAT and the Alluvial diagram allowed us to explore the themes of social network anonymization and scrutinize their evolution over time. These analyses culminated in an innovative taxonomy of the existing approaches and anticipation of potential trends in this domain. To the best of our knowledge, this is the first bibliometric analysis in the social network anonymization field, which offers a deeper understanding of the current state and an insightful roadmap for future research in this domain.","sentences":["In recent decades, social network anonymization has become a crucial research field due to its pivotal role in preserving users' privacy.","However, the high diversity of approaches introduced in relevant studies poses a challenge to gaining a profound understanding of the field.","In response to this, the current study presents an exhaustive and well-structured bibliometric analysis of the social network anonymization field.","To begin our research, related studies from the period of 2007-2022 were collected from the Scopus Database then pre-processed.","Following this, the VOSviewer was used to visualize the network of authors' keywords.","Subsequently, extensive statistical and network analyses were performed to identify the most prominent keywords and trending topics.","Additionally, the application of co-word analysis through SciMAT and the Alluvial diagram allowed us to explore the themes of social network anonymization and scrutinize their evolution over time.","These analyses culminated in an innovative taxonomy of the existing approaches and anticipation of potential trends in this domain.","To the best of our knowledge, this is the first bibliometric analysis in the social network anonymization field, which offers a deeper understanding of the current state and an insightful roadmap for future research in this domain."],"url":"http://arxiv.org/abs/2307.13179v1"}
{"created":"2023-07-24 23:57:29","title":"Evaluating the reliability of automatically generated pedestrian and bicycle crash surrogates","abstract":"Vulnerable road users (VRUs), such as pedestrians and bicyclists, are at a higher risk of being involved in crashes with motor vehicles, and crashes involving VRUs also are more likely to result in severe injuries or fatalities. Signalized intersections are a major safety concern for VRUs due to their complex and dynamic nature, highlighting the need to understand how these road users interact with motor vehicles and deploy evidence-based countermeasures to improve safety performance. Crashes involving VRUs are relatively infrequent, making it difficult to understand the underlying contributing factors. An alternative is to identify and use conflicts between VRUs and motorized vehicles as a surrogate for safety performance. Automatically detecting these conflicts using a video-based systems is a crucial step in developing smart infrastructure to enhance VRU safety. The Pennsylvania Department of Transportation conducted a study using video-based event monitoring system to assess VRU and motor vehicle interactions at fifteen signalized intersections across Pennsylvania to improve VRU safety performance. This research builds on that study to assess the reliability of automatically generated surrogates in predicting confirmed conflicts using advanced data-driven models. The surrogate data used for analysis include automatically collectable variables such as vehicular and VRU speeds, movements, post-encroachment time, in addition to manually collected variables like signal states, lighting, and weather conditions. The findings highlight the varying importance of specific surrogates in predicting true conflicts, some being more informative than others. The findings can assist transportation agencies to collect the right types of data to help prioritize infrastructure investments, such as bike lanes and crosswalks, and evaluate their effectiveness.","sentences":["Vulnerable road users (VRUs), such as pedestrians and bicyclists, are at a higher risk of being involved in crashes with motor vehicles, and crashes involving VRUs also are more likely to result in severe injuries or fatalities.","Signalized intersections are a major safety concern for VRUs due to their complex and dynamic nature, highlighting the need to understand how these road users interact with motor vehicles and deploy evidence-based countermeasures to improve safety performance.","Crashes involving VRUs are relatively infrequent, making it difficult to understand the underlying contributing factors.","An alternative is to identify and use conflicts between VRUs and motorized vehicles as a surrogate for safety performance.","Automatically detecting these conflicts using a video-based systems is a crucial step in developing smart infrastructure to enhance VRU safety.","The Pennsylvania Department of Transportation conducted a study using video-based event monitoring system to assess VRU and motor vehicle interactions at fifteen signalized intersections across Pennsylvania to improve VRU safety performance.","This research builds on that study to assess the reliability of automatically generated surrogates in predicting confirmed conflicts using advanced data-driven models.","The surrogate data used for analysis include automatically collectable variables such as vehicular and VRU speeds, movements, post-encroachment time, in addition to manually collected variables like signal states, lighting, and weather conditions.","The findings highlight the varying importance of specific surrogates in predicting true conflicts, some being more informative than others.","The findings can assist transportation agencies to collect the right types of data to help prioritize infrastructure investments, such as bike lanes and crosswalks, and evaluate their effectiveness."],"url":"http://arxiv.org/abs/2307.13178v1"}
{"created":"2023-07-24 23:53:13","title":"Schema-Driven Actionable Insight Generation and Smart Recommendation","abstract":"In natural language generation (NLG), insight mining is seen as a data-to-text task, where data is mined for interesting patterns and verbalised into 'insight' statements. An 'over-generate and rank' paradigm is intuitively used to generate such insights. The multidimensionality and subjectivity of this process make it challenging. This paper introduces a schema-driven method to generate actionable insights from data to drive growth and change. It also introduces a technique to rank the insights to align with user interests based on their feedback. We show preliminary qualitative results of the insights generated using our technique and demonstrate its ability to adapt to feedback.","sentences":["In natural language generation (NLG), insight mining is seen as a data-to-text task, where data is mined for interesting patterns and verbalised into 'insight' statements.","An 'over-generate and rank' paradigm is intuitively used to generate such insights.","The multidimensionality and subjectivity of this process make it challenging.","This paper introduces a schema-driven method to generate actionable insights from data to drive growth and change.","It also introduces a technique to rank the insights to align with user interests based on their feedback.","We show preliminary qualitative results of the insights generated using our technique and demonstrate its ability to adapt to feedback."],"url":"http://arxiv.org/abs/2307.13176v1"}
{"created":"2023-07-24 23:42:32","title":"Opinion Mining Using Population-tuned Generative Language Models","abstract":"We present a novel method for mining opinions from text collections using generative language models trained on data collected from different populations. We describe the basic definitions, methodology and a generic algorithm for opinion insight mining. We demonstrate the performance of our method in an experiment where a pre-trained generative model is fine-tuned using specifically tailored content with unnatural and fully annotated opinions. We show that our approach can learn and transfer the opinions to the semantic classes while maintaining the proportion of polarisation. Finally, we demonstrate the usage of an insight mining system to scale up the discovery of opinion insights from a real text corpus.","sentences":["We present a novel method for mining opinions from text collections using generative language models trained on data collected from different populations.","We describe the basic definitions, methodology and a generic algorithm for opinion insight mining.","We demonstrate the performance of our method in an experiment where a pre-trained generative model is fine-tuned using specifically tailored content with unnatural and fully annotated opinions.","We show that our approach can learn and transfer the opinions to the semantic classes while maintaining the proportion of polarisation.","Finally, we demonstrate the usage of an insight mining system to scale up the discovery of opinion insights from a real text corpus."],"url":"http://arxiv.org/abs/2307.13173v1"}
{"created":"2023-07-24 23:37:50","title":"HasTEE: Programming Trusted Execution Environments with Haskell","abstract":"Trusted Execution Environments (TEEs) are hardware-enforced memory isolation units, emerging as a pivotal security solution for security-critical applications. TEEs, like Intel SGX and ARM TrustZone, allow the isolation of confidential code and data within an untrusted host environment, such as the cloud and IoT. Despite strong security guarantees, TEE adoption has been hindered by an awkward programming model. This model requires manual application partitioning and the use of error-prone, memory-unsafe, and potentially information-leaking low-level C/C++ libraries.   We address the above with \\textit{HasTEE}, a domain-specific language (DSL) embedded in Haskell for programming TEE applications. HasTEE includes a port of the GHC runtime for the Intel-SGX TEE. HasTEE uses Haskell's type system to automatically partition an application and to enforce \\textit{Information Flow Control} on confidential data. The DSL, being embedded in Haskell, allows for the usage of higher-order functions, monads, and a restricted set of I/O operations to write any standard Haskell application. Contrary to previous work, HasTEE is lightweight, simple, and is provided as a \\emph{simple security library}; thus avoiding any GHC modifications. We show the applicability of HasTEE by implementing case studies on federated learning, an encrypted password wallet, and a differentially-private data clean room.","sentences":["Trusted Execution Environments (TEEs) are hardware-enforced memory isolation units, emerging as a pivotal security solution for security-critical applications.","TEEs, like Intel SGX and ARM TrustZone, allow the isolation of confidential code and data within an untrusted host environment, such as the cloud and IoT.","Despite strong security guarantees, TEE adoption has been hindered by an awkward programming model.","This model requires manual application partitioning and the use of error-prone, memory-unsafe, and potentially information-leaking low-level C/C++ libraries.   ","We address the above with \\textit{HasTEE}, a domain-specific language (DSL) embedded in Haskell for programming TEE applications.","HasTEE includes a port of the GHC runtime for the Intel-SGX TEE.","HasTEE uses Haskell's type system to automatically partition an application and to enforce \\textit{Information Flow Control} on confidential data.","The DSL, being embedded in Haskell, allows for the usage of higher-order functions, monads, and a restricted set of I/O operations to write any standard Haskell application.","Contrary to previous work, HasTEE is lightweight, simple, and is provided as a \\emph{simple security library}; thus avoiding any GHC modifications.","We show the applicability of HasTEE by implementing case studies on federated learning, an encrypted password wallet, and a differentially-private data clean room."],"url":"http://arxiv.org/abs/2307.13172v1"}
