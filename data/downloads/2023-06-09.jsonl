{"created":"2023-06-08","title":"Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models","abstract":"Conversation agents fueled by Large Language Models (LLMs) are providing a new way to interact with visual data. While there have been initial attempts for image-based conversation models, this work addresses the underexplored field of video-based conversation by introducing Video-ChatGPT. It is a multimodal model that merges a video-adapted visual encoder with a LLM. The model is capable of understanding and generating human-like conversations about videos. We introduce a new dataset of 100,000 video-instruction pairs used to train Video-ChatGPT acquired via manual and semi-automated pipeline that is easily scalable and robust to label noise. We also develop a quantiative evaluation framework for video-based dialogue models to objectively analyse the strengths and weaknesses of proposed models. Our code, models, instruction-sets and demo are released at https://github.com/mbzuai-oryx/Video-ChatGPT.","sentences":["Conversation agents fueled by Large Language Models (LLMs) are providing a new way to interact with visual data.","While there have been initial attempts for image-based conversation models, this work addresses the underexplored field of video-based conversation by introducing Video-ChatGPT.","It is a multimodal model that merges a video-adapted visual encoder with a LLM.","The model is capable of understanding and generating human-like conversations about videos.","We introduce a new dataset of 100,000 video-instruction pairs used to train Video-ChatGPT acquired via manual and semi-automated pipeline that is easily scalable and robust to label noise.","We also develop a quantiative evaluation framework for video-based dialogue models to objectively analyse the strengths and weaknesses of proposed models.","Our code, models, instruction-sets and demo are released at https://github.com/mbzuai-oryx/Video-ChatGPT."],"url":"http://arxiv.org/abs/2306.05424v1"}
{"created":"2023-06-08","title":"Closing the Loop: Testing ChatGPT to Generate Model Explanations to Improve Human Labelling of Sponsored Content on Social Media","abstract":"Regulatory bodies worldwide are intensifying their efforts to ensure transparency in influencer marketing on social media through instruments like the Unfair Commercial Practices Directive (UCPD) in the European Union, or Section 5 of the Federal Trade Commission Act. Yet enforcing these obligations has proven to be highly problematic due to the sheer scale of the influencer market. The task of automatically detecting sponsored content aims to enable the monitoring and enforcement of such regulations at scale. Current research in this field primarily frames this problem as a machine learning task, focusing on developing models that achieve high classification performance in detecting ads. These machine learning tasks rely on human data annotation to provide ground truth information. However, agreement between annotators is often low, leading to inconsistent labels that hinder the reliability of models. To improve annotation accuracy and, thus, the detection of sponsored content, we propose using chatGPT to augment the annotation process with phrases identified as relevant features and brief explanations. Our experiments show that this approach consistently improves inter-annotator agreement and annotation accuracy. Additionally, our survey of user experience in the annotation task indicates that the explanations improve the annotators' confidence and streamline the process. Our proposed methods can ultimately lead to more transparency and alignment with regulatory requirements in sponsored content detection.","sentences":["Regulatory bodies worldwide are intensifying their efforts to ensure transparency in influencer marketing on social media through instruments like the Unfair Commercial Practices Directive (UCPD) in the European Union, or Section 5 of the Federal Trade Commission Act.","Yet enforcing these obligations has proven to be highly problematic due to the sheer scale of the influencer market.","The task of automatically detecting sponsored content aims to enable the monitoring and enforcement of such regulations at scale.","Current research in this field primarily frames this problem as a machine learning task, focusing on developing models that achieve high classification performance in detecting ads.","These machine learning tasks rely on human data annotation to provide ground truth information.","However, agreement between annotators is often low, leading to inconsistent labels that hinder the reliability of models.","To improve annotation accuracy and, thus, the detection of sponsored content, we propose using chatGPT to augment the annotation process with phrases identified as relevant features and brief explanations.","Our experiments show that this approach consistently improves inter-annotator agreement and annotation accuracy.","Additionally, our survey of user experience in the annotation task indicates that the explanations improve the annotators' confidence and streamline the process.","Our proposed methods can ultimately lead to more transparency and alignment with regulatory requirements in sponsored content detection."],"url":"http://arxiv.org/abs/2306.05115v1"}
{"created":"2023-06-08","title":"Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Cost-Efficient Question Answering","abstract":"Large language models (LLMs), such as ChatGPT and GPT-4, are gaining wide-spread real world use. Yet, the two LLMs are closed source, and little is known about the LLMs' performance in real-world use cases. In academia, LLM performance is often measured on benchmarks which may have leaked into ChatGPT's and GPT-4's training data. In this paper, we apply and evaluate ChatGPT and GPT-4 for the real-world task of cost-efficient extractive question answering over a text corpus that was published after the two LLMs completed training. More specifically, we extract research challenges for researchers in the field of HCI from the proceedings of the 2023 Conference on Human Factors in Computing Systems (CHI). We critically evaluate the LLMs on this practical task and conclude that the combination of ChatGPT and GPT-4 makes an excellent cost-efficient means for analyzing a text corpus at scale. Cost-efficiency is key for prototyping research ideas and analyzing text corpora from different perspectives, with implications for applying LLMs in academia and practice. For researchers in HCI, we contribute an interactive visualization of 4392 research challenges in over 90 research topics. We share this visualization and the dataset in the spirit of open science.","sentences":["Large language models (LLMs), such as ChatGPT and GPT-4, are gaining wide-spread real world use.","Yet, the two LLMs are closed source, and little is known about the LLMs' performance in real-world use cases.","In academia, LLM performance is often measured on benchmarks which may have leaked into ChatGPT's and GPT-4's training data.","In this paper, we apply and evaluate ChatGPT and GPT-4 for the real-world task of cost-efficient extractive question answering over a text corpus that was published after the two LLMs completed training.","More specifically, we extract research challenges for researchers in the field of HCI from the proceedings of the 2023 Conference on Human Factors in Computing Systems (CHI).","We critically evaluate the LLMs on this practical task and conclude that the combination of ChatGPT and GPT-4 makes an excellent cost-efficient means for analyzing a text corpus at scale.","Cost-efficiency is key for prototyping research ideas and analyzing text corpora from different perspectives, with implications for applying LLMs in academia and practice.","For researchers in HCI, we contribute an interactive visualization of 4392 research challenges in over 90 research topics.","We share this visualization and the dataset in the spirit of open science."],"url":"http://arxiv.org/abs/2306.05036v1"}
{"created":"2023-06-08","title":"Cash, Credibility, and Conversion: The Influence of Synthetic Media on Investment Behavior","abstract":"Prior to November of 2022, the topic of synthetic media was largely buried within academic journals, constrained to conversations about national security, and often fundamentally misunderstood. The release of ChatGPT, however, has accelerated discourse on the societal impacts of synthetic media. This study first highlights several gaps within existing literature on synthetic media, structuring the impact potential and limitations of synthetic media threats within a theoretical framework. Second, it identifies financial information environments as prime candidates for future disruption via synthetic text modalities, proposing an experimental survey for measuring the influential power of synthetic financial text on global investment communities. Rather than merely assessing the ability of survey participants to distinguish genuine from synthetic text, the experiment contained within this study measures synthetic media influence by observing its ability to manipulate belief via a series of behavioral variables. The results indicate that synthetic text can significantly shift investor sentiment away from what it might otherwise have been under truthful information conditions. Furthermore, synthetic financial text demonstrated a unique ability to \"convert\" investors, inspiring extreme changes in outlook about a company compared to genuine financial texts. This trend should inspire concern within the global financial community, particularly given the historical vulnerability of equity markets to investor sentiment shocks.","sentences":["Prior to November of 2022, the topic of synthetic media was largely buried within academic journals, constrained to conversations about national security, and often fundamentally misunderstood.","The release of ChatGPT, however, has accelerated discourse on the societal impacts of synthetic media.","This study first highlights several gaps within existing literature on synthetic media, structuring the impact potential and limitations of synthetic media threats within a theoretical framework.","Second, it identifies financial information environments as prime candidates for future disruption via synthetic text modalities, proposing an experimental survey for measuring the influential power of synthetic financial text on global investment communities.","Rather than merely assessing the ability of survey participants to distinguish genuine from synthetic text, the experiment contained within this study measures synthetic media influence by observing its ability to manipulate belief via a series of behavioral variables.","The results indicate that synthetic text can significantly shift investor sentiment away from what it might otherwise have been under truthful information conditions.","Furthermore, synthetic financial text demonstrated a unique ability to \"convert\" investors, inspiring extreme changes in outlook about a company compared to genuine financial texts.","This trend should inspire concern within the global financial community, particularly given the historical vulnerability of equity markets to investor sentiment shocks."],"url":"http://arxiv.org/abs/2306.05033v1"}
{"created":"2023-06-08","title":"Scalable and Adaptive Log-based Anomaly Detection with Expert in the Loop","abstract":"System logs play a critical role in maintaining the reliability of software systems. Fruitful studies have explored automatic log-based anomaly detection and achieved notable accuracy on benchmark datasets. However, when applied to large-scale cloud systems, these solutions face limitations due to high resource consumption and lack of adaptability to evolving logs. In this paper, we present an accurate, lightweight, and adaptive log-based anomaly detection framework, referred to as SeaLog. Our method introduces a Trie-based Detection Agent (TDA) that employs a lightweight, dynamically-growing trie structure for real-time anomaly detection. To enhance TDA's accuracy in response to evolving log data, we enable it to receive feedback from experts. Interestingly, our findings suggest that contemporary large language models, such as ChatGPT, can provide feedback with a level of consistency comparable to human experts, which can potentially reduce manual verification efforts. We extensively evaluate SeaLog on two public datasets and an industrial dataset. The results show that SeaLog outperforms all baseline methods in terms of effectiveness, runs 2X to 10X faster and only consumes 5% to 41% of the memory resource.","sentences":["System logs play a critical role in maintaining the reliability of software systems.","Fruitful studies have explored automatic log-based anomaly detection and achieved notable accuracy on benchmark datasets.","However, when applied to large-scale cloud systems, these solutions face limitations due to high resource consumption and lack of adaptability to evolving logs.","In this paper, we present an accurate, lightweight, and adaptive log-based anomaly detection framework, referred to as SeaLog.","Our method introduces a Trie-based Detection Agent (TDA) that employs a lightweight, dynamically-growing trie structure for real-time anomaly detection.","To enhance TDA's accuracy in response to evolving log data, we enable it to receive feedback from experts.","Interestingly, our findings suggest that contemporary large language models, such as ChatGPT, can provide feedback with a level of consistency comparable to human experts, which can potentially reduce manual verification efforts.","We extensively evaluate SeaLog on two public datasets and an industrial dataset.","The results show that SeaLog outperforms all baseline methods in terms of effectiveness, runs 2X to 10X faster and only consumes 5% to 41% of the memory resource."],"url":"http://arxiv.org/abs/2306.05032v1"}
{"created":"2023-06-08","title":"Assessing Phrase Break of ESL Speech with Pre-trained Language Models and Large Language Models","abstract":"This work introduces approaches to assessing phrase breaks in ESL learners' speech using pre-trained language models (PLMs) and large language models (LLMs). There are two tasks: overall assessment of phrase break for a speech clip and fine-grained assessment of every possible phrase break position. To leverage NLP models, speech input is first force-aligned with texts, and then pre-processed into a token sequence, including words and phrase break information. To utilize PLMs, we propose a pre-training and fine-tuning pipeline with the processed tokens. This process includes pre-training with a replaced break token detection module and fine-tuning with text classification and sequence labeling. To employ LLMs, we design prompts for ChatGPT. The experiments show that with the PLMs, the dependence on labeled training data has been greatly reduced, and the performance has improved. Meanwhile, we verify that ChatGPT, a renowned LLM, has potential for further advancement in this area.","sentences":["This work introduces approaches to assessing phrase breaks in ESL learners' speech using pre-trained language models (PLMs) and large language models (LLMs).","There are two tasks: overall assessment of phrase break for a speech clip and fine-grained assessment of every possible phrase break position.","To leverage NLP models, speech input is first force-aligned with texts, and then pre-processed into a token sequence, including words and phrase break information.","To utilize PLMs, we propose a pre-training and fine-tuning pipeline with the processed tokens.","This process includes pre-training with a replaced break token detection module and fine-tuning with text classification and sequence labeling.","To employ LLMs, we design prompts for ChatGPT.","The experiments show that with the PLMs, the dependence on labeled training data has been greatly reduced, and the performance has improved.","Meanwhile, we verify that ChatGPT, a renowned LLM, has potential for further advancement in this area."],"url":"http://arxiv.org/abs/2306.04980v1"}
{"created":"2023-06-08","title":"covLLM: Large Language Models for COVID-19 Biomedical Literature","abstract":"The COVID-19 pandemic led to 1.1 million deaths in the United States, despite the explosion of coronavirus research. These new findings are slow to translate to clinical interventions, leading to poorer patient outcomes and unnecessary deaths. One reason is that clinicians, overwhelmed by patients, struggle to keep pace with the rate of new coronavirus literature. A potential solution is developing a tool for evaluating coronavirus literature using large language models (LLMs) -- neural networks that are deployed for natural language processing. LLMs can be used to summarize and extract user-specified information. The greater availability and advancement of LLMs and pre-processed coronavirus literature databases provide the opportunity to assist clinicians in evaluating coronavirus literature through a coronavirus literature specific LLM (covLLM), a tool that directly takes an inputted research article and a user query to return an answer. Using the COVID-19 Open Research Dataset (CORD-19), we produced two datasets: (1) synCovid, which uses a combination of handwritten prompts and synthetic prompts generated using OpenAI, and (2) real abstracts, which contains abstract and title pairs. covLLM was trained with LLaMA 7B as a baseline model to produce three models trained on (1) the Alpaca and synCovid datasets, (2) the synCovid dataset, and (3) the synCovid and real abstract datasets. These models were evaluated by two human evaluators and ChatGPT. Results demonstrate that training covLLM on the synCovid and abstract pairs datasets performs competitively with ChatGPT and outperforms covLLM trained primarily using the Alpaca dataset.","sentences":["The COVID-19 pandemic led to 1.1 million deaths in the United States, despite the explosion of coronavirus research.","These new findings are slow to translate to clinical interventions, leading to poorer patient outcomes and unnecessary deaths.","One reason is that clinicians, overwhelmed by patients, struggle to keep pace with the rate of new coronavirus literature.","A potential solution is developing a tool for evaluating coronavirus literature using large language models (LLMs) -- neural networks that are deployed for natural language processing.","LLMs can be used to summarize and extract user-specified information.","The greater availability and advancement of LLMs and pre-processed coronavirus literature databases provide the opportunity to assist clinicians in evaluating coronavirus literature through a coronavirus literature specific LLM (covLLM), a tool that directly takes an inputted research article and a user query to return an answer.","Using the COVID-19 Open Research Dataset (CORD-19), we produced two datasets: (1) synCovid, which uses a combination of handwritten prompts and synthetic prompts generated using OpenAI, and (2) real abstracts, which contains abstract and title pairs.","covLLM was trained with LLaMA 7B as a baseline model to produce three models trained on (1) the Alpaca and synCovid datasets, (2) the synCovid dataset, and (3) the synCovid and real abstract datasets.","These models were evaluated by two human evaluators and ChatGPT.","Results demonstrate that training covLLM on the synCovid and abstract pairs datasets performs competitively with ChatGPT and outperforms covLLM trained primarily using the Alpaca dataset."],"url":"http://arxiv.org/abs/2306.04926v1"}
{"created":"2023-06-08","title":"Grounded Text-to-Image Synthesis with Attention Refocusing","abstract":"Driven by scalable diffusion models trained on large-scale paired text-image datasets, text-to-image synthesis methods have shown compelling results. However, these models still fail to precisely follow the text prompt when multiple objects, attributes, and spatial compositions are involved in the prompt. In this paper, we identify the potential reasons in both the cross-attention and self-attention layers of the diffusion model. We propose two novel losses to refocus the attention maps according to a given layout during the sampling process. We perform comprehensive experiments on the DrawBench and HRS benchmarks using layouts synthesized by Large Language Models, showing that our proposed losses can be integrated easily and effectively into existing text-to-image methods and consistently improve their alignment between the generated images and the text prompts.","sentences":["Driven by scalable diffusion models trained on large-scale paired text-image datasets, text-to-image synthesis methods have shown compelling results.","However, these models still fail to precisely follow the text prompt when multiple objects, attributes, and spatial compositions are involved in the prompt.","In this paper, we identify the potential reasons in both the cross-attention and self-attention layers of the diffusion model.","We propose two novel losses to refocus the attention maps according to a given layout during the sampling process.","We perform comprehensive experiments on the DrawBench and HRS benchmarks using layouts synthesized by Large Language Models, showing that our proposed losses can be integrated easily and effectively into existing text-to-image methods and consistently improve their alignment between the generated images and the text prompts."],"url":"http://arxiv.org/abs/2306.05427v1"}
{"created":"2023-06-08","title":"Background Prompting for Improved Object Depth","abstract":"Estimating the depth of objects from a single image is a valuable task for many vision, robotics, and graphics applications. However, current methods often fail to produce accurate depth for objects in diverse scenes. In this work, we propose a simple yet effective Background Prompting strategy that adapts the input object image with a learned background. We learn the background prompts only using small-scale synthetic object datasets. To infer object depth on a real image, we place the segmented object into the learned background prompt and run off-the-shelf depth networks. Background Prompting helps the depth networks focus on the foreground object, as they are made invariant to background variations. Moreover, Background Prompting minimizes the domain gap between synthetic and real object images, leading to better sim2real generalization than simple finetuning. Results on multiple synthetic and real datasets demonstrate consistent improvements in real object depths for a variety of existing depth networks. Code and optimized background prompts can be found at: https://mbaradad.github.io/depth_prompt.","sentences":["Estimating the depth of objects from a single image is a valuable task for many vision, robotics, and graphics applications.","However, current methods often fail to produce accurate depth for objects in diverse scenes.","In this work, we propose a simple yet effective Background Prompting strategy that adapts the input object image with a learned background.","We learn the background prompts only using small-scale synthetic object datasets.","To infer object depth on a real image, we place the segmented object into the learned background prompt and run off-the-shelf depth networks.","Background Prompting helps the depth networks focus on the foreground object, as they are made invariant to background variations.","Moreover, Background Prompting minimizes the domain gap between synthetic and real object images, leading to better sim2real generalization than simple finetuning.","Results on multiple synthetic and real datasets demonstrate consistent improvements in real object depths for a variety of existing depth networks.","Code and optimized background prompts can be found at: https://mbaradad.github.io/depth_prompt."],"url":"http://arxiv.org/abs/2306.05428v1"}
{"created":"2023-06-08","title":"SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling with Backtracking","abstract":"In many domains, autoregressive models can achieve low log-likelihood on the task of predicting the next observation. However, this maximum-likelihood (MLE) objective does not necessarily match a downstream use-case of autoregressively generating high-quality sequences. The MLE objective weights sequences proportionally to their frequency under the data distribution, with no guidance for the model's behaviour out of distribution (OOD): leading to compounding error during autoregressive generation. In order to address this compounding error problem, we formulate sequence generation as an imitation learning (IL) problem. This allows us to minimize a variety of divergences between the distribution of sequences generated by an autoregressive model and sequences from a dataset, including divergences with weight on OOD generated sequences. The IL framework also allows us to incorporate backtracking by introducing a backspace action into the generation process. This further mitigates the compounding error problem by allowing the model to revert a sampled token if it takes the sequence OOD. Our resulting method, SequenceMatch, can be implemented without adversarial training or major architectural changes. We identify the SequenceMatch-$\\chi^2$ divergence as a more suitable training objective for autoregressive models which are used for generation. We show that empirically, SequenceMatch training leads to improvements over MLE on text generation with language models.","sentences":["In many domains, autoregressive models can achieve low log-likelihood on the task of predicting the next observation.","However, this maximum-likelihood (MLE) objective does not necessarily match a downstream use-case of autoregressively generating high-quality sequences.","The MLE objective weights sequences proportionally to their frequency under the data distribution, with no guidance for the model's behaviour out of distribution (OOD): leading to compounding error during autoregressive generation.","In order to address this compounding error problem, we formulate sequence generation as an imitation learning (IL) problem.","This allows us to minimize a variety of divergences between the distribution of sequences generated by an autoregressive model and sequences from a dataset, including divergences with weight on OOD generated sequences.","The IL framework also allows us to incorporate backtracking by introducing a backspace action into the generation process.","This further mitigates the compounding error problem by allowing the model to revert a sampled token if it takes the sequence OOD.","Our resulting method, SequenceMatch, can be implemented without adversarial training or major architectural changes.","We identify the SequenceMatch-$\\chi^2$ divergence as a more suitable training objective for autoregressive models which are used for generation.","We show that empirically, SequenceMatch training leads to improvements over MLE on text generation with language models."],"url":"http://arxiv.org/abs/2306.05426v1"}
{"created":"2023-06-08","title":"Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models","abstract":"Conversation agents fueled by Large Language Models (LLMs) are providing a new way to interact with visual data. While there have been initial attempts for image-based conversation models, this work addresses the underexplored field of video-based conversation by introducing Video-ChatGPT. It is a multimodal model that merges a video-adapted visual encoder with a LLM. The model is capable of understanding and generating human-like conversations about videos. We introduce a new dataset of 100,000 video-instruction pairs used to train Video-ChatGPT acquired via manual and semi-automated pipeline that is easily scalable and robust to label noise. We also develop a quantiative evaluation framework for video-based dialogue models to objectively analyse the strengths and weaknesses of proposed models. Our code, models, instruction-sets and demo are released at https://github.com/mbzuai-oryx/Video-ChatGPT.","sentences":["Conversation agents fueled by Large Language Models (LLMs) are providing a new way to interact with visual data.","While there have been initial attempts for image-based conversation models, this work addresses the underexplored field of video-based conversation by introducing Video-ChatGPT.","It is a multimodal model that merges a video-adapted visual encoder with a LLM.","The model is capable of understanding and generating human-like conversations about videos.","We introduce a new dataset of 100,000 video-instruction pairs used to train Video-ChatGPT acquired via manual and semi-automated pipeline that is easily scalable and robust to label noise.","We also develop a quantiative evaluation framework for video-based dialogue models to objectively analyse the strengths and weaknesses of proposed models.","Our code, models, instruction-sets and demo are released at https://github.com/mbzuai-oryx/Video-ChatGPT."],"url":"http://arxiv.org/abs/2306.05424v1"}
{"created":"2023-06-08","title":"MIMIC-IT: Multi-Modal In-Context Instruction Tuning","abstract":"High-quality instructions and responses are essential for the zero-shot performance of large language models on interactive natural language tasks. For interactive vision-language tasks involving intricate visual scenes, a large quantity of diverse and creative instruction-response pairs should be imperative to tune vision-language models (VLMs). Nevertheless, the current availability of vision-language instruction-response pairs in terms of quantity, diversity, and creativity remains limited, posing challenges to the generalization of interactive VLMs. Here we present MultI-Modal In-Context Instruction Tuning (MIMIC-IT), a dataset comprising 2.8 million multimodal instruction-response pairs, with 2.2 million unique instructions derived from images and videos. Each pair is accompanied by multi-modal in-context information, forming conversational contexts aimed at empowering VLMs in perception, reasoning, and planning. The instruction-response collection process, dubbed as Syphus, is scaled using an automatic annotation pipeline that combines human expertise with GPT's capabilities. Using the MIMIC-IT dataset, we train a large VLM named Otter. Based on extensive evaluations conducted on vision-language benchmarks, it has been observed that Otter demonstrates remarkable proficiency in multi-modal perception, reasoning, and in-context learning. Human evaluation reveals it effectively aligns with the user's intentions. We release the MIMIC-IT dataset, instruction-response collection pipeline, benchmarks, and the Otter model.","sentences":["High-quality instructions and responses are essential for the zero-shot performance of large language models on interactive natural language tasks.","For interactive vision-language tasks involving intricate visual scenes, a large quantity of diverse and creative instruction-response pairs should be imperative to tune vision-language models (VLMs).","Nevertheless, the current availability of vision-language instruction-response pairs in terms of quantity, diversity, and creativity remains limited, posing challenges to the generalization of interactive VLMs.","Here we present MultI-Modal In-Context Instruction Tuning (MIMIC-IT), a dataset comprising 2.8 million multimodal instruction-response pairs, with 2.2 million unique instructions derived from images and videos.","Each pair is accompanied by multi-modal in-context information, forming conversational contexts aimed at empowering VLMs in perception, reasoning, and planning.","The instruction-response collection process, dubbed as Syphus, is scaled using an automatic annotation pipeline that combines human expertise with GPT's capabilities.","Using the MIMIC-IT dataset, we train a large VLM named Otter.","Based on extensive evaluations conducted on vision-language benchmarks, it has been observed that Otter demonstrates remarkable proficiency in multi-modal perception, reasoning, and in-context learning.","Human evaluation reveals it effectively aligns with the user's intentions.","We release the MIMIC-IT dataset, instruction-response collection pipeline, benchmarks, and the Otter model."],"url":"http://arxiv.org/abs/2306.05425v1"}
{"created":"2023-06-08","title":"2D Supervised Monocular 3D Object Detection by Global-to-Local 3D Reconstruction","abstract":"With the advent of the big model era, the demand for data has become more important. Especially in monocular 3D object detection, expensive manual annotations potentially limit further developments. Existing works have investigated weakly supervised algorithms with the help of LiDAR modality to generate 3D pseudo labels, which cannot be applied to ordinary videos. In this paper, we propose a novel paradigm, termed as BA$^2$-Det, leveraging the idea of global-to-local 3D reconstruction for 2D supervised monocular 3D object detection. Specifically, we recover 3D structures from monocular videos by scene-level global reconstruction with global bundle adjustment (BA) and obtain object clusters by the DoubleClustering algorithm. Learning from completely reconstructed objects in global BA, GBA-Learner predicts pseudo labels for occluded objects. Finally, we train an LBA-Learner with object-centric local BA to generalize the generated 3D pseudo labels to moving objects. Experiments on the large-scale Waymo Open Dataset show that the performance of BA$^2$-Det is on par with the fully-supervised BA-Det trained with 10% videos and even outperforms some pioneer fully-supervised methods. We also show the great potential of BA$^2$-Det for detecting open-set 3D objects in complex scenes. The code will be made available. Project page: https://ba2det.site .","sentences":["With the advent of the big model era, the demand for data has become more important.","Especially in monocular 3D object detection, expensive manual annotations potentially limit further developments.","Existing works have investigated weakly supervised algorithms with the help of LiDAR modality to generate 3D pseudo labels, which cannot be applied to ordinary videos.","In this paper, we propose a novel paradigm, termed as BA$^2$-Det, leveraging the idea of global-to-local 3D reconstruction for 2D supervised monocular 3D object detection.","Specifically, we recover 3D structures from monocular videos by scene-level global reconstruction with global bundle adjustment (BA) and obtain object clusters by the DoubleClustering algorithm.","Learning from completely reconstructed objects in global BA, GBA-Learner predicts pseudo labels for occluded objects.","Finally, we train an LBA-Learner with object-centric local BA to generalize the generated 3D pseudo labels to moving objects.","Experiments on the large-scale Waymo Open Dataset show that the performance of BA$^2$-Det is on par with the fully-supervised BA-Det trained with 10% videos and even outperforms some pioneer fully-supervised methods.","We also show the great potential of BA$^2$-Det for detecting open-set 3D objects in complex scenes.","The code will be made available.","Project page: https://ba2det.site ."],"url":"http://arxiv.org/abs/2306.05418v1"}
{"created":"2023-06-08","title":"TopoMask: Instance-Mask-Based Formulation for the Road Topology Problem via Transformer-Based Architecture","abstract":"Driving scene understanding task involves detecting static elements such as lanes, traffic signs, and traffic lights, and their relationships with each other. To facilitate the development of comprehensive scene understanding solutions using multiple camera views, a new dataset called Road Genome (OpenLane-V2) has been released. This dataset allows for the exploration of complex road connections and situations where lane markings may be absent. Instead of using traditional lane markings, the lanes in this dataset are represented by centerlines, which offer a more suitable representation of lanes and their connections. In this study, we have introduced a new approach called TopoMask for predicting centerlines in road topology. Unlike existing approaches in the literature that rely on keypoints or parametric methods, TopoMask utilizes an instance-mask based formulation with a transformer-based architecture and, in order to enrich the mask instances with flow information, a direction label representation is proposed. TopoMask have ranked 4th in the OpenLane-V2 Score (OLS) and ranked 2nd in the F1 score of centerline prediction in OpenLane Topology Challenge 2023. In comparison to the current state-of-the-art method, TopoNet, the proposed method has achieved similar performance in Frechet-based lane detection and outperformed TopoNet in Chamfer-based lane detection without utilizing its scene graph neural network.","sentences":["Driving scene understanding task involves detecting static elements such as lanes, traffic signs, and traffic lights, and their relationships with each other.","To facilitate the development of comprehensive scene understanding solutions using multiple camera views, a new dataset called Road Genome (OpenLane-V2) has been released.","This dataset allows for the exploration of complex road connections and situations where lane markings may be absent.","Instead of using traditional lane markings, the lanes in this dataset are represented by centerlines, which offer a more suitable representation of lanes and their connections.","In this study, we have introduced a new approach called TopoMask for predicting centerlines in road topology.","Unlike existing approaches in the literature that rely on keypoints or parametric methods, TopoMask utilizes an instance-mask based formulation with a transformer-based architecture and, in order to enrich the mask instances with flow information, a direction label representation is proposed.","TopoMask have ranked 4th in the OpenLane-V2 Score (OLS) and ranked 2nd in the F1 score of centerline prediction in OpenLane Topology Challenge 2023.","In comparison to the current state-of-the-art method, TopoNet, the proposed method has achieved similar performance in Frechet-based lane detection and outperformed TopoNet in Chamfer-based lane detection without utilizing its scene graph neural network."],"url":"http://arxiv.org/abs/2306.05419v1"}
{"created":"2023-06-08","title":"Tracking Objects with 3D Representation from Videos","abstract":"Data association is a knotty problem for 2D Multiple Object Tracking due to the object occlusion. However, in 3D space, data association is not so hard. Only with a 3D Kalman Filter, the online object tracker can associate the detections from LiDAR. In this paper, we rethink the data association in 2D MOT and utilize the 3D object representation to separate each object in the feature space. Unlike the existing depth-based MOT methods, the 3D object representation can be jointly learned with the object association module. Besides, the object's 3D representation is learned from the video and supervised by the 2D tracking labels without additional manual annotations from LiDAR or pretrained depth estimator. With 3D object representation learning from Pseudo 3D object labels in monocular videos, we propose a new 2D MOT paradigm, called P3DTrack. Extensive experiments show the effectiveness of our method. We achieve new state-of-the-art performance on the large-scale Waymo Open Dataset.","sentences":["Data association is a knotty problem for 2D Multiple Object Tracking due to the object occlusion.","However, in 3D space, data association is not so hard.","Only with a 3D Kalman Filter, the online object tracker can associate the detections from LiDAR.","In this paper, we rethink the data association in 2D MOT and utilize the 3D object representation to separate each object in the feature space.","Unlike the existing depth-based MOT methods, the 3D object representation can be jointly learned with the object association module.","Besides, the object's 3D representation is learned from the video and supervised by the 2D tracking labels without additional manual annotations from LiDAR or pretrained depth estimator.","With 3D object representation learning from Pseudo 3D object labels in monocular videos, we propose a new 2D MOT paradigm, called P3DTrack.","Extensive experiments show the effectiveness of our method.","We achieve new state-of-the-art performance on the large-scale Waymo Open Dataset."],"url":"http://arxiv.org/abs/2306.05416v1"}
{"created":"2023-06-08","title":"Mixture-of-Domain-Adapters: Decoupling and Injecting Domain Knowledge to Pre-trained Language Models Memories","abstract":"Pre-trained language models (PLMs) demonstrate excellent abilities to understand texts in the generic domain while struggling in a specific domain. Although continued pre-training on a large domain-specific corpus is effective, it is costly to tune all the parameters on the domain. In this paper, we investigate whether we can adapt PLMs both effectively and efficiently by only tuning a few parameters. Specifically, we decouple the feed-forward networks (FFNs) of the Transformer architecture into two parts: the original pre-trained FFNs to maintain the old-domain knowledge and our novel domain-specific adapters to inject domain-specific knowledge in parallel. Then we adopt a mixture-of-adapters gate to fuse the knowledge from different domain adapters dynamically. Our proposed Mixture-of-Domain-Adapters (MixDA) employs a two-stage adapter-tuning strategy that leverages both unlabeled data and labeled data to help the domain adaptation: i) domain-specific adapter on unlabeled data; followed by ii) the task-specific adapter on labeled data. MixDA can be seamlessly plugged into the pretraining-finetuning paradigm and our experiments demonstrate that MixDA achieves superior performance on in-domain tasks (GLUE), out-of-domain tasks (ChemProt, RCT, IMDB, Amazon), and knowledge-intensive tasks (KILT). Further analyses demonstrate the reliability, scalability, and efficiency of our method. The code is available at https://github.com/Amano-Aki/Mixture-of-Domain-Adapters.","sentences":["Pre-trained language models (PLMs) demonstrate excellent abilities to understand texts in the generic domain while struggling in a specific domain.","Although continued pre-training on a large domain-specific corpus is effective, it is costly to tune all the parameters on the domain.","In this paper, we investigate whether we can adapt PLMs both effectively and efficiently by only tuning a few parameters.","Specifically, we decouple the feed-forward networks (FFNs) of the Transformer architecture into two parts: the original pre-trained FFNs to maintain the old-domain knowledge and our novel domain-specific adapters to inject domain-specific knowledge in parallel.","Then we adopt a mixture-of-adapters gate to fuse the knowledge from different domain adapters dynamically.","Our proposed Mixture-of-Domain-Adapters (MixDA) employs a two-stage adapter-tuning strategy that leverages both unlabeled data and labeled data to help the domain adaptation: i) domain-specific adapter on unlabeled data; followed by ii) the task-specific adapter on labeled data.","MixDA can be seamlessly plugged into the pretraining-finetuning paradigm and our experiments demonstrate that MixDA achieves superior performance on in-domain tasks (GLUE), out-of-domain tasks (ChemProt, RCT, IMDB, Amazon), and knowledge-intensive tasks (KILT).","Further analyses demonstrate the reliability, scalability, and efficiency of our method.","The code is available at https://github.com/Amano-Aki/Mixture-of-Domain-Adapters."],"url":"http://arxiv.org/abs/2306.05406v1"}
{"created":"2023-06-08","title":"Fully Robust Federated Submodel Learning in a Distributed Storage System","abstract":"We consider the federated submodel learning (FSL) problem in a distributed storage system. In the FSL framework, the full learning model at the server side is divided into multiple submodels such that each selected client needs to download only the required submodel(s) and upload the corresponding update(s) in accordance with its local training data. The server comprises multiple independent databases and the full model is stored across these databases. An eavesdropper passively observes all the storage and listens to all the communicated data, of its controlled databases, to gain knowledge about the remote client data and the submodel information. In addition, a subset of databases may fail, negatively affecting the FSL process, as FSL process may take a non-negligible amount of time for large models. To resolve these two issues together (i.e., security and database repair), we propose a novel coding mechanism coined ramp secure regenerating coding (RSRC), to store the full model in a distributed manner. Using our new RSRC method, the eavesdropper is permitted to learn a controllable amount of submodel information for the sake of reducing the communication and storage costs. Further, during the database repair process, in the construction of the replacement database, the submodels to be updated are stored in the form of their latest version from updating clients, while the remaining submodels are obtained from the previous version in other databases through routing clients. Our new RSRC-based distributed FSL approach is constructed on top of our earlier two-database FSL scheme which uses private set union (PSU). A complete one-round FSL process consists of FSL-PSU phase, FSL-write phase and additional auxiliary phases. Our proposed FSL scheme is also robust against database drop-outs, client drop-outs, client late-arrivals and an active adversary controlling databases.","sentences":["We consider the federated submodel learning (FSL) problem in a distributed storage system.","In the FSL framework, the full learning model at the server side is divided into multiple submodels such that each selected client needs to download only the required submodel(s) and upload the corresponding update(s) in accordance with its local training data.","The server comprises multiple independent databases and the full model is stored across these databases.","An eavesdropper passively observes all the storage and listens to all the communicated data, of its controlled databases, to gain knowledge about the remote client data and the submodel information.","In addition, a subset of databases may fail, negatively affecting the FSL process, as FSL process may take a non-negligible amount of time for large models.","To resolve these two issues together (i.e., security and database repair), we propose a novel coding mechanism coined ramp secure regenerating coding (RSRC), to store the full model in a distributed manner.","Using our new RSRC method, the eavesdropper is permitted to learn a controllable amount of submodel information for the sake of reducing the communication and storage costs.","Further, during the database repair process, in the construction of the replacement database, the submodels to be updated are stored in the form of their latest version from updating clients, while the remaining submodels are obtained from the previous version in other databases through routing clients.","Our new RSRC-based distributed FSL approach is constructed on top of our earlier two-database FSL scheme which uses private set union (PSU).","A complete one-round FSL process consists of FSL-PSU phase, FSL-write phase and additional auxiliary phases.","Our proposed FSL scheme is also robust against database drop-outs, client drop-outs, client late-arrivals and an active adversary controlling databases."],"url":"http://arxiv.org/abs/2306.05402v1"}
{"created":"2023-06-08","title":"SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling with Backtracking","abstract":"In many domains, autoregressive models can achieve low log-likelihood on the task of predicting the next observation. However, this maximum-likelihood (MLE) objective does not necessarily match a downstream use-case of autoregressively generating high-quality sequences. The MLE objective weights sequences proportionally to their frequency under the data distribution, with no guidance for the model's behaviour out of distribution (OOD): leading to compounding error during autoregressive generation. In order to address this compounding error problem, we formulate sequence generation as an imitation learning (IL) problem. This allows us to minimize a variety of divergences between the distribution of sequences generated by an autoregressive model and sequences from a dataset, including divergences with weight on OOD generated sequences. The IL framework also allows us to incorporate backtracking by introducing a backspace action into the generation process. This further mitigates the compounding error problem by allowing the model to revert a sampled token if it takes the sequence OOD. Our resulting method, SequenceMatch, can be implemented without adversarial training or major architectural changes. We identify the SequenceMatch-$\\chi^2$ divergence as a more suitable training objective for autoregressive models which are used for generation. We show that empirically, SequenceMatch training leads to improvements over MLE on text generation with language models.","sentences":["In many domains, autoregressive models can achieve low log-likelihood on the task of predicting the next observation.","However, this maximum-likelihood (MLE) objective does not necessarily match a downstream use-case of autoregressively generating high-quality sequences.","The MLE objective weights sequences proportionally to their frequency under the data distribution, with no guidance for the model's behaviour out of distribution (OOD): leading to compounding error during autoregressive generation.","In order to address this compounding error problem, we formulate sequence generation as an imitation learning (IL) problem.","This allows us to minimize a variety of divergences between the distribution of sequences generated by an autoregressive model and sequences from a dataset, including divergences with weight on OOD generated sequences.","The IL framework also allows us to incorporate backtracking by introducing a backspace action into the generation process.","This further mitigates the compounding error problem by allowing the model to revert a sampled token if it takes the sequence OOD.","Our resulting method, SequenceMatch, can be implemented without adversarial training or major architectural changes.","We identify the SequenceMatch-$\\chi^2$ divergence as a more suitable training objective for autoregressive models which are used for generation.","We show that empirically, SequenceMatch training leads to improvements over MLE on text generation with language models."],"url":"http://arxiv.org/abs/2306.05426v1"}
{"created":"2023-06-08","title":"HQ-50K: A Large-scale, High-quality Dataset for Image Restoration","abstract":"This paper introduces a new large-scale image restoration dataset, called HQ-50K, which contains 50,000 high-quality images with rich texture details and semantic diversity. We analyze existing image restoration datasets from five different perspectives, including data scale, resolution, compression rates, texture details, and semantic coverage. However, we find that all of these datasets are deficient in some aspects. In contrast, HQ-50K considers all of these five aspects during the data curation process and meets all requirements. We also present a new Degradation-Aware Mixture of Expert (DAMoE) model, which enables a single model to handle multiple corruption types and unknown levels. Our extensive experiments demonstrate that HQ-50K consistently improves the performance on various image restoration tasks, such as super-resolution, denoising, dejpeg, and deraining. Furthermore, our proposed DAMoE, trained on our \\dataset, outperforms existing state-of-the-art unified models designed for multiple restoration tasks and levels. The dataset and code are available at \\url{https://github.com/littleYaang/HQ-50K}.","sentences":["This paper introduces a new large-scale image restoration dataset, called HQ-50K, which contains 50,000 high-quality images with rich texture details and semantic diversity.","We analyze existing image restoration datasets from five different perspectives, including data scale, resolution, compression rates, texture details, and semantic coverage.","However, we find that all of these datasets are deficient in some aspects.","In contrast, HQ-50K considers all of these five aspects during the data curation process and meets all requirements.","We also present a new Degradation-Aware Mixture of Expert (DAMoE) model, which enables a single model to handle multiple corruption types and unknown levels.","Our extensive experiments demonstrate that HQ-50K consistently improves the performance on various image restoration tasks, such as super-resolution, denoising, dejpeg, and deraining.","Furthermore, our proposed DAMoE, trained on our \\dataset, outperforms existing state-of-the-art unified models designed for multiple restoration tasks and levels.","The dataset and code are available at \\url{https://github.com/littleYaang/HQ-50K}."],"url":"http://arxiv.org/abs/2306.05390v1"}
{"created":"2023-06-08","title":"KIT's Multilingual Speech Translation System for IWSLT 2023","abstract":"Many existing speech translation benchmarks focus on native-English speech in high-quality recording conditions, which often do not match the conditions in real-life use-cases. In this paper, we describe our speech translation system for the multilingual track of IWSLT 2023, which focuses on the translation of scientific conference talks. The test condition features accented input speech and terminology-dense contents. The tasks requires translation into 10 languages of varying amounts of resources. In absence of training data from the target domain, we use a retrieval-based approach (kNN-MT) for effective adaptation (+0.8 BLEU for speech translation). We also use adapters to easily integrate incremental training data from data augmentation, and show that it matches the performance of re-training. We observe that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules. Our cascaded speech system substantially outperforms its end-to-end counterpart on scientific talk translation, although their performance remains similar on TED talks.","sentences":["Many existing speech translation benchmarks focus on native-English speech in high-quality recording conditions, which often do not match the conditions in real-life use-cases.","In this paper, we describe our speech translation system for the multilingual track of IWSLT 2023, which focuses on the translation of scientific conference talks.","The test condition features accented input speech and terminology-dense contents.","The tasks requires translation into 10 languages of varying amounts of resources.","In absence of training data from the target domain, we use a retrieval-based approach (kNN-MT) for effective adaptation (+0.8 BLEU for speech translation).","We also use adapters to easily integrate incremental training data from data augmentation, and show that it matches the performance of re-training.","We observe that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules.","Our cascaded speech system substantially outperforms its end-to-end counterpart on scientific talk translation, although their performance remains similar on TED talks."],"url":"http://arxiv.org/abs/2306.05320v1"}
{"created":"2023-06-08","title":"RNN-Based GNSS Positioning using Satellite Measurement Features and Pseudorange Residuals","abstract":"In the Global Navigation Satellite System (GNSS) context, the growing number of available satellites has lead to many challenges when it comes to choosing the most accurate pseudorange contributions, given the strong impact of biased measurements on positioning accuracy, particularly in single-epoch scenarios. This work leverages the potential of machine learning in predicting link-wise measurement quality factors and, hence, optimize measurement weighting. For this purpose, we use a customized matrix composed of heterogeneous features such as conditional pseudorange residuals and per-link satellite metrics (e.g., carrier-to-noise power density ratio and its empirical statistics, satellite elevation, carrier phase lock time). This matrix is then fed as an input to a recurrent neural network (RNN) (i.e., a long-short term memory (LSTM) network). Our experimental results on real data, obtained from extensive field measurements, demonstrate the high potential of our proposed solution being able to outperform traditional measurements weighting and selection strategies from state-of-the-art.","sentences":["In the Global Navigation Satellite System (GNSS) context, the growing number of available satellites has lead to many challenges when it comes to choosing the most accurate pseudorange contributions, given the strong impact of biased measurements on positioning accuracy, particularly in single-epoch scenarios.","This work leverages the potential of machine learning in predicting link-wise measurement quality factors and, hence, optimize measurement weighting.","For this purpose, we use a customized matrix composed of heterogeneous features such as conditional pseudorange residuals and per-link satellite metrics (e.g., carrier-to-noise power density ratio and its empirical statistics, satellite elevation, carrier phase lock time).","This matrix is then fed as an input to a recurrent neural network (RNN) (i.e., a long-short term memory (LSTM) network).","Our experimental results on real data, obtained from extensive field measurements, demonstrate the high potential of our proposed solution being able to outperform traditional measurements weighting and selection strategies from state-of-the-art."],"url":"http://arxiv.org/abs/2306.05319v1"}
{"created":"2023-06-08","title":"Genomic Interpreter: A Hierarchical Genomic Deep Neural Network with 1D Shifted Window Transformer","abstract":"Given the increasing volume and quality of genomics data, extracting new insights requires interpretable machine-learning models. This work presents Genomic Interpreter: a novel architecture for genomic assay prediction. This model outperforms the state-of-the-art models for genomic assay prediction tasks. Our model can identify hierarchical dependencies in genomic sites. This is achieved through the integration of 1D-Swin, a novel Transformer-based block designed by us for modelling long-range hierarchical data. Evaluated on a dataset containing 38,171 DNA segments of 17K base pairs, Genomic Interpreter demonstrates superior performance in chromatin accessibility and gene expression prediction and unmasks the underlying `syntax' of gene regulation.","sentences":["Given the increasing volume and quality of genomics data, extracting new insights requires interpretable machine-learning models.","This work presents Genomic Interpreter: a novel architecture for genomic assay prediction.","This model outperforms the state-of-the-art models for genomic assay prediction tasks.","Our model can identify hierarchical dependencies in genomic sites.","This is achieved through the integration of 1D-Swin, a novel Transformer-based block designed by us for modelling long-range hierarchical data.","Evaluated on a dataset containing 38,171 DNA segments of 17K base pairs, Genomic Interpreter demonstrates superior performance in chromatin accessibility and gene expression prediction and unmasks the underlying `syntax' of gene regulation."],"url":"http://arxiv.org/abs/2306.05143v1"}
{"created":"2023-06-08","title":"Does Image Anonymization Impact Computer Vision Training?","abstract":"Image anonymization is widely adapted in practice to comply with privacy regulations in many regions. However, anonymization often degrades the quality of the data, reducing its utility for computer vision development. In this paper, we investigate the impact of image anonymization for training computer vision models on key computer vision tasks (detection, instance segmentation, and pose estimation). Specifically, we benchmark the recognition drop on common detection datasets, where we evaluate both traditional and realistic anonymization for faces and full bodies. Our comprehensive experiments reflect that traditional image anonymization substantially impacts final model performance, particularly when anonymizing the full body. Furthermore, we find that realistic anonymization can mitigate this decrease in performance, where our experiments reflect a minimal performance drop for face anonymization. Our study demonstrates that realistic anonymization can enable privacy-preserving computer vision development with minimal performance degradation across a range of important computer vision benchmarks.","sentences":["Image anonymization is widely adapted in practice to comply with privacy regulations in many regions.","However, anonymization often degrades the quality of the data, reducing its utility for computer vision development.","In this paper, we investigate the impact of image anonymization for training computer vision models on key computer vision tasks (detection, instance segmentation, and pose estimation).","Specifically, we benchmark the recognition drop on common detection datasets, where we evaluate both traditional and realistic anonymization for faces and full bodies.","Our comprehensive experiments reflect that traditional image anonymization substantially impacts final model performance, particularly when anonymizing the full body.","Furthermore, we find that realistic anonymization can mitigate this decrease in performance, where our experiments reflect a minimal performance drop for face anonymization.","Our study demonstrates that realistic anonymization can enable privacy-preserving computer vision development with minimal performance degradation across a range of important computer vision benchmarks."],"url":"http://arxiv.org/abs/2306.05135v1"}
{"created":"2023-06-08","title":"Beyond Gaia DR3: tracing the [\u03b1/M]-[M/H] bimodality from the inner to the outer Milky Way disc with Gaia RVS and Convolutional Neural-Networks","abstract":"Gaia DR3 has provided the community with about one million RVS spectra covering the CaII triplet region. In the next Gaia data releases, we anticipate the number of RVS spectra to successively increase from several 10 million spectra to eventually more than 200M spectra. Thus, stellar spectra are produced on an \"industrial scale\" with numbers well above those for current and anticipated ground based surveys. However, many of these spectra have low S/N (from 15 to 25 per pixel), such that they pose problems for classical spectral analysis pipelines and therefore alternative ways to tap into these large datasets need to be devised. We aim to leverage the versatility/capabilities of machine learning techniques for supercharged stellar parametrization, by combining Gaia RVS spectra with the full set of Gaia products and high-resolution, high-quality spectroscopic reference data sets. We develop a hybrid Convolutional Neural-Network (CNN) which combines the Gaia DR3 RVS spectra, photometry (G, Bp, Rp), parallaxes, and XP coefficients to derive atmospheric parameters (Teff, log(g), and overall [M/H]) and chemical abundances ([Fe/H] and [$\\alpha$/M]). We trained the CNN with a high-quality training sample based on APOGEE DR17 labels. With this CNN, we derived homogeneous atmospheric parameters and abundances for 841300 stars, that remarkably compared to external data-sets. The CNN is robust against noise in the RVS data, and very precise labels are derived down to S/N=15. We managed to characterize the [$\\alpha$/M]-[M/H] bimodality from the inner regions to the outer parts of the Milky Way, which has never been done using RVS spectra or similar datasets. This work is the first to combine machine-learning with such diverse datasets (spectroscopy, astrometry, and photometry), and paves the way for the large scale machine-learning analysis of Gaia-RVS spectra from future data releases.","sentences":["Gaia DR3 has provided the community with about one million RVS spectra covering the CaII triplet region.","In the next Gaia data releases, we anticipate the number of RVS spectra to successively increase from several 10 million spectra to eventually more than 200M spectra.","Thus, stellar spectra are produced on an \"industrial scale\" with numbers well above those for current and anticipated ground based surveys.","However, many of these spectra have low S/N (from 15 to 25 per pixel), such that they pose problems for classical spectral analysis pipelines and therefore alternative ways to tap into these large datasets need to be devised.","We aim to leverage the versatility/capabilities of machine learning techniques for supercharged stellar parametrization, by combining Gaia RVS spectra with the full set of Gaia products and high-resolution, high-quality spectroscopic reference data sets.","We develop a hybrid Convolutional Neural-Network (CNN) which combines the Gaia DR3 RVS spectra, photometry (G, Bp, Rp), parallaxes, and XP coefficients to derive atmospheric parameters (Teff, log(g), and overall [M/H]) and chemical abundances ([Fe/H] and [$\\alpha$/M]).","We trained the CNN with a high-quality training sample based on APOGEE DR17 labels.","With this CNN, we derived homogeneous atmospheric parameters and abundances for 841300 stars, that remarkably compared to external data-sets.","The CNN is robust against noise in the RVS data, and very precise labels are derived down to S/N=15.","We managed to characterize the [$\\alpha$/M]-[M/H] bimodality from the inner regions to the outer parts of the Milky Way, which has never been done using RVS spectra or similar datasets.","This work is the first to combine machine-learning with such diverse datasets (spectroscopy, astrometry, and photometry), and paves the way for the large scale machine-learning analysis of Gaia-RVS spectra from future data releases."],"url":"http://arxiv.org/abs/2306.05086v1"}
{"created":"2023-06-08","title":"Improving Language Model Integration for Neural Machine Translation","abstract":"The integration of language models for neural machine translation has been extensively studied in the past. It has been shown that an external language model, trained on additional target-side monolingual data, can help improve translation quality. However, there has always been the assumption that the translation model also learns an implicit target-side language model during training, which interferes with the external language model at decoding time. Recently, some works on automatic speech recognition have demonstrated that, if the implicit language model is neutralized in decoding, further improvements can be gained when integrating an external language model. In this work, we transfer this concept to the task of machine translation and compare with the most prominent way of including additional monolingual data - namely back-translation. We find that accounting for the implicit language model significantly boosts the performance of language model fusion, although this approach is still outperformed by back-translation.","sentences":["The integration of language models for neural machine translation has been extensively studied in the past.","It has been shown that an external language model, trained on additional target-side monolingual data, can help improve translation quality.","However, there has always been the assumption that the translation model also learns an implicit target-side language model during training, which interferes with the external language model at decoding time.","Recently, some works on automatic speech recognition have demonstrated that, if the implicit language model is neutralized in decoding, further improvements can be gained when integrating an external language model.","In this work, we transfer this concept to the task of machine translation and compare with the most prominent way of including additional monolingual data - namely back-translation.","We find that accounting for the implicit language model significantly boosts the performance of language model fusion, although this approach is still outperformed by back-translation."],"url":"http://arxiv.org/abs/2306.05077v1"}
{"created":"2023-06-08","title":"A multi-band AGN-SFG classifier for extragalactic radio surveys using machine learning","abstract":"Extragalactic radio continuum surveys play an increasingly more important role in galaxy evolution and cosmology studies. While radio galaxies and radio quasars dominate at the bright end, star-forming galaxies (SFGs) and radio-quiet Active Galactic Nuclei (AGNs) are more common at fainter flux densities. Our aim is to develop a machine learning classifier that can efficiently and reliably separate AGNs and SFGs in radio continuum surveys. We perform supervised classification of SFGs vs AGNs using the Light Gradient Boosting Machine (LGBM) on three LOFAR Deep Fields (Lockman Hole, Bootes and ELAIS-N1), which benefit from a wide range of high-quality multi-wavelength data and classification labels derived from extensive spectral energy distribution (SED) analyses. Our trained model has a precision of 0.92(0.01) and a recall of 0.87(0.02) for SFGs. For AGNs, the model has slightly worse performance, with a precision of 0.87(0.02) and recall of 0.78(0.02). These results demonstrate that our trained model can successfully reproduce the classification labels derived from detailed SED analysis. The model performance decreases towards higher redshifts, mainly due to smaller training sample sizes. To make the classifier more adaptable to other radio galaxy surveys, we also investigate how our classifier performs with a poorer multi-wavelength sampling of the SED. In particular, we find that the far-infrared (FIR) and radio bands are of great importance. We also find that higher S/N in some photometric bands leads to a significant boost in the model's performance. In addition to using the 150 MHz radio data, our model can also be used with 1.4 GHz radio data. Converting 1.4 GHz to 150 MHz radio data reduces performance by about 4% in precision and 3% in recall. The final trained model is publicly available at https://github.com/Jesper-Karsten/MBASC","sentences":["Extragalactic radio continuum surveys play an increasingly more important role in galaxy evolution and cosmology studies.","While radio galaxies and radio quasars dominate at the bright end, star-forming galaxies (SFGs) and radio-quiet Active Galactic Nuclei (AGNs) are more common at fainter flux densities.","Our aim is to develop a machine learning classifier that can efficiently and reliably separate AGNs and SFGs in radio continuum surveys.","We perform supervised classification of SFGs vs AGNs using the Light Gradient Boosting Machine (LGBM) on three LOFAR Deep Fields (Lockman Hole, Bootes and ELAIS-N1), which benefit from a wide range of high-quality multi-wavelength data and classification labels derived from extensive spectral energy distribution (SED) analyses.","Our trained model has a precision of 0.92(0.01) and a recall of 0.87(0.02) for SFGs.","For AGNs, the model has slightly worse performance, with a precision of 0.87(0.02) and recall of 0.78(0.02).","These results demonstrate that our trained model can successfully reproduce the classification labels derived from detailed SED analysis.","The model performance decreases towards higher redshifts, mainly due to smaller training sample sizes.","To make the classifier more adaptable to other radio galaxy surveys, we also investigate how our classifier performs with a poorer multi-wavelength sampling of the SED.","In particular, we find that the far-infrared (FIR) and radio bands are of great importance.","We also find that higher S/N in some photometric bands leads to a significant boost in the model's performance.","In addition to using the 150 MHz radio data, our model can also be used with 1.4 GHz radio data.","Converting 1.4 GHz to 150 MHz radio data reduces performance by about 4% in precision and 3% in recall.","The final trained model is publicly available at https://github.com/Jesper-Karsten/MBASC"],"url":"http://arxiv.org/abs/2306.05062v1"}
{"created":"2023-06-08","title":"Posterior Collapse in Linear Conditional and Hierarchical Variational Autoencoders","abstract":"The posterior collapse phenomenon in variational autoencoders (VAEs), where the variational posterior distribution closely matches the prior distribution, can hinder the quality of the learned latent variables. As a consequence of posterior collapse, the latent variables extracted by the encoder in VAEs preserve less information from the input data and thus fail to produce meaningful representations as input to the reconstruction process in the decoder. While this phenomenon has been an actively addressed topic related to VAEs performance, the theory for posterior collapse remains underdeveloped, especially beyond the standard VAEs. In this work, we advance the theoretical understanding of posterior collapse to two important and prevalent yet less studied classes of VAEs: conditional VAEs and hierarchical VAEs. Specifically, via a non-trivial theoretical analysis of linear conditional VAEs and hierarchical VAEs with two levels of latent, we prove that the cause of posterior collapses in these models includes the correlation between the input and output of the conditional VAEs and the effect of learnable encoder variance in the hierarchical VAEs. We empirically validate our theoretical findings for linear conditional and hierarchical VAEs and demonstrate that these results are also predictive for non-linear cases.","sentences":["The posterior collapse phenomenon in variational autoencoders (VAEs), where the variational posterior distribution closely matches the prior distribution, can hinder the quality of the learned latent variables.","As a consequence of posterior collapse, the latent variables extracted by the encoder in VAEs preserve less information from the input data and thus fail to produce meaningful representations as input to the reconstruction process in the decoder.","While this phenomenon has been an actively addressed topic related to VAEs performance, the theory for posterior collapse remains underdeveloped, especially beyond the standard VAEs.","In this work, we advance the theoretical understanding of posterior collapse to two important and prevalent yet less studied classes of VAEs: conditional VAEs and hierarchical VAEs.","Specifically, via a non-trivial theoretical analysis of linear conditional VAEs and hierarchical VAEs with two levels of latent, we prove that the cause of posterior collapses in these models includes the correlation between the input and output of the conditional VAEs and the effect of learnable encoder variance in the hierarchical VAEs.","We empirically validate our theoretical findings for linear conditional and hierarchical VAEs and demonstrate that these results are also predictive for non-linear cases."],"url":"http://arxiv.org/abs/2306.05023v1"}
{"created":"2023-06-08","title":"FheFL: Fully Homomorphic Encryption Friendly Privacy-Preserving Federated Learning with Byzantine Users","abstract":"The federated learning (FL) technique was initially developed to mitigate data privacy issues that can arise in the traditional machine learning paradigm. While FL ensures that a user's data always remain with the user, the gradients of the locally trained models must be communicated with the centralized server to build the global model. This results in privacy leakage, where the server can infer private information of the users' data from the shared gradients. To mitigate this flaw, the next-generation FL architectures proposed encryption and anonymization techniques to protect the model updates from the server. However, this approach creates other challenges, such as a malicious user might sabotage the global model by sharing false gradients. Since the gradients are encrypted, the server is unable to identify and eliminate rogue users which would protect the global model. Therefore, to mitigate both attacks, this paper proposes a novel fully homomorphic encryption (FHE) based scheme suitable for FL. We modify the one-to-one single-key Cheon-Kim-Kim-Song (CKKS)-based FHE scheme into a distributed multi-key additive homomorphic encryption scheme that supports model aggregation in FL. We employ a novel aggregation scheme within the encrypted domain, utilizing users' non-poisoning rates, to effectively address data poisoning attacks while ensuring privacy is preserved by the proposed encryption scheme. Rigorous security, privacy, convergence, and experimental analyses have been provided to show that FheFL is novel, secure, and private, and achieves comparable accuracy at reasonable computational cost.","sentences":["The federated learning (FL) technique was initially developed to mitigate data privacy issues that can arise in the traditional machine learning paradigm.","While FL ensures that a user's data always remain with the user, the gradients of the locally trained models must be communicated with the centralized server to build the global model.","This results in privacy leakage, where the server can infer private information of the users' data from the shared gradients.","To mitigate this flaw, the next-generation FL architectures proposed encryption and anonymization techniques to protect the model updates from the server.","However, this approach creates other challenges, such as a malicious user might sabotage the global model by sharing false gradients.","Since the gradients are encrypted, the server is unable to identify and eliminate rogue users which would protect the global model.","Therefore, to mitigate both attacks, this paper proposes a novel fully homomorphic encryption (FHE) based scheme suitable for FL.","We modify the one-to-one single-key Cheon-Kim-Kim-Song (CKKS)-based FHE scheme into a distributed multi-key additive homomorphic encryption scheme that supports model aggregation in FL.","We employ a novel aggregation scheme within the encrypted domain, utilizing users' non-poisoning rates, to effectively address data poisoning attacks while ensuring privacy is preserved by the proposed encryption scheme.","Rigorous security, privacy, convergence, and experimental analyses have been provided to show that FheFL is novel, secure, and private, and achieves comparable accuracy at reasonable computational cost."],"url":"http://arxiv.org/abs/2306.05112v1"}
{"created":"2023-06-08","title":"PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization","abstract":"Instruction tuning large language models (LLMs) remains a challenging task, owing to the complexity of hyperparameter selection and the difficulty involved in evaluating the tuned models. To determine the optimal hyperparameters, an automatic, robust, and reliable evaluation benchmark is essential. However, establishing such a benchmark is not a trivial task due to the challenges associated with evaluation accuracy and privacy protection. In response to these challenges, we introduce a judge large language model, named PandaLM, which is trained to distinguish the superior model given several LLMs. PandaLM's focus extends beyond just the objective correctness of responses, which is the main focus of traditional evaluation datasets. It addresses vital subjective factors such as relative conciseness, clarity, adherence to instructions, comprehensiveness, and formality. To ensure the reliability of PandaLM, we collect a diverse human-annotated test dataset, where all contexts are generated by humans and labels are aligned with human preferences. Our results indicate that PandaLM-7B achieves 93.75% of GPT-3.5's evaluation ability and 88.28% of GPT-4's in terms of F1-score on our test dataset. PandaLM enables the evaluation of LLM to be fairer but with less cost, evidenced by significant improvements achieved by models tuned through PandaLM compared to their counterparts trained with default Alpaca's hyperparameters. In addition, PandaLM does not depend on API-based evaluations, thus avoiding potential data leakage. All resources of PandaLM are released at https://github.com/WeOpenML/PandaLM.","sentences":["Instruction tuning large language models (LLMs) remains a challenging task, owing to the complexity of hyperparameter selection and the difficulty involved in evaluating the tuned models.","To determine the optimal hyperparameters, an automatic, robust, and reliable evaluation benchmark is essential.","However, establishing such a benchmark is not a trivial task due to the challenges associated with evaluation accuracy and privacy protection.","In response to these challenges, we introduce a judge large language model, named PandaLM, which is trained to distinguish the superior model given several LLMs.","PandaLM's focus extends beyond just the objective correctness of responses, which is the main focus of traditional evaluation datasets.","It addresses vital subjective factors such as relative conciseness, clarity, adherence to instructions, comprehensiveness, and formality.","To ensure the reliability of PandaLM, we collect a diverse human-annotated test dataset, where all contexts are generated by humans and labels are aligned with human preferences.","Our results indicate that PandaLM-7B achieves 93.75% of GPT-3.5's evaluation ability and 88.28% of GPT-4's in terms of F1-score on our test dataset.","PandaLM enables the evaluation of LLM to be fairer but with less cost, evidenced by significant improvements achieved by models tuned through PandaLM compared to their counterparts trained with default Alpaca's hyperparameters.","In addition, PandaLM does not depend on API-based evaluations, thus avoiding potential data leakage.","All resources of PandaLM are released at https://github.com/WeOpenML/PandaLM."],"url":"http://arxiv.org/abs/2306.05087v1"}
