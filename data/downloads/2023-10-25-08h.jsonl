{"created":"2023-10-24 17:59:55","title":"Synthetic Data as Validation","abstract":"This study leverages synthetic data as a validation set to reduce overfitting and ease the selection of the best model in AI development. While synthetic data have been used for augmenting the training set, we find that synthetic data can also significantly diversify the validation set, offering marked advantages in domains like healthcare, where data are typically limited, sensitive, and from out-domain sources (i.e., hospitals). In this study, we illustrate the effectiveness of synthetic data for early cancer detection in computed tomography (CT) volumes, where synthetic tumors are generated and superimposed onto healthy organs, thereby creating an extensive dataset for rigorous validation. Using synthetic data as validation can improve AI robustness in both in-domain and out-domain test sets. Furthermore, we establish a new continual learning framework that continuously trains AI models on a stream of out-domain data with synthetic tumors. The AI model trained and validated in dynamically expanding synthetic data can consistently outperform models trained and validated exclusively on real-world data. Specifically, the DSC score for liver tumor segmentation improves from 26.7% (95% CI: 22.6%-30.9%) to 34.5% (30.8%-38.2%) when evaluated on an in-domain dataset and from 31.1% (26.0%-36.2%) to 35.4% (32.1%-38.7%) on an out-domain dataset. Importantly, the performance gain is particularly significant in identifying very tiny liver tumors (radius < 5mm) in CT volumes, with Sensitivity improving from 33.1% to 55.4% on an in-domain dataset and 33.9% to 52.3% on an out-domain dataset, justifying the efficacy in early detection of cancer. The application of synthetic data, from both training and validation perspectives, underlines a promising avenue to enhance AI robustness when dealing with data from varying domains.","sentences":["This study leverages synthetic data as a validation set to reduce overfitting and ease the selection of the best model in AI development.","While synthetic data have been used for augmenting the training set, we find that synthetic data can also significantly diversify the validation set, offering marked advantages in domains like healthcare, where data are typically limited, sensitive, and from out-domain sources (i.e., hospitals).","In this study, we illustrate the effectiveness of synthetic data for early cancer detection in computed tomography (CT) volumes, where synthetic tumors are generated and superimposed onto healthy organs, thereby creating an extensive dataset for rigorous validation.","Using synthetic data as validation can improve AI robustness in both in-domain and out-domain test sets.","Furthermore, we establish a new continual learning framework that continuously trains AI models on a stream of out-domain data with synthetic tumors.","The AI model trained and validated in dynamically expanding synthetic data can consistently outperform models trained and validated exclusively on real-world data.","Specifically, the DSC score for liver tumor segmentation improves from 26.7% (95% CI: 22.6%-30.9%) to 34.5% (30.8%-38.2%) when evaluated on an in-domain dataset and from 31.1% (26.0%-36.2%) to 35.4% (32.1%-38.7%) on an out-domain dataset.","Importantly, the performance gain is particularly significant in identifying very tiny liver tumors (radius < 5mm) in CT volumes, with Sensitivity improving from 33.1% to 55.4% on an in-domain dataset and 33.9% to 52.3% on an out-domain dataset, justifying the efficacy in early detection of cancer.","The application of synthetic data, from both training and validation perspectives, underlines a promising avenue to enhance AI robustness when dealing with data from varying domains."],"url":"http://arxiv.org/abs/2310.16052v1"}
{"created":"2023-10-24 17:59:48","title":"EquivAct: SIM(3)-Equivariant Visuomotor Policies beyond Rigid Object Manipulation","abstract":"If a robot masters folding a kitchen towel, we would also expect it to master folding a beach towel. However, existing works for policy learning that rely on data set augmentations are still limited in achieving this level of generalization. Our insight is to add equivariance to both the visual object representation and policy architecture. We propose EquivAct which utilizes SIM(3)-equivariant network structures that guarantee generalization across all possible object translations, 3D rotations, and scales by construction. Training of EquivAct is done in two phases. We first pre-train a SIM(3)-equivariant visual representation on simulated scene point clouds. Then, we learn a SIM(3)-equivariant visuomotor policy on top of the pre-trained visual representation using a small amount of source task demonstrations. We demonstrate that after training, the learned policy directly transfers to objects that substantially differ in scale, position and orientation from the source demonstrations. In simulation, we evaluate our method in three manipulation tasks involving deformable and articulated objects thereby going beyond the typical rigid object manipulation tasks that prior works considered. We show that our method outperforms prior works that do not use equivariant architectures or do not use our contrastive pre-training procedure. We also show quantitative and qualitative experiments on three real robot tasks, where the robot watches twenty demonstrations of a tabletop task and transfers zero-shot to a mobile manipulation task in a much larger setup. Project website: https://equivact.github.io","sentences":["If a robot masters folding a kitchen towel, we would also expect it to master folding a beach towel.","However, existing works for policy learning that rely on data set augmentations are still limited in achieving this level of generalization.","Our insight is to add equivariance to both the visual object representation and policy architecture.","We propose EquivAct which utilizes SIM(3)-equivariant network structures that guarantee generalization across all possible object translations, 3D rotations, and scales by construction.","Training of EquivAct is done in two phases.","We first pre-train a SIM(3)-equivariant visual representation on simulated scene point clouds.","Then, we learn a SIM(3)-equivariant visuomotor policy on top of the pre-trained visual representation using a small amount of source task demonstrations.","We demonstrate that after training, the learned policy directly transfers to objects that substantially differ in scale, position and orientation from the source demonstrations.","In simulation, we evaluate our method in three manipulation tasks involving deformable and articulated objects thereby going beyond the typical rigid object manipulation tasks that prior works considered.","We show that our method outperforms prior works that do not use equivariant architectures or do not use our contrastive pre-training procedure.","We also show quantitative and qualitative experiments on three real robot tasks, where the robot watches twenty demonstrations of a tabletop task and transfers zero-shot to a mobile manipulation task in a much larger setup.","Project website: https://equivact.github.io"],"url":"http://arxiv.org/abs/2310.16050v1"}
{"created":"2023-10-24 17:59:20","title":"MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning","abstract":"While large language models (LLMs) equipped with techniques like chain-of-thought prompting have demonstrated impressive capabilities, they still fall short in their ability to reason robustly in complex settings. However, evaluating LLM reasoning is challenging because system capabilities continue to grow while benchmark datasets for tasks like logical deduction have remained static. We introduce MuSR, a dataset for evaluating language models on multistep soft reasoning tasks specified in a natural language narrative. This dataset has two crucial features. First, it is created through a novel neurosymbolic synthetic-to-natural generation algorithm, enabling the construction of complex reasoning instances that challenge GPT-4 (e.g., murder mysteries roughly 1000 words in length) and which can be scaled further as more capable LLMs are released. Second, our dataset instances are free text narratives corresponding to real-world domains of reasoning; this makes it simultaneously much more challenging than other synthetically-crafted benchmarks while remaining realistic and tractable for human annotators to solve with high accuracy. We evaluate a range of LLMs and prompting techniques on this dataset and characterize the gaps that remain for techniques like chain-of-thought to perform robust reasoning.","sentences":["While large language models (LLMs) equipped with techniques like chain-of-thought prompting have demonstrated impressive capabilities, they still fall short in their ability to reason robustly in complex settings.","However, evaluating LLM reasoning is challenging because system capabilities continue to grow while benchmark datasets for tasks like logical deduction have remained static.","We introduce MuSR, a dataset for evaluating language models on multistep soft reasoning tasks specified in a natural language narrative.","This dataset has two crucial features.","First, it is created through a novel neurosymbolic synthetic-to-natural generation algorithm, enabling the construction of complex reasoning instances that challenge GPT-4 (e.g., murder mysteries roughly 1000 words in length) and which can be scaled further as more capable LLMs are released.","Second, our dataset instances are free text narratives corresponding to real-world domains of reasoning; this makes it simultaneously much more challenging than other synthetically-crafted benchmarks while remaining realistic and tractable for human annotators to solve with high accuracy.","We evaluate a range of LLMs and prompting techniques on this dataset and characterize the gaps that remain for techniques like chain-of-thought to perform robust reasoning."],"url":"http://arxiv.org/abs/2310.16049v1"}
{"created":"2023-10-24 17:59:04","title":"AI Alignment and Social Choice: Fundamental Limitations and Policy Implications","abstract":"Aligning AI agents to human intentions and values is a key bottleneck in building safe and deployable AI applications. But whose values should AI agents be aligned with? Reinforcement learning with human feedback (RLHF) has emerged as the key framework for AI alignment. RLHF uses feedback from human reinforcers to fine-tune outputs; all widely deployed large language models (LLMs) use RLHF to align their outputs to human values. It is critical to understand the limitations of RLHF and consider policy challenges arising from these limitations. In this paper, we investigate a specific challenge in building RLHF systems that respect democratic norms. Building on impossibility results in social choice theory, we show that, under fairly broad assumptions, there is no unique voting protocol to universally align AI systems using RLHF through democratic processes. Further, we show that aligning AI agents with the values of all individuals will always violate certain private ethical preferences of an individual user i.e., universal AI alignment using RLHF is impossible. We discuss policy implications for the governance of AI systems built using RLHF: first, the need for mandating transparent voting rules to hold model builders accountable. Second, the need for model builders to focus on developing AI agents that are narrowly aligned to specific user groups.","sentences":["Aligning AI agents to human intentions and values is a key bottleneck in building safe and deployable AI applications.","But whose values should AI agents be aligned with?","Reinforcement learning with human feedback (RLHF) has emerged as the key framework for AI alignment.","RLHF uses feedback from human reinforcers to fine-tune outputs; all widely deployed large language models (LLMs) use RLHF to align their outputs to human values.","It is critical to understand the limitations of RLHF and consider policy challenges arising from these limitations.","In this paper, we investigate a specific challenge in building RLHF systems that respect democratic norms.","Building on impossibility results in social choice theory, we show that, under fairly broad assumptions, there is no unique voting protocol to universally align AI systems using RLHF through democratic processes.","Further, we show that aligning AI agents with the values of all individuals will always violate certain private ethical preferences of an individual user i.e., universal AI alignment using RLHF is impossible.","We discuss policy implications for the governance of AI systems built using RLHF: first, the need for mandating transparent voting rules to hold model builders accountable.","Second, the need for model builders to focus on developing AI agents that are narrowly aligned to specific user groups."],"url":"http://arxiv.org/abs/2310.16048v1"}
{"created":"2023-10-24 17:58:54","title":"From Posterior Sampling to Meaningful Diversity in Image Restoration","abstract":"Image restoration problems are typically ill-posed in the sense that each degraded image can be restored in infinitely many valid ways. To accommodate this, many works generate a diverse set of outputs by attempting to randomly sample from the posterior distribution of natural images given the degraded input. Here we argue that this strategy is commonly of limited practical value because of the heavy tail of the posterior distribution. Consider for example inpainting a missing region of the sky in an image. Since there is a high probability that the missing region contains no object but clouds, any set of samples from the posterior would be entirely dominated by (practically identical) completions of sky. However, arguably, presenting users with only one clear sky completion, along with several alternative solutions such as airships, birds, and balloons, would better outline the set of possibilities. In this paper, we initiate the study of meaningfully diverse image restoration. We explore several post-processing approaches that can be combined with any diverse image restoration method to yield semantically meaningful diversity. Moreover, we propose a practical approach for allowing diffusion based image restoration methods to generate meaningfully diverse outputs, while incurring only negligent computational overhead. We conduct extensive user studies to analyze the proposed techniques, and find the strategy of reducing similarity between outputs to be significantly favorable over posterior sampling. Code and examples are available in https://noa-cohen.github.io/MeaningfulDiversityInIR","sentences":["Image restoration problems are typically ill-posed in the sense that each degraded image can be restored in infinitely many valid ways.","To accommodate this, many works generate a diverse set of outputs by attempting to randomly sample from the posterior distribution of natural images given the degraded input.","Here we argue that this strategy is commonly of limited practical value because of the heavy tail of the posterior distribution.","Consider for example inpainting a missing region of the sky in an image.","Since there is a high probability that the missing region contains no object but clouds, any set of samples from the posterior would be entirely dominated by (practically identical) completions of sky.","However, arguably, presenting users with only one clear sky completion, along with several alternative solutions such as airships, birds, and balloons, would better outline the set of possibilities.","In this paper, we initiate the study of meaningfully diverse image restoration.","We explore several post-processing approaches that can be combined with any diverse image restoration method to yield semantically meaningful diversity.","Moreover, we propose a practical approach for allowing diffusion based image restoration methods to generate meaningfully diverse outputs, while incurring only negligent computational overhead.","We conduct extensive user studies to analyze the proposed techniques, and find the strategy of reducing similarity between outputs to be significantly favorable over posterior sampling.","Code and examples are available in https://noa-cohen.github.io/MeaningfulDiversityInIR"],"url":"http://arxiv.org/abs/2310.16047v1"}
{"created":"2023-10-24 17:58:26","title":"A Unified, Scalable Framework for Neural Population Decoding","abstract":"Our ability to use deep learning approaches to decipher neural activity would likely benefit from greater scale, in terms of both model size and datasets. However, the integration of many neural recordings into one unified model is challenging, as each recording contains the activity of different neurons from different individual animals. In this paper, we introduce a training framework and architecture designed to model the population dynamics of neural activity across diverse, large-scale neural recordings. Our method first tokenizes individual spikes within the dataset to build an efficient representation of neural events that captures the fine temporal structure of neural activity. We then employ cross-attention and a PerceiverIO backbone to further construct a latent tokenization of neural population activities. Utilizing this architecture and training framework, we construct a large-scale multi-session model trained on large datasets from seven nonhuman primates, spanning over 158 different sessions of recording from over 27,373 neural units and over 100 hours of recordings. In a number of different tasks, we demonstrate that our pretrained model can be rapidly adapted to new, unseen sessions with unspecified neuron correspondence, enabling few-shot performance with minimal labels. This work presents a powerful new approach for building deep learning tools to analyze neural data and stakes out a clear path to training at scale.","sentences":["Our ability to use deep learning approaches to decipher neural activity would likely benefit from greater scale, in terms of both model size and datasets.","However, the integration of many neural recordings into one unified model is challenging, as each recording contains the activity of different neurons from different individual animals.","In this paper, we introduce a training framework and architecture designed to model the population dynamics of neural activity across diverse, large-scale neural recordings.","Our method first tokenizes individual spikes within the dataset to build an efficient representation of neural events that captures the fine temporal structure of neural activity.","We then employ cross-attention and a PerceiverIO backbone to further construct a latent tokenization of neural population activities.","Utilizing this architecture and training framework, we construct a large-scale multi-session model trained on large datasets from seven nonhuman primates, spanning over 158 different sessions of recording from over 27,373 neural units and over 100 hours of recordings.","In a number of different tasks, we demonstrate that our pretrained model can be rapidly adapted to new, unseen sessions with unspecified neuron correspondence, enabling few-shot performance with minimal labels.","This work presents a powerful new approach for building deep learning tools to analyze neural data and stakes out a clear path to training at scale."],"url":"http://arxiv.org/abs/2310.16046v1"}
{"created":"2023-10-24 17:58:07","title":"Woodpecker: Hallucination Correction for Multimodal Large Language Models","abstract":"Hallucination is a big shadow hanging over the rapidly evolving Multimodal Large Language Models (MLLMs), referring to the phenomenon that the generated text is inconsistent with the image content. In order to mitigate hallucinations, existing studies mainly resort to an instruction-tuning manner that requires retraining the models with specific data. In this paper, we pave a different way, introducing a training-free method named Woodpecker. Like a woodpecker heals trees, it picks out and corrects hallucinations from the generated text. Concretely, Woodpecker consists of five stages: key concept extraction, question formulation, visual knowledge validation, visual claim generation, and hallucination correction. Implemented in a post-remedy manner, Woodpecker can easily serve different MLLMs, while being interpretable by accessing intermediate outputs of the five stages. We evaluate Woodpecker both quantitatively and qualitatively and show the huge potential of this new paradigm. On the POPE benchmark, our method obtains a 30.66%/24.33% improvement in accuracy over the baseline MiniGPT-4/mPLUG-Owl. The source code is released at https://github.com/BradyFU/Woodpecker.","sentences":["Hallucination is a big shadow hanging over the rapidly evolving Multimodal Large Language Models (MLLMs), referring to the phenomenon that the generated text is inconsistent with the image content.","In order to mitigate hallucinations, existing studies mainly resort to an instruction-tuning manner that requires retraining the models with specific data.","In this paper, we pave a different way, introducing a training-free method named Woodpecker.","Like a woodpecker heals trees, it picks out and corrects hallucinations from the generated text.","Concretely, Woodpecker consists of five stages: key concept extraction, question formulation, visual knowledge validation, visual claim generation, and hallucination correction.","Implemented in a post-remedy manner, Woodpecker can easily serve different MLLMs, while being interpretable by accessing intermediate outputs of the five stages.","We evaluate Woodpecker both quantitatively and qualitatively and show the huge potential of this new paradigm.","On the POPE benchmark, our method obtains a 30.66%/24.33% improvement in accuracy over the baseline MiniGPT-4/mPLUG-Owl.","The source code is released at https://github.com/BradyFU/Woodpecker."],"url":"http://arxiv.org/abs/2310.16045v1"}
{"created":"2023-10-24 17:57:58","title":"Stanford-ORB: A Real-World 3D Object Inverse Rendering Benchmark","abstract":"We introduce Stanford-ORB, a new real-world 3D Object inverse Rendering Benchmark. Recent advances in inverse rendering have enabled a wide range of real-world applications in 3D content generation, moving rapidly from research and commercial use cases to consumer devices. While the results continue to improve, there is no real-world benchmark that can quantitatively assess and compare the performance of various inverse rendering methods. Existing real-world datasets typically only consist of the shape and multi-view images of objects, which are not sufficient for evaluating the quality of material recovery and object relighting. Methods capable of recovering material and lighting often resort to synthetic data for quantitative evaluation, which on the other hand does not guarantee generalization to complex real-world environments. We introduce a new dataset of real-world objects captured under a variety of natural scenes with ground-truth 3D scans, multi-view images, and environment lighting. Using this dataset, we establish the first comprehensive real-world evaluation benchmark for object inverse rendering tasks from in-the-wild scenes, and compare the performance of various existing methods. All data, code, and models can be accessed at https://stanfordorb.github.io/.","sentences":["We introduce Stanford-ORB, a new real-world 3D Object inverse Rendering Benchmark.","Recent advances in inverse rendering have enabled a wide range of real-world applications in 3D content generation, moving rapidly from research and commercial use cases to consumer devices.","While the results continue to improve, there is no real-world benchmark that can quantitatively assess and compare the performance of various inverse rendering methods.","Existing real-world datasets typically only consist of the shape and multi-view images of objects, which are not sufficient for evaluating the quality of material recovery and object relighting.","Methods capable of recovering material and lighting often resort to synthetic data for quantitative evaluation, which on the other hand does not guarantee generalization to complex real-world environments.","We introduce a new dataset of real-world objects captured under a variety of natural scenes with ground-truth 3D scans, multi-view images, and environment lighting.","Using this dataset, we establish the first comprehensive real-world evaluation benchmark for object inverse rendering tasks from in-the-wild scenes, and compare the performance of various existing methods.","All data, code, and models can be accessed at https://stanfordorb.github.io/."],"url":"http://arxiv.org/abs/2310.16044v1"}
{"created":"2023-10-24 17:57:03","title":"WebWISE: Web Interface Control and Sequential Exploration with Large Language Models","abstract":"The paper investigates using a Large Language Model (LLM) to automatically perform web software tasks using click, scroll, and text input operations. Previous approaches, such as reinforcement learning (RL) or imitation learning, are inefficient to train and task-specific. Our method uses filtered Document Object Model (DOM) elements as observations and performs tasks step-by-step, sequentially generating small programs based on the current observations. We use in-context learning, either benefiting from a single manually provided example, or an automatically generated example based on a successful zero-shot trial. We evaluate the proposed method on the MiniWob++ benchmark. With only one in-context example, our WebWISE method achieves similar or better performance than other methods that require many demonstrations or trials.","sentences":["The paper investigates using a Large Language Model (LLM) to automatically perform web software tasks using click, scroll, and text input operations.","Previous approaches, such as reinforcement learning (RL) or imitation learning, are inefficient to train and task-specific.","Our method uses filtered Document Object Model (DOM) elements as observations and performs tasks step-by-step, sequentially generating small programs based on the current observations.","We use in-context learning, either benefiting from a single manually provided example, or an automatically generated example based on a successful zero-shot trial.","We evaluate the proposed method on the MiniWob++ benchmark.","With only one in-context example, our WebWISE method achieves similar or better performance than other methods that require many demonstrations or trials."],"url":"http://arxiv.org/abs/2310.16042v1"}
{"created":"2023-10-24 17:54:25","title":"Instruct and Extract: Instruction Tuning for On-Demand Information Extraction","abstract":"Large language models with instruction-following capabilities open the door to a wider group of users. However, when it comes to information extraction - a classic task in natural language processing - most task-specific systems cannot align well with long-tail ad hoc extraction use cases for non-expert users. To address this, we propose a novel paradigm, termed On-Demand Information Extraction, to fulfill the personalized demands of real-world users. Our task aims to follow the instructions to extract the desired content from the associated text and present it in a structured tabular format. The table headers can either be user-specified or inferred contextually by the model. To facilitate research in this emerging area, we present a benchmark named InstructIE, inclusive of both automatically generated training data, as well as the human-annotated test set. Building on InstructIE, we further develop an On-Demand Information Extractor, ODIE. Comprehensive evaluations on our benchmark reveal that ODIE substantially outperforms the existing open-source models of similar size. Our code and dataset are released on https://github.com/yzjiao/On-Demand-IE.","sentences":["Large language models with instruction-following capabilities open the door to a wider group of users.","However, when it comes to information extraction - a classic task in natural language processing - most task-specific systems cannot align well with long-tail ad hoc extraction use cases for non-expert users.","To address this, we propose a novel paradigm, termed On-Demand Information Extraction, to fulfill the personalized demands of real-world users.","Our task aims to follow the instructions to extract the desired content from the associated text and present it in a structured tabular format.","The table headers can either be user-specified or inferred contextually by the model.","To facilitate research in this emerging area, we present a benchmark named InstructIE, inclusive of both automatically generated training data, as well as the human-annotated test set.","Building on InstructIE, we further develop an On-Demand Information Extractor, ODIE.","Comprehensive evaluations on our benchmark reveal that ODIE substantially outperforms the existing open-source models of similar size.","Our code and dataset are released on https://github.com/yzjiao/On-Demand-IE."],"url":"http://arxiv.org/abs/2310.16040v1"}
{"created":"2023-10-24 17:50:20","title":"What's Left? Concept Grounding with Logic-Enhanced Foundation Models","abstract":"Recent works such as VisProg and ViperGPT have smartly composed foundation models for visual reasoning-using large language models (LLMs) to produce programs that can be executed by pre-trained vision-language models. However, they operate in limited domains, such as 2D images, not fully exploiting the generalization of language: abstract concepts like \"left\" can also be grounded in 3D, temporal, and action data, as in moving to your left. This limited generalization stems from these inference-only methods' inability to learn or adapt pre-trained models to a new domain. We propose the Logic-Enhanced Foundation Model (LEFT), a unified framework that learns to ground and reason with concepts across domains with a differentiable, domain-independent, first-order logic-based program executor. LEFT has an LLM interpreter that outputs a program represented in a general, logic-based reasoning language, which is shared across all domains and tasks. LEFT's executor then executes the program with trainable domain-specific grounding modules. We show that LEFT flexibly learns concepts in four domains: 2D images, 3D scenes, human motions, and robotic manipulation. It exhibits strong reasoning ability in a wide variety of tasks, including those that are complex and not seen during training, and can be easily applied to new domains.","sentences":["Recent works such as VisProg and ViperGPT have smartly composed foundation models for visual reasoning-using large language models (LLMs) to produce programs that can be executed by pre-trained vision-language models.","However, they operate in limited domains, such as 2D images, not fully exploiting the generalization of language: abstract concepts like \"left\" can also be grounded in 3D, temporal, and action data, as in moving to your left.","This limited generalization stems from these inference-only methods' inability to learn or adapt pre-trained models to a new domain.","We propose the Logic-Enhanced Foundation Model (LEFT), a unified framework that learns to ground and reason with concepts across domains with a differentiable, domain-independent, first-order logic-based program executor.","LEFT has an LLM interpreter that outputs a program represented in a general, logic-based reasoning language, which is shared across all domains and tasks.","LEFT's executor then executes the program with trainable domain-specific grounding modules.","We show that LEFT flexibly learns concepts in four domains: 2D images, 3D scenes, human motions, and robotic manipulation.","It exhibits strong reasoning ability in a wide variety of tasks, including those that are complex and not seen during training, and can be easily applied to new domains."],"url":"http://arxiv.org/abs/2310.16035v1"}
{"created":"2023-10-24 17:48:04","title":"Visual Cropping Improves Zero-Shot Question Answering of Multimodal Large Language Models","abstract":"Multimodal Large Language Models (LLMs) have recently achieved promising zero-shot accuracy on visual question answering (VQA) -- a fundamental task affecting various downstream applications and domains. Given the great potential for the broad use of these models, it is important to investigate their limitations in dealing with different image and question properties. In this work, we investigate whether multimodal LLMs can perceive small details as well as large details in images. In particular, we show that their zero-shot accuracy in answering visual questions is very sensitive to the size of the visual subject of the question, declining up to $46\\%$ with size. Furthermore, we show that this effect is causal by observing that human visual cropping can significantly mitigate their sensitivity to size. Inspired by the usefulness of human cropping, we then propose three automatic visual cropping methods as inference time mechanisms to improve the zero-shot performance of multimodal LLMs. We study their effectiveness on four popular VQA datasets, and a subset of the VQAv2 dataset tailored towards fine visual details. Our findings suggest that multimodal LLMs should be used with caution in detail-sensitive VQA applications, and that visual cropping is a promising direction to improve their zero-shot performance. Our code and data are publicly available.","sentences":["Multimodal Large Language Models (LLMs) have recently achieved promising zero-shot accuracy on visual question answering (VQA) -- a fundamental task affecting various downstream applications and domains.","Given the great potential for the broad use of these models, it is important to investigate their limitations in dealing with different image and question properties.","In this work, we investigate whether multimodal LLMs can perceive small details as well as large details in images.","In particular, we show that their zero-shot accuracy in answering visual questions is very sensitive to the size of the visual subject of the question, declining up to $46\\%$ with size.","Furthermore, we show that this effect is causal by observing that human visual cropping can significantly mitigate their sensitivity to size.","Inspired by the usefulness of human cropping, we then propose three automatic visual cropping methods as inference time mechanisms to improve the zero-shot performance of multimodal LLMs.","We study their effectiveness on four popular VQA datasets, and a subset of the VQAv2 dataset tailored towards fine visual details.","Our findings suggest that multimodal LLMs should be used with caution in detail-sensitive VQA applications, and that visual cropping is a promising direction to improve their zero-shot performance.","Our code and data are publicly available."],"url":"http://arxiv.org/abs/2310.16033v1"}
{"created":"2023-10-24 17:46:12","title":"Finetuning Offline World Models in the Real World","abstract":"Reinforcement Learning (RL) is notoriously data-inefficient, which makes training on a real robot difficult. While model-based RL algorithms (world models) improve data-efficiency to some extent, they still require hours or days of interaction to learn skills. Recently, offline RL has been proposed as a framework for training RL policies on pre-existing datasets without any online interaction. However, constraining an algorithm to a fixed dataset induces a state-action distribution shift between training and inference, and limits its applicability to new tasks. In this work, we seek to get the best of both worlds: we consider the problem of pretraining a world model with offline data collected on a real robot, and then finetuning the model on online data collected by planning with the learned model. To mitigate extrapolation errors during online interaction, we propose to regularize the planner at test-time by balancing estimated returns and (epistemic) model uncertainty. We evaluate our method on a variety of visuo-motor control tasks in simulation and on a real robot, and find that our method enables few-shot finetuning to seen and unseen tasks even when offline data is limited. Videos, code, and data are available at https://yunhaifeng.com/FOWM .","sentences":["Reinforcement Learning (RL) is notoriously data-inefficient, which makes training on a real robot difficult.","While model-based RL algorithms (world models) improve data-efficiency to some extent, they still require hours or days of interaction to learn skills.","Recently, offline RL has been proposed as a framework for training RL policies on pre-existing datasets without any online interaction.","However, constraining an algorithm to a fixed dataset induces a state-action distribution shift between training and inference, and limits its applicability to new tasks.","In this work, we seek to get the best of both worlds: we consider the problem of pretraining a world model with offline data collected on a real robot, and then finetuning the model on online data collected by planning with the learned model.","To mitigate extrapolation errors during online interaction, we propose to regularize the planner at test-time by balancing estimated returns and (epistemic) model uncertainty.","We evaluate our method on a variety of visuo-motor control tasks in simulation and on a real robot, and find that our method enables few-shot finetuning to seen and unseen tasks even when offline data is limited.","Videos, code, and data are available at https://yunhaifeng.com/FOWM ."],"url":"http://arxiv.org/abs/2310.16029v1"}
{"created":"2023-10-24 17:43:29","title":"What Algorithms can Transformers Learn? A Study in Length Generalization","abstract":"Large language models exhibit surprising emergent generalization properties, yet also struggle on many simple reasoning tasks such as arithmetic and parity. This raises the question of if and when Transformer models can learn the true algorithm for solving a task. We study the scope of Transformers' abilities in the specific setting of length generalization on algorithmic tasks. Here, we propose a unifying framework to understand when and how Transformers can exhibit strong length generalization on a given task. Specifically, we leverage RASP (Weiss et al., 2021) -- a programming language designed for the computational model of a Transformer -- and introduce the RASP-Generalization Conjecture: Transformers tend to length generalize on a task if the task can be solved by a short RASP program which works for all input lengths. This simple conjecture remarkably captures most known instances of length generalization on algorithmic tasks. Moreover, we leverage our insights to drastically improve generalization performance on traditionally hard tasks (such as parity and addition). On the theoretical side, we give a simple example where the \"min-degree-interpolator\" model of learning from Abbe et al. (2023) does not correctly predict Transformers' out-of-distribution behavior, but our conjecture does. Overall, our work provides a novel perspective on the mechanisms of compositional generalization and the algorithmic capabilities of Transformers.","sentences":["Large language models exhibit surprising emergent generalization properties, yet also struggle on many simple reasoning tasks such as arithmetic and parity.","This raises the question of if and when Transformer models can learn the true algorithm for solving a task.","We study the scope of Transformers' abilities in the specific setting of length generalization on algorithmic tasks.","Here, we propose a unifying framework to understand when and how Transformers can exhibit strong length generalization on a given task.","Specifically, we leverage RASP (Weiss et al., 2021) -- a programming language designed for the computational model of a Transformer -- and introduce the RASP-Generalization Conjecture:","Transformers tend to length generalize on a task if the task can be solved by a short RASP program which works for all input lengths.","This simple conjecture remarkably captures most known instances of length generalization on algorithmic tasks.","Moreover, we leverage our insights to drastically improve generalization performance on traditionally hard tasks (such as parity and addition).","On the theoretical side, we give a simple example where the \"min-degree-interpolator\" model of learning from Abbe et al.","(2023) does not correctly predict Transformers' out-of-distribution behavior, but our conjecture does.","Overall, our work provides a novel perspective on the mechanisms of compositional generalization and the algorithmic capabilities of Transformers."],"url":"http://arxiv.org/abs/2310.16028v1"}
{"created":"2023-10-24 17:43:16","title":"TimewarpVAE: Simultaneous Time-Warping and Representation Learning of Trajectories","abstract":"Human demonstrations of trajectories are an important source of training data for many machine learning problems. However, the difficulty of collecting human demonstration data for complex tasks makes learning efficient representations of those trajectories challenging. For many problems, such as for handwriting or for quasistatic dexterous manipulation, the exact timings of the trajectories should be factored from their spatial path characteristics. In this work, we propose TimewarpVAE, a fully differentiable manifold-learning algorithm that incorporates Dynamic Time Warping (DTW) to simultaneously learn both timing variations and latent factors of spatial variation. We show how the TimewarpVAE algorithm learns appropriate time alignments and meaningful representations of spatial variations in small handwriting and fork manipulation datasets. Our results have lower spatial reconstruction test error than baseline approaches and the learned low-dimensional representations can be used to efficiently generate semantically meaningful novel trajectories.","sentences":["Human demonstrations of trajectories are an important source of training data for many machine learning problems.","However, the difficulty of collecting human demonstration data for complex tasks makes learning efficient representations of those trajectories challenging.","For many problems, such as for handwriting or for quasistatic dexterous manipulation, the exact timings of the trajectories should be factored from their spatial path characteristics.","In this work, we propose TimewarpVAE, a fully differentiable manifold-learning algorithm that incorporates Dynamic Time Warping (DTW) to simultaneously learn both timing variations and latent factors of spatial variation.","We show how the TimewarpVAE algorithm learns appropriate time alignments and meaningful representations of spatial variations in small handwriting and fork manipulation datasets.","Our results have lower spatial reconstruction test error than baseline approaches and the learned low-dimensional representations can be used to efficiently generate semantically meaningful novel trajectories."],"url":"http://arxiv.org/abs/2310.16027v1"}
{"created":"2023-10-24 17:31:26","title":"A Colorful and Robust Measure for FDFAs","abstract":"We define a measure on families of DFAs (FDFAs) that we show to be robust in the sense that two FDFAs for the same language are guaranteed to agree on this measure. This measure tightly relates to the Wagner-Hierarchy (that defines the complexity of omega regular languages). Inspired by the recently introduced natural colors of infinite words, we define natural colors for finite words (prefixes of periods of infinite words). From this semantic definition we derive the Colorful FDFA a novel canonical model for $\\omega$-regular languages that also assigns correct colors for finite and infinite words. From the colorful FDFA, for languages that can be recognized by deterministic B\\\"uchi or coB\\\"uchi automata, we generate a canonical DBA or DCA termed the Black $\\&$ White Automaton, thus complementing the recent result on canonical good for games coB\\\"uchi automata for coB\\\"uchi languages.","sentences":["We define a measure on families of DFAs (FDFAs) that we show to be robust in the sense that two FDFAs for the same language are guaranteed to agree on this measure.","This measure tightly relates to the Wagner-Hierarchy (that defines the complexity of omega regular languages).","Inspired by the recently introduced natural colors of infinite words, we define natural colors for finite words (prefixes of periods of infinite words).","From this semantic definition we derive the Colorful FDFA a novel canonical model for $\\omega$-regular languages that also assigns correct colors for finite and infinite words.","From the colorful FDFA, for languages that can be recognized by deterministic B\\\"uchi or coB\\\"uchi automata, we generate a canonical DBA or DCA termed the Black $\\&$ White Automaton, thus complementing the recent result on canonical good for games coB\\\"uchi automata for coB\\\"uchi languages."],"url":"http://arxiv.org/abs/2310.16022v1"}
{"created":"2023-10-24 17:30:26","title":"ConvBKI: Real-Time Probabilistic Semantic Mapping Network with Quantifiable Uncertainty","abstract":"In this paper, we develop a modular neural network for real-time semantic mapping in uncertain environments, which explicitly updates per-voxel probabilistic distributions within a neural network layer. Our approach combines the reliability of classical probabilistic algorithms with the performance and efficiency of modern neural networks. Although robotic perception is often divided between modern differentiable methods and classical explicit methods, a union of both is necessary for real-time and trustworthy performance. We introduce a novel Convolutional Bayesian Kernel Inference (ConvBKI) layer which incorporates semantic segmentation predictions online into a 3D map through a depthwise convolution layer by leveraging conjugate priors. We compare ConvBKI against state-of-the-art deep learning approaches and probabilistic algorithms for mapping to evaluate reliability and performance. We also create a Robot Operating System (ROS) package of ConvBKI and test it on real-world perceptually challenging off-road driving data.","sentences":["In this paper, we develop a modular neural network for real-time semantic mapping in uncertain environments, which explicitly updates per-voxel probabilistic distributions within a neural network layer.","Our approach combines the reliability of classical probabilistic algorithms with the performance and efficiency of modern neural networks.","Although robotic perception is often divided between modern differentiable methods and classical explicit methods, a union of both is necessary for real-time and trustworthy performance.","We introduce a novel Convolutional Bayesian Kernel Inference (ConvBKI) layer which incorporates semantic segmentation predictions online into a 3D map through a depthwise convolution layer by leveraging conjugate priors.","We compare ConvBKI against state-of-the-art deep learning approaches and probabilistic algorithms for mapping to evaluate reliability and performance.","We also create a Robot Operating System (ROS) package of ConvBKI and test it on real-world perceptually challenging off-road driving data."],"url":"http://arxiv.org/abs/2310.16020v1"}
{"created":"2023-10-24 17:15:16","title":"Human-in-the-Loop Task and Motion Planning for Imitation Learning","abstract":"Imitation learning from human demonstrations can teach robots complex manipulation skills, but is time-consuming and labor intensive. In contrast, Task and Motion Planning (TAMP) systems are automated and excel at solving long-horizon tasks, but they are difficult to apply to contact-rich tasks. In this paper, we present Human-in-the-Loop Task and Motion Planning (HITL-TAMP), a novel system that leverages the benefits of both approaches. The system employs a TAMP-gated control mechanism, which selectively gives and takes control to and from a human teleoperator. This enables the human teleoperator to manage a fleet of robots, maximizing data collection efficiency. The collected human data is then combined with an imitation learning framework to train a TAMP-gated policy, leading to superior performance compared to training on full task demonstrations. We compared HITL-TAMP to a conventional teleoperation system -- users gathered more than 3x the number of demos given the same time budget. Furthermore, proficient agents (75\\%+ success) could be trained from just 10 minutes of non-expert teleoperation data. Finally, we collected 2.1K demos with HITL-TAMP across 12 contact-rich, long-horizon tasks and show that the system often produces near-perfect agents. Videos and additional results at https://hitltamp.github.io .","sentences":["Imitation learning from human demonstrations can teach robots complex manipulation skills, but is time-consuming and labor intensive.","In contrast, Task and Motion Planning (TAMP) systems are automated and excel at solving long-horizon tasks, but they are difficult to apply to contact-rich tasks.","In this paper, we present Human-in-the-Loop Task and Motion Planning (HITL-TAMP), a novel system that leverages the benefits of both approaches.","The system employs a TAMP-gated control mechanism, which selectively gives and takes control to and from a human teleoperator.","This enables the human teleoperator to manage a fleet of robots, maximizing data collection efficiency.","The collected human data is then combined with an imitation learning framework to train a TAMP-gated policy, leading to superior performance compared to training on full task demonstrations.","We compared HITL-TAMP to a conventional teleoperation system -- users gathered more than 3x the number of demos given the same time budget.","Furthermore, proficient agents (75\\%+ success) could be trained from just 10 minutes of non-expert teleoperation data.","Finally, we collected 2.1K demos with HITL-TAMP across 12 contact-rich, long-horizon tasks and show that the system often produces near-perfect agents.","Videos and additional results at https://hitltamp.github.io ."],"url":"http://arxiv.org/abs/2310.16014v1"}
{"created":"2023-10-24 17:00:00","title":"MLFMF: Data Sets for Machine Learning for Mathematical Formalization","abstract":"We introduce MLFMF, a collection of data sets for benchmarking recommendation systems used to support formalization of mathematics with proof assistants. These systems help humans identify which previous entries (theorems, constructions, datatypes, and postulates) are relevant in proving a new theorem or carrying out a new construction. Each data set is derived from a library of formalized mathematics written in proof assistants Agda or Lean. The collection includes the largest Lean~4 library Mathlib, and some of the largest Agda libraries: the standard library, the library of univalent mathematics Agda-unimath, and the TypeTopology library. Each data set represents the corresponding library in two ways: as a heterogeneous network, and as a list of s-expressions representing the syntax trees of all the entries in the library. The network contains the (modular) structure of the library and the references between entries, while the s-expressions give complete and easily parsed information about every entry. We report baseline results using standard graph and word embeddings, tree ensembles, and instance-based learning algorithms. The MLFMF data sets provide solid benchmarking support for further investigation of the numerous machine learning approaches to formalized mathematics. The methodology used to extract the networks and the s-expressions readily applies to other libraries, and is applicable to other proof assistants. With more than $250\\,000$ entries in total, this is currently the largest collection of formalized mathematical knowledge in machine learnable format.","sentences":["We introduce MLFMF, a collection of data sets for benchmarking recommendation systems used to support formalization of mathematics with proof assistants.","These systems help humans identify which previous entries (theorems, constructions, datatypes, and postulates) are relevant in proving a new theorem or carrying out a new construction.","Each data set is derived from a library of formalized mathematics written in proof assistants Agda or Lean.","The collection includes the largest Lean~4 library Mathlib, and some of the largest Agda libraries: the standard library, the library of univalent mathematics Agda-unimath, and the TypeTopology library.","Each data set represents the corresponding library in two ways: as a heterogeneous network, and as a list of s-expressions representing the syntax trees of all the entries in the library.","The network contains the (modular) structure of the library and the references between entries, while the s-expressions give complete and easily parsed information about every entry.","We report baseline results using standard graph and word embeddings, tree ensembles, and instance-based learning algorithms.","The MLFMF data sets provide solid benchmarking support for further investigation of the numerous machine learning approaches to formalized mathematics.","The methodology used to extract the networks and the s-expressions readily applies to other libraries, and is applicable to other proof assistants.","With more than $250\\,000$ entries in total, this is currently the largest collection of formalized mathematical knowledge in machine learnable format."],"url":"http://arxiv.org/abs/2310.16005v1"}
{"created":"2023-10-24 16:56:58","title":"CVPR 2023 Text Guided Video Editing Competition","abstract":"Humans watch more than a billion hours of video per day. Most of this video was edited manually, which is a tedious process. However, AI-enabled video-generation and video-editing is on the rise. Building on text-to-image models like Stable Diffusion and Imagen, generative AI has improved dramatically on video tasks. But it's hard to evaluate progress in these video tasks because there is no standard benchmark. So, we propose a new dataset for text-guided video editing (TGVE), and we run a competition at CVPR to evaluate models on our TGVE dataset. In this paper we present a retrospective on the competition and describe the winning method. The competition dataset is available at https://sites.google.com/view/loveucvpr23/track4.","sentences":["Humans watch more than a billion hours of video per day.","Most of this video was edited manually, which is a tedious process.","However, AI-enabled video-generation and video-editing is on the rise.","Building on text-to-image models like Stable Diffusion and Imagen, generative AI has improved dramatically on video tasks.","But it's hard to evaluate progress in these video tasks because there is no standard benchmark.","So, we propose a new dataset for text-guided video editing (TGVE), and we run a competition at CVPR to evaluate models on our TGVE dataset.","In this paper we present a retrospective on the competition and describe the winning method.","The competition dataset is available at https://sites.google.com/view/loveucvpr23/track4."],"url":"http://arxiv.org/abs/2310.16003v1"}
{"created":"2023-10-24 16:55:07","title":"Integrating View Conditions for Image Synthesis","abstract":"In the field of image processing, applying intricate semantic modifications within existing images remains an enduring challenge. This paper introduces a pioneering framework that integrates viewpoint information to enhance the control of image editing tasks. By surveying existing object editing methodologies, we distill three essential criteria, consistency, controllability, and harmony, that should be met for an image editing method. In contrast to previous approaches, our method takes the lead in satisfying all three requirements for addressing the challenge of image synthesis. Through comprehensive experiments, encompassing both quantitative assessments and qualitative comparisons with contemporary state-of-the-art methods, we present compelling evidence of our framework's superior performance across multiple dimensions. This work establishes a promising avenue for advancing image synthesis techniques and empowering precise object modifications while preserving the visual coherence of the entire composition.","sentences":["In the field of image processing, applying intricate semantic modifications within existing images remains an enduring challenge.","This paper introduces a pioneering framework that integrates viewpoint information to enhance the control of image editing tasks.","By surveying existing object editing methodologies, we distill three essential criteria, consistency, controllability, and harmony, that should be met for an image editing method.","In contrast to previous approaches, our method takes the lead in satisfying all three requirements for addressing the challenge of image synthesis.","Through comprehensive experiments, encompassing both quantitative assessments and qualitative comparisons with contemporary state-of-the-art methods, we present compelling evidence of our framework's superior performance across multiple dimensions.","This work establishes a promising avenue for advancing image synthesis techniques and empowering precise object modifications while preserving the visual coherence of the entire composition."],"url":"http://arxiv.org/abs/2310.16002v1"}
{"created":"2023-10-24 16:48:56","title":"Transitivity Recovering Decompositions: Interpretable and Robust Fine-Grained Relationships","abstract":"Recent advances in fine-grained representation learning leverage local-to-global (emergent) relationships for achieving state-of-the-art results. The relational representations relied upon by such methods, however, are abstract. We aim to deconstruct this abstraction by expressing them as interpretable graphs over image views. We begin by theoretically showing that abstract relational representations are nothing but a way of recovering transitive relationships among local views. Based on this, we design Transitivity Recovering Decompositions (TRD), a graph-space search algorithm that identifies interpretable equivalents of abstract emergent relationships at both instance and class levels, and with no post-hoc computations. We additionally show that TRD is provably robust to noisy views, with empirical evidence also supporting this finding. The latter allows TRD to perform at par or even better than the state-of-the-art, while being fully interpretable. Implementation is available at https://github.com/abhrac/trd.","sentences":["Recent advances in fine-grained representation learning leverage local-to-global (emergent) relationships for achieving state-of-the-art results.","The relational representations relied upon by such methods, however, are abstract.","We aim to deconstruct this abstraction by expressing them as interpretable graphs over image views.","We begin by theoretically showing that abstract relational representations are nothing but a way of recovering transitive relationships among local views.","Based on this, we design Transitivity Recovering Decompositions (TRD), a graph-space search algorithm that identifies interpretable equivalents of abstract emergent relationships at both instance and class levels, and with no post-hoc computations.","We additionally show that TRD is provably robust to noisy views, with empirical evidence also supporting this finding.","The latter allows TRD to perform at par or even better than the state-of-the-art, while being fully interpretable.","Implementation is available at https://github.com/abhrac/trd."],"url":"http://arxiv.org/abs/2310.15999v1"}
{"created":"2023-10-24 16:39:06","title":"White-box Compiler Fuzzing Empowered by Large Language Models","abstract":"Compiler correctness is crucial, as miscompilation falsifying the program behaviors can lead to serious consequences. In the literature, fuzzing has been extensively studied to uncover compiler defects. However, compiler fuzzing remains challenging: Existing arts focus on black- and grey-box fuzzing, which generates tests without sufficient understanding of internal compiler behaviors. As such, they often fail to construct programs to exercise conditions of intricate optimizations. Meanwhile, traditional white-box techniques are computationally inapplicable to the giant codebase of compilers. Recent advances demonstrate that Large Language Models (LLMs) excel in code generation/understanding tasks and have achieved state-of-the-art performance in black-box fuzzing. Nonetheless, prompting LLMs with compiler source-code information remains a missing piece of research in compiler testing.   To this end, we propose WhiteFox, the first white-box compiler fuzzer using LLMs with source-code information to test compiler optimization. WhiteFox adopts a dual-model framework: (i) an analysis LLM examines the low-level optimization source code and produces requirements on the high-level test programs that can trigger the optimization; (ii) a generation LLM produces test programs based on the summarized requirements. Additionally, optimization-triggering tests are used as feedback to further enhance the test generation on the fly. Our evaluation on four popular compilers shows that WhiteFox can generate high-quality tests to exercise deep optimizations requiring intricate conditions, practicing up to 80 more optimizations than state-of-the-art fuzzers. To date, WhiteFox has found in total 96 bugs, with 80 confirmed as previously unknown and 51 already fixed. Beyond compiler testing, WhiteFox can also be adapted for white-box fuzzing of other complex, real-world software systems in general.","sentences":["Compiler correctness is crucial, as miscompilation falsifying the program behaviors can lead to serious consequences.","In the literature, fuzzing has been extensively studied to uncover compiler defects.","However, compiler fuzzing remains challenging: Existing arts focus on black- and grey-box fuzzing, which generates tests without sufficient understanding of internal compiler behaviors.","As such, they often fail to construct programs to exercise conditions of intricate optimizations.","Meanwhile, traditional white-box techniques are computationally inapplicable to the giant codebase of compilers.","Recent advances demonstrate that Large Language Models (LLMs) excel in code generation/understanding tasks and have achieved state-of-the-art performance in black-box fuzzing.","Nonetheless, prompting LLMs with compiler source-code information remains a missing piece of research in compiler testing.   ","To this end, we propose WhiteFox, the first white-box compiler fuzzer using LLMs with source-code information to test compiler optimization.","WhiteFox adopts a dual-model framework: (i) an analysis LLM examines the low-level optimization source code and produces requirements on the high-level test programs that can trigger the optimization; (ii) a generation LLM produces test programs based on the summarized requirements.","Additionally, optimization-triggering tests are used as feedback to further enhance the test generation on the fly.","Our evaluation on four popular compilers shows that WhiteFox can generate high-quality tests to exercise deep optimizations requiring intricate conditions, practicing up to 80 more optimizations than state-of-the-art fuzzers.","To date, WhiteFox has found in total 96 bugs, with 80 confirmed as previously unknown and 51 already fixed.","Beyond compiler testing, WhiteFox can also be adapted for white-box fuzzing of other complex, real-world software systems in general."],"url":"http://arxiv.org/abs/2310.15991v1"}
{"created":"2023-10-24 16:37:24","title":"FabricCRDT: A Conflict-Free Replicated Datatypes Approach to Permissioned Blockchains","abstract":"With the increased adaption of blockchain technologies, permissioned blockchains such as Hyperledger Fabric provide a robust ecosystem for developing production-grade decentralized applications. However, the additional latency between executing and committing transactions, due to Fabric's three-phase transaction lifecycle of Execute-Order-Validate (EOV), is a potential scalability bottleneck. The added latency increases the probability of concurrent updates on the same keys by different transactions, leading to transaction failures caused by Fabric's concurrency control mechanism. The transaction failures increase the application development complexity and decrease Fabric's throughput. Conflict-free Replicated Datatypes (CRDTs) provide a solution for merging and resolving conflicts in the presence of concurrent updates. In this work, we introduce FabricCRDT, an approach for integrating CRDTs to Fabric. Our evaluations show that in general, FabricCRDT offers higher throughput of successful transactions than Fabric, while successfully committing and merging all conflicting transactions without any failures.","sentences":["With the increased adaption of blockchain technologies, permissioned blockchains such as Hyperledger Fabric provide a robust ecosystem for developing production-grade decentralized applications.","However, the additional latency between executing and committing transactions, due to Fabric's three-phase transaction lifecycle of Execute-Order-Validate (EOV), is a potential scalability bottleneck.","The added latency increases the probability of concurrent updates on the same keys by different transactions, leading to transaction failures caused by Fabric's concurrency control mechanism.","The transaction failures increase the application development complexity and decrease Fabric's throughput.","Conflict-free Replicated Datatypes (CRDTs) provide a solution for merging and resolving conflicts in the presence of concurrent updates.","In this work, we introduce FabricCRDT, an approach for integrating CRDTs to Fabric.","Our evaluations show that in general, FabricCRDT offers higher throughput of successful transactions than Fabric, while successfully committing and merging all conflicting transactions without any failures."],"url":"http://arxiv.org/abs/2310.15988v1"}
{"created":"2023-10-24 16:37:18","title":"Dissecting In-Context Learning of Translations in GPTs","abstract":"Most of the recent work in leveraging Large Language Models (LLMs) such as GPT-3 for Machine Translation (MT) has focused on selecting the few-shot samples for prompting. In this work, we try to better understand the role of demonstration attributes for the in-context learning of translations through perturbations of high-quality, in-domain demonstrations. We find that asymmetric perturbation of the source-target mappings yield vastly different results. We show that the perturbation of the source side has surprisingly little impact, while target perturbation can drastically reduce translation quality, suggesting that it is the output text distribution that provides the most important learning signal during in-context learning of translations. We propose a method named Zero-Shot-Context to add this signal automatically in Zero-Shot prompting. We demonstrate that it improves upon the zero-shot translation performance of GPT-3, even making it competitive with few-shot prompted translations.","sentences":["Most of the recent work in leveraging Large Language Models (LLMs) such as GPT-3 for Machine Translation (MT) has focused on selecting the few-shot samples for prompting.","In this work, we try to better understand the role of demonstration attributes for the in-context learning of translations through perturbations of high-quality, in-domain demonstrations.","We find that asymmetric perturbation of the source-target mappings yield vastly different results.","We show that the perturbation of the source side has surprisingly little impact, while target perturbation can drastically reduce translation quality, suggesting that it is the output text distribution that provides the most important learning signal during in-context learning of translations.","We propose a method named Zero-Shot-Context to add this signal automatically in Zero-Shot prompting.","We demonstrate that it improves upon the zero-shot translation performance of GPT-3, even making it competitive with few-shot prompted translations."],"url":"http://arxiv.org/abs/2310.15987v1"}
{"created":"2023-10-24 16:36:51","title":"Vision-Language Pseudo-Labels for Single-Positive Multi-Label Learning","abstract":"This paper presents a novel approach to Single-Positive Multi-label Learning. In general multi-label learning, a model learns to predict multiple labels or categories for a single input image. This is in contrast with standard multi-class image classification, where the task is predicting a single label from many possible labels for an image. Single-Positive Multi-label Learning (SPML) specifically considers learning to predict multiple labels when there is only a single annotation per image in the training data. Multi-label learning is in many ways a more realistic task than single-label learning as real-world data often involves instances belonging to multiple categories simultaneously; however, most common computer vision datasets predominantly contain single labels due to the inherent complexity and cost of collecting multiple high quality annotations for each instance. We propose a novel approach called Vision-Language Pseudo-Labeling (VLPL), which uses a vision-language model to suggest strong positive and negative pseudo-labels, and outperforms the current SOTA methods by 5.5% on Pascal VOC, 18.4% on MS-COCO, 15.2% on NUS-WIDE, and 8.4% on CUB-Birds. Our code and data are available at https://github.com/mvrl/VLPL.","sentences":["This paper presents a novel approach to Single-Positive Multi-label Learning.","In general multi-label learning, a model learns to predict multiple labels or categories for a single input image.","This is in contrast with standard multi-class image classification, where the task is predicting a single label from many possible labels for an image.","Single-Positive Multi-label Learning (SPML) specifically considers learning to predict multiple labels when there is only a single annotation per image in the training data.","Multi-label learning is in many ways a more realistic task than single-label learning as real-world data often involves instances belonging to multiple categories simultaneously; however, most common computer vision datasets predominantly contain single labels due to the inherent complexity and cost of collecting multiple high quality annotations for each instance.","We propose a novel approach called Vision-Language Pseudo-Labeling (VLPL), which uses a vision-language model to suggest strong positive and negative pseudo-labels, and outperforms the current SOTA methods by 5.5% on Pascal VOC, 18.4% on MS-COCO, 15.2% on NUS-WIDE, and 8.4% on CUB-Birds.","Our code and data are available at https://github.com/mvrl/VLPL."],"url":"http://arxiv.org/abs/2310.15985v1"}
{"created":"2023-10-24 16:34:03","title":"Geometry-Aware Video Quality Assessment for Dynamic Digital Human","abstract":"Dynamic Digital Humans (DDHs) are 3D digital models that are animated using predefined motions and are inevitably bothered by noise/shift during the generation process and compression distortion during the transmission process, which needs to be perceptually evaluated. Usually, DDHs are displayed as 2D rendered animation videos and it is natural to adapt video quality assessment (VQA) methods to DDH quality assessment (DDH-QA) tasks. However, the VQA methods are highly dependent on viewpoints and less sensitive to geometry-based distortions. Therefore, in this paper, we propose a novel no-reference (NR) geometry-aware video quality assessment method for DDH-QA challenge. Geometry characteristics are described by the statistical parameters estimated from the DDHs' geometry attribute distributions. Spatial and temporal features are acquired from the rendered videos. Finally, all kinds of features are integrated and regressed into quality values. Experimental results show that the proposed method achieves state-of-the-art performance on the DDH-QA database.","sentences":["Dynamic Digital Humans (DDHs) are 3D digital models that are animated using predefined motions and are inevitably bothered by noise/shift during the generation process and compression distortion during the transmission process, which needs to be perceptually evaluated.","Usually, DDHs are displayed as 2D rendered animation videos and it is natural to adapt video quality assessment (VQA) methods to DDH quality assessment (DDH-QA) tasks.","However, the VQA methods are highly dependent on viewpoints and less sensitive to geometry-based distortions.","Therefore, in this paper, we propose a novel no-reference (NR) geometry-aware video quality assessment method for DDH-QA challenge.","Geometry characteristics are described by the statistical parameters estimated from the DDHs' geometry attribute distributions.","Spatial and temporal features are acquired from the rendered videos.","Finally, all kinds of features are integrated and regressed into quality values.","Experimental results show that the proposed method achieves state-of-the-art performance on the DDH-QA database."],"url":"http://arxiv.org/abs/2310.15984v1"}
{"created":"2023-10-24 16:26:38","title":"Graph Deep Learning for Time Series Forecasting","abstract":"Graph-based deep learning methods have become popular tools to process collections of correlated time series. Differently from traditional multivariate forecasting methods, neural graph-based predictors take advantage of pairwise relationships by conditioning forecasts on a (possibly dynamic) graph spanning the time series collection. The conditioning can take the form of an architectural inductive bias on the neural forecasting architecture, resulting in a family of deep learning models called spatiotemporal graph neural networks. Such relational inductive biases enable the training of global forecasting models on large time-series collections, while at the same time localizing predictions w.r.t. each element in the set (i.e., graph nodes) by accounting for local correlations among them (i.e., graph edges). Indeed, recent theoretical and practical advances in graph neural networks and deep learning for time series forecasting make the adoption of such processing frameworks appealing and timely. However, most of the studies in the literature focus on proposing variations of existing neural architectures by taking advantage of modern deep learning practices, while foundational and methodological aspects have not been subject to systematic investigation. To fill the gap, this paper aims to introduce a comprehensive methodological framework that formalizes the forecasting problem and provides design principles for graph-based predictive models and methods to assess their performance. At the same time, together with an overview of the field, we provide design guidelines, recommendations, and best practices, as well as an in-depth discussion of open challenges and future research directions.","sentences":["Graph-based deep learning methods have become popular tools to process collections of correlated time series.","Differently from traditional multivariate forecasting methods, neural graph-based predictors take advantage of pairwise relationships by conditioning forecasts on a (possibly dynamic) graph spanning the time series collection.","The conditioning can take the form of an architectural inductive bias on the neural forecasting architecture, resulting in a family of deep learning models called spatiotemporal graph neural networks.","Such relational inductive biases enable the training of global forecasting models on large time-series collections, while at the same time localizing predictions w.r.t.","each element in the set (i.e., graph nodes) by accounting for local correlations among them (i.e., graph edges).","Indeed, recent theoretical and practical advances in graph neural networks and deep learning for time series forecasting make the adoption of such processing frameworks appealing and timely.","However, most of the studies in the literature focus on proposing variations of existing neural architectures by taking advantage of modern deep learning practices, while foundational and methodological aspects have not been subject to systematic investigation.","To fill the gap, this paper aims to introduce a comprehensive methodological framework that formalizes the forecasting problem and provides design principles for graph-based predictive models and methods to assess their performance.","At the same time, together with an overview of the field, we provide design guidelines, recommendations, and best practices, as well as an in-depth discussion of open challenges and future research directions."],"url":"http://arxiv.org/abs/2310.15978v1"}
{"created":"2023-10-24 16:25:52","title":"The Conspiracy Money Machine: Uncovering Telegram's Conspiracy Channels and their Profit Model","abstract":"In recent years, major social media platforms have implemented increasingly strict moderation policies, resulting in bans and restrictions on conspiracy theory-related content. To circumvent these restrictions, conspiracy theorists are turning to alternatives, such as Telegram, where they can express and spread their views with fewer limitations. Telegram offers channels -- virtual rooms where only administrators can broadcast messages -- and a more permissive content policy. These features have created the perfect breeding ground for a complex ecosystem of conspiracy channels.   In this paper, we illuminate this ecosystem. First, we propose an approach to detect conspiracy channels. Then, we discover that conspiracy channels can be clustered into four distinct communities comprising over 17,000 channels. Finally, we uncover the \"Conspiracy Money Machine,\" revealing how most conspiracy channels actively seek to profit from their subscribers. We find conspiracy theorists leverage e-commerce platforms to sell questionable products or lucratively promote them through affiliate links. Moreover, we observe that conspiracy channels use donation and crowdfunding platforms to raise funds for their campaigns. We determine that this business involves hundreds of donors and generates a turnover of over $90 million.","sentences":["In recent years, major social media platforms have implemented increasingly strict moderation policies, resulting in bans and restrictions on conspiracy theory-related content.","To circumvent these restrictions, conspiracy theorists are turning to alternatives, such as Telegram, where they can express and spread their views with fewer limitations.","Telegram offers channels -- virtual rooms where only administrators can broadcast messages -- and a more permissive content policy.","These features have created the perfect breeding ground for a complex ecosystem of conspiracy channels.   ","In this paper, we illuminate this ecosystem.","First, we propose an approach to detect conspiracy channels.","Then, we discover that conspiracy channels can be clustered into four distinct communities comprising over 17,000 channels.","Finally, we uncover the \"Conspiracy Money Machine,\" revealing how most conspiracy channels actively seek to profit from their subscribers.","We find conspiracy theorists leverage e-commerce platforms to sell questionable products or lucratively promote them through affiliate links.","Moreover, we observe that conspiracy channels use donation and crowdfunding platforms to raise funds for their campaigns.","We determine that this business involves hundreds of donors and generates a turnover of over $90 million."],"url":"http://arxiv.org/abs/2310.15977v1"}
{"created":"2023-10-24 16:25:13","title":"Data-driven Traffic Simulation: A Comprehensive Review","abstract":"Autonomous vehicles (AVs) have the potential to significantly revolutionize society by providing a secure and efficient mode of transportation. Recent years have witnessed notable advance-ments in autonomous driving perception and prediction, but the challenge of validating the performance of AVs remains largely unresolved. Data-driven microscopic traffic simulation has be-come an important tool for autonomous driving testing due to 1) availability of high-fidelity traffic data; 2) its advantages of ena-bling large-scale testing and scenario reproducibility; and 3) its potential in reactive and realistic traffic simulation. However, a comprehensive review of this topic is currently lacking. This pa-per aims to fill this gap by summarizing relevant studies. The primary objective of this paper is to review current research ef-forts and provide a futuristic perspective that will benefit future developments in the field. It introduces the general issues of data-driven traffic simulation and outlines key concepts and terms. After overviewing traffic simulation, various datasets and evalua-tion metrics commonly used are reviewed. The paper then offers a comprehensive evaluation of imitation learning, reinforcement learning, generative and deep learning methods, summarizing each and analyzing their advantages and disadvantages in detail. Moreover, it evaluates the state-of-the-art, existing challenges, and future research directions.","sentences":["Autonomous vehicles (AVs) have the potential to significantly revolutionize society by providing a secure and efficient mode of transportation.","Recent years have witnessed notable advance-ments in autonomous driving perception and prediction, but the challenge of validating the performance of AVs remains largely unresolved.","Data-driven microscopic traffic simulation has be-come an important tool for autonomous driving testing due to 1) availability of high-fidelity traffic data; 2) its advantages of ena-bling large-scale testing and scenario reproducibility; and 3) its potential in reactive and realistic traffic simulation.","However, a comprehensive review of this topic is currently lacking.","This pa-per aims to fill this gap by summarizing relevant studies.","The primary objective of this paper is to review current research ef-forts and provide a futuristic perspective that will benefit future developments in the field.","It introduces the general issues of data-driven traffic simulation and outlines key concepts and terms.","After overviewing traffic simulation, various datasets and evalua-tion metrics commonly used are reviewed.","The paper then offers a comprehensive evaluation of imitation learning, reinforcement learning, generative and deep learning methods, summarizing each and analyzing their advantages and disadvantages in detail.","Moreover, it evaluates the state-of-the-art, existing challenges, and future research directions."],"url":"http://arxiv.org/abs/2310.15975v1"}
{"created":"2023-10-24 16:25:13","title":"Convergence of Sign-based Random Reshuffling Algorithms for Nonconvex Optimization","abstract":"signSGD is popular in nonconvex optimization due to its communication efficiency. Yet, existing analyses of signSGD rely on assuming that data are sampled with replacement in each iteration, contradicting the practical implementation where data are randomly reshuffled and sequentially fed into the algorithm. We bridge this gap by proving the first convergence result of signSGD with random reshuffling (SignRR) for nonconvex optimization. Given the dataset size $n$, the number of epochs of data passes $T$, and the variance bound of a stochastic gradient $\\sigma^2$, we show that SignRR has the same convergence rate $O(\\log(nT)/\\sqrt{nT} + \\|\\sigma\\|_1)$ as signSGD \\citep{bernstein2018signsgd}. We then present SignRVR and SignRVM, which leverage variance-reduced gradients and momentum updates respectively, both converging at $O(\\log(nT)/\\sqrt{nT})$. In contrast with the analysis of signSGD, our results do not require an extremely large batch size in each iteration to be of the same order as the total number of iterations \\citep{bernstein2018signsgd} or the signs of stochastic and true gradients match element-wise with a minimum probability of 1/2 \\citep{safaryan2021stochastic}. We also extend our algorithms to cases where data are distributed across different machines, yielding dist-SignRVR and dist-SignRVM, both converging at $O(\\log(n_0T)/\\sqrt{n_0T})$, where $n_0$ is the dataset size of a single machine. We back up our theoretical findings through experiments on simulated and real-world problems, verifying that randomly reshuffled sign methods match or surpass existing baselines.","sentences":["signSGD is popular in nonconvex optimization due to its communication efficiency.","Yet, existing analyses of signSGD rely on assuming that data are sampled with replacement in each iteration, contradicting the practical implementation where data are randomly reshuffled and sequentially fed into the algorithm.","We bridge this gap by proving the first convergence result of signSGD with random reshuffling (SignRR) for nonconvex optimization.","Given the dataset size $n$, the number of epochs of data passes $T$, and the variance bound of a stochastic gradient $\\sigma^2$, we show that SignRR has the same convergence rate $O(\\log(nT)/\\sqrt{nT} + \\|\\sigma\\|_1)$ as signSGD \\citep{bernstein2018signsgd}.","We then present SignRVR and SignRVM, which leverage variance-reduced gradients and momentum updates respectively, both converging at $O(\\log(nT)/\\sqrt{nT})$. In contrast with the analysis of signSGD, our results do not require an extremely large batch size in each iteration to be of the same order as the total number of iterations \\citep{bernstein2018signsgd} or the signs of stochastic and true gradients match element-wise with a minimum probability of 1/2 \\citep{safaryan2021stochastic}.","We also extend our algorithms to cases where data are distributed across different machines, yielding dist-SignRVR and dist-SignRVM, both converging at $O(\\log(n_0T)/\\sqrt{n_0T})$, where $n_0$ is the dataset size of a single machine.","We back up our theoretical findings through experiments on simulated and real-world problems, verifying that randomly reshuffled sign methods match or surpass existing baselines."],"url":"http://arxiv.org/abs/2310.15976v1"}
{"created":"2023-10-24 16:16:30","title":"An Efficient Method for Realizing Contractions of Access Structures in Cloud Storage","abstract":"In single-cloud storage, ciphertext-policy attribute-based encryption (CP-ABE) allows one to encrypt any data under an access structure to a cloud server, specifying what attributes are required to decrypt. In multi-cloud storage, a secret sharing scheme (SSS) allows one to split any data into multiple shares, one to a single server, and specify which subset of the servers are able to recover the data. It is an interesting problem to remove some attributes/servers but still enable the remaining attributes/servers in every authorized set to recover the data. The problem is related to the contraction problem of access structures for SSSs. In this paper, we propose a method that can efficiently transform a given SSS for an access structure to SSSs for contractions of the access structure. We show its applications in solving the attribute removal problem in the CP-ABE based single-cloud storage and the data relocating problem in multi-cloud storage. Our method results in solutions that require either less server storage or even no additional server storage.","sentences":["In single-cloud storage, ciphertext-policy attribute-based encryption (CP-ABE) allows one to encrypt any data under an access structure to a cloud server, specifying what attributes are required to decrypt.","In multi-cloud storage, a secret sharing scheme (SSS) allows one to split any data into multiple shares, one to a single server, and specify which subset of the servers are able to recover the data.","It is an interesting problem to remove some attributes/servers but still enable the remaining attributes/servers in every authorized set to recover the data.","The problem is related to the contraction problem of access structures for SSSs.","In this paper, we propose a method that can efficiently transform a given SSS for an access structure to SSSs for contractions of the access structure.","We show its applications in solving the attribute removal problem in the CP-ABE based single-cloud storage and the data relocating problem in multi-cloud storage.","Our method results in solutions that require either less server storage or even no additional server storage."],"url":"http://arxiv.org/abs/2310.15972v1"}
{"created":"2023-10-24 16:12:52","title":"Characterizing Issue Management in Runtime Systems","abstract":"Modern programming languages like Java require runtime systems to support the implementation and deployment of software applications in diverse computing platforms and operating systems. These runtime systems are normally developed in GitHub-hosted repositories based on close collaboration between large software companies (e.g., IBM, Microsoft) and OSS developers. However, despite their popularity and broad usage; to the best of our knowledge, these repositories have never been studied. We report an empirical study of around 118K issues from 34 runtime system repos in GitHub. We found that issues regarding enhancement, test failure and bug are mostly posted on runtime system repositories and solution related discussion are mostly present on issue discussion. 82.69% issues in the runtime system repositories have been resolved and 0.69% issues are ignored; median of issue close rate, ignore rate and addressing time in these repositories are 76.1%, 2.2% and 58 days respectively. 82.65% issues are tagged with labels while only 28.30% issues have designated assignees and 90.65% issues contain at least one comment; also presence of these features in an issue report can affect issue closure. Based on the findings, we offer six recommendat","sentences":["Modern programming languages like Java require runtime systems to support the implementation and deployment of software applications in diverse computing platforms and operating systems.","These runtime systems are normally developed in GitHub-hosted repositories based on close collaboration between large software companies (e.g., IBM, Microsoft) and OSS developers.","However, despite their popularity and broad usage; to the best of our knowledge, these repositories have never been studied.","We report an empirical study of around 118K issues from 34 runtime system repos in GitHub.","We found that issues regarding enhancement, test failure and bug are mostly posted on runtime system repositories and solution related discussion are mostly present on issue discussion.","82.69% issues in the runtime system repositories have been resolved and 0.69% issues are ignored; median of issue close rate, ignore rate and addressing time in these repositories are 76.1%, 2.2% and 58 days respectively.","82.65% issues are tagged with labels while only 28.30% issues have designated assignees and 90.65% issues contain at least one comment; also presence of these features in an issue report can affect issue closure.","Based on the findings, we offer six recommendat"],"url":"http://arxiv.org/abs/2310.15971v1"}
{"created":"2023-10-24 16:10:58","title":"Accented Speech Recognition With Accent-specific Codebooks","abstract":"Speech accents pose a significant challenge to state-of-the-art automatic speech recognition (ASR) systems. Degradation in performance across underrepresented accents is a severe deterrent to the inclusive adoption of ASR. In this work, we propose a novel accent adaptation approach for end-to-end ASR systems using cross-attention with a trainable set of codebooks. These learnable codebooks capture accent-specific information and are integrated within the ASR encoder layers. The model is trained on accented English speech, while the test data also contained accents which were not seen during training. On the Mozilla Common Voice multi-accented dataset, we show that our proposed approach yields significant performance gains not only on the seen English accents (up to $37\\%$ relative improvement in word error rate) but also on the unseen accents (up to $5\\%$ relative improvement in WER). Further, we illustrate benefits for a zero-shot transfer setup on the L2Artic dataset. We also compare the performance with other approaches based on accent adversarial training.","sentences":["Speech accents pose a significant challenge to state-of-the-art automatic speech recognition (ASR) systems.","Degradation in performance across underrepresented accents is a severe deterrent to the inclusive adoption of ASR.","In this work, we propose a novel accent adaptation approach for end-to-end ASR systems using cross-attention with a trainable set of codebooks.","These learnable codebooks capture accent-specific information and are integrated within the ASR encoder layers.","The model is trained on accented English speech, while the test data also contained accents which were not seen during training.","On the Mozilla Common Voice multi-accented dataset, we show that our proposed approach yields significant performance gains not only on the seen English accents (up to $37\\%$ relative improvement in word error rate) but also on the unseen accents (up to $5\\%$ relative improvement in WER).","Further, we illustrate benefits for a zero-shot transfer setup on the L2Artic dataset.","We also compare the performance with other approaches based on accent adversarial training."],"url":"http://arxiv.org/abs/2310.15970v1"}
{"created":"2023-10-24 16:03:57","title":"Mixture of Tokens: Efficient LLMs through Cross-Example Aggregation","abstract":"Despite the promise of Mixture of Experts (MoE) models in increasing parameter counts of Transformer models while maintaining training and inference costs, their application carries notable drawbacks. The key strategy of these models is to, for each processed token, activate at most a few experts - subsets of an extensive feed-forward layer. But this approach is not without its challenges. The operation of matching experts and tokens is discrete, which makes MoE models prone to issues like training instability and uneven expert utilization. Existing techniques designed to address these concerns, such as auxiliary losses or balance-aware matching, result either in lower model performance or are more difficult to train. In response to these issues, we propose Mixture of Tokens, a fully-differentiable model that retains the benefits of MoE architectures while avoiding the aforementioned difficulties. Rather than routing tokens to experts, this approach mixes tokens from different examples prior to feeding them to experts, enabling the model to learn from all token-expert combinations. Importantly, this mixing can be disabled to avoid mixing of different sequences during inference. Crucially, this method is fully compatible with both masked and causal Large Language Model training and inference.","sentences":["Despite the promise of Mixture of Experts (MoE) models in increasing parameter counts of Transformer models while maintaining training and inference costs, their application carries notable drawbacks.","The key strategy of these models is to, for each processed token, activate at most a few experts - subsets of an extensive feed-forward layer.","But this approach is not without its challenges.","The operation of matching experts and tokens is discrete, which makes MoE models prone to issues like training instability and uneven expert utilization.","Existing techniques designed to address these concerns, such as auxiliary losses or balance-aware matching, result either in lower model performance or are more difficult to train.","In response to these issues, we propose Mixture of Tokens, a fully-differentiable model that retains the benefits of MoE architectures while avoiding the aforementioned difficulties.","Rather than routing tokens to experts, this approach mixes tokens from different examples prior to feeding them to experts, enabling the model to learn from all token-expert combinations.","Importantly, this mixing can be disabled to avoid mixing of different sequences during inference.","Crucially, this method is fully compatible with both masked and causal Large Language Model training and inference."],"url":"http://arxiv.org/abs/2310.15961v1"}
{"created":"2023-10-24 15:59:43","title":"NoteChat: A Dataset of Synthetic Doctor-Patient Conversations Conditioned on Clinical Notes","abstract":"The detailed clinical records drafted by doctors after each patient's visit are crucial for medical practitioners and researchers. Automating the creation of these notes with language models can reduce the workload of doctors. However, training such models can be difficult due to the limited public availability of conversations between patients and doctors. In this paper, we introduce NoteChat, a cooperative multi-agent framework leveraging Large Language Models (LLMs) for generating synthetic doctor-patient conversations conditioned on clinical notes. NoteChat consists of Planning, Roleplay, and Polish modules. We provide a comprehensive automatic and human evaluation of NoteChat, comparing it with state-of-the-art models, including OpenAI's ChatGPT and GPT-4. Results demonstrate that NoteChat facilitates high-quality synthetic doctor-patient conversations, underscoring the untapped potential of LLMs in healthcare. This work represents the first instance of multiple LLMs cooperating to complete a doctor-patient conversation conditioned on clinical notes, offering promising avenues for the intersection of AI and healthcare","sentences":["The detailed clinical records drafted by doctors after each patient's visit are crucial for medical practitioners and researchers.","Automating the creation of these notes with language models can reduce the workload of doctors.","However, training such models can be difficult due to the limited public availability of conversations between patients and doctors.","In this paper, we introduce NoteChat, a cooperative multi-agent framework leveraging Large Language Models (LLMs) for generating synthetic doctor-patient conversations conditioned on clinical notes.","NoteChat consists of Planning, Roleplay, and Polish modules.","We provide a comprehensive automatic and human evaluation of NoteChat, comparing it with state-of-the-art models, including OpenAI's ChatGPT and GPT-4.","Results demonstrate that NoteChat facilitates high-quality synthetic doctor-patient conversations, underscoring the untapped potential of LLMs in healthcare.","This work represents the first instance of multiple LLMs cooperating to complete a doctor-patient conversation conditioned on clinical notes, offering promising avenues for the intersection of AI and healthcare"],"url":"http://arxiv.org/abs/2310.15959v1"}
{"created":"2023-10-24 15:54:11","title":"Decoupled DETR: Spatially Disentangling Localization and Classification for Improved End-to-End Object Detection","abstract":"The introduction of DETR represents a new paradigm for object detection. However, its decoder conducts classification and box localization using shared queries and cross-attention layers, leading to suboptimal results. We observe that different regions of interest in the visual feature map are suitable for performing query classification and box localization tasks, even for the same object. Salient regions provide vital information for classification, while the boundaries around them are more favorable for box regression. Unfortunately, such spatial misalignment between these two tasks greatly hinders DETR's training. Therefore, in this work, we focus on decoupling localization and classification tasks in DETR. To achieve this, we introduce a new design scheme called spatially decoupled DETR (SD-DETR), which includes a task-aware query generation module and a disentangled feature learning process. We elaborately design the task-aware query initialization process and divide the cross-attention block in the decoder to allow the task-aware queries to match different visual regions. Meanwhile, we also observe that the prediction misalignment problem for high classification confidence and precise localization exists, so we propose an alignment loss to further guide the spatially decoupled DETR training. Through extensive experiments, we demonstrate that our approach achieves a significant improvement in MSCOCO datasets compared to previous work. For instance, we improve the performance of Conditional DETR by 4.5 AP. By spatially disentangling the two tasks, our method overcomes the misalignment problem and greatly improves the performance of DETR for object detection.","sentences":["The introduction of DETR represents a new paradigm for object detection.","However, its decoder conducts classification and box localization using shared queries and cross-attention layers, leading to suboptimal results.","We observe that different regions of interest in the visual feature map are suitable for performing query classification and box localization tasks, even for the same object.","Salient regions provide vital information for classification, while the boundaries around them are more favorable for box regression.","Unfortunately, such spatial misalignment between these two tasks greatly hinders DETR's training.","Therefore, in this work, we focus on decoupling localization and classification tasks in DETR.","To achieve this, we introduce a new design scheme called spatially decoupled DETR (SD-DETR), which includes a task-aware query generation module and a disentangled feature learning process.","We elaborately design the task-aware query initialization process and divide the cross-attention block in the decoder to allow the task-aware queries to match different visual regions.","Meanwhile, we also observe that the prediction misalignment problem for high classification confidence and precise localization exists, so we propose an alignment loss to further guide the spatially decoupled DETR training.","Through extensive experiments, we demonstrate that our approach achieves a significant improvement in MSCOCO datasets compared to previous work.","For instance, we improve the performance of Conditional DETR by 4.5 AP.","By spatially disentangling the two tasks, our method overcomes the misalignment problem and greatly improves the performance of DETR for object detection."],"url":"http://arxiv.org/abs/2310.15955v1"}
{"created":"2023-10-24 15:53:07","title":"Improving Robustness and Reliability in Medical Image Classification with Latent-Guided Diffusion and Nested-Ensembles","abstract":"While deep learning models have achieved remarkable success across a range of medical image analysis tasks, deployment of these models in real clinical contexts requires that they be robust to variability in the acquired images. While many methods apply predefined transformations to augment the training data to enhance test-time robustness, these transformations may not ensure the model's robustness to the diverse variability seen in patient images. In this paper, we introduce a novel three-stage approach based on transformers coupled with conditional diffusion models, with the goal of improving model robustness to the kinds of imaging variability commonly encountered in practice without the need for pre-determined data augmentation strategies. To this end, multiple image encoders first learn hierarchical feature representations to build discriminative latent spaces. Next, a reverse diffusion process, guided by the latent code, acts on an informative prior and proposes prediction candidates in a generative manner. Finally, several prediction candidates are aggregated in a bi-level aggregation protocol to produce the final output. Through extensive experiments on medical imaging benchmark datasets, we show that our method improves upon state-of-the-art methods in terms of robustness and confidence calibration. Additionally, we introduce a strategy to quantify the prediction uncertainty at the instance level, increasing their trustworthiness to clinicians using them in clinical practice.","sentences":["While deep learning models have achieved remarkable success across a range of medical image analysis tasks, deployment of these models in real clinical contexts requires that they be robust to variability in the acquired images.","While many methods apply predefined transformations to augment the training data to enhance test-time robustness, these transformations may not ensure the model's robustness to the diverse variability seen in patient images.","In this paper, we introduce a novel three-stage approach based on transformers coupled with conditional diffusion models, with the goal of improving model robustness to the kinds of imaging variability commonly encountered in practice without the need for pre-determined data augmentation strategies.","To this end, multiple image encoders first learn hierarchical feature representations to build discriminative latent spaces.","Next, a reverse diffusion process, guided by the latent code, acts on an informative prior and proposes prediction candidates in a generative manner.","Finally, several prediction candidates are aggregated in a bi-level aggregation protocol to produce the final output.","Through extensive experiments on medical imaging benchmark datasets, we show that our method improves upon state-of-the-art methods in terms of robustness and confidence calibration.","Additionally, we introduce a strategy to quantify the prediction uncertainty at the instance level, increasing their trustworthiness to clinicians using them in clinical practice."],"url":"http://arxiv.org/abs/2310.15952v1"}
{"created":"2023-10-24 15:51:20","title":"Weighted Distance Nearest Neighbor Condensing","abstract":"The problem of nearest neighbor condensing has enjoyed a long history of study, both in its theoretical and practical aspects. In this paper, we introduce the problem of weighted distance nearest neighbor condensing, where one assigns weights to each point of the condensed set, and then new points are labeled based on their weighted distance nearest neighbor in the condensed set.   We study the theoretical properties of this new model, and show that it can produce dramatically better condensing than the standard nearest neighbor rule, yet is characterized by generalization bounds almost identical to the latter. We then suggest a condensing heuristic for our new problem. We demonstrate Bayes consistency for this heuristic, and also show promising empirical results.","sentences":["The problem of nearest neighbor condensing has enjoyed a long history of study, both in its theoretical and practical aspects.","In this paper, we introduce the problem of weighted distance nearest neighbor condensing, where one assigns weights to each point of the condensed set, and then new points are labeled based on their weighted distance nearest neighbor in the condensed set.   ","We study the theoretical properties of this new model, and show that it can produce dramatically better condensing than the standard nearest neighbor rule, yet is characterized by generalization bounds almost identical to the latter.","We then suggest a condensing heuristic for our new problem.","We demonstrate Bayes consistency for this heuristic, and also show promising empirical results."],"url":"http://arxiv.org/abs/2310.15951v1"}
{"created":"2023-10-24 15:51:13","title":"Representation Learning with Large Language Models for Recommendation","abstract":"Recommender systems have seen significant advancements with the influence of deep learning and graph neural networks, particularly in capturing complex user-item relationships. However, these graph-based recommenders heavily depend on ID-based data, potentially disregarding valuable textual information associated with users and items, resulting in less informative learned representations. Moreover, the utilization of implicit feedback data introduces potential noise and bias, posing challenges for the effectiveness of user preference learning. While the integration of large language models (LLMs) into traditional ID-based recommenders has gained attention, challenges such as scalability issues, limitations in text-only reliance, and prompt input constraints need to be addressed for effective implementation in practical recommender systems. To address these challenges, we propose a model-agnostic framework RLMRec that aims to enhance existing recommenders with LLM-empowered representation learning. It proposes a recommendation paradigm that integrates representation learning with LLMs to capture intricate semantic aspects of user behaviors and preferences. RLMRec incorporates auxiliary textual signals, develops a user/item profiling paradigm empowered by LLMs, and aligns the semantic space of LLMs with the representation space of collaborative relational signals through a cross-view alignment framework. This work further establish a theoretical foundation demonstrating that incorporating textual signals through mutual information maximization enhances the quality of representations. In our evaluation, we integrate RLMRec with state-of-the-art recommender models, while also analyzing its efficiency and robustness to noise data. Our implementation codes are available at https://github.com/HKUDS/RLMRec.","sentences":["Recommender systems have seen significant advancements with the influence of deep learning and graph neural networks, particularly in capturing complex user-item relationships.","However, these graph-based recommenders heavily depend on ID-based data, potentially disregarding valuable textual information associated with users and items, resulting in less informative learned representations.","Moreover, the utilization of implicit feedback data introduces potential noise and bias, posing challenges for the effectiveness of user preference learning.","While the integration of large language models (LLMs) into traditional ID-based recommenders has gained attention, challenges such as scalability issues, limitations in text-only reliance, and prompt input constraints need to be addressed for effective implementation in practical recommender systems.","To address these challenges, we propose a model-agnostic framework RLMRec that aims to enhance existing recommenders with LLM-empowered representation learning.","It proposes a recommendation paradigm that integrates representation learning with LLMs to capture intricate semantic aspects of user behaviors and preferences.","RLMRec incorporates auxiliary textual signals, develops a user/item profiling paradigm empowered by LLMs, and aligns the semantic space of LLMs with the representation space of collaborative relational signals through a cross-view alignment framework.","This work further establish a theoretical foundation demonstrating that incorporating textual signals through mutual information maximization enhances the quality of representations.","In our evaluation, we integrate RLMRec with state-of-the-art recommender models, while also analyzing its efficiency and robustness to noise data.","Our implementation codes are available at https://github.com/HKUDS/RLMRec."],"url":"http://arxiv.org/abs/2310.15950v1"}
{"created":"2023-10-24 15:50:35","title":"Language-driven Scene Synthesis using Multi-conditional Diffusion Model","abstract":"Scene synthesis is a challenging problem with several industrial applications. Recently, substantial efforts have been directed to synthesize the scene using human motions, room layouts, or spatial graphs as the input. However, few studies have addressed this problem from multiple modalities, especially combining text prompts. In this paper, we propose a language-driven scene synthesis task, which is a new task that integrates text prompts, human motion, and existing objects for scene synthesis. Unlike other single-condition synthesis tasks, our problem involves multiple conditions and requires a strategy for processing and encoding them into a unified space. To address the challenge, we present a multi-conditional diffusion model, which differs from the implicit unification approach of other diffusion literature by explicitly predicting the guiding points for the original data distribution. We demonstrate that our approach is theoretically supportive. The intensive experiment results illustrate that our method outperforms state-of-the-art benchmarks and enables natural scene editing applications. The source code and dataset can be accessed at https://lang-scene-synth.github.io/.","sentences":["Scene synthesis is a challenging problem with several industrial applications.","Recently, substantial efforts have been directed to synthesize the scene using human motions, room layouts, or spatial graphs as the input.","However, few studies have addressed this problem from multiple modalities, especially combining text prompts.","In this paper, we propose a language-driven scene synthesis task, which is a new task that integrates text prompts, human motion, and existing objects for scene synthesis.","Unlike other single-condition synthesis tasks, our problem involves multiple conditions and requires a strategy for processing and encoding them into a unified space.","To address the challenge, we present a multi-conditional diffusion model, which differs from the implicit unification approach of other diffusion literature by explicitly predicting the guiding points for the original data distribution.","We demonstrate that our approach is theoretically supportive.","The intensive experiment results illustrate that our method outperforms state-of-the-art benchmarks and enables natural scene editing applications.","The source code and dataset can be accessed at https://lang-scene-synth.github.io/."],"url":"http://arxiv.org/abs/2310.15948v1"}
{"created":"2023-10-24 15:47:52","title":"ShARc: Shape and Appearance Recognition for Person Identification In-the-wild","abstract":"Identifying individuals in unconstrained video settings is a valuable yet challenging task in biometric analysis due to variations in appearances, environments, degradations, and occlusions. In this paper, we present ShARc, a multimodal approach for video-based person identification in uncontrolled environments that emphasizes 3-D body shape, pose, and appearance. We introduce two encoders: a Pose and Shape Encoder (PSE) and an Aggregated Appearance Encoder (AAE). PSE encodes the body shape via binarized silhouettes, skeleton motions, and 3-D body shape, while AAE provides two levels of temporal appearance feature aggregation: attention-based feature aggregation and averaging aggregation. For attention-based feature aggregation, we employ spatial and temporal attention to focus on key areas for person distinction. For averaging aggregation, we introduce a novel flattening layer after averaging to extract more distinguishable information and reduce overfitting of attention. We utilize centroid feature averaging for gallery registration. We demonstrate significant improvements over existing state-of-the-art methods on public datasets, including CCVID, MEVID, and BRIAR.","sentences":["Identifying individuals in unconstrained video settings is a valuable yet challenging task in biometric analysis due to variations in appearances, environments, degradations, and occlusions.","In this paper, we present ShARc, a multimodal approach for video-based person identification in uncontrolled environments that emphasizes 3-D body shape, pose, and appearance.","We introduce two encoders: a Pose and Shape Encoder (PSE) and an Aggregated Appearance Encoder (AAE).","PSE encodes the body shape via binarized silhouettes, skeleton motions, and 3-D body shape, while AAE provides two levels of temporal appearance feature aggregation: attention-based feature aggregation and averaging aggregation.","For attention-based feature aggregation, we employ spatial and temporal attention to focus on key areas for person distinction.","For averaging aggregation, we introduce a novel flattening layer after averaging to extract more distinguishable information and reduce overfitting of attention.","We utilize centroid feature averaging for gallery registration.","We demonstrate significant improvements over existing state-of-the-art methods on public datasets, including CCVID, MEVID, and BRIAR."],"url":"http://arxiv.org/abs/2310.15946v1"}
{"created":"2023-10-24 15:40:05","title":"A Roadmap of Emerging Trends Discovery in Hydrology: A Topic Modeling Approach","abstract":"In the new global era, determining trends can play an important role in guiding researchers, scientists, and agencies. The main faced challenge is to track the emerging topics among the stacked publications. Therefore, any study done to propose the trend topics in a field to foresee upcoming subjects is crucial. In the current study, the trend topics in the field of \"Hydrology\" have been attempted to evaluate. To do so, the model is composed of three key components: a gathering of data, preprocessing of the article's significant features, and determining trend topics. Various topic models including Latent Dirichlet Allocation (LDA), Non-negative Matrix Factorization (NMF), and Latent Semantic Analysis (LSA) have been implemented. Comparing the obtained results with respect to the $C_V$ coherence score, in 2022, the topics of \"Climate change\", \"River basin\", \"Water management\", \"Natural hazards/erosion\", and \"Hydrologic cycle\" have been obtained. According to a further analysis, it is shown that these topics keep their impact on the field in 2023, as well.","sentences":["In the new global era, determining trends can play an important role in guiding researchers, scientists, and agencies.","The main faced challenge is to track the emerging topics among the stacked publications.","Therefore, any study done to propose the trend topics in a field to foresee upcoming subjects is crucial.","In the current study, the trend topics in the field of \"Hydrology\" have been attempted to evaluate.","To do so, the model is composed of three key components: a gathering of data, preprocessing of the article's significant features, and determining trend topics.","Various topic models including Latent Dirichlet Allocation (LDA), Non-negative Matrix Factorization (NMF), and Latent Semantic Analysis (LSA) have been implemented.","Comparing the obtained results with respect to the $C_V$ coherence score, in 2022, the topics of \"Climate change\", \"River basin\", \"Water management\", \"Natural hazards/erosion\", and \"Hydrologic cycle\" have been obtained.","According to a further analysis, it is shown that these topics keep their impact on the field in 2023, as well."],"url":"http://arxiv.org/abs/2310.15943v1"}
{"created":"2023-10-24 15:38:21","title":"This is not a Dataset: A Large Negation Benchmark to Challenge Large Language Models","abstract":"Although large language models (LLMs) have apparently acquired a certain level of grammatical knowledge and the ability to make generalizations, they fail to interpret negation, a crucial step in Natural Language Processing. We try to clarify the reasons for the sub-optimal performance of LLMs understanding negation. We introduce a large semi-automatically generated dataset of circa 400,000 descriptive sentences about commonsense knowledge that can be true or false in which negation is present in about 2/3 of the corpus in different forms. We have used our dataset with the largest available open LLMs in a zero-shot approach to grasp their generalization and inference capability and we have also fine-tuned some of the models to assess whether the understanding of negation can be trained. Our findings show that, while LLMs are proficient at classifying affirmative sentences, they struggle with negative sentences and lack a deep understanding of negation, often relying on superficial cues. Although fine-tuning the models on negative sentences improves their performance, the lack of generalization in handling negation is persistent, highlighting the ongoing challenges of LLMs regarding negation understanding and generalization. The dataset and code are publicly available.","sentences":["Although large language models (LLMs) have apparently acquired a certain level of grammatical knowledge and the ability to make generalizations, they fail to interpret negation, a crucial step in Natural Language Processing.","We try to clarify the reasons for the sub-optimal performance of LLMs understanding negation.","We introduce a large semi-automatically generated dataset of circa 400,000 descriptive sentences about commonsense knowledge that can be true or false in which negation is present in about 2/3 of the corpus in different forms.","We have used our dataset with the largest available open LLMs in a zero-shot approach to grasp their generalization and inference capability and we have also fine-tuned some of the models to assess whether the understanding of negation can be trained.","Our findings show that, while LLMs are proficient at classifying affirmative sentences, they struggle with negative sentences and lack a deep understanding of negation, often relying on superficial cues.","Although fine-tuning the models on negative sentences improves their performance, the lack of generalization in handling negation is persistent, highlighting the ongoing challenges of LLMs regarding negation understanding and generalization.","The dataset and code are publicly available."],"url":"http://arxiv.org/abs/2310.15941v1"}
{"created":"2023-10-24 15:35:54","title":"Combining Behaviors with the Successor Features Keyboard","abstract":"The Option Keyboard (OK) was recently proposed as a method for transferring behavioral knowledge across tasks. OK transfers knowledge by adaptively combining subsets of known behaviors using Successor Features (SFs) and Generalized Policy Improvement (GPI). However, it relies on hand-designed state-features and task encodings which are cumbersome to design for every new environment. In this work, we propose the \"Successor Features Keyboard\" (SFK), which enables transfer with discovered state-features and task encodings. To enable discovery, we propose the \"Categorical Successor Feature Approximator\" (CSFA), a novel learning algorithm for estimating SFs while jointly discovering state-features and task encodings. With SFK and CSFA, we achieve the first demonstration of transfer with SFs in a challenging 3D environment where all the necessary representations are discovered. We first compare CSFA against other methods for approximating SFs and show that only CSFA discovers representations compatible with SF&GPI at this scale. We then compare SFK against transfer learning baselines and show that it transfers most quickly to long-horizon tasks.","sentences":["The Option Keyboard (OK) was recently proposed as a method for transferring behavioral knowledge across tasks.","OK transfers knowledge by adaptively combining subsets of known behaviors using Successor Features (SFs) and Generalized Policy Improvement (GPI).","However, it relies on hand-designed state-features and task encodings which are cumbersome to design for every new environment.","In this work, we propose the \"Successor Features Keyboard\" (SFK), which enables transfer with discovered state-features and task encodings.","To enable discovery, we propose the \"Categorical Successor Feature Approximator\" (CSFA), a novel learning algorithm for estimating SFs while jointly discovering state-features and task encodings.","With SFK and CSFA, we achieve the first demonstration of transfer with SFs in a challenging 3D environment where all the necessary representations are discovered.","We first compare CSFA against other methods for approximating SFs and show that only CSFA discovers representations compatible with SF&GPI at this scale.","We then compare SFK against transfer learning baselines and show that it transfers most quickly to long-horizon tasks."],"url":"http://arxiv.org/abs/2310.15940v1"}
{"created":"2023-10-24 15:34:30","title":"ABKD: Graph Neural Network Compression with Attention-Based Knowledge Distillation","abstract":"Graph Neural Networks (GNNs) have proven to be quite versatile for a variety of applications, including recommendation systems, fake news detection, drug discovery, and even computer vision. Due to the expanding size of graph-structured data, GNN models have also increased in complexity, leading to substantial latency issues. This is primarily attributed to the irregular structure of graph data and its access pattern into memory. The natural solution to reduce latency is to compress large GNNs into small GNNs. One way to do this is via knowledge distillation (KD). However, most KD approaches for GNNs only consider the outputs of the last layers and do not consider the outputs of the intermediate layers of the GNNs; these layers may contain important inductive biases indicated by the graph structure. To address this shortcoming, we propose a novel KD approach to GNN compression that we call Attention-Based Knowledge Distillation (ABKD). ABKD is a KD approach that uses attention to identify important intermediate teacher-student layer pairs and focuses on aligning their outputs. ABKD enables higher compression of GNNs with a smaller accuracy dropoff compared to existing KD approaches. On average, we achieve a 1.79% increase in accuracy with a 32.3x compression ratio on OGBN-Mag, a large graph dataset, compared to state-of-the-art approaches.","sentences":["Graph Neural Networks (GNNs) have proven to be quite versatile for a variety of applications, including recommendation systems, fake news detection, drug discovery, and even computer vision.","Due to the expanding size of graph-structured data, GNN models have also increased in complexity, leading to substantial latency issues.","This is primarily attributed to the irregular structure of graph data and its access pattern into memory.","The natural solution to reduce latency is to compress large GNNs into small GNNs.","One way to do this is via knowledge distillation (KD).","However, most KD approaches for GNNs only consider the outputs of the last layers and do not consider the outputs of the intermediate layers of the GNNs; these layers may contain important inductive biases indicated by the graph structure.","To address this shortcoming, we propose a novel KD approach to GNN compression that we call Attention-Based Knowledge Distillation (ABKD).","ABKD is a KD approach that uses attention to identify important intermediate teacher-student layer pairs and focuses on aligning their outputs.","ABKD enables higher compression of GNNs with a smaller accuracy dropoff compared to existing KD approaches.","On average, we achieve a 1.79% increase in accuracy with a 32.3x compression ratio on OGBN-Mag, a large graph dataset, compared to state-of-the-art approaches."],"url":"http://arxiv.org/abs/2310.15938v1"}
{"created":"2023-10-24 15:32:54","title":"Mediator Interpretation and Faster Learning Algorithms for Linear Correlated Equilibria in General Extensive-Form Games","abstract":"A recent paper by Farina & Pipis (2023) established the existence of uncoupled no-linear-swap regret dynamics with polynomial-time iterations in extensive-form games. The equilibrium points reached by these dynamics, known as linear correlated equilibria, are currently the tightest known relaxation of correlated equilibrium that can be learned in polynomial time in any finite extensive-form game. However, their properties remain vastly unexplored, and their computation is onerous. In this paper, we provide several contributions shedding light on the fundamental nature of linear-swap regret. First, we show a connection between linear deviations and a generalization of communication deviations in which the player can make queries to a \"mediator\" who replies with action recommendations, and, critically, the player is not constrained to match the timing of the game as would be the case for communication deviations. We coin this latter set the untimed communication (UTC) deviations. We show that the UTC deviations coincide precisely with the linear deviations, and therefore that any player minimizing UTC regret also minimizes linear-swap regret. We then leverage this connection to develop state-of-the-art no-regret algorithms for computing linear correlated equilibria, both in theory and in practice. In theory, our algorithms achieve polynomially better per-iteration runtimes; in practice, our algorithms represent the state of the art by several orders of magnitude.","sentences":["A recent paper by Farina & Pipis (2023) established the existence of uncoupled no-linear-swap regret dynamics with polynomial-time iterations in extensive-form games.","The equilibrium points reached by these dynamics, known as linear correlated equilibria, are currently the tightest known relaxation of correlated equilibrium that can be learned in polynomial time in any finite extensive-form game.","However, their properties remain vastly unexplored, and their computation is onerous.","In this paper, we provide several contributions shedding light on the fundamental nature of linear-swap regret.","First, we show a connection between linear deviations and a generalization of communication deviations in which the player can make queries to a \"mediator\" who replies with action recommendations, and, critically, the player is not constrained to match the timing of the game as would be the case for communication deviations.","We coin this latter set the untimed communication (UTC) deviations.","We show that the UTC deviations coincide precisely with the linear deviations, and therefore that any player minimizing UTC regret also minimizes linear-swap regret.","We then leverage this connection to develop state-of-the-art no-regret algorithms for computing linear correlated equilibria, both in theory and in practice.","In theory, our algorithms achieve polynomially better per-iteration runtimes; in practice, our algorithms represent the state of the art by several orders of magnitude."],"url":"http://arxiv.org/abs/2310.15935v1"}
{"created":"2023-10-24 15:30:33","title":"Redactable Signature Schemes and Zero-knowledge Proofs: A comparative examination for applications in Decentralized Digital Identity Systems","abstract":"Redactable Signature Schemes and Zero-Knowledge Proofs are two radically different approaches to enable privacy. This paper analyses their merits and drawbacks when applied to decentralized identity system. Redactable Signatures, though competitively quick and compact, are not as expressive as zero-knowledge proofs and do not provide the same level of privacy. On the other hand, zero-knowledge proofs can be much faster but some protocols require a trusted set-up. We conclude that given the benefits and drawbacks, redactable signatures are more appropriate at an earlier stage and zero-knowledge proofs are more appropriate at a later stage for decentralized identity systems","sentences":["Redactable Signature Schemes and Zero-Knowledge Proofs are two radically different approaches to enable privacy.","This paper analyses their merits and drawbacks when applied to decentralized identity system.","Redactable Signatures, though competitively quick and compact, are not as expressive as zero-knowledge proofs and do not provide the same level of privacy.","On the other hand, zero-knowledge proofs can be much faster but some protocols require a trusted set-up.","We conclude that given the benefits and drawbacks, redactable signatures are more appropriate at an earlier stage and zero-knowledge proofs are more appropriate at a later stage for decentralized identity systems"],"url":"http://arxiv.org/abs/2310.15934v1"}
{"created":"2023-10-24 15:28:43","title":"Online Robust Mean Estimation","abstract":"We study the problem of high-dimensional robust mean estimation in an online setting. Specifically, we consider a scenario where $n$ sensors are measuring some common, ongoing phenomenon. At each time step $t=1,2,\\ldots,T$, the $i^{th}$ sensor reports its readings $x^{(i)}_t$ for that time step. The algorithm must then commit to its estimate $\\mu_t$ for the true mean value of the process at time $t$. We assume that most of the sensors observe independent samples from some common distribution $X$, but an $\\epsilon$-fraction of them may instead behave maliciously. The algorithm wishes to compute a good approximation $\\mu$ to the true mean $\\mu^\\ast := \\mathbf{E}[X]$. We note that if the algorithm is allowed to wait until time $T$ to report its estimate, this reduces to the well-studied problem of robust mean estimation. However, the requirement that our algorithm produces partial estimates as the data is coming in substantially complicates the situation.   We prove two main results about online robust mean estimation in this model. First, if the uncorrupted samples satisfy the standard condition of $(\\epsilon,\\delta)$-stability, we give an efficient online algorithm that outputs estimates $\\mu_t$, $t \\in [T],$ such that with high probability it holds that $\\|\\mu-\\mu^\\ast\\|_2 = O(\\delta \\log(T))$, where $\\mu = (\\mu_t)_{t \\in [T]}$. We note that this error bound is nearly competitive with the best offline algorithms, which would achieve $\\ell_2$-error of $O(\\delta)$. Our second main result shows that with additional assumptions on the input (most notably that $X$ is a product distribution) there are inefficient algorithms whose error does not depend on $T$ at all.","sentences":["We study the problem of high-dimensional robust mean estimation in an online setting.","Specifically, we consider a scenario where $n$ sensors are measuring some common, ongoing phenomenon.","At each time step $t=1,2,\\ldots,T$, the $i^{th}$ sensor reports its readings $x^{(i)}_t$ for that time step.","The algorithm must then commit to its estimate $\\mu_t$ for the true mean value of the process at time $t$. We assume that most of the sensors observe independent samples from some common distribution $X$, but an $\\epsilon$-fraction of them may instead behave maliciously.","The algorithm wishes to compute a good approximation $\\mu$ to the true mean $\\mu^\\ast := \\mathbf{E}[X]$. We note that if the algorithm is allowed to wait until time $T$ to report its estimate, this reduces to the well-studied problem of robust mean estimation.","However, the requirement that our algorithm produces partial estimates as the data is coming in substantially complicates the situation.   ","We prove two main results about online robust mean estimation in this model.","First, if the uncorrupted samples satisfy the standard condition of $(\\epsilon,\\delta)$-stability, we give an efficient online algorithm that outputs estimates $\\mu_t$, $t","\\in [T],$ such that with high probability it holds that $\\|\\mu-\\mu^\\ast\\|_2 = O(\\delta \\log(T))$, where $\\mu = (","\\mu_t)_{t \\in","[T]}$. We note that this error bound is nearly competitive with the best offline algorithms, which would achieve $\\ell_2$-error of $O(\\delta)$. Our second main result shows that with additional assumptions on the input (most notably that $X$ is a product distribution) there are inefficient algorithms whose error does not depend on $T$ at all."],"url":"http://arxiv.org/abs/2310.15932v1"}
{"created":"2023-10-24 15:28:06","title":"GO-FEAP: Global Optimal UAV Planner Using Frontier-Omission-Aware Exploration and Altitude-Stratified Planning","abstract":"Autonomous exploration is a fundamental problem for various applications of unmanned aerial vehicles(UAVs). Existing methods, however, are demonstrated to static local optima and two-dimensional exploration. To address these challenges, this paper introduces GO-FEAP (Global Optimal UAV Planner Using Frontier-Omission-Aware Exploration and Altitude-Stratified Planning), aiming to achieve efficient and complete three-dimensional exploration. Frontier-Omission-Aware Exploration module presented in this work takes into account multiple pivotal factors, encompassing frontier distance, nearby frontier count, frontier duration, and frontier categorization, for a comprehensive assessment of frontier importance. Furthermore, to tackle scenarios with substantial vertical variations, we introduce the Altitude-Stratified Planning strategy, which stratifies the three-dimensional space based on altitude, conducting global-local planning for each stratum. The objective of global planning is to identify the most optimal frontier for exploration, followed by viewpoint selection and local path optimization based on frontier type, ultimately generating dynamically feasible three-dimensional spatial exploration trajectories. We present extensive benchmark and real-world tests, in which our method completes the exploration tasks with unprecedented completeness compared to state-of-the-art approaches.","sentences":["Autonomous exploration is a fundamental problem for various applications of unmanned aerial vehicles(UAVs).","Existing methods, however, are demonstrated to static local optima and two-dimensional exploration.","To address these challenges, this paper introduces GO-FEAP (Global Optimal UAV Planner Using Frontier-Omission-Aware Exploration and Altitude-Stratified Planning), aiming to achieve efficient and complete three-dimensional exploration.","Frontier-Omission-Aware Exploration module presented in this work takes into account multiple pivotal factors, encompassing frontier distance, nearby frontier count, frontier duration, and frontier categorization, for a comprehensive assessment of frontier importance.","Furthermore, to tackle scenarios with substantial vertical variations, we introduce the Altitude-Stratified Planning strategy, which stratifies the three-dimensional space based on altitude, conducting global-local planning for each stratum.","The objective of global planning is to identify the most optimal frontier for exploration, followed by viewpoint selection and local path optimization based on frontier type, ultimately generating dynamically feasible three-dimensional spatial exploration trajectories.","We present extensive benchmark and real-world tests, in which our method completes the exploration tasks with unprecedented completeness compared to state-of-the-art approaches."],"url":"http://arxiv.org/abs/2310.15931v1"}
{"created":"2023-10-24 15:27:50","title":"CDSD: Chinese Dysarthria Speech Database","abstract":"We present the Chinese Dysarthria Speech Database (CDSD) as a valuable resource for dysarthria research. This database comprises speech data from 24 participants with dysarthria. Among these participants, one recorded an additional 10 hours of speech data, while each recorded one hour, resulting in 34 hours of speech material. To accommodate participants with varying cognitive levels, our text pool primarily consists of content from the AISHELL-1 dataset and speeches by primary and secondary school students. When participants read these texts, they must use a mobile device or the ZOOM F8n multi-track field recorder to record their speeches. In this paper, we elucidate the data collection and annotation processes and present an approach for establishing a baseline for dysarthric speech recognition. Furthermore, we conducted a speaker-dependent dysarthric speech recognition experiment using an additional 10 hours of speech data from one of our participants. Our research findings indicate that, through extensive data-driven model training, fine-tuning limited quantities of specific individual data yields commendable results in speaker-dependent dysarthric speech recognition. However, we observe significant variations in recognition results among different dysarthric speakers. These insights provide valuable reference points for speaker-dependent dysarthric speech recognition.","sentences":["We present the Chinese Dysarthria Speech Database (CDSD) as a valuable resource for dysarthria research.","This database comprises speech data from 24 participants with dysarthria.","Among these participants, one recorded an additional 10 hours of speech data, while each recorded one hour, resulting in 34 hours of speech material.","To accommodate participants with varying cognitive levels, our text pool primarily consists of content from the AISHELL-1 dataset and speeches by primary and secondary school students.","When participants read these texts, they must use a mobile device or the ZOOM F8n multi-track field recorder to record their speeches.","In this paper, we elucidate the data collection and annotation processes and present an approach for establishing a baseline for dysarthric speech recognition.","Furthermore, we conducted a speaker-dependent dysarthric speech recognition experiment using an additional 10 hours of speech data from one of our participants.","Our research findings indicate that, through extensive data-driven model training, fine-tuning limited quantities of specific individual data yields commendable results in speaker-dependent dysarthric speech recognition.","However, we observe significant variations in recognition results among different dysarthric speakers.","These insights provide valuable reference points for speaker-dependent dysarthric speech recognition."],"url":"http://arxiv.org/abs/2310.15930v1"}
{"created":"2023-10-24 15:27:15","title":"E-Sparse: Boosting the Large Language Model Inference through Entropy-based N:M Sparsity","abstract":"Traditional pruning methods are known to be challenging to work in Large Language Models (LLMs) for Generative AI because of their unaffordable training process and large computational demands. For the first time, we introduce the information entropy of hidden state features into a pruning metric design, namely E-Sparse, to improve the accuracy of N:M sparsity on LLM. E-Sparse employs the information richness to leverage the channel importance, and further incorporates several novel techniques to put it into effect: (1) it introduces information entropy to enhance the significance of parameter weights and input feature norms as a novel pruning metric, and performs N:M sparsity without modifying the remaining weights. (2) it designs global naive shuffle and local block shuffle to quickly optimize the information distribution and adequately cope with the impact of N:M sparsity on LLMs' accuracy. E-Sparse is implemented as a Sparse-GEMM on FasterTransformer and runs on NVIDIA Ampere GPUs. Extensive experiments on the LLaMA family and OPT models show that E-Sparse can significantly speed up the model inference over the dense model (up to 1.53X) and obtain significant memory saving (up to 43.52%), with acceptable accuracy loss.","sentences":["Traditional pruning methods are known to be challenging to work in Large Language Models (LLMs) for Generative AI because of their unaffordable training process and large computational demands.","For the first time, we introduce the information entropy of hidden state features into a pruning metric design, namely E-Sparse, to improve the accuracy of N:M sparsity on LLM.","E-Sparse employs the information richness to leverage the channel importance, and further incorporates several novel techniques to put it into effect: (1) it introduces information entropy to enhance the significance of parameter weights and input feature norms as a novel pruning metric, and performs N:M sparsity without modifying the remaining weights.","(2) it designs global naive shuffle and local block shuffle to quickly optimize the information distribution and adequately cope with the impact of N:M sparsity on LLMs' accuracy.","E-Sparse is implemented as a Sparse-GEMM on FasterTransformer and runs on NVIDIA Ampere GPUs.","Extensive experiments on the LLaMA family and OPT models show that E-Sparse can significantly speed up the model inference over the dense model (up to 1.53X) and obtain significant memory saving (up to 43.52%), with acceptable accuracy loss."],"url":"http://arxiv.org/abs/2310.15929v1"}
{"created":"2023-10-24 15:26:57","title":"AO-Grasp: Articulated Object Grasp Generation","abstract":"We introduce AO-Grasp, a grasp proposal method that generates stable and actionable 6 degree-of-freedom grasps for articulated objects. Our generated grasps enable robots to interact with articulated objects, such as opening and closing cabinets and appliances. Given a segmented partial point cloud of a single articulated object, AO-Grasp predicts the best grasp points on the object with a novel Actionable Grasp Point Predictor model and then finds corresponding grasp orientations for each point by leveraging a state-of-the-art rigid object grasping method. We train AO-Grasp on our new AO-Grasp Dataset, which contains 48K actionable parallel-jaw grasps on synthetic articulated objects. In simulation, AO-Grasp achieves higher grasp success rates than existing rigid object grasping and articulated object interaction baselines on both train and test categories. Additionally, we evaluate AO-Grasp on 120 realworld scenes of objects with varied geometries, articulation axes, and joint states, where AO-Grasp produces successful grasps on 67.5% of scenes, while the baseline only produces successful grasps on 33.3% of scenes.","sentences":["We introduce AO-Grasp, a grasp proposal method that generates stable and actionable 6 degree-of-freedom grasps for articulated objects.","Our generated grasps enable robots to interact with articulated objects, such as opening and closing cabinets and appliances.","Given a segmented partial point cloud of a single articulated object, AO-Grasp predicts the best grasp points on the object with a novel Actionable Grasp Point Predictor model and then finds corresponding grasp orientations for each point by leveraging a state-of-the-art rigid object grasping method.","We train AO-Grasp on our new AO-Grasp Dataset, which contains 48K actionable parallel-jaw grasps on synthetic articulated objects.","In simulation, AO-Grasp achieves higher grasp success rates than existing rigid object grasping and articulated object interaction baselines on both train and test categories.","Additionally, we evaluate AO-Grasp on 120 realworld scenes of objects with varied geometries, articulation axes, and joint states, where AO-Grasp produces successful grasps on 67.5% of scenes, while the baseline only produces successful grasps on 33.3% of scenes."],"url":"http://arxiv.org/abs/2310.15928v1"}
{"created":"2023-10-24 15:22:04","title":"Contrastive Learning-based Sentence Encoders Implicitly Weight Informative Words","abstract":"The performance of sentence encoders can be significantly improved through the simple practice of fine-tuning using contrastive loss. A natural question arises: what characteristics do models acquire during contrastive learning? This paper theoretically and experimentally shows that contrastive-based sentence encoders implicitly weight words based on information-theoretic quantities; that is, more informative words receive greater weight, while others receive less. The theory states that, in the lower bound of the optimal value of the contrastive learning objective, the norm of word embedding reflects the information gain associated with the distribution of surrounding words. We also conduct comprehensive experiments using various models, multiple datasets, two methods to measure the implicit weighting of models (Integrated Gradients and SHAP), and two information-theoretic quantities (information gain and self-information). The results provide empirical evidence that contrastive fine-tuning emphasizes informative words.","sentences":["The performance of sentence encoders can be significantly improved through the simple practice of fine-tuning using contrastive loss.","A natural question arises: what characteristics do models acquire during contrastive learning?","This paper theoretically and experimentally shows that contrastive-based sentence encoders implicitly weight words based on information-theoretic quantities; that is, more informative words receive greater weight, while others receive less.","The theory states that, in the lower bound of the optimal value of the contrastive learning objective, the norm of word embedding reflects the information gain associated with the distribution of surrounding words.","We also conduct comprehensive experiments using various models, multiple datasets, two methods to measure the implicit weighting of models (Integrated Gradients and SHAP), and two information-theoretic quantities (information gain and self-information).","The results provide empirical evidence that contrastive fine-tuning emphasizes informative words."],"url":"http://arxiv.org/abs/2310.15921v1"}
{"created":"2023-10-24 15:17:14","title":"In-Context Learning Creates Task Vectors","abstract":"In-context learning (ICL) in Large Language Models (LLMs) has emerged as a powerful new learning paradigm. However, its underlying mechanism is still not well understood. In particular, it is challenging to map it to the \"standard\" machine learning framework, where one uses a training set $S$ to find a best-fitting function $f(x)$ in some hypothesis class. Here we make progress on this problem by showing that the functions learned by ICL often have a very simple structure: they correspond to the transformer LLM whose only inputs are the query $x$ and a single \"task vector\" calculated from the training set. Thus, ICL can be seen as compressing $S$ into a single task vector $\\boldsymbol{\\theta}(S)$ and then using this task vector to modulate the transformer to produce the output. We support the above claim via comprehensive experiments across a range of models and tasks.","sentences":["In-context learning (ICL) in Large Language Models (LLMs) has emerged as a powerful new learning paradigm.","However, its underlying mechanism is still not well understood.","In particular, it is challenging to map it to the \"standard\" machine learning framework, where one uses a training set $S$ to find a best-fitting function $f(x)$ in some hypothesis class.","Here we make progress on this problem by showing that the functions learned by ICL often have a very simple structure: they correspond to the transformer LLM whose only inputs are the query $x$ and a single \"task vector\" calculated from the training set.","Thus, ICL can be seen as compressing $S$ into a single task vector $\\boldsymbol{\\theta}(S)$ and then using this task vector to modulate the transformer to produce the output.","We support the above claim via comprehensive experiments across a range of models and tasks."],"url":"http://arxiv.org/abs/2310.15916v1"}
{"created":"2023-10-24 15:16:57","title":"A Pure Demand Operational Semantics With Applications to Program Analysis","abstract":"This paper develops a novel minimal-state operational semantics for higher-order functional languages which uses only the call stack and two source program points as the complete state information: there is no environment, no substitution, no continuation, etc. We prove this form of operational semantics is equivalent to standard presentations.   We then show how this approach can open the door to potential new applications: we define a program analysis as a direct finitization of this operational semantics. The program analysis that naturally emerges has a number of novel and interesting properties compared to standard program analyses for higher-order programs: for example, it can infer recurrences, and does not need value widening. We both give a formal definition of the analysis and describe our current implementation.","sentences":["This paper develops a novel minimal-state operational semantics for higher-order functional languages which uses only the call stack and two source program points as the complete state information: there is no environment, no substitution, no continuation, etc.","We prove this form of operational semantics is equivalent to standard presentations.   ","We then show how this approach can open the door to potential new applications: we define a program analysis as a direct finitization of this operational semantics.","The program analysis that naturally emerges has a number of novel and interesting properties compared to standard program analyses for higher-order programs: for example, it can infer recurrences, and does not need value widening.","We both give a formal definition of the analysis and describe our current implementation."],"url":"http://arxiv.org/abs/2310.15915v1"}
{"created":"2023-10-24 15:15:57","title":"Mitigate Domain Shift by Primary-Auxiliary Objectives Association for Generalizing Person ReID","abstract":"While deep learning has significantly improved ReID model accuracy under the independent and identical distribution (IID) assumption, it has also become clear that such models degrade notably when applied to an unseen novel domain due to unpredictable/unknown domain shift. Contemporary domain generalization (DG) ReID models struggle in learning domain-invariant representation solely through training on an instance classification objective. We consider that a deep learning model is heavily influenced and therefore biased towards domain-specific characteristics, e.g., background clutter, scale and viewpoint variations, limiting the generalizability of the learned model, and hypothesize that the pedestrians are domain invariant owning they share the same structural characteristics. To enable the ReID model to be less domain-specific from these pure pedestrians, we introduce a method that guides model learning of the primary ReID instance classification objective by a concurrent auxiliary learning objective on weakly labeled pedestrian saliency detection. To solve the problem of conflicting optimization criteria in the model parameter space between the two learning objectives, we introduce a Primary-Auxiliary Objectives Association (PAOA) mechanism to calibrate the loss gradients of the auxiliary task towards the primary learning task gradients. Benefiting from the harmonious multitask learning design, our model can be extended with the recent test-time diagram to form the PAOA+, which performs on-the-fly optimization against the auxiliary objective in order to maximize the model's generative capacity in the test target domain. Experiments demonstrate the superiority of the proposed PAOA model.","sentences":["While deep learning has significantly improved ReID model accuracy under the independent and identical distribution (IID) assumption, it has also become clear that such models degrade notably when applied to an unseen novel domain due to unpredictable/unknown domain shift.","Contemporary domain generalization (DG) ReID models struggle in learning domain-invariant representation solely through training on an instance classification objective.","We consider that a deep learning model is heavily influenced and therefore biased towards domain-specific characteristics, e.g., background clutter, scale and viewpoint variations, limiting the generalizability of the learned model, and hypothesize that the pedestrians are domain invariant owning they share the same structural characteristics.","To enable the ReID model to be less domain-specific from these pure pedestrians, we introduce a method that guides model learning of the primary ReID instance classification objective by a concurrent auxiliary learning objective on weakly labeled pedestrian saliency detection.","To solve the problem of conflicting optimization criteria in the model parameter space between the two learning objectives, we introduce a Primary-Auxiliary Objectives Association (PAOA) mechanism to calibrate the loss gradients of the auxiliary task towards the primary learning task gradients.","Benefiting from the harmonious multitask learning design, our model can be extended with the recent test-time diagram to form the PAOA+, which performs on-the-fly optimization against the auxiliary objective in order to maximize the model's generative capacity in the test target domain.","Experiments demonstrate the superiority of the proposed PAOA model."],"url":"http://arxiv.org/abs/2310.15913v1"}
{"created":"2023-10-24 15:15:28","title":"Climate Change Impact on Agricultural Land Suitability: An Interpretable Machine Learning-Based Eurasia Case Study","abstract":"The United Nations has identified improving food security and reducing hunger as essential components of its sustainable development goals. As of 2021, approximately 828 million people worldwide are experiencing hunger and malnutrition, with numerous fatalities reported. Climate change significantly impacts agricultural land suitability, potentially leading to severe food shortages and subsequent social and political conflicts. To address this pressing issue, we have developed a machine learning-based approach to predict the risk of substantial land suitability degradation and changes in irrigation patterns. Our study focuses on Central Eurasia, a region burdened with economic and social challenges.   This study represents a pioneering effort in utilizing machine learning methods to assess the impact of climate change on agricultural land suitability under various carbon emissions scenarios. Through comprehensive feature importance analysis, we unveil specific climate and terrain characteristics that exert influence on land suitability. Our approach achieves remarkable accuracy, offering policymakers invaluable insights to facilitate informed decisions aimed at averting a humanitarian crisis, including strategies such as the provision of additional water and fertilizers. This research underscores the tremendous potential of machine learning in addressing global challenges, with a particular emphasis on mitigating hunger and malnutrition.","sentences":["The United Nations has identified improving food security and reducing hunger as essential components of its sustainable development goals.","As of 2021, approximately 828 million people worldwide are experiencing hunger and malnutrition, with numerous fatalities reported.","Climate change significantly impacts agricultural land suitability, potentially leading to severe food shortages and subsequent social and political conflicts.","To address this pressing issue, we have developed a machine learning-based approach to predict the risk of substantial land suitability degradation and changes in irrigation patterns.","Our study focuses on Central Eurasia, a region burdened with economic and social challenges.   ","This study represents a pioneering effort in utilizing machine learning methods to assess the impact of climate change on agricultural land suitability under various carbon emissions scenarios.","Through comprehensive feature importance analysis, we unveil specific climate and terrain characteristics that exert influence on land suitability.","Our approach achieves remarkable accuracy, offering policymakers invaluable insights to facilitate informed decisions aimed at averting a humanitarian crisis, including strategies such as the provision of additional water and fertilizers.","This research underscores the tremendous potential of machine learning in addressing global challenges, with a particular emphasis on mitigating hunger and malnutrition."],"url":"http://arxiv.org/abs/2310.15912v1"}
{"created":"2023-10-24 15:15:18","title":"Characterizing Mechanisms for Factual Recall in Language Models","abstract":"Language Models (LMs) often must integrate facts they memorized in pretraining with new information that appears in a given context. These two sources can disagree, causing competition within the model, and it is unclear how an LM will resolve the conflict. On a dataset that queries for knowledge of world capitals, we investigate both distributional and mechanistic determinants of LM behavior in such situations. Specifically, we measure the proportion of the time an LM will use a counterfactual prefix (e.g., \"The capital of Poland is London\") to overwrite what it learned in pretraining (\"Warsaw\"). On Pythia and GPT2, the training frequency of both the query country (\"Poland\") and the in-context city (\"London\") highly affect the models' likelihood of using the counterfactual. We then use head attribution to identify individual attention heads that either promote the memorized answer or the in-context answer in the logits. By scaling up or down the value vector of these heads, we can control the likelihood of using the in-context answer on new data. This method can increase the rate of generating the in-context answer to 88\\% of the time simply by scaling a single head at runtime. Our work contributes to a body of evidence showing that we can often localize model behaviors to specific components and provides a proof of concept for how future methods might control model behavior dynamically at runtime.","sentences":["Language Models (LMs) often must integrate facts they memorized in pretraining with new information that appears in a given context.","These two sources can disagree, causing competition within the model, and it is unclear how an LM will resolve the conflict.","On a dataset that queries for knowledge of world capitals, we investigate both distributional and mechanistic determinants of LM behavior in such situations.","Specifically, we measure the proportion of the time an LM will use a counterfactual prefix (e.g., \"The capital of Poland is London\") to overwrite what it learned in pretraining (\"Warsaw\").","On Pythia and GPT2, the training frequency of both the query country (\"Poland\") and the in-context city (\"London\") highly affect the models' likelihood of using the counterfactual.","We then use head attribution to identify individual attention heads that either promote the memorized answer or the in-context answer in the logits.","By scaling up or down the value vector of these heads, we can control the likelihood of using the in-context answer on new data.","This method can increase the rate of generating the in-context answer to 88\\% of the time simply by scaling a single head at runtime.","Our work contributes to a body of evidence showing that we can often localize model behaviors to specific components and provides a proof of concept for how future methods might control model behavior dynamically at runtime."],"url":"http://arxiv.org/abs/2310.15910v1"}
{"created":"2023-10-24 15:08:48","title":"LiCROM: Linear-Subspace Continuous Reduced Order Modeling with Neural Fields","abstract":"Linear reduced-order modeling (ROM) simplifies complex simulations by approximating the behavior of a system using a simplified kinematic representation. Typically, ROM is trained on input simulations created with a specific spatial discretization, and then serves to accelerate simulations with the same discretization. This discretization-dependence is restrictive.   Becoming independent of a specific discretization would provide flexibility to mix and match mesh resolutions, connectivity, and type (tetrahedral, hexahedral) in training data; to accelerate simulations with novel discretizations unseen during training; and to accelerate adaptive simulations that temporally or parametrically change the discretization.   We present a flexible, discretization-independent approach to reduced-order modeling. Like traditional ROM, we represent the configuration as a linear combination of displacement fields. Unlike traditional ROM, our displacement fields are continuous maps from every point on the reference domain to a corresponding displacement vector; these maps are represented as implicit neural fields.   With linear continuous ROM (LiCROM), our training set can include multiple geometries undergoing multiple loading conditions, independent of their discretization. This opens the door to novel applications of reduced order modeling. We can now accelerate simulations that modify the geometry at runtime, for instance via cutting, hole punching, and even swapping the entire mesh. We can also accelerate simulations of geometries unseen during training. We demonstrate one-shot generalization, training on a single geometry and subsequently simulating various unseen geometries.","sentences":["Linear reduced-order modeling (ROM) simplifies complex simulations by approximating the behavior of a system using a simplified kinematic representation.","Typically, ROM is trained on input simulations created with a specific spatial discretization, and then serves to accelerate simulations with the same discretization.","This discretization-dependence is restrictive.   ","Becoming independent of a specific discretization would provide flexibility to mix and match mesh resolutions, connectivity, and type (tetrahedral, hexahedral) in training data; to accelerate simulations with novel discretizations unseen during training; and to accelerate adaptive simulations that temporally or parametrically change the discretization.   ","We present a flexible, discretization-independent approach to reduced-order modeling.","Like traditional ROM, we represent the configuration as a linear combination of displacement fields.","Unlike traditional ROM, our displacement fields are continuous maps from every point on the reference domain to a corresponding displacement vector; these maps are represented as implicit neural fields.   ","With linear continuous ROM (LiCROM), our training set can include multiple geometries undergoing multiple loading conditions, independent of their discretization.","This opens the door to novel applications of reduced order modeling.","We can now accelerate simulations that modify the geometry at runtime, for instance via cutting, hole punching, and even swapping the entire mesh.","We can also accelerate simulations of geometries unseen during training.","We demonstrate one-shot generalization, training on a single geometry and subsequently simulating various unseen geometries."],"url":"http://arxiv.org/abs/2310.15907v1"}
{"created":"2023-10-24 15:08:12","title":"Is Probing All You Need? Indicator Tasks as an Alternative to Probing Embedding Spaces","abstract":"The ability to identify and control different kinds of linguistic information encoded in vector representations of words has many use cases, especially for explainability and bias removal. This is usually done via a set of simple classification tasks, termed probes, to evaluate the information encoded in the embedding space. However, the involvement of a trainable classifier leads to entanglement between the probe's results and the classifier's nature. As a result, contemporary works on probing include tasks that do not involve training of auxiliary models. In this work we introduce the term indicator tasks for non-trainable tasks which are used to query embedding spaces for the existence of certain properties, and claim that this kind of tasks may point to a direction opposite to probes, and that this contradiction complicates the decision on whether a property exists in an embedding space. We demonstrate our claims with two test cases, one dealing with gender debiasing and another with the erasure of morphological information from embedding spaces. We show that the application of a suitable indicator provides a more accurate picture of the information captured and removed compared to probes. We thus conclude that indicator tasks should be implemented and taken into consideration when eliciting information from embedded representations.","sentences":["The ability to identify and control different kinds of linguistic information encoded in vector representations of words has many use cases, especially for explainability and bias removal.","This is usually done via a set of simple classification tasks, termed probes, to evaluate the information encoded in the embedding space.","However, the involvement of a trainable classifier leads to entanglement between the probe's results and the classifier's nature.","As a result, contemporary works on probing include tasks that do not involve training of auxiliary models.","In this work we introduce the term indicator tasks for non-trainable tasks which are used to query embedding spaces for the existence of certain properties, and claim that this kind of tasks may point to a direction opposite to probes, and that this contradiction complicates the decision on whether a property exists in an embedding space.","We demonstrate our claims with two test cases, one dealing with gender debiasing and another with the erasure of morphological information from embedding spaces.","We show that the application of a suitable indicator provides a more accurate picture of the information captured and removed compared to probes.","We thus conclude that indicator tasks should be implemented and taken into consideration when eliciting information from embedded representations."],"url":"http://arxiv.org/abs/2310.15905v1"}
{"created":"2023-10-24 15:07:35","title":"Do Stochastic Parrots have Feelings Too? Improving Neural Detection of Synthetic Text via Emotion Recognition","abstract":"Recent developments in generative AI have shone a spotlight on high-performance synthetic text generation technologies. The now wide availability and ease of use of such models highlights the urgent need to provide equally powerful technologies capable of identifying synthetic text. With this in mind, we draw inspiration from psychological studies which suggest that people can be driven by emotion and encode emotion in the text they compose. We hypothesize that pretrained language models (PLMs) have an affective deficit because they lack such an emotional driver when generating text and consequently may generate synthetic text which has affective incoherence i.e. lacking the kind of emotional coherence present in human-authored text. We subsequently develop an emotionally aware detector by fine-tuning a PLM on emotion. Experiment results indicate that our emotionally-aware detector achieves improvements across a range of synthetic text generators, various sized models, datasets, and domains. Finally, we compare our emotionally-aware synthetic text detector to ChatGPT in the task of identification of its own output and show substantial gains, reinforcing the potential of emotion as a signal to identify synthetic text. Code, models, and datasets are available at https: //github.com/alanagiasi/emoPLMsynth","sentences":["Recent developments in generative AI have shone a spotlight on high-performance synthetic text generation technologies.","The now wide availability and ease of use of such models highlights the urgent need to provide equally powerful technologies capable of identifying synthetic text.","With this in mind, we draw inspiration from psychological studies which suggest that people can be driven by emotion and encode emotion in the text they compose.","We hypothesize that pretrained language models (PLMs) have an affective deficit because they lack such an emotional driver when generating text and consequently may generate synthetic text which has affective incoherence i.e. lacking the kind of emotional coherence present in human-authored text.","We subsequently develop an emotionally aware detector by fine-tuning a PLM on emotion.","Experiment results indicate that our emotionally-aware detector achieves improvements across a range of synthetic text generators, various sized models, datasets, and domains.","Finally, we compare our emotionally-aware synthetic text detector to ChatGPT in the task of identification of its own output and show substantial gains, reinforcing the potential of emotion as a signal to identify synthetic text.","Code, models, and datasets are available at https: //github.com/alanagiasi/emoPLMsynth"],"url":"http://arxiv.org/abs/2310.15904v1"}
{"created":"2023-10-24 15:07:16","title":"Neural Collapse in Multi-label Learning with Pick-all-label Loss","abstract":"We study deep neural networks for the multi-label classification (MLab) task through the lens of neural collapse (NC). Previous works have been restricted to the multi-class classification setting and discovered a prevalent NC phenomenon comprising of the following properties for the last-layer features: (i) the variability of features within every class collapses to zero, (ii) the set of feature means form an equi-angular tight frame (ETF), and (iii) the last layer classifiers collapse to the feature mean upon some scaling. We generalize the study to multi-label learning, and prove for the first time that a generalized NC phenomenon holds with the \"pick-all-label'' formulation. Under the natural analog of the unconstrained feature model (UFM), we establish that the only global classifier of the pick-all-label cross entropy loss display the same ETF geometry which further collapse to multiplicity-1 feature class means. Besides, we discover a combinatorial property in generalized NC which is unique for multi-label learning that we call ``tag-wise average'' property, where the feature class-means of samples with multiple labels are scaled average of the feature class-means of single label tags. Theoretically, we establish global optimality result for the pick-all-label cross-entropy risk for the UFM. Additionally, We also provide empirical evidence to support our investigation into training deep neural networks on multi-label datasets, resulting in improved training efficiency.","sentences":["We study deep neural networks for the multi-label classification (MLab) task through the lens of neural collapse (NC).","Previous works have been restricted to the multi-class classification setting and discovered a prevalent NC phenomenon comprising of the following properties for the last-layer features: (i) the variability of features within every class collapses to zero, (ii) the set of feature means form an equi-angular tight frame (ETF), and (iii) the last layer classifiers collapse to the feature mean upon some scaling.","We generalize the study to multi-label learning, and prove for the first time that a generalized NC phenomenon holds with the \"pick-all-label'' formulation.","Under the natural analog of the unconstrained feature model (UFM), we establish that the only global classifier of the pick-all-label cross entropy loss display the same ETF geometry which further collapse to multiplicity-1 feature class means.","Besides, we discover a combinatorial property in generalized NC which is unique for multi-label learning that we call ``tag-wise average'' property, where the feature class-means of samples with multiple labels are scaled average of the feature class-means of single label tags.","Theoretically, we establish global optimality result for the pick-all-label cross-entropy risk for the UFM.","Additionally, We also provide empirical evidence to support our investigation into training deep neural networks on multi-label datasets, resulting in improved training efficiency."],"url":"http://arxiv.org/abs/2310.15903v1"}
{"created":"2023-10-24 15:07:08","title":"Delaunay Bifiltrations of Functions on Point Clouds","abstract":"The Delaunay filtration $\\mathcal{D}_{\\bullet}(X)$ of a point cloud $X\\subset \\mathbb{R}^d$ is a central tool of computational topology. Its use is justified by the topological equivalence of $\\mathcal{D}_{\\bullet}(X)$ and the offset (i.e., union-of-balls) filtration of $X$. Given a function $\\gamma: X \\to \\mathbb{R}$, we introduce a Delaunay bifiltration $\\mathcal{DC}_{\\bullet}(\\gamma)$ that satisfies an analogous topological equivalence, ensuring that $\\mathcal{DC}_{\\bullet}(\\gamma)$ topologically encodes the offset filtrations of all sublevel sets of $\\gamma$, as well as the topological relations between them. $\\mathcal{DC}_{\\bullet}(\\gamma)$ is of size $O(|X|^{\\lceil\\frac{d+1}{2}\\rceil})$, which for $d$ odd matches the worst-case size of $\\mathcal{D}_{\\bullet}(X)$. Adapting the Bowyer-Watson algorithm for computing Delaunay triangulations, we give a simple, practical algorithm to compute $\\mathcal{DC}_{\\bullet}(\\gamma)$ in time $O(|X|^{\\lceil \\frac{d}{2}\\rceil +1})$. Our implementation, based on CGAL, computes $\\mathcal{DC}_{\\bullet}(\\gamma)$ with modest overhead compared to computing $\\mathcal{D}_{\\bullet}(X)$, and handles tens of thousands of points in $\\mathbb{R}^3$ within seconds.","sentences":["The Delaunay filtration $\\mathcal{D}_{\\bullet}(X)$ of a point cloud $X\\subset \\mathbb{R}^d$ is a central tool of computational topology.","Its use is justified by the topological equivalence of $\\mathcal{D}_{\\bullet}(X)$ and the offset (i.e., union-of-balls) filtration of $X$. Given a function $\\gamma: X \\to \\mathbb{R}$, we introduce a Delaunay bifiltration $\\mathcal{DC}_{\\bullet}(\\gamma)$ that satisfies an analogous topological equivalence, ensuring that $\\mathcal{DC}_{\\bullet}(\\gamma)$ topologically encodes the offset filtrations of all sublevel sets of $\\gamma$, as well as the topological relations between them.","$\\mathcal{DC}_{\\bullet}(\\gamma)$ is of size $O(|X|^{\\lceil\\frac{d+1}{2}\\rceil})$, which for $d$ odd matches the worst-case size of $\\mathcal{D}_{\\bullet}(X)$. Adapting the Bowyer-Watson algorithm for computing Delaunay triangulations, we give a simple, practical algorithm to compute $\\mathcal{DC}_{\\bullet}(\\gamma)$ in time $O(|X|^{\\lceil \\frac{d}{2}\\rceil +1})$.","Our implementation, based on CGAL, computes $\\mathcal{DC}_{\\bullet}(\\gamma)$ with modest overhead compared to computing $\\mathcal{D}_{\\bullet}(X)$, and handles tens of thousands of points in $\\mathbb{R}^3$ within seconds."],"url":"http://arxiv.org/abs/2310.15902v1"}
{"created":"2023-10-24 14:57:34","title":"BianQue: Balancing the Questioning and Suggestion Ability of Health LLMs with Multi-turn Health Conversations Polished by ChatGPT","abstract":"Large language models (LLMs) have performed well in providing general and extensive health suggestions in single-turn conversations, exemplified by systems such as ChatGPT, ChatGLM, ChatDoctor, DoctorGLM, and etc. However, the limited information provided by users during single turn results in inadequate personalization and targeting of the generated suggestions, which requires users to independently select the useful part. It is mainly caused by the missing ability to engage in multi-turn questioning. In real-world medical consultations, doctors usually employ a series of iterative inquiries to comprehend the patient's condition thoroughly, enabling them to provide effective and personalized suggestions subsequently, which can be defined as chain of questioning (CoQ) for LLMs. To improve the CoQ of LLMs, we propose BianQue, a ChatGLM-based LLM finetuned with the self-constructed health conversation dataset BianQueCorpus that is consist of multiple turns of questioning and health suggestions polished by ChatGPT. Experimental results demonstrate that the proposed BianQue can simultaneously balance the capabilities of both questioning and health suggestions, which will help promote the research and application of LLMs in the field of proactive health.","sentences":["Large language models (LLMs) have performed well in providing general and extensive health suggestions in single-turn conversations, exemplified by systems such as ChatGPT, ChatGLM, ChatDoctor, DoctorGLM, and etc.","However, the limited information provided by users during single turn results in inadequate personalization and targeting of the generated suggestions, which requires users to independently select the useful part.","It is mainly caused by the missing ability to engage in multi-turn questioning.","In real-world medical consultations, doctors usually employ a series of iterative inquiries to comprehend the patient's condition thoroughly, enabling them to provide effective and personalized suggestions subsequently, which can be defined as chain of questioning (CoQ) for LLMs.","To improve the CoQ of LLMs, we propose BianQue, a ChatGLM-based LLM finetuned with the self-constructed health conversation dataset BianQueCorpus that is consist of multiple turns of questioning and health suggestions polished by ChatGPT.","Experimental results demonstrate that the proposed BianQue can simultaneously balance the capabilities of both questioning and health suggestions, which will help promote the research and application of LLMs in the field of proactive health."],"url":"http://arxiv.org/abs/2310.15896v1"}
{"created":"2023-10-24 14:48:23","title":"Cross-feature Contrastive Loss for Decentralized Deep Learning on Heterogeneous Data","abstract":"The current state-of-the-art decentralized learning algorithms mostly assume the data distribution to be Independent and Identically Distributed (IID). However, in practical scenarios, the distributed datasets can have significantly heterogeneous data distributions across the agents. In this work, we present a novel approach for decentralized learning on heterogeneous data, where data-free knowledge distillation through contrastive loss on cross-features is utilized to improve performance. Cross-features for a pair of neighboring agents are the features (i.e., last hidden layer activations) obtained from the data of an agent with respect to the model parameters of the other agent. We demonstrate the effectiveness of the proposed technique through an exhaustive set of experiments on various Computer Vision datasets (CIFAR-10, CIFAR-100, Fashion MNIST, and ImageNet), model architectures, and network topologies. Our experiments show that the proposed method achieves superior performance (0.2-4% improvement in test accuracy) compared to other existing techniques for decentralized learning on heterogeneous data.","sentences":["The current state-of-the-art decentralized learning algorithms mostly assume the data distribution to be Independent and Identically Distributed (IID).","However, in practical scenarios, the distributed datasets can have significantly heterogeneous data distributions across the agents.","In this work, we present a novel approach for decentralized learning on heterogeneous data, where data-free knowledge distillation through contrastive loss on cross-features is utilized to improve performance.","Cross-features for a pair of neighboring agents are the features (i.e., last hidden layer activations) obtained from the data of an agent with respect to the model parameters of the other agent.","We demonstrate the effectiveness of the proposed technique through an exhaustive set of experiments on various Computer Vision datasets (CIFAR-10, CIFAR-100, Fashion MNIST, and ImageNet), model architectures, and network topologies.","Our experiments show that the proposed method achieves superior performance (0.2-4% improvement in test accuracy) compared to other existing techniques for decentralized learning on heterogeneous data."],"url":"http://arxiv.org/abs/2310.15890v1"}
{"created":"2023-10-24 14:47:02","title":"State Sequences Prediction via Fourier Transform for Representation Learning","abstract":"While deep reinforcement learning (RL) has been demonstrated effective in solving complex control tasks, sample efficiency remains a key challenge due to the large amounts of data required for remarkable performance. Existing research explores the application of representation learning for data-efficient RL, e.g., learning predictive representations by predicting long-term future states. However, many existing methods do not fully exploit the structural information inherent in sequential state signals, which can potentially improve the quality of long-term decision-making but is difficult to discern in the time domain. To tackle this problem, we propose State Sequences Prediction via Fourier Transform (SPF), a novel method that exploits the frequency domain of state sequences to extract the underlying patterns in time series data for learning expressive representations efficiently. Specifically, we theoretically analyze the existence of structural information in state sequences, which is closely related to policy performance and signal regularity, and then propose to predict the Fourier transform of infinite-step future state sequences to extract such information. One of the appealing features of SPF is that it is simple to implement while not requiring storage of infinite-step future states as prediction targets. Experiments demonstrate that the proposed method outperforms several state-of-the-art algorithms in terms of both sample efficiency and performance.","sentences":["While deep reinforcement learning (RL) has been demonstrated effective in solving complex control tasks, sample efficiency remains a key challenge due to the large amounts of data required for remarkable performance.","Existing research explores the application of representation learning for data-efficient RL, e.g., learning predictive representations by predicting long-term future states.","However, many existing methods do not fully exploit the structural information inherent in sequential state signals, which can potentially improve the quality of long-term decision-making but is difficult to discern in the time domain.","To tackle this problem, we propose State Sequences Prediction via Fourier Transform (SPF), a novel method that exploits the frequency domain of state sequences to extract the underlying patterns in time series data for learning expressive representations efficiently.","Specifically, we theoretically analyze the existence of structural information in state sequences, which is closely related to policy performance and signal regularity, and then propose to predict the Fourier transform of infinite-step future state sequences to extract such information.","One of the appealing features of SPF is that it is simple to implement while not requiring storage of infinite-step future states as prediction targets.","Experiments demonstrate that the proposed method outperforms several state-of-the-art algorithms in terms of both sample efficiency and performance."],"url":"http://arxiv.org/abs/2310.15888v1"}
{"created":"2023-10-24 14:44:41","title":"AdaptiX -- A Transitional XR Framework for Development and Evaluation of Shared Control Applications in Assistive Robotics","abstract":"With the ongoing efforts to empower people with mobility impairments and the increase in technological acceptance by the general public, assistive technologies, such as collaborative robotic arms, are gaining popularity. Yet, their widespread success is limited by usability issues, specifically the disparity between user input and software control along the autonomy continuum. To address this, shared control concepts provide opportunities to combine the targeted increase of user autonomy with a certain level of computer assistance. This paper presents the free and open-source AdaptiX XR framework for developing and evaluating shared control applications in a high-resolution simulation environment. The initial framework consists of a simulated robotic arm with an example scenario in Virtual Reality (VR), multiple standard control interfaces, and a specialized recording/replay system. AdaptiX can easily be extended for specific research needs, allowing Human-Robot Interaction (HRI) researchers to rapidly design and test novel interaction methods, intervention strategies, and multi-modal feedback techniques, without requiring an actual physical robotic arm during the early phases of ideation, prototyping, and evaluation. Also, a Robot Operating System (ROS) integration enables the controlling of a real robotic arm in a PhysicalTwin approach without any simulation-reality gap. Here, we review the capabilities and limitations of AdaptiX in detail and present three bodies of research based on the framework. AdaptiX can be accessed at https://adaptix.robot-research.de.","sentences":["With the ongoing efforts to empower people with mobility impairments and the increase in technological acceptance by the general public, assistive technologies, such as collaborative robotic arms, are gaining popularity.","Yet, their widespread success is limited by usability issues, specifically the disparity between user input and software control along the autonomy continuum.","To address this, shared control concepts provide opportunities to combine the targeted increase of user autonomy with a certain level of computer assistance.","This paper presents the free and open-source AdaptiX XR framework for developing and evaluating shared control applications in a high-resolution simulation environment.","The initial framework consists of a simulated robotic arm with an example scenario in Virtual Reality (VR), multiple standard control interfaces, and a specialized recording/replay system.","AdaptiX can easily be extended for specific research needs, allowing Human-Robot Interaction (HRI) researchers to rapidly design and test novel interaction methods, intervention strategies, and multi-modal feedback techniques, without requiring an actual physical robotic arm during the early phases of ideation, prototyping, and evaluation.","Also, a Robot Operating System (ROS) integration enables the controlling of a real robotic arm in a PhysicalTwin approach without any simulation-reality gap.","Here, we review the capabilities and limitations of AdaptiX in detail and present three bodies of research based on the framework.","AdaptiX can be accessed at https://adaptix.robot-research.de."],"url":"http://arxiv.org/abs/2310.15887v1"}
{"created":"2023-10-24 14:30:45","title":"Data-Driven Modeling and Analysis of Transmission Error in Harmonic Drive Systems: Nonlinear Dynamics, Error Modeling, and Compensation Techniques","abstract":"Harmonic drive systems (HDS) are high-precision robotic transmissions featuring compact size and high gear ratios. However, issues like kinematic transmission errors hamper their precision performance. This article focuses on data-driven modeling and analysis of an HDS to improve kinematic error compensation. The background introduces HDS mechanics, nonlinear attributes, and modeling approaches from literature. The HDS dynamics are derived using Lagrange equations. Experiments under aggressive conditions provide training data exhibiting deterministic patterns. Various linear and nonlinear models have been developed. The best-performing model, based on a nonlinear neural network, achieves over 98\\% accuracy for one-step predictions on both the training and validation data sets. A phenomenological model separates the kinematic error into a periodic pure part and flexible part. Apart from implementation of estimated transmission error injection compensation, novel compensation mechanisms policies for the kinematic error are analyzed and proposed, including nonlinear model predictive control and frequency loop-shaping. The feedback loop is analyzed to select the controller for vibration mitigation. Main contributions include the nonlinear dynamics derivation, data-driven nonlinear modeling of flexible kinematic errors, repeatable experiment design, and proposed novel compensation mechanism and policies. Future work involves using physics-informed neural networks, sensitivity analysis, full life-cycle monitoring, and extracting physical laws directly from data.","sentences":["Harmonic drive systems (HDS) are high-precision robotic transmissions featuring compact size and high gear ratios.","However, issues like kinematic transmission errors hamper their precision performance.","This article focuses on data-driven modeling and analysis of an HDS to improve kinematic error compensation.","The background introduces HDS mechanics, nonlinear attributes, and modeling approaches from literature.","The HDS dynamics are derived using Lagrange equations.","Experiments under aggressive conditions provide training data exhibiting deterministic patterns.","Various linear and nonlinear models have been developed.","The best-performing model, based on a nonlinear neural network, achieves over 98\\% accuracy for one-step predictions on both the training and validation data sets.","A phenomenological model separates the kinematic error into a periodic pure part and flexible part.","Apart from implementation of estimated transmission error injection compensation, novel compensation mechanisms policies for the kinematic error are analyzed and proposed, including nonlinear model predictive control and frequency loop-shaping.","The feedback loop is analyzed to select the controller for vibration mitigation.","Main contributions include the nonlinear dynamics derivation, data-driven nonlinear modeling of flexible kinematic errors, repeatable experiment design, and proposed novel compensation mechanism and policies.","Future work involves using physics-informed neural networks, sensitivity analysis, full life-cycle monitoring, and extracting physical laws directly from data."],"url":"http://arxiv.org/abs/2310.15875v1"}
{"created":"2023-10-24 14:28:00","title":"KirchhoffNet: A Circuit Bridging Message Passing and Continuous-Depth Models","abstract":"In this paper, we exploit a fundamental principle of analog electronic circuitry, Kirchhoff's current law, to introduce a unique class of neural network models that we refer to as KirchhoffNet. KirchhoffNet establishes close connections with message passing neural networks and continuous-depth networks. We demonstrate that even in the absence of any traditional layers (such as convolution, pooling, or linear layers), KirchhoffNet attains 98.86% test accuracy on the MNIST dataset, comparable with state of the art (SOTA) results. What makes KirchhoffNet more intriguing is its potential in the realm of hardware. Contemporary deep neural networks are conventionally deployed on GPUs. In contrast, KirchhoffNet can be physically realized by an analog electronic circuit. Moreover, we justify that irrespective of the number of parameters within a KirchhoffNet, its forward calculation can always be completed within 1/f seconds, with f representing the hardware's clock frequency. This characteristic introduces a promising technology for implementing ultra-large-scale neural networks.","sentences":["In this paper, we exploit a fundamental principle of analog electronic circuitry, Kirchhoff's current law, to introduce a unique class of neural network models that we refer to as KirchhoffNet.","KirchhoffNet establishes close connections with message passing neural networks and continuous-depth networks.","We demonstrate that even in the absence of any traditional layers (such as convolution, pooling, or linear layers), KirchhoffNet attains 98.86% test accuracy on the MNIST dataset, comparable with state of the art (SOTA) results.","What makes KirchhoffNet more intriguing is its potential in the realm of hardware.","Contemporary deep neural networks are conventionally deployed on GPUs.","In contrast, KirchhoffNet can be physically realized by an analog electronic circuit.","Moreover, we justify that irrespective of the number of parameters within a KirchhoffNet, its forward calculation can always be completed within 1/f seconds, with f representing the hardware's clock frequency.","This characteristic introduces a promising technology for implementing ultra-large-scale neural networks."],"url":"http://arxiv.org/abs/2310.15872v1"}
{"created":"2023-10-24 14:23:10","title":"Using Causality-Aware Graph Neural Networks to Predict Temporal Centralities in Dynamic Graphs","abstract":"Node centralities play a pivotal role in network science, social network analysis, and recommender systems. In temporal data, static path-based centralities like closeness or betweenness can give misleading results about the true importance of nodes in a temporal graph. To address this issue, temporal generalizations of betweenness and closeness have been defined that are based on the shortest time-respecting paths between pairs of nodes. However, a major issue of those generalizations is that the calculation of such paths is computationally expensive. Addressing this issue, we study the application of De Bruijn Graph Neural Networks (DBGNN), a causality-aware graph neural network architecture, to predict temporal path-based centralities in time series data. We experimentally evaluate our approach in 13 temporal graphs from biological and social systems and show that it considerably improves the prediction of both betweenness and closeness centrality compared to a static Graph Convolutional Neural Network.","sentences":["Node centralities play a pivotal role in network science, social network analysis, and recommender systems.","In temporal data, static path-based centralities like closeness or betweenness can give misleading results about the true importance of nodes in a temporal graph.","To address this issue, temporal generalizations of betweenness and closeness have been defined that are based on the shortest time-respecting paths between pairs of nodes.","However, a major issue of those generalizations is that the calculation of such paths is computationally expensive.","Addressing this issue, we study the application of De Bruijn Graph Neural Networks (DBGNN), a causality-aware graph neural network architecture, to predict temporal path-based centralities in time series data.","We experimentally evaluate our approach in 13 temporal graphs from biological and social systems and show that it considerably improves the prediction of both betweenness and closeness centrality compared to a static Graph Convolutional Neural Network."],"url":"http://arxiv.org/abs/2310.15865v1"}
{"created":"2023-10-24 14:22:29","title":"Metric Clustering and MST with Strong and Weak Distance Oracles","abstract":"We study optimization problems in a metric space $(\\mathcal{X},d)$ where we can compute distances in two ways: via a ''strong'' oracle that returns exact distances $d(x,y)$, and a ''weak'' oracle that returns distances $\\tilde{d}(x,y)$ which may be arbitrarily corrupted with some probability. This model captures the increasingly common trade-off between employing both an expensive similarity model (e.g. a large-scale embedding model), and a less accurate but cheaper model. Hence, the goal is to make as few queries to the strong oracle as possible. We consider both so-called ''point queries'', where the strong oracle is queried on a set of points $S \\subset \\mathcal{X} $ and returns $d(x,y)$ for all $x,y \\in S$, and ''edge queries'' where it is queried for individual distances $d(x,y)$.   Our main contributions are optimal algorithms and lower bounds for clustering and Minimum Spanning Tree (MST) in this model. For $k$-centers, $k$-median, and $k$-means, we give constant factor approximation algorithms with only $\\tilde{O}(k)$ strong oracle point queries, and prove that $\\Omega(k)$ queries are required for any bounded approximation. For edge queries, our upper and lower bounds are both $\\tilde{\\Theta}(k^2)$. Surprisingly, for the MST problem we give a $O(\\sqrt{\\log n})$ approximation algorithm using no strong oracle queries at all, and a matching $\\Omega(\\sqrt{\\log n})$ lower bound. We empirically evaluate our algorithms, and show that their quality is comparable to that of the baseline algorithms that are given all true distances, but while querying the strong oracle on only a small fraction ($<1\\%$) of points.","sentences":["We study optimization problems in a metric space $(\\mathcal{X},d)$ where we can compute distances in two ways: via a ''strong'' oracle that returns exact distances $d(x,y)$, and a ''weak'' oracle that returns distances $\\tilde{d}(x,y)$ which may be arbitrarily corrupted with some probability.","This model captures the increasingly common trade-off between employing both an expensive similarity model (e.g. a large-scale embedding model), and a less accurate but cheaper model.","Hence, the goal is to make as few queries to the strong oracle as possible.","We consider both so-called ''point queries'', where the strong oracle is queried on a set of points $S \\subset \\mathcal{X} $ and returns $d(x,y)$ for all $x,y \\in S$, and ''edge queries'' where it is queried for individual distances $d(x,y)$.   Our main contributions are optimal algorithms and lower bounds for clustering and Minimum Spanning Tree (MST) in this model.","For $k$-centers, $k$-median, and $k$-means, we give constant factor approximation algorithms with only $\\tilde{O}(k)$ strong oracle point queries, and prove that $\\Omega(k)$ queries are required for any bounded approximation.","For edge queries, our upper and lower bounds are both $\\tilde{\\Theta}(k^2)$. Surprisingly, for the MST problem we give a $O(\\sqrt{\\log n})$ approximation algorithm using no strong oracle queries at all, and a matching $\\Omega(\\sqrt{\\log n})$ lower bound.","We empirically evaluate our algorithms, and show that their quality is comparable to that of the baseline algorithms that are given all true distances, but while querying the strong oracle on only a small fraction ($<1\\%$) of points."],"url":"http://arxiv.org/abs/2310.15863v1"}
{"created":"2023-10-24 14:22:09","title":"Is a humorous robot more trustworthy?","abstract":"As more and more social robots are being used for collaborative activities with humans, it is crucial to investigate mechanisms to facilitate trust in the human-robot interaction. One such mechanism is humour: it has been shown to increase creativity and productivity in human-human interaction, which has an indirect influence on trust. In this study, we investigate if humour can increase trust in human-robot interaction. We conducted a between-subjects experiment with 40 participants to see if the participants are more likely to accept the robot's suggestion in the Three-card Monte game, as a trust check task. Though we were unable to find a significant effect of humour, we discuss the effect of possible confounding variables, and also report some interesting qualitative observations from our study: for instance, the participants interacted effectively with the robot as a team member, regardless of the humour or no-humour condition.","sentences":["As more and more social robots are being used for collaborative activities with humans, it is crucial to investigate mechanisms to facilitate trust in the human-robot interaction.","One such mechanism is humour: it has been shown to increase creativity and productivity in human-human interaction, which has an indirect influence on trust.","In this study, we investigate if humour can increase trust in human-robot interaction.","We conducted a between-subjects experiment with 40 participants to see if the participants are more likely to accept the robot's suggestion in the Three-card Monte game, as a trust check task.","Though we were unable to find a significant effect of humour, we discuss the effect of possible confounding variables, and also report some interesting qualitative observations from our study: for instance, the participants interacted effectively with the robot as a team member, regardless of the humour or no-humour condition."],"url":"http://arxiv.org/abs/2310.15862v1"}
{"created":"2023-10-24 14:16:19","title":"Topology-aware Debiased Self-supervised Graph Learning for Recommendation","abstract":"In recommendation, graph-based Collaborative Filtering (CF) methods mitigate the data sparsity by introducing Graph Contrastive Learning (GCL). However, the random negative sampling strategy in these GCL-based CF models neglects the semantic structure of users (items), which not only introduces false negatives (negatives that are similar to anchor user (item)) but also ignores the potential positive samples. To tackle the above issues, we propose Topology-aware Debiased Self-supervised Graph Learning (TDSGL) for recommendation, which constructs contrastive pairs according to the semantic similarity between users (items). Specifically, since the original user-item interaction data commendably reflects the purchasing intent of users and certain characteristics of items, we calculate the semantic similarity between users (items) on interaction data. Then, given a user (item), we construct its negative pairs by selecting users (items) which embed different semantic structures to ensure the semantic difference between the given user (item) and its negatives. Moreover, for a user (item), we design a feature extraction module that converts other semantically similar users (items) into an auxiliary positive sample to acquire a more informative representation. Experimental results show that the proposed model outperforms the state-of-the-art models significantly on three public datasets. Our model implementation codes are available at https://github.com/malajikuai/TDSGL.","sentences":["In recommendation, graph-based Collaborative Filtering (CF) methods mitigate the data sparsity by introducing Graph Contrastive Learning (GCL).","However, the random negative sampling strategy in these GCL-based CF models neglects the semantic structure of users (items), which not only introduces false negatives (negatives that are similar to anchor user (item)) but also ignores the potential positive samples.","To tackle the above issues, we propose Topology-aware Debiased Self-supervised Graph Learning (TDSGL) for recommendation, which constructs contrastive pairs according to the semantic similarity between users (items).","Specifically, since the original user-item interaction data commendably reflects the purchasing intent of users and certain characteristics of items, we calculate the semantic similarity between users (items) on interaction data.","Then, given a user (item), we construct its negative pairs by selecting users (items) which embed different semantic structures to ensure the semantic difference between the given user (item) and its negatives.","Moreover, for a user (item), we design a feature extraction module that converts other semantically similar users (items) into an auxiliary positive sample to acquire a more informative representation.","Experimental results show that the proposed model outperforms the state-of-the-art models significantly on three public datasets.","Our model implementation codes are available at https://github.com/malajikuai/TDSGL."],"url":"http://arxiv.org/abs/2310.15858v1"}
{"created":"2023-10-24 14:08:37","title":"Using Artificial French Data to Understand the Emergence of Gender Bias in Transformer Language Models","abstract":"Numerous studies have demonstrated the ability of neural language models to learn various linguistic properties without direct supervision. This work takes an initial step towards exploring the less researched topic of how neural models discover linguistic properties of words, such as gender, as well as the rules governing their usage. We propose to use an artificial corpus generated by a PCFG based on French to precisely control the gender distribution in the training data and determine under which conditions a model correctly captures gender information or, on the contrary, appears gender-biased.","sentences":["Numerous studies have demonstrated the ability of neural language models to learn various linguistic properties without direct supervision.","This work takes an initial step towards exploring the less researched topic of how neural models discover linguistic properties of words, such as gender, as well as the rules governing their usage.","We propose to use an artificial corpus generated by a PCFG based on French to precisely control the gender distribution in the training data and determine under which conditions a model correctly captures gender information or, on the contrary, appears gender-biased."],"url":"http://arxiv.org/abs/2310.15852v1"}
{"created":"2023-10-24 14:08:26","title":"Self-Guard: Empower the LLM to Safeguard Itself","abstract":"The jailbreak attack can bypass the safety measures of a Large Language Model (LLM), generating harmful content. This misuse of LLM has led to negative societal consequences. Currently, there are two main approaches to address jailbreak attacks: safety training and safeguards. Safety training focuses on further training LLM to enhance its safety. On the other hand, safeguards involve implementing external models or filters to prevent harmful outputs. However, safety training has constraints in its ability to adapt to new attack types and often leads to a drop in model performance. Safeguards have proven to be of limited help. To tackle these issues, we propose a novel approach called Self-Guard, which combines the strengths of both safety methods. Self-Guard includes two stages. In the first stage, we enhance the model's ability to assess harmful content, and in the second stage, we instruct the model to consistently perform harmful content detection on its own responses. The experiment has demonstrated that Self-Guard is robust against jailbreak attacks. In the bad case analysis, we find that LLM occasionally provides harmless responses to harmful queries. Additionally, we evaluated the general capabilities of the LLM before and after safety training, providing evidence that Self-Guard does not result in the LLM's performance degradation. In sensitivity tests, Self-Guard not only avoids inducing over-sensitivity in LLM but also can even mitigate this issue.","sentences":["The jailbreak attack can bypass the safety measures of a Large Language Model (LLM), generating harmful content.","This misuse of LLM has led to negative societal consequences.","Currently, there are two main approaches to address jailbreak attacks: safety training and safeguards.","Safety training focuses on further training LLM to enhance its safety.","On the other hand, safeguards involve implementing external models or filters to prevent harmful outputs.","However, safety training has constraints in its ability to adapt to new attack types and often leads to a drop in model performance.","Safeguards have proven to be of limited help.","To tackle these issues, we propose a novel approach called Self-Guard, which combines the strengths of both safety methods.","Self-Guard includes two stages.","In the first stage, we enhance the model's ability to assess harmful content, and in the second stage, we instruct the model to consistently perform harmful content detection on its own responses.","The experiment has demonstrated that Self-Guard is robust against jailbreak attacks.","In the bad case analysis, we find that LLM occasionally provides harmless responses to harmful queries.","Additionally, we evaluated the general capabilities of the LLM before and after safety training, providing evidence that Self-Guard does not result in the LLM's performance degradation.","In sensitivity tests, Self-Guard not only avoids inducing over-sensitivity in LLM but also can even mitigate this issue."],"url":"http://arxiv.org/abs/2310.15851v1"}
{"created":"2023-10-24 14:04:26","title":"A Resilient Framework for 5G-Edge-Connected UAVs based on Switching Edge-MPC and Onboard-PID Control","abstract":"In recent years, the need for resources for handling processes with high computational complexity for mobile robots is becoming increasingly urgent. More specifically, robots need to autonomously operate in a robust and continuous manner, while keeping high performance, a need that led to the utilization of edge computing to offload many computationally demanding and time-critical robotic procedures. However, safe mechanisms should be implemented to handle situations when it is not possible to use the offloaded procedures, such as if the communication is challenged or the edge cluster is not available. To this end, this article presents a switching strategy for safety, redundancy, and optimized behavior through an edge computing-based Model Predictive Controller (MPC) and a low-level onboard-PID controller for edge-connected Unmanned Aerial Vehicles (UAVs). The switching strategy is based on the communication Key Performance Indicators (KPIs) over 5G to decide whether the UAV should be controlled by the edge-based or have a safe fallback based on the onboard controller.","sentences":["In recent years, the need for resources for handling processes with high computational complexity for mobile robots is becoming increasingly urgent.","More specifically, robots need to autonomously operate in a robust and continuous manner, while keeping high performance, a need that led to the utilization of edge computing to offload many computationally demanding and time-critical robotic procedures.","However, safe mechanisms should be implemented to handle situations when it is not possible to use the offloaded procedures, such as if the communication is challenged or the edge cluster is not available.","To this end, this article presents a switching strategy for safety, redundancy, and optimized behavior through an edge computing-based Model Predictive Controller (MPC) and a low-level onboard-PID controller for edge-connected Unmanned Aerial Vehicles (UAVs).","The switching strategy is based on the communication Key Performance Indicators (KPIs) over 5G to decide whether the UAV should be controlled by the edge-based or have a safe fallback based on the onboard controller."],"url":"http://arxiv.org/abs/2310.15849v1"}
