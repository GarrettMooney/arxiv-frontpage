{"created":"2023-10-04 17:59:49","title":"LanguageMPC: Large Language Models as Decision Makers for Autonomous Driving","abstract":"Existing learning-based autonomous driving (AD) systems face challenges in comprehending high-level information, generalizing to rare events, and providing interpretability. To address these problems, this work employs Large Language Models (LLMs) as a decision-making component for complex AD scenarios that require human commonsense understanding. We devise cognitive pathways to enable comprehensive reasoning with LLMs, and develop algorithms for translating LLM decisions into actionable driving commands. Through this approach, LLM decisions are seamlessly integrated with low-level controllers by guided parameter matrix adaptation. Extensive experiments demonstrate that our proposed method not only consistently surpasses baseline approaches in single-vehicle tasks, but also helps handle complex driving behaviors even multi-vehicle coordination, thanks to the commonsense reasoning capabilities of LLMs. This paper presents an initial step toward leveraging LLMs as effective decision-makers for intricate AD scenarios in terms of safety, efficiency, generalizability, and interoperability. We aspire for it to serve as inspiration for future research in this field. Project page: https://sites.google.com/view/llm-mpc","sentences":["Existing learning-based autonomous driving (AD) systems face challenges in comprehending high-level information, generalizing to rare events, and providing interpretability.","To address these problems, this work employs Large Language Models (LLMs) as a decision-making component for complex AD scenarios that require human commonsense understanding.","We devise cognitive pathways to enable comprehensive reasoning with LLMs, and develop algorithms for translating LLM decisions into actionable driving commands.","Through this approach, LLM decisions are seamlessly integrated with low-level controllers by guided parameter matrix adaptation.","Extensive experiments demonstrate that our proposed method not only consistently surpasses baseline approaches in single-vehicle tasks, but also helps handle complex driving behaviors even multi-vehicle coordination, thanks to the commonsense reasoning capabilities of LLMs.","This paper presents an initial step toward leveraging LLMs as effective decision-makers for intricate AD scenarios in terms of safety, efficiency, generalizability, and interoperability.","We aspire for it to serve as inspiration for future research in this field.","Project page: https://sites.google.com/view/llm-mpc"],"url":"http://arxiv.org/abs/2310.03026v1"}
{"created":"2023-10-04 17:59:41","title":"Retrieval meets Long Context Large Language Models","abstract":"Extending the context window of large language models (LLMs) is getting popular recently, while the solution of augmenting LLMs with retrieval has existed for years. The natural questions are: i) Retrieval-augmentation versus long context window, which one is better for downstream tasks? ii) Can both methods be combined to get the best of both worlds? In this work, we answer these questions by studying both solutions using two state-of-the-art pretrained LLMs, i.e., a proprietary 43B GPT and LLaMA2-70B. Perhaps surprisingly, we find that LLM with 4K context window using simple retrieval-augmentation at generation can achieve comparable performance to finetuned LLM with 16K context window via positional interpolation on long context tasks, while taking much less computation. More importantly, we demonstrate that retrieval can significantly improve the performance of LLMs regardless of their extended context window sizes. Our best model, retrieval-augmented LLaMA2-70B with 32K context window, outperforms GPT-3.5-turbo-16k and Davinci003 in terms of average score on seven long context tasks including question answering and query-based summarization. It also outperforms its non-retrieval LLaMA2-70B-32k baseline by a margin, while being much faster at generation. Our study provides general insights on the choice of retrieval-augmentation versus long context extension of LLM for practitioners.","sentences":["Extending the context window of large language models (LLMs) is getting popular recently, while the solution of augmenting LLMs with retrieval has existed for years.","The natural questions are: i) Retrieval-augmentation versus long context window, which one is better for downstream tasks?","ii) Can both methods be combined to get the best of both worlds?","In this work, we answer these questions by studying both solutions using two state-of-the-art pretrained LLMs, i.e., a proprietary 43B GPT and LLaMA2-70B.","Perhaps surprisingly, we find that LLM with 4K context window using simple retrieval-augmentation at generation can achieve comparable performance to finetuned LLM with 16K context window via positional interpolation on long context tasks, while taking much less computation.","More importantly, we demonstrate that retrieval can significantly improve the performance of LLMs regardless of their extended context window sizes.","Our best model, retrieval-augmented LLaMA2-70B with 32K context window, outperforms GPT-3.5-turbo-16k and Davinci003 in terms of average score on seven long context tasks including question answering and query-based summarization.","It also outperforms its non-retrieval LLaMA2-70B-32k baseline by a margin, while being much faster at generation.","Our study provides general insights on the choice of retrieval-augmentation versus long context extension of LLM for practitioners."],"url":"http://arxiv.org/abs/2310.03025v1"}
{"created":"2023-10-04 17:59:38","title":"Human-oriented Representation Learning for Robotic Manipulation","abstract":"Humans inherently possess generalizable visual representations that empower them to efficiently explore and interact with the environments in manipulation tasks. We advocate that such a representation automatically arises from simultaneously learning about multiple simple perceptual skills that are critical for everyday scenarios (e.g., hand detection, state estimate, etc.) and is better suited for learning robot manipulation policies compared to current state-of-the-art visual representations purely based on self-supervised objectives. We formalize this idea through the lens of human-oriented multi-task fine-tuning on top of pre-trained visual encoders, where each task is a perceptual skill tied to human-environment interactions. We introduce Task Fusion Decoder as a plug-and-play embedding translator that utilizes the underlying relationships among these perceptual skills to guide the representation learning towards encoding meaningful structure for what's important for all perceptual skills, ultimately empowering learning of downstream robotic manipulation tasks. Extensive experiments across a range of robotic tasks and embodiments, in both simulations and real-world environments, show that our Task Fusion Decoder consistently improves the representation of three state-of-the-art visual encoders including R3M, MVP, and EgoVLP, for downstream manipulation policy-learning. Project page: https://sites.google.com/view/human-oriented-robot-learning","sentences":["Humans inherently possess generalizable visual representations that empower them to efficiently explore and interact with the environments in manipulation tasks.","We advocate that such a representation automatically arises from simultaneously learning about multiple simple perceptual skills that are critical for everyday scenarios (e.g., hand detection, state estimate, etc.) and is better suited for learning robot manipulation policies compared to current state-of-the-art visual representations purely based on self-supervised objectives.","We formalize this idea through the lens of human-oriented multi-task fine-tuning on top of pre-trained visual encoders, where each task is a perceptual skill tied to human-environment interactions.","We introduce Task Fusion Decoder as a plug-and-play embedding translator that utilizes the underlying relationships among these perceptual skills to guide the representation learning towards encoding meaningful structure for what's important for all perceptual skills, ultimately empowering learning of downstream robotic manipulation tasks.","Extensive experiments across a range of robotic tasks and embodiments, in both simulations and real-world environments, show that our Task Fusion Decoder consistently improves the representation of three state-of-the-art visual encoders including R3M, MVP, and EgoVLP, for downstream manipulation policy-learning.","Project page: https://sites.google.com/view/human-oriented-robot-learning"],"url":"http://arxiv.org/abs/2310.03023v1"}
{"created":"2023-10-04 17:59:32","title":"Decision ConvFormer: Local Filtering in MetaFormer is Sufficient for Decision Making","abstract":"The recent success of Transformer in natural language processing has sparked its use in various domains. In offline reinforcement learning (RL), Decision Transformer (DT) is emerging as a promising model based on Transformer. However, we discovered that the attention module of DT is not appropriate to capture the inherent local dependence pattern in trajectories of RL modeled as a Markov decision process. To overcome the limitations of DT, we propose a novel action sequence predictor, named Decision ConvFormer (DC), based on the architecture of MetaFormer, which is a general structure to process multiple entities in parallel and understand the interrelationship among the multiple entities. DC employs local convolution filtering as the token mixer and can effectively capture the inherent local associations of the RL dataset. In extensive experiments, DC achieved state-of-the-art performance across various standard RL benchmarks while requiring fewer resources. Furthermore, we show that DC better understands the underlying meaning in data and exhibits enhanced generalization capability.","sentences":["The recent success of Transformer in natural language processing has sparked its use in various domains.","In offline reinforcement learning (RL), Decision Transformer (DT) is emerging as a promising model based on Transformer.","However, we discovered that the attention module of DT is not appropriate to capture the inherent local dependence pattern in trajectories of RL modeled as a Markov decision process.","To overcome the limitations of DT, we propose a novel action sequence predictor, named Decision ConvFormer (DC), based on the architecture of MetaFormer, which is a general structure to process multiple entities in parallel and understand the interrelationship among the multiple entities.","DC employs local convolution filtering as the token mixer and can effectively capture the inherent local associations of the RL dataset.","In extensive experiments, DC achieved state-of-the-art performance across various standard RL benchmarks while requiring fewer resources.","Furthermore, we show that DC better understands the underlying meaning in data and exhibits enhanced generalization capability."],"url":"http://arxiv.org/abs/2310.03022v1"}
{"created":"2023-10-04 17:58:57","title":"Consistent-1-to-3: Consistent Image to 3D View Synthesis via Geometry-aware Diffusion Models","abstract":"Zero-shot novel view synthesis (NVS) from a single image is an essential problem in 3D object understanding. While recent approaches that leverage pre-trained generative models can synthesize high-quality novel views from in-the-wild inputs, they still struggle to maintain 3D consistency across different views. In this paper, we present Consistent-1-to-3, which is a generative framework that significantly mitigate this issue. Specifically, we decompose the NVS task into two stages: (i) transforming observed regions to a novel view, and (ii) hallucinating unseen regions. We design a scene representation transformer and view-conditioned diffusion model for performing these two stages respectively. Inside the models, to enforce 3D consistency, we propose to employ epipolor-guided attention to incorporate geometry constraints, and multi-view attention to better aggregate multi-view information. Finally, we design a hierarchy generation paradigm to generate long sequences of consistent views, allowing a full 360 observation of the provided object image. Qualitative and quantitative evaluation over multiple datasets demonstrate the effectiveness of the proposed mechanisms against state-of-the-art approaches. Our project page is at https://jianglongye.com/consistent123/","sentences":["Zero-shot novel view synthesis (NVS) from a single image is an essential problem in 3D object understanding.","While recent approaches that leverage pre-trained generative models can synthesize high-quality novel views from in-the-wild inputs, they still struggle to maintain 3D consistency across different views.","In this paper, we present Consistent-1-to-3, which is a generative framework that significantly mitigate this issue.","Specifically, we decompose the NVS task into two stages: (i) transforming observed regions to a novel view, and (ii) hallucinating unseen regions.","We design a scene representation transformer and view-conditioned diffusion model for performing these two stages respectively.","Inside the models, to enforce 3D consistency, we propose to employ epipolor-guided attention to incorporate geometry constraints, and multi-view attention to better aggregate multi-view information.","Finally, we design a hierarchy generation paradigm to generate long sequences of consistent views, allowing a full 360 observation of the provided object image.","Qualitative and quantitative evaluation over multiple datasets demonstrate the effectiveness of the proposed mechanisms against state-of-the-art approaches.","Our project page is at https://jianglongye.com/consistent123/"],"url":"http://arxiv.org/abs/2310.03020v1"}
{"created":"2023-10-04 17:58:05","title":"Multimodal Question Answering for Unified Information Extraction","abstract":"Multimodal information extraction (MIE) aims to extract structured information from unstructured multimedia content. Due to the diversity of tasks and settings, most current MIE models are task-specific and data-intensive, which limits their generalization to real-world scenarios with diverse task requirements and limited labeled data. To address these issues, we propose a novel multimodal question answering (MQA) framework to unify three MIE tasks by reformulating them into a unified span extraction and multi-choice QA pipeline. Extensive experiments on six datasets show that: 1) Our MQA framework consistently and significantly improves the performances of various off-the-shelf large multimodal models (LMM) on MIE tasks, compared to vanilla prompting. 2) In the zero-shot setting, MQA outperforms previous state-of-the-art baselines by a large margin. In addition, the effectiveness of our framework can successfully transfer to the few-shot setting, enhancing LMMs on a scale of 10B parameters to be competitive or outperform much larger language models such as ChatGPT and GPT-4. Our MQA framework can serve as a general principle of utilizing LMMs to better solve MIE and potentially other downstream multimodal tasks.","sentences":["Multimodal information extraction (MIE) aims to extract structured information from unstructured multimedia content.","Due to the diversity of tasks and settings, most current MIE models are task-specific and data-intensive, which limits their generalization to real-world scenarios with diverse task requirements and limited labeled data.","To address these issues, we propose a novel multimodal question answering (MQA) framework to unify three MIE tasks by reformulating them into a unified span extraction and multi-choice QA pipeline.","Extensive experiments on six datasets show that: 1) Our MQA framework consistently and significantly improves the performances of various off-the-shelf large multimodal models (LMM) on MIE tasks, compared to vanilla prompting.","2) In the zero-shot setting, MQA outperforms previous state-of-the-art baselines by a large margin.","In addition, the effectiveness of our framework can successfully transfer to the few-shot setting, enhancing LMMs on a scale of 10B parameters to be competitive or outperform much larger language models such as ChatGPT and GPT-4.","Our MQA framework can serve as a general principle of utilizing LMMs to better solve MIE and potentially other downstream multimodal tasks."],"url":"http://arxiv.org/abs/2310.03017v1"}
{"created":"2023-10-04 17:57:33","title":"Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions","abstract":"In order to understand the in-context learning phenomenon, recent works have adopted a stylized experimental framework and demonstrated that Transformers can learn gradient-based learning algorithms for various classes of real-valued functions. However, the limitations of Transformers in implementing learning algorithms, and their ability to learn other forms of algorithms are not well understood. Additionally, the degree to which these capabilities are confined to attention-based models is unclear. Furthermore, it remains to be seen whether the insights derived from these stylized settings can be extrapolated to pretrained Large Language Models (LLMs). In this work, we take a step towards answering these questions by demonstrating the following: (a) On a test-bed with a variety of Boolean function classes, we find that Transformers can nearly match the optimal learning algorithm for 'simpler' tasks, while their performance deteriorates on more 'complex' tasks. Additionally, we find that certain attention-free models perform (almost) identically to Transformers on a range of tasks. (b) When provided a teaching sequence, i.e. a set of examples that uniquely identifies a function in a class, we show that Transformers learn more sample-efficiently. Interestingly, our results show that Transformers can learn to implement two distinct algorithms to solve a single task, and can adaptively select the more sample-efficient algorithm depending on the sequence of in-context examples. (c) Lastly, we show that extant LLMs, e.g. LLaMA-2, GPT-4, can compete with nearest-neighbor baselines on prediction tasks that are guaranteed to not be in their training set.","sentences":["In order to understand the in-context learning phenomenon, recent works have adopted a stylized experimental framework and demonstrated that Transformers can learn gradient-based learning algorithms for various classes of real-valued functions.","However, the limitations of Transformers in implementing learning algorithms, and their ability to learn other forms of algorithms are not well understood.","Additionally, the degree to which these capabilities are confined to attention-based models is unclear.","Furthermore, it remains to be seen whether the insights derived from these stylized settings can be extrapolated to pretrained Large Language Models (LLMs).","In this work, we take a step towards answering these questions by demonstrating the following: (a) On a test-bed with a variety of Boolean function classes, we find that Transformers can nearly match the optimal learning algorithm for 'simpler' tasks, while their performance deteriorates on more 'complex' tasks.","Additionally, we find that certain attention-free models perform (almost) identically to Transformers on a range of tasks.","(b) When provided a teaching sequence, i.e. a set of examples that uniquely identifies a function in a class, we show that Transformers learn more sample-efficiently.","Interestingly, our results show that Transformers can learn to implement two distinct algorithms to solve a single task, and can adaptively select the more sample-efficient algorithm depending on the sequence of in-context examples.","(c) Lastly, we show that extant LLMs, e.g. LLaMA-2, GPT-4, can compete with nearest-neighbor baselines on prediction tasks that are guaranteed to not be in their training set."],"url":"http://arxiv.org/abs/2310.03016v1"}
{"created":"2023-10-04 17:57:07","title":"Efficient-3DiM: Learning a Generalizable Single-image Novel-view Synthesizer in One Day","abstract":"The task of novel view synthesis aims to generate unseen perspectives of an object or scene from a limited set of input images. Nevertheless, synthesizing novel views from a single image still remains a significant challenge in the realm of computer vision. Previous approaches tackle this problem by adopting mesh prediction, multi-plain image construction, or more advanced techniques such as neural radiance fields. Recently, a pre-trained diffusion model that is specifically designed for 2D image synthesis has demonstrated its capability in producing photorealistic novel views, if sufficiently optimized on a 3D finetuning task. Although the fidelity and generalizability are greatly improved, training such a powerful diffusion model requires a vast volume of training data and model parameters, resulting in a notoriously long time and high computational costs. To tackle this issue, we propose Efficient-3DiM, a simple but effective framework to learn a single-image novel-view synthesizer. Motivated by our in-depth analysis of the inference process of diffusion models, we propose several pragmatic strategies to reduce the training overhead to a manageable scale, including a crafted timestep sampling strategy, a superior 3D feature extractor, and an enhanced training scheme. When combined, our framework is able to reduce the total training time from 10 days to less than 1 day, significantly accelerating the training process under the same computational platform (one instance with 8 Nvidia A100 GPUs). Comprehensive experiments are conducted to demonstrate the efficiency and generalizability of our proposed method.","sentences":["The task of novel view synthesis aims to generate unseen perspectives of an object or scene from a limited set of input images.","Nevertheless, synthesizing novel views from a single image still remains a significant challenge in the realm of computer vision.","Previous approaches tackle this problem by adopting mesh prediction, multi-plain image construction, or more advanced techniques such as neural radiance fields.","Recently, a pre-trained diffusion model that is specifically designed for 2D image synthesis has demonstrated its capability in producing photorealistic novel views, if sufficiently optimized on a 3D finetuning task.","Although the fidelity and generalizability are greatly improved, training such a powerful diffusion model requires a vast volume of training data and model parameters, resulting in a notoriously long time and high computational costs.","To tackle this issue, we propose Efficient-3DiM, a simple but effective framework to learn a single-image novel-view synthesizer.","Motivated by our in-depth analysis of the inference process of diffusion models, we propose several pragmatic strategies to reduce the training overhead to a manageable scale, including a crafted timestep sampling strategy, a superior 3D feature extractor, and an enhanced training scheme.","When combined, our framework is able to reduce the total training time from 10 days to less than 1 day, significantly accelerating the training process under the same computational platform (one instance with 8 Nvidia A100 GPUs).","Comprehensive experiments are conducted to demonstrate the efficiency and generalizability of our proposed method."],"url":"http://arxiv.org/abs/2310.03015v1"}
{"created":"2023-10-04 17:56:41","title":"SemiReward: A General Reward Model for Semi-supervised Learning","abstract":"Semi-supervised learning (SSL) has witnessed great progress with various improvements in the self-training framework with pseudo labeling. The main challenge is how to distinguish high-quality pseudo labels against the confirmation bias. However, existing pseudo-label selection strategies are limited to pre-defined schemes or complex hand-crafted policies specially designed for classification, failing to achieve high-quality labels, fast convergence, and task versatility simultaneously. To these ends, we propose a Semi-supervised Reward framework (SemiReward) that predicts reward scores to evaluate and filter out high-quality pseudo labels, which is pluggable to mainstream SSL methods in wide task types and scenarios. To mitigate confirmation bias, SemiReward is trained online in two stages with a generator model and subsampling strategy. With classification and regression tasks on 13 standard SSL benchmarks of three modalities, extensive experiments verify that SemiReward achieves significant performance gains and faster convergence speeds upon Pseudo Label, FlexMatch, and Free/SoftMatch.","sentences":["Semi-supervised learning (SSL) has witnessed great progress with various improvements in the self-training framework with pseudo labeling.","The main challenge is how to distinguish high-quality pseudo labels against the confirmation bias.","However, existing pseudo-label selection strategies are limited to pre-defined schemes or complex hand-crafted policies specially designed for classification, failing to achieve high-quality labels, fast convergence, and task versatility simultaneously.","To these ends, we propose a Semi-supervised Reward framework (SemiReward) that predicts reward scores to evaluate and filter out high-quality pseudo labels, which is pluggable to mainstream SSL methods in wide task types and scenarios.","To mitigate confirmation bias, SemiReward is trained online in two stages with a generator model and subsampling strategy.","With classification and regression tasks on 13 standard SSL benchmarks of three modalities, extensive experiments verify that SemiReward achieves significant performance gains and faster convergence speeds upon Pseudo Label, FlexMatch, and Free/SoftMatch."],"url":"http://arxiv.org/abs/2310.03013v1"}
{"created":"2023-10-04 17:53:53","title":"High-dimensional SGD aligns with emerging outlier eigenspaces","abstract":"We rigorously study the joint evolution of training dynamics via stochastic gradient descent (SGD) and the spectra of empirical Hessian and gradient matrices. We prove that in two canonical classification tasks for multi-class high-dimensional mixtures and either 1 or 2-layer neural networks, the SGD trajectory rapidly aligns with emerging low-rank outlier eigenspaces of the Hessian and gradient matrices. Moreover, in multi-layer settings this alignment occurs per layer, with the final layer's outlier eigenspace evolving over the course of training, and exhibiting rank deficiency when the SGD converges to sub-optimal classifiers. This establishes some of the rich predictions that have arisen from extensive numerical studies in the last decade about the spectra of Hessian and information matrices over the course of training in overparametrized networks.","sentences":["We rigorously study the joint evolution of training dynamics via stochastic gradient descent (SGD) and the spectra of empirical Hessian and gradient matrices.","We prove that in two canonical classification tasks for multi-class high-dimensional mixtures and either 1 or 2-layer neural networks, the SGD trajectory rapidly aligns with emerging low-rank outlier eigenspaces of the Hessian and gradient matrices.","Moreover, in multi-layer settings this alignment occurs per layer, with the final layer's outlier eigenspace evolving over the course of training, and exhibiting rank deficiency when the SGD converges to sub-optimal classifiers.","This establishes some of the rich predictions that have arisen from extensive numerical studies in the last decade about the spectra of Hessian and information matrices over the course of training in overparametrized networks."],"url":"http://arxiv.org/abs/2310.03010v1"}
{"created":"2023-10-04 17:51:02","title":"Towards Domain-Specific Features Disentanglement for Domain Generalization","abstract":"Distributional shift between domains poses great challenges to modern machine learning algorithms. The domain generalization (DG) signifies a popular line targeting this issue, where these methods intend to uncover universal patterns across disparate distributions. Noted, the crucial challenge behind DG is the existence of irrelevant domain features, and most prior works overlook this information. Motivated by this, we propose a novel contrastive-based disentanglement method CDDG, to effectively utilize the disentangled features to exploit the over-looked domain-specific features, and thus facilitating the extraction of the desired cross-domain category features for DG tasks. Specifically, CDDG learns to decouple inherent mutually exclusive features by leveraging them in the latent space, thus making the learning discriminative. Extensive experiments conducted on various benchmark datasets demonstrate the superiority of our method compared to other state-of-the-art approaches. Furthermore, visualization evaluations confirm the potential of our method in achieving effective feature disentanglement.","sentences":["Distributional shift between domains poses great challenges to modern machine learning algorithms.","The domain generalization (DG) signifies a popular line targeting this issue, where these methods intend to uncover universal patterns across disparate distributions.","Noted, the crucial challenge behind DG is the existence of irrelevant domain features, and most prior works overlook this information.","Motivated by this, we propose a novel contrastive-based disentanglement method CDDG, to effectively utilize the disentangled features to exploit the over-looked domain-specific features, and thus facilitating the extraction of the desired cross-domain category features for DG tasks.","Specifically, CDDG learns to decouple inherent mutually exclusive features by leveraging them in the latent space, thus making the learning discriminative.","Extensive experiments conducted on various benchmark datasets demonstrate the superiority of our method compared to other state-of-the-art approaches.","Furthermore, visualization evaluations confirm the potential of our method in achieving effective feature disentanglement."],"url":"http://arxiv.org/abs/2310.03007v1"}
{"created":"2023-10-04 17:49:48","title":"COOLer: Class-Incremental Learning for Appearance-Based Multiple Object Tracking","abstract":"Continual learning allows a model to learn multiple tasks sequentially while retaining the old knowledge without the training data of the preceding tasks. This paper extends the scope of continual learning research to class-incremental learning for \\ac{mot}, which is desirable to accommodate the continuously evolving needs of autonomous systems. Previous solutions for continual learning of object detectors do not address the data association stage of appearance-based trackers, leading to catastrophic forgetting of previous classes' re-identification features. We introduce COOLer, a COntrastive- and cOntinual-Learning-based tracker, which incrementally learns to track new categories while preserving past knowledge by training on a combination of currently available ground truth labels and pseudo-labels generated by the past tracker. To further exacerbate the disentanglement of instance representations, we introduce a novel contrastive class-incremental instance representation learning technique. Finally, we propose a practical evaluation protocol for continual learning for MOT and conduct experiments on the \\bdd and \\shift datasets. Experimental results demonstrate that COOLer continually learns while effectively addressing catastrophic forgetting of both tracking and detection. The code is available at \\url{https://github.com/BoSmallEar/COOLer}.","sentences":["Continual learning allows a model to learn multiple tasks sequentially while retaining the old knowledge without the training data of the preceding tasks.","This paper extends the scope of continual learning research to class-incremental learning for \\ac{mot}, which is desirable to accommodate the continuously evolving needs of autonomous systems.","Previous solutions for continual learning of object detectors do not address the data association stage of appearance-based trackers, leading to catastrophic forgetting of previous classes' re-identification features.","We introduce COOLer, a COntrastive- and cOntinual-Learning-based tracker, which incrementally learns to track new categories while preserving past knowledge by training on a combination of currently available ground truth labels and pseudo-labels generated by the past tracker.","To further exacerbate the disentanglement of instance representations, we introduce a novel contrastive class-incremental instance representation learning technique.","Finally, we propose a practical evaluation protocol for continual learning for MOT and conduct experiments on the \\bdd and \\shift datasets.","Experimental results demonstrate that COOLer continually learns while effectively addressing catastrophic forgetting of both tracking and detection.","The code is available at \\url{https://github.com/BoSmallEar/COOLer}."],"url":"http://arxiv.org/abs/2310.03006v1"}
{"created":"2023-10-04 17:48:23","title":"Reversing Deep Face Embeddings with Probable Privacy Protection","abstract":"Generally, privacy-enhancing face recognition systems are designed to offer permanent protection of face embeddings. Recently, so-called soft-biometric privacy-enhancement approaches have been introduced with the aim of canceling soft-biometric attributes. These methods limit the amount of soft-biometric information (gender or skin-colour) that can be inferred from face embeddings. Previous work has underlined the need for research into rigorous evaluations and standardised evaluation protocols when assessing privacy protection capabilities. Motivated by this fact, this paper explores to what extent the non-invertibility requirement can be met by methods that claim to provide soft-biometric privacy protection. Additionally, a detailed vulnerability assessment of state-of-the-art face embedding extractors is analysed in terms of the transformation complexity used for privacy protection. In this context, a well-known state-of-the-art face image reconstruction approach has been evaluated on protected face embeddings to break soft biometric privacy protection. Experimental results show that biometric privacy-enhanced face embeddings can be reconstructed with an accuracy of up to approximately 98%, depending on the complexity of the protection algorithm.","sentences":["Generally, privacy-enhancing face recognition systems are designed to offer permanent protection of face embeddings.","Recently, so-called soft-biometric privacy-enhancement approaches have been introduced with the aim of canceling soft-biometric attributes.","These methods limit the amount of soft-biometric information (gender or skin-colour) that can be inferred from face embeddings.","Previous work has underlined the need for research into rigorous evaluations and standardised evaluation protocols when assessing privacy protection capabilities.","Motivated by this fact, this paper explores to what extent the non-invertibility requirement can be met by methods that claim to provide soft-biometric privacy protection.","Additionally, a detailed vulnerability assessment of state-of-the-art face embedding extractors is analysed in terms of the transformation complexity used for privacy protection.","In this context, a well-known state-of-the-art face image reconstruction approach has been evaluated on protected face embeddings to break soft biometric privacy protection.","Experimental results show that biometric privacy-enhanced face embeddings can be reconstructed with an accuracy of up to approximately 98%, depending on the complexity of the protection algorithm."],"url":"http://arxiv.org/abs/2310.03005v1"}
{"created":"2023-10-04 17:45:14","title":"Soft Convex Quantization: Revisiting Vector Quantization with Convex Optimization","abstract":"Vector Quantization (VQ) is a well-known technique in deep learning for extracting informative discrete latent representations. VQ-embedded models have shown impressive results in a range of applications including image and speech generation. VQ operates as a parametric K-means algorithm that quantizes inputs using a single codebook vector in the forward pass. While powerful, this technique faces practical challenges including codebook collapse, non-differentiability and lossy compression. To mitigate the aforementioned issues, we propose Soft Convex Quantization (SCQ) as a direct substitute for VQ. SCQ works like a differentiable convex optimization (DCO) layer: in the forward pass, we solve for the optimal convex combination of codebook vectors that quantize the inputs. In the backward pass, we leverage differentiability through the optimality conditions of the forward solution. We then introduce a scalable relaxation of the SCQ optimization and demonstrate its efficacy on the CIFAR-10, GTSRB and LSUN datasets. We train powerful SCQ autoencoder models that significantly outperform matched VQ-based architectures, observing an order of magnitude better image reconstruction and codebook usage with comparable quantization runtime.","sentences":["Vector Quantization (VQ) is a well-known technique in deep learning for extracting informative discrete latent representations.","VQ-embedded models have shown impressive results in a range of applications including image and speech generation.","VQ operates as a parametric K-means algorithm that quantizes inputs using a single codebook vector in the forward pass.","While powerful, this technique faces practical challenges including codebook collapse, non-differentiability and lossy compression.","To mitigate the aforementioned issues, we propose Soft Convex Quantization (SCQ) as a direct substitute for VQ.","SCQ works like a differentiable convex optimization (DCO) layer: in the forward pass, we solve for the optimal convex combination of codebook vectors that quantize the inputs.","In the backward pass, we leverage differentiability through the optimality conditions of the forward solution.","We then introduce a scalable relaxation of the SCQ optimization and demonstrate its efficacy on the CIFAR-10, GTSRB and LSUN datasets.","We train powerful SCQ autoencoder models that significantly outperform matched VQ-based architectures, observing an order of magnitude better image reconstruction and codebook usage with comparable quantization runtime."],"url":"http://arxiv.org/abs/2310.03004v1"}
{"created":"2023-10-04 17:41:59","title":"From Words to Watts: Benchmarking the Energy Costs of Large Language Model Inference","abstract":"Large language models (LLMs) have exploded in popularity due to their new generative capabilities that go far beyond prior state-of-the-art. These technologies are increasingly being leveraged in various domains such as law, finance, and medicine. However, these models carry significant computational challenges, especially the compute and energy costs required for inference. Inference energy costs already receive less attention than the energy costs of training LLMs -- despite how often these large models are called on to conduct inference in reality (e.g., ChatGPT). As these state-of-the-art LLMs see increasing usage and deployment in various domains, a better understanding of their resource utilization is crucial for cost-savings, scaling performance, efficient hardware usage, and optimal inference strategies.   In this paper, we describe experiments conducted to study the computational and energy utilization of inference with LLMs. We benchmark and conduct a preliminary analysis of the inference performance and inference energy costs of different sizes of LLaMA -- a recent state-of-the-art LLM -- developed by Meta AI on two generations of popular GPUs (NVIDIA V100 \\& A100) and two datasets (Alpaca and GSM8K) to reflect the diverse set of tasks/benchmarks for LLMs in research and practice. We present the results of multi-node, multi-GPU inference using model sharding across up to 32 GPUs. To our knowledge, our work is the one of the first to study LLM inference performance from the perspective of computational and energy resources at this scale.","sentences":["Large language models (LLMs) have exploded in popularity due to their new generative capabilities that go far beyond prior state-of-the-art.","These technologies are increasingly being leveraged in various domains such as law, finance, and medicine.","However, these models carry significant computational challenges, especially the compute and energy costs required for inference.","Inference energy costs already receive less attention than the energy costs of training LLMs -- despite how often these large models are called on to conduct inference in reality (e.g., ChatGPT).","As these state-of-the-art LLMs see increasing usage and deployment in various domains, a better understanding of their resource utilization is crucial for cost-savings, scaling performance, efficient hardware usage, and optimal inference strategies.   ","In this paper, we describe experiments conducted to study the computational and energy utilization of inference with LLMs.","We benchmark and conduct a preliminary analysis of the inference performance and inference energy costs of different sizes of LLaMA -- a recent state-of-the-art LLM -- developed by Meta AI on two generations of popular GPUs (NVIDIA V100 \\& A100) and two datasets (Alpaca and GSM8K) to reflect the diverse set of tasks/benchmarks for LLMs in research and practice.","We present the results of multi-node, multi-GPU inference using model sharding across up to 32 GPUs.","To our knowledge, our work is the one of the first to study LLM inference performance from the perspective of computational and energy resources at this scale."],"url":"http://arxiv.org/abs/2310.03003v1"}
{"created":"2023-10-04 17:40:59","title":"No Forking Way: Detecting Cloning Attacks on Intel SGX Applications","abstract":"Forking attacks against TEEs like Intel SGX can be carried out either by rolling back the application to a previous state, or by cloning the application and by partitioning its inputs across the cloned instances. Current solutions to forking attacks require Trusted Third Parties (TTP) that are hard to find in real-world deployments. In the absence of a TTP, many TEE applications rely on monotonic counters to mitigate forking attacks based on rollbacks; however, they have no protection mechanism against forking attack based on cloning. In this paper, we analyze 72 SGX applications and show that approximately 20% of those are vulnerable to forking attacks based on cloning - including those that rely on monotonic counters. To address this problem, we present CloneBuster, the first practical clone-detection mechanism for Intel SGX that does not rely on a TTP and, as such, can be used directly to protect existing applications. CloneBuster allows enclaves to (self-) detect whether another enclave with the same binary is running on the same platform. To do so, CloneBuster relies on a cache-based covert channel for enclaves to signal their presence to (and detect the presence of) clones on the same machine. We show that CloneBuster is robust despite a malicious OS, only incurs a marginal impact on the application performance, and adds approximately 800 LoC to the TCB. When used in conjunction with monotonic counters, CloneBuster allows applications to benefit from a comprehensive protection against forking attacks.","sentences":["Forking attacks against TEEs like Intel SGX can be carried out either by rolling back the application to a previous state, or by cloning the application and by partitioning its inputs across the cloned instances.","Current solutions to forking attacks require Trusted Third Parties (TTP) that are hard to find in real-world deployments.","In the absence of a TTP, many TEE applications rely on monotonic counters to mitigate forking attacks based on rollbacks; however, they have no protection mechanism against forking attack based on cloning.","In this paper, we analyze 72 SGX applications and show that approximately 20% of those are vulnerable to forking attacks based on cloning - including those that rely on monotonic counters.","To address this problem, we present CloneBuster, the first practical clone-detection mechanism for Intel SGX that does not rely on a TTP and, as such, can be used directly to protect existing applications.","CloneBuster allows enclaves to (self-) detect whether another enclave with the same binary is running on the same platform.","To do so, CloneBuster relies on a cache-based covert channel for enclaves to signal their presence to (and detect the presence of) clones on the same machine.","We show that CloneBuster is robust despite a malicious OS, only incurs a marginal impact on the application performance, and adds approximately 800 LoC to the TCB.","When used in conjunction with monotonic counters, CloneBuster allows applications to benefit from a comprehensive protection against forking attacks."],"url":"http://arxiv.org/abs/2310.03002v1"}
{"created":"2023-10-04 17:40:46","title":"Learning characteristic parameters and dynamics of centrifugal pumps under multi-phase flow using physics-informed neural networks","abstract":"Electrical submersible pumps (ESP) are the second most used artificial lifting equipment in the oil and gas industry due to their high flow rates and boost pressures. They often have to handle multiphase flows, which usually contain a mixture of hydrocarbons, water, and/or sediments. Given these circumstances, emulsions are commonly formed. It is a liquid-liquid flow composed of two immiscible fluids whose effective viscosity and density differ from the single phase separately. In this context, accurate modeling of ESP systems is crucial for optimizing oil production and implementing control strategies. However, real-time and direct measurement of fluid and system characteristics is often impractical due to time constraints and economy. Hence, indirect methods are generally considered to estimate the system parameters. In this paper, we formulate a machine learning model based on Physics-Informed Neural Networks (PINNs) to estimate crucial system parameters. In order to study the efficacy of the proposed PINN model, we conduct computational studies using not only simulated but also experimental data for different water-oil ratios. We evaluate the state variable's dynamics and unknown parameters for various combinations when only intake and discharge pressure measurements are available. We also study structural and practical identifiability analyses based on commonly available pressure measurements. The PINN model could reduce the requirement of expensive field laboratory tests used to estimate fluid properties.","sentences":["Electrical submersible pumps (ESP) are the second most used artificial lifting equipment in the oil and gas industry due to their high flow rates and boost pressures.","They often have to handle multiphase flows, which usually contain a mixture of hydrocarbons, water, and/or sediments.","Given these circumstances, emulsions are commonly formed.","It is a liquid-liquid flow composed of two immiscible fluids whose effective viscosity and density differ from the single phase separately.","In this context, accurate modeling of ESP systems is crucial for optimizing oil production and implementing control strategies.","However, real-time and direct measurement of fluid and system characteristics is often impractical due to time constraints and economy.","Hence, indirect methods are generally considered to estimate the system parameters.","In this paper, we formulate a machine learning model based on Physics-Informed Neural Networks (PINNs) to estimate crucial system parameters.","In order to study the efficacy of the proposed PINN model, we conduct computational studies using not only simulated but also experimental data for different water-oil ratios.","We evaluate the state variable's dynamics and unknown parameters for various combinations when only intake and discharge pressure measurements are available.","We also study structural and practical identifiability analyses based on commonly available pressure measurements.","The PINN model could reduce the requirement of expensive field laboratory tests used to estimate fluid properties."],"url":"http://arxiv.org/abs/2310.03001v1"}
{"created":"2023-10-04 17:34:00","title":"ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models","abstract":"Large Vision-Language Models (LVLMs) can understand the world comprehensively by integrating rich information from different modalities, achieving remarkable performance improvements on various multimodal downstream tasks. However, deploying LVLMs is often problematic due to their massive computational/energy costs and carbon consumption. Such issues make it infeasible to adopt conventional iterative global pruning, which is costly due to computing the Hessian matrix of the entire large model for sparsification. Alternatively, several studies have recently proposed layer-wise pruning approaches to avoid the expensive computation of global pruning and efficiently compress model weights according to their importance within a layer. However, these methods often suffer from suboptimal model compression due to their lack of a global perspective. To address this limitation in recent efficient pruning methods for large models, we propose Efficient Coarse-to-Fine Layer-Wise Pruning (ECoFLaP), a two-stage coarse-to-fine weight pruning approach for LVLMs. We first determine the sparsity ratios of different layers or blocks by leveraging the global importance score, which is efficiently computed based on the zeroth-order approximation of the global model gradients. Then, the multimodal model performs local layer-wise unstructured weight pruning based on globally-informed sparsity ratios. We validate our proposed method across various multimodal and unimodal models and datasets, demonstrating significant performance improvements over prevalent pruning techniques in the high-sparsity regime.","sentences":["Large Vision-Language Models (LVLMs) can understand the world comprehensively by integrating rich information from different modalities, achieving remarkable performance improvements on various multimodal downstream tasks.","However, deploying LVLMs is often problematic due to their massive computational/energy costs and carbon consumption.","Such issues make it infeasible to adopt conventional iterative global pruning, which is costly due to computing the Hessian matrix of the entire large model for sparsification.","Alternatively, several studies have recently proposed layer-wise pruning approaches to avoid the expensive computation of global pruning and efficiently compress model weights according to their importance within a layer.","However, these methods often suffer from suboptimal model compression due to their lack of a global perspective.","To address this limitation in recent efficient pruning methods for large models, we propose Efficient Coarse-to-Fine Layer-Wise Pruning (ECoFLaP), a two-stage coarse-to-fine weight pruning approach for LVLMs.","We first determine the sparsity ratios of different layers or blocks by leveraging the global importance score, which is efficiently computed based on the zeroth-order approximation of the global model gradients.","Then, the multimodal model performs local layer-wise unstructured weight pruning based on globally-informed sparsity ratios.","We validate our proposed method across various multimodal and unimodal models and datasets, demonstrating significant performance improvements over prevalent pruning techniques in the high-sparsity regime."],"url":"http://arxiv.org/abs/2310.02998v1"}
{"created":"2023-10-04 17:32:32","title":"Optimizing Key-Selection for Face-based One-Time Biometrics via Morphing","abstract":"Nowadays, facial recognition systems are still vulnerable to adversarial attacks. These attacks vary from simple perturbations of the input image to modifying the parameters of the recognition model to impersonate an authorised subject. So-called privacy-enhancing facial recognition systems have been mostly developed to provide protection of stored biometric reference data, i.e. templates. In the literature, privacy-enhancing facial recognition approaches have focused solely on conventional security threats at the template level, ignoring the growing concern related to adversarial attacks. Up to now, few works have provided mechanisms to protect face recognition against adversarial attacks while maintaining high security at the template level. In this paper, we propose different key selection strategies to improve the security of a competitive cancelable scheme operating at the signal level. Experimental results show that certain strategies based on signal-level key selection can lead to complete blocking of the adversarial attack based on an iterative optimization for the most secure threshold, while for the most practical threshold, the attack success chance can be decreased to approximately 5.0%.","sentences":["Nowadays, facial recognition systems are still vulnerable to adversarial attacks.","These attacks vary from simple perturbations of the input image to modifying the parameters of the recognition model to impersonate an authorised subject.","So-called privacy-enhancing facial recognition systems have been mostly developed to provide protection of stored biometric reference data, i.e. templates.","In the literature, privacy-enhancing facial recognition approaches have focused solely on conventional security threats at the template level, ignoring the growing concern related to adversarial attacks.","Up to now, few works have provided mechanisms to protect face recognition against adversarial attacks while maintaining high security at the template level.","In this paper, we propose different key selection strategies to improve the security of a competitive cancelable scheme operating at the signal level.","Experimental results show that certain strategies based on signal-level key selection can lead to complete blocking of the adversarial attack based on an iterative optimization for the most secure threshold, while for the most practical threshold, the attack success chance can be decreased to approximately 5.0%."],"url":"http://arxiv.org/abs/2310.02997v1"}
{"created":"2023-10-04 17:30:50","title":"IBCL: Zero-shot Model Generation for Task Trade-offs in Continual Learning","abstract":"Like generic multi-task learning, continual learning has the nature of multi-objective optimization, and therefore faces a trade-off between the performance of different tasks. That is, to optimize for the current task distribution, it may need to compromise performance on some previous tasks. This means that there exist multiple models that are Pareto-optimal at different times, each addressing a distinct task performance trade-off. Researchers have discussed how to train particular models to address specific trade-off preferences. However, existing algorithms require training overheads proportional to the number of preferences -- a large burden when there are multiple, possibly infinitely many, preferences. As a response, we propose Imprecise Bayesian Continual Learning (IBCL). Upon a new task, IBCL (1) updates a knowledge base in the form of a convex hull of model parameter distributions and (2) obtains particular models to address task trade-off preferences with zero-shot. That is, IBCL does not require any additional training overhead to generate preference-addressing models from its knowledge base. We show that models obtained by IBCL have guarantees in identifying the Pareto optimal parameters. Moreover, experiments on standard image classification and NLP tasks support this guarantee. Statistically, IBCL improves average per-task accuracy by at most 23\\% and peak per-task accuracy by at most 15\\% with respect to the baseline methods, with steadily near-zero or positive backward transfer. Most importantly, IBCL significantly reduces the training overhead from training 1 model per preference to at most 3 models for all preferences.","sentences":["Like generic multi-task learning, continual learning has the nature of multi-objective optimization, and therefore faces a trade-off between the performance of different tasks.","That is, to optimize for the current task distribution, it may need to compromise performance on some previous tasks.","This means that there exist multiple models that are Pareto-optimal at different times, each addressing a distinct task performance trade-off.","Researchers have discussed how to train particular models to address specific trade-off preferences.","However, existing algorithms require training overheads proportional to the number of preferences -- a large burden when there are multiple, possibly infinitely many, preferences.","As a response, we propose Imprecise Bayesian Continual Learning (IBCL).","Upon a new task, IBCL (1) updates a knowledge base in the form of a convex hull of model parameter distributions and (2) obtains particular models to address task trade-off preferences with zero-shot.","That is, IBCL does not require any additional training overhead to generate preference-addressing models from its knowledge base.","We show that models obtained by IBCL have guarantees in identifying the Pareto optimal parameters.","Moreover, experiments on standard image classification and NLP tasks support this guarantee.","Statistically, IBCL improves average per-task accuracy by at most 23\\% and peak per-task accuracy by at most 15\\% with respect to the baseline methods, with steadily near-zero or positive backward transfer.","Most importantly, IBCL significantly reduces the training overhead from training 1 model per preference to at most 3 models for all preferences."],"url":"http://arxiv.org/abs/2310.02995v1"}
{"created":"2023-10-04 17:29:19","title":"Multiple Physics Pretraining for Physical Surrogate Models","abstract":"We introduce multiple physics pretraining (MPP), an autoregressive task-agnostic pretraining approach for physical surrogate modeling. MPP involves training large surrogate models to predict the dynamics of multiple heterogeneous physical systems simultaneously by learning features that are broadly useful across diverse physical tasks. In order to learn effectively in this setting, we introduce a shared embedding and normalization strategy that projects the fields of multiple systems into a single shared embedding space. We validate the efficacy of our approach on both pretraining and downstream tasks over a broad fluid mechanics-oriented benchmark. We show that a single MPP-pretrained transformer is able to match or outperform task-specific baselines on all pretraining sub-tasks without the need for finetuning. For downstream tasks, we demonstrate that finetuning MPP-trained models results in more accurate predictions across multiple time-steps on new physics compared to training from scratch or finetuning pretrained video foundation models. We open-source our code and model weights trained at multiple scales for reproducibility and community experimentation.","sentences":["We introduce multiple physics pretraining (MPP), an autoregressive task-agnostic pretraining approach for physical surrogate modeling.","MPP involves training large surrogate models to predict the dynamics of multiple heterogeneous physical systems simultaneously by learning features that are broadly useful across diverse physical tasks.","In order to learn effectively in this setting, we introduce a shared embedding and normalization strategy that projects the fields of multiple systems into a single shared embedding space.","We validate the efficacy of our approach on both pretraining and downstream tasks over a broad fluid mechanics-oriented benchmark.","We show that a single MPP-pretrained transformer is able to match or outperform task-specific baselines on all pretraining sub-tasks without the need for finetuning.","For downstream tasks, we demonstrate that finetuning MPP-trained models results in more accurate predictions across multiple time-steps on new physics compared to training from scratch or finetuning pretrained video foundation models.","We open-source our code and model weights trained at multiple scales for reproducibility and community experimentation."],"url":"http://arxiv.org/abs/2310.02994v1"}
{"created":"2023-10-04 17:28:58","title":"Finding coherent node groups in directed graphs","abstract":"Summarizing a large graph by grouping the nodes into clusters is a standard technique for studying the given network. Traditionally, the order of the discovered groups does not matter. However, there are applications where, for example, given a directed graph, we would like to find coherent groups while minimizing the backward cross edges. More formally, in this paper, we study a problem where we are given a directed network and are asked to partition the graph into a sequence of coherent groups while attempting to conform to the cross edges. We assume that nodes in the network have features, and we measure the group coherence by comparing these features. Furthermore, we incorporate the cross edges by penalizing the forward cross edges and backward cross edges with different weights. If the weights are set to 0, then the problem is equivalent to clustering. However, if we penalize the backward edges significantly more, then the order of discovered groups matters, and we can view our problem as a generalization of a classic segmentation problem. To solve the algorithm we consider a common iterative approach where we solve the groups given the centroids, and then find the centroids given the groups. We show that - unlike in clustering - the first subproblem is NP-hard. However, we show that if the underlying graph is a tree we can solve the subproblem with dynamic programming. In addition, if the number of groups is 2, we can solve the subproblem with a minimum cut. For the more general case, we propose a heuristic where we optimize each pair of groups separately while keeping the remaining groups intact. We also propose a greedy search where nodes are moved between the groups while optimizing the overall loss. We demonstrate with our experiments that the algorithms are practical and yield interpretable results.","sentences":["Summarizing a large graph by grouping the nodes into clusters is a standard technique for studying the given network.","Traditionally, the order of the discovered groups does not matter.","However, there are applications where, for example, given a directed graph, we would like to find coherent groups while minimizing the backward cross edges.","More formally, in this paper, we study a problem where we are given a directed network and are asked to partition the graph into a sequence of coherent groups while attempting to conform to the cross edges.","We assume that nodes in the network have features, and we measure the group coherence by comparing these features.","Furthermore, we incorporate the cross edges by penalizing the forward cross edges and backward cross edges with different weights.","If the weights are set to 0, then the problem is equivalent to clustering.","However, if we penalize the backward edges significantly more, then the order of discovered groups matters, and we can view our problem as a generalization of a classic segmentation problem.","To solve the algorithm we consider a common iterative approach where we solve the groups given the centroids, and then find the centroids given the groups.","We show that - unlike in clustering - the first subproblem is NP-hard.","However, we show that if the underlying graph is a tree we can solve the subproblem with dynamic programming.","In addition, if the number of groups is 2, we can solve the subproblem with a minimum cut.","For the more general case, we propose a heuristic where we optimize each pair of groups separately while keeping the remaining groups intact.","We also propose a greedy search where nodes are moved between the groups while optimizing the overall loss.","We demonstrate with our experiments that the algorithms are practical and yield interpretable results."],"url":"http://arxiv.org/abs/2310.02993v1"}
{"created":"2023-10-04 17:28:44","title":"Kosmos-G: Generating Images in Context with Multimodal Large Language Models","abstract":"Recent advancements in text-to-image (T2I) and vision-language-to-image (VL2I) generation have made significant strides. However, the generation from generalized vision-language inputs, especially involving multiple images, remains under-explored. This paper presents Kosmos-G, a model that leverages the advanced perception capabilities of Multimodal Large Language Models (MLLMs) to tackle the aforementioned challenge. Our approach aligns the output space of MLLM with CLIP using the textual modality as an anchor and performs compositional instruction tuning on curated data. Kosmos-G demonstrates a unique capability of zero-shot multi-entity subject-driven generation. Notably, the score distillation instruction tuning requires no modifications to the image decoder. This allows for a seamless substitution of CLIP and effortless integration with a myriad of U-Net techniques ranging from fine-grained controls to personalized image decoder variants. We posit Kosmos-G as an initial attempt towards the goal of \"image as a foreign language in image generation.\"","sentences":["Recent advancements in text-to-image (T2I) and vision-language-to-image (VL2I) generation have made significant strides.","However, the generation from generalized vision-language inputs, especially involving multiple images, remains under-explored.","This paper presents Kosmos-G, a model that leverages the advanced perception capabilities of Multimodal Large Language Models (MLLMs) to tackle the aforementioned challenge.","Our approach aligns the output space of MLLM with CLIP using the textual modality as an anchor and performs compositional instruction tuning on curated data.","Kosmos-G demonstrates a unique capability of zero-shot multi-entity subject-driven generation.","Notably, the score distillation instruction tuning requires no modifications to the image decoder.","This allows for a seamless substitution of CLIP and effortless integration with a myriad of U-Net techniques ranging from fine-grained controls to personalized image decoder variants.","We posit Kosmos-G as an initial attempt towards the goal of \"image as a foreign language in image generation.\""],"url":"http://arxiv.org/abs/2310.02992v1"}
{"created":"2023-10-04 17:26:44","title":"Exploring API Capabilities with Fieldwire","abstract":"Fieldwire, a cloud-based construction management software, has become a pivotal tool in the construction industry. It offers a comprehensive suite of features encompassing project management, task tracking, document management, and collaboration. With the rise of Application Programming Interfaces (APIs) in the software industry, Fieldwire has harnessed this trend to further empower construction professionals. APIs act as bridges between different software systems, and in Fieldwire's context, they hold the potential to integrate with specialized construction tools, eliminating data silos, manual data entry, and real-time information-sharing issues. This integration promises a streamlined and efficient construction management process, saving both time and resources. The research outlined in these abstract focuses on understanding Fieldwire's API capabilities, exploring integration possibilities with various construction tools, evaluating the impact of integration on efficiency and error reduction, establishing best practices, and offering recommendations to construction professionals. Python programming scripts are employed to visualize the benefits of API integration. Empirical findings indicate that Fieldwire's API significantly improves data accuracy, reduces project completion times by an average of 20%, and garners high user satisfaction. Such results are paramount in an industry reliant on precise data and efficient communication. This research underscores the transformative potential of Fieldwire's API and its relevance in modern construction management. It encourages construction professionals to embrace API integration for enhanced project outcomes and serves as an inspiration for software developers to innovate further in construction technology. As the construction industry evolves, API integration remains crucial for staying competitive and efficient.","sentences":["Fieldwire, a cloud-based construction management software, has become a pivotal tool in the construction industry.","It offers a comprehensive suite of features encompassing project management, task tracking, document management, and collaboration.","With the rise of Application Programming Interfaces (APIs) in the software industry, Fieldwire has harnessed this trend to further empower construction professionals.","APIs act as bridges between different software systems, and in Fieldwire's context, they hold the potential to integrate with specialized construction tools, eliminating data silos, manual data entry, and real-time information-sharing issues.","This integration promises a streamlined and efficient construction management process, saving both time and resources.","The research outlined in these abstract focuses on understanding Fieldwire's API capabilities, exploring integration possibilities with various construction tools, evaluating the impact of integration on efficiency and error reduction, establishing best practices, and offering recommendations to construction professionals.","Python programming scripts are employed to visualize the benefits of API integration.","Empirical findings indicate that Fieldwire's API significantly improves data accuracy, reduces project completion times by an average of 20%, and garners high user satisfaction.","Such results are paramount in an industry reliant on precise data and efficient communication.","This research underscores the transformative potential of Fieldwire's API and its relevance in modern construction management.","It encourages construction professionals to embrace API integration for enhanced project outcomes and serves as an inspiration for software developers to innovate further in construction technology.","As the construction industry evolves, API integration remains crucial for staying competitive and efficient."],"url":"http://arxiv.org/abs/2310.02990v1"}
{"created":"2023-10-04 17:25:10","title":"Probing Intersectional Biases in Vision-Language Models with Counterfactual Examples","abstract":"While vision-language models (VLMs) have achieved remarkable performance improvements recently, there is growing evidence that these models also posses harmful biases with respect to social attributes such as gender and race. Prior studies have primarily focused on probing such bias attributes individually while ignoring biases associated with intersections between social attributes. This could be due to the difficulty of collecting an exhaustive set of image-text pairs for various combinations of social attributes from existing datasets. To address this challenge, we employ text-to-image diffusion models to produce counterfactual examples for probing intserctional social biases at scale. Our approach utilizes Stable Diffusion with cross attention control to produce sets of counterfactual image-text pairs that are highly similar in their depiction of a subject (e.g., a given occupation) while differing only in their depiction of intersectional social attributes (e.g., race & gender). We conduct extensive experiments using our generated dataset which reveal the intersectional social biases present in state-of-the-art VLMs.","sentences":["While vision-language models (VLMs) have achieved remarkable performance improvements recently, there is growing evidence that these models also posses harmful biases with respect to social attributes such as gender and race.","Prior studies have primarily focused on probing such bias attributes individually while ignoring biases associated with intersections between social attributes.","This could be due to the difficulty of collecting an exhaustive set of image-text pairs for various combinations of social attributes from existing datasets.","To address this challenge, we employ text-to-image diffusion models to produce counterfactual examples for probing intserctional social biases at scale.","Our approach utilizes Stable Diffusion with cross attention control to produce sets of counterfactual image-text pairs that are highly similar in their depiction of a subject (e.g., a given occupation) while differing only in their depiction of intersectional social attributes (e.g., race & gender).","We conduct extensive experiments using our generated dataset which reveal the intersectional social biases present in state-of-the-art VLMs."],"url":"http://arxiv.org/abs/2310.02988v1"}
{"created":"2023-10-04 17:24:45","title":"Variance Reduced Halpern Iteration for Finite-Sum Monotone Inclusions","abstract":"Machine learning approaches relying on such criteria as adversarial robustness or multi-agent settings have raised the need for solving game-theoretic equilibrium problems. Of particular relevance to these applications are methods targeting finite-sum structure, which generically arises in empirical variants of learning problems in these contexts. Further, methods with computable approximation errors are highly desirable, as they provide verifiable exit criteria. Motivated by these applications, we study finite-sum monotone inclusion problems, which model broad classes of equilibrium problems. Our main contributions are variants of the classical Halpern iteration that employ variance reduction to obtain improved complexity guarantees in which $n$ component operators in the finite sum are ``on average'' either cocoercive or Lipschitz continuous and monotone, with parameter $L$. The resulting oracle complexity of our methods, which provide guarantees for the last iterate and for a (computable) operator norm residual, is $\\widetilde{\\mathcal{O}}( n + \\sqrt{n}L\\varepsilon^{-1})$, which improves upon existing methods by a factor up to $\\sqrt{n}$. This constitutes the first variance reduction-type result for general finite-sum monotone inclusions and for more specific problems such as convex-concave optimization when operator norm residual is the optimality measure. We further argue that, up to poly-logarithmic factors, this complexity is unimprovable in the monotone Lipschitz setting; i.e., the provided result is near-optimal.","sentences":["Machine learning approaches relying on such criteria as adversarial robustness or multi-agent settings have raised the need for solving game-theoretic equilibrium problems.","Of particular relevance to these applications are methods targeting finite-sum structure, which generically arises in empirical variants of learning problems in these contexts.","Further, methods with computable approximation errors are highly desirable, as they provide verifiable exit criteria.","Motivated by these applications, we study finite-sum monotone inclusion problems, which model broad classes of equilibrium problems.","Our main contributions are variants of the classical Halpern iteration that employ variance reduction to obtain improved complexity guarantees in which $n$ component operators in the finite sum are ``on average'' either cocoercive or Lipschitz continuous and monotone, with parameter $L$. The resulting oracle complexity of our methods, which provide guarantees for the last iterate and for a (computable) operator norm residual, is $\\widetilde{\\mathcal{O}}( n","+ \\sqrt{n}L\\varepsilon^{-1})$, which improves upon existing methods by a factor up to $\\sqrt{n}$. This constitutes the first variance reduction-type result for general finite-sum monotone inclusions and for more specific problems such as convex-concave optimization when operator norm residual is the optimality measure.","We further argue that, up to poly-logarithmic factors, this complexity is unimprovable in the monotone Lipschitz setting; i.e., the provided result is near-optimal."],"url":"http://arxiv.org/abs/2310.02987v1"}
{"created":"2023-10-04 17:24:38","title":"Exploring the Impact of Disrupted Peer-to-Peer Communications on Fully Decentralized Learning in Disaster Scenarios","abstract":"Fully decentralized learning enables the distribution of learning resources and decision-making capabilities across multiple user devices or nodes, and is rapidly gaining popularity due to its privacy-preserving and decentralized nature. Importantly, this crowdsourcing of the learning process allows the system to continue functioning even if some nodes are affected or disconnected. In a disaster scenario, communication infrastructure and centralized systems may be disrupted or completely unavailable, hindering the possibility of carrying out standard centralized learning tasks in these settings. Thus, fully decentralized learning can help in this case. However, transitioning from centralized to peer-to-peer communications introduces a dependency between the learning process and the topology of the communication graph among nodes. In a disaster scenario, even peer-to-peer communications are susceptible to abrupt changes, such as devices running out of battery or getting disconnected from others due to their position. In this study, we investigate the effects of various disruptions to peer-to-peer communications on decentralized learning in a disaster setting. We examine the resilience of a decentralized learning process when a subset of devices drop from the process abruptly. To this end, we analyze the difference between losing devices holding data, i.e., potential knowledge, vs. devices contributing only to the graph connectivity, i.e., with no data. Our findings on a Barabasi-Albert graph topology, where training data is distributed across nodes in an IID fashion, indicate that the accuracy of the learning process is more affected by a loss of connectivity than by a loss of data. Nevertheless, the network remains relatively robust, and the learning process can achieve a good level of accuracy.","sentences":["Fully decentralized learning enables the distribution of learning resources and decision-making capabilities across multiple user devices or nodes, and is rapidly gaining popularity due to its privacy-preserving and decentralized nature.","Importantly, this crowdsourcing of the learning process allows the system to continue functioning even if some nodes are affected or disconnected.","In a disaster scenario, communication infrastructure and centralized systems may be disrupted or completely unavailable, hindering the possibility of carrying out standard centralized learning tasks in these settings.","Thus, fully decentralized learning can help in this case.","However, transitioning from centralized to peer-to-peer communications introduces a dependency between the learning process and the topology of the communication graph among nodes.","In a disaster scenario, even peer-to-peer communications are susceptible to abrupt changes, such as devices running out of battery or getting disconnected from others due to their position.","In this study, we investigate the effects of various disruptions to peer-to-peer communications on decentralized learning in a disaster setting.","We examine the resilience of a decentralized learning process when a subset of devices drop from the process abruptly.","To this end, we analyze the difference between losing devices holding data, i.e., potential knowledge, vs. devices contributing only to the graph connectivity, i.e., with no data.","Our findings on a Barabasi-Albert graph topology, where training data is distributed across nodes in an IID fashion, indicate that the accuracy of the learning process is more affected by a loss of connectivity than by a loss of data.","Nevertheless, the network remains relatively robust, and the learning process can achieve a good level of accuracy."],"url":"http://arxiv.org/abs/2310.02986v1"}
{"created":"2023-10-04 17:22:58","title":"Continuous QoS-compliant Orchestration in the Cloud-Edge Continuum","abstract":"The problem of managing multi-service applications on top of Cloud-Edge networks in a QoS-aware manner has been thoroughly studied in recent years from a decision-making perspective. However, only a few studies addressed the problem of actively enforcing such decisions while orchestrating multi-service applications and considering infrastructure and application variations. In this article, we propose a next-gen orchestrator prototype based on Docker to achieve the continuous and QoS-compliant management of multiservice applications on top of geographically distributed Cloud-Edge resources, in continuity with CI/CD pipelines and infrastructure monitoring tools. Finally, we assess our proposal over a geographically distributed testbed across Italy.","sentences":["The problem of managing multi-service applications on top of Cloud-Edge networks in a QoS-aware manner has been thoroughly studied in recent years from a decision-making perspective.","However, only a few studies addressed the problem of actively enforcing such decisions while orchestrating multi-service applications and considering infrastructure and application variations.","In this article, we propose a next-gen orchestrator prototype based on Docker to achieve the continuous and QoS-compliant management of multiservice applications on top of geographically distributed Cloud-Edge resources, in continuity with CI/CD pipelines and infrastructure monitoring tools.","Finally, we assess our proposal over a geographically distributed testbed across Italy."],"url":"http://arxiv.org/abs/2310.02985v1"}
{"created":"2023-10-04 17:18:47","title":"Are LLMs Useful in the Poorest Schools? theTeacherAI in Sierra Leone","abstract":"Education systems in developing countries have few resources to serve large, poor populations. How might generative AI integrate into classrooms? This paper introduces an AI chatbot designed to assist teachers in Sierra Leone with professional development to improve their instruction. We describe initial findings from early implementation across 122 schools and 193 teachers, and analyze its use with qualitative observations and by analyzing queries. Teachers use the system for lesson planning, classroom management, and subject matter. A subset of teachers use the system intensively. We draw conclusions from these findings about how generative AI systems can be integrated into school systems in low income countries.","sentences":["Education systems in developing countries have few resources to serve large, poor populations.","How might generative AI integrate into classrooms?","This paper introduces an AI chatbot designed to assist teachers in Sierra Leone with professional development to improve their instruction.","We describe initial findings from early implementation across 122 schools and 193 teachers, and analyze its use with qualitative observations and by analyzing queries.","Teachers use the system for lesson planning, classroom management, and subject matter.","A subset of teachers use the system intensively.","We draw conclusions from these findings about how generative AI systems can be integrated into school systems in low income countries."],"url":"http://arxiv.org/abs/2310.02982v1"}
{"created":"2023-10-04 17:17:06","title":"Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors","abstract":"Modeling long-range dependencies across sequences is a longstanding goal in machine learning and has led to architectures, such as state space models, that dramatically outperform Transformers on long sequences. However, these impressive empirical gains have been by and large demonstrated on benchmarks (e.g. Long Range Arena), where models are randomly initialized and trained to predict a target label from an input sequence. In this work, we show that random initialization leads to gross overestimation of the differences between architectures and that pretraining with standard denoising objectives, using $\\textit{only the downstream task data}$, leads to dramatic gains across multiple architectures and to very small gaps between Transformers and state space models (SSMs). In stark contrast to prior works, we find vanilla Transformers to match the performance of S4 on Long Range Arena when properly pretrained, and we improve the best reported results of SSMs on the PathX-256 task by 20 absolute points. Subsequently, we analyze the utility of previously-proposed structured parameterizations for SSMs and show they become mostly redundant in the presence of data-driven initialization obtained through pretraining. Our work shows that, when evaluating different architectures on supervised tasks, incorporation of data-driven priors via pretraining is essential for reliable performance estimation, and can be done efficiently.","sentences":["Modeling long-range dependencies across sequences is a longstanding goal in machine learning and has led to architectures, such as state space models, that dramatically outperform Transformers on long sequences.","However, these impressive empirical gains have been by and large demonstrated on benchmarks (e.g. Long Range Arena), where models are randomly initialized and trained to predict a target label from an input sequence.","In this work, we show that random initialization leads to gross overestimation of the differences between architectures and that pretraining with standard denoising objectives, using $\\textit{only the downstream task data}$, leads to dramatic gains across multiple architectures and to very small gaps between Transformers and state space models (SSMs).","In stark contrast to prior works, we find vanilla Transformers to match the performance of S4 on Long Range Arena when properly pretrained, and we improve the best reported results of SSMs on the PathX-256 task by 20 absolute points.","Subsequently, we analyze the utility of previously-proposed structured parameterizations for SSMs and show they become mostly redundant in the presence of data-driven initialization obtained through pretraining.","Our work shows that, when evaluating different architectures on supervised tasks, incorporation of data-driven priors via pretraining is essential for reliable performance estimation, and can be done efficiently."],"url":"http://arxiv.org/abs/2310.02980v1"}
{"created":"2023-10-04 17:12:18","title":"T$^3$Bench: Benchmarking Current Progress in Text-to-3D Generation","abstract":"Recent methods in text-to-3D leverage powerful pretrained diffusion models to optimize NeRF. Notably, these methods are able to produce high-quality 3D scenes without training on 3D data. Due to the open-ended nature of the task, most studies evaluate their results with subjective case studies and user experiments, thereby presenting a challenge in quantitatively addressing the question: How has current progress in Text-to-3D gone so far? In this paper, we introduce T$^3$Bench, the first comprehensive text-to-3D benchmark containing diverse text prompts of three increasing complexity levels that are specially designed for 3D generation. To assess both the subjective quality and the text alignment, we propose two automatic metrics based on multi-view images produced by the 3D contents. The quality metric combines multi-view text-image scores and regional convolution to detect quality and view inconsistency. The alignment metric uses multi-view captioning and Large Language Model (LLM) evaluation to measure text-3D consistency. Both metrics closely correlate with different dimensions of human judgments, providing a paradigm for efficiently evaluating text-to-3D models. The benchmarking results, shown in Fig. 1, reveal performance differences among six prevalent text-to-3D methods. Our analysis further highlights the common struggles for current methods on generating surroundings and multi-object scenes, as well as the bottleneck of leveraging 2D guidance for 3D generation. Our project page is available at: https://t3bench.com.","sentences":["Recent methods in text-to-3D leverage powerful pretrained diffusion models to optimize NeRF.","Notably, these methods are able to produce high-quality 3D scenes without training on 3D data.","Due to the open-ended nature of the task, most studies evaluate their results with subjective case studies and user experiments, thereby presenting a challenge in quantitatively addressing the question: How has current progress in Text-to-3D gone so far?","In this paper, we introduce T$^3$Bench, the first comprehensive text-to-3D benchmark containing diverse text prompts of three increasing complexity levels that are specially designed for 3D generation.","To assess both the subjective quality and the text alignment, we propose two automatic metrics based on multi-view images produced by the 3D contents.","The quality metric combines multi-view text-image scores and regional convolution to detect quality and view inconsistency.","The alignment metric uses multi-view captioning and Large Language Model (LLM) evaluation to measure text-3D consistency.","Both metrics closely correlate with different dimensions of human judgments, providing a paradigm for efficiently evaluating text-to-3D models.","The benchmarking results, shown in Fig. 1, reveal performance differences among six prevalent text-to-3D methods.","Our analysis further highlights the common struggles for current methods on generating surroundings and multi-object scenes, as well as the bottleneck of leveraging 2D guidance for 3D generation.","Our project page is available at: https://t3bench.com."],"url":"http://arxiv.org/abs/2310.02977v1"}
{"created":"2023-10-04 17:11:15","title":"Towards Fully Adaptive Regret Minimization in Heavy-Tailed Bandits","abstract":"Heavy-tailed distributions naturally arise in many settings, from finance to telecommunications. While regret minimization under sub-Gaussian or bounded support rewards has been widely studied, learning on heavy-tailed distributions only gained popularity over the last decade. In the stochastic heavy-tailed bandit problem, an agent learns under the assumption that the distributions have finite moments of maximum order $1+\\epsilon$ which are uniformly bounded by a constant $u$, for some $\\epsilon \\in (0,1]$. To the best of our knowledge, literature only provides algorithms requiring these two quantities as an input. In this paper, we study the stochastic adaptive heavy-tailed bandit, a variation of the standard setting where both $\\epsilon$ and $u$ are unknown to the agent. We show that adaptivity comes at a cost, introducing two lower bounds on the regret of any adaptive algorithm, implying a higher regret w.r.t. the standard setting. Finally, we introduce a specific distributional assumption and provide Adaptive Robust UCB, a regret minimization strategy matching the known lower bound for the heavy-tailed MAB problem.","sentences":["Heavy-tailed distributions naturally arise in many settings, from finance to telecommunications.","While regret minimization under sub-Gaussian or bounded support rewards has been widely studied, learning on heavy-tailed distributions only gained popularity over the last decade.","In the stochastic heavy-tailed bandit problem, an agent learns under the assumption that the distributions have finite moments of maximum order $1+\\epsilon$ which are uniformly bounded by a constant $u$, for some $\\epsilon \\in (0,1]$. To the best of our knowledge, literature only provides algorithms requiring these two quantities as an input.","In this paper, we study the stochastic adaptive heavy-tailed bandit, a variation of the standard setting where both $\\epsilon$ and $u$ are unknown to the agent.","We show that adaptivity comes at a cost, introducing two lower bounds on the regret of any adaptive algorithm, implying a higher regret w.r.t.","the standard setting.","Finally, we introduce a specific distributional assumption and provide Adaptive Robust UCB, a regret minimization strategy matching the known lower bound for the heavy-tailed MAB problem."],"url":"http://arxiv.org/abs/2310.02975v1"}
{"created":"2023-10-04 17:10:23","title":"UniverSLU: Universal Spoken Language Understanding for Diverse Classification and Sequence Generation Tasks with a Single Network","abstract":"Recent studies have demonstrated promising outcomes by employing large language models with multi-tasking capabilities. They utilize prompts to guide the model's behavior and surpass performance of task-specific models. Motivated by this, we ask: can we build a single model that jointly perform various spoken language understanding (SLU) tasks? To address this, we utilize pre-trained automatic speech recognition (ASR) models and employ various task and dataset specifiers as discrete prompts. We demonstrate efficacy of our single multi-task learning (MTL) model \"UniverSLU\" for 12 different speech classification and sequence generation tasks across 17 datasets and 9 languages. Results show that UniverSLU achieves competitive performance and even surpasses task-specific models. We also conduct preliminary investigations into enabling human-interpretable natural phrases instead of task specifiers as discrete prompts and test the model's generalization capabilities to new paraphrases.","sentences":["Recent studies have demonstrated promising outcomes by employing large language models with multi-tasking capabilities.","They utilize prompts to guide the model's behavior and surpass performance of task-specific models.","Motivated by this, we ask: can we build a single model that jointly perform various spoken language understanding (SLU) tasks?","To address this, we utilize pre-trained automatic speech recognition (ASR) models and employ various task and dataset specifiers as discrete prompts.","We demonstrate efficacy of our single multi-task learning (MTL) model \"UniverSLU\" for 12 different speech classification and sequence generation tasks across 17 datasets and 9 languages.","Results show that UniverSLU achieves competitive performance and even surpasses task-specific models.","We also conduct preliminary investigations into enabling human-interpretable natural phrases instead of task specifiers as discrete prompts and test the model's generalization capabilities to new paraphrases."],"url":"http://arxiv.org/abs/2310.02973v1"}
{"created":"2023-10-04 17:06:32","title":"Fast, Expressive SE$(n)$ Equivariant Networks through Weight-Sharing in Position-Orientation Space","abstract":"Based on the theory of homogeneous spaces we derive \\textit{geometrically optimal edge attributes} to be used within the flexible message passing framework. We formalize the notion of weight sharing in convolutional networks as the sharing of message functions over point-pairs that should be treated equally. We define equivalence classes of point-pairs that are identical up to a transformation in the group and derive attributes that uniquely identify these classes. Weight sharing is then obtained by conditioning message functions on these attributes. As an application of the theory, we develop an efficient equivariant group convolutional network for processing 3D point clouds. The theory of homogeneous spaces tells us how to do group convolutions with feature maps over the homogeneous space of positions $\\mathbb{R}^3$, position and orientations $\\mathbb{R}^3 {\\times} S^2$, and the group SE$(3)$ itself. Among these, $\\mathbb{R}^3 {\\times} S^2$ is an optimal choice due to the ability to represent directional information, which $\\mathbb{R}^3$ methods cannot, and it significantly enhances computational efficiency compared to indexing features on the full SE$(3)$ group. We empirically support this claim by reaching state-of-the-art results -- in accuracy and speed -- on three different benchmarks: interatomic potential energy prediction, trajectory forecasting in N-body systems, and generating molecules via equivariant diffusion models.","sentences":["Based on the theory of homogeneous spaces we derive \\textit{geometrically optimal edge attributes} to be used within the flexible message passing framework.","We formalize the notion of weight sharing in convolutional networks as the sharing of message functions over point-pairs that should be treated equally.","We define equivalence classes of point-pairs that are identical up to a transformation in the group and derive attributes that uniquely identify these classes.","Weight sharing is then obtained by conditioning message functions on these attributes.","As an application of the theory, we develop an efficient equivariant group convolutional network for processing 3D point clouds.","The theory of homogeneous spaces tells us how to do group convolutions with feature maps over the homogeneous space of positions $\\mathbb{R}^3$, position and orientations $\\mathbb{R}^3 {\\times} S^2$, and the group SE$(3)$ itself.","Among these, $\\mathbb{R}^3 {\\times} S^2$ is an optimal choice due to the ability to represent directional information, which $\\mathbb{R}^3$ methods cannot, and it significantly enhances computational efficiency compared to indexing features on the full SE$(3)$ group.","We empirically support this claim by reaching state-of-the-art results -- in accuracy and speed -- on three different benchmarks: interatomic potential energy prediction, trajectory forecasting in N-body systems, and generating molecules via equivariant diffusion models."],"url":"http://arxiv.org/abs/2310.02970v1"}
{"created":"2023-10-04 17:06:30","title":"Dual Conic Proxies for AC Optimal Power Flow","abstract":"In recent years, there has been significant interest in the development of machine learning-based optimization proxies for AC Optimal Power Flow (AC-OPF). Although significant progress has been achieved in predicting high-quality primal solutions, no existing learning-based approach can provide valid dual bounds for AC-OPF. This paper addresses this gap by training optimization proxies for a convex relaxation of AC-OPF. Namely, the paper considers a second-order cone (SOC) relaxation of ACOPF, and proposes a novel dual architecture that embeds a fast, differentiable (dual) feasibility recovery, thus providing valid dual bounds. The paper combines this new architecture with a self-supervised learning scheme, which alleviates the need for costly training data generation. Extensive numerical experiments on medium- and large-scale power grids demonstrate the efficiency and scalability of the proposed methodology.","sentences":["In recent years, there has been significant interest in the development of machine learning-based optimization proxies for AC Optimal Power Flow (AC-OPF).","Although significant progress has been achieved in predicting high-quality primal solutions, no existing learning-based approach can provide valid dual bounds for AC-OPF.","This paper addresses this gap by training optimization proxies for a convex relaxation of AC-OPF.","Namely, the paper considers a second-order cone (SOC) relaxation of ACOPF, and proposes a novel dual architecture that embeds a fast, differentiable (dual) feasibility recovery, thus providing valid dual bounds.","The paper combines this new architecture with a self-supervised learning scheme, which alleviates the need for costly training data generation.","Extensive numerical experiments on medium- and large-scale power grids demonstrate the efficiency and scalability of the proposed methodology."],"url":"http://arxiv.org/abs/2310.02969v1"}
{"created":"2023-10-04 16:58:25","title":"Co-modeling the Sequential and Graphical Route for Peptide","abstract":"Peptides are formed by the dehydration condensation of multiple amino acids. The primary structure of a peptide can be represented either as an amino acid sequence or as a molecular graph consisting of atoms and chemical bonds. Previous studies have indicated that deep learning routes specific to sequential and graphical peptide forms exhibit comparable performance on downstream tasks. Despite the fact that these models learn representations of the same modality of peptides, we find that they explain their predictions differently. Considering sequential and graphical models as two experts making inferences from different perspectives, we work on fusing expert knowledge to enrich the learned representations for improving the discriminative performance. To achieve this, we propose a peptide co-modeling method, RepCon, which employs a contrastive learning-based framework to enhance the mutual information of representations from decoupled sequential and graphical end-to-end models. It considers representations from the sequential encoder and the graphical encoder for the same peptide sample as a positive pair and learns to enhance the consistency of representations between positive sample pairs and to repel representations between negative pairs. Empirical studies of RepCon and other co-modeling methods are conducted on open-source discriminative datasets, including aggregation propensity, retention time, antimicrobial peptide prediction, and family classification from Peptide Database. Our results demonstrate the superiority of the co-modeling approach over independent modeling, as well as the superiority of RepCon over other methods under the co-modeling framework. In addition, the attribution on RepCon further corroborates the validity of the approach at the level of model explanation.","sentences":["Peptides are formed by the dehydration condensation of multiple amino acids.","The primary structure of a peptide can be represented either as an amino acid sequence or as a molecular graph consisting of atoms and chemical bonds.","Previous studies have indicated that deep learning routes specific to sequential and graphical peptide forms exhibit comparable performance on downstream tasks.","Despite the fact that these models learn representations of the same modality of peptides, we find that they explain their predictions differently.","Considering sequential and graphical models as two experts making inferences from different perspectives, we work on fusing expert knowledge to enrich the learned representations for improving the discriminative performance.","To achieve this, we propose a peptide co-modeling method, RepCon, which employs a contrastive learning-based framework to enhance the mutual information of representations from decoupled sequential and graphical end-to-end models.","It considers representations from the sequential encoder and the graphical encoder for the same peptide sample as a positive pair and learns to enhance the consistency of representations between positive sample pairs and to repel representations between negative pairs.","Empirical studies of RepCon and other co-modeling methods are conducted on open-source discriminative datasets, including aggregation propensity, retention time, antimicrobial peptide prediction, and family classification from Peptide Database.","Our results demonstrate the superiority of the co-modeling approach over independent modeling, as well as the superiority of RepCon over other methods under the co-modeling framework.","In addition, the attribution on RepCon further corroborates the validity of the approach at the level of model explanation."],"url":"http://arxiv.org/abs/2310.02964v1"}
{"created":"2023-10-04 16:54:03","title":"Potential Factors Leading to Popularity Unfairness in Recommender Systems: A User-Centered Analysis","abstract":"Popularity bias is a well-known issue in recommender systems where few popular items are over-represented in the input data, while majority of other less popular items are under-represented. This disparate representation often leads to bias in exposure given to the items in the recommendation results. Extensive research examined this bias from item perspective and attempted to mitigate it by enhancing the recommendation of less popular items. However, a recent research has revealed the impact of this bias on users. Users with different degree of tolerance toward popular items are not fairly served by the recommendation system: users interested in less popular items receive more popular items in their recommendations, while users interested in popular items are recommended what they want. This is mainly due to the popularity bias that popular items are over-recommended. In this paper, we aim at investigating the factors leading to this user-side unfairness of popularity bias in recommender systems. In particular, we investigate two factors: 1) the relationship between this unfairness and users' interest toward items' categories (e.g., movie genres), 2) the relationship between this unfairness and the diversity of the popularity group in users' profile (the degree to which the user is interested in items with different degree of popularity). Experiments on a movie recommendation dataset using multiple recommendation algorithms show that these two factors are significantly correlated with the degree of popularity unfairness in the recommendation results.","sentences":["Popularity bias is a well-known issue in recommender systems where few popular items are over-represented in the input data, while majority of other less popular items are under-represented.","This disparate representation often leads to bias in exposure given to the items in the recommendation results.","Extensive research examined this bias from item perspective and attempted to mitigate it by enhancing the recommendation of less popular items.","However, a recent research has revealed the impact of this bias on users.","Users with different degree of tolerance toward popular items are not fairly served by the recommendation system: users interested in less popular items receive more popular items in their recommendations, while users interested in popular items are recommended what they want.","This is mainly due to the popularity bias that popular items are over-recommended.","In this paper, we aim at investigating the factors leading to this user-side unfairness of popularity bias in recommender systems.","In particular, we investigate two factors: 1) the relationship between this unfairness and users' interest toward items' categories (e.g., movie genres), 2) the relationship between this unfairness and the diversity of the popularity group in users' profile (the degree to which the user is interested in items with different degree of popularity).","Experiments on a movie recommendation dataset using multiple recommendation algorithms show that these two factors are significantly correlated with the degree of popularity unfairness in the recommendation results."],"url":"http://arxiv.org/abs/2310.02961v1"}
{"created":"2023-10-04 16:50:51","title":"CoDA: Collaborative Novel Box Discovery and Cross-modal Alignment for Open-vocabulary 3D Object Detection","abstract":"Open-vocabulary 3D Object Detection (OV-3DDet) aims to detect objects from an arbitrary list of categories within a 3D scene, which remains seldom explored in the literature. There are primarily two fundamental problems in OV-3DDet, i.e., localizing and classifying novel objects. This paper aims at addressing the two problems simultaneously via a unified framework, under the condition of limited base categories. To localize novel 3D objects, we propose an effective 3D Novel Object Discovery strategy, which utilizes both the 3D box geometry priors and 2D semantic open-vocabulary priors to generate pseudo box labels of the novel objects. To classify novel object boxes, we further develop a cross-modal alignment module based on discovered novel boxes, to align feature spaces between 3D point cloud and image/text modalities. Specifically, the alignment process contains a class-agnostic and a class-discriminative alignment, incorporating not only the base objects with annotations but also the increasingly discovered novel objects, resulting in an iteratively enhanced alignment. The novel box discovery and crossmodal alignment are jointly learned to collaboratively benefit each other. The novel object discovery can directly impact the cross-modal alignment, while a better feature alignment can, in turn, boost the localization capability, leading to a unified OV-3DDet framework, named CoDA, for simultaneous novel object localization and classification. Extensive experiments on two challenging datasets (i.e., SUN-RGBD and ScanNet) demonstrate the effectiveness of our method and also show a significant mAP improvement upon the best-performing alternative method by 80%. Codes and pre-trained models are released on the project page.","sentences":["Open-vocabulary 3D Object Detection (OV-3DDet) aims to detect objects from an arbitrary list of categories within a 3D scene, which remains seldom explored in the literature.","There are primarily two fundamental problems in OV-3DDet, i.e., localizing and classifying novel objects.","This paper aims at addressing the two problems simultaneously via a unified framework, under the condition of limited base categories.","To localize novel 3D objects, we propose an effective 3D Novel Object Discovery strategy, which utilizes both the 3D box geometry priors and 2D semantic open-vocabulary priors to generate pseudo box labels of the novel objects.","To classify novel object boxes, we further develop a cross-modal alignment module based on discovered novel boxes, to align feature spaces between 3D point cloud and image/text modalities.","Specifically, the alignment process contains a class-agnostic and a class-discriminative alignment, incorporating not only the base objects with annotations but also the increasingly discovered novel objects, resulting in an iteratively enhanced alignment.","The novel box discovery and crossmodal alignment are jointly learned to collaboratively benefit each other.","The novel object discovery can directly impact the cross-modal alignment, while a better feature alignment can, in turn, boost the localization capability, leading to a unified OV-3DDet framework, named CoDA, for simultaneous novel object localization and classification.","Extensive experiments on two challenging datasets (i.e., SUN-RGBD and ScanNet) demonstrate the effectiveness of our method and also show a significant mAP improvement upon the best-performing alternative method by 80%.","Codes and pre-trained models are released on the project page."],"url":"http://arxiv.org/abs/2310.02960v1"}
{"created":"2023-10-04 16:50:23","title":"Co-Optimizing Cache Partitioning and Multi-Core Task Scheduling: Exploit Cache Sensitivity or Not?","abstract":"Cache partitioning techniques have been successfully adopted to mitigate interference among concurrently executing real-time tasks on multi-core processors. Considering that the execution time of a cache-sensitive task strongly depends on the cache available for it to use, co-optimizing cache partitioning and task allocation improves the system's schedulability. In this paper, we propose a hybrid multi-layer design space exploration technique to solve this multi-resource management problem. We explore the interplay between cache partitioning and schedulability by systematically interleaving three optimization layers, viz., (i) in the outer layer, we perform a breadth-first search combined with proactive pruning for cache partitioning; (ii) in the middle layer, we exploit a first-fit heuristic for allocating tasks to cores; and (iii) in the inner layer, we use the well-known recurrence relation for the schedulability analysis of non-preemptive fixed-priority (NP-FP) tasks in a uniprocessor setting. Although our focus is on NP-FP scheduling, we evaluate the flexibility of our framework in supporting different scheduling policies (NP-EDF, P-EDF) by plugging in appropriate analysis methods in the inner layer. Experiments show that, compared to the state-of-the-art techniques, the proposed framework can improve the real-time schedulability of NP-FP task sets by an average of 15.2% with a maximum improvement of 233.6% (when tasks are highly cache-sensitive) and a minimum of 1.6% (when cache sensitivity is low). For such task sets, we found that clustering similar-period (or mutually compatible) tasks often leads to higher schedulability (on average 7.6%) than clustering by cache sensitivity. In our evaluation, the framework also achieves good results for preemptive and dynamic-priority scheduling policies.","sentences":["Cache partitioning techniques have been successfully adopted to mitigate interference among concurrently executing real-time tasks on multi-core processors.","Considering that the execution time of a cache-sensitive task strongly depends on the cache available for it to use, co-optimizing cache partitioning and task allocation improves the system's schedulability.","In this paper, we propose a hybrid multi-layer design space exploration technique to solve this multi-resource management problem.","We explore the interplay between cache partitioning and schedulability by systematically interleaving three optimization layers, viz., (i) in the outer layer, we perform a breadth-first search combined with proactive pruning for cache partitioning; (ii) in the middle layer, we exploit a first-fit heuristic for allocating tasks to cores; and (iii) in the inner layer, we use the well-known recurrence relation for the schedulability analysis of non-preemptive fixed-priority (NP-FP) tasks in a uniprocessor setting.","Although our focus is on NP-FP scheduling, we evaluate the flexibility of our framework in supporting different scheduling policies (NP-EDF, P-EDF) by plugging in appropriate analysis methods in the inner layer.","Experiments show that, compared to the state-of-the-art techniques, the proposed framework can improve the real-time schedulability of NP-FP task sets by an average of 15.2% with a maximum improvement of 233.6% (when tasks are highly cache-sensitive) and a minimum of 1.6% (when cache sensitivity is low).","For such task sets, we found that clustering similar-period (or mutually compatible) tasks often leads to higher schedulability (on average 7.6%) than clustering by cache sensitivity.","In our evaluation, the framework also achieves good results for preemptive and dynamic-priority scheduling policies."],"url":"http://arxiv.org/abs/2310.02959v1"}
{"created":"2023-10-04 16:46:26","title":"Credit card score prediction using machine learning models: A new dataset","abstract":"The use of credit cards has recently increased, creating an essential need for credit card assessment methods to minimize potential risks. This study investigates the utilization of machine learning (ML) models for credit card default prediction system. The main goal here is to investigate the best-performing ML model for new proposed credit card scoring dataset. This new dataset includes credit card transaction histories and customer profiles, is proposed and tested using a variety of machine learning algorithms, including logistic regression, decision trees, random forests, multi layer perceptron (MLP) neural network, XGBoost, and LightGBM. To prepare the data for machine learning models, we perform data pre-proccessing, feature extraction, feature selection, and data balancing techniques. Experimental results demonstrate that MLP outperforms logistic regression, decision trees, random forests, LightGBM, and XGBoost in terms of predictive performance in true positive rate, achieving an impressive area under the curve (AUC) of 86.7% and an accuracy rate of 91.6%, with a recall rate exceeding 80%. These results indicate the superiority of MLP in predicting the default customers and assessing the potential risks. Furthermore, they help banks and other financial institutions in predicting loan defaults at an earlier stage.","sentences":["The use of credit cards has recently increased, creating an essential need for credit card assessment methods to minimize potential risks.","This study investigates the utilization of machine learning (ML) models for credit card default prediction system.","The main goal here is to investigate the best-performing ML model for new proposed credit card scoring dataset.","This new dataset includes credit card transaction histories and customer profiles, is proposed and tested using a variety of machine learning algorithms, including logistic regression, decision trees, random forests, multi layer perceptron (MLP) neural network, XGBoost, and LightGBM.","To prepare the data for machine learning models, we perform data pre-proccessing, feature extraction, feature selection, and data balancing techniques.","Experimental results demonstrate that MLP outperforms logistic regression, decision trees, random forests, LightGBM, and XGBoost in terms of predictive performance in true positive rate, achieving an impressive area under the curve (AUC) of 86.7% and an accuracy rate of 91.6%, with a recall rate exceeding 80%.","These results indicate the superiority of MLP in predicting the default customers and assessing the potential risks.","Furthermore, they help banks and other financial institutions in predicting loan defaults at an earlier stage."],"url":"http://arxiv.org/abs/2310.02956v1"}
{"created":"2023-10-04 16:44:38","title":"Perceptual error optimization for Monte Carlo animation rendering","abstract":"Independently estimating pixel values in Monte Carlo rendering results in a perceptually sub-optimal white-noise distribution of error in image space. Recent works have shown that perceptual fidelity can be improved significantly by distributing pixel error as blue noise instead. Most such works have focused on static images, ignoring the temporal perceptual effects of animation display. We extend prior formulations to simultaneously consider the spatial and temporal domains, and perform an analysis to motivate a perceptually better spatio-temporal error distribution. We then propose a practical error optimization algorithm for spatio-temporal rendering and demonstrate its effectiveness in various configurations.","sentences":["Independently estimating pixel values in Monte Carlo rendering results in a perceptually sub-optimal white-noise distribution of error in image space.","Recent works have shown that perceptual fidelity can be improved significantly by distributing pixel error as blue noise instead.","Most such works have focused on static images, ignoring the temporal perceptual effects of animation display.","We extend prior formulations to simultaneously consider the spatial and temporal domains, and perform an analysis to motivate a perceptually better spatio-temporal error distribution.","We then propose a practical error optimization algorithm for spatio-temporal rendering and demonstrate its effectiveness in various configurations."],"url":"http://arxiv.org/abs/2310.02955v1"}
{"created":"2023-10-04 16:44:37","title":"DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning","abstract":"Recent advances in natural language processing, primarily propelled by Large Language Models (LLMs), have showcased their remarkable capabilities grounded in in-context learning. A promising avenue for guiding LLMs in intricate reasoning tasks involves the utilization of intermediate reasoning steps within the Chain-of-Thought (CoT) paradigm. Nevertheless, the central challenge lies in the effective selection of exemplars for facilitating in-context learning. In this study, we introduce a framework that leverages Dual Queries and Low-rank approximation Re-ranking (DQ-LoRe) to automatically select exemplars for in-context learning. Dual Queries first query LLM to obtain LLM-generated knowledge such as CoT, then query the retriever to obtain the final exemplars via both question and the knowledge. Moreover, for the second query, LoRe employs dimensionality reduction techniques to refine exemplar selection, ensuring close alignment with the input question's knowledge. Through extensive experiments, we demonstrate that DQ-LoRe significantly outperforms prior state-of-the-art methods in the automatic selection of exemplars for GPT-4, enhancing performance from 92.5\\% to 94.2\\%. Our comprehensive analysis further reveals that DQ-LoRe consistently outperforms retrieval-based approaches in terms of both performance and adaptability, especially in scenarios characterized by distribution shifts. DQ-LoRe pushes the boundaries of in-context learning and opens up new avenues for addressing complex reasoning challenges. We will release the code soon.","sentences":["Recent advances in natural language processing, primarily propelled by Large Language Models (LLMs), have showcased their remarkable capabilities grounded in in-context learning.","A promising avenue for guiding LLMs in intricate reasoning tasks involves the utilization of intermediate reasoning steps within the Chain-of-Thought (CoT) paradigm.","Nevertheless, the central challenge lies in the effective selection of exemplars for facilitating in-context learning.","In this study, we introduce a framework that leverages Dual Queries and Low-rank approximation Re-ranking (DQ-LoRe) to automatically select exemplars for in-context learning.","Dual Queries first query LLM to obtain LLM-generated knowledge such as CoT, then query the retriever to obtain the final exemplars via both question and the knowledge.","Moreover, for the second query, LoRe employs dimensionality reduction techniques to refine exemplar selection, ensuring close alignment with the input question's knowledge.","Through extensive experiments, we demonstrate that DQ-LoRe significantly outperforms prior state-of-the-art methods in the automatic selection of exemplars for GPT-4, enhancing performance from 92.5\\% to 94.2\\%.","Our comprehensive analysis further reveals that DQ-LoRe consistently outperforms retrieval-based approaches in terms of both performance and adaptability, especially in scenarios characterized by distribution shifts.","DQ-LoRe pushes the boundaries of in-context learning and opens up new avenues for addressing complex reasoning challenges.","We will release the code soon."],"url":"http://arxiv.org/abs/2310.02954v1"}
{"created":"2023-10-04 16:44:23","title":"JsonTuning: Towards Generalizable, Robust, and Controllable Instruction Tuning","abstract":"Instruction tuning has emerged as a crucial process for harnessing the capabilities of large language models (LLMs) by providing explicit task instructions, leading to improved performance in various tasks. However, prevalent text-to-text instruction tuning (TextTuning) methods suffer from limitations in generalization, robustness, and controllability due to the ambiguity and lack of explicit structure in tasks. In this paper, we propose JsonTuning, a novel structure-to-structure approach for instruction tuning. By leveraging the versatility and structured nature of JSON to represent tasks, JsonTuning enhances generalization by helping the model understand essential task elements and their relations, improves robustness by minimizing ambiguity, and increases controllability by providing explicit control over the output. We conduct a comprehensive comparative study with diverse language models and evaluation benchmarks. Experimental results show that JsonTuning outperforms TextTuning in various applications, showcasing improved performance, adaptability, robustness, and controllability. By overcoming the limitations of TextTuning, JsonTuning demonstrates significant potential for more effective and reliable LLMs capable of handling diverse scenarios.","sentences":["Instruction tuning has emerged as a crucial process for harnessing the capabilities of large language models (LLMs) by providing explicit task instructions, leading to improved performance in various tasks.","However, prevalent text-to-text instruction tuning (TextTuning) methods suffer from limitations in generalization, robustness, and controllability due to the ambiguity and lack of explicit structure in tasks.","In this paper, we propose JsonTuning, a novel structure-to-structure approach for instruction tuning.","By leveraging the versatility and structured nature of JSON to represent tasks, JsonTuning enhances generalization by helping the model understand essential task elements and their relations, improves robustness by minimizing ambiguity, and increases controllability by providing explicit control over the output.","We conduct a comprehensive comparative study with diverse language models and evaluation benchmarks.","Experimental results show that JsonTuning outperforms TextTuning in various applications, showcasing improved performance, adaptability, robustness, and controllability.","By overcoming the limitations of TextTuning, JsonTuning demonstrates significant potential for more effective and reliable LLMs capable of handling diverse scenarios."],"url":"http://arxiv.org/abs/2310.02953v1"}
{"created":"2023-10-04 16:39:31","title":"Shadow Alignment: The Ease of Subverting Safely-Aligned Language Models","abstract":"Warning: This paper contains examples of harmful language, and reader discretion is recommended. The increasing open release of powerful large language models (LLMs) has facilitated the development of downstream applications by reducing the essential cost of data annotation and computation. To ensure AI safety, extensive safety-alignment measures have been conducted to armor these models against malicious use (primarily hard prompt attack). However, beneath the seemingly resilient facade of the armor, there might lurk a shadow. By simply tuning on 100 malicious examples with 1 GPU hour, these safely aligned LLMs can be easily subverted to generate harmful content. Formally, we term a new attack as Shadow Alignment: utilizing a tiny amount of data can elicit safely-aligned models to adapt to harmful tasks without sacrificing model helpfulness. Remarkably, the subverted models retain their capability to respond appropriately to regular inquiries. Experiments across 8 models released by 5 different organizations (LLaMa-2, Falcon, InternLM, BaiChuan2, Vicuna) demonstrate the effectiveness of shadow alignment attack. Besides, the single-turn English-only attack successfully transfers to multi-turn dialogue and other languages. This study serves as a clarion call for a collective effort to overhaul and fortify the safety of open-source LLMs against malicious attackers.","sentences":["Warning:","This paper contains examples of harmful language, and reader discretion is recommended.","The increasing open release of powerful large language models (LLMs) has facilitated the development of downstream applications by reducing the essential cost of data annotation and computation.","To ensure AI safety, extensive safety-alignment measures have been conducted to armor these models against malicious use (primarily hard prompt attack).","However, beneath the seemingly resilient facade of the armor, there might lurk a shadow.","By simply tuning on 100 malicious examples with 1 GPU hour, these safely aligned LLMs can be easily subverted to generate harmful content.","Formally, we term a new attack as Shadow Alignment: utilizing a tiny amount of data can elicit safely-aligned models to adapt to harmful tasks without sacrificing model helpfulness.","Remarkably, the subverted models retain their capability to respond appropriately to regular inquiries.","Experiments across 8 models released by 5 different organizations (LLaMa-2, Falcon, InternLM, BaiChuan2, Vicuna) demonstrate the effectiveness of shadow alignment attack.","Besides, the single-turn English-only attack successfully transfers to multi-turn dialogue and other languages.","This study serves as a clarion call for a collective effort to overhaul and fortify the safety of open-source LLMs against malicious attackers."],"url":"http://arxiv.org/abs/2310.02949v1"}
{"created":"2023-10-04 16:24:00","title":"Adaptive Landmark Color for AUV Docking in Visually Dynamic Environments","abstract":"Autonomous Underwater Vehicles (AUVs) conduct missions underwater without the need for human intervention. A docking station (DS) can extend mission times of an AUV by providing a location for the AUV to recharge its batteries and receive updated mission information. Various methods for locating and tracking a DS exist, but most rely on expensive acoustic sensors, or are vision-based, which is significantly affected by water quality. In this \\doctype, we present a vision-based method that utilizes adaptive color LED markers and dynamic color filtering to maximize landmark visibility in varying water conditions. Both AUV and DS utilize cameras to determine the water background color in order to calculate the desired marker color. No communication between AUV and DS is needed to determine marker color. Experiments conducted in a pool and lake show our method performs 10 times better than static color thresholding methods as background color varies. DS detection is possible at a range of 5 meters in clear water with minimal false positives.","sentences":["Autonomous Underwater Vehicles (AUVs) conduct missions underwater without the need for human intervention.","A docking station (DS) can extend mission times of an AUV by providing a location for the AUV to recharge its batteries and receive updated mission information.","Various methods for locating and tracking a DS exist, but most rely on expensive acoustic sensors, or are vision-based, which is significantly affected by water quality.","In this \\doctype, we present a vision-based method that utilizes adaptive color LED markers and dynamic color filtering to maximize landmark visibility in varying water conditions.","Both AUV and DS utilize cameras to determine the water background color in order to calculate the desired marker color.","No communication between AUV and DS is needed to determine marker color.","Experiments conducted in a pool and lake show our method performs 10 times better than static color thresholding methods as background color varies.","DS detection is possible at a range of 5 meters in clear water with minimal false positives."],"url":"http://arxiv.org/abs/2310.02944v1"}
{"created":"2023-10-04 16:23:37","title":"LibriSpeech-PC: Benchmark for Evaluation of Punctuation and Capitalization Capabilities of end-to-end ASR Models","abstract":"Traditional automatic speech recognition (ASR) models output lower-cased words without punctuation marks, which reduces readability and necessitates a subsequent text processing model to convert ASR transcripts into a proper format. Simultaneously, the development of end-to-end ASR models capable of predicting punctuation and capitalization presents several challenges, primarily due to limited data availability and shortcomings in the existing evaluation methods, such as inadequate assessment of punctuation prediction. In this paper, we introduce a LibriSpeech-PC benchmark designed to assess the punctuation and capitalization prediction capabilities of end-to-end ASR models. The benchmark includes a LibriSpeech-PC dataset with restored punctuation and capitalization, a novel evaluation metric called Punctuation Error Rate (PER) that focuses on punctuation marks, and initial baseline models. All code, data, and models are publicly available.","sentences":["Traditional automatic speech recognition (ASR) models output lower-cased words without punctuation marks, which reduces readability and necessitates a subsequent text processing model to convert ASR transcripts into a proper format.","Simultaneously, the development of end-to-end ASR models capable of predicting punctuation and capitalization presents several challenges, primarily due to limited data availability and shortcomings in the existing evaluation methods, such as inadequate assessment of punctuation prediction.","In this paper, we introduce a LibriSpeech-PC benchmark designed to assess the punctuation and capitalization prediction capabilities of end-to-end ASR models.","The benchmark includes a LibriSpeech-PC dataset with restored punctuation and capitalization, a novel evaluation metric called Punctuation Error Rate (PER) that focuses on punctuation marks, and initial baseline models.","All code, data, and models are publicly available."],"url":"http://arxiv.org/abs/2310.02943v1"}
{"created":"2023-10-04 16:09:48","title":"Assessing Large Language Models on Climate Information","abstract":"Understanding how climate change affects us and learning about available solutions are key steps toward empowering individuals and communities to mitigate and adapt to it. As Large Language Models (LLMs) rise in popularity, it is necessary to assess their capability in this domain. In this study, we present a comprehensive evaluation framework, grounded in science communication principles, to analyze LLM responses to climate change topics. Our framework emphasizes both the presentational and epistemological adequacy of answers, offering a fine-grained analysis of LLM generations. Spanning 8 dimensions, our framework discerns up to 30 distinct issues in model outputs. The task is a real-world example of a growing number of challenging problems where AI can complement and lift human performance. We introduce a novel and practical protocol for scalable oversight that uses AI Assistance and relies on raters with relevant educational backgrounds. We evaluate several recent LLMs and conduct a comprehensive analysis of the results, shedding light on both the potential and the limitations of LLMs in the realm of climate communication.","sentences":["Understanding how climate change affects us and learning about available solutions are key steps toward empowering individuals and communities to mitigate and adapt to it.","As Large Language Models (LLMs) rise in popularity, it is necessary to assess their capability in this domain.","In this study, we present a comprehensive evaluation framework, grounded in science communication principles, to analyze LLM responses to climate change topics.","Our framework emphasizes both the presentational and epistemological adequacy of answers, offering a fine-grained analysis of LLM generations.","Spanning 8 dimensions, our framework discerns up to 30 distinct issues in model outputs.","The task is a real-world example of a growing number of challenging problems where AI can complement and lift human performance.","We introduce a novel and practical protocol for scalable oversight that uses AI Assistance and relies on raters with relevant educational backgrounds.","We evaluate several recent LLMs and conduct a comprehensive analysis of the results, shedding light on both the potential and the limitations of LLMs in the realm of climate communication."],"url":"http://arxiv.org/abs/2310.02932v1"}
{"created":"2023-10-04 16:09:35","title":"Graph data modelling for outcome prediction in oropharyngeal cancer patients","abstract":"Graph neural networks (GNNs) are becoming increasingly popular in the medical domain for the tasks of disease classification and outcome prediction. Since patient data is not readily available as a graph, most existing methods either manually define a patient graph, or learn a latent graph based on pairwise similarities between the patients. There are also hypergraph neural network (HGNN)-based methods that were introduced recently to exploit potential higher order associations between the patients by representing them as a hypergraph. In this work, we propose a patient hypergraph network (PHGN), which has been investigated in an inductive learning setup for binary outcome prediction in oropharyngeal cancer (OPC) patients using computed tomography (CT)-based radiomic features for the first time. Additionally, the proposed model was extended to perform time-to-event analyses, and compared with GNN and baseline linear models.","sentences":["Graph neural networks (GNNs) are becoming increasingly popular in the medical domain for the tasks of disease classification and outcome prediction.","Since patient data is not readily available as a graph, most existing methods either manually define a patient graph, or learn a latent graph based on pairwise similarities between the patients.","There are also hypergraph neural network (HGNN)-based methods that were introduced recently to exploit potential higher order associations between the patients by representing them as a hypergraph.","In this work, we propose a patient hypergraph network (PHGN), which has been investigated in an inductive learning setup for binary outcome prediction in oropharyngeal cancer (OPC) patients using computed tomography (CT)-based radiomic features for the first time.","Additionally, the proposed model was extended to perform time-to-event analyses, and compared with GNN and baseline linear models."],"url":"http://arxiv.org/abs/2310.02931v1"}
{"created":"2023-10-04 16:06:18","title":"Joint Network Lifetime Maximization and Relay Selection Design in Underwater Acoustic Sensor Networks","abstract":"The paper proposes a new approach to minimize the number of relays while maximizing the lifetime of underwater acoustic sensor networks (UASNs). This involves formulating the relay node placement (RNP) problem as a multi-objective optimization problem and employing the multi-objective lexico-graphic method (MOLM) to solve it. To achieve the optimal solution, the MOLM consists of two steps. First, the problem of lifetime maximization is tackled to find RNP solutions. This transforms the RNP into a non-convex optimization problem which is then converted into a convex programming equivalent. The proposed method has the same computational complexity as previous relay-node adjustment (RA) and difference convex algorithm (DCA) methods. The second step introduces a novel relay node selection to reach the optimal number of relays. Simulation results demonstrate that it has superior network lifetime and efficiency compared to RA and DCA.","sentences":["The paper proposes a new approach to minimize the number of relays while maximizing the lifetime of underwater acoustic sensor networks (UASNs).","This involves formulating the relay node placement (RNP) problem as a multi-objective optimization problem and employing the multi-objective lexico-graphic method (MOLM) to solve it.","To achieve the optimal solution, the MOLM consists of two steps.","First, the problem of lifetime maximization is tackled to find RNP solutions.","This transforms the RNP into a non-convex optimization problem which is then converted into a convex programming equivalent.","The proposed method has the same computational complexity as previous relay-node adjustment (RA) and difference convex algorithm (DCA) methods.","The second step introduces a novel relay node selection to reach the optimal number of relays.","Simulation results demonstrate that it has superior network lifetime and efficiency compared to RA and DCA."],"url":"http://arxiv.org/abs/2310.02927v1"}
{"created":"2023-10-04 16:05:48","title":"Extensions to the SENSEI In situ Framework for Heterogeneous Architectures","abstract":"The proliferation of GPUs and accelerators in recent supercomputing systems, so called heterogeneous architectures, has led to increased complexity in execution environments and programming models as well as to deeper memory hierarchies on these systems. In this work, we discuss challenges that arise in in situ code coupling on these heterogeneous architectures. In particular, we present data and execution model extensions to the SENSEI in situ framework that are targeted at the effective use of systems with heterogeneous architectures. We then use these new data and execution model extensions to investigate several in situ placement and execution configurations and to analyze the impact these choices have on overall performance.","sentences":["The proliferation of GPUs and accelerators in recent supercomputing systems, so called heterogeneous architectures, has led to increased complexity in execution environments and programming models as well as to deeper memory hierarchies on these systems.","In this work, we discuss challenges that arise in in situ code coupling on these heterogeneous architectures.","In particular, we present data and execution model extensions to the SENSEI in situ framework that are targeted at the effective use of systems with heterogeneous architectures.","We then use these new data and execution model extensions to investigate several in situ placement and execution configurations and to analyze the impact these choices have on overall performance."],"url":"http://arxiv.org/abs/2310.02926v1"}
{"created":"2023-10-04 16:05:36","title":"Optimal Transport with Adaptive Regularisation","abstract":"Regularising the primal formulation of optimal transport (OT) with a strictly convex term leads to enhanced numerical complexity and a denser transport plan. Many formulations impose a global constraint on the transport plan, for instance by relying on entropic regularisation. As it is more expensive to diffuse mass for outlier points compared to central ones, this typically results in a significant imbalance in the way mass is spread across the points. This can be detrimental for some applications where a minimum of smoothing is required per point. To remedy this, we introduce OT with Adaptive RegularIsation (OTARI), a new formulation of OT that imposes constraints on the mass going in or/and out of each point. We then showcase the benefits of this approach for domain adaptation.","sentences":["Regularising the primal formulation of optimal transport (OT) with a strictly convex term leads to enhanced numerical complexity and a denser transport plan.","Many formulations impose a global constraint on the transport plan, for instance by relying on entropic regularisation.","As it is more expensive to diffuse mass for outlier points compared to central ones, this typically results in a significant imbalance in the way mass is spread across the points.","This can be detrimental for some applications where a minimum of smoothing is required per point.","To remedy this, we introduce OT with Adaptive RegularIsation (OTARI), a new formulation of OT that imposes constraints on the mass going in or/and out of each point.","We then showcase the benefits of this approach for domain adaptation."],"url":"http://arxiv.org/abs/2310.02925v1"}
{"created":"2023-10-04 16:01:43","title":"Enhancing Ayurvedic Diagnosis using Multinomial Naive Bayes and K-modes Clustering: An Investigation into Prakriti Types and Dosha Overlapping","abstract":"The identification of Prakriti types for the human body is a long-lost medical practice in finding the harmony between the nature of human beings and their behaviour. There are 3 fundamental Prakriti types of individuals. A person can belong to any Dosha. In the existing models, researchers have made use of SVM, KNN, PCA, Decision Tree, and various other algorithms. The output of these algorithms was quite decent, but it can be enhanced with the help of Multinomial Naive Bayes and K-modes clustering. Most of the researchers have confined themselves to 3 basic classes. This might not be accurate in the real-world scenario, where overlapping might occur. Considering these, we have classified the Doshas into 7 categories, which includes overlapping of Doshas. These are namely, VATT-Dosha, PITT-Dosha, KAPH-Dosha, VATT-PITT-Dosha, PITT-KAPH-Dosha, KAPH-VATT-Dosha, and VATT-PITT-KAPH-Dosha. The data used contains a balanced set of all individual entries on which preprocessing steps of machine learning have been performed. Chi-Square test for handling categorical data is being used for feature selection. For model fitting, the method used in this approach is K-modes clustering. The empirical results demonstrate a better result while using the MNB classifier. All key findings of this work have achieved 0.90 accuracy, 0.81 precision, 0.91 F-score, and 0.90 recall. The discussion suggests a provident analysis of the seven clusters and predicts their occurrence. The results have been consolidated to improve the Ayurvedic advancements with machine learning.","sentences":["The identification of Prakriti types for the human body is a long-lost medical practice in finding the harmony between the nature of human beings and their behaviour.","There are 3 fundamental Prakriti types of individuals.","A person can belong to any Dosha.","In the existing models, researchers have made use of SVM, KNN, PCA, Decision Tree, and various other algorithms.","The output of these algorithms was quite decent, but it can be enhanced with the help of Multinomial Naive Bayes and K-modes clustering.","Most of the researchers have confined themselves to 3 basic classes.","This might not be accurate in the real-world scenario, where overlapping might occur.","Considering these, we have classified the Doshas into 7 categories, which includes overlapping of Doshas.","These are namely, VATT-Dosha, PITT-Dosha, KAPH-Dosha, VATT-PITT-Dosha, PITT-KAPH-Dosha, KAPH-VATT-Dosha, and VATT-PITT-KAPH-Dosha.","The data used contains a balanced set of all individual entries on which preprocessing steps of machine learning have been performed.","Chi-Square test for handling categorical data is being used for feature selection.","For model fitting, the method used in this approach is K-modes clustering.","The empirical results demonstrate a better result while using the MNB classifier.","All key findings of this work have achieved 0.90 accuracy, 0.81 precision, 0.91 F-score, and 0.90 recall.","The discussion suggests a provident analysis of the seven clusters and predicts their occurrence.","The results have been consolidated to improve the Ayurvedic advancements with machine learning."],"url":"http://arxiv.org/abs/2310.02920v1"}
{"created":"2023-10-04 16:01:06","title":"Attention-based Multi-task Learning for Base Editor Outcome Prediction","abstract":"Human genetic diseases often arise from point mutations, emphasizing the critical need for precise genome editing techniques. Among these, base editing stands out as it allows targeted alterations at the single nucleotide level. However, its clinical application is hindered by low editing efficiency and unintended mutations, necessitating extensive trial-and-error experimentation in the laboratory. To speed up this process, we present an attention-based two-stage machine learning model that learns to predict the likelihood of all possible editing outcomes for a given genomic target sequence. We further propose a multi-task learning schema to jointly learn multiple base editors (i.e. variants) at once. Our model's predictions consistently demonstrated a strong correlation with the actual experimental results on multiple datasets and base editor variants. These results provide further validation for the models' capacity to enhance and accelerate the process of refining base editing designs.","sentences":["Human genetic diseases often arise from point mutations, emphasizing the critical need for precise genome editing techniques.","Among these, base editing stands out as it allows targeted alterations at the single nucleotide level.","However, its clinical application is hindered by low editing efficiency and unintended mutations, necessitating extensive trial-and-error experimentation in the laboratory.","To speed up this process, we present an attention-based two-stage machine learning model that learns to predict the likelihood of all possible editing outcomes for a given genomic target sequence.","We further propose a multi-task learning schema to jointly learn multiple base editors (i.e. variants) at once.","Our model's predictions consistently demonstrated a strong correlation with the actual experimental results on multiple datasets and base editor variants.","These results provide further validation for the models' capacity to enhance and accelerate the process of refining base editing designs."],"url":"http://arxiv.org/abs/2310.02919v1"}
{"created":"2023-10-04 15:50:05","title":"ELUQuant: Event-Level Uncertainty Quantification in Deep Inelastic Scattering","abstract":"We introduce a physics-informed Bayesian Neural Network (BNN) with flow approximated posteriors using multiplicative normalizing flows (MNF) for detailed uncertainty quantification (UQ) at the physics event-level. Our method is capable of identifying both heteroskedastic aleatoric and epistemic uncertainties, providing granular physical insights. Applied to Deep Inelastic Scattering (DIS) events, our model effectively extracts the kinematic variables $x$, $Q^2$, and $y$, matching the performance of recent deep learning regression techniques but with the critical enhancement of event-level UQ. This detailed description of the underlying uncertainty proves invaluable for decision-making, especially in tasks like event filtering. It also allows for the reduction of true inaccuracies without directly accessing the ground truth. A thorough DIS simulation using the H1 detector at HERA indicates possible applications for the future EIC. Additionally, this paves the way for related tasks such as data quality monitoring and anomaly detection. Remarkably, our approach effectively processes large samples at high rates.","sentences":["We introduce a physics-informed Bayesian Neural Network (BNN) with flow approximated posteriors using multiplicative normalizing flows (MNF) for detailed uncertainty quantification (UQ) at the physics event-level.","Our method is capable of identifying both heteroskedastic aleatoric and epistemic uncertainties, providing granular physical insights.","Applied to Deep Inelastic Scattering (DIS) events, our model effectively extracts the kinematic variables $x$, $Q^2$, and $y$, matching the performance of recent deep learning regression techniques but with the critical enhancement of event-level UQ.","This detailed description of the underlying uncertainty proves invaluable for decision-making, especially in tasks like event filtering.","It also allows for the reduction of true inaccuracies without directly accessing the ground truth.","A thorough DIS simulation using the H1 detector at HERA indicates possible applications for the future EIC.","Additionally, this paves the way for related tasks such as data quality monitoring and anomaly detection.","Remarkably, our approach effectively processes large samples at high rates."],"url":"http://arxiv.org/abs/2310.02913v1"}
{"created":"2023-10-04 15:48:28","title":"Deciphering the Crypto-shopper: Knowledge and Preferences of Consumers Using Cryptocurrencies for Purchases","abstract":"The swiftly maturing sector of cryptocurrencies proffers an array of challenges and prospects for both enterprises and consumers. This study explores the knowledge, expertise, and purchasing behaviors of individuals engaged in shopping using cryptocurrencies to furnish an exhaustive understanding of this distinctive consumer cohort. By analyzing data from our survey of 516 participants, our findings illuminate a range of knowledge levels, encompassing neophytes to connoisseurs, with a significant segment exhibiting high procurement frequency amidst constrained expertise. Regression analyses unveil that, although knowledge significantly influences purchase behaviors, its explanatory capacity remains restricted. Additionally, a K-means cluster analysis discloses three disparate crypto-shopper profiles, each possessing unique knowledge and expertise levels. These insights contravene conventional wisdom regarding the nexus between domain knowledge and adoption, insinuating that the appeal of cryptocurrencies transcends technical knowledge. The revelations of this research are instrumental for enterprises aspiring to address the diverse needs of the crypto-shopper demographic, accentuating the imperative of personalized strategies and user experiences. This exploration furthermore lays the groundwork for ensuing research focused on unraveling the extensive implications of crypto acceptance and its confluence with consumer conduct.","sentences":["The swiftly maturing sector of cryptocurrencies proffers an array of challenges and prospects for both enterprises and consumers.","This study explores the knowledge, expertise, and purchasing behaviors of individuals engaged in shopping using cryptocurrencies to furnish an exhaustive understanding of this distinctive consumer cohort.","By analyzing data from our survey of 516 participants, our findings illuminate a range of knowledge levels, encompassing neophytes to connoisseurs, with a significant segment exhibiting high procurement frequency amidst constrained expertise.","Regression analyses unveil that, although knowledge significantly influences purchase behaviors, its explanatory capacity remains restricted.","Additionally, a K-means cluster analysis discloses three disparate crypto-shopper profiles, each possessing unique knowledge and expertise levels.","These insights contravene conventional wisdom regarding the nexus between domain knowledge and adoption, insinuating that the appeal of cryptocurrencies transcends technical knowledge.","The revelations of this research are instrumental for enterprises aspiring to address the diverse needs of the crypto-shopper demographic, accentuating the imperative of personalized strategies and user experiences.","This exploration furthermore lays the groundwork for ensuing research focused on unraveling the extensive implications of crypto acceptance and its confluence with consumer conduct."],"url":"http://arxiv.org/abs/2310.02911v1"}
{"created":"2023-10-04 15:45:16","title":"Whole-body MPC for highly redundant legged manipulators: experimental evaluation with a 37 DoF dual-arm quadruped","abstract":"Recent progress in legged locomotion has rendered quadruped manipulators a promising solution for performing tasks that require both mobility and manipulation (\\emph{loco-manipulation}). In the real world, task specifications and/or environment constraints may require the quadruped manipulator to be equipped with \\emph{high redundancy} as well as \\emph{whole-body} motion coordination capabilities. This work presents an experimental evaluation of a whole-body Model Predictive Control (MPC) framework achieving real-time performance on a dual-arm quadruped platform consisting of 37 actuated joints. To the best of our knowledge this is the legged manipulator with the highest number of joints to be controlled with real-time whole-body MPC so far. The computational efficiency of the MPC while considering the full robot kinematics and the centroidal dynamics model builds upon an open-source DDP-variant solver and a state-of-the-art optimal control problem formulation. Differently from previous works on quadruped manipulators, the MPC is directly interfaced with the low-level joint impedance controllers without the need of designing an instantaneous whole-body controller. The feasibility on the real hardware is showcased using the CENTAURO platform for the challenging task of picking a heavy object from the ground. Dynamic stepping (trotting) is also showcased for first time with this robot. The results highlight the potential of replanning with whole-body information in a predictive control loop.","sentences":["Recent progress in legged locomotion has rendered quadruped manipulators a promising solution for performing tasks that require both mobility and manipulation (\\emph{loco-manipulation}).","In the real world, task specifications and/or environment constraints may require the quadruped manipulator to be equipped with \\emph{high redundancy} as well as \\emph{whole-body} motion coordination capabilities.","This work presents an experimental evaluation of a whole-body Model Predictive Control (MPC) framework achieving real-time performance on a dual-arm quadruped platform consisting of 37 actuated joints.","To the best of our knowledge this is the legged manipulator with the highest number of joints to be controlled with real-time whole-body MPC so far.","The computational efficiency of the MPC while considering the full robot kinematics and the centroidal dynamics model builds upon an open-source DDP-variant solver and a state-of-the-art optimal control problem formulation.","Differently from previous works on quadruped manipulators, the MPC is directly interfaced with the low-level joint impedance controllers without the need of designing an instantaneous whole-body controller.","The feasibility on the real hardware is showcased using the CENTAURO platform for the challenging task of picking a heavy object from the ground.","Dynamic stepping (trotting) is also showcased for first time with this robot.","The results highlight the potential of replanning with whole-body information in a predictive control loop."],"url":"http://arxiv.org/abs/2310.02907v1"}
{"created":"2023-10-04 15:43:26","title":"Boosting Dermatoscopic Lesion Segmentation via Diffusion Models with Visual and Textual Prompts","abstract":"Image synthesis approaches, e.g., generative adversarial networks, have been popular as a form of data augmentation in medical image analysis tasks. It is primarily beneficial to overcome the shortage of publicly accessible data and associated quality annotations. However, the current techniques often lack control over the detailed contents in generated images, e.g., the type of disease patterns, the location of lesions, and attributes of the diagnosis. In this work, we adapt the latest advance in the generative model, i.e., the diffusion model, with the added control flow using lesion-specific visual and textual prompts for generating dermatoscopic images. We further demonstrate the advantage of our diffusion model-based framework over the classical generation models in both the image quality and boosting the segmentation performance on skin lesions. It can achieve a 9% increase in the SSIM image quality measure and an over 5% increase in Dice coefficients over the prior arts.","sentences":["Image synthesis approaches, e.g., generative adversarial networks, have been popular as a form of data augmentation in medical image analysis tasks.","It is primarily beneficial to overcome the shortage of publicly accessible data and associated quality annotations.","However, the current techniques often lack control over the detailed contents in generated images, e.g., the type of disease patterns, the location of lesions, and attributes of the diagnosis.","In this work, we adapt the latest advance in the generative model, i.e., the diffusion model, with the added control flow using lesion-specific visual and textual prompts for generating dermatoscopic images.","We further demonstrate the advantage of our diffusion model-based framework over the classical generation models in both the image quality and boosting the segmentation performance on skin lesions.","It can achieve a 9% increase in the SSIM image quality measure and an over 5% increase in Dice coefficients over the prior arts."],"url":"http://arxiv.org/abs/2310.02906v1"}
{"created":"2023-10-04 15:42:23","title":"FroSSL: Frobenius Norm Minimization for Self-Supervised Learning","abstract":"Self-supervised learning (SSL) is an increasingly popular paradigm for representation learning. Recent methods can be classified as sample-contrastive, dimension-contrastive, or asymmetric network-based, with each family having its own approach to avoiding informational collapse. While dimension-contrastive methods converge to similar solutions as sample-contrastive methods, it can be empirically shown that some methods require more epochs of training to converge. Motivated by closing this divide, we present the objective function FroSSL which is both sample- and dimension-contrastive up to embedding normalization. FroSSL works by minimizing covariance Frobenius norms for avoiding collapse and minimizing mean-squared error for augmentation invariance. We show that FroSSL converges more quickly than a variety of other SSL methods and provide theoretical and empirical support that this faster convergence is due to how FroSSL affects the eigenvalues of the embedding covariance matrices. We also show that FroSSL learns competitive representations on linear probe evaluation when used to train a ResNet18 on the CIFAR-10, CIFAR-100, STL-10, and ImageNet datasets.","sentences":["Self-supervised learning (SSL) is an increasingly popular paradigm for representation learning.","Recent methods can be classified as sample-contrastive, dimension-contrastive, or asymmetric network-based, with each family having its own approach to avoiding informational collapse.","While dimension-contrastive methods converge to similar solutions as sample-contrastive methods, it can be empirically shown that some methods require more epochs of training to converge.","Motivated by closing this divide, we present the objective function FroSSL which is both sample- and dimension-contrastive up to embedding normalization.","FroSSL works by minimizing covariance Frobenius norms for avoiding collapse and minimizing mean-squared error for augmentation invariance.","We show that FroSSL converges more quickly than a variety of other SSL methods and provide theoretical and empirical support that this faster convergence is due to how FroSSL affects the eigenvalues of the embedding covariance matrices.","We also show that FroSSL learns competitive representations on linear probe evaluation when used to train a ResNet18 on the CIFAR-10, CIFAR-100, STL-10, and ImageNet datasets."],"url":"http://arxiv.org/abs/2310.02903v1"}
{"created":"2023-10-04 15:40:07","title":"Searching for High-Value Molecules Using Reinforcement Learning and Transformers","abstract":"Reinforcement learning (RL) over text representations can be effective for finding high-value policies that can search over graphs. However, RL requires careful structuring of the search space and algorithm design to be effective in this challenge. Through extensive experiments, we explore how different design choices for text grammar and algorithmic choices for training can affect an RL policy's ability to generate molecules with desired properties. We arrive at a new RL-based molecular design algorithm (ChemRLformer) and perform a thorough analysis using 25 molecule design tasks, including computationally complex protein docking simulations. From this analysis, we discover unique insights in this problem space and show that ChemRLformer achieves state-of-the-art performance while being more straightforward than prior work by demystifying which design choices are actually helpful for text-based molecule design.","sentences":["Reinforcement learning (RL) over text representations can be effective for finding high-value policies that can search over graphs.","However, RL requires careful structuring of the search space and algorithm design to be effective in this challenge.","Through extensive experiments, we explore how different design choices for text grammar and algorithmic choices for training can affect an RL policy's ability to generate molecules with desired properties.","We arrive at a new RL-based molecular design algorithm (ChemRLformer) and perform a thorough analysis using 25 molecule design tasks, including computationally complex protein docking simulations.","From this analysis, we discover unique insights in this problem space and show that ChemRLformer achieves state-of-the-art performance while being more straightforward than prior work by demystifying which design choices are actually helpful for text-based molecule design."],"url":"http://arxiv.org/abs/2310.02902v1"}
{"created":"2023-10-04 15:39:57","title":"Computationally Efficient Quadratic Neural Networks","abstract":"Higher order artificial neurons whose outputs are computed by applying an activation function to a higher order multinomial function of the inputs have been considered in the past, but did not gain acceptance due to the extra parameters and computational cost. However, higher order neurons have significantly greater learning capabilities since the decision boundaries of higher order neurons can be complex surfaces instead of just hyperplanes. The boundary of a single quadratic neuron can be a general hyper-quadric surface allowing it to learn many nonlinearly separable datasets. Since quadratic forms can be represented by symmetric matrices, only $\\frac{n(n+1)}{2}$ additional parameters are needed instead of $n^2$. A quadratic Logistic regression model is first presented. Solutions to the XOR problem with a single quadratic neuron are considered. The complete vectorized equations for both forward and backward propagation in feedforward networks composed of quadratic neurons are derived. A reduced parameter quadratic neural network model with just $ n $ additional parameters per neuron that provides a compromise between learning ability and computational cost is presented. Comparison on benchmark classification datasets are used to demonstrate that a final layer of quadratic neurons enables networks to achieve higher accuracy with significantly fewer hidden layer neurons. In particular this paper shows that any dataset composed of $C$ bounded clusters can be separated with only a single layer of $C$ quadratic neurons.","sentences":["Higher order artificial neurons whose outputs are computed by applying an activation function to a higher order multinomial function of the inputs have been considered in the past, but did not gain acceptance due to the extra parameters and computational cost.","However, higher order neurons have significantly greater learning capabilities since the decision boundaries of higher order neurons can be complex surfaces instead of just hyperplanes.","The boundary of a single quadratic neuron can be a general hyper-quadric surface allowing it to learn many nonlinearly separable datasets.","Since quadratic forms can be represented by symmetric matrices, only $\\frac{n(n+1)}{2}$ additional parameters are needed instead of $n^2$. A quadratic Logistic regression model is first presented.","Solutions to the XOR problem with a single quadratic neuron are considered.","The complete vectorized equations for both forward and backward propagation in feedforward networks composed of quadratic neurons are derived.","A reduced parameter quadratic neural network model with just $ n $ additional parameters per neuron that provides a compromise between learning ability and computational cost is presented.","Comparison on benchmark classification datasets are used to demonstrate that a final layer of quadratic neurons enables networks to achieve higher accuracy with significantly fewer hidden layer neurons.","In particular this paper shows that any dataset composed of $C$ bounded clusters can be separated with only a single layer of $C$ quadratic neurons."],"url":"http://arxiv.org/abs/2310.02901v1"}
{"created":"2023-10-04 15:37:03","title":"Some bidding games converging to their unique pure equilibrium","abstract":"We introduce a class of Bayesian bidding games for which we prove that the set of pure Nash equilibria is a (non-empty) sublattice and we give a sufficient condition for uniqueness that is often verified in the context of markets with inelastic demand. We propose a dynamic that converges to the extrema of the equilibrium set and derive a scheme to compute the extreme Nash equilibria.","sentences":["We introduce a class of Bayesian bidding games for which we prove that the set of pure Nash equilibria is a (non-empty) sublattice and we give a sufficient condition for uniqueness that is often verified in the context of markets with inelastic demand.","We propose a dynamic that converges to the extrema of the equilibrium set and derive a scheme to compute the extreme Nash equilibria."],"url":"http://arxiv.org/abs/2310.02898v1"}
{"created":"2023-10-04 15:36:33","title":"Recovery of Training Data from Overparameterized Autoencoders: An Inverse Problem Perspective","abstract":"We study the recovery of training data from overparameterized autoencoder models. Given a degraded training sample, we define the recovery of the original sample as an inverse problem and formulate it as an optimization task. In our inverse problem, we use the trained autoencoder to implicitly define a regularizer for the particular training dataset that we aim to retrieve from. We develop the intricate optimization task into a practical method that iteratively applies the trained autoencoder and relatively simple computations that estimate and address the unknown degradation operator. We evaluate our method for blind inpainting where the goal is to recover training images from degradation of many missing pixels in an unknown pattern. We examine various deep autoencoder architectures, such as fully connected and U-Net (with various nonlinearities and at diverse train loss values), and show that our method significantly outperforms previous methods for training data recovery from autoencoders. Importantly, our method greatly improves the recovery performance also in settings that were previously considered highly challenging, and even impractical, for such retrieval.","sentences":["We study the recovery of training data from overparameterized autoencoder models.","Given a degraded training sample, we define the recovery of the original sample as an inverse problem and formulate it as an optimization task.","In our inverse problem, we use the trained autoencoder to implicitly define a regularizer for the particular training dataset that we aim to retrieve from.","We develop the intricate optimization task into a practical method that iteratively applies the trained autoencoder and relatively simple computations that estimate and address the unknown degradation operator.","We evaluate our method for blind inpainting where the goal is to recover training images from degradation of many missing pixels in an unknown pattern.","We examine various deep autoencoder architectures, such as fully connected and U-Net (with various nonlinearities and at diverse train loss values), and show that our method significantly outperforms previous methods for training data recovery from autoencoders.","Importantly, our method greatly improves the recovery performance also in settings that were previously considered highly challenging, and even impractical, for such retrieval."],"url":"http://arxiv.org/abs/2310.02897v1"}
{"created":"2023-10-04 15:32:27","title":"CoLiDE: Concomitant Linear DAG Estimation","abstract":"We deal with the combinatorial problem of learning directed acyclic graph (DAG) structure from observational data adhering to a linear structural equation model (SEM). Leveraging advances in differentiable, nonconvex characterizations of acyclicity, recent efforts have advocated a continuous constrained optimization paradigm to efficiently explore the space of DAGs. Most existing methods employ lasso-type score functions to guide this search, which (i) require expensive penalty parameter retuning when the $\\textit{unknown}$ SEM noise variances change across problem instances; and (ii) implicitly rely on limiting homoscedasticity assumptions. In this work, we propose a new convex score function for sparsity-aware learning of linear DAGs, which incorporates concomitant estimation of scale and thus effectively decouples the sparsity parameter from the exogenous noise levels. Regularization via a smooth, nonconvex acyclicity penalty term yields CoLiDE ($\\textbf{Co}$ncomitant $\\textbf{Li}$near $\\textbf{D}$AG $\\textbf{E}$stimation), a regression-based criterion amenable to efficient gradient computation and closed-form estimation of noise variances in heteroscedastic scenarios. Our algorithm outperforms state-of-the-art methods without incurring added complexity, especially when the DAGs are larger and the noise level profile is heterogeneous. We also find CoLiDE exhibits enhanced stability manifested via reduced standard deviations in several domain-specific metrics, underscoring the robustness of our novel linear DAG estimator.","sentences":["We deal with the combinatorial problem of learning directed acyclic graph (DAG) structure from observational data adhering to a linear structural equation model (SEM).","Leveraging advances in differentiable, nonconvex characterizations of acyclicity, recent efforts have advocated a continuous constrained optimization paradigm to efficiently explore the space of DAGs.","Most existing methods employ lasso-type score functions to guide this search, which (i) require expensive penalty parameter retuning when the $\\textit{unknown}$ SEM noise variances change across problem instances; and (ii) implicitly rely on limiting homoscedasticity assumptions.","In this work, we propose a new convex score function for sparsity-aware learning of linear DAGs, which incorporates concomitant estimation of scale and thus effectively decouples the sparsity parameter from the exogenous noise levels.","Regularization via a smooth, nonconvex acyclicity penalty term yields CoLiDE ($\\textbf{Co}$ncomitant $\\textbf{Li}$near $\\textbf{D}$AG $\\textbf{E}$stimation), a regression-based criterion amenable to efficient gradient computation and closed-form estimation of noise variances in heteroscedastic scenarios.","Our algorithm outperforms state-of-the-art methods without incurring added complexity, especially when the DAGs are larger and the noise level profile is heterogeneous.","We also find CoLiDE exhibits enhanced stability manifested via reduced standard deviations in several domain-specific metrics, underscoring the robustness of our novel linear DAG estimator."],"url":"http://arxiv.org/abs/2310.02895v1"}
{"created":"2023-10-04 15:31:02","title":"Human-centric Behavior Description in Videos: New Benchmark and Model","abstract":"In the domain of video surveillance, describing the behavior of each individual within the video is becoming increasingly essential, especially in complex scenarios with multiple individuals present. This is because describing each individual's behavior provides more detailed situational analysis, enabling accurate assessment and response to potential risks, ensuring the safety and harmony of public places. Currently, video-level captioning datasets cannot provide fine-grained descriptions for each individual's specific behavior. However, mere descriptions at the video-level fail to provide an in-depth interpretation of individual behaviors, making it challenging to accurately determine the specific identity of each individual. To address this challenge, we construct a human-centric video surveillance captioning dataset, which provides detailed descriptions of the dynamic behaviors of 7,820 individuals. Specifically, we have labeled several aspects of each person, such as location, clothing, and interactions with other elements in the scene, and these people are distributed across 1,012 videos. Based on this dataset, we can link individuals to their respective behaviors, allowing for further analysis of each person's behavior in surveillance videos. Besides the dataset, we propose a novel video captioning approach that can describe individual behavior in detail on a person-level basis, achieving state-of-the-art results. To facilitate further research in this field, we intend to release our dataset and code.","sentences":["In the domain of video surveillance, describing the behavior of each individual within the video is becoming increasingly essential, especially in complex scenarios with multiple individuals present.","This is because describing each individual's behavior provides more detailed situational analysis, enabling accurate assessment and response to potential risks, ensuring the safety and harmony of public places.","Currently, video-level captioning datasets cannot provide fine-grained descriptions for each individual's specific behavior.","However, mere descriptions at the video-level fail to provide an in-depth interpretation of individual behaviors, making it challenging to accurately determine the specific identity of each individual.","To address this challenge, we construct a human-centric video surveillance captioning dataset, which provides detailed descriptions of the dynamic behaviors of 7,820 individuals.","Specifically, we have labeled several aspects of each person, such as location, clothing, and interactions with other elements in the scene, and these people are distributed across 1,012 videos.","Based on this dataset, we can link individuals to their respective behaviors, allowing for further analysis of each person's behavior in surveillance videos.","Besides the dataset, we propose a novel video captioning approach that can describe individual behavior in detail on a person-level basis, achieving state-of-the-art results.","To facilitate further research in this field, we intend to release our dataset and code."],"url":"http://arxiv.org/abs/2310.02894v1"}
{"created":"2023-10-04 15:24:00","title":"A Grammatical Compositional Model for Video Action Detection","abstract":"Analysis of human actions in videos demands understanding complex human dynamics, as well as the interaction between actors and context. However, these interaction relationships usually exhibit large intra-class variations from diverse human poses or object manipulations, and fine-grained inter-class differences between similar actions. Thus the performance of existing methods is severely limited. Motivated by the observation that interactive actions can be decomposed into actor dynamics and participating objects or humans, we propose to investigate the composite property of them. In this paper, we present a novel Grammatical Compositional Model (GCM) for action detection based on typical And-Or graphs. Our model exploits the intrinsic structures and latent relationships of actions in a hierarchical manner to harness both the compositionality of grammar models and the capability of expressing rich features of DNNs. The proposed model can be readily embodied into a neural network module for efficient optimization in an end-to-end manner. Extensive experiments are conducted on the AVA dataset and the Something-Else task to demonstrate the superiority of our model, meanwhile the interpretability is enhanced through an inference parsing procedure.","sentences":["Analysis of human actions in videos demands understanding complex human dynamics, as well as the interaction between actors and context.","However, these interaction relationships usually exhibit large intra-class variations from diverse human poses or object manipulations, and fine-grained inter-class differences between similar actions.","Thus the performance of existing methods is severely limited.","Motivated by the observation that interactive actions can be decomposed into actor dynamics and participating objects or humans, we propose to investigate the composite property of them.","In this paper, we present a novel Grammatical Compositional Model (GCM) for action detection based on typical And-Or graphs.","Our model exploits the intrinsic structures and latent relationships of actions in a hierarchical manner to harness both the compositionality of grammar models and the capability of expressing rich features of DNNs.","The proposed model can be readily embodied into a neural network module for efficient optimization in an end-to-end manner.","Extensive experiments are conducted on the AVA dataset and the Something-Else task to demonstrate the superiority of our model, meanwhile the interpretability is enhanced through an inference parsing procedure."],"url":"http://arxiv.org/abs/2310.02887v1"}
{"created":"2023-10-04 15:21:54","title":"Something for (almost) nothing: Improving deep ensemble calibration using unlabeled data","abstract":"We present a method to improve the calibration of deep ensembles in the small training data regime in the presence of unlabeled data. Our approach is extremely simple to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member. We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that if we fit such a labeling on unlabeled data, and the true labels on the training data, we obtain low negative log-likelihood and high ensemble diversity on testing samples. Empirically, through detailed experiments, we find that for low to moderately-sized training sets, our ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly.","sentences":["We present a method to improve the calibration of deep ensembles in the small training data regime in the presence of unlabeled data.","Our approach is extremely simple to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member.","We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that if we fit such a labeling on unlabeled data, and the true labels on the training data, we obtain low negative log-likelihood and high ensemble diversity on testing samples.","Empirically, through detailed experiments, we find that for low to moderately-sized training sets, our ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly."],"url":"http://arxiv.org/abs/2310.02885v1"}
{"created":"2023-10-04 15:17:41","title":"Streaming Euclidean $k$-median and $k$-means with $o(\\log n)$ Space","abstract":"We consider the classic Euclidean $k$-median and $k$-means objective on data streams, where the goal is to provide a $(1+\\varepsilon)$-approximation to the optimal $k$-median or $k$-means solution, while using as little memory as possible. Over the last 20 years, clustering in data streams has received a tremendous amount of attention and has been the test-bed for a large variety of new techniques, including coresets, the merge-and-reduce framework, bicriteria approximation, sensitivity sampling, and so on. Despite this intense effort to obtain smaller sketches for these problems, all known techniques require storing at least $\\Omega(\\log(n\\Delta))$ words of memory, where $n$ is the size of the input and $\\Delta$ is the aspect ratio. A natural question is if one can beat this logarithmic dependence on $n$ and $\\Delta$. In this paper, we break this barrier by first giving an insertion-only streaming algorithm that achieves a $(1+\\varepsilon)$-approximation to the more general $(k,z)$-clustering problem, using $\\tilde{\\mathcal{O}}\\left(\\frac{dk}{\\varepsilon^2}\\right)\\cdot(2^{z\\log z})\\cdot\\min\\left(\\frac{1}{\\varepsilon^z},k\\right)\\cdot\\text{poly}(\\log\\log(n\\Delta))$ words of memory. Our techniques can also be used to achieve two-pass algorithms for $k$-median and $k$-means clustering on dynamic streams using $\\tilde{\\mathcal{O}}\\left(\\frac{1}{\\varepsilon^2}\\right)\\cdot\\text{poly}(d,k,\\log\\log(n\\Delta))$ words of memory.","sentences":["We consider the classic Euclidean $k$-median and $k$-means objective on data streams, where the goal is to provide a $(1+\\varepsilon)$-approximation to the optimal $k$-median or $k$-means solution, while using as little memory as possible.","Over the last 20 years, clustering in data streams has received a tremendous amount of attention and has been the test-bed for a large variety of new techniques, including coresets, the merge-and-reduce framework, bicriteria approximation, sensitivity sampling, and so on.","Despite this intense effort to obtain smaller sketches for these problems, all known techniques require storing at least $\\Omega(\\log(n\\Delta))$ words of memory, where $n$ is the size of the input and $\\Delta$ is the aspect ratio.","A natural question is if one can beat this logarithmic dependence on $n$ and $\\Delta$. In this paper, we break this barrier by first giving an insertion-only streaming algorithm that achieves a $(1+\\varepsilon)$-approximation to the more general $(k,z)$-clustering problem, using $\\tilde{\\mathcal{O}}\\left(\\frac{dk}{\\varepsilon^2}\\right)\\cdot(2^{z\\log z})\\cdot\\min\\left(\\frac{1}{\\varepsilon^z},k\\right)\\cdot\\text{poly}(\\log\\log(n\\Delta))$ words of memory.","Our techniques can also be used to achieve two-pass algorithms for $k$-median and $k$-means clustering on dynamic streams using $\\tilde{\\mathcal{O}}\\left(\\frac{1}{\\varepsilon^2}\\right)\\cdot\\text{poly}(d,k,\\log\\log(n\\Delta))$ words of memory."],"url":"http://arxiv.org/abs/2310.02882v1"}
{"created":"2023-10-04 15:17:36","title":"Immersive ExaBrick: Visualizing Large AMR Data in the CAVE","abstract":"Rendering large adaptive mesh refinement (AMR) data in real-time in virtual reality (VR) environments is a complex challenge that demands sophisticated techniques and tools. The proposed solution harnesses the ExaBrick framework and integrates it as a plugin in COVISE, a robust visualization system equipped with the VR-centric OpenCOVER render module. This setup enables direct navigation and interaction within the rendered volume in a VR environment. The user interface incorporates rendering options and functions, ensuring a smooth and interactive experience. We show that high-quality volume rendering of AMR data in VR environments at interactive rates is possible using GPUs.","sentences":["Rendering large adaptive mesh refinement (AMR) data in real-time in virtual reality (VR) environments is a complex challenge that demands sophisticated techniques and tools.","The proposed solution harnesses the ExaBrick framework and integrates it as a plugin in COVISE, a robust visualization system equipped with the VR-centric OpenCOVER render module.","This setup enables direct navigation and interaction within the rendered volume in a VR environment.","The user interface incorporates rendering options and functions, ensuring a smooth and interactive experience.","We show that high-quality volume rendering of AMR data in VR environments at interactive rates is possible using GPUs."],"url":"http://arxiv.org/abs/2310.02881v1"}
{"created":"2023-10-04 15:17:30","title":"Persistent Memory File Systems: A Survey","abstract":"Persistent Memory (PM) is non-volatile byte-addressable memory that offers read and write latencies in the order of magnitude smaller than flash storage, such as SSDs. This survey discusses how file systems address the most prominent challenges in the implementation of file systems for Persistent Memory. First, we discuss how the properties of Persistent Memory change file system design. Second, we discuss work that aims to optimize small file I/O and the associated meta-data resolution. Third, we address how existing Persistent Memory file systems achieve (meta) data persistence and consistency.","sentences":["Persistent Memory (PM) is non-volatile byte-addressable memory that offers read and write latencies in the order of magnitude smaller than flash storage, such as SSDs.","This survey discusses how file systems address the most prominent challenges in the implementation of file systems for Persistent Memory.","First, we discuss how the properties of Persistent Memory change file system design.","Second, we discuss work that aims to optimize small file I/O and the associated meta-data resolution.","Third, we address how existing Persistent Memory file systems achieve (meta) data persistence and consistency."],"url":"http://arxiv.org/abs/2310.02880v1"}
{"created":"2023-10-04 15:17:28","title":"Online Mechanism Design with Predictions","abstract":"Aiming to overcome some of the limitations of worst-case analysis, the recently proposed framework of \"algorithms with predictions\" allows algorithms to be augmented with a (possibly erroneous) machine-learned prediction that they can use as a guide. In this framework, the goal is to obtain improved guarantees when the prediction is correct, which is called \\emph{consistency}, while simultaneously guaranteeing some worst-case bounds even when the prediction is arbitrarily wrong, which is called \\emph{robustness}. The vast majority of the work on this framework has focused on a refined analysis of online algorithms augmented with predictions regarding the future input. A subsequent line of work has also successfully adapted this framework to mechanism design, where the prediction is regarding the private information of strategic agents. In this paper, we initiate the study of online mechanism design with predictions, which combines the challenges of online algorithms with predictions and mechanism design with predictions.   We consider the well-studied problem of designing a revenue-maximizing auction to sell a single item to strategic bidders who arrive and depart over time, each with an unknown, private, value for the item. We study the learning-augmented version of this problem where the auction designer is given a prediction regarding the maximum value over all agents. Our main result is a strategyproof mechanism whose revenue guarantees are $\\alpha$-consistent with respect to the highest value and $(1-\\alpha^2)/4$-robust with respect to the second-highest value, for $\\alpha \\in [0,1]$. We show that this tradeoff is optimal within a broad and natural family of auctions, meaning that any $\\alpha$-consistent mechanism in that family has robustness at most $(1-\\alpha^2)/4$. Finally, we extend our mechanism to also achieve expected revenues proportional to the prediction quality.","sentences":["Aiming to overcome some of the limitations of worst-case analysis, the recently proposed framework of \"algorithms with predictions\" allows algorithms to be augmented with a (possibly erroneous) machine-learned prediction that they can use as a guide.","In this framework, the goal is to obtain improved guarantees when the prediction is correct, which is called \\emph{consistency}, while simultaneously guaranteeing some worst-case bounds even when the prediction is arbitrarily wrong, which is called \\emph{robustness}.","The vast majority of the work on this framework has focused on a refined analysis of online algorithms augmented with predictions regarding the future input.","A subsequent line of work has also successfully adapted this framework to mechanism design, where the prediction is regarding the private information of strategic agents.","In this paper, we initiate the study of online mechanism design with predictions, which combines the challenges of online algorithms with predictions and mechanism design with predictions.   ","We consider the well-studied problem of designing a revenue-maximizing auction to sell a single item to strategic bidders who arrive and depart over time, each with an unknown, private, value for the item.","We study the learning-augmented version of this problem where the auction designer is given a prediction regarding the maximum value over all agents.","Our main result is a strategyproof mechanism whose revenue guarantees are $\\alpha$-consistent with respect to the highest value and $(1-\\alpha^2)/4$-robust with respect to the second-highest value, for $\\alpha \\in [0,1]$. We show that this tradeoff is optimal within a broad and natural family of auctions, meaning that any $\\alpha$-consistent mechanism in that family has robustness at most $(1-\\alpha^2)/4$. Finally, we extend our mechanism to also achieve expected revenues proportional to the prediction quality."],"url":"http://arxiv.org/abs/2310.02879v1"}
{"created":"2023-10-04 15:10:06","title":"Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation","abstract":"A growing body of work has focused on text classification methods for detecting the increasing amount of hate speech posted online. This progress has been limited to only a select number of highly-resourced languages causing detection systems to either under-perform or not exist in limited data contexts. This is majorly caused by a lack of training data which is expensive to collect and curate in these settings. In this work, we propose a data augmentation approach that addresses the problem of lack of data for online hate speech detection in limited data contexts using synthetic data generation techniques. Given a handful of hate speech examples in a high-resource language such as English, we present three methods to synthesize new examples of hate speech data in a target language that retains the hate sentiment in the original examples but transfers the hate targets. We apply our approach to generate training data for hate speech classification tasks in Hindi and Vietnamese. Our findings show that a model trained on synthetic data performs comparably to, and in some cases outperforms, a model trained only on the samples available in the target domain. This method can be adopted to bootstrap hate speech detection models from scratch in limited data contexts. As the growth of social media within these contexts continues to outstrip response efforts, this work furthers our capacities for detection, understanding, and response to hate speech.","sentences":["A growing body of work has focused on text classification methods for detecting the increasing amount of hate speech posted online.","This progress has been limited to only a select number of highly-resourced languages causing detection systems to either under-perform or not exist in limited data contexts.","This is majorly caused by a lack of training data which is expensive to collect and curate in these settings.","In this work, we propose a data augmentation approach that addresses the problem of lack of data for online hate speech detection in limited data contexts using synthetic data generation techniques.","Given a handful of hate speech examples in a high-resource language such as English, we present three methods to synthesize new examples of hate speech data in a target language that retains the hate sentiment in the original examples but transfers the hate targets.","We apply our approach to generate training data for hate speech classification tasks in Hindi and Vietnamese.","Our findings show that a model trained on synthetic data performs comparably to, and in some cases outperforms, a model trained only on the samples available in the target domain.","This method can be adopted to bootstrap hate speech detection models from scratch in limited data contexts.","As the growth of social media within these contexts continues to outstrip response efforts, this work furthers our capacities for detection, understanding, and response to hate speech."],"url":"http://arxiv.org/abs/2310.02876v1"}
{"created":"2023-10-04 15:09:44","title":"Approximating Robot Configuration Spaces with few Convex Sets using Clique Covers of Visibility Graphs","abstract":"Many computations in robotics can be dramatically accelerated if the robot configuration space is described as a collection of simple sets. For example, recently developed motion planners rely on a convex decomposition of the free space to design collision-free trajectories using fast convex optimization. In this work, we present an efficient method for approximately covering complex configuration spaces with a small number of polytopes. The approach constructs a visibility graph using sampling and generates a clique cover of this graph to find clusters of samples that have mutual line of sight. These clusters are then inflated into large, full-dimensional, polytopes. We evaluate our method on a variety of robotic systems and show that it consistently covers larger portions of free configuration space, with fewer polytopes, and in a fraction of the time compared to previous methods.","sentences":["Many computations in robotics can be dramatically accelerated if the robot configuration space is described as a collection of simple sets.","For example, recently developed motion planners rely on a convex decomposition of the free space to design collision-free trajectories using fast convex optimization.","In this work, we present an efficient method for approximately covering complex configuration spaces with a small number of polytopes.","The approach constructs a visibility graph using sampling and generates a clique cover of this graph to find clusters of samples that have mutual line of sight.","These clusters are then inflated into large, full-dimensional, polytopes.","We evaluate our method on a variety of robotic systems and show that it consistently covers larger portions of free configuration space, with fewer polytopes, and in a fraction of the time compared to previous methods."],"url":"http://arxiv.org/abs/2310.02875v1"}
{"created":"2023-10-04 15:09:40","title":"Recent Methodological Advances in Federated Learning for Healthcare","abstract":"For healthcare datasets, it is often not possible to combine data samples from multiple sites due to ethical, privacy or logistical concerns. Federated learning allows for the utilisation of powerful machine learning algorithms without requiring the pooling of data. Healthcare data has many simultaneous challenges which require new methodologies to address, such as highly-siloed data, class imbalance, missing data, distribution shifts and non-standardised variables. Federated learning adds significant methodological complexity to conventional centralised machine learning, requiring distributed optimisation, communication between nodes, aggregation of models and redistribution of models. In this systematic review, we consider all papers on Scopus that were published between January 2015 and February 2023 and which describe new federated learning methodologies for addressing challenges with healthcare data. We performed a detailed review of the 89 papers which fulfilled these criteria. Significant systemic issues were identified throughout the literature which compromise the methodologies in many of the papers reviewed. We give detailed recommendations to help improve the quality of the methodology development for federated learning in healthcare.","sentences":["For healthcare datasets, it is often not possible to combine data samples from multiple sites due to ethical, privacy or logistical concerns.","Federated learning allows for the utilisation of powerful machine learning algorithms without requiring the pooling of data.","Healthcare data has many simultaneous challenges which require new methodologies to address, such as highly-siloed data, class imbalance, missing data, distribution shifts and non-standardised variables.","Federated learning adds significant methodological complexity to conventional centralised machine learning, requiring distributed optimisation, communication between nodes, aggregation of models and redistribution of models.","In this systematic review, we consider all papers on Scopus that were published between January 2015 and February 2023 and which describe new federated learning methodologies for addressing challenges with healthcare data.","We performed a detailed review of the 89 papers which fulfilled these criteria.","Significant systemic issues were identified throughout the literature which compromise the methodologies in many of the papers reviewed.","We give detailed recommendations to help improve the quality of the methodology development for federated learning in healthcare."],"url":"http://arxiv.org/abs/2310.02874v1"}
{"created":"2023-10-04 15:04:13","title":"Stable and Interpretable Deep Learning for Tabular Data: Introducing InterpreTabNet with the Novel InterpreStability Metric","abstract":"As Artificial Intelligence (AI) integrates deeper into diverse sectors, the quest for powerful models has intensified. While significant strides have been made in boosting model capabilities and their applicability across domains, a glaring challenge persists: many of these state-of-the-art models remain as black boxes. This opacity not only complicates the explanation of model decisions to end-users but also obstructs insights into intermediate processes for model designers. To address these challenges, we introduce InterpreTabNet, a model designed to enhance both classification accuracy and interpretability by leveraging the TabNet architecture with an improved attentive module. This design ensures robust gradient propagation and computational stability. Additionally, we present a novel evaluation metric, InterpreStability, which quantifies the stability of a model's interpretability. The proposed model and metric mark a significant stride forward in explainable models' research, setting a standard for transparency and interpretability in AI model design and application across diverse sectors. InterpreTabNet surpasses other leading solutions in tabular data analysis across varied application scenarios, paving the way for further research into creating deep-learning models that are both highly accurate and inherently explainable. The introduction of the InterpreStability metric ensures that the interpretability of future models can be measured and compared in a consistent and rigorous manner. Collectively, these contributions have the potential to promote the design principles and development of next-generation interpretable AI models, widening the adoption of interpretable AI solutions in critical decision-making environments.","sentences":["As Artificial Intelligence (AI) integrates deeper into diverse sectors, the quest for powerful models has intensified.","While significant strides have been made in boosting model capabilities and their applicability across domains, a glaring challenge persists: many of these state-of-the-art models remain as black boxes.","This opacity not only complicates the explanation of model decisions to end-users but also obstructs insights into intermediate processes for model designers.","To address these challenges, we introduce InterpreTabNet, a model designed to enhance both classification accuracy and interpretability by leveraging the TabNet architecture with an improved attentive module.","This design ensures robust gradient propagation and computational stability.","Additionally, we present a novel evaluation metric, InterpreStability, which quantifies the stability of a model's interpretability.","The proposed model and metric mark a significant stride forward in explainable models' research, setting a standard for transparency and interpretability in AI model design and application across diverse sectors.","InterpreTabNet surpasses other leading solutions in tabular data analysis across varied application scenarios, paving the way for further research into creating deep-learning models that are both highly accurate and inherently explainable.","The introduction of the InterpreStability metric ensures that the interpretability of future models can be measured and compared in a consistent and rigorous manner.","Collectively, these contributions have the potential to promote the design principles and development of next-generation interpretable AI models, widening the adoption of interpretable AI solutions in critical decision-making environments."],"url":"http://arxiv.org/abs/2310.02870v1"}
{"created":"2023-10-04 14:54:34","title":"Estimation of Models with Limited Data by Leveraging Shared Structure","abstract":"Modern data sets, such as those in healthcare and e-commerce, are often derived from many individuals or systems but have insufficient data from each source alone to separately estimate individual, often high-dimensional, model parameters. If there is shared structure among systems however, it may be possible to leverage data from other systems to help estimate individual parameters, which could otherwise be non-identifiable. In this paper, we assume systems share a latent low-dimensional parameter space and propose a method for recovering $d$-dimensional parameters for $N$ different linear systems, even when there are only $T<d$ observations per system. To do so, we develop a three-step algorithm which estimates the low-dimensional subspace spanned by the systems' parameters and produces refined parameter estimates within the subspace. We provide finite sample subspace estimation error guarantees for our proposed method. Finally, we experimentally validate our method on simulations with i.i.d. regression data and as well as correlated time series data.","sentences":["Modern data sets, such as those in healthcare and e-commerce, are often derived from many individuals or systems but have insufficient data from each source alone to separately estimate individual, often high-dimensional, model parameters.","If there is shared structure among systems however, it may be possible to leverage data from other systems to help estimate individual parameters, which could otherwise be non-identifiable.","In this paper, we assume systems share a latent low-dimensional parameter space and propose a method for recovering $d$-dimensional parameters for $N$ different linear systems, even when there are only $T<d$ observations per system.","To do so, we develop a three-step algorithm which estimates the low-dimensional subspace spanned by the systems' parameters and produces refined parameter estimates within the subspace.","We provide finite sample subspace estimation error guarantees for our proposed method.","Finally, we experimentally validate our method on simulations with i.i.d. regression data and as well as correlated time series data."],"url":"http://arxiv.org/abs/2310.02864v1"}
{"created":"2023-10-04 14:50:58","title":"A novel asymmetrical autoencoder with a sparsifying discrete cosine Stockwell transform layer for gearbox sensor data compression","abstract":"The lack of an efficient compression model remains a challenge for the wireless transmission of gearbox data in non-contact gear fault diagnosis problems. In this paper, we present a signal-adaptive asymmetrical autoencoder with a transform domain layer to compress sensor signals. First, a new discrete cosine Stockwell transform (DCST) layer is introduced to replace linear layers in a multi-layer autoencoder. A trainable filter is implemented in the DCST domain by utilizing the multiplication property of the convolution. A trainable hard-thresholding layer is applied to reduce redundant data in the DCST layer to make the feature map sparse. In comparison to the linear layer, the DCST layer reduces the number of trainable parameters and improves the accuracy of data reconstruction. Second, training the autoencoder with a sparsifying DCST layer only requires a small number of datasets. The proposed method is superior to other autoencoder-based methods on the University of Connecticut (UoC) and Southeast University (SEU) gearbox datasets, as the average quality score is improved by 2.00% at the lowest and 32.35% at the highest with a limited number of training samples","sentences":["The lack of an efficient compression model remains a challenge for the wireless transmission of gearbox data in non-contact gear fault diagnosis problems.","In this paper, we present a signal-adaptive asymmetrical autoencoder with a transform domain layer to compress sensor signals.","First, a new discrete cosine Stockwell transform (DCST) layer is introduced to replace linear layers in a multi-layer autoencoder.","A trainable filter is implemented in the DCST domain by utilizing the multiplication property of the convolution.","A trainable hard-thresholding layer is applied to reduce redundant data in the DCST layer to make the feature map sparse.","In comparison to the linear layer, the DCST layer reduces the number of trainable parameters and improves the accuracy of data reconstruction.","Second, training the autoencoder with a sparsifying DCST layer only requires a small number of datasets.","The proposed method is superior to other autoencoder-based methods on the University of Connecticut (UoC) and Southeast University (SEU) gearbox datasets, as the average quality score is improved by 2.00% at the lowest and 32.35% at the highest with a limited number of training samples"],"url":"http://arxiv.org/abs/2310.02862v1"}
{"created":"2023-10-04 14:47:27","title":"Rayleigh Quotient Graph Neural Networks for Graph-level Anomaly Detection","abstract":"Graph-level anomaly detection has gained significant attention as it finds many applications in various domains, such as cancer diagnosis and enzyme prediction. However, existing methods fail to capture the underlying properties of graph anomalies, resulting in unexplainable framework design and unsatisfying performance. In this paper, we take a step back and re-investigate the spectral differences between anomalous and normal graphs. Our main observation shows a significant disparity in the accumulated spectral energy between these two classes. Moreover, we prove that the accumulated spectral energy of the graph signal can be represented by its Rayleigh Quotient, indicating that the Rayleigh Quotient is a driving factor behind the anomalous properties of graphs. Motivated by this, we propose Rayleigh Quotient Graph Neural Network (RQGNN), the first spectral GNN for graph-level anomaly detection, providing a new perspective on exploring the inherent spectral features of anomalous graphs. Specifically, we introduce a novel framework that consists of two components: the Rayleigh Quotient learning component (RQL) and Chebyshev Wavelet GNN with RQ-pooling (CWGNN-RQ). RQL explicitly captures the Rayleigh Quotient of graphs and CWGNN-RQ implicitly explores the spectral space of graphs. Extensive experiments on 10 real-world datasets show that RQGNN outperforms the best rival by 6.74% in Macro-F1 score and 1.44% in AUC, demonstrating the effectiveness of our framework.","sentences":["Graph-level anomaly detection has gained significant attention as it finds many applications in various domains, such as cancer diagnosis and enzyme prediction.","However, existing methods fail to capture the underlying properties of graph anomalies, resulting in unexplainable framework design and unsatisfying performance.","In this paper, we take a step back and re-investigate the spectral differences between anomalous and normal graphs.","Our main observation shows a significant disparity in the accumulated spectral energy between these two classes.","Moreover, we prove that the accumulated spectral energy of the graph signal can be represented by its Rayleigh Quotient, indicating that the Rayleigh Quotient is a driving factor behind the anomalous properties of graphs.","Motivated by this, we propose Rayleigh Quotient Graph Neural Network (RQGNN), the first spectral GNN for graph-level anomaly detection, providing a new perspective on exploring the inherent spectral features of anomalous graphs.","Specifically, we introduce a novel framework that consists of two components: the Rayleigh Quotient learning component (RQL) and Chebyshev Wavelet GNN with RQ-pooling (CWGNN-RQ).","RQL explicitly captures the Rayleigh Quotient of graphs and CWGNN-RQ implicitly explores the spectral space of graphs.","Extensive experiments on 10 real-world datasets show that RQGNN outperforms the best rival by 6.74% in Macro-F1 score and 1.44% in AUC, demonstrating the effectiveness of our framework."],"url":"http://arxiv.org/abs/2310.02861v1"}
{"created":"2023-10-04 14:44:44","title":"Tight Sampling in Unbounded Networks","abstract":"The default approach to deal with the enormous size and limited accessibility of many Web and social media networks is to sample one or more subnetworks from a conceptually unbounded unknown network. Clearly, the extracted subnetworks will crucially depend on the sampling scheme. Motivated by studies of homophily and opinion formation, we propose a variant of snowball sampling designed to prioritize inclusion of entire cohesive communities rather than any kind of representativeness, breadth, or depth of coverage. The method is illustrated on a concrete example, and experiments on synthetic networks suggest that it behaves as desired.","sentences":["The default approach to deal with the enormous size and limited accessibility of many Web and social media networks is to sample one or more subnetworks from a conceptually unbounded unknown network.","Clearly, the extracted subnetworks will crucially depend on the sampling scheme.","Motivated by studies of homophily and opinion formation, we propose a variant of snowball sampling designed to prioritize inclusion of entire cohesive communities rather than any kind of representativeness, breadth, or depth of coverage.","The method is illustrated on a concrete example, and experiments on synthetic networks suggest that it behaves as desired."],"url":"http://arxiv.org/abs/2310.02859v1"}
{"created":"2023-10-04 14:41:41","title":"Multi-Domain Causal Representation Learning via Weak Distributional Invariances","abstract":"Causal representation learning has emerged as the center of action in causal machine learning research. In particular, multi-domain datasets present a natural opportunity for showcasing the advantages of causal representation learning over standard unsupervised representation learning. While recent works have taken crucial steps towards learning causal representations, they often lack applicability to multi-domain datasets due to over-simplifying assumptions about the data; e.g. each domain comes from a different single-node perfect intervention. In this work, we relax these assumptions and capitalize on the following observation: there often exists a subset of latents whose certain distributional properties (e.g., support, variance) remain stable across domains; this property holds when, for example, each domain comes from a multi-node imperfect intervention. Leveraging this observation, we show that autoencoders that incorporate such invariances can provably identify the stable set of latents from the rest across different settings.","sentences":["Causal representation learning has emerged as the center of action in causal machine learning research.","In particular, multi-domain datasets present a natural opportunity for showcasing the advantages of causal representation learning over standard unsupervised representation learning.","While recent works have taken crucial steps towards learning causal representations, they often lack applicability to multi-domain datasets due to over-simplifying assumptions about the data; e.g. each domain comes from a different single-node perfect intervention.","In this work, we relax these assumptions and capitalize on the following observation: there often exists a subset of latents whose certain distributional properties (e.g., support, variance) remain stable across domains; this property holds when, for example, each domain comes from a multi-node imperfect intervention.","Leveraging this observation, we show that autoencoders that incorporate such invariances can provably identify the stable set of latents from the rest across different settings."],"url":"http://arxiv.org/abs/2310.02854v1"}
{"created":"2023-10-04 14:34:11","title":"Magicremover: Tuning-free Text-guided Image inpainting with Diffusion Models","abstract":"Image inpainting aims to fill in the missing pixels with visually coherent and semantically plausible content. Despite the great progress brought from deep generative models, this task still suffers from i. the difficulties in large-scale realistic data collection and costly model training; and ii. the intrinsic limitations in the traditionally user-defined binary masks on objects with unclear boundaries or transparent texture. In this paper, we propose MagicRemover, a tuning-free method that leverages the powerful diffusion models for text-guided image inpainting. We introduce an attention guidance strategy to constrain the sampling process of diffusion models, enabling the erasing of instructed areas and the restoration of occluded content. We further propose a classifier optimization algorithm to facilitate the denoising stability within less sampling steps. Extensive comparisons are conducted among our MagicRemover and state-of-the-art methods including quantitative evaluation and user study, demonstrating the significant improvement of MagicRemover on high-quality image inpainting. We will release our code at https://github.com/exisas/Magicremover.","sentences":["Image inpainting aims to fill in the missing pixels with visually coherent and semantically plausible content.","Despite the great progress brought from deep generative models, this task still suffers from i. the difficulties in large-scale realistic data collection and costly model training; and ii.","the intrinsic limitations in the traditionally user-defined binary masks on objects with unclear boundaries or transparent texture.","In this paper, we propose MagicRemover, a tuning-free method that leverages the powerful diffusion models for text-guided image inpainting.","We introduce an attention guidance strategy to constrain the sampling process of diffusion models, enabling the erasing of instructed areas and the restoration of occluded content.","We further propose a classifier optimization algorithm to facilitate the denoising stability within less sampling steps.","Extensive comparisons are conducted among our MagicRemover and state-of-the-art methods including quantitative evaluation and user study, demonstrating the significant improvement of MagicRemover on high-quality image inpainting.","We will release our code at https://github.com/exisas/Magicremover."],"url":"http://arxiv.org/abs/2310.02848v1"}
{"created":"2023-10-04 14:32:54","title":"On the Length of Strongly Monotone Descending Chains over $\\mathbb{N}^d$","abstract":"A recent breakthrough by K\\\"unnemann, Mazowiecki, Sch\\\"utze, Sinclair-Banks, and Wegrzycki (ICALP, 2023) bounds the running time for the coverability problem in $d$-dimensional vector addition systems under unary encoding to $n^{2^{O(d)}}$, improving on Rackoff's $n^{2^{O(d\\lg d)}}$ upper bound (Theor. Comput. Sci., 1978), and provides conditional matching lower bounds.   In this paper, we revisit Lazi\\'c and Schmitz' \"ideal view\" of the backward coverability algorithm (Inform. Comput., 2021) in the light of this breakthrough. We show that the controlled strongly monotone descending chains of downwards-closed sets over $\\mathbb{N}^d$ that arise from the dual backward coverability algorithm of Lazi\\'c and Schmitz on $d$-dimensional unary vector addition systems also enjoy this tight $n^{2^{O(d)}}$ upper bound on their length, and that this also translates into the same bound on the running time of the backward coverability algorithm.   Furthermore, our analysis takes place in a more general setting than that of Lazi\\'c and Schmitz, which allows to show the same results and improve on the 2EXPSPACE upper bound derived by Benedikt, Duff, Sharad, and Worrell (LICS, 2017) for the coverability problem in invertible affine nets.","sentences":["A recent breakthrough by K\\\"unnemann, Mazowiecki, Sch\\\"utze, Sinclair-Banks, and Wegrzycki (ICALP, 2023) bounds the running time for the coverability problem in $d$-dimensional vector addition systems under unary encoding to $n^{2^{O(d)}}$, improving on Rackoff's $n^{2^{O(d\\lg d)}}$ upper bound (Theor.","Comput.","Sci., 1978), and provides conditional matching lower bounds.   ","In this paper, we revisit Lazi\\'c and Schmitz' \"ideal view\" of the backward coverability algorithm (Inform.","Comput., 2021) in the light of this breakthrough.","We show that the controlled strongly monotone descending chains of downwards-closed sets over $\\mathbb{N}^d$ that arise from the dual backward coverability algorithm of Lazi\\'c and Schmitz on $d$-dimensional unary vector addition systems also enjoy this tight $n^{2^{O(d)}}$ upper bound on their length, and that this also translates into the same bound on the running time of the backward coverability algorithm.   ","Furthermore, our analysis takes place in a more general setting than that of Lazi\\'c and Schmitz, which allows to show the same results and improve on the 2EXPSPACE upper bound derived by Benedikt, Duff, Sharad, and Worrell (LICS, 2017) for the coverability problem in invertible affine nets."],"url":"http://arxiv.org/abs/2310.02847v1"}
{"created":"2023-10-04 14:24:26","title":"Note on a Translation from First-Order Logic into the Calculus of Relations Preserving Validity and Finite Validity","abstract":"In this note, we give a linear-size translation from formulas of first-order logic into equations of the calculus of relations preserving validity and finite validity. Our translation also gives a linear-size conservative reduction from formulas of first-order logic into formulas of the three-variable fragment of first-order logic.","sentences":["In this note, we give a linear-size translation from formulas of first-order logic into equations of the calculus of relations preserving validity and finite validity.","Our translation also gives a linear-size conservative reduction from formulas of first-order logic into formulas of the three-variable fragment of first-order logic."],"url":"http://arxiv.org/abs/2310.02845v1"}
{"created":"2023-10-04 14:20:50","title":"Incorporating Target Vehicle Trajectories Predicted by Deep Learning Into Model Predictive Controlled Vehicles","abstract":"Model Predictive Control (MPC) has been widely applied to the motion planning of autonomous vehicles. An MPC-controlled vehicle is required to predict its own trajectories in a finite prediction horizon according to its model. Beyond this, the vehicle should also incorporate the prediction of the trajectory of its nearby vehicles, or target vehicles (TVs) into its decision-making. The conventional trajectory prediction methods, such as the constant-speed-based ones, are too trivial to accurately capture the potential collision risks. In this report, we propose a novel MPC-based motion planning method for an autonomous vehicle with a set of risk-aware constraints. These constraints incorporate the predicted trajectory of a TV learned using a deep-learning-based method. A recurrent neural network (RNN) is used to predict the TV's future trajectory based on its historical data. Then, the predicted TV trajectory is incorporated into the optimization of the MPC of the ego vehicle to generate collision-free motion. Simulation studies are conducted to showcase the prediction accuracy of the RNN model and the collision-free trajectories generated by the MPC.","sentences":["Model Predictive Control (MPC) has been widely applied to the motion planning of autonomous vehicles.","An MPC-controlled vehicle is required to predict its own trajectories in a finite prediction horizon according to its model.","Beyond this, the vehicle should also incorporate the prediction of the trajectory of its nearby vehicles, or target vehicles (TVs) into its decision-making.","The conventional trajectory prediction methods, such as the constant-speed-based ones, are too trivial to accurately capture the potential collision risks.","In this report, we propose a novel MPC-based motion planning method for an autonomous vehicle with a set of risk-aware constraints.","These constraints incorporate the predicted trajectory of a TV learned using a deep-learning-based method.","A recurrent neural network (RNN) is used to predict the TV's future trajectory based on its historical data.","Then, the predicted TV trajectory is incorporated into the optimization of the MPC of the ego vehicle to generate collision-free motion.","Simulation studies are conducted to showcase the prediction accuracy of the RNN model and the collision-free trajectories generated by the MPC."],"url":"http://arxiv.org/abs/2310.02843v1"}
{"created":"2023-10-04 14:11:12","title":"Sweeping Heterogeneity with Smart MoPs: Mixture of Prompts for LLM Task Adaptation","abstract":"Large Language Models (LLMs) have the ability to solve a variety of tasks, such as text summarization and mathematical questions, just out of the box, but they are often trained with a single task in mind. Due to high computational costs, the current trend is to use prompt instruction tuning to better adjust monolithic, pretrained LLMs for new -- but often individual -- downstream tasks. Thus, how one would expand prompt tuning to handle -- concomitantly -- heterogeneous tasks and data distributions is a widely open question. To address this gap, we suggest the use of \\emph{Mixture of Prompts}, or MoPs, associated with smart gating functionality: the latter -- whose design is one of the contributions of this paper -- can identify relevant skills embedded in different groups of prompts and dynamically assign combined experts (i.e., collection of prompts), based on the target task. Additionally, MoPs are empirically agnostic to any model compression technique applied -- for efficiency reasons -- as well as instruction data source and task composition. In practice, MoPs can simultaneously mitigate prompt training \"interference\" in multi-task, multi-source scenarios (e.g., task and data heterogeneity across sources), as well as possible implications from model approximations. As a highlight, MoPs manage to decrease final perplexity from $\\sim20\\%$ up to $\\sim70\\%$, as compared to baselines, in the federated scenario, and from $\\sim 3\\%$ up to $\\sim30\\%$ in the centralized scenario.","sentences":["Large Language Models (LLMs) have the ability to solve a variety of tasks, such as text summarization and mathematical questions, just out of the box, but they are often trained with a single task in mind.","Due to high computational costs, the current trend is to use prompt instruction tuning to better adjust monolithic, pretrained LLMs for new -- but often individual -- downstream tasks.","Thus, how one would expand prompt tuning to handle -- concomitantly -- heterogeneous tasks and data distributions is a widely open question.","To address this gap, we suggest the use of \\emph{Mixture of Prompts}, or MoPs, associated with smart gating functionality: the latter -- whose design is one of the contributions of this paper -- can identify relevant skills embedded in different groups of prompts and dynamically assign combined experts (i.e., collection of prompts), based on the target task.","Additionally, MoPs are empirically agnostic to any model compression technique applied -- for efficiency reasons -- as well as instruction data source and task composition.","In practice, MoPs can simultaneously mitigate prompt training \"interference\" in multi-task, multi-source scenarios (e.g., task and data heterogeneity across sources), as well as possible implications from model approximations.","As a highlight, MoPs manage to decrease final perplexity from $\\sim20\\%$ up to $\\sim70\\%$, as compared to baselines, in the federated scenario, and from $\\sim 3\\%$ up to $\\sim30\\%$ in the centralized scenario."],"url":"http://arxiv.org/abs/2310.02842v1"}
{"created":"2023-10-04 14:09:23","title":"Mosaic benchmark networks: Modular link streams for testing dynamic community detection algorithms","abstract":"Community structure is a critical feature of real networks, providing insights into nodes' internal organization. Nowadays, with the availability of highly detailed temporal networks such as link streams, studying community structures becomes more complex due to increased data precision and time sensitivity. Despite numerous algorithms developed in the past decade for dynamic community discovery, assessing their performance on link streams remains a challenge. Synthetic benchmark graphs are a well-accepted approach for evaluating static community detection algorithms. Additionally, there have been some proposals for slowly evolving communities in low-resolution temporal networks like snapshots. Nevertheless, this approach is not yet suitable for link streams. To bridge this gap, we introduce a novel framework that generates synthetic modular link streams with predefined communities. Subsequently, we evaluate established dynamic community detection methods to uncover limitations that may not be evident in snapshots with slowly evolving communities. While no method emerges as a clear winner, we observe notable differences among them.","sentences":["Community structure is a critical feature of real networks, providing insights into nodes' internal organization.","Nowadays, with the availability of highly detailed temporal networks such as link streams, studying community structures becomes more complex due to increased data precision and time sensitivity.","Despite numerous algorithms developed in the past decade for dynamic community discovery, assessing their performance on link streams remains a challenge.","Synthetic benchmark graphs are a well-accepted approach for evaluating static community detection algorithms.","Additionally, there have been some proposals for slowly evolving communities in low-resolution temporal networks like snapshots.","Nevertheless, this approach is not yet suitable for link streams.","To bridge this gap, we introduce a novel framework that generates synthetic modular link streams with predefined communities.","Subsequently, we evaluate established dynamic community detection methods to uncover limitations that may not be evident in snapshots with slowly evolving communities.","While no method emerges as a clear winner, we observe notable differences among them."],"url":"http://arxiv.org/abs/2310.02840v1"}
{"created":"2023-10-04 14:01:55","title":"Delving into CLIP latent space for Video Anomaly Recognition","abstract":"We tackle the complex problem of detecting and recognising anomalies in surveillance videos at the frame level, utilising only video-level supervision. We introduce the novel method AnomalyCLIP, the first to combine Large Language and Vision (LLV) models, such as CLIP, with multiple instance learning for joint video anomaly detection and classification. Our approach specifically involves manipulating the latent CLIP feature space to identify the normal event subspace, which in turn allows us to effectively learn text-driven directions for abnormal events. When anomalous frames are projected onto these directions, they exhibit a large feature magnitude if they belong to a particular class. We also introduce a computationally efficient Transformer architecture to model short- and long-term temporal dependencies between frames, ultimately producing the final anomaly score and class prediction probabilities. We compare AnomalyCLIP against state-of-the-art methods considering three major anomaly detection benchmarks, i.e. ShanghaiTech, UCF-Crime, and XD-Violence, and empirically show that it outperforms baselines in recognising video anomalies.","sentences":["We tackle the complex problem of detecting and recognising anomalies in surveillance videos at the frame level, utilising only video-level supervision.","We introduce the novel method AnomalyCLIP, the first to combine Large Language and Vision (LLV) models, such as CLIP, with multiple instance learning for joint video anomaly detection and classification.","Our approach specifically involves manipulating the latent CLIP feature space to identify the normal event subspace, which in turn allows us to effectively learn text-driven directions for abnormal events.","When anomalous frames are projected onto these directions, they exhibit a large feature magnitude if they belong to a particular class.","We also introduce a computationally efficient Transformer architecture to model short- and long-term temporal dependencies between frames, ultimately producing the final anomaly score and class prediction probabilities.","We compare AnomalyCLIP against state-of-the-art methods considering three major anomaly detection benchmarks, i.e. ShanghaiTech, UCF-Crime, and XD-Violence, and empirically show that it outperforms baselines in recognising video anomalies."],"url":"http://arxiv.org/abs/2310.02835v1"}
{"created":"2023-10-04 13:59:45","title":"Out-of-Distribution Detection by Leveraging Between-Layer Transformation Smoothness","abstract":"Effective OOD detection is crucial for reliable machine learning models, yet most current methods are limited in practical use due to requirements like access to training data or intervention in training. We present a novel method for detecting OOD data in deep neural networks based on transformation smoothness between intermediate layers of a network (BLOOD), which is applicable to pre-trained models without access to training data. BLOOD utilizes the tendency of between-layer representation transformations of in-distribution (ID) data to be smoother than the corresponding transformations of OOD data, a property that we also demonstrate empirically for Transformer networks. We evaluate BLOOD on several text classification tasks with Transformer networks and demonstrate that it outperforms methods with comparable resource requirements. Our analysis also suggests that when learning simpler tasks, OOD data transformations maintain their original sharpness, whereas sharpness increases with more complex tasks.","sentences":["Effective OOD detection is crucial for reliable machine learning models, yet most current methods are limited in practical use due to requirements like access to training data or intervention in training.","We present a novel method for detecting OOD data in deep neural networks based on transformation smoothness between intermediate layers of a network (BLOOD), which is applicable to pre-trained models without access to training data.","BLOOD utilizes the tendency of between-layer representation transformations of in-distribution (ID) data to be smoother than the corresponding transformations of OOD data, a property that we also demonstrate empirically for Transformer networks.","We evaluate BLOOD on several text classification tasks with Transformer networks and demonstrate that it outperforms methods with comparable resource requirements.","Our analysis also suggests that when learning simpler tasks, OOD data transformations maintain their original sharpness, whereas sharpness increases with more complex tasks."],"url":"http://arxiv.org/abs/2310.02832v1"}
{"created":"2023-10-04 13:45:56","title":"Learning to Scale Logits for Temperature-Conditional GFlowNets","abstract":"GFlowNets are probabilistic models that learn a stochastic policy that sequentially generates compositional structures, such as molecular graphs. They are trained with the objective of sampling such objects with probability proportional to the object's reward. Among GFlowNets, the temperature-conditional GFlowNets represent a family of policies indexed by temperature, and each is associated with the correspondingly tempered reward function. The major benefit of temperature-conditional GFlowNets is the controllability of GFlowNets' exploration and exploitation through adjusting temperature. We propose Learning to Scale Logits for temperature-conditional GFlowNets (LSL-GFN), a novel architectural design that greatly accelerates the training of temperature-conditional GFlowNets. It is based on the idea that previously proposed temperature-conditioning approaches introduced numerical challenges in the training of the deep network because different temperatures may give rise to very different gradient profiles and ideal scales of the policy's logits. We find that the challenge is greatly reduced if a learned function of the temperature is used to scale the policy's logits directly. We empirically show that our strategy dramatically improves the performances of GFlowNets, outperforming other baselines, including reinforcement learning and sampling methods, in terms of discovering diverse modes in multiple biochemical tasks.","sentences":["GFlowNets are probabilistic models that learn a stochastic policy that sequentially generates compositional structures, such as molecular graphs.","They are trained with the objective of sampling such objects with probability proportional to the object's reward.","Among GFlowNets, the temperature-conditional GFlowNets represent a family of policies indexed by temperature, and each is associated with the correspondingly tempered reward function.","The major benefit of temperature-conditional GFlowNets is the controllability of GFlowNets' exploration and exploitation through adjusting temperature.","We propose Learning to Scale Logits for temperature-conditional GFlowNets (LSL-GFN), a novel architectural design that greatly accelerates the training of temperature-conditional GFlowNets.","It is based on the idea that previously proposed temperature-conditioning approaches introduced numerical challenges in the training of the deep network because different temperatures may give rise to very different gradient profiles and ideal scales of the policy's logits.","We find that the challenge is greatly reduced if a learned function of the temperature is used to scale the policy's logits directly.","We empirically show that our strategy dramatically improves the performances of GFlowNets, outperforming other baselines, including reinforcement learning and sampling methods, in terms of discovering diverse modes in multiple biochemical tasks."],"url":"http://arxiv.org/abs/2310.02823v1"}
{"created":"2023-10-04 13:44:56","title":"Improving Vision Anomaly Detection with the Guidance of Language Modality","abstract":"Recent years have seen a surge of interest in anomaly detection for tackling industrial defect detection, event detection, etc. However, existing unsupervised anomaly detectors, particularly those for the vision modality, face significant challenges due to redundant information and sparse latent space. Conversely, the language modality performs well due to its relatively single data. This paper tackles the aforementioned challenges for vision modality from a multimodal point of view. Specifically, we propose Cross-modal Guidance (CMG), which consists of Cross-modal Entropy Reduction (CMER) and Cross-modal Linear Embedding (CMLE), to tackle the redundant information issue and sparse space issue, respectively. CMER masks parts of the raw image and computes the matching score with the text. Then, CMER discards irrelevant pixels to make the detector focus on critical contents. To learn a more compact latent space for the vision anomaly detector, CMLE learns a correlation structure matrix from the language modality, and then the latent space of vision modality will be learned with the guidance of the matrix. Thereafter, the vision latent space will get semantically similar images closer. Extensive experiments demonstrate the effectiveness of the proposed methods. Particularly, CMG outperforms the baseline that only uses images by 16.81%. Ablation experiments further confirm the synergy among the proposed methods, as each component depends on the other to achieve optimal performance.","sentences":["Recent years have seen a surge of interest in anomaly detection for tackling industrial defect detection, event detection, etc.","However, existing unsupervised anomaly detectors, particularly those for the vision modality, face significant challenges due to redundant information and sparse latent space.","Conversely, the language modality performs well due to its relatively single data.","This paper tackles the aforementioned challenges for vision modality from a multimodal point of view.","Specifically, we propose Cross-modal Guidance (CMG), which consists of Cross-modal Entropy Reduction (CMER) and Cross-modal Linear Embedding (CMLE), to tackle the redundant information issue and sparse space issue, respectively.","CMER masks parts of the raw image and computes the matching score with the text.","Then, CMER discards irrelevant pixels to make the detector focus on critical contents.","To learn a more compact latent space for the vision anomaly detector, CMLE learns a correlation structure matrix from the language modality, and then the latent space of vision modality will be learned with the guidance of the matrix.","Thereafter, the vision latent space will get semantically similar images closer.","Extensive experiments demonstrate the effectiveness of the proposed methods.","Particularly, CMG outperforms the baseline that only uses images by 16.81%.","Ablation experiments further confirm the synergy among the proposed methods, as each component depends on the other to achieve optimal performance."],"url":"http://arxiv.org/abs/2310.02821v1"}
