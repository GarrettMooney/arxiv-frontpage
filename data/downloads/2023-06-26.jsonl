{"created":"2023-06-23","title":"MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models","abstract":"Multimodal Large Language Model (MLLM) relies on the powerful LLM to perform multimodal tasks, showing amazing emergent abilities in recent studies, such as writing poems based on an image. However, it is difficult for these case studies to fully reflect the performance of MLLM, lacking a comprehensive evaluation. In this paper, we fill in this blank, presenting the first MLLM Evaluation benchmark MME. It measures both perception and cognition abilities on a total of 14 subtasks. In order to avoid data leakage that may arise from direct use of public datasets for evaluation, the annotations of instruction-answer pairs are all manually designed. The concise instruction design allows us to fairly compare MLLMs, instead of struggling in prompt engineering. Besides, with such an instruction, we can also easily carry out quantitative statistics. A total of 10 advanced MLLMs are comprehensively evaluated on our MME, which not only suggests that existing MLLMs still have a large room for improvement, but also reveals the potential directions for the subsequent model optimization.","sentences":["Multimodal Large Language Model (MLLM) relies on the powerful LLM to perform multimodal tasks, showing amazing emergent abilities in recent studies, such as writing poems based on an image.","However, it is difficult for these case studies to fully reflect the performance of MLLM, lacking a comprehensive evaluation.","In this paper, we fill in this blank, presenting the first MLLM Evaluation benchmark MME.","It measures both perception and cognition abilities on a total of 14 subtasks.","In order to avoid data leakage that may arise from direct use of public datasets for evaluation, the annotations of instruction-answer pairs are all manually designed.","The concise instruction design allows us to fairly compare MLLMs, instead of struggling in prompt engineering.","Besides, with such an instruction, we can also easily carry out quantitative statistics.","A total of 10 advanced MLLMs are comprehensively evaluated on our MME, which not only suggests that existing MLLMs still have a large room for improvement, but also reveals the potential directions for the subsequent model optimization."],"url":"http://arxiv.org/abs/2306.13394v1"}
{"created":"2023-06-23","title":"DiffInfinite: Large Mask-Image Synthesis via Parallel Random Patch Diffusion in Histopathology","abstract":"We present DiffInfinite, a hierarchical diffusion model that generates arbitrarily large histological images while preserving long-range correlation structural information. Our approach first generates synthetic segmentation masks, subsequently used as conditions for the high-fidelity generative diffusion process. The proposed sampling method can be scaled up to any desired image size while only requiring small patches for fast training. Moreover, it can be parallelized more efficiently than previous large-content generation methods while avoiding tiling artefacts. The training leverages classifier-free guidance to augment a small, sparsely annotated dataset with unlabelled data. Our method alleviates unique challenges in histopathological imaging practice: large-scale information, costly manual annotation, and protective data handling. The biological plausibility of DiffInfinite data is validated in a survey by ten experienced pathologists as well as a downstream segmentation task. Furthermore, the model scores strongly on anti-copying metrics which is beneficial for the protection of patient data.","sentences":["We present DiffInfinite, a hierarchical diffusion model that generates arbitrarily large histological images while preserving long-range correlation structural information.","Our approach first generates synthetic segmentation masks, subsequently used as conditions for the high-fidelity generative diffusion process.","The proposed sampling method can be scaled up to any desired image size while only requiring small patches for fast training.","Moreover, it can be parallelized more efficiently than previous large-content generation methods while avoiding tiling artefacts.","The training leverages classifier-free guidance to augment a small, sparsely annotated dataset with unlabelled data.","Our method alleviates unique challenges in histopathological imaging practice: large-scale information, costly manual annotation, and protective data handling.","The biological plausibility of DiffInfinite data is validated in a survey by ten experienced pathologists as well as a downstream segmentation task.","Furthermore, the model scores strongly on anti-copying metrics which is beneficial for the protection of patient data."],"url":"http://arxiv.org/abs/2306.13384v1"}
{"created":"2023-06-23","title":"Multi-objective optimization based network control principles for identifying personalized drug targets with cancer","abstract":"It is a big challenge to develop efficient models for identifying personalized drug targets (PDTs) from high-dimensional personalized genomic profile of individual patients. Recent structural network control principles have introduced a new approach to discover PDTs by selecting an optimal set of driver genes in personalized gene interaction network (PGIN). However, most of current methods only focus on controlling the system through a minimum driver-node set and ignore the existence of multiple candidate driver-node sets for therapeutic drug target identification in PGIN. Therefore, this paper proposed multi-objective optimization-based structural network control principles (MONCP) by considering minimum driver nodes and maximum prior-known drug-target information. To solve MONCP, a discrete multi-objective optimization problem is formulated with many constrained variables, and a novel evolutionary optimization model called LSCV-MCEA was developed by adapting a multi-tasking framework and a rankings-based fitness function method. With genomics data of patients with breast or lung cancer from The Cancer Genome Atlas database, the effectiveness of LSCV-MCEA was validated. The experimental results indicated that compared with other advanced methods, LSCV-MCEA can more effectively identify PDTs with the highest Area Under the Curve score for predicting clinically annotated combinatorial drugs. Meanwhile, LSCV-MCEA can more effectively solve MONCP than other evolutionary optimization methods in terms of algorithm convergence and diversity. Particularly, LSCV-MCEA can efficiently detect disease signals for individual patients with BRCA cancer. The study results show that multi-objective optimization can solve structural network control principles effectively and offer a new perspective for understanding tumor heterogeneity in cancer precision medicine.","sentences":["It is a big challenge to develop efficient models for identifying personalized drug targets (PDTs) from high-dimensional personalized genomic profile of individual patients.","Recent structural network control principles have introduced a new approach to discover PDTs by selecting an optimal set of driver genes in personalized gene interaction network (PGIN).","However, most of current methods only focus on controlling the system through a minimum driver-node set and ignore the existence of multiple candidate driver-node sets for therapeutic drug target identification in PGIN.","Therefore, this paper proposed multi-objective optimization-based structural network control principles (MONCP) by considering minimum driver nodes and maximum prior-known drug-target information.","To solve MONCP, a discrete multi-objective optimization problem is formulated with many constrained variables, and a novel evolutionary optimization model called LSCV-MCEA was developed by adapting a multi-tasking framework and a rankings-based fitness function method.","With genomics data of patients with breast or lung cancer from The Cancer Genome Atlas database, the effectiveness of LSCV-MCEA was validated.","The experimental results indicated that compared with other advanced methods, LSCV-MCEA can more effectively identify PDTs with the highest Area Under the Curve score for predicting clinically annotated combinatorial drugs.","Meanwhile, LSCV-MCEA can more effectively solve MONCP than other evolutionary optimization methods in terms of algorithm convergence and diversity.","Particularly, LSCV-MCEA can efficiently detect disease signals for individual patients with BRCA cancer.","The study results show that multi-objective optimization can solve structural network control principles effectively and offer a new perspective for understanding tumor heterogeneity in cancer precision medicine."],"url":"http://arxiv.org/abs/2306.13349v1"}
{"created":"2023-06-23","title":"Deep Omni-supervised Learning for Rib Fracture Detection from Chest Radiology Images","abstract":"Deep learning (DL)-based rib fracture detection has shown promise of playing an important role in preventing mortality and improving patient outcome. Normally, developing DL-based object detection models requires huge amount of bounding box annotation. However, annotating medical data is time-consuming and expertise-demanding, making obtaining a large amount of fine-grained annotations extremely infeasible. This poses pressing need of developing label-efficient detection models to alleviate radiologists' labeling burden. To tackle this challenge, the literature of object detection has witnessed an increase of weakly-supervised and semi-supervised approaches, yet still lacks a unified framework that leverages various forms of fully-labeled, weakly-labeled, and unlabeled data. In this paper, we present a novel omni-supervised object detection network, ORF-Netv2, to leverage as much available supervision as possible. Specifically, a multi-branch omni-supervised detection head is introduced with each branch trained with a specific type of supervision. A co-training-based dynamic label assignment strategy is then proposed to enable flexibly and robustly learning from the weakly-labeled and unlabeled data. Extensively evaluation was conducted for the proposed framework with three rib fracture datasets on both chest CT and X-ray. By leveraging all forms of supervision, ORF-Netv2 achieves mAPs of 34.7, 44.7, and 19.4 on the three datasets, respectively, surpassing the baseline detector which uses only box annotations by mAP gains of 3.8, 4.8, and 5.0, respectively. Furthermore, ORF-Netv2 consistently outperforms other competitive label-efficient methods over various scenarios, showing a promising framework for label-efficient fracture detection.","sentences":["Deep learning (DL)-based rib fracture detection has shown promise of playing an important role in preventing mortality and improving patient outcome.","Normally, developing DL-based object detection models requires huge amount of bounding box annotation.","However, annotating medical data is time-consuming and expertise-demanding, making obtaining a large amount of fine-grained annotations extremely infeasible.","This poses pressing need of developing label-efficient detection models to alleviate radiologists' labeling burden.","To tackle this challenge, the literature of object detection has witnessed an increase of weakly-supervised and semi-supervised approaches, yet still lacks a unified framework that leverages various forms of fully-labeled, weakly-labeled, and unlabeled data.","In this paper, we present a novel omni-supervised object detection network, ORF-Netv2, to leverage as much available supervision as possible.","Specifically, a multi-branch omni-supervised detection head is introduced with each branch trained with a specific type of supervision.","A co-training-based dynamic label assignment strategy is then proposed to enable flexibly and robustly learning from the weakly-labeled and unlabeled data.","Extensively evaluation was conducted for the proposed framework with three rib fracture datasets on both chest CT and X-ray.","By leveraging all forms of supervision, ORF-Netv2 achieves mAPs of 34.7, 44.7, and 19.4 on the three datasets, respectively, surpassing the baseline detector which uses only box annotations by mAP gains of 3.8, 4.8, and 5.0, respectively.","Furthermore, ORF-Netv2 consistently outperforms other competitive label-efficient methods over various scenarios, showing a promising framework for label-efficient fracture detection."],"url":"http://arxiv.org/abs/2306.13301v1"}
{"created":"2023-06-22","title":"AmicroN: A Framework for Generating Annotations for Human Activity Recognition with Granular Micro-Activities","abstract":"Efficient human activity recognition (HAR) using sensor data needs a significant volume of annotated data. The growing volume of unlabelled sensor data has challenged conventional practices for gathering HAR annotations with human-in-the-loop approaches, often leading to the collection of shallower annotations. These shallower annotations ignore the fine-grained micro-activities that constitute any complex activities of daily living (ADL). Understanding this, we, in this paper, first analyze this lack of granular annotations from available pre-annotated datasets to understand the practical inconsistencies and also perform a detailed survey to look into the human perception surrounding annotations. Drawing motivations from these, we next develop the framework AmicroN that can automatically generate micro-activity annotations using locomotive signatures and the available coarse-grain macro-activity labels. In the backend, AmicroN applies change-point detection followed by zero-shot learning with activity embeddings to identify the unseen micro-activities in an unsupervised manner. Rigorous evaluation on publicly available datasets shows that AmicroN can accurately generate micro-activity annotations with a median F1-score of >0.75. Additionally, we also show that AmicroN can be used in a plug-and-play manner with Large Language Models (LLMs) to obtain the micro-activity labels, thus making it more practical for realistic applications.","sentences":["Efficient human activity recognition (HAR) using sensor data needs a significant volume of annotated data.","The growing volume of unlabelled sensor data has challenged conventional practices for gathering HAR annotations with human-in-the-loop approaches, often leading to the collection of shallower annotations.","These shallower annotations ignore the fine-grained micro-activities that constitute any complex activities of daily living (ADL).","Understanding this, we, in this paper, first analyze this lack of granular annotations from available pre-annotated datasets to understand the practical inconsistencies and also perform a detailed survey to look into the human perception surrounding annotations.","Drawing motivations from these, we next develop the framework AmicroN that can automatically generate micro-activity annotations using locomotive signatures and the available coarse-grain macro-activity labels.","In the backend, AmicroN applies change-point detection followed by zero-shot learning with activity embeddings to identify the unseen micro-activities in an unsupervised manner.","Rigorous evaluation on publicly available datasets shows that AmicroN can accurately generate micro-activity annotations with a median F1-score of >0.75.","Additionally, we also show that AmicroN can be used in a plug-and-play manner with Large Language Models (LLMs) to obtain the micro-activity labels, thus making it more practical for realistic applications."],"url":"http://arxiv.org/abs/2306.13149v1"}
{"created":"2023-06-22","title":"Named entity recognition in resumes","abstract":"Named entity recognition (NER) is used to extract information from various documents and texts such as names and dates. It is important to extract education and work experience information from resumes in order to filter them. Considering the fact that all information in a resume has to be entered to the companys system manually, automatizing this process will save time of the companies. In this study, a deep learning-based semi-automatic named entity recognition system has been implemented with a focus on resumes in the field of IT. Firstly, resumes of employees from five different IT related fields has been annotated. Six transformer based pre-trained models have been adapted to named entity recognition problem using the annotated data. These models have been selected among popular models in the natural language processing field. The obtained system can recognize eight different entity types which are city, date, degree, diploma major, job title, language, country and skill. Models used in the experiments are compared using micro, macro and weighted F1 scores and the performance of the methods was evaluated. Taking these scores into account for test set the best micro and weighted F1 score is obtained by RoBERTa and the best macro F1 score is obtained by Electra model.","sentences":["Named entity recognition (NER) is used to extract information from various documents and texts such as names and dates.","It is important to extract education and work experience information from resumes in order to filter them.","Considering the fact that all information in a resume has to be entered to the companys system manually, automatizing this process will save time of the companies.","In this study, a deep learning-based semi-automatic named entity recognition system has been implemented with a focus on resumes in the field of IT.","Firstly, resumes of employees from five different IT related fields has been annotated.","Six transformer based pre-trained models have been adapted to named entity recognition problem using the annotated data.","These models have been selected among popular models in the natural language processing field.","The obtained system can recognize eight different entity types which are city, date, degree, diploma major, job title, language, country and skill.","Models used in the experiments are compared using micro, macro and weighted F1 scores and the performance of the methods was evaluated.","Taking these scores into account for test set the best micro and weighted F1 score is obtained by RoBERTa and the best macro F1 score is obtained by Electra model."],"url":"http://arxiv.org/abs/2306.13062v1"}
{"created":"2023-06-22","title":"Natural Language Processing in Electronic Health Records in Relation to Healthcare Decision-making: A Systematic Review","abstract":"Background: Natural Language Processing (NLP) is widely used to extract clinical insights from Electronic Health Records (EHRs). However, the lack of annotated data, automated tools, and other challenges hinder the full utilisation of NLP for EHRs. Various Machine Learning (ML), Deep Learning (DL) and NLP techniques are studied and compared to understand the limitations and opportunities in this space comprehensively.   Methodology: After screening 261 articles from 11 databases, we included 127 papers for full-text review covering seven categories of articles: 1) medical note classification, 2) clinical entity recognition, 3) text summarisation, 4) deep learning (DL) and transfer learning architecture, 5) information extraction, 6) Medical language translation and 7) other NLP applications. This study follows the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines.   Result and Discussion: EHR was the most commonly used data type among the selected articles, and the datasets were primarily unstructured. Various ML and DL methods were used, with prediction or classification being the most common application of ML or DL. The most common use cases were: the International Classification of Diseases, Ninth Revision (ICD-9) classification, clinical note analysis, and named entity recognition (NER) for clinical descriptions and research on psychiatric disorders.   Conclusion: We find that the adopted ML models were not adequately assessed. In addition, the data imbalance problem is quite important, yet we must find techniques to address this underlining problem. Future studies should address key limitations in studies, primarily identifying Lupus Nephritis, Suicide Attempts, perinatal self-harmed and ICD-9 classification.","sentences":["Background: Natural Language Processing (NLP) is widely used to extract clinical insights from Electronic Health Records (EHRs).","However, the lack of annotated data, automated tools, and other challenges hinder the full utilisation of NLP for EHRs.","Various Machine Learning (ML), Deep Learning (DL) and NLP techniques are studied and compared to understand the limitations and opportunities in this space comprehensively.   ","Methodology:","After screening 261 articles from 11 databases, we included 127 papers for full-text review covering seven categories of articles: 1) medical note classification, 2) clinical entity recognition, 3) text summarisation, 4) deep learning (DL) and transfer learning architecture, 5) information extraction, 6) Medical language translation and 7) other NLP applications.","This study follows the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines.   ","Result and Discussion: EHR was the most commonly used data type among the selected articles, and the datasets were primarily unstructured.","Various ML and DL methods were used, with prediction or classification being the most common application of ML or DL.","The most common use cases were: the International Classification of Diseases, Ninth Revision (ICD-9) classification, clinical note analysis, and named entity recognition (NER) for clinical descriptions and research on psychiatric disorders.   ","Conclusion: We find that the adopted ML models were not adequately assessed.","In addition, the data imbalance problem is quite important, yet we must find techniques to address this underlining problem.","Future studies should address key limitations in studies, primarily identifying Lupus Nephritis, Suicide Attempts, perinatal self-harmed and ICD-9 classification."],"url":"http://arxiv.org/abs/2306.12834v1"}
{"created":"2023-06-22","title":"A Search Strategy and Vessel Detection in Maritime Environment Using Fixed-Wing UAVs","abstract":"In this paper, we address the problem of autonomous search and vessel detection in an unknown GNSS-denied maritime environment with fixed-wing UAVs. The main challenge in such environments with limited localization, communication range, and the total number of UAVs and sensors is to implement an appropriate search strategy so that a target vessel can be detected as soon as possible. Thus we present informed and non-informed methods used to search the environment. The informed method relies on an obtained probabilistic map, while the non-informed method navigates the UAVs along predefined paths computed with respect to the environment. The vessel detection method is trained on synthetic data collected in the simulator with data annotation tools. Comparative experiments in simulation have shown that our combination of sensors, search methods and a vessel detection algorithm leads to a successful search for the target vessel in such challenging environments.","sentences":["In this paper, we address the problem of autonomous search and vessel detection in an unknown GNSS-denied maritime environment with fixed-wing UAVs.","The main challenge in such environments with limited localization, communication range, and the total number of UAVs and sensors is to implement an appropriate search strategy so that a target vessel can be detected as soon as possible.","Thus we present informed and non-informed methods used to search the environment.","The informed method relies on an obtained probabilistic map, while the non-informed method navigates the UAVs along predefined paths computed with respect to the environment.","The vessel detection method is trained on synthetic data collected in the simulator with data annotation tools.","Comparative experiments in simulation have shown that our combination of sensors, search methods and a vessel detection algorithm leads to a successful search for the target vessel in such challenging environments."],"url":"http://arxiv.org/abs/2306.12767v1"}
{"created":"2023-06-22","title":"Constructing Colloquial Dataset for Persian Sentiment Analysis of Social Microblogs","abstract":"Introduction: Microblogging websites have massed rich data sources for sentiment analysis and opinion mining. In this regard, sentiment classification has frequently proven inefficient because microblog posts typically lack syntactically consistent terms and representatives since users on these social networks do not like to write lengthy statements. Also, there are some limitations to low-resource languages. The Persian language has exceptional characteristics and demands unique annotated data and models for the sentiment analysis task, which are distinctive from text features within the English dialect. Method: This paper first constructs a user opinion dataset called ITRC-Opinion by collaborative environment and insource way. Our dataset contains 60,000 informal and colloquial Persian texts from social microblogs such as Twitter and Instagram. Second, this study proposes a new deep convolutional neural network (CNN) model for more effective sentiment analysis of colloquial text in social microblog posts. The constructed datasets are used to evaluate the presented model. Furthermore, some models, such as LSTM, CNN-RNN, BiLSTM, and BiGRU with different word embeddings, including Fasttext, Glove, and Word2vec, investigated our dataset and evaluated the results. Results: The results demonstrate the benefit of our dataset and the proposed model (72% accuracy), displaying meaningful improvement in sentiment classification performance.","sentences":["Introduction: Microblogging websites have massed rich data sources for sentiment analysis and opinion mining.","In this regard, sentiment classification has frequently proven inefficient because microblog posts typically lack syntactically consistent terms and representatives since users on these social networks do not like to write lengthy statements.","Also, there are some limitations to low-resource languages.","The Persian language has exceptional characteristics and demands unique annotated data and models for the sentiment analysis task, which are distinctive from text features within the English dialect.","Method: This paper first constructs a user opinion dataset called ITRC-Opinion by collaborative environment and insource way.","Our dataset contains 60,000 informal and colloquial Persian texts from social microblogs such as Twitter and Instagram.","Second, this study proposes a new deep convolutional neural network (CNN) model for more effective sentiment analysis of colloquial text in social microblog posts.","The constructed datasets are used to evaluate the presented model.","Furthermore, some models, such as LSTM, CNN-RNN, BiLSTM, and BiGRU with different word embeddings, including Fasttext, Glove, and Word2vec, investigated our dataset and evaluated the results.","Results:","The results demonstrate the benefit of our dataset and the proposed model (72% accuracy), displaying meaningful improvement in sentiment classification performance."],"url":"http://arxiv.org/abs/2306.12679v1"}
{"created":"2023-06-21","title":"Multi-Task Consistency for Active Learning","abstract":"Learning-based solutions for vision tasks require a large amount of labeled training data to ensure their performance and reliability. In single-task vision-based settings, inconsistency-based active learning has proven to be effective in selecting informative samples for annotation. However, there is a lack of research exploiting the inconsistency between multiple tasks in multi-task networks. To address this gap, we propose a novel multi-task active learning strategy for two coupled vision tasks: object detection and semantic segmentation. Our approach leverages the inconsistency between them to identify informative samples across both tasks. We propose three constraints that specify how the tasks are coupled and introduce a method for determining the pixels belonging to the object detected by a bounding box, to later quantify the constraints as inconsistency scores. To evaluate the effectiveness of our approach, we establish multiple baselines for multi-task active learning and introduce a new metric, mean Detection Segmentation Quality (mDSQ), tailored for the multi-task active learning comparison that addresses the performance of both tasks. We conduct extensive experiments on the nuImages and A9 datasets, demonstrating that our approach outperforms existing state-of-the-art methods by up to 3.4% mDSQ on nuImages. Our approach achieves 95% of the fully-trained performance using only 67% of the available data, corresponding to 20% fewer labels compared to random selection and 5% fewer labels compared to state-of-the-art selection strategy. Our code will be made publicly available after the review process.","sentences":["Learning-based solutions for vision tasks require a large amount of labeled training data to ensure their performance and reliability.","In single-task vision-based settings, inconsistency-based active learning has proven to be effective in selecting informative samples for annotation.","However, there is a lack of research exploiting the inconsistency between multiple tasks in multi-task networks.","To address this gap, we propose a novel multi-task active learning strategy for two coupled vision tasks: object detection and semantic segmentation.","Our approach leverages the inconsistency between them to identify informative samples across both tasks.","We propose three constraints that specify how the tasks are coupled and introduce a method for determining the pixels belonging to the object detected by a bounding box, to later quantify the constraints as inconsistency scores.","To evaluate the effectiveness of our approach, we establish multiple baselines for multi-task active learning and introduce a new metric, mean Detection Segmentation Quality (mDSQ), tailored for the multi-task active learning comparison that addresses the performance of both tasks.","We conduct extensive experiments on the nuImages and A9 datasets, demonstrating that our approach outperforms existing state-of-the-art methods by up to 3.4% mDSQ on nuImages.","Our approach achieves 95% of the fully-trained performance using only 67% of the available data, corresponding to 20% fewer labels compared to random selection and 5% fewer labels compared to state-of-the-art selection strategy.","Our code will be made publicly available after the review process."],"url":"http://arxiv.org/abs/2306.12398v1"}
{"created":"2023-06-23","title":"Bring Your Own Data! Self-Supervised Evaluation for Large Language Models","abstract":"With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative. For example, a company deploying a client-facing chatbot must ensure that the model will not respond to client requests with profanity. Current evaluations approach this problem using small, domain-specific datasets with human-curated labels. These evaluation sets are often sampled from a narrow and simplified distribution, and data sources can unknowingly be leaked into the training set which can lead to misleading evaluations. To bypass these drawbacks, we propose a framework for self-supervised evaluation of LLMs by analyzing their sensitivity or invariance to transformations on the input text. Self-supervised evaluation can directly monitor LLM behavior on datasets collected in the wild or streamed during live model deployment. We demonstrate self-supervised evaluation strategies for measuring closed-book knowledge, toxicity, and long-range context dependence, in addition to sensitivity to grammatical structure and tokenization errors. When comparisons to similar human-labeled benchmarks are available, we find strong correlations between self-supervised and human-supervised evaluations. The self-supervised paradigm complements current evaluation strategies that rely on labeled data.","sentences":["With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative.","For example, a company deploying a client-facing chatbot must ensure that the model will not respond to client requests with profanity.","Current evaluations approach this problem using small, domain-specific datasets with human-curated labels.","These evaluation sets are often sampled from a narrow and simplified distribution, and data sources can unknowingly be leaked into the training set which can lead to misleading evaluations.","To bypass these drawbacks, we propose a framework for self-supervised evaluation of LLMs by analyzing their sensitivity or invariance to transformations on the input text.","Self-supervised evaluation can directly monitor LLM behavior on datasets collected in the wild or streamed during live model deployment.","We demonstrate self-supervised evaluation strategies for measuring closed-book knowledge, toxicity, and long-range context dependence, in addition to sensitivity to grammatical structure and tokenization errors.","When comparisons to similar human-labeled benchmarks are available, we find strong correlations between self-supervised and human-supervised evaluations.","The self-supervised paradigm complements current evaluation strategies that rely on labeled data."],"url":"http://arxiv.org/abs/2306.13651v1"}
{"created":"2023-06-23","title":"Margin Maximization in Attention Mechanism","abstract":"Attention mechanism is a central component of the transformer architecture which led to the phenomenal success of large language models. However, the theoretical principles underlying the attention mechanism are poorly understood, especially its nonconvex optimization dynamics. In this work, we explore the seminal softmax-attention model $f(\\boldsymbol{X})=\\langle \\boldsymbol{Xv}, \\texttt{softmax}(\\boldsymbol{XWp})\\rangle$, where, $\\boldsymbol{X}$ is the token sequence and $(\\boldsymbol{v},\\boldsymbol{W},\\boldsymbol{p})$ are tunable parameters. We prove that running gradient descent on $\\boldsymbol{p}$, or equivalently $\\boldsymbol{W}$, converges in direction to a max-margin solution that separates $\\textit{locally-optimal}$ tokens from non-optimal ones. This clearly formalizes attention as a token separation mechanism. Remarkably, our results are applicable to general data and precisely characterize $\\textit{optimality}$ of tokens in terms of the value embeddings $\\boldsymbol{Xv}$ and problem geometry. We also provide a broader regularization path analysis that establishes the margin maximizing nature of attention even for nonlinear prediction heads. When optimizing $\\boldsymbol{v}$ and $\\boldsymbol{p}$ simultaneously with logistic loss, we identify conditions under which the regularization paths directionally converge to their respective hard-margin SVM solutions where $\\boldsymbol{v}$ separates the input features based on their labels. Interestingly, the SVM formulation of $\\boldsymbol{p}$ is influenced by the support vector geometry of $\\boldsymbol{v}$. Finally, we verify our theoretical findings via numerical experiments and provide insights.","sentences":["Attention mechanism is a central component of the transformer architecture which led to the phenomenal success of large language models.","However, the theoretical principles underlying the attention mechanism are poorly understood, especially its nonconvex optimization dynamics.","In this work, we explore the seminal softmax-attention model $f(\\boldsymbol{X})=\\langle \\boldsymbol{Xv}, \\texttt{softmax}(\\boldsymbol{XWp})\\rangle$, where, $\\boldsymbol{X}$ is the token sequence and $(\\boldsymbol{v},\\boldsymbol{W},\\boldsymbol{p})$ are tunable parameters.","We prove that running gradient descent on $\\boldsymbol{p}$, or equivalently $\\boldsymbol{W}$, converges in direction to a max-margin solution that separates $\\textit{locally-optimal}$ tokens from non-optimal ones.","This clearly formalizes attention as a token separation mechanism.","Remarkably, our results are applicable to general data and precisely characterize $\\textit{optimality}$ of tokens in terms of the value embeddings $\\boldsymbol{Xv}$ and problem geometry.","We also provide a broader regularization path analysis that establishes the margin maximizing nature of attention even for nonlinear prediction heads.","When optimizing $\\boldsymbol{v}$ and $\\boldsymbol{p}$ simultaneously with logistic loss, we identify conditions under which the regularization paths directionally converge to their respective hard-margin SVM solutions where $\\boldsymbol{v}$ separates the input features based on their labels.","Interestingly, the SVM formulation of $\\boldsymbol{p}$ is influenced by the support vector geometry of $\\boldsymbol{v}$. Finally, we verify our theoretical findings via numerical experiments and provide insights."],"url":"http://arxiv.org/abs/2306.13596v1"}
{"created":"2023-06-23","title":"A Semi-Paired Approach For Label-to-Image Translation","abstract":"Data efficiency, or the ability to generalize from a few labeled data, remains a major challenge in deep learning. Semi-supervised learning has thrived in traditional recognition tasks alleviating the need for large amounts of labeled data, yet it remains understudied in image-to-image translation (I2I) tasks. In this work, we introduce the first semi-supervised (semi-paired) framework for label-to-image translation, a challenging subtask of I2I which generates photorealistic images from semantic label maps. In the semi-paired setting, the model has access to a small set of paired data and a larger set of unpaired images and labels. Instead of using geometrical transformations as a pretext task like previous works, we leverage an input reconstruction task by exploiting the conditional discriminator on the paired data as a reverse generator. We propose a training algorithm for this shared network, and we present a rare classes sampling algorithm to focus on under-represented classes. Experiments on 3 standard benchmarks show that the proposed model outperforms state-of-the-art unsupervised and semi-supervised approaches, as well as some fully supervised approaches while using a much smaller number of paired samples.","sentences":["Data efficiency, or the ability to generalize from a few labeled data, remains a major challenge in deep learning.","Semi-supervised learning has thrived in traditional recognition tasks alleviating the need for large amounts of labeled data, yet it remains understudied in image-to-image translation (I2I) tasks.","In this work, we introduce the first semi-supervised (semi-paired) framework for label-to-image translation, a challenging subtask of I2I which generates photorealistic images from semantic label maps.","In the semi-paired setting, the model has access to a small set of paired data and a larger set of unpaired images and labels.","Instead of using geometrical transformations as a pretext task like previous works, we leverage an input reconstruction task by exploiting the conditional discriminator on the paired data as a reverse generator.","We propose a training algorithm for this shared network, and we present a rare classes sampling algorithm to focus on under-represented classes.","Experiments on 3 standard benchmarks show that the proposed model outperforms state-of-the-art unsupervised and semi-supervised approaches, as well as some fully supervised approaches while using a much smaller number of paired samples."],"url":"http://arxiv.org/abs/2306.13585v1"}
{"created":"2023-06-23","title":"PathMLP: Smooth Path Towards High-order Homophily","abstract":"Real-world graphs exhibit increasing heterophily, where nodes no longer tend to be connected to nodes with the same label, challenging the homophily assumption of classical graph neural networks (GNNs) and impeding their performance. Intriguingly, we observe that certain high-order information on heterophilous data exhibits high homophily, which motivates us to involve high-order information in node representation learning. However, common practices in GNNs to acquire high-order information mainly through increasing model depth and altering message-passing mechanisms, which, albeit effective to a certain extent, suffer from three shortcomings: 1) over-smoothing due to excessive model depth and propagation times; 2) high-order information is not fully utilized; 3) low computational efficiency. In this regard, we design a similarity-based path sampling strategy to capture smooth paths containing high-order homophily. Then we propose a lightweight model based on multi-layer perceptrons (MLP), named PathMLP, which can encode messages carried by paths via simple transformation and concatenation operations, and effectively learn node representations in heterophilous graphs through adaptive path aggregation. Extensive experiments demonstrate that our method outperforms baselines on 16 out of 20 datasets, underlining its effectiveness and superiority in alleviating the heterophily problem. In addition, our method is immune to over-smoothing and has high computational efficiency.","sentences":["Real-world graphs exhibit increasing heterophily, where nodes no longer tend to be connected to nodes with the same label, challenging the homophily assumption of classical graph neural networks (GNNs) and impeding their performance.","Intriguingly, we observe that certain high-order information on heterophilous data exhibits high homophily, which motivates us to involve high-order information in node representation learning.","However, common practices in GNNs to acquire high-order information mainly through increasing model depth and altering message-passing mechanisms, which, albeit effective to a certain extent, suffer from three shortcomings: 1) over-smoothing due to excessive model depth and propagation times; 2) high-order information is not fully utilized; 3) low computational efficiency.","In this regard, we design a similarity-based path sampling strategy to capture smooth paths containing high-order homophily.","Then we propose a lightweight model based on multi-layer perceptrons (MLP), named PathMLP, which can encode messages carried by paths via simple transformation and concatenation operations, and effectively learn node representations in heterophilous graphs through adaptive path aggregation.","Extensive experiments demonstrate that our method outperforms baselines on 16 out of 20 datasets, underlining its effectiveness and superiority in alleviating the heterophily problem.","In addition, our method is immune to over-smoothing and has high computational efficiency."],"url":"http://arxiv.org/abs/2306.13532v1"}
{"created":"2023-06-23","title":"Understanding quantum machine learning also requires rethinking generalization","abstract":"Quantum machine learning models have shown successful generalization performance even when trained with few data. In this work, through systematic randomization experiments, we show that traditional approaches to understanding generalization fail to explain the behavior of such quantum models. Our experiments reveal that state-of-the-art quantum neural networks accurately fit random states and random labeling of training data. This ability to memorize random data defies current notions of small generalization error, problematizing approaches that build on complexity measures such as the VC dimension, the Rademacher complexity, and all their uniform relatives. We complement our empirical results with a theoretical construction showing that quantum neural networks can fit arbitrary labels to quantum states, hinting at their memorization ability. Our results do not preclude the possibility of good generalization with few training data but rather rule out any possible guarantees based only on the properties of the model family. These findings expose a fundamental challenge in the conventional understanding of generalization in quantum machine learning and highlight the need for a paradigm shift in the design of quantum models for machine learning tasks.","sentences":["Quantum machine learning models have shown successful generalization performance even when trained with few data.","In this work, through systematic randomization experiments, we show that traditional approaches to understanding generalization fail to explain the behavior of such quantum models.","Our experiments reveal that state-of-the-art quantum neural networks accurately fit random states and random labeling of training data.","This ability to memorize random data defies current notions of small generalization error, problematizing approaches that build on complexity measures such as the VC dimension, the Rademacher complexity, and all their uniform relatives.","We complement our empirical results with a theoretical construction showing that quantum neural networks can fit arbitrary labels to quantum states, hinting at their memorization ability.","Our results do not preclude the possibility of good generalization with few training data but rather rule out any possible guarantees based only on the properties of the model family.","These findings expose a fundamental challenge in the conventional understanding of generalization in quantum machine learning and highlight the need for a paradigm shift in the design of quantum models for machine learning tasks."],"url":"http://arxiv.org/abs/2306.13461v1"}
{"created":"2023-06-23","title":"CLUE: Calibrated Latent Guidance for Offline Reinforcement Learning","abstract":"Offline reinforcement learning (RL) aims to learn an optimal policy from pre-collected and labeled datasets, which eliminates the time-consuming data collection in online RL. However, offline RL still bears a large burden of specifying/handcrafting extrinsic rewards for each transition in the offline data. As a remedy for the labor-intensive labeling, we propose to endow offline RL tasks with a few expert data and utilize the limited expert data to drive intrinsic rewards, thus eliminating the need for extrinsic rewards. To achieve that, we introduce \\textbf{C}alibrated \\textbf{L}atent g\\textbf{U}idanc\\textbf{E} (CLUE), which utilizes a conditional variational auto-encoder to learn a latent space such that intrinsic rewards can be directly qualified over the latent space. CLUE's key idea is to align the intrinsic rewards consistent with the expert intention via enforcing the embeddings of expert data to a calibrated contextual representation. We instantiate the expert-driven intrinsic rewards in sparse-reward offline RL tasks, offline imitation learning (IL) tasks, and unsupervised offline RL tasks. Empirically, we find that CLUE can effectively improve the sparse-reward offline RL performance, outperform the state-of-the-art offline IL baselines, and discover diverse skills from static reward-free offline data.","sentences":["Offline reinforcement learning (RL) aims to learn an optimal policy from pre-collected and labeled datasets, which eliminates the time-consuming data collection in online RL.","However, offline RL still bears a large burden of specifying/handcrafting extrinsic rewards for each transition in the offline data.","As a remedy for the labor-intensive labeling, we propose to endow offline RL tasks with a few expert data and utilize the limited expert data to drive intrinsic rewards, thus eliminating the need for extrinsic rewards.","To achieve that, we introduce \\textbf{C}alibrated \\textbf{L}atent g\\textbf{U}idanc\\textbf{E} (CLUE), which utilizes a conditional variational auto-encoder to learn a latent space such that intrinsic rewards can be directly qualified over the latent space.","CLUE's key idea is to align the intrinsic rewards consistent with the expert intention via enforcing the embeddings of expert data to a calibrated contextual representation.","We instantiate the expert-driven intrinsic rewards in sparse-reward offline RL tasks, offline imitation learning (IL) tasks, and unsupervised offline RL tasks.","Empirically, we find that CLUE can effectively improve the sparse-reward offline RL performance, outperform the state-of-the-art offline IL baselines, and discover diverse skills from static reward-free offline data."],"url":"http://arxiv.org/abs/2306.13412v1"}
{"created":"2023-06-23","title":"Judging a book by its cover: how much of REF `research quality' is really `journal prestige'?","abstract":"The Research Excellence Framework (REF) is a periodic UK-wide assessment of the quality of published research in universities. The most recent REF was in 2014, and the next will be in 2021. The published results of REF2014 include a categorical `quality profile' for each unit of assessment (typically a university department), reporting what percentage of the unit's REF-submitted research outputs were assessed as being at each of four quality levels (labelled 4*, 3*, 2* and 1*). Also in the public domain are the original submissions made to REF2014, which include -- for each unit of assessment -- publication details of the REF-submitted research outputs.   In this work, we address the question: to what extent can a REF quality profile for research outputs be attributed to the journals in which (most of) those outputs were published? The data are the published submissions and results from REF2014. The main statistical challenge comes from the fact that REF quality profiles are available only at the aggregated level of whole units of assessment: the REF panel's assessment of each individual research output is not made public. Our research question is thus an `ecological inference' problem, which demands special care in model formulation and methodology. The analysis is based on logit models in which journal-specific parameters are regularized via prior `pseudo-data'. We develop a lack-of-fit measure for the extent to which REF scores appear to depend on publication venues rather than research quality or institution-level differences. Results are presented for several research fields.","sentences":["The Research Excellence Framework (REF) is a periodic UK-wide assessment of the quality of published research in universities.","The most recent REF was in 2014, and the next will be in 2021.","The published results of REF2014 include a categorical `quality profile' for each unit of assessment (typically a university department), reporting what percentage of the unit's REF-submitted research outputs were assessed as being at each of four quality levels (labelled 4*, 3*, 2* and 1*).","Also in the public domain are the original submissions made to REF2014, which include -- for each unit of assessment -- publication details of the REF-submitted research outputs.   ","In this work, we address the question: to what extent can a REF quality profile for research outputs be attributed to the journals in which (most of) those outputs were published?","The data are the published submissions and results from REF2014.","The main statistical challenge comes from the fact that REF quality profiles are available only at the aggregated level of whole units of assessment: the REF panel's assessment of each individual research output is not made public.","Our research question is thus an `ecological inference' problem, which demands special care in model formulation and methodology.","The analysis is based on logit models in which journal-specific parameters are regularized via prior `pseudo-data'.","We develop a lack-of-fit measure for the extent to which REF scores appear to depend on publication venues rather than research quality or institution-level differences.","Results are presented for several research fields."],"url":"http://arxiv.org/abs/2306.13367v1"}
{"created":"2023-06-23","title":"Unsupervised Deformable Ultrasound Image Registration and Its Application for Vessel Segmentation","abstract":"This paper presents a deep-learning model for deformable registration of ultrasound images at online rates, which we call U-RAFT. As its name suggests, U-RAFT is based on RAFT, a convolutional neural network for estimating optical flow. U-RAFT, however, can be trained in an unsupervised manner and can generate synthetic images for training vessel segmentation models. We propose and compare the registration quality of different loss functions for training U-RAFT. We also show how our approach, together with a robot performing force-controlled scans, can be used to generate synthetic deformed images to significantly expand the size of a femoral vessel segmentation training dataset without the need for additional manual labeling. We validate our approach on both a silicone human tissue phantom as well as on in-vivo porcine images. We show that U-RAFT generates synthetic ultrasound images with 98% and 81% structural similarity index measure (SSIM) to the real ultrasound images for the phantom and porcine datasets, respectively. We also demonstrate that synthetic deformed images from U-RAFT can be used as a data augmentation technique for vessel segmentation models to improve intersection-over-union (IoU) segmentation performance","sentences":["This paper presents a deep-learning model for deformable registration of ultrasound images at online rates, which we call U-RAFT.","As its name suggests, U-RAFT is based on RAFT, a convolutional neural network for estimating optical flow.","U-RAFT, however, can be trained in an unsupervised manner and can generate synthetic images for training vessel segmentation models.","We propose and compare the registration quality of different loss functions for training U-RAFT.","We also show how our approach, together with a robot performing force-controlled scans, can be used to generate synthetic deformed images to significantly expand the size of a femoral vessel segmentation training dataset without the need for additional manual labeling.","We validate our approach on both a silicone human tissue phantom as well as on in-vivo porcine images.","We show that U-RAFT generates synthetic ultrasound images with 98% and 81% structural similarity index measure (SSIM) to the real ultrasound images for the phantom and porcine datasets, respectively.","We also demonstrate that synthetic deformed images from U-RAFT can be used as a data augmentation technique for vessel segmentation models to improve intersection-over-union (IoU) segmentation performance"],"url":"http://arxiv.org/abs/2306.13329v1"}
{"created":"2023-06-23","title":"Mutually Guided Few-shot Learning for Relational Triple Extraction","abstract":"Knowledge graphs (KGs), containing many entity-relation-entity triples, provide rich information for downstream applications. Although extracting triples from unstructured texts has been widely explored, most of them require a large number of labeled instances. The performance will drop dramatically when only few labeled data are available. To tackle this problem, we propose the Mutually Guided Few-shot learning framework for Relational Triple Extraction (MG-FTE). Specifically, our method consists of an entity-guided relation proto-decoder to classify the relations firstly and a relation-guided entity proto-decoder to extract entities based on the classified relations. To draw the connection between entity and relation, we design a proto-level fusion module to boost the performance of both entity extraction and relation classification. Moreover, a new cross-domain few-shot triple extraction task is introduced. Extensive experiments show that our method outperforms many state-of-the-art methods by 12.6 F1 score on FewRel 1.0 (single-domain) and 20.5 F1 score on FewRel 2.0 (cross-domain).","sentences":["Knowledge graphs (KGs), containing many entity-relation-entity triples, provide rich information for downstream applications.","Although extracting triples from unstructured texts has been widely explored, most of them require a large number of labeled instances.","The performance will drop dramatically when only few labeled data are available.","To tackle this problem, we propose the Mutually Guided Few-shot learning framework for Relational Triple Extraction (MG-FTE).","Specifically, our method consists of an entity-guided relation proto-decoder to classify the relations firstly and a relation-guided entity proto-decoder to extract entities based on the classified relations.","To draw the connection between entity and relation, we design a proto-level fusion module to boost the performance of both entity extraction and relation classification.","Moreover, a new cross-domain few-shot triple extraction task is introduced.","Extensive experiments show that our method outperforms many state-of-the-art methods by 12.6 F1 score on FewRel 1.0 (single-domain) and 20.5 F1 score on FewRel 2.0 (cross-domain)."],"url":"http://arxiv.org/abs/2306.13310v1"}
{"created":"2023-06-23","title":"Deep Omni-supervised Learning for Rib Fracture Detection from Chest Radiology Images","abstract":"Deep learning (DL)-based rib fracture detection has shown promise of playing an important role in preventing mortality and improving patient outcome. Normally, developing DL-based object detection models requires huge amount of bounding box annotation. However, annotating medical data is time-consuming and expertise-demanding, making obtaining a large amount of fine-grained annotations extremely infeasible. This poses pressing need of developing label-efficient detection models to alleviate radiologists' labeling burden. To tackle this challenge, the literature of object detection has witnessed an increase of weakly-supervised and semi-supervised approaches, yet still lacks a unified framework that leverages various forms of fully-labeled, weakly-labeled, and unlabeled data. In this paper, we present a novel omni-supervised object detection network, ORF-Netv2, to leverage as much available supervision as possible. Specifically, a multi-branch omni-supervised detection head is introduced with each branch trained with a specific type of supervision. A co-training-based dynamic label assignment strategy is then proposed to enable flexibly and robustly learning from the weakly-labeled and unlabeled data. Extensively evaluation was conducted for the proposed framework with three rib fracture datasets on both chest CT and X-ray. By leveraging all forms of supervision, ORF-Netv2 achieves mAPs of 34.7, 44.7, and 19.4 on the three datasets, respectively, surpassing the baseline detector which uses only box annotations by mAP gains of 3.8, 4.8, and 5.0, respectively. Furthermore, ORF-Netv2 consistently outperforms other competitive label-efficient methods over various scenarios, showing a promising framework for label-efficient fracture detection.","sentences":["Deep learning (DL)-based rib fracture detection has shown promise of playing an important role in preventing mortality and improving patient outcome.","Normally, developing DL-based object detection models requires huge amount of bounding box annotation.","However, annotating medical data is time-consuming and expertise-demanding, making obtaining a large amount of fine-grained annotations extremely infeasible.","This poses pressing need of developing label-efficient detection models to alleviate radiologists' labeling burden.","To tackle this challenge, the literature of object detection has witnessed an increase of weakly-supervised and semi-supervised approaches, yet still lacks a unified framework that leverages various forms of fully-labeled, weakly-labeled, and unlabeled data.","In this paper, we present a novel omni-supervised object detection network, ORF-Netv2, to leverage as much available supervision as possible.","Specifically, a multi-branch omni-supervised detection head is introduced with each branch trained with a specific type of supervision.","A co-training-based dynamic label assignment strategy is then proposed to enable flexibly and robustly learning from the weakly-labeled and unlabeled data.","Extensively evaluation was conducted for the proposed framework with three rib fracture datasets on both chest CT and X-ray.","By leveraging all forms of supervision, ORF-Netv2 achieves mAPs of 34.7, 44.7, and 19.4 on the three datasets, respectively, surpassing the baseline detector which uses only box annotations by mAP gains of 3.8, 4.8, and 5.0, respectively.","Furthermore, ORF-Netv2 consistently outperforms other competitive label-efficient methods over various scenarios, showing a promising framework for label-efficient fracture detection."],"url":"http://arxiv.org/abs/2306.13301v1"}
{"created":"2023-06-23","title":"Quasiparticle spectroscopy in technologically-relevant niobium using London penetration depth measurements","abstract":"London penetration depth was measured in niobium foils, thin films, single crystals, and superconducting radio-frequency (SRF) cavity pieces cut out from different places. The low-temperature (T<Tc/3) variation, sensitive to the low-energy quasiparticles with states inside the superconducting gap, differs dramatically between different types of samples. With the help of phenomenological modeling, we correlate these different behaviors with known pair-breaking mechanisms and show that such measurements may help distinguish between different pair-breaking mechanisms, such as niobium hydrides and two-level systems (TLS). The conclusions also apply to SRF cavities when tracking the temperature-dependent quality factor and the resonant frequency.","sentences":["London penetration depth was measured in niobium foils, thin films, single crystals, and superconducting radio-frequency (SRF) cavity pieces cut out from different places.","The low-temperature (T<Tc/3) variation, sensitive to the low-energy quasiparticles with states inside the superconducting gap, differs dramatically between different types of samples.","With the help of phenomenological modeling, we correlate these different behaviors with known pair-breaking mechanisms and show that such measurements may help distinguish between different pair-breaking mechanisms, such as niobium hydrides and two-level systems (TLS).","The conclusions also apply to SRF cavities when tracking the temperature-dependent quality factor and the resonant frequency."],"url":"http://arxiv.org/abs/2306.13654v1"}
{"created":"2023-06-23","title":"ProRes: Exploring Degradation-aware Visual Prompt for Universal Image Restoration","abstract":"Image restoration aims to reconstruct degraded images, e.g., denoising or deblurring. Existing works focus on designing task-specific methods and there are inadequate attempts at universal methods. However, simply unifying multiple tasks into one universal architecture suffers from uncontrollable and undesired predictions. To address those issues, we explore prompt learning in universal architectures for image restoration tasks. In this paper, we present Degradation-aware Visual Prompts, which encode various types of image degradation, e.g., noise and blur, into unified visual prompts. These degradation-aware prompts provide control over image processing and allow weighted combinations for customized image restoration. We then leverage degradation-aware visual prompts to establish a controllable and universal model for image restoration, called ProRes, which is applicable to an extensive range of image restoration tasks. ProRes leverages the vanilla Vision Transformer (ViT) without any task-specific designs. Furthermore, the pre-trained ProRes can easily adapt to new tasks through efficient prompt tuning with only a few images. Without bells and whistles, ProRes achieves competitive performance compared to task-specific methods and experiments can demonstrate its ability for controllable restoration and adaptation for new tasks. The code and models will be released in \\url{https://github.com/leonmakise/ProRes}.","sentences":["Image restoration aims to reconstruct degraded images, e.g., denoising or deblurring.","Existing works focus on designing task-specific methods and there are inadequate attempts at universal methods.","However, simply unifying multiple tasks into one universal architecture suffers from uncontrollable and undesired predictions.","To address those issues, we explore prompt learning in universal architectures for image restoration tasks.","In this paper, we present Degradation-aware Visual Prompts, which encode various types of image degradation, e.g., noise and blur, into unified visual prompts.","These degradation-aware prompts provide control over image processing and allow weighted combinations for customized image restoration.","We then leverage degradation-aware visual prompts to establish a controllable and universal model for image restoration, called ProRes, which is applicable to an extensive range of image restoration tasks.","ProRes leverages the vanilla Vision Transformer (ViT) without any task-specific designs.","Furthermore, the pre-trained ProRes can easily adapt to new tasks through efficient prompt tuning with only a few images.","Without bells and whistles, ProRes achieves competitive performance compared to task-specific methods and experiments can demonstrate its ability for controllable restoration and adaptation for new tasks.","The code and models will be released in \\url{https://github.com/leonmakise/ProRes}."],"url":"http://arxiv.org/abs/2306.13653v1"}
{"created":"2023-06-23","title":"Classical time crystal Ginzburg-Landau study of coupled parametric oscillators","abstract":"Discrete time crystals, which are phases of matter that break the discrete time translational symmetry of a periodically driven system, have generated a wave of recent interest and activity. In this work, we propose a classical system of weakly nonlinear parametrically driven coupled oscillators as a testbed to understand these phases. Such a system of oscillators in the presence of dissipation has a period-doubling instability only at long wavelengths where a large number of oscillators are in phase. To show that this instability leads to a discrete time crystal when exposed to noise and non-linearity, we derive a general condition to predict when a Markov process will break time-translation symmetry. The first requirement of this condition is that the Markov chain over doubled time steps has a stationary probability distribution that spontaneously breaks a local symmetry. The second requirement is that the order parameter flips sign over a single time step. We show that our system of oscillators features period-doubling and yields a stationary probability distribution given by a spatially continuous Ginzburg-Landau Hamiltonian with spontaneous symmetry breaking. We then discuss applications of the general condition to existing time crystal platforms.","sentences":["Discrete time crystals, which are phases of matter that break the discrete time translational symmetry of a periodically driven system, have generated a wave of recent interest and activity.","In this work, we propose a classical system of weakly nonlinear parametrically driven coupled oscillators as a testbed to understand these phases.","Such a system of oscillators in the presence of dissipation has a period-doubling instability only at long wavelengths where a large number of oscillators are in phase.","To show that this instability leads to a discrete time crystal when exposed to noise and non-linearity, we derive a general condition to predict when a Markov process will break time-translation symmetry.","The first requirement of this condition is that the Markov chain over doubled time steps has a stationary probability distribution that spontaneously breaks a local symmetry.","The second requirement is that the order parameter flips sign over a single time step.","We show that our system of oscillators features period-doubling and yields a stationary probability distribution given by a spatially continuous Ginzburg-Landau Hamiltonian with spontaneous symmetry breaking.","We then discuss applications of the general condition to existing time crystal platforms."],"url":"http://arxiv.org/abs/2306.13652v1"}
{"created":"2023-06-23","title":"Bring Your Own Data! Self-Supervised Evaluation for Large Language Models","abstract":"With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative. For example, a company deploying a client-facing chatbot must ensure that the model will not respond to client requests with profanity. Current evaluations approach this problem using small, domain-specific datasets with human-curated labels. These evaluation sets are often sampled from a narrow and simplified distribution, and data sources can unknowingly be leaked into the training set which can lead to misleading evaluations. To bypass these drawbacks, we propose a framework for self-supervised evaluation of LLMs by analyzing their sensitivity or invariance to transformations on the input text. Self-supervised evaluation can directly monitor LLM behavior on datasets collected in the wild or streamed during live model deployment. We demonstrate self-supervised evaluation strategies for measuring closed-book knowledge, toxicity, and long-range context dependence, in addition to sensitivity to grammatical structure and tokenization errors. When comparisons to similar human-labeled benchmarks are available, we find strong correlations between self-supervised and human-supervised evaluations. The self-supervised paradigm complements current evaluation strategies that rely on labeled data.","sentences":["With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative.","For example, a company deploying a client-facing chatbot must ensure that the model will not respond to client requests with profanity.","Current evaluations approach this problem using small, domain-specific datasets with human-curated labels.","These evaluation sets are often sampled from a narrow and simplified distribution, and data sources can unknowingly be leaked into the training set which can lead to misleading evaluations.","To bypass these drawbacks, we propose a framework for self-supervised evaluation of LLMs by analyzing their sensitivity or invariance to transformations on the input text.","Self-supervised evaluation can directly monitor LLM behavior on datasets collected in the wild or streamed during live model deployment.","We demonstrate self-supervised evaluation strategies for measuring closed-book knowledge, toxicity, and long-range context dependence, in addition to sensitivity to grammatical structure and tokenization errors.","When comparisons to similar human-labeled benchmarks are available, we find strong correlations between self-supervised and human-supervised evaluations.","The self-supervised paradigm complements current evaluation strategies that rely on labeled data."],"url":"http://arxiv.org/abs/2306.13651v1"}
{"created":"2023-06-23","title":"Schwarzschild deformed supergravity background: possible geometry origin of fermion generations and mass hierarchy","abstract":"The problem of fermion masses hierarchy in the Standard Model is considered on a toy model of a 10-dimensional space-time with a IIA supergravity type background. Dirac equation on this background, after compactification of extra 4- and 1-dimensional subspaces, gives the spectrum of Fermi fields which profiles in 5 dimensions and corresponding Higgs generated masses in 4 dimensions depend on the eigenvalues of Dirac operator on the named compact subspaces. Schwarzschild Euclidean deformation of the supergravity throat with the \"apple-shaped\" conical singularity permits to leave only three non-divergent angular modes interpreted as three generations of the down-type quarks. Calculated ratios of their masses are close to the experimentally observed values for a natural choice of parameters of 10-dimensional geometry. Equations for non-chiral modes coincide with the non-relativistic Schr\\\"odinger equation for an electron moving in a Coulomb field; the corresponding small fermion masses generated by the twisted boundary conditions are expressed through the degenerate hypergeometric functions.","sentences":["The problem of fermion masses hierarchy in the Standard Model is considered on a toy model of a 10-dimensional space-time with a IIA supergravity type background.","Dirac equation on this background, after compactification of extra 4- and 1-dimensional subspaces, gives the spectrum of Fermi fields which profiles in 5 dimensions and corresponding Higgs generated masses in 4 dimensions depend on the eigenvalues of Dirac operator on the named compact subspaces.","Schwarzschild Euclidean deformation of the supergravity throat with the \"apple-shaped\" conical singularity permits to leave only three non-divergent angular modes interpreted as three generations of the down-type quarks.","Calculated ratios of their masses are close to the experimentally observed values for a natural choice of parameters of 10-dimensional geometry.","Equations for non-chiral modes coincide with the non-relativistic Schr\\\"odinger equation for an electron moving in a Coulomb field; the corresponding small fermion masses generated by the twisted boundary conditions are expressed through the degenerate hypergeometric functions."],"url":"http://arxiv.org/abs/2306.13650v1"}
{"created":"2023-06-23","title":"GKD: Generalized Knowledge Distillation for Auto-regressive Sequence Models","abstract":"Knowledge distillation is commonly used for compressing neural networks to reduce their inference cost and memory footprint. However, current distillation methods for auto-regressive models, such as generative language models (LMs), suffer from two key issues: (1) distribution mismatch between output sequences during training and the sequences generated by the student during its deployment, and (2) model under-specification, where the student model may not be expressive enough to fit the teacher's distribution. To address these issues, we propose Generalized Knowledge Distillation (GKD). GKD mitigates distribution mismatch by sampling output sequences from the student during training. Furthermore, GKD handles model under-specification by optimizing alternative divergences, such as reverse KL, that focus on generating samples from the student that are likely under the teacher's distribution. We demonstrate that GKD outperforms commonly-used approaches for distilling LLMs on summarization, machine translation, and arithmetic reasoning tasks.","sentences":["Knowledge distillation is commonly used for compressing neural networks to reduce their inference cost and memory footprint.","However, current distillation methods for auto-regressive models, such as generative language models (LMs), suffer from two key issues: (1) distribution mismatch between output sequences during training and the sequences generated by the student during its deployment, and (2) model under-specification, where the student model may not be expressive enough to fit the teacher's distribution.","To address these issues, we propose Generalized Knowledge Distillation (GKD).","GKD mitigates distribution mismatch by sampling output sequences from the student during training.","Furthermore, GKD handles model under-specification by optimizing alternative divergences, such as reverse KL, that focus on generating samples from the student that are likely under the teacher's distribution.","We demonstrate that GKD outperforms commonly-used approaches for distilling LLMs on summarization, machine translation, and arithmetic reasoning tasks."],"url":"http://arxiv.org/abs/2306.13649v1"}
{"created":"2023-06-23","title":"Spatially resolved dielectric loss at the Si/SiO$_2$ interface","abstract":"The Si/SiO$_2$ interface is populated by isolated trap states which modify its electronic properties. These traps are of critical interest for the development of semiconductor-based quantum sensors and computers, as well as nanoelectronic devices. Here, we study the electric susceptibility of the Si/SiO$_2$ interface with nm spatial resolution using frequency-modulated atomic force microscopy to measure a patterned dopant delta-layer buried 2 nm beneath the silicon native oxide interface. We show that surface charge organization timescales, which range from 1-150 ns, increase significantly around interfacial states. We conclude that dielectric loss under time-varying gate biases at MHz and sub-MHz frequencies in metal-insulator-semiconductor capacitor device architectures is highly spatially heterogeneous over nm length scales.","sentences":["The Si/SiO$_2$ interface is populated by isolated trap states which modify its electronic properties.","These traps are of critical interest for the development of semiconductor-based quantum sensors and computers, as well as nanoelectronic devices.","Here, we study the electric susceptibility of the Si/SiO$_2$ interface with nm spatial resolution using frequency-modulated atomic force microscopy to measure a patterned dopant delta-layer buried 2 nm beneath the silicon native oxide interface.","We show that surface charge organization timescales, which range from 1-150 ns, increase significantly around interfacial states.","We conclude that dielectric loss under time-varying gate biases at MHz and sub-MHz frequencies in metal-insulator-semiconductor capacitor device architectures is highly spatially heterogeneous over nm length scales."],"url":"http://arxiv.org/abs/2306.13648v1"}
{"created":"2023-06-23","title":"Vorticity and level-set variations of invariant current bound steady-state dissipation","abstract":"A non-vanishing entropy production rate is a hallmark of non-equilibrium stationary states and is therefore at the heart of non-equilibrium thermodynamics. It is a manifestation of a steady circulation $J_{\\rm inv}$ along the level sets of the invariant density $\\rho_{\\rm inv}$, and is thus generically used to quantify how far a steady system is driven out of equilibrium. While it is well known that there exists a continuum of distinct steady states with the same invariant measure, the question how the geometry and topology of the invariant current a priori affect dissipation remained elusive. For confined irreversible diffusions we identify two minimal descriptors, the $\\rho_{\\rm inv}$-weighted vorticity and the variation of $J_{\\rm inv}$ along level sets of $\\rho_{\\rm inv}$, and prove that these jointly bound from above the steady-state entropy production rate. In regions where $\\rho_{\\rm inv}$ is close to Gaussian the bound is dominated solely by the vorticity of the drift field and in the low-noise (Freidlin-Wentzel) limit by any non-potential contribution to the drift, rendering $J_{\\rm inv}$ virtually constant along the level sets of $\\rho_{\\rm inv}$.","sentences":["A non-vanishing entropy production rate is a hallmark of non-equilibrium stationary states and is therefore at the heart of non-equilibrium thermodynamics.","It is a manifestation of a steady circulation $J_{\\rm inv}$ along the level sets of the invariant density $\\rho_{\\rm inv}$, and is thus generically used to quantify how far a steady system is driven out of equilibrium.","While it is well known that there exists a continuum of distinct steady states with the same invariant measure, the question how the geometry and topology of the invariant current a priori affect dissipation remained elusive.","For confined irreversible diffusions we identify two minimal descriptors, the $\\rho_{\\rm inv}$-weighted vorticity and the variation of $J_{\\rm inv}$ along level sets of $\\rho_{\\rm inv}$, and prove that these jointly bound from above the steady-state entropy production rate.","In regions where $\\rho_{\\rm inv}$ is close to Gaussian the bound is dominated solely by the vorticity of the drift field and in the low-noise (Freidlin-Wentzel) limit by any non-potential contribution to the drift, rendering $J_{\\rm inv}$ virtually constant along the level sets of $\\rho_{\\rm inv}$."],"url":"http://arxiv.org/abs/2306.13647v1"}
{"created":"2023-06-23","title":"Perfect single-photon sources","abstract":"We introduce the \"gapped coherent state\" in the form of a single-photon source (SPS) that consists of uncorrelated photons as a background, except that we demand that no two photons can be closer in time than a time gap $t_\\mathrm{G}$. While no obvious quantum mechanism is yet identified to produce exactly such a photon stream, a numerical simulation is easily achieved by first generating an uncorrelated (Poissonian) signal and then for each photon in the list, either adding such a time gap or removing all successive photons that are closer in time from any photon that is kept than $t_\\mathrm{G}$. We study the statistical properties of such a hypothetical signal, which exhibits counter-intuitive features. This provides a neat and natural connection between continuous-wave (stationary) and pulsed single-photon sources, with also a bearing on what it means for such sources to be perfect in terms of single-photon emission.","sentences":["We introduce the \"gapped coherent state\" in the form of a single-photon source (SPS) that consists of uncorrelated photons as a background, except that we demand that no two photons can be closer in time than a time gap $t_\\mathrm{G}$. While no obvious quantum mechanism is yet identified to produce exactly such a photon stream, a numerical simulation is easily achieved by first generating an uncorrelated (Poissonian) signal and then for each photon in the list, either adding such a time gap or removing all successive photons that are closer in time from any photon that is kept than $t_\\mathrm{G}$. We study the statistical properties of such a hypothetical signal, which exhibits counter-intuitive features.","This provides a neat and natural connection between continuous-wave (stationary) and pulsed single-photon sources, with also a bearing on what it means for such sources to be perfect in terms of single-photon emission."],"url":"http://arxiv.org/abs/2306.13646v1"}
{"created":"2023-06-23","title":"Characterising a World Within the Hot Neptune Desert: Transit Observations of LTT 9779 b with HST WFC3","abstract":"We present an atmospheric analysis of LTT 9779 b, a rare planet situated in the hot Neptune desert, that has been observed with HST WFC3 G102 and G141. The combined transmission spectrum, which covers 0.8 - 1.6 $\\mu$m, shows a gradual increase in transit depth with wavelength. Our preferred atmospheric model shows evidence for H$_{\\rm 2}$O, CO$_{\\rm 2}$ and FeH with a significance of 3.1 $\\sigma$, 2.4 $\\sigma$ and 2.1 $\\sigma$, respectively. In an attempt to constrain the rate of atmospheric escape for this planet, we search for the 1.083 $\\mu$m Helium line in the G102 data but find no evidence of excess absorption that would indicate an escaping atmosphere using this tracer. We refine the orbital ephemerides of LTT 9779 b using our HST data and observations from TESS, searching for evidence of orbital decay or apsidal precession, which is not found. The phase-curve observation of LTT 9779 b with JWST NIRISS should provide deeper insights into the atmosphere of this planet and the expected atmospheric escape might be detected with further observations concentrated on other tracers such as Lyman $\\alpha$.","sentences":["We present an atmospheric analysis of LTT 9779 b, a rare planet situated in the hot Neptune desert, that has been observed with HST WFC3 G102 and G141.","The combined transmission spectrum, which covers 0.8 - 1.6 $\\mu$m, shows a gradual increase in transit depth with wavelength.","Our preferred atmospheric model shows evidence for H$_{\\rm 2}$O, CO$_{\\rm 2}$ and FeH with a significance of 3.1 $\\sigma$, 2.4 $\\sigma$ and 2.1 $\\sigma$, respectively.","In an attempt to constrain the rate of atmospheric escape for this planet, we search for the 1.083 $\\mu$m Helium line in the G102 data but find no evidence of excess absorption that would indicate an escaping atmosphere using this tracer.","We refine the orbital ephemerides of LTT 9779 b using our HST data and observations from TESS, searching for evidence of orbital decay or apsidal precession, which is not found.","The phase-curve observation of LTT 9779 b with JWST NIRISS should provide deeper insights into the atmosphere of this planet and the expected atmospheric escape might be detected with further observations concentrated on other tracers such as Lyman $\\alpha$."],"url":"http://arxiv.org/abs/2306.13645v1"}
{"created":"2023-06-23","title":"MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models","abstract":"Multimodal Large Language Model (MLLM) relies on the powerful LLM to perform multimodal tasks, showing amazing emergent abilities in recent studies, such as writing poems based on an image. However, it is difficult for these case studies to fully reflect the performance of MLLM, lacking a comprehensive evaluation. In this paper, we fill in this blank, presenting the first MLLM Evaluation benchmark MME. It measures both perception and cognition abilities on a total of 14 subtasks. In order to avoid data leakage that may arise from direct use of public datasets for evaluation, the annotations of instruction-answer pairs are all manually designed. The concise instruction design allows us to fairly compare MLLMs, instead of struggling in prompt engineering. Besides, with such an instruction, we can also easily carry out quantitative statistics. A total of 10 advanced MLLMs are comprehensively evaluated on our MME, which not only suggests that existing MLLMs still have a large room for improvement, but also reveals the potential directions for the subsequent model optimization.","sentences":["Multimodal Large Language Model (MLLM) relies on the powerful LLM to perform multimodal tasks, showing amazing emergent abilities in recent studies, such as writing poems based on an image.","However, it is difficult for these case studies to fully reflect the performance of MLLM, lacking a comprehensive evaluation.","In this paper, we fill in this blank, presenting the first MLLM Evaluation benchmark MME.","It measures both perception and cognition abilities on a total of 14 subtasks.","In order to avoid data leakage that may arise from direct use of public datasets for evaluation, the annotations of instruction-answer pairs are all manually designed.","The concise instruction design allows us to fairly compare MLLMs, instead of struggling in prompt engineering.","Besides, with such an instruction, we can also easily carry out quantitative statistics.","A total of 10 advanced MLLMs are comprehensively evaluated on our MME, which not only suggests that existing MLLMs still have a large room for improvement, but also reveals the potential directions for the subsequent model optimization."],"url":"http://arxiv.org/abs/2306.13394v1"}
{"created":"2023-06-23","title":"DiffInfinite: Large Mask-Image Synthesis via Parallel Random Patch Diffusion in Histopathology","abstract":"We present DiffInfinite, a hierarchical diffusion model that generates arbitrarily large histological images while preserving long-range correlation structural information. Our approach first generates synthetic segmentation masks, subsequently used as conditions for the high-fidelity generative diffusion process. The proposed sampling method can be scaled up to any desired image size while only requiring small patches for fast training. Moreover, it can be parallelized more efficiently than previous large-content generation methods while avoiding tiling artefacts. The training leverages classifier-free guidance to augment a small, sparsely annotated dataset with unlabelled data. Our method alleviates unique challenges in histopathological imaging practice: large-scale information, costly manual annotation, and protective data handling. The biological plausibility of DiffInfinite data is validated in a survey by ten experienced pathologists as well as a downstream segmentation task. Furthermore, the model scores strongly on anti-copying metrics which is beneficial for the protection of patient data.","sentences":["We present DiffInfinite, a hierarchical diffusion model that generates arbitrarily large histological images while preserving long-range correlation structural information.","Our approach first generates synthetic segmentation masks, subsequently used as conditions for the high-fidelity generative diffusion process.","The proposed sampling method can be scaled up to any desired image size while only requiring small patches for fast training.","Moreover, it can be parallelized more efficiently than previous large-content generation methods while avoiding tiling artefacts.","The training leverages classifier-free guidance to augment a small, sparsely annotated dataset with unlabelled data.","Our method alleviates unique challenges in histopathological imaging practice: large-scale information, costly manual annotation, and protective data handling.","The biological plausibility of DiffInfinite data is validated in a survey by ten experienced pathologists as well as a downstream segmentation task.","Furthermore, the model scores strongly on anti-copying metrics which is beneficial for the protection of patient data."],"url":"http://arxiv.org/abs/2306.13384v1"}
{"created":"2023-06-23","title":"Multi-objective optimization based network control principles for identifying personalized drug targets with cancer","abstract":"It is a big challenge to develop efficient models for identifying personalized drug targets (PDTs) from high-dimensional personalized genomic profile of individual patients. Recent structural network control principles have introduced a new approach to discover PDTs by selecting an optimal set of driver genes in personalized gene interaction network (PGIN). However, most of current methods only focus on controlling the system through a minimum driver-node set and ignore the existence of multiple candidate driver-node sets for therapeutic drug target identification in PGIN. Therefore, this paper proposed multi-objective optimization-based structural network control principles (MONCP) by considering minimum driver nodes and maximum prior-known drug-target information. To solve MONCP, a discrete multi-objective optimization problem is formulated with many constrained variables, and a novel evolutionary optimization model called LSCV-MCEA was developed by adapting a multi-tasking framework and a rankings-based fitness function method. With genomics data of patients with breast or lung cancer from The Cancer Genome Atlas database, the effectiveness of LSCV-MCEA was validated. The experimental results indicated that compared with other advanced methods, LSCV-MCEA can more effectively identify PDTs with the highest Area Under the Curve score for predicting clinically annotated combinatorial drugs. Meanwhile, LSCV-MCEA can more effectively solve MONCP than other evolutionary optimization methods in terms of algorithm convergence and diversity. Particularly, LSCV-MCEA can efficiently detect disease signals for individual patients with BRCA cancer. The study results show that multi-objective optimization can solve structural network control principles effectively and offer a new perspective for understanding tumor heterogeneity in cancer precision medicine.","sentences":["It is a big challenge to develop efficient models for identifying personalized drug targets (PDTs) from high-dimensional personalized genomic profile of individual patients.","Recent structural network control principles have introduced a new approach to discover PDTs by selecting an optimal set of driver genes in personalized gene interaction network (PGIN).","However, most of current methods only focus on controlling the system through a minimum driver-node set and ignore the existence of multiple candidate driver-node sets for therapeutic drug target identification in PGIN.","Therefore, this paper proposed multi-objective optimization-based structural network control principles (MONCP) by considering minimum driver nodes and maximum prior-known drug-target information.","To solve MONCP, a discrete multi-objective optimization problem is formulated with many constrained variables, and a novel evolutionary optimization model called LSCV-MCEA was developed by adapting a multi-tasking framework and a rankings-based fitness function method.","With genomics data of patients with breast or lung cancer from The Cancer Genome Atlas database, the effectiveness of LSCV-MCEA was validated.","The experimental results indicated that compared with other advanced methods, LSCV-MCEA can more effectively identify PDTs with the highest Area Under the Curve score for predicting clinically annotated combinatorial drugs.","Meanwhile, LSCV-MCEA can more effectively solve MONCP than other evolutionary optimization methods in terms of algorithm convergence and diversity.","Particularly, LSCV-MCEA can efficiently detect disease signals for individual patients with BRCA cancer.","The study results show that multi-objective optimization can solve structural network control principles effectively and offer a new perspective for understanding tumor heterogeneity in cancer precision medicine."],"url":"http://arxiv.org/abs/2306.13349v1"}
{"created":"2023-06-23","title":"Deep Omni-supervised Learning for Rib Fracture Detection from Chest Radiology Images","abstract":"Deep learning (DL)-based rib fracture detection has shown promise of playing an important role in preventing mortality and improving patient outcome. Normally, developing DL-based object detection models requires huge amount of bounding box annotation. However, annotating medical data is time-consuming and expertise-demanding, making obtaining a large amount of fine-grained annotations extremely infeasible. This poses pressing need of developing label-efficient detection models to alleviate radiologists' labeling burden. To tackle this challenge, the literature of object detection has witnessed an increase of weakly-supervised and semi-supervised approaches, yet still lacks a unified framework that leverages various forms of fully-labeled, weakly-labeled, and unlabeled data. In this paper, we present a novel omni-supervised object detection network, ORF-Netv2, to leverage as much available supervision as possible. Specifically, a multi-branch omni-supervised detection head is introduced with each branch trained with a specific type of supervision. A co-training-based dynamic label assignment strategy is then proposed to enable flexibly and robustly learning from the weakly-labeled and unlabeled data. Extensively evaluation was conducted for the proposed framework with three rib fracture datasets on both chest CT and X-ray. By leveraging all forms of supervision, ORF-Netv2 achieves mAPs of 34.7, 44.7, and 19.4 on the three datasets, respectively, surpassing the baseline detector which uses only box annotations by mAP gains of 3.8, 4.8, and 5.0, respectively. Furthermore, ORF-Netv2 consistently outperforms other competitive label-efficient methods over various scenarios, showing a promising framework for label-efficient fracture detection.","sentences":["Deep learning (DL)-based rib fracture detection has shown promise of playing an important role in preventing mortality and improving patient outcome.","Normally, developing DL-based object detection models requires huge amount of bounding box annotation.","However, annotating medical data is time-consuming and expertise-demanding, making obtaining a large amount of fine-grained annotations extremely infeasible.","This poses pressing need of developing label-efficient detection models to alleviate radiologists' labeling burden.","To tackle this challenge, the literature of object detection has witnessed an increase of weakly-supervised and semi-supervised approaches, yet still lacks a unified framework that leverages various forms of fully-labeled, weakly-labeled, and unlabeled data.","In this paper, we present a novel omni-supervised object detection network, ORF-Netv2, to leverage as much available supervision as possible.","Specifically, a multi-branch omni-supervised detection head is introduced with each branch trained with a specific type of supervision.","A co-training-based dynamic label assignment strategy is then proposed to enable flexibly and robustly learning from the weakly-labeled and unlabeled data.","Extensively evaluation was conducted for the proposed framework with three rib fracture datasets on both chest CT and X-ray.","By leveraging all forms of supervision, ORF-Netv2 achieves mAPs of 34.7, 44.7, and 19.4 on the three datasets, respectively, surpassing the baseline detector which uses only box annotations by mAP gains of 3.8, 4.8, and 5.0, respectively.","Furthermore, ORF-Netv2 consistently outperforms other competitive label-efficient methods over various scenarios, showing a promising framework for label-efficient fracture detection."],"url":"http://arxiv.org/abs/2306.13301v1"}
{"created":"2023-06-22","title":"AmicroN: A Framework for Generating Annotations for Human Activity Recognition with Granular Micro-Activities","abstract":"Efficient human activity recognition (HAR) using sensor data needs a significant volume of annotated data. The growing volume of unlabelled sensor data has challenged conventional practices for gathering HAR annotations with human-in-the-loop approaches, often leading to the collection of shallower annotations. These shallower annotations ignore the fine-grained micro-activities that constitute any complex activities of daily living (ADL). Understanding this, we, in this paper, first analyze this lack of granular annotations from available pre-annotated datasets to understand the practical inconsistencies and also perform a detailed survey to look into the human perception surrounding annotations. Drawing motivations from these, we next develop the framework AmicroN that can automatically generate micro-activity annotations using locomotive signatures and the available coarse-grain macro-activity labels. In the backend, AmicroN applies change-point detection followed by zero-shot learning with activity embeddings to identify the unseen micro-activities in an unsupervised manner. Rigorous evaluation on publicly available datasets shows that AmicroN can accurately generate micro-activity annotations with a median F1-score of >0.75. Additionally, we also show that AmicroN can be used in a plug-and-play manner with Large Language Models (LLMs) to obtain the micro-activity labels, thus making it more practical for realistic applications.","sentences":["Efficient human activity recognition (HAR) using sensor data needs a significant volume of annotated data.","The growing volume of unlabelled sensor data has challenged conventional practices for gathering HAR annotations with human-in-the-loop approaches, often leading to the collection of shallower annotations.","These shallower annotations ignore the fine-grained micro-activities that constitute any complex activities of daily living (ADL).","Understanding this, we, in this paper, first analyze this lack of granular annotations from available pre-annotated datasets to understand the practical inconsistencies and also perform a detailed survey to look into the human perception surrounding annotations.","Drawing motivations from these, we next develop the framework AmicroN that can automatically generate micro-activity annotations using locomotive signatures and the available coarse-grain macro-activity labels.","In the backend, AmicroN applies change-point detection followed by zero-shot learning with activity embeddings to identify the unseen micro-activities in an unsupervised manner.","Rigorous evaluation on publicly available datasets shows that AmicroN can accurately generate micro-activity annotations with a median F1-score of >0.75.","Additionally, we also show that AmicroN can be used in a plug-and-play manner with Large Language Models (LLMs) to obtain the micro-activity labels, thus making it more practical for realistic applications."],"url":"http://arxiv.org/abs/2306.13149v1"}
{"created":"2023-06-22","title":"Named entity recognition in resumes","abstract":"Named entity recognition (NER) is used to extract information from various documents and texts such as names and dates. It is important to extract education and work experience information from resumes in order to filter them. Considering the fact that all information in a resume has to be entered to the companys system manually, automatizing this process will save time of the companies. In this study, a deep learning-based semi-automatic named entity recognition system has been implemented with a focus on resumes in the field of IT. Firstly, resumes of employees from five different IT related fields has been annotated. Six transformer based pre-trained models have been adapted to named entity recognition problem using the annotated data. These models have been selected among popular models in the natural language processing field. The obtained system can recognize eight different entity types which are city, date, degree, diploma major, job title, language, country and skill. Models used in the experiments are compared using micro, macro and weighted F1 scores and the performance of the methods was evaluated. Taking these scores into account for test set the best micro and weighted F1 score is obtained by RoBERTa and the best macro F1 score is obtained by Electra model.","sentences":["Named entity recognition (NER) is used to extract information from various documents and texts such as names and dates.","It is important to extract education and work experience information from resumes in order to filter them.","Considering the fact that all information in a resume has to be entered to the companys system manually, automatizing this process will save time of the companies.","In this study, a deep learning-based semi-automatic named entity recognition system has been implemented with a focus on resumes in the field of IT.","Firstly, resumes of employees from five different IT related fields has been annotated.","Six transformer based pre-trained models have been adapted to named entity recognition problem using the annotated data.","These models have been selected among popular models in the natural language processing field.","The obtained system can recognize eight different entity types which are city, date, degree, diploma major, job title, language, country and skill.","Models used in the experiments are compared using micro, macro and weighted F1 scores and the performance of the methods was evaluated.","Taking these scores into account for test set the best micro and weighted F1 score is obtained by RoBERTa and the best macro F1 score is obtained by Electra model."],"url":"http://arxiv.org/abs/2306.13062v1"}
{"created":"2023-06-22","title":"Natural Language Processing in Electronic Health Records in Relation to Healthcare Decision-making: A Systematic Review","abstract":"Background: Natural Language Processing (NLP) is widely used to extract clinical insights from Electronic Health Records (EHRs). However, the lack of annotated data, automated tools, and other challenges hinder the full utilisation of NLP for EHRs. Various Machine Learning (ML), Deep Learning (DL) and NLP techniques are studied and compared to understand the limitations and opportunities in this space comprehensively.   Methodology: After screening 261 articles from 11 databases, we included 127 papers for full-text review covering seven categories of articles: 1) medical note classification, 2) clinical entity recognition, 3) text summarisation, 4) deep learning (DL) and transfer learning architecture, 5) information extraction, 6) Medical language translation and 7) other NLP applications. This study follows the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines.   Result and Discussion: EHR was the most commonly used data type among the selected articles, and the datasets were primarily unstructured. Various ML and DL methods were used, with prediction or classification being the most common application of ML or DL. The most common use cases were: the International Classification of Diseases, Ninth Revision (ICD-9) classification, clinical note analysis, and named entity recognition (NER) for clinical descriptions and research on psychiatric disorders.   Conclusion: We find that the adopted ML models were not adequately assessed. In addition, the data imbalance problem is quite important, yet we must find techniques to address this underlining problem. Future studies should address key limitations in studies, primarily identifying Lupus Nephritis, Suicide Attempts, perinatal self-harmed and ICD-9 classification.","sentences":["Background: Natural Language Processing (NLP) is widely used to extract clinical insights from Electronic Health Records (EHRs).","However, the lack of annotated data, automated tools, and other challenges hinder the full utilisation of NLP for EHRs.","Various Machine Learning (ML), Deep Learning (DL) and NLP techniques are studied and compared to understand the limitations and opportunities in this space comprehensively.   ","Methodology:","After screening 261 articles from 11 databases, we included 127 papers for full-text review covering seven categories of articles: 1) medical note classification, 2) clinical entity recognition, 3) text summarisation, 4) deep learning (DL) and transfer learning architecture, 5) information extraction, 6) Medical language translation and 7) other NLP applications.","This study follows the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines.   ","Result and Discussion: EHR was the most commonly used data type among the selected articles, and the datasets were primarily unstructured.","Various ML and DL methods were used, with prediction or classification being the most common application of ML or DL.","The most common use cases were: the International Classification of Diseases, Ninth Revision (ICD-9) classification, clinical note analysis, and named entity recognition (NER) for clinical descriptions and research on psychiatric disorders.   ","Conclusion: We find that the adopted ML models were not adequately assessed.","In addition, the data imbalance problem is quite important, yet we must find techniques to address this underlining problem.","Future studies should address key limitations in studies, primarily identifying Lupus Nephritis, Suicide Attempts, perinatal self-harmed and ICD-9 classification."],"url":"http://arxiv.org/abs/2306.12834v1"}
{"created":"2023-06-22","title":"A Search Strategy and Vessel Detection in Maritime Environment Using Fixed-Wing UAVs","abstract":"In this paper, we address the problem of autonomous search and vessel detection in an unknown GNSS-denied maritime environment with fixed-wing UAVs. The main challenge in such environments with limited localization, communication range, and the total number of UAVs and sensors is to implement an appropriate search strategy so that a target vessel can be detected as soon as possible. Thus we present informed and non-informed methods used to search the environment. The informed method relies on an obtained probabilistic map, while the non-informed method navigates the UAVs along predefined paths computed with respect to the environment. The vessel detection method is trained on synthetic data collected in the simulator with data annotation tools. Comparative experiments in simulation have shown that our combination of sensors, search methods and a vessel detection algorithm leads to a successful search for the target vessel in such challenging environments.","sentences":["In this paper, we address the problem of autonomous search and vessel detection in an unknown GNSS-denied maritime environment with fixed-wing UAVs.","The main challenge in such environments with limited localization, communication range, and the total number of UAVs and sensors is to implement an appropriate search strategy so that a target vessel can be detected as soon as possible.","Thus we present informed and non-informed methods used to search the environment.","The informed method relies on an obtained probabilistic map, while the non-informed method navigates the UAVs along predefined paths computed with respect to the environment.","The vessel detection method is trained on synthetic data collected in the simulator with data annotation tools.","Comparative experiments in simulation have shown that our combination of sensors, search methods and a vessel detection algorithm leads to a successful search for the target vessel in such challenging environments."],"url":"http://arxiv.org/abs/2306.12767v1"}
{"created":"2023-06-22","title":"Constructing Colloquial Dataset for Persian Sentiment Analysis of Social Microblogs","abstract":"Introduction: Microblogging websites have massed rich data sources for sentiment analysis and opinion mining. In this regard, sentiment classification has frequently proven inefficient because microblog posts typically lack syntactically consistent terms and representatives since users on these social networks do not like to write lengthy statements. Also, there are some limitations to low-resource languages. The Persian language has exceptional characteristics and demands unique annotated data and models for the sentiment analysis task, which are distinctive from text features within the English dialect. Method: This paper first constructs a user opinion dataset called ITRC-Opinion by collaborative environment and insource way. Our dataset contains 60,000 informal and colloquial Persian texts from social microblogs such as Twitter and Instagram. Second, this study proposes a new deep convolutional neural network (CNN) model for more effective sentiment analysis of colloquial text in social microblog posts. The constructed datasets are used to evaluate the presented model. Furthermore, some models, such as LSTM, CNN-RNN, BiLSTM, and BiGRU with different word embeddings, including Fasttext, Glove, and Word2vec, investigated our dataset and evaluated the results. Results: The results demonstrate the benefit of our dataset and the proposed model (72% accuracy), displaying meaningful improvement in sentiment classification performance.","sentences":["Introduction: Microblogging websites have massed rich data sources for sentiment analysis and opinion mining.","In this regard, sentiment classification has frequently proven inefficient because microblog posts typically lack syntactically consistent terms and representatives since users on these social networks do not like to write lengthy statements.","Also, there are some limitations to low-resource languages.","The Persian language has exceptional characteristics and demands unique annotated data and models for the sentiment analysis task, which are distinctive from text features within the English dialect.","Method: This paper first constructs a user opinion dataset called ITRC-Opinion by collaborative environment and insource way.","Our dataset contains 60,000 informal and colloquial Persian texts from social microblogs such as Twitter and Instagram.","Second, this study proposes a new deep convolutional neural network (CNN) model for more effective sentiment analysis of colloquial text in social microblog posts.","The constructed datasets are used to evaluate the presented model.","Furthermore, some models, such as LSTM, CNN-RNN, BiLSTM, and BiGRU with different word embeddings, including Fasttext, Glove, and Word2vec, investigated our dataset and evaluated the results.","Results:","The results demonstrate the benefit of our dataset and the proposed model (72% accuracy), displaying meaningful improvement in sentiment classification performance."],"url":"http://arxiv.org/abs/2306.12679v1"}
{"created":"2023-06-21","title":"Multi-Task Consistency for Active Learning","abstract":"Learning-based solutions for vision tasks require a large amount of labeled training data to ensure their performance and reliability. In single-task vision-based settings, inconsistency-based active learning has proven to be effective in selecting informative samples for annotation. However, there is a lack of research exploiting the inconsistency between multiple tasks in multi-task networks. To address this gap, we propose a novel multi-task active learning strategy for two coupled vision tasks: object detection and semantic segmentation. Our approach leverages the inconsistency between them to identify informative samples across both tasks. We propose three constraints that specify how the tasks are coupled and introduce a method for determining the pixels belonging to the object detected by a bounding box, to later quantify the constraints as inconsistency scores. To evaluate the effectiveness of our approach, we establish multiple baselines for multi-task active learning and introduce a new metric, mean Detection Segmentation Quality (mDSQ), tailored for the multi-task active learning comparison that addresses the performance of both tasks. We conduct extensive experiments on the nuImages and A9 datasets, demonstrating that our approach outperforms existing state-of-the-art methods by up to 3.4% mDSQ on nuImages. Our approach achieves 95% of the fully-trained performance using only 67% of the available data, corresponding to 20% fewer labels compared to random selection and 5% fewer labels compared to state-of-the-art selection strategy. Our code will be made publicly available after the review process.","sentences":["Learning-based solutions for vision tasks require a large amount of labeled training data to ensure their performance and reliability.","In single-task vision-based settings, inconsistency-based active learning has proven to be effective in selecting informative samples for annotation.","However, there is a lack of research exploiting the inconsistency between multiple tasks in multi-task networks.","To address this gap, we propose a novel multi-task active learning strategy for two coupled vision tasks: object detection and semantic segmentation.","Our approach leverages the inconsistency between them to identify informative samples across both tasks.","We propose three constraints that specify how the tasks are coupled and introduce a method for determining the pixels belonging to the object detected by a bounding box, to later quantify the constraints as inconsistency scores.","To evaluate the effectiveness of our approach, we establish multiple baselines for multi-task active learning and introduce a new metric, mean Detection Segmentation Quality (mDSQ), tailored for the multi-task active learning comparison that addresses the performance of both tasks.","We conduct extensive experiments on the nuImages and A9 datasets, demonstrating that our approach outperforms existing state-of-the-art methods by up to 3.4% mDSQ on nuImages.","Our approach achieves 95% of the fully-trained performance using only 67% of the available data, corresponding to 20% fewer labels compared to random selection and 5% fewer labels compared to state-of-the-art selection strategy.","Our code will be made publicly available after the review process."],"url":"http://arxiv.org/abs/2306.12398v1"}
{"created":"2023-06-21","title":"M-VAAL: Multimodal Variational Adversarial Active Learning for Downstream Medical Image Analysis Tasks","abstract":"Acquiring properly annotated data is expensive in the medical field as it requires experts, time-consuming protocols, and rigorous validation. Active learning attempts to minimize the need for large annotated samples by actively sampling the most informative examples for annotation. These examples contribute significantly to improving the performance of supervised machine learning models, and thus, active learning can play an essential role in selecting the most appropriate information in deep learning-based diagnosis, clinical assessments, and treatment planning. Although some existing works have proposed methods for sampling the best examples for annotation in medical image analysis, they are not task-agnostic and do not use multimodal auxiliary information in the sampler, which has the potential to increase robustness. Therefore, in this work, we propose a Multimodal Variational Adversarial Active Learning (M-VAAL) method that uses auxiliary information from additional modalities to enhance the active sampling. We applied our method to two datasets: i) brain tumor segmentation and multi-label classification using the BraTS2018 dataset, and ii) chest X-ray image classification using the COVID-QU-Ex dataset. Our results show a promising direction toward data-efficient learning under limited annotations.","sentences":["Acquiring properly annotated data is expensive in the medical field as it requires experts, time-consuming protocols, and rigorous validation.","Active learning attempts to minimize the need for large annotated samples by actively sampling the most informative examples for annotation.","These examples contribute significantly to improving the performance of supervised machine learning models, and thus, active learning can play an essential role in selecting the most appropriate information in deep learning-based diagnosis, clinical assessments, and treatment planning.","Although some existing works have proposed methods for sampling the best examples for annotation in medical image analysis, they are not task-agnostic and do not use multimodal auxiliary information in the sampler, which has the potential to increase robustness.","Therefore, in this work, we propose a Multimodal Variational Adversarial Active Learning (M-VAAL) method that uses auxiliary information from additional modalities to enhance the active sampling.","We applied our method to two datasets: i) brain tumor segmentation and multi-label classification using the BraTS2018 dataset, and ii) chest X-ray image classification using the COVID-QU-Ex dataset.","Our results show a promising direction toward data-efficient learning under limited annotations."],"url":"http://arxiv.org/abs/2306.12376v1"}
{"created":"2023-06-21","title":"ScenarioNet: Open-Source Platform for Large-Scale Traffic Scenario Simulation and Modeling","abstract":"Large-scale driving datasets such as Waymo Open Dataset and nuScenes substantially accelerate autonomous driving research, especially for perception tasks such as 3D detection and trajectory forecasting. Since the driving logs in these datasets contain HD maps and detailed object annotations which accurately reflect the real-world complexity of traffic behaviors, we can harvest a massive number of complex traffic scenarios and recreate their digital twins in simulation. Compared to the hand-crafted scenarios often used in existing simulators, data-driven scenarios collected from the real world can facilitate many research opportunities in machine learning and autonomous driving. In this work, we present ScenarioNet, an open-source platform for large-scale traffic scenario modeling and simulation. ScenarioNet defines a unified scenario description format and collects a large-scale repository of real-world traffic scenarios from the heterogeneous data in various driving datasets including Waymo, nuScenes, Lyft L5, and nuPlan datasets. These scenarios can be further replayed and interacted with in multiple views from Bird-Eye-View layout to realistic 3D rendering in MetaDrive simulator. This provides a benchmark for evaluating the safety of autonomous driving stacks in simulation before their real-world deployment. We further demonstrate the strengths of ScenarioNet on large-scale scenario generation, imitation learning, and reinforcement learning in both single-agent and multi-agent settings. Code, demo videos, and website are available at https://metadriverse.github.io/scenarionet.","sentences":["Large-scale driving datasets such as Waymo Open Dataset and nuScenes substantially accelerate autonomous driving research, especially for perception tasks such as 3D detection and trajectory forecasting.","Since the driving logs in these datasets contain HD maps and detailed object annotations which accurately reflect the real-world complexity of traffic behaviors, we can harvest a massive number of complex traffic scenarios and recreate their digital twins in simulation.","Compared to the hand-crafted scenarios often used in existing simulators, data-driven scenarios collected from the real world can facilitate many research opportunities in machine learning and autonomous driving.","In this work, we present ScenarioNet, an open-source platform for large-scale traffic scenario modeling and simulation.","ScenarioNet defines a unified scenario description format and collects a large-scale repository of real-world traffic scenarios from the heterogeneous data in various driving datasets including Waymo, nuScenes, Lyft L5, and nuPlan datasets.","These scenarios can be further replayed and interacted with in multiple views from Bird-Eye-View layout to realistic 3D rendering in MetaDrive simulator.","This provides a benchmark for evaluating the safety of autonomous driving stacks in simulation before their real-world deployment.","We further demonstrate the strengths of ScenarioNet on large-scale scenario generation, imitation learning, and reinforcement learning in both single-agent and multi-agent settings.","Code, demo videos, and website are available at https://metadriverse.github.io/scenarionet."],"url":"http://arxiv.org/abs/2306.12241v2"}
{"created":"2023-06-21","title":"Lumbar spine segmentation in MR images: a dataset and a public benchmark","abstract":"This paper presents a large publicly available multi-center lumbar spine magnetic resonance imaging (MRI) dataset with reference segmentations of vertebrae, intervertebral discs (IVDs), and spinal canal. The dataset includes 447 sagittal T1 and T2 MRI series from 218 patients with a history of low back pain. It was collected from four different hospitals and was divided into a training (179 patients) and validation (39 patients) set. An iterative data annotation approach was used by training a segmentation algorithm on a small part of the dataset, enabling semi-automatic segmentation of the remaining images. The algorithm provided an initial segmentation, which was subsequently reviewed, manually corrected, and added to the training data. We provide reference performance values for this baseline algorithm and nnU-Net, which performed comparably. We set up a continuous segmentation challenge to allow for a fair comparison of different segmentation algorithms. This study may encourage wider collaboration in the field of spine segmentation, and improve the diagnostic value of lumbar spine MRI.","sentences":["This paper presents a large publicly available multi-center lumbar spine magnetic resonance imaging (MRI) dataset with reference segmentations of vertebrae, intervertebral discs (IVDs), and spinal canal.","The dataset includes 447 sagittal T1 and T2 MRI series from 218 patients with a history of low back pain.","It was collected from four different hospitals and was divided into a training (179 patients) and validation (39 patients) set.","An iterative data annotation approach was used by training a segmentation algorithm on a small part of the dataset, enabling semi-automatic segmentation of the remaining images.","The algorithm provided an initial segmentation, which was subsequently reviewed, manually corrected, and added to the training data.","We provide reference performance values for this baseline algorithm and nnU-Net, which performed comparably.","We set up a continuous segmentation challenge to allow for a fair comparison of different segmentation algorithms.","This study may encourage wider collaboration in the field of spine segmentation, and improve the diagnostic value of lumbar spine MRI."],"url":"http://arxiv.org/abs/2306.12217v2"}
{"created":"2023-06-21","title":"Annotating Ambiguous Images: General Annotation Strategy for Image Classification with Real-World Biomedical Validation on Vertebral Fracture Diagnosis","abstract":"While numerous methods exist to solve classification problems within curated datasets, these solutions often fall short in biomedical applications due to the biased or ambiguous nature of the data. These difficulties are particularly evident when inferring height reduction from vertebral data, a key component of the clinically-recognized Genant score. Although strategies such as semi-supervised learning, proposal usage, and class blending may provide some resolution, a clear and superior solution remains elusive. This paper introduces a flowchart of general strategy to address these issues. We demonstrate the application of this strategy by constructing a vertebral fracture dataset with over 300,000 annotations. This work facilitates the transition of the classification problem into clinically meaningful scores and enriches our understanding of vertebral height reduction.","sentences":["While numerous methods exist to solve classification problems within curated datasets, these solutions often fall short in biomedical applications due to the biased or ambiguous nature of the data.","These difficulties are particularly evident when inferring height reduction from vertebral data, a key component of the clinically-recognized Genant score.","Although strategies such as semi-supervised learning, proposal usage, and class blending may provide some resolution, a clear and superior solution remains elusive.","This paper introduces a flowchart of general strategy to address these issues.","We demonstrate the application of this strategy by constructing a vertebral fracture dataset with over 300,000 annotations.","This work facilitates the transition of the classification problem into clinically meaningful scores and enriches our understanding of vertebral height reduction."],"url":"http://arxiv.org/abs/2306.12189v1"}
{"created":"2023-06-21","title":"Exploiting Multimodal Synthetic Data for Egocentric Human-Object Interaction Detection in an Industrial Scenario","abstract":"In this paper, we tackle the problem of Egocentric Human-Object Interaction (EHOI) detection in an industrial setting. To overcome the lack of public datasets in this context, we propose a pipeline and a tool for generating synthetic images of EHOIs paired with several annotations and data signals (e.g., depth maps or instance segmentation masks). Using the proposed pipeline, we present EgoISM-HOI a new multimodal dataset composed of synthetic EHOI images in an industrial environment with rich annotations of hands and objects. To demonstrate the utility and effectiveness of synthetic EHOI data produced by the proposed tool, we designed a new method that predicts and combines different multimodal signals to detect EHOIs in RGB images. Our study shows that exploiting synthetic data to pre-train the proposed method significantly improves performance when tested on real-world data. Moreover, the proposed approach outperforms state-of-the-art class-agnostic methods. To support research in this field, we publicly release the datasets, source code, and pre-trained models at https://iplab.dmi.unict.it/egoism-hoi.","sentences":["In this paper, we tackle the problem of Egocentric Human-Object Interaction (EHOI) detection in an industrial setting.","To overcome the lack of public datasets in this context, we propose a pipeline and a tool for generating synthetic images of EHOIs paired with several annotations and data signals (e.g., depth maps or instance segmentation masks).","Using the proposed pipeline, we present EgoISM-HOI a new multimodal dataset composed of synthetic EHOI images in an industrial environment with rich annotations of hands and objects.","To demonstrate the utility and effectiveness of synthetic EHOI data produced by the proposed tool, we designed a new method that predicts and combines different multimodal signals to detect EHOIs in RGB images.","Our study shows that exploiting synthetic data to pre-train the proposed method significantly improves performance when tested on real-world data.","Moreover, the proposed approach outperforms state-of-the-art class-agnostic methods.","To support research in this field, we publicly release the datasets, source code, and pre-trained models at https://iplab.dmi.unict.it/egoism-hoi."],"url":"http://arxiv.org/abs/2306.12152v1"}
{"created":"2023-06-21","title":"Online Unsupervised Video Object Segmentation via Contrastive Motion Clustering","abstract":"Online unsupervised video object segmentation (UVOS) uses the previous frames as its input to automatically separate the primary object(s) from a streaming video without using any further manual annotation. A major challenge is that the model has no access to the future and must rely solely on the history, i.e., the segmentation mask is predicted from the current frame as soon as it is captured. In this work, a novel contrastive motion clustering algorithm with an optical flow as its input is proposed for the online UVOS by exploiting the common fate principle that visual elements tend to be perceived as a group if they possess the same motion pattern. We build a simple and effective auto-encoder to iteratively summarize non-learnable prototypical bases for the motion pattern, while the bases in turn help learn the representation of the embedding network. Further, a contrastive learning strategy based on a boundary prior is developed to improve foreground and background feature discrimination in the representation learning stage. The proposed algorithm can be optimized on arbitrarily-scale data i.e., frame, clip, dataset) and performed in an online fashion. Experiments on $\\textit{DAVIS}_{\\textit{16}}$, $\\textit{FBMS}$, and $\\textit{SegTrackV2}$ datasets show that the accuracy of our method surpasses the previous state-of-the-art (SoTA) online UVOS method by a margin of 0.8%, 2.9%, and 1.1%, respectively. Furthermore, by using an online deep subspace clustering to tackle the motion grouping, our method is able to achieve higher accuracy at $3\\times$ faster inference time compared to SoTA online UVOS method, and making a good trade-off between effectiveness and efficiency.","sentences":["Online unsupervised video object segmentation (UVOS) uses the previous frames as its input to automatically separate the primary object(s) from a streaming video without using any further manual annotation.","A major challenge is that the model has no access to the future and must rely solely on the history, i.e., the segmentation mask is predicted from the current frame as soon as it is captured.","In this work, a novel contrastive motion clustering algorithm with an optical flow as its input is proposed for the online UVOS by exploiting the common fate principle that visual elements tend to be perceived as a group if they possess the same motion pattern.","We build a simple and effective auto-encoder to iteratively summarize non-learnable prototypical bases for the motion pattern, while the bases in turn help learn the representation of the embedding network.","Further, a contrastive learning strategy based on a boundary prior is developed to improve foreground and background feature discrimination in the representation learning stage.","The proposed algorithm can be optimized on arbitrarily-scale data i.e., frame, clip, dataset) and performed in an online fashion.","Experiments on $\\textit{DAVIS}_{\\textit{16}}$, $\\textit{FBMS}$, and $\\textit{SegTrackV2}$ datasets show that the accuracy of our method surpasses the previous state-of-the-art (SoTA) online UVOS method by a margin of 0.8%, 2.9%, and 1.1%, respectively.","Furthermore, by using an online deep subspace clustering to tackle the motion grouping, our method is able to achieve higher accuracy at $3\\times$ faster inference time compared to SoTA online UVOS method, and making a good trade-off between effectiveness and efficiency."],"url":"http://arxiv.org/abs/2306.12048v1"}
{"created":"2023-06-20","title":"LVM-Med: Learning Large-Scale Self-Supervised Vision Models for Medical Imaging via Second-order Graph Matching","abstract":"Obtaining large pre-trained models that can be fine-tuned to new tasks with limited annotated samples has remained an open challenge for medical imaging data. While pre-trained deep networks on ImageNet and vision-language foundation models trained on web-scale data are prevailing approaches, their effectiveness on medical tasks is limited due to the significant domain shift between natural and medical images. To bridge this gap, we introduce LVM-Med, the first family of deep networks trained on large-scale medical datasets. We have collected approximately 1.3 million medical images from 55 publicly available datasets, covering a large number of organs and modalities such as CT, MRI, X-ray, and Ultrasound. We benchmark several state-of-the-art self-supervised algorithms on this dataset and propose a novel self-supervised contrastive learning algorithm using a graph-matching formulation. The proposed approach makes three contributions: (i) it integrates prior pair-wise image similarity metrics based on local and global information; (ii) it captures the structural constraints of feature embeddings through a loss function constructed via a combinatorial graph-matching objective; and (iii) it can be trained efficiently end-to-end using modern gradient-estimation techniques for black-box solvers. We thoroughly evaluate the proposed LVM-Med on 15 downstream medical tasks ranging from segmentation and classification to object detection, and both for the in and out-of-distribution settings. LVM-Med empirically outperforms a number of state-of-the-art supervised, self-supervised, and foundation models. For challenging tasks such as Brain Tumor Classification or Diabetic Retinopathy Grading, LVM-Med improves previous vision-language models trained on 1 billion masks by 6-7% while using only a ResNet-50.","sentences":["Obtaining large pre-trained models that can be fine-tuned to new tasks with limited annotated samples has remained an open challenge for medical imaging data.","While pre-trained deep networks on ImageNet and vision-language foundation models trained on web-scale data are prevailing approaches, their effectiveness on medical tasks is limited due to the significant domain shift between natural and medical images.","To bridge this gap, we introduce LVM-Med, the first family of deep networks trained on large-scale medical datasets.","We have collected approximately 1.3 million medical images from 55 publicly available datasets, covering a large number of organs and modalities such as CT, MRI, X-ray, and Ultrasound.","We benchmark several state-of-the-art self-supervised algorithms on this dataset and propose a novel self-supervised contrastive learning algorithm using a graph-matching formulation.","The proposed approach makes three contributions: (i) it integrates prior pair-wise image similarity metrics based on local and global information; (ii) it captures the structural constraints of feature embeddings through a loss function constructed via a combinatorial graph-matching objective; and (iii) it can be trained efficiently end-to-end using modern gradient-estimation techniques for black-box solvers.","We thoroughly evaluate the proposed LVM-Med on 15 downstream medical tasks ranging from segmentation and classification to object detection, and both for the in and out-of-distribution settings.","LVM-Med empirically outperforms a number of state-of-the-art supervised, self-supervised, and foundation models.","For challenging tasks such as Brain Tumor Classification or Diabetic Retinopathy Grading, LVM-Med improves previous vision-language models trained on 1 billion masks by 6-7% while using only a ResNet-50."],"url":"http://arxiv.org/abs/2306.11925v1"}
{"created":"2023-06-20","title":"Int-HRL: Towards Intention-based Hierarchical Reinforcement Learning","abstract":"While deep reinforcement learning (RL) agents outperform humans on an increasing number of tasks, training them requires data equivalent to decades of human gameplay. Recent hierarchical RL methods have increased sample efficiency by incorporating information inherent to the structure of the decision problem but at the cost of having to discover or use human-annotated sub-goals that guide the learning process. We show that intentions of human players, i.e. the precursor of goal-oriented decisions, can be robustly predicted from eye gaze even for the long-horizon sparse rewards task of Montezuma's Revenge - one of the most challenging RL tasks in the Atari2600 game suite. We propose Int-HRL: Hierarchical RL with intention-based sub-goals that are inferred from human eye gaze. Our novel sub-goal extraction pipeline is fully automatic and replaces the need for manual sub-goal annotation by human experts. Our evaluations show that replacing hand-crafted sub-goals with automatically extracted intentions leads to a HRL agent that is significantly more sample efficient than previous methods.","sentences":["While deep reinforcement learning (RL) agents outperform humans on an increasing number of tasks, training them requires data equivalent to decades of human gameplay.","Recent hierarchical RL methods have increased sample efficiency by incorporating information inherent to the structure of the decision problem but at the cost of having to discover or use human-annotated sub-goals that guide the learning process.","We show that intentions of human players, i.e. the precursor of goal-oriented decisions, can be robustly predicted from eye gaze even for the long-horizon sparse rewards task of Montezuma's Revenge - one of the most challenging RL tasks in the Atari2600 game suite.","We propose Int-HRL: Hierarchical RL with intention-based sub-goals that are inferred from human eye gaze.","Our novel sub-goal extraction pipeline is fully automatic and replaces the need for manual sub-goal annotation by human experts.","Our evaluations show that replacing hand-crafted sub-goals with automatically extracted intentions leads to a HRL agent that is significantly more sample efficient than previous methods."],"url":"http://arxiv.org/abs/2306.11483v1"}
{"created":"2023-06-20","title":"Exploring the Effectiveness of Dataset Synthesis: An application of Apple Detection in Orchards","abstract":"Deep object detection models have achieved notable successes in recent years, but one major obstacle remains: the requirement for a large amount of training data. Obtaining such data is a tedious process and is mainly time consuming, leading to the exploration of new research avenues like synthetic data generation techniques. In this study, we explore the usability of Stable Diffusion 2.1-base for generating synthetic datasets of apple trees for object detection and compare it to a baseline model trained on real-world data. After creating a dataset of realistic apple trees with prompt engineering and utilizing a previously trained Stable Diffusion model, the custom dataset was annotated and evaluated by training a YOLOv5m object detection model to predict apples in a real-world apple detection dataset. YOLOv5m was chosen for its rapid inference time and minimal hardware demands. Results demonstrate that the model trained on generated data is slightly underperforming compared to a baseline model trained on real-world images when evaluated on a set of real-world images. However, these findings remain highly promising, as the average precision difference is only 0.09 and 0.06, respectively. Qualitative results indicate that the model can accurately predict the location of apples, except in cases of heavy shading. These findings illustrate the potential of synthetic data generation techniques as a viable alternative to the collection of extensive training data for object detection models.","sentences":["Deep object detection models have achieved notable successes in recent years, but one major obstacle remains: the requirement for a large amount of training data.","Obtaining such data is a tedious process and is mainly time consuming, leading to the exploration of new research avenues like synthetic data generation techniques.","In this study, we explore the usability of Stable Diffusion 2.1-base for generating synthetic datasets of apple trees for object detection and compare it to a baseline model trained on real-world data.","After creating a dataset of realistic apple trees with prompt engineering and utilizing a previously trained Stable Diffusion model, the custom dataset was annotated and evaluated by training a YOLOv5m object detection model to predict apples in a real-world apple detection dataset.","YOLOv5m was chosen for its rapid inference time and minimal hardware demands.","Results demonstrate that the model trained on generated data is slightly underperforming compared to a baseline model trained on real-world images when evaluated on a set of real-world images.","However, these findings remain highly promising, as the average precision difference is only 0.09 and 0.06, respectively.","Qualitative results indicate that the model can accurately predict the location of apples, except in cases of heavy shading.","These findings illustrate the potential of synthetic data generation techniques as a viable alternative to the collection of extensive training data for object detection models."],"url":"http://arxiv.org/abs/2306.11763v1"}
{"created":"2023-06-20","title":"Meerkat Behaviour Recognition Dataset","abstract":"Recording animal behaviour is an important step in evaluating the well-being of animals and further understanding the natural world. Current methods for documenting animal behaviour within a zoo setting, such as scan sampling, require excessive human effort, are unfit for around-the-clock monitoring, and may produce human-biased results. Several animal datasets already exist that focus predominantly on wildlife interactions, with some extending to action or behaviour recognition. However, there is limited data in a zoo setting or data focusing on the group behaviours of social animals. We introduce a large meerkat (Suricata Suricatta) behaviour recognition video dataset with diverse annotated behaviours, including group social interactions, tracking of individuals within the camera view, skewed class distribution, and varying illumination conditions. This dataset includes videos from two positions within the meerkat enclosure at the Wellington Zoo (Wellington, New Zealand), with 848,400 annotated frames across 20 videos and 15 unannotated videos.","sentences":["Recording animal behaviour is an important step in evaluating the well-being of animals and further understanding the natural world.","Current methods for documenting animal behaviour within a zoo setting, such as scan sampling, require excessive human effort, are unfit for around-the-clock monitoring, and may produce human-biased results.","Several animal datasets already exist that focus predominantly on wildlife interactions, with some extending to action or behaviour recognition.","However, there is limited data in a zoo setting or data focusing on the group behaviours of social animals.","We introduce a large meerkat (Suricata Suricatta) behaviour recognition video dataset with diverse annotated behaviours, including group social interactions, tracking of individuals within the camera view, skewed class distribution, and varying illumination conditions.","This dataset includes videos from two positions within the meerkat enclosure at the Wellington Zoo (Wellington, New Zealand), with 848,400 annotated frames across 20 videos and 15 unannotated videos."],"url":"http://arxiv.org/abs/2306.11326v1"}
{"created":"2023-06-19","title":"BioREx: Improving Biomedical Relation Extraction by Leveraging Heterogeneous Datasets","abstract":"Biomedical relation extraction (RE) is the task of automatically identifying and characterizing relations between biomedical concepts from free text. RE is a central task in biomedical natural language processing (NLP) research and plays a critical role in many downstream applications, such as literature-based discovery and knowledge graph construction. State-of-the-art methods were used primarily to train machine learning models on individual RE datasets, such as protein-protein interaction and chemical-induced disease relation. Manual dataset annotation, however, is highly expensive and time-consuming, as it requires domain knowledge. Existing RE datasets are usually domain-specific or small, which limits the development of generalized and high-performing RE models. In this work, we present a novel framework for systematically addressing the data heterogeneity of individual datasets and combining them into a large dataset. Based on the framework and dataset, we report on BioREx, a data-centric approach for extracting relations. Our evaluation shows that BioREx achieves significantly higher performance than the benchmark system trained on the individual dataset, setting a new SOTA from 74.4% to 79.6% in F-1 measure on the recently released BioRED corpus. We further demonstrate that the combined dataset can improve performance for five different RE tasks. In addition, we show that on average BioREx compares favorably to current best-performing methods such as transfer learning and multi-task learning. Finally, we demonstrate BioREx's robustness and generalizability in two independent RE tasks not previously seen in training data: drug-drug N-ary combination and document-level gene-disease RE. The integrated dataset and optimized method have been packaged as a stand-alone tool available at https://github.com/ncbi/BioREx.","sentences":["Biomedical relation extraction (RE) is the task of automatically identifying and characterizing relations between biomedical concepts from free text.","RE is a central task in biomedical natural language processing (NLP) research and plays a critical role in many downstream applications, such as literature-based discovery and knowledge graph construction.","State-of-the-art methods were used primarily to train machine learning models on individual RE datasets, such as protein-protein interaction and chemical-induced disease relation.","Manual dataset annotation, however, is highly expensive and time-consuming, as it requires domain knowledge.","Existing RE datasets are usually domain-specific or small, which limits the development of generalized and high-performing RE models.","In this work, we present a novel framework for systematically addressing the data heterogeneity of individual datasets and combining them into a large dataset.","Based on the framework and dataset, we report on BioREx, a data-centric approach for extracting relations.","Our evaluation shows that BioREx achieves significantly higher performance than the benchmark system trained on the individual dataset, setting a new SOTA from 74.4% to 79.6% in F-1 measure on the recently released BioRED corpus.","We further demonstrate that the combined dataset can improve performance for five different RE tasks.","In addition, we show that on average BioREx compares favorably to current best-performing methods such as transfer learning and multi-task learning.","Finally, we demonstrate BioREx's robustness and generalizability in two independent RE tasks not previously seen in training data: drug-drug N-ary combination and document-level gene-disease RE.","The integrated dataset and optimized method have been packaged as a stand-alone tool available at https://github.com/ncbi/BioREx."],"url":"http://arxiv.org/abs/2306.11189v1"}
{"created":"2023-06-19","title":"Confidence-Based Model Selection: When to Take Shortcuts for Subpopulation Shifts","abstract":"Effective machine learning models learn both robust features that directly determine the outcome of interest (e.g., an object with wheels is more likely to be a car), and shortcut features (e.g., an object on a road is more likely to be a car). The latter can be a source of error under distributional shift, when the correlations change at test-time. The prevailing sentiment in the robustness literature is to avoid such correlative shortcut features and learn robust predictors. However, while robust predictors perform better on worst-case distributional shifts, they often sacrifice accuracy on majority subpopulations. In this paper, we argue that shortcut features should not be entirely discarded. Instead, if we can identify the subpopulation to which an input belongs, we can adaptively choose among models with different strengths to achieve high performance on both majority and minority subpopulations. We propose COnfidence-baSed MOdel Selection (CosMoS), where we observe that model confidence can effectively guide model selection. Notably, CosMoS does not require any target labels or group annotations, either of which may be difficult to obtain or unavailable. We evaluate CosMoS on four datasets with spurious correlations, each with multiple test sets with varying levels of data distribution shift. We find that CosMoS achieves 2-5% lower average regret across all subpopulations, compared to using only robust predictors or other model aggregation methods.","sentences":["Effective machine learning models learn both robust features that directly determine the outcome of interest (e.g., an object with wheels is more likely to be a car), and shortcut features (e.g., an object on a road is more likely to be a car).","The latter can be a source of error under distributional shift, when the correlations change at test-time.","The prevailing sentiment in the robustness literature is to avoid such correlative shortcut features and learn robust predictors.","However, while robust predictors perform better on worst-case distributional shifts, they often sacrifice accuracy on majority subpopulations.","In this paper, we argue that shortcut features should not be entirely discarded.","Instead, if we can identify the subpopulation to which an input belongs, we can adaptively choose among models with different strengths to achieve high performance on both majority and minority subpopulations.","We propose COnfidence-baSed MOdel Selection (CosMoS), where we observe that model confidence can effectively guide model selection.","Notably, CosMoS does not require any target labels or group annotations, either of which may be difficult to obtain or unavailable.","We evaluate CosMoS on four datasets with spurious correlations, each with multiple test sets with varying levels of data distribution shift.","We find that CosMoS achieves 2-5% lower average regret across all subpopulations, compared to using only robust predictors or other model aggregation methods."],"url":"http://arxiv.org/abs/2306.11120v1"}
{"created":"2023-06-19","title":"Cross-Modal Attribute Insertions for Assessing the Robustness of Vision-and-Language Learning","abstract":"The robustness of multimodal deep learning models to realistic changes in the input text is critical for their applicability to important tasks such as text-to-image retrieval and cross-modal entailment. To measure robustness, several existing approaches edit the text data, but do so without leveraging the cross-modal information present in multimodal data. Information from the visual modality, such as color, size, and shape, provide additional attributes that users can include in their inputs. Thus, we propose cross-modal attribute insertions as a realistic perturbation strategy for vision-and-language data that inserts visual attributes of the objects in the image into the corresponding text (e.g., \"girl on a chair\" to \"little girl on a wooden chair\"). Our proposed approach for cross-modal attribute insertions is modular, controllable, and task-agnostic. We find that augmenting input text using cross-modal insertions causes state-of-the-art approaches for text-to-image retrieval and cross-modal entailment to perform poorly, resulting in relative drops of 15% in MRR and 20% in $F_1$ score, respectively. Crowd-sourced annotations demonstrate that cross-modal insertions lead to higher quality augmentations for multimodal data than augmentations using text-only data, and are equivalent in quality to original examples. We release the code to encourage robustness evaluations of deep vision-and-language models: https://github.com/claws-lab/multimodal-robustness-xmai.","sentences":["The robustness of multimodal deep learning models to realistic changes in the input text is critical for their applicability to important tasks such as text-to-image retrieval and cross-modal entailment.","To measure robustness, several existing approaches edit the text data, but do so without leveraging the cross-modal information present in multimodal data.","Information from the visual modality, such as color, size, and shape, provide additional attributes that users can include in their inputs.","Thus, we propose cross-modal attribute insertions as a realistic perturbation strategy for vision-and-language data that inserts visual attributes of the objects in the image into the corresponding text (e.g., \"girl on a chair\" to \"little girl on a wooden chair\").","Our proposed approach for cross-modal attribute insertions is modular, controllable, and task-agnostic.","We find that augmenting input text using cross-modal insertions causes state-of-the-art approaches for text-to-image retrieval and cross-modal entailment to perform poorly, resulting in relative drops of 15% in MRR and 20% in $F_1$ score, respectively.","Crowd-sourced annotations demonstrate that cross-modal insertions lead to higher quality augmentations for multimodal data than augmentations using text-only data, and are equivalent in quality to original examples.","We release the code to encourage robustness evaluations of deep vision-and-language models: https://github.com/claws-lab/multimodal-robustness-xmai."],"url":"http://arxiv.org/abs/2306.11065v1"}
{"created":"2023-06-19","title":"RemoteCLIP: A Vision Language Foundation Model for Remote Sensing","abstract":"General-purpose foundation models have become increasingly important in the field of artificial intelligence. While self-supervised learning (SSL) and Masked Image Modeling (MIM) have led to promising results in building such foundation models for remote sensing, these models primarily learn low-level features, require annotated data for fine-tuning, and not applicable for retrieval and zero-shot applications due to the lack of language understanding. In response to these limitations, we propose RemoteCLIP, the first vision-language foundation model for remote sensing that aims to learn robust visual features with rich semantics, as well as aligned text embeddings for seamless downstream application. To address the scarcity of pre-training data, we leverage data scaling, converting heterogeneous annotations based on Box-to-Caption (B2C) and Mask-to-Box (M2B) conversion, and further incorporating UAV imagery, resulting a 12xlarger pretraining dataset. RemoteCLIP can be applied to a variety of downstream tasks, including zero-shot image classification, linear probing, k-NN classification, few-shot classification, image-text retrieval, and object counting. Evaluations on 16 datasets, including a newly introduced RemoteCount benchmark to test the object counting ability, show that RemoteCLIP consistently outperforms baseline foundation models across different model scales. Impressively, RemoteCLIP outperform previous SoTA by 9.14% mean recall on RSICD dataset and by 8.92% on RSICD dataset. For zero-shot classification, our RemoteCLIP outperform CLIP baseline by up to 6.39% average accuracy on 12 downstream datasets.","sentences":["General-purpose foundation models have become increasingly important in the field of artificial intelligence.","While self-supervised learning (SSL) and Masked Image Modeling (MIM) have led to promising results in building such foundation models for remote sensing, these models primarily learn low-level features, require annotated data for fine-tuning, and not applicable for retrieval and zero-shot applications due to the lack of language understanding.","In response to these limitations, we propose RemoteCLIP, the first vision-language foundation model for remote sensing that aims to learn robust visual features with rich semantics, as well as aligned text embeddings for seamless downstream application.","To address the scarcity of pre-training data, we leverage data scaling, converting heterogeneous annotations based on Box-to-Caption (B2C) and Mask-to-Box (M2B) conversion, and further incorporating UAV imagery, resulting a 12xlarger pretraining dataset.","RemoteCLIP can be applied to a variety of downstream tasks, including zero-shot image classification, linear probing, k-NN classification, few-shot classification, image-text retrieval, and object counting.","Evaluations on 16 datasets, including a newly introduced RemoteCount benchmark to test the object counting ability, show that RemoteCLIP consistently outperforms baseline foundation models across different model scales.","Impressively, RemoteCLIP outperform previous SoTA by 9.14% mean recall on RSICD dataset and by 8.92% on RSICD dataset.","For zero-shot classification, our RemoteCLIP outperform CLIP baseline by up to 6.39% average accuracy on 12 downstream datasets."],"url":"http://arxiv.org/abs/2306.11029v1"}
{"created":"2023-06-19","title":"Detailed retinal vessel segmentation without human annotations using simulated optical coherence tomography angiographs","abstract":"Optical coherence tomography angiography (OCTA) is a non-invasive imaging modality that can acquire high-resolution volumes of the retinal vasculature and aid the diagnosis of ocular, neurological and cardiac diseases. Segmentation of the visible blood vessels is a common first step when extracting quantitative biomarkers from these images. Classical segmentation algorithms based on thresholding are strongly affected by image artifacts and limited signal-to-noise ratio. The use of modern, deep learning-based segmentation methods has been inhibited by a lack of large datasets with detailed annotations of the blood vessels. To address this issue, recent work has employed transfer learning, where a segmentation network is trained on synthetic OCTA images and is then applied to real data. However, the previously proposed simulation models are incapable of faithfully modeling the retinal vasculature and do not provide effective domain adaptation. Because of this, current methods are not able to fully segment the retinal vasculature, in particular the smallest capillaries. In this work, we present a lightweight simulation of the retinal vascular network based on space colonization for faster and more realistic OCTA synthesis. Moreover, we introduce three contrast adaptation pipelines to decrease the domain gap between real and artificial images. We demonstrate the superior performance of our approach in extensive quantitative and qualitative experiments on three public datasets that compare our method to traditional computer vision algorithms and supervised training using human annotations. Finally, we make our entire pipeline publicly available, including the source code, pretrained models, and a large dataset of synthetic OCTA images.","sentences":["Optical coherence tomography angiography (OCTA) is a non-invasive imaging modality that can acquire high-resolution volumes of the retinal vasculature and aid the diagnosis of ocular, neurological and cardiac diseases.","Segmentation of the visible blood vessels is a common first step when extracting quantitative biomarkers from these images.","Classical segmentation algorithms based on thresholding are strongly affected by image artifacts and limited signal-to-noise ratio.","The use of modern, deep learning-based segmentation methods has been inhibited by a lack of large datasets with detailed annotations of the blood vessels.","To address this issue, recent work has employed transfer learning, where a segmentation network is trained on synthetic OCTA images and is then applied to real data.","However, the previously proposed simulation models are incapable of faithfully modeling the retinal vasculature and do not provide effective domain adaptation.","Because of this, current methods are not able to fully segment the retinal vasculature, in particular the smallest capillaries.","In this work, we present a lightweight simulation of the retinal vascular network based on space colonization for faster and more realistic OCTA synthesis.","Moreover, we introduce three contrast adaptation pipelines to decrease the domain gap between real and artificial images.","We demonstrate the superior performance of our approach in extensive quantitative and qualitative experiments on three public datasets that compare our method to traditional computer vision algorithms and supervised training using human annotations.","Finally, we make our entire pipeline publicly available, including the source code, pretrained models, and a large dataset of synthetic OCTA images."],"url":"http://arxiv.org/abs/2306.10941v1"}
{"created":"2023-06-19","title":"Handwritten Text Recognition from Crowdsourced Annotations","abstract":"In this paper, we explore different ways of training a model for handwritten text recognition when multiple imperfect or noisy transcriptions are available. We consider various training configurations, such as selecting a single transcription, retaining all transcriptions, or computing an aggregated transcription from all available annotations. In addition, we evaluate the impact of quality-based data selection, where samples with low agreement are removed from the training set. Our experiments are carried out on municipal registers of the city of Belfort (France) written between 1790 and 1946. % results The results show that computing a consensus transcription or training on multiple transcriptions are good alternatives. However, selecting training samples based on the degree of agreement between annotators introduces a bias in the training data and does not improve the results. Our dataset is publicly available on Zenodo: https://zenodo.org/record/8041668.","sentences":["In this paper, we explore different ways of training a model for handwritten text recognition when multiple imperfect or noisy transcriptions are available.","We consider various training configurations, such as selecting a single transcription, retaining all transcriptions, or computing an aggregated transcription from all available annotations.","In addition, we evaluate the impact of quality-based data selection, where samples with low agreement are removed from the training set.","Our experiments are carried out on municipal registers of the city of Belfort (France) written between 1790 and 1946.","% results The results show that computing a consensus transcription or training on multiple transcriptions are good alternatives.","However, selecting training samples based on the degree of agreement between annotators introduces a bias in the training data and does not improve the results.","Our dataset is publicly available on Zenodo: https://zenodo.org/record/8041668."],"url":"http://arxiv.org/abs/2306.10878v1"}
{"created":"2023-06-19","title":"Jamp: Controlled Japanese Temporal Inference Dataset for Evaluating Generalization Capacity of Language Models","abstract":"Natural Language Inference (NLI) tasks involving temporal inference remain challenging for pre-trained language models (LMs). Although various datasets have been created for this task, they primarily focus on English and do not address the need for resources in other languages. It is unclear whether current LMs realize the generalization capacity for temporal inference across languages. In this paper, we present Jamp, a Japanese NLI benchmark focused on temporal inference. Our dataset includes a range of temporal inference patterns, which enables us to conduct fine-grained analysis. To begin the data annotation process, we create diverse inference templates based on the formal semantics test suites. We then automatically generate diverse NLI examples by using the Japanese case frame dictionary and well-designed templates while controlling the distribution of inference patterns and gold labels. We evaluate the generalization capacities of monolingual/multilingual LMs by splitting our dataset based on tense fragments (i.e., temporal inference patterns). Our findings demonstrate that LMs struggle with specific linguistic phenomena, such as habituality, indicating that there is potential for the development of more effective NLI models across languages.","sentences":["Natural Language Inference (NLI) tasks involving temporal inference remain challenging for pre-trained language models (LMs).","Although various datasets have been created for this task, they primarily focus on English and do not address the need for resources in other languages.","It is unclear whether current LMs realize the generalization capacity for temporal inference across languages.","In this paper, we present Jamp, a Japanese NLI benchmark focused on temporal inference.","Our dataset includes a range of temporal inference patterns, which enables us to conduct fine-grained analysis.","To begin the data annotation process, we create diverse inference templates based on the formal semantics test suites.","We then automatically generate diverse NLI examples by using the Japanese case frame dictionary and well-designed templates while controlling the distribution of inference patterns and gold labels.","We evaluate the generalization capacities of monolingual/multilingual LMs by splitting our dataset based on tense fragments (i.e., temporal inference patterns).","Our findings demonstrate that LMs struggle with specific linguistic phenomena, such as habituality, indicating that there is potential for the development of more effective NLI models across languages."],"url":"http://arxiv.org/abs/2306.10727v1"}
{"created":"2023-06-19","title":"Perturbation-Based Two-Stage Multi-Domain Active Learning","abstract":"In multi-domain learning (MDL) scenarios, high labeling effort is required due to the complexity of collecting data from various domains. Active Learning (AL) presents an encouraging solution to this issue by annotating a smaller number of highly informative instances, thereby reducing the labeling effort. Previous research has relied on conventional AL strategies for MDL scenarios, which underutilize the domain-shared information of each instance during the selection procedure. To mitigate this issue, we propose a novel perturbation-based two-stage multi-domain active learning (P2S-MDAL) method incorporated into the well-regarded ASP-MTL model. Specifically, P2S-MDAL involves allocating budgets for domains and establishing regions for diversity selection, which are further used to select the most cross-domain influential samples in each region. A perturbation metric has been introduced to evaluate the robustness of the shared feature extractor of the model, facilitating the identification of potentially cross-domain influential samples. Experiments are conducted on three real-world datasets, encompassing both texts and images. The superior performance over conventional AL strategies shows the effectiveness of the proposed strategy. Additionally, an ablation study has been carried out to demonstrate the validity of each component. Finally, we outline several intriguing potential directions for future MDAL research, thus catalyzing the field's advancement.","sentences":["In multi-domain learning (MDL) scenarios, high labeling effort is required due to the complexity of collecting data from various domains.","Active Learning (AL) presents an encouraging solution to this issue by annotating a smaller number of highly informative instances, thereby reducing the labeling effort.","Previous research has relied on conventional AL strategies for MDL scenarios, which underutilize the domain-shared information of each instance during the selection procedure.","To mitigate this issue, we propose a novel perturbation-based two-stage multi-domain active learning (P2S-MDAL) method incorporated into the well-regarded ASP-MTL model.","Specifically, P2S-MDAL involves allocating budgets for domains and establishing regions for diversity selection, which are further used to select the most cross-domain influential samples in each region.","A perturbation metric has been introduced to evaluate the robustness of the shared feature extractor of the model, facilitating the identification of potentially cross-domain influential samples.","Experiments are conducted on three real-world datasets, encompassing both texts and images.","The superior performance over conventional AL strategies shows the effectiveness of the proposed strategy.","Additionally, an ablation study has been carried out to demonstrate the validity of each component.","Finally, we outline several intriguing potential directions for future MDAL research, thus catalyzing the field's advancement."],"url":"http://arxiv.org/abs/2306.10700v1"}
{"created":"2023-06-18","title":"Rapid Image Labeling via Neuro-Symbolic Learning","abstract":"The success of Computer Vision (CV) relies heavily on manually annotated data. However, it is prohibitively expensive to annotate images in key domains such as healthcare, where data labeling requires significant domain expertise and cannot be easily delegated to crowd workers. To address this challenge, we propose a neuro-symbolic approach called Rapid, which infers image labeling rules from a small amount of labeled data provided by domain experts and automatically labels unannotated data using the rules. Specifically, Rapid combines pre-trained CV models and inductive logic learning to infer the logic-based labeling rules. Rapid achieves a labeling accuracy of 83.33% to 88.33% on four image labeling tasks with only 12 to 39 labeled samples. In particular, Rapid significantly outperforms finetuned CV models in two highly specialized tasks. These results demonstrate the effectiveness of Rapid in learning from small data and its capability to generalize among different tasks. Code and our dataset are publicly available at https://github.com/Neural-Symbolic-Image-Labeling/","sentences":["The success of Computer Vision (CV) relies heavily on manually annotated data.","However, it is prohibitively expensive to annotate images in key domains such as healthcare, where data labeling requires significant domain expertise and cannot be easily delegated to crowd workers.","To address this challenge, we propose a neuro-symbolic approach called Rapid, which infers image labeling rules from a small amount of labeled data provided by domain experts and automatically labels unannotated data using the rules.","Specifically, Rapid combines pre-trained CV models and inductive logic learning to infer the logic-based labeling rules.","Rapid achieves a labeling accuracy of 83.33% to 88.33% on four image labeling tasks with only 12 to 39 labeled samples.","In particular, Rapid significantly outperforms finetuned CV models in two highly specialized tasks.","These results demonstrate the effectiveness of Rapid in learning from small data and its capability to generalize among different tasks.","Code and our dataset are publicly available at https://github.com/Neural-Symbolic-Image-Labeling/"],"url":"http://arxiv.org/abs/2306.10490v1"}
{"created":"2023-06-17","title":"MO-VLN: A Multi-Task Benchmark for Open-set Zero-Shot Vision-and-Language Navigation","abstract":"Given a natural language, a general robot has to comprehend the instruction and find the target object or location based on visual observations even in unexplored environments. Most agents rely on massive diverse training data to achieve better generalization, which requires expensive labor. These agents often focus on common objects and fewer tasks, thus are not intelligent enough to handle different types of instructions. To facilitate research in open-set vision-and-language navigation, we propose a benchmark named MO-VLN, aiming at testing the effectiveness and generalization of the agent in the multi-task setting. First, we develop a 3D simulator rendered by realistic scenarios using Unreal Engine 5, containing more realistic lights and details. The simulator contains three scenes, i.e., cafe, restaurant, and nursing house, of high value in the industry. Besides, our simulator involves multiple uncommon objects, such as takeaway cup and medical adhesive tape, which are more complicated compared with existing environments. Inspired by the recent success of large language models (e.g., ChatGPT, Vicuna), we construct diverse high-quality data of instruction type without human annotation. Our benchmark MO-VLN provides four tasks: 1) goal-conditioned navigation given a specific object category (e.g., \"fork\"); 2) goal-conditioned navigation given simple instructions (e.g., \"Search for and move towards a tennis ball\"); 3) step-by-step instruction following; 4) finding abstract object based on high-level instruction (e.g., \"I am thirsty\").","sentences":["Given a natural language, a general robot has to comprehend the instruction and find the target object or location based on visual observations even in unexplored environments.","Most agents rely on massive diverse training data to achieve better generalization, which requires expensive labor.","These agents often focus on common objects and fewer tasks, thus are not intelligent enough to handle different types of instructions.","To facilitate research in open-set vision-and-language navigation, we propose a benchmark named MO-VLN, aiming at testing the effectiveness and generalization of the agent in the multi-task setting.","First, we develop a 3D simulator rendered by realistic scenarios using Unreal Engine 5, containing more realistic lights and details.","The simulator contains three scenes, i.e., cafe, restaurant, and nursing house, of high value in the industry.","Besides, our simulator involves multiple uncommon objects, such as takeaway cup and medical adhesive tape, which are more complicated compared with existing environments.","Inspired by the recent success of large language models (e.g., ChatGPT, Vicuna), we construct diverse high-quality data of instruction type without human annotation.","Our benchmark MO-VLN provides four tasks: 1) goal-conditioned navigation given a specific object category (e.g., \"fork\"); 2) goal-conditioned navigation given simple instructions (e.g., \"Search for and move towards a tennis ball\"); 3) step-by-step instruction following; 4) finding abstract object based on high-level instruction (e.g., \"I am thirsty\")."],"url":"http://arxiv.org/abs/2306.10322v1"}
{"created":"2023-06-23","title":"Bring Your Own Data! Self-Supervised Evaluation for Large Language Models","abstract":"With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative. For example, a company deploying a client-facing chatbot must ensure that the model will not respond to client requests with profanity. Current evaluations approach this problem using small, domain-specific datasets with human-curated labels. These evaluation sets are often sampled from a narrow and simplified distribution, and data sources can unknowingly be leaked into the training set which can lead to misleading evaluations. To bypass these drawbacks, we propose a framework for self-supervised evaluation of LLMs by analyzing their sensitivity or invariance to transformations on the input text. Self-supervised evaluation can directly monitor LLM behavior on datasets collected in the wild or streamed during live model deployment. We demonstrate self-supervised evaluation strategies for measuring closed-book knowledge, toxicity, and long-range context dependence, in addition to sensitivity to grammatical structure and tokenization errors. When comparisons to similar human-labeled benchmarks are available, we find strong correlations between self-supervised and human-supervised evaluations. The self-supervised paradigm complements current evaluation strategies that rely on labeled data.","sentences":["With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative.","For example, a company deploying a client-facing chatbot must ensure that the model will not respond to client requests with profanity.","Current evaluations approach this problem using small, domain-specific datasets with human-curated labels.","These evaluation sets are often sampled from a narrow and simplified distribution, and data sources can unknowingly be leaked into the training set which can lead to misleading evaluations.","To bypass these drawbacks, we propose a framework for self-supervised evaluation of LLMs by analyzing their sensitivity or invariance to transformations on the input text.","Self-supervised evaluation can directly monitor LLM behavior on datasets collected in the wild or streamed during live model deployment.","We demonstrate self-supervised evaluation strategies for measuring closed-book knowledge, toxicity, and long-range context dependence, in addition to sensitivity to grammatical structure and tokenization errors.","When comparisons to similar human-labeled benchmarks are available, we find strong correlations between self-supervised and human-supervised evaluations.","The self-supervised paradigm complements current evaluation strategies that rely on labeled data."],"url":"http://arxiv.org/abs/2306.13651v1"}
{"created":"2023-06-23","title":"Margin Maximization in Attention Mechanism","abstract":"Attention mechanism is a central component of the transformer architecture which led to the phenomenal success of large language models. However, the theoretical principles underlying the attention mechanism are poorly understood, especially its nonconvex optimization dynamics. In this work, we explore the seminal softmax-attention model $f(\\boldsymbol{X})=\\langle \\boldsymbol{Xv}, \\texttt{softmax}(\\boldsymbol{XWp})\\rangle$, where, $\\boldsymbol{X}$ is the token sequence and $(\\boldsymbol{v},\\boldsymbol{W},\\boldsymbol{p})$ are tunable parameters. We prove that running gradient descent on $\\boldsymbol{p}$, or equivalently $\\boldsymbol{W}$, converges in direction to a max-margin solution that separates $\\textit{locally-optimal}$ tokens from non-optimal ones. This clearly formalizes attention as a token separation mechanism. Remarkably, our results are applicable to general data and precisely characterize $\\textit{optimality}$ of tokens in terms of the value embeddings $\\boldsymbol{Xv}$ and problem geometry. We also provide a broader regularization path analysis that establishes the margin maximizing nature of attention even for nonlinear prediction heads. When optimizing $\\boldsymbol{v}$ and $\\boldsymbol{p}$ simultaneously with logistic loss, we identify conditions under which the regularization paths directionally converge to their respective hard-margin SVM solutions where $\\boldsymbol{v}$ separates the input features based on their labels. Interestingly, the SVM formulation of $\\boldsymbol{p}$ is influenced by the support vector geometry of $\\boldsymbol{v}$. Finally, we verify our theoretical findings via numerical experiments and provide insights.","sentences":["Attention mechanism is a central component of the transformer architecture which led to the phenomenal success of large language models.","However, the theoretical principles underlying the attention mechanism are poorly understood, especially its nonconvex optimization dynamics.","In this work, we explore the seminal softmax-attention model $f(\\boldsymbol{X})=\\langle \\boldsymbol{Xv}, \\texttt{softmax}(\\boldsymbol{XWp})\\rangle$, where, $\\boldsymbol{X}$ is the token sequence and $(\\boldsymbol{v},\\boldsymbol{W},\\boldsymbol{p})$ are tunable parameters.","We prove that running gradient descent on $\\boldsymbol{p}$, or equivalently $\\boldsymbol{W}$, converges in direction to a max-margin solution that separates $\\textit{locally-optimal}$ tokens from non-optimal ones.","This clearly formalizes attention as a token separation mechanism.","Remarkably, our results are applicable to general data and precisely characterize $\\textit{optimality}$ of tokens in terms of the value embeddings $\\boldsymbol{Xv}$ and problem geometry.","We also provide a broader regularization path analysis that establishes the margin maximizing nature of attention even for nonlinear prediction heads.","When optimizing $\\boldsymbol{v}$ and $\\boldsymbol{p}$ simultaneously with logistic loss, we identify conditions under which the regularization paths directionally converge to their respective hard-margin SVM solutions where $\\boldsymbol{v}$ separates the input features based on their labels.","Interestingly, the SVM formulation of $\\boldsymbol{p}$ is influenced by the support vector geometry of $\\boldsymbol{v}$. Finally, we verify our theoretical findings via numerical experiments and provide insights."],"url":"http://arxiv.org/abs/2306.13596v1"}
{"created":"2023-06-23","title":"A Semi-Paired Approach For Label-to-Image Translation","abstract":"Data efficiency, or the ability to generalize from a few labeled data, remains a major challenge in deep learning. Semi-supervised learning has thrived in traditional recognition tasks alleviating the need for large amounts of labeled data, yet it remains understudied in image-to-image translation (I2I) tasks. In this work, we introduce the first semi-supervised (semi-paired) framework for label-to-image translation, a challenging subtask of I2I which generates photorealistic images from semantic label maps. In the semi-paired setting, the model has access to a small set of paired data and a larger set of unpaired images and labels. Instead of using geometrical transformations as a pretext task like previous works, we leverage an input reconstruction task by exploiting the conditional discriminator on the paired data as a reverse generator. We propose a training algorithm for this shared network, and we present a rare classes sampling algorithm to focus on under-represented classes. Experiments on 3 standard benchmarks show that the proposed model outperforms state-of-the-art unsupervised and semi-supervised approaches, as well as some fully supervised approaches while using a much smaller number of paired samples.","sentences":["Data efficiency, or the ability to generalize from a few labeled data, remains a major challenge in deep learning.","Semi-supervised learning has thrived in traditional recognition tasks alleviating the need for large amounts of labeled data, yet it remains understudied in image-to-image translation (I2I) tasks.","In this work, we introduce the first semi-supervised (semi-paired) framework for label-to-image translation, a challenging subtask of I2I which generates photorealistic images from semantic label maps.","In the semi-paired setting, the model has access to a small set of paired data and a larger set of unpaired images and labels.","Instead of using geometrical transformations as a pretext task like previous works, we leverage an input reconstruction task by exploiting the conditional discriminator on the paired data as a reverse generator.","We propose a training algorithm for this shared network, and we present a rare classes sampling algorithm to focus on under-represented classes.","Experiments on 3 standard benchmarks show that the proposed model outperforms state-of-the-art unsupervised and semi-supervised approaches, as well as some fully supervised approaches while using a much smaller number of paired samples."],"url":"http://arxiv.org/abs/2306.13585v1"}
{"created":"2023-06-23","title":"PathMLP: Smooth Path Towards High-order Homophily","abstract":"Real-world graphs exhibit increasing heterophily, where nodes no longer tend to be connected to nodes with the same label, challenging the homophily assumption of classical graph neural networks (GNNs) and impeding their performance. Intriguingly, we observe that certain high-order information on heterophilous data exhibits high homophily, which motivates us to involve high-order information in node representation learning. However, common practices in GNNs to acquire high-order information mainly through increasing model depth and altering message-passing mechanisms, which, albeit effective to a certain extent, suffer from three shortcomings: 1) over-smoothing due to excessive model depth and propagation times; 2) high-order information is not fully utilized; 3) low computational efficiency. In this regard, we design a similarity-based path sampling strategy to capture smooth paths containing high-order homophily. Then we propose a lightweight model based on multi-layer perceptrons (MLP), named PathMLP, which can encode messages carried by paths via simple transformation and concatenation operations, and effectively learn node representations in heterophilous graphs through adaptive path aggregation. Extensive experiments demonstrate that our method outperforms baselines on 16 out of 20 datasets, underlining its effectiveness and superiority in alleviating the heterophily problem. In addition, our method is immune to over-smoothing and has high computational efficiency.","sentences":["Real-world graphs exhibit increasing heterophily, where nodes no longer tend to be connected to nodes with the same label, challenging the homophily assumption of classical graph neural networks (GNNs) and impeding their performance.","Intriguingly, we observe that certain high-order information on heterophilous data exhibits high homophily, which motivates us to involve high-order information in node representation learning.","However, common practices in GNNs to acquire high-order information mainly through increasing model depth and altering message-passing mechanisms, which, albeit effective to a certain extent, suffer from three shortcomings: 1) over-smoothing due to excessive model depth and propagation times; 2) high-order information is not fully utilized; 3) low computational efficiency.","In this regard, we design a similarity-based path sampling strategy to capture smooth paths containing high-order homophily.","Then we propose a lightweight model based on multi-layer perceptrons (MLP), named PathMLP, which can encode messages carried by paths via simple transformation and concatenation operations, and effectively learn node representations in heterophilous graphs through adaptive path aggregation.","Extensive experiments demonstrate that our method outperforms baselines on 16 out of 20 datasets, underlining its effectiveness and superiority in alleviating the heterophily problem.","In addition, our method is immune to over-smoothing and has high computational efficiency."],"url":"http://arxiv.org/abs/2306.13532v1"}
{"created":"2023-06-23","title":"Understanding quantum machine learning also requires rethinking generalization","abstract":"Quantum machine learning models have shown successful generalization performance even when trained with few data. In this work, through systematic randomization experiments, we show that traditional approaches to understanding generalization fail to explain the behavior of such quantum models. Our experiments reveal that state-of-the-art quantum neural networks accurately fit random states and random labeling of training data. This ability to memorize random data defies current notions of small generalization error, problematizing approaches that build on complexity measures such as the VC dimension, the Rademacher complexity, and all their uniform relatives. We complement our empirical results with a theoretical construction showing that quantum neural networks can fit arbitrary labels to quantum states, hinting at their memorization ability. Our results do not preclude the possibility of good generalization with few training data but rather rule out any possible guarantees based only on the properties of the model family. These findings expose a fundamental challenge in the conventional understanding of generalization in quantum machine learning and highlight the need for a paradigm shift in the design of quantum models for machine learning tasks.","sentences":["Quantum machine learning models have shown successful generalization performance even when trained with few data.","In this work, through systematic randomization experiments, we show that traditional approaches to understanding generalization fail to explain the behavior of such quantum models.","Our experiments reveal that state-of-the-art quantum neural networks accurately fit random states and random labeling of training data.","This ability to memorize random data defies current notions of small generalization error, problematizing approaches that build on complexity measures such as the VC dimension, the Rademacher complexity, and all their uniform relatives.","We complement our empirical results with a theoretical construction showing that quantum neural networks can fit arbitrary labels to quantum states, hinting at their memorization ability.","Our results do not preclude the possibility of good generalization with few training data but rather rule out any possible guarantees based only on the properties of the model family.","These findings expose a fundamental challenge in the conventional understanding of generalization in quantum machine learning and highlight the need for a paradigm shift in the design of quantum models for machine learning tasks."],"url":"http://arxiv.org/abs/2306.13461v1"}
{"created":"2023-06-23","title":"CLUE: Calibrated Latent Guidance for Offline Reinforcement Learning","abstract":"Offline reinforcement learning (RL) aims to learn an optimal policy from pre-collected and labeled datasets, which eliminates the time-consuming data collection in online RL. However, offline RL still bears a large burden of specifying/handcrafting extrinsic rewards for each transition in the offline data. As a remedy for the labor-intensive labeling, we propose to endow offline RL tasks with a few expert data and utilize the limited expert data to drive intrinsic rewards, thus eliminating the need for extrinsic rewards. To achieve that, we introduce \\textbf{C}alibrated \\textbf{L}atent g\\textbf{U}idanc\\textbf{E} (CLUE), which utilizes a conditional variational auto-encoder to learn a latent space such that intrinsic rewards can be directly qualified over the latent space. CLUE's key idea is to align the intrinsic rewards consistent with the expert intention via enforcing the embeddings of expert data to a calibrated contextual representation. We instantiate the expert-driven intrinsic rewards in sparse-reward offline RL tasks, offline imitation learning (IL) tasks, and unsupervised offline RL tasks. Empirically, we find that CLUE can effectively improve the sparse-reward offline RL performance, outperform the state-of-the-art offline IL baselines, and discover diverse skills from static reward-free offline data.","sentences":["Offline reinforcement learning (RL) aims to learn an optimal policy from pre-collected and labeled datasets, which eliminates the time-consuming data collection in online RL.","However, offline RL still bears a large burden of specifying/handcrafting extrinsic rewards for each transition in the offline data.","As a remedy for the labor-intensive labeling, we propose to endow offline RL tasks with a few expert data and utilize the limited expert data to drive intrinsic rewards, thus eliminating the need for extrinsic rewards.","To achieve that, we introduce \\textbf{C}alibrated \\textbf{L}atent g\\textbf{U}idanc\\textbf{E} (CLUE), which utilizes a conditional variational auto-encoder to learn a latent space such that intrinsic rewards can be directly qualified over the latent space.","CLUE's key idea is to align the intrinsic rewards consistent with the expert intention via enforcing the embeddings of expert data to a calibrated contextual representation.","We instantiate the expert-driven intrinsic rewards in sparse-reward offline RL tasks, offline imitation learning (IL) tasks, and unsupervised offline RL tasks.","Empirically, we find that CLUE can effectively improve the sparse-reward offline RL performance, outperform the state-of-the-art offline IL baselines, and discover diverse skills from static reward-free offline data."],"url":"http://arxiv.org/abs/2306.13412v1"}
{"created":"2023-06-23","title":"Judging a book by its cover: how much of REF `research quality' is really `journal prestige'?","abstract":"The Research Excellence Framework (REF) is a periodic UK-wide assessment of the quality of published research in universities. The most recent REF was in 2014, and the next will be in 2021. The published results of REF2014 include a categorical `quality profile' for each unit of assessment (typically a university department), reporting what percentage of the unit's REF-submitted research outputs were assessed as being at each of four quality levels (labelled 4*, 3*, 2* and 1*). Also in the public domain are the original submissions made to REF2014, which include -- for each unit of assessment -- publication details of the REF-submitted research outputs.   In this work, we address the question: to what extent can a REF quality profile for research outputs be attributed to the journals in which (most of) those outputs were published? The data are the published submissions and results from REF2014. The main statistical challenge comes from the fact that REF quality profiles are available only at the aggregated level of whole units of assessment: the REF panel's assessment of each individual research output is not made public. Our research question is thus an `ecological inference' problem, which demands special care in model formulation and methodology. The analysis is based on logit models in which journal-specific parameters are regularized via prior `pseudo-data'. We develop a lack-of-fit measure for the extent to which REF scores appear to depend on publication venues rather than research quality or institution-level differences. Results are presented for several research fields.","sentences":["The Research Excellence Framework (REF) is a periodic UK-wide assessment of the quality of published research in universities.","The most recent REF was in 2014, and the next will be in 2021.","The published results of REF2014 include a categorical `quality profile' for each unit of assessment (typically a university department), reporting what percentage of the unit's REF-submitted research outputs were assessed as being at each of four quality levels (labelled 4*, 3*, 2* and 1*).","Also in the public domain are the original submissions made to REF2014, which include -- for each unit of assessment -- publication details of the REF-submitted research outputs.   ","In this work, we address the question: to what extent can a REF quality profile for research outputs be attributed to the journals in which (most of) those outputs were published?","The data are the published submissions and results from REF2014.","The main statistical challenge comes from the fact that REF quality profiles are available only at the aggregated level of whole units of assessment: the REF panel's assessment of each individual research output is not made public.","Our research question is thus an `ecological inference' problem, which demands special care in model formulation and methodology.","The analysis is based on logit models in which journal-specific parameters are regularized via prior `pseudo-data'.","We develop a lack-of-fit measure for the extent to which REF scores appear to depend on publication venues rather than research quality or institution-level differences.","Results are presented for several research fields."],"url":"http://arxiv.org/abs/2306.13367v1"}
{"created":"2023-06-23","title":"Unsupervised Deformable Ultrasound Image Registration and Its Application for Vessel Segmentation","abstract":"This paper presents a deep-learning model for deformable registration of ultrasound images at online rates, which we call U-RAFT. As its name suggests, U-RAFT is based on RAFT, a convolutional neural network for estimating optical flow. U-RAFT, however, can be trained in an unsupervised manner and can generate synthetic images for training vessel segmentation models. We propose and compare the registration quality of different loss functions for training U-RAFT. We also show how our approach, together with a robot performing force-controlled scans, can be used to generate synthetic deformed images to significantly expand the size of a femoral vessel segmentation training dataset without the need for additional manual labeling. We validate our approach on both a silicone human tissue phantom as well as on in-vivo porcine images. We show that U-RAFT generates synthetic ultrasound images with 98% and 81% structural similarity index measure (SSIM) to the real ultrasound images for the phantom and porcine datasets, respectively. We also demonstrate that synthetic deformed images from U-RAFT can be used as a data augmentation technique for vessel segmentation models to improve intersection-over-union (IoU) segmentation performance","sentences":["This paper presents a deep-learning model for deformable registration of ultrasound images at online rates, which we call U-RAFT.","As its name suggests, U-RAFT is based on RAFT, a convolutional neural network for estimating optical flow.","U-RAFT, however, can be trained in an unsupervised manner and can generate synthetic images for training vessel segmentation models.","We propose and compare the registration quality of different loss functions for training U-RAFT.","We also show how our approach, together with a robot performing force-controlled scans, can be used to generate synthetic deformed images to significantly expand the size of a femoral vessel segmentation training dataset without the need for additional manual labeling.","We validate our approach on both a silicone human tissue phantom as well as on in-vivo porcine images.","We show that U-RAFT generates synthetic ultrasound images with 98% and 81% structural similarity index measure (SSIM) to the real ultrasound images for the phantom and porcine datasets, respectively.","We also demonstrate that synthetic deformed images from U-RAFT can be used as a data augmentation technique for vessel segmentation models to improve intersection-over-union (IoU) segmentation performance"],"url":"http://arxiv.org/abs/2306.13329v1"}
{"created":"2023-06-23","title":"Mutually Guided Few-shot Learning for Relational Triple Extraction","abstract":"Knowledge graphs (KGs), containing many entity-relation-entity triples, provide rich information for downstream applications. Although extracting triples from unstructured texts has been widely explored, most of them require a large number of labeled instances. The performance will drop dramatically when only few labeled data are available. To tackle this problem, we propose the Mutually Guided Few-shot learning framework for Relational Triple Extraction (MG-FTE). Specifically, our method consists of an entity-guided relation proto-decoder to classify the relations firstly and a relation-guided entity proto-decoder to extract entities based on the classified relations. To draw the connection between entity and relation, we design a proto-level fusion module to boost the performance of both entity extraction and relation classification. Moreover, a new cross-domain few-shot triple extraction task is introduced. Extensive experiments show that our method outperforms many state-of-the-art methods by 12.6 F1 score on FewRel 1.0 (single-domain) and 20.5 F1 score on FewRel 2.0 (cross-domain).","sentences":["Knowledge graphs (KGs), containing many entity-relation-entity triples, provide rich information for downstream applications.","Although extracting triples from unstructured texts has been widely explored, most of them require a large number of labeled instances.","The performance will drop dramatically when only few labeled data are available.","To tackle this problem, we propose the Mutually Guided Few-shot learning framework for Relational Triple Extraction (MG-FTE).","Specifically, our method consists of an entity-guided relation proto-decoder to classify the relations firstly and a relation-guided entity proto-decoder to extract entities based on the classified relations.","To draw the connection between entity and relation, we design a proto-level fusion module to boost the performance of both entity extraction and relation classification.","Moreover, a new cross-domain few-shot triple extraction task is introduced.","Extensive experiments show that our method outperforms many state-of-the-art methods by 12.6 F1 score on FewRel 1.0 (single-domain) and 20.5 F1 score on FewRel 2.0 (cross-domain)."],"url":"http://arxiv.org/abs/2306.13310v1"}
{"created":"2023-06-23","title":"Deep Omni-supervised Learning for Rib Fracture Detection from Chest Radiology Images","abstract":"Deep learning (DL)-based rib fracture detection has shown promise of playing an important role in preventing mortality and improving patient outcome. Normally, developing DL-based object detection models requires huge amount of bounding box annotation. However, annotating medical data is time-consuming and expertise-demanding, making obtaining a large amount of fine-grained annotations extremely infeasible. This poses pressing need of developing label-efficient detection models to alleviate radiologists' labeling burden. To tackle this challenge, the literature of object detection has witnessed an increase of weakly-supervised and semi-supervised approaches, yet still lacks a unified framework that leverages various forms of fully-labeled, weakly-labeled, and unlabeled data. In this paper, we present a novel omni-supervised object detection network, ORF-Netv2, to leverage as much available supervision as possible. Specifically, a multi-branch omni-supervised detection head is introduced with each branch trained with a specific type of supervision. A co-training-based dynamic label assignment strategy is then proposed to enable flexibly and robustly learning from the weakly-labeled and unlabeled data. Extensively evaluation was conducted for the proposed framework with three rib fracture datasets on both chest CT and X-ray. By leveraging all forms of supervision, ORF-Netv2 achieves mAPs of 34.7, 44.7, and 19.4 on the three datasets, respectively, surpassing the baseline detector which uses only box annotations by mAP gains of 3.8, 4.8, and 5.0, respectively. Furthermore, ORF-Netv2 consistently outperforms other competitive label-efficient methods over various scenarios, showing a promising framework for label-efficient fracture detection.","sentences":["Deep learning (DL)-based rib fracture detection has shown promise of playing an important role in preventing mortality and improving patient outcome.","Normally, developing DL-based object detection models requires huge amount of bounding box annotation.","However, annotating medical data is time-consuming and expertise-demanding, making obtaining a large amount of fine-grained annotations extremely infeasible.","This poses pressing need of developing label-efficient detection models to alleviate radiologists' labeling burden.","To tackle this challenge, the literature of object detection has witnessed an increase of weakly-supervised and semi-supervised approaches, yet still lacks a unified framework that leverages various forms of fully-labeled, weakly-labeled, and unlabeled data.","In this paper, we present a novel omni-supervised object detection network, ORF-Netv2, to leverage as much available supervision as possible.","Specifically, a multi-branch omni-supervised detection head is introduced with each branch trained with a specific type of supervision.","A co-training-based dynamic label assignment strategy is then proposed to enable flexibly and robustly learning from the weakly-labeled and unlabeled data.","Extensively evaluation was conducted for the proposed framework with three rib fracture datasets on both chest CT and X-ray.","By leveraging all forms of supervision, ORF-Netv2 achieves mAPs of 34.7, 44.7, and 19.4 on the three datasets, respectively, surpassing the baseline detector which uses only box annotations by mAP gains of 3.8, 4.8, and 5.0, respectively.","Furthermore, ORF-Netv2 consistently outperforms other competitive label-efficient methods over various scenarios, showing a promising framework for label-efficient fracture detection."],"url":"http://arxiv.org/abs/2306.13301v1"}
{"created":"2023-06-23","title":"Precise Asymptotic Generalization for Multiclass Classification with Overparameterized Linear Models","abstract":"We study the asymptotic generalization of an overparameterized linear model for multiclass classification under the Gaussian covariates bi-level model introduced in Subramanian et al.~'22, where the number of data points, features, and classes all grow together. We fully resolve the conjecture posed in Subramanian et al.~'22, matching the predicted regimes for generalization. Furthermore, our new lower bounds are akin to an information-theoretic strong converse: they establish that the misclassification rate goes to 0 or 1 asymptotically. One surprising consequence of our tight results is that the min-norm interpolating classifier can be asymptotically suboptimal relative to noninterpolating classifiers in the regime where the min-norm interpolating regressor is known to be optimal.   The key to our tight analysis is a new variant of the Hanson-Wright inequality which is broadly useful for multiclass problems with sparse labels. As an application, we show that the same type of analysis can be used to analyze the related multilabel classification problem under the same bi-level ensemble.","sentences":["We study the asymptotic generalization of an overparameterized linear model for multiclass classification under the Gaussian covariates bi-level model introduced in Subramanian et al.~'22, where the number of data points, features, and classes all grow together.","We fully resolve the conjecture posed in Subramanian et al.~'22, matching the predicted regimes for generalization.","Furthermore, our new lower bounds are akin to an information-theoretic strong converse: they establish that the misclassification rate goes to 0 or 1 asymptotically.","One surprising consequence of our tight results is that the min-norm interpolating classifier can be asymptotically suboptimal relative to noninterpolating classifiers in the regime where the min-norm interpolating regressor is known to be optimal.   ","The key to our tight analysis is a new variant of the Hanson-Wright inequality which is broadly useful for multiclass problems with sparse labels.","As an application, we show that the same type of analysis can be used to analyze the related multilabel classification problem under the same bi-level ensemble."],"url":"http://arxiv.org/abs/2306.13255v1"}
{"created":"2023-06-22","title":"AmicroN: A Framework for Generating Annotations for Human Activity Recognition with Granular Micro-Activities","abstract":"Efficient human activity recognition (HAR) using sensor data needs a significant volume of annotated data. The growing volume of unlabelled sensor data has challenged conventional practices for gathering HAR annotations with human-in-the-loop approaches, often leading to the collection of shallower annotations. These shallower annotations ignore the fine-grained micro-activities that constitute any complex activities of daily living (ADL). Understanding this, we, in this paper, first analyze this lack of granular annotations from available pre-annotated datasets to understand the practical inconsistencies and also perform a detailed survey to look into the human perception surrounding annotations. Drawing motivations from these, we next develop the framework AmicroN that can automatically generate micro-activity annotations using locomotive signatures and the available coarse-grain macro-activity labels. In the backend, AmicroN applies change-point detection followed by zero-shot learning with activity embeddings to identify the unseen micro-activities in an unsupervised manner. Rigorous evaluation on publicly available datasets shows that AmicroN can accurately generate micro-activity annotations with a median F1-score of >0.75. Additionally, we also show that AmicroN can be used in a plug-and-play manner with Large Language Models (LLMs) to obtain the micro-activity labels, thus making it more practical for realistic applications.","sentences":["Efficient human activity recognition (HAR) using sensor data needs a significant volume of annotated data.","The growing volume of unlabelled sensor data has challenged conventional practices for gathering HAR annotations with human-in-the-loop approaches, often leading to the collection of shallower annotations.","These shallower annotations ignore the fine-grained micro-activities that constitute any complex activities of daily living (ADL).","Understanding this, we, in this paper, first analyze this lack of granular annotations from available pre-annotated datasets to understand the practical inconsistencies and also perform a detailed survey to look into the human perception surrounding annotations.","Drawing motivations from these, we next develop the framework AmicroN that can automatically generate micro-activity annotations using locomotive signatures and the available coarse-grain macro-activity labels.","In the backend, AmicroN applies change-point detection followed by zero-shot learning with activity embeddings to identify the unseen micro-activities in an unsupervised manner.","Rigorous evaluation on publicly available datasets shows that AmicroN can accurately generate micro-activity annotations with a median F1-score of >0.75.","Additionally, we also show that AmicroN can be used in a plug-and-play manner with Large Language Models (LLMs) to obtain the micro-activity labels, thus making it more practical for realistic applications."],"url":"http://arxiv.org/abs/2306.13149v1"}
{"created":"2023-06-22","title":"Adversarial Resilience in Sequential Prediction via Abstention","abstract":"We study the problem of sequential prediction in the stochastic setting with an adversary that is allowed to inject clean-label adversarial (or out-of-distribution) examples. Algorithms designed to handle purely stochastic data tend to fail in the presence of such adversarial examples, often leading to erroneous predictions. This is undesirable in many high-stakes applications such as medical recommendations, where abstaining from predictions on adversarial examples is preferable to misclassification. On the other hand, assuming fully adversarial data leads to very pessimistic bounds that are often vacuous in practice.   To capture this motivation, we propose a new model of sequential prediction that sits between the purely stochastic and fully adversarial settings by allowing the learner to abstain from making a prediction at no cost on adversarial examples. Assuming access to the marginal distribution on the non-adversarial examples, we design a learner whose error scales with the VC dimension (mirroring the stochastic setting) of the hypothesis class, as opposed to the Littlestone dimension which characterizes the fully adversarial setting. Furthermore, we design a learner for VC dimension~1 classes, which works even in the absence of access to the marginal distribution. Our key technical contribution is a novel measure for quantifying uncertainty for learning VC classes, which may be of independent interest.","sentences":["We study the problem of sequential prediction in the stochastic setting with an adversary that is allowed to inject clean-label adversarial (or out-of-distribution) examples.","Algorithms designed to handle purely stochastic data tend to fail in the presence of such adversarial examples, often leading to erroneous predictions.","This is undesirable in many high-stakes applications such as medical recommendations, where abstaining from predictions on adversarial examples is preferable to misclassification.","On the other hand, assuming fully adversarial data leads to very pessimistic bounds that are often vacuous in practice.   ","To capture this motivation, we propose a new model of sequential prediction that sits between the purely stochastic and fully adversarial settings by allowing the learner to abstain from making a prediction at no cost on adversarial examples.","Assuming access to the marginal distribution on the non-adversarial examples, we design a learner whose error scales with the VC dimension (mirroring the stochastic setting) of the hypothesis class, as opposed to the Littlestone dimension which characterizes the fully adversarial setting.","Furthermore, we design a learner for VC dimension~1 classes, which works even in the absence of access to the marginal distribution.","Our key technical contribution is a novel measure for quantifying uncertainty for learning VC classes, which may be of independent interest."],"url":"http://arxiv.org/abs/2306.13119v1"}
{"created":"2023-06-22","title":"Online Self-Supervised Learning in Machine Learning Intrusion Detection for the Internet of Things","abstract":"This paper proposes a novel Self-Supervised Intrusion Detection (SSID) framework, which enables a fully online Machine Learning (ML) based Intrusion Detection System (IDS) that requires no human intervention or prior off-line learning. The proposed framework analyzes and labels incoming traffic packets based only on the decisions of the IDS itself using an Auto-Associative Deep Random Neural Network, and on an online estimate of its statistically measured trustworthiness. The SSID framework enables IDS to adapt rapidly to time-varying characteristics of the network traffic, and eliminates the need for offline data collection. This approach avoids human errors in data labeling, and human labor and computational costs of model training and data collection. The approach is experimentally evaluated on public datasets and compared with well-known ML models, showing that this SSID framework is very useful and advantageous as an accurate and online learning ML-based IDS for IoT systems.","sentences":["This paper proposes a novel Self-Supervised Intrusion Detection (SSID) framework, which enables a fully online Machine Learning (ML) based Intrusion Detection System (IDS) that requires no human intervention or prior off-line learning.","The proposed framework analyzes and labels incoming traffic packets based only on the decisions of the IDS itself using an Auto-Associative Deep Random Neural Network, and on an online estimate of its statistically measured trustworthiness.","The SSID framework enables IDS to adapt rapidly to time-varying characteristics of the network traffic, and eliminates the need for offline data collection.","This approach avoids human errors in data labeling, and human labor and computational costs of model training and data collection.","The approach is experimentally evaluated on public datasets and compared with well-known ML models, showing that this SSID framework is very useful and advantageous as an accurate and online learning ML-based IDS for IoT systems."],"url":"http://arxiv.org/abs/2306.13030v1"}
{"created":"2023-06-22","title":"Decentralized Online Federated G-Network Learning for Lightweight Intrusion Detection","abstract":"Cyberattacks are increasingly threatening networked systems, often with the emergence of new types of unknown (zero-day) attacks and the rise of vulnerable devices. While Machine Learning (ML)-based Intrusion Detection Systems (IDSs) have been shown to be extremely promising in detecting these attacks, the need to learn large amounts of labelled data often limits the applicability of ML-based IDSs to cybersystems that only have access to private local data. To address this issue, this paper proposes a novel Decentralized and Online Federated Learning Intrusion Detection (DOF-ID) architecture. DOF-ID is a collaborative learning system that allows each IDS used for a cybersystem to learn from experience gained in other cybersystems in addition to its own local data without violating the data privacy of other systems. As the performance evaluation results using public Kitsune and Bot-IoT datasets show, DOF-ID significantly improves the intrusion detection performance in all collaborating nodes simultaneously with acceptable computation time for online learning.","sentences":["Cyberattacks are increasingly threatening networked systems, often with the emergence of new types of unknown (zero-day) attacks and the rise of vulnerable devices.","While Machine Learning (ML)-based Intrusion Detection Systems (IDSs) have been shown to be extremely promising in detecting these attacks, the need to learn large amounts of labelled data often limits the applicability of ML-based IDSs to cybersystems that only have access to private local data.","To address this issue, this paper proposes a novel Decentralized and Online Federated Learning Intrusion Detection (DOF-ID) architecture.","DOF-ID is a collaborative learning system that allows each IDS used for a cybersystem to learn from experience gained in other cybersystems in addition to its own local data without violating the data privacy of other systems.","As the performance evaluation results using public Kitsune and Bot-IoT datasets show, DOF-ID significantly improves the intrusion detection performance in all collaborating nodes simultaneously with acceptable computation time for online learning."],"url":"http://arxiv.org/abs/2306.13029v1"}
{"created":"2023-06-22","title":"An Interactive Interface for Novel Class Discovery in Tabular Data","abstract":"Novel Class Discovery (NCD) is the problem of trying to discover novel classes in an unlabeled set, given a labeled set of different but related classes. The majority of NCD methods proposed so far only deal with image data, despite tabular data being among the most widely used type of data in practical applications. To interpret the results of clustering or NCD algorithms, data scientists need to understand the domain- and application-specific attributes of tabular data. This task is difficult and can often only be performed by a domain expert. Therefore, this interface allows a domain expert to easily run state-of-the-art algorithms for NCD in tabular data. With minimal knowledge in data science, interpretable results can be generated.","sentences":["Novel Class Discovery (NCD) is the problem of trying to discover novel classes in an unlabeled set, given a labeled set of different but related classes.","The majority of NCD methods proposed so far only deal with image data, despite tabular data being among the most widely used type of data in practical applications.","To interpret the results of clustering or NCD algorithms, data scientists need to understand the domain- and application-specific attributes of tabular data.","This task is difficult and can often only be performed by a domain expert.","Therefore, this interface allows a domain expert to easily run state-of-the-art algorithms for NCD in tabular data.","With minimal knowledge in data science, interpretable results can be generated."],"url":"http://arxiv.org/abs/2306.12919v1"}
{"created":"2023-06-22","title":"Toward Leveraging Pre-Trained Self-Supervised Frontends for Automatic Singing Voice Understanding Tasks: Three Case Studies","abstract":"Automatic singing voice understanding tasks, such as singer identification, singing voice transcription, and singing technique classification, benefit from data-driven approaches that utilize deep learning techniques. These approaches work well even under the rich diversity of vocal and noisy samples owing to their representation ability. However, the limited availability of labeled data remains a significant obstacle to achieving satisfactory performance. In recent years, self-supervised learning models (SSL models) have been trained using large amounts of unlabeled data in the field of speech processing and music classification. By fine-tuning these models for the target tasks, comparable performance to conventional supervised learning can be achieved with limited training data. Therefore, in this paper, we investigate the effectiveness of SSL models for various singing voice recognition tasks. We report the results of experiments comparing SSL models for three different tasks (i.e., singer identification, singing voice transcription, and singing technique classification) as initial exploration and aim to discuss these findings. Experimental results show that each SSL model achieves comparable performance and sometimes outperforms compared to state-of-the-art methods on each task. We also conducted a layer-wise analysis to further understand the behavior of the SSL models.","sentences":["Automatic singing voice understanding tasks, such as singer identification, singing voice transcription, and singing technique classification, benefit from data-driven approaches that utilize deep learning techniques.","These approaches work well even under the rich diversity of vocal and noisy samples owing to their representation ability.","However, the limited availability of labeled data remains a significant obstacle to achieving satisfactory performance.","In recent years, self-supervised learning models (SSL models) have been trained using large amounts of unlabeled data in the field of speech processing and music classification.","By fine-tuning these models for the target tasks, comparable performance to conventional supervised learning can be achieved with limited training data.","Therefore, in this paper, we investigate the effectiveness of SSL models for various singing voice recognition tasks.","We report the results of experiments comparing SSL models for three different tasks (i.e., singer identification, singing voice transcription, and singing technique classification) as initial exploration and aim to discuss these findings.","Experimental results show that each SSL model achieves comparable performance and sometimes outperforms compared to state-of-the-art methods on each task.","We also conducted a layer-wise analysis to further understand the behavior of the SSL models."],"url":"http://arxiv.org/abs/2306.12714v1"}
{"created":"2023-06-21","title":"Rapid building damage assessment workflow: An implementation for the 2023 Rolling Fork, Mississippi tornado event","abstract":"Rapid and accurate building damage assessments from high-resolution satellite imagery following a natural disaster is essential to inform and optimize first responder efforts. However, performing such building damage assessments in an automated manner is non-trivial due to the challenges posed by variations in disaster-specific damage, diversity in satellite imagery, and the dearth of extensive, labeled datasets. To circumvent these issues, this paper introduces a human-in-the-loop workflow for rapidly training building damage assessment models after a natural disaster. This article details a case study using this workflow, executed in partnership with the American Red Cross during a tornado event in Rolling Fork, Mississippi in March, 2023. The output from our human-in-the-loop modeling process achieved a precision of 0.86 and recall of 0.80 for damaged buildings when compared to ground truth data collected post-disaster. This workflow was implemented end-to-end in under 2 hours per satellite imagery scene, highlighting its potential for real-time deployment.","sentences":["Rapid and accurate building damage assessments from high-resolution satellite imagery following a natural disaster is essential to inform and optimize first responder efforts.","However, performing such building damage assessments in an automated manner is non-trivial due to the challenges posed by variations in disaster-specific damage, diversity in satellite imagery, and the dearth of extensive, labeled datasets.","To circumvent these issues, this paper introduces a human-in-the-loop workflow for rapidly training building damage assessment models after a natural disaster.","This article details a case study using this workflow, executed in partnership with the American Red Cross during a tornado event in Rolling Fork, Mississippi in March, 2023.","The output from our human-in-the-loop modeling process achieved a precision of 0.86 and recall of 0.80 for damaged buildings when compared to ground truth data collected post-disaster.","This workflow was implemented end-to-end in under 2 hours per satellite imagery scene, highlighting its potential for real-time deployment."],"url":"http://arxiv.org/abs/2306.12589v1"}
{"created":"2023-06-21","title":"Adversarial Training with Generated Data in High-Dimensional Regression: An Asymptotic Study","abstract":"In recent years, studies such as \\cite{carmon2019unlabeled,gowal2021improving,xing2022artificial} have demonstrated that incorporating additional real or generated data with pseudo-labels can enhance adversarial training through a two-stage training approach. In this paper, we perform a theoretical analysis of the asymptotic behavior of this method in high-dimensional linear regression. While a double-descent phenomenon can be observed in ridgeless training, with an appropriate $\\mathcal{L}_2$ regularization, the two-stage adversarial training achieves a better performance. Finally, we derive a shortcut cross-validation formula specifically tailored for the two-stage training method.","sentences":["In recent years, studies such as \\cite{carmon2019unlabeled,gowal2021improving,xing2022artificial} have demonstrated that incorporating additional real or generated data with pseudo-labels can enhance adversarial training through a two-stage training approach.","In this paper, we perform a theoretical analysis of the asymptotic behavior of this method in high-dimensional linear regression.","While a double-descent phenomenon can be observed in ridgeless training, with an appropriate $\\mathcal{L}_2$ regularization, the two-stage adversarial training achieves a better performance.","Finally, we derive a shortcut cross-validation formula specifically tailored for the two-stage training method."],"url":"http://arxiv.org/abs/2306.12582v1"}
{"created":"2023-06-21","title":"Multi-Task Consistency for Active Learning","abstract":"Learning-based solutions for vision tasks require a large amount of labeled training data to ensure their performance and reliability. In single-task vision-based settings, inconsistency-based active learning has proven to be effective in selecting informative samples for annotation. However, there is a lack of research exploiting the inconsistency between multiple tasks in multi-task networks. To address this gap, we propose a novel multi-task active learning strategy for two coupled vision tasks: object detection and semantic segmentation. Our approach leverages the inconsistency between them to identify informative samples across both tasks. We propose three constraints that specify how the tasks are coupled and introduce a method for determining the pixels belonging to the object detected by a bounding box, to later quantify the constraints as inconsistency scores. To evaluate the effectiveness of our approach, we establish multiple baselines for multi-task active learning and introduce a new metric, mean Detection Segmentation Quality (mDSQ), tailored for the multi-task active learning comparison that addresses the performance of both tasks. We conduct extensive experiments on the nuImages and A9 datasets, demonstrating that our approach outperforms existing state-of-the-art methods by up to 3.4% mDSQ on nuImages. Our approach achieves 95% of the fully-trained performance using only 67% of the available data, corresponding to 20% fewer labels compared to random selection and 5% fewer labels compared to state-of-the-art selection strategy. Our code will be made publicly available after the review process.","sentences":["Learning-based solutions for vision tasks require a large amount of labeled training data to ensure their performance and reliability.","In single-task vision-based settings, inconsistency-based active learning has proven to be effective in selecting informative samples for annotation.","However, there is a lack of research exploiting the inconsistency between multiple tasks in multi-task networks.","To address this gap, we propose a novel multi-task active learning strategy for two coupled vision tasks: object detection and semantic segmentation.","Our approach leverages the inconsistency between them to identify informative samples across both tasks.","We propose three constraints that specify how the tasks are coupled and introduce a method for determining the pixels belonging to the object detected by a bounding box, to later quantify the constraints as inconsistency scores.","To evaluate the effectiveness of our approach, we establish multiple baselines for multi-task active learning and introduce a new metric, mean Detection Segmentation Quality (mDSQ), tailored for the multi-task active learning comparison that addresses the performance of both tasks.","We conduct extensive experiments on the nuImages and A9 datasets, demonstrating that our approach outperforms existing state-of-the-art methods by up to 3.4% mDSQ on nuImages.","Our approach achieves 95% of the fully-trained performance using only 67% of the available data, corresponding to 20% fewer labels compared to random selection and 5% fewer labels compared to state-of-the-art selection strategy.","Our code will be made publicly available after the review process."],"url":"http://arxiv.org/abs/2306.12398v1"}
{"created":"2023-06-21","title":"Geometric Algorithms for $k$-NN Poisoning","abstract":"We propose a label poisoning attack on geometric data sets against $k$-nearest neighbor classification. We provide an algorithm that can compute an $\\varepsilon n$-additive approximation of the optimal poisoning in $n\\cdot 2^{2^{O(d+k/\\varepsilon)}}$ time for a given data set $X \\in \\mathbb{R}^d$, where $|X| = n$. Our algorithm achieves its objectives through the application of multi-scale random partitions.","sentences":["We propose a label poisoning attack on geometric data sets against $k$-nearest neighbor classification.","We provide an algorithm that can compute an $\\varepsilon n$-additive approximation of the optimal poisoning in $n\\cdot 2^{2^{O(d+k/\\varepsilon)}}$ time for a given data set $X \\in \\mathbb{R}^d$, where $|X| = n$. Our algorithm achieves its objectives through the application of multi-scale random partitions."],"url":"http://arxiv.org/abs/2306.12377v1"}
{"created":"2023-06-21","title":"M-VAAL: Multimodal Variational Adversarial Active Learning for Downstream Medical Image Analysis Tasks","abstract":"Acquiring properly annotated data is expensive in the medical field as it requires experts, time-consuming protocols, and rigorous validation. Active learning attempts to minimize the need for large annotated samples by actively sampling the most informative examples for annotation. These examples contribute significantly to improving the performance of supervised machine learning models, and thus, active learning can play an essential role in selecting the most appropriate information in deep learning-based diagnosis, clinical assessments, and treatment planning. Although some existing works have proposed methods for sampling the best examples for annotation in medical image analysis, they are not task-agnostic and do not use multimodal auxiliary information in the sampler, which has the potential to increase robustness. Therefore, in this work, we propose a Multimodal Variational Adversarial Active Learning (M-VAAL) method that uses auxiliary information from additional modalities to enhance the active sampling. We applied our method to two datasets: i) brain tumor segmentation and multi-label classification using the BraTS2018 dataset, and ii) chest X-ray image classification using the COVID-QU-Ex dataset. Our results show a promising direction toward data-efficient learning under limited annotations.","sentences":["Acquiring properly annotated data is expensive in the medical field as it requires experts, time-consuming protocols, and rigorous validation.","Active learning attempts to minimize the need for large annotated samples by actively sampling the most informative examples for annotation.","These examples contribute significantly to improving the performance of supervised machine learning models, and thus, active learning can play an essential role in selecting the most appropriate information in deep learning-based diagnosis, clinical assessments, and treatment planning.","Although some existing works have proposed methods for sampling the best examples for annotation in medical image analysis, they are not task-agnostic and do not use multimodal auxiliary information in the sampler, which has the potential to increase robustness.","Therefore, in this work, we propose a Multimodal Variational Adversarial Active Learning (M-VAAL) method that uses auxiliary information from additional modalities to enhance the active sampling.","We applied our method to two datasets: i) brain tumor segmentation and multi-label classification using the BraTS2018 dataset, and ii) chest X-ray image classification using the COVID-QU-Ex dataset.","Our results show a promising direction toward data-efficient learning under limited annotations."],"url":"http://arxiv.org/abs/2306.12376v1"}
{"created":"2023-06-21","title":"Predicting protein variants with equivariant graph neural networks","abstract":"Pre-trained models have been successful in many protein engineering tasks. Most notably, sequence-based models have achieved state-of-the-art performance on protein fitness prediction while structure-based models have been used experimentally to develop proteins with enhanced functions. However, there is a research gap in comparing structure- and sequence-based methods for predicting protein variants that are better than the wildtype protein. This paper aims to address this gap by conducting a comparative study between the abilities of equivariant graph neural networks (EGNNs) and sequence-based approaches to identify promising amino-acid mutations. The results show that our proposed structural approach achieves a competitive performance to sequence-based methods while being trained on significantly fewer molecules. Additionally, we find that combining assay labelled data with structure pre-trained models yields similar trends as with sequence pre-trained models.","sentences":["Pre-trained models have been successful in many protein engineering tasks.","Most notably, sequence-based models have achieved state-of-the-art performance on protein fitness prediction while structure-based models have been used experimentally to develop proteins with enhanced functions.","However, there is a research gap in comparing structure- and sequence-based methods for predicting protein variants that are better than the wildtype protein.","This paper aims to address this gap by conducting a comparative study between the abilities of equivariant graph neural networks (EGNNs) and sequence-based approaches to identify promising amino-acid mutations.","The results show that our proposed structural approach achieves a competitive performance to sequence-based methods while being trained on significantly fewer molecules.","Additionally, we find that combining assay labelled data with structure pre-trained models yields similar trends as with sequence pre-trained models."],"url":"http://arxiv.org/abs/2306.12231v1"}
{"created":"2023-06-21","title":"Lightweight learning from label proportions on satellite imagery","abstract":"This work addresses the challenge of producing chip level predictions on satellite imagery when only label proportions at a coarser spatial geometry are available, typically from statistical or aggregated data from administrative divisions (such as municipalities or communes). This kind of tabular data is usually widely available in many regions of the world and application areas and, thus, its exploitation may contribute to leverage the endemic scarcity of fine grained labelled data in Earth Observation (EO). This can be framed as a Learning from Label Proportions (LLP) problem setup. LLP applied to EO data is still an emerging field and performing comparative studies in applied scenarios remains a challenge due to the lack of standardized datasets. In this work, first, we show how simple deep learning and probabilistic methods generally perform better than standard more complex ones, providing a surprising level of finer grained spatial detail when trained with much coarser label proportions. Second, we provide a set of benchmarking datasets enabling comparative LLP applied to EO, providing both fine grained labels and aggregated data according to existing administrative divisions. Finally, we argue how this approach might be valuable when considering on-orbit inference and training. Source code is available at https://github.com/rramosp/llpeo","sentences":["This work addresses the challenge of producing chip level predictions on satellite imagery when only label proportions at a coarser spatial geometry are available, typically from statistical or aggregated data from administrative divisions (such as municipalities or communes).","This kind of tabular data is usually widely available in many regions of the world and application areas and, thus, its exploitation may contribute to leverage the endemic scarcity of fine grained labelled data in Earth Observation (EO).","This can be framed as a Learning from Label Proportions (LLP) problem setup.","LLP applied to EO data is still an emerging field and performing comparative studies in applied scenarios remains a challenge due to the lack of standardized datasets.","In this work, first, we show how simple deep learning and probabilistic methods generally perform better than standard more complex ones, providing a surprising level of finer grained spatial detail when trained with much coarser label proportions.","Second, we provide a set of benchmarking datasets enabling comparative LLP applied to EO, providing both fine grained labels and aggregated data according to existing administrative divisions.","Finally, we argue how this approach might be valuable when considering on-orbit inference and training.","Source code is available at https://github.com/rramosp/llpeo"],"url":"http://arxiv.org/abs/2306.12461v1"}
{"created":"2023-06-21","title":"Quantifying lottery tickets under label noise: accuracy, calibration, and complexity","abstract":"Pruning deep neural networks is a widely used strategy to alleviate the computational burden in machine learning. Overwhelming empirical evidence suggests that pruned models retain very high accuracy even with a tiny fraction of parameters. However, relatively little work has gone into characterising the small pruned networks obtained, beyond a measure of their accuracy. In this paper, we use the sparse double descent approach to identify univocally and characterise pruned models associated with classification tasks. We observe empirically that, for a given task, iterative magnitude pruning (IMP) tends to converge to networks of comparable sizes even when starting from full networks with sizes ranging over orders of magnitude. We analyse the best pruned models in a controlled experimental setup and show that their number of parameters reflects task difficulty and that they are much better than full networks at capturing the true conditional probability distribution of the labels. On real data, we similarly observe that pruned models are less prone to overconfident predictions. Our results suggest that pruned models obtained via IMP not only have advantageous computational properties but also provide a better representation of uncertainty in learning.","sentences":["Pruning deep neural networks is a widely used strategy to alleviate the computational burden in machine learning.","Overwhelming empirical evidence suggests that pruned models retain very high accuracy even with a tiny fraction of parameters.","However, relatively little work has gone into characterising the small pruned networks obtained, beyond a measure of their accuracy.","In this paper, we use the sparse double descent approach to identify univocally and characterise pruned models associated with classification tasks.","We observe empirically that, for a given task, iterative magnitude pruning (IMP) tends to converge to networks of comparable sizes even when starting from full networks with sizes ranging over orders of magnitude.","We analyse the best pruned models in a controlled experimental setup and show that their number of parameters reflects task difficulty and that they are much better than full networks at capturing the true conditional probability distribution of the labels.","On real data, we similarly observe that pruned models are less prone to overconfident predictions.","Our results suggest that pruned models obtained via IMP not only have advantageous computational properties but also provide a better representation of uncertainty in learning."],"url":"http://arxiv.org/abs/2306.12190v1"}
{"created":"2023-06-21","title":"End-to-End Augmentation Hyperparameter Tuning for Self-Supervised Anomaly Detection","abstract":"Self-supervised learning (SSL) has emerged as a promising paradigm that presents self-generated supervisory signals to real-world problems, bypassing the extensive manual labeling burden. SSL is especially attractive for unsupervised tasks such as anomaly detection, where labeled anomalies are often nonexistent and costly to obtain. While self-supervised anomaly detection (SSAD) has seen a recent surge of interest, the literature has failed to treat data augmentation as a hyperparameter. Meanwhile, recent works have reported that the choice of augmentation has significant impact on detection performance. In this paper, we introduce ST-SSAD (Self-Tuning Self-Supervised Anomaly Detection), the first systematic approach to SSAD in regards to rigorously tuning augmentation. To this end, our work presents two key contributions. The first is a new unsupervised validation loss that quantifies the alignment between the augmented training data and the (unlabeled) test data. In principle we adopt transduction, quantifying the extent to which augmentation mimics the true anomaly-generating mechanism, in contrast to augmenting data with arbitrary pseudo anomalies without regard to test data. Second, we present new differentiable augmentation functions, allowing data augmentation hyperparameter(s) to be tuned end-to-end via our proposed validation loss. Experiments on two testbeds with semantic class anomalies and subtle industrial defects show that systematically tuning augmentation offers significant performance gains over current practices.","sentences":["Self-supervised learning (SSL) has emerged as a promising paradigm that presents self-generated supervisory signals to real-world problems, bypassing the extensive manual labeling burden.","SSL is especially attractive for unsupervised tasks such as anomaly detection, where labeled anomalies are often nonexistent and costly to obtain.","While self-supervised anomaly detection (SSAD) has seen a recent surge of interest, the literature has failed to treat data augmentation as a hyperparameter.","Meanwhile, recent works have reported that the choice of augmentation has significant impact on detection performance.","In this paper, we introduce ST-SSAD (Self-Tuning Self-Supervised Anomaly Detection), the first systematic approach to SSAD in regards to rigorously tuning augmentation.","To this end, our work presents two key contributions.","The first is a new unsupervised validation loss that quantifies the alignment between the augmented training data and the (unlabeled) test data.","In principle we adopt transduction, quantifying the extent to which augmentation mimics the true anomaly-generating mechanism, in contrast to augmenting data with arbitrary pseudo anomalies without regard to test data.","Second, we present new differentiable augmentation functions, allowing data augmentation hyperparameter(s) to be tuned end-to-end via our proposed validation loss.","Experiments on two testbeds with semantic class anomalies and subtle industrial defects show that systematically tuning augmentation offers significant performance gains over current practices."],"url":"http://arxiv.org/abs/2306.12033v1"}
{"created":"2023-06-21","title":"Towards Mitigating Spurious Correlations in the Wild: A Benchmark & a more Realistic Dataset","abstract":"Deep neural networks often exploit non-predictive features that are spuriously correlated with class labels, leading to poor performance on groups of examples without such features. Despite the growing body of recent works on remedying spurious correlations, the lack of a standardized benchmark hinders reproducible evaluation and comparison of the proposed solutions. To address this, we present SpuCo, a python package with modular implementations of state-of-the-art solutions enabling easy and reproducible evaluation of current methods. Using SpuCo, we demonstrate the limitations of existing datasets and evaluation schemes in validating the learning of predictive features over spurious ones. To overcome these limitations, we propose two new vision datasets: (1) SpuCoMNIST, a synthetic dataset that enables simulating the effect of real world data properties e.g. difficulty of learning spurious feature, as well as noise in the labels and features; (2) SpuCoAnimals, a large-scale dataset curated from ImageNet that captures spurious correlations in the wild much more closely than existing datasets. These contributions highlight the shortcomings of current methods and provide a direction for future research in tackling spurious correlations. SpuCo, containing the benchmark and datasets, can be found at https://github.com/BigML-CS-UCLA/SpuCo, with detailed documentation available at https://spuco.readthedocs.io/en/latest/.","sentences":["Deep neural networks often exploit non-predictive features that are spuriously correlated with class labels, leading to poor performance on groups of examples without such features.","Despite the growing body of recent works on remedying spurious correlations, the lack of a standardized benchmark hinders reproducible evaluation and comparison of the proposed solutions.","To address this, we present SpuCo, a python package with modular implementations of state-of-the-art solutions enabling easy and reproducible evaluation of current methods.","Using SpuCo, we demonstrate the limitations of existing datasets and evaluation schemes in validating the learning of predictive features over spurious ones.","To overcome these limitations, we propose two new vision datasets: (1) SpuCoMNIST, a synthetic dataset that enables simulating the effect of real world data properties e.g. difficulty of learning spurious feature, as well as noise in the labels and features; (2) SpuCoAnimals, a large-scale dataset curated from ImageNet that captures spurious correlations in the wild much more closely than existing datasets.","These contributions highlight the shortcomings of current methods and provide a direction for future research in tackling spurious correlations.","SpuCo, containing the benchmark and datasets, can be found at https://github.com/BigML-CS-UCLA/SpuCo, with detailed documentation available at https://spuco.readthedocs.io/en/latest/."],"url":"http://arxiv.org/abs/2306.11957v1"}
{"created":"2023-06-20","title":"A Parameterized Algorithm for Flat Folding","abstract":"We prove that testing the flat foldability of an origami crease pattern (either labeled with mountain and valley folds, or unlabeled) is fixed-parameter tractable when parameterized by the ply of the flat-folded state and by the treewidth of an associated planar graph, the cell adjacency graph of an arrangement of polygons formed by the flat-folded state. For flat foldings of bounded ply, our algorithm is single-exponential in the treewidth; this dependence on treewidth is necessary under the exponential time hypothesis.","sentences":["We prove that testing the flat foldability of an origami crease pattern (either labeled with mountain and valley folds, or unlabeled) is fixed-parameter tractable when parameterized by the ply of the flat-folded state and by the treewidth of an associated planar graph, the cell adjacency graph of an arrangement of polygons formed by the flat-folded state.","For flat foldings of bounded ply, our algorithm is single-exponential in the treewidth; this dependence on treewidth is necessary under the exponential time hypothesis."],"url":"http://arxiv.org/abs/2306.11939v1"}
{"created":"2023-06-20","title":"A Model-free Closeness-of-influence Test for Features in Supervised Learning","abstract":"Understanding the effect of a feature vector $x \\in \\mathbb{R}^d$ on the response value (label) $y \\in \\mathbb{R}$ is the cornerstone of many statistical learning problems. Ideally, it is desired to understand how a set of collected features combine together and influence the response value, but this problem is notoriously difficult, due to the high-dimensionality of data and limited number of labeled data points, among many others. In this work, we take a new perspective on this problem, and we study the question of assessing the difference of influence that the two given features have on the response value. We first propose a notion of closeness for the influence of features, and show that our definition recovers the familiar notion of the magnitude of coefficients in the parametric model. We then propose a novel method to test for the closeness of influence in general model-free supervised learning problems. Our proposed test can be used with finite number of samples with control on type I error rate, no matter the ground truth conditional law $\\mathcal{L}(Y |X)$. We analyze the power of our test for two general learning problems i) linear regression, and ii) binary classification under mixture of Gaussian models, and show that under the proper choice of score function, an internal component of our test, with sufficient number of samples will achieve full statistical power. We evaluate our findings through extensive numerical simulations, specifically we adopt the datamodel framework (Ilyas, et al., 2022) for CIFAR-10 dataset to identify pairs of training samples with different influence on the trained model via optional black box training mechanisms.","sentences":["Understanding the effect of a feature vector $x \\in \\mathbb{R}^d$ on the response value (label) $y \\in \\mathbb{R}$ is the cornerstone of many statistical learning problems.","Ideally, it is desired to understand how a set of collected features combine together and influence the response value, but this problem is notoriously difficult, due to the high-dimensionality of data and limited number of labeled data points, among many others.","In this work, we take a new perspective on this problem, and we study the question of assessing the difference of influence that the two given features have on the response value.","We first propose a notion of closeness for the influence of features, and show that our definition recovers the familiar notion of the magnitude of coefficients in the parametric model.","We then propose a novel method to test for the closeness of influence in general model-free supervised learning problems.","Our proposed test can be used with finite number of samples with control on type I error rate, no matter the ground truth conditional law $\\mathcal{L}(Y |X)$. We analyze the power of our test for two general learning problems i) linear regression, and ii) binary classification under mixture of Gaussian models, and show that under the proper choice of score function, an internal component of our test, with sufficient number of samples will achieve full statistical power.","We evaluate our findings through extensive numerical simulations, specifically we adopt the datamodel framework (Ilyas, et al., 2022) for CIFAR-10 dataset to identify pairs of training samples with different influence on the trained model via optional black box training mechanisms."],"url":"http://arxiv.org/abs/2306.11855v1"}
{"created":"2023-06-20","title":"Brain Anatomy Prior Modeling to Forecast Clinical Progression of Cognitive Impairment with Structural MRI","abstract":"Brain structural MRI has been widely used to assess the future progression of cognitive impairment (CI). Previous learning-based studies usually suffer from the issue of small-sized labeled training data, while there exist a huge amount of structural MRIs in large-scale public databases. Intuitively, brain anatomical structures derived from these public MRIs (even without task-specific label information) can be used to boost CI progression trajectory prediction. However, previous studies seldom take advantage of such brain anatomy prior. To this end, this paper proposes a brain anatomy prior modeling (BAPM) framework to forecast the clinical progression of cognitive impairment with small-sized target MRIs by exploring anatomical brain structures. Specifically, the BAPM consists of a pretext model and a downstream model, with a shared brain anatomy-guided encoder to model brain anatomy prior explicitly. Besides the encoder, the pretext model also contains two decoders for two auxiliary tasks (i.e., MRI reconstruction and brain tissue segmentation), while the downstream model relies on a predictor for classification. The brain anatomy-guided encoder is pre-trained with the pretext model on 9,344 auxiliary MRIs without diagnostic labels for anatomy prior modeling. With this encoder frozen, the downstream model is then fine-tuned on limited target MRIs for prediction. We validate the BAPM on two CI-related studies with T1-weighted MRIs from 448 subjects. Experimental results suggest the effectiveness of BAPM in (1) four CI progression prediction tasks, (2) MR image reconstruction, and (3) brain tissue segmentation, compared with several state-of-the-art methods.","sentences":["Brain structural MRI has been widely used to assess the future progression of cognitive impairment (CI).","Previous learning-based studies usually suffer from the issue of small-sized labeled training data, while there exist a huge amount of structural MRIs in large-scale public databases.","Intuitively, brain anatomical structures derived from these public MRIs (even without task-specific label information) can be used to boost CI progression trajectory prediction.","However, previous studies seldom take advantage of such brain anatomy prior.","To this end, this paper proposes a brain anatomy prior modeling (BAPM) framework to forecast the clinical progression of cognitive impairment with small-sized target MRIs by exploring anatomical brain structures.","Specifically, the BAPM consists of a pretext model and a downstream model, with a shared brain anatomy-guided encoder to model brain anatomy prior explicitly.","Besides the encoder, the pretext model also contains two decoders for two auxiliary tasks (i.e., MRI reconstruction and brain tissue segmentation), while the downstream model relies on a predictor for classification.","The brain anatomy-guided encoder is pre-trained with the pretext model on 9,344 auxiliary MRIs without diagnostic labels for anatomy prior modeling.","With this encoder frozen, the downstream model is then fine-tuned on limited target MRIs for prediction.","We validate the BAPM on two CI-related studies with T1-weighted MRIs from 448 subjects.","Experimental results suggest the effectiveness of BAPM in (1) four CI progression prediction tasks, (2) MR image reconstruction, and (3) brain tissue segmentation, compared with several state-of-the-art methods."],"url":"http://arxiv.org/abs/2306.11837v1"}
{"created":"2023-06-23","title":"Quasiparticle spectroscopy in technologically-relevant niobium using London penetration depth measurements","abstract":"London penetration depth was measured in niobium foils, thin films, single crystals, and superconducting radio-frequency (SRF) cavity pieces cut out from different places. The low-temperature (T<Tc/3) variation, sensitive to the low-energy quasiparticles with states inside the superconducting gap, differs dramatically between different types of samples. With the help of phenomenological modeling, we correlate these different behaviors with known pair-breaking mechanisms and show that such measurements may help distinguish between different pair-breaking mechanisms, such as niobium hydrides and two-level systems (TLS). The conclusions also apply to SRF cavities when tracking the temperature-dependent quality factor and the resonant frequency.","sentences":["London penetration depth was measured in niobium foils, thin films, single crystals, and superconducting radio-frequency (SRF) cavity pieces cut out from different places.","The low-temperature (T<Tc/3) variation, sensitive to the low-energy quasiparticles with states inside the superconducting gap, differs dramatically between different types of samples.","With the help of phenomenological modeling, we correlate these different behaviors with known pair-breaking mechanisms and show that such measurements may help distinguish between different pair-breaking mechanisms, such as niobium hydrides and two-level systems (TLS).","The conclusions also apply to SRF cavities when tracking the temperature-dependent quality factor and the resonant frequency."],"url":"http://arxiv.org/abs/2306.13654v1"}
{"created":"2023-06-23","title":"ProRes: Exploring Degradation-aware Visual Prompt for Universal Image Restoration","abstract":"Image restoration aims to reconstruct degraded images, e.g., denoising or deblurring. Existing works focus on designing task-specific methods and there are inadequate attempts at universal methods. However, simply unifying multiple tasks into one universal architecture suffers from uncontrollable and undesired predictions. To address those issues, we explore prompt learning in universal architectures for image restoration tasks. In this paper, we present Degradation-aware Visual Prompts, which encode various types of image degradation, e.g., noise and blur, into unified visual prompts. These degradation-aware prompts provide control over image processing and allow weighted combinations for customized image restoration. We then leverage degradation-aware visual prompts to establish a controllable and universal model for image restoration, called ProRes, which is applicable to an extensive range of image restoration tasks. ProRes leverages the vanilla Vision Transformer (ViT) without any task-specific designs. Furthermore, the pre-trained ProRes can easily adapt to new tasks through efficient prompt tuning with only a few images. Without bells and whistles, ProRes achieves competitive performance compared to task-specific methods and experiments can demonstrate its ability for controllable restoration and adaptation for new tasks. The code and models will be released in \\url{https://github.com/leonmakise/ProRes}.","sentences":["Image restoration aims to reconstruct degraded images, e.g., denoising or deblurring.","Existing works focus on designing task-specific methods and there are inadequate attempts at universal methods.","However, simply unifying multiple tasks into one universal architecture suffers from uncontrollable and undesired predictions.","To address those issues, we explore prompt learning in universal architectures for image restoration tasks.","In this paper, we present Degradation-aware Visual Prompts, which encode various types of image degradation, e.g., noise and blur, into unified visual prompts.","These degradation-aware prompts provide control over image processing and allow weighted combinations for customized image restoration.","We then leverage degradation-aware visual prompts to establish a controllable and universal model for image restoration, called ProRes, which is applicable to an extensive range of image restoration tasks.","ProRes leverages the vanilla Vision Transformer (ViT) without any task-specific designs.","Furthermore, the pre-trained ProRes can easily adapt to new tasks through efficient prompt tuning with only a few images.","Without bells and whistles, ProRes achieves competitive performance compared to task-specific methods and experiments can demonstrate its ability for controllable restoration and adaptation for new tasks.","The code and models will be released in \\url{https://github.com/leonmakise/ProRes}."],"url":"http://arxiv.org/abs/2306.13653v1"}
{"created":"2023-06-23","title":"Classical time crystal Ginzburg-Landau study of coupled parametric oscillators","abstract":"Discrete time crystals, which are phases of matter that break the discrete time translational symmetry of a periodically driven system, have generated a wave of recent interest and activity. In this work, we propose a classical system of weakly nonlinear parametrically driven coupled oscillators as a testbed to understand these phases. Such a system of oscillators in the presence of dissipation has a period-doubling instability only at long wavelengths where a large number of oscillators are in phase. To show that this instability leads to a discrete time crystal when exposed to noise and non-linearity, we derive a general condition to predict when a Markov process will break time-translation symmetry. The first requirement of this condition is that the Markov chain over doubled time steps has a stationary probability distribution that spontaneously breaks a local symmetry. The second requirement is that the order parameter flips sign over a single time step. We show that our system of oscillators features period-doubling and yields a stationary probability distribution given by a spatially continuous Ginzburg-Landau Hamiltonian with spontaneous symmetry breaking. We then discuss applications of the general condition to existing time crystal platforms.","sentences":["Discrete time crystals, which are phases of matter that break the discrete time translational symmetry of a periodically driven system, have generated a wave of recent interest and activity.","In this work, we propose a classical system of weakly nonlinear parametrically driven coupled oscillators as a testbed to understand these phases.","Such a system of oscillators in the presence of dissipation has a period-doubling instability only at long wavelengths where a large number of oscillators are in phase.","To show that this instability leads to a discrete time crystal when exposed to noise and non-linearity, we derive a general condition to predict when a Markov process will break time-translation symmetry.","The first requirement of this condition is that the Markov chain over doubled time steps has a stationary probability distribution that spontaneously breaks a local symmetry.","The second requirement is that the order parameter flips sign over a single time step.","We show that our system of oscillators features period-doubling and yields a stationary probability distribution given by a spatially continuous Ginzburg-Landau Hamiltonian with spontaneous symmetry breaking.","We then discuss applications of the general condition to existing time crystal platforms."],"url":"http://arxiv.org/abs/2306.13652v1"}
{"created":"2023-06-23","title":"Bring Your Own Data! Self-Supervised Evaluation for Large Language Models","abstract":"With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative. For example, a company deploying a client-facing chatbot must ensure that the model will not respond to client requests with profanity. Current evaluations approach this problem using small, domain-specific datasets with human-curated labels. These evaluation sets are often sampled from a narrow and simplified distribution, and data sources can unknowingly be leaked into the training set which can lead to misleading evaluations. To bypass these drawbacks, we propose a framework for self-supervised evaluation of LLMs by analyzing their sensitivity or invariance to transformations on the input text. Self-supervised evaluation can directly monitor LLM behavior on datasets collected in the wild or streamed during live model deployment. We demonstrate self-supervised evaluation strategies for measuring closed-book knowledge, toxicity, and long-range context dependence, in addition to sensitivity to grammatical structure and tokenization errors. When comparisons to similar human-labeled benchmarks are available, we find strong correlations between self-supervised and human-supervised evaluations. The self-supervised paradigm complements current evaluation strategies that rely on labeled data.","sentences":["With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative.","For example, a company deploying a client-facing chatbot must ensure that the model will not respond to client requests with profanity.","Current evaluations approach this problem using small, domain-specific datasets with human-curated labels.","These evaluation sets are often sampled from a narrow and simplified distribution, and data sources can unknowingly be leaked into the training set which can lead to misleading evaluations.","To bypass these drawbacks, we propose a framework for self-supervised evaluation of LLMs by analyzing their sensitivity or invariance to transformations on the input text.","Self-supervised evaluation can directly monitor LLM behavior on datasets collected in the wild or streamed during live model deployment.","We demonstrate self-supervised evaluation strategies for measuring closed-book knowledge, toxicity, and long-range context dependence, in addition to sensitivity to grammatical structure and tokenization errors.","When comparisons to similar human-labeled benchmarks are available, we find strong correlations between self-supervised and human-supervised evaluations.","The self-supervised paradigm complements current evaluation strategies that rely on labeled data."],"url":"http://arxiv.org/abs/2306.13651v1"}
{"created":"2023-06-23","title":"Schwarzschild deformed supergravity background: possible geometry origin of fermion generations and mass hierarchy","abstract":"The problem of fermion masses hierarchy in the Standard Model is considered on a toy model of a 10-dimensional space-time with a IIA supergravity type background. Dirac equation on this background, after compactification of extra 4- and 1-dimensional subspaces, gives the spectrum of Fermi fields which profiles in 5 dimensions and corresponding Higgs generated masses in 4 dimensions depend on the eigenvalues of Dirac operator on the named compact subspaces. Schwarzschild Euclidean deformation of the supergravity throat with the \"apple-shaped\" conical singularity permits to leave only three non-divergent angular modes interpreted as three generations of the down-type quarks. Calculated ratios of their masses are close to the experimentally observed values for a natural choice of parameters of 10-dimensional geometry. Equations for non-chiral modes coincide with the non-relativistic Schr\\\"odinger equation for an electron moving in a Coulomb field; the corresponding small fermion masses generated by the twisted boundary conditions are expressed through the degenerate hypergeometric functions.","sentences":["The problem of fermion masses hierarchy in the Standard Model is considered on a toy model of a 10-dimensional space-time with a IIA supergravity type background.","Dirac equation on this background, after compactification of extra 4- and 1-dimensional subspaces, gives the spectrum of Fermi fields which profiles in 5 dimensions and corresponding Higgs generated masses in 4 dimensions depend on the eigenvalues of Dirac operator on the named compact subspaces.","Schwarzschild Euclidean deformation of the supergravity throat with the \"apple-shaped\" conical singularity permits to leave only three non-divergent angular modes interpreted as three generations of the down-type quarks.","Calculated ratios of their masses are close to the experimentally observed values for a natural choice of parameters of 10-dimensional geometry.","Equations for non-chiral modes coincide with the non-relativistic Schr\\\"odinger equation for an electron moving in a Coulomb field; the corresponding small fermion masses generated by the twisted boundary conditions are expressed through the degenerate hypergeometric functions."],"url":"http://arxiv.org/abs/2306.13650v1"}
{"created":"2023-06-23","title":"GKD: Generalized Knowledge Distillation for Auto-regressive Sequence Models","abstract":"Knowledge distillation is commonly used for compressing neural networks to reduce their inference cost and memory footprint. However, current distillation methods for auto-regressive models, such as generative language models (LMs), suffer from two key issues: (1) distribution mismatch between output sequences during training and the sequences generated by the student during its deployment, and (2) model under-specification, where the student model may not be expressive enough to fit the teacher's distribution. To address these issues, we propose Generalized Knowledge Distillation (GKD). GKD mitigates distribution mismatch by sampling output sequences from the student during training. Furthermore, GKD handles model under-specification by optimizing alternative divergences, such as reverse KL, that focus on generating samples from the student that are likely under the teacher's distribution. We demonstrate that GKD outperforms commonly-used approaches for distilling LLMs on summarization, machine translation, and arithmetic reasoning tasks.","sentences":["Knowledge distillation is commonly used for compressing neural networks to reduce their inference cost and memory footprint.","However, current distillation methods for auto-regressive models, such as generative language models (LMs), suffer from two key issues: (1) distribution mismatch between output sequences during training and the sequences generated by the student during its deployment, and (2) model under-specification, where the student model may not be expressive enough to fit the teacher's distribution.","To address these issues, we propose Generalized Knowledge Distillation (GKD).","GKD mitigates distribution mismatch by sampling output sequences from the student during training.","Furthermore, GKD handles model under-specification by optimizing alternative divergences, such as reverse KL, that focus on generating samples from the student that are likely under the teacher's distribution.","We demonstrate that GKD outperforms commonly-used approaches for distilling LLMs on summarization, machine translation, and arithmetic reasoning tasks."],"url":"http://arxiv.org/abs/2306.13649v1"}
{"created":"2023-06-23","title":"Spatially resolved dielectric loss at the Si/SiO$_2$ interface","abstract":"The Si/SiO$_2$ interface is populated by isolated trap states which modify its electronic properties. These traps are of critical interest for the development of semiconductor-based quantum sensors and computers, as well as nanoelectronic devices. Here, we study the electric susceptibility of the Si/SiO$_2$ interface with nm spatial resolution using frequency-modulated atomic force microscopy to measure a patterned dopant delta-layer buried 2 nm beneath the silicon native oxide interface. We show that surface charge organization timescales, which range from 1-150 ns, increase significantly around interfacial states. We conclude that dielectric loss under time-varying gate biases at MHz and sub-MHz frequencies in metal-insulator-semiconductor capacitor device architectures is highly spatially heterogeneous over nm length scales.","sentences":["The Si/SiO$_2$ interface is populated by isolated trap states which modify its electronic properties.","These traps are of critical interest for the development of semiconductor-based quantum sensors and computers, as well as nanoelectronic devices.","Here, we study the electric susceptibility of the Si/SiO$_2$ interface with nm spatial resolution using frequency-modulated atomic force microscopy to measure a patterned dopant delta-layer buried 2 nm beneath the silicon native oxide interface.","We show that surface charge organization timescales, which range from 1-150 ns, increase significantly around interfacial states.","We conclude that dielectric loss under time-varying gate biases at MHz and sub-MHz frequencies in metal-insulator-semiconductor capacitor device architectures is highly spatially heterogeneous over nm length scales."],"url":"http://arxiv.org/abs/2306.13648v1"}
{"created":"2023-06-23","title":"Vorticity and level-set variations of invariant current bound steady-state dissipation","abstract":"A non-vanishing entropy production rate is a hallmark of non-equilibrium stationary states and is therefore at the heart of non-equilibrium thermodynamics. It is a manifestation of a steady circulation $J_{\\rm inv}$ along the level sets of the invariant density $\\rho_{\\rm inv}$, and is thus generically used to quantify how far a steady system is driven out of equilibrium. While it is well known that there exists a continuum of distinct steady states with the same invariant measure, the question how the geometry and topology of the invariant current a priori affect dissipation remained elusive. For confined irreversible diffusions we identify two minimal descriptors, the $\\rho_{\\rm inv}$-weighted vorticity and the variation of $J_{\\rm inv}$ along level sets of $\\rho_{\\rm inv}$, and prove that these jointly bound from above the steady-state entropy production rate. In regions where $\\rho_{\\rm inv}$ is close to Gaussian the bound is dominated solely by the vorticity of the drift field and in the low-noise (Freidlin-Wentzel) limit by any non-potential contribution to the drift, rendering $J_{\\rm inv}$ virtually constant along the level sets of $\\rho_{\\rm inv}$.","sentences":["A non-vanishing entropy production rate is a hallmark of non-equilibrium stationary states and is therefore at the heart of non-equilibrium thermodynamics.","It is a manifestation of a steady circulation $J_{\\rm inv}$ along the level sets of the invariant density $\\rho_{\\rm inv}$, and is thus generically used to quantify how far a steady system is driven out of equilibrium.","While it is well known that there exists a continuum of distinct steady states with the same invariant measure, the question how the geometry and topology of the invariant current a priori affect dissipation remained elusive.","For confined irreversible diffusions we identify two minimal descriptors, the $\\rho_{\\rm inv}$-weighted vorticity and the variation of $J_{\\rm inv}$ along level sets of $\\rho_{\\rm inv}$, and prove that these jointly bound from above the steady-state entropy production rate.","In regions where $\\rho_{\\rm inv}$ is close to Gaussian the bound is dominated solely by the vorticity of the drift field and in the low-noise (Freidlin-Wentzel) limit by any non-potential contribution to the drift, rendering $J_{\\rm inv}$ virtually constant along the level sets of $\\rho_{\\rm inv}$."],"url":"http://arxiv.org/abs/2306.13647v1"}
{"created":"2023-06-23","title":"Perfect single-photon sources","abstract":"We introduce the \"gapped coherent state\" in the form of a single-photon source (SPS) that consists of uncorrelated photons as a background, except that we demand that no two photons can be closer in time than a time gap $t_\\mathrm{G}$. While no obvious quantum mechanism is yet identified to produce exactly such a photon stream, a numerical simulation is easily achieved by first generating an uncorrelated (Poissonian) signal and then for each photon in the list, either adding such a time gap or removing all successive photons that are closer in time from any photon that is kept than $t_\\mathrm{G}$. We study the statistical properties of such a hypothetical signal, which exhibits counter-intuitive features. This provides a neat and natural connection between continuous-wave (stationary) and pulsed single-photon sources, with also a bearing on what it means for such sources to be perfect in terms of single-photon emission.","sentences":["We introduce the \"gapped coherent state\" in the form of a single-photon source (SPS) that consists of uncorrelated photons as a background, except that we demand that no two photons can be closer in time than a time gap $t_\\mathrm{G}$. While no obvious quantum mechanism is yet identified to produce exactly such a photon stream, a numerical simulation is easily achieved by first generating an uncorrelated (Poissonian) signal and then for each photon in the list, either adding such a time gap or removing all successive photons that are closer in time from any photon that is kept than $t_\\mathrm{G}$. We study the statistical properties of such a hypothetical signal, which exhibits counter-intuitive features.","This provides a neat and natural connection between continuous-wave (stationary) and pulsed single-photon sources, with also a bearing on what it means for such sources to be perfect in terms of single-photon emission."],"url":"http://arxiv.org/abs/2306.13646v1"}
{"created":"2023-06-23","title":"Characterising a World Within the Hot Neptune Desert: Transit Observations of LTT 9779 b with HST WFC3","abstract":"We present an atmospheric analysis of LTT 9779 b, a rare planet situated in the hot Neptune desert, that has been observed with HST WFC3 G102 and G141. The combined transmission spectrum, which covers 0.8 - 1.6 $\\mu$m, shows a gradual increase in transit depth with wavelength. Our preferred atmospheric model shows evidence for H$_{\\rm 2}$O, CO$_{\\rm 2}$ and FeH with a significance of 3.1 $\\sigma$, 2.4 $\\sigma$ and 2.1 $\\sigma$, respectively. In an attempt to constrain the rate of atmospheric escape for this planet, we search for the 1.083 $\\mu$m Helium line in the G102 data but find no evidence of excess absorption that would indicate an escaping atmosphere using this tracer. We refine the orbital ephemerides of LTT 9779 b using our HST data and observations from TESS, searching for evidence of orbital decay or apsidal precession, which is not found. The phase-curve observation of LTT 9779 b with JWST NIRISS should provide deeper insights into the atmosphere of this planet and the expected atmospheric escape might be detected with further observations concentrated on other tracers such as Lyman $\\alpha$.","sentences":["We present an atmospheric analysis of LTT 9779 b, a rare planet situated in the hot Neptune desert, that has been observed with HST WFC3 G102 and G141.","The combined transmission spectrum, which covers 0.8 - 1.6 $\\mu$m, shows a gradual increase in transit depth with wavelength.","Our preferred atmospheric model shows evidence for H$_{\\rm 2}$O, CO$_{\\rm 2}$ and FeH with a significance of 3.1 $\\sigma$, 2.4 $\\sigma$ and 2.1 $\\sigma$, respectively.","In an attempt to constrain the rate of atmospheric escape for this planet, we search for the 1.083 $\\mu$m Helium line in the G102 data but find no evidence of excess absorption that would indicate an escaping atmosphere using this tracer.","We refine the orbital ephemerides of LTT 9779 b using our HST data and observations from TESS, searching for evidence of orbital decay or apsidal precession, which is not found.","The phase-curve observation of LTT 9779 b with JWST NIRISS should provide deeper insights into the atmosphere of this planet and the expected atmospheric escape might be detected with further observations concentrated on other tracers such as Lyman $\\alpha$."],"url":"http://arxiv.org/abs/2306.13645v1"}
{"created":"2023-06-23","title":"Thermally-Switchable Metalenses Based on Quasi-Bound States in the Continuum","abstract":"Dynamic wavefront shaping with optical metasurfaces has presented a major challenge and inspired a large number of highly elaborate solutions. Here, we experimentally demonstrate thermo-optically reconfigurable, nonlocal metasurfaces using simple device architectures and conventional CMOS-compatible dielectric materials. These metasurfaces support quasi-bound states in the continuum (q-BICs) derived from symmetry breaking and encoded with a spatially varying geometric phase, such that they shape optical wavefront exclusively on spectrally narrowband resonances. Due to the enhanced light-matter interaction enabled by the resonant q-BICs, a slight variation of the refractive index introduced by heating and cooling the entire device leads to a substantial shift of the resonant wavelength and a subsequent change to the optical wavefront associated with the resonance. We experimentally demonstrate a metalens modulator, the focusing capability of which can be thermally turned on and off, and reconfigurable metalenses, which can be thermo-optically switched to produce two distinct focal patterns. Our devices offer a pathway to realize reconfigurable, multifunctional meta-optics using established manufacturing processes and widely available dielectric materials that are conventionally not considered \"active\" materials due to their small thermo-optic or electro-optic coefficients.","sentences":["Dynamic wavefront shaping with optical metasurfaces has presented a major challenge and inspired a large number of highly elaborate solutions.","Here, we experimentally demonstrate thermo-optically reconfigurable, nonlocal metasurfaces using simple device architectures and conventional CMOS-compatible dielectric materials.","These metasurfaces support quasi-bound states in the continuum (q-BICs) derived from symmetry breaking and encoded with a spatially varying geometric phase, such that they shape optical wavefront exclusively on spectrally narrowband resonances.","Due to the enhanced light-matter interaction enabled by the resonant q-BICs, a slight variation of the refractive index introduced by heating and cooling the entire device leads to a substantial shift of the resonant wavelength and a subsequent change to the optical wavefront associated with the resonance.","We experimentally demonstrate a metalens modulator, the focusing capability of which can be thermally turned on and off, and reconfigurable metalenses, which can be thermo-optically switched to produce two distinct focal patterns.","Our devices offer a pathway to realize reconfigurable, multifunctional meta-optics using established manufacturing processes and widely available dielectric materials that are conventionally not considered \"active\" materials due to their small thermo-optic or electro-optic coefficients."],"url":"http://arxiv.org/abs/2306.13644v1"}
{"created":"2023-06-23","title":"LightGlue: Local Feature Matching at Light Speed","abstract":"We introduce LightGlue, a deep neural network that learns to match local features across images. We revisit multiple design decisions of SuperGlue, the state of the art in sparse matching, and derive simple but effective improvements. Cumulatively, they make LightGlue more efficient - in terms of both memory and computation, more accurate, and much easier to train. One key property is that LightGlue is adaptive to the difficulty of the problem: the inference is much faster on image pairs that are intuitively easy to match, for example because of a larger visual overlap or limited appearance change. This opens up exciting prospects for deploying deep matchers in latency-sensitive applications like 3D reconstruction. The code and trained models are publicly available at https://github.com/cvg/LightGlue.","sentences":["We introduce LightGlue, a deep neural network that learns to match local features across images.","We revisit multiple design decisions of SuperGlue, the state of the art in sparse matching, and derive simple but effective improvements.","Cumulatively, they make LightGlue more efficient - in terms of both memory and computation, more accurate, and much easier to train.","One key property is that LightGlue is adaptive to the difficulty of the problem: the inference is much faster on image pairs that are intuitively easy to match, for example because of a larger visual overlap or limited appearance change.","This opens up exciting prospects for deploying deep matchers in latency-sensitive applications like 3D reconstruction.","The code and trained models are publicly available at https://github.com/cvg/LightGlue."],"url":"http://arxiv.org/abs/2306.13643v1"}
{"created":"2023-06-23","title":"Instantaneous Clear Sky Radiative Forcings of Halogenated Gases","abstract":"The clear sky instantaneous radiative forcings of the 14 halogenated gases previously shown to have the largest contribution to global warming, were found. The calculation used the absorption cross sections for the halogenated gases which are assumed to be independent of temperature as well as over 1/3 million line strengths for the 5 naturally occurring greenhouse gases: H$_2$O, CO$_2$, O$_3$, CH$_4$ and N$_2$O, from the Hitran database. The total radiative forcing of the halogenated gases at their 2020 concentrations is 0.52 (0.67) W/m$^2$ at the tropopause (mesopause). Over half of this forcing is due to CFC11 and CFC12 whose concentrations are declining as a result of the Montreal Protocol. The rate of total forcing change for all 14 halogenated gases is 1.5 (2.2) mW/m$^2$/year at the tropopause (mesopause). The calculations assumed a constant altitude concentration for all halogenated gases except CFC11, CFC12 and SF$_6$. Using the observed altitude dependence for those 3 molecules reduced their radiative forcings by about 10%. The global warming potential values were comparable to those given by the Intergovernmental Panel on Climate Change. The contribution of a gas to global warming was estimated using the forcing power per molecule defined as the derivative of its radiative forcing with respect to its column density. For the present atmosphere, the per-molecule forcing powers of halogenated gases are orders of magnitude larger than those for the 5 naturally occuring greenhouse gases because the latter have much higher concentrations and are strongly saturated. But, the rates of concentration increase of the 5 main greenhouse gases are orders of magnitude greater than that of any halogenated gas. Assuming the temperature increase caused by each gas is proportional to its radiative forcing increase, the 14 halogenated gases are responsible for only 2% of the total global warming.","sentences":["The clear sky instantaneous radiative forcings of the 14 halogenated gases previously shown to have the largest contribution to global warming, were found.","The calculation used the absorption cross sections for the halogenated gases which are assumed to be independent of temperature as well as over 1/3 million line strengths for the 5 naturally occurring greenhouse gases: H$_2$O, CO$_2$, O$_3$, CH$_4$ and N$_2$O, from the Hitran database.","The total radiative forcing of the halogenated gases at their 2020 concentrations is 0.52 (0.67)","W/m$^2$ at the tropopause (mesopause).","Over half of this forcing is due to CFC11 and CFC12 whose concentrations are declining as a result of the Montreal Protocol.","The rate of total forcing change for all 14 halogenated gases is 1.5 (2.2) mW/m$^2$/year at the tropopause (mesopause).","The calculations assumed a constant altitude concentration for all halogenated gases except CFC11, CFC12 and SF$_6$. Using the observed altitude dependence for those 3 molecules reduced their radiative forcings by about 10%.","The global warming potential values were comparable to those given by the Intergovernmental Panel on Climate Change.","The contribution of a gas to global warming was estimated using the forcing power per molecule defined as the derivative of its radiative forcing with respect to its column density.","For the present atmosphere, the per-molecule forcing powers of halogenated gases are orders of magnitude larger than those for the 5 naturally occuring greenhouse gases because the latter have much higher concentrations and are strongly saturated.","But, the rates of concentration increase of the 5 main greenhouse gases are orders of magnitude greater than that of any halogenated gas.","Assuming the temperature increase caused by each gas is proportional to its radiative forcing increase, the 14 halogenated gases are responsible for only 2% of the total global warming."],"url":"http://arxiv.org/abs/2306.13642v1"}
{"created":"2023-06-23","title":"A New Paradigm for Generative Adversarial Networks based on Randomized Decision Rules","abstract":"The Generative Adversarial Network (GAN) was recently introduced in the literature as a novel machine learning method for training generative models. It has many applications in statistics such as nonparametric clustering and nonparametric conditional independence tests. However, training the GAN is notoriously difficult due to the issue of mode collapse, which refers to the lack of diversity among generated data. In this paper, we identify the reasons why the GAN suffers from this issue, and to address it, we propose a new formulation for the GAN based on randomized decision rules. In the new formulation, the discriminator converges to a fixed point while the generator converges to a distribution at the Nash equilibrium. We propose to train the GAN by an empirical Bayes-like method by treating the discriminator as a hyper-parameter of the posterior distribution of the generator. Specifically, we simulate generators from its posterior distribution conditioned on the discriminator using a stochastic gradient Markov chain Monte Carlo (MCMC) algorithm, and update the discriminator using stochastic gradient descent along with simulations of the generators. We establish convergence of the proposed method to the Nash equilibrium. Apart from image generation, we apply the proposed method to nonparametric clustering and nonparametric conditional independence tests. A portion of the numerical results is presented in the supplementary material.","sentences":["The Generative Adversarial Network (GAN) was recently introduced in the literature as a novel machine learning method for training generative models.","It has many applications in statistics such as nonparametric clustering and nonparametric conditional independence tests.","However, training the GAN is notoriously difficult due to the issue of mode collapse, which refers to the lack of diversity among generated data.","In this paper, we identify the reasons why the GAN suffers from this issue, and to address it, we propose a new formulation for the GAN based on randomized decision rules.","In the new formulation, the discriminator converges to a fixed point while the generator converges to a distribution at the Nash equilibrium.","We propose to train the GAN by an empirical Bayes-like method by treating the discriminator as a hyper-parameter of the posterior distribution of the generator.","Specifically, we simulate generators from its posterior distribution conditioned on the discriminator using a stochastic gradient Markov chain Monte Carlo (MCMC) algorithm, and update the discriminator using stochastic gradient descent along with simulations of the generators.","We establish convergence of the proposed method to the Nash equilibrium.","Apart from image generation, we apply the proposed method to nonparametric clustering and nonparametric conditional independence tests.","A portion of the numerical results is presented in the supplementary material."],"url":"http://arxiv.org/abs/2306.13641v1"}
{"created":"2023-06-23","title":"The planar two-loop four-point form factor in maximally supersymmetric Yang-Mills theory","abstract":"We derive the four-dimensional integrand of the maximal-helicity-violating four-particle form factor for the chiral part of the stress-tensor supermultiplet in planar $\\mathcal{N}=4$ super-Yang-Mills theory at two loops. In our integrand construction, we adopt a special integrand basis with triangle powercounting where each basis element has unit leading singularities on all co-dimension eight residues. This basis was first constructed in the context of two-loop $n$-point scattering amplitudes in $\\mathcal{N}=4$ beyond the planar limit and we describe here, how to directly utilize it for the form factor computation. Our result sets the stage for an independent confirmation of the symbol level bootstrap results of Dixon et al.~via direct evaluation. The imminent availability of all relevant two-loop five-point, one-mass master integrals will permit further investigations of a set of marvelous (self-)dualities between form factors and scattering amplitudes in planar $\\mathcal{N}=4$ in the near future.","sentences":["We derive the four-dimensional integrand of the maximal-helicity-violating four-particle form factor for the chiral part of the stress-tensor supermultiplet in planar $\\mathcal{N}=4$ super-Yang-Mills theory at two loops.","In our integrand construction, we adopt a special integrand basis with triangle powercounting where each basis element has unit leading singularities on all co-dimension eight residues.","This basis was first constructed in the context of two-loop $n$-point scattering amplitudes in $\\mathcal{N}=4$ beyond the planar limit and we describe here, how to directly utilize it for the form factor computation.","Our result sets the stage for an independent confirmation of the symbol level bootstrap results of Dixon et al.~via direct evaluation.","The imminent availability of all relevant two-loop five-point, one-mass master integrals will permit further investigations of a set of marvelous (self-)dualities between form factors and scattering amplitudes in planar $\\mathcal{N}=4$ in the near future."],"url":"http://arxiv.org/abs/2306.13640v1"}
{"created":"2023-06-23","title":"X-ray Analysis of AGN from the GALEX Time Domain Survey","abstract":"We analyze the X-ray properties for a sample of 23 high probability AGN candidates with ultraviolet variability identified in Wasleske et al. (2022). Using data from the Chandra X-ray Observatory and the XMM-Newton Observatory, we find 11/23 nuclei are X-ray detected. We use SED modeling to compute star formation rates and show that the X-ray luminosities are typically in excess of the X-ray emission expected from star formation by at least an order of magnitude. Interestingly, this sample shows a diversity of optical spectroscopic properties. We explore possible reasons for why some objects lack optical spectroscopic signatures of black hole activity while still being UV variable and X-ray bright. We find that host galaxy stellar emission and obscuration from gas and dust are all potential factors. We study where this sample falls on relationships such as $\\alpha_{\\rm OX}-L_{2500}$ and $L_{X}-L_{IR}$ and find that some of the sample falls outside the typical scatter for these relations, indicating they differ from the standard quasar population. With the diversity of optical spectroscopic signatures and varying impacts of dust and stellar emissions on our sample, these results emphasizes the strength of variability in selecting the most complete set of AGN, regardless of other host galaxy properties.","sentences":["We analyze the X-ray properties for a sample of 23 high probability AGN candidates with ultraviolet variability identified in Wasleske et al. (2022).","Using data from the Chandra X-ray Observatory and the XMM-Newton Observatory, we find 11/23 nuclei are X-ray detected.","We use SED modeling to compute star formation rates and show that the X-ray luminosities are typically in excess of the X-ray emission expected from star formation by at least an order of magnitude.","Interestingly, this sample shows a diversity of optical spectroscopic properties.","We explore possible reasons for why some objects lack optical spectroscopic signatures of black hole activity while still being UV variable and X-ray bright.","We find that host galaxy stellar emission and obscuration from gas and dust are all potential factors.","We study where this sample falls on relationships such as $\\alpha_{\\rm OX}-L_{2500}$ and $L_{X}-L_{IR}$ and find that some of the sample falls outside the typical scatter for these relations, indicating they differ from the standard quasar population.","With the diversity of optical spectroscopic signatures and varying impacts of dust and stellar emissions on our sample, these results emphasizes the strength of variability in selecting the most complete set of AGN, regardless of other host galaxy properties."],"url":"http://arxiv.org/abs/2306.13639v1"}
{"created":"2023-06-23","title":"Optimal Sensor Placement with Adaptive Constraints for Nuclear Digital Twins","abstract":"Given harsh operating conditions and physical constraints in reactors, nuclear applications cannot afford to equip the physical asset with a large array of sensors. Therefore, it is crucial to carefully determine the placement of sensors within the given spatial limitations, enabling the reconstruction of reactor flow fields and the creation of nuclear digital twins. Various design considerations are imposed, such as predetermined sensor locations, restricted areas within the reactor, a fixed number of sensors allocated to a specific region, or sensors positioned at a designated distance from one another. We develop a data-driven technique that integrates constraints into an optimization procedure for sensor placement, aiming to minimize reconstruction errors. Our approach employs a greedy algorithm that can optimize sensor locations on a grid, adhering to user-defined constraints. We demonstrate the near optimality of our algorithm by computing all possible configurations for selecting a certain number of sensors for a randomly generated state space system. In this work, the algorithm is demonstrated on the Out-of-Pile Testing and Instrumentation Transient Water Irradiation System (OPTI-TWIST) prototype vessel, which is electrically heated to mimic the neutronics effect of the Transient Reactor Test facility (TREAT) at Idaho National Laboratory (INL). The resulting sensor-based reconstruction of temperature within the OPTI-TWIST minimizes error, provides probabilistic bounds for noise-induced uncertainty and will finally be used for communication between the digital twin and experimental facility.","sentences":["Given harsh operating conditions and physical constraints in reactors, nuclear applications cannot afford to equip the physical asset with a large array of sensors.","Therefore, it is crucial to carefully determine the placement of sensors within the given spatial limitations, enabling the reconstruction of reactor flow fields and the creation of nuclear digital twins.","Various design considerations are imposed, such as predetermined sensor locations, restricted areas within the reactor, a fixed number of sensors allocated to a specific region, or sensors positioned at a designated distance from one another.","We develop a data-driven technique that integrates constraints into an optimization procedure for sensor placement, aiming to minimize reconstruction errors.","Our approach employs a greedy algorithm that can optimize sensor locations on a grid, adhering to user-defined constraints.","We demonstrate the near optimality of our algorithm by computing all possible configurations for selecting a certain number of sensors for a randomly generated state space system.","In this work, the algorithm is demonstrated on the Out-of-Pile Testing and Instrumentation Transient Water Irradiation System (OPTI-TWIST) prototype vessel, which is electrically heated to mimic the neutronics effect of the Transient Reactor Test facility (TREAT) at Idaho National Laboratory (INL).","The resulting sensor-based reconstruction of temperature within the OPTI-TWIST minimizes error, provides probabilistic bounds for noise-induced uncertainty and will finally be used for communication between the digital twin and experimental facility."],"url":"http://arxiv.org/abs/2306.13637v1"}
{"created":"2023-06-23","title":"Some new primality criteria based on Lucas sequences","abstract":"In this paper, we provide some novel results concerning the behavior of $\\frac{U_{kn}}{U_k}$ modulo ${U_n}$, where $(U_n)_{n\\in\\mathbb{N}}$ is the Lucas sequence of the first kind. As a consequence, we obtain some primality criteria which do not seem to appear in the literature.","sentences":["In this paper, we provide some novel results concerning the behavior of $\\frac{U_{kn}}{U_k}$ modulo ${U_n}$, where $(U_n)_{n\\in\\mathbb{N}}$ is the Lucas sequence of the first kind.","As a consequence, we obtain some primality criteria which do not seem to appear in the literature."],"url":"http://arxiv.org/abs/2306.13638v1"}
{"created":"2023-06-23","title":"Supersymmetry and trace formulas II. Selberg trace formula","abstract":"By extending the new supersymmetric localization principle introduced in \\cite{Choi:2021yuz}, we present a path integral derivation of the Selberg trace formula on arbitrary compact Riemann surfaces, including the case of arbitrary vector-valued automorphic form and weight corresponding to Maass Laplacian. We also generalize the method to formulate the Selberg trace formula on generic compact locally symmetric space.","sentences":["By extending the new supersymmetric localization principle introduced in \\cite{Choi:2021yuz}, we present a path integral derivation of the Selberg trace formula on arbitrary compact Riemann surfaces, including the case of arbitrary vector-valued automorphic form and weight corresponding to Maass Laplacian.","We also generalize the method to formulate the Selberg trace formula on generic compact locally symmetric space."],"url":"http://arxiv.org/abs/2306.13636v1"}
{"created":"2023-06-23","title":"Fredholm determinants and applications to number theory","abstract":"Products of shifted characteristic polynomials, and ratios of such products, averaged over the classical compact groups are of great interest to number theorists as they model similar averages of L-functions in families with the same symmetry type as the compact group. We use Toeplitz and Toeplitz plus Hankel operators and the identities of Borodin - Okounkov, Case - Geronimo, and Basor - Erhardt to prove that, in certain cases, these unitary averages factor as polynomials in the matrix size into averages over the symplectic group and the orthogonal group. Building on these identities we present new proofs of the exact formulas for these averages where the ``swap'' terms that are characteristic of the number theoretic averages occur from the Fredholm expansions of the determinants of the appropriate Hankel operator. This is the fourth different proof of the formula for the averages of ratios of products of shifted characteristic polynomials; the other proofs are based on supersymmetry; symmetric function theory, and orthogonal polynomial methods from Random Matrix Theory.","sentences":["Products of shifted characteristic polynomials, and ratios of such products, averaged over the classical compact groups are of great interest to number theorists as they model similar averages of L-functions in families with the same symmetry type as the compact group.","We use Toeplitz and Toeplitz plus Hankel operators and the identities of Borodin - Okounkov, Case - Geronimo, and Basor - Erhardt to prove that, in certain cases, these unitary averages factor as polynomials in the matrix size into averages over the symplectic group and the orthogonal group.","Building on these identities we present new proofs of the exact formulas for these averages where the ``swap'' terms that are characteristic of the number theoretic averages occur from the Fredholm expansions of the determinants of the appropriate Hankel operator.","This is the fourth different proof of the formula for the averages of ratios of products of shifted characteristic polynomials; the other proofs are based on supersymmetry; symmetric function theory, and orthogonal polynomial methods from Random Matrix Theory."],"url":"http://arxiv.org/abs/2306.13635v1"}
{"created":"2023-06-23","title":"Many-species ecological fluctuations as a jump process from the brink of extinction","abstract":"Many-species ecological communities can exhibit persistent fluctuations driven by species interactions. These dynamics feature many interesting properties, such as the emergence of long timescales and large fluctuations, that have remained poorly understood. We look at such dynamics, when species are supported by migration at a small rate. We find that the dynamics are characterized by a single long correlation timescale. We prove that the time and abundances can be rescaled to yield a well-defined limiting process when the migration rate is small but positive. The existence of this rescaled dynamics predicts scaling forms for both abundance distributions and timescales, which are verified exactly in scaling collapse of simulation results. In the rescaled process, a clear separation naturally emerges at any given time between rare and abundant species, allowing for a clear-cut definition of the number of coexisting species. Species move back and forth between the rare and abundant subsets. The dynamics of a species entering the abundant subset starts with rapid growth from rare, appearing as an instantaneous jump in rescaled time, followed by meandering abundances with an overall negative bias. The emergence of the long timescale is explained by another rescaling theory for earlier times. Finally, we prove that the number of abundant species is tuned to remain below and without saturating a well-known stability bound, maintaining the system away from marginality. This is traced back to the perturbing effect of the jump processes of incoming species on the abundant ones.","sentences":["Many-species ecological communities can exhibit persistent fluctuations driven by species interactions.","These dynamics feature many interesting properties, such as the emergence of long timescales and large fluctuations, that have remained poorly understood.","We look at such dynamics, when species are supported by migration at a small rate.","We find that the dynamics are characterized by a single long correlation timescale.","We prove that the time and abundances can be rescaled to yield a well-defined limiting process when the migration rate is small but positive.","The existence of this rescaled dynamics predicts scaling forms for both abundance distributions and timescales, which are verified exactly in scaling collapse of simulation results.","In the rescaled process, a clear separation naturally emerges at any given time between rare and abundant species, allowing for a clear-cut definition of the number of coexisting species.","Species move back and forth between the rare and abundant subsets.","The dynamics of a species entering the abundant subset starts with rapid growth from rare, appearing as an instantaneous jump in rescaled time, followed by meandering abundances with an overall negative bias.","The emergence of the long timescale is explained by another rescaling theory for earlier times.","Finally, we prove that the number of abundant species is tuned to remain below and without saturating a well-known stability bound, maintaining the system away from marginality.","This is traced back to the perturbing effect of the jump processes of incoming species on the abundant ones."],"url":"http://arxiv.org/abs/2306.13634v1"}
{"created":"2023-06-23","title":"Optimal Vaccination Policy to Prevent Endemicity: A Stochastic Model","abstract":"We examine here the effects of recurrent vaccination and waning immunity on the establishment of an endemic equilibrium in a population. An individual-based model that incorporates memory effects for transmission rate during infection and subsequent immunity is introduced, considering stochasticity at the individual level. By letting the population size going to infinity, we derive a set of equations describing the large scale behavior of the epidemic. The analysis of the model's equilibria reveals a criterion for the existence of an endemic equilibrium, which depends on the rate of immunity loss and the distribution of time between booster doses. The outcome of a vaccination policy in this context is influenced by the efficiency of the vaccine in blocking transmissions and the distribution pattern of booster doses within the population. Strategies with evenly spaced booster shots at the individual level prove to be more effective in preventing disease spread compared to irregularly spaced boosters, as longer intervals without vaccination increase susceptibility and facilitate more efficient disease transmission. We provide an expression for the critical fraction of the population required to adhere to the vaccination policy in order to eradicate the disease, that resembles a well-known threshold for preventing an outbreak with an imperfect vaccine. We also investigate the consequences of unequal vaccine access in a population and prove that, under reasonable assumptions, fair vaccine allocation is the optimal strategy to prevent endemicity.","sentences":["We examine here the effects of recurrent vaccination and waning immunity on the establishment of an endemic equilibrium in a population.","An individual-based model that incorporates memory effects for transmission rate during infection and subsequent immunity is introduced, considering stochasticity at the individual level.","By letting the population size going to infinity, we derive a set of equations describing the large scale behavior of the epidemic.","The analysis of the model's equilibria reveals a criterion for the existence of an endemic equilibrium, which depends on the rate of immunity loss and the distribution of time between booster doses.","The outcome of a vaccination policy in this context is influenced by the efficiency of the vaccine in blocking transmissions and the distribution pattern of booster doses within the population.","Strategies with evenly spaced booster shots at the individual level prove to be more effective in preventing disease spread compared to irregularly spaced boosters, as longer intervals without vaccination increase susceptibility and facilitate more efficient disease transmission.","We provide an expression for the critical fraction of the population required to adhere to the vaccination policy in order to eradicate the disease, that resembles a well-known threshold for preventing an outbreak with an imperfect vaccine.","We also investigate the consequences of unequal vaccine access in a population and prove that, under reasonable assumptions, fair vaccine allocation is the optimal strategy to prevent endemicity."],"url":"http://arxiv.org/abs/2306.13633v1"}
{"created":"2023-06-23","title":"Light-induced switching between singlet and triplet superconducting states","abstract":"While the search for topological triplet-pairing superconductivity has remained a challenge, recent developments in optically stabilizing metastable superconducting states suggest a new route to realizing this elusive phase. Here, we devise a testable theory of competing superconducting orders that permits ultrafast switching to an opposite-parity superconducting phase in centrosymmetric crystals with strong spin-orbit coupling. Using both microscopic and phenomenological models, we show that dynamical inversion symmetry breaking with a tailored light pulse can induce odd-parity (spin triplet) order parameter oscillations in a conventional even-parity (spin singlet) superconductor, which when driven strongly can send the system to a competing minimum in its free energy landscape. Our results provide new guiding principles for engineering unconventional electronic phases using light, suggesting a fundamentally non-equilibrium route toward realizing topological superconductivity.","sentences":["While the search for topological triplet-pairing superconductivity has remained a challenge, recent developments in optically stabilizing metastable superconducting states suggest a new route to realizing this elusive phase.","Here, we devise a testable theory of competing superconducting orders that permits ultrafast switching to an opposite-parity superconducting phase in centrosymmetric crystals with strong spin-orbit coupling.","Using both microscopic and phenomenological models, we show that dynamical inversion symmetry breaking with a tailored light pulse can induce odd-parity (spin triplet) order parameter oscillations in a conventional even-parity (spin singlet) superconductor, which when driven strongly can send the system to a competing minimum in its free energy landscape.","Our results provide new guiding principles for engineering unconventional electronic phases using light, suggesting a fundamentally non-equilibrium route toward realizing topological superconductivity."],"url":"http://arxiv.org/abs/2306.13632v1"}
{"created":"2023-06-23","title":"OpenMask3D: Open-Vocabulary 3D Instance Segmentation","abstract":"We introduce the task of open-vocabulary 3D instance segmentation. Traditional approaches for 3D instance segmentation largely rely on existing 3D annotated datasets, which are restricted to a closed-set of object categories. This is an important limitation for real-life applications where one might need to perform tasks guided by novel, open-vocabulary queries related to objects from a wide variety. Recently, open-vocabulary 3D scene understanding methods have emerged to address this problem by learning queryable features per each point in the scene. While such a representation can be directly employed to perform semantic segmentation, existing methods have limitations in their ability to identify object instances. In this work, we address this limitation, and propose OpenMask3D, which is a zero-shot approach for open-vocabulary 3D instance segmentation. Guided by predicted class-agnostic 3D instance masks, our model aggregates per-mask features via multi-view fusion of CLIP-based image embeddings. We conduct experiments and ablation studies on the ScanNet200 dataset to evaluate the performance of OpenMask3D, and provide insights about the open-vocabulary 3D instance segmentation task. We show that our approach outperforms other open-vocabulary counterparts, particularly on the long-tail distribution. Furthermore, OpenMask3D goes beyond the limitations of close-vocabulary approaches, and enables the segmentation of object instances based on free-form queries describing object properties such as semantics, geometry, affordances, and material properties.","sentences":["We introduce the task of open-vocabulary 3D instance segmentation.","Traditional approaches for 3D instance segmentation largely rely on existing 3D annotated datasets, which are restricted to a closed-set of object categories.","This is an important limitation for real-life applications where one might need to perform tasks guided by novel, open-vocabulary queries related to objects from a wide variety.","Recently, open-vocabulary 3D scene understanding methods have emerged to address this problem by learning queryable features per each point in the scene.","While such a representation can be directly employed to perform semantic segmentation, existing methods have limitations in their ability to identify object instances.","In this work, we address this limitation, and propose OpenMask3D, which is a zero-shot approach for open-vocabulary 3D instance segmentation.","Guided by predicted class-agnostic 3D instance masks, our model aggregates per-mask features via multi-view fusion of CLIP-based image embeddings.","We conduct experiments and ablation studies on the ScanNet200 dataset to evaluate the performance of OpenMask3D, and provide insights about the open-vocabulary 3D instance segmentation task.","We show that our approach outperforms other open-vocabulary counterparts, particularly on the long-tail distribution.","Furthermore, OpenMask3D goes beyond the limitations of close-vocabulary approaches, and enables the segmentation of object instances based on free-form queries describing object properties such as semantics, geometry, affordances, and material properties."],"url":"http://arxiv.org/abs/2306.13631v1"}
{"created":"2023-06-23","title":"Offline Skill Graph (OSG): A Framework for Learning and Planning using Offline Reinforcement Learning Skills","abstract":"Reinforcement Learning has received wide interest due to its success in competitive games. Yet, its adoption in everyday applications is limited (e.g. industrial, home, healthcare, etc.). In this paper, we address this limitation by presenting a framework for planning over offline skills and solving complex tasks in real-world environments. Our framework is comprised of three modules that together enable the agent to learn from previously collected data and generalize over it to solve long-horizon tasks. We demonstrate our approach by testing it on a robotic arm that is required to solve complex tasks.","sentences":["Reinforcement Learning has received wide interest due to its success in competitive games.","Yet, its adoption in everyday applications is limited (e.g. industrial, home, healthcare, etc.).","In this paper, we address this limitation by presenting a framework for planning over offline skills and solving complex tasks in real-world environments.","Our framework is comprised of three modules that together enable the agent to learn from previously collected data and generalize over it to solve long-horizon tasks.","We demonstrate our approach by testing it on a robotic arm that is required to solve complex tasks."],"url":"http://arxiv.org/abs/2306.13630v1"}
{"created":"2023-06-23","title":"Converging Many-Body Perturbation Theory for Ab Initio Nuclear-Structure: I. Brillouin-Wigner Perturbation Series for Closed-Shell Nuclei","abstract":"Convergence aspects of nuclear many-body perturbation theory for ground states of closed-shell nuclei are explored using a Brillouin-Wigner formulation with a new vertex function enabling high-order calculations. A general formalism for Hamiltonian partitioning and a convergence criterion for the perturbation series are proposed. Analytical derivation shows that with optimal partitionings, the convergence criterion for ground states can always be satisfied. This feature attributes to the variational principle and does not depend on the choice of an internucleon interaction or a many-body basis. Numerical calculations of the ground state energies of 4He and 16O with Daejeon16 and a bare N3LO potential in both harmonic-oscillator and Hartree-Fock bases confirm this finding.","sentences":["Convergence aspects of nuclear many-body perturbation theory for ground states of closed-shell nuclei are explored using a Brillouin-Wigner formulation with a new vertex function enabling high-order calculations.","A general formalism for Hamiltonian partitioning and a convergence criterion for the perturbation series are proposed.","Analytical derivation shows that with optimal partitionings, the convergence criterion for ground states can always be satisfied.","This feature attributes to the variational principle and does not depend on the choice of an internucleon interaction or a many-body basis.","Numerical calculations of the ground state energies of 4He and 16O with Daejeon16 and a bare N3LO potential in both harmonic-oscillator and Hartree-Fock bases confirm this finding."],"url":"http://arxiv.org/abs/2306.13629v1"}
{"created":"2023-06-23","title":"On particular solutions of linear partial differential equations with polynomial right-hand-sides","abstract":"This paper introduces general methodologies for constructing closed-form solutions to several important partial differential equations (PDEs) with polynomial right-hand sides in two and three spatial dimensions. The covered equations include the isotropic and anisotropic Poisson, Helmholtz, Stokes, and elastostatic equations, as well as the time-harmonic linear elastodynamic and Maxwell equations. Polynomial solutions have recently regained significance in the development of numerical techniques for evaluating volume integral operators and have potential applications in certain kinds of Trefftz finite element methods. Our approach to all of these PDEs relates the particular solution to polynomial solutions of the Poisson and Helmholtz polynomial particular solutions, solutions that can in turn be obtained, respectively, from expansions using homogeneous polynomials and the Neumann series expansion of the operator $(k^2+\\Delta)^{-1}$. No matrix inversion is required to compute the solution. The method naturally incorporates divergence constraints on the solution, such as in the case of Maxwell and Stokes flow equations. This work is accompanied by a freely available Julia library, \\texttt{PolynomialSolutions.jl}, which implements the proposed methodology in a non-symbolic format and efficiently constructs and provides access to rapid evaluation of the desired solution.","sentences":["This paper introduces general methodologies for constructing closed-form solutions to several important partial differential equations (PDEs) with polynomial right-hand sides in two and three spatial dimensions.","The covered equations include the isotropic and anisotropic Poisson, Helmholtz, Stokes, and elastostatic equations, as well as the time-harmonic linear elastodynamic and Maxwell equations.","Polynomial solutions have recently regained significance in the development of numerical techniques for evaluating volume integral operators and have potential applications in certain kinds of Trefftz finite element methods.","Our approach to all of these PDEs relates the particular solution to polynomial solutions of the Poisson and Helmholtz polynomial particular solutions, solutions that can in turn be obtained, respectively, from expansions using homogeneous polynomials and the Neumann series expansion of the operator $(k^2+\\Delta)^{-1}$.","No matrix inversion is required to compute the solution.","The method naturally incorporates divergence constraints on the solution, such as in the case of Maxwell and Stokes flow equations.","This work is accompanied by a freely available Julia library, \\texttt{PolynomialSolutions.jl}, which implements the proposed methodology in a non-symbolic format and efficiently constructs and provides access to rapid evaluation of the desired solution."],"url":"http://arxiv.org/abs/2306.13628v1"}
{"created":"2023-06-23","title":"Addressing issues in defining the Love number for black holes","abstract":"We present an analytic method for calculating the tidal response function of a non-rotating and a slowly rotating black hole from the Teukolsky equation in the small frequency and the near horizon limit. We point out that in the relativistic context, there can be two possible definitions of the tidal Love number and the dissipative part that arise from the tidal response function. Our results suggest that both of these definitions predict zero tidal Love number for a non-rotating black hole. On the other hand, for a slowly rotating black hole in a generic tidal environment, these two definitions of the tidal Love number do not coincide. While one procedure suggests a zero tidal Love number, the other procedure gives a purely imaginary tidal Love number. As expected, the dissipative terms differ as well. We emphasize that in our analysis we keep all the terms linear in the frequency, unlike previous works in the literature. Following this, we propose a procedure to calculate the tidal response function and hence the Love number for an arbitrarily rotating black hole.","sentences":["We present an analytic method for calculating the tidal response function of a non-rotating and a slowly rotating black hole from the Teukolsky equation in the small frequency and the near horizon limit.","We point out that in the relativistic context, there can be two possible definitions of the tidal Love number and the dissipative part that arise from the tidal response function.","Our results suggest that both of these definitions predict zero tidal Love number for a non-rotating black hole.","On the other hand, for a slowly rotating black hole in a generic tidal environment, these two definitions of the tidal Love number do not coincide.","While one procedure suggests a zero tidal Love number, the other procedure gives a purely imaginary tidal Love number.","As expected, the dissipative terms differ as well.","We emphasize that in our analysis we keep all the terms linear in the frequency, unlike previous works in the literature.","Following this, we propose a procedure to calculate the tidal response function and hence the Love number for an arbitrarily rotating black hole."],"url":"http://arxiv.org/abs/2306.13627v1"}
{"created":"2023-06-23","title":"Asymmetric Distribution of Extreme Values of Cubic $L$-functions on the $1$-line","abstract":"We investigate the distribution of values of cubic Dirichlet $L$-functions at $s=1$. Following ideas of Granville and Soundararajan for quadratic $L$-functions, we model the distribution of $L(1,\\chi)$ by the distribution of random Euler products $L(1,\\mathbb{X})$ for certain family of random variables $\\mathbb{X}(p)$ attached to each prime. We obtain a description of the proportion of $|L(1,\\chi)|$ that are larger or that are smaller than a given bound, and yield more light into the Littlewood bounds. Unlike the quadratic case, there is an asymmetry between lower and upper bounds for the cubic case, and small values are less probable than large values.","sentences":["We investigate the distribution of values of cubic Dirichlet $L$-functions at $s=1$. Following ideas of Granville and Soundararajan for quadratic $L$-functions, we model the distribution of $L(1,\\chi)$ by the distribution of random Euler products $L(1,\\mathbb{X})$ for certain family of random variables $\\mathbb{X}(p)$ attached to each prime.","We obtain a description of the proportion of $|L(1,\\chi)|$ that are larger or that are smaller than a given bound, and yield more light into the Littlewood bounds.","Unlike the quadratic case, there is an asymmetry between lower and upper bounds for the cubic case, and small values are less probable than large values."],"url":"http://arxiv.org/abs/2306.13626v1"}
{"created":"2023-06-23","title":"Fast Macroscopic Forcing Method","abstract":"The macroscopic forcing method (MFM) of Mani and Park and similar methods for obtaining turbulence closure operators, such as the Green's function-based approach of Hamba, recover reduced solution operators from repeated direct numerical simulations (DNS). MFM has been used to quantify RANS-like operators for homogeneous isotropic turbulence and turbulent channel flows. Standard algorithms for MFM force each coarse-scale degree of freedom (i.e., degree of freedom in the RANS space) and conduct a corresponding fine-scale simulation (i.e., DNS), which is expensive. We combine this method with an approach recently proposed by Sch\\\"afer and Owhadi (2023) to recover elliptic integral operators from a polylogarithmic number of matrix-vector products. The resulting Fast MFM introduced in this work applies sparse reconstruction to expose local features in the closure operator and reconstructs this coarse-grained differential operator in only a few matrix-vector products and correspondingly, a few MFM simulations. For flows with significant nonlocality, the algorithm first \"peels\" long-range effects with dense matrix-vector products to expose a local operator. We demonstrate the algorithm's performance for scalar transport in a laminar channel flow and momentum transport in a turbulent one. For these, we recover eddy diffusivity operators at 1% of the cost of computing the exact operator via a brute-force approach for the laminar channel flow problem and 13% for the turbulent one. We observe that we can reconstruct these operators with an increase in accuracy by about a factor of 100 over randomized low-rank methods. We glean that for problems in which the RANS space is reducible to one dimension, eddy diffusivity and eddy viscosity operators can be reconstructed with reasonable accuracy using only a few simulations, regardless of simulation resolution or degrees of freedom.","sentences":["The macroscopic forcing method (MFM) of Mani and Park and similar methods for obtaining turbulence closure operators, such as the Green's function-based approach of Hamba, recover reduced solution operators from repeated direct numerical simulations (DNS).","MFM has been used to quantify RANS-like operators for homogeneous isotropic turbulence and turbulent channel flows.","Standard algorithms for MFM force each coarse-scale degree of freedom (i.e., degree of freedom in the RANS space) and conduct a corresponding fine-scale simulation (i.e., DNS), which is expensive.","We combine this method with an approach recently proposed by Sch\\\"afer and Owhadi (2023) to recover elliptic integral operators from a polylogarithmic number of matrix-vector products.","The resulting Fast MFM introduced in this work applies sparse reconstruction to expose local features in the closure operator and reconstructs this coarse-grained differential operator in only a few matrix-vector products and correspondingly, a few MFM simulations.","For flows with significant nonlocality, the algorithm first \"peels\" long-range effects with dense matrix-vector products to expose a local operator.","We demonstrate the algorithm's performance for scalar transport in a laminar channel flow and momentum transport in a turbulent one.","For these, we recover eddy diffusivity operators at 1% of the cost of computing the exact operator via a brute-force approach for the laminar channel flow problem and 13% for the turbulent one.","We observe that we can reconstruct these operators with an increase in accuracy by about a factor of 100 over randomized low-rank methods.","We glean that for problems in which the RANS space is reducible to one dimension, eddy diffusivity and eddy viscosity operators can be reconstructed with reasonable accuracy using only a few simulations, regardless of simulation resolution or degrees of freedom."],"url":"http://arxiv.org/abs/2306.13625v1"}
