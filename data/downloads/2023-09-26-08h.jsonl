{"created":"2023-09-25 17:59:55","title":"Extreme Parkour with Legged Robots","abstract":"Humans can perform parkour by traversing obstacles in a highly dynamic fashion requiring precise eye-muscle coordination and movement. Getting robots to do the same task requires overcoming similar challenges. Classically, this is done by independently engineering perception, actuation, and control systems to very low tolerances. This restricts them to tightly controlled settings such as a predetermined obstacle course in labs. In contrast, humans are able to learn parkour through practice without significantly changing their underlying biology. In this paper, we take a similar approach to developing robot parkour on a small low-cost robot with imprecise actuation and a single front-facing depth camera for perception which is low-frequency, jittery, and prone to artifacts. We show how a single neural net policy operating directly from a camera image, trained in simulation with large-scale RL, can overcome imprecise sensing and actuation to output highly precise control behavior end-to-end. We show our robot can perform a high jump on obstacles 2x its height, long jump across gaps 2x its length, do a handstand and run across tilted ramps, and generalize to novel obstacle courses with different physical properties. Parkour videos at https://extreme-parkour.github.io/","sentences":["Humans can perform parkour by traversing obstacles in a highly dynamic fashion requiring precise eye-muscle coordination and movement.","Getting robots to do the same task requires overcoming similar challenges.","Classically, this is done by independently engineering perception, actuation, and control systems to very low tolerances.","This restricts them to tightly controlled settings such as a predetermined obstacle course in labs.","In contrast, humans are able to learn parkour through practice without significantly changing their underlying biology.","In this paper, we take a similar approach to developing robot parkour on a small low-cost robot with imprecise actuation and a single front-facing depth camera for perception which is low-frequency, jittery, and prone to artifacts.","We show how a single neural net policy operating directly from a camera image, trained in simulation with large-scale RL, can overcome imprecise sensing and actuation to output highly precise control behavior end-to-end.","We show our robot can perform a high jump on obstacles 2x its height, long jump across gaps 2x its length, do a handstand and run across tilted ramps, and generalize to novel obstacle courses with different physical properties.","Parkour videos at https://extreme-parkour.github.io/"],"url":"http://arxiv.org/abs/2309.14341v1"}
{"created":"2023-09-25 17:59:43","title":"Chop & Learn: Recognizing and Generating Object-State Compositions","abstract":"Recognizing and generating object-state compositions has been a challenging task, especially when generalizing to unseen compositions. In this paper, we study the task of cutting objects in different styles and the resulting object state changes. We propose a new benchmark suite Chop & Learn, to accommodate the needs of learning objects and different cut styles using multiple viewpoints. We also propose a new task of Compositional Image Generation, which can transfer learned cut styles to different objects, by generating novel object-state images. Moreover, we also use the videos for Compositional Action Recognition, and show valuable uses of this dataset for multiple video tasks. Project website: https://chopnlearn.github.io.","sentences":["Recognizing and generating object-state compositions has been a challenging task, especially when generalizing to unseen compositions.","In this paper, we study the task of cutting objects in different styles and the resulting object state changes.","We propose a new benchmark suite Chop & Learn, to accommodate the needs of learning objects and different cut styles using multiple viewpoints.","We also propose a new task of Compositional Image Generation, which can transfer learned cut styles to different objects, by generating novel object-state images.","Moreover, we also use the videos for Compositional Action Recognition, and show valuable uses of this dataset for multiple video tasks.","Project website: https://chopnlearn.github.io."],"url":"http://arxiv.org/abs/2309.14339v1"}
{"created":"2023-09-25 17:59:26","title":"3D Indoor Instance Segmentation in an Open-World","abstract":"Existing 3D instance segmentation methods typically assume that all semantic classes to be segmented would be available during training and only seen categories are segmented at inference. We argue that such a closed-world assumption is restrictive and explore for the first time 3D indoor instance segmentation in an open-world setting, where the model is allowed to distinguish a set of known classes as well as identify an unknown object as unknown and then later incrementally learning the semantic category of the unknown when the corresponding category labels are available. To this end, we introduce an open-world 3D indoor instance segmentation method, where an auto-labeling scheme is employed to produce pseudo-labels during training and induce separation to separate known and unknown category labels. We further improve the pseudo-labels quality at inference by adjusting the unknown class probability based on the objectness score distribution. We also introduce carefully curated open-world splits leveraging realistic scenarios based on inherent object distribution, region-based indoor scene exploration and randomness aspect of open-world classes. Extensive experiments reveal the efficacy of the proposed contributions leading to promising open-world 3D instance segmentation performance.","sentences":["Existing 3D instance segmentation methods typically assume that all semantic classes to be segmented would be available during training and only seen categories are segmented at inference.","We argue that such a closed-world assumption is restrictive and explore for the first time 3D indoor instance segmentation in an open-world setting, where the model is allowed to distinguish a set of known classes as well as identify an unknown object as unknown and then later incrementally learning the semantic category of the unknown when the corresponding category labels are available.","To this end, we introduce an open-world 3D indoor instance segmentation method, where an auto-labeling scheme is employed to produce pseudo-labels during training and induce separation to separate known and unknown category labels.","We further improve the pseudo-labels quality at inference by adjusting the unknown class probability based on the objectness score distribution.","We also introduce carefully curated open-world splits leveraging realistic scenarios based on inherent object distribution, region-based indoor scene exploration and randomness aspect of open-world classes.","Extensive experiments reveal the efficacy of the proposed contributions leading to promising open-world 3D instance segmentation performance."],"url":"http://arxiv.org/abs/2309.14338v1"}
{"created":"2023-09-25 17:58:46","title":"UnitedHuman: Harnessing Multi-Source Data for High-Resolution Human Generation","abstract":"Human generation has achieved significant progress. Nonetheless, existing methods still struggle to synthesize specific regions such as faces and hands. We argue that the main reason is rooted in the training data. A holistic human dataset inevitably has insufficient and low-resolution information on local parts. Therefore, we propose to use multi-source datasets with various resolution images to jointly learn a high-resolution human generative model. However, multi-source data inherently a) contains different parts that do not spatially align into a coherent human, and b) comes with different scales. To tackle these challenges, we propose an end-to-end framework, UnitedHuman, that empowers continuous GAN with the ability to effectively utilize multi-source data for high-resolution human generation. Specifically, 1) we design a Multi-Source Spatial Transformer that spatially aligns multi-source images to full-body space with a human parametric model. 2) Next, a continuous GAN is proposed with global-structural guidance and CutMix consistency. Patches from different datasets are then sampled and transformed to supervise the training of this scale-invariant generative model. Extensive experiments demonstrate that our model jointly learned from multi-source data achieves superior quality than those learned from a holistic dataset.","sentences":["Human generation has achieved significant progress.","Nonetheless, existing methods still struggle to synthesize specific regions such as faces and hands.","We argue that the main reason is rooted in the training data.","A holistic human dataset inevitably has insufficient and low-resolution information on local parts.","Therefore, we propose to use multi-source datasets with various resolution images to jointly learn a high-resolution human generative model.","However, multi-source data inherently a) contains different parts that do not spatially align into a coherent human, and b) comes with different scales.","To tackle these challenges, we propose an end-to-end framework, UnitedHuman, that empowers continuous GAN with the ability to effectively utilize multi-source data for high-resolution human generation.","Specifically, 1) we design a Multi-Source Spatial Transformer that spatially aligns multi-source images to full-body space with a human parametric model.","2) Next, a continuous GAN is proposed with global-structural guidance and CutMix consistency.","Patches from different datasets are then sampled and transformed to supervise the training of this scale-invariant generative model.","Extensive experiments demonstrate that our model jointly learned from multi-source data achieves superior quality than those learned from a holistic dataset."],"url":"http://arxiv.org/abs/2309.14335v1"}
{"created":"2023-09-25 17:58:23","title":"Tasks Makyth Models: Machine Learning Assisted Surrogates for Tipping Points","abstract":"We present a machine learning (ML)-assisted framework bridging manifold learning, neural networks, Gaussian processes, and Equation-Free multiscale modeling, for (a) detecting tipping points in the emergent behavior of complex systems, and (b) characterizing probabilities of rare events (here, catastrophic shifts) near them. Our illustrative example is an event-driven, stochastic agent-based model (ABM) describing the mimetic behavior of traders in a simple financial market. Given high-dimensional spatiotemporal data -- generated by the stochastic ABM -- we construct reduced-order models for the emergent dynamics at different scales: (a) mesoscopic Integro-Partial Differential Equations (IPDEs); and (b) mean-field-type Stochastic Differential Equations (SDEs) embedded in a low-dimensional latent space, targeted to the neighborhood of the tipping point. We contrast the uses of the different models and the effort involved in learning them.","sentences":["We present a machine learning (ML)-assisted framework bridging manifold learning, neural networks, Gaussian processes, and Equation-Free multiscale modeling, for (a) detecting tipping points in the emergent behavior of complex systems, and (b) characterizing probabilities of rare events (here, catastrophic shifts) near them.","Our illustrative example is an event-driven, stochastic agent-based model (ABM) describing the mimetic behavior of traders in a simple financial market.","Given high-dimensional spatiotemporal data -- generated by the stochastic ABM -- we construct reduced-order models for the emergent dynamics at different scales: (a) mesoscopic Integro-Partial Differential Equations (IPDEs); and (b) mean-field-type Stochastic Differential Equations (SDEs) embedded in a low-dimensional latent space, targeted to the neighborhood of the tipping point.","We contrast the uses of the different models and the effort involved in learning them."],"url":"http://arxiv.org/abs/2309.14334v1"}
{"created":"2023-09-25 17:56:54","title":"LinGCN: Structural Linearized Graph Convolutional Network for Homomorphically Encrypted Inference","abstract":"The growth of Graph Convolution Network (GCN) model sizes has revolutionized numerous applications, surpassing human performance in areas such as personal healthcare and financial systems. The deployment of GCNs in the cloud raises privacy concerns due to potential adversarial attacks on client data. To address security concerns, Privacy-Preserving Machine Learning (PPML) using Homomorphic Encryption (HE) secures sensitive client data. However, it introduces substantial computational overhead in practical applications. To tackle those challenges, we present LinGCN, a framework designed to reduce multiplication depth and optimize the performance of HE based GCN inference. LinGCN is structured around three key elements: (1) A differentiable structural linearization algorithm, complemented by a parameterized discrete indicator function, co-trained with model weights to meet the optimization goal. This strategy promotes fine-grained node-level non-linear location selection, resulting in a model with minimized multiplication depth. (2) A compact node-wise polynomial replacement policy with a second-order trainable activation function, steered towards superior convergence by a two-level distillation approach from an all-ReLU based teacher model. (3) an enhanced HE solution that enables finer-grained operator fusion for node-wise activation functions, further reducing multiplication level consumption in HE-based inference. Our experiments on the NTU-XVIEW skeleton joint dataset reveal that LinGCN excels in latency, accuracy, and scalability for homomorphically encrypted inference, outperforming solutions such as CryptoGCN. Remarkably, LinGCN achieves a 14.2x latency speedup relative to CryptoGCN, while preserving an inference accuracy of 75% and notably reducing multiplication depth.","sentences":["The growth of Graph Convolution Network (GCN) model sizes has revolutionized numerous applications, surpassing human performance in areas such as personal healthcare and financial systems.","The deployment of GCNs in the cloud raises privacy concerns due to potential adversarial attacks on client data.","To address security concerns, Privacy-Preserving Machine Learning (PPML) using Homomorphic Encryption (HE) secures sensitive client data.","However, it introduces substantial computational overhead in practical applications.","To tackle those challenges, we present LinGCN, a framework designed to reduce multiplication depth and optimize the performance of HE based GCN inference.","LinGCN is structured around three key elements: (1) A differentiable structural linearization algorithm, complemented by a parameterized discrete indicator function, co-trained with model weights to meet the optimization goal.","This strategy promotes fine-grained node-level non-linear location selection, resulting in a model with minimized multiplication depth.","(2) A compact node-wise polynomial replacement policy with a second-order trainable activation function, steered towards superior convergence by a two-level distillation approach from an all-ReLU based teacher model.","(3) an enhanced HE solution that enables finer-grained operator fusion for node-wise activation functions, further reducing multiplication level consumption in HE-based inference.","Our experiments on the NTU-XVIEW skeleton joint dataset reveal that LinGCN excels in latency, accuracy, and scalability for homomorphically encrypted inference, outperforming solutions such as CryptoGCN.","Remarkably, LinGCN achieves a 14.2x latency speedup relative to CryptoGCN, while preserving an inference accuracy of 75% and notably reducing multiplication depth."],"url":"http://arxiv.org/abs/2309.14331v1"}
{"created":"2023-09-25 17:55:24","title":"Noise-in, Bias-out: Balanced and Real-time MoCap Solving","abstract":"Real-time optical Motion Capture (MoCap) systems have not benefited from the advances in modern data-driven modeling. In this work we apply machine learning to solve noisy unstructured marker estimates in real-time and deliver robust marker-based MoCap even when using sparse affordable sensors. To achieve this we focus on a number of challenges related to model training, namely the sourcing of training data and their long-tailed distribution. Leveraging representation learning we design a technique for imbalanced regression that requires no additional data or labels and improves the performance of our model in rare and challenging poses. By relying on a unified representation, we show that training such a model is not bound to high-end MoCap training data acquisition, and exploit the advances in marker-less MoCap to acquire the necessary data. Finally, we take a step towards richer and affordable MoCap by adapting a body model-based inverse kinematics solution to account for measurement and inference uncertainty, further improving performance and robustness. Project page: https://moverseai.github.io/noise-tail","sentences":["Real-time optical Motion Capture (MoCap) systems have not benefited from the advances in modern data-driven modeling.","In this work we apply machine learning to solve noisy unstructured marker estimates in real-time and deliver robust marker-based MoCap even when using sparse affordable sensors.","To achieve this we focus on a number of challenges related to model training, namely the sourcing of training data and their long-tailed distribution.","Leveraging representation learning we design a technique for imbalanced regression that requires no additional data or labels and improves the performance of our model in rare and challenging poses.","By relying on a unified representation, we show that training such a model is not bound to high-end MoCap training data acquisition, and exploit the advances in marker-less MoCap to acquire the necessary data.","Finally, we take a step towards richer and affordable MoCap by adapting a body model-based inverse kinematics solution to account for measurement and inference uncertainty, further improving performance and robustness.","Project page: https://moverseai.github.io/noise-tail"],"url":"http://arxiv.org/abs/2309.14330v1"}
{"created":"2023-09-25 17:54:29","title":"Innovative Digital Storytelling with AIGC: Exploration and Discussion of Recent Advances","abstract":"Digital storytelling, as an art form, has struggled with cost-quality balance. The emergence of AI-generated Content (AIGC) is considered as a potential solution for efficient digital storytelling production. However, the specific form, effects, and impacts of this fusion remain unclear, leaving the boundaries of AIGC combined with storytelling undefined. This work explores the current integration state of AIGC and digital storytelling, investigates the artistic value of their fusion in a sample project, and addresses common issues through interviews. Through our study, we conclude that AIGC, while proficient in image creation, voiceover production, and music composition, falls short of replacing humans due to the irreplaceable elements of human creativity and aesthetic sensibilities at present, especially in complex character animations, facial expressions, and sound effects. The research objective is to increase public awareness of the current state, limitations, and challenges arising from combining AIGC and digital storytelling.","sentences":["Digital storytelling, as an art form, has struggled with cost-quality balance.","The emergence of AI-generated Content (AIGC) is considered as a potential solution for efficient digital storytelling production.","However, the specific form, effects, and impacts of this fusion remain unclear, leaving the boundaries of AIGC combined with storytelling undefined.","This work explores the current integration state of AIGC and digital storytelling, investigates the artistic value of their fusion in a sample project, and addresses common issues through interviews.","Through our study, we conclude that AIGC, while proficient in image creation, voiceover production, and music composition, falls short of replacing humans due to the irreplaceable elements of human creativity and aesthetic sensibilities at present, especially in complex character animations, facial expressions, and sound effects.","The research objective is to increase public awareness of the current state, limitations, and challenges arising from combining AIGC and digital storytelling."],"url":"http://arxiv.org/abs/2309.14329v1"}
{"created":"2023-09-25 17:53:52","title":"pyParaOcean: A System for Visual Analysis of Ocean Data","abstract":"Visual analysis is well adopted within the field of oceanography for the analysis of model simulations, detection of different phenomena and events, and tracking of dynamic processes. With increasing data sizes and the availability of multivariate dynamic data, there is a growing need for scalable and extensible tools for visualization and interactive exploration. We describe pyParaOcean, a visualization system that supports several tasks routinely used in the visual analysis of ocean data. The system is available as a plugin to Paraview and is hence able to leverage its distributed computing capabilities and its rich set of generic analysis and visualization functionalities. pyParaOcean provides modules to support different visual analysis tasks specific to ocean data, such as eddy identification and salinity movement tracking. These modules are available as Paraview filters and this seamless integration results in a system that is easy to install and use. A case study on the Bay of Bengal illustrates the utility of the system for the study of ocean phenomena and processes.","sentences":["Visual analysis is well adopted within the field of oceanography for the analysis of model simulations, detection of different phenomena and events, and tracking of dynamic processes.","With increasing data sizes and the availability of multivariate dynamic data, there is a growing need for scalable and extensible tools for visualization and interactive exploration.","We describe pyParaOcean, a visualization system that supports several tasks routinely used in the visual analysis of ocean data.","The system is available as a plugin to Paraview and is hence able to leverage its distributed computing capabilities and its rich set of generic analysis and visualization functionalities.","pyParaOcean provides modules to support different visual analysis tasks specific to ocean data, such as eddy identification and salinity movement tracking.","These modules are available as Paraview filters and this seamless integration results in a system that is easy to install and use.","A case study on the Bay of Bengal illustrates the utility of the system for the study of ocean phenomena and processes."],"url":"http://arxiv.org/abs/2309.14328v1"}
{"created":"2023-09-25 17:53:29","title":"DeepSpeed-VisualChat: Multi-Round Multi-Image Interleave Chat via Multi-Modal Causal Attention","abstract":"Most of the existing multi-modal models, hindered by their incapacity to adeptly manage interleaved image-and-text inputs in multi-image, multi-round dialogues, face substantial constraints in resource allocation for training and data accessibility, impacting their adaptability and scalability across varied interaction realms. To address this, we present the DeepSpeed-VisualChat framework, designed to optimize Large Language Models (LLMs) by incorporating multi-modal capabilities, with a focus on enhancing the proficiency of Large Vision and Language Models in handling interleaved inputs. Our framework is notable for (1) its open-source support for multi-round and multi-image dialogues, (2) introducing an innovative multi-modal causal attention mechanism, and (3) utilizing data blending techniques on existing datasets to assure seamless interactions in multi-round, multi-image conversations. Compared to existing frameworks, DeepSpeed-VisualChat shows superior scalability up to 70B parameter language model size, representing a significant advancement in multi-modal language models and setting a solid foundation for future explorations.","sentences":["Most of the existing multi-modal models, hindered by their incapacity to adeptly manage interleaved image-and-text inputs in multi-image, multi-round dialogues, face substantial constraints in resource allocation for training and data accessibility, impacting their adaptability and scalability across varied interaction realms.","To address this, we present the DeepSpeed-VisualChat framework, designed to optimize Large Language Models (LLMs) by incorporating multi-modal capabilities, with a focus on enhancing the proficiency of Large Vision and Language Models in handling interleaved inputs.","Our framework is notable for (1) its open-source support for multi-round and multi-image dialogues, (2) introducing an innovative multi-modal causal attention mechanism, and (3) utilizing data blending techniques on existing datasets to assure seamless interactions in multi-round, multi-image conversations.","Compared to existing frameworks, DeepSpeed-VisualChat shows superior scalability up to 70B parameter language model size, representing a significant advancement in multi-modal language models and setting a solid foundation for future explorations."],"url":"http://arxiv.org/abs/2309.14327v1"}
{"created":"2023-09-25 17:49:35","title":"Cluster Language Model for Improved E-Commerce Retrieval and Ranking: Leveraging Query Similarity and Fine-Tuning for Personalized Results","abstract":"This paper proposes a novel method to improve the accuracy of product search in e-commerce by utilizing a cluster language model. The method aims to address the limitations of the bi-encoder architecture while maintaining a minimal additional training burden. The approach involves labeling top products for each query, generating semantically similar query clusters using the K-Means clustering algorithm, and fine-tuning a global language model into cluster language models on individual clusters. The parameters of each cluster language model are fine-tuned to learn local manifolds in the feature space efficiently, capturing the nuances of various query types within each cluster. The inference is performed by assigning a new query to its respective cluster and utilizing the corresponding cluster language model for retrieval. The proposed method results in more accurate and personalized retrieval results, offering a superior alternative to the popular bi-encoder based retrieval models in semantic search.","sentences":["This paper proposes a novel method to improve the accuracy of product search in e-commerce by utilizing a cluster language model.","The method aims to address the limitations of the bi-encoder architecture while maintaining a minimal additional training burden.","The approach involves labeling top products for each query, generating semantically similar query clusters using the K-Means clustering algorithm, and fine-tuning a global language model into cluster language models on individual clusters.","The parameters of each cluster language model are fine-tuned to learn local manifolds in the feature space efficiently, capturing the nuances of various query types within each cluster.","The inference is performed by assigning a new query to its respective cluster and utilizing the corresponding cluster language model for retrieval.","The proposed method results in more accurate and personalized retrieval results, offering a superior alternative to the popular bi-encoder based retrieval models in semantic search."],"url":"http://arxiv.org/abs/2309.14323v1"}
{"created":"2023-09-25 17:48:51","title":"Small-scale proxies for large-scale Transformer training instabilities","abstract":"Teams that have trained large Transformer-based models have reported training instabilities at large scale that did not appear when training with the same hyperparameters at smaller scales. Although the causes of such instabilities are of scientific interest, the amount of resources required to reproduce them has made investigation difficult. In this work, we seek ways to reproduce and study training stability and instability at smaller scales. First, we focus on two sources of training instability described in previous work: the growth of logits in attention layers (Dehghani et al., 2023) and divergence of the output logits from the log probabilities (Chowdhery et al., 2022). By measuring the relationship between learning rate and loss across scales, we show that these instabilities also appear in small models when training at high learning rates, and that mitigations previously employed at large scales are equally effective in this regime. This prompts us to investigate the extent to which other known optimizer and model interventions influence the sensitivity of the final loss to changes in the learning rate. To this end, we study methods such as warm-up, weight decay, and the $\\mu$Param (Yang et al., 2022), and combine techniques to train small models that achieve similar losses across orders of magnitude of learning rate variation. Finally, to conclude our exploration we study two cases where instabilities can be predicted before they emerge by examining the scaling behavior of model activation and gradient norms.","sentences":["Teams that have trained large Transformer-based models have reported training instabilities at large scale that did not appear when training with the same hyperparameters at smaller scales.","Although the causes of such instabilities are of scientific interest, the amount of resources required to reproduce them has made investigation difficult.","In this work, we seek ways to reproduce and study training stability and instability at smaller scales.","First, we focus on two sources of training instability described in previous work: the growth of logits in attention layers (Dehghani et al., 2023) and divergence of the output logits from the log probabilities (Chowdhery et al., 2022).","By measuring the relationship between learning rate and loss across scales, we show that these instabilities also appear in small models when training at high learning rates, and that mitigations previously employed at large scales are equally effective in this regime.","This prompts us to investigate the extent to which other known optimizer and model interventions influence the sensitivity of the final loss to changes in the learning rate.","To this end, we study methods such as warm-up, weight decay, and the $\\mu$Param (Yang et al., 2022), and combine techniques to train small models that achieve similar losses across orders of magnitude of learning rate variation.","Finally, to conclude our exploration we study two cases where instabilities can be predicted before they emerge by examining the scaling behavior of model activation and gradient norms."],"url":"http://arxiv.org/abs/2309.14322v1"}
{"created":"2023-09-25 17:45:55","title":"Human-Assisted Continual Robot Learning with Foundation Models","abstract":"Large Language Models (LLMs) have been shown to act like planners that can decompose high-level instructions into a sequence of executable instructions. However, current LLM-based planners are only able to operate with a fixed set of skills. We overcome this critical limitation and present a method for using LLM-based planners to query new skills and teach robots these skills in a data and time-efficient manner for rigid object manipulation. Our system can re-use newly acquired skills for future tasks, demonstrating the potential of open world and lifelong learning. We evaluate the proposed framework on multiple tasks in simulation and the real world. Videos are available at: https://sites.google.com/mit.edu/halp-robot-learning.","sentences":["Large Language Models (LLMs) have been shown to act like planners that can decompose high-level instructions into a sequence of executable instructions.","However, current LLM-based planners are only able to operate with a fixed set of skills.","We overcome this critical limitation and present a method for using LLM-based planners to query new skills and teach robots these skills in a data and time-efficient manner for rigid object manipulation.","Our system can re-use newly acquired skills for future tasks, demonstrating the potential of open world and lifelong learning.","We evaluate the proposed framework on multiple tasks in simulation and the real world.","Videos are available at: https://sites.google.com/mit.edu/halp-robot-learning."],"url":"http://arxiv.org/abs/2309.14321v1"}
{"created":"2023-09-25 17:45:31","title":"MUTEX: Learning Unified Policies from Multimodal Task Specifications","abstract":"Humans use different modalities, such as speech, text, images, videos, etc., to communicate their intent and goals with teammates. For robots to become better assistants, we aim to endow them with the ability to follow instructions and understand tasks specified by their human partners. Most robotic policy learning methods have focused on one single modality of task specification while ignoring the rich cross-modal information. We present MUTEX, a unified approach to policy learning from multimodal task specifications. It trains a transformer-based architecture to facilitate cross-modal reasoning, combining masked modeling and cross-modal matching objectives in a two-stage training procedure. After training, MUTEX can follow a task specification in any of the six learned modalities (video demonstrations, goal images, text goal descriptions, text instructions, speech goal descriptions, and speech instructions) or a combination of them. We systematically evaluate the benefits of MUTEX in a newly designed dataset with 100 tasks in simulation and 50 tasks in the real world, annotated with multiple instances of task specifications in different modalities, and observe improved performance over methods trained specifically for any single modality. More information at https://ut-austin-rpl.github.io/MUTEX/","sentences":["Humans use different modalities, such as speech, text, images, videos, etc., to communicate their intent and goals with teammates.","For robots to become better assistants, we aim to endow them with the ability to follow instructions and understand tasks specified by their human partners.","Most robotic policy learning methods have focused on one single modality of task specification while ignoring the rich cross-modal information.","We present MUTEX, a unified approach to policy learning from multimodal task specifications.","It trains a transformer-based architecture to facilitate cross-modal reasoning, combining masked modeling and cross-modal matching objectives in a two-stage training procedure.","After training, MUTEX can follow a task specification in any of the six learned modalities (video demonstrations, goal images, text goal descriptions, text instructions, speech goal descriptions, and speech instructions) or a combination of them.","We systematically evaluate the benefits of MUTEX in a newly designed dataset with 100 tasks in simulation and 50 tasks in the real world, annotated with multiple instances of task specifications in different modalities, and observe improved performance over methods trained specifically for any single modality.","More information at https://ut-austin-rpl.github.io/MUTEX/"],"url":"http://arxiv.org/abs/2309.14320v1"}
{"created":"2023-09-25 17:38:21","title":"Online and Offline Dynamic Influence Maximization Games Over Social Networks","abstract":"In this work, we consider dynamic influence maximization games over social networks with multiple players (influencers). The goal of each influencer is to maximize their own reward subject to their limited total budget rate constraints. Thus, influencers need to carefully design their investment policies considering individuals' opinion dynamics and other influencers' investment strategies, leading to a dynamic game problem. We first consider the case of a single influencer who wants to maximize its utility subject to a total budget rate constraint. We study both offline and online versions of the problem where the opinion dynamics are either known or not known a priori. In the singe-influencer case, we propose an online no-regret algorithm, meaning that as the number of campaign opportunities grows, the average utilities obtained by the offline and online solutions converge. Then, we consider the game formulation with multiple influencers in offline and online settings. For the offline setting, we show that the dynamic game admits a unique Nash equilibrium policy and provide a method to compute it. For the online setting and with two influencers, we show that if each influencer applies the same no-regret online algorithm proposed for the single-influencer maximization problem, they will converge to the set of $\\epsilon$-Nash equilibrium policies where $\\epsilon=O(\\frac{1}{\\sqrt{K}})$ scales in average inversely with the number of campaign times $K$ considering the average utilities of the influencers. Moreover, we extend this result to any finite number of influencers under more strict requirements on the information structure. Finally, we provide numerical analysis to validate our results under various settings.","sentences":["In this work, we consider dynamic influence maximization games over social networks with multiple players (influencers).","The goal of each influencer is to maximize their own reward subject to their limited total budget rate constraints.","Thus, influencers need to carefully design their investment policies considering individuals' opinion dynamics and other influencers' investment strategies, leading to a dynamic game problem.","We first consider the case of a single influencer who wants to maximize its utility subject to a total budget rate constraint.","We study both offline and online versions of the problem where the opinion dynamics are either known or not known a priori.","In the singe-influencer case, we propose an online no-regret algorithm, meaning that as the number of campaign opportunities grows, the average utilities obtained by the offline and online solutions converge.","Then, we consider the game formulation with multiple influencers in offline and online settings.","For the offline setting, we show that the dynamic game admits a unique Nash equilibrium policy and provide a method to compute it.","For the online setting and with two influencers, we show that if each influencer applies the same no-regret online algorithm proposed for the single-influencer maximization problem, they will converge to the set of $\\epsilon$-Nash equilibrium policies where $\\epsilon=O(\\frac{1}{\\sqrt{K}})$ scales in average inversely with the number of campaign times $K$ considering the average utilities of the influencers.","Moreover, we extend this result to any finite number of influencers under more strict requirements on the information structure.","Finally, we provide numerical analysis to validate our results under various settings."],"url":"http://arxiv.org/abs/2309.14317v1"}
{"created":"2023-09-25 17:37:20","title":"Physics of Language Models: Part 3.1, Knowledge Storage and Extraction","abstract":"Large language models can store extensive world knowledge, often extractable through question-answering (e.g., \"What is Abraham Lincoln's birthday?\"). However, it's unclear whether the model answers questions based on exposure to exact/similar questions during training, or if it genuinely extracts knowledge from the source (e.g., Wikipedia biographies).   In this paper, we conduct an in-depth study of this problem using a controlled set of semi-synthetic biography data. We uncover a relationship between the model's knowledge extraction ability and different diversity measures of the training data. We conduct (nearly) linear probing, revealing a strong correlation between this relationship and whether the model (nearly) linearly encodes the knowledge attributes at the hidden embedding of the entity names, or across the embeddings of other tokens in the training text.","sentences":["Large language models can store extensive world knowledge, often extractable through question-answering (e.g., \"What is Abraham Lincoln's birthday?\").","However, it's unclear whether the model answers questions based on exposure to exact/similar questions during training, or if it genuinely extracts knowledge from the source (e.g., Wikipedia biographies).   ","In this paper, we conduct an in-depth study of this problem using a controlled set of semi-synthetic biography data.","We uncover a relationship between the model's knowledge extraction ability and different diversity measures of the training data.","We conduct (nearly) linear probing, revealing a strong correlation between this relationship and whether the model (nearly) linearly encodes the knowledge attributes at the hidden embedding of the entity names, or across the embeddings of other tokens in the training text."],"url":"http://arxiv.org/abs/2309.14316v1"}
{"created":"2023-09-25 17:30:47","title":"Parallelizing a 1-Dim Nagel-Schreckenberg Traffic Model","abstract":"The Nagel-Schreckenberg model is a stochastic one-dimensional traffic model. In this assignment, we guide students through the process of implementing a shared-memory parallel and reproducible version of an existing serial code that implements this model, and to analyze its scaling behavior. One of the key elements in this traffic model is the presence of randomness, without which it would lack realistic phenomena such as traffic jams. Its implementation thus requires techniques associated with Monte Carlo simulations and pseudo-random number generation (PRNG). PRNGs are notoriously tricky to deal with in parallel when combined with the requirement of reproducibility.   This assignment was created for the graduate course PHY1610 Scientific Computing for Physicists at the University of Toronto, which had its origin in the training program of the SciNet HPC Consortium, and is also very suitable for other scientific disciplines. Several variations of the assignment have been used over the years.","sentences":["The Nagel-Schreckenberg model is a stochastic one-dimensional traffic model.","In this assignment, we guide students through the process of implementing a shared-memory parallel and reproducible version of an existing serial code that implements this model, and to analyze its scaling behavior.","One of the key elements in this traffic model is the presence of randomness, without which it would lack realistic phenomena such as traffic jams.","Its implementation thus requires techniques associated with Monte Carlo simulations and pseudo-random number generation (PRNG).","PRNGs are notoriously tricky to deal with in parallel when combined with the requirement of reproducibility.   ","This assignment was created for the graduate course PHY1610 Scientific Computing for Physicists at the University of Toronto, which had its origin in the training program of the SciNet HPC Consortium, and is also very suitable for other scientific disciplines.","Several variations of the assignment have been used over the years."],"url":"http://arxiv.org/abs/2309.14311v1"}
{"created":"2023-09-25 17:28:28","title":"Multiple Different Explanations for Image Classifiers","abstract":"Existing explanation tools for image classifiers usually give only one single explanation for an image. For many images, however, both humans and image classifiers accept more than one explanation for the image label. Thus, restricting the number of explanations to just one severely limits the insight into the behavior of the classifier. In this paper, we describe an algorithm and a tool, REX, for computing multiple explanations of the output of a black-box image classifier for a given image. Our algorithm uses a principled approach based on causal theory. We analyse its theoretical complexity and provide experimental results showing that REX finds multiple explanations on 7 times more images than the previous work on the ImageNet-mini benchmark.","sentences":["Existing explanation tools for image classifiers usually give only one single explanation for an image.","For many images, however, both humans and image classifiers accept more than one explanation for the image label.","Thus, restricting the number of explanations to just one severely limits the insight into the behavior of the classifier.","In this paper, we describe an algorithm and a tool, REX, for computing multiple explanations of the output of a black-box image classifier for a given image.","Our algorithm uses a principled approach based on causal theory.","We analyse its theoretical complexity and provide experimental results showing that REX finds multiple explanations on 7 times more images than the previous work on the ImageNet-mini benchmark."],"url":"http://arxiv.org/abs/2309.14309v1"}
{"created":"2023-09-25 17:25:39","title":"A post-selection algorithm for improving dynamic ensemble selection methods","abstract":"Dynamic Ensemble Selection (DES) is a Multiple Classifier Systems (MCS) approach that aims to select an ensemble for each query sample during the selection phase. Even with the proposal of several DES approaches, no particular DES technique is the best choice for different problems. Thus, we hypothesize that selecting the best DES approach per query instance can lead to better accuracy. To evaluate this idea, we introduce the Post-Selection Dynamic Ensemble Selection (PS-DES) approach, a post-selection scheme that evaluates ensembles selected by several DES techniques using different metrics. Experimental results show that using accuracy as a metric to select the ensembles, PS-DES performs better than individual DES techniques. PS-DES source code is available in a GitHub repository","sentences":["Dynamic Ensemble Selection (DES) is a Multiple Classifier Systems (MCS) approach that aims to select an ensemble for each query sample during the selection phase.","Even with the proposal of several DES approaches, no particular DES technique is the best choice for different problems.","Thus, we hypothesize that selecting the best DES approach per query instance can lead to better accuracy.","To evaluate this idea, we introduce the Post-Selection Dynamic Ensemble Selection (PS-DES) approach, a post-selection scheme that evaluates ensembles selected by several DES techniques using different metrics.","Experimental results show that using accuracy as a metric to select the ensembles, PS-DES performs better than individual DES techniques.","PS-DES source code is available in a GitHub repository"],"url":"http://arxiv.org/abs/2309.14307v1"}
{"created":"2023-09-25 17:20:51","title":"Overview of Class Activation Maps for Visualization Explainability","abstract":"Recent research in deep learning methodology has led to a variety of complex modelling techniques in computer vision (CV) that reach or even outperform human performance. Although these black-box deep learning models have obtained astounding results, they are limited in their interpretability and transparency which are critical to take learning machines to the next step to include them in sensitive decision-support systems involving human supervision. Hence, the development of explainable techniques for computer vision (XCV) has recently attracted increasing attention. In the realm of XCV, Class Activation Maps (CAMs) have become widely recognized and utilized for enhancing interpretability and insights into the decision-making process of deep learning models. This work presents a comprehensive overview of the evolution of Class Activation Map methods over time. It also explores the metrics used for evaluating CAMs and introduces auxiliary techniques to improve the saliency of these methods. The overview concludes by proposing potential avenues for future research in this evolving field.","sentences":["Recent research in deep learning methodology has led to a variety of complex modelling techniques in computer vision (CV) that reach or even outperform human performance.","Although these black-box deep learning models have obtained astounding results, they are limited in their interpretability and transparency which are critical to take learning machines to the next step to include them in sensitive decision-support systems involving human supervision.","Hence, the development of explainable techniques for computer vision (XCV) has recently attracted increasing attention.","In the realm of XCV, Class Activation Maps (CAMs) have become widely recognized and utilized for enhancing interpretability and insights into the decision-making process of deep learning models.","This work presents a comprehensive overview of the evolution of Class Activation Map methods over time.","It also explores the metrics used for evaluating CAMs and introduces auxiliary techniques to improve the saliency of these methods.","The overview concludes by proposing potential avenues for future research in this evolving field."],"url":"http://arxiv.org/abs/2309.14304v1"}
{"created":"2023-09-25 17:19:26","title":"Dataset Diffusion: Diffusion-based Synthetic Dataset Generation for Pixel-Level Semantic Segmentation","abstract":"Preparing training data for deep vision models is a labor-intensive task. To address this, generative models have emerged as an effective solution for generating synthetic data. While current generative models produce image-level category labels, we propose a novel method for generating pixel-level semantic segmentation labels using the text-to-image generative model Stable Diffusion (SD). By utilizing the text prompts, cross-attention, and self-attention of SD, we introduce three new techniques: \\textit{class-prompt appending}, \\textit{class-prompt cross-attention}, and \\textit{self-attention exponentiation}. These techniques enable us to generate segmentation maps corresponding to synthetic images. These maps serve as pseudo-labels for training semantic segmenters, eliminating the need for labor-intensive pixel-wise annotation. To account for the imperfections in our pseudo-labels, we incorporate uncertainty regions into the segmentation, allowing us to disregard loss from those regions. We conduct evaluations on two datasets, PASCAL VOC and MSCOCO, and our approach significantly outperforms concurrent work. Our benchmarks and code will be released at https://github.com/VinAIResearch/Dataset-Diffusion","sentences":["Preparing training data for deep vision models is a labor-intensive task.","To address this, generative models have emerged as an effective solution for generating synthetic data.","While current generative models produce image-level category labels, we propose a novel method for generating pixel-level semantic segmentation labels using the text-to-image generative model Stable Diffusion (SD).","By utilizing the text prompts, cross-attention, and self-attention of SD, we introduce three new techniques: \\textit{class-prompt appending}, \\textit{class-prompt cross-attention}, and \\textit{self-attention exponentiation}.","These techniques enable us to generate segmentation maps corresponding to synthetic images.","These maps serve as pseudo-labels for training semantic segmenters, eliminating the need for labor-intensive pixel-wise annotation.","To account for the imperfections in our pseudo-labels, we incorporate uncertainty regions into the segmentation, allowing us to disregard loss from those regions.","We conduct evaluations on two datasets, PASCAL VOC and MSCOCO, and our approach significantly outperforms concurrent work.","Our benchmarks and code will be released at https://github.com/VinAIResearch/Dataset-Diffusion"],"url":"http://arxiv.org/abs/2309.14303v1"}
{"created":"2023-09-25 17:10:16","title":"Unwieldy Object Delivery with Nonholonomic Mobile Base: A Stable Pushing Approach","abstract":"This paper addresses the problem of pushing manipulation with nonholonomic mobile robots. Pushing is a fundamental skill that enables robots to move unwieldy objects that cannot be grasped. We propose a stable pushing method that maintains stiff contact between the robot and the object to avoid consuming repositioning actions. We prove that a line contact, rather than a single point contact, is necessary for nonholonomic robots to achieve stable pushing. We also show that the stable pushing constraint and the nonholonomic constraint of the robot can be simplified as a concise linear motion constraint. Then the pushing planning problem can be formulated as a constrained optimization problem using nonlinear model predictive control (NMPC). According to the experiments, our NMPC-based planner outperforms a reactive pushing strategy in terms of efficiency, reducing the robot's traveled distance by 23.8\\% and time by 77.4\\%. Furthermore, our method requires four fewer hyperparameters and decision variables than the Linear Time-Varying (LTV) MPC approach, making it easier to implement. Real-world experiments are carried out to validate the proposed method with two differential-drive robots, Husky and Boxer, under different friction conditions.","sentences":["This paper addresses the problem of pushing manipulation with nonholonomic mobile robots.","Pushing is a fundamental skill that enables robots to move unwieldy objects that cannot be grasped.","We propose a stable pushing method that maintains stiff contact between the robot and the object to avoid consuming repositioning actions.","We prove that a line contact, rather than a single point contact, is necessary for nonholonomic robots to achieve stable pushing.","We also show that the stable pushing constraint and the nonholonomic constraint of the robot can be simplified as a concise linear motion constraint.","Then the pushing planning problem can be formulated as a constrained optimization problem using nonlinear model predictive control (NMPC).","According to the experiments, our NMPC-based planner outperforms a reactive pushing strategy in terms of efficiency, reducing the robot's traveled distance by 23.8\\% and time by 77.4\\%.","Furthermore, our method requires four fewer hyperparameters and decision variables than the Linear Time-Varying (LTV) MPC approach, making it easier to implement.","Real-world experiments are carried out to validate the proposed method with two differential-drive robots, Husky and Boxer, under different friction conditions."],"url":"http://arxiv.org/abs/2309.14295v1"}
{"created":"2023-09-25 17:04:30","title":"NAS-NeRF: Generative Neural Architecture Search for Neural Radiance Fields","abstract":"Neural radiance fields (NeRFs) enable high-quality novel view synthesis, but their prohibitively high computational complexity limits deployability, especially on resource-constrained platforms. To enable practical usage of NeRFs, quality tuning is essential to reduce computational complexity, akin to adjustable graphics settings in video games. However while existing solutions strive for efficiency, they use one-size-fits-all architectures regardless of scene complexity, although the same architecture may be unnecessarily large for simple scenes but insufficient for complex ones. Thus as NeRFs become more widely used for 3D visualization, there is a need to dynamically optimize the neural network component of NeRFs to achieve a balance between computational complexity and specific targets for synthesis quality. Addressing this gap, we introduce NAS-NeRF: a generative neural architecture search strategy uniquely tailored to generate NeRF architectures on a per-scene basis by optimizing the trade-off between complexity and performance, while adhering to constraints on computational budget and minimum synthesis quality. Our experiments on the Blender synthetic dataset show the proposed NAS-NeRF can generate architectures up to 5.74$\\times$ smaller, with 4.19$\\times$ fewer FLOPs, and 1.93$\\times$ faster on a GPU than baseline NeRFs, without suffering a drop in SSIM. Furthermore, we illustrate that NAS-NeRF can also achieve architectures up to 23$\\times$ smaller, 22$\\times$ fewer FLOPs, and 4.7$\\times$ faster than baseline NeRFs with only a 5.3\\% average SSIM drop. The source code for our work is also made publicly available at https://saeejithnair.github.io/NAS-NeRF.","sentences":["Neural radiance fields (NeRFs) enable high-quality novel view synthesis, but their prohibitively high computational complexity limits deployability, especially on resource-constrained platforms.","To enable practical usage of NeRFs, quality tuning is essential to reduce computational complexity, akin to adjustable graphics settings in video games.","However while existing solutions strive for efficiency, they use one-size-fits-all architectures regardless of scene complexity, although the same architecture may be unnecessarily large for simple scenes but insufficient for complex ones.","Thus as NeRFs become more widely used for 3D visualization, there is a need to dynamically optimize the neural network component of NeRFs to achieve a balance between computational complexity and specific targets for synthesis quality.","Addressing this gap, we introduce NAS-NeRF: a generative neural architecture search strategy uniquely tailored to generate NeRF architectures on a per-scene basis by optimizing the trade-off between complexity and performance, while adhering to constraints on computational budget and minimum synthesis quality.","Our experiments on the Blender synthetic dataset show the proposed NAS-NeRF can generate architectures up to 5.74$\\times$ smaller, with 4.19$\\times$ fewer FLOPs, and 1.93$\\times$ faster on a GPU than baseline NeRFs, without suffering a drop in SSIM.","Furthermore, we illustrate that NAS-NeRF can also achieve architectures up to 23$\\times$ smaller, 22$\\times$ fewer FLOPs, and 4.7$\\times$ faster than baseline NeRFs with only a 5.3\\% average SSIM drop.","The source code for our work is also made publicly available at https://saeejithnair.github.io/NAS-NeRF."],"url":"http://arxiv.org/abs/2309.14293v1"}
{"created":"2023-09-25 17:04:09","title":"On the Non-Associativity of Analog Computations","abstract":"The energy efficiency of analog forms of computing makes it one of the most promising candidates to deploy resource-hungry machine learning tasks on resource-constrained system such as mobile or embedded devices. However, it is well known that for analog computations the safety net of discretization is missing, thus all analog computations are exposed to a variety of imperfections of corresponding implementations. Examples include non-linearities, saturation effect and various forms of noise. In this work, we observe that the ordering of input operands of an analog operation also has an impact on the output result, which essentially makes analog computations non-associative, even though the underlying operation might be mathematically associative. We conduct a simple test by creating a model of a real analog processor which captures such ordering effects. With this model we assess the importance of ordering by comparing the test accuracy of a neural network for keyword spotting, which is trained based either on an ordered model, on a non-ordered variant, and on real hardware. The results prove the existence of ordering effects as well as their high impact, as neglecting ordering results in substantial accuracy drops.","sentences":["The energy efficiency of analog forms of computing makes it one of the most promising candidates to deploy resource-hungry machine learning tasks on resource-constrained system such as mobile or embedded devices.","However, it is well known that for analog computations the safety net of discretization is missing, thus all analog computations are exposed to a variety of imperfections of corresponding implementations.","Examples include non-linearities, saturation effect and various forms of noise.","In this work, we observe that the ordering of input operands of an analog operation also has an impact on the output result, which essentially makes analog computations non-associative, even though the underlying operation might be mathematically associative.","We conduct a simple test by creating a model of a real analog processor which captures such ordering effects.","With this model we assess the importance of ordering by comparing the test accuracy of a neural network for keyword spotting, which is trained based either on an ordered model, on a non-ordered variant, and on real hardware.","The results prove the existence of ordering effects as well as their high impact, as neglecting ordering results in substantial accuracy drops."],"url":"http://arxiv.org/abs/2309.14292v1"}
{"created":"2023-09-25 16:56:40","title":"Tiled Multiplane Images for Practical 3D Photography","abstract":"The task of synthesizing novel views from a single image has useful applications in virtual reality and mobile computing, and a number of approaches to the problem have been proposed in recent years. A Multiplane Image (MPI) estimates the scene as a stack of RGBA layers, and can model complex appearance effects, anti-alias depth errors and synthesize soft edges better than methods that use textured meshes or layered depth images. And unlike neural radiance fields, an MPI can be efficiently rendered on graphics hardware. However, MPIs are highly redundant and require a large number of depth layers to achieve plausible results. Based on the observation that the depth complexity in local image regions is lower than that over the entire image, we split an MPI into many small, tiled regions, each with only a few depth planes. We call this representation a Tiled Multiplane Image (TMPI). We propose a method for generating a TMPI with adaptive depth planes for single-view 3D photography in the wild. Our synthesized results are comparable to state-of-the-art single-view MPI methods while having lower computational overhead.","sentences":["The task of synthesizing novel views from a single image has useful applications in virtual reality and mobile computing, and a number of approaches to the problem have been proposed in recent years.","A Multiplane Image (MPI) estimates the scene as a stack of RGBA layers, and can model complex appearance effects, anti-alias depth errors and synthesize soft edges better than methods that use textured meshes or layered depth images.","And unlike neural radiance fields, an MPI can be efficiently rendered on graphics hardware.","However, MPIs are highly redundant and require a large number of depth layers to achieve plausible results.","Based on the observation that the depth complexity in local image regions is lower than that over the entire image, we split an MPI into many small, tiled regions, each with only a few depth planes.","We call this representation a Tiled Multiplane Image (TMPI).","We propose a method for generating a TMPI with adaptive depth planes for single-view 3D photography in the wild.","Our synthesized results are comparable to state-of-the-art single-view MPI methods while having lower computational overhead."],"url":"http://arxiv.org/abs/2309.14291v1"}
{"created":"2023-09-25 16:53:37","title":"Automated Market Makers for Cross-chain DeFi and Sharded Blockchains","abstract":"In this paper we provide an execution framework for Automated Market Maker (AMM) to be deployed across independent blockchain platforms as well as concurrent sharding within the same blockchain platform. The framework provides economic incentives to participate through a mechanism that guarantee fixed prices across pairwise liquidity pools.","sentences":["In this paper we provide an execution framework for Automated Market Maker (AMM) to be deployed across independent blockchain platforms as well as concurrent sharding within the same blockchain platform.","The framework provides economic incentives to participate through a mechanism that guarantee fixed prices across pairwise liquidity pools."],"url":"http://arxiv.org/abs/2309.14290v1"}
{"created":"2023-09-25 16:52:59","title":"CLIP-DIY: CLIP Dense Inference Yields Open-Vocabulary Semantic Segmentation For-Free","abstract":"The emergence of CLIP has opened the way for open-world image perception. The zero-shot classification capabilities of the model are impressive but are harder to use for dense tasks such as image segmentation. Several methods have proposed different modifications and learning schemes to produce dense output. Instead, we propose in this work an open-vocabulary semantic segmentation method, dubbed CLIP-DIY, which does not require any additional training or annotations, but instead leverages existing unsupervised object localization approaches. In particular, CLIP-DIY is a multi-scale approach that directly exploits CLIP classification abilities on patches of different sizes and aggregates the decision in a single map. We further guide the segmentation using foreground/background scores obtained using unsupervised object localization methods. With our method, we obtain state-of-the-art zero-shot semantic segmentation results on PASCAL VOC and perform on par with the best methods on COCO.","sentences":["The emergence of CLIP has opened the way for open-world image perception.","The zero-shot classification capabilities of the model are impressive but are harder to use for dense tasks such as image segmentation.","Several methods have proposed different modifications and learning schemes to produce dense output.","Instead, we propose in this work an open-vocabulary semantic segmentation method, dubbed CLIP-DIY, which does not require any additional training or annotations, but instead leverages existing unsupervised object localization approaches.","In particular, CLIP-DIY is a multi-scale approach that directly exploits CLIP classification abilities on patches of different sizes and aggregates the decision in a single map.","We further guide the segmentation using foreground/background scores obtained using unsupervised object localization methods.","With our method, we obtain state-of-the-art zero-shot semantic segmentation results on PASCAL VOC and perform on par with the best methods on COCO."],"url":"http://arxiv.org/abs/2309.14289v1"}
{"created":"2023-09-25 16:48:09","title":"Calibration-based Dual Prototypical Contrastive Learning Approach for Domain Generalization Semantic Segmentation","abstract":"Prototypical contrastive learning (PCL) has been widely used to learn class-wise domain-invariant features recently. These methods are based on the assumption that the prototypes, which are represented as the central value of the same class in a certain domain, are domain-invariant. Since the prototypes of different domains have discrepancies as well, the class-wise domain-invariant features learned from the source domain by PCL need to be aligned with the prototypes of other domains simultaneously. However, the prototypes of the same class in different domains may be different while the prototypes of different classes may be similar, which may affect the learning of class-wise domain-invariant features. Based on these observations, a calibration-based dual prototypical contrastive learning (CDPCL) approach is proposed to reduce the domain discrepancy between the learned class-wise features and the prototypes of different domains for domain generalization semantic segmentation. It contains an uncertainty-guided PCL (UPCL) and a hard-weighted PCL (HPCL). Since the domain discrepancies of the prototypes of different classes may be different, we propose an uncertainty probability matrix to represent the domain discrepancies of the prototypes of all the classes. The UPCL estimates the uncertainty probability matrix to calibrate the weights of the prototypes during the PCL. Moreover, considering that the prototypes of different classes may be similar in some circumstances, which means these prototypes are hard-aligned, the HPCL is proposed to generate a hard-weighted matrix to calibrate the weights of the hard-aligned prototypes during the PCL. Extensive experiments demonstrate that our approach achieves superior performance over current approaches on domain generalization semantic segmentation tasks.","sentences":["Prototypical contrastive learning (PCL) has been widely used to learn class-wise domain-invariant features recently.","These methods are based on the assumption that the prototypes, which are represented as the central value of the same class in a certain domain, are domain-invariant.","Since the prototypes of different domains have discrepancies as well, the class-wise domain-invariant features learned from the source domain by PCL need to be aligned with the prototypes of other domains simultaneously.","However, the prototypes of the same class in different domains may be different while the prototypes of different classes may be similar, which may affect the learning of class-wise domain-invariant features.","Based on these observations, a calibration-based dual prototypical contrastive learning (CDPCL) approach is proposed to reduce the domain discrepancy between the learned class-wise features and the prototypes of different domains for domain generalization semantic segmentation.","It contains an uncertainty-guided PCL (UPCL) and a hard-weighted PCL (HPCL).","Since the domain discrepancies of the prototypes of different classes may be different, we propose an uncertainty probability matrix to represent the domain discrepancies of the prototypes of all the classes.","The UPCL estimates the uncertainty probability matrix to calibrate the weights of the prototypes during the PCL.","Moreover, considering that the prototypes of different classes may be similar in some circumstances, which means these prototypes are hard-aligned, the HPCL is proposed to generate a hard-weighted matrix to calibrate the weights of the hard-aligned prototypes during the PCL.","Extensive experiments demonstrate that our approach achieves superior performance over current approaches on domain generalization semantic segmentation tasks."],"url":"http://arxiv.org/abs/2309.14282v1"}
{"created":"2023-09-25 16:42:23","title":"Spring-IMU Fusion Based Proprioception for Feedback Control of Soft Manipulators","abstract":"This paper presents a novel framework to realize proprioception and closed-loop control for soft manipulators. Deformations with large elongation and large bending can be precisely predicted using geometry-based sensor signals obtained from the inductive springs and the inertial measurement units (IMUs) with the help of machine learning techniques. Multiple geometric signals are fused into robust pose estimations, and a data-efficient training process is achieved after applying the strategy of sim-to-real transfer. As a result, we can achieve proprioception that is robust to the variation of external loading and has an average error of 0.7% across the workspace on a pneumatic-driven soft manipulator. The realized proprioception on soft manipulator is then contributed to building a sensor-space based algorithm for closed-loop control. A gradient descent solver is developed to drive the end-effector to achieve the required poses by iteratively computing a sequence of reference sensor signals. A conventional controller is employed in the inner loop of our algorithm to update actuators (i.e., the pressures in chambers) for approaching a reference signal in the sensor-space. The systematic function of closed-loop control has been demonstrated in tasks like path following and pick-and-place under different external loads.","sentences":["This paper presents a novel framework to realize proprioception and closed-loop control for soft manipulators.","Deformations with large elongation and large bending can be precisely predicted using geometry-based sensor signals obtained from the inductive springs and the inertial measurement units (IMUs) with the help of machine learning techniques.","Multiple geometric signals are fused into robust pose estimations, and a data-efficient training process is achieved after applying the strategy of sim-to-real transfer.","As a result, we can achieve proprioception that is robust to the variation of external loading and has an average error of 0.7% across the workspace on a pneumatic-driven soft manipulator.","The realized proprioception on soft manipulator is then contributed to building a sensor-space based algorithm for closed-loop control.","A gradient descent solver is developed to drive the end-effector to achieve the required poses by iteratively computing a sequence of reference sensor signals.","A conventional controller is employed in the inner loop of our algorithm to update actuators (i.e., the pressures in chambers) for approaching a reference signal in the sensor-space.","The systematic function of closed-loop control has been demonstrated in tasks like path following and pick-and-place under different external loads."],"url":"http://arxiv.org/abs/2309.14279v1"}
{"created":"2023-09-25 16:40:56","title":"SINCERE: Supervised Information Noise-Contrastive Estimation REvisited","abstract":"The information noise-contrastive estimation (InfoNCE) loss function provides the basis of many self-supervised deep learning methods due to its strong empirical results and theoretic motivation. Previous work suggests a supervised contrastive (SupCon) loss to extend InfoNCE to learn from available class labels. This SupCon loss has been widely-used due to reports of good empirical performance. However, in this work we suggest that the specific SupCon loss formulated by prior work has questionable theoretic justification, because it can encourage images from the same class to repel one another in the learned embedding space. This problematic behavior gets worse as the number of inputs sharing one class label increases. We propose the Supervised InfoNCE REvisited (SINCERE) loss as a remedy. SINCERE is a theoretically justified solution for a supervised extension of InfoNCE that never causes images from the same class to repel one another. We further show that minimizing our new loss is equivalent to maximizing a bound on the KL divergence between class conditional embedding distributions. We compare SINCERE and SupCon losses in terms of learning trajectories during pretraining and in ultimate linear classifier performance after finetuning. Our proposed SINCERE loss better separates embeddings from different classes during pretraining while delivering competitive accuracy.","sentences":["The information noise-contrastive estimation (InfoNCE) loss function provides the basis of many self-supervised deep learning methods due to its strong empirical results and theoretic motivation.","Previous work suggests a supervised contrastive (SupCon) loss to extend InfoNCE to learn from available class labels.","This SupCon loss has been widely-used due to reports of good empirical performance.","However, in this work we suggest that the specific SupCon loss formulated by prior work has questionable theoretic justification, because it can encourage images from the same class to repel one another in the learned embedding space.","This problematic behavior gets worse as the number of inputs sharing one class label increases.","We propose the Supervised InfoNCE REvisited (SINCERE) loss as a remedy.","SINCERE is a theoretically justified solution for a supervised extension of InfoNCE that never causes images from the same class to repel one another.","We further show that minimizing our new loss is equivalent to maximizing a bound on the KL divergence between class conditional embedding distributions.","We compare SINCERE and SupCon losses in terms of learning trajectories during pretraining and in ultimate linear classifier performance after finetuning.","Our proposed SINCERE loss better separates embeddings from different classes during pretraining while delivering competitive accuracy."],"url":"http://arxiv.org/abs/2309.14277v1"}
{"created":"2023-09-25 16:35:13","title":"ECN with QUIC: Challenges in the Wild","abstract":"TCP and QUIC can both leverage ECN to avoid congestion loss and its retransmission overhead. However, both protocols require support of their remote endpoints and it took two decades since the initial standardization of ECN for TCP to reach 80% ECN support and more in the wild. In contrast, the QUIC standard mandates ECN support, but there are notable ambiguities that make it unclear if and how ECN can actually be used with QUIC on the Internet. Hence, in this paper, we analyze ECN support with QUIC in the wild: We conduct repeated measurements on more than 180M domains to identify HTTP/3 websites and analyze the underlying QUIC connections w.r.t. ECN support. We only find 20% of QUIC hosts, providing 6% of HTTP/3 websites, to mirror client ECN codepoints. Yet, mirroring ECN is only half of what is required for ECN with QUIC, as QUIC validates mirrored ECN codepoints to detect network impairments: We observe that less than 2% of QUIC hosts, providing less than 0.3% of HTTP/3 websites, pass this validation. We identify possible root causes in content providers not supporting ECN via QUIC and network impairments hindering ECN. We thus also characterize ECN with QUIC distributedly to traverse other paths and discuss our results w.r.t. QUIC and ECN innovations beyond QUIC.","sentences":["TCP and QUIC can both leverage ECN to avoid congestion loss and its retransmission overhead.","However, both protocols require support of their remote endpoints and it took two decades since the initial standardization of ECN for TCP to reach 80% ECN support and more in the wild.","In contrast, the QUIC standard mandates ECN support, but there are notable ambiguities that make it unclear if and how ECN can actually be used with QUIC on the Internet.","Hence, in this paper, we analyze ECN support with QUIC in the wild: We conduct repeated measurements on more than 180M domains to identify HTTP/3 websites and analyze the underlying QUIC connections w.r.t.","ECN support.","We only find 20% of QUIC hosts, providing 6% of HTTP/3 websites, to mirror client ECN codepoints.","Yet, mirroring ECN is only half of what is required for ECN with QUIC, as QUIC validates mirrored ECN codepoints to detect network impairments: We observe that less than 2% of QUIC hosts, providing less than 0.3% of HTTP/3 websites, pass this validation.","We identify possible root causes in content providers not supporting ECN via QUIC and network impairments hindering ECN.","We thus also characterize ECN with QUIC distributedly to traverse other paths and discuss our results w.r.t.","QUIC and ECN innovations beyond QUIC."],"url":"http://arxiv.org/abs/2309.14273v1"}
{"created":"2023-09-25 16:34:54","title":"Perception-and-Energy-aware Motion Planning for UAV using Learning-based Model under Heteroscedastic Uncertainty","abstract":"Global navigation satellite systems (GNSS) denied environments/conditions require unmanned aerial vehicles (UAVs) to energy-efficiently and reliably fly. To this end, this study presents perception-and-energy-aware motion planning for UAVs in GNSS-denied environments. The proposed planner solves the trajectory planning problem by optimizing a cost function consisting of two indices: the total energy consumption of a UAV and the perception quality of light detection and ranging (LiDAR) sensor mounted on the UAV. Before online navigation, a high-fidelity simulator acquires a flight dataset to learn energy consumption for the UAV and heteroscedastic uncertainty associated with LiDAR measurements, both as functions of the horizontal velocity of the UAV. The learned models enable the online planner to estimate energy consumption and perception quality, reducing UAV battery usage and localization errors. Simulation experiments in a photorealistic environment confirm that the proposed planner can address the trade-off between energy efficiency and perception quality under heteroscedastic uncertainty. The open-source code is released at https://gitlab.com/ReI08/perception-energy-planner.","sentences":["Global navigation satellite systems (GNSS) denied environments/conditions require unmanned aerial vehicles (UAVs) to energy-efficiently and reliably fly.","To this end, this study presents perception-and-energy-aware motion planning for UAVs in GNSS-denied environments.","The proposed planner solves the trajectory planning problem by optimizing a cost function consisting of two indices: the total energy consumption of a UAV and the perception quality of light detection and ranging (LiDAR) sensor mounted on the UAV.","Before online navigation, a high-fidelity simulator acquires a flight dataset to learn energy consumption for the UAV and heteroscedastic uncertainty associated with LiDAR measurements, both as functions of the horizontal velocity of the UAV.","The learned models enable the online planner to estimate energy consumption and perception quality, reducing UAV battery usage and localization errors.","Simulation experiments in a photorealistic environment confirm that the proposed planner can address the trade-off between energy efficiency and perception quality under heteroscedastic uncertainty.","The open-source code is released at https://gitlab.com/ReI08/perception-energy-planner."],"url":"http://arxiv.org/abs/2309.14272v1"}
{"created":"2023-09-25 16:29:18","title":"Unsupervised correspondence with combined geometric learning and imaging for radiotherapy applications","abstract":"The aim of this study was to develop a model to accurately identify corresponding points between organ segmentations of different patients for radiotherapy applications. A model for simultaneous correspondence and interpolation estimation in 3D shapes was trained with head and neck organ segmentations from planning CT scans. We then extended the original model to incorporate imaging information using two approaches: 1) extracting features directly from image patches, and 2) including the mean square error between patches as part of the loss function. The correspondence and interpolation performance were evaluated using the geodesic error, chamfer distance and conformal distortion metrics, as well as distances between anatomical landmarks. Each of the models produced significantly better correspondences than the baseline non-rigid registration approach. The original model performed similarly to the model with direct inclusion of image features. The best performing model configuration incorporated imaging information as part of the loss function which produced more anatomically plausible correspondences. We will use the best performing model to identify corresponding anatomical points on organs to improve spatial normalisation, an important step in outcome modelling, or as an initialisation for anatomically informed registrations. All our code is publicly available at https://github.com/rrr-uom-projects/Unsup-RT-Corr-Net","sentences":["The aim of this study was to develop a model to accurately identify corresponding points between organ segmentations of different patients for radiotherapy applications.","A model for simultaneous correspondence and interpolation estimation in 3D shapes was trained with head and neck organ segmentations from planning CT scans.","We then extended the original model to incorporate imaging information using two approaches: 1) extracting features directly from image patches, and 2) including the mean square error between patches as part of the loss function.","The correspondence and interpolation performance were evaluated using the geodesic error, chamfer distance and conformal distortion metrics, as well as distances between anatomical landmarks.","Each of the models produced significantly better correspondences than the baseline non-rigid registration approach.","The original model performed similarly to the model with direct inclusion of image features.","The best performing model configuration incorporated imaging information as part of the loss function which produced more anatomically plausible correspondences.","We will use the best performing model to identify corresponding anatomical points on organs to improve spatial normalisation, an important step in outcome modelling, or as an initialisation for anatomically informed registrations.","All our code is publicly available at https://github.com/rrr-uom-projects/Unsup-RT-Corr-Net"],"url":"http://arxiv.org/abs/2309.14269v1"}
{"created":"2023-09-25 16:28:39","title":"Identity-preserving Editing of Multiple Facial Attributes by Learning Global Edit Directions and Local Adjustments","abstract":"Semantic facial attribute editing using pre-trained Generative Adversarial Networks (GANs) has attracted a great deal of attention and effort from researchers in recent years. Due to the high quality of face images generated by StyleGANs, much work has focused on the StyleGANs' latent space and the proposed methods for facial image editing. Although these methods have achieved satisfying results for manipulating user-intended attributes, they have not fulfilled the goal of preserving the identity, which is an important challenge. We present ID-Style, a new architecture capable of addressing the problem of identity loss during attribute manipulation. The key components of ID-Style include Learnable Global Direction (LGD), which finds a shared and semi-sparse direction for each attribute, and an Instance-Aware Intensity Predictor (IAIP) network, which finetunes the global direction according to the input instance. Furthermore, we introduce two losses during training to enforce the LGD to find semi-sparse semantic directions, which along with the IAIP, preserve the identity of the input instance. Despite reducing the size of the network by roughly 95% as compared to similar state-of-the-art works, it outperforms baselines by 10% and 7% in Identity preserving metric (FRS) and average accuracy of manipulation (mACC), respectively.","sentences":["Semantic facial attribute editing using pre-trained Generative Adversarial Networks (GANs) has attracted a great deal of attention and effort from researchers in recent years.","Due to the high quality of face images generated by StyleGANs, much work has focused on the StyleGANs' latent space and the proposed methods for facial image editing.","Although these methods have achieved satisfying results for manipulating user-intended attributes, they have not fulfilled the goal of preserving the identity, which is an important challenge.","We present ID-Style, a new architecture capable of addressing the problem of identity loss during attribute manipulation.","The key components of ID-Style include Learnable Global Direction (LGD), which finds a shared and semi-sparse direction for each attribute, and an Instance-Aware Intensity Predictor (IAIP) network, which finetunes the global direction according to the input instance.","Furthermore, we introduce two losses during training to enforce the LGD to find semi-sparse semantic directions, which along with the IAIP, preserve the identity of the input instance.","Despite reducing the size of the network by roughly 95% as compared to similar state-of-the-art works, it outperforms baselines by 10% and 7% in Identity preserving metric (FRS) and average accuracy of manipulation (mACC), respectively."],"url":"http://arxiv.org/abs/2309.14267v1"}
{"created":"2023-09-25 16:27:51","title":"The Hydra Hand: A Mode-Switching Underactuated Gripper with Precision and Power Grasping Modes","abstract":"Human hands are able to grasp a wide range of object sizes, shapes, and weights, achieved via reshaping and altering their apparent grasping stiffness between compliant power and rigid precision. Achieving similar versatility in robotic hands remains a challenge, which has often been addressed by adding extra controllable degrees of freedom, tactile sensors, or specialised extra grasping hardware, at the cost of control complexity and robustness. We introduce a novel reconfigurable four-fingered two-actuator underactuated gripper -- the Hydra Hand -- that switches between compliant power and rigid precision grasps using a single motor, while generating grasps via a single hydraulic actuator -- exhibiting adaptive grasping between finger pairs, enabling the power grasping of two objects simultaneously. The mode switching mechanism and the hand's kinematics are presented and analysed, and performance is tested on two grasping benchmarks: one focused on rigid objects, and the other on items of clothing. The Hydra Hand is shown to excel at grasping large and irregular objects, and small objects with its respective compliant power and rigid precision configurations. The hand's versatility is then showcased by executing the challenging manipulation task of safely grasping and placing a bunch of grapes, and then plucking a single grape from the bunch.","sentences":["Human hands are able to grasp a wide range of object sizes, shapes, and weights, achieved via reshaping and altering their apparent grasping stiffness between compliant power and rigid precision.","Achieving similar versatility in robotic hands remains a challenge, which has often been addressed by adding extra controllable degrees of freedom, tactile sensors, or specialised extra grasping hardware, at the cost of control complexity and robustness.","We introduce a novel reconfigurable four-fingered two-actuator underactuated gripper -- the Hydra Hand -- that switches between compliant power and rigid precision grasps using a single motor, while generating grasps via a single hydraulic actuator -- exhibiting adaptive grasping between finger pairs, enabling the power grasping of two objects simultaneously.","The mode switching mechanism and the hand's kinematics are presented and analysed, and performance is tested on two grasping benchmarks: one focused on rigid objects, and the other on items of clothing.","The Hydra Hand is shown to excel at grasping large and irregular objects, and small objects with its respective compliant power and rigid precision configurations.","The hand's versatility is then showcased by executing the challenging manipulation task of safely grasping and placing a bunch of grapes, and then plucking a single grape from the bunch."],"url":"http://arxiv.org/abs/2309.14266v1"}
{"created":"2023-09-25 16:23:49","title":"Industrial Application of 6D Pose Estimation for Robotic Manipulation in Automotive Internal Logistics","abstract":"Despite the advances in robotics a large proportion of the of parts handling tasks in the automotive industry's internal logistics are not automated but still performed by humans. A key component to competitively automate these processes is a 6D pose estimation that can handle a large number of different parts, is adaptable to new parts with little manual effort, and is sufficiently accurate and robust with respect to industry requirements. In this context, the question arises as to the current status quo with respect to these measures. To address this we built a representative 6D pose estimation pipeline with state-of-the-art components from economically scalable real to synthetic data generation to pose estimators and evaluated it on automotive parts with regards to a realistic sequencing process. We found that using the data generation approaches, the performance of the trained 6D pose estimators are promising, but do not meet industry requirements. We reveal that the reason for this is the inability of the estimators to provide reliable uncertainties for their poses, rather than the ability of to provide sufficiently accurate poses. In this context we further analyzed how RGB- and RGB-D-based approaches compare against this background and show that they are differently vulnerable to the domain gap induced by synthetic data.","sentences":["Despite the advances in robotics a large proportion of the of parts handling tasks in the automotive industry's internal logistics are not automated but still performed by humans.","A key component to competitively automate these processes is a 6D pose estimation that can handle a large number of different parts, is adaptable to new parts with little manual effort, and is sufficiently accurate and robust with respect to industry requirements.","In this context, the question arises as to the current status quo with respect to these measures.","To address this we built a representative 6D pose estimation pipeline with state-of-the-art components from economically scalable real to synthetic data generation to pose estimators and evaluated it on automotive parts with regards to a realistic sequencing process.","We found that using the data generation approaches, the performance of the trained 6D pose estimators are promising, but do not meet industry requirements.","We reveal that the reason for this is the inability of the estimators to provide reliable uncertainties for their poses, rather than the ability of to provide sufficiently accurate poses.","In this context we further analyzed how RGB- and RGB-D-based approaches compare against this background and show that they are differently vulnerable to the domain gap induced by synthetic data."],"url":"http://arxiv.org/abs/2309.14265v1"}
{"created":"2023-09-25 16:16:11","title":"A Table of Contents for the Front Page of the Internet","abstract":"We create monthly snapshot community embeddings that infer relationships between subreddits, allowing clustering as an intuitive way to explore subreddit communities. Through two annotation tasks, we validate that these subreddit clusterings align well with expert judgements. Although embeddings are created independently from different time periods of data, clusterings produced from monthly snapshots change gradually over time, and the stability of a subreddit's nearest neighbors can be analyzed to understand how that subreddit fits in or evolves relative to other communities on Reddit.","sentences":["We create monthly snapshot community embeddings that infer relationships between subreddits, allowing clustering as an intuitive way to explore subreddit communities.","Through two annotation tasks, we validate that these subreddit clusterings align well with expert judgements.","Although embeddings are created independently from different time periods of data, clusterings produced from monthly snapshots change gradually over time, and the stability of a subreddit's nearest neighbors can be analyzed to understand how that subreddit fits in or evolves relative to other communities on Reddit."],"url":"http://arxiv.org/abs/2309.14259v1"}
{"created":"2023-09-25 16:15:09","title":"OmniEvent: A Comprehensive, Fair, and Easy-to-Use Toolkit for Event Understanding","abstract":"Event understanding aims at understanding the content and relationship of events within texts, which covers multiple complicated information extraction tasks: event detection, event argument extraction, and event relation extraction. To facilitate related research and application, we present an event understanding toolkit OmniEvent, which features three desiderata: (1) Comprehensive. OmniEvent supports mainstream modeling paradigms of all the event understanding tasks and the processing of 15 widely-used English and Chinese datasets. (2) Fair. OmniEvent carefully handles the inconspicuous evaluation pitfalls reported in Peng et al. (2023), which ensures fair comparisons between different models. (3) Easy-to-use. OmniEvent is designed to be easily used by users with varying needs. We provide off-the-shelf models that can be directly deployed as web services. The modular framework also enables users to easily implement and evaluate new event understanding models with OmniEvent. The toolkit (https://github.com/THU-KEG/OmniEvent) is publicly released along with the demonstration website and video (https://omnievent.xlore.cn/).","sentences":["Event understanding aims at understanding the content and relationship of events within texts, which covers multiple complicated information extraction tasks: event detection, event argument extraction, and event relation extraction.","To facilitate related research and application, we present an event understanding toolkit OmniEvent, which features three desiderata: (1) Comprehensive.","OmniEvent supports mainstream modeling paradigms of all the event understanding tasks and the processing of 15 widely-used English and Chinese datasets.","(2) Fair.","OmniEvent carefully handles the inconspicuous evaluation pitfalls reported in Peng et al. (2023), which ensures fair comparisons between different models.","(3) Easy-to-use.","OmniEvent is designed to be easily used by users with varying needs.","We provide off-the-shelf models that can be directly deployed as web services.","The modular framework also enables users to easily implement and evaluate new event understanding models with OmniEvent.","The toolkit (https://github.com/THU-KEG/OmniEvent) is publicly released along with the demonstration website and video (https://omnievent.xlore.cn/)."],"url":"http://arxiv.org/abs/2309.14258v1"}
{"created":"2023-09-25 16:07:07","title":"Rethinking Internet Communication Through LLMs: How Close Are We?","abstract":"In this paper, we rethink the way that communication among users over the Internet, one of the fundamental outcomes of the Internet evolution, takes place. Instead of users communicating directly over the Internet, we explore an architecture that enables users to communicate with (query) Large Language Models (LLMs) that capture the cognition of users on the other end of the communication channel. We present an architecture to achieve such LLM-based communication and we perform a reality check to assess how close we are today to realizing such a communication architecture from a technical point of view. Finally, we discuss several research challenges and identify interesting directions for future research.","sentences":["In this paper, we rethink the way that communication among users over the Internet, one of the fundamental outcomes of the Internet evolution, takes place.","Instead of users communicating directly over the Internet, we explore an architecture that enables users to communicate with (query) Large Language Models (LLMs) that capture the cognition of users on the other end of the communication channel.","We present an architecture to achieve such LLM-based communication and we perform a reality check to assess how close we are today to realizing such a communication architecture from a technical point of view.","Finally, we discuss several research challenges and identify interesting directions for future research."],"url":"http://arxiv.org/abs/2309.14247v1"}
{"created":"2023-09-25 16:05:32","title":"Learning Risk-Aware Quadrupedal Locomotion using Distributional Reinforcement Learning","abstract":"Deployment in hazardous environments requires robots to understand the risks associated with their actions and movements to prevent accidents. Despite its importance, these risks are not explicitly modeled by currently deployed locomotion controllers for legged robots. In this work, we propose a risk sensitive locomotion training method employing distributional reinforcement learning to consider safety explicitly. Instead of relying on a value expectation, we estimate the complete value distribution to account for uncertainty in the robot's interaction with the environment. The value distribution is consumed by a risk metric to extract risk sensitive value estimates. These are integrated into Proximal Policy Optimization (PPO) to derive our method, Distributional Proximal Policy Optimization (DPPO). The risk preference, ranging from risk-averse to risk-seeking, can be controlled by a single parameter, which enables to adjust the robot's behavior dynamically. Importantly, our approach removes the need for additional reward function tuning to achieve risk sensitivity. We show emergent risk sensitive locomotion behavior in simulation and on the quadrupedal robot ANYmal.","sentences":["Deployment in hazardous environments requires robots to understand the risks associated with their actions and movements to prevent accidents.","Despite its importance, these risks are not explicitly modeled by currently deployed locomotion controllers for legged robots.","In this work, we propose a risk sensitive locomotion training method employing distributional reinforcement learning to consider safety explicitly.","Instead of relying on a value expectation, we estimate the complete value distribution to account for uncertainty in the robot's interaction with the environment.","The value distribution is consumed by a risk metric to extract risk sensitive value estimates.","These are integrated into Proximal Policy Optimization (PPO) to derive our method, Distributional Proximal Policy Optimization (DPPO).","The risk preference, ranging from risk-averse to risk-seeking, can be controlled by a single parameter, which enables to adjust the robot's behavior dynamically.","Importantly, our approach removes the need for additional reward function tuning to achieve risk sensitivity.","We show emergent risk sensitive locomotion behavior in simulation and on the quadrupedal robot ANYmal."],"url":"http://arxiv.org/abs/2309.14246v1"}
{"created":"2023-09-25 16:04:11","title":"Do We Run How We Say We Run? Formalization and Practice of Governance in OSS Communities","abstract":"Open Source Software (OSS) communities often resist regulation typical of traditional organizations. Yet formal governance systems are being increasingly adopted among communities, particularly through non-profit mentor foundations. Our study looks at the Apache Software Foundation Incubator program and 208 projects it supports. We assemble a scalable, semantic pipeline to discover and analyze the governance behavior of projects from their mailing lists. We then investigate the reception of formal policies among communities, through their own governance priorities and internalization of the policies. Our findings indicate that while communities observe formal requirements and policies as extensively as they are defined, their day-to-day governance focus does not dwell on topics that see most formal policy-making. Moreover formalization, be it dedicating governance focus or adopting policy, has limited association with project sustenance.","sentences":["Open Source Software (OSS) communities often resist regulation typical of traditional organizations.","Yet formal governance systems are being increasingly adopted among communities, particularly through non-profit mentor foundations.","Our study looks at the Apache Software Foundation Incubator program and 208 projects it supports.","We assemble a scalable, semantic pipeline to discover and analyze the governance behavior of projects from their mailing lists.","We then investigate the reception of formal policies among communities, through their own governance priorities and internalization of the policies.","Our findings indicate that while communities observe formal requirements and policies as extensively as they are defined, their day-to-day governance focus does not dwell on topics that see most formal policy-making.","Moreover formalization, be it dedicating governance focus or adopting policy, has limited association with project sustenance."],"url":"http://arxiv.org/abs/2309.14245v1"}
{"created":"2023-09-25 16:03:08","title":"Enhancing data efficiency in reinforcement learning: a novel imagination mechanism based on mesh information propagation","abstract":"Reinforcement learning (RL) algorithms face the challenge of limited data efficiency, particularly when dealing with high-dimensional state spaces and large-scale problems. Most RL methods often rely solely on state transition information within the same episode when updating the agent's Critic, which can lead to low data efficiency and sub-optimal training time consumption. Inspired by human-like analogical reasoning abilities, we introduce a novel mesh information propagation mechanism, termed the 'Imagination Mechanism (IM)', designed to significantly enhance the data efficiency of RL algorithms. Specifically, IM enables information generated by a single sample to be effectively broadcasted to different states, instead of simply transmitting in the same episode and it allows the model to better understand the interdependencies between states and learn scarce sample information more efficiently. To promote versatility, we extend the imagination mechanism to function as a plug-and-play module that can be seamlessly and fluidly integrated into other widely adopted RL models. Our experiments demonstrate that Imagination mechanism consistently boosts four mainstream SOTA RL-algorithms, such as SAC, PPO, DDPG, and DQN, by a considerable margin, ultimately leading to superior performance than before across various tasks. For access to our code and data, please visit https://github.com/Zero-coder/FECAM.","sentences":["Reinforcement learning (RL) algorithms face the challenge of limited data efficiency, particularly when dealing with high-dimensional state spaces and large-scale problems.","Most RL methods often rely solely on state transition information within the same episode when updating the agent's Critic, which can lead to low data efficiency and sub-optimal training time consumption.","Inspired by human-like analogical reasoning abilities, we introduce a novel mesh information propagation mechanism, termed the 'Imagination Mechanism (IM)', designed to significantly enhance the data efficiency of RL algorithms.","Specifically, IM enables information generated by a single sample to be effectively broadcasted to different states, instead of simply transmitting in the same episode and it allows the model to better understand the interdependencies between states and learn scarce sample information more efficiently.","To promote versatility, we extend the imagination mechanism to function as a plug-and-play module that can be seamlessly and fluidly integrated into other widely adopted RL models.","Our experiments demonstrate that Imagination mechanism consistently boosts four mainstream SOTA RL-algorithms, such as SAC, PPO, DDPG, and DQN, by a considerable margin, ultimately leading to superior performance than before across various tasks.","For access to our code and data, please visit https://github.com/Zero-coder/FECAM."],"url":"http://arxiv.org/abs/2309.14243v1"}
{"created":"2023-09-25 15:56:01","title":"Informative Data Mining for One-Shot Cross-Domain Semantic Segmentation","abstract":"Contemporary domain adaptation offers a practical solution for achieving cross-domain transfer of semantic segmentation between labeled source data and unlabeled target data. These solutions have gained significant popularity; however, they require the model to be retrained when the test environment changes. This can result in unbearable costs in certain applications due to the time-consuming training process and concerns regarding data privacy. One-shot domain adaptation methods attempt to overcome these challenges by transferring the pre-trained source model to the target domain using only one target data. Despite this, the referring style transfer module still faces issues with computation cost and over-fitting problems. To address this problem, we propose a novel framework called Informative Data Mining (IDM) that enables efficient one-shot domain adaptation for semantic segmentation. Specifically, IDM provides an uncertainty-based selection criterion to identify the most informative samples, which facilitates quick adaptation and reduces redundant training. We then perform a model adaptation method using these selected samples, which includes patch-wise mixing and prototype-based information maximization to update the model. This approach effectively enhances adaptation and mitigates the overfitting problem. In general, we provide empirical evidence of the effectiveness and efficiency of IDM. Our approach outperforms existing methods and achieves a new state-of-the-art one-shot performance of 56.7\\%/55.4\\% on the GTA5/SYNTHIA to Cityscapes adaptation tasks, respectively. The code will be released at \\url{https://github.com/yxiwang/IDM}.","sentences":["Contemporary domain adaptation offers a practical solution for achieving cross-domain transfer of semantic segmentation between labeled source data and unlabeled target data.","These solutions have gained significant popularity; however, they require the model to be retrained when the test environment changes.","This can result in unbearable costs in certain applications due to the time-consuming training process and concerns regarding data privacy.","One-shot domain adaptation methods attempt to overcome these challenges by transferring the pre-trained source model to the target domain using only one target data.","Despite this, the referring style transfer module still faces issues with computation cost and over-fitting problems.","To address this problem, we propose a novel framework called Informative Data Mining (IDM) that enables efficient one-shot domain adaptation for semantic segmentation.","Specifically, IDM provides an uncertainty-based selection criterion to identify the most informative samples, which facilitates quick adaptation and reduces redundant training.","We then perform a model adaptation method using these selected samples, which includes patch-wise mixing and prototype-based information maximization to update the model.","This approach effectively enhances adaptation and mitigates the overfitting problem.","In general, we provide empirical evidence of the effectiveness and efficiency of IDM.","Our approach outperforms existing methods and achieves a new state-of-the-art one-shot performance of 56.7\\%/55.4\\% on the GTA5/SYNTHIA to Cityscapes adaptation tasks, respectively.","The code will be released at \\url{https://github.com/yxiwang/IDM}."],"url":"http://arxiv.org/abs/2309.14241v1"}
{"created":"2023-09-25 15:55:55","title":"Learning to Abstain From Uninformative Data","abstract":"Learning and decision-making in domains with naturally high noise-to-signal ratio, such as Finance or Healthcare, is often challenging, while the stakes are very high. In this paper, we study the problem of learning and acting under a general noisy generative process. In this problem, the data distribution has a significant proportion of uninformative samples with high noise in the label, while part of the data contains useful information represented by low label noise. This dichotomy is present during both training and inference, which requires the proper handling of uninformative data during both training and testing. We propose a novel approach to learning under these conditions via a loss inspired by the selective learning theory. By minimizing this loss, the model is guaranteed to make a near-optimal decision by distinguishing informative data from uninformative data and making predictions. We build upon the strength of our theoretical guarantees by describing an iterative algorithm, which jointly optimizes both a predictor and a selector, and evaluates its empirical performance in a variety of settings.","sentences":["Learning and decision-making in domains with naturally high noise-to-signal ratio, such as Finance or Healthcare, is often challenging, while the stakes are very high.","In this paper, we study the problem of learning and acting under a general noisy generative process.","In this problem, the data distribution has a significant proportion of uninformative samples with high noise in the label, while part of the data contains useful information represented by low label noise.","This dichotomy is present during both training and inference, which requires the proper handling of uninformative data during both training and testing.","We propose a novel approach to learning under these conditions via a loss inspired by the selective learning theory.","By minimizing this loss, the model is guaranteed to make a near-optimal decision by distinguishing informative data from uninformative data and making predictions.","We build upon the strength of our theoretical guarantees by describing an iterative algorithm, which jointly optimizes both a predictor and a selector, and evaluates its empirical performance in a variety of settings."],"url":"http://arxiv.org/abs/2309.14240v1"}
{"created":"2023-09-25 15:54:32","title":"Hierarchical Reinforcement Learning based on Planning Operators","abstract":"Long-horizon manipulation tasks such as stacking represent a longstanding challenge in the field of robotic manipulation, particularly when using reinforcement learning (RL) methods which often struggle to learn the correct sequence of actions for achieving these complex goals. To learn this sequence, symbolic planning methods offer a good solution based on high-level reasoning, however, planners often fall short in addressing the low-level control specificity needed for precise execution. This paper introduces a novel framework that integrates symbolic planning with hierarchical RL through the cooperation of high-level operators and low-level policies. Our contribution integrates planning operators (e.g. preconditions and effects) as part of the hierarchical RL algorithm based on the Scheduled Auxiliary Control (SAC-X) method. We developed a dual-purpose high-level operator, which can be used both in holistic planning and as independent, reusable policies. Our approach offers a flexible solution for long-horizon tasks, e.g., stacking a cube. The experimental results show that our proposed method obtained an average of 97.2% success rate for learning and executing the whole stack sequence, and the success rate for learning independent policies, e.g. reach (98.9%), lift (99.7%), stack (85%), etc. The training time is also reduced by 68% when using our proposed approach.","sentences":["Long-horizon manipulation tasks such as stacking represent a longstanding challenge in the field of robotic manipulation, particularly when using reinforcement learning (RL) methods which often struggle to learn the correct sequence of actions for achieving these complex goals.","To learn this sequence, symbolic planning methods offer a good solution based on high-level reasoning, however, planners often fall short in addressing the low-level control specificity needed for precise execution.","This paper introduces a novel framework that integrates symbolic planning with hierarchical RL through the cooperation of high-level operators and low-level policies.","Our contribution integrates planning operators (e.g. preconditions and effects) as part of the hierarchical RL algorithm based on the Scheduled Auxiliary Control (SAC-X) method.","We developed a dual-purpose high-level operator, which can be used both in holistic planning and as independent, reusable policies.","Our approach offers a flexible solution for long-horizon tasks, e.g., stacking a cube.","The experimental results show that our proposed method obtained an average of 97.2% success rate for learning and executing the whole stack sequence, and the success rate for learning independent policies, e.g. reach (98.9%), lift (99.7%), stack (85%), etc.","The training time is also reduced by 68% when using our proposed approach."],"url":"http://arxiv.org/abs/2309.14237v1"}
{"created":"2023-09-25 15:51:29","title":"MoDem-V2: Visuo-Motor World Models for Real-World Robot Manipulation","abstract":"Robotic systems that aspire to operate in uninstrumented real-world environments must perceive the world directly via onboard sensing. Vision-based learning systems aim to eliminate the need for environment instrumentation by building an implicit understanding of the world based on raw pixels, but navigating the contact-rich high-dimensional search space from solely sparse visual reward signals significantly exacerbates the challenge of exploration. The applicability of such systems is thus typically restricted to simulated or heavily engineered environments since agent exploration in the real-world without the guidance of explicit state estimation and dense rewards can lead to unsafe behavior and safety faults that are catastrophic. In this study, we isolate the root causes behind these limitations to develop a system, called MoDem-V2, capable of learning contact-rich manipulation directly in the uninstrumented real world. Building on the latest algorithmic advancements in model-based reinforcement learning (MBRL), demo-bootstrapping, and effective exploration, MoDem-V2 can acquire contact-rich dexterous manipulation skills directly in the real world. We identify key ingredients for leveraging demonstrations in model learning while respecting real-world safety considerations -- exploration centering, agency handover, and actor-critic ensembles. We empirically demonstrate the contribution of these ingredients in four complex visuo-motor manipulation problems in both simulation and the real world. To the best of our knowledge, our work presents the first successful system for demonstration-augmented visual MBRL trained directly in the real world. Visit https://sites.google.com/view/modem-v2 for videos and more details.","sentences":["Robotic systems that aspire to operate in uninstrumented real-world environments must perceive the world directly via onboard sensing.","Vision-based learning systems aim to eliminate the need for environment instrumentation by building an implicit understanding of the world based on raw pixels, but navigating the contact-rich high-dimensional search space from solely sparse visual reward signals significantly exacerbates the challenge of exploration.","The applicability of such systems is thus typically restricted to simulated or heavily engineered environments since agent exploration in the real-world without the guidance of explicit state estimation and dense rewards can lead to unsafe behavior and safety faults that are catastrophic.","In this study, we isolate the root causes behind these limitations to develop a system, called MoDem-V2, capable of learning contact-rich manipulation directly in the uninstrumented real world.","Building on the latest algorithmic advancements in model-based reinforcement learning (MBRL), demo-bootstrapping, and effective exploration, MoDem-V2 can acquire contact-rich dexterous manipulation skills directly in the real world.","We identify key ingredients for leveraging demonstrations in model learning while respecting real-world safety considerations -- exploration centering, agency handover, and actor-critic ensembles.","We empirically demonstrate the contribution of these ingredients in four complex visuo-motor manipulation problems in both simulation and the real world.","To the best of our knowledge, our work presents the first successful system for demonstration-augmented visual MBRL trained directly in the real world.","Visit https://sites.google.com/view/modem-v2 for videos and more details."],"url":"http://arxiv.org/abs/2309.14236v1"}
{"created":"2023-09-25 15:47:07","title":"Stackelberg Driver Model for Continual Policy Improvement in Scenario-Based Closed-Loop Autonomous Driving","abstract":"The deployment of autonomous vehicles (AVs) has faced hurdles due to the dominance of rare but critical corner cases within the long-tail distribution of driving scenarios, which negatively affects their overall performance. To address this challenge, adversarial generation methods have emerged as a class of efficient approaches to synthesize safety-critical scenarios for AV testing. However, these generated scenarios are often underutilized for AV training, resulting in the potential for continual AV policy improvement remaining untapped, along with a deficiency in the closed-loop design needed to achieve it. Therefore, we tailor the Stackelberg Driver Model (SDM) to accurately characterize the hierarchical nature of vehicle interaction dynamics, facilitating iterative improvement by engaging background vehicles (BVs) and AV in a sequential game-like interaction paradigm. With AV acting as the leader and BVs as followers, this leader-follower modeling ensures that AV would consistently refine its policy, always taking into account the additional information that BVs play the best response to challenge AV. Extensive experiments have shown that our algorithm exhibits superior performance compared to several baselines especially in higher dimensional scenarios, leading to substantial advancements in AV capabilities while continually generating progressively challenging scenarios.","sentences":["The deployment of autonomous vehicles (AVs) has faced hurdles due to the dominance of rare but critical corner cases within the long-tail distribution of driving scenarios, which negatively affects their overall performance.","To address this challenge, adversarial generation methods have emerged as a class of efficient approaches to synthesize safety-critical scenarios for AV testing.","However, these generated scenarios are often underutilized for AV training, resulting in the potential for continual AV policy improvement remaining untapped, along with a deficiency in the closed-loop design needed to achieve it.","Therefore, we tailor the Stackelberg Driver Model (SDM) to accurately characterize the hierarchical nature of vehicle interaction dynamics, facilitating iterative improvement by engaging background vehicles (BVs) and AV in a sequential game-like interaction paradigm.","With AV acting as the leader and BVs as followers, this leader-follower modeling ensures that AV would consistently refine its policy, always taking into account the additional information that BVs play the best response to challenge AV.","Extensive experiments have shown that our algorithm exhibits superior performance compared to several baselines especially in higher dimensional scenarios, leading to substantial advancements in AV capabilities while continually generating progressively challenging scenarios."],"url":"http://arxiv.org/abs/2309.14235v1"}
{"created":"2023-09-25 15:44:24","title":"Urdu Poetry Generated by Using Deep Learning Techniques","abstract":"This study provides Urdu poetry generated using different deep-learning techniques and algorithms. The data was collected through the Rekhta website, containing 1341 text files with several couplets. The data on poetry was not from any specific genre or poet. Instead, it was a collection of mixed Urdu poems and Ghazals. Different deep learning techniques, such as the model applied Long Short-term Memory Networks (LSTM) and Gated Recurrent Unit (GRU), have been used. Natural Language Processing (NLP) may be used in machine learning to understand, analyze, and generate a language humans may use and understand. Much work has been done on generating poetry for different languages using different techniques. The collection and use of data were also different for different researchers. The primary purpose of this project is to provide a model that generates Urdu poems by using data completely, not by sampling data. Also, this may generate poems in pure Urdu, not Roman Urdu, as in the base paper. The results have shown good accuracy in the poems generated by the model.","sentences":["This study provides Urdu poetry generated using different deep-learning techniques and algorithms.","The data was collected through the Rekhta website, containing 1341 text files with several couplets.","The data on poetry was not from any specific genre or poet.","Instead, it was a collection of mixed Urdu poems and Ghazals.","Different deep learning techniques, such as the model applied Long Short-term Memory Networks (LSTM) and Gated Recurrent Unit (GRU), have been used.","Natural Language Processing (NLP) may be used in machine learning to understand, analyze, and generate a language humans may use and understand.","Much work has been done on generating poetry for different languages using different techniques.","The collection and use of data were also different for different researchers.","The primary purpose of this project is to provide a model that generates Urdu poems by using data completely, not by sampling data.","Also, this may generate poems in pure Urdu, not Roman Urdu, as in the base paper.","The results have shown good accuracy in the poems generated by the model."],"url":"http://arxiv.org/abs/2309.14233v1"}
{"created":"2023-09-25 15:43:17","title":"The Governance of Distributed Autonomous Organizations: A Study of Contributors' Influence, Networks, and Shifts in Voting Power","abstract":"We present a study analyzing the voting behavior of contributors, or vested users, in Decentralized Autonomous Organizations (DAOs). We evaluate their involvement in decision-making processes, discovering that in at least 7.54% of all DAOs, contributors, on average, held the necessary majority to control governance decisions. Furthermore, contributors have singularly decided at least one proposal in 20.41% of DAOs. Notably, contributors tend to be centrally positioned within the DAO governance ecosystem, suggesting the presence of inner power circles. Additionally, we observed a tendency for shifts in governance token ownership shortly before governance polls take place in 1202 (14.81%) of 8116 evaluated proposals. Our findings highlight the central role of contributors across a spectrum of DAOs, including Decentralized Finance protocols. Our research also offers important empirical insights pertinent to ongoing regulatory activities aimed at increasing transparency to DAO governance frameworks.","sentences":["We present a study analyzing the voting behavior of contributors, or vested users, in Decentralized Autonomous Organizations (DAOs).","We evaluate their involvement in decision-making processes, discovering that in at least 7.54% of all DAOs, contributors, on average, held the necessary majority to control governance decisions.","Furthermore, contributors have singularly decided at least one proposal in 20.41% of DAOs.","Notably, contributors tend to be centrally positioned within the DAO governance ecosystem, suggesting the presence of inner power circles.","Additionally, we observed a tendency for shifts in governance token ownership shortly before governance polls take place in 1202 (14.81%) of 8116 evaluated proposals.","Our findings highlight the central role of contributors across a spectrum of DAOs, including Decentralized Finance protocols.","Our research also offers important empirical insights pertinent to ongoing regulatory activities aimed at increasing transparency to DAO governance frameworks."],"url":"http://arxiv.org/abs/2309.14232v1"}
{"created":"2023-09-25 15:35:51","title":"ID.8: Co-Creating Visual Stories with Generative AI","abstract":"Storytelling is an integral part of human culture and significantly impacts cognitive and socio-emotional development and connection. Despite the importance of interactive visual storytelling, the process of creating such content requires specialized skills and is labor-intensive. This paper introduces ID.8, an open-source system designed for the co-creation of visual stories with generative AI. We focus on enabling an inclusive storytelling experience by simplifying the content creation process and allowing for customization. Our user evaluation confirms a generally positive user experience in domains such as enjoyment and exploration, while highlighting areas for improvement, particularly in immersiveness, alignment, and partnership between the user and the AI system. Overall, our findings indicate promising possibilities for empowering people to create visual stories with generative AI. This work contributes a novel content authoring system, ID.8, and insights into the challenges and potential of using generative AI for multimedia content creation.","sentences":["Storytelling is an integral part of human culture and significantly impacts cognitive and socio-emotional development and connection.","Despite the importance of interactive visual storytelling, the process of creating such content requires specialized skills and is labor-intensive.","This paper introduces ID.8, an open-source system designed for the co-creation of visual stories with generative AI.","We focus on enabling an inclusive storytelling experience by simplifying the content creation process and allowing for customization.","Our user evaluation confirms a generally positive user experience in domains such as enjoyment and exploration, while highlighting areas for improvement, particularly in immersiveness, alignment, and partnership between the user and the AI system.","Overall, our findings indicate promising possibilities for empowering people to create visual stories with generative AI.","This work contributes a novel content authoring system, ID.8, and insights into the challenges and potential of using generative AI for multimedia content creation."],"url":"http://arxiv.org/abs/2309.14228v1"}
{"created":"2023-09-25 15:31:38","title":"Daily Assistive Modular Robot Design Based on Multi-Objective Black-Box Optimization","abstract":"The range of robot activities is expanding from industries with fixed environments to diverse and changing environments, such as nursing care support and daily life support. In particular, autonomous construction of robots that are personalized for each user and task is required. Therefore, we develop an actuator module that can be reconfigured to various link configurations, can carry heavy objects using a locking mechanism, and can be easily operated by human teaching using a releasing mechanism. Given multiple target coordinates, a modular robot configuration that satisfies these coordinates and minimizes the required torque is automatically generated by Tree-structured Parzen Estimator (TPE), a type of black-box optimization. Based on the obtained results, we show that the robot can be reconfigured to perform various functions such as moving monitors and lights, serving food, and so on.","sentences":["The range of robot activities is expanding from industries with fixed environments to diverse and changing environments, such as nursing care support and daily life support.","In particular, autonomous construction of robots that are personalized for each user and task is required.","Therefore, we develop an actuator module that can be reconfigured to various link configurations, can carry heavy objects using a locking mechanism, and can be easily operated by human teaching using a releasing mechanism.","Given multiple target coordinates, a modular robot configuration that satisfies these coordinates and minimizes the required torque is automatically generated by Tree-structured Parzen Estimator (TPE), a type of black-box optimization.","Based on the obtained results, we show that the robot can be reconfigured to perform various functions such as moving monitors and lights, serving food, and so on."],"url":"http://arxiv.org/abs/2309.14226v1"}
{"created":"2023-09-25 15:31:34","title":"HumanMimic: Learning Natural Locomotion and Transitions for Humanoid Robot via Wasserstein Adversarial Imitation","abstract":"Transferring human motion skills to humanoid robots remains a significant challenge. In this study, we introduce a Wasserstein adversarial imitation learning system, allowing humanoid robots to replicate natural whole-body locomotion patterns and execute seamless transitions by mimicking human motions. First, we present a unified primitive-skeleton motion retargeting to mitigate morphological differences between arbitrary human demonstrators and humanoid robots. An adversarial critic component is integrated with Reinforcement Learning (RL) to guide the control policy to produce behaviors aligned with the data distribution of mixed reference motions. Additionally, we employ a specific Integral Probabilistic Metric (IPM), namely the Wasserstein-1 distance with a novel soft boundary constraint to stabilize the training process and prevent model collapse. Our system is evaluated on a full-sized humanoid JAXON in the simulator. The resulting control policy demonstrates a wide range of locomotion patterns, including standing, push-recovery, squat walking, human-like straight-leg walking, and dynamic running. Notably, even in the absence of transition motions in the demonstration dataset, robots showcase an emerging ability to transit naturally between distinct locomotion patterns as desired speed changes.","sentences":["Transferring human motion skills to humanoid robots remains a significant challenge.","In this study, we introduce a Wasserstein adversarial imitation learning system, allowing humanoid robots to replicate natural whole-body locomotion patterns and execute seamless transitions by mimicking human motions.","First, we present a unified primitive-skeleton motion retargeting to mitigate morphological differences between arbitrary human demonstrators and humanoid robots.","An adversarial critic component is integrated with Reinforcement Learning (RL) to guide the control policy to produce behaviors aligned with the data distribution of mixed reference motions.","Additionally, we employ a specific Integral Probabilistic Metric (IPM), namely the Wasserstein-1 distance with a novel soft boundary constraint to stabilize the training process and prevent model collapse.","Our system is evaluated on a full-sized humanoid JAXON in the simulator.","The resulting control policy demonstrates a wide range of locomotion patterns, including standing, push-recovery, squat walking, human-like straight-leg walking, and dynamic running.","Notably, even in the absence of transition motions in the demonstration dataset, robots showcase an emerging ability to transit naturally between distinct locomotion patterns as desired speed changes."],"url":"http://arxiv.org/abs/2309.14225v1"}
{"created":"2023-09-25 15:22:58","title":"On LCP codes over a mixed ring alphabet","abstract":"In this paper, we introduce a standard generator matrix for mixed-alphabet linear codes over finite chain rings. Furthermore, we show that, when one has a linear complementary pair (LCP) of mixed-alphabet linear codes, both codes are weakly-free. Additionally, we establish that any mixed-alphabet product group code is separable. Thus, if one has a pair $\\{C, D\\}$ of mixed-alphabet product group codes over a finite chain ring that forms a LCP, it follows that $C$ and the Euclidean dual of $D$ are permutation equivalent.","sentences":["In this paper, we introduce a standard generator matrix for mixed-alphabet linear codes over finite chain rings.","Furthermore, we show that, when one has a linear complementary pair (LCP) of mixed-alphabet linear codes, both codes are weakly-free.","Additionally, we establish that any mixed-alphabet product group code is separable.","Thus, if one has a pair $\\{C, D\\}$ of mixed-alphabet product group codes over a finite chain ring that forms a LCP, it follows that $C$ and the Euclidean dual of $D$ are permutation equivalent."],"url":"http://arxiv.org/abs/2309.14217v1"}
{"created":"2023-09-25 15:22:28","title":"MemDA: Forecasting Urban Time Series with Memory-based Drift Adaptation","abstract":"Urban time series data forecasting featuring significant contributions to sustainable development is widely studied as an essential task of the smart city. However, with the dramatic and rapid changes in the world environment, the assumption that data obey Independent Identically Distribution is undermined by the subsequent changes in data distribution, known as concept drift, leading to weak replicability and transferability of the model over unseen data. To address the issue, previous approaches typically retrain the model, forcing it to fit the most recent observed data. However, retraining is problematic in that it leads to model lag, consumption of resources, and model re-invalidation, causing the drift problem to be not well solved in realistic scenarios. In this study, we propose a new urban time series prediction model for the concept drift problem, which encodes the drift by considering the periodicity in the data and makes on-the-fly adjustments to the model based on the drift using a meta-dynamic network. Experiments on real-world datasets show that our design significantly outperforms state-of-the-art methods and can be well generalized to existing prediction backbones by reducing their sensitivity to distribution changes.","sentences":["Urban time series data forecasting featuring significant contributions to sustainable development is widely studied as an essential task of the smart city.","However, with the dramatic and rapid changes in the world environment, the assumption that data obey Independent Identically Distribution is undermined by the subsequent changes in data distribution, known as concept drift, leading to weak replicability and transferability of the model over unseen data.","To address the issue, previous approaches typically retrain the model, forcing it to fit the most recent observed data.","However, retraining is problematic in that it leads to model lag, consumption of resources, and model re-invalidation, causing the drift problem to be not well solved in realistic scenarios.","In this study, we propose a new urban time series prediction model for the concept drift problem, which encodes the drift by considering the periodicity in the data and makes on-the-fly adjustments to the model based on the drift using a meta-dynamic network.","Experiments on real-world datasets show that our design significantly outperforms state-of-the-art methods and can be well generalized to existing prediction backbones by reducing their sensitivity to distribution changes."],"url":"http://arxiv.org/abs/2309.14216v1"}
{"created":"2023-09-25 15:19:09","title":"Autonomous Vehicles an overview on system, cyber security, risks, issues, and a way forward","abstract":"This chapter explores the complex realm of autonomous cars, analyzing their fundamental components and operational characteristics. The initial phase of the discussion is elucidating the internal mechanics of these automobiles, encompassing the crucial involvement of sensors, artificial intelligence (AI) identification systems, control mechanisms, and their integration with cloud-based servers within the framework of the Internet of Things (IoT). It delves into practical implementations of autonomous cars, emphasizing their utilization in forecasting traffic patterns and transforming the dynamics of transportation. The text also explores the topic of Robotic Process Automation (RPA), illustrating the impact of autonomous cars on different businesses through the automation of tasks. The primary focus of this investigation lies in the realm of cybersecurity, specifically in the context of autonomous vehicles. A comprehensive analysis will be conducted to explore various risk management solutions aimed at protecting these vehicles from potential threats including ethical, environmental, legal, professional, and social dimensions, offering a comprehensive perspective on their societal implications. A strategic plan for addressing the challenges and proposing strategies for effectively traversing the complex terrain of autonomous car systems, cybersecurity, hazards, and other concerns are some resources for acquiring an understanding of the intricate realm of autonomous cars and their ramifications in contemporary society, supported by a comprehensive compilation of resources for additional investigation.   Keywords: RPA, Cyber Security, AV, Risk, Smart Cars","sentences":["This chapter explores the complex realm of autonomous cars, analyzing their fundamental components and operational characteristics.","The initial phase of the discussion is elucidating the internal mechanics of these automobiles, encompassing the crucial involvement of sensors, artificial intelligence (AI) identification systems, control mechanisms, and their integration with cloud-based servers within the framework of the Internet of Things (IoT).","It delves into practical implementations of autonomous cars, emphasizing their utilization in forecasting traffic patterns and transforming the dynamics of transportation.","The text also explores the topic of Robotic Process Automation (RPA), illustrating the impact of autonomous cars on different businesses through the automation of tasks.","The primary focus of this investigation lies in the realm of cybersecurity, specifically in the context of autonomous vehicles.","A comprehensive analysis will be conducted to explore various risk management solutions aimed at protecting these vehicles from potential threats including ethical, environmental, legal, professional, and social dimensions, offering a comprehensive perspective on their societal implications.","A strategic plan for addressing the challenges and proposing strategies for effectively traversing the complex terrain of autonomous car systems, cybersecurity, hazards, and other concerns are some resources for acquiring an understanding of the intricate realm of autonomous cars and their ramifications in contemporary society, supported by a comprehensive compilation of resources for additional investigation.   ","Keywords: RPA, Cyber Security, AV, Risk, Smart Cars"],"url":"http://arxiv.org/abs/2309.14213v1"}
{"created":"2023-09-25 15:18:08","title":"QuadricsNet: Learning Concise Representation for Geometric Primitives in Point Clouds","abstract":"This paper presents a novel framework to learn a concise geometric primitive representation for 3D point clouds. Different from representing each type of primitive individually, we focus on the challenging problem of how to achieve a concise and uniform representation robustly. We employ quadrics to represent diverse primitives with only 10 parameters and propose the first end-to-end learning-based framework, namely QuadricsNet, to parse quadrics in point clouds. The relationships between quadrics mathematical formulation and geometric attributes, including the type, scale and pose, are insightfully integrated for effective supervision of QuaidricsNet. Besides, a novel pattern-comprehensive dataset with quadrics segments and objects is collected for training and evaluation. Experiments demonstrate the effectiveness of our concise representation and the robustness of QuadricsNet. Our code is available at \\url{https://github.com/MichaelWu99-lab/QuadricsNet}","sentences":["This paper presents a novel framework to learn a concise geometric primitive representation for 3D point clouds.","Different from representing each type of primitive individually, we focus on the challenging problem of how to achieve a concise and uniform representation robustly.","We employ quadrics to represent diverse primitives with only 10 parameters and propose the first end-to-end learning-based framework, namely QuadricsNet, to parse quadrics in point clouds.","The relationships between quadrics mathematical formulation and geometric attributes, including the type, scale and pose, are insightfully integrated for effective supervision of QuaidricsNet.","Besides, a novel pattern-comprehensive dataset with quadrics segments and objects is collected for training and evaluation.","Experiments demonstrate the effectiveness of our concise representation and the robustness of QuadricsNet.","Our code is available at \\url{https://github.com/MichaelWu99-lab/QuadricsNet}"],"url":"http://arxiv.org/abs/2309.14211v1"}
{"created":"2023-09-25 15:14:54","title":"Continual Driving Policy Optimization with Closed-Loop Individualized Curricula","abstract":"The safety of autonomous vehicles (AV) has been a long-standing top concern, stemming from the absence of rare and safety-critical scenarios in the long-tail naturalistic driving distribution. To tackle this challenge, a surge of research in scenario-based autonomous driving has emerged, with a focus on generating high-risk driving scenarios and applying them to conduct safety-critical testing of AV models. However, limited work has been explored on the reuse of these extensive scenarios to iteratively improve AV models. Moreover, it remains intractable and challenging to filter through gigantic scenario libraries collected from other AV models with distinct behaviors, attempting to extract transferable information for current AV improvement. Therefore, we develop a continual driving policy optimization framework featuring Closed-Loop Individualized Curricula (CLIC), which we factorize into a set of standardized sub-modules for flexible implementation choices: AV Evaluation, Scenario Selection, and AV Training. CLIC frames AV Evaluation as a collision prediction task, where it estimates the chance of AV failures in these scenarios at each iteration. Subsequently, by re-sampling from historical scenarios based on these failure probabilities, CLIC tailors individualized curricula for downstream training, aligning them with the evaluated capability of AV. Accordingly, CLIC not only maximizes the utilization of the vast pre-collected scenario library for closed-loop driving policy optimization but also facilitates AV improvement by individualizing its training with more challenging cases out of those poorly organized scenarios. Experimental results clearly indicate that CLIC surpasses other curriculum-based training strategies, showing substantial improvement in managing risky scenarios, while still maintaining proficiency in handling simpler cases.","sentences":["The safety of autonomous vehicles (AV) has been a long-standing top concern, stemming from the absence of rare and safety-critical scenarios in the long-tail naturalistic driving distribution.","To tackle this challenge, a surge of research in scenario-based autonomous driving has emerged, with a focus on generating high-risk driving scenarios and applying them to conduct safety-critical testing of AV models.","However, limited work has been explored on the reuse of these extensive scenarios to iteratively improve AV models.","Moreover, it remains intractable and challenging to filter through gigantic scenario libraries collected from other AV models with distinct behaviors, attempting to extract transferable information for current AV improvement.","Therefore, we develop a continual driving policy optimization framework featuring Closed-Loop Individualized Curricula (CLIC), which we factorize into a set of standardized sub-modules for flexible implementation choices: AV Evaluation, Scenario Selection, and AV Training.","CLIC frames AV Evaluation as a collision prediction task, where it estimates the chance of AV failures in these scenarios at each iteration.","Subsequently, by re-sampling from historical scenarios based on these failure probabilities, CLIC tailors individualized curricula for downstream training, aligning them with the evaluated capability of AV.","Accordingly, CLIC not only maximizes the utilization of the vast pre-collected scenario library for closed-loop driving policy optimization but also facilitates AV improvement by individualizing its training with more challenging cases out of those poorly organized scenarios.","Experimental results clearly indicate that CLIC surpasses other curriculum-based training strategies, showing substantial improvement in managing risky scenarios, while still maintaining proficiency in handling simpler cases."],"url":"http://arxiv.org/abs/2309.14209v1"}
{"created":"2023-09-25 15:11:52","title":"Framework based on complex networks to model and mine patient pathways","abstract":"The automatic discovery of a model to represent the history of encounters of a group of patients with the healthcare system -- the so-called ``pathway of patients'' -- is a new field of research that supports clinical and organisational decisions to improve the quality and efficiency of the treatment provided. The pathways of patients with chronic conditions tend to vary significantly from one person to another, have repetitive tasks, and demand the analysis of multiple perspectives (interventions, diagnoses, medical specialities, among others) influencing the results. Therefore, modelling and mining those pathways is still a challenging task. In this work, we propose a framework comprising: (i) a pathway model based on a multi-aspect graph, (ii) a novel dissimilarity measurement to compare pathways taking the elapsed time into account, and (iii) a mining method based on traditional centrality measures to discover the most relevant steps of the pathways. We evaluated the framework using the study cases of pregnancy and diabetes, which revealed its usefulness in finding clusters of similar pathways, representing them in an easy-to-interpret way, and highlighting the most significant patterns according to multiple perspectives.","sentences":["The automatic discovery of a model to represent the history of encounters of a group of patients with the healthcare system -- the so-called ``pathway of patients'' -- is a new field of research that supports clinical and organisational decisions to improve the quality and efficiency of the treatment provided.","The pathways of patients with chronic conditions tend to vary significantly from one person to another, have repetitive tasks, and demand the analysis of multiple perspectives (interventions, diagnoses, medical specialities, among others) influencing the results.","Therefore, modelling and mining those pathways is still a challenging task.","In this work, we propose a framework comprising: (i) a pathway model based on a multi-aspect graph, (ii) a novel dissimilarity measurement to compare pathways taking the elapsed time into account, and (iii) a mining method based on traditional centrality measures to discover the most relevant steps of the pathways.","We evaluated the framework using the study cases of pregnancy and diabetes, which revealed its usefulness in finding clusters of similar pathways, representing them in an easy-to-interpret way, and highlighting the most significant patterns according to multiple perspectives."],"url":"http://arxiv.org/abs/2309.14208v1"}
{"created":"2023-09-25 15:11:40","title":"Automatic Animation of Hair Blowing in Still Portrait Photos","abstract":"We propose a novel approach to animate human hair in a still portrait photo. Existing work has largely studied the animation of fluid elements such as water and fire. However, hair animation for a real image remains underexplored, which is a challenging problem, due to the high complexity of hair structure and dynamics. Considering the complexity of hair structure, we innovatively treat hair wisp extraction as an instance segmentation problem, where a hair wisp is referred to as an instance. With advanced instance segmentation networks, our method extracts meaningful and natural hair wisps. Furthermore, we propose a wisp-aware animation module that animates hair wisps with pleasing motions without noticeable artifacts. The extensive experiments show the superiority of our method. Our method provides the most pleasing and compelling viewing experience in the qualitative experiments and outperforms state-of-the-art still-image animation methods by a large margin in the quantitative evaluation. Project url: \\url{https://nevergiveu.github.io/AutomaticHairBlowing/}","sentences":["We propose a novel approach to animate human hair in a still portrait photo.","Existing work has largely studied the animation of fluid elements such as water and fire.","However, hair animation for a real image remains underexplored, which is a challenging problem, due to the high complexity of hair structure and dynamics.","Considering the complexity of hair structure, we innovatively treat hair wisp extraction as an instance segmentation problem, where a hair wisp is referred to as an instance.","With advanced instance segmentation networks, our method extracts meaningful and natural hair wisps.","Furthermore, we propose a wisp-aware animation module that animates hair wisps with pleasing motions without noticeable artifacts.","The extensive experiments show the superiority of our method.","Our method provides the most pleasing and compelling viewing experience in the qualitative experiments and outperforms state-of-the-art still-image animation methods by a large margin in the quantitative evaluation.","Project url: \\url{https://nevergiveu.github.io/AutomaticHairBlowing/}"],"url":"http://arxiv.org/abs/2309.14207v1"}
{"created":"2023-09-25 15:05:46","title":"Detecting and Grounding Multi-Modal Media Manipulation and Beyond","abstract":"Misinformation has become a pressing issue. Fake media, in both visual and textual forms, is widespread on the web. While various deepfake detection and text fake news detection methods have been proposed, they are only designed for single-modality forgery based on binary classification, let alone analyzing and reasoning subtle forgery traces across different modalities. In this paper, we highlight a new research problem for multi-modal fake media, namely Detecting and Grounding Multi-Modal Media Manipulation (DGM^4). DGM^4 aims to not only detect the authenticity of multi-modal media, but also ground the manipulated content, which requires deeper reasoning of multi-modal media manipulation. To support a large-scale investigation, we construct the first DGM^4 dataset, where image-text pairs are manipulated by various approaches, with rich annotation of diverse manipulations. Moreover, we propose a novel HierArchical Multi-modal Manipulation rEasoning tRansformer (HAMMER) to fully capture the fine-grained interaction between different modalities. HAMMER performs 1) manipulation-aware contrastive learning between two uni-modal encoders as shallow manipulation reasoning, and 2) modality-aware cross-attention by multi-modal aggregator as deep manipulation reasoning. Dedicated manipulation detection and grounding heads are integrated from shallow to deep levels based on the interacted multi-modal information. To exploit more fine-grained contrastive learning for cross-modal semantic alignment, we further integrate Manipulation-Aware Contrastive Loss with Local View and construct a more advanced model HAMMER++. Finally, we build an extensive benchmark and set up rigorous evaluation metrics for this new research problem. Comprehensive experiments demonstrate the superiority of HAMMER and HAMMER++.","sentences":["Misinformation has become a pressing issue.","Fake media, in both visual and textual forms, is widespread on the web.","While various deepfake detection and text fake news detection methods have been proposed, they are only designed for single-modality forgery based on binary classification, let alone analyzing and reasoning subtle forgery traces across different modalities.","In this paper, we highlight a new research problem for multi-modal fake media, namely Detecting and Grounding Multi-Modal Media Manipulation (DGM^4).","DGM^4 aims to not only detect the authenticity of multi-modal media, but also ground the manipulated content, which requires deeper reasoning of multi-modal media manipulation.","To support a large-scale investigation, we construct the first DGM^4 dataset, where image-text pairs are manipulated by various approaches, with rich annotation of diverse manipulations.","Moreover, we propose a novel HierArchical Multi-modal Manipulation rEasoning tRansformer (HAMMER) to fully capture the fine-grained interaction between different modalities.","HAMMER performs 1) manipulation-aware contrastive learning between two uni-modal encoders as shallow manipulation reasoning, and 2) modality-aware cross-attention by multi-modal aggregator as deep manipulation reasoning.","Dedicated manipulation detection and grounding heads are integrated from shallow to deep levels based on the interacted multi-modal information.","To exploit more fine-grained contrastive learning for cross-modal semantic alignment, we further integrate Manipulation-Aware Contrastive Loss with Local View and construct a more advanced model HAMMER++.","Finally, we build an extensive benchmark and set up rigorous evaluation metrics for this new research problem.","Comprehensive experiments demonstrate the superiority of HAMMER and HAMMER++."],"url":"http://arxiv.org/abs/2309.14203v1"}
{"created":"2023-09-25 15:01:11","title":"Towards a Theory of Maximal Extractable Value II: Uncertainty","abstract":"Maximal Extractable Value (MEV) is value extractable by temporary monopoly power commonly found in decentralized systems. This extraction stems from a lack of user privacy upon transaction submission and the ability of a monopolist validator to reorder, add, and/or censor transactions. There are two main directions to reduce MEV: reduce the flexibility of the miner to reorder transactions by enforcing ordering rules and/or introduce a competitive market for the right to reorder, add, and/or censor transactions. In this work, we unify these approaches via \\emph{uncertainty principles}, akin to those found in harmonic analysis and physics. This provides a quantitative trade-off between the freedom to reorder transactions and the complexity of an economic payoff to a user in a decentralized network. This trade off is analogous to the Nyquist-Shannon sampling theorem and demonstrates that sequencing rules in blockchains need to be application specific. Our results suggest that neither so-called fair ordering techniques nor economic mechanisms can individually mitigate MEV for arbitrary payoff functions.","sentences":["Maximal Extractable Value (MEV) is value extractable by temporary monopoly power commonly found in decentralized systems.","This extraction stems from a lack of user privacy upon transaction submission and the ability of a monopolist validator to reorder, add, and/or censor transactions.","There are two main directions to reduce MEV: reduce the flexibility of the miner to reorder transactions by enforcing ordering rules and/or introduce a competitive market for the right to reorder, add, and/or censor transactions.","In this work, we unify these approaches via \\emph{uncertainty principles}, akin to those found in harmonic analysis and physics.","This provides a quantitative trade-off between the freedom to reorder transactions and the complexity of an economic payoff to a user in a decentralized network.","This trade off is analogous to the Nyquist-Shannon sampling theorem and demonstrates that sequencing rules in blockchains need to be application specific.","Our results suggest that neither so-called fair ordering techniques nor economic mechanisms can individually mitigate MEV for arbitrary payoff functions."],"url":"http://arxiv.org/abs/2309.14201v1"}
{"created":"2023-09-25 14:57:43","title":"(Predictable) Performance Bias in Unsupervised Anomaly Detection","abstract":"Background: With the ever-increasing amount of medical imaging data, the demand for algorithms to assist clinicians has amplified. Unsupervised anomaly detection (UAD) models promise to aid in the crucial first step of disease detection. While previous studies have thoroughly explored fairness in supervised models in healthcare, for UAD, this has so far been unexplored.   Methods: In this study, we evaluated how dataset composition regarding subgroups manifests in disparate performance of UAD models along multiple protected variables on three large-scale publicly available chest X-ray datasets. Our experiments were validated using two state-of-the-art UAD models for medical images. Finally, we introduced a novel subgroup-AUROC (sAUROC) metric, which aids in quantifying fairness in machine learning.   Findings: Our experiments revealed empirical \"fairness laws\" (similar to \"scaling laws\" for Transformers) for training-dataset composition: Linear relationships between anomaly detection performance within a subpopulation and its representation in the training data. Our study further revealed performance disparities, even in the case of balanced training data, and compound effects that exacerbate the drop in performance for subjects associated with multiple adversely affected groups.   Interpretation: Our study quantified the disparate performance of UAD models against certain demographic subgroups. Importantly, we showed that this unfairness cannot be mitigated by balanced representation alone. Instead, the representation of some subgroups seems harder to learn by UAD models than that of others. The empirical fairness laws discovered in our study make disparate performance in UAD models easier to estimate and aid in determining the most desirable dataset composition.","sentences":["Background: With the ever-increasing amount of medical imaging data, the demand for algorithms to assist clinicians has amplified.","Unsupervised anomaly detection (UAD) models promise to aid in the crucial first step of disease detection.","While previous studies have thoroughly explored fairness in supervised models in healthcare, for UAD, this has so far been unexplored.   ","Methods: In this study, we evaluated how dataset composition regarding subgroups manifests in disparate performance of UAD models along multiple protected variables on three large-scale publicly available chest X-ray datasets.","Our experiments were validated using two state-of-the-art UAD models for medical images.","Finally, we introduced a novel subgroup-AUROC (sAUROC) metric, which aids in quantifying fairness in machine learning.   ","Findings: Our experiments revealed empirical \"fairness laws\" (similar to \"scaling laws\" for Transformers) for training-dataset composition: Linear relationships between anomaly detection performance within a subpopulation and its representation in the training data.","Our study further revealed performance disparities, even in the case of balanced training data, and compound effects that exacerbate the drop in performance for subjects associated with multiple adversely affected groups.   ","Interpretation: Our study quantified the disparate performance of UAD models against certain demographic subgroups.","Importantly, we showed that this unfairness cannot be mitigated by balanced representation alone.","Instead, the representation of some subgroups seems harder to learn by UAD models than that of others.","The empirical fairness laws discovered in our study make disparate performance in UAD models easier to estimate and aid in determining the most desirable dataset composition."],"url":"http://arxiv.org/abs/2309.14198v1"}
{"created":"2023-09-25 14:47:47","title":"Two tricks to trivialize higher-indexed families","abstract":"The conventional general syntax of indexed families in dependent type theories follow the style of \"constructors returning a special case\", as in Agda, Lean, Idris, Coq, and probably many other systems. Fording is a method to encode indexed families of this style with index-free inductive types and an identity type. There is another trick that merges interleaved higher inductive-inductive types into a single big family of types. It makes use of a small universe as the index to distinguish the original types. In this paper, we show that these two methods can trivialize some very fancy-looking indexed families with higher inductive indices (which we refer to as higher indexed families).","sentences":["The conventional general syntax of indexed families in dependent type theories follow the style of \"constructors returning a special case\", as in Agda, Lean, Idris, Coq, and probably many other systems.","Fording is a method to encode indexed families of this style with index-free inductive types and an identity type.","There is another trick that merges interleaved higher inductive-inductive types into a single big family of types.","It makes use of a small universe as the index to distinguish the original types.","In this paper, we show that these two methods can trivialize some very fancy-looking indexed families with higher inductive indices (which we refer to as higher indexed families)."],"url":"http://arxiv.org/abs/2309.14187v1"}
{"created":"2023-09-25 14:46:54","title":"Temporal Separators with Deadlines","abstract":"We study temporal analogues of the Unrestricted Vertex Separator problem from the static world. An $(s,z)$-temporal separator is a set of vertices whose removal disconnects vertex $s$ from vertex $z$ for every time step in a temporal graph. The $(s,z)$-Temporal Separator problem asks to find the minimum size of an $(s,z)$-temporal separator for the given temporal graph. We introduce a generalization of this problem called the $(s,z,t)$-Temporal Separator problem, where the goal is to find a smallest subset of vertices whose removal eliminates all temporal paths from $s$ to $z$ which take less than $t$ time steps. Let $\\tau$ denote the number of time steps over which the temporal graph is defined (we consider discrete time steps). We characterize the set of parameters $\\tau$ and $t$ when the problem is $\\mathcal{NP}$-hard and when it is polynomial time solvable. Then we present a $\\tau$-approximation algorithm for the $(s,z)$-Temporal Separator problem and convert it to a $\\tau^2$-approximation algorithm for the $(s,z,t)$-Temporal Separator problem. We also present an inapproximability lower bound of $\\Omega(\\ln(n) + \\ln(\\tau))$ for the $(s,z,t)$-Temporal Separator problem assuming that $\\mathcal{NP}\\not\\subset\\mbox{\\sc Dtime}(n^{\\log\\log n})$. Then we consider three special families of graphs: (1) graphs of branchwidth at most $2$, (2) graphs $G$ such that the removal of $s$ and $z$ leaves a tree, and (3) graphs of bounded pathwidth. We present polynomial-time algorithms to find a minimum $(s,z,t)$-temporal separator for (1) and (2). As for (3), we show a polynomial-time reduction from the Discrete Segment Covering problem with bounded-length segments to the $(s,z,t)$-Temporal Separator problem where the temporal graph has bounded pathwidth.","sentences":["We study temporal analogues of the Unrestricted Vertex Separator problem from the static world.","An $(s,z)$-temporal separator is a set of vertices whose removal disconnects vertex $s$ from vertex $z$ for every time step in a temporal graph.","The $(s,z)$-Temporal Separator problem asks to find the minimum size of an $(s,z)$-temporal separator for the given temporal graph.","We introduce a generalization of this problem called the $(s,z,t)$-Temporal Separator problem, where the goal is to find a smallest subset of vertices whose removal eliminates all temporal paths from $s$ to $z$ which take less than $t$ time steps.","Let $\\tau$ denote the number of time steps over which the temporal graph is defined (we consider discrete time steps).","We characterize the set of parameters $\\tau$ and $t$ when the problem is $\\mathcal{NP}$-hard and when it is polynomial time solvable.","Then we present a $\\tau$-approximation algorithm for the $(s,z)$-Temporal Separator problem and convert it to a $\\tau^2$-approximation algorithm for the $(s,z,t)$-Temporal Separator problem.","We also present an inapproximability lower bound of $\\Omega(\\ln(n)","+ \\ln(\\tau))$ for the $(s,z,t)$-Temporal Separator problem assuming that $\\mathcal{NP}\\not\\subset\\mbox{\\sc Dtime}(n^{\\log\\log n})$.","Then we consider three special families of graphs: (1) graphs of branchwidth at most $2$, (2) graphs $G$ such that the removal of $s$ and $z$ leaves a tree, and (3) graphs of bounded pathwidth.","We present polynomial-time algorithms to find a minimum $(s,z,t)$-temporal separator for (1) and (2).","As for (3), we show a polynomial-time reduction from the Discrete Segment Covering problem with bounded-length segments to the $(s,z,t)$-Temporal Separator problem where the temporal graph has bounded pathwidth."],"url":"http://arxiv.org/abs/2309.14185v1"}
{"created":"2023-09-25 14:46:01","title":"Species196: A One-Million Semi-supervised Dataset for Fine-grained Species Recognition","abstract":"The development of foundation vision models has pushed the general visual recognition to a high level, but cannot well address the fine-grained recognition in specialized domain such as invasive species classification. Identifying and managing invasive species has strong social and ecological value. Currently, most invasive species datasets are limited in scale and cover a narrow range of species, which restricts the development of deep-learning based invasion biometrics systems. To fill the gap of this area, we introduced Species196, a large-scale semi-supervised dataset of 196-category invasive species. It collects over 19K images with expert-level accurate annotations Species196-L, and 1.2M unlabeled images of invasive species Species196-U. The dataset provides four experimental settings for benchmarking the existing models and algorithms, namely, supervised learning, semi-supervised learning, self-supervised pretraining and zero-shot inference ability of large multi-modal models. To facilitate future research on these four learning paradigms, we conduct an empirical study of the representative methods on the introduced dataset. The dataset is publicly available at https://species-dataset.github.io/.","sentences":["The development of foundation vision models has pushed the general visual recognition to a high level, but cannot well address the fine-grained recognition in specialized domain such as invasive species classification.","Identifying and managing invasive species has strong social and ecological value.","Currently, most invasive species datasets are limited in scale and cover a narrow range of species, which restricts the development of deep-learning based invasion biometrics systems.","To fill the gap of this area, we introduced Species196, a large-scale semi-supervised dataset of 196-category invasive species.","It collects over 19K images with expert-level accurate annotations Species196-L, and 1.2M unlabeled images of invasive species Species196-U.","The dataset provides four experimental settings for benchmarking the existing models and algorithms, namely, supervised learning, semi-supervised learning, self-supervised pretraining and zero-shot inference ability of large multi-modal models.","To facilitate future research on these four learning paradigms, we conduct an empirical study of the representative methods on the introduced dataset.","The dataset is publicly available at https://species-dataset.github.io/."],"url":"http://arxiv.org/abs/2309.14183v1"}
{"created":"2023-09-25 14:43:43","title":"Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision","abstract":"The rapid evolution of Multi-modality Large Language Models (MLLMs) has catalyzed a shift in computer vision from specialized models to general-purpose foundation models. Nevertheless, there is still an inadequacy in assessing the abilities of MLLMs on low-level visual perception and understanding. To address this gap, we present Q-Bench, a holistic benchmark crafted to systematically evaluate potential abilities of MLLMs on three realms: low-level visual perception, low-level visual description, and overall visual quality assessment. a) To evaluate the low-level perception ability, we construct the LLVisionQA dataset, consisting of 2,990 diverse-sourced images, each equipped with a human-asked question focusing on its low-level attributes. We then measure the correctness of MLLMs on answering these questions. b) To examine the description ability of MLLMs on low-level information, we propose the LLDescribe dataset consisting of long expert-labelled golden low-level text descriptions on 499 images, and a GPT-involved comparison pipeline between outputs of MLLMs and the golden descriptions. c) Besides these two tasks, we further measure their visual quality assessment ability to align with human opinion scores. Specifically, we design a softmax-based strategy that enables MLLMs to predict quantifiable quality scores, and evaluate them on various existing image quality assessment (IQA) datasets. Our evaluation across the three abilities confirms that MLLMs possess fundamental low-level visual skills. However, these skills are still unstable and relatively imprecise, indicating the need for specific enhancements on MLLMs towards these abilities. We hope that our benchmark can encourage the research community to delve deeper to discover and enhance these untapped potentials of MLLMs.","sentences":["The rapid evolution of Multi-modality Large Language Models (MLLMs) has catalyzed a shift in computer vision from specialized models to general-purpose foundation models.","Nevertheless, there is still an inadequacy in assessing the abilities of MLLMs on low-level visual perception and understanding.","To address this gap, we present Q-Bench, a holistic benchmark crafted to systematically evaluate potential abilities of MLLMs on three realms: low-level visual perception, low-level visual description, and overall visual quality assessment.","a) To evaluate the low-level perception ability, we construct the LLVisionQA dataset, consisting of 2,990 diverse-sourced images, each equipped with a human-asked question focusing on its low-level attributes.","We then measure the correctness of MLLMs on answering these questions.","b)","To examine the description ability of MLLMs on low-level information, we propose the LLDescribe dataset consisting of long expert-labelled golden low-level text descriptions on 499 images, and a GPT-involved comparison pipeline between outputs of MLLMs and the golden descriptions.","c)","Besides these two tasks, we further measure their visual quality assessment ability to align with human opinion scores.","Specifically, we design a softmax-based strategy that enables MLLMs to predict quantifiable quality scores, and evaluate them on various existing image quality assessment (IQA) datasets.","Our evaluation across the three abilities confirms that MLLMs possess fundamental low-level visual skills.","However, these skills are still unstable and relatively imprecise, indicating the need for specific enhancements on MLLMs towards these abilities.","We hope that our benchmark can encourage the research community to delve deeper to discover and enhance these untapped potentials of MLLMs."],"url":"http://arxiv.org/abs/2309.14181v1"}
{"created":"2023-09-25 14:40:27","title":"Federated Learning Under Restricted User Availability","abstract":"Federated Learning (FL) is a decentralized machine learning framework that enables collaborative model training while respecting data privacy. In various applications, non-uniform availability or participation of users is unavoidable due to an adverse or stochastic environment, the latter often being uncontrollable during learning. Here, we posit a generic user selection mechanism implementing a possibly randomized, stationary selection policy, suggestively termed as a Random Access Model (RAM). We propose a new formulation of the FL problem which effectively captures and mitigates limited participation of data originating from infrequent, or restricted users, at the presence of a RAM. By employing the Conditional Value-at-Risk (CVaR) over the (unknown) RAM distribution, we extend the expected loss FL objective to a risk-aware objective, enabling the design of an efficient training algorithm that is completely oblivious to the RAM, and with essentially identical complexity as FedAvg. Our experiments on synthetic and benchmark datasets show that the proposed approach achieves significantly improved performance as compared with standard FL, under a variety of setups.","sentences":["Federated Learning (FL) is a decentralized machine learning framework that enables collaborative model training while respecting data privacy.","In various applications, non-uniform availability or participation of users is unavoidable due to an adverse or stochastic environment, the latter often being uncontrollable during learning.","Here, we posit a generic user selection mechanism implementing a possibly randomized, stationary selection policy, suggestively termed as a Random Access Model (RAM).","We propose a new formulation of the FL problem which effectively captures and mitigates limited participation of data originating from infrequent, or restricted users, at the presence of a RAM.","By employing the Conditional Value-at-Risk (CVaR) over the (unknown) RAM distribution, we extend the expected loss FL objective to a risk-aware objective, enabling the design of an efficient training algorithm that is completely oblivious to the RAM, and with essentially identical complexity as FedAvg.","Our experiments on synthetic and benchmark datasets show that the proposed approach achieves significantly improved performance as compared with standard FL, under a variety of setups."],"url":"http://arxiv.org/abs/2309.14176v1"}
{"created":"2023-09-25 14:37:38","title":"The Influence of Cognitive Biases on Architectural Technical Debt","abstract":"Cognitive biases exert a significant influence on human thinking and decision-making. In order to identify how they influence the occurrence of architectural technical debt, a series of semi-structured interviews with software architects was performed. The results show which classes of architectural technical debt originate from cognitive biases, and reveal the antecedents of technical debt items (classes) through biases. This way, we analysed how and when cognitive biases lead to the creation of technical debt. We also identified a set of debiasing techniques that can be used in order to prevent the negative influence of cognitive biases. The observations of the role of organisational culture in the avoidance of inadvertent technical debt throw a new light on that issue.","sentences":["Cognitive biases exert a significant influence on human thinking and decision-making.","In order to identify how they influence the occurrence of architectural technical debt, a series of semi-structured interviews with software architects was performed.","The results show which classes of architectural technical debt originate from cognitive biases, and reveal the antecedents of technical debt items (classes) through biases.","This way, we analysed how and when cognitive biases lead to the creation of technical debt.","We also identified a set of debiasing techniques that can be used in order to prevent the negative influence of cognitive biases.","The observations of the role of organisational culture in the avoidance of inadvertent technical debt throw a new light on that issue."],"url":"http://arxiv.org/abs/2309.14175v1"}
{"created":"2023-09-25 14:33:47","title":"Only 5\\% Attention Is All You Need: Efficient Long-range Document-level Neural Machine Translation","abstract":"Document-level Neural Machine Translation (DocNMT) has been proven crucial for handling discourse phenomena by introducing document-level context information. One of the most important directions is to input the whole document directly to the standard Transformer model. In this case, efficiency becomes a critical concern due to the quadratic complexity of the attention module. Existing studies either focus on the encoder part, which cannot be deployed on sequence-to-sequence generation tasks, e.g., Machine Translation (MT), or suffer from a significant performance drop. In this work, we keep the translation performance while gaining 20\\% speed up by introducing extra selection layer based on lightweight attention that selects a small portion of tokens to be attended. It takes advantage of the original attention to ensure performance and dimension reduction to accelerate inference. Experimental results show that our method could achieve up to 95\\% sparsity (only 5\\% tokens attended) approximately, and save 93\\% computation cost on the attention module compared with the original Transformer, while maintaining the performance.","sentences":["Document-level Neural Machine Translation (DocNMT) has been proven crucial for handling discourse phenomena by introducing document-level context information.","One of the most important directions is to input the whole document directly to the standard Transformer model.","In this case, efficiency becomes a critical concern due to the quadratic complexity of the attention module.","Existing studies either focus on the encoder part, which cannot be deployed on sequence-to-sequence generation tasks, e.g., Machine Translation (MT), or suffer from a significant performance drop.","In this work, we keep the translation performance while gaining 20\\% speed up by introducing extra selection layer based on lightweight attention that selects a small portion of tokens to be attended.","It takes advantage of the original attention to ensure performance and dimension reduction to accelerate inference.","Experimental results show that our method could achieve up to 95\\% sparsity (only 5\\% tokens attended) approximately, and save 93\\% computation cost on the attention module compared with the original Transformer, while maintaining the performance."],"url":"http://arxiv.org/abs/2309.14174v1"}
{"created":"2023-09-25 14:21:59","title":"Targeted Attacks: Redefining Spear Phishing and Business Email Compromise","abstract":"In today's digital world, cybercrime is responsible for significant damage to organizations, including financial losses, operational disruptions, or intellectual property theft. Cyberattacks often start with an email, the major means of corporate communication. Some rare, severely damaging email threats - known as spear phishing or Business Email Compromise - have emerged. However, the literature disagrees on their definition, impeding security vendors and researchers from mitigating targeted attacks. Therefore, we introduce targeted attacks. We describe targeted-attack-detection techniques as well as social-engineering methods used by fraudsters. Additionally, we present text-based attacks - with textual content as malicious payload - and compare non-targeted and targeted variants.","sentences":["In today's digital world, cybercrime is responsible for significant damage to organizations, including financial losses, operational disruptions, or intellectual property theft.","Cyberattacks often start with an email, the major means of corporate communication.","Some rare, severely damaging email threats - known as spear phishing or Business Email Compromise - have emerged.","However, the literature disagrees on their definition, impeding security vendors and researchers from mitigating targeted attacks.","Therefore, we introduce targeted attacks.","We describe targeted-attack-detection techniques as well as social-engineering methods used by fraudsters.","Additionally, we present text-based attacks - with textual content as malicious payload - and compare non-targeted and targeted variants."],"url":"http://arxiv.org/abs/2309.14166v1"}
{"created":"2023-09-25 14:21:24","title":"Towards End-User Development for IoT: A Case Study on Semantic Parsing of Cooking Recipes for Programming Kitchen Devices","abstract":"Semantic parsing of user-generated instructional text, in the way of enabling end-users to program the Internet of Things (IoT), is an underexplored area. In this study, we provide a unique annotated corpus which aims to support the transformation of cooking recipe instructions to machine-understandable commands for IoT devices in the kitchen. Each of these commands is a tuple capturing the semantics of an instruction involving a kitchen device in terms of \"What\", \"Where\", \"Why\" and \"How\". Based on this corpus, we developed machine learning-based sequence labelling methods, namely conditional random fields (CRF) and a neural network model, in order to parse recipe instructions and extract our tuples of interest from them. Our results show that while it is feasible to train semantic parsers based on our annotations, most natural-language instructions are incomplete, and thus transforming them into formal meaning representation, is not straightforward.","sentences":["Semantic parsing of user-generated instructional text, in the way of enabling end-users to program the Internet of Things (IoT), is an underexplored area.","In this study, we provide a unique annotated corpus which aims to support the transformation of cooking recipe instructions to machine-understandable commands for IoT devices in the kitchen.","Each of these commands is a tuple capturing the semantics of an instruction involving a kitchen device in terms of \"What\", \"Where\", \"Why\" and \"How\".","Based on this corpus, we developed machine learning-based sequence labelling methods, namely conditional random fields (CRF) and a neural network model, in order to parse recipe instructions and extract our tuples of interest from them.","Our results show that while it is feasible to train semantic parsers based on our annotations, most natural-language instructions are incomplete, and thus transforming them into formal meaning representation, is not straightforward."],"url":"http://arxiv.org/abs/2309.14165v1"}
{"created":"2023-09-25 14:18:51","title":"What rationales drive architectural decisions? An empirical inquiry","abstract":"Architectural decision-making is a crucial concern for researchers and practitioners alike. There is a rationale behind every architectural decision that motivates an architect to choose one architectural solution out of a set of options. This study aims to identify which categories of rationale most frequently impact architectural decisions and investigates why these are important to practitioners. Our research comprises two steps of empirical inquiry: a questionnaire (63 participants) and 13 interviews. As a result, we obtained a set of rationales that motivated architects' decisions in practice. Out of them, we extracted a list of software quality attributes that practitioners were the most concerned about. We found that, overall, architects prefer to choose solutions which are familiar to them or that guarantee fast software implementation. Mid-career architects (5 to 15 years of experience) are more open to new solutions than senior and junior practitioners. Additionally, we found that most practitioners are not concerned about the quality attributes of compatibility and portability due to modern software development practices, such as the prevalence of using specific standards and virtualisation/containerization.","sentences":["Architectural decision-making is a crucial concern for researchers and practitioners alike.","There is a rationale behind every architectural decision that motivates an architect to choose one architectural solution out of a set of options.","This study aims to identify which categories of rationale most frequently impact architectural decisions and investigates why these are important to practitioners.","Our research comprises two steps of empirical inquiry: a questionnaire (63 participants) and 13 interviews.","As a result, we obtained a set of rationales that motivated architects' decisions in practice.","Out of them, we extracted a list of software quality attributes that practitioners were the most concerned about.","We found that, overall, architects prefer to choose solutions which are familiar to them or that guarantee fast software implementation.","Mid-career architects (5 to 15 years of experience) are more open to new solutions than senior and junior practitioners.","Additionally, we found that most practitioners are not concerned about the quality attributes of compatibility and portability due to modern software development practices, such as the prevalence of using specific standards and virtualisation/containerization."],"url":"http://arxiv.org/abs/2309.14164v1"}
{"created":"2023-09-25 14:13:26","title":"Data Upcycling Knowledge Distillation for Image Super-Resolution","abstract":"Knowledge distillation (KD) emerges as a challenging yet promising technique for compressing deep learning models, characterized by the transmission of extensive learning representations from proficient and computationally intensive teacher models to compact student models. However, only a handful of studies have endeavored to compress the models for single image super-resolution (SISR) through KD, with their effects on student model enhancement remaining marginal. In this paper, we put forth an approach from the perspective of efficient data utilization, namely, the Data Upcycling Knowledge Distillation (DUKD) which facilitates the student model by the prior knowledge teacher provided via upcycled in-domain data derived from their inputs. This upcycling process is realized through two efficient image zooming operations and invertible data augmentations which introduce the label consistency regularization to the field of KD for SISR and substantially boosts student model's generalization. The DUKD, due to its versatility, can be applied across a broad spectrum of teacher-student architectures. Comprehensive experiments across diverse benchmarks demonstrate that our proposed DUKD method significantly outperforms previous art, exemplified by an increase of up to 0.5dB in PSNR over baselines methods, and a 67% parameters reduced RCAN model's performance remaining on par with that of the RCAN teacher model.","sentences":["Knowledge distillation (KD) emerges as a challenging yet promising technique for compressing deep learning models, characterized by the transmission of extensive learning representations from proficient and computationally intensive teacher models to compact student models.","However, only a handful of studies have endeavored to compress the models for single image super-resolution (SISR) through KD, with their effects on student model enhancement remaining marginal.","In this paper, we put forth an approach from the perspective of efficient data utilization, namely, the Data Upcycling Knowledge Distillation (DUKD) which facilitates the student model by the prior knowledge teacher provided via upcycled in-domain data derived from their inputs.","This upcycling process is realized through two efficient image zooming operations and invertible data augmentations which introduce the label consistency regularization to the field of KD for SISR and substantially boosts student model's generalization.","The DUKD, due to its versatility, can be applied across a broad spectrum of teacher-student architectures.","Comprehensive experiments across diverse benchmarks demonstrate that our proposed DUKD method significantly outperforms previous art, exemplified by an increase of up to 0.5dB in PSNR over baselines methods, and a 67% parameters reduced RCAN model's performance remaining on par with that of the RCAN teacher model."],"url":"http://arxiv.org/abs/2309.14162v1"}
{"created":"2023-09-25 14:08:48","title":"An Investigation of Distribution Alignment in Multi-Genre Speaker Recognition","abstract":"Multi-genre speaker recognition is becoming increasingly popular due to its ability to better represent the complexities of real-world applications. However, a major challenge is the significant shift in the distribution of speaker vectors across different genres. While distribution alignment is a common approach to address this challenge, previous studies have mainly focused on aligning a source domain with a target domain, and the performance of multi-genre data is unknown.   This paper presents a comprehensive study of mainstream distribution alignment methods on multi-genre data, where multiple distributions need to be aligned. We analyze various methods both qualitatively and quantitatively. Our experiments on the CN-Celeb dataset show that within-between distribution alignment (WBDA) performs relatively better. However, we also found that none of the investigated methods consistently improved performance in all test cases. This suggests that solely aligning the distributions of speaker vectors may not fully address the challenges posed by multi-genre speaker recognition. Further investigation is necessary to develop a more comprehensive solution.","sentences":["Multi-genre speaker recognition is becoming increasingly popular due to its ability to better represent the complexities of real-world applications.","However, a major challenge is the significant shift in the distribution of speaker vectors across different genres.","While distribution alignment is a common approach to address this challenge, previous studies have mainly focused on aligning a source domain with a target domain, and the performance of multi-genre data is unknown.   ","This paper presents a comprehensive study of mainstream distribution alignment methods on multi-genre data, where multiple distributions need to be aligned.","We analyze various methods both qualitatively and quantitatively.","Our experiments on the CN-Celeb dataset show that within-between distribution alignment (WBDA) performs relatively better.","However, we also found that none of the investigated methods consistently improved performance in all test cases.","This suggests that solely aligning the distributions of speaker vectors may not fully address the challenges posed by multi-genre speaker recognition.","Further investigation is necessary to develop a more comprehensive solution."],"url":"http://arxiv.org/abs/2309.14158v1"}
{"created":"2023-09-25 14:08:45","title":"LAPP: Layer Adaptive Progressive Pruning for Compressing CNNs from Scratch","abstract":"Structured pruning is a commonly used convolutional neural network (CNN) compression approach. Pruning rate setting is a fundamental problem in structured pruning. Most existing works introduce too many additional learnable parameters to assign different pruning rates across different layers in CNN or cannot control the compression rate explicitly. Since too narrow network blocks information flow for training, automatic pruning rate setting cannot explore a high pruning rate for a specific layer. To overcome these limitations, we propose a novel framework named Layer Adaptive Progressive Pruning (LAPP), which gradually compresses the network during initial training of a few epochs from scratch. In particular, LAPP designs an effective and efficient pruning strategy that introduces a learnable threshold for each layer and FLOPs constraints for network. Guided by both task loss and FLOPs constraints, the learnable thresholds are dynamically and gradually updated to accommodate changes of importance scores during training. Therefore the pruning strategy can gradually prune the network and automatically determine the appropriate pruning rates for each layer. What's more, in order to maintain the expressive power of the pruned layer, before training starts, we introduce an additional lightweight bypass for each convolutional layer to be pruned, which only adds relatively few additional burdens. Our method demonstrates superior performance gains over previous compression methods on various datasets and backbone architectures. For example, on CIFAR-10, our method compresses ResNet-20 to 40.3% without accuracy drop. 55.6% of FLOPs of ResNet-18 are reduced with 0.21% top-1 accuracy increase and 0.40% top-5 accuracy increase on ImageNet.","sentences":["Structured pruning is a commonly used convolutional neural network (CNN) compression approach.","Pruning rate setting is a fundamental problem in structured pruning.","Most existing works introduce too many additional learnable parameters to assign different pruning rates across different layers in CNN or cannot control the compression rate explicitly.","Since too narrow network blocks information flow for training, automatic pruning rate setting cannot explore a high pruning rate for a specific layer.","To overcome these limitations, we propose a novel framework named Layer Adaptive Progressive Pruning (LAPP), which gradually compresses the network during initial training of a few epochs from scratch.","In particular, LAPP designs an effective and efficient pruning strategy that introduces a learnable threshold for each layer and FLOPs constraints for network.","Guided by both task loss and FLOPs constraints, the learnable thresholds are dynamically and gradually updated to accommodate changes of importance scores during training.","Therefore the pruning strategy can gradually prune the network and automatically determine the appropriate pruning rates for each layer.","What's more, in order to maintain the expressive power of the pruned layer, before training starts, we introduce an additional lightweight bypass for each convolutional layer to be pruned, which only adds relatively few additional burdens.","Our method demonstrates superior performance gains over previous compression methods on various datasets and backbone architectures.","For example, on CIFAR-10, our method compresses ResNet-20 to 40.3% without accuracy drop.","55.6% of FLOPs of ResNet-18 are reduced with 0.21% top-1 accuracy increase and 0.40% top-5 accuracy increase on ImageNet."],"url":"http://arxiv.org/abs/2309.14157v1"}
{"created":"2023-09-25 14:08:21","title":"Designing and evaluating an online reinforcement learning agent for physical exercise recommendations in N-of-1 trials","abstract":"Personalized adaptive interventions offer the opportunity to increase patient benefits, however, there are challenges in their planning and implementation. Once implemented, it is an important question whether personalized adaptive interventions are indeed clinically more effective compared to a fixed gold standard intervention. In this paper, we present an innovative N-of-1 trial study design testing whether implementing a personalized intervention by an online reinforcement learning agent is feasible and effective. Throughout, we use a new study on physical exercise recommendations to reduce pain in endometriosis for illustration. We describe the design of a contextual bandit recommendation agent and evaluate the agent in simulation studies. The results show that adaptive interventions add complexity to the design and implementation process, but have the potential to improve patients' benefits even if only few observations are available. In order to quantify the expected benefit, data from previous interventional studies is required. We expect our approach to be transferable to other interventions and clinical interventions.","sentences":["Personalized adaptive interventions offer the opportunity to increase patient benefits, however, there are challenges in their planning and implementation.","Once implemented, it is an important question whether personalized adaptive interventions are indeed clinically more effective compared to a fixed gold standard intervention.","In this paper, we present an innovative N-of-1 trial study design testing whether implementing a personalized intervention by an online reinforcement learning agent is feasible and effective.","Throughout, we use a new study on physical exercise recommendations to reduce pain in endometriosis for illustration.","We describe the design of a contextual bandit recommendation agent and evaluate the agent in simulation studies.","The results show that adaptive interventions add complexity to the design and implementation process, but have the potential to improve patients' benefits even if only few observations are available.","In order to quantify the expected benefit, data from previous interventional studies is required.","We expect our approach to be transferable to other interventions and clinical interventions."],"url":"http://arxiv.org/abs/2309.14156v1"}
{"created":"2023-09-25 14:07:27","title":"An optimized quantum minimum searching algorithm with sure-success probability and its experiment simulation with Cirq","abstract":"Finding a minimum is an essential part of mathematical models, and it plays an important role in some optimization problems. Durr and Hoyer proposed a quantum searching algorithm (DHA), with a certain probability of success, to achieve quadratic speed than classical ones. In this paper, we propose an optimized quantum minimum searching algorithm with sure-success probability, which utilizes Grover-Long searching to implement the optimal exact searching, and the dynamic strategy to reduce the iterations of our algorithm. Besides, we optimize the oracle circuit to reduce the number of gates by the simplified rules. The performance evaluation including the theoretical success rate and computational complexity shows that our algorithm has higher accuracy and efficiency than DHA algorithm. Finally, a simulation experiment based on Cirq is performed to verify its feasibility.","sentences":["Finding a minimum is an essential part of mathematical models, and it plays an important role in some optimization problems.","Durr and Hoyer proposed a quantum searching algorithm (DHA), with a certain probability of success, to achieve quadratic speed than classical ones.","In this paper, we propose an optimized quantum minimum searching algorithm with sure-success probability, which utilizes Grover-Long searching to implement the optimal exact searching, and the dynamic strategy to reduce the iterations of our algorithm.","Besides, we optimize the oracle circuit to reduce the number of gates by the simplified rules.","The performance evaluation including the theoretical success rate and computational complexity shows that our algorithm has higher accuracy and efficiency than DHA algorithm.","Finally, a simulation experiment based on Cirq is performed to verify its feasibility."],"url":"http://arxiv.org/abs/2309.14153v1"}
{"created":"2023-09-25 14:04:31","title":"Learned Contextual LiDAR Informed Visual Search in Unseen Environments","abstract":"This paper presents LIVES: LiDAR Informed Visual Search, an autonomous planner for unknown environments. We consider the pixel-wise environment perception problem where one is given 2D range data from LiDAR scans and must label points contextually as map or non-map in the surroundings for visual planning. LIVES classifies incoming 2D scans from the wide Field of View (FoV) LiDAR in unseen environments without prior map information. The map-generalizable classifier is trained from expert data collected using a simple cart platform equipped with a map-based classifier in real environments. A visual planner takes contextual data from scans and uses this information to plan viewpoints more likely to yield detection of the search target. While conventional frontier based methods for LiDAR and multi sensor exploration effectively map environments, they are not tailored to search for people indoors, which we investigate in this paper. LIVES is baselined against several existing exploration methods in simulation to verify its performance. Finally, it is validated in real-world experiments with a Spot robot in a 20x30m indoor apartment setting. Videos of experimental validation can be found on our project website at https://sites.google.com/view/lives-icra-2024/home.","sentences":["This paper presents LIVES:","LiDAR Informed Visual Search, an autonomous planner for unknown environments.","We consider the pixel-wise environment perception problem where one is given 2D range data from LiDAR scans and must label points contextually as map or non-map in the surroundings for visual planning.","LIVES classifies incoming 2D scans from the wide Field of View (FoV) LiDAR in unseen environments without prior map information.","The map-generalizable classifier is trained from expert data collected using a simple cart platform equipped with a map-based classifier in real environments.","A visual planner takes contextual data from scans and uses this information to plan viewpoints more likely to yield detection of the search target.","While conventional frontier based methods for LiDAR and multi sensor exploration effectively map environments, they are not tailored to search for people indoors, which we investigate in this paper.","LIVES is baselined against several existing exploration methods in simulation to verify its performance.","Finally, it is validated in real-world experiments with a Spot robot in a 20x30m indoor apartment setting.","Videos of experimental validation can be found on our project website at https://sites.google.com/view/lives-icra-2024/home."],"url":"http://arxiv.org/abs/2309.14150v1"}
{"created":"2023-09-25 14:02:16","title":"Multi-Domain Adaptation by Self-Supervised Learning for Speaker Verification","abstract":"In real-world applications, speaker recognition models often face various domain-mismatch challenges, leading to a significant drop in performance. Although numerous domain adaptation techniques have been developed to address this issue, almost all present methods focus on a simple configuration where the model is trained in one domain and deployed in another. However, real-world environments are often complex and may contain multiple domains, making the methods designed for one-to-one adaptation suboptimal. In our paper, we propose a self-supervised learning method to tackle this multi-domain adaptation problem. Building upon the basic self-supervised adaptation algorithm, we designed three strategies to make it suitable for multi-domain adaptation: an in-domain negative sampling strategy, a MoCo-like memory bank scheme, and a CORAL-like distribution alignment. We conducted experiments using VoxCeleb2 as the source domain dataset and CN-Celeb1 as the target multi-domain dataset. Our results demonstrate that our method clearly outperforms the basic self-supervised adaptation method, which simply treats the data of CN-Celeb1 as a single domain. Importantly, the improvement is consistent in nearly all in-domain tests and cross-domain tests, demonstrating the effectiveness of our proposed method.","sentences":["In real-world applications, speaker recognition models often face various domain-mismatch challenges, leading to a significant drop in performance.","Although numerous domain adaptation techniques have been developed to address this issue, almost all present methods focus on a simple configuration where the model is trained in one domain and deployed in another.","However, real-world environments are often complex and may contain multiple domains, making the methods designed for one-to-one adaptation suboptimal.","In our paper, we propose a self-supervised learning method to tackle this multi-domain adaptation problem.","Building upon the basic self-supervised adaptation algorithm, we designed three strategies to make it suitable for multi-domain adaptation: an in-domain negative sampling strategy, a MoCo-like memory bank scheme, and a CORAL-like distribution alignment.","We conducted experiments using VoxCeleb2 as the source domain dataset and CN-Celeb1 as the target multi-domain dataset.","Our results demonstrate that our method clearly outperforms the basic self-supervised adaptation method, which simply treats the data of CN-Celeb1 as a single domain.","Importantly, the improvement is consistent in nearly all in-domain tests and cross-domain tests, demonstrating the effectiveness of our proposed method."],"url":"http://arxiv.org/abs/2309.14149v1"}
{"created":"2023-09-25 14:01:35","title":"SPIRT: A Fault-Tolerant and Reliable Peer-to-Peer Serverless ML Training Architecture","abstract":"The advent of serverless computing has ushered in notable advancements in distributed machine learning, particularly within parameter server-based architectures. Yet, the integration of serverless features within peer-to-peer (P2P) distributed networks remains largely uncharted. In this paper, we introduce SPIRT, a fault-tolerant, reliable, and secure serverless P2P ML training architecture. designed to bridge this existing gap.   Capitalizing on the inherent robustness and reliability innate to P2P systems, SPIRT employs RedisAI for in-database operations, leading to an 82\\% reduction in the time required for model updates and gradient averaging across a variety of models and batch sizes. This architecture showcases resilience against peer failures and adeptly manages the integration of new peers, thereby highlighting its fault-tolerant characteristics and scalability. Furthermore, SPIRT ensures secure communication between peers, enhancing the reliability of distributed machine learning tasks. Even in the face of Byzantine attacks, the system's robust aggregation algorithms maintain high levels of accuracy. These findings illuminate the promising potential of serverless architectures in P2P distributed machine learning, offering a significant stride towards the development of more efficient, scalable, and resilient applications.","sentences":["The advent of serverless computing has ushered in notable advancements in distributed machine learning, particularly within parameter server-based architectures.","Yet, the integration of serverless features within peer-to-peer (P2P) distributed networks remains largely uncharted.","In this paper, we introduce SPIRT, a fault-tolerant, reliable, and secure serverless P2P ML training architecture.","designed to bridge this existing gap.   ","Capitalizing on the inherent robustness and reliability innate to P2P systems, SPIRT employs RedisAI for in-database operations, leading to an 82\\% reduction in the time required for model updates and gradient averaging across a variety of models and batch sizes.","This architecture showcases resilience against peer failures and adeptly manages the integration of new peers, thereby highlighting its fault-tolerant characteristics and scalability.","Furthermore, SPIRT ensures secure communication between peers, enhancing the reliability of distributed machine learning tasks.","Even in the face of Byzantine attacks, the system's robust aggregation algorithms maintain high levels of accuracy.","These findings illuminate the promising potential of serverless architectures in P2P distributed machine learning, offering a significant stride towards the development of more efficient, scalable, and resilient applications."],"url":"http://arxiv.org/abs/2309.14148v1"}
{"created":"2023-09-25 13:59:39","title":"Examining Temporal Bias in Abusive Language Detection","abstract":"The use of abusive language online has become an increasingly pervasive problem that damages both individuals and society, with effects ranging from psychological harm right through to escalation to real-life violence and even death. Machine learning models have been developed to automatically detect abusive language, but these models can suffer from temporal bias, the phenomenon in which topics, language use or social norms change over time. This study aims to investigate the nature and impact of temporal bias in abusive language detection across various languages and explore mitigation methods. We evaluate the performance of models on abusive data sets from different time periods. Our results demonstrate that temporal bias is a significant challenge for abusive language detection, with models trained on historical data showing a significant drop in performance over time. We also present an extensive linguistic analysis of these abusive data sets from a diachronic perspective, aiming to explore the reasons for language evolution and performance decline. This study sheds light on the pervasive issue of temporal bias in abusive language detection across languages, offering crucial insights into language evolution and temporal bias mitigation.","sentences":["The use of abusive language online has become an increasingly pervasive problem that damages both individuals and society, with effects ranging from psychological harm right through to escalation to real-life violence and even death.","Machine learning models have been developed to automatically detect abusive language, but these models can suffer from temporal bias, the phenomenon in which topics, language use or social norms change over time.","This study aims to investigate the nature and impact of temporal bias in abusive language detection across various languages and explore mitigation methods.","We evaluate the performance of models on abusive data sets from different time periods.","Our results demonstrate that temporal bias is a significant challenge for abusive language detection, with models trained on historical data showing a significant drop in performance over time.","We also present an extensive linguistic analysis of these abusive data sets from a diachronic perspective, aiming to explore the reasons for language evolution and performance decline.","This study sheds light on the pervasive issue of temporal bias in abusive language detection across languages, offering crucial insights into language evolution and temporal bias mitigation."],"url":"http://arxiv.org/abs/2309.14146v1"}
{"created":"2023-09-25 13:58:11","title":"Feedback Increases the Capacity of Queues with Bounded Service Times","abstract":"In the \"Bits Through Queues\" paper, it was conjectured that full feedback always increases the capacity of first-in-first-out queues, except when the service time distribution is memoryless. More recently, a non-explicit sufficient condition on the service time under which feedback increases capacity was provided, along with simple examples of service times satisfying this condition.   In this paper, it is shown that full feedback increases the capacity of queues with bounded service times. This result is obtained by investigating a generalized notion of feedback, with full feedback and weak feedback as particular cases.","sentences":["In the \"Bits Through Queues\" paper, it was conjectured that full feedback always increases the capacity of first-in-first-out queues, except when the service time distribution is memoryless.","More recently, a non-explicit sufficient condition on the service time under which feedback increases capacity was provided, along with simple examples of service times satisfying this condition.   ","In this paper, it is shown that full feedback increases the capacity of queues with bounded service times.","This result is obtained by investigating a generalized notion of feedback, with full feedback and weak feedback as particular cases."],"url":"http://arxiv.org/abs/2309.14145v1"}
{"created":"2023-09-25 13:51:07","title":"Exploring the Impact of Serverless Computing on Peer To Peer Training Machine Learning","abstract":"The increasing demand for computational power in big data and machine learning has driven the development of distributed training methodologies. Among these, peer-to-peer (P2P) networks provide advantages such as enhanced scalability and fault tolerance. However, they also encounter challenges related to resource consumption, costs, and communication overhead as the number of participating peers grows. In this paper, we introduce a novel architecture that combines serverless computing with P2P networks for distributed training and present a method for efficient parallel gradient computation under resource constraints.   Our findings show a significant enhancement in gradient computation time, with up to a 97.34\\% improvement compared to conventional P2P distributed training methods. As for costs, our examination confirmed that the serverless architecture could incur higher expenses, reaching up to 5.4 times more than instance-based architectures. It is essential to consider that these higher costs are associated with marked improvements in computation time, particularly under resource-constrained scenarios. Despite the cost-time trade-off, the serverless approach still holds promise due to its pay-as-you-go model. Utilizing dynamic resource allocation, it enables faster training times and optimized resource utilization, making it a promising candidate for a wide range of machine learning applications.","sentences":["The increasing demand for computational power in big data and machine learning has driven the development of distributed training methodologies.","Among these, peer-to-peer (P2P) networks provide advantages such as enhanced scalability and fault tolerance.","However, they also encounter challenges related to resource consumption, costs, and communication overhead as the number of participating peers grows.","In this paper, we introduce a novel architecture that combines serverless computing with P2P networks for distributed training and present a method for efficient parallel gradient computation under resource constraints.   ","Our findings show a significant enhancement in gradient computation time, with up to a 97.34\\% improvement compared to conventional P2P distributed training methods.","As for costs, our examination confirmed that the serverless architecture could incur higher expenses, reaching up to 5.4 times more than instance-based architectures.","It is essential to consider that these higher costs are associated with marked improvements in computation time, particularly under resource-constrained scenarios.","Despite the cost-time trade-off, the serverless approach still holds promise due to its pay-as-you-go model.","Utilizing dynamic resource allocation, it enables faster training times and optimized resource utilization, making it a promising candidate for a wide range of machine learning applications."],"url":"http://arxiv.org/abs/2309.14139v1"}
{"created":"2023-09-25 13:48:39","title":"IEBins: Iterative Elastic Bins for Monocular Depth Estimation","abstract":"Monocular depth estimation (MDE) is a fundamental topic of geometric computer vision and a core technique for many downstream applications. Recently, several methods reframe the MDE as a classification-regression problem where a linear combination of probabilistic distribution and bin centers is used to predict depth. In this paper, we propose a novel concept of iterative elastic bins (IEBins) for the classification-regression-based MDE. The proposed IEBins aims to search for high-quality depth by progressively optimizing the search range, which involves multiple stages and each stage performs a finer-grained depth search in the target bin on top of its previous stage. To alleviate the possible error accumulation during the iterative process, we utilize a novel elastic target bin to replace the original target bin, the width of which is adjusted elastically based on the depth uncertainty. Furthermore, we develop a dedicated framework composed of a feature extractor and an iterative optimizer that has powerful temporal context modeling capabilities benefiting from the GRU-based architecture. Extensive experiments on the KITTI, NYU-Depth-v2 and SUN RGB-D datasets demonstrate that the proposed method surpasses prior state-of-the-art competitors. The source code is publicly available at https://github.com/ShuweiShao/IEBins.","sentences":["Monocular depth estimation (MDE) is a fundamental topic of geometric computer vision and a core technique for many downstream applications.","Recently, several methods reframe the MDE as a classification-regression problem where a linear combination of probabilistic distribution and bin centers is used to predict depth.","In this paper, we propose a novel concept of iterative elastic bins (IEBins) for the classification-regression-based MDE.","The proposed IEBins aims to search for high-quality depth by progressively optimizing the search range, which involves multiple stages and each stage performs a finer-grained depth search in the target bin on top of its previous stage.","To alleviate the possible error accumulation during the iterative process, we utilize a novel elastic target bin to replace the original target bin, the width of which is adjusted elastically based on the depth uncertainty.","Furthermore, we develop a dedicated framework composed of a feature extractor and an iterative optimizer that has powerful temporal context modeling capabilities benefiting from the GRU-based architecture.","Extensive experiments on the KITTI, NYU-Depth-v2 and SUN RGB-D datasets demonstrate that the proposed method surpasses prior state-of-the-art competitors.","The source code is publicly available at https://github.com/ShuweiShao/IEBins."],"url":"http://arxiv.org/abs/2309.14137v1"}
{"created":"2023-09-25 13:45:28","title":"Masked Image Residual Learning for Scaling Deeper Vision Transformers","abstract":"Deeper Vision Transformers (ViTs) are more challenging to train. We expose a degradation problem in deeper layers of ViT when using masked image modeling (MIM) for pre-training. To ease the training of deeper ViTs, we introduce a self-supervised learning framework called \\textbf{M}asked \\textbf{I}mage \\textbf{R}esidual \\textbf{L}earning (\\textbf{MIRL}), which significantly alleviates the degradation problem, making scaling ViT along depth a promising direction for performance upgrade. We reformulate the pre-training objective for deeper layers of ViT as learning to recover the residual of the masked image. We provide extensive empirical evidence showing that deeper ViTs can be effectively optimized using MIRL and easily gain accuracy from increased depth. With the same level of computational complexity as ViT-Base and ViT-Large, we instantiate 4.5{$\\times$} and 2{$\\times$} deeper ViTs, dubbed ViT-S-54 and ViT-B-48. The deeper ViT-S-54, costing 3{$\\times$} less than ViT-Large, achieves performance on par with ViT-Large. ViT-B-48 achieves 86.2\\% top-1 accuracy on ImageNet. On one hand, deeper ViTs pre-trained with MIRL exhibit excellent generalization capabilities on downstream tasks, such as object detection and semantic segmentation. On the other hand, MIRL demonstrates high pre-training efficiency. With less pre-training time, MIRL yields competitive performance compared to other approaches.","sentences":["Deeper Vision Transformers (ViTs) are more challenging to train.","We expose a degradation problem in deeper layers of ViT when using masked image modeling (MIM) for pre-training.","To ease the training of deeper ViTs, we introduce a self-supervised learning framework called \\textbf{M}asked \\textbf{I}mage \\textbf{R}esidual \\textbf{L}earning (\\textbf{MIRL}), which significantly alleviates the degradation problem, making scaling ViT along depth a promising direction for performance upgrade.","We reformulate the pre-training objective for deeper layers of ViT as learning to recover the residual of the masked image.","We provide extensive empirical evidence showing that deeper ViTs can be effectively optimized using MIRL and easily gain accuracy from increased depth.","With the same level of computational complexity as ViT-Base and ViT-Large, we instantiate 4.5{$\\times$} and 2{$\\times$} deeper ViTs, dubbed ViT-S-54 and ViT-B-48.","The deeper ViT-S-54, costing 3{$\\times$} less than ViT-Large, achieves performance on par with ViT-Large.","ViT-B-48 achieves 86.2\\% top-1 accuracy on ImageNet.","On one hand, deeper ViTs pre-trained with MIRL exhibit excellent generalization capabilities on downstream tasks, such as object detection and semantic segmentation.","On the other hand, MIRL demonstrates high pre-training efficiency.","With less pre-training time, MIRL yields competitive performance compared to other approaches."],"url":"http://arxiv.org/abs/2309.14136v1"}
