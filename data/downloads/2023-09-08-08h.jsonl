{"created":"2023-09-07 17:59:45","title":"ImageBind-LLM: Multi-modality Instruction Tuning","abstract":"We present ImageBind-LLM, a multi-modality instruction tuning method of large language models (LLMs) via ImageBind. Existing works mainly focus on language and image instruction tuning, different from which, our ImageBind-LLM can respond to multi-modality conditions, including audio, 3D point clouds, video, and their embedding-space arithmetic by only image-text alignment training. During training, we adopt a learnable bind network to align the embedding space between LLaMA and ImageBind's image encoder. Then, the image features transformed by the bind network are added to word tokens of all layers in LLaMA, which progressively injects visual instructions via an attention-free and zero-initialized gating mechanism. Aided by the joint embedding of ImageBind, the simple image-text training enables our model to exhibit superior multi-modality instruction-following capabilities. During inference, the multi-modality inputs are fed into the corresponding ImageBind encoders, and processed by a proposed visual cache model for further cross-modal embedding enhancement. The training-free cache model retrieves from three million image features extracted by ImageBind, which effectively mitigates the training-inference modality discrepancy. Notably, with our approach, ImageBind-LLM can respond to instructions of diverse modalities and demonstrate significant language generation quality. Code is released at https://github.com/OpenGVLab/LLaMA-Adapter.","sentences":["We present ImageBind-LLM, a multi-modality instruction tuning method of large language models (LLMs) via ImageBind.","Existing works mainly focus on language and image instruction tuning, different from which, our ImageBind-LLM can respond to multi-modality conditions, including audio, 3D point clouds, video, and their embedding-space arithmetic by only image-text alignment training.","During training, we adopt a learnable bind network to align the embedding space between LLaMA and ImageBind's image encoder.","Then, the image features transformed by the bind network are added to word tokens of all layers in LLaMA, which progressively injects visual instructions via an attention-free and zero-initialized gating mechanism.","Aided by the joint embedding of ImageBind, the simple image-text training enables our model to exhibit superior multi-modality instruction-following capabilities.","During inference, the multi-modality inputs are fed into the corresponding ImageBind encoders, and processed by a proposed visual cache model for further cross-modal embedding enhancement.","The training-free cache model retrieves from three million image features extracted by ImageBind, which effectively mitigates the training-inference modality discrepancy.","Notably, with our approach, ImageBind-LLM can respond to instructions of diverse modalities and demonstrate significant language generation quality.","Code is released at https://github.com/OpenGVLab/LLaMA-Adapter."],"url":"http://arxiv.org/abs/2309.03905v1"}
{"created":"2023-09-07 17:59:43","title":"Exploring Sparse MoE in GANs for Text-conditioned Image Synthesis","abstract":"Due to the difficulty in scaling up, generative adversarial networks (GANs) seem to be falling from grace on the task of text-conditioned image synthesis. Sparsely-activated mixture-of-experts (MoE) has recently been demonstrated as a valid solution to training large-scale models with limited computational resources. Inspired by such a philosophy, we present Aurora, a GAN-based text-to-image generator that employs a collection of experts to learn feature processing, together with a sparse router to help select the most suitable expert for each feature point. To faithfully decode the sampling stochasticity and the text condition to the final synthesis, our router adaptively makes its decision by taking into account the text-integrated global latent code. At 64x64 image resolution, our model trained on LAION2B-en and COYO-700M achieves 6.2 zero-shot FID on MS COCO. We release the code and checkpoints to facilitate the community for further development.","sentences":["Due to the difficulty in scaling up, generative adversarial networks (GANs) seem to be falling from grace on the task of text-conditioned image synthesis.","Sparsely-activated mixture-of-experts (MoE) has recently been demonstrated as a valid solution to training large-scale models with limited computational resources.","Inspired by such a philosophy, we present Aurora, a GAN-based text-to-image generator that employs a collection of experts to learn feature processing, together with a sparse router to help select the most suitable expert for each feature point.","To faithfully decode the sampling stochasticity and the text condition to the final synthesis, our router adaptively makes its decision by taking into account the text-integrated global latent code.","At 64x64 image resolution, our model trained on LAION2B-en and COYO-700M achieves 6.2 zero-shot FID on MS COCO.","We release the code and checkpoints to facilitate the community for further development."],"url":"http://arxiv.org/abs/2309.03904v1"}
{"created":"2023-09-07 17:59:41","title":"Tracking Anything with Decoupled Video Segmentation","abstract":"Training data for video segmentation are expensive to annotate. This impedes extensions of end-to-end algorithms to new video segmentation tasks, especially in large-vocabulary settings. To 'track anything' without training on video data for every individual task, we develop a decoupled video segmentation approach (DEVA), composed of task-specific image-level segmentation and class/task-agnostic bi-directional temporal propagation. Due to this design, we only need an image-level model for the target task (which is cheaper to train) and a universal temporal propagation model which is trained once and generalizes across tasks. To effectively combine these two modules, we use bi-directional propagation for (semi-)online fusion of segmentation hypotheses from different frames to generate a coherent segmentation. We show that this decoupled formulation compares favorably to end-to-end approaches in several data-scarce tasks including large-vocabulary video panoptic segmentation, open-world video segmentation, referring video segmentation, and unsupervised video object segmentation. Code is available at: https://hkchengrex.github.io/Tracking-Anything-with-DEVA","sentences":["Training data for video segmentation are expensive to annotate.","This impedes extensions of end-to-end algorithms to new video segmentation tasks, especially in large-vocabulary settings.","To 'track anything' without training on video data for every individual task, we develop a decoupled video segmentation approach (DEVA), composed of task-specific image-level segmentation and class/task-agnostic bi-directional temporal propagation.","Due to this design, we only need an image-level model for the target task (which is cheaper to train) and a universal temporal propagation model which is trained once and generalizes across tasks.","To effectively combine these two modules, we use bi-directional propagation for (semi-)online fusion of segmentation hypotheses from different frames to generate a coherent segmentation.","We show that this decoupled formulation compares favorably to end-to-end approaches in several data-scarce tasks including large-vocabulary video panoptic segmentation, open-world video segmentation, referring video segmentation, and unsupervised video object segmentation.","Code is available at: https://hkchengrex.github.io/Tracking-Anything-with-DEVA"],"url":"http://arxiv.org/abs/2309.03903v1"}
{"created":"2023-09-07 17:58:05","title":"The Making and Breaking of Camouflage","abstract":"Not all camouflages are equally effective, as even a partially visible contour or a slight color difference can make the animal stand out and break its camouflage. In this paper, we address the question of what makes a camouflage successful, by proposing three scores for automatically assessing its effectiveness. In particular, we show that camouflage can be measured by the similarity between background and foreground features and boundary visibility. We use these camouflage scores to assess and compare all available camouflage datasets. We also incorporate the proposed camouflage score into a generative model as an auxiliary loss and show that effective camouflage images or videos can be synthesised in a scalable manner. The generated synthetic dataset is used to train a transformer-based model for segmenting camouflaged animals in videos. Experimentally, we demonstrate state-of-the-art camouflage breaking performance on the public MoCA-Mask benchmark.","sentences":["Not all camouflages are equally effective, as even a partially visible contour or a slight color difference can make the animal stand out and break its camouflage.","In this paper, we address the question of what makes a camouflage successful, by proposing three scores for automatically assessing its effectiveness.","In particular, we show that camouflage can be measured by the similarity between background and foreground features and boundary visibility.","We use these camouflage scores to assess and compare all available camouflage datasets.","We also incorporate the proposed camouflage score into a generative model as an auxiliary loss and show that effective camouflage images or videos can be synthesised in a scalable manner.","The generated synthetic dataset is used to train a transformer-based model for segmenting camouflaged animals in videos.","Experimentally, we demonstrate state-of-the-art camouflage breaking performance on the public MoCA-Mask benchmark."],"url":"http://arxiv.org/abs/2309.03899v1"}
{"created":"2023-09-07 17:58:04","title":"Multivariate, Multi-step, and Spatiotemporal Traffic Prediction for NextG Network Slicing under SLA Constraints","abstract":"This study presents a spatiotemporal traffic prediction approach for NextG mobile networks, ensuring the service-level agreements (SLAs) of each network slice. Our approach is multivariate, multi-step, and spatiotemporal. Leveraging 20 radio access network (RAN) features, peak traffic hour data, and mobility-based clustering, we propose a parametric SLA-based loss function to guarantee an SLA violation rate. We focus on single-cell, multi-cell, and slice-based prediction approaches and present a detailed comparative analysis of their performances, strengths, and limitations.   First, we address the application of single-cell and multi-cell training architectures. While single-cell training offers individual cell-level prediction, multi-cell training involves training a model using traffic from multiple cells from the same or different base stations. We show that the single-cell approach outperforms the multi-cell approach and results in test loss improvements of 11.4% and 38.1% compared to baseline SLA-based and MAE-based models, respectively.   Next, we explore slice-based traffic prediction. We present single-slice and multi-slice methods for slice-based downlink traffic volume prediction, arguing that multi-slice prediction offers a more accurate forecast. The slice-based model we introduce offers substantial test loss improvements of 28.2%, 36.4%, and 55.6% compared to our cell-based model, the baseline SLA-based model, and the baseline MAE-based model, respectively.","sentences":["This study presents a spatiotemporal traffic prediction approach for NextG mobile networks, ensuring the service-level agreements (SLAs) of each network slice.","Our approach is multivariate, multi-step, and spatiotemporal.","Leveraging 20 radio access network (RAN) features, peak traffic hour data, and mobility-based clustering, we propose a parametric SLA-based loss function to guarantee an SLA violation rate.","We focus on single-cell, multi-cell, and slice-based prediction approaches and present a detailed comparative analysis of their performances, strengths, and limitations.   ","First, we address the application of single-cell and multi-cell training architectures.","While single-cell training offers individual cell-level prediction, multi-cell training involves training a model using traffic from multiple cells from the same or different base stations.","We show that the single-cell approach outperforms the multi-cell approach and results in test loss improvements of 11.4% and 38.1% compared to baseline SLA-based and MAE-based models, respectively.   ","Next, we explore slice-based traffic prediction.","We present single-slice and multi-slice methods for slice-based downlink traffic volume prediction, arguing that multi-slice prediction offers a more accurate forecast.","The slice-based model we introduce offers substantial test loss improvements of 28.2%, 36.4%, and 55.6% compared to our cell-based model, the baseline SLA-based model, and the baseline MAE-based model, respectively."],"url":"http://arxiv.org/abs/2309.03898v1"}
{"created":"2023-09-07 17:57:29","title":"ProPainter: Improving Propagation and Transformer for Video Inpainting","abstract":"Flow-based propagation and spatiotemporal Transformer are two mainstream mechanisms in video inpainting (VI). Despite the effectiveness of these components, they still suffer from some limitations that affect their performance. Previous propagation-based approaches are performed separately either in the image or feature domain. Global image propagation isolated from learning may cause spatial misalignment due to inaccurate optical flow. Moreover, memory or computational constraints limit the temporal range of feature propagation and video Transformer, preventing exploration of correspondence information from distant frames. To address these issues, we propose an improved framework, called ProPainter, which involves enhanced ProPagation and an efficient Transformer. Specifically, we introduce dual-domain propagation that combines the advantages of image and feature warping, exploiting global correspondences reliably. We also propose a mask-guided sparse video Transformer, which achieves high efficiency by discarding unnecessary and redundant tokens. With these components, ProPainter outperforms prior arts by a large margin of 1.46 dB in PSNR while maintaining appealing efficiency.","sentences":["Flow-based propagation and spatiotemporal Transformer are two mainstream mechanisms in video inpainting (VI).","Despite the effectiveness of these components, they still suffer from some limitations that affect their performance.","Previous propagation-based approaches are performed separately either in the image or feature domain.","Global image propagation isolated from learning may cause spatial misalignment due to inaccurate optical flow.","Moreover, memory or computational constraints limit the temporal range of feature propagation and video Transformer, preventing exploration of correspondence information from distant frames.","To address these issues, we propose an improved framework, called ProPainter, which involves enhanced ProPagation and an efficient Transformer.","Specifically, we introduce dual-domain propagation that combines the advantages of image and feature warping, exploiting global correspondences reliably.","We also propose a mask-guided sparse video Transformer, which achieves high efficiency by discarding unnecessary and redundant tokens.","With these components, ProPainter outperforms prior arts by a large margin of 1.46 dB in PSNR while maintaining appealing efficiency."],"url":"http://arxiv.org/abs/2309.03897v1"}
{"created":"2023-09-07 17:56:57","title":"InstructDiffusion: A Generalist Modeling Interface for Vision Tasks","abstract":"We present InstructDiffusion, a unifying and generic framework for aligning computer vision tasks with human instructions. Unlike existing approaches that integrate prior knowledge and pre-define the output space (e.g., categories and coordinates) for each vision task, we cast diverse vision tasks into a human-intuitive image-manipulating process whose output space is a flexible and interactive pixel space. Concretely, the model is built upon the diffusion process and is trained to predict pixels according to user instructions, such as encircling the man's left shoulder in red or applying a blue mask to the left car. InstructDiffusion could handle a variety of vision tasks, including understanding tasks (such as segmentation and keypoint detection) and generative tasks (such as editing and enhancement). It even exhibits the ability to handle unseen tasks and outperforms prior methods on novel datasets. This represents a significant step towards a generalist modeling interface for vision tasks, advancing artificial general intelligence in the field of computer vision.","sentences":["We present InstructDiffusion, a unifying and generic framework for aligning computer vision tasks with human instructions.","Unlike existing approaches that integrate prior knowledge and pre-define the output space (e.g., categories and coordinates) for each vision task, we cast diverse vision tasks into a human-intuitive image-manipulating process whose output space is a flexible and interactive pixel space.","Concretely, the model is built upon the diffusion process and is trained to predict pixels according to user instructions, such as encircling the man's left shoulder in red or applying a blue mask to the left car.","InstructDiffusion could handle a variety of vision tasks, including understanding tasks (such as segmentation and keypoint detection) and generative tasks (such as editing and enhancement).","It even exhibits the ability to handle unseen tasks and outperforms prior methods on novel datasets.","This represents a significant step towards a generalist modeling interface for vision tasks, advancing artificial general intelligence in the field of computer vision."],"url":"http://arxiv.org/abs/2309.03895v1"}
{"created":"2023-09-07 17:55:01","title":"DiffusionEngine: Diffusion Model is Scalable Data Engine for Object Detection","abstract":"Data is the cornerstone of deep learning. This paper reveals that the recently developed Diffusion Model is a scalable data engine for object detection. Existing methods for scaling up detection-oriented data often require manual collection or generative models to obtain target images, followed by data augmentation and labeling to produce training pairs, which are costly, complex, or lacking diversity. To address these issues, we presentDiffusionEngine (DE), a data scaling-up engine that provides high-quality detection-oriented training pairs in a single stage. DE consists of a pre-trained diffusion model and an effective Detection-Adapter, contributing to generating scalable, diverse and generalizable detection data in a plug-and-play manner. Detection-Adapter is learned to align the implicit semantic and location knowledge in off-the-shelf diffusion models with detection-aware signals to make better bounding-box predictions. Additionally, we contribute two datasets, i.e., COCO-DE and VOC-DE, to scale up existing detection benchmarks for facilitating follow-up research. Extensive experiments demonstrate that data scaling-up via DE can achieve significant improvements in diverse scenarios, such as various detection algorithms, self-supervised pre-training, data-sparse, label-scarce, cross-domain, and semi-supervised learning. For example, when using DE with a DINO-based adapter to scale up data, mAP is improved by 3.1% on COCO, 7.6% on VOC, and 11.5% on Clipart.","sentences":["Data is the cornerstone of deep learning.","This paper reveals that the recently developed Diffusion Model is a scalable data engine for object detection.","Existing methods for scaling up detection-oriented data often require manual collection or generative models to obtain target images, followed by data augmentation and labeling to produce training pairs, which are costly, complex, or lacking diversity.","To address these issues, we presentDiffusionEngine (DE), a data scaling-up engine that provides high-quality detection-oriented training pairs in a single stage.","DE consists of a pre-trained diffusion model and an effective Detection-Adapter, contributing to generating scalable, diverse and generalizable detection data in a plug-and-play manner.","Detection-Adapter is learned to align the implicit semantic and location knowledge in off-the-shelf diffusion models with detection-aware signals to make better bounding-box predictions.","Additionally, we contribute two datasets, i.e., COCO-DE and VOC-DE, to scale up existing detection benchmarks for facilitating follow-up research.","Extensive experiments demonstrate that data scaling-up via DE can achieve significant improvements in diverse scenarios, such as various detection algorithms, self-supervised pre-training, data-sparse, label-scarce, cross-domain, and semi-supervised learning.","For example, when using DE with a DINO-based adapter to scale up data, mAP is improved by 3.1% on COCO, 7.6% on VOC, and 11.5% on Clipart."],"url":"http://arxiv.org/abs/2309.03893v1"}
{"created":"2023-09-07 17:53:20","title":"ArtiGrasp: Physically Plausible Synthesis of Bi-Manual Dexterous Grasping and Articulation","abstract":"We present ArtiGrasp, a novel method to synthesize bi-manual hand-object interactions that include grasping and articulation. This task is challenging due to the diversity of the global wrist motions and the precise finger control that are necessary to articulate objects. ArtiGrasp leverages reinforcement learning and physics simulations to train a policy that controls the global and local hand pose. Our framework unifies grasping and articulation within a single policy guided by a single hand pose reference. Moreover, to facilitate the training of the precise finger control required for articulation, we present a learning curriculum with increasing difficulty. It starts with single-hand manipulation of stationary objects and continues with multi-agent training including both hands and non-stationary objects. To evaluate our method, we introduce Dynamic Object Grasping and Articulation, a task that involves bringing an object into a target articulated pose. This task requires grasping, relocation, and articulation. We show our method's efficacy towards this task. We further demonstrate that our method can generate motions with noisy hand-object pose estimates from an off-the-shelf image-based regressor.","sentences":["We present ArtiGrasp, a novel method to synthesize bi-manual hand-object interactions that include grasping and articulation.","This task is challenging due to the diversity of the global wrist motions and the precise finger control that are necessary to articulate objects.","ArtiGrasp leverages reinforcement learning and physics simulations to train a policy that controls the global and local hand pose.","Our framework unifies grasping and articulation within a single policy guided by a single hand pose reference.","Moreover, to facilitate the training of the precise finger control required for articulation, we present a learning curriculum with increasing difficulty.","It starts with single-hand manipulation of stationary objects and continues with multi-agent training including both hands and non-stationary objects.","To evaluate our method, we introduce Dynamic Object Grasping and Articulation, a task that involves bringing an object into a target articulated pose.","This task requires grasping, relocation, and articulation.","We show our method's efficacy towards this task.","We further demonstrate that our method can generate motions with noisy hand-object pose estimates from an off-the-shelf image-based regressor."],"url":"http://arxiv.org/abs/2309.03891v1"}
{"created":"2023-09-07 17:47:26","title":"A Function Interpretation Benchmark for Evaluating Interpretability Methods","abstract":"Labeling neural network submodules with human-legible descriptions is useful for many downstream tasks: such descriptions can surface failures, guide interventions, and perhaps even explain important model behaviors. To date, most mechanistic descriptions of trained networks have involved small models, narrowly delimited phenomena, and large amounts of human labor. Labeling all human-interpretable sub-computations in models of increasing size and complexity will almost certainly require tools that can generate and validate descriptions automatically. Recently, techniques that use learned models in-the-loop for labeling have begun to gain traction, but methods for evaluating their efficacy are limited and ad-hoc. How should we validate and compare open-ended labeling tools? This paper introduces FIND (Function INterpretation and Description), a benchmark suite for evaluating the building blocks of automated interpretability methods. FIND contains functions that resemble components of trained neural networks, and accompanying descriptions of the kind we seek to generate. The functions are procedurally constructed across textual and numeric domains, and involve a range of real-world complexities, including noise, composition, approximation, and bias. We evaluate new and existing methods that use language models (LMs) to produce code-based and language descriptions of function behavior. We find that an off-the-shelf LM augmented with only black-box access to functions can sometimes infer their structure, acting as a scientist by forming hypotheses, proposing experiments, and updating descriptions in light of new data. However, LM-based descriptions tend to capture global function behavior and miss local corruptions. These results show that FIND will be useful for characterizing the performance of more sophisticated interpretability methods before they are applied to real-world models.","sentences":["Labeling neural network submodules with human-legible descriptions is useful for many downstream tasks: such descriptions can surface failures, guide interventions, and perhaps even explain important model behaviors.","To date, most mechanistic descriptions of trained networks have involved small models, narrowly delimited phenomena, and large amounts of human labor.","Labeling all human-interpretable sub-computations in models of increasing size and complexity will almost certainly require tools that can generate and validate descriptions automatically.","Recently, techniques that use learned models in-the-loop for labeling have begun to gain traction, but methods for evaluating their efficacy are limited and ad-hoc.","How should we validate and compare open-ended labeling tools?","This paper introduces FIND (Function INterpretation and Description), a benchmark suite for evaluating the building blocks of automated interpretability methods.","FIND contains functions that resemble components of trained neural networks, and accompanying descriptions of the kind we seek to generate.","The functions are procedurally constructed across textual and numeric domains, and involve a range of real-world complexities, including noise, composition, approximation, and bias.","We evaluate new and existing methods that use language models (LMs) to produce code-based and language descriptions of function behavior.","We find that an off-the-shelf LM augmented with only black-box access to functions can sometimes infer their structure, acting as a scientist by forming hypotheses, proposing experiments, and updating descriptions in light of new data.","However, LM-based descriptions tend to capture global function behavior and miss local corruptions.","These results show that FIND will be useful for characterizing the performance of more sophisticated interpretability methods before they are applied to real-world models."],"url":"http://arxiv.org/abs/2309.03886v1"}
{"created":"2023-09-07 17:45:58","title":"Zero-Shot Audio Captioning via Audibility Guidance","abstract":"The task of audio captioning is similar in essence to tasks such as image and video captioning. However, it has received much less attention. We propose three desiderata for captioning audio -- (i) fluency of the generated text, (ii) faithfulness of the generated text to the input audio, and the somewhat related (iii) audibility, which is the quality of being able to be perceived based only on audio. Our method is a zero-shot method, i.e., we do not learn to perform captioning. Instead, captioning occurs as an inference process that involves three networks that correspond to the three desired qualities: (i) A Large Language Model, in our case, for reasons of convenience, GPT-2, (ii) A model that provides a matching score between an audio file and a text, for which we use a multimodal matching network called ImageBind, and (iii) A text classifier, trained using a dataset we collected automatically by instructing GPT-4 with prompts designed to direct the generation of both audible and inaudible sentences. We present our results on the AudioCap dataset, demonstrating that audibility guidance significantly enhances performance compared to the baseline, which lacks this objective.","sentences":["The task of audio captioning is similar in essence to tasks such as image and video captioning.","However, it has received much less attention.","We propose three desiderata for captioning audio -- (i) fluency of the generated text, (ii) faithfulness of the generated text to the input audio, and the somewhat related (iii) audibility, which is the quality of being able to be perceived based only on audio.","Our method is a zero-shot method, i.e., we do not learn to perform captioning.","Instead, captioning occurs as an inference process that involves three networks that correspond to the three desired qualities: (i) A Large Language Model, in our case, for reasons of convenience, GPT-2, (ii) A model that provides a matching score between an audio file and a text, for which we use a multimodal matching network called ImageBind, and (iii) A text classifier, trained using a dataset we collected automatically by instructing GPT-4 with prompts designed to direct the generation of both audible and inaudible sentences.","We present our results on the AudioCap dataset, demonstrating that audibility guidance significantly enhances performance compared to the baseline, which lacks this objective."],"url":"http://arxiv.org/abs/2309.03884v1"}
{"created":"2023-09-07 17:45:31","title":"DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models","abstract":"Despite their impressive capabilities, large language models (LLMs) are prone to hallucinations, i.e., generating content that deviates from facts seen during pretraining. We propose a simple decoding strategy for reducing hallucinations with pretrained LLMs that does not require conditioning on retrieved external knowledge nor additional fine-tuning. Our approach obtains the next-token distribution by contrasting the differences in logits obtained from projecting the later layers versus earlier layers to the vocabulary space, exploiting the fact that factual knowledge in an LLMs has generally been shown to be localized to particular transformer layers. We find that this Decoding by Contrasting Layers (DoLa) approach is able to better surface factual knowledge and reduce the generation of incorrect facts. DoLa consistently improves the truthfulness across multiple choices tasks and open-ended generation tasks, for example improving the performance of LLaMA family models on TruthfulQA by 12-17% absolute points, demonstrating its potential in making LLMs reliably generate truthful facts.","sentences":["Despite their impressive capabilities, large language models (LLMs) are prone to hallucinations, i.e., generating content that deviates from facts seen during pretraining.","We propose a simple decoding strategy for reducing hallucinations with pretrained LLMs that does not require conditioning on retrieved external knowledge nor additional fine-tuning.","Our approach obtains the next-token distribution by contrasting the differences in logits obtained from projecting the later layers versus earlier layers to the vocabulary space, exploiting the fact that factual knowledge in an LLMs has generally been shown to be localized to particular transformer layers.","We find that this Decoding by Contrasting Layers (DoLa) approach is able to better surface factual knowledge and reduce the generation of incorrect facts.","DoLa consistently improves the truthfulness across multiple choices tasks and open-ended generation tasks, for example improving the performance of LLaMA family models on TruthfulQA by 12-17% absolute points, demonstrating its potential in making LLMs reliably generate truthful facts."],"url":"http://arxiv.org/abs/2309.03883v1"}
{"created":"2023-09-07 17:44:56","title":"On Large Language Models' Selection Bias in Multi-Choice Questions","abstract":"Multi-choice questions (MCQs) serve as a common yet important task format in the research of large language models (LLMs). Our work shows that LLMs exhibit an inherent \"selection bias\" in MCQs, which refers to LLMs' preferences to select options located at specific positions (like \"Option C\"). This bias is prevalent across various LLMs, making their performance vulnerable to option position changes in MCQs. We identify that one primary cause resulting in selection bias is option numbering, i.e., the ID symbols A/B/C/D associated with the options. To mitigate selection bias, we propose a new method called PriDe. PriDe first decomposes the observed model prediction distribution into an intrinsic prediction over option contents and a prior distribution over option IDs. It then estimates the prior by permutating option contents on a small number of test samples, which is used to debias the subsequent test samples. We demonstrate that, as a label-free, inference-time method, PriDe achieves a more effective and computation-efficient debiasing than strong baselines. We further show that the priors estimated by PriDe generalize well across different domains, highlighting its practical potential in broader scenarios.","sentences":["Multi-choice questions (MCQs) serve as a common yet important task format in the research of large language models (LLMs).","Our work shows that LLMs exhibit an inherent \"selection bias\" in MCQs, which refers to LLMs' preferences to select options located at specific positions (like \"Option C\").","This bias is prevalent across various LLMs, making their performance vulnerable to option position changes in MCQs.","We identify that one primary cause resulting in selection bias is option numbering, i.e., the ID symbols A/B/C/D associated with the options.","To mitigate selection bias, we propose a new method called PriDe.","PriDe first decomposes the observed model prediction distribution into an intrinsic prediction over option contents and a prior distribution over option IDs.","It then estimates the prior by permutating option contents on a small number of test samples, which is used to debias the subsequent test samples.","We demonstrate that, as a label-free, inference-time method, PriDe achieves a more effective and computation-efficient debiasing than strong baselines.","We further show that the priors estimated by PriDe generalize well across different domains, highlighting its practical potential in broader scenarios."],"url":"http://arxiv.org/abs/2309.03882v1"}
{"created":"2023-09-07 17:44:18","title":"Better Practices for Domain Adaptation","abstract":"Distribution shifts are all too common in real-world applications of machine learning. Domain adaptation (DA) aims to address this by providing various frameworks for adapting models to the deployment data without using labels. However, the domain shift scenario raises a second more subtle challenge: the difficulty of performing hyperparameter optimisation (HPO) for these adaptation algorithms without access to a labelled validation set. The unclear validation protocol for DA has led to bad practices in the literature, such as performing HPO using the target test labels when, in real-world scenarios, they are not available. This has resulted in over-optimism about DA research progress compared to reality. In this paper, we analyse the state of DA when using good evaluation practice, by benchmarking a suite of candidate validation criteria and using them to assess popular adaptation algorithms. We show that there are challenges across all three branches of domain adaptation methodology including Unsupervised Domain Adaptation (UDA), Source-Free Domain Adaptation (SFDA), and Test Time Adaptation (TTA). While the results show that realistically achievable performance is often worse than expected, they also show that using proper validation splits is beneficial, as well as showing that some previously unexplored validation metrics provide the best options to date. Altogether, our improved practices covering data, training, validation and hyperparameter optimisation form a new rigorous pipeline to improve benchmarking, and hence research progress, within this important field going forward.","sentences":["Distribution shifts are all too common in real-world applications of machine learning.","Domain adaptation (DA) aims to address this by providing various frameworks for adapting models to the deployment data without using labels.","However, the domain shift scenario raises a second more subtle challenge: the difficulty of performing hyperparameter optimisation (HPO) for these adaptation algorithms without access to a labelled validation set.","The unclear validation protocol for DA has led to bad practices in the literature, such as performing HPO using the target test labels when, in real-world scenarios, they are not available.","This has resulted in over-optimism about DA research progress compared to reality.","In this paper, we analyse the state of DA when using good evaluation practice, by benchmarking a suite of candidate validation criteria and using them to assess popular adaptation algorithms.","We show that there are challenges across all three branches of domain adaptation methodology including Unsupervised Domain Adaptation (UDA), Source-Free Domain Adaptation (SFDA), and Test Time Adaptation (TTA).","While the results show that realistically achievable performance is often worse than expected, they also show that using proper validation splits is beneficial, as well as showing that some previously unexplored validation metrics provide the best options to date.","Altogether, our improved practices covering data, training, validation and hyperparameter optimisation form a new rigorous pipeline to improve benchmarking, and hence research progress, within this important field going forward."],"url":"http://arxiv.org/abs/2309.03879v1"}
{"created":"2023-09-07 17:41:41","title":"Introducing \"Forecast Utterance\" for Conversational Data Science","abstract":"Envision an intelligent agent capable of assisting users in conducting forecasting tasks through intuitive, natural conversations, without requiring in-depth knowledge of the underlying machine learning (ML) processes. A significant challenge for the agent in this endeavor is to accurately comprehend the user's prediction goals and, consequently, formulate precise ML tasks. In this paper, we take a pioneering step towards this ambitious goal by introducing a new concept called Forecast Utterance and then focus on the automatic and accurate interpretation of users' prediction goals from these utterances. Specifically, we frame the task as a slot-filling problem, where each slot corresponds to a specific aspect of the goal prediction task. We then employ two zero-shot methods for solving the slot-filling task, namely: 1) Entity Extraction (EE), and 2) Question-Answering (QA) techniques. Our experiments, conducted with three meticulously crafted data sets, validate the viability of our ambitious goal and demonstrate the effectiveness of both EE and QA techniques in interpreting Forecast Utterances.","sentences":["Envision an intelligent agent capable of assisting users in conducting forecasting tasks through intuitive, natural conversations, without requiring in-depth knowledge of the underlying machine learning (ML) processes.","A significant challenge for the agent in this endeavor is to accurately comprehend the user's prediction goals and, consequently, formulate precise ML tasks.","In this paper, we take a pioneering step towards this ambitious goal by introducing a new concept called Forecast Utterance and then focus on the automatic and accurate interpretation of users' prediction goals from these utterances.","Specifically, we frame the task as a slot-filling problem, where each slot corresponds to a specific aspect of the goal prediction task.","We then employ two zero-shot methods for solving the slot-filling task, namely: 1) Entity Extraction (EE), and 2) Question-Answering (QA) techniques.","Our experiments, conducted with three meticulously crafted data sets, validate the viability of our ambitious goal and demonstrate the effectiveness of both EE and QA techniques in interpreting Forecast Utterances."],"url":"http://arxiv.org/abs/2309.03877v1"}
{"created":"2023-09-07 17:41:01","title":"OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs","abstract":"Instruction-tuned Large Language Models (LLMs) have recently showcased remarkable ability to generate fitting responses to natural language instructions. However, an open research question concerns the inherent biases of trained models and their responses. For instance, if the data used to tune an LLM is dominantly written by persons with a specific political bias, we might expect generated answers to share this bias. Current research work seeks to de-bias such models, or suppress potentially biased answers. With this demonstration, we take a different view on biases in instruction-tuning: Rather than aiming to suppress them, we aim to make them explicit and transparent. To this end, we present OpinionGPT, a web demo in which users can ask questions and select all biases they wish to investigate. The demo will answer this question using a model fine-tuned on text representing each of the selected biases, allowing side-by-side comparison. To train the underlying model, we identified 11 different biases (political, geographic, gender, age) and derived an instruction-tuning corpus in which each answer was written by members of one of these demographics. This paper presents OpinionGPT, illustrates how we trained the bias-aware model and showcases the web application (available at https://opiniongpt.informatik.hu-berlin.de).","sentences":["Instruction-tuned Large Language Models (LLMs) have recently showcased remarkable ability to generate fitting responses to natural language instructions.","However, an open research question concerns the inherent biases of trained models and their responses.","For instance, if the data used to tune an LLM is dominantly written by persons with a specific political bias, we might expect generated answers to share this bias.","Current research work seeks to de-bias such models, or suppress potentially biased answers.","With this demonstration, we take a different view on biases in instruction-tuning: Rather than aiming to suppress them, we aim to make them explicit and transparent.","To this end, we present OpinionGPT, a web demo in which users can ask questions and select all biases they wish to investigate.","The demo will answer this question using a model fine-tuned on text representing each of the selected biases, allowing side-by-side comparison.","To train the underlying model, we identified 11 different biases (political, geographic, gender, age) and derived an instruction-tuning corpus in which each answer was written by members of one of these demographics.","This paper presents OpinionGPT, illustrates how we trained the bias-aware model and showcases the web application (available at https://opiniongpt.informatik.hu-berlin.de)."],"url":"http://arxiv.org/abs/2309.03876v1"}
{"created":"2023-09-07 17:38:10","title":"Network Sampling Methods for Estimating Social Networks, Population Percentages and Totals of People Experiencing Homelessness","abstract":"In this article, we propose using network-based sampling strategies to estimate the number of unsheltered people experiencing homelessness within a given administrative service unit, known as a Continuum of Care. Further, we specifically advocate for the network sampling method known as Respondent Driven Sampling (RDS), which has been shown to provide unbiased or low-biased estimates of totals and proportions for hard-to-reach populations in contexts where a sampling frame (e.g., housing addresses) not available. To make the RDS estimator work for estimating the total number of unsheltered people, we introduce a new method that leverages administrative data from the HUD-mandated Homeless Management Information System (HMIS). The HMIS provides high-quality counts and demographics for people experiencing homelessness who sleep in emergency shelters. We then demonstrate this method using network data collected in Nashville, TN, combined with simulation methods to illustrate the efficacy of this approach. Finally, we end with discussing how this could be used in practice.","sentences":["In this article, we propose using network-based sampling strategies to estimate the number of unsheltered people experiencing homelessness within a given administrative service unit, known as a Continuum of Care.","Further, we specifically advocate for the network sampling method known as Respondent Driven Sampling (RDS), which has been shown to provide unbiased or low-biased estimates of totals and proportions for hard-to-reach populations in contexts where a sampling frame (e.g., housing addresses) not available.","To make the RDS estimator work for estimating the total number of unsheltered people, we introduce a new method that leverages administrative data from the HUD-mandated Homeless Management Information System (HMIS).","The HMIS provides high-quality counts and demographics for people experiencing homelessness who sleep in emergency shelters.","We then demonstrate this method using network data collected in Nashville, TN, combined with simulation methods to illustrate the efficacy of this approach.","Finally, we end with discussing how this could be used in practice."],"url":"http://arxiv.org/abs/2309.03875v1"}
{"created":"2023-09-07 17:36:02","title":"Box-based Refinement for Weakly Supervised and Unsupervised Localization Tasks","abstract":"It has been established that training a box-based detector network can enhance the localization performance of weakly supervised and unsupervised methods. Moreover, we extend this understanding by demonstrating that these detectors can be utilized to improve the original network, paving the way for further advancements. To accomplish this, we train the detectors on top of the network output instead of the image data and apply suitable loss backpropagation. Our findings reveal a significant improvement in phrase grounding for the ``what is where by looking'' task, as well as various methods of unsupervised object discovery. Our code is available at https://github.com/eyalgomel/box-based-refinement.","sentences":["It has been established that training a box-based detector network can enhance the localization performance of weakly supervised and unsupervised methods.","Moreover, we extend this understanding by demonstrating that these detectors can be utilized to improve the original network, paving the way for further advancements.","To accomplish this, we train the detectors on top of the network output instead of the image data and apply suitable loss backpropagation.","Our findings reveal a significant improvement in phrase grounding for the ``what is where by looking'' task, as well as various methods of unsupervised object discovery.","Our code is available at https://github.com/eyalgomel/box-based-refinement."],"url":"http://arxiv.org/abs/2309.03874v1"}
{"created":"2023-09-07 17:33:27","title":"Private Membership Aggregation","abstract":"We consider the problem of private membership aggregation (PMA), in which a user counts the number of times a certain element is stored in a system of independent parties that store arbitrary sets of elements from a universal alphabet. The parties are not allowed to learn which element is being counted by the user. Further, neither the user nor the other parties are allowed to learn the stored elements of each party involved in the process. PMA is a generalization of the recently introduced problem of $K$ private set intersection ($K$-PSI). The $K$-PSI problem considers a set of $M$ parties storing arbitrary sets of elements, and a user who wants to determine if a certain element is repeated at least at $K$ parties out of the $M$ parties without learning which party has the required element and which party does not. To solve the general problem of PMA, we dissect it into four categories based on the privacy requirement and the collusions among databases/parties. We map these problems into equivalent private information retrieval (PIR) problems. We propose achievable schemes for each of the four variants of the problem based on the concept of cross-subspace alignment (CSA). The proposed schemes achieve \\emph{linear} communication complexity as opposed to the state-of-the-art $K$-PSI scheme that requires \\emph{exponential} complexity even though our PMA problems contain more security and privacy constraints.","sentences":["We consider the problem of private membership aggregation (PMA), in which a user counts the number of times a certain element is stored in a system of independent parties that store arbitrary sets of elements from a universal alphabet.","The parties are not allowed to learn which element is being counted by the user.","Further, neither the user nor the other parties are allowed to learn the stored elements of each party involved in the process.","PMA is a generalization of the recently introduced problem of $K$ private set intersection ($K$-PSI).","The $K$-PSI problem considers a set of $M$ parties storing arbitrary sets of elements, and a user who wants to determine if a certain element is repeated at least at $K$ parties out of the $M$ parties without learning which party has the required element and which party does not.","To solve the general problem of PMA, we dissect it into four categories based on the privacy requirement and the collusions among databases/parties.","We map these problems into equivalent private information retrieval (PIR) problems.","We propose achievable schemes for each of the four variants of the problem based on the concept of cross-subspace alignment (CSA).","The proposed schemes achieve \\emph{linear} communication complexity as opposed to the state-of-the-art $K$-PSI scheme that requires \\emph{exponential} complexity even though our PMA problems contain more security and privacy constraints."],"url":"http://arxiv.org/abs/2309.03872v1"}
{"created":"2023-09-07 17:30:36","title":"Text-to-feature diffusion for audio-visual few-shot learning","abstract":"Training deep learning models for video classification from audio-visual data commonly requires immense amounts of labeled training data collected via a costly process. A challenging and underexplored, yet much cheaper, setup is few-shot learning from video data. In particular, the inherently multi-modal nature of video data with sound and visual information has not been leveraged extensively for the few-shot video classification task. Therefore, we introduce a unified audio-visual few-shot video classification benchmark on three datasets, i.e. the VGGSound-FSL, UCF-FSL, ActivityNet-FSL datasets, where we adapt and compare ten methods. In addition, we propose AV-DIFF, a text-to-feature diffusion framework, which first fuses the temporal and audio-visual features via cross-modal attention and then generates multi-modal features for the novel classes. We show that AV-DIFF obtains state-of-the-art performance on our proposed benchmark for audio-visual (generalised) few-shot learning. Our benchmark paves the way for effective audio-visual classification when only limited labeled data is available. Code and data are available at https://github.com/ExplainableML/AVDIFF-GFSL.","sentences":["Training deep learning models for video classification from audio-visual data commonly requires immense amounts of labeled training data collected via a costly process.","A challenging and underexplored, yet much cheaper, setup is few-shot learning from video data.","In particular, the inherently multi-modal nature of video data with sound and visual information has not been leveraged extensively for the few-shot video classification task.","Therefore, we introduce a unified audio-visual few-shot video classification benchmark on three datasets, i.e. the VGGSound-FSL, UCF-FSL, ActivityNet-FSL datasets, where we adapt and compare ten methods.","In addition, we propose AV-DIFF, a text-to-feature diffusion framework, which first fuses the temporal and audio-visual features via cross-modal attention and then generates multi-modal features for the novel classes.","We show that AV-DIFF obtains state-of-the-art performance on our proposed benchmark for audio-visual (generalised) few-shot learning.","Our benchmark paves the way for effective audio-visual classification when only limited labeled data is available.","Code and data are available at https://github.com/ExplainableML/AVDIFF-GFSL."],"url":"http://arxiv.org/abs/2309.03869v1"}
{"created":"2023-09-07 17:14:59","title":"The complexity of solving a random polynomial system","abstract":"A multivariate cryptograpic instance in practice is a multivariate polynomial system. So the security of a protocol rely on the complexity of solving a multivariate polynomial system. In this paper there is an overview on a general algorithm used to solve a multivariate system and the quantity to which the complexity of this algorithm depends on: the solving degree. Unfortunately, it is hard to compute. For this reason, it is introduced an invariant: the degree of regularity. This invariant, under certain condition, give us an upper bound on the solving degree. Then we speak about random polynomial systems and in particular what \"random\" means to us. Finally, we give an upper bound on both the degree of regularity and the solving degree of such random systems.","sentences":["A multivariate cryptograpic instance in practice is a multivariate polynomial system.","So the security of a protocol rely on the complexity of solving a multivariate polynomial system.","In this paper there is an overview on a general algorithm used to solve a multivariate system and the quantity to which the complexity of this algorithm depends on: the solving degree.","Unfortunately, it is hard to compute.","For this reason, it is introduced an invariant: the degree of regularity.","This invariant, under certain condition, give us an upper bound on the solving degree.","Then we speak about random polynomial systems and in particular what \"random\" means to us.","Finally, we give an upper bound on both the degree of regularity and the solving degree of such random systems."],"url":"http://arxiv.org/abs/2309.03855v1"}
{"created":"2023-09-07 17:07:36","title":"FLM-101B: An Open LLM and How to Train It with $100K Budget","abstract":"Large language models (LLMs) have achieved remarkable success in NLP and multimodal tasks. Despite these successes, their development faces two main challenges: (i) high computational cost; and (ii) difficulty in conducting fair and objective evaluations. LLMs are prohibitively expensive, making it feasible for only a few major players to undertake their training, thereby constraining both research and application opportunities. This underscores the importance of cost-effective LLM training. In this paper, we utilize a growth strategy to significantly reduce LLM training cost. We demonstrate that an LLM with 101B parameters and 0.31TB tokens can be trained on a $100K budget. We also adopt a systematic evaluation paradigm for the IQ evaluation of LLMs, in complement to existing evaluations that focus more on knowledge-oriented abilities. We introduce our benchmark including evaluations on important aspects of intelligence including symbolic mapping, itrule understanding, pattern mining, and anti-interference. Such evaluations minimize the potential impact of memorization. Experimental results show that our model FLM-101B, trained with a budget of $100K, achieves comparable performance to powerful and well-known models, eg GPT-3 and GLM-130B, especially in the IQ benchmark evaluations with contexts unseen in training data. The checkpoint of FLM-101B will be open-sourced at https://huggingface.co/CofeAI/FLM-101B.","sentences":["Large language models (LLMs) have achieved remarkable success in NLP and multimodal tasks.","Despite these successes, their development faces two main challenges: (i) high computational cost; and (ii) difficulty in conducting fair and objective evaluations.","LLMs are prohibitively expensive, making it feasible for only a few major players to undertake their training, thereby constraining both research and application opportunities.","This underscores the importance of cost-effective LLM training.","In this paper, we utilize a growth strategy to significantly reduce LLM training cost.","We demonstrate that an LLM with 101B parameters and 0.31TB tokens can be trained on a $100K budget.","We also adopt a systematic evaluation paradigm for the IQ evaluation of LLMs, in complement to existing evaluations that focus more on knowledge-oriented abilities.","We introduce our benchmark including evaluations on important aspects of intelligence including symbolic mapping, itrule understanding, pattern mining, and anti-interference.","Such evaluations minimize the potential impact of memorization.","Experimental results show that our model FLM-101B, trained with a budget of $100K, achieves comparable performance to powerful and well-known models, eg GPT-3 and GLM-130B, especially in the IQ benchmark evaluations with contexts unseen in training data.","The checkpoint of FLM-101B will be open-sourced at https://huggingface.co/CofeAI/FLM-101B."],"url":"http://arxiv.org/abs/2309.03852v1"}
{"created":"2023-09-07 17:07:33","title":"CenTime: Event-Conditional Modelling of Censoring in Survival Analysis","abstract":"Survival analysis is a valuable tool for estimating the time until specific events, such as death or cancer recurrence, based on baseline observations. This is particularly useful in healthcare to prognostically predict clinically important events based on patient data. However, existing approaches often have limitations; some focus only on ranking patients by survivability, neglecting to estimate the actual event time, while others treat the problem as a classification task, ignoring the inherent time-ordered structure of the events. Furthermore, the effective utilization of censored samples - training data points where the exact event time is unknown - is essential for improving the predictive accuracy of the model. In this paper, we introduce CenTime, a novel approach to survival analysis that directly estimates the time to event. Our method features an innovative event-conditional censoring mechanism that performs robustly even when uncensored data is scarce. We demonstrate that our approach forms a consistent estimator for the event model parameters, even in the absence of uncensored data. Furthermore, CenTime is easily integrated with deep learning models with no restrictions on batch size or the number of uncensored samples. We compare our approach with standard survival analysis methods, including the Cox proportional-hazard model and DeepHit. Our results indicate that CenTime offers state-of-the-art performance in predicting time-to-death while maintaining comparable ranking performance. Our implementation is publicly available at https://github.com/ahmedhshahin/CenTime.","sentences":["Survival analysis is a valuable tool for estimating the time until specific events, such as death or cancer recurrence, based on baseline observations.","This is particularly useful in healthcare to prognostically predict clinically important events based on patient data.","However, existing approaches often have limitations; some focus only on ranking patients by survivability, neglecting to estimate the actual event time, while others treat the problem as a classification task, ignoring the inherent time-ordered structure of the events.","Furthermore, the effective utilization of censored samples - training data points where the exact event time is unknown - is essential for improving the predictive accuracy of the model.","In this paper, we introduce CenTime, a novel approach to survival analysis that directly estimates the time to event.","Our method features an innovative event-conditional censoring mechanism that performs robustly even when uncensored data is scarce.","We demonstrate that our approach forms a consistent estimator for the event model parameters, even in the absence of uncensored data.","Furthermore, CenTime is easily integrated with deep learning models with no restrictions on batch size or the number of uncensored samples.","We compare our approach with standard survival analysis methods, including the Cox proportional-hazard model and DeepHit.","Our results indicate that CenTime offers state-of-the-art performance in predicting time-to-death while maintaining comparable ranking performance.","Our implementation is publicly available at https://github.com/ahmedhshahin/CenTime."],"url":"http://arxiv.org/abs/2309.03851v1"}
{"created":"2023-09-07 16:58:15","title":"Experimental Study of Adversarial Attacks on ML-based xApps in O-RAN","abstract":"Open Radio Access Network (O-RAN) is considered as a major step in the evolution of next-generation cellular networks given its support for open interfaces and utilization of artificial intelligence (AI) into the deployment, operation, and maintenance of RAN. However, due to the openness of the O-RAN architecture, such AI models are inherently vulnerable to various adversarial machine learning (ML) attacks, i.e., adversarial attacks which correspond to slight manipulation of the input to the ML model. In this work, we showcase the vulnerability of an example ML model used in O-RAN, and experimentally deploy it in the near-real time (near-RT) RAN intelligent controller (RIC). Our ML-based interference classifier xApp (extensible application in near-RT RIC) tries to classify the type of interference to mitigate the interference effect on the O-RAN system. We demonstrate the first-ever scenario of how such an xApp can be impacted through an adversarial attack by manipulating the data stored in a shared database inside the near-RT RIC. Through a rigorous performance analysis deployed on a laboratory O-RAN testbed, we evaluate the performance in terms of capacity and the prediction accuracy of the interference classifier xApp using both clean and perturbed data. We show that even small adversarial attacks can significantly decrease the accuracy of ML application in near-RT RIC, which can directly impact the performance of the entire O-RAN deployment.","sentences":["Open Radio Access Network (O-RAN) is considered as a major step in the evolution of next-generation cellular networks given its support for open interfaces and utilization of artificial intelligence (AI) into the deployment, operation, and maintenance of RAN.","However, due to the openness of the O-RAN architecture, such AI models are inherently vulnerable to various adversarial machine learning (ML) attacks, i.e., adversarial attacks which correspond to slight manipulation of the input to the ML model.","In this work, we showcase the vulnerability of an example ML model used in O-RAN, and experimentally deploy it in the near-real time (near-RT) RAN intelligent controller (RIC).","Our ML-based interference classifier xApp (extensible application in near-RT RIC) tries to classify the type of interference to mitigate the interference effect on the O-RAN system.","We demonstrate the first-ever scenario of how such an xApp can be impacted through an adversarial attack by manipulating the data stored in a shared database inside the near-RT RIC.","Through a rigorous performance analysis deployed on a laboratory O-RAN testbed, we evaluate the performance in terms of capacity and the prediction accuracy of the interference classifier xApp using both clean and perturbed data.","We show that even small adversarial attacks can significantly decrease the accuracy of ML application in near-RT RIC, which can directly impact the performance of the entire O-RAN deployment."],"url":"http://arxiv.org/abs/2309.03844v1"}
{"created":"2023-09-07 16:52:27","title":"Bootstrapping Adaptive Human-Machine Interfaces with Offline Reinforcement Learning","abstract":"Adaptive interfaces can help users perform sequential decision-making tasks like robotic teleoperation given noisy, high-dimensional command signals (e.g., from a brain-computer interface). Recent advances in human-in-the-loop machine learning enable such systems to improve by interacting with users, but tend to be limited by the amount of data that they can collect from individual users in practice. In this paper, we propose a reinforcement learning algorithm to address this by training an interface to map raw command signals to actions using a combination of offline pre-training and online fine-tuning. To address the challenges posed by noisy command signals and sparse rewards, we develop a novel method for representing and inferring the user's long-term intent for a given trajectory. We primarily evaluate our method's ability to assist users who can only communicate through noisy, high-dimensional input channels through a user study in which 12 participants performed a simulated navigation task by using their eye gaze to modulate a 128-dimensional command signal from their webcam. The results show that our method enables successful goal navigation more often than a baseline directional interface, by learning to denoise user commands signals and provide shared autonomy assistance. We further evaluate on a simulated Sawyer pushing task with eye gaze control, and the Lunar Lander game with simulated user commands, and find that our method improves over baseline interfaces in these domains as well. Extensive ablation experiments with simulated user commands empirically motivate each component of our method.","sentences":["Adaptive interfaces can help users perform sequential decision-making tasks like robotic teleoperation given noisy, high-dimensional command signals (e.g., from a brain-computer interface).","Recent advances in human-in-the-loop machine learning enable such systems to improve by interacting with users, but tend to be limited by the amount of data that they can collect from individual users in practice.","In this paper, we propose a reinforcement learning algorithm to address this by training an interface to map raw command signals to actions using a combination of offline pre-training and online fine-tuning.","To address the challenges posed by noisy command signals and sparse rewards, we develop a novel method for representing and inferring the user's long-term intent for a given trajectory.","We primarily evaluate our method's ability to assist users who can only communicate through noisy, high-dimensional input channels through a user study in which 12 participants performed a simulated navigation task by using their eye gaze to modulate a 128-dimensional command signal from their webcam.","The results show that our method enables successful goal navigation more often than a baseline directional interface, by learning to denoise user commands signals and provide shared autonomy assistance.","We further evaluate on a simulated Sawyer pushing task with eye gaze control, and the Lunar Lander game with simulated user commands, and find that our method improves over baseline interfaces in these domains as well.","Extensive ablation experiments with simulated user commands empirically motivate each component of our method."],"url":"http://arxiv.org/abs/2309.03839v1"}
{"created":"2023-09-07 16:50:40","title":"Cross-Task Attention Network: Improving Multi-Task Learning for Medical Imaging Applications","abstract":"Multi-task learning (MTL) is a powerful approach in deep learning that leverages the information from multiple tasks during training to improve model performance. In medical imaging, MTL has shown great potential to solve various tasks. However, existing MTL architectures in medical imaging are limited in sharing information across tasks, reducing the potential performance improvements of MTL. In this study, we introduce a novel attention-based MTL framework to better leverage inter-task interactions for various tasks from pixel-level to image-level predictions. Specifically, we propose a Cross-Task Attention Network (CTAN) which utilizes cross-task attention mechanisms to incorporate information by interacting across tasks. We validated CTAN on four medical imaging datasets that span different domains and tasks including: radiation treatment planning prediction using planning CT images of two different target cancers (Prostate, OpenKBP); pigmented skin lesion segmentation and diagnosis using dermatoscopic images (HAM10000); and COVID-19 diagnosis and severity prediction using chest CT scans (STOIC). Our study demonstrates the effectiveness of CTAN in improving the accuracy of medical imaging tasks. Compared to standard single-task learning (STL), CTAN demonstrated a 4.67% improvement in performance and outperformed both widely used MTL baselines: hard parameter sharing (HPS) with an average performance improvement of 3.22%; and multi-task attention network (MTAN) with a relative decrease of 5.38%. These findings highlight the significance of our proposed MTL framework in solving medical imaging tasks and its potential to improve their accuracy across domains.","sentences":["Multi-task learning (MTL) is a powerful approach in deep learning that leverages the information from multiple tasks during training to improve model performance.","In medical imaging, MTL has shown great potential to solve various tasks.","However, existing MTL architectures in medical imaging are limited in sharing information across tasks, reducing the potential performance improvements of MTL.","In this study, we introduce a novel attention-based MTL framework to better leverage inter-task interactions for various tasks from pixel-level to image-level predictions.","Specifically, we propose a Cross-Task Attention Network (CTAN) which utilizes cross-task attention mechanisms to incorporate information by interacting across tasks.","We validated CTAN on four medical imaging datasets that span different domains and tasks including: radiation treatment planning prediction using planning CT images of two different target cancers (Prostate, OpenKBP); pigmented skin lesion segmentation and diagnosis using dermatoscopic images (HAM10000); and COVID-19 diagnosis and severity prediction using chest CT scans (STOIC).","Our study demonstrates the effectiveness of CTAN in improving the accuracy of medical imaging tasks.","Compared to standard single-task learning (STL), CTAN demonstrated a 4.67% improvement in performance and outperformed both widely used MTL baselines: hard parameter sharing (HPS) with an average performance improvement of 3.22%; and multi-task attention network (MTAN) with a relative decrease of 5.38%.","These findings highlight the significance of our proposed MTL framework in solving medical imaging tasks and its potential to improve their accuracy across domains."],"url":"http://arxiv.org/abs/2309.03837v1"}
{"created":"2023-09-07 16:49:38","title":"Learning from Demonstration via Probabilistic Diagrammatic Teaching","abstract":"Learning for Demonstration (LfD) enables robots to acquire new skills by imitating expert demonstrations, allowing users to communicate their instructions in an intuitive manner. Recent progress in LfD often relies on kinesthetic teaching or teleoperation as the medium for users to specify the demonstrations. Kinesthetic teaching requires physical handling of the robot, while teleoperation demands proficiency with additional hardware. This paper introduces an alternative paradigm for LfD called Diagrammatic Teaching. Diagrammatic Teaching aims to teach robots novel skills by prompting the user to sketch out demonstration trajectories on 2D images of the scene, these are then synthesised as a generative model of motion trajectories in 3D task space. Additionally, we present the Ray-tracing Probabilistic Trajectory Learning (RPTL) framework for Diagrammatic Teaching. RPTL extracts time-varying probability densities from the 2D sketches, applies ray-tracing to find corresponding regions in 3D Cartesian space, and fits a probabilistic model of motion trajectories to these regions. New motion trajectories, which mimic those sketched by the user, can then be generated from the probabilistic model. We empirically validate our framework both in simulation and on real robots, which include a fixed-base manipulator and a quadruped-mounted manipulator.","sentences":["Learning for Demonstration (LfD) enables robots to acquire new skills by imitating expert demonstrations, allowing users to communicate their instructions in an intuitive manner.","Recent progress in LfD often relies on kinesthetic teaching or teleoperation as the medium for users to specify the demonstrations.","Kinesthetic teaching requires physical handling of the robot, while teleoperation demands proficiency with additional hardware.","This paper introduces an alternative paradigm for LfD called Diagrammatic Teaching.","Diagrammatic Teaching aims to teach robots novel skills by prompting the user to sketch out demonstration trajectories on 2D images of the scene, these are then synthesised as a generative model of motion trajectories in 3D task space.","Additionally, we present the Ray-tracing Probabilistic Trajectory Learning (RPTL) framework for Diagrammatic Teaching.","RPTL extracts time-varying probability densities from the 2D sketches, applies ray-tracing to find corresponding regions in 3D Cartesian space, and fits a probabilistic model of motion trajectories to these regions.","New motion trajectories, which mimic those sketched by the user, can then be generated from the probabilistic model.","We empirically validate our framework both in simulation and on real robots, which include a fixed-base manipulator and a quadruped-mounted manipulator."],"url":"http://arxiv.org/abs/2309.03835v1"}
{"created":"2023-09-07 16:45:42","title":"Uncovering Drift in Textual Data: An Unsupervised Method for Detecting and Mitigating Drift in Machine Learning Models","abstract":"Drift in machine learning refers to the phenomenon where the statistical properties of data or context, in which the model operates, change over time leading to a decrease in its performance. Therefore, maintaining a constant monitoring process for machine learning model performance is crucial in order to proactively prevent any potential performance regression. However, supervised drift detection methods require human annotation and consequently lead to a longer time to detect and mitigate the drift. In our proposed unsupervised drift detection method, we follow a two step process. Our first step involves encoding a sample of production data as the target distribution, and the model training data as the reference distribution. In the second step, we employ a kernel-based statistical test that utilizes the maximum mean discrepancy (MMD) distance metric to compare the reference and target distributions and estimate any potential drift. Our method also identifies the subset of production data that is the root cause of the drift. The models retrained using these identified high drift samples show improved performance on online customer experience quality metrics.","sentences":["Drift in machine learning refers to the phenomenon where the statistical properties of data or context, in which the model operates, change over time leading to a decrease in its performance.","Therefore, maintaining a constant monitoring process for machine learning model performance is crucial in order to proactively prevent any potential performance regression.","However, supervised drift detection methods require human annotation and consequently lead to a longer time to detect and mitigate the drift.","In our proposed unsupervised drift detection method, we follow a two step process.","Our first step involves encoding a sample of production data as the target distribution, and the model training data as the reference distribution.","In the second step, we employ a kernel-based statistical test that utilizes the maximum mean discrepancy (MMD) distance metric to compare the reference and target distributions and estimate any potential drift.","Our method also identifies the subset of production data that is the root cause of the drift.","The models retrained using these identified high drift samples show improved performance on online customer experience quality metrics."],"url":"http://arxiv.org/abs/2309.03831v1"}
{"created":"2023-09-07 16:40:49","title":"ArtHDR-Net: Perceptually Realistic and Accurate HDR Content Creation","abstract":"High Dynamic Range (HDR) content creation has become an important topic for modern media and entertainment sectors, gaming and Augmented/Virtual Reality industries. Many methods have been proposed to recreate the HDR counterparts of input Low Dynamic Range (LDR) images/videos given a single exposure or multi-exposure LDRs. The state-of-the-art methods focus primarily on the preservation of the reconstruction's structural similarity and the pixel-wise accuracy. However, these conventional approaches do not emphasize preserving the artistic intent of the images in terms of human visual perception, which is an essential element in media, entertainment and gaming. In this paper, we attempt to study and fill this gap. We propose an architecture called ArtHDR-Net based on a Convolutional Neural Network that uses multi-exposed LDR features as input. Experimental results show that ArtHDR-Net can achieve state-of-the-art performance in terms of the HDR-VDP-2 score (i.e., mean opinion score index) while reaching competitive performance in terms of PSNR and SSIM.","sentences":["High Dynamic Range (HDR) content creation has become an important topic for modern media and entertainment sectors, gaming and Augmented/Virtual Reality industries.","Many methods have been proposed to recreate the HDR counterparts of input Low Dynamic Range (LDR) images/videos given a single exposure or multi-exposure LDRs.","The state-of-the-art methods focus primarily on the preservation of the reconstruction's structural similarity and the pixel-wise accuracy.","However, these conventional approaches do not emphasize preserving the artistic intent of the images in terms of human visual perception, which is an essential element in media, entertainment and gaming.","In this paper, we attempt to study and fill this gap.","We propose an architecture called ArtHDR-Net based on a Convolutional Neural Network that uses multi-exposed LDR features as input.","Experimental results show that ArtHDR-Net can achieve state-of-the-art performance in terms of the HDR-VDP-2 score (i.e., mean opinion score index) while reaching competitive performance in terms of PSNR and SSIM."],"url":"http://arxiv.org/abs/2309.03827v1"}
{"created":"2023-09-07 16:34:30","title":"Prime and Modulate Learning: Generation of forward models with signed back-propagation and environmental cues","abstract":"Deep neural networks employing error back-propagation for learning can suffer from exploding and vanishing gradient problems. Numerous solutions have been proposed such as normalisation techniques or limiting activation functions to linear rectifying units. In this work we follow a different approach which is particularly applicable to closed-loop learning of forward models where back-propagation makes exclusive use of the sign of the error signal to prime the learning, whilst a global relevance signal modulates the rate of learning. This is inspired by the interaction between local plasticity and a global neuromodulation. For example, whilst driving on an empty road, one can allow for slow step-wise optimisation of actions, whereas, at a busy junction, an error must be corrected at once. Hence, the error is the priming signal and the intensity of the experience is a modulating factor in the weight change. The advantages of this Prime and Modulate paradigm is twofold: it is free from normalisation and it makes use of relevant cues from the environment to enrich the learning. We present a mathematical derivation of the learning rule in z-space and demonstrate the real-time performance with a robotic platform. The results show a significant improvement in the speed of convergence compared to that of the conventional back-propagation.","sentences":["Deep neural networks employing error back-propagation for learning can suffer from exploding and vanishing gradient problems.","Numerous solutions have been proposed such as normalisation techniques or limiting activation functions to linear rectifying units.","In this work we follow a different approach which is particularly applicable to closed-loop learning of forward models where back-propagation makes exclusive use of the sign of the error signal to prime the learning, whilst a global relevance signal modulates the rate of learning.","This is inspired by the interaction between local plasticity and a global neuromodulation.","For example, whilst driving on an empty road, one can allow for slow step-wise optimisation of actions, whereas, at a busy junction, an error must be corrected at once.","Hence, the error is the priming signal and the intensity of the experience is a modulating factor in the weight change.","The advantages of this Prime and Modulate paradigm is twofold: it is free from normalisation and it makes use of relevant cues from the environment to enrich the learning.","We present a mathematical derivation of the learning rule in z-space and demonstrate the real-time performance with a robotic platform.","The results show a significant improvement in the speed of convergence compared to that of the conventional back-propagation."],"url":"http://arxiv.org/abs/2309.03825v1"}
{"created":"2023-09-07 16:33:42","title":"Training Acceleration of Low-Rank Decomposed Networks using Sequential Freezing and Rank Quantization","abstract":"Low Rank Decomposition (LRD) is a model compression technique applied to the weight tensors of deep learning models in order to reduce the number of trainable parameters and computational complexity. However, due to high number of new layers added to the architecture after applying LRD, it may not lead to a high training/inference acceleration if the decomposition ranks are not small enough. The issue is that using small ranks increases the risk of significant accuracy drop after decomposition. In this paper, we propose two techniques for accelerating low rank decomposed models without requiring to use small ranks for decomposition. These methods include rank optimization and sequential freezing of decomposed layers. We perform experiments on both convolutional and transformer-based models. Experiments show that these techniques can improve the model throughput up to 60% during training and 37% during inference when combined together while preserving the accuracy close to that of the original models","sentences":["Low Rank Decomposition (LRD) is a model compression technique applied to the weight tensors of deep learning models in order to reduce the number of trainable parameters and computational complexity.","However, due to high number of new layers added to the architecture after applying LRD, it may not lead to a high training/inference acceleration if the decomposition ranks are not small enough.","The issue is that using small ranks increases the risk of significant accuracy drop after decomposition.","In this paper, we propose two techniques for accelerating low rank decomposed models without requiring to use small ranks for decomposition.","These methods include rank optimization and sequential freezing of decomposed layers.","We perform experiments on both convolutional and transformer-based models.","Experiments show that these techniques can improve the model throughput up to 60% during training and 37% during inference when combined together while preserving the accuracy close to that of the original models"],"url":"http://arxiv.org/abs/2309.03824v1"}
{"created":"2023-09-07 16:22:55","title":"On the Reduction of the Spherical Point-in-Polygon Problem for Antipode-Excluding Spherical Polygons","abstract":"Spherical polygons used in practice are nice, but the spherical point-in-polygon problem (SPiP) has long eluded solutions based on the winding number (wn). That a punctured sphere is simply connected is to blame. As a workaround, we prove that requiring the boundary of a spherical polygon to never intersect its antipode is sufficient to reduce its SPiP problem to the planar, point-in-polygon (PiP) problem, whose state-of-the-art solution uses wn and does not utilize known interior points (KIP). We refer to such spherical polygons as boundary antipode-excluding (BAE) and show that all spherical polygons fully contained within an open hemisphere is BAE. We document two successful reduction methods, one based on rotation and the other on shearing, and address a common concern. Both reduction algorithms, when combined with a wn-PiP algorithm, solve SPiP correctly and efficiently for BAE spherical polygons. The MATLAB code provided demonstrates scenarios that are problematic for previous work.","sentences":["Spherical polygons used in practice are nice, but the spherical point-in-polygon problem (SPiP) has long eluded solutions based on the winding number (wn).","That a punctured sphere is simply connected is to blame.","As a workaround, we prove that requiring the boundary of a spherical polygon to never intersect its antipode is sufficient to reduce its SPiP problem to the planar, point-in-polygon (PiP) problem, whose state-of-the-art solution uses wn and does not utilize known interior points (KIP).","We refer to such spherical polygons as boundary antipode-excluding (BAE) and show that all spherical polygons fully contained within an open hemisphere is BAE.","We document two successful reduction methods, one based on rotation and the other on shearing, and address a common concern.","Both reduction algorithms, when combined with a wn-PiP algorithm, solve SPiP correctly and efficiently for BAE spherical polygons.","The MATLAB code provided demonstrates scenarios that are problematic for previous work."],"url":"http://arxiv.org/abs/2309.03822v1"}
{"created":"2023-09-07 16:12:06","title":"T2IW: Joint Text to Image & Watermark Generation","abstract":"Recent developments in text-conditioned image generative models have revolutionized the production of realistic results. Unfortunately, this has also led to an increase in privacy violations and the spread of false information, which requires the need for traceability, privacy protection, and other security measures. However, existing text-to-image paradigms lack the technical capabilities to link traceable messages with image generation. In this study, we introduce a novel task for the joint generation of text to image and watermark (T2IW). This T2IW scheme ensures minimal damage to image quality when generating a compound image by forcing the semantic feature and the watermark signal to be compatible in pixels. Additionally, by utilizing principles from Shannon information theory and non-cooperative game theory, we are able to separate the revealed image and the revealed watermark from the compound image. Furthermore, we strengthen the watermark robustness of our approach by subjecting the compound image to various post-processing attacks, with minimal pixel distortion observed in the revealed watermark. Extensive experiments have demonstrated remarkable achievements in image quality, watermark invisibility, and watermark robustness, supported by our proposed set of evaluation metrics.","sentences":["Recent developments in text-conditioned image generative models have revolutionized the production of realistic results.","Unfortunately, this has also led to an increase in privacy violations and the spread of false information, which requires the need for traceability, privacy protection, and other security measures.","However, existing text-to-image paradigms lack the technical capabilities to link traceable messages with image generation.","In this study, we introduce a novel task for the joint generation of text to image and watermark (T2IW).","This T2IW scheme ensures minimal damage to image quality when generating a compound image by forcing the semantic feature and the watermark signal to be compatible in pixels.","Additionally, by utilizing principles from Shannon information theory and non-cooperative game theory, we are able to separate the revealed image and the revealed watermark from the compound image.","Furthermore, we strengthen the watermark robustness of our approach by subjecting the compound image to various post-processing attacks, with minimal pixel distortion observed in the revealed watermark.","Extensive experiments have demonstrated remarkable achievements in image quality, watermark invisibility, and watermark robustness, supported by our proposed set of evaluation metrics."],"url":"http://arxiv.org/abs/2309.03815v1"}
{"created":"2023-09-07 16:09:06","title":"AnthroNet: Conditional Generation of Humans via Anthropometrics","abstract":"We present a novel human body model formulated by an extensive set of anthropocentric measurements, which is capable of generating a wide range of human body shapes and poses. The proposed model enables direct modeling of specific human identities through a deep generative architecture, which can produce humans in any arbitrary pose. It is the first of its kind to have been trained end-to-end using only synthetically generated data, which not only provides highly accurate human mesh representations but also allows for precise anthropometry of the body. Moreover, using a highly diverse animation library, we articulated our synthetic humans' body and hands to maximize the diversity of the learnable priors for model training. Our model was trained on a dataset of $100k$ procedurally-generated posed human meshes and their corresponding anthropometric measurements. Our synthetic data generator can be used to generate millions of unique human identities and poses for non-commercial academic research purposes.","sentences":["We present a novel human body model formulated by an extensive set of anthropocentric measurements, which is capable of generating a wide range of human body shapes and poses.","The proposed model enables direct modeling of specific human identities through a deep generative architecture, which can produce humans in any arbitrary pose.","It is the first of its kind to have been trained end-to-end using only synthetically generated data, which not only provides highly accurate human mesh representations but also allows for precise anthropometry of the body.","Moreover, using a highly diverse animation library, we articulated our synthetic humans' body and hands to maximize the diversity of the learnable priors for model training.","Our model was trained on a dataset of $100k$ procedurally-generated posed human meshes and their corresponding anthropometric measurements.","Our synthetic data generator can be used to generate millions of unique human identities and poses for non-commercial academic research purposes."],"url":"http://arxiv.org/abs/2309.03812v1"}
{"created":"2023-09-07 16:07:31","title":"Panoramas from Photons","abstract":"Scene reconstruction in the presence of high-speed motion and low illumination is important in many applications such as augmented and virtual reality, drone navigation, and autonomous robotics. Traditional motion estimation techniques fail in such conditions, suffering from too much blur in the presence of high-speed motion and strong noise in low-light conditions. Single-photon cameras have recently emerged as a promising technology capable of capturing hundreds of thousands of photon frames per second thanks to their high speed and extreme sensitivity. Unfortunately, traditional computer vision techniques are not well suited for dealing with the binary-valued photon data captured by these cameras because these are corrupted by extreme Poisson noise. Here we present a method capable of estimating extreme scene motion under challenging conditions, such as low light or high dynamic range, from a sequence of high-speed image frames such as those captured by a single-photon camera. Our method relies on iteratively improving a motion estimate by grouping and aggregating frames after-the-fact, in a stratified manner. We demonstrate the creation of high-quality panoramas under fast motion and extremely low light, and super-resolution results using a custom single-photon camera prototype. For code and supplemental material see our $\\href{https://wisionlab.com/project/panoramas-from-photons/}{\\text{project webpage}}$.","sentences":["Scene reconstruction in the presence of high-speed motion and low illumination is important in many applications such as augmented and virtual reality, drone navigation, and autonomous robotics.","Traditional motion estimation techniques fail in such conditions, suffering from too much blur in the presence of high-speed motion and strong noise in low-light conditions.","Single-photon cameras have recently emerged as a promising technology capable of capturing hundreds of thousands of photon frames per second thanks to their high speed and extreme sensitivity.","Unfortunately, traditional computer vision techniques are not well suited for dealing with the binary-valued photon data captured by these cameras because these are corrupted by extreme Poisson noise.","Here we present a method capable of estimating extreme scene motion under challenging conditions, such as low light or high dynamic range, from a sequence of high-speed image frames such as those captured by a single-photon camera.","Our method relies on iteratively improving a motion estimate by grouping and aggregating frames after-the-fact, in a stratified manner.","We demonstrate the creation of high-quality panoramas under fast motion and extremely low light, and super-resolution results using a custom single-photon camera prototype.","For code and supplemental material see our $\\href{https://wisionlab.com/project/panoramas-from-photons/}{\\text{project webpage}}$."],"url":"http://arxiv.org/abs/2309.03811v1"}
{"created":"2023-09-07 16:04:45","title":"Three Hardness Results for Graph Similarity Problems","abstract":"Notions of graph similarity provide alternative perspective on the graph isomorphism problem and vice-versa. In this paper, we consider measures of similarity arising from mismatch norms as studied in Gervens and Grohe: the edit distance $\\delta_{\\mathcal{E}}$, and the metrics arising from $\\ell_p$-operator norms, which we denote by $\\delta_p$ and $\\delta_{|p|}$. We address the following question: can these measures of similarity be used to design polynomial-time approximation algorithms for graph isomorphism? We show that computing an optimal value of $\\delta_{\\mathcal{E}}$ is \\NP-hard on pairs of graphs with the same number of edges. In addition, we show that computing optimal values of $\\delta_p$ and $\\delta_{|p|}$ is \\NP-hard even on pairs of $1$-planar graphs with the same degree sequence and bounded degree. These two results improve on previous known ones, which did not examine the restricted case where the pairs of graphs are required to have the same number of edges.   Finally, we study similarity problems on strongly regular graphs and prove some near optimal inequalities with interesting consequences on the computational complexity of graph and group isomorphism.","sentences":["Notions of graph similarity provide alternative perspective on the graph isomorphism problem and vice-versa.","In this paper, we consider measures of similarity arising from mismatch norms as studied in Gervens and Grohe: the edit distance $\\delta_{\\mathcal{E}}$, and the metrics arising from $\\ell_p$-operator norms, which we denote by $\\delta_p$ and $\\delta_{|p|}$. We address the following question: can these measures of similarity be used to design polynomial-time approximation algorithms for graph isomorphism?","We show that computing an optimal value of $\\delta_{\\mathcal{E}}$ is \\NP-hard on pairs of graphs with the same number of edges.","In addition, we show that computing optimal values of $\\delta_p$ and $\\delta_{|p|}$ is \\NP-hard even on pairs of $1$-planar graphs with the same degree sequence and bounded degree.","These two results improve on previous known ones, which did not examine the restricted case where the pairs of graphs are required to have the same number of edges.   ","Finally, we study similarity problems on strongly regular graphs and prove some near optimal inequalities with interesting consequences on the computational complexity of graph and group isomorphism."],"url":"http://arxiv.org/abs/2309.03810v1"}
{"created":"2023-09-07 16:02:40","title":"SimNP: Learning Self-Similarity Priors Between Neural Points","abstract":"Existing neural field representations for 3D object reconstruction either (1) utilize object-level representations, but suffer from low-quality details due to conditioning on a global latent code, or (2) are able to perfectly reconstruct the observations, but fail to utilize object-level prior knowledge to infer unobserved regions. We present SimNP, a method to learn category-level self-similarities, which combines the advantages of both worlds by connecting neural point radiance fields with a category-level self-similarity representation. Our contribution is two-fold. (1) We design the first neural point representation on a category level by utilizing the concept of coherent point clouds. The resulting neural point radiance fields store a high level of detail for locally supported object regions. (2) We learn how information is shared between neural points in an unconstrained and unsupervised fashion, which allows to derive unobserved regions of an object during the reconstruction process from given observations. We show that SimNP is able to outperform previous methods in reconstructing symmetric unseen object regions, surpassing methods that build upon category-level or pixel-aligned radiance fields, while providing semantic correspondences between instances","sentences":["Existing neural field representations for 3D object reconstruction either (1) utilize object-level representations, but suffer from low-quality details due to conditioning on a global latent code, or (2) are able to perfectly reconstruct the observations, but fail to utilize object-level prior knowledge to infer unobserved regions.","We present SimNP, a method to learn category-level self-similarities, which combines the advantages of both worlds by connecting neural point radiance fields with a category-level self-similarity representation.","Our contribution is two-fold.","(1) We design the first neural point representation on a category level by utilizing the concept of coherent point clouds.","The resulting neural point radiance fields store a high level of detail for locally supported object regions.","(2) We learn how information is shared between neural points in an unconstrained and unsupervised fashion, which allows to derive unobserved regions of an object during the reconstruction process from given observations.","We show that SimNP is able to outperform previous methods in reconstructing symmetric unseen object regions, surpassing methods that build upon category-level or pixel-aligned radiance fields, while providing semantic correspondences between instances"],"url":"http://arxiv.org/abs/2309.03809v1"}
{"created":"2023-09-07 15:59:32","title":"Novel Power-Imbalanced Dense Codebooks for Reliable Multiplexing in Nakagami Channels","abstract":"This paper studies enhanced dense code multiple access (DCMA) system design for downlink transmission over the Nakagami-$m$ fading channels. By studying the DCMA pairwise error probability (PEP) in a Nakagami-$m$ channel, a novel design metric called minimum logarithmic sum distance (MLSD) is first derived. With respect to the proposed MLSD, we introduce a new family of power-imbalanced dense codebooks by deleting certain rows of a special non-unimodular circulant matrix. Simulation results demonstrate that our proposed dense codebooks lead to both larger minimum Euclidean distance and MLSD, thus yielding significant improvements of error performance over the existing sparse code multiple access and conventional unimodular DCMA schemes in Nakagami-$m$ fading channels under different overloading factors.","sentences":["This paper studies enhanced dense code multiple access (DCMA) system design for downlink transmission over the Nakagami-$m$ fading channels.","By studying the DCMA pairwise error probability (PEP) in a Nakagami-$m$ channel, a novel design metric called minimum logarithmic sum distance (MLSD) is first derived.","With respect to the proposed MLSD, we introduce a new family of power-imbalanced dense codebooks by deleting certain rows of a special non-unimodular circulant matrix.","Simulation results demonstrate that our proposed dense codebooks lead to both larger minimum Euclidean distance and MLSD, thus yielding significant improvements of error performance over the existing sparse code multiple access and conventional unimodular DCMA schemes in Nakagami-$m$ fading channels under different overloading factors."],"url":"http://arxiv.org/abs/2309.03806v1"}
{"created":"2023-09-07 15:58:49","title":"Mapping of CNNs on multi-core RRAM-based CIM architectures","abstract":"RRAM-based multi-core systems improve the energy efficiency and performance of CNNs. Thereby, the distributed parallel execution of convolutional layers causes critical data dependencies that limit the potential speedup. This paper presents synchronization techniques for parallel inference of convolutional layers on RRAM-based CIM architectures. We propose an architecture optimization that enables efficient data exchange and discuss the impact of different architecture setups on the performance. The corresponding compiler algorithms are optimized for high speedup and low memory consumption during CNN inference. We achieve more than 99% of the theoretical acceleration limit with a marginal data transmission overhead of less than 4% for state-of-the-art CNN benchmarks.","sentences":["RRAM-based multi-core systems improve the energy efficiency and performance of CNNs.","Thereby, the distributed parallel execution of convolutional layers causes critical data dependencies that limit the potential speedup.","This paper presents synchronization techniques for parallel inference of convolutional layers on RRAM-based CIM architectures.","We propose an architecture optimization that enables efficient data exchange and discuss the impact of different architecture setups on the performance.","The corresponding compiler algorithms are optimized for high speedup and low memory consumption during CNN inference.","We achieve more than 99% of the theoretical acceleration limit with a marginal data transmission overhead of less than 4% for state-of-the-art CNN benchmarks."],"url":"http://arxiv.org/abs/2309.03805v1"}
{"created":"2023-09-07 15:52:48","title":"Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and Luck","abstract":"This work investigates the nuanced algorithm design choices for deep learning in the presence of computational-statistical gaps. We begin by considering offline sparse parity learning, a supervised classification problem which admits a statistical query lower bound for gradient-based training of a multilayer perceptron. This lower bound can be interpreted as a multi-resource tradeoff frontier: successful learning can only occur if one is sufficiently rich (large model), knowledgeable (large dataset), patient (many training iterations), or lucky (many random guesses). We show, theoretically and experimentally, that sparse initialization and increasing network width yield significant improvements in sample efficiency in this setting. Here, width plays the role of parallel search: it amplifies the probability of finding \"lottery ticket\" neurons, which learn sparse features more sample-efficiently. Finally, we show that the synthetic sparse parity task can be useful as a proxy for real problems requiring axis-aligned feature learning. We demonstrate improved sample efficiency on tabular classification benchmarks by using wide, sparsely-initialized MLP models; these networks sometimes outperform tuned random forests.","sentences":["This work investigates the nuanced algorithm design choices for deep learning in the presence of computational-statistical gaps.","We begin by considering offline sparse parity learning, a supervised classification problem which admits a statistical query lower bound for gradient-based training of a multilayer perceptron.","This lower bound can be interpreted as a multi-resource tradeoff frontier: successful learning can only occur if one is sufficiently rich (large model), knowledgeable (large dataset), patient (many training iterations), or lucky (many random guesses).","We show, theoretically and experimentally, that sparse initialization and increasing network width yield significant improvements in sample efficiency in this setting.","Here, width plays the role of parallel search: it amplifies the probability of finding \"lottery ticket\" neurons, which learn sparse features more sample-efficiently.","Finally, we show that the synthetic sparse parity task can be useful as a proxy for real problems requiring axis-aligned feature learning.","We demonstrate improved sample efficiency on tabular classification benchmarks by using wide, sparsely-initialized MLP models; these networks sometimes outperform tuned random forests."],"url":"http://arxiv.org/abs/2309.03800v1"}
{"created":"2023-09-07 15:51:31","title":"FisheyePP4AV: A privacy-preserving method for autonomous vehicles on fisheye camera images","abstract":"In many parts of the world, the use of vast amounts of data collected on public roadways for autonomous driving has increased. In order to detect and anonymize pedestrian faces and nearby car license plates in actual road-driving scenarios, there is an urgent need for effective solutions. As more data is collected, privacy concerns regarding it increase, including but not limited to pedestrian faces and surrounding vehicle license plates. Normal and fisheye cameras are the two common camera types that are typically mounted on collection vehicles. With complex camera distortion models, fisheye camera images were deformed in contrast to regular images. It causes computer vision tasks to perform poorly when using numerous deep learning models. In this work, we pay particular attention to protecting privacy while yet adhering to several laws for fisheye camera photos taken by driverless vehicles. First, we suggest a framework for extracting face and plate identification knowledge from several teacher models. Our second suggestion is to transform both the image and the label from a regular image to fisheye-like data using a varied and realistic fisheye transformation. Finally, we run a test using the open-source PP4AV dataset. The experimental findings demonstrated that our model outperformed baseline methods when trained on data from autonomous vehicles, even when the data were softly labeled. The implementation code is available at our github: https://github.com/khaclinh/FisheyePP4AV.","sentences":["In many parts of the world, the use of vast amounts of data collected on public roadways for autonomous driving has increased.","In order to detect and anonymize pedestrian faces and nearby car license plates in actual road-driving scenarios, there is an urgent need for effective solutions.","As more data is collected, privacy concerns regarding it increase, including but not limited to pedestrian faces and surrounding vehicle license plates.","Normal and fisheye cameras are the two common camera types that are typically mounted on collection vehicles.","With complex camera distortion models, fisheye camera images were deformed in contrast to regular images.","It causes computer vision tasks to perform poorly when using numerous deep learning models.","In this work, we pay particular attention to protecting privacy while yet adhering to several laws for fisheye camera photos taken by driverless vehicles.","First, we suggest a framework for extracting face and plate identification knowledge from several teacher models.","Our second suggestion is to transform both the image and the label from a regular image to fisheye-like data using a varied and realistic fisheye transformation.","Finally, we run a test using the open-source PP4AV dataset.","The experimental findings demonstrated that our model outperformed baseline methods when trained on data from autonomous vehicles, even when the data were softly labeled.","The implementation code is available at our github: https://github.com/khaclinh/FisheyePP4AV."],"url":"http://arxiv.org/abs/2309.03799v1"}
{"created":"2023-09-07 15:50:48","title":"Conformal Autoregressive Generation: Beam Search with Coverage Guarantees","abstract":"We introduce two new extensions to the beam search algorithm based on conformal predictions (CP) to produce sets of sequences with theoretical coverage guarantees. The first method is very simple and proposes dynamically-sized subsets of beam search results but, unlike typical CP procedures, has an upper bound on the achievable guarantee depending on a post-hoc calibration measure. Our second algorithm introduces the conformal set prediction procedure as part of the decoding process, producing a variable beam width which adapts to the current uncertainty. While more complex, this procedure can achieve coverage guarantees selected a priori. We provide marginal coverage bounds for each method, and evaluate them empirically on a selection of tasks drawing from natural language processing and chemistry.","sentences":["We introduce two new extensions to the beam search algorithm based on conformal predictions (CP) to produce sets of sequences with theoretical coverage guarantees.","The first method is very simple and proposes dynamically-sized subsets of beam search results but, unlike typical CP procedures, has an upper bound on the achievable guarantee depending on a post-hoc calibration measure.","Our second algorithm introduces the conformal set prediction procedure as part of the decoding process, producing a variable beam width which adapts to the current uncertainty.","While more complex, this procedure can achieve coverage guarantees selected a priori.","We provide marginal coverage bounds for each method, and evaluate them empirically on a selection of tasks drawing from natural language processing and chemistry."],"url":"http://arxiv.org/abs/2309.03797v1"}
{"created":"2023-09-07 15:47:11","title":"Systematic Mapping of Monolithic Applications to Microservices Architecture","abstract":"The aim of this paper to provide the solution microservices architecture as a popular alternative to monolithic architecture. It discusses the advantages of microservices and the challenges that organizations face when transitioning from a monolithic system. It presents a case study of a financial application and proposed techniques for identifying microservices on monolithic systems using domain-driven development concepts. In recent years, microservices architecture has emerged as a new architectural style in the software development industry. As legacy monolithic software becomes too large to manage, many large corporations are considering converting their traditional monolithic systems into small-scale, self-contained microservices. However, migrating from monolithic to microservices architecture is a difficult and challenging task. It presents a comparison of the two architectural styles and discusses the difficulties that led companies to switch to microservices. The study's findings suggest that the proposed technique can improve work performance and establish clear models, but it may not be useful for systems with lower levels of complexity. This research paper has practical implications for software architects and developers who are considering migrating from monolithic to microservices architecture.","sentences":["The aim of this paper to provide the solution microservices architecture as a popular alternative to monolithic architecture.","It discusses the advantages of microservices and the challenges that organizations face when transitioning from a monolithic system.","It presents a case study of a financial application and proposed techniques for identifying microservices on monolithic systems using domain-driven development concepts.","In recent years, microservices architecture has emerged as a new architectural style in the software development industry.","As legacy monolithic software becomes too large to manage, many large corporations are considering converting their traditional monolithic systems into small-scale, self-contained microservices.","However, migrating from monolithic to microservices architecture is a difficult and challenging task.","It presents a comparison of the two architectural styles and discusses the difficulties that led companies to switch to microservices.","The study's findings suggest that the proposed technique can improve work performance and establish clear models, but it may not be useful for systems with lower levels of complexity.","This research paper has practical implications for software architects and developers who are considering migrating from monolithic to microservices architecture."],"url":"http://arxiv.org/abs/2309.03796v1"}
{"created":"2023-09-07 15:41:45","title":"Adversarially Robust Deep Learning with Optimal-Transport-Regularized Divergences","abstract":"We introduce the $ARMOR_D$ methods as novel approaches to enhancing the adversarial robustness of deep learning models. These methods are based on a new class of optimal-transport-regularized divergences, constructed via an infimal convolution between an information divergence and an optimal-transport (OT) cost. We use these as tools to enhance adversarial robustness by maximizing the expected loss over a neighborhood of distributions, a technique known as distributionally robust optimization. Viewed as a tool for constructing adversarial samples, our method allows samples to be both transported, according to the OT cost, and re-weighted, according to the information divergence. We demonstrate the effectiveness of our method on malware detection and image recognition applications and find that, to our knowledge, it outperforms existing methods at enhancing the robustness against adversarial attacks. $ARMOR_D$ yields the robustified accuracy of $98.29\\%$ against $FGSM$ and $98.18\\%$ against $PGD^{40}$ on the MNIST dataset, reducing the error rate by more than $19.7\\%$ and $37.2\\%$ respectively compared to prior methods. Similarly, in malware detection, a discrete (binary) data domain, $ARMOR_D$ improves the robustified accuracy under $rFGSM^{50}$ attack compared to the previous best-performing adversarial training methods by $37.0\\%$ while lowering false negative and false positive rates by $51.1\\%$ and $57.53\\%$, respectively.","sentences":["We introduce the $ARMOR_D$ methods as novel approaches to enhancing the adversarial robustness of deep learning models.","These methods are based on a new class of optimal-transport-regularized divergences, constructed via an infimal convolution between an information divergence and an optimal-transport (OT) cost.","We use these as tools to enhance adversarial robustness by maximizing the expected loss over a neighborhood of distributions, a technique known as distributionally robust optimization.","Viewed as a tool for constructing adversarial samples, our method allows samples to be both transported, according to the OT cost, and re-weighted, according to the information divergence.","We demonstrate the effectiveness of our method on malware detection and image recognition applications and find that, to our knowledge, it outperforms existing methods at enhancing the robustness against adversarial attacks.","$ARMOR_D$ yields the robustified accuracy of $98.29\\%$ against $FGSM$ and $98.18\\%$ against $PGD^{40}$ on the MNIST dataset, reducing the error rate by more than $19.7\\%$ and $37.2\\%$ respectively compared to prior methods.","Similarly, in malware detection, a discrete (binary) data domain, $ARMOR_D$ improves the robustified accuracy under $rFGSM^{50}$ attack compared to the previous best-performing adversarial training methods by $37.0\\%$ while lowering false negative and false positive rates by $51.1\\%$ and $57.53\\%$, respectively."],"url":"http://arxiv.org/abs/2309.03791v1"}
{"created":"2023-09-07 15:40:06","title":"TaleStream: Supporting Story Ideation with Trope Knowledge","abstract":"Story ideation is a critical part of the story-writing process. It is challenging to support computationally due to its exploratory and subjective nature. Tropes, which are recurring narrative elements across stories, are essential in stories as they shape the structure of narratives and our understanding of them. In this paper, we propose to use tropes as an intermediate representation of stories to approach story ideation. We present TaleStream, a canvas system that uses tropes as building blocks of stories while providing steerable suggestions of story ideas in the form of tropes. Our trope suggestion methods leverage data from the tvtropes.org wiki. We find that 97% of the time, trope suggestions generated by our methods provide better story ideation materials than random tropes. Our system evaluation suggests that TaleStream can support writers' creative flow and greatly facilitates story development. Tropes, as a rich lexicon of narratives with available examples, play a key role in TaleStream and hold promise for story-creation support systems.","sentences":["Story ideation is a critical part of the story-writing process.","It is challenging to support computationally due to its exploratory and subjective nature.","Tropes, which are recurring narrative elements across stories, are essential in stories as they shape the structure of narratives and our understanding of them.","In this paper, we propose to use tropes as an intermediate representation of stories to approach story ideation.","We present TaleStream, a canvas system that uses tropes as building blocks of stories while providing steerable suggestions of story ideas in the form of tropes.","Our trope suggestion methods leverage data from the tvtropes.org wiki.","We find that 97% of the time, trope suggestions generated by our methods provide better story ideation materials than random tropes.","Our system evaluation suggests that TaleStream can support writers' creative flow and greatly facilitates story development.","Tropes, as a rich lexicon of narratives with available examples, play a key role in TaleStream and hold promise for story-creation support systems."],"url":"http://arxiv.org/abs/2309.03790v1"}
{"created":"2023-09-07 15:35:00","title":"USA: Universal Sentiment Analysis Model & Construction of Japanese Sentiment Text Classification and Part of Speech Dataset","abstract":"Sentiment analysis is a pivotal task in the domain of natural language processing. It encompasses both text-level sentiment polarity classification and word-level Part of Speech(POS) sentiment polarity determination. Such analysis challenges models to understand text holistically while also extracting nuanced information. With the rise of Large Language Models(LLMs), new avenues for sentiment analysis have opened. This paper proposes enhancing performance by leveraging the Mutual Reinforcement Effect(MRE) between individual words and the overall text. It delves into how word polarity influences the overarching sentiment of a passage. To support our research, we annotated four novel Sentiment Text Classification and Part of Speech(SCPOS) datasets, building upon existing sentiment classification datasets. Furthermore, we developed a Universal Sentiment Analysis(USA) model, with a 7-billion parameter size. Experimental results revealed that our model surpassed the performance of gpt-3.5-turbo across all four datasets, underscoring the significance of MRE in sentiment analysis.","sentences":["Sentiment analysis is a pivotal task in the domain of natural language processing.","It encompasses both text-level sentiment polarity classification and word-level Part of Speech(POS) sentiment polarity determination.","Such analysis challenges models to understand text holistically while also extracting nuanced information.","With the rise of Large Language Models(LLMs), new avenues for sentiment analysis have opened.","This paper proposes enhancing performance by leveraging the Mutual Reinforcement Effect(MRE) between individual words and the overall text.","It delves into how word polarity influences the overarching sentiment of a passage.","To support our research, we annotated four novel Sentiment Text Classification and Part of Speech(SCPOS) datasets, building upon existing sentiment classification datasets.","Furthermore, we developed a Universal Sentiment Analysis(USA) model, with a 7-billion parameter size.","Experimental results revealed that our model surpassed the performance of gpt-3.5-turbo across all four datasets, underscoring the significance of MRE in sentiment analysis."],"url":"http://arxiv.org/abs/2309.03787v1"}
{"created":"2023-09-07 15:28:03","title":"CPU frequency scheduling of real-time applications on embedded devices with temporal encoding-based deep reinforcement learning","abstract":"Small devices are frequently used in IoT and smart-city applications to perform periodic dedicated tasks with soft deadlines. This work focuses on developing methods to derive efficient power-management methods for periodic tasks on small devices. We first study the limitations of the existing Linux built-in methods used in small devices. We illustrate three typical workload/system patterns that are challenging to manage with Linux's built-in solutions. We develop a reinforcement-learning-based technique with temporal encoding to derive an effective DVFS governor even with the presence of the three system patterns. The derived governor uses only one performance counter, the same as the built-in Linux mechanism, and does not require an explicit task model for the workload. We implemented a prototype system on the Nvidia Jetson Nano Board and experimented with it with six applications, including two self-designed and four benchmark applications. Under different deadline constraints, our approach can quickly derive a DVFS governor that can adapt to performance requirements and outperform the built-in Linux approach in energy saving. On Mibench workloads, with performance slack ranging from 0.04 s to 0.4 s, the proposed method can save 3% - 11% more energy compared to Ondemand. AudioReg and FaceReg applications tested have 5%- 14% energy-saving improvement. We have open-sourced the implementation of our in-kernel quantized neural network engine. The codebase can be found at: https://github.com/coladog/tinyagent.","sentences":["Small devices are frequently used in IoT and smart-city applications to perform periodic dedicated tasks with soft deadlines.","This work focuses on developing methods to derive efficient power-management methods for periodic tasks on small devices.","We first study the limitations of the existing Linux built-in methods used in small devices.","We illustrate three typical workload/system patterns that are challenging to manage with Linux's built-in solutions.","We develop a reinforcement-learning-based technique with temporal encoding to derive an effective DVFS governor even with the presence of the three system patterns.","The derived governor uses only one performance counter, the same as the built-in Linux mechanism, and does not require an explicit task model for the workload.","We implemented a prototype system on the Nvidia Jetson Nano Board and experimented with it with six applications, including two self-designed and four benchmark applications.","Under different deadline constraints, our approach can quickly derive a DVFS governor that can adapt to performance requirements and outperform the built-in Linux approach in energy saving.","On Mibench workloads, with performance slack ranging from 0.04 s to 0.4 s, the proposed method can save 3% - 11% more energy compared to Ondemand.","AudioReg and FaceReg applications tested have 5%- 14% energy-saving improvement.","We have open-sourced the implementation of our in-kernel quantized neural network engine.","The codebase can be found at: https://github.com/coladog/tinyagent."],"url":"http://arxiv.org/abs/2309.03779v1"}
{"created":"2023-09-07 15:25:47","title":"Deep Learning Safety Concerns in Automated Driving Perception","abstract":"Recent advances in the field of deep learning and impressive performance of deep neural networks (DNNs) for perception have resulted in an increased demand for their use in automated driving (AD) systems. The safety of such systems is of utmost importance and thus requires to consider the unique properties of DNNs.   In order to achieve safety of AD systems with DNN-based perception components in a systematic and comprehensive approach, so-called safety concerns have been introduced as a suitable structuring element. On the one hand, the concept of safety concerns is -- by design -- well aligned to existing standards relevant for safety of AD systems such as ISO 21448 (SOTIF). On the other hand, it has already inspired several academic publications and upcoming standards on AI safety such as ISO PAS 8800.   While the concept of safety concerns has been previously introduced, this paper extends and refines it, leveraging feedback from various domain and safety experts in the field. In particular, this paper introduces an additional categorization for a better understanding as well as enabling cross-functional teams to jointly address the concerns.","sentences":["Recent advances in the field of deep learning and impressive performance of deep neural networks (DNNs) for perception have resulted in an increased demand for their use in automated driving (AD) systems.","The safety of such systems is of utmost importance and thus requires to consider the unique properties of DNNs.   ","In order to achieve safety of AD systems with DNN-based perception components in a systematic and comprehensive approach, so-called safety concerns have been introduced as a suitable structuring element.","On the one hand, the concept of safety concerns is -- by design -- well aligned to existing standards relevant for safety of AD systems such as ISO 21448 (SOTIF).","On the other hand, it has already inspired several academic publications and upcoming standards on AI safety such as ISO PAS 8800.   ","While the concept of safety concerns has been previously introduced, this paper extends and refines it, leveraging feedback from various domain and safety experts in the field.","In particular, this paper introduces an additional categorization for a better understanding as well as enabling cross-functional teams to jointly address the concerns."],"url":"http://arxiv.org/abs/2309.03774v1"}
{"created":"2023-09-07 15:24:18","title":"Extending Transductive Knowledge Graph Embedding Models for Inductive Logical Relational Inference","abstract":"Many downstream inference tasks for knowledge graphs, such as relation prediction, have been handled successfully by knowledge graph embedding techniques in the transductive setting. To address the inductive setting wherein new entities are introduced into the knowledge graph at inference time, more recent work opts for models which learn implicit representations of the knowledge graph through a complex function of a network's subgraph structure, often parametrized by graph neural network architectures. These come at the cost of increased parametrization, reduced interpretability and limited generalization to other downstream inference tasks. In this work, we bridge the gap between traditional transductive knowledge graph embedding approaches and more recent inductive relation prediction models by introducing a generalized form of harmonic extension which leverages representations learned through transductive embedding methods to infer representations of new entities introduced at inference time as in the inductive setting. This harmonic extension technique provides the best such approximation, can be implemented via an efficient iterative scheme, and can be employed to answer a family of conjunctive logical queries over the knowledge graph, further expanding the capabilities of transductive embedding methods. In experiments on a number of large-scale knowledge graph embedding benchmarks, we find that this approach for extending the functionality of transductive knowledge graph embedding models to perform knowledge graph completion and answer logical queries in the inductive setting is competitive with--and in some scenarios outperforms--several state-of-the-art models derived explicitly for such inductive tasks.","sentences":["Many downstream inference tasks for knowledge graphs, such as relation prediction, have been handled successfully by knowledge graph embedding techniques in the transductive setting.","To address the inductive setting wherein new entities are introduced into the knowledge graph at inference time, more recent work opts for models which learn implicit representations of the knowledge graph through a complex function of a network's subgraph structure, often parametrized by graph neural network architectures.","These come at the cost of increased parametrization, reduced interpretability and limited generalization to other downstream inference tasks.","In this work, we bridge the gap between traditional transductive knowledge graph embedding approaches and more recent inductive relation prediction models by introducing a generalized form of harmonic extension which leverages representations learned through transductive embedding methods to infer representations of new entities introduced at inference time as in the inductive setting.","This harmonic extension technique provides the best such approximation, can be implemented via an efficient iterative scheme, and can be employed to answer a family of conjunctive logical queries over the knowledge graph, further expanding the capabilities of transductive embedding methods.","In experiments on a number of large-scale knowledge graph embedding benchmarks, we find that this approach for extending the functionality of transductive knowledge graph embedding models to perform knowledge graph completion and answer logical queries in the inductive setting is competitive with--and in some scenarios outperforms--several state-of-the-art models derived explicitly for such inductive tasks."],"url":"http://arxiv.org/abs/2309.03773v1"}
{"created":"2023-09-07 15:20:21","title":"Space-Time Shift Keying Aided OTFS Modulation for Orthogonal Multiple Access","abstract":"Space-time shift keying-aided orthogonal time frequency space modulation-based multiple access (STSK-OTFS-MA) is proposed for reliable uplink transmission in high-Doppler scenarios. As a beneficial feature of our STSK-OTFS-MA system, extra information bits are mapped onto the indices of the active dispersion matrices, which allows the system to enjoy the joint benefits of both STSK and OTFS signalling. Due to the fact that both the time-, space- and DD-domain degrees of freedom are jointly exploited, our STSK-OTFS-MA achieves increased diversity and coding gains. To mitigate the potentially excessive detection complexity, the sparse structure of the equivalent transmitted symbol vector is exploited, resulting in a pair of low-complexity near-maximum likelihood (ML) multiuser detection algorithms. Explicitly, we conceive a progressive residual check-based greedy detector (PRCGD) and an iterative reduced-space check-based detector (IRCD). Then, we derive both the unconditional single-user pairwise error probability (SU-UPEP) and a tight bit error ratio (BER) union-bound for our single-user STSK-OTFS-MA system employing the ML detector. Furthermore, the discrete-input continuous-output memoryless channel (DCMC) capacity of the proposed system is derived. The optimal dispersion matrices (DMs) are designed based on the maximum attainable diversity and coding gain metrics. Finally, it is demonstrated that our STSK-OTFS-MA system achieves both a lower BER and a higher DCMC capacity than its conventional spatial modulation (SM) {and its orthogonal frequency-division multiplexing (OFDM) counterparts. As a benefit, the proposed system strikes a compelling BER vs. system complexity as well as BER vs. detection complexity trade-offs.","sentences":["Space-time shift keying-aided orthogonal time frequency space modulation-based multiple access (STSK-OTFS-MA) is proposed for reliable uplink transmission in high-Doppler scenarios.","As a beneficial feature of our STSK-OTFS-MA system, extra information bits are mapped onto the indices of the active dispersion matrices, which allows the system to enjoy the joint benefits of both STSK and OTFS signalling.","Due to the fact that both the time-, space- and DD-domain degrees of freedom are jointly exploited, our STSK-OTFS-MA achieves increased diversity and coding gains.","To mitigate the potentially excessive detection complexity, the sparse structure of the equivalent transmitted symbol vector is exploited, resulting in a pair of low-complexity near-maximum likelihood (ML) multiuser detection algorithms.","Explicitly, we conceive a progressive residual check-based greedy detector (PRCGD) and an iterative reduced-space check-based detector (IRCD).","Then, we derive both the unconditional single-user pairwise error probability (SU-UPEP) and a tight bit error ratio (BER) union-bound for our single-user STSK-OTFS-MA system employing the ML detector.","Furthermore, the discrete-input continuous-output memoryless channel (DCMC) capacity of the proposed system is derived.","The optimal dispersion matrices (DMs) are designed based on the maximum attainable diversity and coding gain metrics.","Finally, it is demonstrated that our STSK-OTFS-MA system achieves both a lower BER and a higher DCMC capacity than its conventional spatial modulation (SM) {and its orthogonal frequency-division multiplexing (OFDM) counterparts.","As a benefit, the proposed system strikes a compelling BER vs. system complexity as well as BER vs. detection complexity trade-offs."],"url":"http://arxiv.org/abs/2309.03771v1"}
{"created":"2023-09-07 15:13:28","title":"Equivariant Symmetries for Inertial Navigation Systems","abstract":"This paper investigates the problem of inertial navigation system (INS) filter design through the lens of symmetry. The extended Kalman filter (EKF) and its variants, have been the staple of INS filtering for 50 years; however, recent advances in inertial navigation systems have exploited matrix Lie group structure to design stochastic filters and state observers that have been shown to display superior performance compared to classical solutions. In this work we consider the case where a vehicle has an inertial measurement unit (IMU) and a global navigation satellite system (GNSS) receiver. We show that all the modern variants of the EKF for these sensors can be interpreted as the recently proposed Equivariant Filter (EqF) design methodology applied to different choices of symmetry group for the INS problem. This leads us to propose two new symmetries for the INS problem that have not been considered in the prior literature, and provide a discussion of the relative strengths and weaknesses of all the different algorithms. We believe the collection of symmetries that we present here capture all the sensible choices of symmetry for this problem and sensor suite, and that the analysis provided is indicative of the relative real-world performance potential of the different algorithms.","sentences":["This paper investigates the problem of inertial navigation system (INS) filter design through the lens of symmetry.","The extended Kalman filter (EKF) and its variants, have been the staple of INS filtering for 50 years; however, recent advances in inertial navigation systems have exploited matrix Lie group structure to design stochastic filters and state observers that have been shown to display superior performance compared to classical solutions.","In this work we consider the case where a vehicle has an inertial measurement unit (IMU) and a global navigation satellite system (GNSS) receiver.","We show that all the modern variants of the EKF for these sensors can be interpreted as the recently proposed Equivariant Filter (EqF) design methodology applied to different choices of symmetry group for the INS problem.","This leads us to propose two new symmetries for the INS problem that have not been considered in the prior literature, and provide a discussion of the relative strengths and weaknesses of all the different algorithms.","We believe the collection of symmetries that we present here capture all the sensible choices of symmetry for this problem and sensor suite, and that the analysis provided is indicative of the relative real-world performance potential of the different algorithms."],"url":"http://arxiv.org/abs/2309.03765v1"}
{"created":"2023-09-07 15:08:12","title":"$L_{2,1}$-Norm Regularized Quaternion Matrix Completion Using Sparse Representation and Quaternion QR Decomposition","abstract":"Color image completion is a challenging problem in computer vision, but recent research has shown that quaternion representations of color images perform well in many areas. These representations consider the entire color image and effectively utilize coupling information between the three color channels. Consequently, low-rank quaternion matrix completion (LRQMC) algorithms have gained significant attention. We propose a method based on quaternion Qatar Riyal decomposition (QQR) and quaternion $L_{2,1}$-norm called QLNM-QQR. This new approach reduces computational complexity by avoiding the need to calculate the QSVD of large quaternion matrices. We also present two improvements to the QLNM-QQR method: an enhanced version called IRQLNM-QQR that uses iteratively reweighted quaternion $L_{2,1}$-norm minimization and a method called QLNM-QQR-SR that integrates sparse regularization. Our experiments on natural color images and color medical images show that IRQLNM-QQR outperforms QLNM-QQR and that the proposed QLNM-QQR-SR method is superior to several state-of-the-art methods.","sentences":["Color image completion is a challenging problem in computer vision, but recent research has shown that quaternion representations of color images perform well in many areas.","These representations consider the entire color image and effectively utilize coupling information between the three color channels.","Consequently, low-rank quaternion matrix completion (LRQMC) algorithms have gained significant attention.","We propose a method based on quaternion Qatar Riyal decomposition (QQR) and quaternion $L_{2,1}$-norm called QLNM-QQR.","This new approach reduces computational complexity by avoiding the need to calculate the QSVD of large quaternion matrices.","We also present two improvements to the QLNM-QQR method: an enhanced version called IRQLNM-QQR that uses iteratively reweighted quaternion $L_{2,1}$-norm minimization and a method called QLNM-QQR-SR that integrates sparse regularization.","Our experiments on natural color images and color medical images show that IRQLNM-QQR outperforms QLNM-QQR and that the proposed QLNM-QQR-SR method is superior to several state-of-the-art methods."],"url":"http://arxiv.org/abs/2309.03764v1"}
{"created":"2023-09-07 15:05:35","title":"dacl1k: Real-World Bridge Damage Dataset Putting Open-Source Data to the Test","abstract":"Recognising reinforced concrete defects (RCDs) is a crucial element for determining the structural integrity, traffic safety and durability of bridges. However, most of the existing datasets in the RCD domain are derived from a small number of bridges acquired in specific camera poses, lighting conditions and with fixed hardware. These limitations question the usability of models trained on such open-source data in real-world scenarios. We address this problem by testing such models on our \"dacl1k\" dataset, a highly diverse RCD dataset for multi-label classification based on building inspections including 1,474 images. Thereby, we trained the models on different combinations of open-source data (meta datasets) which were subsequently evaluated both extrinsically and intrinsically. During extrinsic evaluation, we report metrics on dacl1k and the meta datasets. The performance analysis on dacl1k shows practical usability of the meta data, where the best model shows an Exact Match Ratio of 32%. Additionally, we conduct an intrinsic evaluation by clustering the bottleneck features of the best model derived from the extrinsic evaluation in order to find out, if the model has learned distinguishing datasets or the classes (RCDs) which is the aspired goal. The dacl1k dataset and our trained models will be made publicly available, enabling researchers and practitioners to put their models to the real-world test.","sentences":["Recognising reinforced concrete defects (RCDs) is a crucial element for determining the structural integrity, traffic safety and durability of bridges.","However, most of the existing datasets in the RCD domain are derived from a small number of bridges acquired in specific camera poses, lighting conditions and with fixed hardware.","These limitations question the usability of models trained on such open-source data in real-world scenarios.","We address this problem by testing such models on our \"dacl1k\" dataset, a highly diverse RCD dataset for multi-label classification based on building inspections including 1,474 images.","Thereby, we trained the models on different combinations of open-source data (meta datasets) which were subsequently evaluated both extrinsically and intrinsically.","During extrinsic evaluation, we report metrics on dacl1k and the meta datasets.","The performance analysis on dacl1k shows practical usability of the meta data, where the best model shows an Exact Match Ratio of 32%.","Additionally, we conduct an intrinsic evaluation by clustering the bottleneck features of the best model derived from the extrinsic evaluation in order to find out, if the model has learned distinguishing datasets or the classes (RCDs) which is the aspired goal.","The dacl1k dataset and our trained models will be made publicly available, enabling researchers and practitioners to put their models to the real-world test."],"url":"http://arxiv.org/abs/2309.03763v1"}
{"created":"2023-09-07 15:00:49","title":"Hybrid of representation learning and reinforcement learning for dynamic and complex robotic motion planning","abstract":"Motion planning is the soul of robot decision making. Classical planning algorithms like graph search and reaction-based algorithms face challenges in cases of dense and dynamic obstacles. Deep learning algorithms generate suboptimal one-step predictions that cause many collisions. Reinforcement learning algorithms generate optimal or near-optimal time-sequential predictions. However, they suffer from slow convergence, suboptimal converged results, and overfittings. This paper introduces a hybrid algorithm for robotic motion planning: long short-term memory (LSTM) pooling and skip connection for attention-based discrete soft actor critic (LSA-DSAC). First, graph network (relational graph) and attention network (attention weight) interpret the environmental state for the learning of the discrete soft actor critic algorithm. The expressive power of attention network outperforms that of graph in our task by difference analysis of these two representation methods. However, attention based DSAC faces the overfitting problem in training. Second, the skip connection method is integrated to attention based DSAC to mitigate overfitting and improve convergence speed. Third, LSTM pooling is taken to replace the sum operator of attention weigh and eliminate overfitting by slightly sacrificing convergence speed at early-stage training. Experiments show that LSA-DSAC outperforms the state-of-the-art in training and most evaluations. The physical robot is also implemented and tested in the real world.","sentences":["Motion planning is the soul of robot decision making.","Classical planning algorithms like graph search and reaction-based algorithms face challenges in cases of dense and dynamic obstacles.","Deep learning algorithms generate suboptimal one-step predictions that cause many collisions.","Reinforcement learning algorithms generate optimal or near-optimal time-sequential predictions.","However, they suffer from slow convergence, suboptimal converged results, and overfittings.","This paper introduces a hybrid algorithm for robotic motion planning: long short-term memory (LSTM) pooling and skip connection for attention-based discrete soft actor critic (LSA-DSAC).","First, graph network (relational graph) and attention network (attention weight) interpret the environmental state for the learning of the discrete soft actor critic algorithm.","The expressive power of attention network outperforms that of graph in our task by difference analysis of these two representation methods.","However, attention based DSAC faces the overfitting problem in training.","Second, the skip connection method is integrated to attention based DSAC to mitigate overfitting and improve convergence speed.","Third, LSTM pooling is taken to replace the sum operator of attention weigh and eliminate overfitting by slightly sacrificing convergence speed at early-stage training.","Experiments show that LSA-DSAC outperforms the state-of-the-art in training and most evaluations.","The physical robot is also implemented and tested in the real world."],"url":"http://arxiv.org/abs/2309.03758v1"}
{"created":"2023-09-07 14:51:42","title":"TSGBench: Time Series Generation Benchmark","abstract":"Synthetic Time Series Generation (TSG) is crucial in a range of applications, including data augmentation, anomaly detection, and privacy preservation. Although significant strides have been made in this field, existing methods exhibit three key limitations: (1) They often benchmark against similar model types, constraining a holistic view of performance capabilities. (2) The use of specialized synthetic and private datasets introduces biases and hampers generalizability. (3) Ambiguous evaluation measures, often tied to custom networks or downstream tasks, hinder consistent and fair comparison.   To overcome these limitations, we introduce \\textsf{TSGBench}, the inaugural TSG Benchmark, designed for a unified and comprehensive assessment of TSG methods. It comprises three modules: (1) a curated collection of publicly available, real-world datasets tailored for TSG, together with a standardized preprocessing pipeline; (2) a comprehensive evaluation measures suite including vanilla measures, new distance-based assessments, and visualization tools; (3) a pioneering generalization test rooted in Domain Adaptation (DA), compatible with all methods. We have conducted extensive experiments across ten real-world datasets from diverse domains, utilizing ten advanced TSG methods and twelve evaluation measures, all gauged through \\textsf{TSGBench}. The results highlight its remarkable efficacy and consistency. More importantly, \\textsf{TSGBench} delivers a statistical breakdown of method rankings, illuminating performance variations across different datasets and measures, and offering nuanced insights into the effectiveness of each method.","sentences":["Synthetic Time Series Generation (TSG) is crucial in a range of applications, including data augmentation, anomaly detection, and privacy preservation.","Although significant strides have been made in this field, existing methods exhibit three key limitations: (1) They often benchmark against similar model types, constraining a holistic view of performance capabilities.","(2) The use of specialized synthetic and private datasets introduces biases and hampers generalizability.","(3) Ambiguous evaluation measures, often tied to custom networks or downstream tasks, hinder consistent and fair comparison.   ","To overcome these limitations, we introduce \\textsf{TSGBench}, the inaugural TSG Benchmark, designed for a unified and comprehensive assessment of TSG methods.","It comprises three modules: (1) a curated collection of publicly available, real-world datasets tailored for TSG, together with a standardized preprocessing pipeline; (2) a comprehensive evaluation measures suite including vanilla measures, new distance-based assessments, and visualization tools; (3) a pioneering generalization test rooted in Domain Adaptation (DA), compatible with all methods.","We have conducted extensive experiments across ten real-world datasets from diverse domains, utilizing ten advanced TSG methods and twelve evaluation measures, all gauged through \\textsf{TSGBench}.","The results highlight its remarkable efficacy and consistency.","More importantly, \\textsf{TSGBench} delivers a statistical breakdown of method rankings, illuminating performance variations across different datasets and measures, and offering nuanced insights into the effectiveness of each method."],"url":"http://arxiv.org/abs/2309.03755v1"}
{"created":"2023-09-07 14:50:31","title":"Convergence Analysis of Decentralized ASGD","abstract":"Over the last decades, Stochastic Gradient Descent (SGD) has been intensively studied by the Machine Learning community. Despite its versatility and excellent performance, the optimization of large models via SGD still is a time-consuming task. To reduce training time, it is common to distribute the training process across multiple devices. Recently, it has been shown that the convergence of asynchronous SGD (ASGD) will always be faster than mini-batch SGD. However, despite these improvements in the theoretical bounds, most ASGD convergence-rate proofs still rely on a centralized parameter server, which is prone to become a bottleneck when scaling out the gradient computations across many distributed processes.   In this paper, we present a novel convergence-rate analysis for decentralized and asynchronous SGD (DASGD) which does not require partial synchronization among nodes nor restrictive network topologies. Specifically, we provide a bound of $\\mathcal{O}(\\sigma\\epsilon^{-2}) + \\mathcal{O}(QS_{avg}\\epsilon^{-3/2}) + \\mathcal{O}(S_{avg}\\epsilon^{-1})$ for the convergence rate of DASGD, where $S_{avg}$ is the average staleness between models, $Q$ is a constant that bounds the norm of the gradients, and $\\epsilon$ is a (small) error that is allowed within the bound. Furthermore, when gradients are not bounded, we prove the convergence rate of DASGD to be $\\mathcal{O}(\\sigma\\epsilon^{-2}) + \\mathcal{O}(\\sqrt{\\hat{S}_{avg}\\hat{S}_{max}}\\epsilon^{-1})$, with $\\hat{S}_{max}$ and $\\hat{S}_{avg}$ representing a loose version of the average and maximum staleness, respectively. Our convergence proof holds for a fixed stepsize and any non-convex, homogeneous, and L-smooth objective function. We anticipate that our results will be of high relevance for the adoption of DASGD by a broad community of researchers and developers.","sentences":["Over the last decades, Stochastic Gradient Descent (SGD) has been intensively studied by the Machine Learning community.","Despite its versatility and excellent performance, the optimization of large models via SGD still is a time-consuming task.","To reduce training time, it is common to distribute the training process across multiple devices.","Recently, it has been shown that the convergence of asynchronous SGD (ASGD) will always be faster than mini-batch SGD.","However, despite these improvements in the theoretical bounds, most ASGD convergence-rate proofs still rely on a centralized parameter server, which is prone to become a bottleneck when scaling out the gradient computations across many distributed processes.   ","In this paper, we present a novel convergence-rate analysis for decentralized and asynchronous SGD (DASGD) which does not require partial synchronization among nodes nor restrictive network topologies.","Specifically, we provide a bound of $\\mathcal{O}(\\sigma\\epsilon^{-2})","+ \\mathcal{O}(QS_{avg}\\epsilon^{-3/2})","+ \\mathcal{O}(S_{avg}\\epsilon^{-1})$ for the convergence rate of DASGD, where $S_{avg}$ is the average staleness between models, $Q$ is a constant that bounds the norm of the gradients, and $\\epsilon$ is a (small) error that is allowed within the bound.","Furthermore, when gradients are not bounded, we prove the convergence rate of DASGD to be $\\mathcal{O}(\\sigma\\epsilon^{-2})","+ \\mathcal{O}(\\sqrt{\\hat{S}_{avg}\\hat{S}_{max}}\\epsilon^{-1})$, with $\\hat{S}_{max}$ and $\\hat{S}_{avg}$ representing a loose version of the average and maximum staleness, respectively.","Our convergence proof holds for a fixed stepsize and any non-convex, homogeneous, and L-smooth objective function.","We anticipate that our results will be of high relevance for the adoption of DASGD by a broad community of researchers and developers."],"url":"http://arxiv.org/abs/2309.03754v1"}
{"created":"2023-09-07 14:46:48","title":"Medoid Silhouette clustering with automatic cluster number selection","abstract":"The evaluation of clustering results is difficult, highly dependent on the evaluated data set and the perspective of the beholder. There are many different clustering quality measures, which try to provide a general measure to validate clustering results. A very popular measure is the Silhouette. We discuss the efficient medoid-based variant of the Silhouette, perform a theoretical analysis of its properties, provide two fast versions for the direct optimization, and discuss the use to choose the optimal number of clusters. We combine ideas from the original Silhouette with the well-known PAM algorithm and its latest improvements FasterPAM. One of the versions guarantees equal results to the original variant and provides a run speedup of $O(k^2)$. In experiments on real data with 30000 samples and $k$=100, we observed a 10464$\\times$ speedup compared to the original PAMMEDSIL algorithm. Additionally, we provide a variant to choose the optimal number of clusters directly.","sentences":["The evaluation of clustering results is difficult, highly dependent on the evaluated data set and the perspective of the beholder.","There are many different clustering quality measures, which try to provide a general measure to validate clustering results.","A very popular measure is the Silhouette.","We discuss the efficient medoid-based variant of the Silhouette, perform a theoretical analysis of its properties, provide two fast versions for the direct optimization, and discuss the use to choose the optimal number of clusters.","We combine ideas from the original Silhouette with the well-known PAM algorithm and its latest improvements FasterPAM.","One of the versions guarantees equal results to the original variant and provides a run speedup of $O(k^2)$. In experiments on real data with 30000 samples and $k$=100, we observed a 10464$\\times$ speedup compared to the original PAMMEDSIL algorithm.","Additionally, we provide a variant to choose the optimal number of clusters directly."],"url":"http://arxiv.org/abs/2309.03751v1"}
{"created":"2023-09-07 14:45:41","title":"PBP: Path-based Trajectory Prediction for Autonomous Driving","abstract":"Trajectory prediction plays a crucial role in the autonomous driving stack by enabling autonomous vehicles to anticipate the motion of surrounding agents. Goal-based prediction models have gained traction in recent years for addressing the multimodal nature of future trajectories. Goal-based prediction models simplify multimodal prediction by first predicting 2D goal locations of agents and then predicting trajectories conditioned on each goal. However, a single 2D goal location serves as a weak inductive bias for predicting the whole trajectory, often leading to poor map compliance, i.e., part of the trajectory going off-road or breaking traffic rules. In this paper, we improve upon goal-based prediction by proposing the Path-based prediction (PBP) approach. PBP predicts a discrete probability distribution over reference paths in the HD map using the path features and predicts trajectories in the path-relative Frenet frame. We applied the PBP trajectory decoder on top of the HiVT scene encoder and report results on the Argoverse dataset. Our experiments show that PBP achieves competitive performance on the standard trajectory prediction metrics, while significantly outperforming state-of-the-art baselines in terms of map compliance.","sentences":["Trajectory prediction plays a crucial role in the autonomous driving stack by enabling autonomous vehicles to anticipate the motion of surrounding agents.","Goal-based prediction models have gained traction in recent years for addressing the multimodal nature of future trajectories.","Goal-based prediction models simplify multimodal prediction by first predicting 2D goal locations of agents and then predicting trajectories conditioned on each goal.","However, a single 2D goal location serves as a weak inductive bias for predicting the whole trajectory, often leading to poor map compliance, i.e., part of the trajectory going off-road or breaking traffic rules.","In this paper, we improve upon goal-based prediction by proposing the Path-based prediction (PBP) approach.","PBP predicts a discrete probability distribution over reference paths in the HD map using the path features and predicts trajectories in the path-relative Frenet frame.","We applied the PBP trajectory decoder on top of the HiVT scene encoder and report results on the Argoverse dataset.","Our experiments show that PBP achieves competitive performance on the standard trajectory prediction metrics, while significantly outperforming state-of-the-art baselines in terms of map compliance."],"url":"http://arxiv.org/abs/2309.03750v1"}
{"created":"2023-09-07 14:43:17","title":"Enhancing Pipeline-Based Conversational Agents with Large Language Models","abstract":"The latest advancements in AI and deep learning have led to a breakthrough in large language model (LLM)-based agents such as GPT-4. However, many commercial conversational agent development tools are pipeline-based and have limitations in holding a human-like conversation. This paper investigates the capabilities of LLMs to enhance pipeline-based conversational agents during two phases: 1) in the design and development phase and 2) during operations. In 1) LLMs can aid in generating training data, extracting entities and synonyms, localization, and persona design. In 2) LLMs can assist in contextualization, intent classification to prevent conversational breakdown and handle out-of-scope questions, auto-correcting utterances, rephrasing responses, formulating disambiguation questions, summarization, and enabling closed question-answering capabilities. We conducted informal experiments with GPT-4 in the private banking domain to demonstrate the scenarios above with a practical example. Companies may be hesitant to replace their pipeline-based agents with LLMs entirely due to privacy concerns and the need for deep integration within their existing ecosystems. A hybrid approach in which LLMs' are integrated into the pipeline-based agents allows them to save time and costs of building and running agents by capitalizing on the capabilities of LLMs while retaining the integration and privacy safeguards of their existing systems.","sentences":["The latest advancements in AI and deep learning have led to a breakthrough in large language model (LLM)-based agents such as GPT-4.","However, many commercial conversational agent development tools are pipeline-based and have limitations in holding a human-like conversation.","This paper investigates the capabilities of LLMs to enhance pipeline-based conversational agents during two phases: 1) in the design and development phase and 2) during operations.","In 1) LLMs can aid in generating training data, extracting entities and synonyms, localization, and persona design.","In 2) LLMs can assist in contextualization, intent classification to prevent conversational breakdown and handle out-of-scope questions, auto-correcting utterances, rephrasing responses, formulating disambiguation questions, summarization, and enabling closed question-answering capabilities.","We conducted informal experiments with GPT-4 in the private banking domain to demonstrate the scenarios above with a practical example.","Companies may be hesitant to replace their pipeline-based agents with LLMs entirely due to privacy concerns and the need for deep integration within their existing ecosystems.","A hybrid approach in which LLMs' are integrated into the pipeline-based agents allows them to save time and costs of building and running agents by capitalizing on the capabilities of LLMs while retaining the integration and privacy safeguards of their existing systems."],"url":"http://arxiv.org/abs/2309.03748v1"}
{"created":"2023-09-07 14:42:35","title":"The Daunting Dilemma with Sentence Encoders: Success on Standard Benchmarks, Failure in Capturing Basic Semantic Properties","abstract":"In this paper, we adopted a retrospective approach to examine and compare five existing popular sentence encoders, i.e., Sentence-BERT, Universal Sentence Encoder (USE), LASER, InferSent, and Doc2vec, in terms of their performance on downstream tasks versus their capability to capture basic semantic properties. Initially, we evaluated all five sentence encoders on the popular SentEval benchmark and found that multiple sentence encoders perform quite well on a variety of popular downstream tasks. However, being unable to find a single winner in all cases, we designed further experiments to gain a deeper understanding of their behavior. Specifically, we proposed four semantic evaluation criteria, i.e., Paraphrasing, Synonym Replacement, Antonym Replacement, and Sentence Jumbling, and evaluated the same five sentence encoders using these criteria. We found that the Sentence-Bert and USE models pass the paraphrasing criterion, with SBERT being the superior between the two. LASER dominates in the case of the synonym replacement criterion. Interestingly, all the sentence encoders failed the antonym replacement and jumbling criteria. These results suggest that although these popular sentence encoders perform quite well on the SentEval benchmark, they still struggle to capture some basic semantic properties, thus, posing a daunting dilemma in NLP research.","sentences":["In this paper, we adopted a retrospective approach to examine and compare five existing popular sentence encoders, i.e., Sentence-BERT, Universal Sentence Encoder (USE), LASER, InferSent, and Doc2vec, in terms of their performance on downstream tasks versus their capability to capture basic semantic properties.","Initially, we evaluated all five sentence encoders on the popular SentEval benchmark and found that multiple sentence encoders perform quite well on a variety of popular downstream tasks.","However, being unable to find a single winner in all cases, we designed further experiments to gain a deeper understanding of their behavior.","Specifically, we proposed four semantic evaluation criteria, i.e., Paraphrasing, Synonym Replacement, Antonym Replacement, and Sentence Jumbling, and evaluated the same five sentence encoders using these criteria.","We found that the Sentence-Bert and USE models pass the paraphrasing criterion, with SBERT being the superior between the two.","LASER dominates in the case of the synonym replacement criterion.","Interestingly, all the sentence encoders failed the antonym replacement and jumbling criteria.","These results suggest that although these popular sentence encoders perform quite well on the SentEval benchmark, they still struggle to capture some basic semantic properties, thus, posing a daunting dilemma in NLP research."],"url":"http://arxiv.org/abs/2309.03747v1"}
{"created":"2023-09-07 14:28:31","title":"Detecting unknown HTTP-based malicious communication behavior via generated adversarial flows and hierarchical traffic features","abstract":"Malicious communication behavior is the network communication behavior generated by malware (bot-net, spyware, etc.) after victim devices are infected. Experienced adversaries often hide malicious information in HTTP traffic to evade detection. However, related detection methods have inadequate generalization ability because they are usually based on artificial feature engineering and outmoded datasets. In this paper, we propose an HTTP-based Malicious Communication traffic Detection Model (HMCD-Model) based on generated adversarial flows and hierarchical traffic features. HMCD-Model consists of two parts. The first is a generation algorithm based on WGAN-GP to generate HTTP-based malicious communication traffic for data enhancement. The second is a hybrid neural network based on CNN and LSTM to extract hierarchical spatial-temporal features of traffic. In addition, we collect and publish a dataset, HMCT-2020, which consists of large-scale malicious and benign traffic during three years (2018-2020). Taking the data in HMCT-2020(18) as the training set and the data in other datasets as the test set, the experimental results show that the HMCD-Model can effectively detect unknown HTTP-based malicious communication traffic. It can reach F1 = 98.66% in the dataset HMCT-2020(19-20), F1 = 90.69% in the public dataset CIC-IDS-2017, and F1 = 83.66% in the real traffic, which is 20+% higher than other representative methods on average. This validates that HMCD-Model has the ability to discover unknown HTTP-based malicious communication behavior.","sentences":["Malicious communication behavior is the network communication behavior generated by malware (bot-net, spyware, etc.)","after victim devices are infected.","Experienced adversaries often hide malicious information in HTTP traffic to evade detection.","However, related detection methods have inadequate generalization ability because they are usually based on artificial feature engineering and outmoded datasets.","In this paper, we propose an HTTP-based Malicious Communication traffic Detection Model (HMCD-Model) based on generated adversarial flows and hierarchical traffic features.","HMCD-Model consists of two parts.","The first is a generation algorithm based on WGAN-GP to generate HTTP-based malicious communication traffic for data enhancement.","The second is a hybrid neural network based on CNN and LSTM to extract hierarchical spatial-temporal features of traffic.","In addition, we collect and publish a dataset, HMCT-2020, which consists of large-scale malicious and benign traffic during three years (2018-2020).","Taking the data in HMCT-2020(18) as the training set and the data in other datasets as the test set, the experimental results show that the HMCD-Model can effectively detect unknown HTTP-based malicious communication traffic.","It can reach F1 = 98.66% in the dataset HMCT-2020(19-20), F1 = 90.69% in the public dataset CIC-IDS-2017, and F1 = 83.66% in the real traffic, which is 20+% higher than other representative methods on average.","This validates that HMCD-Model has the ability to discover unknown HTTP-based malicious communication behavior."],"url":"http://arxiv.org/abs/2309.03739v1"}
{"created":"2023-09-07 14:23:47","title":"ClusterFusion: Leveraging Radar Spatial Features for Radar-Camera 3D Object Detection in Autonomous Vehicles","abstract":"Thanks to the complementary nature of millimeter wave radar and camera, deep learning-based radar-camera 3D object detection methods may reliably produce accurate detections even in low-visibility conditions. This makes them preferable to use in autonomous vehicles' perception systems, especially as the combined cost of both sensors is cheaper than the cost of a lidar. Recent radar-camera methods commonly perform feature-level fusion which often involves projecting the radar points onto the same plane as the image features and fusing the extracted features from both modalities. While performing fusion on the image plane is generally simpler and faster, projecting radar points onto the image plane flattens the depth dimension of the point cloud which might lead to information loss and makes extracting the spatial features of the point cloud harder. We proposed ClusterFusion, an architecture that leverages the local spatial features of the radar point cloud by clustering the point cloud and performing feature extraction directly on the point cloud clusters before projecting the features onto the image plane. ClusterFusion achieved the state-of-the-art performance among all radar-monocular camera methods on the test slice of the nuScenes dataset with 48.7% nuScenes detection score (NDS). We also investigated the performance of different radar feature extraction strategies on point cloud clusters: a handcrafted strategy, a learning-based strategy, and a combination of both, and found that the handcrafted strategy yielded the best performance. The main goal of this work is to explore the use of radar's local spatial and point-wise features by extracting them directly from radar point cloud clusters for a radar-monocular camera 3D object detection method that performs cross-modal feature fusion on the image plane.","sentences":["Thanks to the complementary nature of millimeter wave radar and camera, deep learning-based radar-camera 3D object detection methods may reliably produce accurate detections even in low-visibility conditions.","This makes them preferable to use in autonomous vehicles' perception systems, especially as the combined cost of both sensors is cheaper than the cost of a lidar.","Recent radar-camera methods commonly perform feature-level fusion which often involves projecting the radar points onto the same plane as the image features and fusing the extracted features from both modalities.","While performing fusion on the image plane is generally simpler and faster, projecting radar points onto the image plane flattens the depth dimension of the point cloud which might lead to information loss and makes extracting the spatial features of the point cloud harder.","We proposed ClusterFusion, an architecture that leverages the local spatial features of the radar point cloud by clustering the point cloud and performing feature extraction directly on the point cloud clusters before projecting the features onto the image plane.","ClusterFusion achieved the state-of-the-art performance among all radar-monocular camera methods on the test slice of the nuScenes dataset with 48.7% nuScenes detection score (NDS).","We also investigated the performance of different radar feature extraction strategies on point cloud clusters: a handcrafted strategy, a learning-based strategy, and a combination of both, and found that the handcrafted strategy yielded the best performance.","The main goal of this work is to explore the use of radar's local spatial and point-wise features by extracting them directly from radar point cloud clusters for a radar-monocular camera 3D object detection method that performs cross-modal feature fusion on the image plane."],"url":"http://arxiv.org/abs/2309.03734v1"}
{"created":"2023-09-07 14:17:44","title":"Learning continuous-valued treatment effects through representation balancing","abstract":"Estimating the effects of treatments with an associated dose on an instance's outcome, the \"dose response\", is relevant in a variety of domains, from healthcare to business, economics, and beyond. Such effects, also known as continuous-valued treatment effects, are typically estimated from observational data, which may be subject to dose selection bias. This means that the allocation of doses depends on pre-treatment covariates. Previous studies have shown that conventional machine learning approaches fail to learn accurate individual estimates of dose responses under the presence of dose selection bias. In this work, we propose CBRNet, a causal machine learning approach to estimate an individual dose response from observational data. CBRNet adopts the Neyman-Rubin potential outcome framework and extends the concept of balanced representation learning for overcoming selection bias to continuous-valued treatments. Our work is the first to apply representation balancing in a continuous-valued treatment setting. We evaluate our method on a newly proposed benchmark. Our experiments demonstrate CBRNet's ability to accurately learn treatment effects under selection bias and competitive performance with respect to other state-of-the-art methods.","sentences":["Estimating the effects of treatments with an associated dose on an instance's outcome, the \"dose response\", is relevant in a variety of domains, from healthcare to business, economics, and beyond.","Such effects, also known as continuous-valued treatment effects, are typically estimated from observational data, which may be subject to dose selection bias.","This means that the allocation of doses depends on pre-treatment covariates.","Previous studies have shown that conventional machine learning approaches fail to learn accurate individual estimates of dose responses under the presence of dose selection bias.","In this work, we propose CBRNet, a causal machine learning approach to estimate an individual dose response from observational data.","CBRNet adopts the Neyman-Rubin potential outcome framework and extends the concept of balanced representation learning for overcoming selection bias to continuous-valued treatments.","Our work is the first to apply representation balancing in a continuous-valued treatment setting.","We evaluate our method on a newly proposed benchmark.","Our experiments demonstrate CBRNet's ability to accurately learn treatment effects under selection bias and competitive performance with respect to other state-of-the-art methods."],"url":"http://arxiv.org/abs/2309.03731v1"}
{"created":"2023-09-07 14:14:30","title":"A Causal Perspective on Loan Pricing: Investigating the Impacts of Selection Bias on Identifying Bid-Response Functions","abstract":"In lending, where prices are specific to both customers and products, having a well-functioning personalized pricing policy in place is essential to effective business making. Typically, such a policy must be derived from observational data, which introduces several challenges. While the problem of ``endogeneity'' is prominently studied in the established pricing literature, the problem of selection bias (or, more precisely, bid selection bias) is not. We take a step towards understanding the effects of selection bias by posing pricing as a problem of causal inference. Specifically, we consider the reaction of a customer to price a treatment effect. In our experiments, we simulate varying levels of selection bias on a semi-synthetic dataset on mortgage loan applications in Belgium. We investigate the potential of parametric and nonparametric methods for the identification of individual bid-response functions. Our results illustrate how conventional methods such as logistic regression and neural networks suffer adversely from selection bias. In contrast, we implement state-of-the-art methods from causal machine learning and show their capability to overcome selection bias in pricing data.","sentences":["In lending, where prices are specific to both customers and products, having a well-functioning personalized pricing policy in place is essential to effective business making.","Typically, such a policy must be derived from observational data, which introduces several challenges.","While the problem of ``endogeneity'' is prominently studied in the established pricing literature, the problem of selection bias (or, more precisely, bid selection bias) is not.","We take a step towards understanding the effects of selection bias by posing pricing as a problem of causal inference.","Specifically, we consider the reaction of a customer to price a treatment effect.","In our experiments, we simulate varying levels of selection bias on a semi-synthetic dataset on mortgage loan applications in Belgium.","We investigate the potential of parametric and nonparametric methods for the identification of individual bid-response functions.","Our results illustrate how conventional methods such as logistic regression and neural networks suffer adversely from selection bias.","In contrast, we implement state-of-the-art methods from causal machine learning and show their capability to overcome selection bias in pricing data."],"url":"http://arxiv.org/abs/2309.03730v1"}
{"created":"2023-09-07 14:14:11","title":"Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption","abstract":"Training a generative model with limited number of samples is a challenging task. Current methods primarily rely on few-shot model adaption to train the network. However, in scenarios where data is extremely limited (less than 10), the generative network tends to overfit and suffers from content degradation. To address these problems, we propose a novel phasic content fusing few-shot diffusion model with directional distribution consistency loss, which targets different learning objectives at distinct training stages of the diffusion model. Specifically, we design a phasic training strategy with phasic content fusion to help our model learn content and style information when t is large, and learn local details of target domain when t is small, leading to an improvement in the capture of content, style and local details. Furthermore, we introduce a novel directional distribution consistency loss that ensures the consistency between the generated and source distributions more efficiently and stably than the prior methods, preventing our model from overfitting. Finally, we propose a cross-domain structure guidance strategy that enhances structure consistency during domain adaptation. Theoretical analysis, qualitative and quantitative experiments demonstrate the superiority of our approach in few-shot generative model adaption tasks compared to state-of-the-art methods. The source code is available at: https://github.com/sjtuplayer/few-shot-diffusion.","sentences":["Training a generative model with limited number of samples is a challenging task.","Current methods primarily rely on few-shot model adaption to train the network.","However, in scenarios where data is extremely limited (less than 10), the generative network tends to overfit and suffers from content degradation.","To address these problems, we propose a novel phasic content fusing few-shot diffusion model with directional distribution consistency loss, which targets different learning objectives at distinct training stages of the diffusion model.","Specifically, we design a phasic training strategy with phasic content fusion to help our model learn content and style information when t is large, and learn local details of target domain when t is small, leading to an improvement in the capture of content, style and local details.","Furthermore, we introduce a novel directional distribution consistency loss that ensures the consistency between the generated and source distributions more efficiently and stably than the prior methods, preventing our model from overfitting.","Finally, we propose a cross-domain structure guidance strategy that enhances structure consistency during domain adaptation.","Theoretical analysis, qualitative and quantitative experiments demonstrate the superiority of our approach in few-shot generative model adaption tasks compared to state-of-the-art methods.","The source code is available at: https://github.com/sjtuplayer/few-shot-diffusion."],"url":"http://arxiv.org/abs/2309.03729v1"}
{"created":"2023-09-07 14:13:44","title":"Adjacency Sketches in Adversarial Environments","abstract":"An adjacency sketching or implicit labeling scheme for a family $\\cal F$ of graphs is a method that defines for any $n$ vertex $G \\in \\cal F$ an assignment of labels to each vertex in $G$, so that the labels of two vertices tell you whether or not they are adjacent. The goal is to come up with labeling schemes that use as few bits as possible to represent the labels. By using randomness when assigning labels, it is sometimes possible to produce adjacency sketches with much smaller label sizes, but this comes at the cost of introducing some probability of error. Both deterministic and randomized labeling schemes have been extensively studied, as they have applications for distributed data structures and deeper connections to universal graphs and communication complexity. The main question of interest is which graph families have schemes using short labels, usually $O(\\log n)$ in the deterministic case or constant for randomized sketches.   In this work we consider the resilience of probabilistic adjacency sketches against an adversary making adaptive queries to the labels. This differs from the previously analyzed probabilistic setting which is ``one shot\". We show that in the adaptive adversarial case the size of the labels is tightly related to the maximal degree of the graphs in $\\cal F$. This results in a stronger characterization compared to what is known in the non-adversarial setting. In more detail, we construct sketches that fail with probability $\\varepsilon$ for graphs with maximal degree $d$ using $2d\\log (1/\\varepsilon)$ bit labels and show that this is roughly the best that can be done for any specific graph of maximal degree $d$, e.g.\\ a $d$-ary tree.","sentences":["An adjacency sketching or implicit labeling scheme for a family $\\cal F$ of graphs is a method that defines for any $n$ vertex $G \\in \\cal F$ an assignment of labels to each vertex in $G$, so that the labels of two vertices tell you whether or not they are adjacent.","The goal is to come up with labeling schemes that use as few bits as possible to represent the labels.","By using randomness when assigning labels, it is sometimes possible to produce adjacency sketches with much smaller label sizes, but this comes at the cost of introducing some probability of error.","Both deterministic and randomized labeling schemes have been extensively studied, as they have applications for distributed data structures and deeper connections to universal graphs and communication complexity.","The main question of interest is which graph families have schemes using short labels, usually $O(\\log n)$ in the deterministic case or constant for randomized sketches.   ","In this work we consider the resilience of probabilistic adjacency sketches against an adversary making adaptive queries to the labels.","This differs from the previously analyzed probabilistic setting which is ``one shot\".","We show that in the adaptive adversarial case the size of the labels is tightly related to the maximal degree of the graphs in $\\cal F$.","This results in a stronger characterization compared to what is known in the non-adversarial setting.","In more detail, we construct sketches that fail with probability $\\varepsilon$ for graphs with maximal degree $d$ using $2d\\log (1/\\varepsilon)$ bit labels and show that this is roughly the best that can be done for any specific graph of maximal degree $d$, e.g.\\ a $d$-ary tree."],"url":"http://arxiv.org/abs/2309.03728v1"}
{"created":"2023-09-07 14:12:31","title":"Interpretable Visual Question Answering via Reasoning Supervision","abstract":"Transformer-based architectures have recently demonstrated remarkable performance in the Visual Question Answering (VQA) task. However, such models are likely to disregard crucial visual cues and often rely on multimodal shortcuts and inherent biases of the language modality to predict the correct answer, a phenomenon commonly referred to as lack of visual grounding. In this work, we alleviate this shortcoming through a novel architecture for visual question answering that leverages common sense reasoning as a supervisory signal. Reasoning supervision takes the form of a textual justification of the correct answer, with such annotations being already available on large-scale Visual Common Sense Reasoning (VCR) datasets. The model's visual attention is guided toward important elements of the scene through a similarity loss that aligns the learned attention distributions guided by the question and the correct reasoning. We demonstrate both quantitatively and qualitatively that the proposed approach can boost the model's visual perception capability and lead to performance increase, without requiring training on explicit grounding annotations.","sentences":["Transformer-based architectures have recently demonstrated remarkable performance in the Visual Question Answering (VQA) task.","However, such models are likely to disregard crucial visual cues and often rely on multimodal shortcuts and inherent biases of the language modality to predict the correct answer, a phenomenon commonly referred to as lack of visual grounding.","In this work, we alleviate this shortcoming through a novel architecture for visual question answering that leverages common sense reasoning as a supervisory signal.","Reasoning supervision takes the form of a textual justification of the correct answer, with such annotations being already available on large-scale Visual Common Sense Reasoning (VCR) datasets.","The model's visual attention is guided toward important elements of the scene through a similarity loss that aligns the learned attention distributions guided by the question and the correct reasoning.","We demonstrate both quantitatively and qualitatively that the proposed approach can boost the model's visual perception capability and lead to performance increase, without requiring training on explicit grounding annotations."],"url":"http://arxiv.org/abs/2309.03726v1"}
{"created":"2023-09-07 14:12:04","title":"Immersive Virtual Reality Platform for Robot-Assisted Antenatal Ultrasound Scanning","abstract":"Maternal health remains a pervasive challenge in developing and underdeveloped countries. Inadequate access to basic antenatal Ultrasound (US) examinations, limited resources such as primary health services and infrastructure, and lack of skilled healthcare professionals are the major concerns. To improve the quality of maternal care, robot-assisted antenatal US systems with teleoperable and autonomous capabilities were introduced. However, the existing teleoperation systems rely on standard video stream-based approaches that are constrained by limited immersion and scene awareness. Also, there is no prior work on autonomous antenatal robotic US systems that automate standardized scanning protocols. To that end, this paper introduces a novel Virtual Reality (VR) platform for robotic antenatal ultrasound, which enables sonologists to control a robotic arm over a wired network. The effectiveness of the system is enhanced by providing a reconstructed 3D view of the environment and immersing the user in a VR space. Also, the system facilitates a better understanding of the anatomical surfaces to perform pragmatic scans using 3D models. Further, the proposed robotic system also has autonomous capabilities; under the supervision of the sonologist, it can perform the standard six-step approach for obstetric US scanning recommended by the ISUOG. Using a 23-week fetal phantom, the proposed system was demonstrated to technology and academia experts at MEDICA 2022 as a part of the KUKA Innovation Award. The positive feedback from them supports the feasibility of the system. It also gave an insight into the improvisations to be carried out to make it a clinically viable system.","sentences":["Maternal health remains a pervasive challenge in developing and underdeveloped countries.","Inadequate access to basic antenatal Ultrasound (US) examinations, limited resources such as primary health services and infrastructure, and lack of skilled healthcare professionals are the major concerns.","To improve the quality of maternal care, robot-assisted antenatal US systems with teleoperable and autonomous capabilities were introduced.","However, the existing teleoperation systems rely on standard video stream-based approaches that are constrained by limited immersion and scene awareness.","Also, there is no prior work on autonomous antenatal robotic US systems that automate standardized scanning protocols.","To that end, this paper introduces a novel Virtual Reality (VR) platform for robotic antenatal ultrasound, which enables sonologists to control a robotic arm over a wired network.","The effectiveness of the system is enhanced by providing a reconstructed 3D view of the environment and immersing the user in a VR space.","Also, the system facilitates a better understanding of the anatomical surfaces to perform pragmatic scans using 3D models.","Further, the proposed robotic system also has autonomous capabilities; under the supervision of the sonologist, it can perform the standard six-step approach for obstetric US scanning recommended by the ISUOG.","Using a 23-week fetal phantom, the proposed system was demonstrated to technology and academia experts at MEDICA 2022 as a part of the KUKA Innovation Award.","The positive feedback from them supports the feasibility of the system.","It also gave an insight into the improvisations to be carried out to make it a clinically viable system."],"url":"http://arxiv.org/abs/2309.03725v1"}
{"created":"2023-09-07 14:06:15","title":"HSTF-Model: an HTTP-based Trojan Detection Model via the Hierarchical Spatio-Temporal Features of Traffics","abstract":"HTTP-based Trojan is extremely threatening, and it is difficult to be effectively detected because of its concealment and confusion. Previous detection methods usually are with poor generalization ability due to outdated datasets and reliance on manual feature extraction, which makes these methods always perform well under their private dataset, but poorly or even fail to work in real network environment. In this paper, we propose an HTTP-based Trojan detection model via the Hierarchical Spatio-Temporal Features of traffics (HSTF-Model) based on the formalized description of traffic spatio-temporal behavior from both packet level and flow level. In this model, we employ Convolutional Neural Network (CNN) to extract spatial information and Long Short-Term Memory (LSTM) to extract temporal information. In addition, we present a dataset consisting of Benign and Trojan HTTP Traffic (BTHT-2018). Experimental results show that our model can guarantee high accuracy (the F1 of 98.62%-99.81% and the FPR of 0.34%-0.02% in BTHT-2018). More importantly, our model has a huge advantage over other related methods in generalization ability. HSTF-Model trained with BTHT-2018 can reach the F1 of 93.51% on the public dataset ISCX-2012, which is 20+% better than the best of related machine learning methods.","sentences":["HTTP-based Trojan is extremely threatening, and it is difficult to be effectively detected because of its concealment and confusion.","Previous detection methods usually are with poor generalization ability due to outdated datasets and reliance on manual feature extraction, which makes these methods always perform well under their private dataset, but poorly or even fail to work in real network environment.","In this paper, we propose an HTTP-based Trojan detection model via the Hierarchical Spatio-Temporal Features of traffics (HSTF-Model) based on the formalized description of traffic spatio-temporal behavior from both packet level and flow level.","In this model, we employ Convolutional Neural Network (CNN) to extract spatial information and Long Short-Term Memory (LSTM) to extract temporal information.","In addition, we present a dataset consisting of Benign and Trojan HTTP Traffic (BTHT-2018).","Experimental results show that our model can guarantee high accuracy (the F1 of 98.62%-99.81% and the FPR of 0.34%-0.02% in BTHT-2018).","More importantly, our model has a huge advantage over other related methods in generalization ability.","HSTF-Model trained with BTHT-2018 can reach the F1 of 93.51% on the public dataset ISCX-2012, which is 20+% better than the best of related machine learning methods."],"url":"http://arxiv.org/abs/2309.03724v1"}
{"created":"2023-09-07 13:58:31","title":"A boundary-aware point clustering approach in Euclidean and embedding spaces for roof plane segmentation","abstract":"Roof plane segmentation from airborne LiDAR point clouds is an important technology for 3D building model reconstruction. One of the key issues of plane segmentation is how to design powerful features that can exactly distinguish adjacent planar patches. The quality of point feature directly determines the accuracy of roof plane segmentation. Most of existing approaches use handcrafted features to extract roof planes. However, the abilities of these features are relatively low, especially in boundary area. To solve this problem, we propose a boundary-aware point clustering approach in Euclidean and embedding spaces constructed by a multi-task deep network for roof plane segmentation. We design a three-branch network to predict semantic labels, point offsets and extract deep embedding features. In the first branch, we classify the input data as non-roof, boundary and plane points. In the second branch, we predict point offsets for shifting each point toward its respective instance center. In the third branch, we constrain that points of the same plane instance should have the similar embeddings. We aim to ensure that points of the same plane instance are close as much as possible in both Euclidean and embedding spaces. However, although deep network has strong feature representative ability, it is still hard to accurately distinguish points near plane instance boundary. Therefore, we first group plane points into many clusters in the two spaces, and then we assign the rest boundary points to their closest clusters to generate final complete roof planes. In this way, we can effectively reduce the influence of unreliable boundary points. In addition, we construct a synthetic dataset and a real dataset to train and evaluate our approach. The experiments results show that the proposed approach significantly outperforms the existing state-of-the-art approaches.","sentences":["Roof plane segmentation from airborne LiDAR point clouds is an important technology for 3D building model reconstruction.","One of the key issues of plane segmentation is how to design powerful features that can exactly distinguish adjacent planar patches.","The quality of point feature directly determines the accuracy of roof plane segmentation.","Most of existing approaches use handcrafted features to extract roof planes.","However, the abilities of these features are relatively low, especially in boundary area.","To solve this problem, we propose a boundary-aware point clustering approach in Euclidean and embedding spaces constructed by a multi-task deep network for roof plane segmentation.","We design a three-branch network to predict semantic labels, point offsets and extract deep embedding features.","In the first branch, we classify the input data as non-roof, boundary and plane points.","In the second branch, we predict point offsets for shifting each point toward its respective instance center.","In the third branch, we constrain that points of the same plane instance should have the similar embeddings.","We aim to ensure that points of the same plane instance are close as much as possible in both Euclidean and embedding spaces.","However, although deep network has strong feature representative ability, it is still hard to accurately distinguish points near plane instance boundary.","Therefore, we first group plane points into many clusters in the two spaces, and then we assign the rest boundary points to their closest clusters to generate final complete roof planes.","In this way, we can effectively reduce the influence of unreliable boundary points.","In addition, we construct a synthetic dataset and a real dataset to train and evaluate our approach.","The experiments results show that the proposed approach significantly outperforms the existing state-of-the-art approaches."],"url":"http://arxiv.org/abs/2309.03722v1"}
{"created":"2023-09-07 13:52:20","title":"A Natural Gas Consumption Forecasting System for Continual Learning Scenarios based on Hoeffding Trees with Change Point Detection Mechanism","abstract":"Forecasting natural gas consumption, considering seasonality and trends, is crucial in planning its supply and consumption and optimizing the cost of obtaining it, mainly by industrial entities. However, in times of threats to its supply, it is also a critical element that guarantees the supply of this raw material to meet individual consumers' needs, ensuring society's energy security. This article introduces a novel multistep ahead forecasting of natural gas consumption with change point detection integration for model collection selection with continual learning capabilities using data stream processing. The performance of the forecasting models based on the proposed approach is evaluated in a complex real-world use case of natural gas consumption forecasting. We employed Hoeffding tree predictors as forecasting models and the Pruned Exact Linear Time (PELT) algorithm for the change point detection procedure. The change point detection integration enables selecting a different model collection for successive time frames. Thus, three model collection selection procedures (with and without an error feedback loop) are defined and evaluated for forecasting scenarios with various densities of detected change points. These models were compared with change point agnostic baseline approaches. Our experiments show that fewer change points result in a lower forecasting error regardless of the model collection selection procedure employed. Also, simpler model collection selection procedures omitting forecasting error feedback leads to more robust forecasting models suitable for continual learning tasks.","sentences":["Forecasting natural gas consumption, considering seasonality and trends, is crucial in planning its supply and consumption and optimizing the cost of obtaining it, mainly by industrial entities.","However, in times of threats to its supply, it is also a critical element that guarantees the supply of this raw material to meet individual consumers' needs, ensuring society's energy security.","This article introduces a novel multistep ahead forecasting of natural gas consumption with change point detection integration for model collection selection with continual learning capabilities using data stream processing.","The performance of the forecasting models based on the proposed approach is evaluated in a complex real-world use case of natural gas consumption forecasting.","We employed Hoeffding tree predictors as forecasting models and the Pruned Exact Linear Time (PELT) algorithm for the change point detection procedure.","The change point detection integration enables selecting a different model collection for successive time frames.","Thus, three model collection selection procedures (with and without an error feedback loop) are defined and evaluated for forecasting scenarios with various densities of detected change points.","These models were compared with change point agnostic baseline approaches.","Our experiments show that fewer change points result in a lower forecasting error regardless of the model collection selection procedure employed.","Also, simpler model collection selection procedures omitting forecasting error feedback leads to more robust forecasting models suitable for continual learning tasks."],"url":"http://arxiv.org/abs/2309.03720v1"}
{"created":"2023-09-07 13:42:05","title":"Word segmentation granularity in Korean","abstract":"This paper describes word {segmentation} granularity in Korean language processing. From a word separated by blank space, which is termed an eojeol, to a sequence of morphemes in Korean, there are multiple possible levels of word segmentation granularity in Korean. For specific language processing and corpus annotation tasks, several different granularity levels have been proposed and utilized, because the agglutinative languages including Korean language have a one-to-one mapping between functional morpheme and syntactic category. Thus, we analyze these different granularity levels, presenting the examples of Korean language processing systems for future reference. Interestingly, the granularity by separating only functional morphemes including case markers and verbal endings, and keeping other suffixes for morphological derivation results in the optimal performance for phrase structure parsing. This contradicts previous best practices for Korean language processing, which has been the de facto standard for various applications that require separating all morphemes.","sentences":["This paper describes word {segmentation} granularity in Korean language processing.","From a word separated by blank space, which is termed an eojeol, to a sequence of morphemes in Korean, there are multiple possible levels of word segmentation granularity in Korean.","For specific language processing and corpus annotation tasks, several different granularity levels have been proposed and utilized, because the agglutinative languages including Korean language have a one-to-one mapping between functional morpheme and syntactic category.","Thus, we analyze these different granularity levels, presenting the examples of Korean language processing systems for future reference.","Interestingly, the granularity by separating only functional morphemes including case markers and verbal endings, and keeping other suffixes for morphological derivation results in the optimal performance for phrase structure parsing.","This contradicts previous best practices for Korean language processing, which has been the de facto standard for various applications that require separating all morphemes."],"url":"http://arxiv.org/abs/2309.03713v1"}
{"created":"2023-09-07 13:38:36","title":"A State Representation for Diminishing Rewards","abstract":"A common setting in multitask reinforcement learning (RL) demands that an agent rapidly adapt to various stationary reward functions randomly sampled from a fixed distribution. In such situations, the successor representation (SR) is a popular framework which supports rapid policy evaluation by decoupling a policy's expected discounted, cumulative state occupancies from a specific reward function. However, in the natural world, sequential tasks are rarely independent, and instead reflect shifting priorities based on the availability and subjective perception of rewarding stimuli. Reflecting this disjunction, in this paper we study the phenomenon of diminishing marginal utility and introduce a novel state representation, the $\\lambda$ representation ($\\lambda$R) which, surprisingly, is required for policy evaluation in this setting and which generalizes the SR as well as several other state representations from the literature. We establish the $\\lambda$R's formal properties and examine its normative advantages in the context of machine learning, as well as its usefulness for studying natural behaviors, particularly foraging.","sentences":["A common setting in multitask reinforcement learning (RL) demands that an agent rapidly adapt to various stationary reward functions randomly sampled from a fixed distribution.","In such situations, the successor representation (SR) is a popular framework which supports rapid policy evaluation by decoupling a policy's expected discounted, cumulative state occupancies from a specific reward function.","However, in the natural world, sequential tasks are rarely independent, and instead reflect shifting priorities based on the availability and subjective perception of rewarding stimuli.","Reflecting this disjunction, in this paper we study the phenomenon of diminishing marginal utility and introduce a novel state representation, the $\\lambda$ representation ($\\lambda$R) which, surprisingly, is required for policy evaluation in this setting and which generalizes the SR as well as several other state representations from the literature.","We establish the $\\lambda$R's formal properties and examine its normative advantages in the context of machine learning, as well as its usefulness for studying natural behaviors, particularly foraging."],"url":"http://arxiv.org/abs/2309.03710v1"}
{"created":"2023-09-07 13:36:03","title":"Chat Failures and Troubles: Reasons and Solutions","abstract":"This paper examines some common problems in Human-Robot Interaction (HRI) causing failures and troubles in Chat. A given use case's design decisions start with the suitable robot, the suitable chatting model, identifying common problems that cause failures, identifying potential solutions, and planning continuous improvement. In conclusion, it is recommended to use a closed-loop control algorithm that guides the use of trained Artificial Intelligence (AI) pre-trained models and provides vocabulary filtering, re-train batched models on new datasets, learn online from data streams, and/or use reinforcement learning models to self-update the trained models and reduce errors.","sentences":["This paper examines some common problems in Human-Robot Interaction (HRI) causing failures and troubles in Chat.","A given use case's design decisions start with the suitable robot, the suitable chatting model, identifying common problems that cause failures, identifying potential solutions, and planning continuous improvement.","In conclusion, it is recommended to use a closed-loop control algorithm that guides the use of trained Artificial Intelligence (AI) pre-trained models and provides vocabulary filtering, re-train batched models on new datasets, learn online from data streams, and/or use reinforcement learning models to self-update the trained models and reduce errors."],"url":"http://arxiv.org/abs/2309.03708v1"}
{"created":"2023-09-07 13:31:27","title":"A Food Package Recognition and Sorting System Based on Structured Light and Deep Learning","abstract":"Vision algorithm-based robotic arm grasping system is one of the robotic arm systems that can be applied to a wide range of scenarios. It uses algorithms to automatically identify the location of the target and guide the robotic arm to grasp it, which has more flexible features than the teachable robotic arm grasping system. However, for some food packages, their transparent packages or reflective materials bring challenges to the recognition of vision algorithms, and traditional vision algorithms cannot achieve high accuracy for these packages. In addition, in the process of robotic arm grasping, the positioning on the z-axis height still requires manual setting of parameters, which may cause errors. Based on the above two problems, we designed a sorting system for food packaging using deep learning algorithms and structured light 3D reconstruction technology. Using a pre-trained MASK R-CNN model to recognize the class of the object in the image and get its 2D coordinates, then using structured light 3D reconstruction technique to calculate its 3D coordinates, and finally after the coordinate system conversion to guide the robotic arm for grasping. After testing, it is shown that the method can fully automate the recognition and grasping of different kinds of food packages with high accuracy. Using this method, it can help food manufacturers to reduce production costs and improve production efficiency.","sentences":["Vision algorithm-based robotic arm grasping system is one of the robotic arm systems that can be applied to a wide range of scenarios.","It uses algorithms to automatically identify the location of the target and guide the robotic arm to grasp it, which has more flexible features than the teachable robotic arm grasping system.","However, for some food packages, their transparent packages or reflective materials bring challenges to the recognition of vision algorithms, and traditional vision algorithms cannot achieve high accuracy for these packages.","In addition, in the process of robotic arm grasping, the positioning on the z-axis height still requires manual setting of parameters, which may cause errors.","Based on the above two problems, we designed a sorting system for food packaging using deep learning algorithms and structured light 3D reconstruction technology.","Using a pre-trained MASK R-CNN model to recognize the class of the object in the image and get its 2D coordinates, then using structured light 3D reconstruction technique to calculate its 3D coordinates, and finally after the coordinate system conversion to guide the robotic arm for grasping.","After testing, it is shown that the method can fully automate the recognition and grasping of different kinds of food packages with high accuracy.","Using this method, it can help food manufacturers to reduce production costs and improve production efficiency."],"url":"http://arxiv.org/abs/2309.03704v1"}
{"created":"2023-09-07 13:28:36","title":"DiffDefense: Defending against Adversarial Attacks via Diffusion Models","abstract":"This paper presents a novel reconstruction method that leverages Diffusion Models to protect machine learning classifiers against adversarial attacks, all without requiring any modifications to the classifiers themselves. The susceptibility of machine learning models to minor input perturbations renders them vulnerable to adversarial attacks. While diffusion-based methods are typically disregarded for adversarial defense due to their slow reverse process, this paper demonstrates that our proposed method offers robustness against adversarial threats while preserving clean accuracy, speed, and plug-and-play compatibility. Code at: https://github.com/HondamunigePrasannaSilva/DiffDefence.","sentences":["This paper presents a novel reconstruction method that leverages Diffusion Models to protect machine learning classifiers against adversarial attacks, all without requiring any modifications to the classifiers themselves.","The susceptibility of machine learning models to minor input perturbations renders them vulnerable to adversarial attacks.","While diffusion-based methods are typically disregarded for adversarial defense due to their slow reverse process, this paper demonstrates that our proposed method offers robustness against adversarial threats while preserving clean accuracy, speed, and plug-and-play compatibility.","Code at: https://github.com/HondamunigePrasannaSilva/DiffDefence."],"url":"http://arxiv.org/abs/2309.03702v1"}
{"created":"2023-09-07 13:23:16","title":"User's Reaction Patterns in Online Social Network Communities","abstract":"Several one-fits-all intervention policies were introduced by the Online Social Networks (OSNs) platforms to mitigate potential harms. Nevertheless, some studies showed the limited effectiveness of these approaches. An alternative to this would be a user-centered design of intervention policies. In this context, we study the susceptibility of users to undesired behavior in communities on OSNs. In particular, we explore their reaction to specific events. Our study shows that communities develop different undesired behavior patterns in reaction to specific events. These events can significantly alter the behavior of the community and invert the dynamics of behavior within the whole network. Our findings stress out the importance of understanding the reasons behind the changes in users' reactions and highlights the need of fine-tuning the research to the individual's level. It paves the way towards building better OSNs' intervention strategies centered on the user.","sentences":["Several one-fits-all intervention policies were introduced by the Online Social Networks (OSNs) platforms to mitigate potential harms.","Nevertheless, some studies showed the limited effectiveness of these approaches.","An alternative to this would be a user-centered design of intervention policies.","In this context, we study the susceptibility of users to undesired behavior in communities on OSNs.","In particular, we explore their reaction to specific events.","Our study shows that communities develop different undesired behavior patterns in reaction to specific events.","These events can significantly alter the behavior of the community and invert the dynamics of behavior within the whole network.","Our findings stress out the importance of understanding the reasons behind the changes in users' reactions and highlights the need of fine-tuning the research to the individual's level.","It paves the way towards building better OSNs' intervention strategies centered on the user."],"url":"http://arxiv.org/abs/2309.03701v1"}
{"created":"2023-09-07 13:10:06","title":"Efficient Adaptive Human-Object Interaction Detection with Concept-guided Memory","abstract":"Human Object Interaction (HOI) detection aims to localize and infer the relationships between a human and an object. Arguably, training supervised models for this task from scratch presents challenges due to the performance drop over rare classes and the high computational cost and time required to handle long-tailed distributions of HOIs in complex HOI scenes in realistic settings. This observation motivates us to design an HOI detector that can be trained even with long-tailed labeled data and can leverage existing knowledge from pre-trained models. Inspired by the powerful generalization ability of the large Vision-Language Models (VLM) on classification and retrieval tasks, we propose an efficient Adaptive HOI Detector with Concept-guided Memory (ADA-CM). ADA-CM has two operating modes. The first mode makes it tunable without learning new parameters in a training-free paradigm. Its second mode incorporates an instance-aware adapter mechanism that can further efficiently boost performance if updating a lightweight set of parameters can be afforded. Our proposed method achieves competitive results with state-of-the-art on the HICO-DET and V-COCO datasets with much less training time. Code can be found at https://github.com/ltttpku/ADA-CM.","sentences":["Human Object Interaction (HOI) detection aims to localize and infer the relationships between a human and an object.","Arguably, training supervised models for this task from scratch presents challenges due to the performance drop over rare classes and the high computational cost and time required to handle long-tailed distributions of HOIs in complex HOI scenes in realistic settings.","This observation motivates us to design an HOI detector that can be trained even with long-tailed labeled data and can leverage existing knowledge from pre-trained models.","Inspired by the powerful generalization ability of the large Vision-Language Models (VLM) on classification and retrieval tasks, we propose an efficient Adaptive HOI Detector with Concept-guided Memory (ADA-CM).","ADA-CM has two operating modes.","The first mode makes it tunable without learning new parameters in a training-free paradigm.","Its second mode incorporates an instance-aware adapter mechanism that can further efficiently boost performance if updating a lightweight set of parameters can be afforded.","Our proposed method achieves competitive results with state-of-the-art on the HICO-DET and V-COCO datasets with much less training time.","Code can be found at https://github.com/ltttpku/ADA-CM."],"url":"http://arxiv.org/abs/2309.03696v1"}
